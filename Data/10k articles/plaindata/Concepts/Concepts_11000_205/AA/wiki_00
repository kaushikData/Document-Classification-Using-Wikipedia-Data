{"id": "51647482", "url": "https://en.wikipedia.org/wiki?curid=51647482", "title": "Antonia Maymón", "text": "Antonia Maymón\n\nAntonia Rufina Maymón Giménez (18 July 1881 – 20 December 1959) was a Spanish rationalist pedagogue, militant naturist, anarchist, and feminist who published books on various topics.\n\nAntonia Rufina Maymón Giménez was born on July 18, 1881 in Madrid, Spain to a family from Aragon. She studied to be a teacher in the 'Escuela Normal Femenina' of Zaragoza, a city where she also married professor Lorenzo Lagoon, an anarchist. For her membership in the National Committee against the war in Morocco, she was tried and convicted, along with Teresa Claramunt and Josefa Lopez. In those years, she published her first newspaper articles in various anarchist journals, as 'La Enseñanza Moderna' (Modern Education) and 'Cultura y Acción' (Culture and Action). The couple was exiled to Bordeaux in 1911, but she received amnesty two years later after the death of her husband. Upon her return, she spoke at rallies across the country and worked as a teacher in schools in Barcelona, Sant Feliu de Guíxols, Elda and Beniaján. Driving the naturist movement in Spain, she participated in and presided over congresses on these ideals in Bilbao and Malaga. After the proclamation of the Second Spanish Republic, she moved to Beniaján, where she settled permanently. There, she gave rallies for the Confederación Nacional del Trabajo (CNT), held a school in her own home and developed an intense social work program among the needy. In 1932, she published \"Estudios Racionalistas\", where she exhibited her educational thoughts regarding children's education regardless of social class. At the end of the Spanish Civil War, she was convicted and imprisoned until 1944. Two years later, she was arrested and imprisoned again for almost a year. Her health impaired, she returned to her home Beniaján where she gave private lessons. She died in a local hospital on 20 December 1959.\n\n\n\n"}
{"id": "52385740", "url": "https://en.wikipedia.org/wiki?curid=52385740", "title": "Anviksiki", "text": "Anviksiki\n\nĀnvīkṣikī is a term in Sanskrit denoting roughly the \"science of inquiry\" and it should have been recognized in India as a distinct branch of learning as early as 650 BCE. However, over the centuries its meaning and import have undergone considerable variations. In the earliest period, the term was used to denote Atma-vidya, the science of the soul, in contrast to Adhyatma-vidya, the spiritual science, or Brahma-vidya, the divine science. In Manu Smriti the term Ānvīkṣikī has been used as equivalent to Atma-vidya and it has been described as a branch of the Vedas. In the fourth century BCE, Kautilya in his Arthashastra recognised it as a distinct branch of learning different from Vedas and other disciplines. Kautilya classifies all disciplines into four categories: scripture (the three Vedas, \"trayi\"), agriculture and commerce (\"varta\"), politics and public administration (\"danda-niti\"), and \"Ānvīkṣikī\", the investigative reflective science. The distinction between Atma-vidya and Ānvīkṣikī is that while the former embodied certain dogmatic assertions about the nature of the soul, the latter contained reasons supporting those assertions. Thus Ānvīkṣikī dealt with two subjects, namely, \"atma\", soul, and \"hetu\", theory of reasons. The Samkhya, Yoga, and Lokayata, in so far as they treated of reasons affirming or denying the existence of soul, were included by Kautilya in the Ānvīkṣikī. Of the two subjects studied in the ambit of Ānvīkṣikī, the study of soul later developed and matured into a separate independent study described by the term \"Darsanas\" (meaning philosophy), and the theory of reasons was developed into an independent branch of study referred to as \"Nyaya\" or logic. This bifurcation of Ānvīkṣikī into philosophy and logic must have had its beginning in around 550 BCE with the exposition of the logical side of Ānvīkṣikī by Medhatithi Gautama. However the term Ānvīkṣikī has been in use in the general sense of a science embracing both the science of soul and the theory of reasons.\n\nIt is interesting to observe that when the part of Ānvīkṣikī dealing with the theory of reasons developed into logic, the term Ānvīkṣikī began to be used to denote in this exclusive sense also. For example, Manusamhita has used this term in this special sense of logic. Gautama-dharma-sutra, Ramayana, Mahabharata all have used the term Ānvīkṣikī in this special sense. Ānvīkṣikī in this special sense has also been called by several other names, namely, \"Hetu-sastra\", \"Hetu-vidya\", \"Tarka-sastra\", \"Vada-vidya\", and also by Nyaya-sastra.\n\nThere are a few great teachers who wrote about and taught the doctrines of Ānvīkṣikī in the earliest sense of the term, that is, as a study of both philosophy and logic. Charvaka (c. 650 BCE), known for his materialistic doctrine, Kapila (c. 650–575 BCE), known for his doctrine of matter and soul, Dattatreya (c. 650 BCE), known for his parable of a tree, Punarvasu Atreya (c. 550 BCE), known for his dissertation on senses, Sulabha (c. 550 BCE), a lady ascetic known for canons of speech, Ashtavakra (c. 550–500 BCE) known as a violent debater, and Medhatithi Gautama (c. 550 BCE), known as the founder of Indian logic, are some of these great teachers.\n"}
{"id": "3095397", "url": "https://en.wikipedia.org/wiki?curid=3095397", "title": "Asian pride", "text": "Asian pride\n\nAsian pride is a term utilized internationally but has various origins and meanings.\n\nAsian pride is a broad term that can cover several topics. Within the international relations context, Asian pride can be seen within Asian politics as advancement of Pan-Asianism through heavy criticism of the West.\n\nIn 2014, China referred to India's successful Mars Orbiter Mission of \"Mangalyaan\" as the \"pride of Asia\".\n\nThe pan-ethnicity Asian American concept is not embraced by many Asian Americans in the United States.\n\nIn the United States the term has older roots within the counter culture movement among Asian Americans in the 1960s. During the period there was the Black Power movement, and Asian Americans seeing the impact it had on African-American culture and overall society, rejecting being called \"Oriental\" and the stereotype of the \"yellow peril\" used the term Asian Pride, along with \"yellow power\", to advance empowerment of Asian Americans.\n\nA more modern usage of the term \"Asian Pride\" (also spelled AZN pride) the United States is a positive stance to being Asian American. The term arose from influences of hip hop culture within Asian American communities in the Western United States due to the creation of an Asian American pan-ethnicity (the concept was influenced in the late 20th century due to the influence of publications such as \"Yolk\" and \"Giant Robot\" magazines) that did not specify a specific ethnicity (such as Vietnamese, or Hmong). One manifestation of this was the Got Rice? term, which spun off from the advertising campaign Got Milk?. Younger Asian Americans are finding strength from their Asian identity. Another usage of the term was Greg Pak's \"Asian Pride Porn!\", which used political correct pornography parody to present Asian Americans in a positive light compared to their portrayal in late 20th century mainstream media. Sometimes this arises due to being made to feel different from the prevalent culture surrounding the Asian American youth. \n\nThe term can be used as a negative, being used to describe individuals who prefer only to have Asian American relationships with the exclusion of potential diverse relationships. It has also been criticized as being primarily a marketing gimmick that \"is wide open to model minority accusations.\" \n\nThe term has been adopted by a few Filipino American gang members in Los Angeles, who used the term to assist them in their construction of their ethnic identity. It has also been used as the name of a gang in Florida and Colorado.\n\nThe phrase \"Got Rice?\" is a term that was coined by Asian American youth in the 1990s shortly after the original \"Got Milk?\" advertising campaign for the California Milk Board in 1993. The phrase has since come to be used as a symbol for the cohesiveness of Asian American cultural identity and cultural pride, especially on the Internet. It's usually mentioned close to the Asian Pride slogan.\n\nThe humor is derived from the fact that rice is a staple food in many Asian cultures. The slogan can thus be viewed as an Asian American cultural response to American media and advertising.\n\nThere is also a parody song called \"Got Rice?\", often referred as AZN Pride, which samples 2Pac's \"Changes\". The song dates back to at least 2000, and has been described as being in the raptivist genre; it is also noted as an example of Asian Americans, specifically Chinese Americans, adoption and adaption of Hip Hop culture. It has also been referred to as \"satirically pro-Asian\", for its use of the AZN terminology which is not fully embraced by all Asian Americans. The Fung Brothers released a modification of the song in 2010.\n\nWhile the phrase itself presumably began as Asian American slang, the first notable usage is the T-shirt campaign first started by the Asian American magazine \"Yolk\".\n\nSoon, other Asian American organizations began promoting the phrase and selling similar T-shirt designs. The organizations and their proponents intended for the T-shirts to be a fun way of promoting Asian American cultural heritage:\n\"Political identi-tees don’t all have to be so in-your-face. The Japanese American National Museum (http://www.janm.org/) in L.A.’s Little Tokyo offers an array of kinder, gentler tees commemorating aspects of Japanese-American heritage both fun and serious. Among the most popular designs, a line of adult and baby tees feature the rallying cry of the lactose liberation movement, \"Got Rice?\"\n\nMany in the Asian American community viewed the design as evidence of significant progress for the viability of Asian American culture and identity; whereas before identity may have been enforced on Asians via stereotypes from the dominant society, the \"Got Rice?\" shirts were an attempt by Asian Americans to define their identity and to take back those symbols used to stereotype them.\n\n\n"}
{"id": "50371284", "url": "https://en.wikipedia.org/wiki?curid=50371284", "title": "Assistant Secretary for Terrorist Financing", "text": "Assistant Secretary for Terrorist Financing\n\nThe Assistant Secretary for Terrorist Financing is an office of the United States government within the United States Treasury Department.\n\nThe office of Assistant Secretary for Terrorist Financing is statutorily responsible for \"formulating and coordinating the counter terrorist financing and anti-money laundering efforts of the Department of the Treasury\". It is subordinate to that of the Undersecretary for Terrorism and Financial Crimes and is appointed by the President of the United States, subject to the approval of the U.S. Senate. The office of Assistant Secretary for Terrorist Financing was established by the United States Congress in 2004.\n\n"}
{"id": "13273027", "url": "https://en.wikipedia.org/wiki?curid=13273027", "title": "Boyar (caste)", "text": "Boyar (caste)\n\nThe Boyar are a caste commonly found in Tamil Nadu, Karnataka and Andhra Pradesh India.\n\n"}
{"id": "52864339", "url": "https://en.wikipedia.org/wiki?curid=52864339", "title": "Carpathian boar", "text": "Carpathian boar\n\nThe Carpathian boar (\"Sus scrofa attila\") is a large subspecies of the wild boar native to Romania, Hungary, Northern Iran, Ukraine and the Balkans.\n"}
{"id": "5869", "url": "https://en.wikipedia.org/wiki?curid=5869", "title": "Category theory", "text": "Category theory\n\nCategory theory formalizes mathematical structure and its concepts in terms of a labeled directed graph called a \"category\", whose nodes are called \"objects\", and whose labelled directed edges are called \"arrows\" (or morphisms). A category has two basic properties: the ability to compose the arrows associatively, and the existence of an identity arrow for each object. The language of category theory has been used to formalize concepts of other high-level abstractions such as sets, rings, and groups. Informally, category theory is a general theory of functions.\n\nSeveral terms used in category theory, including the term \"morphism\", are used differently from their uses in the rest of mathematics. In category theory, morphisms obey conditions specific to category theory itself.\n\nSamuel Eilenberg and Saunders Mac Lane introduced the concepts of categories, functors, and natural transformations in 1942–45 in their study of algebraic topology, with the goal of understanding the processes that preserve mathematical structure.\n\nCategory theory has practical applications in programming language theory, for example the usage of monads in functional programming. It may also be used as an axiomatic foundation for mathematics, as an alternative to set theory and other proposed foundations.\n\nCategories represent abstractions of other mathematical concepts.\nMany areas of mathematics can be formalised by category theory as categories. Hence category theory uses abstraction to make it possible to state and prove many intricate and subtle mathematical results in these fields in a much simpler way.\n\nA basic example of a category is the category of sets, where the objects are sets and the arrows are functions from one set to another. However, the objects of a category need not be sets, and the arrows need not be functions. Any way of formalising a mathematical concept such that it meets the basic conditions on the behaviour of objects and arrows is a valid category—and all the results of category theory apply to it.\n\nThe \"arrows\" of category theory are often said to represent a process connecting two objects, or in many cases a \"structure-preserving\" transformation connecting two objects. There are, however, many applications where much more abstract concepts are represented by objects and morphisms. The most important property of the arrows is that they can be \"composed\", in other words, arranged in a sequence to form a new arrow.\n\nCategories now appear in many branches of mathematics, some areas of theoretical computer science where they can correspond to types or to database schemas, and mathematical physics where they can be used to describe vector spaces. Linear algebra can also be expressed in terms of categories of matrices. Probably the first application of category theory outside pure mathematics was the \"metabolism-repair\" model of autonomous living organisms by Robert Rosen.\n\nThe study of categories is an attempt to \"axiomatically\" capture what is commonly found in various classes of related mathematical structures by relating them to the \"structure-preserving functions\" between them. A systematic study of category theory then allows us to prove general results about any of these types of mathematical structures from the axioms of a category.\n\nConsider the following example. The class Grp of groups consists of all objects having a \"group structure\". One can proceed to prove theorems about groups by making logical deductions from the set of axioms defining groups. For example, it is immediately proven from the axioms that the identity element of a group is unique.\n\nInstead of focusing merely on the individual objects (e.g., groups) possessing a given structure, category theory emphasizes the morphisms – the structure-preserving mappings – \"between\" these objects; by studying these morphisms, one is able to learn more about the structure of the objects. In the case of groups, the morphisms are the group homomorphisms. A group homomorphism between two groups \"preserves the group structure\" in a precise sense; informally it is a \"process\" taking one group to another, in a way that carries along information about the structure of the first group into the second group. The study of group homomorphisms then provides a tool for studying general properties of groups and consequences of the group axioms.\n\nA similar type of investigation occurs in many mathematical theories, such as the study of continuous maps (morphisms) between topological spaces in topology (the associated category is called Top), and the study of smooth functions (morphisms) in manifold theory.\n\nNot all categories arise as \"structure preserving (set) functions\", however; the standard example is the category of homotopies between pointed topological spaces.\n\nIf one axiomatizes relations instead of functions, one obtains the theory of allegories.\n\nA category is \"itself\" a type of mathematical structure, so we can look for \"processes\" which preserve this structure in some sense; such a process is called a functor.\n\nDiagram chasing is a visual method of arguing with abstract \"arrows\" joined in diagrams. Functors are represented by arrows between categories, subject to specific defining commutativity conditions. Functors can define (construct) categorical diagrams and sequences (viz. Mitchell, 1965). A functor associates to every object of one category an object of another category, and to every morphism in the first category a morphism in the second.\n\nAs a result, this defines a category \"of categories and functors\" – the objects are categories, and the morphisms (between categories) are functors.\n\nStudying categories and functors is not just studying a class of mathematical structures and the morphisms between them but rather the \"relationships between various classes of mathematical structures\". This fundamental idea first surfaced in algebraic topology. Difficult \"topological\" questions can be translated into \"algebraic\" questions which are often easier to solve. Basic constructions, such as the fundamental group or the fundamental groupoid of a topological space, can be expressed as functors to the category of groupoids in this way, and the concept is pervasive in algebra and its applications.\n\nAbstracting yet again, some diagrammatic and/or sequential constructions are often \"naturally related\" – a vague notion, at first sight. This leads to the clarifying concept of natural transformation, a way to \"map\" one functor to another. Many important constructions in mathematics can be studied in this context. \"Naturality\" is a principle, like general covariance in physics, that cuts deeper than is initially apparent. An arrow between two functors is a natural transformation when it is subject to certain naturality or commutativity conditions.\n\nFunctors and natural transformations ('naturality') are the key concepts in category theory.\n\nA \"category\" \"C\" consists of the following three mathematical entities:\n\nRelations among morphisms (such as ) are often depicted using commutative diagrams, with \"points\" (corners) representing objects and \"arrows\" representing morphisms.\n\nMorphisms can have any of the following properties. A morphism is a:\n\nEvery retraction is an epimorphism, and every section is a monomorphism. Furthermore, the following three statements are equivalent:\n\nFunctors are structure-preserving maps between categories. They can be thought of as morphisms in the category of all (small) categories.\n\nA (covariant) functor \"F\" from a category \"C\" to a category \"D\", written , consists of:\n\nsuch that the following two properties hold:\n\nA contravariant functor is like a covariant functor, except that it \"turns morphisms around\" (\"reverses all the arrows\"). More specifically, every morphism in \"C\" must be assigned to a morphism in \"D\". In other words, a contravariant functor acts as a covariant functor from the opposite category \"C\" to \"D\".\n\nA \"natural transformation\" is a relation between two functors. Functors often describe \"natural constructions\" and natural transformations then describe \"natural homomorphisms\" between two such constructions. Sometimes two quite different constructions yield \"the same\" result; this is expressed by a natural isomorphism between the two functors.\n\nIf \"F\" and \"G\" are (covariant) functors between the categories \"C\" and \"D\", then a natural transformation η from \"F\" to \"G\" associates to every object \"X\" in \"C\" a morphism in \"D\" such that for every morphism in \"C\", we have ; this means that the following diagram is commutative:\n\nThe two functors \"F\" and \"G\" are called \"naturally isomorphic\" if there exists a natural transformation from \"F\" to \"G\" such that η is an isomorphism for every object \"X\" in \"C\".\n\nUsing the language of category theory, many areas of mathematical study can be categorized. Categories include sets, groups and topologies.\n\nEach category is distinguished by properties that all its objects have in common, such as the empty set or the product of two topologies, yet in the definition of a category, objects are considered atomic, i.e., we \"do not know\" whether an object \"A\" is a set, a topology, or any other abstract concept. Hence, the challenge is to define special objects without referring to the internal structure of those objects. To define the empty set without referring to elements, or the product topology without referring to open sets, one can characterize these objects in terms of their relations to other objects, as given by the morphisms of the respective categories. Thus, the task is to find \"universal properties\" that uniquely determine the objects of interest.\n\nNumerous important constructions can be described in a purely categorical way if the \"category limit\" can be developed and dualized to yield the notion of a \"colimit\".\n\nIt is a natural question to ask: under which conditions can two categories be considered \"essentially the same\", in the sense that theorems about one category can readily be transformed into theorems about the other category? The major tool one employs to describe such a situation is called \"equivalence of categories\", which is given by appropriate functors between two categories. Categorical equivalence has found numerous applications in mathematics.\n\nThe definitions of categories and functors provide only the very basics of categorical algebra; additional important topics are listed below. Although there are strong interrelations between all of these topics, the given order can be considered as a guideline for further reading.\n\nMany of the above concepts, especially equivalence of categories, adjoint functor pairs, and functor categories, can be situated into the context of \"higher-dimensional categories\". Briefly, if we consider a morphism between two objects as a \"process taking us from one object to another\", then higher-dimensional categories allow us to profitably generalize this by considering \"higher-dimensional processes\".\n\nFor example, a (strict) 2-category is a category together with \"morphisms between morphisms\", i.e., processes which allow us to transform one morphism into another. We can then \"compose\" these \"bimorphisms\" both horizontally and vertically, and we require a 2-dimensional \"exchange law\" to hold, relating the two composition laws. In this context, the standard example is Cat, the 2-category of all (small) categories, and in this example, bimorphisms of morphisms are simply natural transformations of morphisms in the usual sense. Another basic example is to consider a 2-category with a single object; these are essentially monoidal categories. Bicategories are a weaker notion of 2-dimensional categories in which the composition of morphisms is not strictly associative, but only associative \"up to\" an isomorphism.\n\nThis process can be extended for all natural numbers \"n\", and these are called \"n\"-categories. There is even a notion of \"ω-category\" corresponding to the ordinal number ω.\n\nHigher-dimensional categories are part of the broader mathematical field of higher-dimensional algebra, a concept introduced by Ronald Brown. For a conversational introduction to these ideas, see John Baez, 'A Tale of \"n\"-categories' (1996).\n\nIn 1942–45, Samuel Eilenberg and Saunders Mac Lane introduced categories, functors, and natural transformations as part of their work in topology, especially algebraic topology. Their work was an important part of the transition from intuitive and geometric homology to axiomatic homology theory. Eilenberg and Mac Lane later wrote that their goal was to understand natural transformations. That required defining functors, which required categories.\n\nStanislaw Ulam, and some writing on his behalf, have claimed that related ideas were current in the late 1930s in Poland. Eilenberg was Polish, and studied mathematics in Poland in the 1930s. Category theory is also, in some sense, a continuation of the work of Emmy Noether (one of Mac Lane's teachers) in formalizing abstract processes; Noether realized that understanding a type of mathematical structure requires understanding the processes that preserve that structure. To achieve this understanding, Eilenberg and Mac Lane proposed an axiomatic formalization of the relation between structures and the processes that preserve them.\n\nThe subsequent development of category theory was powered first by the computational needs of homological algebra, and later by the axiomatic needs of algebraic geometry. General category theory, an extension of universal algebra having many new features allowing for semantic flexibility and higher-order logic, came later; it is now applied throughout mathematics.\n\nCertain categories called topoi (singular \"topos\") can even serve as an alternative to axiomatic set theory as a foundation of mathematics. A topos can also be considered as a specific type of category with two additional topos axioms. These foundational applications of category theory have been worked out in fair detail as a basis for, and justification of, constructive mathematics. Topos theory is a form of abstract sheaf theory, with geometric origins, and leads to ideas such as pointless topology.\n\nCategorical logic is now a well-defined field based on type theory for intuitionistic logics, with applications in functional programming and domain theory, where a cartesian closed category is taken as a non-syntactic description of a lambda calculus. At the very least, category theoretic language clarifies what exactly these related areas have in common (in some abstract sense).\n\nCategory theory has been applied in other fields as well. For example, John Baez has shown a link between Feynman diagrams in Physics and monoidal categories. Another application of category theory, more specifically: topos theory, has been made in mathematical music theory, see for example the book \"The Topos of Music, Geometric Logic of Concepts, Theory, and Performance\" by Guerino Mazzola.\n\nMore recent efforts to introduce undergraduates to categories as a foundation for mathematics include those of William Lawvere and Rosebrugh (2003) and Lawvere and Stephen Schanuel (1997) and Mirroslav Yotov (2012).\n\n\n\n"}
{"id": "3323565", "url": "https://en.wikipedia.org/wiki?curid=3323565", "title": "Cauchy stress tensor", "text": "Cauchy stress tensor\n\nIn continuum mechanics, the Cauchy stress tensor formula_1, true stress tensor, or simply called the stress tensor is a second order tensor named after Augustin-Louis Cauchy. The tensor consists of nine components formula_2 that completely define the state of stress at a point inside a material in the deformed state, placement, or configuration. The tensor relates a unit-length direction vector n to the stress vector T across an imaginary surface perpendicular to n:\n\nwhere,\n\nThe SI units of both stress tensor and stress vector are N/m, corresponding to the stress scalar. The unit vector is dimensionless.\n\nThe Cauchy stress tensor obeys the tensor transformation law under a change in the system of coordinates. A graphical representation of this transformation law is the Mohr's circle for stress.\n\nThe Cauchy stress tensor is used for stress analysis of material bodies experiencing small deformations: It is a central concept in the linear theory of elasticity. For large deformations, also called finite deformations, other measures of stress are required, such as the Piola–Kirchhoff stress tensor, the Biot stress tensor, and the Kirchhoff stress tensor.\n\nAccording to the principle of conservation of linear momentum, if the continuum body is in static equilibrium it can be demonstrated that the components of the Cauchy stress tensor in every material point in the body satisfy the equilibrium equations (Cauchy's equations of motion for zero acceleration). At the same time, according to the principle of conservation of angular momentum, equilibrium requires that the summation of moments with respect to an arbitrary point is zero, which leads to the conclusion that the stress tensor is symmetric, thus having only six independent stress components, instead of the original nine.\n\nThere are certain invariants associated with the stress tensor, whose values do not depend upon the coordinate system chosen, or the area element upon which the stress tensor operates. These are the three eigenvalues of the stress tensor, which are called the principal stresses.\n\nThe Euler–Cauchy stress principle states that \"upon any surface (real or imaginary) that divides the body, the action of one part of the body on the other is equivalent (equipollent) to the system of distributed forces and couples on the surface dividing the body\", and it is represented by a field formula_5, called the stress vector, defined on the surface formula_6 and assumed to depend continuously on the surface's unit vector formula_7.\n\nTo formulate the Euler–Cauchy stress principle, consider an imaginary surface formula_6 passing through an internal material point formula_9 dividing the continuous body into two segments, as seen in Figure 2.1a or 2.1b (one may use either the cutting plane diagram or the diagram with the arbitrary volume inside the continuum enclosed by the surface formula_6).\n\nFollowing the classical dynamics of Newton and Euler, the motion of a material body is produced by the action of externally applied forces which are assumed to be of two kinds: surface forces formula_11 and body forces formula_12. Thus, the total force formula_13 applied to a body or to a portion of the body can be expressed as:\n\nOnly surface forces will be discussed in this article as they are relevant to the Cauchy stress tensor.\n\nWhen the body is subjected to external surface forces or \"contact forces\" formula_11, following Euler's equations of motion, internal contact forces and moments are transmitted from point to point in the body, and from one segment to the other through the dividing surface formula_6, due to the mechanical contact of one portion of the continuum onto the other (Figure 2.1a and 2.1b). On an element of area formula_17 containing formula_9, with normal vector formula_7, the force distribution is equipollent to a contact force formula_20 exerted at point P and surface moment formula_21. In particular, the contact force is given by\n\nwhere formula_23 is the \"mean surface traction\".\n\nCauchy’s stress principle asserts that as formula_17 becomes very small and tends to zero the ratio formula_25 becomes formula_26 and the couple stress vector formula_21 vanishes. In specific fields of continuum mechanics the couple stress is assumed not to vanish; however, classical branches of continuum mechanics address non-polar materials which do not consider couple stresses and body moments.\n\nThe resultant vector formula_26 is defined as the \"surface traction\", also called \"stress vector\", \"traction\", or \"traction vector\". given by formula_29 at the point formula_9 associated with a plane with a normal vector formula_7:\n\nThis equation means that the stress vector depends on its location in the body and the orientation of the plane on which it is acting.\n\nThis implies that the balancing action of internal contact forces generates a \"contact force density\" or \"Cauchy traction field\" formula_33 that represents a distribution of internal contact forces throughout the volume of the body in a particular configuration of the body at a given time formula_34. It is not a vector field because it depends not only on the position formula_35 of a particular material point, but also on the local orientation of the surface element as defined by its normal vector formula_7.\n\nDepending on the orientation of the plane under consideration, the stress vector may not necessarily be perpendicular to that plane, \"i.e.\" parallel to formula_7, and can be resolved into two components (Figure 2.1c):\n\n\n\nAccording to the \"Cauchy Postulate\", the stress vector formula_5 remains unchanged for all surfaces passing through the point formula_9 and having the same normal vector formula_7 at formula_9, i.e., having a common tangent at formula_9. This means that the stress vector is a function of the normal vector formula_7 only, and is not influenced by the curvature of the internal surfaces.\n\nA consequence of Cauchy’s postulate is \"Cauchy’s Fundamental Lemma\", also called the \"Cauchy reciprocal theorem\", which states that the stress vectors acting on opposite sides of the same surface are equal in magnitude and opposite in direction. Cauchy’s fundamental lemma is equivalent to Newton's third law of motion of action and reaction, and is expressed as\n\n\"The state of stress at a point\" in the body is then defined by all the stress vectors T associated with all planes (infinite in number) that pass through that point. However, according to \"Cauchy’s fundamental theorem\", also called \"Cauchy’s stress theorem\", merely by knowing the stress vectors on three mutually perpendicular planes, the stress vector on any other plane passing through that point can be found through coordinate transformation equations.\n\nCauchy’s stress theorem states that there exists a second-order tensor field σ(x, t), called the Cauchy stress tensor, independent of n, such that T is a linear function of n:\n\nThis equation implies that the stress vector T at any point \"P\" in a continuum associated with a plane with normal unit vector n can be expressed as a function of the stress vectors on the planes perpendicular to the coordinate axes, \"i.e.\" in terms of the components \"σ\" of the stress tensor σ.\n\nTo prove this expression, consider a tetrahedron with three faces oriented in the coordinate planes, and with an infinitesimal area d\"A\" oriented in an arbitrary direction specified by a normal unit vector n (Figure 2.2). The tetrahedron is formed by slicing the infinitesimal element along an arbitrary plane n. The stress vector on this plane is denoted by T. The stress vectors acting on the faces of the tetrahedron are denoted as T, T, and T, and are by definition the components \"σ\" of the stress tensor σ. This tetrahedron is sometimes called the \"Cauchy tetrahedron\". The equilibrium of forces, \"i.e.\" Euler’s first law of motion (Newton’s second law of motion), gives:\n\nwhere the right-hand-side represents the product of the mass enclosed by the tetrahedron and its acceleration: \"ρ\" is the density, a is the acceleration, and \"h\" is the height of the tetrahedron, considering the plane n as the base. The area of the faces of the tetrahedron perpendicular to the axes can be found by projecting d\"A\" into each face (using the dot product):\n\nand then substituting into the equation to cancel out d\"A\":\n\nTo consider the limiting case as the tetrahedron shrinks to a point, \"h\" must go to 0 (intuitively, the plane n is translated along n toward \"O\"). As a result, the right-hand-side of the equation approaches 0, so\n\nAssuming a material element (Figure 2.3) with planes perpendicular to the coordinate axes of a Cartesian coordinate system, the stress vectors associated with each of the element planes, \"i.e.\" T, T, and T can be decomposed into a normal component and two shear components, \"i.e.\" components in the direction of the three coordinate axes. For the particular case of a surface with normal unit vector oriented in the direction of the \"x\"-axis, denote the normal stress by \"σ\", and the two shear stresses as \"σ\" and \"σ\":\n\nIn index notation this is\n\nThe nine components \"σ\" of the stress vectors are the components of a second-order Cartesian tensor called the \"Cauchy stress tensor\", which completely defines the state of stress at a point and is given by\n\nwhere \"σ\", \"σ\", and \"σ\" are normal stresses, and \"σ\", \"σ\", \"σ\", \"σ\", \"σ\", and \"σ\" are shear stresses. The first index \"i\" indicates that the stress acts on a plane normal to the \"X\" -axis, and the second index \"j\" denotes the direction in which the stress acts (For example, σ implies that the stress is acting on the plane that is normal to the 1 axis i.e.;\"X\" and acts along the 2 axis i.e.;\"X\"). A stress component is positive if it acts in the positive direction of the coordinate axes, and if the plane where it acts has an outward normal vector pointing in the positive coordinate direction.\n\nThus, using the components of the stress tensor\n\nor, equivalently,\n\nAlternatively, in matrix form we have\n\nThe Voigt notation representation of the Cauchy stress tensor takes advantage of the symmetry of the stress tensor to express the stress as a six-dimensional vector of the form:\nThe Voigt notation is used extensively in representing stress–strain relations in solid mechanics and for computational efficiency in numerical structural mechanics software.\n\nIt can be shown that the stress tensor is a contravariant second order tensor, which is a statement of how it transforms under a change of the coordinate system. From an \"x\"-system to an \" x' \"-system, the components \"σ\" in the initial system are transformed into the components \"σ' \" in the new system according to the tensor transformation rule (Figure 2.4):\n\nwhere A is a rotation matrix with components \"a\". In matrix form this is\n\nExpanding the matrix operation, and simplifying terms using the symmetry of the stress tensor, gives\nThe Mohr circle for stress is a graphical representation of this transformation of stresses.\n\nThe magnitude of the normal stress component \"σ\" of any stress vector T acting on an arbitrary plane with normal unit vector n at a given point, in terms of the components \"σ\" of the stress tensor σ, is the dot product of the stress vector and the normal unit vector:\n\nThe magnitude of the shear stress component \"τ\", acting orthogonal to the vector n, can then be found using the Pythagorean theorem:\nwhere\n\nAccording to the principle of conservation of linear momentum, if the continuum body is in static equilibrium it can be demonstrated that the components of the Cauchy stress tensor in every material point in the body satisfy the equilibrium equations.\n\nFor example, for a hydrostatic fluid in equilibrium conditions, the stress tensor takes on the form:\n\nwhere formula_82 is the hydrostatic pressure, and formula_83 is the kronecker delta.\n\nAccording to the principle of conservation of angular momentum, equilibrium requires that the summation of moments with respect to an arbitrary point is zero, which leads to the conclusion that the stress tensor is symmetric, thus having only six independent stress components, instead of the original nine:\n\nHowever, in the presence of couple-stresses, i.e. moments per unit volume, the stress tensor is non-symmetric. This also is the case when the Knudsen number is close to one, formula_85, or the continuum is a non-Newtonian fluid, which can lead to rotationally non-invariant fluids, such as polymers.\n\nAt every point in a stressed body there are at least three planes, called \"principal planes\", with normal vectors formula_86, called \"principal directions\", where the corresponding stress vector is perpendicular to the plane, i.e., parallel or in the same direction as the normal vector formula_86, and where there are no normal shear stresses formula_88. The three stresses normal to these principal planes are called \"principal stresses\".\n\nThe components formula_2 of the stress tensor depend on the orientation of the coordinate system at the point under consideration. However, the stress tensor itself is a physical quantity and as such, it is independent of the coordinate system chosen to represent it. There are certain invariants associated with every tensor which are also independent of the coordinate system. For example, a vector is a simple tensor of rank one. In three dimensions, it has three components. The value of these components will depend on the coordinate system chosen to represent the vector, but the magnitude of the vector is a physical quantity (a scalar) and is independent of the Cartesian coordinate system chosen to represent the vector. Similarly, every second rank tensor (such as the stress and the strain tensors) has three independent invariant quantities associated with it. One set of such invariants are the principal stresses of the stress tensor, which are just the eigenvalues of the stress tensor. Their direction vectors are the principal directions or eigenvectors.\n\nA stress vector parallel to the normal unit vector formula_86 is given by:\n\nwhere formula_92 is a constant of proportionality, and in this particular case corresponds to the magnitudes formula_93 of the normal stress vectors or principal stresses.\n\nKnowing that formula_94 and formula_95, we have\n\nThis is a homogeneous system, i.e. equal to zero, of three linear equations where formula_97 are the unknowns. To obtain a nontrivial (non-zero) solution for formula_97, the determinant matrix of the coefficients must be equal to zero, i.e. the system is singular. Thus,\n\nExpanding the determinant leads to the \"characteristic equation\"\n\nwhere\n\nThe characteristic equation has three real roots formula_102, i.e. not imaginary due to the symmetry of the stress tensor. The formula_103, formula_104 and formula_105, are the principal stresses, functions of the eigenvalues formula_102. The eigenvalues are the roots of the characteristic polynomial. The principal stresses are unique for a given stress tensor. Therefore, from the characteristic equation, the coefficients formula_107, formula_108 and formula_109, called the first, second, and third \"stress invariants\", respectively, always have the same value regardless of the coordinate system's orientation.\n\nFor each eigenvalue, there is a non-trivial solution for formula_97 in the equation formula_111. These solutions are the principal directions or eigenvectors defining the plane where the principal stresses act. The principal stresses and principal directions characterize the stress at a point and are independent of the orientation.\n\nA coordinate system with axes oriented to the principal directions implies that the normal stresses are the principal stresses and the stress tensor is represented by a diagonal matrix:\n\nThe principal stresses can be combined to form the stress invariants, formula_107, formula_108, and formula_109. The first and third invariant are the trace and determinant respectively, of the stress tensor. Thus,\n\nBecause of its simplicity, the principal coordinate system is often useful when considering the state of the elastic medium at a particular point. Principal stresses are often expressed in the following equation for evaluating stresses in the x and y directions or axial and bending stresses on a part. The principal normal stresses can then be used to calculate the von Mises stress and ultimately the safety factor and margin of safety.\n\nUsing just the part of the equation under the square root is equal to the maximum and minimum shear stress for plus and minus. This is shown as:\n\nThe maximum shear stress or maximum principal shear stress is equal to one-half the difference between the largest and smallest principal stresses, and acts on the plane that bisects the angle between the directions of the largest and smallest principal stresses, i.e. the plane of the maximum shear stress is oriented formula_119 from the principal stress planes. The maximum shear stress is expressed as\n\nAssuming formula_121 then\n\nWhen the stress tensor is non zero the normal stress component acting on the plane for the maximum shear stress is non-zero and it is equal to\n\nformula_123\n\nThe stress tensor formula_2 can be expressed as the sum of two other stress tensors:\nSo:\n\nwhere formula_128 is the mean stress given by\n\nPressure (formula_82) is generally defined as negative one-third the trace of the stress tensor minus any stress the divergence of the velocity contributes with, i.e.\n\nwhere formula_92 is a proportionality constant, formula_133 is the divergence operator, formula_134 is the \"k\":th Cartesian coordinate, formula_135 is the velocity and formula_136 is the \"k\":th Cartesian component of formula_135.\n\nThe deviatoric stress tensor can be obtained by subtracting the hydrostatic stress tensor from the Cauchy stress tensor:\n\nAs it is a second order tensor, the stress deviator tensor also has a set of invariants, which can be obtained using the same procedure used to calculate the invariants of the stress tensor. It can be shown that the principal directions of the stress deviator tensor formula_126 are the same as the principal directions of the stress tensor formula_2. Thus, the characteristic equation is\n\nwhere formula_142, formula_143 and formula_144 are the first, second, and third \"deviatoric stress invariants\", respectively. Their values are the same (invariant) regardless of the orientation of the coordinate system chosen. These deviatoric stress invariants can be expressed as a function of the components of formula_126 or its principal values formula_146, formula_147, and formula_148, or alternatively, as a function of formula_2 or its principal values formula_150, formula_151, and formula_152. Thus,\n\nBecause formula_154, the stress deviator tensor is in a state of pure shear.\n\nA quantity called the equivalent stress or von Mises stress is commonly used in solid mechanics. The equivalent stress is defined as\n\nConsidering the principal directions as the coordinate axes, a plane whose normal vector makes equal angles with each of the principal axes (i.e. having direction cosines equal to formula_156) is called an \"octahedral plane\". There are a total of eight octahedral planes (Figure 6). The normal and shear components of the stress tensor on these planes are called \"octahedral normal stress\" formula_157 and \"octahedral shear stress\" formula_158, respectively. Octahedral plane passing through the origin is known as the \"π-plane\" (\"π\" not to be confused with \"mean stress\" denoted by \"π\" in above section) \".\" On the \"π-plane\", formula_159.\n\nKnowing that the stress tensor of point O (Figure 6) in the principal axes is\n\nthe stress vector on an octahedral plane is then given by:\n\nThe normal component of the stress vector at point O associated with the octahedral plane is\n\nwhich is the mean normal stress or hydrostatic stress. This value is the same in all eight octahedral planes.\nThe shear stress on the octahedral plane is then\n\n"}
{"id": "993153", "url": "https://en.wikipedia.org/wiki?curid=993153", "title": "Certainty", "text": "Certainty\n\nCertainty is perfect knowledge that has total security from error, or the mental state of being without doubt.\n\nObjectively defined, certainty is total continuity and validity of all foundational inquiry, to the highest degree of precision. Something is certain only if no skepticism can occur. Philosophy (at least, historical Cartesian philosophy) seeks this state.\n\nPyrrho is credited as being the first Skeptic philosopher.\nThe main principle of Pyrrho's thought is expressed by the word acatalepsia, which denotes the ability to withhold assent from doctrines regarding the truth of things in their own nature; against every statement its contradiction may be advanced with equal justification. Secondly, it is necessary in view of this fact to preserve an attitude of intellectual suspense, or, as Timon expressed it, no assertion can be known to be better than another.\n\nAverroes was a purveyor of certain parts of Aristotelian philosophy. His philosophy was considered controversial in Muslim circles. as well as in West with thinkers like St. Thomas Aquinas who said of Averroes, \"the Arabian commentator as one who had, indeed, perverted the Peripatetic tradition, but whose words, nevertheless, should be treated with respect and consideration.\" Averroes' contribution to epistemology is only noted for the fact that he was one of the first to write on the topic and acted as a comparison for the traditional and definitive works of the Western tradition.\n\nDescartes' \"Meditations on First Philosophy\" is a book in which Descartes first discards all belief in things which are not absolutely certain, and then tries to establish what can be known for sure. Although the phrase \"Cogito, ergo sum\" is often attributed to Descartes' \"Meditations on First Philosophy\", it is actually put forward in his \"Discourse on Method\". Due to the implications of inferring the conclusion within the predicate, however, he changed the argument to \"I think, I exist\"; this then became his first certainty.\n\n\"On Certainty\" is a series of notes made by Ludwig Wittgenstein just prior to his death. The main theme of the work is that context plays a role in epistemology. Wittgenstein asserts an anti-foundationalist message throughout the work: that every claim can be doubted but certainty is possible in a framework. \"The function [propositions] serve in language is to serve as a kind of framework within which empirical propositions can make sense\".\n\nPhysicist Lawrence M. Krauss suggests that the need for identifying degrees of certainty is under-appreciated in various domains, including policy making and the understanding of science. This is because different goals require different degrees of certainty—and politicians are not always aware of (or do not make it clear) how much certainty we are working with.\n\nRudolf Carnap viewed certainty as a matter of degree (\"degrees of certainty\") which could be objectively measured, with degree one being certainty. Bayesian analysis derives degrees of certainty which are interpreted as a measure of subjective psychological belief.\n\nAlternatively, one might use the legal degrees of certainty. These standards of evidence ascend as follows: no credible evidence, some credible evidence, a preponderance of evidence, clear and convincing evidence, beyond reasonable doubt, and beyond any shadow of a doubt (i.e. \"undoubtable\"—recognized as an impossible standard to meet—which serves only to terminate the list).\n\nThe \"foundational crisis of mathematics\" was the early 20th century's term for the search for proper foundations of mathematics.\n\nAfter several schools of the philosophy of mathematics ran into difficulties one after the other in the 20th century, the assumption that mathematics had any foundation that could be stated within mathematics itself began to be heavily challenged.\n\nOne attempt after another to provide unassailable foundations for mathematics was found to suffer from various paradoxes (such as Russell's paradox) and to be inconsistent.\n\nVarious schools of thought were opposing each other. The leading school was that of the formalist approach, of which David Hilbert was the foremost proponent, culminating in what is known as Hilbert's program, which sought to ground mathematics on a small basis of a formal system proved sound by metamathematical finitistic means. The main opponent was the intuitionist school, led by L.E.J. Brouwer, which resolutely discarded formalism as a meaningless game with symbols. The fight was acrimonious. In 1920 Hilbert succeeded in having Brouwer, whom he considered a threat to mathematics, removed from the editorial board of \"Mathematische Annalen\", the leading mathematical journal of the time.\n\nGödel's incompleteness theorems, proved in 1931, showed that essential aspects of Hilbert's program could not be attained. In Gödel's first result he showed how to construct, for any sufficiently powerful and consistent finitely axiomatizable system—such as necessary to axiomatize the elementary theory of arithmetic—a statement that can be shown to be true, but that does not follow from the rules of the system. It thus became clear that the notion of mathematical truth can not be reduced to a purely formal system as envisaged in Hilbert's program. In a next result Gödel showed that such a system was not powerful enough for proving its own consistency, let alone that a simpler system could do the job. This dealt a final blow to the heart of Hilbert's program, the hope that consistency could be established by finitistic means (it was never made clear exactly what axioms were the \"finitistic\" ones, but whatever axiomatic system was being referred to, it was a \"weaker\" system than the system whose consistency it was supposed to prove). Meanwhile, the intuitionistic school had failed to attract adherents among working mathematicians, and floundered due to the difficulties of doing mathematics under the constraint of constructivism.\n\nIn a sense, the crisis has not been resolved, but faded away: most mathematicians either do not work from axiomatic systems, or if they do, do not doubt the consistency of Zermelo–Fraenkel set theory, generally their preferred axiomatic system. In most of mathematics as it is practiced, the various logical paradoxes never played a role anyway, and in those branches in which they do (such as logic and category theory), they may be avoided.\n\n\n"}
{"id": "37777670", "url": "https://en.wikipedia.org/wiki?curid=37777670", "title": "Collective intentionality", "text": "Collective intentionality\n\nIn the philosophy of mind, collective intentionality characterizes the intentionality that occurs when two or more individuals undertake a task together. Examples include two individuals carrying a heavy table up a flight of stairs or dancing a tango.\n\nThis phenomenon is approached from psychological and normative perspectives, among others. Prominent philosophers working in the psychological manner are Raimo Tuomela, Kaarlo Miller, John R. Searle, and Michael E. Bratman. Margaret Gilbert takes a normative approach dealing specifically with group formation. David Velleman is also concerned with how groups are formed, but his account lacks the normative element present in Gilbert.\n\nThe notion that collectives are capable of forming intentions can be found, whether implicitly or explicitly, in literature going back thousands of years. For example, ancient texts such as Plato's \"Republic\" discuss the cooperative determination of laws and social order by the group composed of society as a whole. This theme was later expanded into social contract theory by Enlightenment-era philosophers such as Thomas Hobbes and John Locke. In the 20th century, the likes of Wilfrid Sellars and Anthony Quinton noted the existence of \"We-Intentions\" amid broader discussion of the concept of intentionality, and thus laid the groundwork for the focused philosophical analysis of collective intentionality that began in the late 1980s.\n\nContemporary philosophical discussion of collective intentionality was initiated by Raimo Tuomela and Kaarlo Miller's \"We-Intentions\". In this paper, Tuomela and Miller assert three conditions necessary for a collective intention, highlighting the importance of beliefs among the agents of the group. After citing examples that are commonly accepted as requiring more than one member to participate (carrying a table upstairs, playing tennis, toasting to a friend, conversing, etc.), they state their criteria:\n\nTo illustrate this idea, imagine Anne and Bob intend to carry a table (that is far too heavy for one person to carry) upstairs. In order for this action to qualify as a we-intention, Anne first needs to intend to do her part in carrying the table. Next, Anne needs to believe that carrying the table upstairs is possible, and that Bob intends to do his part in carrying. Finally, Anne needs to believe that Bob also believes that carrying the table upstairs is possible. If all of these conditions are met, then Anne and Bob have collective intentions under Tuomela and Miller's criteria.\n\nJohn Searle's 1990 paper, \"Collective Intentions and Actions\" offers another interpretation of collective action. In contrast to Tuomela and Miller, Searle claims that collective intentionality is a \"primitive phenomenon, which cannot be analyzed as the summation of individual intentional behavior\". He exemplifies the fundamental distinction between \"I-intentions\" and \"We-intentions\" by comparing the hypothetical case of a set of picnickers and a dance troupe. During a rainstorm, each picnicker \"spontaneously\" runs for cover. On the other hand, the members of the dance troupe run for cover \"as part of a preconceived routine\". Searle claims that the picnickers, whose intentions are individually oriented and simply happen to coincide, do not display collective intentionality, while members of the dance troupe do, because they deliberately cooperate with one another.\n\nSearle's rebuttal to Tuomela and Miller's account begins with a counterexample involving a group of business school graduates who intend to pursue their own selfish interests, but believe that by doing so, they will indirectly serve humanity. These young businessmen believe that their fellow graduates will do likewise, but do not actively \"cooperate\" with one another in pursuing their goals. Searle holds that this example fulfills all of Tuomela and Miller's criteria for collective intentionality. However, he claims that collective intentionality does not actually exist in such a situation unless the graduates have organized and formed an explicit \"pact\" with one another to serve humanity through self-interested action.\n\nAlthough a \"we-intention\" is always held by an individual, it must make fundamental reference to a collective formed in conjunction with the other individual(s). For instance, two individuals who, while sharing the labor of hollandaise-sauce production, each believe the proposition \"\"We\" are making hollandaise sauce\", have formed a collective intention. This would not exist if they only held beliefs to the effect of \"\"I\" am stirring\", or \"\"I\" am pouring\". It is thus, Searle claims, that collective intentionality is not reducible to individual intentionality.\n\nMichael Bratman's 1992 paper \"Shared Cooperative Activity\", contends that shared cooperative activity (SCA) can be reduced to \"I-intentions\". In other words, just as an individual can plan to act by him or herself, that same individual can also plan for a group to act. With this in mind, he presents three characteristics of shared cooperative activity:\n\nOne aspect of Bratman's argument that supports these criteria is the idea of meshing subplans. Bratman claims that in a shared cooperative activity, individuals' secondary plans do not need to be the same, but they cannot conflict. For example, consider his example of two people who intend to paint a house together. Let us call these two people Alice and Bill. Suppose Alice wants to paint the house red and Bill wants to paint the house blue. Both are aware that their subplans conflict, and that the other is aware of it as well. Bratman argues that even if Alice and Bill do end up painting the house together, they do not have a shared cooperative activity, because their subplans are in conflict. Furthermore, each participant must also be committed to having subplans that mesh. Without this commitment, participants might disregard others' subplans, leading to a lack of cooperation. However, he additionally claims that their subplans need not be identical. For instance, suppose Alice wants to use an inexpensive paint and Bill wants paint from a specific hardware store. In this case, there is a way that both subplans can achieved: they could buy an inexpensive paint from Bill's store of choice. The details of Bratman's view are as follows:\n\nOne work associated with Bratman is Facundo Alonso's \"Shared Intention, Reliance, and Interpersonal Obligations\". Alonso contends that shared intention is a basis for interpersonal obligation. He begins the paper by asserting characteristics of joint action, which do not include multiple agents acting individually or factors of body movements, but instead are shared or collective intentions to act. Alonso distinguishes the normative theory supplied by Gilbert and the descriptive theory supplied by Bratman. Whereas Bratman focuses on intents, Alonso is also careful to point out Tuomela and Miller's focus on action to describe the roots of joint action. Alonso attempts to compromise both views by taking a path where joint action is not necessarily a normative or descriptive case. He argues for a system built off Bratman's that can take place in a descriptive nature addressed by Margaret Gilbert.\n\nStephen Butterfill offers another response to Bratman's view. He argues that Bratman's account is unable to explain simple interactions between agents. For example, Butterfill states that Bratman cannot explain cooperative actions between very young children, who do not yet have an understanding of other minds.\n\nWhereas Bratman argues for a descriptive account of collective intentionality, other authors have taken a normative approach. Margaret Gilbert in \"Walking Together: A Paradigmatic Social Phenomena\", sets the conditions for people entering, enduring, and exiting acts of collective intentionality. Gilbert asserts that social groups in general can be defined by something as simple as two people walking together. In her analysis the basic conditions for collective intentions that must be satisfied are as follows:\n\nA number of philosophers have responded to the normative theory of Gilbert with papers that consider obligations, promises and commitments. One of these, Christopher McMahon, argues that Gilbert has observed crucial behavioral phenomena involved in acts of collective intentionality, but has misidentified the psychological dynamics underlying these phenomena. Specifically, he holds that the behaviors characterizing collective intentionality arise not from a set of mutual obligations which facilitate a \"right to rebuke\" but from the existence of de facto authority, or some kind of social decision-making process. This de facto authority gives one party a right to partially determine another's intentions.\n\nFacundo M. Alonso sets conditions for how the normative phenomenon of shared intention can arise. Alonso claims that shared intention involves mutual reliance between participants. He further argues for a cognitive requirement that each member publicly intends the joint activity. Thus, Alonso states, \"[R]elations of mutual reliance generate...interpersonal obligations between the participants\". As a result, shared intentions generate normative promises that are enforced by mutual reliance and relevant obligation.\n\nA. S. Roth offers his own modifications to Gilbert's account of intentionality. He, too, relies on a normative notion to explain collective intentions. Rather than obligations, however, Roth is interested in commitments. Roth enumerates four different types of commitment: participatory, contralateral, executive, and ipsilateral commitments. Roth claims that the contralateral commitments are necessary for joint actions to occur, and that they may have a moral component (though not necessarily). This opposes Gilbert's claim that the obligations found in joint activity have no moral component.\n\nChristopher Kutz's work \"Acting Together\" contests the basis for what is considered a group. When speaking of a group, it becomes common to say \"they\" did whatever action the group is seen as doing. However, Kutz explains that each person may have varying levels of involvement in their group or their group efforts. He also questions what obligations each member is considered to have to the group and what binds those individuals to their group. To illustrate his objections, Kutz describes two group types: executive and participatory. An \"executive\" commitment would extend to those members of a group who participate with others of a group only superficially but still carry the name of the group as a title. This includes people working in an office or an assembly line. A \"participatory\" group is involved directly with the process and end results of an action. Each member is assumed to have at least some knowledge of all of the plans and sub-plans for the actions taken by the group. This opens Kutz to a discussion about who, within the group, may be considered responsible for the actions of the group.\n\nJ. David Velleman provides a reaction to Gilbert as well as Searle. Velleman is concerned with explaining how a group is capable of making a decision, or, as he puts it, \"how... several different minds (can) submit themselves to a single making up\". To that end, he picks up Gilbert's notion of the 'pool of wills', that is, \"a single will forged from the wills of different individuals\". However, according to Velleman, Gilbert does not explain how such a thing can be formed. To solve this problem, he turns to a portion of Searle's theory of intentions, namely that an \"intention is a mental representation that causes behavior by representing itself as causing it\".\n\nVelleman explains that, since a representation is capable of causing behavior, and speech acts are a form of representation, it is possible for a speech act to cause a behavior. That is, saying a thing can cause one to do that thing. Thus, a speech act can, in itself, be an intention. This is critical for him to make the case that an agent, having made a decision or an intending speech act, can \"remain decided\". In other words, that agent can continue to intend after the speech act has been accomplished. With this, Velleman shows how an agent can make a decision for a group. If an agent utters a conditional intention, and another agent utters an intention that fulfills the conditions present in the previous utterance, then the second agent has effectively decided the question for the first agent. Thus, a single collective will has been formed from multiple individual wills.\n\nTherefore, Velleman argues that collective intention is not the summation of multiple individual intentions, but rather one shared intention. This is accomplished by perceiving intentions as existing outside the mind of an individual and within a verbal statement. The verbal statements have causal power because of the desire to not speak falsely.\n\nCollective intentionality has also been approached in light of economic theories, including game theory. According to Natalie Gold and Robert Sugden, efforts to define collective intentions as individual intentions and related beliefs (such as those of Tuomela & Miller and Michael Bratman) fail because they allow obviously non-cooperative actions to be counted as cooperative. For example, in many simple games analyzed by game theory, the players are counted as acting jointly when they achieve the Nash equilibrium, even though that equilibrium state is neither optimal nor achieved cooperatively. In the prisoner's dilemma, the Nash equilibrium occurs when each player defects against the other, even though they would both do better if they cooperated.\n\nThe normal game for prisoners' dilemma is shown below:\n\nStandard game theory bases rationality in individual self-interest, and thus predicts that all rational agents will choose \"defect\". However, as Gold and Sugden note, between 40 and 50 percent of participants in prisoner's dilemma trials instead choose \"cooperate\". They argue that by employing we-reasoning, a team of people can intend and act in rational ways to achieve the outcome they, as a group, desire. Members of a group reason with the goal of achieving not \"what is best for me\", but \"what is best for us\". This distinction draws on Searle's claim that \"the notion of a we-intention...implies the notion of \"cooperation\"\". As a result, if each prisoner recognizes that he or she belongs to a team, he or she will conclude that cooperation is in the best interest of the group.\n\n\n\n"}
{"id": "3533357", "url": "https://en.wikipedia.org/wiki?curid=3533357", "title": "Evolution (term)", "text": "Evolution (term)\n\nThe English noun evolution (from Latin \"unfolding, unrolling\") refers to any kind of accumulation of change, or gradual directional change. It is the 3,117th most commonly used word in English.\n\nWhile the term primarily refers to biological evolution, there are various types of chemical evolution and it is also found in economics, historical linguistics, and many other technical fields where systems develop or change gradually over time, e.g. stellar evolution, cultural evolution, the evolution of an idea, metaphysical evolution, spiritual evolution, etc.\n\nThe English term prior to the late 19th century was confined to referring to goal-directed, pre-programmed processes such as embryological development. A pre-programmed task, as in a military maneuver, using this definition, may be termed an \"evolution.\" \n\nThe term \"evolution\" (from its literal meaning of \"unfolding\" of something into its true or explicit form) carries a connotation of gradual improvement or directionality from a beginning to an end point. This contrasts with the more general development, which can indicate change in any direction, or revolution, which implies recurring, periodic change. The term biological devolution is coined as an antonym to \"evolution\", indicating such degeneration or decrease in quality or complexity.\n"}
{"id": "12125107", "url": "https://en.wikipedia.org/wiki?curid=12125107", "title": "FFF system", "text": "FFF system\n\nThe furlong–firkin–fortnight (FFF) system is a humorous system of units based on unusual or impractical measurements. The length unit of the system is the furlong, the mass unit is the mass of a firkin of water, and the time unit is the fortnight. Like the SI or meter–kilogram–second systems, there are derived units for velocity, volume, mass and weight, etc.\n\nWhile the FFF system is not used in practice, it has been used as an example in discussions of the relative merits of different systems of units. Some of the FFF units, notably the microfortnight, have been used jokingly in computer science. Besides having the meaning \"any obscure unit\", the derived unit \"furlongs per fortnight\" has also served frequently in classroom examples of unit conversion and dimensional analysis.\n\nOne microfortnight is equal to 1.2096 seconds. This has become a joke in computer science because in the VMS operating system, the TIMEPROMPTWAIT variable, which holds the time the system will wait for an operator to set the correct date and time at boot if it realizes that the current value is bogus, is set in microfortnights. This is because the computer uses a loop instead of the internal clock which has not been activated yet to run the timer. The documentation notes that \"[t]he time unit of micro-fortnights is approximated as seconds in the implementation.\"\n\n\"Jargon File\" reports that the millifortnight (about 20 minutes) and nanofortnight have been occasionally used.\n\nOne furlong per fortnight is a speed which would be barely noticeable to the naked eye. It converts to: \n\nThe speed of light is 1.8026 furlongs/fortnight (1.8026 megafurlongs/microfortnight). By mass–energy equivalence, 1 firkin is equal to 3.24936676 formula_1 (approx. or ).\n\nIn the FFF system, heat transfer coefficients are conventionally reported as BTU per foot-fathom per degree Fahrenheit per fortnight.\n\nLike the more common furlongs per fortnight, firkins per fortnight have been used with the meaning \"any obscure unit\".\n\n"}
{"id": "35947951", "url": "https://en.wikipedia.org/wiki?curid=35947951", "title": "Foreign and Commonwealth Office migrated archives", "text": "Foreign and Commonwealth Office migrated archives\n\nThe Foreign and Commonwealth Office migrated archives are sensitive and incriminating collections of documents from Britain's former colonial governments that were sent back to the UK (hence \"migrated\") on the eve of decolonisation for storage in the FCO archives to avoid their disclosure and subsequent embarrassment to Her Majesty's Government. A great many similar documents were not repatriated, but instead destroyed.\n\nBetween 1963 and 1994 the migrated archives were stored in Hayes repository; in 1994 they were moved to Hanslope Park, home of Her Majesty's Government Communications Centre, to save on storage costs. In 1967, in 1974, and again in the early 1980s, Kenya asked for them to be released, but the UK refused.\n\nBen Macintyre of the \"Times\" summarised the procedure for declassifying Foreign Office archival material as follows:\n\nIn 2005, two Freedom of Information (FoI) requests were submitted to the FCO by researchers wanting Mau Mau-era government files. The second request was very specific, and did not warrant checking the migrated archives, but the first request should have warranted such a check, yet none was made. More seriously still, in 2006, lawyers for Leigh Day, the legal firm representing former Mau Mau members who were attempting to sue the UK for their torture during the uprising, submitted a court disclosure request for \"a final tranche of documents relating to the suppression of the Mau Mau\" that the government was \"refusing to release\"; the FCO response explicitly denied the existence of this tranche of documents, i.e. the migrated archives, stating that all information they had held had been transferred to The National Archives (TNA). The Treasury Solicitor's response to Leigh Day went even further, stating that not only were all relevant documents with TNA but that they were also in the public domain. It was only the persistence of a handful of FCO officials, notably Edward Inglett, and a witness statement by Oxford professor David Anderson in December 2010 alleging \"systematic withholding by HMG of 1,500 files in 300 boxes taking up 100 linear feet\", that eventually resulted in the migrated archives coming to light in January 2011.\n\nUpon their 'discovery', Foreign Secretary William Hague requested Anthony Cary, a former British High Commissioner to Canada, to conduct an internal review into why the migrated archives had been spotlighted neither by the FoI requests nor by the initial Court Disclosure request. Cary reported the following month, and outlined the background as follows:\n\nThough sympathetic to the FCO, Cary's report nonetheless judged that despite the involvement of relatively junior staff, who had been genuinely ignorant about the contents of the migrated archives, there were more knowledgeable staff who had not been. Conveniently, in 2006, after the FoI requests came in, the fifty-year-old migrated archives were relocated to the section for \"FCO material of between 3 and 30 years old\".\n\nOne excuse offered by the FCO for their failure to consult the files was that the ownership of the papers was confused, that the FCO merely possessed stewardship, thus the archives had been considered \"out of bounds\" for FoI requests (the FCO were not the owners, so they did not have the right to go through the documents). Cary, however, managed to uncover the fact that this was not the case, that there had been \"major exceptions to the general principle that these papers have been considered 'out of bounds'.\" Such an excuse became irrelevant after the 2006 legal request from Leigh Day because \"all\" documents have to be checked when it comes to court cases. \"It was perhaps convenient to [think] that the migrated archives . . . did not need to be consulted for the purposes of FOI requests, while also being conscious of the files as a sort of guilty secret, of uncertain status and in the 'too difficult' tray\", Cary concluded.\n\nAfter making Cary's report public in May 2011, Hague declared his \"intention to release every part of every paper of interest subject only to legal exemptions\"; \"the sooner the better\", urged David Anderson. Edward Inglett conveyed \"sincere and unreserved apologies on the FCO's behalf to both the claimants and the court\", and the Foreign Office promised a \"process of transparency\" and the appointment by Hague of an independent \"colonial files tsar\" to oversee the release as a matter of urgency.\n\nThe search that turned up the \"lost\" documents on Mau Mau revealed a second raft of documents had also been \"lost\" and, hopefully, also therefore awaited discovery. This second batch included files on: the rebellion against British rule in Cyprus; Special Branch; the Colonial Office's use of witch doctors during Mau Mau; Uganda; Nigeria; and Sierra Leone. This second batch were labelled \"Top Secret\" and held separately from the other files \"migrated\" from former colonies, which suggests they contain the most sensitive and incriminating material.\n\nDocuments that were to be left to post-independence governments, known as \"legacy files\", were separated from \"watch files\", which were marked for destruction or repatriation. In Uganda, the process was codenamed Operation Legacy; in Kenya, the process was described as \"a thorough purge\" and directed by colonial Special Branch officers. Africans were forbidden from involvement: only \"a servant of the Kenya government who is a British subject of European descent\" could participate. The watch-file instructions also made clear to leave no trace of their existence to successor governments: \"The legacy files must leave no reference to watch material. Indeed, the very existence of the watch series, though it may be guessed at, should never be revealed.\" If possible, a dummy file was inserted to ensure file and page numbering was uninterrupted by the cull; when too many dummies were needed, they simply removed or destroyed the entire section. In Kenya, instructions insisted that \"emphasis is placed upon destruction\", meaning much of the most shocking material was probably destroyed, and \"the waste should be reduced to ash and the ashes broken up\", so that not even a trace of the destruction was left. Large quantities of files were also \"packed in weighted crates and dumped in very deep and current-free water at maximum practicable distance from the coast\". Malaya's purge was less rigorous, and was facilitated by less experienced officials.\n\nCary's report and the documents initially released had shown that, on 3 December 1963, nine days before Kenya formally declared independence, three wooden packing crates containing 1,500 highly sensitive government files were loaded on to a British United Airways flight bound for Gatwick. On the eve of Kenya's independence, Colonial Secretary Iain Macleod ordered that sensitive colonial-government documentation be destroyed or flown out of the country because its disclosure \"might embarrass Her Majesty's Government\". \"Embarrassment hardly covers it,\" remarked a \"Times\" editorial, noting that \"the covert history of colonial administration in Kenya bears comparison to the methods of torture and summary execution in the French war in Algeria.\" In April 2011, the government officially admitted for the first time not merely to having relevant Mau Mau documents, but that it had a total of 8,800 files from 37 ex-colonies, which it would make public in batches from April 2012 to November 2013. The \"Times\" opined: \"Even given the Foreign and Commonwealth Office's apparent skill in such matters, it is quite a feat to ignore 300 boxes of documents filling 110ft of shelving for almost half a century.\"\n\nDavid Anderson, describing the Mau Mau initial 2011 revelations as just a start, emphasised that other former British domains, including Malaya, Cyprus, and the Gulf States, likewise await a final reckoning, and that colonial personnel and tactics subsequently made their way into the policing of The Troubles. In particular, noted Aileen McColgan, the techniques alleged in 1950s Kenya were refined into what are now known as the \"five techniques\" for use in internment in 1970s Northern Ireland: wall-standing, hooding, subjection to noise, deprivation of sleep, and deprivation of food and drink. She went on to note: \"The European Court of Human Rights ruled in 1977 that Britain had breached Article 3 of the European Convention on Human Rights, which prohibits torture and 'inhuman and degrading treatment', by the use of the five techniques in Northern Ireland. The Prime Minister, Edward Heath, told the Commons in 1972 that the techniques would never again be used 'as an aid to interrogation', a commitment reiterated before the European Court.\"\n\nAfter the Cary investigation, Hague appointed Cambridge's Tony Badger as \"colonial files tsar\" to oversee the review and transfer of the hidden files to the public domain. The Foreign Office duly released a first batch of more than 1,200 records from 12 former colonial territories in April 2012, a portion of some 10,000 files that Britain removed from 37 of its colonies. Badger described the migrated archives episode as \"embarrassing, scandalous. . . . These documents should have been in the public archives in the 1980s. It's long overdue.\" Harvard's Caroline Elkins observed: \"At the time, Britain was in the middle of parallel, massive cover-ups. While the government was besieged publicly with allegations of brutalities in the detention camps and the cover-up of systematised violence—and denying all allegations—it was culling and purging the record. The process—practised in other colonies as well—deliberately sought to remove incriminating evidence. So, too, did it seek to shape the future colonial archive and the realities it would produce.\"\n\nIt is not the first time a UK government department has systematically withheld files regarding British colonial crimes—and not the first time that Professor Anderson has been involved in challenging it. As he and two colleagues noted in 2006 after their reconstruction of the Chuka massacre: \"Evidence on these events should have been released into the Public Record Office in 1984. The file was withheld by the Ministry of Defence and marked for closure until 2038. . . . But not everything on this [Chuka] file has been revealed: and that raises tough questions about the culpability of the British Army in colonial war crimes, official secrecy, and the inadequacies of Freedom of Information legislation\". In 2009, British taxpayers were presented with a £1 million bill after the Ministry of Defence failed to disclose relevant evidence in a 2009 court case involving allegations of murder by British troops in Iraq.\n\nThe \"Guardian\" stated:\nAs the \"Guardian\"'s summary shows, even after the first 2012 release of Tony Badger's review, the FCO continued to deny the existence of documentation on the repeated British subversion of democracy in British Guiana in the 1950s and 1960s, though Richard Drayton, Rhodes Professor of Imperial History at King's College London, said this was simply not credible: \"When Kenyan historians requested documents in the past, they were told repeatedly by the FCO that they had been destroyed, only for the FCO, under judicial pressure, to yield them. It is to be hoped that the FCO will at some point 'discover' its British Guiana archive. Already, under my pressure, having asserted that it held no British Guiana materials whatsoever, the FCO has found one document which describes 'a formidable schedule of documents which the Governor of British Guiana sent home in April 1966 showing how the accountable documents in his custody were disposed of '.\" Elkins agreed that it was \"frankly impossible, given that there were well-established procedures for handling archives at decolonisation by the 1960s. Warning bells should be going off.\" Drayton also noted that the FCO \"refuses to make public the full inventory of the Hanslope Park archive. While we have full confidence in Professor Badger, many historians now wonder if he was not handed an archive which, once again, had been screened and culled.\" Drayton further mused that \"it was almost as if the material now made public had also been screened according to the same criteria applied c. 1960—preventing potential prosecutions, protecting collaborators, and protecting the reputation of Britain.\"\n\nThere was wide agreement that the FCO was still withholding files. Keith Flett said: \"It is likely to be correct that despite William Hague's professed policy of transparency towards the release of government files from the colonial era that far from everything will be released and it will depend on the skills of historians to spot gaps in the record.\" Elkins, who, like Anderson, is an expert witness for the Mau Mau legal action, highlighted the need for caution, and wrote of her involvement with trying to get files out of the foreign office for analysis back at Harvard: \"This process has been anything but straightforward. Despite the legal context, the FCO has culled files, requiring multiple requests for full disclosure, and still files have not been forthcoming.\" Of the April 2012 release, she noted that it \"excludes territories such as Palestine and Rhodesia. The Cyprus files exclude the period of the emergency. The Malaya files cover very little of the contested emergency years. The Kenya documents are a meagre subset of the files released (though culled) in the context of the Mau Mau case. For all 12 colonies covered in today's release, there appears to be a great deal pertaining to finance, tourism, administration and the like. . . . The first release of the 'migrated archives' is, at first glance, lacking in substantive files, particularly for former colonies like Cyprus and Malaya where future lawsuits potentially loom.\"\n\nLaleh Khalili of SOAS declared:\nJournalist Ian Cobain and others suggested that, owing to the nature of the British withdrawal from the Colony of Aden, the incriminating material may, instead of being withheld, actually have been more comprehensively destroyed at the time of decolonisation, rather than migrated.\n\nBadger accepted that historians believed the FCO was \"up to its old tricks again\", and added: \"Given the failure of the Foreign Office to acknowledge the existence of the migrated archives, I understand the legacy of suspicion. It is difficult to overestimate the degree of suspicion.\"\n\nOminously, the \"Guardian\" noted:\n\nDavid Anderson expressed alarm at the Foreign Office refusal to release the index of the files that might enable historians to know what is missing.\n\nRegarding the Mau Mau Uprising, the records included confirmation of \"the extent of the violence inflicted on suspected Mau Mau rebels\" in British detention camps documented in Caroline Elkins' study. Numerous allegations of murder and rape by British military personnel are recorded in the files, including an incident where an African baby was \"burnt to death\", the \"defilement of a young girl\", and a soldier in Royal Irish Fusiliers who killed \"in cold blood two people who had been his captives for over 12 hours\". Baring himself was aware of the \"extreme brutality\" of the sometimes-lethal torture meted out—which included \"most drastic\" beatings, solitary confinement, starvation, castration, whipping, burning, rape, sodomy, and forceful insertion of objects into orifices—but took no action. Baring's inaction was despite the urging of people like Arthur Young, Commissioner of Police for Kenya for less than eight months of 1954 before he resigned in protest, that \"the horror of some of the [camps] should be investigated without delay\". In February 1956, a provincial commissioner in Kenya, \"Monkey\" Johnson, wrote to Attorney General Reginald Manningham-Buller urging him to block any enquiry into the methods used against Mau Mau: \"It would now appear that each and every one of us, from the Governor downwards, may be in danger of removal from public service by a commission of enquiry as a result of enquiries made by the CID.\" The April 2012 release also included detailed accounts of the policy of seizing livestock from Kenyans suspected of supporting Mau Mau rebels.\n\nCommenting on the papers, David Anderson stated that the \"documents were hidden away to protect the guilty\", and \"that the extent of abuse now being revealed is truly disturbing.\" \"Everything that could happen did happen. Allegations about beatings and violence were widespread. Basically you could get away with murder. It was systematic\", Anderson said. An example of this impunity is the case of eight colonial officials accused of having prisoners tortured to death going unpunished even after their crimes were reported to London. Huw Bennett of King's College London, who had worked with Anderson on the Chuka massacre, said in a witness statement to the court that the new documents \"considerably strengthen\" the knowledge that the British Army were \"intimately involved\" with the colonial security forces, whom they knew were \"systematically abusing and torturing detainees in screening centres and detention camps\". In April 2011, lawyers for the Foreign and Commonwealth Office continued to maintain that there was no such policy. As early as November 1952, however, military reports noted that \"[t]he Army has been used for carrying out certain functions that properly belonged to the Police, eg. searching of huts and screening of Africans\", and British soldiers arrested and transferred Mau Mau suspects to camps where they were beaten and tortured until they confessed. Bennett said that \"the British Army retained ultimate operational control over all security forces throughout the Emergency\", and that its military intelligence operation worked \"hand in glove\" with the Kenyan Special Branch \"including in screening and interrogations in centres and detention camps\".\n\nThe Kenyan government sent a letter to Hague insisting that the UK government was legally liable for the atrocities. The Foreign Office, however, reaffirmed its position that it was not, in fact, liable for colonial atrocities, and argued that the documents had not \"disappeared\" as part of a cover up. Nearly ten years before, in late 2002, as the BBC aired a damning documentary on British crimes committed during the rebellion and 6,000 depositions had been taken for the legal case, former district colonial officer John Nottingham had expressed concern that compensation be paid soon, since most victims were in their 80s and would soon pass away. He told the BBC: \"What went on in the Kenya camps and villages was brutal, savage torture. It is time that the mockery of justice that was perpetrated in this country at that time, should be, must be righted. I feel ashamed to have come from a Britain that did what it did here [in Kenya].\"\n\nThirteen boxes of \"top secret\" Kenya files are still missing.\n\nThe release of material in 2011 sparked legal threats from veterans of EOKA, who fought a campaign against the British occupation of Cyprus.\n\nDavid French also utilised the FCO files on Cyprus from the Migrated Archives to prove that the British did not intentionally use a colonial policy of 'Divide and Rule' to flare up Community Tensions on the Island.\n\nThe April 2012 documents suggested that the British never intended peace talks with the rebels to succeed. The UK conspired with its Seychelles colony to deport the troublesome Archbishop Makarios even as the talks took place.\n\nIn 1943, Britain planned to test a \"very virulent\" type of poison gas in what was Bechuanaland (now Botswana). On 6 June 1943, Harold Eddey Priestman, Administrative Secretary to the High Commissioner in South Africa, sent a hand-written letter, marked \"secret and personal\", to Aubrey Denzil Forsyth-Thompson, Resident Commissioner of Bechuanaland, in which he explained: \"Certain types of poison gas are being manufactured in the union [South Africa] on UK account. The UK Ministry of Aircraft Production have now asked that practical trials may be carried out on a considerable scale. . . . We understand this poison gas is a very virulent type. It would therefore be necessary 1) to preclude access to the experimental area for a considerable time after the experiments had ceased. 2) and also to take into consideration any danger of the gas being carried by wind to areas adjacent to the experimental area.\"\n\nThe British looked for an \"isolated area\" within \"reasonable distance\" of an air base, that had a 15-mile buffer zone with no water sources, and that was \"comparatively free from vegetation\". Nowhere suitable could be found in South Africa, but they provisionally settled on somewhere in the Makgadikgadi Pan. Forsyth-Thompson later said that he was unwilling to consider testing in that area because it was surrounded by farms and it would be impossible to maintain secrecy. Under the codename of FORENSIC, air-launched trials were envisaged, but the approach of the rainy season prevented testing from going ahead. There is currently no evidence FORENSIC was actually executed.\n\nAlthough it was never deployed, Britain stockpiled poison gas because of fears of its possible use by Germany.\n\n\n\n"}
{"id": "11157", "url": "https://en.wikipedia.org/wiki?curid=11157", "title": "Fudge (role-playing game system)", "text": "Fudge (role-playing game system)\n\nFudge is a generic role-playing game system for use in freeform role-playing games. The name \"FUDGE\" was once an acronym for \"Freeform Universal Donated\" (later, \"Do-it-yourself\") \"Gaming Engine\" and, though the acronym has since been dropped, that phrase remains a good summation of the game's design goals. \"Fudge\" has been nominated for an Origins Award for \"Best Role-Playing Game System\" for the \"Deryni Role-Playing Game\".\n\nRather than being a rigidly pre-defined set of rules like \"d20 System\" or \"GURPS\", \"Fudge\" offers a customizable toolkit for building the users' own specialized role-playing game system. Such things as what attributes and skills will define characters are left to be determined by the Game Master and players, and several different optional systems for resolving actions and conflicts are offered. \"Fudge\" is not tied to any particular genre or setting and world builders are encouraged to invent appropriate attributes and rules tailored to the campaign.\n\nThe project that would lead to \"Fudge\" was first proposed by Steffan O'Sullivan in November 1992 on the rec.games.design newsgroup, and over the following months that online community would contribute to the directed project. One of the earliest stipulations of O'Sullivan was that the basic system would always remain free to the public over the internet, and the PDF of the 1995 version still is. The 1995 version of \"Fudge\" is available under a non-commercial licence.\n\nGrey Ghost Press, with the endorsement of Steffan O'Sullivan, publishes an expanded form of the \"Fudge\" system. There have been three Grey Ghost Press editions, the most current being the \"Fudge 10th Anniversary Edition\", which includes several suggested rules systems for common RPG elements and an example basic fantasy \"build\" of the game.\n\nIn March 2004, Grey Ghost Press acquired the copyright of \"Fudge\", and on April 6, 2005, they released a version of \"Fudge\" under the Open Game License.\n\nThe OGL license has allowed the \"FATE role-playing game system\" to build on \"Fudge\" as its underlying mechanic.\n\nIn 1999 \"Pyramid\" magazine named \"Fudge\" as one of \"The Millennium's Most Underrated Games\". Editor Scott Haring stated that \"\"Fudge\" is an extremely flexible, rules-light system. It works great, and everybody who plays it, loves it. Why isn't it more popular? I dunno.\"\n\nAt the time \"Fudge\" was conceived, it was stylish to give role-playing games acronyms for names (for instance, \"GURPS\" and \"TWERPS\") and originally the usenet design project referred to the game as \"SLUG\", for \"Simple Laid-back Universal Game\". However, this was soon changed to \"FUDGE\" for \"Free-form Universal Donated Gaming Engine\", but also because the word invoked connotations of an easy to make source of fun. This again was changed when Grey Ghost Press released their 1995 hardcopy version of the game, to \"Free-form Universal Do-it-yourself Gaming Engine\".\n\nWith the publication of the Expanded Edition in 2000, the fad for acronym-based names had long since faded, and the writer and the publisher both felt that the forced acronym had become irrelevant. The game has been referred to officially as just \"Fudge\" ever since, though fans often still refer to it in the old manner as \"FUDGE\".\n\nIn \"Fudge\", character Traits such as Attributes and Skills, are rated on a seven-level, ascending adjective scale: \"Terrible, Poor, Mediocre, Fair, Good, Great,\" and \"Superb.\"\n\n\"Fudge\" characters can also have Gifts and Faults, which are positive and negative traits that do not fit into the adjective scale.\n\n\"Fudge\" uses customized \"\"Fudge\" dice\" which have an equal number of plus, minus and blank sides. A number of these dice are rolled, usually four at a time (\"4dF\" in Fudge dice notation), and for every plus side that comes up the result of using the Trait is considered one step higher (e.g. from \"Fair\" to \"Good\") and for every minus side that comes up the result is considered one step lower. The goal is to match or surpass the difficulty level, also on the adjective scale, of the test. Thus, a \"Good\" attribute is considered to be \"Great\" if the player were to roll two plus sides, one minus side, and one blank—the minus side cancels out one of the plus sides and the remaining plus side raises the result by one step. The same \"Good\" attribute would be considered \"Poor\" if you were to roll three minus sides and one blank. The same dice roll can be achieved with six-sided dice, treating a 1 or 2 as [−], a 3-4 as [ ] and a 5-6 as [+].\n\nThere are also several alternative dice systems available that use ten-sided dice, coins, or playing cards.\n\nThe rules of \"Fudge\" are highly customizable and can be adjusted for the level of simplicity or complexity desired by the Game Master and Players. Overall, the system is designed to encourage role-playing over strict adherence to an arbitrary set of rules. In fact, the main \"Fudge\" documents encourage players to \"Just Fudge It\"; that is, to focus on the story being created rather than on the game rules. For example, one character creation method encourages players to first write prose descriptions of their characters and then translate those into \"Fudge\" Traits.\n\n"}
{"id": "11556", "url": "https://en.wikipedia.org/wiki?curid=11556", "title": "Fundamental theorem of arithmetic", "text": "Fundamental theorem of arithmetic\n\nIn number theory, the fundamental theorem of arithmetic, also called the unique factorization theorem or the unique-prime-factorization theorem, states that every integer greater than 1 either is a prime number itself or can be represented as the product of prime numbers and that, moreover, this representation is unique, up to (except for) the order of the factors. For example,\n\nThe theorem says two things for this example: first, that 1200 be represented as a product of primes, and second, that no matter how this is done, there will always be exactly four 2s, one 3, two 5s, and no other primes in the product.\n\nThe requirement that the factors be prime is necessary: factorizations containing composite numbers may not be unique (e.g., 12 = 2 × 6 = 3 × 4).\n\nThis theorem is one of the main reasons why 1 is not considered a prime number: if 1 were prime, then factorization into primes would not be unique; for example, \n\nBook VII, propositions 30, 31 and 32, and Book IX, proposition 14 of Euclid's \"Elements\" are essentially the statement and proof of the fundamental theorem.\n\n(In modern terminology: if a prime \"p\" divides the product \"ab\", then \"p\" divides either \"a\" or \"b\" or both.) Proposition 30 is referred to as Euclid's lemma, and it is the key in the proof of the fundamental theorem of arithmetic.\n\n(In modern terminology: every integer greater than one is divided evenly by some prime number.) Proposition 31 is proved directly by infinite descent.\n\nProposition 32 is derived from proposition 31, and proves that the decomposition is possible.\n\n(In modern terminology: a least common multiple of several prime numbers is not a multiple of any other prime number.) Book IX, proposition 14 is derived from Book VII, proposition 30, and proves partially that the decomposition is unique – a point critically noted by André Weil. Indeed, in this proposition the exponents are all equal to one, so nothing is said for the general case.\n\nArticle 16 of Gauss' \"Disquisitiones Arithmeticae\" is an early modern statement and proof employing modular arithmetic.\n\nEvery positive integer \"n\" > 1 can be represented in exactly one way as a product of prime powers:\nwhere \"p\" < \"p\" < ... < \"p\" are primes and the \"n\" are positive integers. This representation is commonly extended to all positive integers, including 1, by the convention that the empty product is equal to 1 (the empty product corresponds to \"k\" = 0).\n\nThis representation is called the canonical representation of \"n\", or the standard form of \"n\". For example,\n\nNote that factors \"p\" = 1 may be inserted without changing the value of \"n\" (e.g., 1000 = 2×3×5).<br>In fact, any positive integer can be uniquely represented as an infinite product taken over all the positive prime numbers:\nwhere a finite number of the \"n\" are positive integers, and the rest are zero. Allowing negative exponents provides a canonical form for positive rational numbers.\n\nThe canonical representations of the product, greatest common divisor (GCD), and least common multiple (LCM) of two numbers \"a\" and \"b\" can be expressed simply in terms of the canonical representations of \"a\" and \"b\" themselves:\n\nHowever, integer factorization, especially of large numbers, is much more difficult than computing products, GCDs, or LCMs. So these formulas have limited use in practice.\n\nMany arithmetic functions are defined using the canonical representation. In particular, the values of additive and multiplicative functions are determined by their values on the powers of prime numbers.\n\nThe proof uses Euclid's lemma (\"Elements\" VII, 30): if a prime \"p\" divides the product of two natural numbers \"a\" and \"b\", then \"p\" divides \"a\" or \"p\" divides \"b\".\n\nWe need to show that every integer greater than 1 is either prime or a product of primes.\nFor the base case, note that 2 is prime.\nBy strong induction: assume true for all numbers between 1 and \"n\". If \"n\" is prime, there is nothing more to prove. Otherwise, there are integers \"a\" and \"b\", where \"n\" = \"ab\" and 1 < \"a\" ≤ \"b\" < \"n\".\nBy the induction hypothesis,\n\"a\" = \"p\"\"p\"...\"p\"\nand\n\"b\" = \"q\"\"q\"...\"q\" are products of primes. But then\n\"n\" = \"ab\" = \"p\"\"p\"...\"p\"\"q\"\"q\"...\"q\" is a product of primes.\n\nAssume that \"s\" > 1 is the product of prime numbers in two different ways:\n\nWe must show \"m\" = \"n\" and that the \"q\" are a rearrangement of the \"p\".\n\nAs \"p\" divides \"s\", Euclid's lemma implies that \"p\" divides one of the \"q\"; relabeling the \"q\" if necessary, say that \"p\" divides \"q\". But \"q\" is prime, so its only divisors are itself and 1. Therefore, \"p\" = \"q\", so that\n\nReasoning the same way, \"p\" must equal one of the remaining \"q\". Relabeling again if necessary, say \"p\" = \"q\". Then\n\nThis can be done for each of the \"m\" \"p\"'s, showing that \"m\" ≤ \"n\" and every \"p\" is a \"q\". Applying the same argument with the formula_7's and formula_8's reversed shows \"n\" ≤ \"m\" (hence \"m\" = \"n\") and every \"q\" is a \"p\".\n\nThe fundamental theorem of arithmetic can also be proved without using Euclid's lemma, as follows:\n\nAssume that \"s\" > 1 is the smallest positive integer which is the product of prime numbers in two different ways. If \"s\" were prime then it would factor uniquely as itself, so there must be at least two primes in each factorization of \"s\":\n\nIf any \"p\" = \"q\" then, by cancellation, \"s\"/\"p\" = \"s\"/\"q\" would be another positive integer, different from s, which is greater than 1 and also has two distinct factorizations. But \"s\"/\"p\" is smaller than \"s\", meaning \"s\" would not actually be the smallest such integer. Therefore every \"p\" must be distinct from every \"q\".\n\nWithout loss of generality, take \"p\" < \"q\" (if this is not already the case, switch the \"p\" and \"q\" designations.) Consider\n\nand note that 1 < \"q\" ≤ \"t\" < \"s\". Therefore \"t\" must have a unique prime factorization. By rearrangement we see,\n\nHere \"u\" = ((\"p\" ... \"p\") - (\"q\" ... \"q\")) is positive, for if it were negative or zero then so would be its product with \"p\", but that product equals \"t\" which is positive. So \"u\" is either 1 or factors into primes. In either case, \"t\" = \"p\"\"u\" yields a prime factorization of \"t\", which we know to be unique, so \"p\" appears in the prime factorization of \"t\".\n\nIf (\"q\" - \"p\") equaled 1 then the prime factorization of \"t\" would be all \"q\"'s, which would preclude \"p\" from appearing. Thus (\"q\" - \"p\") is not 1, but is positive, so it factors into primes: (\"q\" - \"p\") = (\"r\" ... \"r\"). This yields a prime factorization of\n\nwhich we know is unique. Now, \"p\" appears in the prime factorization of \"t\", and it is not equal to any \"q\", so it must be one of the \"r\"'s. That means \"p\" is a factor of (\"q\" - \"p\"), so there exists a positive integer \"k\" such that \"p\"\"k\" = (\"q\" - \"p\"), and therefore\n\nBut that means \"q\" has a proper factorization, so it is not a prime number. This contradiction shows that \"s\" does not actually have two different prime factorizations. As a result, there is no smallest positive integer with multiple prime factorizations, hence all positive integers greater than 1 factor uniquely into primes.\n\nThe first generalization of the theorem is found in Gauss's second monograph (1832) on biquadratic reciprocity. This paper introduced what is now called the ring of Gaussian integers, the set of all complex numbers \"a\" + \"bi\" where \"a\" and \"b\" are integers. It is now denoted by formula_14 He showed that this ring has the four units ±1 and ±\"i\", that the non-zero, non-unit numbers fall into two classes, primes and composites, and that (except for order), the composites have unique factorization as a product of primes.\n\nSimilarly, in 1844 while working on cubic reciprocity, Eisenstein introduced the ring formula_15, where formula_16   formula_17 is a cube root of unity. This is the ring of Eisenstein integers, and he proved it has the six units formula_18 and that it has unique factorization.\n\nHowever, it was also discovered that unique factorization does not always hold. An example is given by formula_19. In this ring one has\n\nExamples like this caused the notion of \"prime\" to be modified. In formula_19 it can be proven that if any of the factors above can be represented as a product, e.g., 2 = \"ab\", then one of \"a\" or \"b\" must be a unit. This is the traditional definition of \"prime\". It can also be proven that none of these factors obeys Euclid's lemma; e.g.,\n2 divides neither (1 + ) nor (1 − ) even though it divides their product 6. In algebraic number theory 2 is called irreducible in formula_19 (only divisible by itself or a unit) but not prime in formula_19 (if it divides a product it must divide one of the factors). The mention of formula_19 is required because 2 is prime and irreducible in formula_25 Using these definitions it can be proven that in any ring a prime must be irreducible. Euclid's classical lemma can be rephrased as \"in the ring of integers formula_26 every irreducible is prime\". This is also true in formula_27 and formula_28 but not in formula_29\n\nThe rings in which factorization into irreducibles is essentially unique are called unique factorization domains. Important examples are polynomial rings over the integers or over a field, Euclidean domains and principal ideal domains.\n\nIn 1843 Kummer introduced the concept of ideal number, which was developed further by Dedekind (1876) into the modern theory of ideals, special subsets of rings. Multiplication is defined for ideals, and the rings in which they have unique factorization are called Dedekind domains.\n\nThere is a version of unique factorization for ordinals, though it requires some additional conditions to ensure uniqueness.\n\n\nThe \"Disquisitiones Arithmeticae\" has been translated from Latin into English and German. The German edition includes all of his papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes.\n\nThe two monographs Gauss published on biquadratic reciprocity have consecutively numbered sections: the first contains §§ 1–23 and the second §§ 24–76. Footnotes referencing these are of the form \"Gauss, BQ, § \"n\"\". Footnotes referencing the \"Disquisitiones Arithmeticae\" are of the form \"Gauss, DA, Art. \"n\"\".\n\nThese are in Gauss's \"Werke\", Vol II, pp. 65–92 and 93–148; German translations are pp. 511–533 and 534–586 of the German edition of the \"Disquisitiones\".\n\n"}
{"id": "1411958", "url": "https://en.wikipedia.org/wiki?curid=1411958", "title": "Handsel Monday", "text": "Handsel Monday\n\nIn Scotland, the first Monday after New Year's Day was traditionally known as Hansel Monday, or Handsel Monday, and gifts () were given at this time.\n\nAmong the rural population of Scotland, \"Auld Hansel Monday\", is traditionally celebrated on the first Monday after January 12. This custom reflects a reluctance to switch from the old (Julian) style calendar to the new (Gregorian) calendar.\n\nThe word \"handsel\" originates from old Saxon word which means “to deliver into the hand”. It refers to small tips and gifts of money given as a token of good luck, particularly at the beginning of something; the modern house-warming gift would be a good example. An 1825 glossary marks Handsel Monday as an occasion \"when it is customary to make children and servants a present\". On this day, tips of small gifts were expected by servants, as well as by the postman, the deliverers of newspapers, scavengers, and all persons who wait upon the house.\n\nIn this respect it is somewhat similar to Boxing Day, which eventually supplanted it. If the handsel was a physical object rather than money, tradition said that the object could not be sharp, or it would \"cut\" the relationship between the giver and the recipient. The day is known in Scottish Gaelic as (drained Monday).\n\nThe custom was also known as “handseling a purse”. A new purse would not be given to anyone without placing money in it for good luck. Money received during Handsel Monday is supposed to insure monetary luck all for the rest of the year.\n\n"}
{"id": "32789022", "url": "https://en.wikipedia.org/wiki?curid=32789022", "title": "Houston Galveston Institute", "text": "Houston Galveston Institute\n\nThe Houston Galveston Institute is a non-profit organization that offers a method of collaborative counseling and postmodern therapy to individuals, families and communities of all socioeconomic backgrounds. The Institute is strongly associated with collaborative language systems (or Collaborative Therapy), a type of postmodern therapy that works with clients within a cooperative partnership that holds their expertise in high regard, and that encourages them to access their own natural resources to develop solutions to their problems. The Houston Galveston Institute is a sponsor of the International Journal of Collaborative Practices.\n\nThe beginnings of the Houston Galveston Institute date back to the 1950s at the University of Texas Medical Branch in Galveston, Texas with the federally funded family therapy project to research the Multiple Impact Theory. In 1978, the Galveston Family Institute was established by Harlene Anderson, Ph.D., Paul Dell, Ph.D., Harold Goolishian, Ph.D. and George Pulliam, M.S.W. to meet the demands of mental health professionals seeking to increase their understanding of families and further develop their skills in systems-oriented therapy with individuals, couples, families and groups. From this group, the ideas of Collaborative Language System Theory emerged. The institute officially became the Houston Galveston Institute in the 1990s when the project expanded beyond Galveston. Other contributors are Diane Gehart, Sue Levin, Diana Carleton, Lynn Hoffmann, Tom Andersen, Vivien Burr, John Cromby, Kenneth Gergen, Mary Gergen, Lois Holzman, Imelda McCarthy, Susan McDaniel, Sheila McNamee, Robert Neimeyer, David Nightingale, Peggy Penn, Sallyann Roth, Jaakko Seikkula, John Shotter, Lois Shawver, and Michael White.\n\nThis type of approach formed at Houston Galveston Institute takes the unique stance that “problems are not solved, but dissolved in language.” Collaborative therapy is now recognized as one of the current schools of family therapy and is included in graduate school textbooks. Some of the general philosophic assumptions of the theory are:\nThese assumptions are post-modern in nature and inform the clinical practice of the Collaborative Therapy approach. The following list is of the various impacts that these assumptions have on the therapist and therapeutic relationship. \nCollaborative therapy shares similar epistemological roots with Narrative Therapy and Solution-focused therapy. These therapies are similar, yet distinct. An article by Gehart & Paré summarizes the differences between the therapies in the following way: “In collaborative language systems, the “dis-solving” of problems through conversation (Anderson & Goolishian, 1988; Goolishian & Anderson, 1992), in narrative therapy, reauthoring one’s story about the problem (White 2004; White & Epston, 1990), and in solution-focused therapy (SFT), building solutions (Berg, 1994; de Shazer, 1994; Lipchik, 2002)” \n\nThe Houston Galveston Institute currently is involved in the use of the Collaborative Approach in training, counseling and researching. The office is located in Houston’s museum district and is serving the community needs while training students from local, national and international programs. HGI also provides various training programs for mental health professionals who want to develop a collaborative and postmodern approach to therapeutic work with individuals, couples, families, groups, organizations and community.\n\nThe Institute currently offers an International Certificate in Collaborative Practices program with participation around the world. The program is sponsored by the Houston Galveston Institute and the Taos Institute. It is a response to the numerous practitioners around the world who are interested in expanding their knowledge and competency in collaborative practice. The Certificate Program provides practitioners across disciplines—therapy, organization development, education and research—an intensive, in-depth study of collaborative practices based on postmodern-social construction philosophy. The Program includes the study of the theoretical and philosophical assumptions and their application to practice in a variety of contexts and cultures. The program is offered in Brazil, Colombia, Czech Republic, Germany, China, Mexico, United States, and Canada. In 2009, the International Journal of Collaborative Practices was founded in order to publish the collaborative works developing worldwide.\n\n"}
{"id": "3805048", "url": "https://en.wikipedia.org/wiki?curid=3805048", "title": "Idol (philosophy)", "text": "Idol (philosophy)\n\nSeveral philosophers have developed concepts that they have called idols, including:\n\n"}
{"id": "45333638", "url": "https://en.wikipedia.org/wiki?curid=45333638", "title": "Inclusive masculinity", "text": "Inclusive masculinity\n\nInclusive masculinity is an approach to thinking about masculinity in the context of social changes that have undermined traditional hegemonic masculinity and its associated homophobia, which each have driven men to avoid certain behaviors in order to avoid being publicly perceived as gay; it holds that there are increasingly societal spaces in which men no longer need to behave in hypermasculine ways in order to be accepted. When this occurs, men can engage in a variety of previously feminine practices without the fear of being perceived gay or weak.\n\nThe theory was published in 2009 by Eric Anderson in a book called \"Inclusive Masculinity\". and further elaborated by Mark McCormack in a 2012 book.\n\nIt can be contrasted with views that of contemporary masculinity as being a crisis and in need of restoration.\n\n"}
{"id": "30221251", "url": "https://en.wikipedia.org/wiki?curid=30221251", "title": "Kate Vrijmoet", "text": "Kate Vrijmoet\n\nKate Vrijmoet is an American artist who lives and works in Seattle.\n\nKate Vrijmoet began formal art studies at Moore College of Art, Philadelphia, taking weekend classes while attending high school (1982–1983). She went on to study at the School of Visual and Performing Arts at Syracuse University, and was invited to teach there in 1994, earning her MFA in 1997. She studied painting with Evelina Brozgul at the School of the Museum of Fine Arts, Boston in 2004 and with Richard Ryan at Boston University from 2005 to 2006. After recognition in New York City for her project, \"50 Paintings in 50 Days\", her work was curated into a group show receiving press in the \"New York Times\" and the \"New York Journal News\". In 2010 she had her first solo exhibition at the Center on Contemporary Art CoCA in Seattle, and was reviewed in the \"Seattle Times\". Her painting, \"Shotgun Accident\" won third place in the 2010 Ecuador Biennale of Painting, a decision that has recently caused controversy according to the Ecuador newspaper \"El Telégrafo\", which reported that many considered Vrijmoet the rightful first-place winner. Vrijmoet was one of 16 American artists whose work was included in the 5th Beijing International Art Biennale. Her painting, \"Naked Snow Blower\", a part of Vrijmoet's \"Accident's\" series, was exhibited in the National Museum of China beginning September 28, 2012. In 2014 she curated the Social Practice Art exhibit, \"The Incredible Intensity of Just Being Human,\" in Seattle City Hall, a traveling exhibit aimed at ending the stigma and silence surrounding mental illness.\n\nThrough paintings, installations and social art, Vrijmoet focuses on issues of consciousness, scale, accessibility and ownership. A student of anatomy since childhood, Vrijmoet has for three decades included life drawing in her daily practice. She is currently completing her \"Accident\" series and her \"Non-ordinary Reality\" series. In August, 2010, the Center on Contemporary Art in Seattle published a 42-page catalog for her solo show, \"Kate Vrijmoet: Essential Gestures\". In 2011 Vrijmoet's work was featured in a South Seattle Community College showing, and during a solo show at the LANN Museum in Guayaquil, Ecuador.\n\nHer profile was featured in the inaugural issue of the \"Huffington Post\" Arts Section. Kate discuses her work in detail in an interview published by the science and culture digest 3 Quarks Daily. In her exhibit book, The Incredible Intensity of Just Being Human[14], she writes, \"Art connects us. It tells us we're human, we're like one another, we feel the same emotions. My mission as a human being, and my job as an artist, is to use art to create deep connections among us. Those deep connections already exist, but sometimes convention rewards us for ignoring them. I contend that the greater rewards come from exploring them.\".\n\nIn 2011 Vrijmoet's installation piece \"Mother May I…?\" was exhibited at the Orange County Center on Contemporary Arts (OCCCA),in a show that was endorsed by Nicolas Bourriaud, who coined the term relational aesthetics, or Relational art. In 2012 this installation was featured in the largest artist-run, not for profit organization in Brooklyn, the Brooklyn Artists Waterfront Coalition's (BWAC) juried show. \"Mother May I…?,\" — an interactive audio installment designed to address our fundamental sense of belonging — was awarded \"Best Installation\" by Charlotta Kotik, curator of the Brooklyn Museum of Art. Vrijmoet's work has featured in New York City shows juried by curators of the Metropolitan Museum of Art (Anne Strauss), the Guggenheim (Nat Trotman), and Museum of Modern Art (Paulina Pobocha).\n\nIn 2013 she began curating a Social Practice Art exhibit aimed at ending the stigma and silence surrounding mental illness. The Incredible Intensity of Just Being Human has been exhibited at the Seattle Center, and Highline College. In 2014 she won prestigious grants through Artist Trust and Seattle Department of Neighborhoods to further fund this exhibit in Seattle City Hall where civic leaders Mayor Ed Murray, Randy Revelle, Brady Walkinshaw, and Tina Orwall spoke at the opening reception about mental illness. Vrijmoet's project was supported by Seattle Office of Arts and Culture, and Allied Arts Foundation.\n\nAlso in 2013 she participated in SEAF with her social sculpture \"Poor Impulse Control\"- an example of relational art, social sculpture, or ironic participation. In this form the artist exploits the role of the viewer as the art object. The primary role of social sculpture is not one of beauty, but of intervention through discomfort. The audience has an interdependent relationship with the work. Of this social sculpture Vrijmoet writes, \"The collapse of the emotional and physical boundaries inherent to the human experience is a recurrent theme in my work. [...] my work directly engages participants communally, even as it remains distinctly personal to each audience member. Although initiated by a single creator, audience participation is fundamental to making my work come to life.\"\n\nIn the catalog essay of her CoCA solo exhibit, \"Essential Gestures\", Elatia Harris writes of her work, \"Any single image from the \"Accident\" series will freeze you where you stand. Motionlessly, you check yourself for parts and think, \"Oh, that's the thing, the thing that happened to me, even if no one sees it\". The Water paintings, on the other hand, will dislocate you – you are pulled, plunged and buoyed, seeing up and through and down.\" Maine writer and art critic, Dan Kany, writes Vrijmoet's work takes a \"supremely anti-modernist stance – following the idea that Modernism doesn't privilege the artist/author over the viewer.\" A show of her \"Accident\" Series Paintings was exhibited in 2013 at Columbia Basin College's Esvelt Gallery in Eastern Washington.\n\nIn 2014 she published an article The Broader Economic Impact of Donating Your Art, that went viral on social media outlets and was viewed more than 2 million times across the globe. This article continues to inspire dialog surrounding fundraising in the arts.\n\nIn 2015 Vrijmoet participated in The Richard Siken Project, in which 11 artists respond to The War of the Foxes, through Copper Canyon Press.\n\n"}
{"id": "12979265", "url": "https://en.wikipedia.org/wiki?curid=12979265", "title": "Lars Vilks", "text": "Lars Vilks\n\nLars Endel Roger Vilks Lanat (born 20 June 1946) is a Swedish artist, Doctor of Philosophy, and activist who garnered fame for his drawings of Muhammad, which resulted in at least two failed attempts by Islamic extremists to murder him. He is also known for his sculptures, \"Nimis\" and \"Arx\", made entirely of driftwood, and the small area where the sculptures are located which was proclaimed by Vilks as an independent country, \"Ladonia\".\n\nVilks was born in Helsingborg, Sweden, to a Latvian father and a Swedish mother. He earned his doctoral degree in art history from Lund University in 1987, and worked at the Oslo National Academy of the Arts from 1988 to 1997. From 1997 to 2003, he was a professor in art theory at the Bergen National Academy of the Arts. As an art theorist, Vilks is a proponent of the institutional theory of art. \n\nAlthough an academically trained art theorist, Vilks is a self-taught artist. In the 1970s, he started painting, and in 1984, he embarked on creating the idiosyncratic sculptures that have been his hallmark, starting with \"Nimis\". At this time, in the early 1980s, postmodernism made its definite entry into the Swedish art scene, using inspiration from e.g. the French art philosopher Jean-François Lyotard. Conceptual artists took the place of the earlier modernists on the contemporary art scene. These conceptual artists did not want their art to have any aesthetic or programmatic content, but often focused on the artist's self. Vilks was part of this movement in Sweden. He turned himself in as a piece of art to the spring saloon at , and turned his own car into a piece of art at the fall exhibition at Skånes konstförening.\n\nIn 1980 Vilks created two wooden sculptures, \"Nimis\" and \"Arx\", made entirely of drift wood, now located in the Kullaberg nature reserve in Höganäs, Skåne. In 1996, the small area where the sculptures are located was proclaimed by Vilks as an independent country, \"Ladonia\". \"Nimis\" was sold to Joseph Beuys as a means to circumvent the Swedish building code laws concerning unlawful building process. The sculpture of Nimis is now owned by concept artist Christo; the legal document documenting the sale is on display at the Swedish Museum of Sketches. \n\nVilks has characterized his own skill in the actual crafts involved in sculpture as quite limited, and although his artistic ideas can be seen as characteristic for his generation of Swedish conceptual artists. One of the few works of Vilks to be incorporated into a collection is the concrete sculpture \"Omphalos\", measuring 1.6 meters high and weighing one tonne, which is owned by Moderna Museet after it was first bought by fellow artist Ernst Billgren for 10 000 Swedish kronor.\n\nVilks' long-standing controversies with different authorities due to his activities in the nature reserve Kullaberg, where \"Nimis\", \"Arx\" and \"Landonien\" are all located, receive significant attention in Swedish media, which has mostly portrayed Vilks' work as specifically designed to be provocative. This attention has turned the area into something of a tourist attraction. In Vilks' activity as an art theorist, he comments on his own artistic activities in the second or third person. His different works of art, his actions, actions by those authorities with whom Vilks has been in conflict, and the media attention, are brought together in a \"Gesamtkunstwerk\". He has described himself as an \"equal opportunity offender\" in his critical depictions of religion.\n\nIn 2007, Vilks caused an international controversy when he depicted Muhammad as a roundabout dog in three drawings, designated to be shown at an art exhibition at Tällerud, in July of the same year. Shortly before its opening, the organizers cancelled their invitation with reference to serious security concerns, and despite Vilks' effort no other Swedish art gallery offered to exhibit his drawings.\n\nEventually, on 18 August, one of his drawings was published in the Örebro-based regional newspaper, \"Nerikes Allehanda\", as part of an editorial on self-censorship and freedom of religion. and even though other leading Swedish newspapers had published the drawings before, it was this publication that led to protests from Muslim organizations in Sweden as well as condemnations from several foreign governments including Iran, Pakistan, Afghanistan, Egypt, and Jordan as well as by the inter-governmental Organisation of the Islamic Conference (OIC), which also called for the Swedish government to take \"punitive actions\" against Vilks. Following this controversy, Vilks has been forced to live under police protection after having received several death threats, including a statement by the al-Qaeda-affiliated Islamic State of Iraq which has offered up to $150,000 for his assassination.\n\nIn 2009, a failed plot to kill Vilks was hatched. Three U.S. citizens, Colleen LaRose (known as \"Jihad Jane\"), Mohammad Hassas Khalid, and Jamie Paulin Ramirez, participated in the plot. On 9 March 2010, LaRose's federal indictment was unsealed charging her with trying to recruit Muslims to murder Vilks.\n\nOn the same day, seven people were arrested in the Republic of Ireland over an alleged plot to assassinate Vilks. Police officers close to the investigation said those arrested were foreign-born Irish residents, mostly from Yemen and Morocco and had refugee status. Of the seven, three men and two women were arrested in Waterford and Tramore, and another man and woman at Ballincollig, near Cork. Garda Síochána (the Irish police force), which conducted the arrests with support from the National Support Services and the counter-terrorist Special Detective Unit, said the suspects ranged in age from mid 20s to late 40s. The Irish police added that throughout the investigation they had been \"working closely with law enforcement agencies in the United States and in a number of European countries\".\n\nOn 11 May 2010, Muslim protesters assaulted Vilks while he was giving a lecture about free speech at Uppsala University. The attacks started when a film about Islam and homosexuality (the video depicts images of topless men, including one brief image of two fully clothed men kissing, all interspersed with Islamic imagery) was shown and some Islamists began to demand that the film be stopped, claiming it to be gay porn. The film in question was Iranian artist Sooreh Hera's \"Allah ho Gaybar\". Vilks' eyeglasses were broken but he did not suffer any serious injuries, and was escorted to safety by security, while a few of the protesters were detained by police. Despite previous death threats, this was the first act of violence against Vilks. \n\nA few days later, on 15 May 2010, Vilks' house in southern Sweden was attacked by arsonists. They smashed the windows and threw in bottles of gasoline. There was a small fire, but the house was not burned to the ground. Vilks was not at home at the time of the attack. Two Kosovar-Swedish brothers were arrested, and July 15 they were sentenced to two and three years, respectively, of imprisonment.\nOn 24 November 2010, a video produced by the Somali Islamic organization Al-Shaabab was sent out. In the video, a Swedish speaking voice appeals to \"all the Somali brothers and sisters\" in Sweden, to leave that country and come to Somalia to fight for Al-Shabaab. He announces a death threat against Vilks. On 11 December 2010, a suicide bomber in Stockholm said in a message to media and the Swedish Security Police that \"Now will your children, daughters and sisters die the same way our brothers and sisters die. Our actions will speak for themselves. As long as you don't end your war against Islam and degradation against the prophet and your foolish support for the pig Vilks.\" \n\nIn 2010 Anwar al-Awlaki published an Al-Qaeda hit list in \"Inspire\" magazine, including Lars Vilks. In 2013 the list was later expanded to include Stéphane \"Charb\" Charbonnier, who the Lars Vilks committee gave their freedom prize in 2014. When Charb was murdered in a terror attack on \"Charlie Hebdo\" in Paris, along with 11 other people, Al-Qaeda called for more cartoonists to be killed, and Vilks stepped up his security.\n\nAt an event called \"Art, blasphemy and the freedom of expression\", which was organized by Vilks at the Krudttønden cafe in Copenhagen, Denmark on 14 February 2015, semi automatic gunfire left one civilian dead and three police officers wounded. At least 30 bullet holes were visible in the window of the cafe. Participants at the event included speaker Niels Ivar Larsen and organizer Helle Merete Brix, the latter describing the attack as targeted at Vilks. Ukrainian FEMEN organizer Inna Shevchenko and the French ambassador Francois Zimeray also were present at the event. A suspect, acting alone, was identified by surveillance cameras and killed in gunfire with police the following day. Police believe the attack in Copenhagen may have been inspired by the \"Charlie Hebdo\" shooting.\n\nAfter the attack, Vilks went into hiding.\n\nIn March 2015, Vilks received the Sappho Award from the Danish Free Press Society. The award ceremony took place under tight security in the Parliament wing of Christiansborg Palace. It was Vilks's first public appearance since the 2015 February attack.\n\n\n"}
{"id": "38383955", "url": "https://en.wikipedia.org/wiki?curid=38383955", "title": "List of largest languages without official status", "text": "List of largest languages without official status\n\nBelow is list of languages without any official status (or a minority language) with at least two million speakers, ordered by the number of native speakers\n\n\n\n\n"}
{"id": "3055274", "url": "https://en.wikipedia.org/wiki?curid=3055274", "title": "Lost in the mall technique", "text": "Lost in the mall technique\n\nThe \"Lost in the Mall\" technique, or the \"lost in the mall\" experiment, is a memory implantation technique used to demonstrate that confabulations about events that never took place – such as having been lost in a shopping mall as a child – can be created through suggestions made to experimental subjects. It was first developed by Jim Coan, an undergraduate student of psychologist Elizabeth Loftus as support for the claim that it is possible to implant entirely false memories in people. The technique was developed in the context of the debate about the existence of repressed memories and false memories (see False memory syndrome).\n\nA lost in the mall experiment is a memory implantation technique used to demonstrate that confabulations about events that never took place, such as having been lost in a shopping mall as a child. It can be created through suggestions made to experimental subjects. It was first developed by Jim Coan, an undergraduate student of psychologist Elizabeth Loftus at the University of Washington as support for the claim that it is possible to implant entirely false memories in people. It was developed in the context of a debate about the existence of repressed memories and false memories (see False memory syndrome).\n\nCoan designed the first lost in the mall experiment as an extra-credit assignment for a course in cognitive psychology. The professor—Loftus—invited her students to design and execute an experiment implanting false memories in subjects. Coan enlisted his mother, sister and brother as subjects. He assembled booklets containing four short narratives describing childhood events, and instructed them to try to remember as much as possible about each of the four events, and to write down those details over the course of six days. Unbeknownst to the participants, one of the narratives was false; it described Coan's brother getting lost in a shopping mall at around the age of 5, then being rescued by an elderly person and reunited with his family. During the experiment, Coan's brother unwittingly invented several additional details of the false narrative. At the conclusion of the experiment during a tape-recorded debriefing when told that one of the narratives was false, Coan's brother could not identify which one was false and expressed disbelief when told.\n\nCoan later refined the study methodology for his senior thesis, in collaboration with Loftus and graduate student Jacqueline Pickrell. In their experiment, they adapted the methods Coan had used on his brother in a formal study with 24 participants, 25% of whom reported remembering the false event. The memory for the false event was usually reported to be less clear than the true events, and people generally used more words to describe the true events than the false events. At the end of the study when the participants were told that one of the 4 events was false, some people (5 out of 24) failed to identify the lost in the mall event as the false event and instead picked one of the true events to be false. Loftus calls this study \"existence proof\" for the phenomenon of false memory creation and suggests that the false memory is formed as a result of the suggested event (being lost in a mall) being incorporated into already existing memories of going to the mall. With the passage of time it becomes harder for people to differentiate between what actually happened and what was imagined and they make memory errors.\n\nThe lost in the mall experiment has been replicated and extended with different ages of subjects. About 25 percent of the participants not only \"remembered\" the implanted memory but also filled in the missing details.\n\nThe Lost in the Mall technique is generally accepted as a memory implantation study that is useful for investigating the effect of suggestions on memory. However some people have argued that this is not generalizable to memories for traumatic events. An article in the journal \"Child Development\" by Pezdek and Hodges described an extension of the experiment. By using the subjects' family members to do the interviewing, their study was able to replicate Loftus' findings that memories of being lost in the mall could be created and were more likely to occur in young children. However, a much smaller number of children reported false memories of another untrue incident: that of a painful and embarrassing enema. Another article by Kenneth Pope in the \"American Psychologist\" suggested possible confounding variables in the study as well as questioning whether the technique's ability to generate a false memory could be compared with the ability of a therapist to create a pseudomemory of childhood sexual abuse. \n\nIn 1995, Lynn Crook who had recovered memories of childhood sexual abuse, filed an ethics complaint with the American Psychological Association charging Loftus with misrepresenting Crook's successful recovered memory lawsuit in a media interview with \"Psychology Today\" (\"Dispatch from the Memory War\").\nIn an article (1999 in the Journal \"Ethics & Behavior\") two women who had recovered memories of childhood sexual abuse, Lynn Crook and Martha Dean, questioned Loftus' Lost in the Mall-study, arguing that the methods used were unethical and the results not generalizable to real life memories of trauma. Loftus responded to Crook and Dean's criticism pointing to the exaggerations, omissions and errors in Crook and Dean's description of the technique and their mistakes about the study's representation in the media. Loftus made it clear that the Lost in the Mall study and other studies using memory implantation techniques in no way tried to claim that all memories of childhood sexual abuse discovered in therapy are false, they merely try to show how relatively easy it is to manipulate human memory. Loftus also accused Crook of writing the article as part of a long series of efforts to discredit her integrity as a researcher and her work. \n\n"}
{"id": "14575128", "url": "https://en.wikipedia.org/wiki?curid=14575128", "title": "Margin of appreciation", "text": "Margin of appreciation\n\nThe margin of appreciation (or \"margin of state discretion\") is a doctrine with a wide scope in international human rights law. It was developed by the European Court of Human Rights, to judge whether a state party to the European Convention on Human Rights should be sanctioned for derogations. The doctrine allows the Court to reconcile practical differences in implementing the articles of the Convention. Such differences create a limited right, for Contracting Parties, \"to derogate from the obligations laid down in the Convention\". The doctrine also reinforces the role of the European Convention, as a supervisory framework for human rights. In applying this discretion, European Court judges must take into account differences between domestic laws of the Contracting States as they relate to substance and procedure. The margin of appreciation doctrine contains concepts that are analogous to the principle of subsidiarity, which occurs in the unrelated field of European Union law. The purpose of the margin of appreciation is to balance individual rights with national interests, as well as resolve any potential conflicts. It has been suggested that the European Court should generally refer back to the State's decision, as they are an international court instead of a bill of rights.\n\nThe phrase \"margin of appreciation\" is a literal translation of the French \"marge d'appréciation\". The latter phrase refers to a notion of administrative law that was developed by the Conseil d'Etat, but equivalent concepts have also emerged in every other civil jurisdiction. At the level of the European Convention on Human Rights, a margin of appreciation refers to some \"latitude of deference or error which the Strasbourg organs will allow to national legislative, executive, administrative and judicial bodies\". This is an intermediary norm in the jurisprudence of the European Court of Human Rights. It allows for some compromise between the aspirations of the Convention and the circumstances faced by a Contracting Party. This doctrine of \"administrative\" discretion first gained national levels of prominence, most notably under the German \"Bundesverwaltungsgericht\" (or Supreme Administrative Court), before it was translated into a doctrine of \"supervisory\" discretion for a regional context.\n\nThe concept of a margin of appreciation at the European level emerged through questions surrounding martial law. It was introduced to European Convention jurisprudence in 1956. This occurred through an opinion of the European Commission of Human Rightsin a \"Cyprus\" caseto permit the United Kingdom, under Article 15, to derogate from its obligations in a time of public emergency. Subsequently, the hearing for \"Lawless v Ireland\" (that is, the first formally decided case of the Court) included an oral argument from the Commission President Sir Humphrey Waldock that:\n\nLater, the \"Belgian Linguistic Case (No. 2)\" of 1968 introduced a margin of appreciation to circumstances that fell outside emergency situations that were identified by Article 15 of the European Convention. This case proved to be critical in establishing a wide scope for the emerging doctrine of discretion. It identified two key elements for establishing a margin of appreciation: a focused consensus standard among 'Convention signatory states', as well as a proportionality principle in the jurisprudence of the European Convention. The latter element consisted of two weighting factors, which are necessary to establish the extent of a particular margin. These factors are the 'nature of the right' in question, as well as 'the aim pursued by the contested measure'. With an expansive doctrine in view, the European Court also sought to constrain itself by stating that:\n\nThe margin of appreciation doctrine received considerable development in 1976, with the Court decision of \"Handyside v United Kingdom\". This concerned the publication of a Danish textbook for primary school children, in which sexual behaviour was discussed using explicit terms. It was successfully published in several signatory states, but was met with controversy in the United Kingdom. Handyside, an English publisher, was convicted for violating domestic laws on obscene publications. The case that was brought before the European Court challenged whether the United Kingdom could infringe freedom of expression, under Article 10, on the ground of protecting moral norms. The fact that the \"Little Red Schoolbook\" had been received in other European countries formed a basis for this challenge. However, the Court permitted the imposed limitation on freedom of expression and found no violation of the Convention. It held that:\n\nWith this judgment, the European Court reinforced its distinction between the supervisory jurisdiction of the Convention framework and domestic forms of discretion. However, it also affirmed that:\n\nIn the case of Z v. Finland, while accepting that individual interests could sometimes be outweighed by the public interest in the investigation and prosecution of crime, the Court emphasized the fundamental importance of protecting the confidentiality of medical data, for the sake of personal privacy and to preserve confidence in the medical profession and health services. It found that that measures including the disclosure of the applicant's medical records without her consent in the course of criminal proceedings against her husband amounted to a violation of Article 8.\n\nThe European Court decision in \"Handyside v United Kingdom\" framed the margin of appreciation doctrine in terms of a systemic tension in the European Convention framework. It is therefore easy to distort the concept, in a negative sense, 'to circumvent the express requirements of the Convention'. However, the official position of the Court is that a margin of appreciation must be derived from 'a just balance between the protection of the general interest of the community and the respect due to fundamental human rights while attaching particular importance to the latter.' This precedent illustrates some continuity between the original function of a margin of appreciationas a justified derogation \"simpliciter\"and its present purpose of delimiting rights and freedoms for individuals in relation to state parties. Yet a clear distinction has also been made between this latter \"substantive\" purpose, which evolved over time, as well as the \"structural\" aim of the doctrine. The structural purpose for a margin of appreciation was to construct 'a geographically and cultural plural notion of implementation'. As a result of this, the doctrine has continued to subsist in an unstructured set of elements. This is possible, because the foundation concept of a margin is essentially abstract in nature and less connected to the core purposes of the Conventionespecially when it is compared with other interpretive principles, such as legality or the effective protection of rights.\n\nAs justification for any derogation from the European Convention ultimately rests on the concept of \"democratic necessity\" in a society, margins of appreciation are situation-oriented and the case law regarding this subject frequently lacks consistency. The expanded margin of appreciation doctrine has been used to interpret European Convention guarantees regarding due process (that is, Articles 5 and 6) and personal freedoms (that is, Articles 8-11). This infused the doctrine with a sense of ubiquity and has led to its invocation in major legal developments, including challenges surrounding discrimination as they relate to human rights. However, the doctrine has also been invoked in such varied questions as the enjoyment of possessions, the use of religious symbols and the implementation of environmental policies and regulations. The margin of appreciation in each of these categories of cases has differed according to the kind of right in question; for example, where private individuals are more directly involved, less discretion is typically permitted to the discretion of state parties. Naturally, this criterion comes under just one of the three criteriathat is, the nature of the right, the aims pursued, as well as the presence or absence of a European consensusthat are used to determine the scope of any given margin. As the European Court decided in \"Dickson v United Kingdom\":\n\nThe margin of appreciation doctrine has gained sufficient prominence, under an emerging principle of subsidiarity, to merit impending incorporation into the Preamble of the European Convention. This formal acknowledgment indicates awareness, on the part of the Council of Europe, that the evolution of the Convention must include jurisprudence that justifies the application of this doctrine in so many different issues. The margin of appreciation doctrine may also expand further throughout international law. This is because its underlying concept of a derogation being \"necessary in a democratic society\"as it is provided for in the European Conventionalso resonates with other international human rights regimes. Although many regimes remain formally ambivalent (or even negative) towards margins of appreciation, the growing influence of Convention law on international norms is, in turn, making the doctrine more attractive to the global community.\n\n\n"}
{"id": "16399866", "url": "https://en.wikipedia.org/wiki?curid=16399866", "title": "Mentalization-based treatment", "text": "Mentalization-based treatment\n\nMentalization-based treatment (MBT) is an integrative form of psychotherapy, bringing together aspects of psychodynamic, cognitive-behavioral, systemic and ecological approaches. MBT was developed and manualised by Peter Fonagy and Anthony Bateman, designed for individuals with borderline personality disorder (BPD). Some of these individuals suffer from disorganized attachment and failed to develop a robust mentalization capacity. Fonagy and Bateman define mentalization as the process by which we implicitly and explicitly interpret the actions of oneself and others as meaningful on the basis of intentional mental states. The object of treatment is that patients with BPD increase their mentalization capacity, which should improve affect regulation, thereby reducing suicidality and self-harm, as well as strengthening interpersonal relationships.\n\nMore recently, a range of mentalization-based treatments, using the \"mentalizing stance\" defined in MBT but directed at children (MBT-C), families (MBT-F) and adolescents (MBT-A), and for chaotic multi-problem youth, AMBIT (adaptive mentalization-based integrative treatment) has been under development by groups mainly gravitating around the Anna Freud National Centre for Children and Families.\n\nThe treatment should be distinguished from and has no connection with mindfulness-based stress reduction (MBSR) therapy developed by Jon Kabat-Zinn.\n\nThe major goals of MBT are: (1) better behavioral control, (2) increased affect regulation, (3) more intimate and gratifying relationships and (4) the ability to pursue life goals. This is believed to be accomplished through increasing the patient's capacity for mentalization in order to stabilize the client's sense of self and to enhance stability in emotions and relationships.\n\nA distinctive feature of MBT is placing the enhancement of mentalizing itself as focus of treatment. The aim of therapy is not developing insight, but the recovery of mentalizing. Therapy examines mainly the present moment, attending to events of the past only insofar as they affect the individual in the present. Other core aspects of treatment include a stance of curiosity, partnership with the patient rather than an 'expert' type role, monitoring and regulating emotional arousal, and identifying the affect focus. Transference in classical understanding of this term is not included in the MBT model. MBT does encourage consideration of the patient-therapist relationship, but without necessarily generalizing to other relationships, past or present.\n\nMBT should be offered to patients twice per week with sessions alternating between group therapy and individual treatment. During sessions the therapist works to stimulate or nurture mentalizing. Particular techniques are employed to lower or raise emotional arousal as needed, to interrupt non-mentalizing and to foster flexibility in perspective-taking. Activation occurs through the elaboration of current attachment relationships, the therapist’s encouragement and regulation of the patient’s attachment bond with the therapist and the therapist’s attempts to create attachment bonds between members of the therapy group.\n\nThe safe attachment relationship with the therapist provides a relational context in which it is safe for the patient to explore the mind of the other. Fonagy and Bateman have recently proposed that MBT (and other evidence-based therapies) works by providing ostensive cues that stimulate epistemic trust. The increase in epistemic trust, together with a persistent focus on mentalizing in therapy, appear to facilitate change by leaving people more open to learning outside of therapy, in the social interactions of their day-to-day lives. \n\nFonagy, Bateman, and colleagues have done extensive outcome research on MBT for borderline personality disorder. The first randomized, controlled trial was published in 1999, concerning MBT delivered in a partial hospital setting. The results showed real-world clinical effectiveness that compared favorably with existing treatments for BPD. A follow-up study published in 2003 demonstrated that MBT is cost-effective. Encouraging results were also found in an 18-month study, in which subjects were randomly assigned to an outpatient MBT treatment condition versus a structured clinical management (SCM) treatment. The lasting efficacy of MBT was demonstrated in an 8-year follow-up of patients from the original trial, comparing MBT versus treatment as usual. In that research, patients who had received MBT had less medication use, fewer hospitalizations and longer periods of employment compared to patients who received standard care. Replication studies have been published by other European investigators. Researchers have also demonstrated the effectiveness of MBT for adolescents as well as that of a group-only format of MBT.\n\n\n"}
{"id": "42478068", "url": "https://en.wikipedia.org/wiki?curid=42478068", "title": "Moduli stack of formal group laws", "text": "Moduli stack of formal group laws\n\nIn algebraic geometry, the moduli stack of formal group laws is a stack classifying formal group laws and isomorphisms between them. It is denoted by formula_1. It is a \"geometric “object\" that underlies the chromatic approach to the stable homotopy theory, a branch of algebraic topology.\n\nCurrently, it is not known whether formula_1 is a derived stack or not. Hence, it is typical to work with stratifications. Let formula_3 be given so that formula_4 consists of formal group laws over \"R\" of height exactly \"n\". They form a stratification of the moduli stack formula_1. formula_6 is faithfully flat. In fact, formula_3 is of the form formula_8 where formula_9 is a profinite group called the Morava stabilizer group. The Lubin–Tate theory describes how the strata formula_3 fit together.\n"}
{"id": "45795", "url": "https://en.wikipedia.org/wiki?curid=45795", "title": "Natural capital", "text": "Natural capital\n\nNatural capital is the world's stock of natural resources, which includes geology, soils, air, water and all living organisms. Some natural capital assets provide people with free goods and services, often called ecosystem services. Two of these (clean water and fertile soil) underpin our economy and society and make human life possible.\n\nIt is an extension of the economic notion of capital (resources which enable the production of more resources) to goods and services provided by the natural environment. For example, a well-maintained forest or river may provide an indefinitely sustainable flow of new trees or fish, whereas over-use of those resources may lead to a permanent decline in timber availability or fish stocks. Natural capital also provides people with essential services, like water catchment, erosion control and crop pollination by insects, which in turn ensure the long-term viability of other natural resources. Since the continuous supply of services from the available natural capital assets is dependent upon a healthy, functioning environment, the structure and diversity of habitats and ecosystems are important components of natural capital. Methods, called 'natural capital asset checks', help decision-makers understand how changes in the current and future performance of natural capital assets will impact on human well-being and the economy.\n\nNatural capital is one approach to ecosystem valuation which revolves around the idea, in contrast to traditional economics, that non-human life produces essential resources. Thus, ecological health is essential to the sustainability of the economy. In \"\" the author claims that the global economy is within a larger economy of natural resources and ecosystem services that sustain us. In order to continue to reap the benefits of our natural environment, we need to recognize the importance of natural capital within the economy. According to the authors, the \"next industrial revolution\" depends on the espousal of four central strategies: \"the conservation of resources through more effective manufacturing processes, the reuse of materials as found in natural systems, a change in values from quantity to quality, and investing in natural capital, or restoring and sustaining natural resources.\"\n\nIn a traditional economic analysis of the factors of production, natural capital would usually be classified as \"land\" distinct from traditional \"capital\". The historical distinction between \"land\" and \"capital\" defined “land” as naturally occurring with a fixed supply, whereas “capital”, as originally defined referred only to man-made goods. (e.g., Georgism) It is however, misleading to view \"land\" as if its productive capacity is fixed, because natural capital can be improved or degraded by the actions of man over time (see Tragedy of the Commons). Moreover, natural capital yields benefits and goods, such as timber or food, which can be harvested by humans. These benefits are similar to those realized by owners of infrastructural capital which yields more goods, such as a factory which produces automobiles just as an apple tree produces apples.\n\nThe term 'natural capital' was first used in 1973 by E.F. Schumacher in his book \"Small Is Beautiful\" and is closely identified with Herman Daly, Robert Costanza, the Biosphere 2 project, and the Natural Capitalism economic model of Paul Hawken, Amory Lovins, and Hunter Lovins. Recently, it has begun to be used by politicians, notably Ralph Nader, Paul Martin Jr., and agencies of the UK government, including its Natural Capital Committee and the London Health Observatory. All users of the term currently differentiate natural from man-made or infrastructural capital in some way. Indicators adopted by United Nations Environment Programme's World Conservation Monitoring Centre and the Organisation for Economic Co-operation and Development (OECD) to measure natural biodiversity use the term in a slightly more specific way. According to the OECD, natural capital is “natural assets in their role of providing natural resource inputs and environmental services for economic production” and is “generally considered to comprise three principal categories: natural resources stocks, land, and ecosystems.”\n\nWithin the international community the basic principle is not controversial, although much uncertainty exists over how best to value different aspects of ecological health, natural capital and ecosystem services. Full-cost accounting, triple bottom line, measuring well-being and other proposals for accounting reform often include suggestions to measure an \"ecological deficit\" or \"natural deficit\" alongside a social and financial deficit. It is difficult to measure such a deficit without some agreement on methods of valuation and auditing of at least the global forms of natural capital (e.g. value of air, water, soil).\n\nEcologists are teaming up with economists to measure and express values of the wealth of ecosystems as a way of finding solutions to the biodiversity crisis. Some researchers have attempted to place a dollar figure on ecosystem services such as the value that the Canadian boreal forest's contribution to global ecosystem services. If ecologically intact, the boreal forest has an estimated value of US$3.7 trillion. The boreal forest ecosystem is one of the planet's great atmospheric regulators and it stores more carbon than any other biome on the planet. The annual value for ecological services of the Boreal Forest is estimated at US$93.2 billion, or 2.5 greater than the annual value of resource extraction. The economic value of 17 ecosystem services for the entire biosphere (calculated in 1997) has an estimated average value of US$33 trillion per year. These ecological economic values are not currently included in calculations of national income accounts, the GDP and they have no price attributes because they exist mostly outside of the global markets. The loss of natural capital continues to accelerate and goes undetected or ignored by mainstream monetary analysis.\n\nIn June 2012 a 'natural capital declaration' (NCD) was launched at the Rio+20 summit held in Brazil. An initiative of the global finance sector, it was signed by 40 CEOs to 'integrate natural capital considerations into loans, equity, fixed income and insurance products, as well as in accounting, disclosure and reporting frameworks.' They worked with supporting organisations to develop tools and metrics to integrate natural capital factors into existing business structures. In summary, its four key aims are to:\n\nIn July 2016, the Natural Capital Coalition released the Natural Capital Protocol. The Protocol provides a standardised framework for organisations to identify, measure and value their direct and indirect impacts and dependencies on natural capital. The Protocol harmonises existing tools and methodologies, and guides organisations towards the information they need to make strategic and operational decisions that include impacts and dependencies on natural capital.\n\nThe Protocol was developed in a unique collaboration between 38 organisations who signed voluntary, pre-competitive contracts.\n\nThe Protocol is available on a creative commons license and is free for organisations to apply.\n\nEnvironmental-economic accounts provide the conceptual framework for integrated statistics on the environment and its relationship with the economy, including the impacts of the economy on the environment and the contribution of the environment to the economy. A coherent set of indicators and descriptive statistics can be derived from the accounts that inform a wide range of policies, including, but not limited to, green economy/green growth, natural resource management and sustainable development. The System of Environmental-Economic Accounting (SEEA) contains the internationally agreed standard concepts, definitions, classifications, accounting rules and tables for producing internationally comparable statistics on the environment and its relationship with the economy. The SEEA is a flexible system in the sense that its implementation can be adapted to countries' specific situations and priorities. Coordination of the implementation of the SEEA and on-going work on new methodological developments is managed and supervised by the UN Committee of Experts on Environmental-Economic Accounting (UNCEEA). The final, official version of the SEEA Central Framework was published in February 2014.\n\nWhilst measuring the components of natural capital in any region is a relatively straightforward process, both the task and the rationale of putting a monetary valuation on them, or on the value of the goods and services they freely give us, has proved more contentious.\nWithin the UK, Guardian columnist, George Monbiot, has been critical of the work of the government's Natural Capital Committee and of other attempts to place any sort of monetary value on natural capital assets, or on the free ecosystem services they provide us with. In a speech referring to a report to government which suggested that better protection of the UK's freshwater ecosystems would yield an enhancement in aesthetic value of £700m, he derided attempts 'to compare things which cannot be directly compared'. He went on to say:\n\nOthers have defended efforts to integrate the valuation of natural capital into local and national economic decision-making, arguing that it puts the environment on a more balanced footing when weighed against other commercial pressures, and that 'valuation' of those assets is not the same as monetisation.\n\n\n\n"}
{"id": "1749418", "url": "https://en.wikipedia.org/wiki?curid=1749418", "title": "Naturalization of value systems", "text": "Naturalization of value systems\n\nThe naturalization of value systems in the human sciences is the process by which other frameworks were sought to replace spiritual, \"other-worldly\", religious explanations of nature, life and humanity with respect to fundamental values.\n\n"}
{"id": "36352733", "url": "https://en.wikipedia.org/wiki?curid=36352733", "title": "Peer learning", "text": "Peer learning\n\nOne of the most visible approaches to peer learning comes out of cognitive psychology, and is applied within a \"mainstream\" educational framework: \"Peer learning is an educational practice in which students interact with other students to attain educational goals.\" In this context, it can be compared to the practices that go by the name cooperative learning. However, other contemporary views on peer learning relax the constraints, and position \"peer-to-peer learning\" as a mode of \"learning for everyone, by everyone, about almost anything.\" Whether it takes place in a formal or informal learning context, in small groups or online, peer learning manifests aspects of self-organization that are mostly absent from pedagogical models of teaching and learning.\n\nIn his 1916 book, Democracy and Education, John Dewey wrote, “Education is not an affair of 'telling' and being told, but an active and constructive process.” In a later essay, entitled \"Experience and Education\", Dewey went into greater detail about the science of child development and developed the basic Constructivist theory that knowledge is created through experience, rather than passed down from teacher to student through rote memorization. Soviet psychologist Lev Vygotsky, who developed the concept of the Zone of Proximal Development, was another proponent of constructivist learning: his book, \"Thought and Language\", provides evidence that students learn better through collaborative, meaningful problem-solving activities than through solo exercises.\n\nThe three distinguishing features of constructivist theory are claims that:\nThese are clearly meaningful propositions in a social context with sustained relationships, where people work on projects or tasks that are collaborative or otherwise shared.\n\nEducational Psychology Professor Alison King explains in \"Promoting Thinking Through Peer Learning\" that peer learning exercises as simple as having students explain concepts to one another are proof of social constructivism theory at work; the act of teaching another individual demands that students “clarify, elaborate on, and otherwise reconceptualize material.” Joss Winn, Senior Lecturer in Educational Research at University of Lincoln, proposes that schools radically redefine the teacher-student relationship to fit this constructivist theory of knowledge in his December 2011 paper, \"Student as Producer\". Carl Rogers' \"Personal Thoughts on Learning\" focus on the individual’s experience of effective learning, and eventually conclude that nearly the entire traditional educational structure is at odds with this experience. Self-discovered learning in a group that designates a facilitator is the “new approach” Rogers recommends for education.\n\nIn general, peer learning may adapt constructivist or discovery learning methods for the peer-to-peer context: however, peer learning typically manifests constructivist ideas in a more informal way, when learning and collaboration are simply applied to solve some real shared problem.\n\nCritical pedagogy engages students and instructors in analyzing and critiquing power structures around them. The most influential scholar in the development of this field was Paulo Freire, whose book Pedagogy of the Oppressed described the traditional teaching framework as a “banking system” in which students are thought of as empty vessels to be filled with knowledge and concepts. Instead, Freire advocated a more equitable relationship between teachers and students, one in which information is questioned and situated in political context, and all participants in the classroom work together to create knowledge.\n\nFreire’s vision for dialogical education, where learning is situated within students’ lived experience, has been commonly deemed idealistic by modern educators. Yet Paulo Blikstein, Assistant Professor of Education at Stanford University wrote in \"Travels in Troy with Freire: Technology as an Agent of Emancipation\" that through exploratory building activities, “Not only did students become more autonomous and responsible, they learned to teach one another.”\n\nYochai Benkler explains how the now-ubiquitous computer helps us produce and process knowledge together with others in his book, The Wealth of Networks. George Siemens argues in Connectivism: A Learning Theory for the Digital Age, that technology has changed the way we learn, explaining how it tends to complicate or expose the limitations of the learning theories of the past. In practice, the ideas of connectivism developed in and alongside the then-new social formation, \"massive open online courses\" or MOOCs.\n\nConnectivism proposes that the knowledge we can access by virtue of our connections with others is just as valuable as the information carried inside our minds. The learning process, therefore, is not entirely under an individual’s control—learning can happen outside ourselves, as if we are a member of a large organization where many people are continuously updating a shared database.\n\nRita Kop and Adrian Hill, in their critique of connectivism, state that:\n\nIn a joint paper, Roy Williams, Regina Karousou, and Jenny Mackness argue that educational institutions should consider \"emergent learning,\" in which learning arises from a self-organized group interaction, as a valuable component of education in the Digital Age. Web 2.0 puts distributed individuals into a group setting where emergent learning can occur. However, deciding how to manage emergence is important; “fail-safe” management drives activity towards pre-determined outcomes, while “safe/fail experiments” steer away from negative outcomes while leaving space open for mistakes and innovation. Williams \"et al.\" also distinguish between the term “environment” as controlled, and “ecology” as free/open.\n\nCathy Davidson and David Theo Goldberg write in \"The Future of Learning Institutions in a Digital Age\" about the potential of “participatory learning,” and a new paradigm of education that is focused on mediated interactions between peers.\nThey argue that if institutions of higher learning could begin to value this type of learning, instead of simply trying to implement “Instructional Technology” in classrooms, they could transform old models of university education. Davidson and Goldberg introduce “Ten Principles for the Future of Learning,” which include self-learning, horizontal structures, and open source education. Peter Sloterdijk's recent book \"You Must Change Your Life\" proposes similar ideas in the context of a \"General Disciplinics\" that would \"counteract the atrophy of the educational system\" by focusing on forms of learning that takes place through direct participation in the disciplines. (p. 156)\n\nYochai Benkler & Helen Nissenbaum discuss implications for the realm of moral philosophy in their 2006 essay, \n\"Commons-Based Peer Production and Virtue\". They argue that the “socio-technical systems” of today’s Internet make it easier for people to role-model and adopt positive, virtuous behaviors on a large scale.\n\nJoseph Corneli and Charles Jeffrey Danoff proposed the label “paragogy” to describe a collection of “best practices of effective peer learning.” They published a short book\nalong with several papers in which they discuss five \"paragogical principles\" that form the core of their proposed learning theory. These were generated by rethinking Malcolm Knowles principles of andragogy for a learning context that is co-created by the learners.\n\nThe learning theories and approaches described above are currently being tested in peer-learning communities around the world, often adapting educational technology to support informal learning, though results in formal learning contexts exist too. For example, Eric Mazur and colleagues report on \"Ten years of experience and results\" with a teaching technique they call \"Peer Instruction\":\n\nThis approach made early use of a variant of the technique that is now known as the \"flipped classroom\":\n\nPeer 2 Peer University, or P2PU, which was founded in 2009 by Philipp Schmidt and others, is an example from the informal learning side. Speaking about the beginnings of P2PU, Schmidt echoes Siemens’ connectivism ideas and explains that, “The expertise is in the group. That’s the message, that everyone can bring something to the conversation.” In numerous public talks, Schmidt argues that current educational models are \"broken\" (particularly on the basis of the high cost of university-level training). He suggests that social assessment mechanisms similar to those applied in open-source software development can be applied to education. In practice, this approach uses peer-based assessment including recommendations and badges to provide an alternative form of accreditation.\n\nJeff Young’s article in the Chronicle of Higher Education, \"When Professors Print Their Own Diplomas\", sparked a conversation about the necessity of formal degrees in an age when class lectures can be uploaded for free. The MIT Open Teaching initiative, for example, has since 2001 put all of its course materials online. But David A. Wiley, then Psychology Professor at Utah State, went further, signing certificates for whoever takes his class. A similar practice has become even more visible in learning projects like Udacity, Coursera, and EdX. Although these projects attempt to \"scale education\" by distributing learning materials produced by experts (not classic examples of peer learning), they do frequently feature peer-to-peer discussions in forums or offline.\n\nIn the forward to a book on the \"Power of peer learning\" by Jean-H. Guilmette, Maureen O'Neil, then president of Canada's International Development Research Centre, states that\n\nGuilmette suggests that peer learning is useful in the development context because\n\nGuilmette cites Anne K. Bernard, who in a report based on extensive interviews, concludes:\n\nScardamalia and Bereiter explain in \"Computer Support for Knowledge-Building Communities\" that computers in the classroom have the opportunity to restructure the learning environment, but too often they are simply used to provide a digital version of a normal lesson or exam. They propose that classrooms be exchanged for “knowledge-building communities” where students can use computers to connect to and create knowledge in the outside world. However, as illustrated in citations above, this way of thinking about learning is often at odds with traditional educational praxis.\n\nIn \"The Role of the Learning Platform in Student-Centered E-Learning\", Kurliha, Miettinen, Nokelainen, and Tirri found a \"difference in\nlearning outcomes based on the tools used.\" However, the variables at work are not well understood, and are the subject of ongoing research. Within a formal education setting, a 1994 study found that students were more responsive to feedback from a teacher than they were to peer feedback. However, another later study showed that training in assessment techniques had a positive impact on individual student performance.\n\nA classic study on motivation in peer tutoring showed that \"reward is no motivator.\" Although other more recent work has shown that non-monetary rewards or acknowledgement can make a difference in \"performance\" (for certain populations of peer producers), the exact motivations for going out of the way to teach or tutor someone else are not clearly understood. As mentioned above, learning is often just part of solving a problem, so \"peer learning\" and \"peer teaching\" would tend to happen informally when people solve problems in groups.\n\nResearch on peer learning may involve participant observation, and may itself be peer produced. Some of this research falls under the broader umbrella of Scholarship of Teaching and Learning. Computer-supported collaborative learning is one obvious context in which to study peer learning, since in such settings \"learning is observably and accountably embedded in collaborative activity.\" However, peer learning can play a role in settings where traditional conceptions of both \"teaching\" and \"learning\" do not apply, for instance, in academic peer review, in organizational learning, in development work, and in public health programmes. Research in these areas may fall within the area of organization science, science, technology and society (STS) or other fields.\n\n"}
{"id": "24740", "url": "https://en.wikipedia.org/wiki?curid=24740", "title": "Political question", "text": "Political question\n\nIn American Constitutional law, the political question doctrine is closely linked to the concept of justiciability, as it comes down to a question of whether or not the court system is an appropriate forum in which to hear the case. This is because the court system only has authority to hear and decide a legal question, not a political question. Legal questions are deemed to be justiciable, while political questions are nonjusticiable. One scholar explained:\n\nA ruling of nonjusticiability will ultimately prohibit the issue that is bringing the case before the court from being able to be heard in a court of law. In the typical case where there is a finding of nonjusticiability due to the political question doctrine, the issue presented before the court is usually so specific that the Constitution gives all power to one of the coordinate political branches, or at the opposite end of the spectrum, the issue presented is so vague that the United States Constitution does not even consider it. A court can only decide issues based on law. The Constitution dictates the different legal responsibilities of each respective branch of government. If there is an issue where the court does not have the Constitution as a guide, there are no legal criteria to use. When there are no specific constitutional duties involved, the issue is to be decided through the democratic process. The court will not engage in political disputes.\n\nA constitutional dispute that requires knowledge of a non-legal character or the use of techniques not suitable for a court or explicitly assigned by the Constitution to the U.S. Congress, or the President of the United States, is a political question, which judges customarily refuse to address.\n\nThe doctrine has its roots in the historic Supreme Court case of \"Marbury v. Madison\" (1803). In that case, Chief Justice John Marshall drew a distinction between two different functions of the U.S. Secretary of State. Marshall stated that when the Secretary of State was performing a purely discretionary matter, such as advising the President on matters of policy, he was not held to any legally identifiable standards. Therefore, some of the Secretary's actions are unable to be reviewed by a court of law.\n\nThe doctrine is grounded in the federal judiciary's desire to avoid inserting itself into conflicts between branches of the federal government. It is justified by the notion that there exist some questions best resolved through the political process, voters approving or correcting the challenged action by voting for or against those involved in the decision.\n\nThe leading Supreme Court case in the area of political question doctrine is \"Baker v. Carr\" (1962). In the opinion written for Baker, the Court outlined six characteristics of a political question. These include:\n\nWhile this is a still rather unsettled doctrine, its application has been settled in a few decided areas. These areas are:\n\nThe Guarantee Clause, Article IV, section 4, requires the federal government to \"guarantee to every State in this Union a Republican Form of Government\". The Supreme Court has declared that this Clause does not imply any set of \"judicially manageable standards which a court could utilize independently in order to identify a State's lawful government\".\n\nArticle I, section 2 of the Constitution states that the House \"shall have the sole power of Impeachment\", and Article I, section 3 provides that the \"Senate shall have the sole Power to try all Impeachments\". Since the Constitution placed the sole power of impeachment in two political bodies, it is qualified as a political question. As a result, neither the decision of the House to impeach nor a vote of the Senate to remove a President or any other official can be appealed to any court. \n\n\n\n\nImportant cases discussing the political question doctrine:\n\nThe political question doctrine has also had significance beyond American constitutional law. \n\nBefore international courts, the International Court of Justice has dealt with the doctrine in its advisory function, and the European Court of Human Rights has engaged with the doctrine through the margin of appreciation. \n\nWithin European Union law, the Court of Justice of the European Union has never addressed the political question doctrine in its jurisprudence explicitly, yet it has been argued that there are traces of the doctrine present in its rulings. \n\n"}
{"id": "38841583", "url": "https://en.wikipedia.org/wiki?curid=38841583", "title": "Program on Energy Efficiency in Artisanal Brick Kilns in Latin America to Mitigate Climate Change", "text": "Program on Energy Efficiency in Artisanal Brick Kilns in Latin America to Mitigate Climate Change\n\nThe Program on Energy Efficiency in Artisanal Brick Kilns in Latin America to Mitigate Climate Change (EELA) is a program of the Swiss Agency for Development and Cooperation (SDC) which is implemented by Swiss contact in conjunction with its partners in nine countries in Latin America. The objective is to mitigate climate change through the reduction of greenhouse gas emissions in Latin America and to improve the quality of life of the population in the areas of intervention.\n\nArtisanal brick producers in Latin America use fuel with high environmental impact in kilns with low energy efficiency. Wood, tires and plastics, among other fuels, are used to fire bricks, contributing to air pollution and deforestation as well as increasing the causes of climate change. Despite their contribution to the construction industry and the generation of jobs, artisanal brick producers largely operate informally and are generally excluded from social, environmental and economic public policies.\n\nThe EELA program is focused on developing management models for artisanal brick producers, and includes activities that range from the adoption of more efficient production processes that require less fuel and emit less greenhouse gases, to the creation of new products that use less raw materials.\n\nEELA began its first phase working with 970 artisanal brick producers in seven areas located in San Juan (Argentina), Cochabamba (Bolivia), Serido (Brazil), Nemocon (Colombia), Cuenca (Ecuador), Leon (Mexico) and Cusco (Peru). In 2012, Nicaragua and Honduras joined the initiative. The experience gained in the pilot areas will serve as a basis to expand EELA’s intervention at a national level.\n\nEELA hopes to reduce the GHG emissions of artisanal brick producers in the countries of operation by 30% and increase their income by 10%.\n\nIn conjunction with the Ministry of Production, the Regional Directorate of Production and the Municipality of San Jeronimo, EELA works to promote good manufacturing practices to better employ heat as well as provide technical assistance in the following areas:\n\nEELA constructed a downdraft kiln that is more efficient than a traditional kiln and that is affordable for an artisanal brick producer. The kiln is being replicated by brick producers in San Jerónimo, Cuenca (Ecuador) and in Mexico.\n\nIn a second phase, EELA will seek to improve the management models through the use of knowledge gained from its first phase. \nEELA is supported by a group of partners that includes both public and private entities with experience in the brick sector, in each of the countries in which it operates.\n\n"}
{"id": "5609345", "url": "https://en.wikipedia.org/wiki?curid=5609345", "title": "Prohairesis", "text": "Prohairesis\n\nProhairesis (; variously translated as \"moral character\", \"will\", \"volition\", \"choice\", \"intention\", or \"moral choice\") is a fundamental concept in the Stoic philosophy of Epictetus. It represents the choice involved in giving or withholding assent to impressions (phantasiai). The use of this Greek word was first introduced into philosophy by Aristotle in the \"Nicomachean Ethics\". To Epictetus, it is the faculty that distinguishes human beings from all other creatures. The concept of prohairesis plays a cardinal role in the \"Discourses\" and in the \"Manual\": the terms \"prohairesis\", \"prohairetic\", and \"aprohairetic\" appear some 168 times.\n\nAccording to Epictetus, nothing is properly considered either good, or bad, aside from those things that are within our own power to control, and the only thing fully in our power to control is our own volition (prohairesis) which exercises the faculty of choice that we use to judge our impressions. For example, if a person says something critical to us, that is not bad; or, if something complimentary is said, that is not good, because such things are externals and not in our power to control. By exerting the power of choice, it is possible to maintain equanimity in the face of either criticism and praise, which is a moral good. On the other hand, when people become troubled by criticism, or elated by praise, that is a moral evil because they have misjudged impressions by thinking that things not in their power (such as criticism or praise) have value, and by doing that they place a measure of control of their own life in the hands of others. \n\nThe importance of prohairesis for Epictetus is that it exerts a power that allows people to choose how they will react to impressions rationally:\n\nRemember that what is insulting is not the person who abuses or hits you, but the judgment that these things are insulting. So when someone irritates you, realize that it is your own opinion that has irritated you. Try, therefore, in the first place, not to be carried away by the impression; for if you once gain time and respite, you will find it easier to control yourself. \n\nBy exerting their prohairesis (will, volition, or choice), people can choose rationally how to react to impressions. Prohairesis is the faculty that distinguishes human beings from all other creatures. Epictetus defines it as:\n"}
{"id": "43732489", "url": "https://en.wikipedia.org/wiki?curid=43732489", "title": "Purple economy", "text": "Purple economy\n\nThe purple economy is that part of the economy which contributes to sustainable development by promoting the cultural potential of goods and services.\n\n“The purple economy refers to taking account of cultural aspects in economics. It designates an economy that adapts to the human diversity in globalization and that relies on the cultural dimension to give value to goods and services.” These two trends, one vertical and one horizontal, feed one another. In fact the growth in the cultural component attached to products is linked to each territory’s cultural vitality.\n\nThe context of the purple economy is that of the growing importance of culture in contemporary society. The factors involved in this include in particular: a global economic and political readjustment in favour of emerging countries, a return to local environments (once again perceived as centres for stability), new forms of claims (following on from the collapse of the great ideologies), growing social demand for quality based on cultural consumption patterns (which go hand in hand with the logic of popularization, individualization and longer life expectancies), innovative approaches (that presuppose a cultural state of mind and interdisciplinarity conducive to serendipity), and so on.\n\nThe purple economy is multidisciplinary, in that it enriches all goods and services by capitalizing on the cultural dimension inherent to every sector. The sensory, experiential economy is one application of this.\n\nIt differs from the cultural economy, which is sector-based.\n\nIn June 2013, the conclusions of a first inter-institutional working group on the purple economy, formed of experts from UNESCO, the OECD, the International Organisation of the Francophonie, French ministries, various companies and civil society. That document underscored the impact of the phenomenon of culturalization, which now affects the entire economy, with follow-on effects on employment and training. The report differentiates between \"purple jobs\" and \"purplifying professions\": the former are directly linked to the cultural environment by their very purpose (like town planners and developers), while the latter are merely caused to transform under the effect of culturalization (such as positions in human resources or in marketing and communications).\n\nAnother reference document published in June 2017 mentioned various aspects of the human environment in which economics are likely to produce cultural benefits: architecture, art, colours, enjoyment, ethics, heritage, imagination, learning, social skills, singularity, etc.\n\nThe term first appeared in 2011, in France, in a manifest published on Le Monde.fr. The signatories included the board members of the association Diversum, which organized the first International Purple Economy Forum under the patronage of UNESCO, the European Parliament and the European Commission.\n\nThe purple economy emphasizes the presence of externalities: the cultural environment from which agents draw and on which, in return, they leave their own footprints is a common good. As a result, the purple economy sees culture as an axis for sustainable development.\n\nIn fact, culture has been a whole sub-section of sustainability since the beginning. Corporate social responsibility can even be said to have originated in the International Covenant on Economic, Social and Cultural Rights adopted by the United Nations in 1966.\n\nThis issue is just one of the different components of sustainable development, alongside concerns relating to the natural environment (green economy) and to the social environment (social economy). The complementary nature of these aspects of the sustainable economy was reaffirmed in a call published by \"Le Monde Économie\" in 2015, leading up to the 21st United Nations Conference on Climate Change.\n"}
{"id": "26000505", "url": "https://en.wikipedia.org/wiki?curid=26000505", "title": "Quadray coordinates", "text": "Quadray coordinates\n\nQuadray coordinates, also known as tetray coordinates or Chakovian coordinates, were Invented by Darrel Jarmusch and further developed by David Chako, Tom Ace, Kirby Urner, et al., as another take on simplicial coordinates, a coordinate system using a simplex or tetrahedron as its basis polyhedron.\n\nThe four basis vectors stem from the center of a regular tetrahedron and go to its four corners. Their coordinate addresses are (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) and (0, 0, 0, 1) respectively. These may be scaled and linearly combined to span conventional \"XYZ\" space, with at least one of the four coordinates unneeded (set to zero) in any given quadrant.\n\nThe normalization scheme is somewhat unusual in keeping all coordinates non-negative. Typical of coordinate systems of this type (a, a, a, a) is an identity vector and may be added to normalize a result. To negate (1,0,0,0), write (−1, 0, 0, 0) then add (1, 1, 1, 1) to get (0, 1, 1, 1).\n\nA typical application might set the edges of the basis tetrahedron as unit, with the quadrays considered unit on some other scale. The tetrahedron itself may also be defined as the unit of volume, although the infrastructure does not demand using this setting.\n\nThe four quadrays may be linearly combined to provide integer coordinates for the inverse tetrahedron (0,1,1,1), (1,0,1,1), (1,1,0,1), (1,1,1,0), and for the cube, octahedron, rhombic dodecahedron and cuboctahedron of volumes 3, 4, 6 and 20 respectively, given the starting tetrahedron of unit volume.\n\nFor example, given A, B, C, D as (1,0,0,0), (0,1,0,0), (0,0,1,0) and (0,0,0,1) respectively, the vertices of an octahedron with the same edge length and volume four would be A + B, A + C, A + D, B + C, B + D, C + D or all eight permutations of {1,1,0,0}. The vertices of the volume 20 cuboctahedron are all 12 permutations of {2,1,1,0}.\n\nIf one now calls this volume \"4D\" as in \"four-dimensional\" or \"four-directional\" we have primed the pump for an understanding of R. Buckminster Fuller's \"4D geometry,\" or \"Synergetics\".\n\n\n"}
{"id": "13403591", "url": "https://en.wikipedia.org/wiki?curid=13403591", "title": "Rate of response", "text": "Rate of response\n\nIn behaviorism, rate of response is a ratio between two measurements with different units. Rate of responding is the number of responses per minute, or some other time unit. It is usually written as \"R\". Its first major exponent was B.F. Skinner (1939). It is used in the Matching Law.\n\n\"R\" = # of Responses/Unit of time = \"B\"/\"t\"\n\n\n"}
{"id": "36307450", "url": "https://en.wikipedia.org/wiki?curid=36307450", "title": "Reactive transport modeling in porous media", "text": "Reactive transport modeling in porous media\n\nReactive transport modeling in porous media refers to the creation of computer models integrating chemical reaction with transport of fluids through the Earth's crust. Such models predict the distribution in space and time of the chemical reactions that occur along a flowpath. Reactive transport modeling in general can refer to many other processes, including reactive flow of chemicals through tanks, reactors, or membranes; particles and species in the atmosphere; gases exiting a smokestack; and migrating magma.\n\nReactive transport models are constructed to understand the composition of natural waters; the origin of economic mineral deposits; the formation and dissolution of rocks and minerals in geologic formations in response to injection of industrial wastes, steam, or carbon dioxide; and the generation of acidic waters and leaching of metals from mine wastes. They are often relied upon to predict the migration of contaminant plumes; the mobility of radionuclides in waste repositories; and the biodegradation of chemicals in landfills. When applied to the study of contaminants in the environments, they are known as fate and transport models.\n\nModern reactive transport modeling has arisen from several separate schools of thought. Hydrologists primarily concerned with the physical nature of mass transport assumed relatively simple reaction formulations, such as linear distribution coefficients or linear decay terms, which could be added to the advection-dispersion equation. By assuming linear, equilibrium sorption, for example, the advection-dispersion equation can be modified by a simple retardation factor and solved analytically. Such analytical solutions are limited to relatively simple flow systems and reactions.\n\nGeochemical models, on the other hand, have been developed to provide thermodynamic descriptions of multicomponent systems without regard to transport. Reaction path models were created, for instance, to describe the sequence of chemical reactions resulting from chemical weathering or hydrothermal alteration in batch systems, in terms of the overall reaction progress. By adopting the reference frame of a packet of fluid and treating reaction progress as travel time (or distance along a flowpath), however, a batch reaction path model could be thought of as describing advective transport through an aquifer.\n\nThe most sophisticated multi-component reactive transport models considered both reaction and transport. Early studies developed the theoretical basis of reactive transport models, and the numerical tools necessary to solve them, and applied them to problems of reactive contaminant transport and flow through reacting hydrothermal systems.\n\nReactive transport models have found increased application in recent years with improvements in the power of personal computers and modeling software.\n\nReactive transport models couple a large number chemical reactions with mass transport. Certain applications, such as geothermal energy production and ore deposit modeling, require the additional calculation of heat transfer. In modeling carbon sequestration and hydraulic fracturing, moreover, it may be necessary to describe rock deformation resulting from mineral growth or abnormally high fluid pressure. Description of transport through the unsaturated zone and multiphase flow modeling, as applied to transport of petroleum and natural gas; non-aqueous phase liquids (DNAPL or LNAPL); and supercritical carbon dioxide requires increasingly complex models which are prone to considerable uncertainty.\n\nIn many cases the processes simulated in reactive transport models are highly related. Mineral dissolution and precipitation, for example, can affect the porosity and permeability of the domain, which in turn affect the flow field and groundwater velocity. Heat transport greatly affects the viscosity of water and its ability to flow. Below are many of the physical and chemical processes which can be simulated with reactive transport models.\n\nGeochemical reactions:\n\nMass Transport:\n\nHeat transport:\n\nMedium deformation:\n\nSome of the simplest reactive transport problems can be solved analytically. Where equilibrium sorption is described by a linear distribution coefficient, for example, the sorbing solute's velocity is retarded relative to that of a nonreactive tracer; the relative velocities can be described with a retardation factor. Analytical solutions are exact solutions of the governing equations. \n\nComplex reactive transport problems are more commonly solved numerically. In this case, the governing equations are approximated so that they can be solved by computer algorithms. The governing equations, including both reaction and transport terms, can be solved simultaneously using a one-step or global implicit simulator. This technique is straightforward conceptually, but computationally very difficult.\n\nInstead of solving all the relevant equations together, the transport and chemical reaction equations can be solved separately. Operator splitting, as this technique is known, uses appropriate numerical techniques to solve the reaction and transport equations at each time step. Various methods exist, including the sequential non-iterative approach (SNIA), Strang splitting, and sequential iterative approach (SIA). Since the reaction and transport terms are handled separately, separate programs for batch reaction and transport can be linked together. Cross-linkable re-entrant software objects designed for this purpose readily enable construction of reactive transport models of any flow configuration.\n\nReactive transport modeling requires input from numerous fields, including hydrology, geochemistry and biogeochemistry, microbiology, soil physics, and fluid dynamics. The numerical formulation and solution of reactive transport problems can be especially difficult due to errors arising in the coupling process, beyond those inherent to the individual processes. Valocchi and Malmstead (1992), for example, reported on the potential errors arising from the operator splitting technique.\n\nEven in the absence of numerical difficulties, the general lack of knowledge available to practitioners creates uncertainty. Field sites are typically heterogeneous, both physically and chemically, and sampling is often sparse. The prevailing assumption of Fickian dispersion is often inadequate. Equilibrium constants and kinetic rate laws for relevant reactions are often poorly known. The complexity of many processes requires expertise in one or more of the above mentioned fields. Many processes, such as long-term nuclear waste storage, cannot be experimentally verified; reactive transport problems can only attempt to predict such long-term behavior. The current descriptions of multi-phase flow and mechanical deformation processes are still being developed.\n\n\n\n"}
{"id": "26644416", "url": "https://en.wikipedia.org/wiki?curid=26644416", "title": "Relaxation (psychology)", "text": "Relaxation (psychology)\n\nRelaxation in psychology, is the emotional state of a living being, of low tension, in which there is an absence of arousal that could come from sources such as anger, anxiety, or fear. According to the Oxford dictionary relaxation is when the body and mind are free from tension and anxiety. Relaxation is a form of mild ecstasy coming from the frontal lobe of the brain in which the backward cortex sends signals to the frontal cortex via a mild sedative. Relaxation can be achieved through meditation, autogenics, and progressive muscle relaxation. Relaxation helps improve coping with stress. Stress is the leading cause of mental problems and physical problems, therefore feeling relaxed is beneficial for a person's health. When we are stressed, the sympathetic nervous system is activated because we are in a fight-or-flight response mode; over time, this could have negative effects on a human body.\n\nThe idea of relaxation in psychology was popularized by Dr.Edmund Jacobson in his published book \"Progressive Relaxation\". It was a technical book intended for doctors and scientists. His book describes tensing and relaxing specific muscles at a time to achieve overall relaxation in the body. Jacobson then published another book called \"You Must Relax \"published in 1934 that was geared towards the general public. According to Jacobson, his research started in 1908 at Harvard University, and later moving on to Cornell and University of Chicago. His research was aimed at improving the general human well being.\n\nIn 1932, Johannes Schultz and Wolfgang Luthe developed a method of relaxation that emphasized using the power of suggestion, called autogenic training.\n\nIn 1975, Herbert Benson and Mirium Z. Klipper published a book called \"The Relaxation Response\", which gives instructions on tying meditation techniques into daily activities the average person could do.\n\nAlthough stress levels vary across society, the fact remains that stress can be detrimental to one's health. In order to combat this stress, there have been a variety of methods developed that have been proven to reduce stress and its consequences in everyday life. The majority of techniques can be classified in to either Physical, Mental or Therapeutic techniques.\n\nBreathing techniques is one of the easiest ways to reduce stress. It requires little effort and can be done anywhere at any time. Proper breathing techniques that incorporate deep abdominal breathing have been shown to reduce the physical symptoms of depression, anxiety and hypertension as well as everyday emotional symptoms of anger and nervousness.\n\nProgressive muscle relaxation is a relaxation technique that requires an individual to focus on flexing and holding a certain set of muscles and then slowly relaxing those same muscles. As the individual flexes and releases those muscles from top to bottom they will feel a deep sense of relaxation. Progressive muscle relaxation is a somewhat adapted version of the Jacobsonian Relaxation Technique developed in the 1920s. Progressive muscle relaxation is currently used in clinical and non-clinical settings to reduce the effects of anxiety and sleeplessness brought upon by stress. The long-term goal of this relaxation technique is to be able to identify when your body's muscles are suffering the effects of stress and to be able to relax the individual and the individuals muscles when directed.\n\nMeditation has long been practiced in other regions around the world. However, it is a practice that is fairly new to North America and it is gaining attention quickly for the physical and psychological benefits it provides to your body. Studies have shown that in addition to reducing physiological and psychological stresses placed on your body, individuals who practice meditation have much fewer doctor visits for both physical and psychological illnesses.\n\nHypnosis relaxation therapy has recently become another technique used among healthcare professionals to promote relaxation. When performed correctly, hypnosis has the ability to put an individual in a deep state of relaxation. During this state the individual is vulnerable to suggestions stated by the person performing the hypnosis. Not only will the hypnotized individual be stress free and in a deep state of relaxation but it is thought that when the individual is out of hypnosis they will be less susceptible to the effects of stress as suggested by the person who performed the hypnosis on them. In addition to relaxation, hypnosis therapy is being used to treat a variety of conditions. Treatments for conditions using hypnosis that are currently being promoted by The Mayo Clinic are; smoking addiction therapy, pain control therapy, weight loss, coping with chemotherapy, asthma, and allergy relief.\n\nRelaxation techniques used in therapy by a certified counselor or therapist could include any of the previous techniques discussed. Professionals in the fields of psychology or counseling will have the ability to administer a variety of these techniques. If they feel it is appropriate they may prescribe medication to assist the patient with relaxation. Although a number of these techniques are simple and can be performed on one's own time, patients may receive better results if they are guided by a professional who is very familiar with the techniques.\n\nHerbert Benson, a professor at the medical school at Harvard University, has proposed in his book \"The Relaxation Response\" a mechanism of the body that counters the fight-or-flight response. The relaxation response reduces the body’s metabolism, heart and breathing rate, blood pressure, muscle tension, and calms brain activity. It increases the immune response, helps attention and decision making, and changes gene activities that are the opposite of those associated stress. The relaxation response is achieved through meditation. Benson's meditation technique involves these four steps:\n\nAutogenics was invented by Dr. Johannes Heinrich Schultz in the 1920s. The process of autogenics is by relaxing muscles deeply, and by doing so, the mind follows through and relaxes as well. There as six parts to autogenics training:\n\nProgressive muscle relaxation helps relax your muscles by tensing certain parts of the body (such as the neck), and then releasing the tension in order to feel the muscles relaxing. This technique helps for people with anxiety because they are always tense throughout the day.\n\nThe benefits of relaxation can be found in three main areas of an individual’s health, including; mental, physical and physiological health. Being relaxed can do positive things for someone’s health from just elevating your mood to helping with insomnia. All of these things can help an individual live a happier and healthier life and may increase the longevity of one's life. There are not many draw backs of relaxation. It is an easy technique to understand and follow through with. Three categories that relaxation can help with are mental, physical, and physiological.\n\nMental health is very important and needs to be worked on every day. Relaxation can help with many impairments that can occur in one's mental health. There is a higher mood and lower anxiety in those who practice relaxation techniques. Those who are relaxed have much slower and clearer thought processes than those who are not relaxed; this can be shown on an EEG. It is well known that relaxation can help reduce stress. With reducing stress, a person can help reduce the negative things that stress can do to the body. Coping mechanisms are also improved with relaxation techniques in both mental and physical pain.\n\nSleep disorders are an area that can produce stress and mental health issues. Relaxation may help reduce insomnia in those who have sleeping disorders. Those with insomnia may even give up sleeping aids just by practicing relaxation techniques. Being off of unnecessary medication or sleep aids will help health as an over all. Even though relaxation cannot get rid of chronic diseases, it may help dull of the symptoms one may have. Many cancer and AIDS patients are taught relaxation techniques.\n\nPhysical health is also something that needs to be worked on daily, whether it is exercise, healthy eating, or relaxation. states that blood pressure, heart rate, and respiration rate will all decrease when one is relaxed. This means that a person's heart does not beat as fast and their breathing is shallow, helping one's body have time to rest. This will reduce the extra stress that these things can do to the body if they are over worked. Muscle tension will decrease. If one's muscle tension is decreased they are not burning up extra energy that they may need later in the day. Metabolism can also decrease; this is mostly seen in hibernation and sleep and that gives the body extra time to rest and focus on other aspect that it needs to. This could be seen as a good or bad thing, depending on the overall quality of health. People who practice relaxation have said to be able to tolerate pain better both mentally and physically.\n\nIn regards to the nervous system, relaxation can also play a big role. An individual will go from active and alert, which is the sympathetic, to parasympathetic which is rest and digest. When they are relaxing, it gives the body time to catch up. A person does not need to worry about running, because they are sitting still and allowing “rest and digest”. Immune systems will increase with increased relaxation which is why relaxation can be seen as part of treatment for AIDS and cancer patients.\n\n\n"}
{"id": "25964", "url": "https://en.wikipedia.org/wiki?curid=25964", "title": "Revolution", "text": "Revolution\n\nIn political science, a revolution (Latin: \"revolutio\", \"a turn around\") is a fundamental and relatively sudden change in political power and political organization which occurs when the population revolt against the government, typically due to perceived oppression (political, social, economic). In book V of the \"Politics\", the Ancient Greek philosopher Aristotle (384–322 BC) described two types of political revolution:\n\nRevolutions have occurred through human history and vary widely in terms of methods, duration and motivating ideology. Their results include major changes in culture, economy and socio-political institutions, usually in response to perceived overwhelming autocracy or plutocracy.\n\nScholarly debates about what does and does not constitute a revolution center on several issues. Early studies of revolutions primarily analyzed events in European history from a psychological perspective, but more modern examinations include global events and incorporate perspectives from several social sciences, including sociology and political science. Several generations of scholarly thought on revolutions have generated many competing theories and contributed much to the current understanding of this complex phenomenon.\n\nNotable revolutions during later centuries include the creation of the United States through the American Revolutionary War (1775-1783), the French Revolution (1789-1799), the 1848 European Revolutions, The Russian Revolutions in March and November 1917. \nThe word \"revolucion\" is known in French from the 13th century, and \"revolution\" in English by the late fourteenth century, with regard to the revolving motion of celestial bodies. \"Revolution\" in the sense of representing abrupt change in a social order is attested by at least 1450. Political usage of the term had been well established by 1688 in the description of the replacement of James II with William III. This incident was termed the \"Glorious Revolution\".\nThere are many different typologies of revolutions in social science and literature.\n\nAlexis de Tocqueville differentiated between; \n\nOne of several different Marxist typologies divides revolutions into; \n\nCharles Tilly, a modern scholar of revolutions, differentiated between; \n\nMark Katz identified six forms of revolution;\n\nThese categories are not mutually exclusive; the Russian revolution of 1917 began with urban revolution to depose the Czar, followed by rural revolution, followed by the Bolshevik coup in November. Katz also cross-classified revolutions as follows;\n\nA further dimension to Katz's typology is that revolutions are either against (anti-monarchy, anti-dictatorial, anti-communist, anti-democratic) or for (pro-fascism, communism, nationalism etc.).In the latter cases, a transition period is often necessary to decide on the direction taken.\n\nOther types of revolution, created for other typologies, include the social revolutions; proletarian or communist revolutions (inspired by the ideas of Marxism that aims to replace capitalism with Communism); failed or abortive revolutions (revolutions that fail to secure power after temporary victories or large-scale mobilization); or violent vs. nonviolent revolutions.\n\nThe term \"revolution\" has also been used to denote great changes outside the political sphere. Such revolutions are usually recognized as having transformed in society, culture, philosophy, and technology much more than political systems; they are often known as social revolutions. Some can be global, while others are limited to single countries. One of the classic examples of the usage of the word \"revolution\" in such context is the Industrial Revolution, or the Commercial Revolution. Note that such revolutions also fit the \"slow revolution\" definition of Tocqueville.\nA similar example is the Digital Revolution.\n\nPerhaps most often, the word \"revolution\" is employed to denote a change in social and political institutions. Jeff Goodwin gives two definitions of a revolution. First, a broad one, including\nany and all instances in which a state or a political regime is overthrown and thereby transformed by a popular movement in an irregular, extraconstitutional and/or violent fashion.\nSecond, a narrow one, in which\n\nrevolutions entail not only mass mobilization and regime change, but also more or less rapid and fundamental social, economic and/or cultural change, during or soon after the struggle for state power.\n\nJack Goldstone defines a revolution as\nan effort to transform the political institutions and the justifications for political authority in society, accompanied by formal or informal mass mobilization and non-institutionalized actions that undermine authorities.\n\nPolitical and socioeconomic revolutions have been studied in many social sciences, particularly sociology, political sciences and history. Among the leading scholars in that area have been or are Crane Brinton, Charles Brockett, Farideh Farhi, John Foran, John Mason Hart, Samuel Huntington, Jack Goldstone, Jeff Goodwin, Ted Roberts Gurr, Fred Halliday, Chalmers Johnson, Tim McDaniel, Barrington Moore, Jeffery Paige, Vilfredo Pareto, Terence Ranger, Eugen Rosenstock-Huessy, Theda Skocpol, James Scott, Eric Selbin, Charles Tilly, Ellen Kay Trimberger, Carlos Vistas, John Walton, Timothy Wickham-Crowley, and Eric Wolf.\n\nScholars of revolutions, like Jack Goldstone, differentiate four current 'generations' of scholarly research dealing with revolutions. The scholars of the first generation such as Gustave Le Bon, Charles A. Ellwood, or Pitirim Sorokin, were mainly descriptive in their approach, and their explanations of the phenomena of revolutions was usually related to social psychology, such as Le Bon's crowd psychology theory.\n\nSecond generation theorists sought to develop detailed theories of why and when revolutions arise, grounded in more complex social behavior theories. They can be divided into three major approaches: psychological, sociological and political.\n\nThe works of Ted Robert Gurr, Ivo K. Feierbrand, Rosalind L. Feierbrand, James A. Geschwender, David C. Schwartz, and Denton E. Morrison fall into the first category. They followed theories of cognitive psychology and frustration-aggression theory and saw the cause of revolution in the state of mind of the masses, and while they varied in their approach as to what exactly caused the people to revolt (e.g., modernization, recession, or discrimination), they agreed that the primary cause for revolution was the widespread frustration with socio-political situation.\n\nThe second group, composed of academics such as Chalmers Johnson, Neil Smelser, Bob Jessop, Mark Hart, Edward A. Tiryakian, and Mark Hagopian, followed in the footsteps of Talcott Parsons and the structural-functionalist theory in sociology; they saw society as a system in equilibrium between various resources, demands and subsystems (political, cultural, etc.). As in the psychological school, they differed in their definitions of what causes disequilibrium, but agreed that it is a state of a severe disequilibrium that is responsible for revolutions.\n\nFinally, the third group, which included writers such as Charles Tilly, Samuel P. Huntington, Peter Ammann, and Arthur L. Stinchcombe followed the path of political sciences and looked at pluralist theory and interest group conflict theory. Those theories see events as outcomes of a power struggle between competing interest groups. In such a model, revolutions happen when two or more groups cannot come to terms within a normal decision making process traditional for a given political system, and simultaneously have enough resources to employ force in pursuing their goals.\n\nThe second generation theorists saw the development of the revolutions as a two-step process; first, some change results in the present situation being different from the past; second, the new situation creates an opportunity for a revolution to occur. In that situation, an event that in the past would not be sufficient to cause a revolution (e.g., a war, a riot, a bad harvest), now is sufficient; however, if authorities are aware of the danger, they can still prevent a revolution through reform or repression.\n\nMany such early studies of revolutions tended to concentrate on four classic cases: famous and uncontroversial examples that fit virtually all definitions of revolutions, such as the Glorious Revolution (1688), the French Revolution (1789–1799), the Russian Revolution of 1917, and the Chinese Revolution (also known as the Chinese Civil War) (1927–1949). In his \"The Anatomy of Revolution\", however, the Harvard historian Crane Brinton focused on the English Civil War, the American Revolution, the French Revolution, and the Russian Revolution.\n\nIn time, scholars began to analyze hundreds of other events as revolutions (see List of revolutions and rebellions), and differences in definitions and approaches gave rise to new definitions and explanations. The theories of the second generation have been criticized for their limited geographical scope, difficulty in empirical verification, as well as that while they may explain some particular revolutions, they did not explain why revolutions did not occur in other societies in very similar situations.\n\nThe criticism of the second generation led to the rise of a third generation of theories, with writers such as Theda Skocpol, Barrington Moore, Jeffrey Paige, and others expanding on the old Marxist class conflict approach, turning their attention to rural agrarian-state conflicts, state conflicts with autonomous elites, and the impact of interstate economic and military competition on domestic political change Particularly Skocpol's \"States and Social Revolutions\" became one of the most widely recognized works of the third generation; Skocpol defined revolution as \"rapid, basic transformations of society's state and class structures [...] accompanied and in part carried through by class-based revolts from below\", attributing revolutions to a conjunction of multiple conflicts involving state, elites and the lower classes.\nFrom the late 1980s a new body of scholarly work began questioning the dominance of the third generation's theories. The old theories were also dealt a significant blow by new revolutionary events that could not be easily explain by them. The Iranian and Nicaraguan Revolutions of 1979, the 1986 People Power Revolution in the Philippines and the 1989 Autumn of Nations in Europe saw multi-class coalitions topple seemingly powerful regimes amidst popular demonstrations and mass strikes in nonviolent revolutions.\n\nDefining revolutions as mostly European violent state versus people and class struggles conflicts was no longer sufficient. The study of revolutions thus evolved in three directions, firstly, some researchers were applying previous or updated structuralist theories of revolutions to events beyond the previously analyzed, mostly European conflicts. Secondly, scholars called for greater attention to conscious agency in the form of ideology and culture in shaping revolutionary mobilization and objectives. Third, analysts of both revolutions and social movements realized that those phenomena have much in common, and a new 'fourth generation' literature on contentious politics has developed that attempts to combine insights from the study of social movements and revolutions in hopes of understanding both phenomena.\n\nFurther, social science research on revolution, primarily work in political science, has begun to move beyond individual or comparative case studies towards large-N empirical studies assessing the causes and implications of revolution. Initial studies generally rely on the Polity Project’s data on democratization. Such analyses, like those by Enterline, Maoz, and Mansfield and Snyder, identify revolutions based on regime changes indicated by a change in the country’s score on Polity’s autocracy to democracy scale. More recently, scholars like Jeff Colgan have argued that Polity, which measures the degree of democratic or autocratic authority in a state's governing institutions based on the openness of executive recruitment, constraints on executive authority, and political competition, is inadequate because it measures democratization, not revolution, and fails to account for regimes which come to power by revolution but fail to change the structure of the state and society sufficiently to yield a notable difference in Polity score. Instead, Colgan offers a new data set on revolutionary leaders which identifies governments that \"transform the existing social, political, and economic relationships of the state by overthrowing or rejecting the principal existing institutions of society.\" This most recent data set has been employed to make empirically-based contributions to the literature on revolution by identifying links between revolution and the likelihood of international disputes.\n\nRevolutions have also been approached from anthropological perspectives. Drawing on Victor Turner’s writings on ritual and performance, Bjorn Thomassen has argued that revolutions can be understood as \"liminal\" moments: modern political revolutions very much resemble rituals and can therefore be studied within a process approach. This would imply not only a focus on political behavior \"from below\", but also to recognize moments where \"high and low\" are relativized, made irrelevant or subverted, and where the micro and macro levels fuse together in critical conjunctions.\n\nEconomist Douglass North argued that it is much easier for revolutionaries to alter formal political institutions such as laws and constitutions than to alter informal social conventions. According to North, inconsistencies between rapidly changing formal institutions and slow-changing informal ones can inhibit effective sociopolitical change. Because of this, the long-term effect of revolutionary political restructuring is often more moderate than the ostensible short-term effect.\n\nWhile revolutions encompass events ranging from the relatively peaceful revolutions that overthrew communist regimes to the violent Islamic revolution in Afghanistan, they exclude \"coups d'état\", civil wars, revolts, and rebellions that make no effort to transform institutions or the justification for authority (such as Józef Piłsudski's May Coup of 1926 or the American Civil War), as well as peaceful transitions to democracy through institutional arrangements such as plebiscites and free elections, as in Spain after the death of Francisco Franco.\n\n\n\n"}
{"id": "49682842", "url": "https://en.wikipedia.org/wiki?curid=49682842", "title": "Right to be heard", "text": "Right to be heard\n\nThe right to be heard (also children's participation) is a child rights principle as defined by the UN Convention on the Rights of the Child. According to Article 12 of the Convention, children have the right to express their views in all matters affecting them and their views have to be given due weight in accordance with the age and maturity of the child. This right applies equally to children’s participation in social and political matters as well as in judicial and administrative proceedings. As a general principle, the child’s right to be heard reflects the concept of children‘s ‘agency’, viewing children not only as vulnerable persons in need of special protection, but also as informed decision makers, rights holders and active members of society.\n\nThe right to be heard from Article 12 relates closely to other articles under the Convention, which together form the so-called ‘participatory rights’ of children and underline the understanding of children as citizens who are rights holders. These articles include:\n\nTrust is a key element of encouraging a child to express their views. Strategies for building trust with children include: \n\nIn the cases of younger children or children with impaired cognitive skills, the child’s participation can be through drawing or play, or by observing of the child’s behaviour with family members and care staff. Adapting the language to the age and development of the child helps insure the child can understand the issues at stake and express her or his feelings and views.\n\nNational laws usually define age limits for children to have the right to contact social services on their own initiative, to be heard in judicial and administrative procedures, to act as a litigant or party to a case, to appeal against decisions, and to complain and seek redress. The age limits defined under national law differ among countries and, in some cases, also between the various laws applying to different groups of children and contexts. The right of younger children to be heard is often not addressed in the same way as the right of adolescents. Special measures nationally can ensure younger children are not excluded from exercising their right to be heard.\n\nFor some children, the gender of the interviewer, interpreter, cultural mediator, guardian or care staff may change their willingness to express themselves. The may depend on the experiences that children have with men and women in their homes and communities, and if in migration, during their journey or in places of destination. Traditional gender roles and relations can also play a role. The gender identity of the child should be respected.\n\nMany children do not want to tell their story to the authorities because they fear it might not be in their interest and might lead to unwanted consequences, such as being returned. Children might have been instructed or even threatened by third persons to only tell parts of their story, and the child might not trust the police and local authorities can protect them. A reception system that respects and upholds the dignity of the child can foster a sense of trust.\n\nInterpreters can influence the information gathering process in transnational child protection cases, asylum procedures and criminal investigations as they affect how the child’s disclosure is being understood and perceived. Inaccurate translation might compromise the child’s statement to the effect that decisions are taken on the basis of incorrect information. This relates not only to the content translated but also to the style and semantic choices made by the child and how these are rendered by the interpreters.\n\nIn addition to training and recruiting qualified interpreters, the following measures protect the child's right to be heard: \n\nChild victims of crime have a right to be protected from harm and secondary victimisation during investigations and proceedings. The standards for are described in the UN Guidelines on Justice in Matters Involving Child Victims and Witnesses of Crime, the Council of Europe Convention on the Protection of Children against Sexual Exploitation and Sexual Abuse and the 2011 EU Anti-Trafficking Directive. The following protect children from harm in investigations and proceedings: \n\nThe Children’s House model is a good practice for conducting forensic interviews and gathering evidence from child victims of crime., the Council of Europe Convention on the Protection of Children against Sexual Exploitation and Sexual Abuse and the 2011 EU Anti-Trafficking Directive.\n\nInterview style and the type of questions asked affect the quality of the interview. They can influence the child’s willingness to disclose information. They can also influence the type and quality of information, and the level of detail, that the child is able and willing to share. Strategies for interviewers and interpreters to lessen this include prioritising open questions and avoiding closed and focused questions, suggestive prompts and leading questions; remaining neutral; be open and empathic; avoid criticism and confrontations.\n"}
{"id": "6876579", "url": "https://en.wikipedia.org/wiki?curid=6876579", "title": "Spherical cow", "text": "Spherical cow\n\nA spherical cow is a humorous metaphor for highly simplified scientific models of complex real life phenomena. The implication is that theoretical physicists will often reduce a problem to the simplest form they can imagine in order to make calculations more feasible, even though such simplification may hinder the model's application to reality.\n\nThe phrase comes from a joke that spoofs the simplifying assumptions that are sometimes used in theoretical physics.\n\nIt is told in many variants, including a joke about a physicist who said he could predict the winner of any race provided it involved spherical horses moving through a vacuum or a physicist whose solution to a poultry farm's egg-production problems began \"Postulate a spherical chicken ...\", as presented in a 1973 letter to the editor of the journal Science titled \"A Spherical Chicken\".\n\nAlan Turing, in his 1952 paper \"The Chemical Basis of Morphogenesis\" asserted that: \"a system which has spherical symmetry, and whose state is changing because of chemical reactions and diffusion ... cannot result in an organism such as a horse, which is not spherically symmetrical.\"\n\n\n\n"}
{"id": "17563810", "url": "https://en.wikipedia.org/wiki?curid=17563810", "title": "Structural abuse", "text": "Structural abuse\n\nStructural abuse is the process by which an individual is dealt with unfairly by a system of harm in ways that the person cannot protect themselves against, cannot deal with, cannot break out of, cannot mobilise against, cannot seek justice for, cannot redress, cannot avoid, cannot reverse and cannot change.\n\nEvery system contains at least one level at which structural abuse occurs, when the actions of the system takes over the actions of individuals within that system to create structures by which abuse of others occurs.\n\nStructural abuse should not be confused with structural violence. Structural violence refers to action committed by a larger society, such as racism or classism in an entire society. Structural abuse refers to actions that are not necessarily endorsed by the broader society.\n\nThere are three kinds of structural abuse:\n\nStructural abuse is indirect, and exploits the victim on an emotional, mental and psychological level. It manifests itself in specific situations within each cultural, social, corporate and family framework.\n\nStructural abuse is also called societal abuse. It has four permanent impacts upon the individuals subjected to it:\n\nAn example of how surface-level structural abuses are accepted by the community is where a political journalist in Australia presented a review of the day's work within the Australian Parliament in August 2011. During the one-minute presentation, consisting of 18 points, she began eight new points with the word \"Now\". \"Now\" is a fixation cue for viewers to forget about the past and the future, but to concentrate only on the \"now\" time frame. The use of the word was surplus to the data she presented, and even contradictory to it. The regularity of the word \"Now\", its placement at the front of each point by which the interpretation of each point is shaped, and the later repetitive use of the word by the anchor journalist steering the news program, who does not normally use such a control habit, showed that the word was a verbal dissociative cue by which hypnotic states are induced.\n\nOther examples include:\n\nCues indicating a Structurally Abusive Corporate System\n\nStructural Abuse Indicators include the inability of an outsider to make contact on a personal level with the people who work within an organisation. Cafe meetings turn discussions into plagiarisable events, while lack of agendas for high performance meetings create heightened levels of feeling threatened which impacts on how such meetings are approached. Being kept on hold with music blaring down the earpiece is structural abuse because by listening for the resumption of the discussion there is no escape from the sound.\n\nStructurally abusive political systems\n\nMaking promises which are not kept is a category of political structural abuse. Unkept promises fixate the expectations that people create from such promises. Expectations that create physical arousal states and a physical, emotional, intellectual and behavioural mindset by which to accommodate the fulfillment of those promises. When those visualisations of the future and its mobilisation of personal responsiveness is not satisfied in a timely or appropriate manner the result is an extended period of physiological arousal which can turn into stress and emotional depression over time. Hence the anger responses of electorates to the unkept promises of politicians, as well as the frustrated responses of victims of abuses of court processes (e.g. \"protective\" orders) to the abuse of discretion exhibited by misfeasant court and law enforcement officers who can claim to be acting under authority or color of law.\n\nCommunity Control Functions of Structural Abuse\n\nAll categories of structural abuse involve the manipulative control of time, energy, focus and connection between people, groups and organisations, in the service of one side, and to the disservice of the other.\n\nMost people call structural abuse \"bad manners\" or \"rudeness\", since it generally breaks conventions by which there is mutual control within each situation.\n\nEach instance of structural abuse breaks down the positive relationship between the two parties, creating for those being abused increasingly negative relationships built on expectations of exploitation, snatching of time, waste of effort, missing redress, and feelings of entrapment from which it is hard to escape.\n\nDealing with structural abuse\n\nStructural abuse is helped by talking therapies in which those abused find a listener, and then find their voice by which to begin to remove the power of the abusing system to continue to harm their inner identities.\n\nCurrently in most countries, there is no formal law that has been formulated against structural abuse, protecting the victim from such abuse, and enabling him or her to approach the court for relevant justice.\n\n\n\n"}
{"id": "20208804", "url": "https://en.wikipedia.org/wiki?curid=20208804", "title": "Structure chart", "text": "Structure chart\n\nA Structure Chart (SC) in software engineering and organizational theory is a chart which shows the breakdown of a system to its lowest manageable levels. They are used in structured programming to arrange program modules into a tree. Each module is represented by a box, which contains the module's name. The tree structure visualizes the relationships between modules.\n\nA structure chart is a top-down modular design tool, constructed of squares representing the different modules in the system, and lines that connect them. The lines represent the connection and or ownership between activities and subactivities as they are used in organization charts.\n\nIn structured analysis structure charts, according to Wolber (2009), \"are used to specify the high-level design, or architecture, of a computer program. As a design tool, they aid the programmer in dividing and conquering a large software problem, that is, recursively breaking a problem down into parts that are small enough to be understood by a human brain. The process is called top-down design, or functional decomposition. Programmers use a structure chart to build a program in a manner similar to how an architect uses a blueprint to build a house. In the design stage, the chart is drawn and used as a way for the client and the various software designers to communicate. During the actual building of the program (implementation), the chart is continually referred to as \"the master-plan\".\n\nA structure chart depicts\n\nA structure chart is also used to diagram associated elements that comprise a run stream or thread. It is often developed as a hierarchical diagram, but other representations are allowable. The representation must describe the breakdown of the configuration system into subsystems and the lowest manageable level. An accurate and complete structure chart is the key to the determination of the configuration items (CI), and a visual representation of the configuration system and the internal interfaces among its CIs. During the configuration control process, the structure chart is used to identify CIs and their associated artifacts that a proposed change may impact.\n\n According to Wolber (2009), \"a structure chart can be developed starting with the creating of a structure, which places the root of an upside-down tree which forms the structure chart. The next step is to conceptualize the main sub-tasks that must be performed by the program to solve the problem. Next, the programmer focuses on each sub-task individually, and conceptualizes how each can be broken down into even smaller tasks. Eventually, the program is broken down to a point where the leaves of the tree represent simple methods that can be coded with just a few program statements\".\n\nIn practice, see figure, first it is checked if a Structure Chart has been developed already. If so an expert needs to review it to ensure it represents the current structure and if not, updates the chart where needed..\n\n\n\n"}
{"id": "30872676", "url": "https://en.wikipedia.org/wiki?curid=30872676", "title": "Tally stick", "text": "Tally stick\n\nA tally stick (or simply tally) was an ancient memory aid device used to record and document numbers, quantities, or even messages. Tally sticks first appear as animal bones carved with notches during the Upper Paleolithic; a notable example is the Ishango Bone. Historical reference is made by Pliny the Elder (AD 23–79) about the best wood to use for tallies, and by Marco Polo (1254–1324) who mentions the use of the tally in China. Tallies have been used for numerous purposes such as messaging and scheduling, and especially in financial and legal transactions, \n\nPrincipally, there are two different kinds of tally sticks: the single tally and the split tally. A common form of the same kind of primitive counting device is seen in various kinds of prayer beads.\n\nA number of anthropological artefacts have been conjectured to be tally sticks:\n\n\nThe single tally stick was an elongated piece of bone, ivory, wood, or stone which is marked with a system of notches (see: Tally marks). The single tally stick serves predominantly mnemonic purposes. Related to the single tally concept are messenger sticks (e.g., Inuit tribes), the knotted cords, \"khipus\" or \"quipus\", as used by the Inca. Herodotus (c. 485–425 BC) reported the use of a knotted cord by Darius I of Persia (c. 521–486 BC).\n\nThe split tally was a technique which became common in medieval Europe, which was constantly short of money (coins) and predominantly illiterate, in order to record bilateral exchange and debts. A stick (squared hazelwood sticks were most common) was marked with a system of notches and then split lengthwise. This way the two halves both record the same notches and each party to the transaction received one half of the marked stick as proof. Later this technique was refined in various ways and became virtually tamper proof. One of the refinements was to make the two halves of the stick of different lengths. The longer part was called \"stock\" and was given to the party which had advanced money (or other items) to the receiver. The shorter portion of the stick was called \"foil\" and was given to the party which had received the funds or goods. Using this technique each of the parties had an identifiable record of the transaction. The natural irregularities in the surfaces of the tallies where they were split would mean that only the original two halves would fit back together perfectly, and so would verify that they were matching halves of the same transaction. If one party tried to unilaterally change the value of his half of the tally stick by adding more notches, the absence of those notches would be apparent on the other party's tally stick. The split tally was accepted as legal proof in medieval courts and the Napoleonic Code (1804) still makes reference to the tally stick in Article 1333. Along the Danube and in Switzerland the tally was still used in the 20th century in rural economies.\n\nThe most prominent and best recorded use of the split tally stick or \"nick-stick\" being used as a form of currency was when Henry I introduced the tally stick system in medieval England in around 1100. He would accept the tally stick only for taxes, and it was a tool of the Exchequer for the collection of taxes by local sheriffs (tax farmers \"farming the shire\") for seven centuries. The split tally of the Exchequer was in continuous use until 1826. In 1834 tally sticks representing six centuries worth of financial records were ordered to be burned in a stove in the Houses of Parliament. The resulting fire set the chimney ablaze and then spread until most of the building was destroyed. This event was described by Charles Dickens in an 1855 article on administrative reform.\n\nThe system of tally marks of the Exchequer is described in \"The Dialogue Concerning the Exchequer\" (see external links below) as follows:\n\nThe cuts were made the full width of the stick so that, after splitting, the portion kept by the issuer (the \"stock\") exactly matched the piece (the \"foil\") given as a receipt. Each stick had to have the details of the transaction written on it, in ink, to make it a valid record.\n\nRoyal tallies (debt of the Crown) also played a role in the formation of the Bank of England at the end of the 17th century. In 1697, the bank issued £1 million worth of stock in exchange for £800,000 worth of tallies at par and £200,000 in bank notes. This new stock was said to be \"engrafted\". The government promised not only to pay the Bank interest on the tallies subscribed but to redeem them over a period of years. The \"engrafted\" stock was then cancelled simultaneously with the redemption.\n\nTally sticks feature in the design of the entrance gates to The National Archives at Kew.\n\n\n\n\n"}
{"id": "1847690", "url": "https://en.wikipedia.org/wiki?curid=1847690", "title": "Timestream", "text": "Timestream\n\nThe timestream or time stream is a metaphorical conception of time as a stream, a flowing body of water. In \"Brave New Words: The Oxford Dictionary of Science Fiction\", the term is more narrowly defined as: \"the series of all events from past to future, especially when conceived of as one of many such series\". Timestream is the normal passage or flow of time and its historical developments, within a given dimension of reality. The concept of the time stream, and the ability to travel within and around it, are the fundamentals of a genre of science fiction.\n\nThis conception has been widely used in mythology and in fiction.\n\nThis analogy is useful in several ways:\n\n\nScience fiction scholar Andrew Sawyer writes, \"The paradoxes of time — do \"we\" move in time, or does \"it\" move by us? Does it exist or is it merely an illusion of our limited perception? — are puzzles that exercise both physicists and philosophers...\"\n\nBrian Stableford writes of the historical and philosophical concepts of time (and using the terminology of \"flow\"): \n\nThe ancient Greek philosopher Heraclitus was famous for a statement that has been translated in many ways, most commonly as \"No man ever steps in the same river twice,\" which is often called his \"flux [flow] doctrine.\" An essayist for the \"Stanford Encyclopedia of Philosophy\" explained it in this manner: \"Everything is in flux (in the sense that 'everything is always flowing in \"some\" respects'...) ...\"\n\nIn fiction, an alternate continuity is sometimes called an alternate timestream.\n\n\"The Time Stream\", a 1946 science fiction novel by author John Taine (pseudonym of Eric Temple Bell), is the first novel to see time as a flowing stream. It was originally serialized in \"Wonder Stories\", in four parts, from December, 1931, to March, 1932. Science fiction scholar E. F. Bleiler described how Taine employed the metaphor:\n\nThe basic concept is that time is a circular stream that runs eternally, with far past blending into far future. It is possible for certain individuals to enter this stream mentally and move in either direction, although this is a dangerous venture, for they may be carried away erratically by the stream. ... In San Francisco nine associates, who have been troubled by occasional memories of [the planet] Eos, band together to explore the time stream. They live out crisis moments in both times.\n\nAnother mid-century novel which employed the term in its title was \"The Ship That Sailed the Time Stream\" (1965) by G. C. Edmondson (pseudonym of José Mario Garry Ordoñez Edmondson y Cotton). John Clute writes that this \"and its sequel, \"To Sail the Century Sea\" (1981), are amusingly and graphically told Fantastic-Voyage tales involving a US ship and its inadvertent Time Travels. They remain his most successful books.\"\n\nOther fiction titles with the term include J. Robert King's 1999 novel \"Time Streams\" (), Michael Moorcock's 1993 collection \"A Nomad of the Time Streams\" (), and Charles M. Saplak's short story \"Backwater by the Time Stream\" (\"Manifest Destiny\" #1, Winter 1993).\n\nDiscussing the theme of parallel universes, in an encyclopedia article which can usefully be applied to the concept of timestreams, Brian Stableford and David Langford write, \"A parallel world is another universe situated 'alongside' our own, displaced from it along a spatial fourth Dimension (parallel worlds are often referred to in sf as 'other dimensions'). Although whole universes may lie parallel in this sense, most stories focus on parallel Earths. The parallel-world idea forms a useful framework for the notion of Alternate History, and is often used in this way... The idea that other worlds lie parallel to our own and occasionally connect with it is one of the oldest speculative ideas in literature and legend; examples range from Fairyland to the 'astral plane' of Spiritualists and mystics. There are two basic folkloristic themes connected with the notion; in one, an ordinary human is translocated into a fantasy land where s/he undergoes adventures and may find the love and fulfilment that remain beyond reach on Earth; in the other, a communication or visitation from the other world affects the life of an individual within this world, often injuring or destroying that person. Both patterns are very evident in modern imaginative fiction, shaping whole subgenres... A common variant of the theme is that of a multiplicity of almost-identical worlds existing in parallel: alternate worlds in which there has been no significant change.\"\n\nRick Sutcliffe provides a definition in a brief essay on his own fiction: \"The timestream is an alternate history device used in Rick Sutcliffe's fiction. It is the medium in which the various alternate earths exist, or, if one prefers, it provides the connections among them, in the manner of C. S. Lewis' wood between the worlds -- a place between.\"\n\nWhile not discussing the timestream \"per se\", scholar John Grant discusses a related topic, that of the time slip: \"Generally protagonists [return] to their starting points but a frequent device is that, after repeated timeslips, the 'traveler' chooses to remain in the other period. Generally there is an emotional or psychological connection of some kind between the character and the earlier time — most often love... Unsurprisingly, timeslips are a staple of the subgenre of romance fiction called the Paranormal Romance, exemplified by Diana Gabaldson's \"Outlander\" (1991) and its sequels.\"\n\nExamples of the usage of timestream:\n\n"}
{"id": "34213849", "url": "https://en.wikipedia.org/wiki?curid=34213849", "title": "Toy drive", "text": "Toy drive\n\nA Toy drive is a charity event that collects toys or money for them to be distributed to poor children.\n\nThis is usually for the celebration of Christmas. Volunteers are brought together to sort through toys to wrap and sort for age appropriateness. Appeals are made in shopping centers, schools, and other places for the public to purchase toys and to meet certain goals. Many charities or organizations will orchestrate a seasonal effort on top of their usual practices. Many police departments, fire departments, and military groups are involved in these efforts. One of the most important and famous toy drives is Toys For Tots which is operated by the United States Marine Corps.\n"}
{"id": "29736005", "url": "https://en.wikipedia.org/wiki?curid=29736005", "title": "Transportation Equity Network", "text": "Transportation Equity Network\n\nThe Transportation Equity Network (TEN) is a project of the Gamaliel Foundation and a grassroots organization with more than 350 community organizations in 41 states in the United States. TEN's stated goal is \"to create an equity-based transportation system by connecting local transportation campaigns with D.C.-based advocacy.\"\n\nThe Transportation Equity Network was founded in 1997 by the Center for Community Change but has since been adopted as a project of the Gamaliel Foundation. TEN was founded to advocate for public transportation on a national level, to provide assistance to community organizations on the local level, and to advocate for public transportation as a civil rights issue.\n\nIn August 2005, TEN celebrated the signing of Safe Accountable Flexible and Efficient Transportation Equity Act-A Legacy for Users (SAFETEA-LU). TEN had worked with congressional representatives from both parties to ensure that language in the bill reflected TEN's priorities. In many cases, language in the bill matched TEN's language verbatim. The adopted language allowed for construction projects. The changes pushed by TEN required public participation plans to be developed with the involvement of local residents in the metropolitan transportation planning process. Changes in the legislation required greater transparency in the planning process and set aside $1 million each year for transportation equity research. TEN's work helped secure the Job Access and Reverse Commute Program by making it a formula program with a guaranteed $700 million over six years.\n\nTEN worked in 2005 with then-Senator Barack Obama to put workforce development language into a federal transportation authorization bill. This allowed local and state officials to craft local hiring agreements to create employment and training opportunities in the transportation construction sector. One early success was in St. Louis, Missouri, where TEN affiliate Metropolitan Congregations United brought the Missouri Department of Transportation to the table and won an agreement that 30% of the workforce on a $500 million highway project would be low-income apprentices and that 1/2 of 1% of the project budget ($2.5 million) would go to job training. This became known as the Missouri Model. Recently, TEN won a commitment from Secretary of Transportation Ray LaHood to encourage state Departments of Transportation to adopt TEN’s “Green Construction Careers (Missouri Model)” of workforce development nationwide. TEN also recently worked with Rep. Russ Carnahan to secure language in the jobs bill that passed the U.S. House of Representatives on December 17, 2009, to give transit authorities local control over spending priorities for up to 10 percent of the bill’s $8.4 billion in emergency public transit funding. In December 2009, the Congressional Black Caucus lifted up TEN’s “Green Construction Careers (Missouri Model)” in an open letter to President Obama.\n\nTEN and its affiliates also pursue causes on a local level. In April 2010, TEN member Metropolitan Congregations United (MCU) and allies led a successful campaign in support of a ballot initiative to reinvest in transit in St. Louis city and county. Voters overwhelmingly supported the measure, which will provide $75 million a year to restore service cuts. In the San Francisco Bay Area, TEN affiliate GENESIS was among several civil rights groups that filed a federal civil rights complaint and successfully stopped the use of $70 million in stimulus funds for a rail project that would have violated the Civil Rights Act. Instead, the money will be used to avoid cuts in the region’s other transit lines. In August 2010, in Kansas City, Missouri, TEN member MORE2 secured $11 million in local transit funding over 10 years, an increase of $5 million over previous levels. In Minnesota, TEN member ISAIAH successfully argued that a planned light rail line (the METRO Green Line) connecting Minneapolis and Saint Paul should include three additional stops in underserved, low-income communities. Also in Minnesota, after a five-year-long intensive campaign, ISAIAH convinced Minnesota Department of Transportation to dedicate $6.2 million in federal highway money over the next five years to training and apprenticeships in highway construction work to low-wage workers, people of color and women. In October 2010, TEN affiliate MORE2 successfully worked to ensure that equity requirements would be included in the new TIGER II federal grants.\n\nIn January 2007, TEN released a study called \"The Road to Jobs\", which used census] and other government data to the examine the employment of African Americans, Hispanics, and women in the construction field in 18 metropolitan areas. The study found that African-Americans, Latinos and women] are underrepresented compared to white men in every one of the 18 metropolitan areas. TEN has since worked to incorporate workforce equity requirements into federal, state, and local transportation legislation.\n\nIn September 2008, TEN released a follow-up study called \"The Road to Good Jobs.\" The report built upon the foundation laid in \"The Road to Jobs\" but went further in examining patterns of pay and union membership in construction across the nation's top twenty-five metropolitan areas.\n\nIn 2009, TEN and PolicyLink released a joint report entitled \"An Engine of Opportunity: A User’s Guide to Advocate for Transportation Equity in the 2009 Recovery Act\". The report was designed as guide to activists, advocates, and journalists on the distribution of billions of dollars in transportation funding. The report also highlighted the key deadlines, reporting requirements and policy targets that were still to come that year.\n\nLater in 2009, TEN released a study co-authored by Transportation for America on the effects of service cuts on transit systems across the country. Entitled \"Stranded at the Station: The Impact of the Financial Crisis in Public Transportation\", the study looked at the challenges facing 25 communities across the country. Many communities were facing record levels of ridership and simultaneously dealing with crippling budget and service cuts. The authors of the study found that failures on the federal level had compounded these problems and that older Americans and members of racial minorities were disproportionately affected by the cuts.\n\nIn August 2010, a major study authored by TEN entitled \"More Transit = More Jobs\" was released. The study looked at 20 metropolitan areas and the potential effects of shifting 50% of highway spending to public transit. The report concluded that such a shift would create 1,123,674 new transit jobs over a five-year period in the 20 metropolitan areas. This would mean a net gain of 180,150 jobs over five years. The study was designed to demonstrate the positive impact of spending on public transit compared to spending highways.\n\nTEN's current stated platform centers around four issues:\n\n\n"}
{"id": "491097", "url": "https://en.wikipedia.org/wiki?curid=491097", "title": "Variational principle", "text": "Variational principle\n\nA variational principle is a scientific principle used within the calculus of variations, which develops general methods for finding functions which extremize the value of quantities that depend upon those functions. For example, to answer this question: \"What is the shape of a chain suspended at both ends?\" we can use the variational principle that the shape must minimize the gravitational potential energy.\n\nAny physical law which can be expressed as a variational principle describes a self-adjoint operator. These expressions are also called Hermitian. Such an expression describes an invariant under a Hermitian transformation.\n\nFelix Klein's Erlangen program attempted to identify such invariants under a group of transformations. In what is referred to in physics as Noether's theorem, the Poincaré group of transformations (what is now called a gauge group) for general relativity defines symmetries under a group of transformations which depend on a variational principle, or action principle.\n\n\n"}
{"id": "12727767", "url": "https://en.wikipedia.org/wiki?curid=12727767", "title": "Waldhausen category", "text": "Waldhausen category\n\nIn mathematics, a Waldhausen category is a category \"C\" equipped with some additional data, which makes it possible to construct the K-theory spectrum of \"C\" using a so-called S-construction. It's named after Friedhelm Waldhausen, who introduced this notion (under the term category with cofibrations and weak equivalences) to extend the methods of algebraic K-theory to categories not necessarily of algebraic origin, for example the category of topological spaces.\n\nLet \"C\" be a category, co(\"C\") and we(\"C\") two classes of morphisms in \"C\", called cofibrations and weak equivalences respectively. The triple (\"C\", co(\"C\"), we(\"C\")) is called a Waldhausen category if it satisfies the following axioms, motivated by the similar properties for the notions of cofibrations and weak homotopy equivalences of topological spaces:\n\n\nFor example, if formula_1 is a cofibration and formula_2 is any map, then there must exist a pushout formula_3, and the natural map formula_4 should be cofibration:\n\nIn algebraic K-theory and homotopy theory there are several notions of categories equipped with some specified classes of morphisms. If \"C\" has a structure of an exact category, then by defining we(\"C\") to be isomorphisms, co(\"C\") to be admissible monomorphisms, one obtains a structure of a Waldhausen category on \"C\". Both kinds of structure may be used to define K-theory of \"C\", using the Q-construction for an exact structure and S-construction for a Waldhausen structure. An important fact is that the resulting K-theory spaces are homotopy equivalent.\n\nIf \"C\" is a model category with a zero object, then the full subcategory of cofibrant objects in \"C\" may be given a Waldhausen structure.\n\nThe Waldhausen S-construction produces from a Waldhausen category \"C\" a sequence of Kan complexes formula_5, which forms a spectrum. Let formula_6 denote the loop space of the geometric realization formula_7 of formula_8. Then the group\nis the \"n\"-th \"K\"-group of \"C\". Thus, it gives a way to define higher \"K\"-groups. Another approach for higher \"K\"-theory is Quillen's Q-construction.\n\nThe construction is due to Friedhelm Waldhausen.\n\nA category \"C\" is equipped with bifibrations if it has cofibrations and its opposite category \"C\" has so also. In that case, we denote the fibrations of \"C\" by quot(\"C\"). \nIn that case, \"C\" is a biWaldhausen category if \"C\" has bifibrations and weak equivalences such that both (\"C\", co(\"C\"), we) and (\"C\", quot(\"C\"), we) are Waldhausen categories.\n\nWaldhausen and biWaldhausen categories are linked with algebraic K-theory. There, many interesting categories are complicial biWaldhausen categories. For example: \nThe category formula_10 of bounded chain complexes on an exact category formula_11.\nThe category formula_12 of functors formula_13 when formula_14 is so.\nAnd given a diagram formula_15, then formula_16 is a nice complicial biWaldhausen category when formula_17 is.\n\n\n"}
{"id": "26378079", "url": "https://en.wikipedia.org/wiki?curid=26378079", "title": "Womyn-born womyn", "text": "Womyn-born womyn\n\nWomyn-born womyn (WBW) is a term developed during second-wave feminism to designate women who were identified as female at birth, were raised as girls, and identify as women (or womyn, a deliberately alternative spelling that challenges the centering of male as norm).\n\nEvents and organizations that have womyn-born-womyn-only policies bar access to anyone who was assigned male at birth: male children of attendees, trans women, gay men, bisexual men and heterosexual men. These cisgender women-only spaces have raised a number of concerns from transgender groups.\n\nThe term gained usage and popularity during the second wave feminist movement. In 1978, the Lesbian Organization of Toronto adopted a womyn-born womyn-only policy in response to a request for admittance by a transgender woman who identified as lesbian. Womyn-born womyn policies held that the nature of the feminine experience over the course of a lifetime could only be experienced by someone who experienced life presenting as a woman. The intent was to create a space for only women, defined not by identity but experience, defined in a way that excluded transgender women.\n\nSecond-wave feminism is a period in the feminist movement lasting from the 1960s until around the 1980s. Some feminists of the period such as scholars Sheila Jeffreys, Janice Raymond, and theologist Mary Daly were proponents of womyn-born womyn policies. These policies created controversy and scholarly discussion.\n\nRaymond's \"The Transsexual Empire\" (1979) is often seen as the characterizing work of this movement. It is known for its view of trans women as privileged men who did not previously live in the oppression of the patriarchy, stating, \"We know who we are. We know that we are women who are born with female chromosomes and anatomy, and that whether or not we were socialised to be so-called normal women, patriarchy has treated and will treat us like women. Transsexuals have not had this same history.\"\n\nJeffreys was similarly outspoken in her criticisms of trans women, arguing that the feminine characteristics they were adopting are simply those that women must adopt to avoid punishment from the patriarchy. She believed trans women adopt stereotypical attributes that are enforced by the patriarchy and were political signifiers of the oppression of women.\n\nJudith Butler, despite being opposed to womyn-born womyn policies, is often used as an argument for them by modern second-wave feminists. Butler's \"Gender Trouble\" (1990) contained discussion of performativity versus performance, which second-wave feminists used to exclude trans women on account of their performativity through repetition of gender norms, which is \"real only to the extent that it is performed\", which was used as a separator from experience.\n\nOlivia Records, a feminist music collective, employed transgender employees, notably Sandy Stone. In response to this, Michigan Womyn's Music Festival's primary owner in 1977, Lisa Vogel, issued a letter to the music collective along with other second wave feminists:\nThroughout the final quarter of the twentieth century, women's music festivals often enacted womyn-born womyn policies. Although transgender and intersex people had been present in \"women-only spaces\" for decades (usually closeted or passing), the term garnered wider attention in response to the exclusion of trans women from the Michigan Womyn's Music Festival (MichFest) after it was described as a gathering for \"women born as women and living as women\". In 1992, a gender survey was taken at MichFest by Nancy Burkholder that asked, \"Do you think male-to-female transsexuals should be welcome at Michigan?\" Out of approximately 7500 women present, 633 responded to the inquiry with 73.1% (463) responding \"yes\" and 22.6% (143) responding \"no\" (the margin of error was 3.8%). Although admitting that the sample was not \"randomly selected\", surveyors calculated the results as indicating that \"less than 1 in 100,000\" attendees would be against the exclusion of transsexual women from the festival; and while the replies about \"female-to-male transsexuals\" were not tabulated, it was determined that \"80% of respondents were against their inclusion\". However, the presence of male-to-female transsexual people at MichFest was understood to exist.\n\nWith the advent of third-wave feminism, objections to womyn-born womyn policies increased. Many women-only music festivals also began to close. The RadFem Collective, which describes its membership as \"restricted to 'women born women and living as women'\", continues to promote womyn-born womyn policies. The statement for the 2015 conference was rephrased in explanatory form to read \"RadFems Resist is a women only, feminist event. Our conference is a space for women to share our experiences as women, to politically self organise for women's liberation and to celebrate womanhood in a safe environment. We welcome all women who were raised and socialized as girls to join us...We are gender abolitionists who have been raised and socialized as girls and women *because of our female bodies* in the context of patriarchy.\"\n\nAfter 40 years, the Michigan Womyn's Music Festival held its last event in 2015. This final gathering followed the withdrawal of support by the National Center for Lesbian Rights, National LGBTQ Task Force, and \"The TransAdvocate\" nonprofit website, of a boycott petition against MichFest and its womyn-born womyn intention.\n\nThere have been other instances where transgender women have been denied access to, or been evicted from, women's spaces; for example, the Vancouver Rape Relief & Women's Shelter and Mountain Moving Coffeehouse.\n\nThe feminist sex wars signaled a divide in second-wave feminism on issues of sex expression, pornography, sexuality, and gender identity. It led to many trans-affirming feminist views, and more criticism toward the womyn-born womyn culture that thrived in radical feminism. With the rise of third-wave feminism, the radical feminism that supports womyn-born womyn policies and agendas became less prevalent.\n\nJudith Butler was characteristic in her approach to third-wave feminist opposition of womyn-born womyn politics. The fluidity in gender, a more modern adaptation in feminist thought, is reflected in her views, \"We form ourselves within the vocabularies that we did not choose, and sometimes we have to reject those vocabularies, or actively develop new ones. For instance, gender assignment is a 'construction' and yet many genderqueer and trans people refuse those assignments in part or in full. That refusal opens the way for a more radical form of self-determination, one that happens in solidarity with others who are undergoing a similar struggle.\" This is in response to claims by Jeffreys and others of the time who believed that those born womyn embodied true patriarchal struggle, while transgender women still benefited from the patriarchy. In a more direct reaction from Butler, she states, \"The feminist police comes along to expose the construction and dispute a trans person's sense of their lived reality. I oppose this use of social construction absolutely, and consider it to be a false, misleading, and oppressive use of the theory.\" Some prominent figures in the second wave also readjusted views when presented with changing times, such as Gloria Steinem, who previously referred to transgender women as men with mutilated bodies in the late 1970s, and has since revised her beliefs as stated in a 2013 opinion piece: \"I believe that transgender people, including those who have transitioned, are living out real, authentic lives. Those lives should be celebrated, not questioned.\"\n\nThe understanding of gender, gender politics, and trans politics has changed over the latter half of the twentieth century and has led to more LGBTQ-led opposition to womyn-born womyn policies and the music festivals that tend to employ them. Kelsie Brynn Jones, a transgender woman and advocate, wrote that \"in [radical feminists'] words, a transgender woman is a \"[sic]\" nothing but a 'self loathing gay man' and they claim that trans women are gay men who, rather than stand up and come out as gay, would rather 'hide' by being transgender, as if it makes things more palatable for friends, family and co-workers.\" Activists for transgender-inclusionary policies often refer to those who promote womyn-born womyn policies as TERFs, an acronym meaning \"Trans Exclusionary Radical Feminists\".\n\nIn 1991, Nancy Burkholder was kicked out of the Michigan Womyn’s Music Festival for being transgender. \nWith support from the Lesbian Avengers, she and other activists, specifically transgender women, created Camp Trans in 1992 to stage protests outside of the Michigan Womyn's Music Festival against its womyn-born womyn policy. Transgender supporters passed out flyers and held workshops across the road from the festival. Transgender activist Julia Serano described the festival as insensitive and ignorant: \"[The] idea that the femaleness of my mind, personality, lived experiences, and the rest of my body can somehow be trumped by the mere presence of a penis can only be described as phallocentric.\" Activist Riki Wilchins noted that Camp Trans \"was the first time that significant numbers of the hard-core lesbian feminist community backed us”.\n\n\n\n\n"}
{"id": "32228572", "url": "https://en.wikipedia.org/wiki?curid=32228572", "title": "Wonderland model", "text": "Wonderland model\n\nWonderland is an integrated mathematical model used for studying phenomena in sustainable development. First introduced by \n(Sanderson 1994), there are now several related versions of the model in use. Wonderland allows economists, policy analysts and environmentalist to study the interactions\nbetween the economic, demographic and anthropogenic sectors of an idealized world, thereby enabling them to obtain insights transferable to the real world.\n\nWonderland is a compact model.\nIn total, there are only four continuous state variables, one each for the economic and demographic sectors and two for the anthropogenic sector; thus making Wonderland more compact and amenable to analysis than larger, more intricate models like World3. For this reason it is often used as an initial testing ground for new techniques in the area of policy analysis (Lempert, et al., 2003).\n\nDenote the four state variables as: formula_1 – population, formula_2 – per capita output, formula_3 – stock of natural capital and formula_4 – pollution flow per unit of output. Let formula_5 and\nformula_6, then the state variables evolve in discrete time, according to the following recurrence relations (Sanderson, 1994).\n\nAltogether, these equations depend upon 15 parameters.\n\nThe form of formula_10 follows from the I = PAT hypothesis.\n\nUsing the Scenario analysis technique, Sanderson (1994) studied two possible futures for the idealized world described by Wonderland. One future entitled \"Dream\", held out the possibility of unending sustainable growth, while the other termed \"Horror\", ended in environmental collapse and eventual extinction of the population. Subsequent work (Kohring, 2006) showed that the parameters of the model can be bisected into two sets, one which always produces sustainable futures and one which always ends in collapse and extinction. Additionally, the equations of Wonderland exhibit chaotic behavior (Gröller, et al., 1996, Wegenkittl, et al., 1997, Leeves and Herbert, 1998).\n\nIn the basic model it is impossible to avoid or recover from the environmental collapse seen in the \"Horror\" scenario without changes to the model itself. Two such changes have been studied: \npollution \"abatement\" and pollution \"avoidance\".\n\nAbating the effects of pollution draws funds from other sources to pay for cleaning up the environment (Sanderson, 1994). This decreases the value of formula_11 entering into the equations for birth, formula_12, and death, formula_13:\n\nThe time evolution of formula_2 is unaffected because those goods and services needed for pollution abatement must also be considered part of the overall output. The impact of these changes on the environment is expressed by changes to formula_16:\n\nThese changes introduce three new parameters into the model:\n\nBy adjusting the policy levers, it is possible to clean up a polluted environment and recover from the collapse seen in the \"Horror\" scenario. However, the recovery is only temporary, after a brief time of robust growth the system again collapses, leading to endless cycles of collapse followed by recovery. Abating pollution does not alter the fundamental division of the parameters into the two sets of sustainable and unsustainable futures (Kohring, 2006).\n\nPollution avoidance aims to prevent pollution from entering into the environment, by making its production unprofitable. This is modeled by means of a pollution tax (Herbert and Leeves, 1998, Lempert, et al., 2003):\n\nThe new parameters for the pollution avoidance model are:\n\nWith these changes, it is possible to raise the tax rate, formula_19, such that the system never collapses and the horror scenario is avoided altogether. Regardless of the other parameters, it is always possible to increase formula_19 in order to avoid collapse thereby enabling unending sustainable growth (Kohring, 2006).\n\nInstead of the relatively simple economic growth equation used for formula_2 some researchers use a Cobb–Douglas production function instead (Leeves and Herbert, 2002).\n\nThe standard form of the Wonderland model contains a single, homogeneous entity. Herbert et al. (2005) extended Wonderland to a multi-country model by allowing the different entities to use different sets parameters and assuming the outputs are coupled through trade flows.\n\nOriginally developed in terms of discrete time, finite difference equations, it is often recast as a set of continuous time differential equations (Gröller, et al., 1996)\n\n"}
