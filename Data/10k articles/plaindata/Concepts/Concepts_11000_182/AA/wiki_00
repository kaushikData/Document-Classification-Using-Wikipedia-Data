{"id": "44621834", "url": "https://en.wikipedia.org/wiki?curid=44621834", "title": "16 Days of Activism against Gender-based Violence", "text": "16 Days of Activism against Gender-based Violence\n\n16 Days of Activism Against Gender-Based Violence is an international campaign to challenge violence against women and girls. The campaign runs every year from 25 November, the International Day for the Elimination of Violence against Women, to 10 December, Human Rights Day. It was initiated in 1991 by the first Women's Global Leadership Institute, held by the Center for Women's Global Leadership (CWGL) at Rutgers University.\n\nCurrently, more than 3,700 organizations from approximately 164 countries participate in the campaign annually.\n\n\nEvery year, the 16 Days of Activism Against Gender-Based Violence Campaign either introduces a new theme, or continues an old theme. The theme focuses on one particular area of gender inequality and works to bring attention to these issues and make changes that will have an impact. The Center for Women's Global Leadership sends out a \"Take Action Kit\" every year, detailing how participants can get involved and campaign in order to make a change.\n\n\n"}
{"id": "55796794", "url": "https://en.wikipedia.org/wiki?curid=55796794", "title": "Barbara Ball", "text": "Barbara Ball\n\nBarbara Ball MRCS, LRCP, OBE (13 June 1924-13 March 2011) was a Bermudian physician, politician and social activist. She was the first woman physician to practice in Bermuda and took both black and white patients, an unusual event in the 1950s. During the time that segregation was rigidly enforced, Ball actively ignored the social norms, actively fighting for the civil rights of black Bermudians. She served as a member of the Parliament of Bermuda and represented black workers through her work with the Bermuda Industrial Union. In 1963, at a United Nations meeting regarding colonialism, Ball brought the situation of black workers on the island to the table. In 2000, she was honoured as an officer of the Order of the British Empire.\n\nBarbara Bertha Ball was born on 13 June 1924 in Bermuda to Jessie Alice (née Clap) and Carlton Ball. Her mother was a native Bermudian and her father was an English carpenter who came to Bermuda to work at Prospect Garrison. Ball's younger brother Walter was physically disabled and would later become well-known newspaper vendor. After completing her secondary education at the all-white Bermuda High School for Girls, she won a government scholarship to attend medical school in Liverpool. In 1942, she entered Liverpool University, and also studied judo, graduating with her medical degree seven years later.\n\nBall began her career in England and spent the next five years working as a physician at hospitals in Liverpool, Merseyside and Westmorland. In 1954, Ball returned to Bermuda and joined an existing medical practice, Bermuda Medical Associates (BMA). Though the third woman to train as a physician, she was the first Bermudian-born practitioner. She quickly became known for taking and providing equal care to patients without regard to their race. Her actions caused the other physicians at BMA to ask her to withdraw from the practice. She withdrew, rented a small office space on Cedar Avenue from the St. Theresa’s Catholic Cathedral, and continued treating patients from all races. She simultaneously began teaching judo classes in the evenings, but after receiving warnings from the police that she could not teach black Bermudians, she formed her own judo club, which was one of the first integrated sports centres in the country. \n\nIn 1959, during the Bermuda Theatre Boycott, Ball publicly supported black Bermudians in their quest for equality. She was well aware of the difficulties many of her black patients had in paying for medical treatment and felt that lack of income should not impact one's health. The following year, speaking at a public meeting, she supported the abolition of the property requirement as a qualifier to being able to vote, instead expressing support for universal suffrage for all adults upon attaining the age of 21. Her radical stance was that wealth should be equally distributed among society. Her support of blacks and workers, caused a rift with her church causing her conversion from Anglicanism to Catholicism that same year. \n\nBall joined the Bermuda Industrial Union (BIU) in 1961. The BIU had been formed in 1946 to represent the working class, which was predominantly black and disenfranchised. By the following year, she became the BIU's General Secretary. In 1963, Ball and Walton Brown attended a United Nations subcommittee meeting regarding colonialism. She stressed that the racism in the country created unequal opportunity for black Bermudians and pressed for self-determination. British representatives dismissed the idea. \n\nBall's work with the union caused her to be unpopular with those whites who thought she was a \"traitor to her race\". In 1964, she lost admitting privileges at King Edward VII Memorial Hospital and was dismissed as choirmistress and organist of her church, St. Michael's in Paget. The following year Ball was threatened with a prison sentence for her participation in the Bermuda Electrical Light Company (BELCO) strike. She gained respect from the underground civil rights workers during the BELCO strike because she used her skill with judo to avoid police detention. Charged with inciting a riot, Ball and six other accused strike leaders, were tried in the Supreme Court. Four of the accused men were found guilty of obstruction and incitement, while Ball and the other defendant were acquitted.\n\nUnder Ball's leadership, the BIU expanded its base of labourers, seeking construction workers and hotel workers as members. After her trial, union membership grew and the BIU became the largest union in the country. \nIn 1968 and again in 1972, Ball was a successful candidate for the Progressive Labour Party (PLP), as a member of the House of Assembly of Bermuda. The 1968 race was the first general election in Bermuda after the passage of the universal suffrage law. She resigned as General Secretary of BIU in 1974, but continued to remain active negotiations for pay increases and benefits, like pensions and insurance as well as paid maternity and sick leave until 2005. In 2000, Ball was honoured as an officer in the Order of the British Empire.\n\nBall died on 13 March 2011 at the Sylvia Richardson Care Facility in St. George's, Bermuda. She was buried on St Paul’s Anglican Cemetery in Paget on 19 March 2011, after her funeral service which was widely attended by noted politicians and trade unionists. While she is remembered as a pioneering doctor in Bermuda, her legacy was in her fight for the civil rights of Bermuda's black residents. The government established the Dr. Barbara Ball Public Health Scholarship in her honour. Ottiwell Simmons, with whom Ball had worked at BIU, published a biography of Ball's life, \"Our Lady of Labour\" in 2010.\n\n"}
{"id": "50791445", "url": "https://en.wikipedia.org/wiki?curid=50791445", "title": "Beef carcass classification", "text": "Beef carcass classification\n\nCountries regulate the marketing and sale of beef by observing criteria of Cattle Carcasses at the Abattoir and classifying the carcasses. This classification, sometimes optional, can suggest a market demand for a particular animal's attributes and therefore the price owed to the producer.\n\nIn the United States, the United States Department of Agriculture's (USDA's) Agricultural Marketing Service (AMS) operates a voluntary beef grading program that began in 1917. A meat processor pays for a trained AMS meat grader to grade whole carcasses at the abattoir. Such processors are required to comply with Food Safety and Inspection Service (FSIS) grade labeling procedures. The official USDA grade designation can appear as markings on retail containers, individual bags, or on USDA shield stamps, as well as on legible roller brands appearing on the meat itself. \n\nThe USDA grading system uses eight different grades to represent various levels of marbling in beef: Prime, Choice, Select, Standard, Commercial, Utility, Cutter and Canner. The grades are based on two main criteria: the degree of marbling (intramuscular fat) in the beef, and the maturity (estimated age of the animal at slaughter). Prime has the highest marbling content when compared to other grades, and is capable of fetching a premium at restaurants and supermarkets. As of June 2009, about 2.9% of carcasses grade as Prime. Choice is the most common grade sold in retail outlets, and represents roughly half of all graded beef. Select is sold as a cheaper, leaner option in many stores and is the lowest grade typically found for consumer purchase as a steak. Younger cattle (under 42 months of age) tend to be graded as Prime, Choice, Select or Standard, while older cattle are more likely to be graded Commercial, Utility, Canner or Cutter. These latter grades of beef are used for ground products rather than for consumer sale or food service.\nSome meat scientists object to the current scheme of USDA grading since it is not based on direct measurement of tenderness, although marbling and maturity are indicators of tenderness. Most other countries' beef grading systems mirror the U.S. model, except for those in the European Union (EU). The EU employs a grading scheme that emphasizes carcass shape and amount of fat covering instead of marbling and aging. The differences in grading yield incompatible value judgments of beef value in the United States and the EU. Most beef offered for sale in supermarkets in the United States is graded U.S. Choice or Select. U.S. Prime beef is sold to hotels and upscale restaurants, and usually marketed as such.\n\nIn 1997, the official standards were revised to restrict the Select grade to A maturity carcasses, and to raise the minimum marbling score to qualify for Choice to modest for B maturity cattle. These changes were implemented to improve the uniformity and consistency of the grading system.\nYield grades are intended to estimate the pounds of boneless closely trimmed retail cuts from the carcass. Closely trimmed refers to approximately ¼ inch of external fat. Yield grade is determined by considering 4 carcass characteristics: external fat, Kidney, pelvic and heart fat (KPH), Ribeye area (REA), and Hot carcass weight (HCW). The amount of external fat is measured at the ribbed surface between the 12th and 13th ribs. The ribbing of carcasses is described in the U.S. standards for beef grading. External fat is measured at a distance of ¾ the length of the ribeye from the chine bone end. This initial number can be adjusted up or down depending on any abnormal fat deposits. As the amount of external fat increases, the percent of retail cuts decreases.\n\nKidney fat is assessed subjectively and is expressed as a percentage of the carcass weight. As the percentage of KPH increases, the percent of retail cuts decreases. The ribeye area is measured at the ribbed surface, it can be estimated subjectively or measured with a device approved by the AMS. As ribeye area increase, percent retail cuts increases. Hot carcass weight is used to determine yield grade. As carcass weight increases, percent retail cuts decrease. The following equation is used to determine yield grade:\n\nThere are five grades, 1-5. Yield grade one carcasses are of the highest cutability, while yield grade 5 yields the lowest cutability.\n\nBeef sold in U.S. restaurants and supermarkets is usually described by its USDA grade; however, in the early twenty-first century many restaurants and retailers began selling beef on the strength of brand names and the reputation of a specific breed of cattle, such as black Angus.\n\nThe EUROP grid method of carcass classification was implemented in 1981. European Economic Community Regulations (EEC) No. 1208/81 and No. 2930/81 were enacted to facilitate the application of a community scale for the classification of carcases of adult bovine animals. This was to ensure the uniform classification of the carcases of adult bovine animals in the EEC and make the definitions of conformation classes and fat classes more precise. The need arose for a common grading scale when member states of the EEC began operating in the common beef market in 1968 (EEC) No. 805/68 and price reporting to the EC became mandatory.\n\nIn the UK, the Meat and Livestock Commission (MLC Services Ltd) is responsible for the classification of over 80% of the cattle slaughtered in Britain. The EUROP grid consists of a 5-point scale in which each conformation and fat class is subdivided into low medium and high classes resulting in 15 classes. In the UK, the fat classes range from 1-5 with classes 4 and 5 having a high and low sub-class which results in a seven-point scale for fatness (figure 1). It is argued by the MLC that this subdivision allows a more precise description of the carcase.\n\nThe price a farmer receives for a beast sent for slaughter is calculated by multiplying the carcase weight by the classification price for a particular category of animal (heifer, steer, bull, cow etc.). This classification is subjectively assigned by the meat grader according to the EUROP system where E is excellent, U is Very Good, R is Good, O is Fair and P is Poor. Likewise for the fat class, where 1 is Low, 2 is Slight, 3 is Average, 4 is High, and 5 is Very High. A typical classification would be R4L where the R refers to a \"Good” carcass with an “Average” to “High” covering of fat according to the MLC.\n\nThe grader is usually an independent classifier who also monitors carcass dressing specification. Most classifiers are employed by MLC services and they are audited quarterly by the Rural Payments Agency (RPA) which is a government organisation. More recently Video Image analysis has been used to classify beef carcasses according to the EUROP scale. There are several machines that can do this, several of which were trialled in Ireland. The Republic of Ireland has used video image analysis for assignment of the EUROP classification grid since 2004.\n\nTwo main problems that are often cited in reference to the EUROP grid are its subjective application and its lack of consideration for meat eating quality.\n"}
{"id": "22554105", "url": "https://en.wikipedia.org/wiki?curid=22554105", "title": "Bike rage", "text": "Bike rage\n\nBike rage refers to acts of verbal or gestural anger or physical aggression between cyclists and other users of bike paths or roadways, including pedestrians, other cyclists, motorcyclists, or drivers. Bike rage can consist of shouting at other road users, making obscene gestures or threats, hitting or punching, or in rare cases, even more violent acts. The term can refer either to acts committed by cyclists or by drivers. Bike rage is related to other explosive outbursts of anger such as road rage.\n\nA bike rage incident can start because a cyclist, driver, or pedestrian believes that another road user was being discourteous, breaking traffic rules, or in many cases because someone felt that their safety was being compromised by the actions of another road user. According to University of Hawaii professor of psychology Leon James, \"bike rage is a common occurrence, and quite predictable\", because urban commuting causes \"tension, anxiety, and anger – in drivers as well as cyclists\". Montogomery claims some cyclists hit cars using a \"classic U-lock bash-and-run\" tactic. He argues that \"some cyclists consider such attacks acts of driver education\". Montogomery claims the \"...problem is that city planners have mixed bikes and cars together in ways that offer little certainty about how each should operate, and lots of chances for conflict\". As such, \"cyclists feel threatened in traffic\" and \"...hard done by and under attack.\"\nAn article in \"Toronto Life\" magazine argues that the \"...source of the problem [bike and road rage] is neither the arrogance of drivers nor the militancy of cyclists, but the environment in which they interact.\" The article claims that the \"...urban grid, already congested with cars, is being flooded with cyclists...intensifying competition for road space.\" One issue is that \"[d]rivers are not sufficiently alert to the presence and the quickness of cyclists\". A possible explanation for all of the aggression that occurs between cyclists and drivers is the anonymity of the big city: \"...they know they will never run into that person again.\"\n\nA member of the S.F. Bicycle Coalition argues that \"Road rage is a symptom of a contradiction between the image and promise of cars and the reality,\" because \"You never see a car ad showing someone stuck in traffic.\" After an altercation between cyclists and police, an observer noted that \"The sheep -- like the man who was just riding to the gym and decided to join and have a little fun -- were bewildered, angry, defiant. Turned into wolves.\"\n\nA 2008 \"New York Times\" article stated that \"...overwhelmingly, on blogs and Web sites nationwide, drivers and cyclists routinely describe shouted epithets, flung water bottles, sprays of spit and harrowing near-misses of the intentional kind.\" The article noted that there is \"a whiff of class warfare in the simmering hostility, too. During morning rush, the teeth-gritting of drivers is almost audible, as superbly fit cyclists, wearing Sharpie-toned spandex and riding $3,000 bikes, cockily dart through the swampy, stolid traffic to offices with bike racks and showers.\"\n\nBike rage may also be caused by confusion about how the rules of the road apply to cyclists. In some jurisdictions, cyclists are allowed to ride on the sidewalk, whereas in other places, this is against the law. In all fifty U.S. states, bicycles are classified as vehicles and cyclists have many of the same rights and responsibilities as other drivers; however, other jurisdictions may place restrictions on where citizens may operate bicycles. These differences in rules may lead drivers to believe that a cyclist is violating the law by cycling on a roadway, even if local laws require cyclists to be on the road. Many citizens are also ignorant of their localities' laws concerning bicycles. \n\nIn Toronto in January 2006, a driver tossed his lunch out the window of his car in a traffic jam. A 26-year-old bike courier threw the food back into the car. The driver tossed two cups of hot coffee at the courier, and then, after they exchanged insults, the driver attacked the woman and her bike.\n\nIn 2009 in Los Angeles, a 59-year-old man was \"charged with two felony counts each of reckless driving causing injury, battery with serious bodily injury and the special allegation of causing great bodily injury\". After the man had an argument with two cyclists, he \"allegedly stopped short and caused one [bike] rider to go through the rear window of Dr. Thompson's Infiniti and other rider to crash onto the pavement. The driver, who admitted slamming on his brakes, was later sentenced to 10 years in prison.\"\n\nA \"New York Times\" story stated a 41-year-old cyclist, Dan Cooley was injured by a driver who became angry at him after an exchange of swear words. The incident began when the driver came out of a driveway in front of Mr. Cooley. Angered, Mr. Cooley cursed at the driver, who responded in kind. As Mr. Cooley moved off the road, the car drove into him, and knocked him to the ground with the vehicle, and then the driver got out of the car and attacked him, leaving him with a concussion and a torn ligament. Mr. Cooley thinks that the anger between cyclists and drivers might be due to the relatively new arrival of bikes on city streets: “We’ve had a car culture for so long and suddenly the roads become saturated with bicyclists trying to save gas\"; however, he added,“No one knows how to share the road.”\n\nAccording to the \"UK Guardian\", a cyclist named Jefferey Guffey from Indiana told a driver to slow down. The driver attacked Guffey and bit part of his ear off. After the incident, police charged the attacker with battery. In Oxford, \"police investigated a spate of attacks on cyclists motivated, apparently, by hatred of bicycles and their riders\".\n\nChristian Wolmar, an international expert on transportation, stated that Sydney \"drivers are more hostile towards cyclists than motorists of any other country\".\n\nIn Toronto in 2007, \"... after being cut off by a driver just after morning rush hour in Toronto, a cyclist caught up to the car, reached inside the window, and stabbed the driver in the face and neck with a screwdriver.\"\n\nA 2004 \"Chicago Sun-Times\" article states that a Pennsylvania bicyclist shot a truck driver in the arm after an altercation. The truck driver, William Nicoletti, 51, drove past the cyclist, who made an obscene gesture. Mr. Nicoletti stated that when he turned his truck around and drove toward the cyclist, man on the bike drew a pistol and shot Mr. Nicoletti. The man on the bicycle, Robert Urick, 41, was \"charged with attempted homicide, aggravated assault and weapons offenses\".\n\nA 2008 \"Newsweek\" article entitled \"Pedal vs. Metal: A surge in bike ridership spurs a new kind of road rage\" described an altercation which began after a driver named Patrick Schrepping told cyclist Adam Leckie to wear a helmet. Following this conversation, Leckie \"allegedly responded by keying Schrepping's car\", and then Schrepping struck Leckie with a metal object. Both men were arrested and charged with assault.\n\nMichael J. Bryant (born April 13, 1966) is a former public administrator and former politician in Ontario, Canada who was involved in an incident with a cyclist. After an altercation with a cyclist on August 31, 2009, in which Bryant's car struck a bike courier, Bryant was charged with criminal negligence causing death and dangerous driving causing death. On May 25, 2010, all charges against Bryant were withdrawn, with prosecutors describing the cyclist as the aggressor in the incident.\n\nBike rage does not only involve altercations between drivers and cyclists. In some cases, there have been fights between cyclists. In an incident in Madison, Wisconsin, a 51-year-old cyclist suggested to a 28-year-old cyclist that he should get a bike light so that others could see him. After hearing this comment, the younger cyclist felt \"extremely insulted\" and allegedly tried to force the older man off the road. The 51-year-old was followed to his home, at which point the 28-year-old \"clamped his hands around O'Brien's head\" and then \"... twisted O'Brien to the ground and kicked him in the ribs.\" Police indicated that they planned to charge the younger man.\n\n"}
{"id": "22512949", "url": "https://en.wikipedia.org/wiki?curid=22512949", "title": "Branko Cvetkovic", "text": "Branko Cvetkovic\n\nBranko Cvetkovic (born 1951), a Slovenian photographer known for his philosophically conceptualized approach to photography. Working mostly with large-format cameras, his architecture photography is minimalistically structured. From symmetry he opens up the space perspective to deconstructivism, and in art there is a transition to a non-perspective suprematist plane, thus coinciding with abstract expressionism. Besides space, his main concern is the phenomenon of light itself, the two basic postulates in photography.\n\nBranko Cvetkovic was born on April 15, 1951 in Novo Mesto, Slovenia, former Yugoslavia. He graduated in political economics under the mentorship of one of the best known Yugoslavian economists, France Cerne, at the Faculty of Economics of the University of Ljubljana. After working for various research institutions he served as an expert for manpower for the government of the Republic of Seychelles. He was also appointed as an expert for the United Nations organization Habitat.\n\nHe started to become involved with photography in 1986 and 1987 in the Seychelles. This coincidental beginning and later obsession was triggered by his fascination with light – a reminiscence of a childhood awareness of the light on the houses of his birthplace – and an emerging sensitivity to fine art, dating from his student years. Nevertheless, his first two independent, and still amateur, projects were the Creole houses and a continuous conceptual recording of the light above the island Silhouette. After his return home he abandoned his work as an economist and went on to work as an artist, a profession in his belief of greater importance and of greater and lasting value. He started to work professionally in photography; upgrading his technical skills and perception of fine art. Since 1990 he has been a free-lance photographer working mainly in architecture, industry and art; in the early years he also dealt with creative and artistic management and design.\n\nIn the years 1992 – 98 the several works were awarded, where Cvetkovic played a role as creative, conceptual or art director, co-designer and photographer.\n\nBranko Cvetkovic resides in Ljubljana.\n\nInitially, his approaches had evolved intuitively, then there was a cognition process of photography and art, involving analyses of conceptual art and minimalistic expression in Bauhaus modernism and avant-garde upgraded by Russian constructivism. In architectural photography he radicalized certain conceptual and functionalist approaches which can be compared with or are similar to those of the Bechers’ Düsseldorf school. He worked conceptually and was particularly devoted to defining spatial light and transmitting and upgrading the form or architecture of space. In spite of his highly objective aspirations in this period he could be considered a constructivist.\n\nIn his late period he established a philosophical idea of Non-Space as a totality of abstract space. In the fine art sense he transformed space into an abstract expressive image of the (suprematist) plane as the ultimate transformation of three-dimensional space into nil or zero dimension. Therefore, he discovered his artistic ambitions in the field of abstract expressionism.\n\nIn his early studies Cvetkovic found himself mainly occupied with the issue of the complexity of light and image, its disintegration into layers with various depths of field, in order to envisage a new image and to formulate or to frame it on the Bauhaus modernist plane.\n\nIn this period (1990-1995) he dealt with minimalistic and conceptual topics summed up in projects: Rocks and Water, Light within Seashells, Waves and Series of Seawater Abstractions. His projects continued with almost abstract cycles in the Bauhaus constructivist manner: Lux Plantarum (1997) and Light of Shadow – Drawing of Form (1998), both exhibited in Ljubljana.\n\nThis was the introduction leading to his most complex opus of industrial photography, still defined by the Bauhaus spirit and undertaken at the industrial premises of the Akrapovic firm in the years 1997 and 1998, continuing in 2002 and 2003: Tubes, Chinese Cosmos, Abstractions and Bauhaus . His final creation in this field was in 8x10 inches LF and was named Locomotives (2005).\n\nIn architectural photography Cvetkovic has made his way from structuralism to deconstructivism. At his early stage of involvement in photography, Cvetkovic had been posing himself the question of the construction of the constructivist frame on the one hand and on the other the problem of defining or constructing light within space. Thus, his architectural photography is minimalistic, rationalized and architecturally schematic. A reading of light is defined by the architectural shell itself. With this approach he autonomously developed modernist functionalist architectural photography and only in this way did he find himself side by side with the developing Düsseldorf school.\n\nHis first exhibition The Old Power Station in Ljubljana in 1992, was the first in this series, as well as the continuation of his project of old industrial buildings, namely Rog and the old brick factory of Ljubljana, which were exhibited in 1997 under the title Past Spaces. In the old power station Cvetkovic did not only make a so-called archeological inventory of the building, he also introduced the archeology of spatial light. He had researched light, as one of the critics put it. In Past Spaces (1997), he had already presented architecture by sequencing the framing and \"new\" construction of the perspective by overturning the areas or planes of a picture similar to Russian constructivism.\n\nRadical in his concept, Cvetkovic was presented as an architectural photographer in the full complexity of his work in 1996, with his exhibition of Plecnik`s Marketplace. In this exhibition he broke with the contemporary post-modernist tradition of representing architecture in Slovenia by replacing it with a functionalist overview. The scheme and the structure of the photographic work were outlined by him during the period of the renovation of Plecnik’s buildings. He shaped the Plecnik’s architecture in doctrinaire typology by using the symmetrical minimalist concept, perspective-corrected images of the architectural structures, consistently outlined only by a diffused non-shadow light, which became the light of an object itself. This was the method the photographer strictly implemented during the period coinciding with the emerging Düsseldorf school. The whole exhibition took place at the Municipal Gallery of Ljubljana and was accompanied by the artist’s monograph. It paved the way for him to the most important cultural and professional Slovenian institutions, whilst he became distinguished with his interpretation of the architecture of their home buildings, their reconstructions and renovations. The collections of his photographs are represented as the core of the archives of the National University Library, Cankar Cultural Centre, Slovenian Philharmonic Hall, Slovenian National Opera and Ballet, Municipal Museum and Galleries of Ljubljana, the Institution for Public Health, House of Constitutional Law, etc.\n\nCvetkovic completed extensive work on Plecnik`s architecture of the National and University Library of Slovenia (NUK) in the years 1998–1999 and 2003. The originals were taken by large format 4x5 inch and 13x18 cm Sinar P2 and Hasselblad 6x6. The lead and the principle of the photography and composition are based on the Düsseldorf school doctrine. In some cases sequential photographing was also taken into account. Truly exceptional is the photograph of the main entrance façade; for the first time in the history of the NUK this is seen and established in one perspective-corrected picture, actually amalgamated from three vertically positioned originals in 13x18 cm format. Because of the narrow street and the extent of the façade, this had hitherto been an unattainable, a constant enigmatic frustration never to be overcome.\n\nCvetkovic has approached Plecnik not only in his creative aspiration, but also ethically in his unconditional aspiration to perfection. In each of the photographed spaces his interest was also in its symbolic meaning. For him, in his picturing the Plecnik`s architecture, the basic message was the fine art transmittance of architecture with the sequential construction of the planes with the typical reduction of the light and the maximal objectivistic and plastic construction of the space, thus positioning the Plecnik`s sequencing of the classical, almost renaissance architectural space.\n\nAlmost the contrary has been achieved with Cvetkovic`s architectural photography in his introspective survey of the Slovenian National Opera and Ballet Theatre in Ljubljana as a paradigmatic amphitheatric space. This extensive work was accomplished in the years 2002, 2003, 2007, 2007-2011.\n\nIn 2004 Cvetkovic exhibited his new de-constructivist series entitled Deconstruction of Light – Sequential Constructions of the Space Planes: the Spaces of Spaces, shortly deKons. The oeuvre started to emerge during the renovation of the Auersperg palace Turjaska palaca. The author departed from the Düsseldorf school presentation. He radicalized the classical upright perspective; he controlled the architectural image by framing it in the sense of Russian constructivism, thus opening up the way to abstraction. This transformation enabled Cvetkovic to be liberated from the classical principle.\n\nIndirect recording of light within the shell of the architecture as an analytical tool necessarily makes it possible to create a new abstract quality – the quality of the light as a means of the sequential decomposition of spatial framings. The author gives the explanation himself: \"Therefore we do not only achieve the effect of constructing the perspective by overturning planes in two-dimensional space (in constructivist sense) but deconstruction of perspective and disintegration of planes by the act of deconstruction of light. Inversely that means creation or construction of a new abstract deconstructed space.\" \n\nAnother constructivist project entitled Backstage was recorded in Cankar Cultural Centre (Cankarjev dom) in 2004 and 2005. Cvetkovic develops his idea of abstract space as a dynamic construction never defined, yet firmly built on its groundwork base, but varied in its contingency forms upon the physical optics of various projects. These are the spaces of Backstage, which both serve and model the creativity. The static picture of a construction-based form is varied to a dynamic deconstructed space, decomposed into planes; the planes that host the people as creative figures and momentary actors.\n\nBeside the main opus, there are two special series in Backstage, denoting solely the Stage as a Podium and as a Hall. The first is designed to comply with the idea of Stage as Pollock’s fine art image plane. Cvetkovic’s photographic plane is marked by unnumbered timeless coloured traces that physically mark and embody human action on the stage for ever. The other series denotes a hall as a deconstructed space of a suprematist Malevich square plane. Each is determined and sponsored by the unique colour of the square plane. Both series are initiated and denoted by a black square – seven minutes exposure in the totally dark space of the stage – as a prelude to an abstract image of indefinable expectation on the part of the spectator.\n\nAccording to several art critics, Cvetkovic reached the heights in the programmed course with the En Face exhibition in the National Gallery of Slovenia (Narodna galerija) in 2005, accompanied with the monograph – catalogue. \nLarge format photographs with substantial enlargements, some of them digitally composed into one unified frame enlargement, speak of the façade and its embodying the technical, cultural, social and historical artefact. The façade shows itself as a connotation and determiner of the place. Quoting the author, \"the only one building of certain space is the unicum of that place and that place alone becomes the only one place of that certain building\". From this intentionally prefixed tautology it may be established that in his work, Cvetkovic, who has been constantly loyal to his conceptual reasoning in the photographic sense of the matter, wider in the fields of fine art and theory, has approached the Düsseldorf school most closely.\n\nTo finalize the representation of Cvetkovic oeuvre attention should be drawn to his outstanding management of space and perspective correction and his ability to impart to the image in his photography the archetypes, the timelessness and the entireness of the structured spaces as a whole or things as architectures by themselves.\n\nIn the years 2008, 2009 and 2010 Cvetkovic concluded his complex and extensive project entitled NON-SPACE / ZeroSPACE. The author goes through abstraction to the field of abstract expressionism, both conceptually and philosophically, both in the elaboration and execution of his work on 5x7 and 8x10 large format film originals.\nHis philosophical reductionist idea of non-space is presented as an antithesis of real space. Real space has converged into anti-space, into a totality of absolute abstraction of space which in terms of fine art, after the exclusion of perspective, light and real time, denotes an abstract expressive plane as a final transformation of space. In this way the basic three fine art issues are once again introduced into modernist art discourse. These are: perspective, light and the concept of space. The transformation of space into plane confirms and challenges the idea of a black and white square plane. Cvetkovic is radical in developing his thesis. He confronts his conception of the basic fine art principles with the most human abstract and universal experience; the human comprehension of death. Within this conceptual context, with utmost consistency and vigorousness, the author elaborates his exceptional frames of vast seascapes, transforming these huge spaces into vast abstract minimalistic planes; the screens and the images are ones that have not yet been encountered in Slovenian art. \nThe main idea is the gradual elimination of perspective and sublime transition of space to plane – \"screen\". Series called Screens, with many derivations, colours and transformations, accentuate abstraction of space to an expressive two-dimensional plane. The last are those of the \"Black and white plane\" as the final synthesis of denomination to NON-SPACE│ZeroSPACE, concluded as a total abstraction with no dimension.\n\nIn spite of total reduction and final darkness, the definitive will towards total liberation, as the idea of huge space in open sky and light, emerges. It could be termed heaven`s light or simply the big magic light, which outlasts and illuminates everything in all its material transformations. This light is the symbol of human mental eternal space.\n\nWhite lights; open ocean spaces with vast light ruptures and immense light rays, and even bigger light chasms that literally swallow and dematerialize everything by colouring it into white dazzling lights, are the founding idea for the project that also opens up for the terminating idea of the Heaven Lights.\n\nMuch earlier than impressionists, and later abstract expressionists, William Turner was the first painter of romantic and symbolic heritage, who was mainly preoccupied with the idea of light. In his paintings: , 1812, Shade and Darkness – the Evening of the Deluge, 1843, Light and Colour – the Morning after the Deluge, 1843, he tried to introspect and consume the light as a spiritual category in its mysticism and abstraction of its highest spiritual elevation. In the first painting, the light and the sun rest under the firmament of clouds shaped like a cathedral vault. Respectively, in other above-mentioned paintings, the light is embodied in the circle that reflects the gaze into a dome. Turner`s approach gave to the phenomenon of light the power for elevation that absorbs the spectator.\n\nIn the author’s opinion, these are fantastic grounds for deviation into abstract, non-material, non-objective matter; confrontation of photography with the essential and most basic constitutional matter, Light. This is the reason why his project, based on introspection of sublime light, elevation from darkness into the light, and spiritual absorption, a voyage that is traced by light, could be handled and tracked by photography and its basic tool, Light.\n\nCvetkovic’s work is based on the movement of the large format 8x10 in. camera which, with its resolution power of 8x10 in. film and long exposures, can absorb the light in its abstract images.\n\nPhotography is rigorously objectivistic. Symmetries are their basic orientation points. The notion of expressiveness is accentuated by perspective and the absence of it, respectively. The series of Screen and Plane coincide with abstract expressionism. In addition, the presentiment and sensation of huge minimalistic planes with expressive supernatural connotation have to possess monumental momentum. Their modem is an abstract pattern which we, unawares, inhibit in ourselves. White Lights is mainly based on symmetries and very strong reflective light on the ocean.\n\nCvetkovic started to exhibit in 1992. His major conceptual and programmed solo exhibitions are contextualized within the description of his work.\n\n\n\nTill 2006 Cvetkovic`s exhibitions were strictly solo and were organized and curated by himself. After his major exhibition in Slovenian National Gallery in 2005 he started to associate with Photon Gallery based in Ljubljana. Between 2010 and 2016 he was represented by Prom-Galerie, Munich.\n\nCvetkovic`s works are held in numerous collections and archives of Slovenian cultural institutions and by private owners, including National University Library, Cankar Cultural Centre, Slovenian National Opera and Ballet, Slovenian Philharmonic Hall, Municipal Museum and Galleries of Ljubljana, the Institution of Public Health, House of Constitutional Law, Porsche, The Carmen Würth Collection Museum Würth Kunzelsau etc.\n\nCvetkovic has extensive bibliography with more than 125 references in Slovenian Online Bibliographic System COBISS. His most important books are: \n\nIn the years 1992 – 1996 the following works were awarded, where Cvetkovic played a role as creative, conceptual or art director, co-designer and photographer. \n"}
{"id": "914564", "url": "https://en.wikipedia.org/wiki?curid=914564", "title": "Chekhov's gun", "text": "Chekhov's gun\n\nChekhov's gun () is a dramatic principle that states that every element in a story must be necessary, and irrelevant elements should be removed; elements should not appear to make \"false promises\" by never coming into play. The statement is recorded in letters by Anton Chekhov several times, with some variation:\n\n\nNote the difference between Chekhov's Gun and foreshadowing. Foreshadowing only vaguely implies that an event will take place in the future, meanwhile, the Chekhov's Gun principle guarantee's that an event will happen further along in the story.\n"}
{"id": "5653", "url": "https://en.wikipedia.org/wiki?curid=5653", "title": "Clarke's three laws", "text": "Clarke's three laws\n\nBritish science fiction writer Arthur C. Clarke formulated three adages that are known as Clarke's three laws, of which the third law is the best known and most widely cited. They were part of his ideas in his extensive writings about the future. These so-called laws include:\n\n\nOne account claimed that Clarke's \"laws\" were developed after the editor of his works in French started numbering the author's assertions. All three laws appear in Clarke's essay \"Hazards of Prophecy: The Failure of Imagination\", first published in \"Profiles of the Future\" (1962). However, they were not published at the same time. Clarke's first law was proposed in the 1962 edition of the essay, as \"Clarke's Law\" in \"Profiles of the Future\".\n\nThe second law is offered as a simple observation in the same essay but its status as Clarke's second law was conferred by others. It was initially a derivative of the first law and formally became Clarke's second law where the author proposed the third law in the 1973 revision of \"Profiles of the Future,\" which included an acknowledgement\".\" It was also here that Clarke wrote about the third law in these words: \"As three laws were good enough for Newton, I have modestly decided to stop there\".\n\nThe third law, despite being latest stated by a decade, is the best known and most widely cited. It appears only in the 1973 revision of the \"Hazards of Prophecy\" essay. It echoes a statement in a 1942 story by Leigh Brackett: \"Witchcraft to the ignorant, … simple science to the learned\". Earlier examples of this sentiment may be found in \"Wild Talents\" (1932) by Charles Fort: \"...a performance that may some day be considered understandable, but that, in these primitive times, so transcends what is said to be the known that it is what I mean by magic,\" and in the short story \"The Hound of Death\" (1933) by Agatha Christie: \"The supernatural is only the natural of which the laws are not yet understood.\"\n\nClarke gave an example of the third law when he said that while he \"would have believed anyone who told him back in 1962 that there would one day exist a book-sized object capable of holding the content of an entire library, he would never have accepted that the same device could find a page or word in a second and then convert it into any typeface and size from Albertus Extra Bold to Zurich Calligraphic\", referring to his memory of \"seeing and hearing Linotype machines which slowly converted ‘molten lead into front pages that required two men to lift them’\".\n\nA fourth law has been proposed for the canon, despite Clarke's declared intention of stopping at three laws. Geoff Holder quotes: \"For every expert, there is an equal and opposite expert,\" which is part of American economist Thomas Sowell's \"For every expert, there is an equal and opposite expert, but for every fact there is not necessarily an equal and opposite fact\", from his 1995 book \"The Vision of the Anointed\".\n\nThe third law has inspired many snowclones and other variations:\n\n\nA of the third law is\n\n\nThe third law has been:\n\n\n\n"}
{"id": "1588279", "url": "https://en.wikipedia.org/wiki?curid=1588279", "title": "Combinatorial principles", "text": "Combinatorial principles\n\nIn proving results in combinatorics several useful combinatorial rules or combinatorial principles are commonly recognized and used.\n\nThe rule of sum, rule of product, and inclusion–exclusion principle are often used for enumerative purposes. Bijective proofs are utilized to demonstrate that two sets have the same number of elements. The pigeonhole principle often ascertains the existence of something or is used to determine the minimum or maximum number of something in a discrete context. Many combinatorial identities arise from double counting methods or the method of distinguished element. Generating functions and recurrence relations are powerful tools that can be used to manipulate sequences, and can describe if not resolve many combinatorial situations.\n\nThe rule of sum is an intuitive principle stating that if there are \"a\" possible outcomes for an event (or ways to do something) and \"b\" possible outcomes for another event (or ways to do another thing), and the two events cannot both occur (or the two things can't both be done), then there are \"a + b\" total possible outcomes for the events (or total possible ways to do one of the things). More formally, the sum of the sizes of two disjoint sets is equal to the size of their union.\n\nThe rule of product is another intuitive principle stating that if there are \"a\" ways to do something and \"b\" ways to do another thing, then there are \"a\" · \"b\" ways to do both things.\n\nThe inclusion–exclusion principle relates the size of the union of multiple sets, the size of each set, and the size of each possible intersection of the sets. The smallest example is when there are two sets: the number of elements in the union of \"A\" and \"B\" is equal to the sum of the number of elements in \"A\" and \"B\", minus the number of elements in their intersection.\n\nGenerally, according to this principle, if \"A\", ..., \"A\" are finite sets, then\n\nBijective proofs prove that two sets have the same number of elements by finding a bijective function (one-to-one correspondence) from one set to the other.\n\nDouble counting is a technique that equates two expressions that count the size of a set in two ways.\n\nThe pigeonhole principle states that if \"a\" items are each put into one of \"b\" boxes, where \"a\" > \"b\", then one of the boxes contains more than one item. Using this one can, for example, demonstrate the existence of some element in a set with some specific properties.\n\nThe method of distinguished element singles out a \"distinguished element\" of a set to prove some result.\n\nGenerating functions can be thought of as polynomials with infinitely many terms whose coefficients correspond to terms of a sequence. This new representation of the sequence opens up new methods for finding identities and closed forms pertaining to certain sequences. The (ordinary) generating function of a sequence \"a\" is\n\nA recurrence relation defines each term of a sequence in terms of the preceding terms. Recurrence relations may lead to previously unknown properties of a sequence, but generally closed-form expressions for the terms of a sequence are more desired.\n\n"}
{"id": "41700062", "url": "https://en.wikipedia.org/wiki?curid=41700062", "title": "Community reinforcement approach and family training", "text": "Community reinforcement approach and family training\n\nCommunity reinforcement approach and family training (CRAFT) is a behavior therapy approach for treating addiction. The original community reinforcement approach (CRA), developed by Nate Azrin in the 1970s, uses operant conditioning to help people learn to reduce the power of their addictions and enjoy healthy living. CRAFT combines CRA with family training, which equips families and friends with supportive techniques to encourage their loved ones to begin and continue treatment, and provides defenses against addiction's damaging effects on loved ones.\n\nThe \"community reinforcement approach\" (CRA) was \"originally developed for individuals with alcohol use disorders, [but] has been successfully employed to treat a variety of substance use disorders for more than 35 years. Based on operant conditioning [a type of learning], CRA helps people rearrange their lifestyles so that healthy, drug-free living becomes rewarding and thereby competes with alcohol and drug use.\"\n\n\"CRA is a time-limited treatment.\" \"In time-limited therapy, a set number of sessions (for example, 16 sessions) or time limit (for example, one year) is decided upon either at the very beginning of therapy or within the early stages of therapy.\"\n\n\"Community reinforcement and family training\" (CRAFT) is CRA that \"works through family members.\" It \"is designed to increase the odds of the substance user who is refusing treatment to enter treatment, as well as improve the lives of the concerned family members. CRAFT \"teaches the use of healthy rewards to encourage positive behaviors. Plus, it focuses on helping both the substance user and the family.\"\n\n\"Adolescent Community Reinforcement Approach\" (A-CRA) is CRA that \"targets adolescents with substance use problems and their caregivers.\"\n\nCRAFT is a motivational model of family therapy. It is reward-based—that is, based on positive reinforcement. CRAFT is aimed at the families and friends of treatment-refusing individuals who have a substance abuse problem. \"CRAFT works to affect [influence] the substance users’ behavior by changing the way the family interacts with them.\"\n\nIn the model, the following terms are used:\n\n\n\"CRAFT grew out of the understanding that although individuals who truly need help with substance use problems often are strongly opposed to treatment. On the other hand, the concerned significant others (CSOs) of the substance abuser are commonly highly motivated to get help for them.\"\n\nWhen a loved one is abusing substances and refusing to get help, CRAFT is designed to help families learn practical and effective ways to accomplish these three goals:\n\n\nOne experiment compared CRAFT with Al-Anon and Nar-Anon facilitation therapies for their impacts on addicts to enter treatment. The finding was that concerned significant others who participated in Al-Anon and Nar-Anon facilitation therapy engaged 29.0% of addicts into treatment, whereas those who went through CRAFT engaged 67.2%. Another study compared CRAFT, Al-Anon facilitation therapy designed to encourage involvement in the 12-step program, and a Johnson intervention. The study found that all of these approaches were associated with similar improvements in the functioning of concerned significant others and improvements in their relationship quality with the addicts. However, the CRAFT approach was more effective in engaging initially unmotivated problem drinkers in treatment (64%) as compared with the Al-Anon (13%) and Johnson interventions (30%).\n\nRobert J. Meyers, PhD wrote about the influence that concerned family members have in treatment of the substance user, and the benefits for themselves:\n\nThe following CRA procedures and descriptions are from Meyers, Roozen, and Smith for the substance user:\n\n\n\"(For details, please see the article: \"The Community Reinforcement Approach: An Update of the Evidence\" published in the Alcohol Research and Health journal by NIAAA.)\"\n\nWith CRAFT, families/friends (CSOs) are trained in various strategies, including positive reinforcement, various communication skills, and natural consequences. \"One of the big pieces that has a lot of influence over all the other strategies is positive communication. \"There are seven steps in the CRAFT model for implementing positive communication strategies.\"\n\n\n\"The overarching goals for the strategies for communicating are to help decrease defensiveness on the part of the loved one that you are speaking to, and increase the chances that your message is really going to be heard—so, increasing the ability that you have to really get across the message that you want.\" In fact, the title of Robert J. Meyers' and Brenda L. Wolfe's book based on CRAFT is, \"Get Your Loved One Sober: Alternatives to Nagging, Pleading, and Threatening.\"\n\n\"Consequences being in place is really important and helpful in terms of communicating your message, but it's also really important, maybe even more so, to be consistent in following through with those consequences and rewards.\"\n\nAl-Anon does not currently adopt, hold, or promote the view that concerned significant others (CSOs) can, with any certainty, make a positive, direct, and active contribution to arrest compulsive drinking. However, Al-Anon says that by CSOs improving their own attitudes, and offering support and encouragement to the user, the \"family situation is bound to improve.\" On the other hand, the premise of CRAFT is that deliberate, positive interactions can increase willingness and decrease resistance of users to treatment. Al-Anon recognizes that while increased willingness and decreased resistance may be a happy by-product of detaching from the adverse behaviors of alcoholics, there are no guarantees that this will occur. Al-Anon is a fellowship with a focus on helping families and friends, themselves, without promoting a direct intervention process for alcoholics \"(see Al-Anon/Alateen)\". Because \"no one ever graduates\" from Al-Anon, Al-Anon can be viewed as an open-ended program, not time-limited, whereas CRAFT is more specific.\n\nRegarding the CSO's relationship to alcoholism and sobriety, the view from the Al-Anon organization can be summarized:\n\n\n\nRegarding alcoholics, the Al-Anon-recommended approach for CSOs (families/friends) is \"detachment with love\"\n\nAs far as the CSOs having a direct and positive impact on another's sobriety, Al-Anon asks and answers itself:\nThis answer has these three characteristics:\n\n\n\"From SMART Recovery, section: Family & Friends:\"\n\nThe CRAFT program uses a variety of interventions based on functional assessment including a module to prevent domestic violence.\n\n\"There are questions about the long-term effectiveness of interventions for those addicted to drugs or alcohol. A study examining addicts who had undergone a standard intervention (called the Johnson Intervention) found that they had a higher relapse rate than any other method of referral to outpatient Alcohol and Other Drug treatment\"\"(see Intervention, section: Controversy)\".\n\nSmith, Campos-Melady and Meyers describe the Johnson Institute intervention as a \"surprise party\" that is uncomfortable for many CSOs (families/friends):\n\nResearch suggests that CRAFT has had significantly greater success than the Johnson Intervention method or Al-Anon/Alateen, as far as engaging loved ones in treatment.\n\nThe community reinforcement approach has considerable research supporting it as effective. Community reinforcement has both efficacy and effectiveness data. Started in the 1970s, community reinforcement approach is a comprehensive operant program built on a functional assessment of a client's drinking behavior and the use of positive reinforcement and contingency management for non-drinking. When combined with disulfiram (an aversive procedure) community reinforcement showed remarkable effects. One component of the program that appears to be particularly strong is the non-drinking club. Applications of community reinforcement to public policy has become the recent focus of this approach.\n\n\"The Community Reinforcement Approach has been found to be extremely effective in outpatient settings as well. In one study, clients treated with CRA and the disulfiram compliance component were abstinent an average of 97% of the days during the last month of the 6-month followup, whereas clients treated with a combination of a 12-step program and the CRA disulfiram compliance training were\nabstinent an average of 74% of the days. For those clients who received a 12-step program and a prescription for disulfiram, an average of only 45% of the comparable days were abstinent (Azrin, Sisson, Meyers, & Godley, 1982).\"\n\nAn offshoot of the community reinforcement approach is the community reinforcement approach and family training. This program is designed to help family members of substance abusers feel empowered to engage in treatment. Community reinforcement approach and family training (CRAFT) has helped family members to get their loved ones into treatment. The rates of success have varied somewhat by study but seem to cluster around 70%. CRAFT is one of the only family-aimed treatments with proven results for getting people with drug or alcohol problems into treatment. The program uses a variety of interventions based on functional assessment including a module to prevent domestic violence. Partners are trained to use positive reinforcement, various communication skills and natural consequences.\n\nFrom an article on the American Psychology Association (APA) website about the success of CRAFT in substance abuse treatment and intervention, these are the success outcomes for engaging drinkers into treatment:\n\n\nFrom the article:\n\nFrom the same article on the American Psychology Association (APA) website about the success of CRAFT in substance abuse treatment and intervention, these are the success outcomes for persons abusing drugs to enter treatment (the success outcomes were nearly the same as the alcohol abuse outcomes):\n\n\nFrom the article:\n\nNote: When the articles states \"there was no group x time interaction,\" it simply means the CRAFT outcome (64%) and the TSF outcome (17%) remained the same over time, even though there was a reduction in drug use during the study.\n\n\"(For details, please see the American Psychological Association (APA) article: \"Community Reinforcement and Family Training (CRAFT)\", published by the APA)\"\n\n\"In a parallel study sponsored by the National Institute on Drug Abuse that focused on abusers of other drugs, family members receiving CRAFT successfully engaged 74 percent of initially unmotivated drug users in treatment (Meyers et al. 1999).\"\n\nCRA was designed by Nate Azrin in the early 1970s:\n\nThe origin of CRAFT:\n\nUp to 2009, CRAFT and CRA programs were not widespread amongst addiction counselors. Instead, many addiction counselors were tied to a twelve-step model that had much less research support. Recent trends by the National Institute on Drug Abuse (NIDA) have been to help deploy these intervention techniques. In 2007, CRAFT was being used in 25 clinics in the United States.\n\nThe Association for Behavior Analysis International (ABAI) has a special interest group in clinical behavior analysis.\n\nThe Association for Behavioral and Cognitive Therapies (ABCT) also has an interest group in behavior analysis, which focuses on clinical behavior analysis. In addition, ABCT has a special interest group on addictions.\n\n\n"}
{"id": "3885297", "url": "https://en.wikipedia.org/wiki?curid=3885297", "title": "Comprehension (logic)", "text": "Comprehension (logic)\n\nIn logic, the comprehension of an object is the totality of intensions, that is, attributes, characters, marks, properties, or qualities, that the object possesses, or else the totality of intensions that are pertinent to the context of a given discussion. This is the correct technical term for the whole collection of intensions of an object, but it is common in less technical usage to see 'intension' used for both the composite and the primitive ideas.\n\n"}
{"id": "23931493", "url": "https://en.wikipedia.org/wiki?curid=23931493", "title": "EWMA chart", "text": "EWMA chart\n\nIn statistical quality control, the EWMA chart (or exponentially weighted moving average chart) is a type of control chart used to monitor either variables or attributes-type data using the monitored business or industrial process's entire history of output. While other control charts treat rational subgroups of samples individually, the EWMA chart tracks the exponentially-weighted moving average of all prior sample means. EWMA weights samples in geometrically decreasing order so that the most recent samples are weighted most highly while the most distant samples contribute very little.\n\nAlthough the normal distribution is the basis of the EWMA chart, the chart is also relatively robust in the face of non-normally distributed quality characteristics. There is, however, an adaptation of the chart that accounts for quality characteristics that are better modeled by the Poisson distribution. The chart monitors only the process mean; monitoring the process variability requires the use of some other technique.\n\nThe EWMA control chart requires a knowledgeable person to select two parameters before setup:\n\nInstead of plotting rational subgroup averages directly, the EWMA chart computes successive observations z by computing the rational subgroup average, formula_1, and then combining that new subgroup average with the running average of all preceding observations, z, using the specially–chosen weight, λ, as follows:\n\nThe control limits for this chart type are formula_3 where T and S are the estimates of the long-term process mean and standard deviation established during control-chart setup and n is the number of samples in the rational subgroup. Note that the limits widen for each successive rational subgroup, approaching formula_4.\n\nThe EWMA chart is sensitive to small shifts in the process mean, but does not match the ability of Shewhart-style charts (namely the formula_5 and R and formula_5 and s charts) to detect larger shifts. One author recommends superimposing the EWMA chart on top of a suitable Shewhart-style chart with widened control limits in order to detect both small and large shifts in the process mean.\n\nExponentially weighted moving variance (EWMVar) can be used to obtain a significance score or limits that automatically adjust to the observed data.\n"}
{"id": "9708", "url": "https://en.wikipedia.org/wiki?curid=9708", "title": "European Charter for Regional or Minority Languages", "text": "European Charter for Regional or Minority Languages\n\nThe European Charter for Regional or Minority Languages (ECRML) is a European treaty (CETS 148) adopted in 1992 under the auspices of the Council of Europe to protect and promote historical regional and minority languages in Europe. The preparation for the charter was undertaken by the predecessor to the current Congress of Local and Regional Authorities, the Standing Conference of Local and Regional Authorities of Europe because involvement of local and regional government was essential. The actual charter was written in the Parliamentary Assembly based on the Congress' Recommendations. It only applies to languages traditionally used by the nationals of the State Parties (thus excluding languages used by recent immigrants from other states, see immigrant languages), which significantly differ from the majority or official language (thus excluding what the state party wishes to consider as mere local dialects of the official or majority language) and that either have a territorial basis (and are therefore traditionally spoken by populations of regions or areas within the State) or are used by linguistic minorities within the State as a whole (thereby including such languages as Yiddish, Romani and Lemko, which are used over a wide geographic area).\n\nSome states, such as Ukraine and Sweden, have tied the status of minority language to the recognized national minorities, which are defined by ethnic, cultural and/or religious criteria, thereby circumventing the Charter's notion of linguistic minority. \n\nLanguages that are official within regions, provinces or federal units within a State (for example Catalan in Spain) are not classified as official languages of the State and may therefore benefit from the Charter. On the other hand, Ireland has not been able to sign the Charter on behalf of the Irish language (although a minority language) as it is defined as the first official language of the state. The United Kingdom has ratified the Charter in respect to (among other languages) Welsh in Wales, Scots in Scotland, and Irish in Northern Ireland. France, although a signatory, has been constitutionally blocked from ratifying the Charter in respect to the languages of France.\n\nThe charter provides a large number of different actions state parties can take to protect and promote historical regional and minority languages. There are two levels of protection—all signatories must apply the lower level of protection to qualifying languages. Signatories may further declare that a qualifying language or languages will benefit from the higher level of protection, which lists a range of actions from which states must agree to undertake at least 35.\n\nCountries can ratify the charter in respect of its minority languages based on Part II or Part III of the charter, which contain varying principles. Countries can treat languages differently under the charter, for example, in the United Kingdom, the Welsh language is ratified under the general Part II principles as well as the more specific Part III commitments, while the Cornish language is ratified only under Part II.\n\nPart II of the Charter details eight main principles and objectives upon which States must base their policies and legislation. They are seen as a framework for the preservation of the languages concerned.\n\nPart III details comprehensive rules across a number of sectors, that states agree to abide by. Each language to which Part III of the Charter is applied must be specifically named by the government. States must select at least thirty-five of the undertakings in respect of each language. Many provisions contain several options, of varying degrees of stringency, one of which has to be chosen “according to the situation of each language”. The areas from which these specific undertakings must be chosen are as follows:\n\nCountries that have ratified the Charter, and languages for which the ratification was made:\n\n\n"}
{"id": "27132266", "url": "https://en.wikipedia.org/wiki?curid=27132266", "title": "Excitation-transfer theory", "text": "Excitation-transfer theory\n\nExcitation-transfer theory purports that residual excitation from one stimulus will amplify the excitatory response to another stimulus, though the hedonic valences of the stimuli may differ (Bryant & Miron, 2003). The excitation-transfer process is not limited to a single emotion (cf. Zillmann, 1983, 1996, 1998). For example, when watching a movie, a viewer may be angered by seeing the hero wronged by the villain, but this initial excitation may intensify the viewer's pleasure in witnessing the villain's punishment later. Thus, although the excitation from the original stimulus of seeing the hero wronged was cognitively accessed as anger, the excitation after the second stimulus of seeing the villain punished is cognitively assessed as pleasure, though part of the excitation from the second stimulus is residual from the first. \nHowever, the excitation-transfer process requires the presence of three conditions. One: the second stimulus occurs before the complete decay of residual excitation from the first stimulus (e.g., Tannenbaum & Zillmann, 1975). Two: there is the misattribution of excitation, that is, after exposure to the second stimulus, the individual experiencing the excitation attributes full excitation to the second stimulus (e.g., Cantor, Bryant, & Zillmann, 1974; Cantor, Zillmann, & Bryant, 1975). Three: the individual has not reached an excitatory threshold before exposure to the second stimulus (e.g., Zillmann, 1983).\n\nDolf Zillmann began developing excitation-transfer theory in the late 1960s/ early 1970s, and through the start of the 21st century, Zillmann continued to refine it (Bryant & Miron, 2003). Excitation-transfer theory is based largely on Clark Hull's notion of residual excitation (i.e., drive theory) and Stanley Schachter's two factor theory of emotion. As Bryant and Miron (2003) stated: \n\nZillmann collapsed and connected Hull's drive theory and Schachter's two-factor theory, which posited an excitatory and a cognitive component of emotional states. In contrast to Hull's hypothesis that excitatory reactions \"lose\" their specificity under new stimulation, Schachter claimed that emotional arousal is nonspecific, and the individual cognitively assess the emotion he is experiencing for the purpose of behavioral guidance and adjustment. Zillmann adopted and modified Schacter's view on this.(p. 35)\nIn other words, excitation-transfer theory is based on the assumption that excitation responses are, for the most part, ambiguous and are differentiated only by what emotions the brain assigns to them. As Zillmann (2006) stated, \"Residual excitation from essentially any excited emotional reaction is capable of intensifying any other excited emotional reaction. The degree of intensification depends, of course, on the magnitude of residues prevailing at the time\" (p. 223). Hence, excitation transfer theory helps to explain the fickleness of emotional arousal (i.e., how it is possible for fear to be transferred into relief, anger into delight, etc.), and how the reaction to one stimulus can intensify the reaction to another. \nAlthough excitation-transfer theory was based heavily on psychology, psychophysiology, and biochemistry, it has been often applied to effects studies in the field of communication (Bryant & Miron, 2003, p. 31). As Bryant and Miron explained, \"Growing concern about the increasingly violent media content in the late 1960s and early 1970s spurred debate over the possible effects of such content on the real-life behavior of media consumers\" (p. 32). Eventually, excitation-transfer theory became one of the dominant theoretical underpinnings for predicting, testing, and explaining the effects of such media (e.g., violent movies/ television shows, pornography, music etc.). Zillmann (1971) stated that \"Communication-produced excitation may serve to intensify or 'energize' post-exposure emotional states\" (p. 431). However, excitation transfer is not limited to face-to-face communication stimuli, but can occur from an array of stimuli, including mediated messages. Tannenbaum and Zillmann (1975) argued: \n\nMost people probably do not consider arousal from media exposure to be pronounced enough to warrant any attention, and hence they do not expect it to affect their behavior. Dismissing such arousals as trivial, the individual will tend to attribute any accumulating residues not to the preceding communication events [which are, in this instance, mediated messages] but to the new stimulus situations in which he finds himself. Moreover, by virtue of their very \"unreal\" and symbolic (possibly-fantasy encouraging) content, communication messages are generally not related to the person's real and immediate problems and concerns. This should further encourage misattribution of accruing arousal and hence make the person all the more vulnerable to transfer effects in his postcommunication behavior. (p. 187)\nIn short, stimuli, whether they be in real-life, on a television or movie screen, or a combination of the two, can elicit excitation-transfers. Today, excitation-transfer theory remains a key component of the theoretical framework of studies focusing on communication and emotion.\n"}
{"id": "216186", "url": "https://en.wikipedia.org/wiki?curid=216186", "title": "Explanation", "text": "Explanation\n\nAn explanation is a set of statements usually constructed to describe a set of facts which clarifies the causes, context, and consequences of those facts. This description of the facts et cetera may establish rules or laws, and may clarify the existing rules or laws in relation to any objects, or phenomena examined. The components of an explanation can be implicit, and interwoven with one another.\n\nAn explanation is often underpinned by an understanding or norm that can be represented by different media such as music, text, and graphics. Thus, an explanation is subjected to interpretation, and discussion.\n\nIn scientific research, explanation is one of several purposes for empirical research. Explanation is a way to uncover new knowledge, and to report relationships among different aspects of studied phenomena. Explanation attempts to answer the \"why\" and \"how\" questions. Explanations have varied explanatory power. The formal hypothesis is the theoretical tool used to verify explanation in empirical research.\n\nWhile arguments attempt to show that something is, will be, or should be the case, explanations try to show \"why\" or \"how\" something is or will be. If Fred and Joe address the issue of \"whether\" or not Fred's cat has fleas, Joe may state: \"Fred, your cat has fleas. Observe the cat is scratching right now.\" Joe has made an \"argument that\" the cat has fleas. However, if Fred and Joe agree on the fact that the cat has fleas, they may further question \"why\" this is so and put forth an \"explanation\": \"The reason the cat has fleas is that the weather has been damp.\" The difference is that the attempt is not to settle whether or not some claim is true, but to show \"why\" it is true.\n\nIn this sense, arguments aim to contribute \"knowledge\", whereas explanations aim to contribute \"understanding\".\n\nArguments and explanations largely resemble each other in rhetorical use. This is the cause of much difficulty in thinking critically about claims. There are several reasons for this difficulty.\n\n\nJustification is the reason why someone properly holds a belief, the explanation as to why the belief is a true one, or an account of how one knows what one knows. In much the same way arguments and explanations may be confused with each other, so too may explanations and justifications. Statements which are justifications of some action take the form of arguments. For example, attempts to justify a theft usually explain the motives (e.g., to feed a starving family).\n\nIt is important to be aware when an explanation is \"not\" a justification. A criminal profiler may offer an explanation of a suspect's behavior (e.g.; the person lost their job, the person got evicted, etc.). Such statements may help us understand why the person committed the crime, however an uncritical listener may believe the speaker is trying to gain sympathy for the person and his or her actions. It does not follow that a person proposing an explanation has any sympathy for the views or actions being explained. This is an important distinction because we need to be able to understand and explain terrible events and behavior in attempting to discourage or prevent them.\n\nThere are many and varied events, objects, and facts which require explanation. So too, there are many different types of explanation. Aristotle recognized at least four types of explanation. Other types of explanation are Deductive-nomological, Functional, Historical, Psychological, Reductive, Teleological, Methodological explanations.\n\nThe notion of meta-explanation is important in behavioral scenarios that involve conflicting agents. In these scenarios, implicit or explicit conflict can be caused by contradictory agents' interests, as communicated in their explanations for why they behaved in a particular way, by a lack of knowledge of the situation, or by a mixture of explanations of multiple factors. In many cases to assess the plausibility of explanations, one must analyze two following components and their interrelations: (1) explanation at the actual object level (explanation itself) and (2) explanation at the higher level (meta-explanation). Comparative analysis of the roles of both is conducted to assess the plausibility of how agents explain the scenarios of their interactions. Object-level explanation assesses the plausibility of individual claims by using a traditional approach to handle argumentative structure of a dialog. Meta-explanation links the structure of a current scenario with that of previously learned scenarios of multi-agent interaction. The scenario structure includes agents' communicative actions and argumentation defeat relations between the subjects of these actions. The data for both object-level and meta-explanation can be visually specified, and a plausibility of how agent behavior in a scenario can be visually explained. Meta-explanation in the form of machine learning of scenario structure can be augmented by conventional explanation by finding arguments in the form of defeasibility analysis of individual claims, to increase the accuracy of plausibility assessment.\n\nA ratio between object-level and meta-explanation can be defined as the relative accuracy of plausibility assessment based on the former and latter sources. The groups of scenarios can then be clustered based on this ratio; hence, such a ratio is an important parameter of human behavior associated with explaining something to other humans.\n\n\n"}
{"id": "8026498", "url": "https://en.wikipedia.org/wiki?curid=8026498", "title": "Faux pas derived from Chinese pronunciation", "text": "Faux pas derived from Chinese pronunciation\n\nThe following faux pas are derived from homonyms in Mandarin and Cantonese. While originating in Greater China, they may also apply to Chinese-speaking people around the world. However, most homonymic pairs listed work only in some varieties of Chinese (for example, Mandarin only or Cantonese only), and may appear bewildering even to speakers of other varieties of Chinese.\n\nCertain customs regarding good and bad luck are important to many Chinese people. Although these might be regarded as superstitions by people from other cultures, these customs are often tied to religious traditions and are an important part of many people's belief systems, even among well-educated people and affluent sectors of society.\n\nGiving a clock (送鐘/送钟, sòng zhōng) is often taboo, especially to the elderly as the term for this act is a homophone with the term for the act of attending another's funeral (送終/送终, sòngzhōng). A UK government official Susan Kramer gave a watch to Taipei mayor Ko Wen-je unaware of such a taboo which resulted in some professional embarrassment and a pursuant apology.\nCantonese people consider such a gift as a curse.\n\nThis homonymic pair works in both Mandarin and Cantonese, although in most parts of China only clocks and large bells, and not watches, are called \"zhong\", and watches are commonly given as gifts in China.\n\nHowever, should such a gift be given, the \"unluckiness\" of the gift can be countered by exacting a small monetary payment so the recipient is buying the clock and thereby counteracting the (\"give\") expression of the phrase.\n\nIt is undesirable to give someone a fan or an umbrella as a gift. The words fan \"shàn\" () and umbrella \"sǎn\" () sound like the word \"sǎn/sàn\" (), meaning to scatter, or to part company, to separate, to break up with someone, to split.\n\nThese homonymic pairs work in Mandarin and Cantonese, though Cantonese has a more idiomatic term for umbrellas (\"ze1\" in Cantonese, ) to avoid precisely this association.\n\nAs a book () is a Mandarin homophone of \"loss, to lose\" (), carrying or looking at a book () where people are taking a risk, such as gambling or investing in stocks, may be considered to invite bad luck and loss (). This bad luck does not apply to carrying or reading newspapers () as newspapers () are not books.\n\nThis homonymic pair works in Mandarin.\n\nSharing a pear with friends or loved ones can be a mistake. \"Sharing a pear\" () is a homophone of \"to separate, to part, to leave\" (), both pronounced \"fēnlí\" in Mandarin. Sharing with distant friends is okay.\n\nThis homonymic pair works in Mandarin.\n\nIt is also thought to be bad luck to give shoes as a gift. \"Shoes\" ( xié) in Mandarin is a homophone of \"evil\" ( xié). Additionally, the Chinese people believe that gifting shoes equips a person to \"walk away\" from a relationship.\n\nThis homonymic pair works in Mandarin only and, other than part of northern China, there is no such superstition in any other part of China.\n\n"}
{"id": "23759925", "url": "https://en.wikipedia.org/wiki?curid=23759925", "title": "Field metabolic rate", "text": "Field metabolic rate\n\nField metabolic rate (FMR) refers to a measurement of the metabolic rate of a free-living animal in the wild.\n\nMeasurement of the Field metabolic rate is made using the doubly labeled water method, although alternative techniques, such as monitoring heart rates, can also be used. The advantages and disadvantages of the alternative approaches have been reviewed by Butler, \"et al.\" Several summary reviews have been published.\n"}
{"id": "1777495", "url": "https://en.wikipedia.org/wiki?curid=1777495", "title": "Global change", "text": "Global change\n\nGlobal change refers to planetary-scale changes in the Earth system. The system consists of the land, oceans, atmosphere, polar regions, life, the planet's natural cycles and deep Earth processes. These constituent parts influence one another. The Earth system now includes human society, so global change also refers to large-scale changes in society.\n\nMore completely, the term \"global change\" encompasses: population, climate, the economy, resource use, energy development, transport, communication, land use and land cover, urbanization, globalization, atmospheric circulation, ocean circulation, the carbon cycle, the nitrogen cycle, the water cycle and other cycles, sea ice loss, sea-level rise, food webs, biological diversity, pollution, health, over fishing, and more.\n\nIn 1980, a group of scientists led by Swedish meteorologist Bert Bolin set up an international program called the World Climate Research Programme (WCRP), to determine whether the climate was changing, whether climate could be predicted and whether humans were in some way responsible for the change. The programme was sponsored by the World Meteorological Organization and the International Council for Science (ICSU). As time went on, there was a growing realisation that climate change was one part of a larger phenomenon, global change. In 1987, a team of researchers, led again by Bert Bolin, James McCarthy, Paul Crutzen, H. Oeschger and others, successfully argued for an international research programme to investigate global change. This programme, sponsored by ICSU, is the International Geosphere-Biosphere Programme (IGBP). The programme has eight projects investigating different parts of the Earth system and links between them.\n\nIGBP, WCRP and a third programme, the International Human Dimensions Programme (IHDP, founded in 1996), spearheaded a landmark science conference held in Amsterdam in 2001. The conference, \"Challenges of a Changing Earth: Global Change Open Science Conference\", led to the Amsterdam Declaration which stated, \"In addition to the threat of significant climate change, there is growing concern over the ever-increasing human modification of other aspects of the global environment and the consequent implications for human well-being. Basic goods and services supplied by the planetary life support system, such as food, water, clean air and an environment conducive to human health, are being affected increasingly by global change.\"\n\nThe declaration goes on to say, \"The international global change programmes urge governments, public and private institutions and people of the world to agree that an ethical framework for global stewardship and strategies for Earth System management are urgently needed.\"\n\nMany nations now have their own global change programmes and institutes, for example the US Global Change Research Program and the UK's Quantifying and Understanding the Earth System (QUEST) programme. And since the Amsterdam conference another international programme focusing on biodiversity has been set up, DIVERSITAS. These programmes form the Earth System Science Partnership.\n\nIn 2012, these international programmes held another major science conference in London, Planet Under Pressure: new knowledge towards solutions.\n\nIn the past, the main drivers of global change have been solar variation, plate tectonics, volcanism, proliferation and abatement of life, meteorite impact, resource depletion, changes in Earth's orbit around the sun and changes in the tilt of Earth on its axis. There is overwhelming evidence that now the main driver of planetary-scale change, or global change, is the growing human population's demand for energy, food, goods, services and information, and its disposal of its waste products. In the last 250 years, global change has caused climate change, widespread species extinctions, fish-stock collapse, desertification, ocean acidification, ozone depletion, pollution, and other large-scale shifts.\n\nScientists working on the International Geosphere-Biosphere Programme have said that Earth is now operating in a \"no analogue\" state. Measurements of Earth system processes, past and present, have led to the conclusion that the planet has moved well outside the range of natural variability in the last half million years at least. \"Homo sapiens\" have been around for about 200,000 years.\n\nWhat this means for the planet and society remains unclear. But, in the last 20 years there has been an enormous international research effort to understand global change and the Earth system. An aim of this research is to work out if there are planetary boundaries and are we approaching them. Scientists, international governmental organizations and lobbying organizations like World Wide Fund for Nature argue that current consumption levels, particularly in developed countries, are not sustainable because there is a very real danger they will push the planet into a new state. What this new state might look like is still being debated, but sea levels are likely to rise several meters, the pH of the oceans, a measure of its acidity, is likely to drop farther than it has in 20 million years, and global atmospheric and ocean circulations may shift markedly. The major cycles – carbon, nitrogen, sulfur, phosphorus, water – and other important parameters would alter, bringing drought to some places, floods to others. Governments will no longer be able to take for granted the relative environmental stability that has allowed human society to flourish and led to rapid globalization. Most of the population of the planet will be affected. The re-insurance industry is already taking measures to protect its interests and maximize profits as turbulent times approach.\n\nHumans have always altered their environment. The advent of agriculture around 10000 years ago led to a radical change in land use that still continues. But, the relatively small human population had little impact on a global scale until the start of the industrial revolution in 1750. This event, followed by the invention of the Haber-Bosch process in 1909, which allowed large-scale manufacture of fertilizers, led directly to rapid changes to many of the planet's most important physical, chemical and biological processes.\n\nThe 1950s marked a shift in gear: global change began accelerating. Between 1950 and 2010, the population more than doubled. In that time, rapid expansion of international trade coupled with upsurges in capital flows and new technologies, particularly information and communication technologies, led to national economies becoming more fully integrated. There was a tenfold increase in economic activity and the world's human population became more tightly connected than ever before. The period saw sixfold increases in water use and river damming. About 70 percent of the world's freshwater resource is now used for agriculture. This rises to 90 percent in India and China. Half of the Earth's land surface had now been domesticated. By 2010, urban population, for the first time, exceeded rural population. And there has been a fivefold increase in fertilizer use. Indeed, manufactured reactive nitrogen from fertilizer production and industry now exceeds global terrestrial production of reactive nitrogen. Without artificial fertilizers there would not be enough food to sustain a population of seven billion people.\n\nThese changes to the human sub-system have a direct influence on all components of the Earth system. The chemical composition of the atmosphere has changed significantly. Concentrations of important greenhouse gases, carbon dioxide, methane and nitrous oxide are rising fast. Over Antarctica a large hole in the ozone layer appeared. Fisheries collapsed: most of the world's fisheries are now fully or over-exploited. Thirty percent of tropical rainforests disappeared.\n\nIn 2000, Nobel prize-winning scientist Paul Crutzen announced the scale of change is so great that in just 250 years, human society has pushed the planet into a new geological era: the Anthropocene. This name has stuck and there are calls for the Anthropocene to be adopted officially. If it is, it may be the shortest of all geological eras. Evidence suggests that if human activities continue to change components of the Earth system, which are all interlinked, this could heave the Earth system out of a one state and into a new state.\n\nGlobal change in a societal context encompasses social, cultural, technological, political, economic and legal change. Terms closely related to global change and society are globalization and global integration. Globalization began with long-distance trade and urbanism. The first record of long distance trading routes is in the third millennium BC. Sumerians in Mesopotamia traded with settlers in the Indus Valley, in modern-day India.\n\nSince 1750, but more significantly, since the 1950s, global integration has accelerated. This era has witnessed incredible global changes in communications, transportation, and computer technology. Ideas, cultures, people, goods, services and money move around the planet with ease. This new global interconnectedness and free flow of information has radically altered notions of other cultures, conflicts, religions and taboos. Now, social movements can and do form at a planetary scale.\n\nEvidence, if more were needed, of the link between social and environmental global change came with the 2008-2009 global financial crisis. The crisis pushed the planet's main economic powerhouses, the United States, Europe and much of Asia into recession. According to the Global Carbon Project, global atmospheric emissions of carbon dioxide fell from an annual growth rate of around 3.4% between 2000 and 2008, to a growth rate of about 2% in 2008.\n\nHumans are altering the planet's biogeochemical cycles in a largely unregulated way with limited knowledge of the consequences. Without steps to effectively manage the Earth system – the planet's physical, chemical, biological and social components – it is likely there will be severe impacts on people and ecosystems. Perhaps the largest concern is that a component of the Earth system, for example, an ocean circulation, the Amazon rainforest, or Arctic sea ice, will reach a tipping point and flip from its current state to another state: flowing to not flowing, rainforest to savanna, or ice to no ice. A domino effect could ensue with other components of the Earth system changing state rapidly.\n\nIntensive research over the last 20 years has shown that tipping points do exist in the Earth system, and wide-scale change can be rapid – a matter of decades. Potential tipping points have been identified and attempts have been made to quantify thresholds. But to date, the best efforts can only identify loosely defined \"planetary boundaries\" beyond which tipping points exist but their precise locations remain elusive.\n\nThere have been calls for a better way to manage the environment on a planetary scale, sometimes referred to as managing \"Earth's life support system\". The United Nations was formed to stop wars and provide a platform for dialogue between countries. It was not created to avoid major environmental catastrophe on regional or global scales. But several international environmental conventions exist under the UN, including the Framework Convention on Climate Change, Montreal Protocol, Convention to Combat Desertification, and Convention on Biological Diversity. Additionally, the UN has two bodies charged with coordinating environmental and development activities, the United Nations Environment Programme (UNEP) and the United Nations Development Programme (UNDP).\n\nIn 2004, the IGBP published \"Global Change and the Earth System, a planet under pressure.\" The publication's executive summary concluded: \"An overall, comprehensive, internally consistent strategy for stewardship of the Earth system is required\". It stated that a research goal is to define and maintain a stable equilibrium in the global environment.\n\nIn 2007, France called for UNEP to be replaced by a new and more powerful organization called the \"United Nations Environment Organization\". The rationale was that UNEP's status as a \"programme\", rather than an \"organization\" in the tradition of the World Health Organization or the World Meteorological Organization, weakened it to the extent that it was no longer fit for purpose given current knowledge of the state of the planet.\n"}
{"id": "12656", "url": "https://en.wikipedia.org/wiki?curid=12656", "title": "Godwin's law", "text": "Godwin's law\n\nGodwin's law (or Godwin's rule of Hitler analogies) is an Internet adage asserting that \"As an online discussion grows longer, the probability of a comparison involving Nazis or Hitler approaches 1\"; that is, if an online discussion (regardless of topic or scope) goes on long enough, sooner or later someone will compare someone or something to Adolf Hitler or his deeds, the point at which effectively the discussion or thread often ends. Promulgated by the American attorney and author Mike Godwin in 1990, Godwin's law originally referred specifically to Usenet newsgroup discussions. It is now applied to any threaded online discussion, such as Internet forums, chat rooms, and comment threads, as well as to speeches, articles, and other rhetoric where \"reductio ad Hitlerum\" occurs.\n\nThere are many corollaries to Godwin's law, some considered more canonical (by being adopted by Godwin himself) than others. For example, there is a tradition in many newsgroups and other Internet discussion forums that, when a Hitler comparison is made, the thread is finished and whoever made the comparison loses whatever debate is in progress. This principle is itself frequently referred to as Godwin's law.\n\nGodwin's law itself can be abused as a distraction, diversion or even as censorship, fallaciously miscasting an opponent's argument as hyperbole when the comparisons made by the argument are actually appropriate. Similar criticisms of the \"law\" (or \"at least the distorted version which purports to prohibit all comparisons to German crimes\") have been made by the American lawyer, journalist, and author Glenn Greenwald.\n\nGodwin's law does not claim to articulate a fallacy; it is instead framed as a memetic tool to reduce the incidence of inappropriate hyperbolic comparisons. \"Although deliberately framed as if it were a law of nature or of mathematics,\" Godwin wrote, \"its purpose has always been rhetorical and pedagogical: I wanted folks who glibly compared someone else to Hitler to think a bit harder about the Holocaust.\"\n\nGodwin has stated that he introduced Godwin's law in 1990 as an experiment in memetics.\n\nIn 2012, \"Godwin's law\" became an entry in the third edition of the \"Oxford English Dictionary\".\n\nIn December 2015, Godwin commented on the Nazi and fascist comparisons being made by several articles about Republican presidential candidate Donald Trump, saying: \"If you're thoughtful about it and show some real awareness of history, go ahead and refer to Hitler when you talk about Trump, or any other politician.\" In August 2017, Godwin made similar remarks on social networking websites Facebook and Twitter with respect to the two previous days' Unite the Right rally in Charlottesville, Virginia, endorsing and encouraging efforts to compare its alt-right organizers to Nazis.\n\nIn October 2018, Godwin made a similar statement when someone asked him, via Twitter, if it would be OK to call Brazilian presidential candidate Jair Bolsonaro a \"nazi\", answering a direct question (\"So, just to be clear, is it OK to call Bolsonaro a nazi?\") with the portuguese word \"Sim!\" (meaning \"yes\" in English). \n\n\n"}
{"id": "19249767", "url": "https://en.wikipedia.org/wiki?curid=19249767", "title": "Hip hip hooray", "text": "Hip hip hooray\n\nHip hip hooray (also hippity hip hooray; \"Hooray\" may also be spelled and pronounced hoorah, hurrah, hurray etc.) is a cheer called out to express congratulation toward someone or something, in the English speaking world and elsewhere.\n\nBy a sole speaker, it is a form of interjection. In a group, it takes the form of call and response: the cheer is initiated by one person exclaiming \"Three cheers for...[someone or something]\" (or, more archaically, \"Three times three\"), then calling out \"hip hip\" (archaically, \"hip hip hip\") three times, each time being responded by \"hooray\" or \"hurrah\".\n\nThe call was recorded in England in the beginning of the 19th century in connection with making a toast. Eighteenth century dictionaries list \"Hip\" as an attention-getting interjection, and in an example from 1790 it is repeated.\"Hip-hip\" was added as a preparatory call before making a toast or cheer in the early 19th century, probably after 1806. By 1813, it had reached its modern form, hip-hip-hurrah.\n\nIt has been suggested that the word \"hip\" stems from a medieval Latin acronym, \"\"H\"ierosolyma \"E\"st \"P\"erdita\", meaning \"Jerusalem is lost\", a term that gained notoriety in the German Hep hep riots of August to October 1819. Cornell's Michael Fontaine disputes this etymology, tracing it to a single letter in an English newspaper published August 28, 1819, some weeks after the riots. He concludes that the \"acrostic interpretation ... has no basis in fact.\". Ritchie Robertson also disputes the \"false etymology\" of the acronym interpretation, citing Katz.\n\nOne theory about the origin of \"hurrah\" is that the Europeans picked up the Mongol exclamation \"hooray\" as an enthusiastic cry of bravado and mutual encouragement. See Jack Weatherford's book \"Genghis Khan and the Making of the Modern World\".\n\n"}
{"id": "43131303", "url": "https://en.wikipedia.org/wiki?curid=43131303", "title": "Historical dynamics", "text": "Historical dynamics\n\nHistorical dynamics broadly includes the scientific modeling of history. This might also be termed computer modeling of history, historical simulation, or simulation of history - allowing for an extensive range of techniques in simulation and estimation. Historical dynamics does not exist as a separate science, but there are individual efforts such as long range planning, population modeling, economic forecasting, demographics, global modeling, country modeling, regional planning, urban planning and many others in the general categories of computer modeling, planning, forecasting, and simulations.\n\nSome examples of \"large\" history where historical dynamics simulations would be helpful include; global history, large structures, , long duration history, philosophy of history, Eurasian history, comparative history, long-range environmental history, world systems theory, non-Western political and economic development, and historical demography.\nWith the rise of technologies like wikis, and internet-wide search engines, some historical and social data can be mined to constrain models of history and society. Data from social media sites, and busy sites, can be mined for human patterns of action. These can provide more and more realistic behavioral models for individuals and groups of any size. Agent-based models and microsimulations of human behavior can be embedded in larger historical simulations. Related subfields are behavioral economics and human behavioral ecology.\n\nIn every sector of human activity, there are extensive databases for transportation data, urban development, health statistics, education data, social data, economic data—along with many projections. See , , , and .\n\nSome examples of database activity include Asian Development Bank statistics, World Bank data, and the International Monetary Fund data.\n\nTime series analysis and econometrics are well established fields for the analysis of trends and forecasting; but, survey data and microdatasets can also be used in forecasts and simulations.\n\nThe United Nations and other organizations routinely project the population of individual countries and regions of the world decades into the future. These demographic models are used by other organizations for projecting demand for services in all sectors of each economy.\n\n\nEach country often has their corresponding modeling groups for each of these major sectors. These can be grouped in separate articles according to sector. Groups include government departments, international aid agencies, as well as nonprofit and non-governmental organizations.\n\nA broad class of models used for economic and social modeling of countries and sectors are the Computable general equilibrium (CGE) model - also called applied general equilibrium models. In the context of time based simulations and policy analysis, see dynamic stochastic general equilibrium models.\n\nPartly because of the controversy over global climate change, there is an extensive network of global climate models, and related social and economic models. These seek to estimate, not only the change in climate and its physical effects, but also the impact on human society and the natural environment. See global economic models, social model, microsimulation, climate model, global climate models, and general circulation model.\n\nThe relationship between the environment and society is examined through environmental social science. human ecology, political ecology, and ecology, in general, can be areas where computer and mathematical modeling over time can be relevant to historical simulation.\n\nWeb-based historical simulations, simulations of history, interactive historical simulations, are increasingly popular for entertainment and educational purposes. The field is expanding rapidly and no central index seems to be available. Another example is \n\nSeveral computer games allow players to interact with the game to model societies over time. The Civilization (series) is one example. Others include Age of Empires, Rise of Nations, Spore, Colonization, Alpha Centauri, Call to Power, and . A longer list of games in historical context, which might include degrees of simulation, are found at .\n\nMilitary simulation is a well-developed field and increasingly accessible on the internet.\n\nComputer models for simulating society fall under artificial society, social simulation, computational sociology, computational social science, and mathematical sociology. There is an interdisciplinary Journal of Artificial Societies and Social Simulation for computer simulation of social processes. The European Social Simulation Association promotes social simulation research in Europe; it is the publisher of JASSS. There is a corresponding Computational Social Science Society of the Americas., and a Pan-Asian Association for Agent-based Approach in Social Systems Sciences. PAAA lists some related Japanese associations.\n\nThe SimSoc (Simulated Society tool) is in its fifth edition.\n\nThere has been extensive research in urban planning, environmental planning and related fields: regional planning, land-use planning, transportation planning, urban studies, and regional science. Journals for these fields are listed at List of planning journals.\n\nSimCity is a game for simulations of artificial cities. It has spawned a range of \"sim\" games. The planning groups try to simulate changes in real cities. The game groups allow experiments with artificial cities. And the two are merging in such efforts as Vizicities\n\nThe profiling of industries is well developed, and most industries make forecasts and plans. See industrial history, history of steel, history of mining, history of construction, history of the petroleum industry, and many other histories of specific industries. See cyclical industrial dynamics for modeling of industries in the sense of \"historical dynamics of industries\". Some related terms are industrial planning, history of industry, industrial evolution, technology change, and technology forecasting. An example of \"history friendly\" industrial models. from the journal, Industrial and Corporate Change.\n\nEconomy-wide models must take into account the interactions between industry and the rest of the economy. See Input–output model, economic planning, and social accounting matrix for some relevant techniques.\n\nMany of the techniques from futures studies are applicable to historical dynamics. Whether projecting forward from a point in the past to the present for validation studies, or projecting backwards from the present into the past - many of the techniques are useful. Likewise, simulations of the past, or alternative pasts, provide a groundwork of techniques for futures studies.\n\n"}
{"id": "246532", "url": "https://en.wikipedia.org/wiki?curid=246532", "title": "Homesteading", "text": "Homesteading\n\nHomesteading is a lifestyle of self-sufficiency. It is characterized by subsistence agriculture, home preservation of food, and may also involve the small scale production of textiles, clothing, and craftwork for household use or sale. Pursued in different ways around the world—and in different historical eras—homesteading is generally differentiated from rural village or commune living by isolation (either socially or physically) of the homestead. Use of the term in the United States dates back to the Homestead Act (1862) and before. In sub-Saharan Africa, particularly in nations formerly controlled by the British Empire, a homestead is the household compound for a single extended family. In the UK, the term 'smallholder' or 'crofts' is the rough equivalent of 'homesteader'.\n\nModern homesteaders often use renewable energy options including solar electricity and wind power. Many also choose to plant and grow heirloom vegetables and to raise heritage livestock. Homesteading is not defined by where someone lives, such as the city or the country, but by the lifestyle choices they make.\n\nHistorically, homesteading has been used by governmental entities (engaged in national expansion) to help populate and make habitable what were previously little-desired areas; especially in the United States, Canada, and Australia. Guided by legal \"homestead principles\", many of these \"homestead acts\" were instituted in the 19th and 20th centuries in order to drive the populating of specific, national areas; with most being discontinued after a set time-frame or goal were achieved.\n\nRenewed interest in homesteading was brought about by U.S. President Franklin D. Roosevelt's program of Subsistence Homesteading in the 1930s and 1940s.\n\nThe attractiveness of back-to-the-land movements dates from the Roman era, and has been noted in Asian poetry and philosophy tracts as well. The ideas of modern homesteading proponents, such as Ralph Borsodi, gained in popularity in the 1960s in the United States. Self-sufficiency movements in the 1990s and 2000s began to apply the concept to urban and suburban settings, known as urban homesteading. According to author John Seymour, \"urban homesteading\" incorporates small-scale, sustainable agriculture and homemaking.\n\nIn homesteading, social and government support systems are frequently eschewed in favor of self-reliance and relative deprivation, in order to maximize independence and self-determination. The degree of independence occurs along a spectrum, with many homesteaders creating foodstuffs or crafts to appeal to high-end niche markets in order to meet financial needs. Other homesteaders come to the lifestyle following successful careers which provide the funding for land, housing, taxes, and specialized equipment such as solar panels, farm equipment and electricity generators.\n\nModern government regulation—in the form of building codes, food safety codes, zoning regulations, minimum wage and social security for occasional labor, and town council restrictions on landscaping and animal keeping— can increase the marginal cost of home production of food in areas affected by these restrictions. Careful choice of homesteading location is essential for economic success.\n\nActual financial savings from adopting a homesteading lifestyle can be significant if planned and executed properly. Many homesteaders express deep satisfaction with their standard of living and feel that their lifestyle is healthier and more rewarding than more conventional patterns of living.\n\n\n\n"}
{"id": "53779016", "url": "https://en.wikipedia.org/wiki?curid=53779016", "title": "Human shields (law)", "text": "Human shields (law)\n\nHuman shields may be civilians used against their will to deter attacks on military targets during an international armed conflict or they may be civilians who voluntarily protect either military or civilian targets from attack. The use of human shields is forbidden by \"Protocol I\" of the Geneva Conventions. It is also a specific intent war crime as codified in the \"Rome Statute\", which was adopted in 1998. The language of the \"Rome Statute\" prohibits \"utilizing the presence of a civilian or other protected person to render certain points, areas, or military forces immune from military operations.\"\n\nHistorically the law of armed conflict only applied to sovereign states. Non-international conflicts were governed by the domestic law of the State concerned. Under the current terms of the \"Rome Statute\" the use of human shields is defined as a war crime only in the context of an international armed conflict.\n\nAfter the end of World War II, non-international armed conflicts have become more commonplace. The \"Customary International Humanitarian Law\" guide suggests that rules prohibiting use of civilians as human shields are \"arguably\" customary in non-international armed conflict. The development and application of humanitarian law to modern asymmetric warfare is currently being debated by legal scholars.\n\nThe laws of war first began to develop the distinction between military and civilian targets at The Second Hague Peace Conference of 1907.\n\nDuring World War I, the concept of total war permitted most actions that supported the war effort. In \"total war\" targeting civilians was allowed, if it would support a military objective to demoralize the enemy. Indiscriminate bombing was considered an acceptable method to achieve the military advantage of defeating enemy morale and eroding popular support for the war effort. Early attempts to protect civilians as a class were largely unsuccessful. World War II was also fought within the framework of the total war concept.\n\nThe Geneva Conventions of 1949 were the first significant protections for civilians in war. These protections were expanded by the Additional Protocols in 1977. Protocol I requires that attacks be limited to military objectives, which are defined as targets that make an \"effective contribution to military action\" where the destruction of the target provides a \"definite military advantage\" to the attacker.\n\nMilitary necessity can justify the use of force in certain circumstances, where there is a military advantage to be gained by an attack. When the use of force is excessive relative to its anticipated military advantage it is said to be disproportionate. Disproportionate force is prohibited under international law.\n\nRisk to civilians does not bar military action, but the principle of proportionality requires that precautions be taken to minimize the harm to these protected persons. This analysis includes considerations like whether circumstances permit the attacker to time a military action to minimize the presence of civilians at the location.\n\nUnder the Rome Statute using protected persons as shields in an international armed conflict is a war crime. There is currently debate amongst legal scholars about whether traditional proportionality analysis should be modified to take into account the culpability of actors who use human shields to gain a strategic advantage. In modern asymmetric warfare it has become difficult to distinguish between military targets and civilians, but State actors still rely on traditional principles that present challenges when applied to asymmetric conflicts. Non-state forces, like guerillas and terrorists, conceal themselves among civilian populations and may take advantage of this position to launch attacks. When military action targeting these unconventional combatants results in civilian deaths, State actors may blame the deaths on enemy forces who use human shields.\n\nSome scholars, including Ammon Rubinstein and Yaniv Roznai, argue that the use of human shields should be a factor in determining whether the use of force was justifiable under the guiding principles of distinction and proportionality. In their view, the use of human shields undermines an attackers right to self defense because the military necessity of self-defense must be a consideration in the excessive force analysis. Rubinstein and Roznai have described this analysis as a \"proportionate proportionality.\"\n\nRubinstein and Roznai argue that an attack that would be disproportionate ought to be considered proportionate, if the presence of civilians is due to the wrongful actions of the enemy. They use the term \"impeded party\" to describe the burden placed on the attacking party under International Humanitarian Law norms. They point out that \"attacking party\" has traditionally been synonymous with the aggressor, but that it is often the attacker who is \"defending democracy\" and acting in self-defense when they use force in response to a prior attack.\n\nDouglas Fischer believes that the increase of civilian casualties that began with the Vietnam War is partially due to an increased use of \"illegal and perfidious\" tactics in modern warfare, including the use of civilians as human shields. He has criticized Human Rights Watch for not including human shields doctrine as a factor in excessive force analysis.\n\nCombatants in an armed conflict are prohibited from using protected civilians as involuntary human shields to support an unjust war effort. Civilians who are used as involuntary human shields by unlawful combatants do not lose their basic rights. The use of involuntary human shields does not release the other party from legal obligations to not target civilians or inflict excessive collateral damage.\n\nVoluntary human shields may be considered \"direct participants in hostilities,\" if they shield targeted personnel or properties. This could also be considered treason. However, if they are shielding protected personnel or properties, they may still retain their protected status. This debated area of customary international law has not yet been codified.\n\nThe United States and the European Union are considered the main sources for voluntary human shields. In 2003, human rights activists travelled to Baghdad to serve as human shields and protest the unpopular U.S. invasion.\nAlso in 2003, American peace activist Rachel Corrie was killed after she was crushed to death by an Israeli army bulldozer in Rafah while volunteering with the International Solidarity Movement as a human shield to prevent the demolition of homes in Palestine.\n\nWhile IHL does prohibit attacks on civilians, the precautions a power must take before an attack remain ill-defined. Proportionality remains a nebulous standard that does not set a predictable standard of when a military action would be considered lawful. There is a lack of enforcement, and the increasing role of private actors and contractors on the battlefield presents new challenges.\n\nDuring the Civil War, the United States adopted the Lieber Code, recognized by many scholars as the first detailed code governing conduct in war. Dr. Francis Lieber articulated an early version of the principle of proportionality: that civilians were not to be targeted, but were also not immune in all circumstances.\n\nThe use of human shields is prohibited and defined as a war crime by several U.S. military manuals. It is also defined as a crime triable by military commission under the US Military Commissions Act (2006).\n\nIf the belligerent attacks in areas where human shields are used, this can weaken international and domestic support by exploiting harmed civilians. For nations that are particularly sensitive to collateral damage, an enemy's use of shields may effectively deter or delay military actions.\n\nThere have been numerous documented incidents where this tactic has not been successful in deterring attacks, including the Amiriyah shelter bombing during the First Gulf War. After the death of two Western activists serving as voluntary human shields in Gaza, Véronique Dudouet wrote that human shields have become less effective, since bad media publicity no longer deters soldiers from using lethal force against them.\n"}
{"id": "161999", "url": "https://en.wikipedia.org/wiki?curid=161999", "title": "Idea", "text": "Idea\n\nIn philosophy, ideas are usually taken as mental representational images of some object. Ideas can also be abstract concepts that do not present as mental images. Many philosophers have considered ideas to be a fundamental ontological category of being. The capacity to create and understand the meaning of ideas is considered to be an essential and defining feature of human beings. In a popular sense, an idea arises in a reflexive, spontaneous manner, even without thinking or serious reflection, for example, when we talk about the \"idea\" of a person or a place. A new or original idea can often lead to innovation.\n\nThe word \"idea\" comes from Greek ἰδέα \"idea\" \"form, pattern,\" from the root of ἰδεῖν \"idein\", \"to see.\" \n\nOne view on the nature of ideas is that there exist some ideas (called \"innate ideas\") which are so general and abstract that they could not have arisen as a representation of an object of our perception but rather were in some sense always present. These are distinguished from \"adventitious ideas\" which are images or concepts which are accompanied by the judgment that they are caused or occasioned by an external object.\n\nAnother view holds that we only discover ideas in the same way that we discover the real world, from personal experiences. The view that humans acquire all or almost all their behavioral traits from nurture (life experiences) is known as \"tabula rasa\" (\"blank slate\"). Most of the confusions in the way ideas arise is at least in part due to the use of the term \"idea\" to cover both the representation perceptics and the object of conceptual thought. This can be always illustrated in terms of the scientific doctrines of innate ideas, \"concrete ideas versus abstract ideas\", as well as \"simple ideas versus complex ideas\".\n\nPlato in Ancient Greece was one of the earliest philosophers to provide a detailed discussion of ideas and of the thinking process (it must be noted that in Plato's Greek the word \"idea\" carries a rather different sense from our modern English term). Plato argued in dialogues such as the \"Phaedo\", \"Symposium\", \"Republic\", and \"Timaeus\" that there is a realm of ideas or forms (\"eidei\"), which exist independently of anyone who may have thoughts on these ideas, and it is the ideas which distinguish mere opinion from knowledge, for unlike material things which are transient and liable to contrary properties, ideas are unchanging and nothing but just what they are. Consequently, Plato seems to assert forcefully that material things can only be the objects of opinion; real knowledge can only be had of unchanging ideas. Furthermore, ideas for Plato appear to serve as universals; consider the following passage from the \"Republic\":\nDescartes often wrote of the meaning of \"idea\" as an image or representation, often but not necessarily \"in the mind\", which was well known in the vernacular. Despite that Descartes is usually credited with the invention of the non-Platonic use of the term, he at first followed this vernacular use. In his \"Meditations on First Philosophy\" he says, \"Some of my thoughts are like images of things, and it is to these alone that the name 'idea' properly belongs.\" He sometimes maintained that ideas were innate and uses of the term \"idea\" diverge from the original primary scholastic use. He provides multiple non-equivalent definitions of the term, uses it to refer to as many as six distinct kinds of entities, and divides \"ideas\" inconsistently into various genetic categories. For him knowledge took the form of ideas and philosophical investigation is the deep consideration of these entities.\n\nIn striking contrast to Plato's use of idea is that of John Locke. In his Introduction to An Essay Concerning Human Understanding, Locke defines \"idea\" as \"that term which, I think, serves best to stand for whatsoever is the object of the understanding when a man thinks, I have used it to express whatever is meant by phantasm, notion, species, or whatever it is which the mind can be employed about in thinking; and I could not avoid frequently using it.\" He said he regarded the book necessary to examine our own abilities and see what objects our understandings were, or were not, fitted to deal with. In his philosophy other outstanding figures followed in his footsteps — Hume and Kant in the 18th century, Arthur Schopenhauer in the 19th century, and Bertrand Russell, Ludwig Wittgenstein, and Karl Popper in the 20th century. Locke always believed in \"good sense\" — not pushing things to extremes and on taking fully into account the plain facts of the matter. He considered his common-sense ideas \"good-tempered, moderate, and down-to-earth.\"\n\nAs John Locke studied humans in his work “An Essay Concerning Human Understanding” he continually referenced Descartes for ideas as he asked this fundamental question: “When we are concerned with something about which we have no certain knowledge, what rules or standards should guide how confident we allow ourselves to be that our opinions are right?” A simpler way of putting it is how do humans know ideas, and what are the different types of ideas. An idea to Locke “can simply mean some sort of brute experience.” He shows that there are “No innate principles in the mind.”. Thus, he concludes that “our ideas are all experiential in nature.” An experience can either be a sensation or a reflection: “consider whether there are any innate ideas in the mind before any are brought in by the impression from sensation or reflection.” Therefore, an idea was an experience in which the human mind apprehended something.\n\nIn a Lockean view, there are really two types of ideas: complex and simple. Simple ideas are the building blocks for much more complex ideas, and “While the mind is wholly passive in the reception of simple ideas, it is very active in the building of complex ideas…” Complex ideas, therefore, can either be modes, substances, or relations. Modes are when ideas are combined in order to convey new information. For instance, David Banach gives the example of beauty as a mode. He says that it is the combination of color and form. Substances, however, is different. Substances are certain objects, that can either be dogs, cats, or tables. And relations represent the relationship between two or more ideas. In this way, Locke did, in fact, answer his own questions about ideas and humans.\n\nHume differs from Locke by limiting \"idea\" to the more or less vague mental reconstructions of perceptions, the perceptual process being described as an \"impression.\" Hume shared with Locke the basic empiricist premise that it is only from life experiences (whether their own or others') that humans' knowledge of the existence of anything outside of themselves can be ultimately derived, that they shall carry on doing what they are prompted to do by their emotional drives of varying kinds. In choosing the means to those ends, they shall follow their accustomed associations of ideas. Hume has contended and defended the notion that \"reason alone is merely the 'slave of the passions'.\" \n\nImmanuel Kant defines an \"idea\" as opposed to a \"concept\". \"Regulative ideas\" are ideals that one must tend towards, but by definition may not be completely realized. Liberty, according to Kant, is an idea. The autonomy of the rational and universal subject is opposed to the determinism of the empirical subject. Kant felt that it is precisely in knowing its limits that philosophy exists. The business of philosophy he thought was not to give rules, but to analyze the private judgements of good common sense.\n\nWhereas Kant declares limits to knowledge (\"we can never know the thing in itself\"), in his epistemological work, Rudolf Steiner sees \"ideas\" as \"objects of experience\" which the mind apprehends, much as the eye apprehends light. In \"Goethean Science\" (1883), he declares, \"Thinking ... is no more and no less an organ of perception than the eye or ear. Just as the eye perceives colors and the ear sounds, so thinking perceives ideas.\" He holds this to be the premise upon which Goethe made his natural-scientific observations.\n\nWundt widens the term from Kant's usage to include \"conscious representation of some object or process of the external world\". In so doing, he includes not only ideas of memory and imagination, but also perceptual processes, whereas other psychologists confine the term to the first two groups. One of Wundt's main concerns was to investigate conscious processes in their own context by experiment and introspection. He regarded both of these as \"exact methods\", interrelated in that experimentation created optimal conditions for introspection. Where the experimental method failed, he turned to other \"objectively valuable aids\", specifically to \"those products of cultural communal life which lead one to infer particular mental motives. Outstanding among these are speech, myth, and social custom.\" Wundt designed the basic mental activity apperception — a unifying function which should be understood as an activity of the will. Many aspects of his empirical physiological psychology are used today. One is his principles of mutually enhanced contrasts and of assimilation and dissimilation (i.e. in color and form perception and his advocacy of \"objective\" methods of expression and of recording results, especially in language. Another is the principle of heterogony of ends — that multiply motivated acts lead to unintended side effects which in turn become motives for new actions.\n\nC. S. Peirce published the first full statement of pragmatism in his important works \"\" (1878) and \"\" (1877). In \"How to Make Our Ideas Clear\" he proposed that a \"clear idea\" (in his study he uses concept and \"idea\" as synonymic) is defined as one, when it is apprehended such as it will be recognized wherever it is met, and no other will be mistaken for it. If it fails of this clearness, it is said to be obscure. He argued that to understand an idea clearly we should ask ourselves what difference its application would make to our evaluation of a proposed solution to the problem at hand. Pragmatism (a term he appropriated for use in this context), he defended, was a method for ascertaining the meaning of terms (as a theory of meaning). The originality of his ideas is in their rejection of what was accepted as a view and understanding of knowledge by scientists for some 250 years, i.e. that, he pointed, knowledge was an impersonal fact. Peirce contended that we acquire knowledge as \"participants\", not as \"spectators\". He felt \"the real\", sooner or later, is information acquired through ideas and knowledge with the application of logical reasoning would finally result in. He also published many papers on logic in relation to \"ideas\".\n\nG. F. Stout and J. M. Baldwin, in the \"Dictionary of Philosophy and Psychology\", define \"idea\" as \"the reproduction with a more or less adequate image, of an object not actually present to the senses.\" They point out that an idea and a perception are by various authorities contrasted in various ways. \"Difference in degree of intensity\", \"comparative absence of bodily movement on the part of the subject\", \"comparative dependence on mental activity\", are suggested by psychologists as characteristic of an idea as compared with a perception.\n\nIt should be observed that an idea, in the narrower and generally accepted sense of a mental reproduction, is frequently composite. That is, as in the example given above of the idea of a chair, a great many objects, differing materially in detail, all call a single idea. When a man, for example, has obtained an idea of chairs in general by comparison with which he can say \"This is a chair, that is a stool\", he has what is known as an \"abstract idea\" distinct from the reproduction in his mind of any particular chair (see abstraction). Furthermore, a complex idea may not have any corresponding physical object, though its particular constituent elements may severally be the reproductions of actual perceptions. Thus the idea of a centaur is a complex mental picture composed of the ideas of man and horse, that of a mermaid of a woman and a fish.\n\nDiffusion studies explore the spread of ideas from culture to culture. Some anthropological theories hold that all cultures imitate ideas from one or a few original cultures, the Adam of the Bible, or several cultural circles that overlap. Evolutionary diffusion theory holds that cultures are influenced by one another but that similar ideas can be developed in isolation.\n\nIn the mid-20th century, social scientists began to study how and why ideas spread from one person or culture to another. Everett Rogers pioneered diffusion of innovations studies, using research to prove factors in adoption and profiles of adopters of ideas. In 1976, in his book \"The Selfish Gene\", Richard Dawkins suggested applying biological evolutionary theories to the spread of ideas. He coined the term \"meme\" to describe an abstract unit of selection, equivalent to the gene in evolutionary biology.\n\nJames Boswell recorded Samuel Johnson's opinion about ideas. Johnson claimed that they are mental images or internal visual pictures. As such, they have no relation to words or the concepts which are designated by verbal names.\n\nTo protect the cause of invention and innovation, the legal constructions of Copyrights and Patents were established. Patent law regulates various aspects related to the functional manifestation of inventions based on new ideas or incremental improvements to existing ones. Thus, patents have a direct relationship to ideas.\n\nIn some cases, authors can be granted limited legal monopolies on the manner in which certain works are expressed. This is known colloquially as copyright, although the term intellectual property is used mistakenly in place of \"copyright\". Copyright law regulating the aforementioned monopolies generally does not cover the actual ideas. The law does not bestow the legal status of property upon ideas per se. Instead, laws purport to regulate events related to the usage, copying, production, sale and other forms of exploitation of the fundamental expression of a work, that may or may not carry ideas. Copyright law is fundamentally different from patent law in this respect: patents do grant monopolies on ideas (more on this below).\n\nA copyright is meant to regulate some aspects of the usage of expressions of a work, \"not\" an idea. Thus, copyrights have a negative relationship to ideas.\n\nWork means a tangible medium of expression. It may be an original or derivative work of art, be it literary, dramatic, musical recitation, artistic, related to sound recording, etc. In (at least) countries adhering to the Berne Convention, copyright automatically starts covering the work upon the original creation and fixation thereof, without any extra steps. While creation usually involves an idea, the idea in itself does not suffice for the purposes of claiming copyright. \nConfidentiality and nondisclosure agreements are legal instruments that assist corporations and individuals in keeping ideas from escaping to the general public. Generally, these instruments are covered by contract law.\n\n\n"}
{"id": "36990744", "url": "https://en.wikipedia.org/wiki?curid=36990744", "title": "Ideomotor phenomenon", "text": "Ideomotor phenomenon\n\nIdeomotor phenomenon is a psychological phenomenon wherein a subject makes motions unconsciously.\n\nThe ideomotor response (or ideomotor reflex), often abbreviated to IMR, is a concept in hypnosis and psychological research. It is derived from the terms \"ideo\" (idea, or mental representation) and \"motor\" (muscular action). The phrase is most commonly used in reference to the process whereby a thought or mental image brings about a seemingly \"reflexive\" or automatic muscular reaction, often of minuscule degree, and potentially outside of the awareness of the subject. As in reflexive responses to pain, the body sometimes reacts reflexively with an ideomotor effect to ideas alone without the person consciously deciding to take action. The effects of automatic writing, dowsing, facilitated communication, and Ouija boards have been attributed to the phenomenon.\n\nThe associated term \"ideo-\"dynamic\" response\" (or \"reflex\") applies to a wider domain, and extends to the description of all bodily reactions (including ideo-motor and ideo-sensory responses) caused in a similar manner by certain ideas, e.g., the salivation often caused by imagining sucking a lemon, which is a secretory response. The notion of an ideo-dynamic response contributed to James Braid's first neuro-psychological explanation of the principle through which suggestion operated in hypnotism.\n\nWith the rise of Spiritualism in 1840s, mediums devised and refined a variety of techniques for communicating, ostensibly, with the spirit world including table-turning and planchette writing boards (the precursor to later Ouija boards). These phenomena and devices quickly became the subject of scientific investigation.\n\nThe term Ideomotor was first used in a scientific paper discussing the means through which these spiritualistic phenomena produced effect, by William Benjamin Carpenter in 1852, hence the alternative term Carpenter effect. (Carpenter derived the word \"ideomotor\" from the components \"ideo\", meaning \"idea\" or \"mental representation\", and \"motor\", meaning \"muscular action\"). In the paper, Carpenter explained his theory that muscular movement can be independent of conscious desires or emotions.\n\nCarpenter was a friend and collaborator of James Braid, the founder of modern hypnotism. Braid soon adopted Carpenter's ideo-motor terminology, to facilitate the transmission of his most fundamental views, based upon those of his teacher, the philosopher Thomas Brown, that the efficacy of hypnotic suggestion was contingent upon the subject's concentration upon a single (thus, \"dominant\") idea. In 1855, Braid explained his decision to abandon his earlier term \"mono-ideo-motor\", based on Carpenter's (1852) \"ideo-motor principle\", and adopt the more appropriate and more descriptive term \"mono-ideo-dynamic\". His decision was based upon suggestions made to Carpenter (in 1854) by their friend in common, Daniel Noble, that the activity that Carpenter was describing would be more accurately understood in its wider applications (viz., wider than pendulums and ouija boards) if it were to denominated the \"ideo-dynamic principle\":In order that I may do full justice to two esteemed friends, I beg to state, in connection with this term \"monoideo-dynamics\", that, several years ago, Dr. W. B. Carpenter introduced the term \"ideo-motor\" to characterise the reflex or automatic muscular motions which arise merely from ideas associated with motion existing in the mind, without any conscious effort of volition. In 1853, in referring to this term, Daniel Noble said, \"\"Ideo-dynamic\" would probably constitute a phraseology more appropriate, as applicable to a wider range of phenomena.\" In this opinion I quite concurred, because I was well aware that an idea could \"arrest\" as well as \"excite\" motion automatically, not only in the muscles of voluntary motion, but also as regards the condition of \"every other function of the body\". I have, therefore, adopted the term \"monoideo-dynamics\", as still more comprehensive and characteristic as regards the true mental relations which subsist during all dynamic changes which take place, in every other function of the body, as well as in the muscles of voluntary motion.Scientific tests by the English scientist Michael Faraday, Manchester surgeon James Braid, the French chemist Michel Eugène Chevreul, and the American psychologists William James and Ray Hyman have demonstrated that many phenomena attributed to spiritual or paranormal forces, or to mysterious \"energies\", are actually due to ideomotor action. Furthermore, these tests demonstrate that \"honest, intelligent people can unconsciously engage in muscular activity that is consistent with their expectations\". They also show that suggestions that can guide behavior can be given by subtle clues (Hyman 1977).\n\nSome operators claim to use ideomotor responses to communicate with a subject's \"unconscious mind\" using a system of physical signals (such as finger movements) for the unconscious mind to indicate \"yes\", \"no\", \"I don't know\", or \"I'm not ready to know that consciously\".\n\nA simple experiment to demonstrate the ideomotor effect is to allow a hand-held pendulum to hover over a sheet of paper. The paper has keywords such as YES, NO and MAYBE printed on it. Small movements in the hand, in response to questions, can cause the pendulum to move towards key words on the paper. This technique has been used for experiments in extrasensory perception, lie detection, and ouija boards. This type of experiment was used by Kreskin and has also been used by illusionists such as Derren Brown.\n\nIt is strongly associated with the practice of analytical hypnotherapy based on \"uncovering techniques\" such as Watkins' \"Affect Bridge\", whereby a subject's \"yes\", \"no\", \"I don't know\", or \"I don't want to answer\" responses to an operator's questions are indicated by physical movements rather than verbal signals; and are produced \"per medium\" of a pre-determined (between operator and subject) and pre-calibrated set of responses.\n\n"}
{"id": "186351", "url": "https://en.wikipedia.org/wiki?curid=186351", "title": "In Situ Conservation in India", "text": "In Situ Conservation in India\n\n\"In-situ\" conservation is the on-site conservation or the conservation of genetic resources in natural populations of plant or animal species, such as forest genetic resources in natural populations of Teagan species. It is the process of protecting an endangered plant or animal species in its natural habitat, either by protecting or restoring the habitat itself, or by defending the species from predators. It is applied to conservation of agricultural biodiversity in agro ecosystems by farmers, especially those using unconventional farming practices.\nAbout 4% of the total geographical area of the country is used for \"in situ\" conservation. The following methods are presently used for \"in situ\" conservation.\n\nBiosphere reserves cover very large areas, often more than 5000 km. They are used to protect species for a long time. Currently, there are 18 Biosphere Reserves in India.\nA national park is an area dedicated for the conservation of wildlife along with its environment. It is usually a small reserve covering an area of about 100 to 500 square kilometers. Within biosphere reserves, one or more national parks may also exist. Currently, there are 103 national parks in India.\nA wildlife sanctuary is an area which is reserved for the conservation of animals only. Currently, there are 543 wild sanctuaries in India.\n\nA gene sanctuary is an area where plants are conserved.\nIt includes both biosphere reserves as well as national parks.\nIndia has set up its first gene sanctuary in the Garo Hills of Meghalaya for wild relatives of citrus. Efforts are also being made to set up gene sanctuaries for banana, sugarcane, rice and mango.\n\nIt is the type of protected area introduced in Wildlife Protection Amendment Act 2002 to provide legal support to community or privately owned reserves which cannot be designated as national park or wildlife sanctuary.\n\nThey are tracts of forest set aside where all the trees and wildlife within are venerated and given total protection.\n\nOne benefit of \"in situ\" conservation is that it maintains recovering populations in the environment where they have developed their distinctive properties. Another benefit is that this strategy helps ensure the ongoing processes of evolution and adaptation within their environments. As a last resort, ex-situ conservation may be used on some or all of the population, when \"in situ\" conservation is too difficult, or impossible. The species gets adjusted to the natural disasters like drought, floods, forest fires and this method is very cheap and convenient.\n\nWildlife and livestock conservation is mostly based on nothing. This involves the protection of wildlife habitats. Also, sufficiently large reserves are maintained to enable the target species to exist in large numbers. The population size must be sufficient to enable the necessary genetic diversity to survive within the population, so that it has a good chance of continuing to adapt and evolve over time. This reserve size can be calculated for target species by examining the population density in naturally occurring situations. The reserves must then be protected from intrusion or destruction by man, and against other catastrophes.\n\nIn agriculture, \"in situ conservation\" techniques are an effective way to improve, maintain, and use traditional or native varieties of agricultural crops. Such methodologies link the positive output of scientific research with farmers' experience and field work.\n\nFirst, the accessions of a variety stored at a germplasm bank and those of the same variety multiplied by farmers are jointly tested in the producers field and in the laboratory, under different situations and stresses. Thus, the scientific knowledge about the production characteristics of the native varieties is enhanced. Later, the best tested accessions are crossed, mixed, and multiplied under replicable situations. At last, these improved accessions are supplied to the producers. Thus, farmers are enabled to crop improved selections of their own varieties, instead of being lured to substitute their own varieties with commercial ones or to abandon their crop. This technique of conservation of agricultural biodiversity is more successful in marginal areas, where commercial varieties are not expedient, due to climate and soil fertility constraints. Or where the taste and cooking characteristics of traditional varieties compensate for their lower yields.\n\n\n"}
{"id": "1042133", "url": "https://en.wikipedia.org/wiki?curid=1042133", "title": "Influences on the standing of the Jews in England", "text": "Influences on the standing of the Jews in England\n\nAround the start of the 19th century, various factors led to a more positive image of the Jews in England. As the century went on, Jews of German origin acquired greater social status. Despite powerful opposition, there was a gradual move towards religious toleration and full civil rights for the Jews. \n\nOne reason for an improvement in the public image of the Jews at the end of the 18th century and beginning of the 19th can be found in positive attitudes towards Jewish pugilists. A further cause for kindlier feeling on the part of at least the middle classes of Englishmen toward the Jews was supplied by the revival of conversionist hopes at the beginning of the nineteenth century. Misled doubtless by the tendency to desertion shown by not a few of the Sephardim, many evangelical Christians anticipated the conversion \"en masse\" of the Jewish population, and on the initiative of Lewis Way the London Society for the Promotion of Christianity Among the Jews was founded in 1809. This and kindred societies wasted large sums of money with indifferent results but, politically, they helped to increase sympathy for the Jews among the non-conformists, who formed the bulk of their contributors and were at the same time becoming a leading factor in the formation of Liberal policy.\n\nSimilarly, at a much later period the craze of British Israelism made many of the narrower Bible Christians more sympathetic toward the Jews. On the other hand, the great influence of Dr. Thomas Arnold in the Liberal ranks was ultimately directed against the Jewish hopes. The more Erastian he was, the more he desired to see the legislature exclusively Christian.\n\nIn the meanwhile the lead among the English Jews was passing from the Spanish to the German section of the community. The bankers Goldsmid acquired both influence and culture, and their efforts to raise the community were soon to be supplemented by those of Nathan Rothschild, the ablest of Mayer Rothschild's sons, who had settled first in Manchester and afterward in London. The times were in a measure propitious for a new effort to remove the civil disabilities of the Jews. The example of France had not been without its effect. The rising tide in favour of religious liberty, as applied to dissenters generally and to Roman Catholics in particular, might have been expected to carry with it more favourable conditions for the Jews; but a long struggle was to intervene before \"Englishmen of the Jewish persuasion\" were to have equal rights with other Englishmen.\n\n"}
{"id": "11495343", "url": "https://en.wikipedia.org/wiki?curid=11495343", "title": "John P. Davis", "text": "John P. Davis\n\nJohn Preston Davis (January 19, 1905 – September 11, 1973) was an American journalist, lawyer and activist intellectual, who became prominent for his work with the Joint Committee on National Recovery. He co-founded the National Negro Congress in 1935, which was affiliated with the Communist Party of America.\n\nHe founded \"Our World\" magazine in 1946, a full-size, nationally distributed magazine edited for African-American readers. He also published the \"American Negro Reference Book,\" covering virtually every aspect of African-American life, present and past.\n\nJohn P. Davis was born in Washington, D.C., the son of Dr. William Henry Davis and Julia Davis. His father was a graduate of Howard University and served as principal of Armstrong High School. During World War I, Dr. Davis was appointed as Secretary to Dr. Emmett Jay Scott, Special Assistant to the United States Secretary of War. In the 1920s, Dr. Davis served as Secretary to the Presidential Commission investigating the economic conditions in the Virgin Islands.\n\nDavis attended segregated schools in Washington, D.C., graduating from the elite Dunbar High School, which stressed an academic curriculum. In 1922 he enrolled in Bates College in Lewiston, Maine. He graduated in 1926, earning an A.B. and double honors in English and Psychology. At Bates, Davis was president of Delta Sigma Rho, an honorary debating fraternity, and editor of the student publication \"The Bobcat\".\n\nDavis toured Europe with the Bates College debating team. He was among the first African-American men to be sent overseas under the auspices of the American University Union to engage in international debate; his team from Bates met and defeated Cambridge University. While he was an undergraduate at Bates College, Davis was nominated for a Rhodes scholarship. He contributed short stories to the magazines, \"The Crisis\" and \"Opportunity,\" published by the NAACP.\nWith his literary interests, Davis was drawn into the Harlem Renaissance. After college, he moved to New York City, where for a time, he replaced the celebrated scholar W. E. B. Du Bois as literary editor of \"The Crisis\". During this period, Davis joined with other young black writers – Zora Neale Hurston, Langston Hughes, Gwendolyn Bennett, Wallace Thurman, Aaron Douglas, Richard Bruce – to produce \"Fire!!\", a magazine devoted to young African-American artists.\n\nDavis had a fellowship to Harvard University from 1926 to 1927, and earned his master's degree in Journalism. He left Harvard to join the staff of Fisk University, a historically black college in Nashville, where he served as Director of Publicity from (1927 to 1928). He returned to Harvard University and earned an LLB degree from Harvard Law School in 1933.\n\nAt Harvard, Davis cemented lifelong friendships with a small core of black students, including fellow Dunbar High School alumni Robert C. Weaver, later appointed as the first black member of a Presidential cabinet; William Hastie, later appointed as the first black federal judge; and Ralph Bunche, later a statesman and diplomat who was awarded a Nobel Prize for Peace.\n\nThese friends remained important throughout his career. During their student years, the men discussed race and politics, especially the inadequacy of the black Republican leadership. When the Great Depression intensified the social and economic problems confronting black America, Davis and his colleagues looked to the example of Reconstruction, when federal power was used to redress the plight of former slaves. They called on the federal government to ensure black civil and political rights. The New Deal of Franklin D. Roosevelt seemed to offer the possibility of federal intervention for economic justice.\n\nDavis married Marguerite DeMond, the daughter of Reverend Abraham Lincoln DeMond and Lula Watkins (Patterson) DeMond. She had attended Avery Normal Institute in Charleston, South Carolina, operated by the American Missionary Association and the Congregationalist Church. Even before the Civil War, Avery Normal Institute's racially integrated faculty was providing quality educations for African Americans. She attended Syracuse University in 1931 and came to Washington, D.C., with her mother in 1932, after the death of her father.\n\nMarguerite DeMond went to work as a researcher for African-American historian Carter G. Woodson's Association for the Study of African American Life and History. After a one-year courtship, she and Davis were married. They had four children, including Michael DeMond Davis, who became a journalist who authored Black American Women in Olympic track and Field and the Thurgood Marshall biography.\n\nIn the summer of 1933 John P. Davis, a law graduate, and Robert C. Weaver, a doctoral student at Harvard, acted to ensure that African-American interests were represented in government programs. The two men returned to Washington, D.C. and established an office on Capitol Hill, where they fought successfully against the racial wage differential and for the integration of Negro families into the program of the Homestead Subsistence Division in the first recovery program.\n\nDavis and Weaver organized the Negro Industrial League to pressure New Deal agencies to address the needs of blacks. They monitored the hearings of the National Recovery Administration to ensure that blacks benefited from the program.\n\nTheir efforts led to the establishment of the Joint Committee on National Recovery, a group of twenty-six national groups, including the YWCA, National Urban League (NUL), and the National Association for the Advancement of Colored People (NAACP). Davis became Executive Secretary of the JCNR, a position he held until 1936, serving as a legislative lobbyist. The committee lobbied for fair inclusion of African Americans in government-sponsored programs. It publicized incidents and patterns of racial discrimination. The implementation of a National Recovery Program promised to have immediate and long-term consequences for African Americans. While Davis and Weaver worked, more established African-American leaders deliberated about how to respond to the flurry of New Deal legislation.\n\nIn May 1935 a conference on the economic status of the Negro was held at Howard University in Washington, D.C., out of which emerged a major civil rights coalition that was active in the late 1930s and 1940s. The National Negro Congress—whose sponsors included Davis, Ralph J. Bunche and Alain Locke of Howard University, A. Philip Randolph of the Brotherhood of Sleeping Car Porters, James Ford of the Communist Party, Lester Granger and Elmer Carter of the Urban League, and Charles Hamilton Houston of the NAACP—was significant in two respects. Davis was one of the original founders; he served as Executive Secretary until 1942.\n\nThe NNC represented one of the first efforts of the 20th century to bring together under one umbrella black secular leaders, preachers, labor organizers, workers, businessmen, radicals, and professional politicians, with the assumption that the common denominator of race could weld together such divergent segments of black society. It was the Communist Party’s effort to build support among activists in the black mainstream. The evolution of the National Negro Congress dramatized the growing convergence of outlook between Communists and activist black intellectuals that had taken shape in the protests of the early Depression years and reached full fruition during the years of the Popular Front.\n\nIn 1943 Davis brought the first lawsuit challenging segregated schools in Washington, D.C., in the name of his five-year-old son Michael D. Davis, who was rejected from his neighborhood's Noyes School, a white elementary school. The \"Washington Star\" criticized the African-American lawyer for legally challenging the District's dual segregated school system after the principal of Noyes School refused to admit Mike Davis. The \"Washington Star\" paper said that District citizens had long accepted separate schools for blacks and whites, and that the suit brought by John P. Davis would cause deeper racial divisions in the nation's capital.\n\nIn response to Davis' suit, the US Congress appropriated federal funds to construct the Lucy D. Slowe elementary school, for African-American children, directly across the street from his Brookland neighborhood home. At that time, a committee of Congress directly administered District government.\n\nAfter World War II, in 1946 Davis was founding publisher of \"Our World\" magazine, a full-size, nationally distributed magazine to appeal to African-American readers. Its first issue, with singer-actress Lena Horne on the cover, appeared on the nation's newsstands in April 1946. \"Our World\" was a premier publication, covering contemporary topics from black history to sports and entertainment, with regular articles on health, fashion, politics and social awareness. It was based in New York City, the publishing capital of the country.\n\n\"Our World\" portrayed a thriving black America; its covers featured entertainers such as Lena Horne, Marian Anderson, Harry Belafonte, Eartha Kitt, Ella Fitzgerald, Louis Armstrong, Duke Ellington and Nat King Cole.\n\nIn 1964 Davis served as editor of special publications for the Phelps-Stokes Fund. He compiled in a single volume a reliable summary on the main aspects of Negro life in America, presenting it with historical depth to provide the reader with a true perspective. \"The American Negro Reference Book\" covered virtually every aspect of African-American life, present and past.\n\nThe largest collection of Davis' papers is in the Schomburg Center for Research in Black Culture, New York Public Library. Insight into Davis' political and social views can be found in his own writings. \"The Papers of the National Negro Congress\" reproduces all of the organization’s records that are housed at the Schomburg Center for Research in Black Culture, including the voluminous working files of Davis and successive executive secretaries of the National Negro Congress. Beginning with papers from 1933 that predate the formation of the National Negro Congress, the wide-ranging collection documents Davis’ involvement in the Negro Industrial League. It includes the \"Report Files\" of Davis’ interest in the \"Negro problem.\"\n\nThe most extensive overview of Davis' life is by Hilmar Jenson in an edition of his writings, John Preston Davis, \"The Forgotten Civil Rights\" (1996). Much of the scholarly writing about Davis focuses on his experiences in the National Negro Congress.\n\nArtifacts and papers of Davis are being acquired by the Smithsonian Institution's National Museum of African-American History and Culture.\n\n\"What the ‘New Deal’ Means for the Negro,\" 1935, from John P. Davis, \"A Black Inventory of the New Deal,\" \"The Crisis\" 42 (May 1935), 141-42, 154.\n\"The Overcoat,\" John P. Davis\n"}
{"id": "5396100", "url": "https://en.wikipedia.org/wiki?curid=5396100", "title": "Left-wing terrorism", "text": "Left-wing terrorism\n\nLeft-wing terrorism (sometimes called Marxist–Leninist terrorism or revolutionary/left-wing terrorism) is terrorism meant to overthrow conservative or capitalist systems and replace them with Marxist–Leninist, socialist, or anarchist societies. Left-wing terrorism also occurs within already socialist states as activism against the current ruling government. It has taken vivid manifestations across the world and presented diverging dynamics and relationships with national governments and political economies.\n\nLeft-wing terrorists have been influenced by various communist and socialist currents, including Marxism. Narodnaya Volya, a 19th-century terrorist group that killed tsar Alexander II of Russia in 1881 and developed the concept of propaganda by the deed, is a major influence.\n\nAccording to Sarah Brockhoff, Tim Krieger and Daniel Meierrieks, while left-wing terrorism is ideologically motivated, nationalist-separatist terrorism is ethnically motivated. They argue that the revolutionary goal of left-wing terrorism is non-negotiable, whereas nationalist terrorists are willing to make concessions. They suggest that rigidity of the demands of left-wing terrorists may explain their lack of support relative to nationalist groups. Nevertheless, many on the revolutionary left have showed solidarity for national liberation groups employing terrorism, such as Irish nationalists, the Palestine Liberation Organization and the South American Tupamaros, seeing them as engaged in a global struggle against capitalism. Since nationalist sentiment is fueled by socio-economic conditions, some separatist movements, including the Basque ETA, the Provisional Irish Republican Army and the Irish National Liberation Army incorporated communist and socialist ideology into their policies.\n\nLeft-wing terrorism has its roots in 19th and early 20th century anarchist terrorism and became pronounced during the Cold War. Modern left-wing terrorism developed in the context of the political unrest of 1968. In Western Europe, notable groups included the West German Red Army Faction (RAF), the Italian Red Brigades, the French Action Directe (AD), and the Belgian Communist Combatant Cells (CCC). Asian groups have included the Japanese Red Army and the Liberation Tigers of Tamil Eelam, although the latter organization later adopted nationalist terrorism. In Latin America, groups that became actively involved in terrorism in the 1970s and 1980s included the Nicaraguan Sandinistas, the Peruvian Shining Path, and the Colombian 19th of April Movement.\n\nThe Front de libération du Québec was a Marxist-Leninist group active in Canada in the 1960s and '70s, promoting socialist insurrection and an independent Quebec. They are known for over 160 bombings and other violent incidents that killed eight, and for the kidnap-murder of Quebec politician Pierre Laporte in 1970.\n\nModern left-wing terrorist groups in the United States developed from remnants of the Weather Underground and extremist elements of the Students for a Democratic Society. Between 1973 and 1975, the Symbionese Liberation Army was active, committing bank robberies, murders, and other acts of violence. Most notably, the group kidnapped heiress Patty Hearst. During the 1980s, both the May 19th Communist Organization (M19CO) and the smaller United Freedom Front were active. A 1994 study found that in the 1980s \"the actual number of acts of terrorism committed by left-wing groups accounted for about three-fourths of all officially designated acts of domestic terrorism in America. About half of these leftist acts were committed by Puerto Rican groups, while the rest were committed by traditional leftist terrorist groups like M19CO\". After 1985, following the dismantling of both groups, one source reports there were no confirmed acts of left-wing terrorism by similar groups.\n\nIncidents of left-wing terrorism dropped off at the end of the Cold War (circa 1989), partly due to the loss of support for communism. \n\nStefan M. Audrey describes the Sandinistas, Shining Path, 19th of April Movement, and Revolutionary Armed Forces of Colombia (FARC) as the main organizations involved in left-wing terrorism in Latin America during the 1970s and 1980s. These organizations opposed the United States government and drew local support, as well as receiving support from the Soviet Union and Cuba.\n\nThe Revolutionary Armed Forces of Colombia (FARC) is a Marxist–Leninist organization in Colombia which has engaged in vehicle bombings, gas cylinder bombs, killings, landmines, kidnapping, extortion, hijacking, as well as guerilla and conventional military. The United States Department of State includes the FARC-EP on its list of foreign terrorist organizations, as does the European Union. It funds itself primarily through extortion, kidnapping and their participation in the illegal drug trade. Many of their fronts enlist new and underage recruits by force, distribute propaganda and rob banks. Businesses operating in rural areas, including agricultural, oil, and mining interests, were required to pay \"vaccines\" (monthly payments) which \"protected\" them from subsequent attacks and kidnappings. An additional, albeit less lucrative, source of revenue was highway blockades in which guerrillas stopped motorists and buses in order to confiscate jewelry and money. An estimated 20 to 30 percent of FARC combatants are under 18 years old, with many as young as 12 years old, for a total of around 5000 children. Children who try to escape the ranks of the guerrillas are punished with torture and death.\n\nThe May 19th Communist Organization, also referred to as the May 19 Communist Coalition, was a United States-based, self-described revolutionary organization formed by splintered-off members of the Weather Underground and the Black Liberation Army. The M19CO name was derived from the birthdays of Ho Chi Minh and Malcolm X. The May 19 Communist Organization was active from 1978 to 1985. It also included members of the Black Panthers and the Republic of New Africa (RNA). According to a 2001 US government report, the alliance between Black Liberation Army and Weather Underground members had three objectives: free political prisoners from US prisons; appropriate capitalist wealth (through armed robberies) to fund their operations; and initiate a series of bombings and terrorist attacks against the United States.\n\nThe Communist Party of Peru, more commonly known as the Shining Path (Sendero Luminoso), is a Maoist guerrilla organization that launched the internal conflict in Peru in 1980. Widely condemned for its brutality, including violence deployed against peasants, trade union organizers, popularly elected officials and the general civilian population, Shining Path is on the United States Department of State's \"Designated Foreign Terrorist Organizations\" list. Peru, the European Union, and Canada likewise regard Shining Path as a terrorist group and prohibit providing funding or other financial support.\n\nStefan M. Audrey describes the Japanese Red Army and the Liberation Tigers of Tamil Eelam (LTTE) as the main left-wing terrorist organizations in Asia, although he notes that the LTTE later transformed into a nationalist terrorist organization.\n\nArmed Naxalite groups operate across large parts of the central and eastern rural regions of India. Informed by the People's War strategy of Maoism, the most prominent of the groups is the Communist Party of India (Maoist), formed through the merging of two previous Naxalite organizations, the People's War Group and the Maoist Communist Centre of India (MCC). Armed Naxalite movements are considered India's largest internal security threat. Naxalite militants have engaged in numerous terrorist attacks and human rights violations in India's Red Corridor. A \"Frontline\" magazine article calls the Bhamragad Taluka, where the Madia Gond Adivasis live, the heart of the Naxalite-affected region in Maharashtra.\n\nThe Communist Party of Nepal (Maoist) has been responsible for hundreds of attacks on government and civilian targets.\nAfter the United People's Front of Nepal (UPF)'s Maoist wing, CPN-M, performed poorly in elections and was excluded from the 194 election, the Maoists turned to insurgency. They aimed to overthrow Nepal's monarchy and parliamentary democracy, and to change Nepalese society, including a purge of the nation's elite class, a state takeover of private industry, and collectivization of agriculture. In Nepal, attacks against civilian populations occurred as part of Maoist strategy, leading Amnesty International to state: The CPN (Maoist) has consistently targeted private schools, which it ideologically opposes. On the 14 April 2005 the CPN (Maoist) demanded that all private schools shut down, although this demand was withdrawn on 28 April. Following this demand, it bombed two schools in western Nepal on 15 April, a school in Nepalganj, Banke district on 17 April and a school in Kalyanpur, Chitwan on 21 April. CPN (Maoist) cadres also reportedly threw a bomb at students taking classes in a school in Khara, Rukum district. \n\nThe Japanese Red Army (JRA) was founded in 1969 as the \"Red Army Faction\" by students impatient with the Communist Party. In 1970, they hijacked a plane to North Korea, where nine of their members were interned. Fourteen members were killed during an internal purge. In 1971, the renamed JRA formed a connection with the Popular Front for the Liberation of Palestine and established a base in Lebanon. Their major terrorist acts included an armed attack on the Tel Aviv airport, highjacking planes to Libya and Bangladesh, kidnapping the French ambassador to the Hague, and bombing a United Service Organizations (USO) nightclub in Naples, Italy. By the mid-1990s, their level of activity had declined and the US State Department no longer considered them a terrorist threat. In 2001, their leader announced the dissolution of the group, although some of its members were in prison and others were still wanted by police.\n\nLeft wing groups like the Pakhtoon Zalmay, Al-Zulfiqar organisation (AZO) and the MQM including its predecessor the Muhajir Qaumi Movement committed numerous acts of violence including bombings, targeted killings, disinformation and assassinations.\n\nTypically small and urban-based, left-wing terrorist organizations in Europe have been committed to overthrowing their countries' governments and replacing them with regimes guided by Marxist–Leninist ideology. Although none have achieved any degree of success in accomplishing their goals, they have caused serious security problems in Germany, Belgium, Italy, Greece, France, Turkey, Portugal and Spain.\n\nAction Directe (AD) was active in France between 1979 and 1987. Between 1979 and 1985, they concentrated on non-lethal bombings and strafings of government buildings, although they assassinated a French Ministry of Defense official. Following arrests of some of its members, the organization declined and became inactive. The French government has banned the group.\n\nThe Communist Combatant Cells (CCC) was founded in 1982 in Belgium by Pierre Carette. With about ten members, the CCC financed its activities through a series of bank robberies. Over the course of 14 months, they carried out 20 attacks against property, mostly North Atlantic Treaty Organization (NATO) facilities. Despite attempts to avoid loss of life, there were casualties as a result of these attacks. After Carette and other members were arrested in 1985, the group ceased to be operational. Carette served 17 years of a life sentence, although his colleagues that were convicted with him were released earlier.\n\nThe First of October Anti-Fascist Resistance Groups (GRAPO) was a Maoist terrorist group in Spain that was founded in 1975. Since its inception 2007, it assassinated 84 people, including police, military personnel, judges and civilians; either by bombings or shootings. The group has committed a number of kidnappings, initially for political reasons, later on, mainly for extortion. Its last attack was committed in 2006, when GRAPO militants shot dead Ana Isabel Herrero, the owner of a temporary work agency in Zaragoza.\n\nThe Irish People's Liberation Organisation (IPLO) was a small Irish republican Revolutionary socialist paramilitary organisation which was formed in 1986 by disaffected and expelled members of the Irish National Liberation Army (INLA). It carried out paramilitary/guerrilla style attacks in Northern Ireland between 1986 - 1992 until the Provisional IRA destroyed the group.\n\nSome of the IPLO's most notable attacks during its existence were: \n\nThe IPLO remains a Proscribed Organisation in the United Kingdom under the Terrorism Act 2000.\n\nThe Popular Forces 25 April (FP-25) was formed in Portugal under the leadership of Lt. Col. Otelo Saraiva de Carvalho. Named after the 1974 military coup that overthrew the right-wing regime that had ruled Portugal since 1926, FP-25 aimed to overthrow the Portuguese government and establish a Marxist state. It carried out a series of assassinations and bombing attacks against the Portuguese government. They ceased activity in the mid 1980s.\n\nThe Red Army Faction (RAF), which developed out of the Baader-Meinhof Group in Germany, carried out a series of terrorist attacks in the 1970s and remained active for over 20 years. The RAF was organized into small isolated cells, and had connections with the Popular Front for the Liberation of Palestine and Carlos the Jackal. Although the group's leaders, including Gudrun Ensslin, Andreas Baader and Ulrike Meinhof were arrested in 1972, it carried out major attacks, including kidnapping and hijacking. On April 7, 1977 unknown RAF members assassinated a Prosecutor-General, Siegfried Buback, a former Nazi.\n\nThe Red Brigades were founded in August 1970, mostly by former members of the Communist Youth movement who had been expelled from the parent party for extremist views. The largest terrorist group in Italy, its aim was to overthrow the government and replace it with a communist system.\n\nRevolutionary Organization 17 November (also known as 17N or N17) was a long-lasting urban terrorist organization named in commemoration of a 1973 riot against the Greek government. By 2001, the group had killed 23 people, including US officials, NATO officials and Greek politicians, magistrates and businessmen. Attempts by the Greek police, the Central Intelligence Agency (CIA), and Scotland Yard to investigate the group were unsuccessful. The group was captured in 2002, after one of its members was wounded by a bomb he was carrying. It has been recognized as a terrorist organization by the Greek State, the US and international law enforcement agencies.\n\nThe Revolutionary People's Liberation Party/Front, is a militant Marxist–Leninist party in Turkey. The US, UK and EU categorize it as a terrorist organization. As of 2007, the Counter-Terrorism and Operations Department of Directorate General for Security list it among the 12 active terrorist organizations in Turkey. It is one of the 44 names listed in the 2008 U.S. State Department list of Foreign Terrorist Organizations, one of the 48 groups and entities to which the EU's Common Position 2001/931/CFSP on the application of specific measures to combat terrorism applies and one of the 45 international terrorist organisations in the list of Proscribed Terrorist Groups of the UK Home Office.\n\n\n"}
{"id": "38214881", "url": "https://en.wikipedia.org/wiki?curid=38214881", "title": "Neo-Vedanta", "text": "Neo-Vedanta\n\nNeo-Vedanta, also called Hindu modernism, neo-Hinduism, Global Hinduism and Hindu Universalism, are terms to characterize interpretations of Hinduism that developed in the 19th century. Some scholars argue that these modern interpretations incorporate western ideas into traditional Indian religions, especially Advaita Vedanta, which is asserted as central or fundamental to Hindu culture.\n\nThe term \"Neo-Vedanta\" was coined by Paul Hacker, in a somewhat pejorative way, to disntinguish modern developments from \"traditional\" Advaita Vedanta. Other scholars have pointed out that a Greater Advaita Vedānta developed since medieaval times, in the Muslim period of India, when Hindus responded to Muslim rule and domination. When Muslim rule was replaced by British rule, Hindu religious and political leaders and thinkers responded to this western colonialism and orientalism, contributing to the Indian freedom struggle and the modern national and religious identity of Hindus in the Republic of India. This societal aspect is covered under the term of Hindu reform movements.\n\nAmong the main proponents of such modern interpretations of Hinduism were Vivekananda, Aurobindo and Radhakrishnan, who to some extent also contributed to the emergence of Neo-Hindu movements in the West.\n\nNeo-Vedanta has been influential in the perception of Hinduism, both in the west and in the higher educated classes in India. It has received appraisal for its \"solution of synthesis\", but has also been criticised for its Universalism. The terms \"Neo-Hindu\" or \"Neo-Vedanta\" themselves have also been criticised for its polemical usage, the prefix \"Neo-\" then intended to imply that these modern interpretations of Hinduism are \"inauthentic\" or in other ways problematic.\n\nAccording to Halbfass, the terms \"Neo-Vedanta\" and \"Neo-Hinduism\" refer to \"the adoption of Western concepts and standards and the readiness to reinterpret traditional ideas in light of these new, imported and imposed modes of thought\". Promiment in Neo-Vedanta is Vivekananda, who's theology, according to Madaio, is often characterised in earlier scholarship as \"a rupture from 'traditional' or 'classical' Hindusim, particularly the 'orthodox' Advaita Vedanta of the eight century Samkara.\"\n\nThe term \"Neo-Vedanta\" appears to have arisen in Bengal in the 19th century, where it was used by both Indians and Europeans. According to Halbfass the term was invented by a Bengali, Brajendra Nath Seal (1864–1938), who used the term to characterise the literary work of Bankim Chandra Chatterjee (1838–1894).\n\nThe term \"neo-Vedanta\" was used by Christian missionaries as well as Hindu traditionalists to criticize the emerging ideas of the Brahmo Samaj, a critical usage whose \"polemical undertone [...] is obvious\".\n\nThe term \"neo-Hinduism\" was used by a Jesuit scholar resident in India, Robert Antoine (1914–1981), from whom it was borrowed by Paul Hacker, who used it to demarcate these modernist ideas from \"surviving traditional Hinduism,\" and treating the Neo-Advaitins as \"dialogue partners with a broken identity who cannot truly and authentically speak for themselves and for the Indian tradition\". Hacker made a distinction between \"Neo-Vedanta\" and \"neo-Hinduism\", seeing nationalism as a prime concern of \"neo-Hinduism\".\n\nAlthough neo-Vedanta proper developed in the 19th century in response to western colonialism, it has got deeper origins in the Muslim period of India.\n\nWith the onset of Islamic rule, hierarchical classifications of the various orthodox schools were developed to defend Hinduism against Islamic influences. According to Nicholson, already between the twelfth and the sixteenth century,\nThe tendency of \"a blurring of philosophical distinctions\" has also been noted by Burley. Lorenzen locates the origins of a distinct Hindu identity in the interaction between Muslims and Hindus, and a process of \"mutual self-definition with a contrasting Muslim other\", which started well before 1800. Both the Indian and the European thinkers who developed the term \"Hinduism\" in the 19th century were influenced by these philosophers.\n\nWithin these so-called \"doxologies\" Advaita Vedanta was given the highest position, since it was regarded to be most inclusive system. Vijnanabhiksu, a 16th-century philosopher and writer, is still an influential representant of these doxologies. He's been a prime influence on 19th century Hindu modernists like Vivekananda, who also tried to integrate various strands of Hindu thought, taking Advaita Vedanta as its most representative specimen.\n\nWith the colonisation of India by the British, a darker era in the history of India began. Prior to this, Muslim rule over North India had had a drastic effect on Hinduism (and Buddhism) through systematic persecution. While the Indian society was greatly impacted, its economy however continued to remain one of the largest in the World. Muslim rule over Southern India was also relatively short-lived before the 17th century. In contrast to the Muslim rulers, the British actively engaged in destroying the Indian economy as well. The economic destruction wrought by restrictive British policies and Industrial revolution in Europe, led to the dismantling of the prevailing decentralized education systems in India in the 18th century. The British state-supported education system, after the English Education Act of 1835, emphasized western religions and thoughts at the cost of indigenous ones.\n\nThe British also nurtured and were involved, post 1813, in the aggressive propagation of Protestant Christianity. This was concomitant with the British propaganda machine's involvement in the spreading anti-Hindu sentiments.\n\nIn response to the British rule and cultural dominance, Hindu reform movements developed, propagating societal and religious reforms, exemplifying what Percival Spear has called\nNeo-Vedanta, also called \"neo-Hinduism\" is a central theme in these reform-movements. The earliest of these reform-movements was Ram Mohan Roy's Brahmo Samaj, who strived toward a purified and monotheistic Hinduism.\n\nNeo-vedanta's main proponents are the leaders of the Brahmo Samaj, especially Ram Mohan Roy, while Vivekananda, Gandhi, Aurobindo and Radhakrishnan are the main proponents of neo-Hinduism.\n\nThe Brahmo Samaj was the first of the 19th century reform movements. Its founder, Ram Mohan Roy (1772–1833), strived toward an universalistic interpretation of Hinduism. He rejected Hindu mythology, but also the Christian trinity. He found that Unitarianism came closest to true Christianity, and had a strong sympathy for the Unitarians. He founded a missionary committee in Calcutta, and in 1828 asked for support for missionary activities from the American Unitarians. By 1829, Roy had abandoned the Unitarian Committee, but after Roy's death, the Brahmo Samaj kept close ties to the Unitarian Church, who strived towards a rational faith, social reform, and the joining of these two in a renewed religion. The Unitarians were closely connected to the Transcendentalists, who were interested in and influenced by Indian religions early on.\n\nRammohan Roy's ideas were \"altered ... considerably\" by Debendranath Tagore, who had a Romantic approach to the development of these new doctrines, and questioned central Hindu beliefs like reincarnation and karma, and rejected the authority of the \"Vedas\". Tagore also brought this \"neo-Hinduism\" closer in line with western esotericism, a development which was furthered by Keshubchandra Sen. Sen was influencded by Transcendentalism, an American philosophical-religious movement stringly connected with Unitarianism, which emphasized personal religious experience over mere reasoning and theology. Sen strived to \"an accessible, non-renunciatory, everyman type of spirituality\", introducing \"lay systems of spiritual practice\" which can be regarded as proto-types of the kind of Yoga-exercises which Vivekananda populurized in the west.\n\nThe theology of the Brahmo Samaj was called \"neo-Vedanta\" by Christian commentators, who \"partly admired [the Brahmos] for their courage in abandoning traditions of polytheism and image worship, but whom they also scorned for having proffered to other Hindus a viable alternative to conversion\". Critics accused classical Vedanta of being \"cosmic self-infatuation\" and \"ethical nihilism\". Brahmo Samaj leaders responded to such attacks by redefining the Hindu path to liberation, making the Hindu path available to both genders and all castes, incorporating \"notions of democracy and worldly improvement\".\n\nAccording to Gavin Flood, Vivekananda (1863–1902) (Narendranath Dutta) \"is a figure of great importance in the development of a modern Hindu self-understanding and in formulating the West's view of Hinduism\". He played a major role in the revival of Hinduism, and the spread of Advaita Vedanta to the west via the Ramakrishna Mission.\n\nIn 1880 Vivekananda joined Keshub Chandra Sen's \"Nava Vidhan\", which was established by Sen after meeting Ramakrishna and reconverting from Christianity to Hinduism. Narendranath (a.k.a. Narendra) became a member of a Freemasonry lodge \"at some point before 1884\" and of the Sadharan Brahmo Samaj in his twenties, a breakaway faction of the Brahmo Samaj led by Keshub Chandra Sen and Debendranath Tagore. From 1881 to 1884 he was also active in Sen's Band of Hope, which tried to discourage the youth from smoking and drinking. It was in this cultic milieu that Narendra became acquainted with western esotericism. His initial beliefs were shaped by Brahmo concepts, which included belief in a formless God and the deprecation of idolatry, and a \"streamlined, rationalized, monotheistic theology strongly coloured by a selective and modernistic reading of the \"Upanisads\" and of the Vedanta\". He propagated the idea that \"the divine, the absolute, exists within all human beings regardless of social status\", and that \"seeing the divine as the essence of others will promote love and social harmony\".\n\nDuring this period, he came in contact with Ramakrishna, who eventually became his guru, and fitted into his broadening views on spirituality and liberation.\n\nVivekananda's acquaintance with western esotericism made him very successful in western esoteric circles, beginning with his speech in 1893 at the Parliament of Religions. Vivekananda adapted traditional Hindu ideas and religiosity to suit the needs and understandings of his western audiences, who were especially attracted by and familiar with western esoteric traditions and movements like Transcendentalism and New thought. An important element in his adaptation of Hindu religiosity was the introduction of his four yoga's model, which includes Raja yoga, his interpretation of Patanjali's Yoga sutras, which offered a practical means to realize the divine force within which is central to modern western esotericism. In 1896 his book \"Raja Yoga\" was published, which became an instant success and was highly influential in the western understanding of Yoga.\n\nIn line with Advaita vedanta texts like \"Dŗg-Dŗśya-Viveka\" (14th century) and \"Vedantasara (of Sadananda)\" (15th century), Vivekananda saw samadhi as a means to attain liberation.\n\nGandhi (1869–1948) has become a worldwide hero of tolerance and striving toward freedom. In his own time, he objected to the growing forces of Indian nationalism, communalism and the subaltern response. Gandhi saw religion as an uniting force, confessing the equality of all religions. He synthesized the \"Astika\", \"Nastika\" and \"Semitic religions\", promoting an inclusive culture for peaceful living. Gandhi pled for a new hermeneutics of Indian scriptures and philosophy, observing that \"there are ample religious literature both in \"Astika\" and \"Nastika\" religions supporting for a pluralistic approach to religious and cultural diversity\".\n\nThe orthodox Advaita Vedanta, and the heterodox Jain concept Anekantavada provided him concepts for an \"integral approach to religious pluralism\". He regarded Advaita as a universal religion (\"dharma\") which could unite both the orthodox and nationalistic religious interpretations, as the subaltern alternatives. Hereby Gandhi offers an interpretation of \"Hindutva\" which is basically different from the \"Sangh Parivar\"-interpretation. The concept of \"anekantavada\" offered Gandhi an axiom that \"truth is many-sided and relative\". It is \"a methodology to counter exclusivism or absolutism propounded by many religious interpretations\". It has the capability of synthesizing different percpetions of reality. In Gandhi's view,\nAnekantavada also gives room to an organic understanding of \"spatio-temporal process\", that is, the daily world and its continued change. The doctrine of anekantavada is a plea for \"samvada\", \"dialogue\", and an objection against proselytizing activities.\n\nSarvepalli Radhakrishnan was a major force in the further popularization of Neo-Vedanta. As a schoolboy, Sarvepalli Radhakrishnan was inspired by Vivekananda's lectures, in which he found \"an ennobling vision of truth and harmony as well as a message of Indian pride\". He was educated by Christian missionaries, and wrote a master thesis on Vedanta and ethics. In later life, he became vice-president and president of India. According to Rinehart, he presented his view of Hinduism as \"the\" view of Hinduism. Central in his presentation was the claim that religion is fundamentally a kind of experience, \"anubhava\", reducing religion \"to the core experience of reality in its fundamental unity\". For Radhakrishnan, Vedanta was the essence and bedrock of religion.\n\nVivekananda \"occupies a very important place\" in the development of Indian nationalism as well as Hindu nationalism, and has been called \"the prophet of nationalism\", pleading for a \"Hindu regeneration\". According to S.N. Sen, his motto \"Arise, Awake and do not stop until the goal is reached\" had a strong appeal for millions of Indians. According to Bijoy Misra, a private blogger,\nAccording to Bijoy Misra, a private blogger,\n\nNeo-Vedanta aims to present Hinduism as a \"homogenized ideal of Hinduism\" with Advaita Vedanta as its central doctrine. It presents\nNeo-Vedanta was influenced by Oriental scholarship, which portrayed Hinduism as a \"single world religion\", and denigrated the heterogeneousity of Hindu beliefs and practices as 'distortions' of the basic teachings of Vedanta.\n\nFollowing Ramakrishna, neo-Vedanta regards all religions to be equal paths to liberation, but also gives a special place to Hinduism, as the ultimate universal religion.\n\nAccording to Benavides, neo-Vedanta is closer to Ramanuja's qualified non-dualism than it is to Shankara Advaita Vedanta. Nicholas F. Gier notes that neo-Vedanta does not regard the world to be illusionary, in contrast to Shankara's Advaita.\n\nAccording to Michael Taft, Ramakrishna reconciled the dualism of formless and form. Ramakrishna regarded the Supreme Being to be both Personal and Impersonal, active and inactive. According to Anil Sooklal, Vivekananda's neo-Advaita \"reconciles Dvaita or dualism and Advaita or non-dualism\".\n\nRadhakrishnan acknowledged the reality and diversity of the world of experience, which he saw as grounded in and supported by the absolute or Brahman. Radhakrishnan also reinterpreted Shankara's notion of \"maya\". According to Radhakrishnan, maya is not a strict absolute idealism, but \"a subjective misperception of the world as ultimately real\".\n\nGandhi endorsed the Jain concept of Anekantavada, the notion that truth and reality are perceived differently from diverse points of view, and that no single point of view is the complete truth. This concept embraces the perspectives of both Vedānta which, according to Jainism, \"recognizes substances but not process\", and Buddhism, which \"recognizes process but not substance\". Jainism, on the other hand, pays equal attention to both substance (\"dravya\") and process (\"paryaya\").\n\nAccording to Sarma, who stands in the tradition of Nisargadatta Maharaj, Advaitavāda means \"spiritual non-dualism or absolutism\", in which opposites are \"manifestations\" of the Absolute, which itself is immanent and transcendent.\n\nA central concern in Neo-Vedanta is the role of \"sruti\", sacred texts, versus (personal) experience. Classical Advaita Vedanta is centered on the correct understanding of \"sruti\", the sacred texts. Correct understanding of the \"sruti\" is a \"pramana\", a means of knowledge to attain liberation. It takes years of preparation and study to accomplish this task, and includes the mastery of Sanskrit, the memorisation of texts, and the meditation over the interpretation of those texts. Understanding is called \"anubhava\", knowledge or understanding derived from (personal) experience. \"Anubhava\" removes \"Avidya\", ignorance, regarding Brahman and Atman, and leads to \"moksha\", liberation. In neo-Vedanta, the status of \"sruti\" becomes secondary, and \"personal experience\" itself becomes the primary means to liberation.\n\nAccording to Ninian Smart, Neo-Vedanta is \"largely a smarta account.\" In modern times Smarta-views have been highly influential in both the Indian and western understanding of Hinduism. According to iskcon.org, \nVaitheespara notes adherence of Smartha Brahmans to \"the pan-Indian Sanskrit-Brahmanical tradition\":\nThe majority of members of Smarta community follow the Advaita Vedanta philosophy of Shankara. Smarta and Advaita have become almost synonymous, though not all Advaitins are Smartas. Shankara was a Smarta, just like Radhakrishnan. Smartas believe in the essential oneness of five (panchadeva) or six (Shanmata deities as personifications of the Supreme. According to Smartism, supreme reality, Brahman, transcends all of the various forms of personal deity. God is both Saguna and Nirguna:\nLola Williamson further notes that \"what is called Vedic in the smarta tradition, and in much of Hinduism, is essentially Tantric in its range of deities and liturgical forms.\"\n\nNeo-Vedanta was popularised in the 20th century in both India and the west by Vivekananda, Sarvepalli Radhakrishnan, and western orientalists who regarded Vedanta to be the \"central theology of Hinduism\".\n\nNeo-Vedanta has become a broad current in Indian culture, extending far beyond the Dashanami Sampradaya, the Advaita Vedanta Sampradaya founded by Adi Shankara. The influence of Neo-Vedanta on Indian culture has been called \"Vedanticization\" by Richard King.\n\nAn example of this \"Vedanticization\" is Ramana Maharshi, who is regarded as one of the greatest Hindu-saints of modern times, of whom Sharma notes that \"among all the major figures of modern Hinduism [he] is the one person who is widely regarded as a \"jivanmukti\"\". Although Sharma admits that Ramana was not acquainted with Advaita Vedanta before his personal experience of liberation, and Ramana never received initiation into the Dashanami Sampradaya or any other sampradaya, Sharma nevertheless sees Ramana's answers to questions by devotees as being within an Advaita Vedanta framework.\n\nIn response to the British dominance and the British critique of Hinduism, various visions on Indian diversity and unity have been developed within the nationalistic and reform movements.\n\nThe Brahmo Samaj strived towards monotheism, while no longer regarding the Vedas as sole religious authority. The Brahmo Samaj had a strong influence on the Neo-Vedanta of Vivekananda, Aurobindo, Radhakrishnan and Gandhi, who strived toward a modernized, humanistic Hinduism with an open eye for societal problems and needs. Other groups, like the Arya Samaj, strived toward a revival of Vedic authority. In this context, various responses toward India's diversity developed.\n\nIn modern times, the orthodox measure of the primacy of the Vedas has been joined with the 'grand narrative' of the Vedic origins of Hinduism. The exclusion of Jainism and Buddhism excludes a substantial part of India's cultural and religious history from the asserttion of a strong and positive Hindu identity. Hindutva-ideology solves this problem by taking recourse to the notion of \"Hindutva\", \"Hinduness\", which includes Jainism and Buddhism. A recent strategy, exemplified by Rajiv Malhotra, is the use of the term \"dharma\" as a common denominator, which also includes Jainism and Buddhism.\n\nAccording to Larson, Malhotra's notion of \"the so-called \"Dharma” traditions\" and their \"integral unity\" is another example of \"neo-Hindu discourse\". Malhotra, in his \"Being Different\", uses the term \"Dharmic tradition\" or \"dharmic systems\", \"referring to all the Hindu, Buddhist, Jaina and Sikh traditions\". He proposes that those traditions, despite their differences, share common features, the most important being \"Dharma\". They are also characterised by the notion of \"Integral Unity\", which means that \"ultimately only the whole exists; the parts that make up the whole have but a relative existence. The whole is independent and indivisible\", as opposed to \"Synthetic Unity\", which \"starts with parts that exist separately from one another\". Malhotra has received strong criticism of his ideas, for 'glossing over' the differences between and even within the various traditions of India.\n\nIn response, Malhotra explains that some of his critics confused \"integral unity\" with \"homogeneity\", thinking that Malhotra said all those traditions are essentially the same, when he actually wrote that Dharmic traditions share a sense of an \"integral unity\" despite differences.\n\nAccording to Rinehart, neo-Vedanta is \"a theological scheme for subsuming religious difference under the aegis of Vedantic truth\". According to Rinehart, the consequence of this line of reasoning is Communalism, the idea that \"all people belonging to one religion have common economic, social and political interests and these interests are contrary to the interests of those belonging to another religion.\" Communalism has become a growing force in Indian politics, presenting several threats to India, hindring its nation-building and threatening \"the secular, democratic character of the Indian state\".\n\nRinehart notes that Hindu religiosity plays an important role in the nationalist movement, and that \"the neo-Hindu discource is the unintended consequence of the initial moves made by thinkers like Rammohan Roy and Vivekananda.\" But Rinehart also points out that it is \nNeo-Vedanta has been influenced by western ideas, but has also had a reverse influence on western spirituality. Due to the colonisation of Asia by the western world, since the late 18th century an exchange of ideas has been taking place between the western world and Asia, which also influenced western religiosity. In 1785 appeared the first western translation of a Sanskrit-text. It marked the growing interest in the Indian culture and languages. The first translation of Upanishads appeared in two parts in 1801 and 1802, which influenced Arthur Schopenhauer, who called them \"the consolation of my life\". Early translations also appeared in other European languages.\n\nA major force in the mutual influence of eastern and western ideas and religiosity was the Theosophical Society. It searched for ancient wisdom in the east, spreading eastern religious ideas in the west. One of its salient features was the belief in \"Masters of Wisdom\", \"beings, human or once human, who have transcended the normal frontiers of knowledge, and who make their wisdom available to others\". The Theosophical Society also spread western ideas in the east, aiding a modernisation of eastern traditions, and contributing to a growing nationalism in the Asian colonies. Another major influence was Vivekananda, who popularised his modernised interpretation of Advaita Vedanta in the 19th and early 20th century in both India and the west, emphasising \"anubhava\" (\"personal experience\") over scriptural authority.\n\nAccording to Larson, the \"solution of synthesis\" prevailed in the work of Rammohun Roy, Sayyid Ahmed Khan, Rabindranath Tagore, Swami Vivekananda, M.K. Gandhi, Muhammad Ali Jinnah, Muhammad Iqbal, V.D. Savarkar, Jawaharlal Nehru, \"and many others\". Spear voices appraisal of this \"solution of synthesis\", while G.R. Sharma emphasises the humanism of neo-Vedanta.\n\nVivekenanda's presentation of Advaita Vedanta has been criticised for its misinterpretation of this tradition:\nAccording to Anantanand Rambachan, Vivekananda emphasised \"anubhava\" (\"personal experience\") over scriptural authority, but in his interpretation of Shankara, deviated from Shankara, who saw knowledge and understanding of the scriptures as the primary means to moksha. According to Comans, the emphasis on samadhi also is not to be found in the Upanishads nor with Shankara. For Shankara, meditation and Nirvikalpa Samadhi are means to gain knowledge of the already existing unity of Brahman and Atman.\n\nIn the 21st century, Neo-Vedanta has been criticized by Hindu traditionalists for the influence of \"Radical Universalism\", arguing that it leads to a \"self-defeating philosophical relativism,\" and has weakened the status and strength of Hinduism.\n\nIn the 20th century the German Indologist used the terms \"Neo-Vedanta\" and \"Neo-Hinduism\" polemically, to criticize modern Hindu thinkers. Halbfass regards the terms \"Neo-Vedanta\" and \"Neo-Hinduism\" as \"useful and legitimate as convenient labels\", but has criticized Hacker for use that was \"simplistic\". Furthermore, he asks,\nHalbfass wrote that the adoption of the terms \nBagchee and Adluri argue that German Indology, including Hacker, was merely \"a barely disguised form of religious evangelism\".\n\nAccording to Malhotra, an Indian-American Hindu writer, it was Paul Hacker who popularized the term 'neo-Hinduism' in the 1950s, \"to refer to the modernization of Hinduism brought about by many Indian thinkers, the most prominent being Swami Vivekananda.\" In Malhotra's view, \"Hacker charged that 'neo-Hindus', most notably Vivekananda, have disingenuously adopted Western ideas and expressed them using Sanskrit.\" Malhotra also notes that Hacker was a biased Christian apologist: \nAccording to David Smith, Hacker's belief was that the ethical values of 'neo-Hinduism\" came from Western philosophy and Christianity, just in Hindu terms. Hacker also believed that Hinduism began in the 1870's. He saw Bankin Chattopadhyaya, Aruobindo, Gandhi, and Radhakishnan as its most famous proponents.\n\nBrian K. Smith notes that \"The Neo-Hindu indigenous authorities are often dismissed as 'inauthentic,' their claims to legitimacy compromised by their encounters with modernity\", which influenced their worldview and religious positions, but points out that \nAccording to Madaio, the notion that Vivekananda and other Hindu modernists deviate from orthodox, classical Advaita Vedanta, neglects the fact that considerable developments took place in Indian religious thinking, including Advaita Vedanta.\n\nRajiv Malhotra, in his book Indra's Net, has stated that there is a \"myth of Neo-Hinduism\". According to him, there are \"eight myths\" of Neo-Hinduism such as \"colonial Indology's biases were turned into Hinduism\" (Myth 2) and \"Hinduism was manufactured and did not grow organically\" (Myth 3). Malhotra denies that \"Vivekananda manufactured Hinduism\", or that `neo-Vedanta' suppressed \"the traditions of the Indian masses.\" According to Malhotra, there is \"an integrated, unified spiritual substratum in ancient India,\" and argues that\nAccording to Malhotra, the 'myth of neo-Hinduism' \"is used to fragment Hindu society by pitting its spiritual giants against one another and distorting their subtle and deeply intricate viewpoints.\" Also according to him, \"the definition of neo-Hinduism has been contrived and [...] gained authenticity, in part because it suits certain academic and political agendas, and in part because it has been reiterated extensively without adequate critical response.\"\n\n\n\nHistory\n\nCriticism\n"}
{"id": "22035894", "url": "https://en.wikipedia.org/wiki?curid=22035894", "title": "Paradox of analysis", "text": "Paradox of analysis\n\nThe paradox of analysis is a paradox that concerns how an analysis can be both correct and informative. Although the problem takes its origin from the conflict in Plato's \"Meno\", it was formulated in its complete form by philosopher G. E. Moore in his book \"Principia Ethica\", and first named by C. H. Langford in his 1942 article \"The Notion of Analysis in Moore's Philosophy\".\n\nA conceptual analysis is something like the definition of a word. However, unlike a standard dictionary definition (which may list examples or talk about related terms as well), a completely correct analysis of a concept in terms of others seems like it should have exactly the same meaning as the original concept. Thus, in order to be correct, the analysis should be able to be used in any context where the original concept is used, without changing the meaning of the discussion in context. Conceptual analyses of this sort are a major goal of analytic philosophy.\n\nHowever, if such an analysis is to be useful, it should be informative. That is, it should tell us something we don't already know (or at least, something one can imagine someone might not already know). But it seems that no conceptual analysis can both meet the requirement of correctness and of informativeness, on these understandings of the requirements.\n\nTo see why, consider a potential simple analysis:\n\nOne can say that (1) is correct because the expression \"brother\" represents the same concept as the expression \"male sibling,\" and (1) seems to be informative because the two expressions are not identical. And if (1) is truly correct, then \"brother\" and \"male sibling\" must be interchangeable:\n\nYet (2) is not informative, so either (1) is not informative, or the two expressions used in (1) are not interchangeable (because they change an informative analysis into an uninformative one) so (1) is not actually correct. In other words, if the analysis is correct and informative, then (1) and (2) must be essentially equal, but this is not true because (2) is not informative. Therefore, it seems an analysis cannot be both correct and informative at the same time.\n\nOne way to resolve this paradox is to redefine what is an analysis. In explaining the paradox, a potential analysis is assumed to be a relation between concepts rather than the verbal expressions used to illustrate them. If the verbal expression is part of the analysis, then we shouldn't expect complete intersubstitutivity even in cases of correct analyses. However, this response seems to move the notion of analysis into mere linguistic definition, rather than doing interesting work with concepts.\n\nAnother response is to bite the bullet and just say that correct analyses are uninformative — which then raises the question of what positive cognitive notion should be used instead of this one, if any.\n\nOne further response would be to take Willard Van Orman Quine's position and reject the notion of conceptual analysis altogether. This is a natural response to the rejection of the analytic–synthetic distinction. The fact that many philosophers have followed Quine in this direction is part of the reason that many now say that the term \"analytic philosophy\" is a misnomer.\n\n"}
{"id": "42631052", "url": "https://en.wikipedia.org/wiki?curid=42631052", "title": "Paul Weston (politician)", "text": "Paul Weston (politician)\n\nPaul Martin Laurence Weston (born 1965) is a British far-right politician and a member of the Pegida UK leadership team. An activist and blogger, Weston joined the UK Independence Party (UKIP) in 2010 and stood as a Parliamentary candidate for Cities of London and Westminster. In 2011, Weston left UKIP and joined the now-defunct British Freedom Party with members of the English Defence League (EDL) and former members of the British National Party (BNP). He was the chairman of Liberty GB before the party was dissolved in December 2017, recommending its members to join For Britain.\n\nFor Liberty GB, he was a candidate for South East England in the 2014 European election and for Luton South in the 2015 general election. He obtained 158 votes (0.4%).\n\nHe married a Romanian after meeting her in Romania. He was the President of the English branch of the International Free Press Society founded in 2009.\n\nWhen interviewed in 2010 as a member of UKIP, Weston described himself as a \"natural Conservative\" and described immigration as the \"ethnic cleansing of the English\". At the time Weston was standing as the UKIP candidate for Cities of London and Westminster in the UK general election of 2010. With a 1.8% share of the vote Weston finished in fifth place. The Conservative candidate, Mark Field, won the seat with 19,264 votes.\n\nSoon after leaving UKIP, in 2011 Weston became the chairman of the British Freedom Party (BFP) the same year after he had been asked to do so by the activists who had broken away from the BNP in October 2010 to found a new party. Over the years, Weston has attended and addressed numerous gatherings and rallies for such groups as Bloc Identitaire in France, Die Freiheit in Germany and the Jewish Defence League in Canada. As chairman of the BFP, Weston attended an international conference of counter-jihadists in September 2011. Yet in an interview, Weston cited a poll conducted by \"Searchlight\", which had found that 48% of the British public would support an anti-immigrant party, so long as the party did not take on explicitly fascist regalia and was non-violent, as evidence for an electoral basis for the BFP. This was in the midst of a crisis within the BNP and Weston held meetings with Andrew Brons, an MEP, and longstanding figure on the far-right, who was vying for the leadership of the party. Ultimately, Weston left the BFP saying, \"I joined the British Freedom Party in late 2011, but became disillusioned with the direction it was taking, over which I had little control.\"\n\nIn November 2012, the BFP officially announced that it had agreed to enter into a formal political alliance with the English Defence League. In October 2012, the party failed to hand-in its annual registration form and pay the fee of £25 and, in December of the same year, was deregistered by the Electoral Commission. The deregistration was statutory rather than voluntary. \"Searchlight\" speculated that Weston let the party's registration lapse because Jim Dowson of Britain First had initiated legal action against the BFP for defamation over claims made against Britain First's leadership on the BFP website.\n\nEarly on, the group was criticised as \"old fascist rubbish\" in an article by Sonia Gable published in \"Searchlight\". Gable ranked the group alongside the British Democratic Party, Britain First and the National Front. Weston responded and accused his critics at \"Searchlight\" of being \"a communist front operation disguised as an anti-fascist organisation\". Weston has characterized himself as an \"Islamo-realist\" and is against Muslim people being able to hold public office in the United Kingdom. He has made a video in which he says \"I am a racist\". In an interview, the BBC's Andrew Neil brought up the subject of this video and asked him, \"Do you regard yourself as a racist?\" Weston responded, \"No I don't, no.\" Weston explained that he was indignant about the gang rape that took place in Rotherham and Rochdale and the fact that people sometimes fear being labeled racist. He then said, \"If you watch the entire video, it is actually making the point that you cannot be quiet about what's going on because you're afraid of one word. It is better to speak out and be honest.\"\n\nThe other Liberty GB candidates in the South East England 2014 election were Enza Ferreri and Jack Buckby. In 2012, Buckby founded the \"National Culturists\" while at university in Liverpool. At the time, Buckby was a member of the BNP and received support from Nick Griffin after he and his group were prevented from advertising themselves at the freshers' fair by anti-fascist demonstrators. Buckby was later invited to speak at the Alliance of European National Movements and introduced by Griffin.\n\nAt the 2015 general election, Weston contested Luton South for Liberty GB and polled 158 votes (0.4%).\n\nOn 26 April 2014, Weston was arrested on the steps of the Winchester Guildhall for failing to comply with a dispersal notice issued under section 27 of the Violent Crime Reduction Act 2006 as he was reading out a passage from Winston Churchill's 1899 book \"The River War\" that is critical of Islam. He had been reported to the police by a member of the public after they had asked him if he had permission to give the speech and he replied that he did not. At the police station Weston was then rearrested for a racially aggravated offence under section 4 of the Public Order Act 1986, compounded with a Crime and Disorder Act 1998 section 31 racially aggravated public order offence, and was bailed to return to Winchester Police on 24 May.\n\nIn the days after, the story was picked up by news outlets. In \"The Telegraph\", Daniel Hannan, an MEP for South East England, whom Weston was running against at the time, asked: \"Why should it fall to me to defend him? Where are the lion-hearted liberals who are so quick to denounce political arrests in distant dictatorships? I realise that 'political arrest' is a strong phrase, but it's hard to think of any other way to describe a candidate for public office being taken into police custody because of objections to the content of his pitch.\"\n\nHampshire Police and Crime Commissioner Simon Hayes responded to the media coverage on the Hampshire Police and Crime Commission website:\n\nIt has been wrongly suggested that Mr Weston was arrested for reciting passages written by Winston Churchill. I understand he was not welcome outside the Winchester Guildhall, the Police were called and he was asked to move on. I also understand that he was not prepared to move on and was arrested for this reason.\n\nMembers of the public are of course at liberty to debate issues of importance to them in private or public spaces. However, there must be a level of decorum and decency.\n\nHampshire Constabulary has an obligation to ensure action is taken if decency or safety is put at risk and, if there is any reason to suspect they have intervened unnecessary , this will be investigated.\n\nAs far as I am aware, this is not so in this case. With the local and European elections coming up, it is important to register that there is a great deal of politically motivated spin going on at the moment which it is having a significant impact on local policing – both in terms of vital frontline rescourse and reputation.\n\nWeston promotes the white genocide conspiracy theory. He claimed white genocide is occurring in Britain, and has used the United Nations definition of genocide as proof of its existence.\n"}
{"id": "609194", "url": "https://en.wikipedia.org/wiki?curid=609194", "title": "Personality test", "text": "Personality test\n\nA personality test is a method of assessing human personality constructs. Most personality assessment instruments (despite being loosely referred to as \"personality tests\") are in fact introspective (i.e., subjective) self-report questionnaire (Q-data) measures or reports from life records (L-data) such as rating scales. Attempts to construct actual performance tests of personality have been very limited even though Raymond Cattell with his colleague Frank Warburton compiled a list of over 2000 separate objective tests that could be used in constructing objective personality tests. One exception however, was the Objective-Analytic Test Battery, a performance test designed to quantitatively measure 10 factor-analytically discerned personality trait dimensions. A major problem with both L-data and Q-data methods is that because of item transparency, rating scales and self-report questionnaires are highly susceptible to motivational and response distortion ranging all the way from lack of adequate self-insight (or biased perceptions of others) to downright dissimulation (faking good/faking bad) depending on the reason/motivation for the assessment being undertaken.\n\nThe first personality assessment measures were developed in the 1920s and were intended to ease the process of personnel selection, particularly in the armed forces. Since these early efforts, a wide variety of personality scales and questionnaires have been developed, including the Minnesota Multiphasic Personality Inventory (MMPI), the Sixteen Personality Factor Questionnaire (16PF), the Comrey Personality Scales (CPS), among many others. Although popular especially among personnel consultants, the Myers–Briggs Type Indicator (MBTI) has numerous psychometric deficiencies. More recently, a number of instruments based on the Five Factor Model of personality have been constructed such as the Revised NEO Personality Inventory. However, the Big Five and related Five Factor Model have been challenged for accounting for less than two-thirds of the known trait variance in the normal personality sphere alone.\n\nEstimates of how much the personality assessment industry in the US is worth range anywhere from $2 and $4 billion a year (as of 2013). Personality assessment is used in wide a range of contexts, including individual and relationship counseling, clinical psychology, forensic psychology, school psychology, career counseling, employment testing, occupational health and safety and customer relationship management.\n\nThe origins of personality assessment date back to the 18th and 19th centuries, when personality was assessed through phrenology, the measurement of bumps on the human skull, and physiognomy, which assessed personality based on a person's outer appearances. Sir Francis Galton took another approach to assessing personality late in the 19th century. Based on the lexical hypothesis, Galton estimated the number of adjectives that described personality in the English dictionary Galton's list was eventually refined by Louis Leon Thurstone to 60 words that were commonly used for describing personality at the time. Through factor analyzing responses from 1300 participants, Thurstone was able to reduce this severely restricted pool of 60 adjectives into seven common factors. This procedure of factor analyzing common adjectives was later utilized by Raymond Cattell (7th most highly cited psychologist of the 20th Century—based on the peer-reviewed journal literature), who subsequently utilized a data set of over 4000 affect terms from the English dictionary that eventually resulted in construction of the Sixteen Personality Factor Questionnaire (16PF) which also measured up to eight second-stratum personality factors. Of the many introspective (ie. subjective) self-report instruments constructed to measure the putative Big Five personality dimensions, perhaps the most popular has been the Revised NEO Personality Inventory (NEO-PI-R) However, it should be noted that the psychometric properties of the NEO-PI-R (including its factor analytic/construct validity) has been severely criticized.\n\nAnother early personality instrument was the Woodworth Personal Data Sheet, a self-report inventory developed for World War I and used for the psychiatric screening of new draftees.\n\nThere are many different types of personality assessment measures. The self-report inventory involves administration of many items requiring respondents to introspectively assess their own personality characteristics. This is highly subjective, and because of item transparency, such Q-data measures are highly susceptible to motivational and response distortion. Respondents are required to indicate their level of agreement with each item using a Likert scale or, more accurately, a Likert-type scale. An item on a personality questionnaire, for example, might ask respondents to rate the degree to which they agree with the statement \"I talk to a lot of different people at parties\" on a scale from 1 (\"strongly disagree\") to 5 (\"strongly agree\").\n\nHistorically, the most widely used multidimensional personality instrument is the Minnesota Multiphasic Personality Inventory (MMPI), a psychopathology instrument originally designed to assess archaic psychiatric nosology.\n\nIn addition to subjective/introspective self-report inventories, there are several other methods for assessing human personality, including observational measures, ratings of others, projective tests (e.g., the TAT and Ink Blots), and actual objective performance tests (T-data).\n\nThe meaning of \"personality test\" scores are difficult to interpret in a direct sense. For this reason substantial effort is made by producers of personality tests to produce norms to provide a comparative basis for interpreting a respondent's test scores. Common formats for these norms include percentile ranks, z scores, sten scores, and other forms of standardised scores.\n\nA substantial amount of research and thinking has gone into the topic of \"personality test\" development. Development of personality tests tends to be an iterative process whereby a test is progressively refined. Test development can proceed on theoretical or statistical grounds. There are three commonly used general strategies: Inductive, Deductive, and Empirical. Scales created today will often incorporate elements of all three methods.\n\nDeductive assessment construction begins by selecting a domain or construct to measure. The construct is thoroughly defined by experts and items are created which fully represent all the attributes of the construct definition. Test items are then selected or eliminated based upon which will result in the strongest internal validity for the scale. Measures created through deductive methodology are equally valid and take significantly less time to construct compared to inductive and empirical measures. The clearly defined and face valid questions that result from this process make them easy for the person taking the assessment to understand. Although subtle items can be created through the deductive process, these measure often are not as capable of detecting lying as other methods of personality assessment construction.\n\nInductive assessment construction begins with the creation of a multitude of diverse items.The items created for an inductive measure to not intended to represent any theory or construct in particular. Once the items have been created they are administered to a large group of participants. This allows researchers to analyze natural relationships among the questions and label components of the scale based upon how the questions group together. Several statistical techniques can be used to determine the constructs assessed by the measure. Exploratory Factor Analysis and Confirmatory Factor Analysis are two of the most common data reduction techniques that allow researchers to create scales from responses on the initial items.\n\nThe Five Factor Model of personality was developed using this method. Advanced statistical methods include the opportunity to discover previously unidentified or unexpected relationships between items or constructs. It also may allow for the development of subtle items that prevent test takers from knowing what is being measured and may represent the actual structure of a construct better than a pre-developed theory. Criticisms include a vulnerability to finding item relationships that do not apply to a broader population, difficulty identifying what may be measured in each component because of confusing item relationships, or constructs that were not fully addressed by the originally created questions.\n\nEmpirically derived personality assessments require statistical techniques. One of the central goals of empirical personality assessment is to create a test that validly discriminates between two distinct dimensions of personality. Empirical tests can take a great deal of time to construct. In order to ensure that the test is measuring what it is purported to measure, psychologists first collect data through self- or observer reports, ideally from a large number of participants.\n\nA personality test can be administered directly to the person being evaluated or to an observer. In a self-report, the individual responds to personality items as they pertain to the person himself/herself. Self-reports are commonly used. In an observer-report, a person responds to the personality items as those items pertain to someone else. To produce the most accurate results, the observer needs to know the individual being evaluated. Combining the scores of a self-report and an observer report can reduce error, providing a more accurate depiction of the person being evaluated. Self- and observer-reports tend to yield similar results, supporting their validity.\n\nDirect observation involves a second party directly observing and evaluating someone else. The second party observes how the target of the observation behaves in certain situations (e.g., how a child behaves in a schoolyard during recess). The observations can take place in a natural (e.g., a schoolyard) or artificial setting (social psychology laboratory). Direct observation can help identify job applicants (e.g., work samples) who are likely to be successful or maternal attachment in young children (e.g., Mary Ainsworth's strange situation). The object of the method is to directly observe \"genuine\" behaviors in the target. A limitation of direct observation is that the target persons may change their behavior because they know that they are being observed. A second limitation is that some behavioral traits are more difficult to observe (e.g., sincerity) than others (e.g., sociability). A third limitation is that direct observation is more expensive and time consuming than a number of other methods (e.g., self-report).\n\nPersonality tests can predict something about how a job applicant will act in some workplace situations. Conscientiousness is one of the big five personality traits. A person is high in conscientiousness will ordinarily be less likely to commit crimes (e.g., stealing property) against the employer. People who are higher in the agreeableness trait tend to be less likely to fight or argue with other employees. There is a chance that an applicant may fake responses to personality test items in order to make the applicant appear more attractive to the employing organization than the individual actually is.\n\nThere are several criteria for evaluating a \"personality test\". For a test to be successful, users need to be sure that (a) test results are replicable and (b) the test measures what its creators purport it to measure. Fundamentally, a \"personality test\" is expected to demonstrate reliability and validity. Reliability refers to the extent to which test scores, if a test were administered to a sample twice within a short period of time, would be similar in both administrations. Test validity refers to evidence that a test measures the construct (e.g., neuroticism) that it is supposed to measure.\n\nA respondent's response is used to compute the analysis. Analysis of data is a long process. Two major theories are used here; Classical test theory (CTT)- used for the observed score, and item response theory (IRT)- \"a family of models for persons' responses to items\". The two theories focus upon different 'levels' of responses and researchers are implored to use both in order to fully appreciate their results.\n\nFirstly, item non-response needs to be addressed. Non-response can either be 'unit'- where a person gave no response for any of the n items, or 'item'- i.e., individual question. Unit non-response is generally dealt with exclusion. Item non-response should be handled by imputation- the method used can vary between test and questionnaire items. Literature about the most appropriate method to use and when can be found here.\n\nThe conventional method of scoring items is to assign '0' for an incorrect answer '1' for a correct answer. When tests have more response options (e.g. multiple choice items) '0' when incorrect, '1' for being partly correct and '2' for being correct. Personality tests can also be scored using a dimensional (normative) or a typological (ipsative) approach. Dimensional approaches such as the Big 5 describe personality as a set of continuous dimensions on which individuals differ. From the item scores, an 'observed' score is computed. This is generally found by summing the un-weighted item scores.\n\nOne problem of a personality test is that the users of the test could only find it accurate because of the subjective validation involved. Users of personality tests have to assume that the subjective responses that are given by participants on such tests, represent the actual personality of those participants. Also, one must assume that personality is a reliable, constant part of the human mind or behaviour.\n\nIn the 60s and 70s some psychologists dismissed the whole idea of personality, considering much behaviour to be context-specific. This idea was supported by the fact that personality often does not predict behaviour in specific contexts. However, more extensive research has shown that when behaviour is aggregated across contexts, that personality can be a modest to good predictor of behaviour. Almost all psychologists now acknowledge that both social and individual difference factors (i.e., personality) influence behaviour. The debate is currently more around the relative importance of each of these factors and how these factors interact.\n\nOne problem with self-report measures of personality is that respondents are often able to distort their responses. Emotive tests in particular could in theory become prey to unreliable results due to people striving to pick the answer they feel the best fitting of an ideal character and therefore not their true response. This is particularly problematic in employment contexts and other contexts where important decisions are being made and there is an incentive to present oneself in a favourable manner.\n\nWork in experimental settings has also shown that when student samples have been asked to deliberately fake on a personality test, they clearly demonstrated that they are capable of doing so.\nHogan, Barett and Hogan (2007) analyzed data of 5,266 applicants who did a personality test based on the big five. At the first application the applicants were rejected. After six months the applicants reapplied and completed the same personality test. The answers on the personality tests were compared and there was no significant difference between the answers.\n\nSo in practice, most people do not significantly distort. Nevertheless, a researcher has to be prepared for such possibilities. Also, sometimes participants think that tests results are more valid than they really are because they like the results that they get. People want to believe that the positive traits that the test results say they possess are in fact present in their personality. This leads to distorted results of people's sentiments on the validity of such tests.\n\nSeveral strategies have been adopted for reducing respondent faking. One strategy involves providing a warning on the test that methods exist for detecting faking and that detection will result in negative consequences for the respondent (e.g., not being considered for the job). Forced choice item formats (ipsative testing) have been adopted which require respondents to choose between alternatives of equal social desirability. Social desirability and lie scales are often included which detect certain patterns of responses, although these are often confounded by true variability in social desirability.\n\nMore recently, Item Response Theory approaches have been adopted with some success in identifying item response profiles that flag fakers. Other researchers are looking at the timing of responses on electronically administered tests to assess faking. While people can fake in practice they seldom do so to any significant level. To successfully fake means knowing what the ideal answer would be. Even with something as simple as assertiveness people who are unassertive and try to appear assertive often endorse the wrong items. This is because unassertive people confuse assertion with aggression, anger, oppositional behavior, etc.\n\nResearch on the importance of personality and intelligence in education shows evidence that when others provide the personality rating, rather than providing a self-rating, the outcome is nearly four times more accurate for predicting grades.\n\nA study by American Management Association reveals that 39 percent of companies surveyed use personality testing as part of their hiring process. However, ipsative personality tests are often misused in recruitment and selection, where they are mistakenly treated as if they were normative measures.\n\nMore people are using personality testing to evaluate their business partners, their dates and their spouses. Salespeople are using personality testing to better understand the needs of their customers and to gain a competitive edge in the closing of deals. College students have started to use personality testing to evaluate their roommates. Lawyers are beginning to use personality testing for criminal behavior analysis, litigation profiling, witness examination and jury selection.\n\nPersonality tests have been around for a long time, but it wasn't until it became illegal for employers to use polygraphs that we began to see the widespread use of personality tests. The idea behind these personality tests is that employers can reduce their turnover rates and prevent economic losses in the form of people prone to thievery, drug abuse, emotional disorders or violence in the workplace.\n\nEmployers may also view personality tests as more accurate assessment of a candidate's behavioral characteristics versus an employment reference. But the problem with using personality tests as a hiring tool is the notion a person's job performance in one environment will carry over to another work environment. However, the reality is that one's environment plays a crucial role in determining job performance, and not all environments are created equally. One danger of using personality tests is the results may be skewed based on a person's mood so good candidates may potentially be screened out because of unfavorable responses that reflect that mood.\n\nAnother danger of personality tests is that they can create false-negative results (i.e. honest people being labeled as dishonest) especially in cases when stress on the applicant's part is involved. There is also the issue of privacy to be of concern forcing applicants to reveal private thoughts and feelings through his or her responses that seem to become a condition for employment. Another danger of personality tests is the illegal discrimination of certain groups under the guise of a personality test.\n\n\nDifferent types of the Big Five personality traits:\n\n"}
{"id": "958627", "url": "https://en.wikipedia.org/wiki?curid=958627", "title": "Persuasive definition", "text": "Persuasive definition\n\nA persuasive definition is a form of stipulative definition which purports to describe the 'true' or 'commonly accepted' meaning of a term, while in reality stipulating an uncommon or altered use, usually to support an argument for some view, or to create or alter rights, duties or crimes.\nThe terms thus defined will often involve emotionally charged but imprecise notions, such as \"freedom\", \"terrorism\", \"democracy\", etc. In argumentation the use of a persuasive definition is sometimes called \"definist fallacy\". (The latter sometimes more broadly refers to a fallacy of a definition based on improper identification of two distinct properties.)\nExamples of persuasive definitions (definist fallacies) include: \n\nPersuasive definitions commonly appear in controversial topics such as politics, sex, and religion, as participants in emotionally charged exchanges will sometimes become more concerned about swaying people to one side or another than expressing the unbiased facts. A persuasive definition of a term is favorable to one argument or unfavorable to the other argument, but is presented as if it were neutral and well-accepted, and the listener is expected to accept such a definition without question.\n\nThe term \"persuasive definition\" was introduced by philosopher C.L. Stevenson as part of his emotive theory of meaning.\n\nLanguage can simultaneously communicate information (informative) and feelings (expressive). Unlike other common types of definitions in logic, persuasive definitions focus on the expressive use of language to affect the feelings of readers and listeners ultimately with an aim to change their behavior. With this fundamentally different purpose, persuasive definitions are evaluated not on their truth or falsehood but rather on their effectiveness as a persuasive device. \nStevenson showed how these two dimensions are combined when he investigated the terms he called \"ethical\" or emotive. He noted that some words, such as 'peace' or 'war', are not simply used to describe reality by modifying the cognitive response of the interlocutor. They have also the power of directing the interlocutor's attitudes and suggesting a course of action. For this reason, they evoke a different kind of reaction, emotive in nature. As Stevenson put it \"Instead of merely describing people's interests, they change and intensify them. They recommend an interest in an object, rather than state that the interest already exists.\" These words have the tendency to encourage future actions, to lead the hearer towards a decision by affecting his or her system of interests. Stevenson distinguished between the use of a word (a stimulus) and its possible psychological effects on the addressee's cognitive and the emotive reactions by labeling them as \"descriptive meaning\" and \"emotive meaning\". Applying this distinction reveals how the redefinition of an ethical word is transformed into an instrument of persuasion, a tool for redirecting preferences and emotions:\n\nIn persuasive definitions the evaluative component associated with a concept is left unaltered while the descriptive meaning is modified. In this fashion, imprisonment can become \"true freedom\", and massacres \"pacification\". Persuasive definitions can change or distort the meaning while keeping the original evaluations that the use of a word evokes. Quasi-definitions consist in the modification of the emotive meaning of a word without altering the descriptive one. The speaker can quasi-define a word by qualifying the \"definiendum\" without setting forth what the term actually means. For instance, we can consider the following quasi-definition taken from Casanova's Fuga dai Piombi. In this example (1), the speaker, Mr. Soradaci, tries to convince his interlocutor (Casanova) that being a \"sneak\" is an honorable behavior:\n\nThis quasi-definition employed in case 1 underscores a fundamental dimension of the \"emotive\" meaning of a word, namely its relationship with the shared values, which are attacked as \"prejudices.\" This account given by the spy shows how describing the referent based on a different hierarchy of values can modify emotive meaning. The value of trust is not denied, but is placed in a hierarchy where the highest worth is given to the State.Stevenson provides us with two definitions of the word culture in order to illustrate what a persuasive definition can accomplish:\n\nBoth carry with them the positive emotive meaning of culture; it is still a good thing to be cultured no matter which definition is used. What they change is what exactly it means to be called \"cultured.\" Because being cultured is a positive trait, the society views being well read and acquainted with the arts as positive traits to have. By promoting a persuasive definition of \"imaginative sensitivity\" the society begins to views those qualities positively because they are attached to a word with a positive emotive meaning.\n\nUnclear, figurative language is often used in persuasive definitions. Although several techniques can be used to form such a definition, the genus and difference technique is the usual one applied. Both definitions in the taxation example above agree that the genus is a procedure relating to governance but disagree on the difference. Persuasive definitions combine elements of stipulative definitions, lexical definitions, and sometimes theoretical definitions.\n\nPersuasive definitions commonly appear in political speeches, editorials and other situations where the power to influence is most in demand. They have been dismissed as serving only to confuse readers and listeners without legitimate purpose. Critical scrutiny is often necessary to identify persuasive definitions in an argument as they are meant to appear as honest definitions.\n\n\n"}
{"id": "30711679", "url": "https://en.wikipedia.org/wiki?curid=30711679", "title": "Population fragmentation", "text": "Population fragmentation\n\nPopulation fragmentation is a form of population segregation. It is often caused by habitat fragmentation. \n\nFragmentation can be natural or caused by human actions. In modern times, human activity is the most common cause.\n\nPopulation fragmentation causes inbreeding depression, which leads to a decrease in genetic variability in the species involved. This decreases the fitness of the population for several reasons. First, inbreeding forces competition with relatives, which decreases the evolutionary fitness of the species. Secondly, the decrease in genetic variability causes an increased possibility a lethal homozygous recessive trait may be expressed; this decreases the average litter size reproduced, indirectly decreasing the population. When a population is small, the influence of genetic drift increases, which leads to less and/or random fixation of alleles. In turn, this leads to increased homozygosity, negatively affecting individual fitness. The performance of plants may be compromised by less effective selection which causes an accumulation of deleterious mutations in small populations. Since individuals in small populations are more likely to be related, they are more likely to inbreed. A reduction in fitness may occur in small plant populations because of mutation accumulation, reduced genetic diversity, and increased inbreeding. Over time, the evolutionary potential and a species’s ability to adapt to a changing environment, such as climate change, is decreased.\n\n"}
{"id": "3758730", "url": "https://en.wikipedia.org/wiki?curid=3758730", "title": "Privacy software", "text": "Privacy software\n\nPrivacy software is software built to protect the privacy of its users. The software typically works in conjunction with Internet usage to control or limit the amount of information made available to third parties. The software can apply encryption or filtering of various kinds.\n\nPrivacy software can refer to two different types of protection. One type is protecting a user's Internet privacy from the World Wide Web. There are software products that will mask or hide a user's IP address from the outside world in order to protect the user from identity theft. The second type of protection is hiding or deleting the users Internet traces that are left on their PC after they have been surfing the Internet. There is software that will erase all the users Internet traces and there is software that will hide and encrypt a user's traces so that others using their PC will not know where they have been surfing.\n\nOne solution to enhance privacy software is whitelisting. Whitelisting is a process in which a company identifies the software that it will allow to and does not try to recognize malware. Whitelisting permits acceptable software to run and either prevents anything else from running or lets new software run in a quarantined environment until the can verify its validity. Whereas whitelisting allows nothing to run unless it is on the whitelist, blacklisting allows everything to run unless it is on the black. A blacklist then includes certain types of software that are not allowed to run in the company environment. For example, a company might blacklist peer-to-peer file sharing on its systems. In addition to software, people, devices, and web sites can also be whitelisted or blacklisted.\n\nIntrusion detection systems are designed to detect all types of malicious network traffic and computer usage that cannot be detected by a firewall. These systems capture all network traffic flows and examine the contents of each packet for malicious traffic.\n\nEncryption is another form for privacy security. When organizations do not have secure channel for sending information, they use encryption to stop unauthorized eavesdroppers. Encryption is the process of converting an original message into a form that cannot be read by anyone except the intended receiver.\n\nSteganography is sometimes used to hide messages from eavesdropping and e-surveillance.\n\nPrivacy is different from anonymity in its applicability and usage. Anonymity is subordinate to privacy and might be desired for the exchange, retrieval or publication of specific information.\n\nUses of privacy software are not free from legal issues. For instance, there are regulations for export of cryptography from the United States. Similarly, key disclosure law also requires individuals to surrender cryptographic keys to law enforcement agencies. Encryption laws in India also carry many legal restrictions in diverse situations.<ref name=\"http://perry4law.co.in/blog/?p=67\"></ref> Talks are also in pipeline to include cyber security technologies, like encryption related software, under the Wassenaar Arrangement thereby making its export more cumbersome.<ref name=\"http://perry4law.co.in/cyber_security/?p=61\"></ref>\n\n\n\n"}
{"id": "4137557", "url": "https://en.wikipedia.org/wiki?curid=4137557", "title": "Pyeong", "text": "Pyeong\n\nA pyeong (abbreviationpy) is a Korean unit of area and floorspace, equal to a square \"kan\" or 36square Korean feet. The ping and tsubo are its equivalent Chinese and Japanese units, similarly based on a square \"bu\" () or \"ken\", equivalent to 36square Chinese or Japanese feet.\n\nIn Korea, the period of Japanese occupation produced a \"pyeong\" of or 3.3058m. It is the standard traditional measure for real estate floorspace, with an average house reckoned as about 25\"pyeong\", a studio apartment as 8–12py, and a garret as 1½py. In South Korea, the unit has been officially banned since 1961 but with little effect prior to the criminalization of its commercial use effective 1 July 2007. Informal use continues, however, including in the form of real estate use of unusual fractions of meters equivalent to unit amounts of \"pyeong\".\n\nIn Taiwan, the Taiwanese \"ping\" remains in fairly common use and is about 3.306m. In mainland China, the metrification of traditional units would produce a \"ping\" of 4m, but it is almost unknown with most real estate floorspace simply reckoned in square meters. The longer length of the Hong Kong foot produces a larger \"ping\" of almost 5m, but it is similarly uncommon.\n\nIn Japan, the usual measure of real estate floorspace is the \"tatami\" and the \"tsubo\" is reckoned as two \"tatami\". The \"tatami\" varies by region but the modern standard is usually taken to be the Nagoya \"tatami\" of about 1.653m, producing a \"tsubo\" of 3.306m. It is sometimes reckoned as comprising 10gō.\n\n"}
{"id": "18861519", "url": "https://en.wikipedia.org/wiki?curid=18861519", "title": "Redress (charitable organisation)", "text": "Redress (charitable organisation)\n\nRedress, or The Redress Trust is a human rights organisation based in London, England, that helps survivors of torture to obtain justice and reparation, in the form of compensation, rehabilitation, official acknowledgement of the wrong and formal apologies. In addition Redress seek accountability for those who have been tortured.\n\nRedress provides legal and related support in obtaining legal reparations, promote survivors' rights in international and regional courts and tribunals and promotes survivors’ rights in national policy and practice contexts in the United Kingdom.\n\nIn 2008 Redress was addressing torture and related crimes in more than 50 countries in all regions or the world and having over 50 active case files relating to more than 957 survivors.\n\nRedress was founded in 1992 by Keith Carmichael, a British torture survivor who sought justice for how he had been treated while a prisoner in Saudi Arabia from November 1981 until March 1984. After his release, Carmichael found that while the existing non-governmental organizations advocated for the release of prisoners, provided medical attention, and operated safe havens, none existed to seek reparations under international law. Redress was founded to fill that gap.\n\n\nRedress pursues its mission through legal assistance and advice to torture survivors, their families and communities, sharing information and support in partnership with other organizations around the world and advocacy by providing information to governments, other organizations and the media.\n\nRedress is supported by the United Nations, the European Commission, Oxfam, the Joseph Rowntree Charitable Trust, UK Department for International Development DFID, Bromley Trust, John D. and Catherine T. MacArthur Foundation, Oak Foundation, City Parochial Foundation.\n\n\n"}
{"id": "2120001", "url": "https://en.wikipedia.org/wiki?curid=2120001", "title": "Retract", "text": "Retract\n\nIn topology, a branch of mathematics, a retraction is a continuous mapping from a topological space into a subspace which preserves the position of all points in that subspace. A deformation retraction is a mapping which captures the idea of \"continuously shrinking\" a space into a subspace.\n\nAn absolute neighborhood retract (ANR) is a particularly well-behaved type of topological space. For example, every topological manifold is an ANR. Every ANR has the homotopy type of a very simple topological space, a CW complex.\n\nLet \"X\" be a topological space and \"A\" a subspace of \"X\". Then a continuous map\n\nis a retraction if the restriction of \"r\" to \"A\" is the identity map on \"A\"; that is, formula_2 for all \"a\" in \"A\". Equivalently, denoting by\n\nthe inclusion, a retraction is a continuous map \"r\" such that\nthat is, the composition of \"r\" with the inclusion is the identity of \"A\". Note that, by definition, a retraction maps \"X\" onto \"A\". A subspace \"A\" is called a retract of \"X\" if such a retraction exists. For instance, any non-empty space retracts to a point in the obvious way (the constant map yields a retraction). If \"X\" is Hausdorff, then \"A\" must be a closed subset of \"X\".\n\nIf formula_5 is a retraction, then the composition ι∘\"r\" is an idempotent continuous map from \"X\" to \"X\". Conversely, given any idempotent continuous map formula_6 we obtain a retraction onto the image of \"s\" by restricting the codomain.\n\nA continuous map\nis a \"deformation retraction\" of a space \"X\" onto a subspace \"A\" if, for every \"x\" in \"X\" and \"a\" in \"A\",\nIn other words, a deformation retraction is a homotopy between a retraction and the identity map on \"X\". The subspace \"A\" is called a deformation retract of \"X\". A deformation retraction is a special case of a homotopy equivalence.\n\nA retract need not be a deformation retract. For instance, having a single point as a deformation retract of a space \"X\" would imply that \"X\" is path connected (and in fact that \"X\" is contractible).\n\n\"Note:\" An equivalent definition of deformation retraction is the following. A continuous map formula_5 is a deformation retraction if it is a retraction and its composition with the inclusion is homotopic to the identity map on \"X\". In this formulation, a deformation retraction carries with it a homotopy between the identity map on \"X\" and itself.\n\nIf, in the definition of a deformation retraction, we add the requirement that\nfor all \"t\" in [0, 1] and \"a\" in \"A\", then \"F\" is called a strong deformation retraction. In other words, a strong deformation retraction leaves points in \"A\" fixed throughout the homotopy. (Some authors, such as Hatcher, take this as the definition of deformation retraction.)\n\nAs an example, the \"n\"-sphere \"formula_11\" is a strong deformation retract of formula_12 as strong deformation retraction one can choose the map \n\nA map \"f\": \"A\" → \"X\" of topological spaces is a (Hurewicz) cofibration if it has the homotopy extension property for maps to any space. This is one of the central concepts of homotopy theory. A cofibration \"f\" is always injective, in fact a homeomorphism to its image. If \"X\" is Hausdorff (or a compactly generated weak Hausdorff space), then the image of a cofibration \"f\" is closed in \"X\".\n\nAmong all closed inclusions, cofibrations can be characterized as follows. The inclusion of a closed subspace \"A\" in a space \"X\" is a cofibration if and only if \"A\" is a neighborhood deformation retract of \"X\", meaning that there is a continuous map formula_14 (where formula_15) with formula_16 and a homotopy formula_17such that formula_18formula_19and formula_20.\n\nFor example, the inclusion of a subcomplex in a CW complex is a cofibration.\n\n\nThe boundary of the \"n\"-dimensional ball, that is, the (\"n\"−1)-sphere, is not a retract of the ball. (See .)\n\nA closed subset formula_25 of a topological space formula_26 is called a neighborhood retract of formula_26 if formula_25 is a retract of some open subset of formula_26 that contains formula_25.\n\nLet formula_31 be a class of topological spaces, closed under homeomorphisms and passage to closed subsets. Following Borsuk (starting in 1931), a space \"formula_25\" is called an absolute retract for the class formula_31, written formula_34 if \"formula_25\" is in formula_31 and whenever \"formula_25\" is a closed subset of a space formula_26in formula_31, formula_25 is a retract of formula_26. A space formula_25 is an absolute neighborhood retract for the class formula_31, written formula_44 if formula_25 is in formula_31 and whenever formula_25 is a closed subset of a space formula_26 in formula_31, formula_25 is a neighborhood retract of formula_26.\n\nVarious classes formula_31 such as normal spaces have been considered in this definition, but the class formula_53 of metrizable spaces has been found to give the most satisfactory theory. For that reason, the notations AR and ANR by themselves are used in this article to mean formula_54 and formula_55.\n\nA metrizable space is an AR if and only if it is contractible and an ANR. By Dugundji, every locally convex metrizable topological vector space formula_56 is an AR; more generally, every nonempty convex subset of such a vector space formula_56 is an AR. For example, any normed vector space (complete or not) is an AR. More concretely, Euclidean space formula_58 the unit cube formula_59and the Hilbert cube formula_60 are ARs.\n\nANRs form a remarkable class of \"well-behaved\" topological spaces. Among their properties are:\n\n"}
{"id": "17173550", "url": "https://en.wikipedia.org/wiki?curid=17173550", "title": "Self-categorization theory", "text": "Self-categorization theory\n\nSelf-categorization theory is a theory in social psychology that describes the circumstances under which a person will perceive collections of people (including themselves) as a group, as well as the consequences of perceiving people in group terms. Although the theory is often introduced as an explanation of psychological group formation (which was one of its early goals), it is more accurately thought of as general analysis of the functioning of categorization processes in social perception and interaction that speaks to issues of individual identity as much as group phenomena. It was developed by John Turner and colleagues, and along with social identity theory it is a constituent part of the social identity approach. It was in part developed to address questions that arose in response to social identity theory about the mechanistic underpinnings of social identification.\n\nSelf-categorization theory has been influential in the academic field of social psychology and beyond. It was first applied to the topics of social influence, group cohesion, group polarization, and collective action. In subsequent years the theory, often as part of the social identity approach, has been applied to further topics such as leadership, personality, outgroup homogeneity, and power. One tenet of the theory is that the self should not be considered as a foundational aspect of cognition, but rather the self should be seen as a product of the cognitive system at work.\n\nDrawing inspiration from cognitive psychology, self-categorization theory assumes that the self can be categorized at various levels of abstraction. In other words, humans may categorize the self as a singular “I”(personal identity), or as a more inclusive “we”(social identity). In the latter case the self is cognitively grouped as identical and interchangeable to other stimuli within that category. It is argued that it is this variation in self categorization that underpins many intergroup phenomenon, including those described in social identity theory.\n\nTo demonstrate the notion of varying levels of abstraction and inclusiveness, three types of self category are often given as examples. The lowest level of abstraction is given as a personal self, where the perceiver self categorizes as “I”. A higher level of abstraction corresponds to a social self, where the perceiver self categorizes as “we” in comparison to a salient outgroup (them). A highest level of abstraction is represented by \"we humans\", where the salient outgroup is animals or other non-humans. A common misconception is that these three example categories represent \"the\" self categories that humans use. Instead, the theory posits that there are innumerable self categories that a perceiver may use (see, online category formation), and in particular that there are a myriad of different personal and social identities that a perceiver may invoke in his or her day-to-day life. The misconception may also be attributable to the early writing of Turner where a singular social identity was contrasted against a singular personal identity. This however predates the formal statement of self-categorization theory.\n\nIn self-categorization theory, categorizing people does not simply involve the redescription of characteristics and categories present in social stimuli. Rather, salient \"social categories\" form the basis of a social world that is enriched with meaning. This is achieved through a non-conscious process of accentuation, where \"differences between\" social categories are accentuated along with the \"similarities within\" social categories. The resulting augmentation of social content allows the perceiver to interact with others with greater confidence and ease.\n\nThe accentuation component of self-categorization theory stems from prior research that demonstrated an accentuation effect for categorized non-social stimuli. A prototypical example of non-social accentuation came from Tajfel and Wilkes, who found that when a categorization scheme corresponded to line length participants would view lines belonging to different categories as more different than if no categorization scheme was present. Consistent with the idea that an efficient cognitive system would, where possible, use the same systems regardless of the social or non-social nature of the stimuli, self-categorization theorists have demonstrated similar effects for social stimuli. For example, Haslam and Turner found that a perceiver would describe another person as more or less similar to themselves as a function of the likely categorization scheme.\n\nAccording to self-categorization theory, depersonalization describes a process of self-stereotyping. This is where, under conditions of social category salience and consequent accentuation, “people come to see themselves more as the interchangeable exemplars of a social category than as unique personalities defined by their differences from others”. Under these conditions a perceiver directly bases their behaviour and beliefs on the norms, goals and needs of a salient ingroup. For example, if a person's salient self-category becomes 'army officer' then that person is more likely to act in terms of the norms associated with that category (e.g. to wear a uniform, follow orders, and distrust an enemy) and less likely to act in terms of other potential self-categories. Here the person can be said to be accentuating the similarities between his or herself and other members of the 'army officers' category.\n\nTurner and colleagues stress that depersonalization is not a loss of self, but rather a \"redefinition\" of the self in terms of group membership. A depersonalized self, or a social identity, is every bit as valid and meaningful as a personalized self, or personal identity. A loss of self is sometimes referred to using the alternative term deindividuation. Further, although the term depersonalization has been used in clinical psychology to describe a type of disordered experience, this is completely different from depersonalization in the sense intended by self-categorization theory authors.\n\nThe concept of depersonalization is critical to a range of group phenomena including social influence, social stereotyping, in-group cohesiveness, ethnocentrism, intragroup cooperation, altruism, emotional empathy, and the emergence of social norms.\n\nIn self-categorization theory the formation and use of a social category in a certain context is predicted by an interaction between perceiver readiness and category-stimulus fit. The latter being broken down into comparative fit and normative fit. This predictive interaction was heavily influenced by Bruner’s accessibility and fit formula. A social category that is currently in use is called a \"salient\" social category, and in the case of a self category is called a \"salient social identity\". The latter should not be confused with \"level of identification\", which is a component of perceiver readiness.\n\nPerceiver readiness, which Turner first described as \"relative accessibility\", “reflects a person’s past experiences, present expectations, and current motives, values, goals and needs”. It is the relevant aspects of cognition that the perceiver brings to the environment. For example, a perceiver who categorizes frequently on the basis of nationality (e.g., “we Americans”) is, due to that past experience, more likely to formulate a similar self category under new conditions. Accordingly, \"social identification\", or the degree to which the group is valued and self-involving, may be thought of as an important factor that affects a person’s readiness to use a particular social category.\n\nComparative fit is determined by the meta-contrast principle—which states that people are more likely to believe that a collection of stimuli represents an entity to the degree that the differences between those stimuli are less than the differences between that collection of stimuli and other stimuli. For predicting whether a group will categorize an individual as an ingroup or outgroup member, the meta-contrast principle may be defined as the ratio of the average similarity of the individual to outgroup members over the average similarity of the individual to ingroup members. The meta-contrast ratio is dependent on the context, or frame of reference, in which the categorization process is occurring. That is, the ratio is a comparison based on whichever stimuli are cognitively present. For example, if the frame of reference is reduced such that potential outgroup members are no longer cognitively present, ingroup members regard the individual as less similar to the group and are less likely to categorize that individual as belonging to that group.\n\nNormative fit is the extent that the perceived behaviour or attributes of an individual or collection of individuals conforms to the perceiver’s knowledge-based expectations. Thus, normative fit is evaluated with reference to the \"perceiver readiness\" component of the categorisation process. As an example of the role of normative fit in categorization, although a collection of individuals may be categorized as an entity on the basis of \"comparative fit\", they are only labelled using the specific social category of “science students” if perceived as hard working. That is, they fit the normative content of that category.\n\nSelf-categorization theorists posit “self-categorization is comparative, inherently variable, fluid and context dependent.” They reject the notion that self concepts are stored invariant structures that exist ready for application. Where stability is observed in self perception this is not attributed to stored stable categories, but rather to stability in both the perceiver and the social context in which the perceiver is situated. This variability is systematic and occurs in response to the changing context in which the perceiver is situated. As an example, the category of psychologists can be perceived quite differently if compared to physicists as opposed to artists (with variation perhaps on how scientific psychologists are perceived to be). In self-categorization theory contextual changes to the salient social category are sometimes referred to as shifting prototypicality.\n\nAlthough the theory accepts that prior categorization behaviour impacts present perception (i.e., as part of perceiver readiness), self-categorization theory has key advantages over descriptions of social categorization where categories are rigid and invariant cognitive structures that are stored in comparative isolation prior to application. One advantage is that this perspective removes the implausibility of storing enough categorical information to account for all the nuanced categorization that humans use daily. Another advantage is that it brings social cognition in line with a connectionist approach to cognition. The connectionist approach is a neurologically plausible model of cognition where semantic units are not stored, but rather semantic information forms as a consequence of network pattern activation (both current and prior).\n\nIn social psychology a category prototype may be thought of as a “representative exemplar” of a category. Self-categorization theory predicts that what is prototypical of a category is contingent on the context in which the category is encountered. More specifically, when the comparative context changes (i.e., the psychologically available stimuli change) this has implications for how the self category is perceived and the nature of subsequent depersonalization. Self-categorization theory predicts that individuals adopt the features of a salient self category (self-stereotyping), and the content of the category they adopt depends on the present comparative context.\n\nAn individual’s degree of prototypicality also varies in relation to changes in the comparative context, and self-categorization theory expects this to have direct implications for interpersonal phenomenon. Specifically, prototypicality plays an important role in the social identity approach to leadership, influence, and interpersonal attraction. For example, on interpersonal attraction, self-categorization theory states that \"self and others are evaluated positively to the degree that they are perceived as prototypical (representative, exemplary, etc.) of the next more inclusive (positively valued) self-category of which they are being compared\".\n\nLevels of individual prototypicality may be gauged using the meta-contrast principle, and indeed it is this purpose the meta-contrast ratio is more often used for. Furthermore, although prototypicality is most often discussed in relation to the perception of individuals within a group, groups may also be assessed in terms of how prototypical they are of a superordinate category.\n\nSelf-categorization theory provides an account of social influence. This account is sometimes referred to as the theory of \"referent informational influence\". According to self-categorization theory, as social identities become salient, and depersonalization and self-stereotyping occurs, people adopt the norms, beliefs, and behaviors of fellow ingroup members. They also distance themselves from the norms, beliefs, and behaviors of comparison outgroup members. When someone observes a difference between themselves and a fellow ingroup member that person will experience subjective uncertainty. That uncertainty can be resolved by either a) recategorizing people or the situation to reflect those perceived differences, or b) engaging in a social influence process whereby one person makes changes to become more similar to the other. Which person adopts the views or behaviors of the other (i.e. who influences who) is predicted to be that person who is most prototypical of the ingroup. In other words, the person who exemplifies the norms, values, and behaviors of the ingroup the most. The self-categorization theory account of social influence has received a large amount of empirical support.\n\nSelf-categorization theory’s account of social influence differs from other social psychological approaches to social influence. It rejects the traditional distinction between informational influence and normative influence, where informational influence involves the assessment of social information based on its merit and normative influence involves public compliance to the expectations of group members. For self-categorization theory social information does not have merit independent of self-categorization. Instead, information is perceived as valid to the extent that it is perceived to be a normative belief of the ingroup. Normative influence, on the other hand, is not normative at all. Rather, it is counter-normative influence based compliance to expectations of psychological outgroup members. In a similar vein self-categorization theory also challenges the distinction between objective reality testing and social reality testing (e.g. the elaboration likelihood model). It argues that there is no such thing as objective reality testing isolated from social reality testing. Sensory data is always interpreted with respect of the beliefs and ideas of the perceiver, which in turn are bound up in the psychological group memberships of that perceiver.\n\nOutgroup homogeneity can be defined as seeing the outgroup members as more homogeneous than ingroup members. Self-categorization accounts for the outgroup homogeneity effect as a function of perceiver motivation and the resultant comparative context, which is a description of the psychologically available stimuli at any one time. The theory argues that when perceiving an outgroup the psychologically available stimuli include both ingroup and outgroup members. Under these conditions the perceiver is more likely to categorize in accordance with ingroup and outgroup memberships and is consequently naturally motivated to accentuate intergroup differences as well as intragroup similarities. Conversely, when perceiving an ingroup the outgroup members may not be psychologically available. In such circumstances there is no ingroup-outgroup categorization and thus no accentuation. Indeed, accentuation of intragroup differences may occur under these circumstances for the same sense making reasons.\n\nIn line with this explanation it has been shown that in an intergroup context both the ingroup and outgroup is perceived as more homogeneous, while when judged in isolation the ingroup is perceived as comparatively heterogeneous. This is also congruent with depersonalization, where under certain circumstances perceivers may see themselves as interchangeable members of the ingroup. The self-categorization theory eliminates the need to posit differing processing mechanisms for ingroups and outroups, as well as accounting for findings of outgroup homogeneity in the minimal group paradigm.\n\nThe social identity approach explicitly rejects the metatheory of research that regards limited information processing as the cause of social stereotyping. Specifically, where other researchers adopt the position that stereotyping is second best to other information processing techniques (e.g., individuation), social identity theorists argue that in many contexts a stereotypical perspective is entirely appropriate. Moreover, it is argued that in many intergroup contexts to take an individualistic view would be decidedly maladaptive and demonstrate ignorance of important social realities.\n\nSelf-categorization theory emphasises the role of category hierarchies in social perception. That is, much like a biological taxonomy, social groups at lower levels of abstraction are subsumed within social groups at higher levels of abstraction. A useful example comes from the world of team sports, where a particular social group such as Manchester United fans may be an ingroup for a perceiver who may compare with a relevant outgroup (e.g., Liverpool fans). However, at a higher level of abstraction, both social groups may be subsumed into the singular category of football fans. This is known as a superordinate category, and in this context those Liverpool fans once considered outgroup members are now considered fellow ingroup members. The new salient outgroup might instead be rugby fans. Awareness of category hierarchies has led to the development of the common ingroup identity model. This model suggests that conflict at one level of abstraction (e.g., between Manchester United fans and Liverpool fans) might be ameliorated by making salient a more inclusive superordinate ingroup.\n\nIt has been noted, however, that very few social groups can be described in hierarchical terms. For example, Catholic people in Germany cannot be always considered a subordinate category of Germans, as there are Catholic people throughout the globe. McGarty proposes that the theory's use of hierarchies as an organizing principle must be relaxed. The alternative proposition is that social psychologists should look to Venn-like structures for descriptions of social structure. The awareness of crossed cutting social categories has allowed for the development of further intergroup conflict reduction strategies.\n\nBrewer and Brown describe self-categorization theory as a “version of social identity theory” that is heavily cognitive and is not attentive to many motivational and affective processes. Turner and Reynolds, in response to this style of commentary, counter that describing self-categorization theory as a replacement to social identity theory is an error, and that self-categorization theory was always intended to complement social identity theory. Turner and Reynolds also argue that such commentary unreasonably discounts the motivational concerns that are articulated in self-categorization theory. For example, the motivation to maintain positive self categories and the motivation to achieve ingroup consensus.\n"}
{"id": "5501897", "url": "https://en.wikipedia.org/wiki?curid=5501897", "title": "Seven rays", "text": "Seven rays\n\nThe seven rays is an occult concept that has appeared in several religions and esoteric philosophies in both Western culture and in India since at least the sixth century BCE. Also they are known as gods or angels from different planets or can be called fallen angels.\n\nIn the west, it can be seen in early western mystery traditions such as Gnosticism and Mithraism; and in texts and iconic art of the Catholic Church as early as the Byzantine Empire. In India, the concept has been part of Hindu religious philosophy and scripture since at least the Vishnu Purana, dating from the post-Vedic era.\n\nBeginning in the late 19th century, the seven rays appeared in a modified and elaborated form in the teachings of Theosophy, first presented by Helena Blavatsky. The Theosophical concept of the seven rays was further developed in the late 19th and early 20th centuries in the writings of Theosophist Charles Webster Leadbeater, and by other authors such as Alice Bailey, Manly P. Hall, and others, including notably the teachings of Benjamin Creme and his group Share International; and in the philosophies of organizations such as Temple of the People, \"I AM\" Activity, The Bridge to Freedom, The Summit Lighthouse, The Temple of The Presence (1995) and various other such organizations promulgating what are called the Ascended Master Teachings, a group of religious teachings based on Theosophy.\n\nAs the New Age movement of the mid-to-late 20th century developed, the seven rays concept appeared as an element of metaphysical healing methods such as Reiki and other modalities, and in esoteric astrology.\n\nIn ancient Greek mythology, Zeus takes the bull-form known as Taurus in order to win Europa. Taurus is also associated with Aphrodite and other goddesses, as well as with Pan and Dionysus. The face of Taurus \"gleams with seven rays of fire.\"\n\nThe Chaldean Oracles of the 2nd century CE feature the seven rays as purifying agents of Helios, symbolism featured in Mithraic liturgy as well. Later, in the 4th century, Emperor Julian Saturnalia composed a \"Hymn to the Solemn Sun\", and in his \"Hymn to the Mother of the Gods\" spoke of \"unspeakable mysteries hidden from the crowd such as Julian the Chaldean prophesied concerning the god of the seven rays.\" In Greek Gnostic magic of the same era, colored gemstones were often used as talismans for medicine or healing; they were often engraved with a symbol borrowed from the Egyptian deity Chnuphis: a hooded serpent or great snake. The snake was shown with a lion's head, from which emanated either twelve or seven rays. The twelve rays represented the zodiac, and the seven rays represented the planets, usually with the seven Greek vowels engraved at the tips of the seven rays. The reverse sides of the talismans were engraved with a snake twisting around a vertical rod. These were known as \"Gnostic amulets\" and were sometimes also engraved with the names \"Iao Sabao\" (the Archon Iao). Gnostic gems with Abraxas also featured the seven rays.\n\nIn early Christian iconography, the dove of the Holy Ghost is often shown with an emanation of seven rays, as is the image of the Madonna, often in conjunction with a dove or doves. The Monastery of St. Catherine on Mount Sinai, circa 565 CE, shows the Transfiguration of Christ in the apse mosaic, with \"seven rays of light shining from the luminous body of Christ over the apostles Peter, James and John.\" In the present day Byzantine-style St. Louis Cathedral in Missouri, the center of the sanctuary has an engraved circle with many symbols of the Holy Trinity. The inscription reads: \"Radiating from this symbol are seven rays of light representing the seven gifts of the Holy Ghost.\"\n\nDuring the 12th century, Saint Norbert of Xanten, founder of the Order of Canons Regular of Prémontré, discovered the spot where the relics of Saint Ursula and her companions of Saint Gereon and of other martyrs lay hidden while in a dream. In the dream that led him to this location, he was guided by \"the seven rays of light... surrounding the head of the crucified Redeemer.\"\n\nThe Annunciation is an oil painting by Early Netherlandish master Jan van Eyck, from around 1434-1436. The picture depicts the Annunciation by the Archangel Gabriel to the Virgin Mary that she will bear the Son of God (Luke 1:26-38). In a prominent element of the complex iconographic work, the Seven gifts of the Holy Spirit descend to her on seven rays of light from the upper window to the left, with the dove symbolising the Holy Spirit following the same path. The seven rays on which the doves descend are unique elements in the painting in that they are of the heavenly realm rather than the earthly realm, with the difference shown by the artist through the use of gold leaf rather than ordinary oil paint. Only the seven rays are so treated, and while all of the other light sources in the painting cast shadows, the seven rays do not.\n\nThe Italian secret society of the late 17th century, Knights of the Apocalypse, was founded with the professed aim to defend the Catholic Church against the expected Antichrist, though it was accused of having political motives as well. They wore on their breasts a star with seven rays.\n\nAgni is a Hindu and Vedic deity depicted in three forms: fire, lightning and the sun. In Hindu art, Agni is depicted with two or seven hands, two heads, and three legs. In each head, he has seven fiery tongues with which he licks sacrificial butter. He rides a ram or a chariot harnessed by fiery horses. His attributes are an axe, a torch, prayer beads and a flaming spear. Agni is represented as red and two-faced, suggesting both his destructive and his beneficent qualities, and with black eyes and hair. Seven rays of light emanate from his body.\n\nThe Vishnu Purana, a post-vedic scripture, describes how Vishnu \"enters into the seven solar rays which dilate into seven suns.\" These are the \"seven principal solar rays,\" the source of heat even to the planet Jupiter, and the \"seven suns into which the seven solar rays dilate at the consummation of all things...\"\n\n20th century Hindu scholar, poet and mystic, Sri Aurobindo, described the Vedic seven rays of knowledge, or Agni, as \"the seven forms of the Thought-principle\" and wrote that \"the seven brilliant horses of the sun and their full union constitutes the seven-headed Thought of Ayasya by which the lost sun of Truth is recovered. That thought is again established in the seven rivers, the seven principles of being divine and human, the totality of which founds the perfect spiritual existence.\"\n\nEgyptologist Gerald Massey wrote in 1881 of what he described as connections between Vedic scripture, ancient Egyptian mythology and the Gospel stories. He theorized that the Archon Iao, the \"Seven-rayed Sun-God of the Gnostic-stones\" was also the \"Serpent Chnubis,\" and \"the Second Beast in the Book of Revelation.\" In 1900, he elaborated further, describing the unity of \"the seven souls of the Pharaoh,\" \"the seven arms of the Hindu god Agni,\" \"the seven stars in the hand of the Christ in Revelation,\" and \"the seven rays of the Chaldean god Heptaktis, or Iao, on the Gnostic stones.\"\n\nSamuel Fales Dunlap, wrote in 1894:\n\nMoses was of the race of the Chaldeans. The Chaldean Mithra had his Seven Rays, and Moses his Seven Days. The other planets which circling around the sun lead the dance as round the King of heaven receive from him with the light also their powers; while as the light comes to them from the sun so from him they receive their powers that he pours out into the Seven Spheres of the Seven Planets of which the sun is the centre.\nDunlap wrote that the idea of spirit as the ultimate cause is present in all of the great religions of the East (which in the terminology of his time included the area now known as the Near East or Middle East), and that this idea can be found in \"the Seven Rays of the Chaldaean Mithra and the Seven Days of Genesis. From the Sun came fire and spirit.\" According to Dunlap, \"this was the astronomical religion of the Chaldeans, Jews, Persians, Syrians, Phoenicians and Egyptians.\"\n\nDunlap compared the nimbus of Apollo to the seven rays of Dionysus, presiding over the orbits of the seven planets. The seven rays are found also in the Chaldean mystery of \"the God of the Seven Rays, who held the Seven Stars in his hand, through whom (as Chaldaeans supposed) the souls were raised.\" Prior to the Christian era, this deity was known as Iao (the first birth) or Sabaoth (the Sun), and later described as \"Christos of the Resurrection of Souls.\"\n\nIn the late 1940s, art historian and writer Ananda Coomaraswamy was curator in the department of Asiatic Art at the Boston Museum of Fine Arts and built the first large collection of Indian art in the United States. His writings in the field of perennial philosophy and the Traditionalist School included complex essays collating symbols of ancient wisdom and metaphysics from widely diverse cultures including Indian, Islamic, Chinese, Hellenic, and Christian sources. He wrote that the seven rays of the sun appear in both Hindu and Christian symbolism, representing similar concepts, and in particular the symbolism of the seventh ray that \"corresponds to the distinction of transcendent from immanent and of infinite from finite.\" He added that of \"our Axis of the Universe (skambha, divo dharuna, etc.) and Islamic Qutb ... The seventh ray alone passes through the Sun to the suprasolar Brahma worlds, \"where no sun shines\" ('all that is under the Sun being in the power of Death, and all beyond immortal').\"\n\nSyncretism is one of the core principles of Theosophy, a religious philosophy originating with Helena Petrovna Blavatsky from the 1870s, and the seven rays appear repeatedly in the related writings. Theosophy holds that all religions are attempts by the \"Spiritual Hierarchy\" to help humanity in evolving to greater perfection, and that each religion therefore has a portion of the truth.\n\nBlavatsky wrote in the first book of \"The Secret Doctrine\" of an \" analogy between the Aryan or Brahmanical and the Egyptian esotericism\" and that the \"seven rays of the Chaldean Heptakis or Iao, on the Gnostic stones\" represent the seven large stars of the Egyptian \"Great Bear\" constellation, the seven elemental powers, and the Hindu \"seven Rishis.\" She stated that the seven rays of the Vedic sun deity Vishnu represent the same concept as the \"astral fluid or 'Light' of the Kabalists,\" and that the seven emanations of the lower seven sephiroth are the \"primeval seven rays,\" and \"will be found and recognized in every religion.\"\n\nIn the second volume of the \"Secret Doctrine\", Blavatsky discusses the \"seven nervous plexuses of the body\" and the seven rays they radiate, stating that this principle is found in the Rig Veda, in the mythology of Ahura Mazda, in the beliefs of the Incas, the Chinese Yao, and the Egyptian Osiris, who \"when he enters the ark, or solar boat, takes seven Rays with him.\" She describes the \"seven wise ones\" of the Veda as \"the seven Rays which fall free from the macrocosmic centre\".\n\nBlavatsky summarizes the syncretistic principle of her doctrine as it relates to the seven rays:\n\n\"...a key which reveals to us on indisputable grounds of comparative analogy... the Indian phœnix, the emblem of cyclic and periodical time, the \"man-lion\" Singha, of whose representations the so-called \"gnostic gems\" are so full. Over the seven rays of the lion's crown, and corresponding to their points, stand, in many cases, the seven vowels of the Greek alphabet AEHIOYW, testifying to the Seven Heavens. This is the Solar lion and the emblem of the Solar cycle, as Garuda is that of the great cycle, the \"Maha-Kalpa\" co-eternal with Vishnu, and also, of course, the emblem of the Sun, and Solar cycle. ... As well remarked by C. W. King: — \"Whatever the primary meaning (of the gem with the solar lion and vowels) it was probably imported in its present shape from India, that true fountain head of gnostic iconography.\" (Gnostics, p. 218)\n\nIn the third volume of the \"Secret Doctrine\", published posthumously, Blavatsky described the \"Seven Primeval Rays\" as a group of celestial beings also known as \"Gods\" or \"Angels\" or \"Powers\". She stated that this symbolism was \"adopted later on by the Christian Religion as the 'Seven Angels of the Presence.'\"\n\nIn Theosophy, the seven rays are said to be seven major types of \"Light-Substance\" (spirit/matter) (waves/particles) that compose the created universes. These are also believed to convey \"Divine Qualities\".\n\nC.W. Leadbeater gave a list showing the characteristic type of magic for each ray. This list indicates what he regarded as the most compatible type of magic to be performed by persons on each ray (although anyone of any ray can do any of these various types of magic).\n\n\nAccording to Alice A. Bailey, each person has a \"soul ray\" that remains the same through all their incarnations, and a \"personality ray\" that is different for each incarnation. Each ray is also correspondent with certain Masters of Wisdom, and with particular planets, cycles, nations, etc. The seven rays are the basis for what Alice A. Bailey called \"New Age Psychology\"—she divides everyone in the human race into these seven psychological types.\n\nBailey stated that the seven rays that reach us on Earth locally originate within the \"Solar Logos,\" i.e., the consciousness of the \"Divine Being\" of the Sun. According to Alice A. Bailey and Benjamin Creme, the seven rays are focused to the Solar Logos, through Sirius, the seven stars of the Big Dipper in the Great Bear, and the seven major stars of the Pleiades form the \"Galactic Logos,\" (the consciousness of the \"Divine Being\" of the Milky Way Galaxy), and have their ultimate origin within the mind of God.\n\nOn the local planetary level, it is believed that the seven rays are transmitted from the Solar Logos through the God of our planet, Sanat Kumara, then through the spiritual hierarchy of our planet which includes the \"Masters of Wisdom\" (Some writings term them the Ascended Masters or the Great White Brotherhood).\n\nEach of the seven rays is believed to be associated with a different kind of occult energy, and a different color.\n\nThe \"seven rays\" are listed below:\n\nAlice A. Bailey and the Church Universal and Triumphant assign different colors and in some cases different Masters to each of the seven rays. In \"Letters on Occult Meditation\", Alice Bailey indicates that there is no simple correspondence between the rays and these colors. The colors, Masters, and Retreats indicated here are those indicated by both Alice Bailey and the Church Universal and Triumphant.\n\nAccording to Alice A. Bailey the Masters live in immortal bodies at a \"residence\" on the physical plane at the indicated location (although a given Master may physically travel extensively incognito to various locations, become invisible, teleport to various locations, and walk through walls, as well as influence humans telepathically and travel on the inner planes, as required by the demands of his spiritual work).\n\nAccording to the Church Universal and Triumphant, and other \"Ascended Master Activities\", each Master is believed to serve at a \"Retreat\" on the physical or etheric plane at the geographical location shown after their name.\n\nThe \"Gifts of the Holy Spirit\" of the Church Universal and Triumphant for each ray are shown. For both Alice A. Bailey and the Church Universal and Triumphant, each ray has a jewel which is believed to focus the energy of that ray, which is indicated.\n\nIn the mid-to-late 20th century, as the New Age movement gained in popularity, the concept and imagery of the seven rays appeared in a variety of settings.\n\nIn esoteric astrology, the seven rays are considered to be split into three groups: the first two rays represent Will and Wisdom, respectively, and the remaining five rays together form the group that represents Activity. In a style of Reiki adapted by Carolyn E. Jackson the student passes through a sequence of levels by mastering the \"key\" to each level. The key for the second level is known as the key of \"oneness\" and is attained by passing through each of the seven rays. This, however, is not part of traditional Reiki or other versions of the Reiki system.\n\nAccording to psychic counselor Samantha Stevens, an individual can use affirmations, candles, color therapy, vibrational medicines and other methods to contact \"archangels,\" which she defines as the \"seven rays,\" based on Buddhist and Christian theories: \"The Rays or Divine Flames (as they are sometimes called) represent elements in the perfectly integrated human being - one whose heart is aligned with their will and inspired by the Divine Imagination.\"\n\nLight therapist and Radionics Practitioner Primrose Cooper writes that in using light as a healing modality, she finds it helpful to use the seven rays as defined in Theosophy to assist her clients in finding \"psychological insight into their soul's purpose.\"\n\nIn recent years, there was the creation of a secretive group named \"The Keepers of the Seven Rays\". Their philosophy is the human being has seven emanations in which it finds itself, or connects with the Higher Self. These emanations are extensions of the Higher Self or otherwise called the Higher Will. These emanations reach out like arms and grasp onto the knowledge(of all types) needed for the full development of the individual into his/her Higher Potential. All a human has to do to use these emanations is to know basic moral law, what their body and/or psyche can and cannot handle, and listen.\n\nMetaphysical philosopher Gurdjieff writes frequently of his \"Seven Rays of Creation\". According to Gurdjieff, the Seven Rays of Creation are the seven manifestations of Energy in our Universe. The first Ray contains all things (THE ENTIRE UNIVERSE) and all things obey the laws inherent in the First Ray. The First Ray then manifests itself in the 2nd Realm, the realm of Galaxies. From Galaxies to Solar Systems, Solar Systems to Planets. From Planets to Organisms on the planets, etc.\n\n\n\n\n\n"}
{"id": "1638128", "url": "https://en.wikipedia.org/wiki?curid=1638128", "title": "Spirit", "text": "Spirit\n\nA spirit is a supernatural being, often, but not exclusively, a non-physical entity; such as a ghost, fairy, or angel. The concepts of a person's spirit and soul, often also overlap, as both are either contrasted with or given ontological priority over the body and both are believed to survive bodily death in some religions, and \"spirit\" can also have the sense of \"ghost\", i.e. a manifestation of the spirit of a deceased person. In English Bibles, \"the Spirit\" (with a capital \"S\"), specifically denotes the Holy Spirit.\n\nSpirit is often used metaphysically to refer to the consciousness or personality.\n\nHistorically, it was also used to refer to a \"subtle\" as opposed to \"gross\" material substance, as in the famous last paragraph of Sir Isaac Newton's \"Principia Mathematica\".\n\nThe English word \"spirit\" comes from the Latin \"spiritus\",but also \"spirit, soul, courage, vigor\", ultimately from a Proto-Indo-European \"*(s)peis\". It is distinguished from Latin \"anima\", \"soul\" (which nonetheless also derives from an Indo-European root meaning \"to breathe\", earliest form \"*henh-\"). In Greek, this distinction exists between \"pneuma\" (), \"breath, motile air, spirit,\" and \"psykhē\" (), \"soul\" (even though the latter term, = \"psykhē/psūkhē\", is also from an Indo-European root meaning \"to breathe\": \"*bhes-\", zero grade \"*bhs-\" devoicing in proto-Greek to \"*phs-\", resulting in historical-period Greek \"ps-\" in \"psūkhein\", \"to breathe\", whence \"psūkhē\", \"spirit\", \"soul\").\n\nThe word \"spirit\" came into Middle English via Old French. The distinction between soul and spirit also developed in the Abrahamic religions: Arabic \"nafs\" () opposite \"rūħ\" (); Hebrew \"neshama\" ( \"nəšâmâh\") or \"nephesh\" \"nép̄eš\" (in Hebrew \"neshama\" comes from the root \"NŠM\" or \"breath\") opposite \"ruach\" ( \"rúaħ\"). (Note, however, that in Semitic just as in Indo-European, this dichotomy has not \"always\" been as neat historically as it has come to be taken over a long period of development: Both (root ) and (root ), as well as cognate words in various Semitic languages, including Arabic, also preserve meanings involving misc. air phenomena: \"breath\", \"wind\", and even \"odour\").\n\nIn spiritual and metaphysical terms, \"spirit\" has acquired a number of meanings:\n\n\nSimilar concepts in other languages include Greek \"pneuma\" and Sanskrit \"akasha / atman\" (see also \"prana\"). Some languages use a word for \"spirit\" often closely related (if not synonymous) to \"mind\". Examples include the German \"Geist\" (related to the English word \"ghost\") or the French \"l'esprit\". English versions of the Bible most commonly translate the Hebrew word \"ruach\" (רוח; \"wind\") as \"the spirit\", whose essence is divine.\n\nAlternatively, Hebrew texts commonly use the word \"nephesh\". Kabbalists regard \"nephesh\" as one of the five parts of the Jewish soul, where \"nephesh\" (animal) refers to the physical being and its animal instincts. Similarly, Scandinavian, Baltic, and Slavic languages, as well as Chinese (气 \"qi\"), use the words for \"breath\" to express concepts similar to \"the spirit\".\n\n"}
{"id": "696464", "url": "https://en.wikipedia.org/wiki?curid=696464", "title": "Status group", "text": "Status group\n\nThe German sociologist Max Weber (1864-1920) formulated a three-component theory of stratification that defines a status group (also status class and status estate) as a group of people who, within a society, can be differentiated on the basis of non-economic qualities such as honour, prestige, ethnicity, race and religion. (Weber used the German terms \"Stand\" (status group) and \"Stände\" (status groups).)\n\nSince Weber's day, sociologists have intensively studied the matter of “status incongruence” - both in post-industrial societies, and in other countries.\n\nWeber said that status groups emerge from \"the house of honor\", and that such status-honor stands in contrast with:\n\nStatus groups, social classes, and political parties are the constituent concepts of the three-component theory of stratification. Discussion of the relationships among status groups, social class, and political parties occurs in Weber's essay \"Class, Status, Party\", written before the First World War (1914–18); the first translation into English, by Hans Gerth and C. Wright Mills, was published in the 1940s. Dagmar Waters and colleagues produced a newer English translation of the essay, titled “The Distribution of Power within the Community: Classes, Stände, Parties” (2010), published in the “Journal of Classical Sociology”; the title of the new English-language translation includes the German word “Stände” (status groups) in place of the English term.\n\nAccording to Weber, status groups feature in a wide variety of social stratifications which both popular discourse and the academic literature commonly refer to. These include categorization by race, ethnicity, caste, professional groups, neighborhood groups, nationalities, and so forth. These contrast with relationships rooted in economic relations, which Weber calls \"class\".\n\nSociologist Pierre Bourdieu (1930-2002) discusses issues of cultural capital and symbolic capital. Like Weber, he comments on how non-monetary means are used to confer and deny status to individuals and groups. However, Bourdieu developed independently from Weber, even though they probably do reflect the type of \"capital\" that status groups confer on those who are privileged.\n\n"}
{"id": "8921111", "url": "https://en.wikipedia.org/wiki?curid=8921111", "title": "Telescoping effect", "text": "Telescoping effect\n\nIn cognitive psychology, the telescoping effect (or telescoping bias) refers to the temporal displacement of an event whereby people perceive recent events as being more remote than they are and distant events as being more recent than they are. The former is known as backward telescoping or time expansion, and the latter as is known as forward telescoping. Three years is approximately the time frame in which events switch from being displaced backward in time to forward in time, with events occurring three years in the past being equally likely to be reported with forward telescoping bias as with backward telescoping bias. Although telescoping occurs in both the forward and backward directions, in general the effect is to increase the number of events reported too recently. This net effect in the forward direction is because of forces that impair memory, such as lack of salience, also impair time perception. Telescoping leads to an over reporting of the frequency of events. This over reporting is because participants include events beyond the period, either events that are too recent for the target time period (backward telescoping) or events that are too old for the target time period (forward telescoping).\n\nThe original work on telescoping is usually attributed to a 1964 article by Neter and Waksberg in the \"Journal of the American Statistical Association\". The term telescoping comes from the idea that time seems to shrink toward the present in the way that the distance to objects seems to shrink when they are viewed through a telescope.\n\nA real-world example of the telescoping effect is the case of , an infamous kidnapper and murderer in the Netherlands. When he was let out of prison, most of the general population did not believe he had been in prison long enough. Due to forward telescoping, people thought Ferdi Elsas' sentence started more recently than it actually did. Telescoping has important real world applications, especially in survey research. Marketing firms often use surveys to ask when consumers last bought a product, and government agencies often use surveys to discover information about drug abuse or about victimology. Telescoping may bias answers to these questions.\n\nTelescoping is studied in psychology by asking participants to recall dates or to estimate the recency of a personal event. Another procedure that is often used is called the diary procedure, in which participants record personal events in a diary each day for several months. After the diary is completed, participants are asked to date events and assess how well they remember those events. Their recollections are then compared to the actual dates and details of the events in order to determine if telescoping has occurred.\n\nResearchers have examined possible reasons that the telescoping effect occurs. They have proposed the following hypotheses and models. The two models that are currently favored are the associative and boundary models.\n\nBrown, Rips, and Shevell created the accessibility hypothesis. This hypothesis states that dates are estimated, not recalled, and these estimates are based on what is remembered about the event. People use how much detail they recall about an event to infer how long ago the event occurred. Therefore, memorable events should be recalled as occurring recently. Since these memorable events are recalled as occurring more recently, in general people overestimate the recency of events and forward telescoping occurs. For example, when people are asked to estimate the dates of the shooting of Ronald Reagan and Pope John Paul II, which occurred in the same year, they typically estimate that Ronald Reagan's shooting occurred more recently. Ronald Reagan's shooting is usually a more memorable event and was more heavily publicized, so the memory of this event was more accessible to participants, indicating that accessibility plays a role in the dating of events. However, these results are not always replicated, and sometimes the reverse is found. For this reason, other explanations have been presented to explain telescoping.\n\nThompson et al. used the conveyor belt model of memory to explain forward telescoping. It assumes that events are stored in the order that they occur. When individuals try to remember the date of an event, they scan serially backward through memory. Since events are only remembered by order or time between events in this model, if an event is forgotten, previous events are recalled as if they occurred more recently and forward telescoping occurs. Another way of interpreting this theory is that people estimate the dates of events based on the number of personal events that have occurred since the target event. Since people underestimate memory loss over long periods of time, target events are moved closer to the present. Although this model explains forward telescoping, it does not explain backward telescoping. \n\nSome psychologists have suggested that telescoping occurs because people are guessing the date of an event. According to this theory, if a person is unsure of a date, they minimize their chance of erring by placing events toward the middle of the period. However, telescoping occurs at the same frequency if events are remembered well or if events are not remembered well. Therefore, guessing is not a complete explanation for telescoping, and another one of these models is likely responsible.\n\nRubin and Baddley created the boundary model to explain telescoping. When people date events, they often get information from a bounded period, such as a year or a vacation. This model assumes events are not assigned outside of the boundaries of this period, so dating errors can only move toward the middle of a boundary and that since recent events are dated more accurately, forward telescoping has a stronger effect. It postulates that, without boundaries, an estimation would be unbiased.\n\nThere is some evidence against the boundary model. A study by Lee and Brown in 2004 looked at how four different groups dated news events under different conditions. They found that the different boundaries had no effect on date estimation, and the existence of a boundary had no effect on date estimation. This study suggests that telescoping is not due solely to boundaries.\n\nSimon Kemp proposed the associative model to explain telescoping without using boundaries. Kemp argued that people use an association strategy that links target events to other events for which dating information is available. According to Kemp, this association leads to a regression to the mean of known dates. This approach assumes that the date of an event is determined by using memories from other similar events, that ability to recall relevant information decreases overtime, and that the associated event is more likely to be more recent than the actual event because the ability to retrieve information decreases overtime.\n\nA variation of this theory is the prototype model. This model states that prototypes can aid the process of dating events. A prototype event is a general event. For example, a specific event could be the assassination of John F. Kennedy and a prototype event could be the assassination of a world leader. People can use associated prototype events to help them recall events in the same way they use normal events.\n\nAlthough the prototype model is based on general events and the associative model is based on actual events, both have been supported in experiments. Participants are worse at estimating the dates of events if they have to date events spontaneously, without using context or associated events, and prototype event estimates resemble spontaneously estimated events. The associative model does not predict what occurs if a person has never heard of an event and cannot predict what sort of biasing will occur for these responses. Therefore, the associative model, like the boundary effect model, cannot explain all aspects of telescoping but can explain new aspects of telescoping.\n\nHeuristics\nSome psychologists suggest telescoping errors are due to the heuristics used to answer dating and frequency questions. When asked questions about frequency, people often answer using phrases like \"all the time\" and \"everyday\" and therefore don't account for exceptions. Depending on the events in question, this could lead to an over or under estimation of the occurrence of an event, and be perceived as telescoping. This over reporting is a result of telescoping because telescoping causes participants include events beyond the period. Therefore, heuristics may be responsible for some of the telescoping errors.\n\nDemand characteristics\n\nOther psychologists believe that the telescoping errors that have been reported in studies are not due to a phenomenon of memory, but demand characteristics. Responses to questions about the frequency of behavior can be biased because of demand characteristics. Respondents may provide too much information, rather than too little, because they are trying to provide as much useful information as possible, and therefore over-report the frequency of events. Some researchers perceive this over reporting as telescoping because people are including events beyond the given period, but the over reporting could be due to the demand characteristics of the study. Demand characteristics can explain the appearance of forward telescoping, but cannot explain backwards telescoping and can not explain the inaccurate recall of dates when respondents are not led to believe that a certain answer is desirable.\n\nPsychologists have studied the telescoping effect in children because a person's development can have a significant impact on his or her memory. Telescoping occurs at all ages, but to different degrees. Older children have a greater tendency to telescope earlier memories and a weaker tendency to telescope recent memories than younger children. Children's telescoping errors occur for their earliest memories. This finding is significant because it probably occurs for adults as well, and therefore people's earliest memories are reported as more recent than they actually are. This finding indicates that the earliest memories reported in childhood amnesia literature should be questioned because they may have occurred earlier than they are reported.\n\nMany older adults claim time speeds up as they get older, which can be explained by forward telescoping. Since forward telescoping leads people to underestimate the amount of time that has occurred since an event, people may feel as if time has passed quickly when they discover the true amount of time since that event. This explanation is one reason for why people perceive time as moving faster as they age, but it does not take into account changes in the amount of telescoping that occurs with age. People are best at accurately identifying dates when they are ages 35–50. Participants age 60 and older show a decrease in the degree of forward telescoping and tend to date events too remotely instead of too recently. The sensation of time speeding up may be derived from the fact that time is subjectively longer and therefore people assume that the time must be going by more quickly.\n\nThe way a question is phrased is an important factor in minimizing the telescoping effect. If a question clearly defines the time period of interest, telescoping errors will be reduced. Also, if a question is more specific or difficult, it requires more reconstructive processes; therefore, the answers to these questions will include less telescoping.\n\nNeter and Waksberg also developed a procedure called bounded recall to help decrease the effect of telescoping. In preliminary interviews, participants are asked about events, and then, in later interviews, participants are reminded of these events and then asked about additional occurrences. One limitation of this process is that it requires information from preliminary interviews be correct.\n\nA person's temporal framework is also related to the amount of telescoping errors that they make. As a person's temporal framework becomes more elaborate, they have more reference points from which to date events and commit fewer telescoping errors.\n\nThe telescoping effect is pertinent for behaviors such as smoking and alcohol usage, especially when they are early onset behaviors. Studies of the telescoping effect have examined the reported age of onset of smoking, alcohol, and drug use. Forward telescoping has been found in reported age of initial use of cigarettes and in reported age of beginning daily smoking. Therefore, people may be misclassified as having late onset of drug use, when in reality, they had early onset. Forward telescoping of risky behaviors can be problematic in monitoring patients for issues associated with early onset drug use because if they are misclassified, they may not be correctly monitored. The same effect of forward telescoping is found for marijuana, alcohol, and hard drug usage. The implications of forward telescoping on these behaviors are similar to those of smoking.\n\nIn the United States, in the 1950s, a telescoping effect was observed with women entering alcohol abuse treatment programs with shorter histories than their male counterparts, but with symptoms of equivalent severity. The forward telescoping of alcohol histories is still prevalent today and has since been observed in opiate abuse and pathological gambling. Several theories have been suggested to explain the effect, though the exact mechanism remains unclear. \n\nMarketing firms often use survey data to estimate when consumers will next buy a product. Telescoping errors may bias these estimates and cause faulty marketing campaigns. Respondents on marketing research surveys are often inaccurate when recalling the time period of their last purchase, and forward telescoping is common. Backward telescoping is also common and leads to respondents overstating their intention to buy a replacement product as they underestimate the likelihood of their product breaking down. Telescoping has a significant effect on market research and therefore should be taken into account in marketing strategies.\n\n\n"}
{"id": "18792968", "url": "https://en.wikipedia.org/wiki?curid=18792968", "title": "Tetrad test", "text": "Tetrad test\n\nThe tetrad test is a series of behavioral paradigms in which rodents treated with cannabinoids such as THC show effects.\nIt is widely used for screening drugs that induce cannabinoid receptor-mediated effects in rodents. The four behavioral components of the tetrad are spontaneous activity, catalepsy, hypothermia, and analgesia. Common assays for these behavioral paradigms are as follows:\n\nDirect CB1 agonists, such as THC (the psychoactive component of marijuana), or WIN 55,212-2, have effects in all components of the tetrad and induce hypomotility, catalepsy, hypothermia, and analgesia in rodents. Accordingly, all true \"tetrad effects\" are not observed following treatment with antagonists or inverse agonists of CB1 such as rimonabant.\n"}
{"id": "20293213", "url": "https://en.wikipedia.org/wiki?curid=20293213", "title": "The Kindness Offensive", "text": "The Kindness Offensive\n\nThe Kindness Offensive (TKO) is a group based in London known for orchestrating large-scale random acts of kindness, involving the distribution of industrial quantities of goods to unsuspecting members of the public and charities. The group's stated purpose is to \"Practice random kindness and senseless acts of beauty\", a phrase first coined by Anne Herbert.\n\nThe Kindness Offensive was formed in August 2008, when three of the four founding members (David Goodfellow, Benny Crane and James Hunter) asked members of the public in Hampstead what \"random acts of kindness\" they would like done for them. They received many requests from the public, and the group attempted to meet some of them by contacting companies and persuading them to donate the required goods for free, a technique developed by fourth founding member Robert Williams and referred to by the group as \"phone whispering\".\n\nTKO attracted press attention in October 2008 for giving away twenty-five tonnes of non-perishable foods to fourteen soup kitchens and drop-in centres across London England; the event came to be known as 'The Mountain of Food'. This event was the first of many large-scale events centred on distributing industrial quantities of goods in short periods of time to a wide variety of locations and causes; the most notable of these were The Vinspired Kindness Offensive (2008), The White Stuff Kindness Offensive, which was widely reported as a record-breaking event (2010), The Barclaycard Kindness Offensive (2011) the Hasbro Kindness Offensive (2013), and the Read Free! Kindness Offensive. The large scale 2014 XL Catlin Kindness Offensive event resulted in the events organiser and group co-founder David Goodfellow being awarded with a Points of Light, award by the then UK Prime Minister David Cameron who ackoloeged that it generated \"...a record-breaking Christmas toy donation\". \n\nAs well as large giveaways, TKO has also staged a series of pop-up events, including The Everyday Kindness Awards in 2009. Over the course of a weekend, actors in public places pretended to need help, and when members of the public stepped up to offer a hand, they received a pop-up celebration rewarding their kindness with champagne, flowers and a gold medal.\n\nThe Kindness Offensive established their headquarters in Islington in 2013, which includes a bookshop that offers 100,000's of books free of charge to the public. and a community space who's grounds have been converted into a sensory garden for special needs students. The building has become something of a local landmark due to installations such as a set of giant brockley and a replica TARDIS from the long running UK TV show Doctor Who.\n\nIn 2017 Joanna Bevan become the fourthmember of The Kindness Offensive to be awarded a place on The Independent Happy List in recognition of her Kindness Offensive work with special needs children and with providing free language lessons to new comers to the UK.\n\n"}
{"id": "956872", "url": "https://en.wikipedia.org/wiki?curid=956872", "title": "Viola Liuzzo", "text": "Viola Liuzzo\n\nViola Fauver Gregg Liuzzo (April 11, 1925 – March 25, 1965) was a Unitarian Universalist civil rights activist from Michigan. In March 1965 Liuzzo, then a housewife and mother of five with a history of local activism, heeded the call of Martin Luther King Jr and traveled from Detroit, Michigan, to Selma, Alabama in the wake of the Bloody Sunday attempt at marching across the Edmund Pettus Bridge. Liuzzo participated in the successful Selma to Montgomery marches and helped with coordination and logistics. Driving back from a trip shuttling fellow activists to the Montgomery airport, she was murdered by members of the Ku Klux Klan. She was 39 years old.\n\nOne of the four Klansmen in the car from which the shots were fired was Federal Bureau of Investigation (FBI) informant Gary Thomas Rowe. Rowe testified against the shooters and was given witness protection by the FBI. The FBI later leaked what were purported to be salacious details about Liuzzo. The FBI attempted to downplay the situation and discredit Liuzzo by spreading rumors that she was a member of the Communist Party, was a heroin addict, and had abandoned her children to have sexual relationships with African-Americans involved in the Civil Rights Movement. None of these were either proved or substantiated in any way.\n\nIn addition to other honors, Liuzzo's name is today inscribed on the Civil Rights Memorial in Montgomery, Alabama, created by Maya Lin.\n\nLiuzzo was born Viola Fauver Gregg on April 1, 1925, in the small town of California, Pennsylvania, the elder daughter of Eva Wilson, a teacher, and Heber Ernest Gregg, a coal miner and World War I veteran. He left school in the eighth grade but taught himself to read. Her mother Eva had a teaching certificate from the University of Pittsburgh. The couple had one other daughter, Rose Mary, in 1930. While on the job, Heber's right hand was blown off in a mine explosion and, during the Great Depression, the Greggs became solely dependent on Eva's income. Work was very hard to come by for Mrs. Gregg, as she could pick up only sporadic, short-term teaching positions. The family descended further into poverty and decided to move from Georgia to Chattanooga, Tennessee, where Eva found a teaching position, when Viola was six.\n\nThe family was very poor and lived in one-room shacks with no running water. The schools Liuzzo attended did not have adequate supplies and the teachers were too busy to give extra attention to children in need. Because the family moved so often, Liuzzo never began and ended the school year in the same place. Having spent much of her childhood and adolescence poor in Tennessee, Viola experienced the segregated nature of the South firsthand. This would have a powerful impact on her activism. It was during her formative years that she realized the injustice of segregation and racism, as she and her family, in similar conditions of great poverty, were still afforded social privilege and amenities denied to African-Americans under the Jim Crow laws.\n\nIn 1941 the Gregg family moved to Ypsilanti, Michigan, where her father sought a job assembling bombs at the Ford Motor Co. Viola's strong-willed nature led her to drop out of high school after one year, and elope at the age of 16. The marriage did not last and she returned to her family. Two years later the Gregg family moved to Detroit, Michigan, which was starkly segregated by race. Tensions between whites and blacks there was very high and the early 1940s saw violence and rioting. Witnessing these horrific ordeals was a major motivator that influenced Viola's future civil rights work.\n\nIn 1943 she married George Argyris, the manager of a restaurant where she worked. They had two children, Penny and Evangeline Mary, and divorced in 1949. She later married Anthony Liuzzo, a Teamsters union business agent. They had three children: Tommy, Anthony Jr. and Sally. Liuzzo sought to return to school, and attended the Carnegie Institute in Detroit, Michigan. She then enrolled part-time at Wayne State University in 1962.\n\nIn 1964 she began attending the First Unitarian Universalist Church of Detroit, and joined the National Association for the Advancement of Colored People (NAACP).\n\nA large part of Viola's activism, particularly with the NAACP, was due to a close friendship with an African-American woman, Sarah Evans. After initially meeting in a grocery store where Liuzzo worked as a cashier, the two kept in touch. Evans eventually became Liuzzo's housekeeper while still maintaining a close, friendly relationship in which they shared similar views including support for the civil rights movement. In the aftermath of Liuzzo's death, Evans would go on to become the permanent caretaker of Liuzzo's five young children.\n\nLiuzzo so passionately believed in the fight for civil rights that she helped organize Detroit protests, attended civil rights conferences and worked with the NAACP. She had a strong desire to make a difference on as large a scale as she could.\n\nIn addition to actively supporting the civil rights movement, Liuzzo was also notable for her protest against Detroit's laws that allowed for students to more easily drop out of school. Her disagreement with this law led her to withdraw her children from school in protest. Because she deliberately home-schooled them for two months, Liuzzo was arrested, but did not waiver. She pleaded guilty in court and was placed on probation.\n\nIn February 1965 a night demonstration for voting rights at the Marion, Alabama, courthouse turned violent. State troopers clubbed marchers and beat and shot a 26-year-old African-American named Jimmie Lee Jackson, who later died. His death spurred on the fight for civil rights in Selma, Alabama. The Southern Christian Leadership Conference (SCLC) scheduled a protest march for Sunday, March 7, 1965. Gov. George Wallace banned the march, but the ban was ignored. Six hundred marchers headed for the arched Edmund Pettus Bridge that crossed the Alabama River. As the protesters reached the crest of the bridge, they saw a terrifying sight on the other side: state troopers armed with clubs, whips and tear gas and a sheriff's posse on horseback. When told to stop and disperse, the marchers refused. The troopers advanced on the marchers, clubbing and whipping them, fracturing bones and gashing heads. Seventeen people were hospitalized on the day later called \"Bloody Sunday\".\n\nLiuzzo was horrified by the images of the aborted march on Bloody Sunday. A second march took place March 9. Troopers, police and marchers confronted each other at the county end of the bridge, but when the troopers stepped aside to let them pass, the Rev. Martin Luther King led the marchers back to the church. He was obeying a federal injunction while seeking protection from federal court for the march. That night a white group beat and murdered civil rights activist James Reeb, a Unitarian Universalist minister from Boston, who had come to Selma to march with the second group. Many other clergy and sympathizers from across the country also gathered for the second march.\n\nOn March 16, Liuzzo took part in a protest at Wayne State. She then called her husband to tell him she would be traveling to Selma after hearing the Rev Dr. Martin Luther King, Jr. call for people of all faiths to come and help, saying that the struggle \"was everybody's fight.\" Leaving her children in the care of family and friends she contacted the Southern Christian Leadership Conference who took her on and tasked her with delivering aid to various locations, welcoming and recruiting volunteers and transporting volunteers and marchers to and from airports, bus terminals and train stations, for which she volunteered the use of her car, a 1963 Oldsmobile.\n\nOn March 21, 1965 more than 3,000 people began the third march, including blacks, whites, doctors, nurses, working-class people, priests, nuns, rabbis, homemakers, students, actors, and farmers. Many famous people participated, including Dr. Martin Luther King, Ralph Bunche, Coretta Scott King, Ralph Abernathy, and Andrew Young. It took five days for the protesters to reach their goal. Liuzzo marched the first full day and returned to Selma for the night. That Wednesday, March 24, she rejoined the march four miles from the end, where a \"Night of the Stars\" celebration was held the City of St. Jude with performances by many popular entertainers of the day, including Harry Belafonte, Sammy Davis, Jr., Joan Baez, and Dick Gregory. Liuzzo helped at the first aid station. On Thursday, Liuzzo and other marchers reached the state capitol building, with a Confederate flag flying above it. Martin Luther King addressed the crowd of 25,000, calling the march, a \"shining moment in American history.\"\n\nAfter the third march concluded on March 25, Liuzzo, assisted by Leroy Moton, a 19-year-old African American, continued shuttling marchers and volunteers from Montgomery back to Selma in her car. As they were driving along Route 80, a car tried to force them off the road. After dropping passengers in Selma, she and Moton headed back to Montgomery. As they were getting gas at a local filling station, they were subject to abusive calls and racist scorn. When Liuzzo stopped at a red light, a car with four members of the local Ku Klux Klan pulled up alongside her. When they saw a white woman and a black man in a car together, they followed Liuzzo as she tried to outrun them. Overtaking the Oldsmobile, they shot directly at Liuzzo, mortally wounding her twice in the head. The car veered into a ditch, crashing into a fence.\n\nAlthough Moton was covered with blood, the bullets missed him. He lay motionless when the Klansmen reached the car to check on their victims. After the Klansmen left, Moton began searching for help, and eventually flagged down a truck driven by Rev. Leon Riley. Like Moton and Liuzzo, Riley was shuttling civil rights workers back to Selma.\n\nLiuzzo's funeral was held at Immaculate Heart of Mary Catholic Church on March 30 in Detroit, with many prominent members of both the civil rights movement and government there to pay their respects. Included in this group were Dr. Martin Luther King, Jr.; NAACP executive director Roy Wilkins; Congress on Racial Equality national leader James Farmer; Michigan lieutenant governor William G. Milliken; Teamsters president Jimmy Hoffa; and United Auto Workers president Walter Reuther. She was buried at Holy Sepulchre Cemetery in Southfield, Michigan.\n\nLess than two weeks after her death, a charred cross was found in front of four Detroit homes, including the Liuzzo residence.\n\nThe four Klan members in the car, Collie Wilkins (21), FBI informant Gary Rowe (34), William Eaton (41) and Eugene Thomas (42) were quickly arrested; within 24 hours, President Lyndon Johnson appeared on national television to announce their arrest. In order to avoid bad press, President Johnson made sure to focus on the positive work of the FBI agents' solving of the murder of Viola Liuzzo, in an attempt to divert scrutiny away from the fact that one of the men in the car, Gary Thomas Rowe, Jr., was an FBI informant and therefore protected by the FBI.\n\nWilkins, Eaton, and Thomas were indicted in the State of Alabama for Liuzzo's death on April 22. FBI informant Rowe was not indicted and served as a witness. Rowe testified that Wilkins had fired two shots on the order of Thomas.\n\nThe next phase of the lengthy process began when a federal trial charged the defendants with conspiracy to intimidate African Americans under the 1871 Ku Klux Klan Act, a Reconstruction civil rights statute. The charges did not specifically refer to Liuzzo's murder. On December 3, the trio were found guilty by an all-white, all-male jury, and were sentenced to ten years in prison, a landmark in Southern legal history.\n\nWhile out on appeal, Wilkins and Thomas were each found guilty of firearms violations and sent to jail for those crimes. During this period, the January 15, 1966, edition of the \"Birmingham News\" published an ad offering Liuzzo's bullet-ridden car for sale. Asking $3,500, the ad read, \"Do you need a crowd-getter? I have a 1963 Oldsmobile two-door in which Mrs. Viola Liuzzo was killed. Bullet holes and everything intact. Ideal to bring in crowds.\"\n\nAfter all three defendants were convicted of the federal charges, state murder cases proceeded against Eaton and Thomas. Eaton, the only defendant who remained out of jail, died of a heart attack on March 9. Thomas's state murder trial – the final trial – got under way on September 26, 1966. The prosecution built a strong circumstantial case in the trial that included an FBI ballistics expert testifying that the bullet removed from the woman's brain was fired from a revolver owned by Thomas. Two witnesses testified they had seen Wilkins drinking beer at a VFW Hall near Birmingham, 125 miles from the murder scene, an hour or less after Liuzzo was shot. Despite the presence of eight African Americans on the jury, Thomas was acquitted of the state murder charge the following day after just 90 minutes of deliberations. State attorney general Richmond Flowers, Sr. criticized the verdict, deriding the black members of the panel, who had been carefully screened, as \"Uncle Toms.\"\n\nOn April 27, 1967, the Fifth Circuit Court of Appeals in New Orleans upheld the federal convictions of the surviving defendants. Thomas served six years in prison for the crime. Due to threats from the Klan, both before and after his testimony, Gary Thomas Rowe went into the federal witness protection program. Rowe died in 1998 in Savannah, Georgia, after having lived several decades under several assumed identities.\n\nWithin 24 hours after Liuzzo's assassination by the Ku Klux Klan and the FBI's informant Gary Thomas Rowe, J. Edgar Hoover began a smear campaign to the press, to subordinate FBI agents and to select politicians, claiming the cut marks from the car's shattered window were \"puncture marks in her arm indicating recent use of a hypodermic needle; she was sitting very, very close to that negro in the car; that it has the appearance of a necking party.\"\n\nWhile attempting to obscure the fact that an FBI informant was in the car, and to ensure that the FBI was not held responsible for permitting their informant to participate in violent acts, without FBI surveillance or backup, the FBI was concerned that they might be held accountable for their informant's (Rowe) role in the death. Rowe had been an informant for the FBI since 1960. The FBI was aware that Rowe had participated in acts of violence during Ku Klux Klan activities. On the day of Liuzzo's death, prior to the shooting, Rowe called his FBI contact and notified him that Rowe and other Klansman were travelling to Montgomery, and that violence was planned.\n\nAutopsy testing in 1965 showed no traces of drugs in Liuzzo's system, and that she had not had sex recently at the time of death. The FBI's role in the smear campaign was uncovered in 1978 when Liuzzo's children obtained case documents from the FBI under the Freedom of Information Act.\n\nLiuzzo was condemned by different racist organizations for having brought her death upon herself. At the time, Liuzzo's choice to immerse herself in such a dangerous undertaking was seen by some as radical and controversial. However, of all the deaths to occur during the campaign, Liuzzo's was the only one scrutinized in such a way, where other male activists who were killed were recognized as heroes.\n\nRowe was indicted in 1978 and tried for his involvement in the murder. The first trial ended in a hung jury, and the second trial ended in his acquittal.\n\nOn May 27, 1983, Judge Charles Wycliffe Joiner rejected the claims in the Liuzzo family lawsuit, saying there was \"no evidence the FBI was in any type of joint venture with Rowe or conspiracy against Mrs. Liuzzo. Rowe's presence in the car was the principal reason why the crime was solved so quickly.\" In response to the verdict, Liuzzo family lawyer Dean A. Robb said \"This is a terrible opinion. I'm shocked. I think this is incredible.\" In August 1983, the FBI was awarded $79,873 in court costs, but costs were later reduced to $3,645 after the ACLU appealed on behalf of the family.\n\nThe Walter P. Reuther Library contains original archival material surrounding Liuzzo and her case. The Viola Liuzzo Papers contain documentation of the events surrounding the murder, the resulting investigation, and later legal involvement of the Liuzzo Family. The papers contain FBI murder investigation files and completed Freedom of Information and Privacy Act (FOIPA) requests for the FBI's involvement with the Ku Klux Klan. Several documents relate to the Freedom Riders.\n\nLiuzzo was featured in part 3 of a series of videos, \"Free at Last: Civil Rights Heroes\".\n\nHer murder was shown in Episode 2 of the \"King\" miniseries.\n\nViola Liuzzo Park is located at Winthrop and Trojan in Detroit.\n\nLiuzzo has her name included as part of the Civil Rights Memorial, a monument in Montgomery, Alabama, created by Maya Lin.\n\nIn 2004, Liuzzo was the subject of a documentary, \"Home of the Brave\".\n\nIn 2008, Liuzzo's story was memorialized in a song, \"Color Blind Angel\" by the late blues singer Robin Rogers on her album \"Treat Me Right\".\n\nIn 2011, the Viola Liuzzo Ethics Scholarship was started at Adrian College by her grandson, Joshua James Liuzzo.\n\nIn 2014, \"Outside Agitators\" was written by 20% Theater's Artistic Associate, Laura Nessler. Inspired by and based on Liuzzo's story, the play premiered at the Prop Theater in Chicago, Illinois, on September 20.\n\nLiuzzo was played by Tara Ochs in the 2014 film \"Selma\".\n\nIn 2015, Wayne State University bestowed its first posthumous honorary doctorate degree on Liuzzo.\n\n\n\n"}
{"id": "228178", "url": "https://en.wikipedia.org/wiki?curid=228178", "title": "Vipāka", "text": "Vipāka\n\nVipāka (Sanskrit and Pāli) is a Buddhist term for the ripening or maturation of \"karma\" (Pāli \"kamma\"), or intentional actions. The theory of karmic action and result (\"kamma-vipāka\") is a central belief within the Buddhist tradition.\n\nThe term \"vipaka\" is translated as:\n\nThe Samyutta Nikaya states:\n\n\n"}
{"id": "43697903", "url": "https://en.wikipedia.org/wiki?curid=43697903", "title": "Waelz process", "text": "Waelz process\n\nThe Waelz process is a method of recovering zinc and other relatively low boiling point metals from metallurgical waste (typically EAF flue dust) and other recycled materials using a rotary kiln (waelz kiln).\n\nThe zinc enriched product is referred to as waelz oxide, and the reduced zinc by product as waelz slag.\n\nThe concept of using a rotary kiln for the recovery of Zinc by volatization dates to at least 1888. A process was patented by Edward Dedolph in 1910. Subsequently, the Dedpolph patent was taken up and developed by Metallgesellschaft (Frankfurt) with Chemische Fabrik Griesheim-Elektron but without leading to a production scale ready process. In 1923 the Krupp Grusonwerk independently developed a process (1923), named the \"Waelz process\" (from the German \"Waelzen\", a reference to the motion of the materials in the kiln); the two German firms later collaborated and improved the process marketing under the name \"Waelz-Gemeinschaft\" (German for Waelz association).\n\nThe process consists of treating zinc containing material, in which zinc can be in the form zinc oxide, zinc silicate, zinc ferrite, zinc sulphide together with a carbon containing reductant/fuel, within a rotary kiln at 1000 °C to 1500 °C. The kiln feed material comprising zinc 'waste', fluxes and reductant (coke) is typically pelletized before addition to the kiln. The chemical process involves the reduction of zinc compounds to elemental zinc (boiling point 907 °C) which volatalises, which oxidises in the vapour phase to zinc oxide. The zinc oxide is collected from the kiln outlet exhaust by filters/electrostatic precipitators/settling chambers etc.\n\nKiln size is typically long / internal diameter, with a rotation speed of around 1 rpm. The recovered dust (\"Waelz oxide\") is enriched in zinc oxide and is a feed product for zinc smelters, the zinc reduced by-product is known as \"Waelz slag\". Sub-optimal features of the process are high energy consumption, and lack of iron recovery (and iron rich slag). The process also captures other low boiling metals in the \"waelz oxide\" including lead, cadmium and silver. Halogen compounds are also present in the product oxide.\n\nIncreased use of galvanised steel has resulted in increased levels of zinc in steel scrap which in turn leads to higher levels of zinc in electric arc furnace flue dusts - as of 2000 the waelz process is considered to be a \"best available technology\" for flue dust zinc recovery, and the process is used at industrial scale worldwide.\n\nAs of 2014 the Waelz process is the preferred or most widely used process for zinc recovery of zinc from electric arc furnace dust (90%).\n\nAlternative production and experimental scale zinc recovery processes include the rotary hearth treatment of pelletised zinc containing dust (Kimitsu works, Nippon Steel); the SDHL (Saage, Dittrich, Hasche, Langbein) process, an efficiency modification of the Waelz process; the \"DK process\" a modified blast furnace process producing pig iron and zinc (oxide) dust from blast furnace dusts, sludges and other wastes; and the PRIMUS process (multi-stage zinc volatilisation furnace).\n\n"}
{"id": "2583747", "url": "https://en.wikipedia.org/wiki?curid=2583747", "title": "Work of art", "text": "Work of art\n\nA work of art, artwork, art piece, piece of art or art object is an aesthetic physical item or artistic creation. Apart from \"work of art\", which may be used of any work regarded as art in its widest sense, including works from literature and music, these terms apply principally to tangible, portable forms of visual art: \nUsed more broadly, the term is less commonly applied to:\n\nThis article is concerned with the terms and concept as used in and applied to the visual arts, although other fields such as aural-music and written word-literature have similar issues and philosophies. The term \"objet d'art\" is reserved to describe works of art that are not paintings, prints, drawings or large or medium-sized sculptures, or architecture (e.g. household goods, figurines, etc., some purely aesthetic, some also practical). The term oeuvre is used to describe the complete body of work completed by an artist throughout a career.\n\nA \"work of art\" in the visual arts is a physical two- or three- dimensional object that is professionally determined or otherwise considered to fulfill a primarily independent aesthetic function. A singular art object is often seen in the context of a larger art movement or artistic era, such as: a genre, aesthetic convention, culture, or regional-national distinction. It can also be seen as an item within an artist's \"body of work\" or \"oeuvre\". The term is commonly used by: museum and cultural heritage curators, the interested public, the art patron-private art collector community, and art galleries.\n\nPhysical objects that document immaterial or conceptual art works, but do not conform to artistic conventions can be redefined and reclassified as art objects. Some Dada and Neo-Dada conceptual and readymade works have received later inclusion. Also, some architectural renderings and models of unbuilt projects, such as by Vitruvius, Leonardo da Vinci, Frank Lloyd Wright, and Frank Gehry, are other examples.\n\nThe products of environmental design, depending on intention and execution, can be \"works of art\" and include: land art, site-specific art, architecture, gardens, landscape architecture, installation art, rock art, and megalithic monuments.\n\nLegal definitions of \"work of art\" are used in copyright law; \"see \".\n\nMarcel Duchamp critiqued the idea that the work of art should be a unique product of an artist's labour, representational of their technical skill or artistic caprice. Theorists have argued that objects and people do not have a constant meaning, but their meanings are fashioned by humans in the context of their culture, as they have the ability to make things mean or signify something.\n\nArtist Michael Craig-Martin, creator of \"An Oak Tree\", said of his work – \"It's not a symbol. I have changed the physical substance of the glass of water into that of an oak tree. I didn't change its appearance. The actual oak tree is physically present, but in the form of a glass of water.\"\n\nSome art theorists and writers have long made a distinction between the physical qualities of an art object and its identity-status as an artwork. For example, a painting by Rembrandt has a physical existence as an \"oil painting on canvas\" that is separate from its identity as a masterpiece \"work of art\" or the artist's \"magnum opus\". Many works of art are initially denied \"museum quality\" or artistic merit, and later become accepted and valued in museum and private collections. Works by the Impressionists and non-representational abstract artists are examples. Some, such as the \"Readymades\" of Marcel Duchamp including his infamous urinal \"Fountain\", are later reproduced as museum quality replicas.\n\nThere is an indefinite distinction, for current or historical aesthetic items: between \"fine art\" objects made by \"artists\"; and folk art, craft-work, or \"applied art\" objects made by \"first, second, or third-world\" designers, artisans and craftspeople. Contemporary and archeological indigenous art, industrial design items in limited or mass production, and places created by environmental designers and cultural landscapes, are some examples. The term has been consistently available for debate, reconsideration, and redefinition.\n\n\n"}
