{"id": "5506090", "url": "https://en.wikipedia.org/wiki?curid=5506090", "title": "Agni (Ayurveda)", "text": "Agni (Ayurveda)\n\nAgni in Samskrita means \"fire\", and according to Ayurveda Agni happens to be the entity that is responsible for all digestive and metabolic processes in the human beings.\n\nDepending upon the stage of metabolism where a specific Agni is functionally active, Agni has been classified into three sub-classes: 'Jaṭharāgni', 'Bhūtāgni' and 'Dhātvagni'.\n\nWhile Jaṭharāgni acts on the food in the digestive tract and converts it into absorbable form, the Bhūtāgni acts after the digested material has been absorbed.\n\nBhūtāgni is of 5 types. Each of these 5 acts on the 5 primordial constituents of the absorbed food: Earth, Water, Fire, Air, and Space. These 5 Bhutagnis transform the substrates into such form that can be assimilated at tissue level.\n\nThe third class of Agni, the Dhātvagni, acts at the level of tissue metabolism and is helpful in the tissue nourishment tissue metabolism. This is of 7 types based on the kind of tissue that it helps nourishing.\n\nFurther, Ayurveda recognizes four functional states of Agni: regular, irregular, intense, and weak. \n\nSamāgni ensures complete digestion of the food ingested at the proper time without any irregularity. Its activity is neither too intense nor too weak. It is just appropriate and therefore, is ideal too. This results when all Doshas, Vata-Pitta-Kapha are in a state of equilibrium.\n\nVişamāgni represents an unpredictable state of Agni, which is due to the dominance of Vayu. It sometimes quickly digests the food and at other times it does so very slowly, representing unpredictability.\n\nTīkşņāgni results because of the dominance of Pitta which is intense, and hence, it easily digests even a very heavy meal, in a very short span of time.\n\nMandāgni is opposite to the Tīkşņāgni: it is subdued in its activity. This Agni is unable to digest and metabolize even a small quantity of food. This state of Agni is a result of the dominance of Kapha.\n\n"}
{"id": "58662817", "url": "https://en.wikipedia.org/wiki?curid=58662817", "title": "Altamuran Revolution", "text": "Altamuran Revolution\n\nThe Altamuran Revolution (, also \"Rivoluzione altamurana\") was a three month period of self-government of Italian town Altamura, right after the birth of the Parthenopean Republic (23 January 1799) which ousted the Bourbons and the Kingdom of Naples. The city of the Kingdom of Naples was then defeated and taken by the so-called Sanfedisti, led by cardinal Fabrizio Ruffo, after a battle on the city walls. After being defeated, most Altamurans managed to flee from \"porta Bari\", one of Altamura's main gates.\n\nIn February 1799, the news that the king had fled to Palermo arrived in Altamura. Altamura population then reorganized and embraced the ideals propagated by the French Revolution. The Liberty Tree was also planted in what it was then called \"piazza del mercato\" (today it's called \"piazza Duomo\"). In the meantime, the Sanfedisti,led by the cardinal Fabrizio Ruffo, were getting closer and closer, determined to restore the Kingdom of Naples and the Bourbons dynasty. Sanfedisti left Matera and arrived at the gates of Altamura on 9 May 1799. Altamura had already fixed everything before the battle, by closing the secondary city gates, fusing the church bells in order to make new cannons and preparing ammunition. On 9 May, the battle took place, but soon Altamurans ran off of ammunition and they started to shoot coins. This let the enemy realize that the situation inside the city was critical and that they wouldn't last for long. On the night of 9 May 1799, most Altamurans managed to escape from \"porta Bari\" (perhaps accidentally or thanks to Ruffo unbeknown to his troops). On the morning of 10 May, Sanfedisti entered Altamura, sacking and slaughtering an unknown number of Altamurans who had remained there. The stay of Sanfedisti and Ruffo inside the city lasted 14 days, during which Altamurans gradually returned and some of them were killed or imprisoned. By the end of May 1799, the situation had already normalized and Altamura had returned under the full control of the Kingdom of Naples.\n\nThe number of deaths among Sanfedisti has been estimated at around 1,400 people, but it is not clear how many Altamurans were killed. Some historians estimated the losses among Altamurans from about forty to a hundred people, while other historians suggested that many Altamurans and Neapolitan Jacobin people from other cities may have been counted as Sanfedisti. In this case, the death toll among Altamurans and Parthenopean Republicans would be much higher.\n\n\n"}
{"id": "4740896", "url": "https://en.wikipedia.org/wiki?curid=4740896", "title": "Ambiguity effect", "text": "Ambiguity effect\n\nThe ambiguity effect is a cognitive bias where decision making is affected by a lack of information, or \"ambiguity\". The effect implies that people tend to select options for which the probability of a favorable outcome is known, over an option for which the probability of a favorable outcome is unknown. The effect was first described by Daniel Ellsberg in 1961.\n\nWhen buying a house, many people choose a fixed rate mortgage, where the interest rate is set in stone, over a variable rate mortgage, where the interest rate fluctuates with the market. This is the case even though a variable rate mortgage has statistically been shown to save money.\n\nAs an example, consider a bucket containing 30 balls. The balls are either red, black or white. Ten of the balls are red, and the remaining 20 are either black or white, with all combinations of black and white being equally likely. In option X, drawing a red ball wins a person $100, and in option Y, drawing a black ball wins them $100. The probability of picking a winning ball is the same for both options X and Y. In option X, the probability of selecting a winning ball is 1 in 3 (10 red balls out of 30 total balls). In option Y, despite the fact that the number of black balls is uncertain, the probability of selecting a winning ball is also 1 in 3. This is because the number of black balls is equally distributed among all possibilities between 0 and 20. The difference between the two options is that in option X, the probability of a favorable outcome is known, but in option Y, the probability of a favorable outcome is unknown (\"ambiguous\").\n\nIn spite of the equal probability of a favorable outcome, people have a greater tendency to select a ball under option X, where the probability of selecting a winning ball is perceived to be more certain. The uncertainty as to the number of black balls means that option Y tends to be viewed less favorably. Despite the fact that there could possibly be twice as many black balls as red balls, people tend not to want to take the opposing risk that there may be fewer than 10 black balls. The \"ambiguity\" behind option Y means that people tend to favor option X, even when the probability is the same.\n\nA more realistic example might be the way people invest money. A risk-averse investor might tend to put their money into \"safe\" investments such as government bonds and bank deposits, as opposed to more volatile investments such as stocks and funds. Even though the stock market is likely to provide a significantly higher return over time, the investor might prefer the \"safe\" investment in which the return is known, instead of the less predictable stock market in which the return is not known. The ambiguity effect is a possible explanation why people are reluctant to adopt new practices in the work place.\n\nIt is human to avoid ambiguous knowledge - to assume things are knowable when they are not. This is related to the clustering illusion. When presented with large amounts of confounding variables, people still tend to claim knowledge of the unknowable. This produces cognitive dissonance which when avoided leads people to try to change venues to something with more certainty.\n\nOne possible explanation of the effect is that people have a rule of thumb (heuristic) to avoid options where information is missing. This will often lead them to seek out the missing information. In many cases, though, the information cannot be obtained. The effect is often the result of calling some particular missing piece of information to the person's attention.\n\n"}
{"id": "69274", "url": "https://en.wikipedia.org/wiki?curid=69274", "title": "Animal echolocation", "text": "Animal echolocation\n\nEcholocation, also called bio sonar, is the biological sonar used by several kinds of animals.\nEcholocating animals emit calls out to the environment and listen to the echoes of those calls that return from various objects near them. They use these echoes to locate and identify the objects. Echolocation is used for navigation and for foraging (or hunting) in various environments.\n\nEcholocating animals include some mammals and a few birds; most notably microchiropteran bats and odontocetes (toothed whales and dolphins), but also in simpler form in other groups such as shrews, one genus of megachiropteran bats (\"Rousettus\") and two cave dwelling bird groups, the so-called cave swiftlets in the genus \"Aerodramus\" (formerly \"Collocalia\") and the unrelated Oilbird \"Steatornis caripensis\".\n\nThe term \"echolocation\" was coined by the American zoologist Donald Griffin, whose work with Robert Galambos was the first to convincingly demonstrate its existence in bats in 1938. As Griffin described in his book, the 18th century Italian scientist Lazzaro Spallanzani had, by means of a series of elaborate experiments, concluded that when bats fly at night, they rely on some sense besides vision, but he did not discover that the other sense was hearing. The Swiss physician and naturalist Louis Jurine repeated Spallanzani's experiments (using different species of bat), and concluded that when bats hunt at night, they rely on hearing. In 1908, Walter Louis Hahn confirmed Spallanzani's and Jurine's findings.\n\nIn 1912, the inventor Hiram Maxim independently proposed that bats used sound below the human auditory range to avoid obstacles. In 1920, the English physiologist Hamilton Hartridge correctly proposed instead that bats used frequencies above the range of human hearing.\n\nEcholocation in odontocetes (toothed whales) was not properly described until two decades after Griffin and Galambos' work, by Schevill and McBride in 1956. However, in 1953, Jacques Yves Cousteau suggested in his first book, \"\" (pp. 206–207) that porpoises had something like sonar, judging by their navigational abilities.\n\nEcholocation is the same as active sonar, using sounds made by the animal itself. Ranging is done by measuring the time delay between the animal's own sound emission and any echoes that return from the environment. The relative intensity of sound received at each ear as well as the time delay between arrival at the two ears provide information about the horizontal angle (azimuth) from which the reflected sound waves arrive.\n\nUnlike some human-made sonars that rely on many extremely narrow beams and many receivers to localize a target (multibeam sonar), animal echolocation has only one transmitter and two receivers (the ears) positioned slightly apart. The echoes returning to the ears arrive at different times and at different loudness levels, depending on the position of the object generating the echoes. The time and loudness differences are used by the animals to perceive distance and direction. With echolocation, the bat or other animal can see not only where it is going but also how big another animal is, what kind of animal it is, and other features..\n\nAt the most basic level, echolocation is based on the neural anatomy of auditory brain circuitry. In essence, ascending brain pathways in the brain stem allow the brain to calculate the difference between the two ears to very small fractions of a second.\n\nMicrobats use echolocation to navigate and forage, often in total darkness. They generally emerge from their roosts in caves, attics, or trees at dusk and hunt for insects into the night. Their use of echolocation allows them to occupy a niche where there are often many insects (that come out at night since there are fewer predators then), less competition for food, and fewer species that may prey on the bats themselves.\n\nMicrobats generate ultrasound via the larynx and emit the sound through the open mouth or, much more rarely, the nose. The latter is most pronounced in the horseshoe bats (\"Rhinolophus spp.\"). Microbat range in frequency from 14,000 to well over 100,000 Hz, mostly beyond the range of the human ear (typical human hearing range is considered to be from 20 Hz to 20,000 Hz). Bats may estimate the elevation of targets by interpreting the interference patterns caused by the echoes reflecting from the tragus, a flap of skin in the external ear.\n\nThere are two hypotheses about the evolution of echolocation in bats. The first suggests that laryngeal echolocation evolved twice in Chiroptera, once in the Yangochiroptera and once in the horseshoe bats (Rhinolophidae). The second proposes that laryngeal echolocation had a single origin in Chiroptera, was subsequently lost in the family Pteropodidae (all megabats), and later evolved as a system of tongue-clicking in the genus \"Rousettus\".\n\nIndividual bat species echolocate within specific frequency ranges that suit their environment and prey types. This has sometimes been used by researchers to identify bats flying in an area simply by recording their calls with ultrasonic recorders known as \"bat detectors\". However echolocation calls are not always species specific and some bats overlap in the type of calls they use so recordings of echolocation calls cannot be used to identify all bats. In recent years researchers in several countries have developed \"bat call libraries\" that contain recordings of local bat species that have been identified known as \"reference calls\" to assist with identification.\n\nSince the 1970s there has been an ongoing controversy among researchers as to whether bats use a form of processing known from radar termed coherent cross-correlation. Coherence means that the phase of the echolocation signals is used by the bats, while cross-correlation just implies that the outgoing signal is compared with the returning echoes in a running process. Today most – but not all – researchers believe that they use cross-correlation, but in an incoherent form, termed a filter bank receiver.\n\nWhen searching for prey they produce sounds at a low rate (10–20 clicks/second). During the search phase the sound emission is coupled to respiration, which is again coupled to the wingbeat. This coupling appears to dramatically conserve energy as there is little to no additional energetic cost of echolocation to flying bats. After detecting a potential prey item, microbats increase the rate of pulses, ending with the terminal buzz, at rates as high as 200 clicks/second. During approach to a detected target, the duration of the sounds is gradually decreased, as is the energy of the sound.\n\nBats belonging to the suborder Microchiroptera (microbats) occupy a diverse set of ecological conditions – they can be found living in environments as different as Europe and Madagascar, and hunting for food sources as different as insects, frogs, nectar, fruit, and blood. Additionally, the characteristics of an echolocation call are adapted to the particular environment, hunting behavior, and food source of the particular bat. However, this adaptation of echolocation calls to ecological factors is constrained by the phylogenetic relationship of the bats, leading to a process known as descent with modification, and resulting in the diversity of the Microchiroptera today.\n\nDescribing the diversity of bat echolocation calls requires examination of the frequency and temporal features of the calls. It is the variations in these aspects that produce echolocation calls suited for different acoustic environments and hunting behaviors.\n\nBat call frequencies range from as low as 11 kHz to as high as 212 kHz. Insectivorous aerial-hawking bats have a call frequency between 20 kHz and 60 kHz because it is the frequency that gives the best range and image acuity and makes them less conspicuous to insects. However, low frequencies are adaptive for some species with different prey and environments. \"Euderma maculatum\", a species that feeds on moths, uses a particularly low frequency of 12.7 kHz that cannot be heard by moths.\n\nEcholocation calls can be composed of two different types of frequency structure: frequency modulated (FM) sweeps, and constant frequency (CF) tones. A particular call can consist of one, the other, or both structures. An FM sweep is a broadband signal – that is, it contains a downward sweep through a range of frequencies. A CF tone is a narrowband signal: the sound stays constant at one frequency throughout its duration.\n\nEcholocation calls have been measured at intensities anywhere between 60 and 140 decibels. Certain microbat species can modify their call intensity mid-call, lowering the intensity as they approach objects that reflect sound strongly. This prevents the returning echo from deafening the bat. High-intensity calls such as those from aerial-hawking bats (133 dB) are adaptive to hunting in open skies. Their high intensity calls are necessary to even have moderate detection of surroundings because air has a high absorption of ultrasound and because insects’ size only provide a small target for sound reflection. Additionally, the so-called \"whispering bats\" have adapted low-amplitude echolocation so that their prey, moths, which are able to hear echolocation calls, are less able to detect and avoid an oncoming bat.\n\nCalls can be composed of one frequency or multiple frequencies comprising a harmonic series. In the latter case, the call is usually dominated by a certain harmonic (\"dominant\" frequencies are those present at higher intensities than other harmonics present in the call).\n\nA single echolocation call (a call being a single continuous trace on a sound spectrogram, and a series of calls comprising a sequence or pass) can last anywhere from 0.2 to 100 milliseconds in duration, depending on the stage of prey-catching behavior that the bat is engaged in. For example, the duration of a call usually decreases when the bat is in the final stages of prey capture – this enables the bat to call more rapidly without overlap of call and echo. Reducing duration comes at the cost of having less total sound available for reflecting off objects and being heard by the bat.\n\nThe time interval between subsequent echolocation calls (or pulses) determines two aspects of a bat's perception. First, it establishes how quickly the bat's auditory scene information is updated. For example, bats increase the repetition rate of their calls (that is, decrease the pulse interval) as they home in on a target. This allows the bat to get new information regarding the target's location at a faster rate when it needs it most. Secondly, the pulse interval determines the maximum range that bats can detect objects. This is because bats can only keep track of the echoes from one call at a time; as soon as they make another call they stop listening for echoes from the previously made call. For example, a pulse interval of 100 ms (typical of a bat searching for insects) allows sound to travel in air roughly 34 meters so a bat can only detect objects as far away as 17 meters (the sound has to travel out and back). With a pulse interval of 5 ms (typical of a bat in the final moments of a capture attempt), the bat can only detect objects up to 85 cm away. Therefore, the bat constantly has to make a choice between getting new information updated quickly and detecting objects far away.\n\nThe major advantage conferred by an FM signal is extremely precise range discrimination, or localization, of the target. J.A. Simmons demonstrated this effect with a series of elegant experiments that showed how bats using FM signals could distinguish between two separate targets even when the targets were less than half a millimeter apart. This ability is due to the broadband sweep of the signal, which allows for better resolution of the time delay between the call and the returning echo, thereby improving the cross correlation of the two. Additionally, if harmonic frequencies are added to the FM signal, then this localization becomes even more precise.\n\nOne possible disadvantage of the FM signal is a decreased operational range of the call. Because the energy of the call is spread out among many frequencies, the distance at which the FM-bat can detect targets is limited. This is in part because any echo returning at a particular frequency can only be evaluated for a brief fraction of a millisecond, as the fast downward sweep of the call does not remain at any one frequency for long.\n\nThe structure of a CF signal is adaptive in that it allows the CF-bat to detect both the velocity of a target, and the fluttering of a target's wings as Doppler shifted frequencies. A Doppler shift is an alteration in sound wave frequency, and is produced in two relevant situations: when the bat and its target are moving relative to each other, and when the target's wings are oscillating back and forth. CF-bats must compensate for Doppler shifts, lowering the frequency of their call in response to echoes of elevated frequency – this ensures that the returning echo remains at the frequency to which the ears of the bat are most finely tuned. The oscillation of a target's wings also produces amplitude shifts, which gives a CF-bat additional help in distinguishing a flying target from a stationary one.\n\nAdditionally, because the signal energy of a CF call is concentrated into a narrow frequency band, the operational range of the call is much greater than that of an FM signal. This relies on the fact that echoes returning within the narrow frequency band can be summed over the entire length of the call, which maintains a constant frequency for up to 100 milliseconds.\n\nA frequency modulated (FM) component is excellent for hunting prey while flying in close, cluttered environments. Two aspects of the FM signal account for this fact: the precise target localization conferred by the broadband signal, and the short duration of the call. The first of these is essential because in a cluttered environment, the bats must be able to resolve their prey from large amounts of background noise. The 3D localization abilities of the broadband signal enable the bat to do exactly that, providing it with what Simmons and Stein (1980) call a \"clutter rejection strategy.\" This strategy is further improved by the use of harmonics, which, as previously stated, enhance the localization properties of the call. The short duration of the FM call is also best in close, cluttered environments because it enables the bat to emit many calls extremely rapidly without overlap. This means that the bat can get an almost continuous stream of information – essential when objects are close, because they will pass by quickly – without confusing which echo corresponds to which call.\n\nA constant frequency (CF) component is often used by bats hunting for prey while flying in open, clutter-free environments, or by bats that wait on perches for their prey to appear. The success of the former strategy is due to two aspects of the CF call, both of which confer excellent prey-detection abilities. First, the greater working range of the call allows bats to detect targets present at great distances – a common situation in open environments. Second, the length of the call is also suited for targets at great distances: in this case, there is a decreased chance that the long call will overlap with the returning echo. The latter strategy is made possible by the fact that the long, narrowband call allows the bat to detect Doppler shifts, which would be produced by an insect moving either towards or away from a perched bat.\n\nBecause bats use echolocation to orient themselves and to locate objects, their auditory systems are adapted for this purpose, highly specialized for sensing and interpreting the stereotyped echolocation calls characteristic of their own species. This specialization is evident from the inner ear up to the highest levels of information processing in the auditory cortex.\n\nBoth CF and FM bats have specialized inner ears which allow them to hear sounds in the ultrasonic range, far outside the range of human hearing. Although in most other aspects, the bat's auditory organs are similar to those of most other mammals, certain bats (horseshoe bats, \"Rhinolophus spp.\" and the moustached bat, \"Pteronotus parnelii\") with a constant frequency (CF) component to their call (known as high duty cycle bats) do have a few additional adaptations for detecting the predominant frequency (and harmonics) of the CF vocalization. These include a narrow frequency \"tuning\" of the inner ear organs, with an especially large area responding to the frequency of the bat's returning echoes.\n\nThe basilar membrane within the cochlea contains the first of these specializations for echo information processing. In bats that use CF signals, the section of membrane that responds to the frequency of returning echoes is much larger than the region of response for any other frequency. For example, in the greater horseshoe bat, \"Rhinolophus ferrumequinum\", there is a disproportionately lengthened and thickened section of the membrane that responds to sounds around 83 kHz, the constant frequency of the echo produced by the bat's call. This area of high sensitivity to a specific, narrow range of frequency is known as an \"acoustic fovea\".\n\nOdontocetes (toothed whales and dolphins) have similar cochlear specializations to those found in bats. Odontocetes also have the highest neural investment of any cochleae reported to date with ratios of greater than 1500 ganglion cells/mm of basilar membrane.\n\nFurther along the auditory pathway, the movement of the basilar membrane results in the stimulation of primary auditory neurons. Many of these neurons are specifically \"tuned\" (respond most strongly) to the narrow frequency range of returning echoes of CF calls. Because of the large size of the acoustic fovea, the number of neurons responding to this region, and thus to the echo frequency, is especially high.\n\nIn the Inferior colliculus, a structure in the bat's midbrain, information from lower in the auditory processing pathway is integrated and sent on to the auditory cortex. As George Pollak and others showed in a series of papers in 1977, the interneurons in this region have a very high level of sensitivity to time differences, since the time delay between a call and the returning echo tells the bat its distance from the target object. While most neurons respond more quickly to stronger stimuli, collicular neurons maintain their timing accuracy even as signal intensity changes.\n\nThese interneurons are specialized for time sensitivity in several ways. First, when activated, they generally respond with only one or two action potentials. This short duration of response allows their action potentials to give a very specific indication of the exact moment of the time when the stimulus arrived, and to respond accurately to stimuli that occur close in time to one another. In addition, the neurons have a very low threshold of activation – they respond quickly even to weak stimuli. Finally, for FM signals, each interneuron is tuned to a specific frequency within the sweep, as well as to that same frequency in the following echo. There is specialization for the CF component of the call at this level as well. The high proportion of neurons responding to the frequency of the acoustic fovea actually increases at this level.\n\nThe auditory cortex in bats is quite large in comparison with other mammals. Various characteristics of sound are processed by different regions of the cortex, each providing different information about the location or movement of a target object. Most of the existing studies on information processing in the auditory cortex of the bat have been done by Nobuo Suga on the mustached bat, \"Pteronotus parnellii\". This bat's call has both CF tone and FM sweep components.\n\nSuga and his colleagues have shown that the cortex contains a series of \"maps\" of auditory information, each of which is organized systematically based on characteristics of sound such as frequency and amplitude. The neurons in these areas respond only to a specific combination of frequency and timing (sound-echo delay), and are known as combination-sensitive neurons.\n\nThe systematically organized maps in the auditory cortex respond to various aspects of the echo signal, such as its delay and its velocity. These regions are composed of \"combination sensitive\" neurons that require at least two specific stimuli to elicit a response. The neurons vary systematically across the maps, which are organized by acoustic features of the sound and can be two dimensional. The different features of the call and its echo are used by the bat to determine important characteristics of their prey. The maps include:\n\n\nBiosonar is valuable to toothed whales (suborder Odontoceti), including dolphins, porpoises, river dolphins, killer whales and sperm whales, because they live in an underwater habitat that has favourable acoustic characteristics and where vision is extremely limited in range due to absorption or turbidity.\n\nCetacean evolution consisted of three main radiations. Throughout the middle and late Eocene periods (49-31.5 million years ago), archaeocetes, primitive toothed Cetacea that arose from terrestrial mammals with the creation of aquatic adaptations, were the only known archaic Cetacea. These primitive aquatic mammals did not possess the ability to echolocate, although they did have slightly adapted underwater hearing. The morphology of acoustically isolated ear bones in basilosaurid archaeocetes indicates that this order had directional hearing underwater at low to mid frequencies by the late middle Eocene. However, with the extinction of archaeocete at the onset of the Oligocene, two new lineages in the early Oligocene period (31.5-28 million years ago) comprised a second radiation. These early mysticetes (baleen whales) and odontocetes can be dated back to the middle Oligocene in New Zealand. Based on past phylogenies, it has been found that the evolution of odontocetes is monophyletic, suggesting that echolocation evolved only once 36 to 34 million years ago. Dispersal rates routes of early odontocetes included transoceanic travel to new adaptive zones. The third radiation occurred later in the Neogene, when present dolphins and their relatives evolved to be the most common species in the modern sea.\n\nThe evolution of echolocation could be attributed to several theories. There are two proposed drives for the hypotheses of cetacean radiation, one biotic and the other abiotic in nature. The first, adaptive radiation, is the result of a rapid divergence into new adaptive zones. This results in diverse, ecologically different clades that are incomparable. Clade Neocete (crown cetacean) has been characterized by an evolution from archaeocetes and a dispersion across the world's oceans, and even estuaries and rivers. These ecological opportunities were the result of abundant dietary resources with low competition for hunting. This hypothesis of lineage diversification, however, can be unconvincing due to a lack of support for rapid speciation early in cetacean history. A second, more abiotic drive is better supported. Physical restructuring of the oceans has played a role in echolocation radiation. This was a result of global climate change at the Eocene-Oligocene boundary; from a greenhouse to an icehouse world. Tectonic openings created the emergence of the Southern ocean with a free flowing Antarctic Circumpolar current. These events allowed for a selection regime characterized by the ability to locate and capture prey in turbid river waters, or allow odontocetes to invade and feed at depths below the photic zone. Further studies have found that echolocation below the photic zone could have been a predation adaptation to diel migrating cephalopods. Since its advent, there has been adaptive radiation especially in the family Delphinidae (dolphins) in which echolocation has become extremely derived.\n\nTwo proteins have been found to play a major role in toothed whale echolocation. Prestin, a motor protein of the outer hair cells of the inner ear of the mammalian cochlea, has an association between the number of nonsynonymous substitutions and hearing sensitivity. It has undergone two clear episodes of accelerated protein evolution in cetaceans: on the ancestral branch of odontocetes and on the branch leading to delphinioidae. The first episode of acceleration is connected to odontocete divergence, when echolocation first developed, and the second occurs with the increase in echolocation frequency seen in the family Delphinioidae. Cldn14, a member of the tight junction proteins which form barriers between inner ear cells, shows exactly the same evolutionary pattern as Prestin. The two events of protein evolution, for Prestin and Cldn14, occurred at the same times as the tectonic opening of the Drake Passage (34-31 Ma) and the Antarctic ice growth at the middle Miocene climate transition (14 Ma), with the divergence of odontocetes and mysticetes occurring with the former, and the speciation of delphinioidae with the latter. There is a strong connection between these proteins, the ocean restructuring events, and the echolocation evolution.\n\nOne specific type of echolocation, narrow-band high frequency (NBHF) clicks, evolved at least four times in groups of odontocetes, including the pygmy sperm whale (Kogiidae) and porpoise (Phocoenidae) families, \"Pontoporia blainvillei\", the genus \"Cephalorhynchus\", and part of the genus \"Lagenorhynchus\". These high frequency clicks likely evolved as adaptation of predator avoidance, as they inhabit areas that have many killer whales and the signals are inaudible to killer whales due to the absence of energy below 100 kHz.\n\nAnother reason for variation in echolocation is habitat. For all sonar systems the limiting factor deciding whether a returning echo is detected is the echo-to-noise ratio (ENR). The ENR is given by the emitted source level (SL) plus the target strength, minus the two-way transmission loss (absorption and spreading) and the received noise. Animals will adapt either to maximize range under noise-limited conditions (increase source level) or to reduce noise clutter in a shallow and/or littered habitat (decrease source level). In cluttered habitats, such as coastal areas, prey ranges are smaller, and species like Commerson's dolphin (\"Cephalorhynchus commersonii'') have lowered source levels to better suit their environment.\n\nToothed whales emit a focused beam of high-frequency clicks in the direction that their head is pointing. Sounds are generated by passing air from the bony nares through the phonic lips. These sounds are reflected by the dense concave bone of the cranium and an air sac at its base. The focused beam is modulated by a large fatty organ known as the 'melon'. This acts like an acoustic lens because it is composed of lipids of differing densities. Most toothed whales use clicks in a series, or click train, for echolocation, while the sperm whale may produce clicks individually. Toothed whale whistles do not appear to be used in echolocation. Different rates of click production in a click train give rise to the familiar barks, squeals and growls of the bottlenose dolphin. A click train with a repetition rate over 600 per second is called a burst pulse. In bottlenose dolphins, the auditory brain response resolves individual clicks up to 600 per second, but yields a graded response for higher repetition rates.\n\nIt has been suggested that some smaller toothed whales may have their tooth arrangement suited to aid in echolocation. The placement of teeth in the jaw of a bottlenose dolphin, for example, are not symmetrical when seen from a vertical plane, and this asymmetry could possibly be an aid in the dolphin sensing if echoes from its biosonar are coming from one side or the other. However, this idea lacks experimental support.\n\nEchoes are received using complex fatty structures around the lower jaw as the primary reception path, from where they are transmitted to the middle ear via a continuous fat body. Lateral sound may be received though fatty lobes surrounding the ears with a similar density to water. Some researchers believe that when they approach the object of interest, they protect themselves against the louder echo by quietening the emitted sound. In bats this is known to happen, but here the hearing sensitivity is also reduced close to a target.\n\nOilbirds and some species of swiftlet are known to use a relatively crude form of echolocation compared to that of bats and dolphins. These nocturnal birds emit calls while flying and use the calls to navigate through trees and caves where they live.\n\nTerrestrial mammals other than bats known to echolocate include two genera (\"Sorex\" and \"Blarina\") of shrews and the tenrecs of Madagascar. These include the wandering shrew (\"Sorex vagrans\"), the common or Eurasian shrew (\"Sorex araneus\"), and the short-tailed shrew (\"Blarina brevicauda\"). The nature of shrew sounds unlike those of bats are low amplitude, broadband, multi-harmonic and frequency modulated. They contain no ‘echolocation clicks’ with reverberations and would seem to be used for simple, close range spatial orientation. In contrast to bats, shrews use echolocation only to investigate their habitat rather than additionally to pinpoint food.\n\nThere is evidence that blinded laboratory rats can use echolocation to navigate mazes.\n\nEcholocation systems are susceptible to interference known as echolocation jamming or sonar jamming. Jamming occurs when non-target sounds interfere with target echoes. Jamming can be purposeful or inadvertent and can be caused by the echolocation system itself, other echolocating animals, prey, or humans. Echolocating animals have evolved to minimize jamming; however, echolocation avoidance behaviors are not always successful.\n\n\"Galleria mellonella\" exhibits predator avoidance behaviors such as dropping, looping, and freezing when emitters sent out ultrasound waves, indicating that \"G. mellonella\" can both detect and differentiate between ultrasound frequencies used by predators or from other members of their species.\n\n\n\n\n\n\n\n\n\n"}
{"id": "4966559", "url": "https://en.wikipedia.org/wiki?curid=4966559", "title": "Avidyā (Buddhism)", "text": "Avidyā (Buddhism)\n\nAvidyā (Sanskrit; Pāli: \"avijjā\"; Tibetan phonetic: \"ma rigpa\") in Buddhist literature is commonly translated as \"ignorance\". The concept refers to ignorance or misconceptions about the nature of metaphysical reality, in particular about the impermanence and non-self doctrines about reality. It is the root cause of \"Dukkha\" (suffering, pain, unsatisfactoriness), and asserted as the first link, in Buddhist phenomenology, of a process that leads to repeated birth.\n\nAvidyā is mentioned within the Buddhist teachings as ignorance or misunderstanding in various contexts:\n\nWithin the context of the twelve links of dependent origination, avidya is typically symbolized by a person who is blind or wearing a blindfold.\n\n\"Avidyā\" is a Vedic Sanskrit word, and is a compound of \"a\" and \"vidya\", meaning \"not vidya\". The word \"vidya\" is derived from the Sanskrit root \"vid\", which means \"to know, to perceive, to see, to understand\". Therefore, \"avidya\" means to \"not know\". The \"vid*\"-related terms appear extensively in the Rigveda and other Vedas.\n\nIn Vedic literature, \"avidya\" refers to \"ignorance, spiritual ignorance, illusion\"; in early Buddhist texts, states Monier-Williams, it means \"ignorance with non-existence\".\n\nThe word is derived from the Proto-Indo-European root *\"weid\"-, meaning \"to see\" or \"to know\". It is a cognate with the Latin verb \"vidēre\" (\"to see\") and English \"wit\".\n\nAvidya is explained in different ways or on different levels within different Buddhist teachings or traditions. On the most fundamental level, it is ignorance or misunderstanding of the nature of reality; more specifically about the nature of not-Self and dependent origination doctrines. \"Avidya\" is not lack of information, states Peter Harvey, but a \"more deep seated misperception of reality\". Gethin calls Avidya as 'positive misconception', not mere absence of knowledge. It is a key concept in Buddhism, wherein \"Avidya\" about the nature of reality, rather than sin, is considered the basic root of \"Dukkha\". Removal of this \"Avidya\" leads to overcoming of \"Dukkha\".\n\nWhile Avidyā found in Buddhism and other Indian philosophies is often translated as \"ignorance\", states Alex Wayman, this is a mistranslation because it means more than ignorance. He suggests the term \"unwisdom\" to be a better rendition. The term includes not only ignorance out of darkness, but also obscuration, misconceptions, mistaking illusion to be reality or impermanent to be permanent or suffering to be bliss or non-self to be self (delusions). Incorrect knowledge is another form of Avidya, states Wayman.\nIn other contexts, avidya includes not knowing or not understanding the nature of phenomena as impermanent, the Four Noble Truths, other Buddhist doctrines, or the path to end suffering. Sonam Rinchen states \"Avidya\" in the context of the twelve links, that \"[Ignorance] is the opposite of the understanding that the person or other phenomena lack intrinsic existence. Those who are affected by this ignorance create actions which precipitate them into further worldly existence.\" Not understanding the Four Noble Truths, or its implications, is also Avidya.\n\nAvidya appears as a major item of discussion in two doctrines about the nature of reality, in various Buddhist traditions. One relates to the Anatta (Anatman) doctrine, that is ignorance or misconceptions about \"Self\", when in reality there is only non-Self according to Buddhism. The second relates to Anicca doctrine, that is ignorance or misconceptions about \"permanence\", when the nature of reality is impermanence.\n\nBhikkhu Bodhi states that Avidya is an important part of the Theravada Abhidharma teachings about dependent arising about conditions that sustain the wheel of birth and death. One such condition is the karmic formations that arise from ignorance. In other words, states Bodhi, ignorance (avijja) obscures \"perception of the true nature of things just as a cataract obscures perception of visible objects\". In the Suttanta literature, this ignorance refers to the non-knowledge of the Four Noble Truths. In the Abhidharma literature, in addition to the Four Noble Truths, it is the non-knowledge of one's 'past pre-natal lives' and 'post-mortem future lives' and of dependent arising.\n\nThe Mahayana tradition considers ignorance about the nature of reality and immemorial past lives to be a primordial force, which can only be broken through the insight of Emptiness (\"sunyata\"). However, compared to other Buddhist traditions, states Jens Braarvig, Avidyā is not so much emphasized, instead the emphasis on \"construing an illusory reality\" based on conceptualization when the ultimate reality is Emptiness.\n\nAvidya is the greatest impurity and the primary cause of suffering, rebirth. The insight into Emptiness, state Garfield and Edelglass, that is the \"lack of inherent nature of all phenomena, including the self, cuts the impurities\", an insight into Emptiness yields full awakening.\n\nThe Vajrayana tradition considers ignorance as fetters of bondage into samsara, and its teachings have focussed on a Tantric path under the guidance of a teacher, to remove \"Avidya\" and achieve liberation in a single lifetime.\n\nAvidyā is identified as the first of the twelve links of dependent origination (twelve nidanas)—a sequence of links that describe why a being reincarnates and remains bound within the samsara, a cycle of repeated births and deaths in six realms of existence. The twelve nidanas are an application of the Buddhist concept of pratītyasamutpāda (dependent origination). This theory, presented in Samyutta Nikaya II.2–4 and Digha Nikaya II.55–63, asserts that rebirth, re-aging and re-death ultimately arise through a series of twelve links or \"nidanas\" ultimately rooted in Avidyā, and the twelfth step \"Jarāmaraṇa\" triggers the dependent origination of \"Avidyā\", recreating an unending cycle of dukkha (suffering, pain, unsatisfactoriness).\n\nAvidya or ignorance can be eliminated directly by cultivating its opposite viz. Knowledge, wisdom and perception, where the above refer to the true knowledge and perception of reality. \nThe various ways to remove Avidya is by learning from Guru/teacher who knows or from books and scriptures. Also Avidya can be removed through Meditation or more precisely practice of Dhyana and Yoga. Through practice of Dharma and righteousness Avidya gets removed. \nUnrighteous karma increases Ignorance while Ignorance perpetuates Adharma.\n\n\n\n"}
{"id": "23469405", "url": "https://en.wikipedia.org/wiki?curid=23469405", "title": "Awe", "text": "Awe\n\nAwe is an emotion comparable to wonder but less joyous. On Robert Plutchik's wheel of emotions awe is modeled as a combination of surprise and fear.\n\nOne dictionary definition is \"an overwhelming feeling of reverence, admiration, fear, etc., produced by that which is grand, sublime, extremely powerful, or the like: in awe of God; in awe of great political figures.\" Another dictionary definition is a \"mixed emotion of reverence, respect, dread, and wonder inspired by authority, genius, great beauty, sublimity, or might: We felt awe when contemplating the works of Bach. The observers were in awe of the destructive power of the new weapon.\"\n\nIn general, awe is directed at objects considered to be more powerful than the subject, such as the Great Pyramid of Giza, the Grand Canyon, the vastness of the cosmos, or God.\n\nAwe is difficult to define, and the meaning of the word has changed over time. Related concepts are wonder, admiration, elevation, and the sublime. In \"Awe: The Delights and Dangers of Our Eleventh Emotion\", neuropsychologist and positive psychology guru Pearsall presents a phenomenological study of awe. He defines awe as an \"overwhelming and bewildering sense of connection with a startling universe that is usually far beyond the narrow band of our consciousness.\" Pearsall sees awe as the 11th emotion, beyond those now scientifically accepted (i.e., love, fear, sadness, embarrassment, curiosity, pride, enjoyment, despair, guilt, and anger).” Most definitions allow for awe to be a positive or a negative experience, but when asked to describe events that elicit awe, most people only cite positive experiences.\n\nThe term awe stems from the Old English word \"ege\", meaning “terror, dread, awe,” which may have arisen from the Greek word \"áchos\", meaning “pain.” The word \"awesome\" originated from the word \"awe\" in the late 16th century, to mean “filled with awe.” The word \"awful\" also originated from the word \"awe\", to replace the word Old English word \"egeful\" (“dreadful”).\n\nAwe reinforces social hierarchies\n\nKeltner and Haidt proposed an evolutionary explanation for awe. They suggested that the current emotion of awe originated from feelings of \"primordial awe\" – a hard-wired response that low-status individuals felt in the presence of more powerful, high-status individuals, which would have been adaptive by reinforcing social hierarchies. This primordial awe would have only occurred when the high-status person had characteristics of vastness (in size, fame, authority, or prestige) that required the low-status individual to engage in Piagetian accommodation (changing one’s mental representation of the world to accommodate the new experience). Keltner and Haidt propose that this primordial awe later generalized to any stimulus that is both vast and that requires accommodation. These stimuli still include being in the presence of a more powerful other (prototypical primordial awe), but also spiritual experiences, grand vistas, natural forces/disasters, human-made works, music, or the experience of understanding a grand scientific theory. Keltner and Haidt propose that awe can have both positive and negative connotations, and that there are five additional features of awe that can color one’s experience of the emotion: threat, beauty, ability, virtue, and the supernatural.\n\nAwe is a sexually-selected characteristic\n\nKeltner and Haidt’s model has been critiqued by some researchers, including by psychologist Vladimir J. Konečni. Konečni argued that people can only experience awe, especially aesthetic awe (of which, according to him, a \"sublime stimulus-in-context\" is the principal cause) when they are not in actual physical danger. Konečni postulated that the evolutionary origins of awe are from unexpected encounters with natural wonders, which would have been sexually selected for because reverence, intellectual sensitivity, emotional sensitivity, and elite membership would have been attractive characteristics in a mate, and these characteristics would also have given individuals greater access to awe-inspiring situations. Since high-status people are more likely to be safe from danger and to have access to awe-inspiring situations, Konečni argued that high-status people should feel awe more often than low-status people. However, this hypothesis has yet to be tested and verified.\n\nAwe increases systematic processing\n\nA third evolutionary theory is that awe serves to draw attention away from the self and toward the environment. This occurs as a way to build informational resources when in the presence of novel and complex stimuli that cannot be assimilated by current knowledge structures. In other words, awe functions to increase systematic, accommodative processing, and this would have been adaptive for survival. This hypothesis is the most recent and has received the most empirical support, as described in the section on social consequences of awe.\n\nSundararajan's awe\n\nHumanistic/forensic psychologist Louis Sundararajan also critiqued Keltner and Haidt’s model by arguing that being in the presence of a more powerful other elicits admiration, but does not require mental accommodation because admiration merely reinforces existing social hierarchies. Sundararajan expanded upon Keltner and Haidt’s model by arguing that first, an individual must be confronted with perceived vastness. If an individual can assimilate this perceived vastness into her or his existing mental categories, s/he will not experience awe. If an individual cannot assimilate the perceived vastness, then s/he will need to accommodate to the new information (change her or his mental categories). If this is not accomplished, an individual will experience trauma, such as developing PTSD. If an individual can accommodate, s/he will experience awe and wonder. By this model, the same vast experience could lead to increased rigidity (when assimilation succeeds), increased flexibility (when assimilation fails but accommodation succeeds), or psychopathology (when both assimilation and accommodation fail). Sundararajan did not speculate on the evolutionary origins of awe.\n\nDespite the meaningfulness that feelings of awe can bring, it has rarely been scientifically studied. As Richard Lazarus (1994) wrote in his book on emotions, “Given their [awe and wonder’s] importance and emotional power, it is remarkable that so little scientific attention has been paid to aesthetic experience as a source of emotion in our lives” (p. 136). Research on awe is in its infancy and has primarily focused on describing awe (e.g., physical displays of awe and who is likely to experience awe) and the social consequences of awe (e.g., helping behavior and susceptibility to persuasion by weak messages).\n\nShiota, Keltner, and Mossman (2007) had participants write about a time they felt awe and found that nature and art/music were frequently cited as the eliciting stimulus. Although most definitions allow for awe to be positive or negative, participants only described positive precipitants to awe, and it is therefore possible that positive awe and awe+fear (i.e., horror) are distinctly different emotions.\n\nIn the same set of experiments by Shiota, Keltner, and Mossman (2007), the researchers had participants write about a time they recently experienced natural beauty (awe condition) or accomplishment (pride condition). When describing the experience of natural beauty, participants were more likely to report that they felt unaware of day-to-day concerns, felt the presence of something greater, didn't want the experience to end, felt connected with the world, and felt small or insignificant. \n\nIt is not yet known whether awe is experienced differently in different cultures.\n\nResearchers have also attempted to observe the physical, non-verbal reactions to awe by asking participants to remember a time they felt awe and to express the emotion nonverbally. Using this method, researchers observed that awe is often displayed through raised inner eyebrows (78%), widened eyes (61%), and open, slightly drop-jawed mouths (80%). A substantial percent of people also display awe by slightly jutting forward their head (27%) and visibly inhaling (27%), but smiling is uncommon (10%). Cross-cultural research is needed to determine whether physical displays of awe differ by culture.\n\nSome individuals may be more prone to experiencing awe. Using self- and peer-reports, researchers found that regularly experiencing awe was associated with openness to experience (self and peer-ratings) and extroversion (self-ratings). Later studies also found that people who regularly experience awe (\"awe-prone\") have lower need for cognitive closure and are more likely to describe themselves in oceanic (e.g. \"I am an inhabitant of the planet Earth\"), individuated, and universal terms, as opposed to more specific terms (e.g. \"I have blonde hair\").\n\nA more recent study found that experiencing awe increased perceptions of time and led to a greater willingness to donate time, but not to donate money. The greater willingness to donate time appeared to be driven by decreased impatience after experiencing awe. Experiencing awe also led participants to report greater momentary life satisfaction and stronger preferences for experiential versus material goods (e.g. prefer a massage to a watch). Awe, unlike most other positive emotions, has been shown to increase systematic processing, rather than heuristic processing, leading participants who experience awe to become less susceptible to weak arguments.\n\nAwe has recently become a topic of interest in atheist groups, in response to statements from some religious individuals who say that atheists do not experience awe, or that experiencing awe makes one spiritual or religious, rather than an atheist. For example, see Oprah's comment that she would not consider swimmer Diana Nyad an atheist because Nyad experiences awe, as well as the response to this video by interfaith activist Chris Stedman.\n\nAwe is often tied to religion, but awe can also be secular. For more examples, see the writings on being an \"aweist\" by sociologist and atheist Phil Zuckerman, the book \"Religion for Atheists\" by author Alain de Botton, and the video on how secular institutions should inspire awe by performance philosopher Jason Silva.\n\n\n"}
{"id": "45086", "url": "https://en.wikipedia.org/wiki?curid=45086", "title": "Biodiversity", "text": "Biodiversity\n\nBiodiversity generally refers to the variety and variability of life on Earth. According to the United Nations Environment Programme (UNEP), biodiversity typically measures variation at the genetic, species, and ecosystem level. Terrestrial biodiversity tends to be greater near the equator, which seems to be the result of the warm climate and high primary productivity. Biodiversity is not distributed evenly on Earth, and is richest in the tropics. These tropical forest ecosystems cover less than 10 percent of earth's surface, and contain about 90 percent of the world's species. Marine biodiversity tends to be highest along coasts in the Western Pacific, where sea surface temperature is highest, and in the mid-latitudinal band in all oceans. There are latitudinal gradients in species diversity. Biodiversity generally tends to cluster in hotspots, and has been increasing through time, but will be likely to slow in the future.\n\nRapid environmental changes typically cause mass extinctions. More than 99.9 percent of all species that ever lived on Earth, amounting to over five billion species, are estimated to be extinct. Estimates on the number of Earth's current species range from 10 million to 14 million, of which about 1.2 million have been documented and over 86 percent have not yet been described. More recently, in May 2016, scientists reported that 1 trillion species are estimated to be on Earth currently with only one-thousandth of one percent described. The total amount of related DNA base pairs on Earth is estimated at 5.0 x 10 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon). In July 2016, scientists reported identifying a set of 355 genes from the Last Universal Common Ancestor (LUCA) of all organisms living on Earth.\n\nThe age of the Earth is about 4.54 billion years. The earliest undisputed evidence of life on Earth dates at least from 3.5 billion years ago, during the Eoarchean Era after a geological crust started to solidify following the earlier molten Hadean Eon. There are microbial mat fossils found in 3.48 billion-year-old sandstone discovered in Western Australia. Other early physical evidence of a biogenic substance is graphite in 3.7 billion-year-old meta-sedimentary rocks discovered in Western Greenland. More recently, in 2015, \"remains of biotic life\" were found in 4.1 billion-year-old rocks in Western Australia. According to one of the researchers, \"If life arose relatively quickly on Earth .. then it could be common in the universe.\"\n\nSince life began on Earth, five major mass extinctions and several minor events have led to large and sudden drops in biodiversity. The Phanerozoic eon (the last 540 million years) marked a rapid growth in biodiversity via the Cambrian explosion—a period during which the majority of multicellular phyla first appeared. The next 400 million years included repeated, massive biodiversity losses classified as mass extinction events. In the Carboniferous, rainforest collapse led to a great loss of plant and animal life. The Permian–Triassic extinction event, 251 million years ago, was the worst; vertebrate recovery took 30 million years. The most recent, the Cretaceous–Paleogene extinction event, occurred 65 million years ago and has often attracted more attention than others because it resulted in the extinction of the dinosaurs.\n\nThe period since the emergence of humans has displayed an ongoing biodiversity reduction and an accompanying loss of genetic diversity. Named the Holocene extinction, the reduction is caused primarily by human impacts, particularly habitat destruction. Conversely, biodiversity positively impacts human health in a number of ways, although a few negative effects are studied.\n\nThe United Nations designated 2011–2020 as the United Nations Decade on Biodiversity.\n\nThe term \"biological diversity\" was used first by wildlife scientist and conservationist Raymond F. Dasmann in the year 1968 lay book \"A Different Kind of Country\" advocating conservation. The term was widely adopted only after more than a decade, when in the 1980s it came into common usage in science and environmental policy. Thomas Lovejoy, in the foreword to the book \"Conservation Biology\", introduced the term to the scientific community. Until then the term \"natural diversity\" was common, introduced by The Science Division of The Nature Conservancy in an important 1975 study, \"The Preservation of Natural Diversity.\" By the early 1980s TNC's Science program and its head, Robert E. Jenkins, Lovejoy and other leading conservation scientists at the time in America advocated the use of the term \"biological diversity\".\n\nThe term's contracted form \"biodiversity\" may have been coined by W.G. Rosen in 1985 while planning the 1986 \"National Forum on Biological Diversity\" organized by the National Research Council (NRC). It first appeared in a publication in 1988 when sociobiologist E. O. Wilson used it as the title of the proceedings of that forum.\n\nSince this period the term has achieved widespread use among biologists, environmentalists, political leaders and concerned citizens.\n\nA similar term in the United States is \"natural heritage.\" It pre-dates the others and is more accepted by the wider audience interested in conservation. Broader than biodiversity, it includes geology and landforms.\n\n\"Biodiversity\" is most commonly used to replace the more clearly defined and long established terms, species diversity and species richness. Biologists most often define biodiversity as the \"totality of genes, species and ecosystems of a region\". An advantage of this definition is that it seems to describe most circumstances and presents a unified view of the traditional types of biological variety previously identified:\n\n\nThis multilevel construct is consistent with Datman and Lovejoy. An explicit definition consistent with this interpretation was first given in a paper by Bruce A. Wilcox commissioned by the International Union for the Conservation of Nature and Natural Resources (IUCN) for the 1982 World National Parks Conference. Wilcox's definition was \"Biological diversity is the variety of life forms...at all levels of biological systems (i.e., molecular, organismic, population, species and ecosystem)...\".\nThe 1992 United Nations Earth Summit defined \"biological diversity\" as \"the variability among living organisms from all sources, including, 'inter alia', terrestrial, marine and other aquatic ecosystems and the ecological complexes of which they are part: this includes diversity within species, between species and of ecosystems\". This definition is used in the United Nations Convention on Biological Diversity.\n\nOne textbook's definition is \"variation of life at all levels of biological organization\".\n\nBiodiversity can be defined genetically as the diversity of alleles, genes and organisms. They study processes such as mutation and gene transfer that drive evolution.\n\nMeasuring diversity at one level in a group of organisms may not precisely correspond to diversity at other levels. However, tetrapod (terrestrial vertebrates) taxonomic and ecological diversity shows a very close correlation.\n\nBiodiversity is not evenly distributed, rather it varies greatly across the globe as well as within regions. Among other factors, the diversity of all living things (biota) depends on temperature, precipitation, altitude, soils, geography and the presence of other species. The study of the spatial distribution of organisms, species and ecosystems, is the science of biogeography.\n\nDiversity consistently measures higher in the tropics and in other localized regions such as the Cape Floristic Region and lower in polar regions generally. Rain forests that have had wet climates for a long time, such as Yasuní National Park in Ecuador, have particularly high biodiversity.\n\nTerrestrial biodiversity is thought to be up to 25 times greater than ocean biodiversity. A new method used in 2011, put the total number of species on Earth at 8.7 million, of which 2.1 million were estimated to live in the ocean. However, this estimate seems to under-represent the diversity of microorganisms.\n\nGenerally, there is an increase in biodiversity from the poles to the tropics. Thus localities at lower latitudes have more species than localities at higher latitudes. This is often referred to as the latitudinal gradient in species diversity. Several ecological mechanisms may contribute to the gradient, but the ultimate factor behind many of them is the greater mean temperature at the equator compared to that of the poles.\n\nEven though terrestrial biodiversity declines from the equator to the poles, some studies claim that this characteristic is unverified in aquatic ecosystems, especially in marine ecosystems. The latitudinal distribution of parasites does not appear to follow this rule.\n\nIn 2016, an alternative hypothesis (\"the fractal biodiversity\") was proposed to explain the biodiversity latitudinal gradient. In this study, the species pool size and the fractal nature of ecosystems were combined to clarify some general patterns of this gradient. This hypothesis considers temperature, moisture, and net primary production (NPP) as the main variables of an ecosystem niche and as the axis of the ecological hypervolume. In this way, it is possible to build fractal hypervolumes, whose fractal dimension rises up to three moving towards the equator.\n\nA biodiversity hotspot is a region with a high level of endemic species that have experienced great habitat loss. The term hotspot was introduced in 1988 by Norman Myers. While hotspots are spread all over the world, the majority are forest areas and most are located in the tropics.\n\nBrazil's Atlantic Forest is considered one such hotspot, containing roughly 20,000 plant species, 1,350 vertebrates and millions of insects, about half of which occur nowhere else. The island of Madagascar and India are also particularly notable. Colombia is characterized by high biodiversity, with the highest rate of species by area unit worldwide and it has the largest number of endemics (species that are not found naturally anywhere else) of any country. About 10% of the species of the Earth can be found in Colombia, including over 1,900 species of bird, more than in Europe and North America combined, Colombia has 10% of the world's mammals species, 14% of the amphibian species and 18% of the bird species of the world. Madagascar dry deciduous forests and lowland rainforests possess a high ratio of endemism. Since the island separated from mainland Africa 66 million years ago, many species and ecosystems have evolved independently. Indonesia's 17,000 islands cover and contain 10% of the world's flowering plants, 12% of mammals and 17% of reptiles, amphibians and birds—along with nearly 240 million people. Many regions of high biodiversity and/or endemism arise from specialized habitats which require unusual adaptations, for example, alpine environments in high mountains, or Northern European peat bogs.\n\nAccurately measuring differences in biodiversity can be difficult. Selection bias amongst researchers may contribute to biased empirical research for modern estimates of biodiversity. In 1768, Rev. Gilbert White succinctly observed of his Selborne, Hampshire \"\"all nature is so full, that that district produces the most variety which is the most examined.\"\"\n\nBiodiversity is the result of 3.5 billion years of evolution. The origin of life has not been definitely established by science, however some evidence suggests that life may already have been well-established only a few hundred million years after the formation of the Earth. Until approximately 600 million years ago, all life consisted of microorganisms – archaea, bacteria, and single-celled protozoans and protists.\n\nThe history of biodiversity during the Phanerozoic (the last 540 million years), starts with rapid growth during the Cambrian explosion—a period during which nearly every phylum of multicellular organisms first appeared. Over the next 400 million years or so, invertebrate diversity showed little overall trend and vertebrate diversity shows an overall exponential trend. This dramatic rise in diversity was marked by periodic, massive losses of diversity classified as mass extinction events. A significant loss occurred when rainforests collapsed in the carboniferous. The worst was the Permian-Triassic extinction event, 251 million years ago. Vertebrates took 30 million years to recover from this event.\n\nThe fossil record suggests that the last few million years featured the greatest biodiversity in history. However, not all scientists support this view, since there is uncertainty as to how strongly the fossil record is biased by the greater availability and preservation of recent geologic sections. Some scientists believe that corrected for sampling artifacts, modern biodiversity may not be much different from biodiversity 300 million years ago., whereas others consider the fossil record reasonably reflective of the diversification of life. Estimates of the present global macroscopic species diversity vary from 2 million to 100 million, with a best estimate of somewhere near 9 million, the vast majority arthropods. Diversity appears to increase continually in the absence of natural selection.\n\nThe existence of a \"global carrying capacity\", limiting the amount of life that can live at once, is debated, as is the question of whether such a limit would also cap the number of species. While records of life in the sea shows a logistic pattern of growth, life on land (insects, plants and tetrapods) shows an exponential rise in diversity. As one author states, \"Tetrapods have not yet invaded 64 per cent of potentially habitable modes and it could be that without human influence the ecological and taxonomic diversity of tetrapods would continue to increase in an exponential fashion until most or all of the available ecospace is filled.\"\n\nIt also appears that the diversity continue to increase over time, especially after mass extinctions.\n\nOn the other hand, changes through the Phanerozoic correlate much better with the hyperbolic model (widely used in population biology, demography and macrosociology, as well as fossil biodiversity) than with exponential and logistic models. The latter models imply that changes in diversity are guided by a first-order positive feedback (more ancestors, more descendants) and/or a negative feedback arising from resource limitation. Hyperbolic model implies a second-order positive feedback. The hyperbolic pattern of the world population growth arises from a second-order positive feedback between the population size and the rate of technological growth. The hyperbolic character of biodiversity growth can be similarly accounted for by a feedback between diversity and community structure complexity. The similarity between the curves of biodiversity and human population probably comes from the fact that both are derived from the interference of the hyperbolic trend with cyclical and stochastic dynamics.\n\nMost biologists agree however that the period since human emergence is part of a new mass extinction, named the Holocene extinction event, caused primarily by the impact humans are having on the environment. It has been argued that the present rate of extinction is sufficient to eliminate most species on the planet Earth within 100 years.\n\nIn 2011, in his \"Biodiversity-related Niches Differentiation Theory\", Roberto Cazzolla Gatti proposed that species themselves are the architects of biodiversity, by proportionally increasing the number of potentially available niches in a given ecosystem. This study led to the idea that biodiversity is autocatalytic. An ecosystem of interdependent species can be, therefore, considered as an emergent autocatalytic set (a self-sustaining network of mutually \"catalytic\" entities), where one (group of) species enables the existence of (i.e., creates niches for) other species. This view offers a possible answer to the fundamental question of why so many species can coexist in the same ecosystem.\n\nNew species are regularly discovered (on average between 5–10,000 new species each year, most of them insects) and many, though discovered, are not yet classified (estimates are that nearly 90% of all arthropods are not yet classified). Most of the terrestrial diversity is found in tropical forests and in general, land has more species than the ocean; some 8.7 million species may exists on Earth, of which some 2.1 million live in the ocean.\n\n\"Ecosystem services are the suite of benefits that ecosystems provide to humanity.\" The natural species, or biota, are the caretakers of all ecosystems. It is as if the natural world is an enormous bank account of capital assets capable of paying life sustaining dividends indefinitely, but only if the capital is maintained.\n\nThese services come in three flavors:\n\nThere have been many claims about biodiversity's effect on these ecosystem services, especially provisioning and regulating services. After an exhaustive survey through peer-reviewed literature to evaluate 36 different claims about biodiversity's effect on ecosystem services, 14 of those claims have been validated, 6 demonstrate mixed support or are unsupported, 3 are incorrect and 13 lack enough evidence to draw definitive conclusions.\n\nGreater species diversity \n\nGreater species diversity\n\n\n\n\n\n\n\nOther sources have reported somewhat conflicting results and in 1997 Robert Costanza and his colleagues reported the estimated global value of ecosystem services (not captured in traditional markets) at an average of $33 trillion annually.\n\nSince the stone age, species loss has accelerated above the average basal rate, driven by human activity. Estimates of species losses are at a rate 100-10,000 times as fast as is typical in the fossil record.\nBiodiversity also affords many non-material benefits including spiritual and aesthetic values, knowledge systems and education.\n\nAgricultural diversity can be divided into two categories: intraspecific diversity, which includes the genetic variety within a single species, like the potato (\"Solanum tuberosum\") that is composed of many different forms and types (e.g. in the U.S. they might compare russet potatoes with new potatoes or purple potatoes, all different, but all part of the same species, \"S. tuberosum\").\n\nThe other category of agricultural diversity is called interspecific diversity and refers to the number and types of different species. Thinking about this diversity we might note that many small vegetable farmers grow many different crops like potatoes and also carrots, peppers, lettuce etc.\n\nAgricultural diversity can also be divided by whether it is ‘planned’ diversity or ‘associated’ diversity. This is a functional classification that we impose and not an intrinsic feature of life or diversity. Planned diversity includes the crops which a farmer has encouraged, planted or raised (e.g. crops, covers, symbionts and livestock, among others), which can be contrasted with the associated diversity that arrives among the crops, uninvited (e.g. herbivores, weed species and pathogens, among others).\n\nThe control of associated biodiversity is one of the great agricultural challenges that farmers face. On monoculture farms, the approach is generally to eradicate associated diversity using a suite of biologically destructive pesticides, mechanized tools and transgenic engineering techniques, then to rotate crops. Although some polyculture farmers use the same techniques, they also employ integrated pest management strategies as well as strategies that are more labor-intensive, but generally less dependent on capital, biotechnology and energy.\n\nInterspecific crop diversity is, in part, responsible for offering variety in what we eat. Intraspecific diversity, the variety of alleles within a single species, also offers us choice in our diets. If a crop fails in a monoculture, we rely on agricultural diversity to replant the land with something new. If a wheat crop is destroyed by a pest we may plant a hardier variety of wheat the next year, relying on intraspecific diversity. We may forgo wheat production in that area and plant a different species altogether, relying on interspecific diversity. Even an agricultural society which primarily grows monocultures, relies on biodiversity at some point.\n\nMonoculture was a contributing factor to several agricultural disasters, including the European wine industry collapse in the late 19th century and the US southern corn leaf blight epidemic of 1970.\n\nAlthough about 80 percent of humans' food supply comes from just 20 kinds of plants, humans use at least 40,000 species. Many people depend on these species for food, shelter and clothing. Earth's surviving biodiversity provides resources for increasing the range of food and other products suitable for human use, although the present extinction rate shrinks that potential.\n\nBiodiversity's relevance to human health is becoming an international political issue, as scientific evidence builds on the global health implications of biodiversity loss.\n\nThe growing demand and lack of drinkable water on the planet presents an additional challenge to the future of human health. Partly, the problem lies in the success of water suppliers to increase supplies and failure of groups promoting preservation of water resources. While the distribution of clean water increases, in some parts of the world it remains unequal. According to the World Health Organisation (2018) only 71% of the global population used a safely managed drinking-water service.\n\nSome of the health issues influenced by biodiversity include dietary health and nutrition security, infectious disease, medical science and medicinal resources, social and psychological health. Biodiversity is also known to have an important role in reducing disaster risk and in post-disaster relief and recovery efforts.\n\nBiodiversity provides critical support for drug discovery and the availability of medicinal resources. A significant proportion of drugs are derived, directly or indirectly, from biological sources: at least 50% of the pharmaceutical compounds on the US market are derived from plants, animals and micro-organisms, while about 80% of the world population depends on medicines from nature (used in either modern or traditional medical practice) for primary healthcare. Only a tiny fraction of wild species has been investigated for medical potential. Biodiversity has been critical to advances throughout the field of bionics. Evidence from market analysis and biodiversity science indicates that the decline in output from the pharmaceutical sector since the mid-1980s can be attributed to a move away from natural product exploration (\"bioprospecting\") in favor of genomics and synthetic chemistry, indeed claims about the value of undiscovered pharmaceuticals may not provide enough incentive for companies in free markets to search for them because of the high cost of development; meanwhile, natural products have a long history of supporting significant economic and health innovation. Marine ecosystems are particularly important, although inappropriate bioprospecting can increase biodiversity loss, as well as violating the laws of the communities and states from which the resources are taken.\n\nMany industrial materials derive directly from biological sources. These include building materials, fibers, dyes, rubber and oil. Biodiversity is also important to the security of resources such as water, timber, paper, fiber and food. As a result, biodiversity loss is a significant risk factor in business development and a threat to long term economic sustainability.\n\nBiodiversity enriches leisure activities such as hiking, birdwatching or natural history study. Biodiversity inspires musicians, painters, sculptors, writers and other artists. Many cultures view themselves as an integral part of the natural world which requires them to respect other living organisms.\n\nPopular activities such as gardening, fishkeeping and specimen collecting strongly depend on biodiversity. The number of species involved in such pursuits is in the tens of thousands, though the majority do not enter commerce.\n\nThe relationships between the original natural areas of these often exotic animals and plants and commercial collectors, suppliers, breeders, propagators and those who promote their understanding and enjoyment are complex and poorly understood. The general public responds well to exposure to rare and unusual organisms, reflecting their inherent value.\n\nPhilosophically it could be argued that biodiversity has intrinsic aesthetic and spiritual value to mankind \"in and of itself\". This idea can be used as a counterweight to the notion that tropical forests and other ecological realms are only worthy of conservation because of the services they provide.\n\nBiodiversity supports many ecosystem services:\n\n\"There is now unequivocal evidence that biodiversity loss reduces the efficiency by which ecological communities capture biologically essential resources, produce biomass, decompose and recycle biologically essential nutrients... There is mounting evidence that biodiversity increases the stability of ecosystem functions through time... Diverse communities are more productive because they contain key species that have a large influence on productivity and differences in functional traits among organisms increase total resource capture... The impacts of diversity loss on ecological processes might be sufficiently large to rival the impacts of many other global drivers of environmental change... Maintaining multiple ecosystem processes at multiple places and times requires higher levels of biodiversity than does a single process at a single place and time.\"\n\nIt plays a part in regulating the chemistry of our atmosphere and water supply. Biodiversity is directly involved in water purification, recycling nutrients and providing fertile soils. Experiments with controlled environments have shown that humans cannot easily build ecosystems to support human needs; for example insect pollination cannot be mimicked, though there have been attempts to create artificial pollinators using unmanned aerial vehicles. The economic activity of pollination alone represented between $2.1-14.6 billions in 2003.\n\nAccording to Mora and colleagues, the total number of terrestrial species is estimated to be around 8.7 million while the number of oceanic species is much lower, estimated at 2.2 million. The authors note that these estimates are strongest for eukaryotic organisms and likely represent the lower bound of prokaryote diversity. Other estimates include:\n\nSince the rate of extinction has increased, many extant species may become extinct before they are described. Not surprisingly, in the animalia the most studied groups are birds and mammals, whereas fishes and arthropods are the least studied animals groups.\n\nDuring the last century, decreases in biodiversity have been increasingly observed. In 2007, German Federal Environment Minister Sigmar Gabriel cited estimates that up to 30% of all species will be extinct by 2050. Of these, about one eighth of known plant species are threatened with extinction. Estimates reach as high as 140,000 species per year (based on Species-area theory). This figure indicates unsustainable ecological practices, because few species emerge each year. Almost all scientists acknowledge that the rate of species loss is greater now than at any time in human history, with extinctions occurring at rates hundreds of times higher than background extinction rates. As of 2012, some studies suggest that 25% of all mammal species could be extinct in 20 years.\n\nIn absolute terms, the planet has lost 58% of its biodiversity since 1970 according to a 2016 study by the World Wildlife Fund. The Living Planet Report 2014 claims that \"the number of mammals, birds, reptiles, amphibians and fish across the globe is, on average, about half the size it was 40 years ago\". Of that number, 39% accounts for the terrestrial wildlife gone, 39% for the marine wildlife gone and 76% for the freshwater wildlife gone. Biodiversity took the biggest hit in Latin America, plummeting 83 percent. High-income countries showed a 10% increase in biodiversity, which was canceled out by a loss in low-income countries. This is despite the fact that high-income countries use five times the ecological resources of low-income countries, which was explained as a result of process whereby wealthy nations are outsourcing resource depletion to poorer nations, which are suffering the greatest ecosystem losses.\n\nA 2017 study published in \"PLOS One\" found that the biomass of insect life in Germany had declined by three-quarters in the last 25 years. Dave Goulson of Sussex University stated that their study suggested that humans \"appear to be making vast tracts of land inhospitable to most forms of life, and are currently on course for ecological Armageddon. If we lose the insects then everything is going to collapse.\"\n\nIn 2006, many species were formally classified as rare or endangered or threatened; moreover, scientists have estimated that millions more species are at risk which have not been formally recognized. About 40 percent of the 40,177 species assessed using the IUCN Red List criteria are now listed as threatened with extinction—a total of 16,119.\n\nJared Diamond describes an \"Evil Quartet\" of habitat destruction, overkill, introduced species and secondary extinctions. Edward O. Wilson prefers the acronym HIPPO, standing for Habitat destruction, Invasive species, Pollution, human over-Population and Over-harvesting. The most authoritative classification in use today is IUCN's Classification of Direct Threats which has been adopted by major international conservation organizations such as the US Nature Conservancy, the World Wildlife Fund, Conservation International and BirdLife International.\n\nHabitat destruction has played a key role in extinctions, especially in relation to tropical forest destruction. Factors contributing to habitat loss include: overconsumption, overpopulation, land use change, deforestation, pollution (air pollution, water pollution, soil contamination) and global warming or climate change.\n\nHabitat size and numbers of species are systematically related. Physically larger species and those living at lower latitudes or in forests or oceans are more sensitive to reduction in habitat area. Conversion to \"trivial\" standardized ecosystems (e.g., monoculture following deforestation) effectively destroys habitat for the more diverse species that preceded the conversion. Even the simplest forms of agriculture affect diversity - through clearing/draining land, discouraging weeds and \"pests\", and encouraging just a limited set of domesticated plant and animal species. In some countries lack of property rights or lax law/regulatory enforcement necessarily leads to biodiversity loss (degradation costs having to be supported by the community).\n\nA 2007 study conducted by the National Science Foundation found that biodiversity and genetic diversity are codependent—that diversity among species requires diversity within a species and \"vice versa\". \"If any one type is removed from the system, the cycle can break down and the community becomes dominated by a single species.\"\n, the most threatened ecosystems occur in fresh water, according to the Millennium Ecosystem Assessment 2005, which was confirmed by the \"Freshwater Animal Diversity Assessment\" organised by the biodiversity platform and the French \"Institut de recherche pour le développement\" (MNHNP).\n\nCo-extinctions are a form of habitat destruction. Co-extinction occurs when the extinction or decline in one species accompanies similar processes in another, such as in plants and beetles.\n\nBarriers such as large rivers, seas, oceans, mountains and deserts encourage diversity by enabling independent evolution on either side of the barrier, via the process of allopatric speciation. The term invasive species is applied to species that breach the natural barriers that would normally keep them constrained. Without barriers, such species occupy new territory, often supplanting native species by occupying their niches, or by using resources that would normally sustain native species.\n\nThe number of species invasions has been on the rise at least since the beginning of the 1900s. Species are increasingly being moved by humans (on purpose and accidentally). In some cases the invaders are causing drastic changes and damage to their new habitats (e.g.: zebra mussels and the emerald ash borer in the Great Lakes region and the lion fish along the North American Atlantic coast). Some evidence suggests that invasive species are competitive in their new habitats because they are subject to less pathogen disturbance. Others report confounding evidence that occasionally suggest that species-rich communities harbor many native and exotic species simultaneously while some say that diverse ecosystems are more resilient and resist invasive plants and animals. An important question is, \"do invasive species cause extinctions?\" Many studies cite effects of invasive species on natives, but not extinctions. Invasive species seem to increase local (i.e.: alpha diversity) diversity, which decreases turnover of diversity (i.e.: beta diversity). Overall gamma diversity may be lowered because species are going extinct because of other causes, but even some of the most insidious invaders (e.g.: Dutch elm disease, emerald ash borer, chestnut blight in North America) have not caused their host species to become extinct. Extirpation, population decline and homogenization of regional biodiversity are much more common. Human activities have frequently been the cause of invasive species circumventing their barriers, by introducing them for food and other purposes. Human activities therefore allow species to migrate to new areas (and thus become invasive) occurred on time scales much shorter than historically have been required for a species to extend its range.\n\nNot all introduced species are invasive, nor all invasive species deliberately introduced. In cases such as the zebra mussel, invasion of US waterways was unintentional. In other cases, such as mongooses in Hawaii, the introduction is deliberate but ineffective (nocturnal rats were not vulnerable to the diurnal mongoose). In other cases, such as oil palms in Indonesia and Malaysia, the introduction produces substantial economic benefits, but the benefits are accompanied by costly unintended consequences.\n\nFinally, an introduced species may unintentionally injure a species that depends on the species it replaces. In Belgium, Prunus spinosa from Eastern Europe leafs much sooner than its West European counterparts, disrupting the feeding habits of the \"Thecla betulae\" butterfly (which feeds on the leaves). Introducing new species often leaves endemic and other local species unable to compete with the exotic species and unable to survive. The exotic organisms may be predators, parasites, or may simply outcompete indigenous species for nutrients, water and light.\n\nAt present, several countries have already imported so many exotic species, particularly agricultural and ornamental plants, that their own indigenous fauna/flora may be outnumbered. For example, the introduction of kudzu from Southeast Asia to Canada and the United States has threatened biodiversity in certain areas.\n\nEndemic species can be threatened with extinction through the process of genetic pollution, i.e. uncontrolled hybridization, introgression and genetic swamping. Genetic pollution leads to homogenization or replacement of local genomes as a result of either a numerical and/or fitness advantage of an introduced species.\nHybridization and introgression are side-effects of introduction and invasion. These phenomena can be especially detrimental to rare species that come into contact with more abundant ones. The abundant species can interbreed with the rare species, swamping its gene pool. This problem is not always apparent from morphological (outward appearance) observations alone. Some degree of gene flow is normal adaptation and not all gene and genotype constellations can be preserved. However, hybridization with or without introgression may, nevertheless, threaten a rare species' existence.\n\nOverexploitation occurs when a resource is consumed at an unsustainable rate. This occurs on land in the form of overhunting, excessive logging, poor soil conservation in agriculture and the illegal wildlife trade.\n\nAbout 25% of world fisheries are now overfished to the point where their current biomass is less than the level that maximizes their sustainable yield.\n\nThe overkill hypothesis, a pattern of large animal extinctions connected with human migration patterns, can be used explain why megafaunal extinctions can occur within a relatively short time period.\n\nIn agriculture and animal husbandry, the Green Revolution popularized the use of conventional hybridization to increase yield. Often hybridized breeds originated in developed countries and were further hybridized with local varieties in the developing world to create high yield strains resistant to local climate and diseases. Local governments and industry have been pushing hybridization. Formerly huge gene pools of various wild and indigenous breeds have collapsed causing widespread genetic erosion and genetic pollution. This has resulted in loss of genetic diversity and biodiversity as a whole.\n\nGenetically modified organisms contain genetic material that is altered through genetic engineering. Genetically modified crops have become a common source for genetic pollution in not only wild varieties, but also in domesticated varieties derived from classical hybridization.\n\nGenetic erosion and genetic pollution have the potential to destroy unique genotypes, threatening future access to food security. A decrease in genetic diversity weakens the ability of crops and livestock to be hybridized to resist disease and survive changes in climate.\n\nGlobal warming is also considered to be a major potential threat to global biodiversity in the future. For example, coral reefs - which are biodiversity hotspots - will be lost within the century if global warming continues at the current trend.\n\nClimate change has seen many claims about potential to affect biodiversity but evidence supporting the statement is tenuous. Increasing atmospheric carbon dioxide certainly affects plant morphology and is acidifying oceans, and temperature affects species ranges, phenology, and weather, but the major impacts that have been predicted are still just \"potential\" impacts. We have not documented major extinctions yet, even as climate change drastically alters the biology of many species.\n\nIn 2004, an international collaborative study on four continents estimated that 10 percent of species would become extinct by 2050 because of global warming. \"We need to limit climate change or we wind up with a lot of species in trouble, possibly extinct,\" said Dr. Lee Hannah, a co-author of the paper and chief climate change biologist at the Center for Applied Biodiversity Science at Conservation International.\n\nA recent study predicts that up to 35% of the world terrestrial carnivores and ungulates will be at higher risk of extinction by 2050 because of the joint effects of predicted climate and land-use change under business-as-usual human development scenarios.\n\nThe world’s population numbered nearly 7.6 billion as of mid-2017 (which is approximately one billion more inhabitants compared to 2005) and is forecast to reach 11.1 billion in 2100. Sir David King, former chief scientific adviser to the UK government, told a parliamentary inquiry: \"It is self-evident that the massive growth in the human population through the 20th century has had more impact on biodiversity than any other single factor.\" At least until the middle of the 21st century, worldwide losses of pristine biodiverse land will probably depend much on the worldwide human birth rate. Biologists such as Paul R. Ehrlich and Stuart Pimm have noted that human population growth and overconsumption are the main drivers of species extinction.\n\nAccording to a 2014 study by the World Wildlife Fund, the global human population already exceeds planet's biocapacity - it would take the equivalent of 1.5 Earths of biocapacity to meet our current demands. The report further points that if everyone on the planet had the Footprint of the average resident of Qatar, we would need 4.8 Earths and if we lived the lifestyle of a typical resident of the USA, we would need 3.9 Earths.\n\nRates of decline in biodiversity in this sixth mass extinction match or exceed rates of loss in the five previous mass extinction events in the fossil record. Loss of biodiversity results in the loss of natural capital that supplies ecosystem goods and services. From the perspective of the method known as Natural Economy the economic value of 17 ecosystem services for Earth's biosphere (calculated in 1997) has an estimated value of US$33 trillion (3.3x10) per year.\n\nConservation biology matured in the mid-20th century as ecologists, naturalists and other scientists began to research and address issues pertaining to global biodiversity declines.\n\nThe conservation ethic advocates management of natural resources for the purpose of sustaining biodiversity in species, ecosystems, the evolutionary process and human culture and society.\n\nConservation biology is reforming around strategic plans to protect biodiversity. Preserving global biodiversity is a priority in strategic conservation plans that are designed to engage public policy and concerns affecting local, regional and global scales of communities, ecosystems and cultures. Action plans identify ways of sustaining human well-being, employing natural capital, market capital and ecosystem services.\n\nIn the EU Directive 1999/22/EC zoos are described as having a role in the preservation of the biodiversity of wildlife animals by conducting research or participation in breeding programs.\n\nRemoval of exotic species will allow the species that they have negatively impacted to recover their ecological niches. Exotic species that have become pests can be identified taxonomically (e.g., with Digital Automated Identification SYstem (DAISY), using the barcode of life). Removal is practical only given large groups of individuals due to the economic cost.\n\nAs sustainable populations of the remaining native species in an area become assured, \"missing\" species that are candidates for reintroduction can be identified using databases such as the \"Encyclopedia of Life\" and the Global Biodiversity Information Facility.\n\n\nProtected areas are meant for affording protection to wild animals and their habitat which also includes forest reserves and biosphere reserves. Protected areas have been set up all over the world with the specific aim of protecting and conserving plants and animals. Some scientists have called on the global community to designate as protected areas 30 percent of the planet by 2030, and 50 percent by 2050, in order to mitigate biodiversity loss from anthropogenic causes.\n\nNational park and nature reserve is the area selected by governments or private organizations for special protection against damage or degradation with the objective of biodiversity and landscape conservation. National parks are usually owned and managed by national or state governments. A limit is placed on the number of visitors permitted to enter certain fragile areas. Designated trails or roads are created. The visitors are allowed to enter only for study, cultural and recreation purposes. Forestry operations, grazing of animals and hunting of animals are regulated. Exploitation of habitat or wildlife is banned.\n\nWildlife sanctuaries aim only at conservation of species and have the following features:\n\n\nThe forests play a vital role in harbouring more than 45,000 floral and 81,000 faunal species of which 5150 floral and 1837 faunal species are endemic. Plant and animal species confined to a specific geographical area are called endemic species. In reserved forests, rights to activities like hunting and grazing are sometimes given to communities living on the fringes of the forest, who sustain their livelihood partially or wholly from forest resources or products. The unclassed forests covers 6.4 percent of the total forest area and they are marked by the following characteristics:\n\n\n\nIn zoological parks or zoos, live animals are kept for public recreation, education and conservation purposes. Modern zoos offer veterinary facilities, provide opportunities for threatened species to breed in captivity and usually build environments that simulate the native habitats of the animals in their care. Zoos play a major role in creating awareness about the need to conserve nature.\n\nIn botanical gardens, plants are grown and displayed primarily for scientific and educational purposes. They consist of a collection of living plants, grown outdoors or under glass in greenhouses and conservatories. In addition, a botanical garden may include a collection of dried plants or herbarium and such facilities as lecture rooms, laboratories, libraries, museums and experimental or research plantings.\n\nFocusing on limited areas of higher potential biodiversity promises greater immediate return on investment than spreading resources evenly or focusing on areas of little diversity but greater interest in biodiversity.\n\nA second strategy focuses on areas that retain most of their original diversity, which typically require little or no restoration. These are typically non-urbanized, non-agricultural areas. Tropical areas often fit both criteria, given their natively high diversity and relative lack of development.\n\n\nGlobal agreements such as the Convention on Biological Diversity, give \"sovereign national rights over biological resources\" (not property). The agreements commit countries to \"conserve biodiversity\", \"develop resources for sustainability\" and \"share the benefits\" resulting from their use. Biodiverse countries that allow bioprospecting or collection of natural products, expect a share of the benefits rather than allowing the individual or institution that discovers/exploits the resource to capture them privately. Bioprospecting can become a type of biopiracy when such principles are not respected.\n\nSovereignty principles can rely upon what is better known as Access and Benefit Sharing Agreements (ABAs). The Convention on Biodiversity implies informed consent between the source country and the collector, to establish which resource will be used and for what and to settle on a fair agreement on benefit sharing.\n\nBiodiversity is taken into account in some political and judicial decisions:\n\nUniform approval for use of biodiversity as a legal standard has not been achieved, however. Bosselman argues that biodiversity should not be used as a legal standard, claiming that the remaining areas of scientific uncertainty cause unacceptable administrative waste and increase litigation without promoting preservation goals.\n\nIndia passed the Biological Diversity Act in 2002 for the conservation of biological diversity in India. The Act also provides mechanisms for equitable sharing of benefits from the use of traditional biological resources and knowledge.\n\nLess than 1% of all species that have been described have been studied beyond simply noting their existence. The vast majority of Earth's species are microbial. Contemporary biodiversity physics is \"firmly fixated on the visible [macroscopic] world\". For example, microbial life is metabolically and environmentally more diverse than multicellular life (see e.g., extremophile). \"On the tree of life, based on analyses of small-subunit ribosomal RNA, visible life consists of barely noticeable twigs. The inverse relationship of size and population recurs higher on the evolutionary ladder—to a first approximation, all multicellular species on Earth are insects\". Insect extinction rates are high—supporting the Holocene extinction hypothesis.\n\nThe number of morphological attributes that can be scored for diversity study is generally limited and prone to environmental influences; thereby reducing the fine resolution required to ascertain the phylogenetic relationships. DNA based markers- microsatellites otherwise known as \"simple sequence repeats\" (SSR) were therefore used for the diversity studies of certain species and their wild relatives.\n\nIn the case of cowpea, a study conducted to assess the level of genetic diversity in cowpea germplasm and related wide species, where the relatedness among various taxa were compared, primers useful for classification of taxa identified, and the origin and phylogeny of cultivated cowpea classified show that SSR markers are useful in validating with species classification and revealing the center of diversity.\n\n\n\n\n\n"}
{"id": "35927838", "url": "https://en.wikipedia.org/wiki?curid=35927838", "title": "Britten–Davidson model", "text": "Britten–Davidson model\n\nThe Britten–Davidson model, also known as the gene-battery model, is a hypothesis for the regulation of protein synthesis in eukaryotes. Proposed by Roy John Britten and Eric H. Davidson in 1969, the model postulates four classes of DNA sequence: an integrator gene, a producer gene, a receptor site, and a sensor site. The sensor site regulates the integrator gene, responsible for synthesis of activator RNA. The integrator gene cannot synthesize activator RNA unless the sensor site is activated. Activation and deactivation of the sensor site is done by external stimuli, such as hormones. The activator RNA then binds with a nearby receptor site, which stimulates the synthesis of mRNA at the structural gene.\n\nThis theory would explain how several different integrators could be synthesized at the same time. In addition, this theory would explain the pattern of repetitive DNA sequences followed by a unique DNA sequence that exists in genes.,\n\n"}
{"id": "20077025", "url": "https://en.wikipedia.org/wiki?curid=20077025", "title": "Carrier-to-noise-density ratio", "text": "Carrier-to-noise-density ratio\n\nIn satellite communications, carrier-to-noise-density ratio (C/N) is the ratio of the carrier power \"C\" to the noise power density \"N\", expressed in dB-Hz.\nWhen considering only the receiver as a source of noise, it is called carrier-to-receiver-noise-density ratio.\n\nIt determines whether a receiver can lock on to the carrier and if the information encoded in the signal can be retrieved, given the amount of noise present in the received signal. The carrier-to-receiver noise density ratio is usually expressed in dBHz.\n\nThe noise power density, \"N\"=\"kT\", is the receiver noise power per hertz, which can be written in terms of the Boltzmann constant \"k\" (in joules per kelvin) and the noise temperature \"T\" (in kelvins). \n\n\n"}
{"id": "269974", "url": "https://en.wikipedia.org/wiki?curid=269974", "title": "Chaordic organization", "text": "Chaordic organization\n\nA chaordic organization refers to a system of organization that blends characteristics of chaos and order. The term was coined by Dee Hock, the founder and former CEO of the VISA credit card association.\n\nThe mix of chaos and order is often described as a harmonious coexistence displaying characteristics of both, with neither chaotic nor ordered behavior dominating. The chaordic principles have also been used as guidelines for creating human organizations -- business, nonprofit, government and hybrids—that would be neither centralized nor anarchical networks.\n\n\n\n"}
{"id": "38794693", "url": "https://en.wikipedia.org/wiki?curid=38794693", "title": "Class consciousness", "text": "Class consciousness\n\nIn political theory and particularly Marxism, class consciousness is the set of beliefs that a person holds regarding their social class or economic rank in society, the structure of their class, and their class interests. It is an awareness that is key to sparking a revolution that would, \"create a dictatorship of the proletariat, transforming it from a wage-earning, property-less mass into the ruling class\" according to Karl Marx.\n\nWhile German theorist Karl Marx rarely used the term \"class consciousness\", he did make the distinction between \"class in itself\", which is defined as a category of people having a common relation to the means of production, and a \"class for itself\", which is defined as a stratum organized in active pursuit of its own interests.\n\nDefining a person's social class can be a determinant for their awareness of it. Marxists define classes on the basis of their relation to the means of production – especially on whether they own capital. Non-Marxist social scientists distinguish various social strata on the basis of income, occupation, or status.\n\nEarly in the nineteenth century, the labels \"working classes\" and \"middle classes\" were already coming into common usage. \"The old hereditary aristocracy, reinforced by the new gentry who owed their success to commerce, industry, and the professions, evolved into an \"upper class\". Its consciousness was formed in part by public schools (in the British sense where it refers to a form of private school) and Universities. The upper class tenaciously maintained control over the political system, depriving not only the working classes but the middle classes of a voice in the political process.\"\n\nClass consciousness, as described by Georg Lukács's famous \"History and Class Consciousness\" (1923), is opposed to any psychological conception of consciousness, which forms the basis of individual or mass psychology (see Freud or, before him, Gustave Le Bon). According to Lukács, each social class has a determined class consciousness which it can achieve. In effect, as opposed to the liberal conception of consciousness as the basis of individual freedom and of the social contract, Marxist class consciousness is not an origin, but an achievement (i.e. it must be \"earned\" or won). Hence, it is never assured: the proletariat's class consciousness is the result of a permanent struggle to understand the \"concrete totality\" of the historical process.\n\nAccording to Lukács, the proletariat was the first class in history that may achieve true class consciousness, because of its specific position highlighted in the \"Communist Manifesto\" as the \"living negation\" of capitalism. All others classes, including the bourgeoisie, are limited to a \"false consciousness\" which impedes them from understanding the totality of history: instead of understanding each specific moment as a portion of a supposedly deterministic historical process, they universalize it and believe it is everlasting. Hence, capitalism is not thought as a specific phase of history, but is naturalized and thought of as an eternal solidified part of history. Says Lukács, this \"false consciousness\", which forms ideology itself, is not a simple error as in classical philosophy, but an illusion which cannot be dispelled.\n\nMarx described it in his theory of commodity fetishism, which Lukács completed with his concept of reification: alienation is what follows the worker's estrangement to the world following the new life acquired by the product of his work. The dominant bourgeois ideology thus leads the individual to see the achievement of his labour take a life of its own. Furthermore, specialization is also seen as a characteristic of the ideology of modern rationalism, which creates specific and independent domains (art, politics, science, etc.). Only a global perspective can point out how all these different domains interact, argues Lukács. He also points out how Kant brought to its limit the classical opposition between the abstract form and the concrete, historical content, which is abstractly conceived as irrational and contingent. Thus, with Kant's rational system, history becomes totally contingent and is thus ignored. Only with Hegel's dialectic can a mediation be found between the abstract form and the abstract notion of a concrete content.\n\nEven if the bourgeois loses his individual point of view in an attempt to grasp the reality of the totality of society and of the historical process, he is condemned to a form of false consciousness. As an individual, he will always see the collective result of individual actions as a form of \"objective law\" to which he must submit himself (liberalism has gone so far as seeing an invisible hand in this collective results, making capitalism the best of all possible worlds). By contrast, the proletariat would be, according to Lukács, the first class in history with the possibility to achieve a true form of class consciousness, granting it knowledge of the totality of the historical process.\n\nThe proletariat takes the place of Hegel's \"Weltgeist\" (\"World Spirit\"), which achieves history through \"Volksgeist\" (\"the spirit of the people\"): the idealist conception of an abstract Spirit making history, which ends in the realm of Reason, is replaced by a materialist conception based not on mythical Spirits, but on a concrete \"identical subject-object of history\": the proletariat. The proletariat is both the \"object\" of history, created by the capitalist social formation; but it is also the \"subject\" of history, as it is its labour that shapes the world, and thus, knowledge of itself is also, necessarily, knowledge of the reality and of the totality of the historical process. The proletariat's class consciousness is not immediate; class consciousness must not be mistaken either with the consciousness of one's future and collective interests, opposed to personal immediate interests.\n\nThe possibility of class consciousness is given by the objective process of history, which transforms the proletariat into a commodity, hence objectifying it. Class consciousness is thus not a simple subjective act: \"as consciousness here is not the consciousness of an object opposed to itself, but the object's consciousness, the act of being conscious of oneself disrupts the objectivity form of its object\" (in \"Reification and the Proletariat's Consciousness\" §3, III \"The proletariat's point of view\"). In other words, instead of the bourgeois subject and its corresponding ideological concept of individual free will, the proletariat has been transformed into an object (a commodity) which, when it takes consciousness of itself, transforms the very structure of objectivity, that is of reality.\n\nThis specific role of the proletariat is a consequence of its specific position; thus, for the first time, consciousness of itself (class consciousness) is also consciousness of the totality (knowledge of the entire social and historical process). Through dialectical materialism, the proletariat understands that what the individual bourgeois conceived as \"laws\" akin to the laws of nature, which may be only manipulated, as in Descartes's dream, but not changed, is in fact the result of a social and historical process, which can be controlled. Furthermore, only dialectical materialism links together all specialized domains, which modern rationalism can only think as separate instead of as forming a totality.\n\nOnly the proletariat can understand that the so-called \"eternal laws of economics\" are in fact nothing more than the historical form taken by the social and economical process in a capitalist society. Since these \"laws\" are the result of the collective actions of individuals, and are thus created by society, Marx and Lukács reasoned that this necessarily meant that they could be \"changed\". Any attempt in transforming the so-called \"laws\" governing capitalism into universal principles, valid in all times and places, are criticized by Lukács as a form of false consciousness.\n\nAs the \"expression of the revolutionary process itself\", dialectical materialism, which is the only theory with an understanding of the totality of the historical process, is the theory which may help the proletariat in its \"struggle for class consciousness\". Although Lukács does not contest the Marxist primacy of the economic base on the ideological superstructure (not to be mistaken with vulgar economic determinism), he considers that there is a place for autonomous struggle for class consciousness.\n\nIn order to achieve a unity of theory and praxis, theory must not only tend toward reality in an attempt to change it; reality must also tend towards theory. Otherwise, the historical process leads a life of its own, while theorists make their own little theories, desperately waiting for some kind of possible influence over the historical process. Henceforth, reality itself must tend toward the theory, making it the \"expression of the revolutionary process itself\". In turn, a theory which has as its goal helping the proletariat achieve class consciousness must first be an \"objective theory of class consciousness\". However, theory in itself is insufficient, and ultimately relies on the struggle of humankind and of the proletariat for consciousness: the \"objective theory of class consciousness is only the theory of its objective possibility\".\n\nEconomist Ludwig Von Mises argued that \"Marx confus[ed] the notions of caste and class\". Mises allowed that class consciousness, and the associated class struggle, were valid concepts in some circumstances where rigid social castes exist; e.g., when slavery is legal, and slaves thus share a common motive for ending their disadvantaged status relative to other castes. \"But no such conflicts are present in a society in which all citizens are equal before the law,\" according to Mises. \"No logical objection can be advanced against distinguishing various classes among the members of such a society. Any classification is logically permissible, however arbitrarily the mark of distinction may be chosen. But it is nonsensical to classify the members of a capitalistic society according to their position in the framework of the social division of labor and then to identify these classes with the castes of a status society.\"\n\nPhilosopher Leszek Kołakowski argued that the \"theory of class consciousness is false\" and that attempts by Marxist–Leninists to advance the concept of class consciousness necessarily led to totalitarianism.\n\nSociologist Ernest van den Haag has argued:\n\nIndeed, it has been argued that the class interests of any class must be empirically determined by examining their actual behavior - they do not have objectively existing interests. People must assume social identities as members of a class before it becomes possible to identify what those interests are by examining their behavior and positions. It has been observed, for example, that workers form attachment to the capitalist system (through trade unions) rather than antagonism.\n\n"}
{"id": "621215", "url": "https://en.wikipedia.org/wiki?curid=621215", "title": "Cointerpretability", "text": "Cointerpretability\n\nIn mathematical logic, cointerpretability is a binary relation on formal theories: a formal theory \"T\" is cointerpretable in another such theory \"S\", when the language of \"S\" can be translated into the language of \"T\" in such a way that \"S\" proves every formula whose translation is a theorem of \"T\". The \"translation\" here is required to preserve the logical structure of formulas. \n\nThis concept, in a sense dual to interpretability, was introduced by , who also proved that, for theories of Peano arithmetic and any stronger theories with effective axiomatizations, cointerpretability is equivalent to formula_1-conservativity.\n\n\n"}
{"id": "5863", "url": "https://en.wikipedia.org/wiki?curid=5863", "title": "Copenhagen interpretation", "text": "Copenhagen interpretation\n\nThe Copenhagen interpretation is an expression of the meaning of quantum mechanics that was largely devised in the years 1925 to 1927 by Niels Bohr and Werner Heisenberg. It remains one of the most commonly taught interpretations of quantum mechanics.\n\nAccording to the Copenhagen interpretation, physical systems generally do not have definite properties prior to being measured, and quantum mechanics can only predict the probabilities that measurements will produce certain results. The act of measurement affects the system, causing the set of probabilities to reduce to only one of the possible values immediately after the measurement. This feature is known as wave function collapse.\n\nThere have been many objections to the Copenhagen interpretation over the years. These include: discontinuous jumps when there is an observation, the probabilistic element introduced upon observation, the subjectiveness of requiring an observer, the difficulty of defining a measuring device, and the necessity of invoking classical physics to describe the \"laboratory\" in which the results are measured.\n\nAlternatives to the Copenhagen interpretation include the many-worlds interpretation, the De Broglie–Bohm (pilot-wave) interpretation, quantum Bayesianism, and quantum decoherence theories.\n\nMax Planck, Albert Einstein, and Niels Bohr postulated the occurrence of energy in discrete quantities (quanta) in order to explain phenomena such as the spectrum of black-body radiation, the photoelectric effect, and the stability and spectra of atoms. These phenomena had eluded explanation by classical physics and even appeared to be in contradiction with it. Although elementary particles show predictable properties in many experiments, they become thoroughly unpredictable in others, such as attempts to identify individual particle trajectories through a simple physical apparatus.\n\nClassical physics draws a distinction between particles and waves. It also relies on continuity and determinism in natural phenomena. In the early twentieth century, newly discovered atomic and subatomic phenomena seemed to defy those conceptions. In 1925–1926, quantum mechanics was invented as a mathematical formalism that accurately describes the experiments, yet appears to reject those classical conceptions. Instead, it posits that probability, and discontinuity, are fundamental in the physical world. Classical physics also relies on causality. The standing of causality for quantum mechanics is disputed.\n\nQuantum mechanics cannot easily be reconciled with everyday language and observation, and has often seemed counter-intuitive to physicists, including its inventors.\n\nThe Copenhagen interpretation intends to indicate the proper ways of thinking and speaking about the physical meaning of the mathematical formulations of quantum mechanics and the corresponding experimental results. It offers due respect to discontinuity, probability, and a conception of wave–particle dualism. In some respects, it denies standing to causality.\n\nWerner Heisenberg had been an assistant to Niels Bohr at his institute in Copenhagen during part of the 1920s, when they helped originate quantum mechanical theory. In 1929, Heisenberg gave a series of invited lectures at the University of Chicago explaining the new field of quantum mechanics. The lectures then served as the basis for his textbook, \"The Physical Principles of the Quantum Theory\", published in 1930. In the book's preface, Heisenberg wrote:\n\nOn the whole, the book contains nothing that is not to be found in previous publications, particularly in the investigations of Bohr. The purpose of the book seems to me to be fulfilled if it contributes somewhat to the diffusion of that 'Kopenhagener Geist der Quantentheorie' [i.e., Copenhagen spirit of quantum theory] if I may so express myself, which has directed the entire development of modern atomic physics.\n\nThe term 'Copenhagen interpretation' suggests something more than just a spirit, such as some definite set of rules for interpreting the mathematical formalism of quantum mechanics, presumably dating back to the 1920s. However, no such text exists, apart from some informal popular lectures by Bohr and Heisenberg, which contradict each other on several important issues. It appears that the particular term, with its more definite sense, was coined by Heisenberg in the 1950s, while criticizing alternate \"interpretations\" (e.g., David Bohm's) that had been developed. Lectures with the titles 'The Copenhagen Interpretation of Quantum Theory' and 'Criticisms and Counterproposals to the Copenhagen Interpretation', that Heisenberg delivered in 1955, are reprinted in the collection \"Physics and Philosophy\". Before the book was released for sale, Heisenberg privately expressed regret for having used the term, due to its suggestion of the existence of other interpretations, that he considered to be \"nonsense\".\n\nAccording to an opponent of the Copenhagen interpretation, John G. Cramer, \"Despite an extensive literature which refers to, discusses, and criticizes the Copenhagen interpretation of quantum mechanics, nowhere does there seem to be any concise statement which defines the full Copenhagen interpretation.\"\n\nThere is no uniquely definitive statement of the Copenhagen interpretation. It consists of the views developed by a number of scientists and philosophers during the second quarter of the 20th Century. Bohr and Heisenberg never totally agreed on how to understand the mathematical formalism of quantum mechanics. Bohr once distanced himself from what he considered to be Heisenberg's more subjective interpretation.\n\nDifferent commentators and researchers have associated various ideas with it. Asher Peres remarked that very different, sometimes opposite, views are presented as \"the Copenhagen interpretation\" by different authors.\n\nSome basic principles generally accepted as part of the interpretation include:\n\n\nThe Copenhagen interpretation denies that the wave function provides a directly apprehensible image of an ordinary material body or a discernible component of some such, or anything more than a theoretical concept.\n\nIn metaphysical terms, the Copenhagen interpretation views quantum mechanics as providing knowledge of phenomena, but not as pointing to 'really existing objects', which it regarded as residues of ordinary intuition. This makes it an epistemic theory. This may be contrasted with Einstein's view, that physics should look for 'really existing objects', making itself an ontic theory.\n\nThe metaphysical question is sometimes asked: \"Could quantum mechanics be extended by adding so-called \"hidden variables\" to the mathematical formalism, to convert it from an epistemic to an ontic theory?\" The Copenhagen interpretation answers this with a strong 'No'. It is sometimes alleged, for example by J.S. Bell, that Einstein opposed the Copenhagen interpretation because he believed that the answer to that question of \"hidden variables\" was \"yes\". That allegation has achieved mythical potency, but is mistaken. Countering that myth, Max Jammer writes \"Einstein never proposed a hidden variable theory.\" Einstein explored the possibility of a hidden variable theory, and wrote a paper describing his exploration, but withdrew it from publication because he felt it was faulty.\n\nBecause it asserts that a wave function becomes 'real' only when the system is observed, the term \"subjective\" is sometimes proposed for the Copenhagen interpretation. This term is rejected by many Copenhagenists because the process of observation is mechanical and does not depend on the individuality of the observer.\n\nSome authors have proposed that Bohr was influenced by positivism (or even pragmatism). On the other hand, Bohr and Heisenberg were not in complete agreement, and they held different views at different times. Heisenberg in particular was prompted to move towards realism.\n\nCarl Friedrich von Weizsäcker, while participating in a colloquium at Cambridge, denied that the Copenhagen interpretation asserted \"What cannot be observed does not exist.\" He suggested instead that the Copenhagen interpretation follows the principle \"What is observed certainly exists; about what is not observed we are still free to make suitable assumptions. We use that freedom to avoid paradoxes.\"\n\nMax Born speaks of his probability interpretation as a \"statistical interpretation\" of the wave function, and the Born rule is essential to the Copenhagen interpretation.\n\nWriters do not all follow the same terminology. The phrase \"statistical interpretation\", referring to the \"ensemble interpretation\", often indicates an interpretation of the Born rule somewhat different from the Copenhagen interpretation. For the Copenhagen interpretation, it is axiomatic that the wave function exhausts all that can ever be known in advance about a particular occurrence of the system. The \"statistical\" or \"ensemble\" interpretation, on the other hand, is explicitly agnostic about whether the information in the wave function is exhaustive of what might be known in advance. It sees itself as more 'minimal' than the Copenhagen interpretation in its claims. It only goes as far as saying that on every occasion of observation, some actual value of some property is found, and that such values are found probabilistically, as detected by many occasions of observation of the same system. The many occurrences of the system are said to constitute an 'ensemble', and they jointly reveal the probability through these occasions of observation. Though they all have the same wave function, the elements of the ensemble might not be identical to one another in all respects, according to the 'agnostic' interpretations. They may, for all we know, beyond current knowledge and beyond the wave function, have individual distinguishing properties. For present-day science, the experimental significance of these various forms of Born's rule is the same, since they make the same predictions about the probability distribution of outcomes of observations, and the unobserved or unactualized potential properties are not accessible to experiment.\n\nThose who hold to the Copenhagen interpretation are willing to say that a wave function involves the various probabilities that a given event will proceed to certain different outcomes. But when the apparatus registers one of those outcomes, no probabilities or superposition of the others linger.\n\nAccording to Howard, wave function collapse is not mentioned in the writings of Bohr.\n\nSome argue that the concept of the collapse of a \"real\" wave function was introduced by Heisenberg and later developed by John von Neumann in 1932. However, Heisenberg spoke of the wavefunction as representing available knowledge of a system, and did not use the term \"collapse\" per se, but instead termed it \"reduction\" of the wavefunction to a new state representing the change in available knowledge which occurs once a particular phenomenon is registered by the apparatus (often called \"measurement\").\n\nIn 1952 David Bohm developed decoherence, an \"explanatory mechanism\" for the \"appearance\" of wave function collapse. Bohm applied decoherence to Louis DeBroglie's pilot wave theory, producing Bohmian mechanics, the first successful hidden variables interpretation of quantum mechanics. Collapse was avoided by Hugh Everett in 1957 in his relative state interpretation. Decoherence was largely ignored until the 1980s.\n\nThe domain of the wave function is configuration space, an abstract object quite different from ordinary physical space–time. At a single \"point\" of configuration space, the wave function collects probabilistic information about several distinct particles, that respectively have physically space-like separation. So the wave function is said to supply a non-separable representation. This reflects a feature of the quantum world that was recognized by Einstein as early as 1905.\n\nIn 1927, Bohr drew attention to a consequence of non-separability. The evolution of the system, as determined by the Schrödinger equation, does not display particle trajectories through space–time. It is possible to extract trajectory information from such evolution, but not simultaneously to extract energy–momentum information. This incompatibility is expressed in the Heisenberg uncertainty principle. The two kinds of information have to be extracted on different occasions, because of the non-separability of the wave function representation. In Bohr's thinking, space–time visualizability meant trajectory information. Again, in Bohr's thinking, 'causality' referred to energy–momentum transfer; in his view, lack of energy–momentum knowledge meant lack of 'causality' knowledge. Therefore Bohr thought that knowledge respectively of 'causality' and of space–time visualizability were incompatible but complementary.\n\nThe term Copenhagen interpretation is not well defined when one asks about the wave–particle dilemma, because Bohr and Heisenberg had different or perhaps disagreeing views on it.\n\nAccording to Camilleri, Bohr thought that the distinction between a wave view and a particle view was defined by a distinction between experimental setups, while, differing, Heisenberg thought that it was defined by the possibility of viewing the mathematical formulas as referring to waves or particles. Bohr thought that a particular experimental setup would display either a wave picture or a particle picture, but not both. Heisenberg thought that every mathematical formulation was capable of both wave and particle interpretations.\n\nAlfred Landé was for a long time considered orthodox. He did, however, take the Heisenberg viewpoint, in so far as he thought that the wave function was always mathematically open to both interpretations. Eventually this led to his being considered unorthodox, partly because he did not accept Bohr's one-or-the-other view, preferring Heisenberg's always-both view. Another part of the reason for branding Landé unorthodox was that he recited, as did Heisenberg, the 1923 work of old-quantum-theorist William Duane, which anticipated a quantum mechanical theorem that had not been recognized by Born. That theorem seems to make the always-both view, like the one adopted by Heisenberg, rather cogent. One might say \"It's there in the mathematics\", but that is not a physical statement that would have convinced Bohr. Perhaps the main reason for attacking Landé is that his work demystified the phenomenon of diffraction of particles of matter, such as buckyballs.\n\nThroughout much of the twentieth century the Copenhagen interpretation had overwhelming acceptance among physicists. Although astrophysicist and science writer John Gribbin described it as having fallen from primacy after the 1980s, according to a very informal poll (some people voted for multiple interpretations) conducted at a quantum mechanics conference in 1997, the Copenhagen interpretation remained the most widely accepted specific interpretation of quantum mechanics among physicists. In more recent polls conducted at various quantum mechanics conferences, varying results have been found. In a 2017 article, physicist and Nobel laureate Steven Weinberg states that the Copenhagen interpretation \"is now widely felt to be unacceptable.\"\n\nThe nature of the Copenhagen interpretation is exposed by considering a number of experiments and paradoxes.\n\n1. Schrödinger's cat\n\n2. Wigner's friend\n\n3. Double-slit diffraction\n\n4. EPR (Einstein–Podolsky–Rosen) paradox\n\nThe completeness of quantum mechanics (thesis 1) was attacked by the Einstein–Podolsky–Rosen thought experiment which was intended to show that quantum mechanics could not be a complete theory.\n\nExperimental tests of Bell's inequality using particles have supported the quantum mechanical prediction of entanglement.\n\nThe Copenhagen interpretation gives special status to measurement processes without clearly defining them or explaining their peculiar effects. In his article entitled \"Criticism and Counterproposals to the Copenhagen Interpretation of Quantum Theory,\" countering the view of Alexandrov that (in Heisenberg's paraphrase) \"the wave function in configuration space characterizes the objective state of the electron.\" Heisenberg says,\n\nMany physicists and philosophers have objected to the Copenhagen interpretation, both on the grounds that it is non-deterministic and that it includes an undefined measurement process that converts probability functions into non-probabilistic measurements. Einstein's comments \"I, at any rate, am convinced that He (God) does not throw dice.\" and \"Do you really think the moon isn't there if you aren't looking at it?\" exemplify this. Bohr, in response, said, \"Einstein, don't tell God what to do.\"\n\nSteven Weinberg in \"Einstein's Mistakes\", \"Physics Today\", November 2005, page 31, said:\n\nThe problem of thinking in terms of classical measurements of a quantum system becomes particularly acute in the field of quantum cosmology, where the quantum system is the universe.\n\nE. T. Jaynes, from a Bayesian point of view, argued that probability is a measure of a state of information about the physical world. Quantum mechanics under the Copenhagen interpretation interpreted probability as a physical phenomenon, which is what Jaynes called a mind projection fallacy.\n\nCommon criticisms of the Copenhagen interpretation often lead to the problem of continuum of random occurrences: whether in time (as subsequent measurements, which under certain interpretations of the measurement problem may happen continuously) or even in space. A recent experiment showed that a particle may leave a trace about the path which it used when travelling as a wave – and that this trace exhibits equality of both paths. If such result is raised to the rank of a wave-only non-transactional worldview and proved better – i.e. that a particle is in fact a continuum of points capable of acting independently but under a common wavefunction – it would rather support theories such as Bohm's one (with its guiding towards the centre of orbital and spreading of physical properties over it) than interpretations which presuppose full randomness, because with the latter it will be problematic to demonstrate universally and in all practical cases how can a particle remain coherent in time, in spite of non-zero probabilities of its individual points going into regions distant from the centre of mass (through a continuum of different random determinations). An alternative possibility would be to assume that there is a finite number of instants/points within a given time or area, but theories which try to quantize the space or time itself seem to be fatally incompatible with the special relativity.\n\nThe view that particle diffraction logically guarantees the need for a wave interpretation has been questioned. A recent experiment has carried out the two-slit protocol with helium atoms. The basic physics of quantal momentum transfer considered here was originally pointed out in 1923, by William Duane, before quantum mechanics was invented. It was later recognized by Heisenberg and by Pauling. It was championed against orthodox ridicule by Alfred Landé. It has also recently been considered by Van Vliet. If the diffracting slits are considered as classical objects, theoretically ideally seamless, then a wave interpretation seems necessary, but if the diffracting slits are considered physically, as quantal objects exhibiting collective quantal motions, then the particle-only and wave-only interpretations seem perhaps equally valid.\n\nThe Ensemble interpretation is similar; it offers an interpretation of the wave function, but not for single particles. The consistent histories interpretation advertises itself as \"Copenhagen done right\". Although the Copenhagen interpretation is often confused with the idea that consciousness causes collapse, it defines an \"observer\" merely as that which collapses the wave function. Quantum information theories are more recent, and have attracted growing support.\n\nUnder realism and determinism, if the wave function is regarded as ontologically real, and collapse is entirely rejected, a many worlds theory results. If wave function collapse is regarded as ontologically real as well, an objective collapse theory is obtained. Under realism and determinism (as well as non-localism), a hidden variable theory exists, e.g., the de Broglie–Bohm interpretation, which treats the wavefunction as real, position and momentum as definite and resulting from the expected values, and physical properties as spread in space. For an atemporal indeterministic interpretation that “makes no attempt to give a ‘local’ account on the level of determinate particles”, the conjugate wavefunction, (\"advanced\" or time-reversed) of the relativistic version of the wavefunction, and the so-called \"retarded\" or time-forward version are both regarded as real and the transactional interpretation results.\n\nMany physicists have subscribed to the instrumentalist interpretation of quantum mechanics, a position often equated with eschewing all interpretation. It is summarized by the sentence \"Shut up and calculate!\". While this slogan is sometimes attributed to Paul Dirac or Richard Feynman, it seems to be due to David Mermin.\n\n\n\n"}
{"id": "10944821", "url": "https://en.wikipedia.org/wiki?curid=10944821", "title": "David Hammons", "text": "David Hammons\n\nDavid Hammons (born 1943) is an American artist especially known for his works in and around New York City and Los Angeles during the 1970s and 1980s.\n\nDavid Hammons was born in 1943 in Springfield, Illinois, the youngest of ten children of a single mother. In 1962 he moved to Los Angeles, where he started attending Chouinard Art Institute (now CalArts) from 1966 to 1968 and the Otis Art Institute from 1968 to 1972. There he was influenced by internationally known artists such as Bruce Nauman, John Baldessari, and Chris Burden, but was also part of a pioneering group of African-American artists and jazz musicians in Los Angeles, with influence outside the area. In 1974 Hammons settled in New York City, where he slowly became better known nationally. He still lives and works in New York.\n\nMuch of his work reflects his commitment to the civil rights and Black Power movements. A good example is the early \"Spade with Chains\" (1973), where the artist employs a provocative, derogatory term, coupled with the literal gardening instrument, in order to make a visual pun between the blade of a shovel and an African mask, and a contemporary statement about the issues of bondage and resistance. This was part of a larger series of \"Spade\" works in the 1970s, including \"Bird\" (1973), where Charlie Parker is evoked by a spade emerging from a saxophone, and \"Spade\", a 1974 print where the artist pressed his face against the shape leaving a caricature-like imprint of Negroid features.\n\nIn 1980, Hammons took part in Colab's ground-breaking \"The Times Square Show\", which acted as a forum for exchange of ideas for a younger set of alternative artists in New York. His installation was made of glistening scattered shards of glass (from broken bottles of Night Train wine).\n\nOther works play on the association of basketball and young black men, such as drawings made by repeatedly bouncing a dirty basketball on huge sheets of clean white paper set on the floor; a series of larger-than-life basketball hoops, meticulously decorated with bottle caps, evoking Islamic mosaic and design; and \"Higher Goals\" (1986), where an ordinary basketball hoop, net, and backboard are set on a three-story high pole - commenting on the almost impossible aspirations of sports stardom as a way out of the ghetto.\n\nThrough his varied work and media, and frequent changes in direction, Hammons has managed to avoid one signature visual style. Much of his work makes allusions to, and shares concerns with minimalism and post-minimal art, but with added Duchampian references to the place of Black people in American society.\n\nOn James Turrell's works concerning perception of light, Hammons said \"I wish I could make art like that, but we're too oppressed for me to be dabbling out there... I would love to do that because that could also be very black. You know, as a black artist, dealing just with light. They would say, \"how in the hell could he deal with that, coming from where he did?\" I want to get to that, I'm trying to get to that, but I'm not free enough yet. I still feel I have to get my message out.\"\n\nAlong with his focus on cultural overtones, Hammons’s work also discusses the notions of public and private spaces, as well as what constitutes a valuable commodity. An illustration of these concepts can be seen in \"Bliz-aard Ball Sale\" (1983), a performance piece in which Hammons situates himself alongside street vendors in downtown Manhattan in order to sell snowballs which are priced according to size. This act serves both as a parody on commodity exchange and a commentary on the capitalistic nature of art fostered by art galleries. Furthermore, it puts a satirical premium on \"whiteness\", ridiculing the superficial luxury of racial classification as well as critiquing the hard social realities of street vending experienced by those who have been discriminated against in terms of race or class.\n\nAlso noteworthy is the artist's use of discarded or abject materials, including but not limited to elephant dung, chicken parts, strands of African-American hair, and bottles of cheap wine. Many critics see these objects as evocative of the desperation of the poor, Black urban class, but Hammons reportedly saw a sort of sacrosanct or ritualistic power in these materials, which is why he utilized them so extensively.\n\nIn \"The Window: Rented Earth: David Hammons,\" an early solo exhibition at the New Museum, Hammons dealt with the diametrically opposed relationship between spirituality and technology by juxtaposing an African tribal mask with a modern-day invention—a child’s toy television set.\n\nHammons explored the video medium, collaborating with artist Alex Harsley on a number of video works, including \"Phat Free\" (originally titled \"Kick the Bucket\"), which was included in the Whitney Biennial and other venues. Hammons and Harsley have also collaborated on installations at New York's 4th Street Photo Gallery, a noted East Village artist exhibition and project space.\n\nIn a show at L & M Arts in uptown Manhattan (January 18–March 31, 2007, his first authorized New York show since 2002, although there have been unauthorized surveys), Hammons collaborated with Japanese artist Chie (Hasegawa) Hammons in a piece that enjoyed public acclaim. In the posh uptown gallery specially selected by Hammons (who does not accept to be associated with any one gallery), they installed full-length fur coats on antique dress forms—two minks, a fox, a sable, a wolf and a chinchilla: \"Hammons and his wife have also painted, burned, burnished, and stained the backs of all of these coats, turning them into aesthetic/ethical/sartorial traps... Hammons has said that he wants 'to slide away from visuals and get deeper.' At L & M, not only does Hammons do this; along the way he conjures thoughts of shamanism, politics, consumerism, animism, genre painting, animal rights, and jokes. Here, we're treated to a sensibility as barbed, serious, maybe fearsome, and as passionate as any in the art world.\"\n\nHammons’s \"African American Flag\" is a part of the permanent collection of New York’s Museum of Modern Art. He also has work in the permanent collections of the Whitney Museum of American Art, New York; Fogg Art Museum, Cambridge; Hirshhorn Museum and Sculpture Garden in Washington DC; Museum of Contemporary Art Chicago, Chicago; Museum of Contemporary Art, Los Angeles; Fondation Cartier pour l'art contemporain, Paris; The Tate, London; and other museums and collections.\n\nHammons received the MacArthur Fellowship (popularly known as the \"Genius Grant\") in July 1991.\n\naliaseditorial.com/en/colecciones/por-esto-estamos-aqui/\n\n"}
{"id": "1007973", "url": "https://en.wikipedia.org/wiki?curid=1007973", "title": "Dāna", "text": "Dāna\n\nDāna (Devanagari: दान) is a Sanskrit and Pali word that connotes the virtue of generosity, charity or giving of alms in Indian philosophies. It is alternatively transliterated as \"daana\".\n\nIn Hinduism, Buddhism, Jainism and Sikhism, dāna is the practice of cultivating generosity. It can take the form of giving to an individual in distress or need. It can also take the form of philanthropic public projects that empower and help many.\n\nAccording to historical records, dāna is an ancient practice in Indian traditions, tracing back to Vedic traditions.\n\nDāna (Sanskrit: दान) means giving, often in the context of donation and charity. In other contexts, such as rituals, it can simply refer to the act of giving something. Dāna is related to and mentioned in ancient texts with concepts of \"Paropakāra\" (परोपकार) which means benevolent deed, helping others; \"Dakshina\" (दक्षिणा) which means gift or fee one can afford; and \"Bhiksha\" (भिक्षा), which means alms.\n\nDāna has been defined in traditional texts as any action of relinquishing the ownership of what one considered or identified as one's own, and investing the same in a recipient without expecting anything in return.\n\nWhile dāna is typically given to one person or family, Hinduism also discusses charity or giving aimed at public benefit, sometimes called \"utsarga\". This aims at larger projects such as building a rest house, school, drinking water or irrigation well, planting trees, and building care facility among others.\n\nThe \"Rigveda\" has the earliest discussion of \"dāna\" in the Vedas. The \"Rigveda\" relates it to \"satya\" \"truth\" and in another hymn points to the guilt one feels from not giving to those in need. It uses \"da\", the root of word \"dāna\", in its hymns to refer to the act of giving to those in distress. Ralph T. H. Griffith, for example, translates Book 10, Hymn 117 of the Rig veda as follows:\nThe Upanishads, composed before 500 BCE, present some of the earliest Upanishadic discussion of dāna. Brihadaranyaka Upanishad, in verse 5.2.3, states that three characteristics of a good, developed person are self-restraint (damah), compassion or love for all sentient life (daya), and charity (dāna).\n\nChandogya Upanishad, Book III, similarly, states that a virtuous life requires: tapas (asceticism), dāna (charity), arjava (straightforwardness), ahimsa (non-injury to all sentinent beings) and satyavacana (truthfulness).\n\n\"Bhagavad Gita\" describes the right and wrong forms of \"dāna\" in verses 17.20 through 17.22. It defines \"sāttvikam\" (good, enlightened, pure) charity, in verse 17.20, as one given without expectation of return, at the proper time and place, and to a worthy person. It defines \"rajas\" (passion, ego driven, active) charity, in verse 17.21, as one given with the expectation of some return, or with a desire for fruits and results, or grudgingly. It defines \"tamas\" (ignorant, dark, destructive) charity, in verse 17.22, as one given with contempt, to unworthy person(s), at a wrong place and time. In Book 17, Bhadwad Gita suggests steadiness in \"sattvikam dāna\", or the good form of charity is better; and that \"tamas\" should be avoided. These three psychological categories are referred to as the \"guṇas\" in Hindu philosophy.\n\nThe \"Adi Parva\" of the Hindu Epic \"Mahabharata\", in Chapter 91, states that a person must first acquire wealth by honest means, then embark on charity; be hospitable to those who come to him; never inflict pain on any living being; and share a portion with others whatever he consumes. In Chapter 87 of \"Adi Parva\", it calls sweet speech and refusal to use harsh words or wrong others even if you have been wronged, as a form of charity. In the \"Vana Parva\", Chapter 194, the Mahabharata recommends that one must, \"conquer the mean by charity, the untruthful by truth, the wicked by forgiveness, and dishonesty by honesty\". \"Anushasana Parva\" in Chapter 58, recommends public projects as a form of dāna. It discusses the building of drinking water tanks for people and cattle as a noble form of giving, as well as giving of lamps for lighting dark public spaces. In later sections of Chapter 58, it describes planting public orchards, with trees that give fruits to strangers and shade to travelers, as meritorious acts of benevolent charity. In Chapter 59 of Book 13 of the \"Mahabharata\", Yudhishthira and Bhishma discuss the best and lasting gifts between people:\n\nThe \"Bhagavata Purana\" discusses when dāna is proper and when it is improper. In Book 8, Chapter 19, verse 36 it states that charity is inappropriate if it endangers and cripples modest livelihood of one's biological dependents or of one’s own. Charity from surplus income above that required for modest living is recommended in the Puranas.\n\nHindu scriptures exist in many Indian languages. For example, the \"Tirukkuṛaḷ\", written between 200 BCE and 400 CE, is one of the most cherished classics on Hinduism written in a South Indian language. It discusses charity, dedicating Chapter 23 of Book 1 on Virtues to it. \"Tirukkuṛaḷ\" suggests charity is necessary for an virtuous life and happiness. He states in Chapter 23: \"Giving to the poor is true charity, all other giving expects some return\"; \"Great, indeed, is the power to endure hunger.\nGreater still is the power to relieve other's hunger\"; \"Giving alms is a great reward in itself to one who gives\". In Chapter 101, he states: \"Believing wealth is everything, yet giving away nothing, is a miserable state of mind\"; \"Vast wealth can be a curse to one who neither enjoys it nor gives to the worthy\". Like the Mahabharata, Tirukkuṛaḷ also extends the concept of charity to deeds (body), words (speech) and thoughts (mind). It states that a brightly beaming smile, the kindly light of loving eye, and saying pleasant words with sincere heart is a form of charity that every human being should strive to give.\n\nDāna is also used to refer to rituals. For example, in a Hindu wedding, \"kanyādāna\" (कन्यादान) refers to the ritual where a father gives his daughter's hand in marriage to the groom, after asking the groom to promise that he will never fail in his pursuit of dharma (moral and lawful life), artha (wealth) and kama (love). The groom promises to the bride's father, and repeats his promise three times in presence of all gathered as witness.\n\nOther types of charity includes donating means of economic activity and food source. For example, godāna (donation of a cow), bhudāna (भूदान) (donation of land), and \"vidyādāna\" or jñānadāna (विद्यादान, ज्ञानदान): Sharing knowledge and teaching skills, \"aushadhādāna\" (औषधदान): Charity of care for the sick and diseased, \"abhayadāna\"(अभयदान): giving freedom from fear (asylum, protection to someone facing imminent injury), and \"anna dāna\" (अन्नादान): Giving food to the poor, needy and all visitors.\n\nCharity is held as a noble deed in Hinduism, to be done without expectation of any return from those who receive the charity. Some texts reason, referring to the nature of social life, that charity is a form of good karma that affects one's future circumstances and environment, and that good charitable deeds leads to good future life because of the reciprocity principle.\nOther Hindu texts, such as \"Vyasa Samhita\", state that reciprocity may be innate in human nature and social functions but dāna is a virtue in itself, as doing good lifts the nature of one who gives. The texts do not recommend charity to unworthy recipients or where charity may harm or encourage injury to or by the recipient. Dāna, thus, is a dharmic act, requires idealistic-normative approach, and has spiritual and philosophical context. The donor's intent and responsibility for diligence about the effect of dāna on the recipient is considered as important as the dāna itself. While the donor should not expect anything in return with dāna, the donor is expected to make an effort to determine the character of the recipient, likely return to the recipient and to the society. Some medieval era authors state that \"dāna\" is best done with \"shraddha\" (faith), which is defined as being in good will, cheerful, welcoming the recipient of the charity and giving without \"anasuya\" (finding faults in the recipient). These scholars of Hinduism, states Kohler, suggest that charity is most effective when it is done with delight, a sense of \"unquestioning hospitality\", where the \"dāna\" ignores the short term weaknesses as well as the circumstances of the recipient and takes a long term view.\n\nAl-Biruni, the Persian historian, who visited and lived in India for 16 years from about 1017, mentions the practice of charity and almsgiving among Hindus as he observed during his stay. He wrote, \"It is obligatory with them (Hindus) every day to give alms as much as possible.\"\n\n\"Satram\"s, called \"Choultry\", \"Dharamsala\" or \"Chathram\"s in parts of India, have been one expression of Hindu charity. Satrams are shelters (rest houses) for travelers and the poor, with many serving water and free food. These were usually established along the roads connecting major Hindu temple sites in South Asia as well as near major temples.\n\nHindu temples served as charitable institutions. Burton Stein states that South Indian temples collected donations (melvarum) from devotees, during the Chola dynasty and Vijayanagara Empire periods in 1st millennium through first half of 2nd millennium AD. These \"dāna\" were then used to feed people in distress as well as fund public projects such as irrigation and land reclamation.\n\n\"Mitākṣarā\" by Vijñāneśvara is an 11th-century canonical discussion and commentary on dāna, composed under the patronage of Chalukya dynasty. The discussion about charity is included in its thesis on \"ācāra\" (moral conduct).\n\nMajor Sanskrit treatises that discuss ethics, methods and rationale for charity and alms giving in Hinduism include, states Maria Heim, the 12th-century \"Dāna Kānda\" \"Book of Giving\" by Laksmidhara of Kannauj, the 12th-century \"Dāna Sāgara\" \"Sea of Giving\" by Ballālasena of Bengal, and the 14th-century sub-book \"Dānakhanda\" in \"Caturvargacintamani\" \"The Gem of the Four Aims of Human Life\" by Hemadiri of Devagiri (modern Daulatabad, Maharashtra). The first two are few hundred page treatises each, while the third is over a thousand-page compendium on charity, from a region that is now part of modern-day eastern Maharashtra and Telangana; the text influenced Hindus of Deccan region and South India from 14th to 19th centuries.\n\nDāna as a formal religious act is directed specifically to a monastic or spiritually-developed person. In Buddhist thought, it has the effect of purifying and transforming the mind of the giver.\n\nGenerosity developed through giving leads to experience of material wealth and possibly being reborn in happy states. In the Pāli Canon's \"Dighajanu Sutta\", generosity (denoted there by the Pāli word \"cāga\", which can be synonymous with \"dāna\") is identified as one of the four traits conditioning happiness and wealth in the next life. Conversely, lack of giving leads to unhappy states and poverty.\n\nDāna leads to one of the pāramitās or \"perfections\", the \"dānapāramitā\". This can be characterized by unattached and unconditional generosity, giving and letting go.\n\nBuddhists believe that giving without seeking anything in return leads to greater spiritual wealth. Moreover, it reduces the acquisitive impulses that ultimately lead to continued suffering from egotism.\n\nDana is, as with Hindu texts like Mitaksara and Vahni Purana and in Buddhist texts, described as a virtue and duty in Jainism. It is considered an act of compassion, and must be done with no desire for material gain. Four types of Dana are discussed in the texts of Jainism: \"Ahara-dana\" (donation of food), \"Ausadha-dana\" (donation of medicine), \"Jnana-dana\" (donation of knowledge) and \"Abhaya-dana\" (giving of protection or freedom from fear, asylum to someone under threat). Dāna is one of ten means to gain positive karma, in the soteriological theories of Jainism. Medieval era texts of Jainism dedicate a substantial portion of their discussions to the need and virtue of Dāna.\n\nDāna, called Vand Chhako, is considered one of three duties of Sikhs. The duty entails sharing part of one's earnings with others, by giving to charity and caring for others. Examples of dāna in Sikhism include selfless service and langar.\n\n\n\n"}
{"id": "83877", "url": "https://en.wikipedia.org/wiki?curid=83877", "title": "Enema", "text": "Enema\n\nAn enema is the injection of fluid into the lower bowel by way of the rectum. \n\nIn standard medicine, the most frequent uses of enemas are to relieve constipation and for bowel cleansing before a medical examination or procedure; also, they are employed as a lower gastrointestinal series (also called a barium enema), to check diarrhea, as a vehicle for the administration of food, water or medicine, as a stimulant to the general system, as a local application and, more rarely, as a means of reducing temperature, as treatment for encopresis, and as a form of rehydration therapy (proctoclysis) in patients for whom intravenous therapy is not applicable.\n\nIn other contexts, enemas are used by some alternative health therapies, used recreationally, chiefly as part of sexual activities, but also in sadomasochism, as well as simply for pleasure, used to intoxicate with alcohol, used to administer drugs for both recreational and religious reasons, and used for punishment.\n\nThe principal medical usages of enemas are:\n\nAs bowel stimulants, enemas are employed for the same purposes as orally administered laxatives: To relieve constipation; To treat fecal impaction; To empty the colon prior to a medical procedure such as a colonoscopy. A large volume or high enema can be given to cleanse as much of the colon as possible of feces. However, a low enema is generally useful only for stool in the rectum, not in the intestinal tract.\n\nSuch enemas' mechanism consists of the volume of the liquid causing rapid expansion of the intestinal tract in conjunction with, in the case of certain solutions, irritation of the intestinal mucosa, resulting in powerful peristalsis and a feeling of extreme fecal urgency. The enema is retained until there is a uncontrollable urge to defecate, at which time the recipient may expel any fecal matter loosened by the instilled solution together with the solution itself. The procedure may cause uncomfortable bloating and cramping.\n\nPlain water can be used, simply functioning mechanically to expand the colon, thus prompting evacuation.\n\nCastile soap is commonly added because its irritation of the colon's lining increases the urgency to defecate.\n\nLikewise, mild hand soap can be dissolved in the water. However, liquid handsoaps and detergents should not be used.\n\nGlycerol is a specific bowel mucosa irritant serving to induce peristalsis via a hyperosmotic effect. It is used in a dilute solution, e.g., 5%.\n\nBuffered sodium phosphate solution draws additional water from the bloodstream into the colon to increase the effectiveness of the enema, but can be rather irritating to the colon, causing intense cramping or \"griping.\"\n\nNormal saline is least irritating to the colon, at the opposite end of the spectrum. Like plain water, it simply functions mechanically to expand the colon, but having a neutral concentration gradient, it neither draws electrolytes from the body, as happens with plain water, nor draws water into the colon, as occurs with phosphates. Thus, a salt water solution can be used when a longer period of retention is desired, such as to soften an impaction.\n\nLikewise, baking soda (sodium bicarbonate) can be dissolved in the water.\n\nEqual parts of milk and molasses heated together to slightly above normal body temperature have been used. Neither the milk sugars and proteins nor the molasses are absorbed in the lower intestine, thus keeping the water from the enema in the intestine. \n\nMineral oil functions as a lubricant and stool softener, but often has the side effect of sporadic seepage from the patient's anus which can soil undergarments for up to 24 hours.\n\n\"TAI\", also termed \"retrograde irrigation\", is designed to assist evacuation using a water enema as a treatment for persons with bowel dysfunction, including fecal incontinence or constipation, especially obstructed defecation. Its effectiveness varies considerably, some individuals experiencing complete control of incontinence but others reporting little or no benefit.\n\nThe term \"retrograde irrigation\" distinguishes this procedure from the Malone antegrade continence enema, where irrigation fluid is introduced into the colon proximal to the anus via a surgically created irrigation port.\n\nPatients who have a bowel disability, a medical condition which impairs control of defecation, e.g., fecal incontinence or constipation, can use bowel management techniques to choose a predictable time and place to evacuate. Without bowel management, such persons might either suffer from the feeling of not getting relief, or they might soil themselves.\n\nWhile simple techniques might include a controlled diet and establishing a toilet routine, a daily enema can be taken to empty the colon, thus preventing unwanted and uncontrolled bowel movements that day.\nBy regularly emptying the bowel using transanal irrigation, controlled bowel function is often re-established to a high degree, thus enabling development of a consistent bowel routine. An international consensus on when and how to use transanal irrigation for people with bowel problems was published in 2013, offering practitioners a clear, comprehensive and simple guide to practice for the emerging therapeutic area of transanal irrigation.\n\nIn a lower gastrointestinal series an enema that may contain barium sulfate powder or a water-soluble contrast agent is used in the radiological imaging of the bowel. Called a \"barium enema\", such enemas are sometimes the only practical way to \"view\" the colon in a relatively safe manner. Following barium enema administration, patients often find that flushing the remaining barium with additional water, baking soda, or saline enemas helps restore normal colon activity without complications of constipation from the administration of the barium sulfate.\n\nThe administration of substances into the bloodstream. This may be done in situations where it is undesirable or impossible to deliver a medication by mouth, such as antiemetics given to reduce nausea (though not many antiemetics are delivered by enema). Additionally, several anti-angiogenic agents, which work better without digestion, can be safely administered via a gentle enema.\n\nThe topical administration of medications into the rectum, such as corticosteroids and mesalazine used in the treatment of inflammatory bowel disease. Administration by enema avoids having the medication pass through the entire gastrointestinal tract, therefore simplifying the delivery of the medication to the affected area and limiting the amount that is absorbed into the bloodstream.\n\nRectal corticosteroid enemas are sometimes used to treat mild or moderate ulcerative colitis. They also may be used along with systemic (oral or injection) corticosteroids or other medicines to treat severe disease or mild to moderate disease that has spread too far to be treated effectively by medicine inserted into the rectum alone.\n\n\nImproper administration of an enema can cause electrolyte imbalance (with repeated enemas) or ruptures to the bowel or rectal tissues resulting in internal bleeding. However, these occurrences are rare in healthy, sober adults. Internal bleeding or rupture may leave the individual exposed to infections from intestinal bacteria. Blood resulting from tears in the colon may not always be visible, but can be distinguished if the feces are unusually dark or have a red hue. If intestinal rupture is suspected, medical assistance should be obtained immediately.\n\nThe enema tube and solution may stimulate the vagus nerve, which may trigger an arrhythmia such as bradycardia. Enemas should not be used if there is an undiagnosed abdominal pain since the peristalsis of the bowel can cause an inflamed appendix to rupture.\n\nThere are arguments both for and against colonic irrigation in people with diverticulitis, ulcerative colitis, Crohn's disease, severe or internal hemorrhoids or tumors in the rectum or colon, and its usage is not recommended soon after bowel surgery (unless directed by one's health care provider). Regular treatments should be avoided by people with heart disease or renal failure. Colonics are inappropriate for people with bowel, rectal or anal pathologies where the pathology contributes to the risk of bowel perforation.\n\nRecent research has shown that ozone water, which is sometimes used in enemas, can immediately cause microscopic colitis.\n\nA recent case series of 11 patients with five deaths illustrated the danger of phosphate enemas in high-risk patients.\n\n\"Enema\" comes from Greek ἔνεμα (\"énema\"), from ἐνίημι (\"eníēmi\"), \"(I) inject\".\n\n\"Clyster\" (/ˈklɪstə(r)/), also spelled \"glister\" in the 17th century, rarely \"cloister\" or \"clister\" comes from Greek κλυστήρ (\"klystḗr\"), from κλύζω (\"klýzo\"), \"(I) wash\". It is an archaic word for enema, more particularly for enemas administered using a \"clyster syringe\" – that is, a syringe with a rectal nozzle and a plunger rather than a bulb. Clyster syringes were used from the 17th century (or before) to the 19th century, when they were largely replaced by enema bulb syringes, bocks, and bags.\n\nThe first mention of the enema in medical literature is in the Ancient Egyptian Ebers Papyrus ( BCE). One of the many types of medical specialists was an Iri, the Shepherd of the Anus. Many medications were administered by enemas. There was a Keeper of the Royal Rectum who may have primarily been the pharaoh's enema maker. The god Thoth, according to Egyptian mythology, invented the enema.\n\nThe Olmec from their middle preclassic period (10th through 7th centeries BCE) through the Spanish Conquest used trance-inducing substances ceremonially, and these were ingested via, among other routes, enemas administered using jars.\n\nThe Maya in their late classic age (7th through 10th centuries CE) used enemas for, at least, ritual purposes, in the Xibalban court of the God D whose worship included ritual cult paraphernalia. It is hypothesized that these enemas were for ritual purification and the ingestion of intoxicants and hallucinogens. The Maya illustrated the use of a characteristic enema bulb syringe by female attendants administering clysters ritually.\n\nIn the first century BC the Greek physician Asclepiades of Bithynia wrote \"Treatment consists merely of three elements: drink, food, and the enema\". Also, he contended that indigestion is caused by particles of food that are too big and his prescribed treatment was proper amounts of food and wine followed by an enema which would remove the improper food doing the damage.\n\nIn the second century CE the Greek philosopher Celsus recommended an enema of pearl barley in milk or rose oil with butter as a nutrient for those suffering from dysentery and unable to eat and Galen mentions enemas in several contexts.\n\nIn medieval times appear the first illustrations of enema equipment, a clyster syringe consisting of a tube attached to a pump action bulb made of a pig bladder and the 15th century Simple piston syringe clysters came into use. Beginning in the 17th century enema apperatus was chiefly designed for self-administration at home and many were French as enemas enjoyed wide usage in France.\n\nWhen clyster syringes were in use in Europe, the patient was placed in an appropriate position (kneeling, with the buttocks raised, or lying on the side); a servant or apothecary would then insert the nozzle into the anus and press the plunger, resulting in the liquid remedy (generally, water, but also some other preparations) being injected into the colon.\n\nBecause of the embarrassment a woman might feel when showing her buttocks (and possibly her genitals, depending on the position) to a male apothecary, some contraptions were invented that blocked all from the apothecary's view except for the anal area. Another invention was syringes equipped with a special bent nozzle, which enabled self-administration, thereby eliminating the embarrassment.\n\nClysters were administered for symptoms of constipation and, with more questionable effectiveness, stomach aches and other illnesses. In his early-modern treatise, \"The Diseases of Women with Child,\" François Mauriceau records that both midwives and man-midwives commonly administered clysters to labouring mothers just prior to their delivery.\n\nIn the 16th century, satirists made physicians a favorite target, resembling Molière's caricature whose prescription for anything was \"clyster, bleed, purge,\" or \"purge, bleed, clyster.\" Sir Thomas More's eldest daughter had fallen sick of the sweating sickness and could not be awakened by doctors. More prayed for her recovery, and then\n\nwhere incontinent came into his mind, that a glister should be the only way to help her, which when he had told the physicians, they by-and-by confessed, that if there were any hope of health, that it was the very best help indeed, much marvelling of themselves, that they had not afore remembered it.\n\nIn the 18th century tobacco smoke enemas were used to resuscitate drowned people. Tobacco resuscitation kits consisting of a pair of bellows and a tube were provided by the Royal Humane Society of London and placed at various points along the Thames.\n\nClysters were a favourite medical treatment in the bourgeoisie and nobility of the Western world up to the 19th century. As medical knowledge was fairly limited at the time, purgative clysters were used for a wide variety of ailments, the foremost of which were stomach aches and constipation.\n\nMolière, in several of his plays, introduces characters of incompetent physicians and apothecaries fond of prescribing this remedy, also discussed by Argan, the hypochondriac patient of \"Le Malade Imaginaire\". More generally, clysters were a theme in the burlesque comedies of that time.\n\nAccording to Claude de Rouvroy, duc de Saint-Simon, clysters were so popular at the court of King Louis XIV of France that the duchess of Burgundy had her servant give her a clyster in front of the King (her modesty being preserved by an adequate posture) before going to the comedy. However, he also mentions the astonishment of the King and Mme de Maintenon that she should take it before them.\n\nIn the 19th century many new types of enema administration equipment were devised, including the bulb enema. Later there came to be a device to allow gravity to infuse the solution into the recipient, consisting of a rubber bag or bucket connected to a hose with a nozzle at the other end to insert into the patient's anus, the bag or bucket being held or hung above the patient. These continue to be used, although rubber has been replaced by modern materials and the bags, at least in hospital use, as disposable.\n\nIn the late 20th century the microenema was invented, this being a disposable squeeze bottle with contents that cause the body to draw water into the colon, e.g., sodium biphosphate (popular in the United States) or glycerin (popular in Japan).\n\nNutrient enemas were administered with the intent of providing nutrition when normal eating is not possible. Although this treatment is ancient, dating back at least to Galen, and commonly used in the Middle Ages, and still a common technique in 19th century medicine, Nutrient enemas have been superseded in modern medical care by tube feeding and intravenous feeding.\n\nThe term \"colonic irrigation\" is commonly used in gastroenterology to refer to the practice of introducing water through a colostomy or a surgically constructed conduit as a treatment for constipation. The Food and Drug Administration has ruled that colonic irrigation equipment is not approved for sale for the purpose of general well-being and has taken action against many distributors of this equipment, including a Warning Letter. \n\nThe same term is also used in alternative medicine where it may involve the use of substances mixed with water in order to detoxify the body. Practitioners believe the accumulation of fecal matter in the large intestine leads to ill health. This resurrects the old medical concept of \"autointoxication\" which was orthodox doctrine up to the end of the 19th century but which has now been discredited.\n\nAlthough well documented, the procedure of inserting coffee through the anus to cleanse the rectum and large intestines is considered by most medical authorities to be unproven, rash and potentially dangerous.\n\nIn the Gerson therapy, coffee enemas are administered.\n\nSome proponents of alternative medicine have claimed that coffee enemas have an anti-cancer effect by \"detoxifying\" metabolic products of tumors but there is no medical scientific evidence to support this.\n\nIn the late 19th century Dr. John Harvey Kellogg made sure that the bowel of each and every patient was plied with water, from above and below. His favorite device was an enema machine (\"just like one I saw in Germany\") that could run fifteen gallons of water through a person's bowel in a matter of seconds. Every water enema was followed by a pint of yogurt—half was eaten, the other half was administered by enema \"thus planting the protective germs where they are most needed and may render most effective service.\" The yogurt served to replace \"the intestinal flora\" of the bowel, creating what Kellogg claimed was a completely clean intestine.\n\nEnjoyment of enemas is known as klismaphilia, which medically is classified as a paraphilia. A person with klismaphilia is a \"klismaphile\".\n\nKlismaphiles can gain satisfaction of enemas through fantasies, by actually receiving or giving one, or through the process of eliminating steps to being administered one (e.g., under the pretense of being constipated). An enema can be an auxiliary to, or even a substitute for, genital sexual activity. Additionally, enemas can stimulate the prostate gland.\n\nThat some women use enemas while masturbating was documented by Kinsey, A. in \"Sexual Behavior in the Human Female.\" H stated, :There still other masturbatory techniques which were regularly or occasionally employed by some 11 percent of the females in the sample ... enemas, and other anal insertions, ... were employed.\"\n\nEnemas are sometimes used in sadomasochistic activities for erotic humiliation or for physical discomfort.\nAn enema can be employed prior to anal sexual activities such as anal sex, anilingus, and pegging to enhance sensation or remove feces, possibly reducing risk of infection.\n\nNoting that deaths have been reported from alcohol poisoning via enemas, an alcohol enema can be used to very quickly instill alcohol into the bloodstream, absorbed through the membranes of the colon. However, great care must be taken as to the amount of alcohol used. Only a small amount is needed as the intestine absorbs the alcohol far more quickly than the stomach.\n\nPreceding an enema for administration of drugs or alcohol, a cleansing enema may first be used for cleaning the colon to help increase the rate of absorption.\n\nEnemas have been used for ritual rectal drug administration such as balché, alcohol, tobacco, peyote, and other hallucinogenic drugs and entheogens, most notably by the Maya and also some other American Indian tribes. Some tribes continue the practice in the present day.\n\nCalled Basti or Vasti in Ayurveda, enemas are part of Panchakarma procedure in which herbal medicines are introduced rectally.\n\nEnemas have also been forcibly applied as a means of punishment. In the vastly influential Latin American text \"Facundo, or Civilization and Barbarism\", for example, Domingo Faustino Sarmiento describes the use of pepper and turpentine enemas by police forces as a way of discouraging political dissent in post-independence Argentina.\n\nThe Senate Intelligence Committee report on CIA torture documented instances of enemas being used by the Central Intelligence Agency in order to ensure \"total control\" over detainees.\n\nA brass statue of a syringe enema bulb held aloft by three angels stands in front of the \"Mashuk\" spa in the settlement of Zheleznovodsk in Russia. It is the only known monument to the enema.\n\n\nNotes\n"}
{"id": "5974803", "url": "https://en.wikipedia.org/wiki?curid=5974803", "title": "Etz Chaim Center for Jewish Learning", "text": "Etz Chaim Center for Jewish Learning\n\nEtz Chaim Center for Jewish Learning is an Orthodox Jewish organization designed to reach out to secular and non-Orthodox Jews in the hopes of bringing them into the Baal teshuva movement.\n\nOfficially incorporated on November 30, 1983, Etz Chaim is a multi-faceted outreach center dedicated to reaching Jews of all backgrounds to experience Orthodox Judaism. Among its programs, Etz Chaim helps people find study partners for the process of conversion to Orthodox Judaism. Etz Chaim says that success is when a person considers their Jewish identity more valuable, when a person chooses not to intermarry, or when a person does one mitzvah.\nIn 1992, a Lubavitch family advertised and held Jewish services, ceremonies, and celebrations in their house in Baltimore County. Neighbors complained to the local zoning commission, stating that the family were using their home as a synagogue, in direct violation of local zoning laws, parking laws, and noise restrictions. Etz Chaim supported the family, stating that enforcing such laws on a place of worship was unconstitutional.\n\nIn 1992, Etz Chaim supported detailed recommendations regarding Jewish celebrations that restricted kiddush to only one hot dish, cake, and drinks, while a b'nai mitzvah or wedding celebration may have up to two hot dishes. The recommendations stated that all religious celebrations be held only at a synagogue itself or a synagogue's facilities.\n\nIn 1993, Etz Chaim honored Marc Hurwitz for his working helping college students discover or maintain their Jewish identities and fighting assimilation on college campuses.\n\nIn 1998, Etz Chaim moved its headquarters from Northeast Baltimore to Center City Baltimore.\n\nIn 2001, a bill was proposed to prohibiting discrimination based on sexual orientation with regard to public accommodations, housing, and employment in Maryland. Etz Chaim opposed the bill, stating that Orthodox Judaism opposes homosexuality.\n\nIn 2001, a choir of 61 mixed-gender students in third through fifth grades prepared to sing at a Jewish food and life expo. When Etz Chaim was asked whether it was religiously appropriate for female and male children to sing together, Etz Chaim determined the performance should not go forward.\n\nOn February 6, 2002, a fire destroyed the Etz Chaim Center for Jewish Studies. A teenager was arrested and charged with arson. With money from its insurance carrier and several donors, Etz Chaim was able to rebuild. The new, larger facility included a Shabbaton center, coffee shop, and library, and it was dedicated in June 2015.\n\nEtz Chaim is under the direction of Rabbi Shlomo Porter. Rabbi Porter has led the organization since 1981. Originally from Milwaukee, Wisconsin, Rabbi Porter graduated from Ner Israel Rabbinical College.\n\nEtz Chaim's national headquarters in located in Baltimore, Maryland, with other locations in Owings Mills, Maryland, Philadelphia, Pennsylvania, and Washington, D.C.\n\n"}
{"id": "11408", "url": "https://en.wikipedia.org/wiki?curid=11408", "title": "Female genital mutilation", "text": "Female genital mutilation\n\nFemale genital mutilation (FGM), also known as female genital cutting and female circumcision, is the ritual cutting or removal of some or all of the external female genitalia. The practice is found in Africa, Asia and the Middle East, and within communities from countries in which FGM is common. UNICEF estimated in 2016 that 200 million women living today in 30 countries—27 African countries, Indonesia, Iraqi Kurdistan and Yemen—have undergone the procedures.\n\nTypically carried out by a traditional circumciser using a blade, FGM is conducted from days after birth to puberty and beyond. In half the countries for which national figures are available, most girls are cut before the age of five. Procedures differ according to the country or ethnic group. They include removal of the clitoral hood and clitoral glans; removal of the inner labia; and removal of the inner and outer labia and closure of the vulva. In this last procedure, known as infibulation, a small hole is left for the passage of urine and menstrual fluid; the vagina is opened for intercourse and opened further for childbirth.\n\nThe practice is rooted in gender inequality, attempts to control women's sexuality, and ideas about purity, modesty and beauty. It is usually initiated and carried out by women, who see it as a source of honour and fear that failing to have their daughters and granddaughters cut will expose the girls to social exclusion. Adverse health effects depend on the type of procedure; they can include recurrent infections, difficulty urinating and passing menstrual flow, chronic pain, the development of cysts, an inability to get pregnant, complications during childbirth, and fatal bleeding. There are no known health benefits.\n\nThere have been international efforts since the 1970s to persuade practitioners to abandon FGM, and it has been outlawed or restricted in most of the countries in which it occurs, although the laws are poorly enforced. Since 2010 the United Nations has called upon healthcare providers to stop performing all forms of the procedure, including reinfibulation after childbirth and symbolic \"nicking\" of the clitoral hood. The opposition to the practice is not without its critics, particularly among anthropologists, who have raised difficult questions about cultural relativism and the universality of human rights.\n\nUntil the 1980s FGM was widely known in English as female circumcision, implying an equivalence in severity with male circumcision. From 1929 the Kenya Missionary Council referred to it as the sexual mutilation of women, following the lead of Marion Scott Stevenson, a Church of Scotland missionary. References to the practice as mutilation increased throughout the 1970s. In 1975 Rose Oldfield Hayes, an American anthropologist, used the term \"female genital mutilation\" in the title of a paper in \"American Ethnologist\", and four years later Fran Hosken, an Austrian-American feminist writer, called it mutilation in her influential \"The Hosken Report: Genital and Sexual Mutilation of Females\". The Inter-African Committee on Traditional Practices Affecting the Health of Women and Children began referring to it as female genital mutilation in 1990, and the World Health Organization (WHO) followed suit in 1991. Other English terms include \"female genital cutting\" (FGC) and \"female genital mutilation/cutting\" (FGM/C), preferred by those who work with practitioners.\n\nIn countries where FGM is common, the practice's many variants are reflected in dozens of terms, often alluding to purification. In the Bambara language, spoken mostly in Mali, it is known as \"bolokoli\" (\"washing your hands\") and in the Igbo language in eastern Nigeria as \"isa aru\" or \"iwu aru\" (\"having your bath\"). A common Arabic term for purification has the root \"t-h-r\", used for male and female circumcision (\"tahur\" and \"tahara\"). It is also known in Arabic as \"khafḍ\" or \"khifaḍ\". Communities may refer to FGM as \"pharaonic\" for infibulation and \"sunna\" circumcision for everything else. \"Sunna\" means \"path or way\" in Arabic and refers to the tradition of Muhammad, although none of the procedures are required within Islam. The term \"infibulation\" derives from \"fibula\", Latin for clasp; the Ancient Romans reportedly fastened clasps through the foreskins or labia of slaves to prevent sexual intercourse. The surgical infibulation of women came to be known as pharaonic circumcision in Sudan, and as Sudanese circumcision in Egypt. In Somalia it is known simply as \"qodob\" (\"to sew up\").\n\nThe procedures are generally performed by a traditional circumciser (cutter or \"exciseuse\") in the girls' homes, with or without anaesthesia. The cutter is usually an older woman, but in communities where the male barber has assumed the role of health worker he will perform FGM too. When traditional cutters are involved, non-sterile devices are likely to be used, including knives, razors, scissors, glass, sharpened rocks and fingernails. According to a nurse in Uganda, quoted in 2007 in \"The Lancet\", a cutter would use one knife on up to 30 girls at a time. Health professionals are often involved in Egypt, Kenya, Indonesia and Sudan; in Egypt 77 percent of FGM procedures, and in Indonesia over 50 percent, were performed by medical professionals as of 2008 and 2016. Women in Egypt reported in 1995 that a local anaesthetic had been used on their daughters in 60 percent of cases, a general anaesthetic in 13 percent, and neither in 25 percent (two percent were missing/don't know).\n\nThe WHO, UNICEF and UNFPA issued a joint statement in 1997 defining FGM as \"all procedures involving partial or total removal of the external female genitalia or other injury to the female genital organs whether for cultural or other non-therapeutic reasons\". The procedures vary considerably according to ethnicity and individual practitioners. During a 1998 survey in Niger, women responded with over 50 different terms when asked what was done to them. Translation problems are compounded by the women's confusion over which type of FGM they experienced, or even whether they experienced it. Several studies have suggested that survey responses are unreliable. A 2003 study in Ghana found that in 1995 four percent said they had not undergone FGM, but in 2000 said they had, while 11 percent switched in the other direction. In Tanzania in 2005, 66 percent reported FGM, but a medical exam found that 73 percent had undergone it. In Sudan in 2006, a significant percentage of infibulated women and girls reported a less severe type.\n\nStandard questionnaires from United Nations bodies ask women whether they or their daughters have undergone the following: (1) cut, no flesh removed (symbolic nicking); (2) cut, some flesh removed; (3) sewn closed; or (4) type not determined/unsure/doesn't know. The most common procedures fall within the \"cut, some flesh removed\" category and involve complete or partial removal of the clitoral glans. The World Health Organization (a UN agency) created a more detailed typology: Types I–III vary in how much tissue is removed; Type III is equivalent to the UNICEF category \"sewn closed\"; and Type IV describes miscellaneous procedures, including symbolic nicking.\nType I is \"partial or total removal of the clitoris and/or the prepuce\". Type Ia involves removal of the clitoral hood only. This is rarely performed alone. The more common procedure is Type Ib (clitoridectomy), the complete or partial removal of the clitoral glans (the visible tip of the clitoris) and clitoral hood. The circumciser pulls the clitoral glans with her thumb and index finger and cuts it off.\n\nType II (excision) is the complete or partial removal of the inner labia, with or without removal of the clitoral glans and outer labia. Type IIa is removal of the inner labia; Type IIb, removal of the clitoral glans and inner labia; and Type IIc, removal of the clitoral glans, inner and outer labia. \"Excision\" in French can refer to any form of FGM.\n\nType III (infibulation or pharaonic circumcision), the \"sewn closed\" category, involves the removal of the external genitalia and fusion of the wound. The inner and/or outer labia are cut away, with or without removal of the clitoral glans. Type III is found largely in northeast Africa, particularly Djibouti, Eritrea, Ethiopia, Somalia, and Sudan (although not in South Sudan). According to one 2008 estimate, over eight million women in Africa are living with Type III FGM. According to UNFPA in 2010, 20 percent of women with FGM have been infibulated. In Somalia \"[t]he child is made to squat on a stool or mat facing the circumciser at a height that offers her a good view of the parts to be handled. ... adult helpers grab and pull apart the legs of the girl. ... If available, this is the stage at which a local anaesthetic would be used\":\n\nThe element of speed and surprise is vital and the circumciser immediately grabs the clitoris by pinching it between her nails aiming to amputate it with a slash. The organ is then shown to the senior female relatives of the child who will decide whether the amount that has been removed is satisfactory or whether more is to be cut off.\n\nAfter the clitoris has been satisfactorily amputated ... the circumciser can proceed with the total removal of the labia minora and the paring of the inner walls of the labia majora. Since the entire skin on the inner walls of the labia majora has to be removed all the way down to the perineum, this becomes a messy business. By now, the child is screaming, struggling, and bleeding profusely, which makes it difficult for the circumciser to hold with bare fingers and nails the slippery skin and parts that are to be cut or sutured together. ...\n\nHaving ensured that sufficient tissue has been removed to allow the desired fusion of the skin, the circumciser pulls together the opposite sides of the labia majora, ensuring that the raw edges where the skin has been removed are well approximated. The wound is now ready to be stitched or for thorns to be applied. If a needle and thread are being used, close tight sutures will be placed to ensure that a flap of skin covers the vulva and extends from the mons veneris to the perineum, and which, after the wound heals, will form a bridge of scar tissue that will totally occlude the vaginal introitus.\nThe amputated parts might be placed in a pouch for the girl to wear. A single hole of 2–3 mm is left for the passage of urine and menstrual fluid. The vulva is closed with surgical thread, or agave or acacia thorns, and might be covered with a poultice of raw egg, herbs and sugar. To help the tissue bond, the girl's legs are tied together, often from hip to ankle; the bindings are usually loosened after a week and removed after two to six weeks. If the remaining hole is too large in the view of the girl's family, the procedure is repeated.\n\nThe vagina is opened for sexual intercourse, for the first time either by a midwife with a knife or by the woman's husband with his penis. In some areas, including Somaliland, female relatives of the bride and groom might watch the opening of the vagina to check that the girl is a virgin. The woman is opened further for childbirth (\"defibulation\" or \"deinfibulation\"), and closed again afterwards (\"reinfibulation\"). Reinfibulation can involve cutting the vagina again to restore the pinhole size of the first infibulation. This might be performed before marriage, and after childbirth, divorce and widowhood. Hanny Lightfoot-Klein interviewed hundreds of women and men in Sudan in the 1980s about sexual intercourse with Type III:\n\nThe penetration of the bride's infibulation takes anywhere from 3 or 4 days to several months. Some men are unable to penetrate their wives at all (in my study over 15%), and the task is often accomplished by a midwife under conditions of great secrecy, since this reflects negatively on the man's potency. Some who are unable to penetrate their wives manage to get them pregnant in spite of the infibulation, and the woman's vaginal passage is then cut open to allow birth to take place. ... Those men who do manage to penetrate their wives do so often, or perhaps always, with the help of the \"little knife\". This creates a tear which they gradually rip more and more until the opening is sufficient to admit the penis.\n\nType IV is \"[a]ll other harmful procedures to the female genitalia for non-medical purposes\", including pricking, piercing, incising, scraping and cauterization. It includes nicking of the clitoris (symbolic circumcision), burning or scarring the genitals, and introducing substances into the vagina to tighten it. Labia stretching is also categorized as Type IV. Common in southern and eastern Africa, the practice is supposed to enhance sexual pleasure for the man and add to the sense of a woman as a closed space. From the age of eight, girls are encouraged to stretch their inner labia using sticks and massage. Girls in Uganda are told they may have difficulty giving birth without stretched labia.\n\nA definition of FGM from the WHO in 1995 included gishiri cutting and angurya cutting, found in Nigeria and Niger. These were removed from the WHO's 2008 definition because of insufficient information about prevalence and consequences. Angurya cutting is excision of the hymen, usually performed seven days after birth. Gishiri cutting involves cutting the vagina's front or back wall with a blade or penknife, performed in response to infertility, obstructed labour and other conditions. In a study by Nigerian physician Mairo Usman Mandara, over 30 percent of women with gishiri cuts were found to have vesicovaginal fistulae (holes that allow urine to seep into the vagina).\n\nFGM harms women's physical and emotional health throughout their lives. It has no known health benefits. The short-term and late complications depend on the type of FGM, whether the practitioner has had medical training, and whether they used antibiotics and sterilized or single-use surgical instruments. In the case of Type III, other factors include how small a hole was left for the passage of urine and menstrual blood, whether surgical thread was used instead of agave or acacia thorns, and whether the procedure was performed more than once (for example, to close an opening regarded as too wide or re-open one too small).\nCommon short-term complications include swelling, excessive bleeding, pain, urine retention, and healing problems/wound infection. A 2014 systematic review of 56 studies suggested that over one in ten girls and women undergoing any form of FGM, including symbolic nicking of the clitoris (Type IV), experience immediate complications, although the risks increased with Type III. The review also suggested that there was under-reporting. Other short-term complications include fatal bleeding, anaemia, urinary infection, septicaemia, tetanus, gangrene, necrotizing fasciitis (flesh-eating disease), and endometritis. It is not known how many girls and women die as a result of the practice, because complications may not be recognized or reported. The practitioners' use of shared instruments is thought to aid the transmission of hepatitis B, hepatitis C and HIV, although no epidemiological studies have shown this.\n\nLate complications vary depending on the type of FGM. They include the formation of scars and keloids that lead to strictures and obstruction, epidermoid cysts that may become infected, and neuroma formation (growth of nerve tissue) involving nerves that supplied the clitoris. An infibulated girl may be left with an opening as small as 2–3 mm, which can cause prolonged, drop-by-drop urination, pain while urinating, and a feeling of needing to urinate all the time. Urine may collect underneath the scar, leaving the area under the skin constantly wet, which can lead to infection and the formation of small stones. The opening is larger in women who are sexually active or have given birth by vaginal delivery, but the urethra opening may still be obstructed by scar tissue. Vesicovaginal or rectovaginal fistulae can develop (holes that allow urine or faeces to seep into the vagina). This and other damage to the urethra and bladder can lead to infections and incontinence, pain during sexual intercourse and infertility. Painful periods are common because of the obstruction to the menstrual flow, and blood can stagnate in the vagina and uterus. Complete obstruction of the vagina can result in hematocolpos and hematometra (where the vagina and uterus fill with menstrual blood). The swelling of the abdomen that results from the collection of fluid, together with the lack of menstruation, can lead to suspicion of pregnancy; Asma El Dareer, a Sudanese physician, reported in 1979 that a girl in Sudan with this condition was killed by her family.\n\nFGM may place women at higher risk of problems during pregnancy and childbirth, which are more common with the more extensive FGM procedures. Infibulated women may try to make childbirth easier by eating less during pregnancy to reduce the baby's size. In women with vesicovaginal or rectovaginal fistulae, it is difficult to obtain clear urine samples as part of prenatal care, making the diagnosis of conditions such as pre-eclampsia harder. Cervical evaluation during labour may be impeded and labour prolonged or obstructed. Third-degree laceration (tears), anal-sphincter damage and emergency caesarean section are more common in infibulated women.\n\nNeonatal mortality is increased. The WHO estimated in 2006 that an additional 10–20 babies die per 1,000 deliveries as a result of FGM. The estimate was based on a study conducted on 28,393 women attending delivery wards at 28 obstetric centres in Burkina Faso, Ghana, Kenya, Nigeria, Senegal and Sudan. In those settings all types of FGM were found to pose an increased risk of death to the baby: 15 percent higher for Type I, 32 percent for Type II, and 55 percent for Type III. The reasons for this were unclear, but may be connected to genital and urinary tract infections and the presence of scar tissue. According to the study, FGM was associated with an increased risk to the mother of damage to the perineum and excessive blood loss, as well as a need to resuscitate the baby, and stillbirth, perhaps because of a long .\n\nAccording to a 2015 systematic review there is little high-quality information available on the psychological effects of FGM. Several small studies have concluded that women with FGM suffer from anxiety, depression and post-traumatic stress disorder. Feelings of shame and betrayal can develop when women leave the culture that practises FGM and learn that their condition is not the norm, but within the practising culture they may view their FGM with pride, because for them it signifies beauty, respect for tradition, chastity and hygiene. Studies on sexual function have also been small. A 2013 meta-analysis of 15 studies involving 12,671 women from seven countries concluded that women with FGM were twice as likely to report no sexual desire and 52 percent more likely to report dyspareunia (painful sexual intercourse). One third reported reduced sexual feelings.\n\nAid agencies define the prevalence of FGM as the percentage of the 15–49 age group that has experienced it. These figures are based on nationally representative household surveys known as Demographic and Health Surveys (DHS), developed by Macro International and funded mainly by the United States Agency for International Development (USAID); and Multiple Indicator Cluster Surveys (MICS) conducted with financial and technical help from UNICEF. These surveys have been carried out in Africa, Asia, Latin America and elsewhere roughly every five years, since 1984 and 1995 respectively. The first to ask about FGM was the 1989–1990 DHS in northern Sudan. The first publication to estimate FGM prevalence based on DHS data (in seven countries) was written by Dara Carr of Macro International in 1997.\n\nQuestions the women are asked during the surveys include: \"Was the genital area just nicked/cut without removing any flesh? Was any flesh (or something) removed from the genital area? Was your genital area sewn?\" Most women report \"cut, some flesh removed\" (Types I and II).\n\nType I is the most common form in Egypt, and in the southern parts of Nigeria. Type III (infibulation) is concentrated in northeastern Africa, particularly Djibouti, Eritrea, Somalia and Sudan. In surveys in 2002–2006, 30 percent of cut girls in Djibouti, 38 percent in Eritrea, and 63 percent in Somalia had experienced Type III. There is also a high prevalence of infibulation among girls in Niger and Senegal, and in 2013 it was estimated that in Nigeria three percent of the 0–14 age group had been infibulated. The type of procedure is often linked to ethnicity. In Eritrea, for example, a survey in 2002 found that all Hedareb girls had been infibulated, compared with two percent of the Tigrinya, most of whom fell into the \"cut, no flesh removed\" category.\n\nFGM is mostly found in what Gerry Mackie called an \"intriguingly contiguous\" zone in Africa—east to west from Somalia to Senegal, and north to south from Egypt to Tanzania. Nationally representative figures are available for 27 countries in Africa, as well as Indonesia, Iraqi Kurdistan and Yemen. Over 200 million women and girls are thought to be living with FGM in those 30 countries.\n\nThe highest concentrations among the 15–49 age group are in Somalia (98 percent), Guinea (97 percent), Djibouti (93 percent), Egypt (91 percent) and Sierra Leone (90 percent). As of 2013, 27.2 million women had undergone FGM in Egypt, 23.8 million in Ethiopia, and 19.9 million in Nigeria. There is a high concentration in Indonesia, where according to UNICEF Type I (clitoridectomy) and Type IV (symbolic nicking) are practised; the Indonesian Ministry of Health and Indonesian Ulema Council both say the clitoris should not be cut. The prevalence rate for the 0–11 group in Indonesia is 49 percent (13.4 million). Smaller studies or anecdotal reports suggest that FGM is also practised in Colombia, Jordan, Oman, Saudi Arabia and parts of Malaysia; in the United Arab Emirates; and in India by the Dawoodi Bohra. It is found within immigrant communities around the world.\n\nPrevalence figures for the 15–19 age group and younger show a downward trend. For example, Burkina Faso fell from 89 percent (1980) to 58 percent (2010); Egypt from 97 percent (1985) to 70 percent (2015); and Kenya from 41 percent (1984) to 11 percent (2014). Beginning in 2010, household surveys asked women about the FGM status of all their living daughters. The highest concentrations among girls aged 0–14 were in Gambia (56 percent), Mauritania (54 percent), Indonesia (49 percent for 0–11) and Guinea (46 percent). The figures suggest that a girl was one third less likely in 2014 to undergo FGM than she was 30 years ago. If the rate of decline continues, the number of girls cut will nevertheless rise, because of population growth, from 3.6 million a year in 2013 to 4.1 million in 2050.\n\nAccording to a 2018 study published in the British Medical Journal there has been a large decline in number of FGM cases among the 0-14 year old in Africa in the 1990-2017 period.\n\nSurveys have found FGM to be more common in rural areas, less common in most countries among girls from the wealthiest homes, and (except in Sudan and Somalia) less common in girls whose mothers had access to primary or secondary/higher education. In Somalia and Sudan the situation was reversed: in Somalia the mothers' access to secondary/higher education was accompanied by a rise in prevalence of FGM in their daughters, and in Sudan access to any education was accompanied by a rise.\n\nFGM is not invariably a rite of passage between childhood and adulthood, but is often performed on much younger children. Girls are most commonly cut shortly after birth to age 15. In half the countries for which national figures were available in 2000–2010, most girls had been cut by age five. Over 80 percent (of those cut) are cut before the age of five in Nigeria, Mali, Eritrea, Ghana and Mauritania. The 1997 Demographic and Health Survey in Yemen found that 76 percent of girls had been cut within two weeks of birth. The percentage is reversed in Somalia, Egypt, Chad and the Central African Republic, where over 80 percent (of those cut) are cut between five and 14. Just as the type of FGM is often linked to ethnicity, so is the mean age. In Kenya, for example, the Kisi cut around age 10 and the Kamba at 16.\n\nA country's national prevalence often reflects a high sub-national prevalence among certain ethnicities, rather than a widespread practice. In Iraq, for example, FGM is found mostly among the Kurds in Erbil (58 percent prevalence within age group 15–49, as of 2011), Sulaymaniyah (54 percent) and Kirkuk (20 percent), giving the country a national prevalence of eight percent. The practice is sometimes an ethnic marker, but it may differ along national lines. For example, in the northeastern regions of Ethiopia and Kenya, which share a border with Somalia, the Somali people practise FGM at around the same rate as they do in Somalia. But in Guinea all Fulani women responding to a survey in 2012 said they had experienced FGM, against 12 percent of the Fulani in Chad, while in Nigeria the Fulani are the only large ethnic group in the country not to practise it.\n\nDahabo Musa, a Somali woman, described infibulation in a 1988 poem as the \"three feminine sorrows\": the procedure itself, the wedding night when the woman is cut open, then childbirth when she is cut again. Despite the evident suffering, it is women who organize all forms of FGM. Anthropologist Rose Oldfield Hayes wrote in 1975 that educated Sudanese men who did not want their daughters to be infibulated (preferring clitoridectomy) would find the girls had been sewn up after the grandmothers arranged a visit to relatives. Gerry Mackie has compared the practice to footbinding. Like FGM, footbinding was carried out on young girls, nearly universal where practised, tied to ideas about honour, chastity and appropriate marriage, and \"supported and transmitted\" by women.\nFGM practitioners see the procedures as marking not only ethnic boundaries but also gender difference. According to this view, male circumcision defeminizes men while FGM demasculinizes women. Fuambai Ahmadu, an anthropologist and member of the Kono people of Sierra Leone, who in 1992 underwent clitoridectomy as an adult during a Sande society initiation, argued in 2000 that it is a male-centred assumption that the clitoris is important to female sexuality. African female symbolism revolves instead around the concept of the womb. Infibulation draws on that idea of enclosure and fertility. \"[G]enital cutting completes the social definition of a child's sex by eliminating external traces of androgyny,\" Janice Boddy wrote in 2007. \"The female body is then covered, closed, and its productive blood bound within; the male body is unveiled, opened and exposed.\"\n\nIn communities where infibulation is common, there is a preference for women's genitals to be smooth, dry and without odour, and both women and men may find the natural vulva repulsive. Some men seem to enjoy the effort of penetrating an infibulation. The local preference for dry sex causes women to introduce substances into the vagina to reduce lubrication, including leaves, tree bark, toothpaste and Vicks menthol rub. The WHO includes this practice within Type IV FGM, because the added friction during intercourse can cause lacerations and increase the risk of infection. Because of the smooth appearance of an infibulated vulva, there is also a belief that infibulation increases hygiene.\n\nCommon reasons for FGM cited by women in surveys are social acceptance, religion, hygiene, preservation of virginity, marriageability and enhancement of male sexual pleasure. In a study in northern Sudan, published in 1983, only 17.4 percent of women opposed FGM (558 out of 3,210), and most preferred excision and infibulation over clitoridectomy. Attitudes are changing slowly. In Sudan in 2010, 42 percent of women who had heard of FGM said the practice should continue. In several surveys since 2006, over 50 percent of women in Mali, Guinea, Sierra Leone, Somalia, Gambia and Egypt supported FGM's continuance, while elsewhere in Africa, Iraq and Yemen most said it should end, although in several countries only by a narrow margin.\n\nAgainst the argument that women willingly choose FGM for their daughters, UNICEF calls the practice a \"self-enforcing social convention\" to which families feel they must conform to avoid uncut daughters facing social exclusion. Ellen Gruenbaum reported that, in Sudan in the 1970s, cut girls from an Arab ethnic group would mock uncut Zabarma girls with \"Ya, Ghalfa!\" (\"Hey, unclean!\"). The Zabarma girls would respond \"Ya, mutmura!\" (A \"mutmara\" was a storage pit for grain that was continually opened and closed, like an infibulated woman.) But despite throwing the insult back, the Zabarma girls would ask their mothers, \"What's the matter? Don't we have razor blades like the Arabs?\"\n\nBecause of poor access to information, and because circumcisers downplay the causal connection, women may not associate the health consequences with the procedure. Lala Baldé, president of a women's association in Medina Cherif, a village in Senegal, told Mackie in 1998 that when girls fell ill or died, it was attributed to evil spirits. When informed of the causal relationship between FGM and ill health, Mackie wrote, the women broke down and wept. He argued that surveys taken before and after this sharing of information would show very different levels of support for FGM. The American non-profit group Tostan, founded by Molly Melching in 1991, introduced community-empowerment programs in several countries that focus on local democracy, literacy, and education about healthcare, giving women the tools to make their own decisions. In 1997, using the Tostan program, Malicounda Bambara in Senegal became the first village to abandon FGM. By 2018 over 8,000 communities in eight countries had pledged to abandon FGM and child marriage.\n\nSurveys have shown a widespread belief, particularly in Mali, Mauritania, Guinea and Egypt, that FGM is a religious requirement. Gruenbaum has argued that practitioners may not distinguish between religion, tradition and chastity, making it difficult to interpret the data. FGM's origins in northeastern Africa are pre-Islamic, but the practice became associated with Islam because of that religion's focus on female chastity and seclusion. There is no mention of it in the Quran. It is praised in a few \"daʻīf\" (weak) \"hadith\" (sayings attributed to Muhammad) as noble but not required, although it is regarded as obligatory by the Shafi'i version of Sunni Islam. In 2007 the Al-Azhar Supreme Council of Islamic Research in Cairo ruled that FGM had \"no basis in core Islamic law or any of its partial provisions\".\n\nThere is no mention of FGM in the Bible. Christian missionaries in Africa were among the first to object to FGM, but Christian communities in Africa do practise it. A 2013 UNICEF report identified 17 African countries in which at least 10 percent of Christian women and girls aged 15 to 49 had undergone FGM; in Niger 55 percent of Christian women and girls had experienced it, compared with two percent of their Muslim counterparts. The only Jewish group known to have practised it are the Beta Israel of Ethiopia. Judaism requires male circumcision, but does not allow FGM. FGM is also practised by animist groups, particularly in Guinea and Mali.\nThe practice's origins are unknown. Gerry Mackie has suggested that, because FGM's east-west, north-south distribution in Africa meets in Sudan, infibulation may have begun there with the Meroite civilization (c. 800 BCE – c. 350 CE), before the rise of Islam, to increase confidence in paternity. According to historian Mary Knight, Spell 1117 (c. 1991–1786 BCE) of the Ancient Egyptian Coffin Texts may refer in hieroglyphs to an uncircumcised girl (\"'m't\"):\n\na-m-a:X1-D53-B1\n\nThe spell was found on the sarcophagus of Sit-hedjhotep, now in the Egyptian Museum, and dates to Egypt's Middle Kingdom. (Paul F. O'Rourke argues that \"'m't\" probably refers instead to a menstruating woman.) The proposed circumcision of an Egyptian girl, Tathemis, is also mentioned on a Greek papyrus, from 163 BCE, in the British Museum: \"Sometime after this, Nephoris [Tathemis's mother] defrauded me, being anxious that it was time for Tathemis to be circumcised, as is the custom among the Egyptians.\"\n\nThe examination of mummies has shown no evidence of FGM. Citing the Australian pathologist Grafton Elliot Smith, who examined hundreds of mummies in the early 20th century, Knight writes that the genital area may resemble Type III because during mummification the skin of the outer labia was pulled toward the anus to cover the pudendal cleft, possibly to prevent sexual violation. It was similarly not possible to determine whether Types I or II had been performed, because soft tissues had deteriorated or been removed by the embalmers.\n\nThe Greek geographer Strabo (c. 64 BCE – c. 23 CE) wrote about FGM after visiting Egypt around 25 BCE: \"This is one of the customs most zealously pursued by them [the Egyptians]: to raise every child that is born and to circumcise [\"peritemnein\"] the males and excise [\"ektemnein\"] the females ...\" Philo of Alexandria (c. 20 BCE – 50 CE) also made reference to it: \"the Egyptians by the custom of their country circumcise the marriageable youth and maid in the fourteenth (year) of their age, when the male begins to get seed, and the female to have a menstrual flow.\" It is mentioned briefly in a work attributed to the Greek physician Galen (129 – c. 200 CE): \"When [the clitoris] sticks out to a great extent in their young women, Egyptians consider it appropriate to cut it out.\" Another Greek physician, Aëtius of Amida (mid-5th to mid-6th century CE), offered more detail in book 16 of his \"Sixteen Books on Medicine\", citing the physician Philomenes. The procedure was performed in case the clitoris, or \"nymphê\", grew too large or triggered sexual desire when rubbing against clothing. \"On this account, it seemed proper to the Egyptians to remove it before it became greatly enlarged,\" Aëtius wrote, \"especially at that time when the girls were about to be married\":\n\nThe surgery is performed in this way: Have the girl sit on a chair while a muscled young man standing behind her places his arms below the girl's thighs. Have him separate and steady her legs and whole body. Standing in front and taking hold of the clitoris with a broad-mouthed forceps in his left hand, the surgeon stretches it outward, while with the right hand, he cuts it off at the point next to the pincers of the forceps.\n\nIt is proper to let a length remain from that cut off, about the size of the membrane that's between the nostrils, so as to take away the excess material only; as I have said, the part to be removed is at that point just above the pincers of the forceps. Because the clitoris is a skinlike structure and stretches out excessively, do not cut off too much, as a urinary fistula may result from cutting such large growths too deeply.\n\nThe genital area was then cleaned with a sponge, frankincense powder and wine or cold water, and wrapped in linen bandages dipped in vinegar, until the seventh day when calamine, rose petals, date pits or a \"genital powder made from baked clay\" might be applied.\n\nWhatever the practice's origins, infibulation became linked to slavery. Mackie cites the Portuguese missionary João dos Santos, who in 1609 wrote of a group near Mogadishu who had a \"custome to sew up their Females, especially their slaves being young to make them unable for conception, which makes these slaves sell dearer, both for their chastitie, and for better confidence which their Masters put in them\". Thus, Mackie argues, a \"practice associated with shameful female slavery came to stand for honor\".\n\nGynaecologists in 19th-century Europe and the United States removed the clitoris to treat insanity and masturbation. A British doctor, Robert Thomas, suggested clitoridectomy as a cure for nymphomania in 1813.\nThe first reported clitoridectomy in the West, described in \"The Lancet\" in 1825, was performed in 1822 in Berlin by Karl Ferdinand von Graefe on a 15-year-old girl who was masturbating excessively.\n\nIsaac Baker Brown, an English gynaecologist, president of the Medical Society of London and co-founder in 1845 of St. Mary's Hospital, believed that masturbation, or \"unnatural irritation\" of the clitoris, caused hysteria, spinal irritation, fits, idiocy, mania and death. He therefore \"set to work to remove the clitoris whenever he had the opportunity of doing so\", according to his obituary. Brown performed several clitoridectomies between 1859 and 1866. In the United States, J. Marion Sims followed Brown's work and in 1862 slit the neck of a woman's uterus and amputated her clitoris, \"for the relief of the nervous or hysterical condition as recommended by Baker Brown\". When Brown published his views in \"On the Curability of Certain Forms of Insanity, Epilepsy, Catalepsy, and Hysteria in Females\" (1866), doctors in London accused him of quackery and expelled him from the Obstetrical Society.\n\nLater in the 19th century, A. J. Bloch, a surgeon in New Orleans, removed the clitoris of a two-year-old girl who was reportedly masturbating. According to a 1985 paper in the \"Obstetrical & Gynecological Survey\", clitoridectomy was performed in the United States into the 1960s to treat hysteria, erotomania and lesbianism. From the mid-1950s, James Burt, a gynaecologist in Dayton, Ohio, performed non-standard repairs of episiotomies after childbirth, adding more stitches to make the vaginal opening smaller. From 1966 until 1989, he performed \"love surgery\" by cutting women's pubococcygeus muscle, repositioning the vagina and urethra, and removing the clitoral hood, thereby making their genital area more appropriate, in his view, for intercourse in the missionary position. \"Women are structurally inadequate for intercourse,\" he wrote; he said he would turn them into \"horny little mice\". In the 1960s and 1970s he performed these procedures without consent while repairing episiotomies and performing hysterectomies and other surgery; he said he had performed a variation of them on 4,000 women by 1975. Following complaints, he was required in 1989 to stop practicing medicine in the United States.\n\nProtestant missionaries in British East Africa (present-day Kenya) began campaigning against FGM in the early 20th century, when Dr. John Arthur joined the Church of Scotland Mission (CSM) in Kikuyu. An important ethnic marker, the practice was known by the Kikuyu, the country's main ethnic group, as \"irua\" for both girls and boys. It involved excision (Type II) for girls and removal of the foreskin for boys. Unexcised Kikuyu women (\"irugu\") were outcasts.\n\nJomo Kenyatta, general secretary of the Kikuyu Central Association and later Kenya's first prime minister, wrote in 1938 that, for the Kikuyu, the institution of FGM was the \"\"conditio sine qua non\" of the whole teaching of tribal law, religion and morality\". No proper Kikuyu man or woman would marry or have sexual relations with someone who was not circumcised. A woman's responsibilities toward the tribe began with her initiation. Her age and place within tribal history was traced to that day, and the group of girls with whom she was cut was named according to current events, an oral tradition that allowed the Kikuyu to track people and events going back hundreds of years.\n\nBeginning with the CSM mission in 1925, several missionary churches declared that FGM was prohibited for African Christians. The CSM announced that Africans practising it would be excommunicated, which resulted in hundreds leaving or being expelled. The stand-off turned FGM into a focal point of the Kenyan independence movement; the 1929–1931 period is known in the country's historiography as the female circumcision controversy.\n\nIn 1929 the Kenya Missionary Council began referring to FGM as the \"sexual mutilation of women\", rather than circumcision, and a person's stance toward the practice became a test of loyalty, either to the Christian churches or to the Kikuyu Central Association. Hulda Stumpf, an American missionary with the Africa Inland Mission who opposed FGM in the girls' school she helped to run, was murdered in 1930. Edward Grigg, the governor of Kenya, told the British Colonial Office that the killer, who was never identified, had tried to circumcise her.\n\nIn 1956 the council of male elders (the \"Njuri Nchecke\") in Meru announced a ban on FGM. Over the next three years, thousands of girls cut each other's genitals with razor blades as a symbol of defiance. The movement came to be known as \"Ngaitana\" (\"I will circumcise myself\"), because to avoid naming their friends the girls said they had cut themselves. Historian Lynn Thomas described the episode as significant in the history of FGM because it made clear that its victims were also its perpetrators.\n\nThe first known non-colonial campaign against FGM began in Egypt in the 1920s, when the Egyptian Doctors' Society called for a ban. There was a parallel campaign in Sudan, run by religious leaders and British women. Infibulation was banned there in 1946, but the law was unpopular and barely enforced. The Egyptian government banned infibulation in state-run hospitals in 1959, but allowed partial clitoridectomy if parents requested it. (Egypt banned FGM entirely in 2007.)\n\nIn 1959, the UN asked the WHO to investigate FGM, but the latter responded that it was not a medical matter. Feminists took up the issue throughout the 1970s. The Egyptian physician and feminist Nawal El Saadawi criticized FGM in her book \"Women and Sex\" (1972); the book was banned in Egypt and El Saadawi lost her job as director general of public health. She followed up with a chapter, \"The Circumcision of Girls\", in her book \"The Hidden Face of Eve: Women in the Arab World\" (1980), which described her own clitoridectomy when she was six years old:\n\nI did not know what they had cut off from my body, and I did not try to find out. I just wept, and called out to my mother for help. But the worst shock of all was when I looked around and found her standing by my side. Yes, it was her, I could not be mistaken, in flesh and blood, right in the midst of these strangers, talking to them and smiling at them, as though they had not participated in slaughtering her daughter just a few moments ago.\nIn 1975, Rose Oldfield Hayes, an American social scientist, became the first female academic to publish a detailed account of FGM, aided by her ability to discuss it directly with women in Sudan. Her article in \"American Ethnologist\" called it \"female genital mutilation\", rather than female circumcision, and brought it to wider academic attention. Edna Adan Ismail, who worked at the time for the Somalia Ministry of Health, discussed the health consequences of FGM in 1977 with the Somali Women's Democratic Organization. Two years later Fran Hosken, an Austria-American feminist, published \"The Hosken Report: Genital and Sexual Mutilation of Females\" (1979), the first to offer global figures. She estimated that 110,529,000 women in 20 African countries had experienced FGM. The figures were speculative but consistent with later surveys. Describing FGM as a \"training ground for male violence\", Hosken accused female practitioners of \"participating in the destruction of their own kind\". The language caused a rift between Western and African feminists; African women boycotted a session featuring Hosken during the UN's Mid-Decade Conference on Women in Copenhagen in July 1980.\n\nIn 1979, the WHO held a seminar, \"Traditional Practices Affecting the Health of Women and Children\", in Khartoum, Sudan, and in 1981, also in Khartoum, 150 academics and activists signed a pledge to fight FGM after a workshop held by the Babiker Badri Scientific Association for Women's Studies (BBSAWS), \"Female Circumcision Mutilates and Endangers Women – Combat it!\" Another BBSAWS workshop in 1984 invited the international community to write a joint statement for the United Nations. It recommended that the \"goal of all African women\" should be the eradication of FGM and that, to sever the link between FGM and religion, clitoridectomy should no longer be referred to as \"sunna\".\n\nThe Inter-African Committee on Traditional Practices Affecting the Health of Women and Children, founded in 1984 in Dakar, Senegal, called for an end to the practice, as did the UN's World Conference on Human Rights in Vienna in 1993. The conference listed FGM as a form of violence against women, marking it as a human-rights violation, rather than a medical issue. Throughout the 1990s and 2000s governments in Africa and the Middle East passed legislation banning or restricting FGM. In 2003 the African Union ratified the Maputo Protocol on the rights of women, which supported the elimination of FGM. By 2015 laws restricting FGM had been passed in at least 23 of the 27 African countries in which it is concentrated, although several fell short of a ban.\n\nIn December 1993, the United Nations General Assembly included FGM in resolution 48/104, the Declaration on the Elimination of Violence Against Women, and from 2003 sponsored International Day of Zero Tolerance for Female Genital Mutilation, held every 6 February. UNICEF began in 2003 to promote an evidence-based social norms approach, using ideas from game theory about how communities reach decisions about FGM, and building on the work of Gerry Mackie on the demise of footbinding in China. In 2005 the UNICEF Innocenti Research Centre in Florence published its first report on FGM. UNFPA and UNICEF launched a joint program in Africa in 2007 to reduce FGM by 40 percent within the 0–15 age group and eliminate it from at least one country by 2012, goals that were not met and which they later described as unrealistic. In 2008 several UN bodies recognized FGM as a human-rights violation, and in 2010 the UN called upon healthcare providers to stop carrying out the procedures, including reinfibulation after childbirth and symbolic nicking. In 2012 the General Assembly passed resolution 67/146, \"Intensifying global efforts for the elimination of female genital mutilations\".\n\nImmigration spread the practice to Australia, New Zealand, Europe and North America, all of which outlawed it entirely or restricted it to consenting adults. Sweden outlawed FGM in 1982 with the \"Act Prohibiting the Genital Mutilation of Women\", the first Western country to do so. Several former colonial powers, including Belgium, Britain, France and the Netherlands, introduced new laws or made clear that it was covered by existing legislation. legislation banning FGM had been passed in 33 countries outside Africa and the Middle East.\n\nIn the United States an estimated 513,000 women and girls had experienced FGM or were at risk as of 2012. A Nigerian woman successfully contested deportation in March 1994 on the grounds that her daughters might be cut, and in 1996 Fauziya Kasinga from Togo became the first to be granted asylum to escape FGM. In 1996 the Federal Prohibition of Female Genital Mutilation Act made it illegal to perform FGM on minors for non-medical reasons, and in 2013 the Transport for Female Genital Mutilation Act prohibited transporting a minor out of the country for the purpose of FGM. A federal judge ruled in 2018 that the 1996 Act was unconstitutional, arguing that FGM is a \"local criminal activity\" that should be regulated by states, not by Congress; he made his ruling during a case against members of the Dawoodi Bohra community in Michigan accused of carrying out FGM. Twenty-four states had legislation banning FGM as of 2016. The first FGM conviction in the US was in 2006, when Khalid Adem, who had emigrated from Ethiopia, was sentenced to ten years for aggravated battery and cruelty to children after severing his two-year-old daughter's clitoris with a pair of scissors. The American Academy of Pediatrics opposes all forms of the practice, including pricking the clitoral skin. \n\nCanada recognized FGM as a form of persecution in July 1994, when it granted refugee status to Khadra Hassan Farah, who had fled Somalia to avoid her daughter being cut. In 1997 section 268 of its Criminal Code was amended to ban FGM, except where \"the person is at least eighteen years of age and there is no resulting bodily harm\". there had been no prosecutions. Canadian officials have expressed concern that a few thousand Canadian girls are at risk of \"vacation cutting\", whereby girls are taken overseas to undergo the procedure, but as of 2017 there were no firm figures.\n\nAccording to the European Parliament, 500,000 women in Europe had undergone FGM . France is known for its tough stance against FGM. Up to 30,000 women there were thought to have experienced it as of 1995. According to Colette Gallard, a family-planning counsellor, when FGM was first encountered in France, the reaction was that Westerners ought not to intervene. It took the deaths of two girls in 1982, one of them three months old, for that attitude to change. In 1991 a French court ruled that the Convention Relating to the Status of Refugees offered protection to FGM victims; the decision followed an asylum application from Aminata Diop, who fled an FGM procedure in Mali. The practice is outlawed by several provisions of France's penal code that address bodily harm causing permanent mutilation or torture. All children under six who were born in France undergo medical examinations that include inspection of the genitals, and doctors are obliged to report FGM. The first civil suit was in 1982, and the first criminal prosecution in 1993. In 1999 a woman was given an eight-year sentence for having performed FGM on 48 girls. By 2014 over 100 parents and two practitioners had been prosecuted in over 40 criminal cases.\n\nAround 137,000 women and girls living in England and Wales were born in countries where FGM is practised, as of 2011. Performing FGM on children or adults was outlawed under the Prohibition of Female Circumcision Act 1985. This was replaced by the Female Genital Mutilation Act 2003 and Prohibition of Female Genital Mutilation (Scotland) Act 2005, which added a prohibition on arranging FGM outside the country for British citizens or permanent residents. The United Nations Committee on the Elimination of Discrimination against Women (CEDAW) asked the government in July 2013 to \"ensure the full implementation of its legislation on FGM\". The first charges were brought in 2014 against a physician and another man; the physician had stitched an infibulated woman after opening her for childbirth. Both men were acquitted in 2015.\n\nAnthropologists have accused FGM eradicationists of cultural colonialism, and have been criticized in turn for their moral relativism and failure to defend the idea of universal human rights. According to critics of the eradicationist position, the biological reductionism of the opposition to FGM, and the failure to appreciate FGM's cultural context, serves to \"other\" practitioners and undermine their agency—in particular when parents are referred to as \"mutilators\".\n\nAfricans who object to the tone of FGM opposition risk appearing to defend the practice. The feminist theorist Obioma Nnaemeka, herself strongly opposed to FGM, argued in 2005 that renaming the practice \"female genital mutilation\" had introduced \"a subtext of barbaric African and Muslim cultures and the West's relevance (even indispensability) in purging [it]\". According to Ugandan law professor Sylvia Tamale, the early Western opposition to FGM stemmed from a Judeo-Christian judgment that African sexual and family practices, including not only FGM but also dry sex, polygyny, bride price and levirate marriage, required correction. African feminists \"take strong exception to the imperialist, racist and dehumanising infantilization of African women\", she wrote in 2011. Commentators highlight the voyeurism in the treatment of women's bodies as exhibits. Examples include images of women's vaginas after FGM or girls undergoing the procedure. The 1996 Pulitzer-prize-winning photographs of a 16-year-old Kenyan girl experiencing FGM were published by 12 American newspapers, without her consent either to be photographed or to have the images published.\n\nThe debate has highlighted a tension between anthropology and feminism, with the former's focus on tolerance and the latter's on equal rights for women. According to the anthropologist Christine Walley, a common position within anti-FGM literature has been to present African women as victims of false consciousness participating in their own oppression, a position promoted by feminists in the 1970s and 1980s, including Fran Hosken, Mary Daly and Hanny Lightfoot-Klein. It prompted the French Association of Anthropologists to issue a statement in 1981, at the height of the early debates, that \"a certain feminism resuscitates (today) the moralistic arrogance of yesterday's colonialism\".\n\nNnaemeka argues that the crucial question, broader than FGM, is why the female body is subjected to so much \"abuse and indignity\", including in the West. Several authors have drawn a parallel between FGM and cosmetic procedures. Ronán Conroy of the Royal College of Surgeons in Ireland wrote in 2006 that cosmetic genital procedures were \"driving the advance\" of FGM by encouraging women to see natural variations as defects. Anthropologist Fadwa El Guindi compared FGM to breast enhancement, in which the maternal function of the breast becomes secondary to men's sexual pleasure. Benoîte Groult, the French feminist, made a similar point in 1975, citing FGM and cosmetic surgery as sexist and patriarchal. Against this, the medical anthropologist Carla Obermeyer argued in 1999 that FGM may be conducive to a subject's social well-being in the same way that rhinoplasty and male circumcision are. Despite the 2007 ban in Egypt, Egyptian women wanting FGM for their daughters seek \"amalyet tajmeel\" (cosmetic surgery) to remove what they see as excess genital tissue.\nCosmetic procedures such as labiaplasty and clitoral hood reduction do fall within the WHO's definition of FGM, which aims to avoid loopholes, but the WHO notes that these elective practices are generally not regarded as FGM. Some legislation banning FGM, such as in Canada and the US, covers minors only, but several countries, including Sweden and the UK, have banned it regardless of consent. Sweden, for example, has banned operations \"on the outer female sexual organs with a view to mutilating them or bringing about some other permanent change in them, regardless of whether or not consent has been given for the operation\". Gynaecologist Birgitta Essén and anthropologist Sara Johnsdotter argue that the law seems to distinguish between Western and African genitals, and deems only African women (such as those seeking reinfibulation after childbirth) unfit to make their own decisions.\n\nThe philosopher Martha Nussbaum argues that a key concern with FGM is that it is mostly conducted on children using physical force. The distinction between social pressure and physical force is morally and legally salient, comparable to the distinction between seduction and rape. She argues further that the literacy of women in practising countries is generally poorer than in developed nations, which reduces their ability to make informed choices.\n\nSeveral commentators maintain that children's rights are violated not only by FGM but also by the genital alteration of intersex children, who are born with anomalies that physicians choose to correct. Arguments have been made that non-therapeutic male circumcision, practised by Muslims, Jews and some Christian groups, also violates children's rights. Globally about 30 percent of males over 15 are circumcised; of these, about two-thirds are Muslim. An American Academy of Pediatrics circumcision task force issued a policy statement in 2012 that the health benefits of male circumcision outweigh the risks; they recommended that it be carried out, if it is performed, by \"trained and competent practitioners ... using sterile techniques and effective pain management\". The statement met with protests from a group of 38 doctors in Europe, who accused the task force of \"cultural bias\". At least half the male population of the United States is circumcised, while most men in Europe are not.\n\n\nBooks and book chapters\n\nJournal articles\nUnited Nations reports\n\nPersonal stories\n"}
{"id": "58864450", "url": "https://en.wikipedia.org/wiki?curid=58864450", "title": "Feminism of the 99%", "text": "Feminism of the 99%\n\nFeminism of the 99% (F99) is a contemporary, grassroots, radical feminist movement, which recognises intersectionality and advocates activism for and by all women - including those who have been overlooked by other feminist movements. It was proposed by a collective of prominent American feminists in an appeal published in Viewpoint Magazine in February 2017, and built upon the mobilisation of women seen in the 2017 Women’s March in January. The appeal simultaneously called for an International Women’s Strike on 8 March 2017. It is a successor to the accumulated intellectual legacy of feminist movements such as radical feminism, Marxist feminism, Black feminism and transnational/decolonial feminism, and asserts that gender oppression is not caused by a single factor, sexism. They insist that it is rather a multifaceted product of the intersections of sexism, racism, colonialism and capitalism.\n\nThe demand for a Feminism of the 99% was published in Viewpoint Magazine on the 3@th of February 2017. It was made in response to the mass mobilisation of women seen in the 2017 Women’s March – a worldwide protest on 21 January 2017, protesting the inauguration of Donald Trump as President of the United States and advocating for women’s rights\",\" human rights and policy reform. The authors cite the Argentinian movement Ni Una Menos as their inspiration, as it too is a fourth-wave grassroots movement which aims to address intersectional issues.  Aiming to build on the momentum of the Women’s March, the authors call attention to what they see as the failures of contemporary feminist movements such as lean-in feminism, which they argue have failed the “overwhelming majority” of women who “do not have access to individual self-promotion and advancement and whose conditions of life can be improved only through policies that defend social reproduction, secure reproductive justice, and guarantee labor rights”. They further argue that the conditions of life of women have deteriorated over the last 30 years due to corporate globalisation and capitalist systems, especially those of colour, of working class, of migrant backgrounds or who are unemployed.\n\nF99 criticises other contemporary feminist movements, such as lean-in feminism and corporate feminism, for only serving the privileged top 1% of women. It holds the logic that women are able to succeed in their career as long as they work to serve the benefit of the patriarchy, and that this relies on these women having access to resources and opportunities that most women are unable to access. The authors of the appeal recognise the need for a feminist movement which serves the needs of the many, and calls attention to the women who are overlooked by neoliberal feminism. However, they call for the movement to look beyond just issues of gender, criticising a number of key issues and movements including: racialized gender violence, the failings of neoliberalism, attacks on labour rights and the undervaluing of labour; reproductive injustices; homophobia; transphobia; and xenophobia. The aim of the movement is to contribute to what its creators see as a “a new international feminist movement with an expanded agenda–at once anti-racist, anti-imperialist, anti-heterosexist, and anti-neoliberal”.\n\nAngela Davis is described to be an advocate for the oppressed, she is the author of many books, her most renowned being “Women, Race and Class”. She is identified as an activist, scholar and writer. Born in 1944, in Birmingham Alabama, Davis completed her masters and joined the U.S. Communist Party, during which time she was jailed on charges relating to a prison outbreak. She was a co-chair for the Women’s March in 2017 and is an activist for civil rights and for the state of prisons in the U.S.A. She has openly opposed the \"Million Man March\" and has often spoken against the death penalty.\n\nBarbara Ransby graduated from Columbia University with a bachelor's degree in history in 1984. She earned her master's and Ph.D. at the University of Michigan. She is a long-time political activist and is a professor at the University of Illinois. After writing a biography of civil rights activist Ella Baker, she became the founder of Ella’s Daughters, a group of women who network in Ella Baker’s tradition. Ransby was also a co-convenor for \"The Black Radical Congress\" in 1998. In 2016, Barbara Ransby was elected the president of National Women’s Studies Association.\n\nCinzia Arruza is a Philosophy associate professor at the New York School for Social Research, she also identifies as a feminist and social activist. She is an advocate for feminism of the 99%, where she believes that the movement is a “coordinated actions that respond to the needs of each region, and that in turn allow simultaneous presence in different parts of the world, or from the same city…”.\n\nKeeanga-Yamahtta Taylor is an African-American Academic and an assistant professor for African American Studies at the University of Princeton. She has also authored books for #BlackLivesMatter and “Black Liberation”, in which she is a prominent activist for \"Black Lives Matter\" campaign. In January 2017, she was a speaker at the anti-inauguration of President Donald Trump and has openly voiced her views againstTrump. Keeanga-Yamahtta Taylor has described feminism of the 99% as, “a fight against the idea that women are only part of a male centred society.”\n\nLinda Martin Alcoff is the author of “Visible Identities: Race, Gender, and the Self” (2006) and “The Future of Whiteness” (2015) and professor of Philosophy at the University of New York. She has called for more inclusion of underrepresented groups in philosophy.\n\nNancy Fraser is an American critical theorist who has written extensive critiques of capitalism and how it contributes to feminist theory. She is a well-known feminist, an American philosopher and professor.  She has actively advocated for left-wing feminism and seeks to reverse what she sees as its marginalization in American society.\n\nRasmea Yousef Odeh was a member of the Popular front for the Liberation of Palestine. She is an associate director at the Arab American Action Network in Chicago, Illinois. She has been criminally charged for her involvement of two terrorist bombings in Jerusalem in which one killed 2 students and the other injured 9. Yousef Odeh was a key organiser for the \"A Day Without A Woman\" strike.\n\nTithi Bhattacharya is a prominent Marxist feminist and a professor of South Asian history at Purdue University. She is an advocate for Palestinian rights and the \"Boycott, divestment and sanctions.\" Bhattacharya is an extensive writer on gender in which she has authored the book \"The Sentinels of Culture.\" She has also written on the politics of Islamophobia and the women in Islam.\n\nFeminism of the 99% has ideological groundings consistent with different but distinct feminist groups. Best understood as a rejection of a perceived failure of mainstream liberal feminism, Feminism of the 99% seeks to combine the positions of anti-racism, anti-sexism, and anti-neoliberalism. In doing so Feminism of the 99% is linked very closely to existing feminist movements globally.\n\nIntersectional feminist thought holds that the lived experience of oppression cannot simply be observed through a single lens of identity: that it’s the combinations of identity expressions, and the kind of experience afforded together that provide a more accurate picture of the hierarchies under which one operates. Intersectionality considers that various forms of social stratification, such as class, race, sexual orientation, age, disability and gender, do not exist separately from each other but are interwoven together. Feminism for the 99% embraces this framework on a fundamental level, and purports that meaningful change must originate from those who experience it firsthand.\n\nBlack feminism is a school of thought stating that sexism, class oppression, gender identity and racism are inextricably bound together. Naturally, this closely aligns with feminism for the 99% given their simultaneous use of intersectionality. A point of difference between the two movement is that feminism for the 99% has a defined strategy for change, taking inspiration from \"Ni Una Menos\".\n\nSocialist feminism is feminism that focuses upon the interconnectivity of the patriarchy and capitalism. Feminism of the 99% frequently parallels with Socialist Feminism given their similar critical assessments of capitalism, and the role of domestic work and social reproduction theory.\n\nAngela Davis, as one of the keystone ideological sources of feminism for the 99%’s ideological perspective holds liberal feminism in contempt for its failure to address the concerns of women perceived to be betrayed by their class position: “If standards for feminism are created for those who have already ascended the economic hierarchies of feminism, how is this relevant to women at the bottom?”. In other words: Davis criticises liberal feminists for acting primarily in the interests of women privileged from race-based and class-based disadvantage.\n\nTithi Bhattacharya, another key signatory of the feminism for the 99% manifesto, has expanded on social reproduction theory within the context of gender, providing a marxist analysis of gender disparate divisions of labor as an integral part of the capitalist mode of production. Specifically, Bhattacharya suggests that the unpaid acts of childbirth, child-rearing, and domestic duties are themselves acts of productive labor, acted within an as exploitative context consistent with marxist labor theory. A key point, is that these acts are disparately the role of women.\n\nIn stark contrast to Liberal Feminism, feminism for the 99% holds that effective and meaningful change comes from a non-reformist perspective: that revolutionary change necessitates a more utopian vision. Feminism for the 99% holds that incremental adjustment of an existing unjust and oppressive hierarchy will never precipitate a just society. To this end, a change from the ground up is required.\n\nThe Feminism of the 99% manifesto specifically cites Ni Una Menos as a source of inspiration for the movement. Specifically, the use of a mass strike of all women as the main form of political activism. On 8 March 2017 (International Women’s Day), activists across the feminist continuum organised the International Women’s Strike (known in the US as  the Day Without Women), and the 2017 Women’s March. The 2017 Women’s Day March was the largest single day protest in US history.\n"}
{"id": "37004368", "url": "https://en.wikipedia.org/wiki?curid=37004368", "title": "FusionCharts", "text": "FusionCharts\n\nFusionCharts, part of InfoSoft Global (P) Ltd, is privately held software provider of data visualization products (JavaScript Charts, Maps, Widgets and Dashboards) with offices in Bangalore and Kolkata, India. FusionCharts has 23,000 customers and 500,000 users in 120 countries, including technology giants such as Apple, Google, ZOHO, Cisco, Facebook, Intel, LinkedIn, Microsoft, Hewlett-Packard, IBM, EMC, Nokia, Tibco, as well as The Weather Channel, NASA, and the Federal Government of the United States.\n\nA 100% bootstrapped company, FusionCharts has earned a 2010-11 revenue of $4.5 million and has clocked revenues of up to $7 million, or Rs 39 crore.\n\nThe idea behind FusionCharts was born in 2001 when 16-year-old Pallav Nadhani found himself dissatisfied with Microsoft Excel's charting capabilities while using the program to complete high school class assignments. Nadhani subsequently authored an article on Wrox Press's ASPToday.com technology website which examined the thesis that Macromedia Flash, then used mainly for web banners and pop-up ad, could be used to build an interactive charting solution for business applications such as dashboards and reports. The article earned him $1,500 and feedback from developers, which together acted as seed money and motivation for establishing the FusionCharts concept.\n\nIn 2002 at 17, Nadhani founded Infosoft Global. The initial product had 6 charts and was built using ActionScript. Nadhani worked alone developing the product, website, documents, sales and marketing and customer support for the first three years. As the company began to take off in 2005, he acquired office space in Bangur and hired 20 employees over the following 2–3 years. The venture grew during this period without raising external funding by bootstrapping.\n\nBy 2009, the company had moved to Salt Lake City, Kolkata, and had grown to over 50 employees. Since arriving in Salt Lake, the staff has expanded by 250 percent of its original size, and in 2011 FusionCharts opened their second office in Bangalore.\n\nFusionCharts' client list, with customers across 118 countries and numerous business sectors, has drawn significant attention to the company. The company was placed squarely on the global platform following its 2010 selection by US President Barack Obama to design the digital dashboards for the federal administration, the Federal IT Dashboard. FusionCharts was the first Indian startup to gain the attention of the Obama administration.\n\nCo-founder Pallav Nadhani is the CEO of FusionCharts and also runs a seed funding venture capital fund named Seeders Inc.\n\nIn 2009, the company was included in the NASSCOM EMERGE 50 Leaders for 2009 due to its success in establishing its data visualization software globally. In the same year it was also awarded the Deloitte Technology Fast50 India award in 2009.\n\nFusionCharts was in 2010 named as one of the 15 companies likely to become the next Infosys.\n\nThe chart-gadget within Google Docs is powered by FusionCharts. Internally, Google employees also employ FusionCharts software for reporting. FusionCharts says that it powers over one billion charts every month globally.\n\nSince its founding in 2003, FusionCharts has put together an almost completely online network of international resellers serving places like Korea, Brazil, China and the United States.\n\nThe company has also made use of search engine optimization and pay per click marketing, and engages users and developers by composing articles, whitepapers, and case studies on the subject of data visualization in various online publications.\n\nFusionCharts also engages in advertising in both online and print developer magazines in key markets such as the US, Europe and Korea. The company is increasing its social media marketing and is emphasizing push–pull marketing strategy.\n\nAnother aspect of marketing is a simple licensing framework as well as a FOSS version of its FusionCharts product that serves over 100,000 users.\n\nFusionCharts is typically targeted to developers who wish to integrate interactive charts in their reports, dashboards, analytics, monitors, and surveys.\n\nPallav Nadhani's original ASPToday.com article called for creating a charting library using Flash, combined with ASP to power it with data. Developers responded positively and shared ideas on how to increase its power and functionality. Subsequently, Pallav coded this idea into a charting application, which led to the birth of the FusionCharts software.\n\nFusionCharts has since transitioned to use JavaScript, SVG and VML to render charts, widgets and maps. This allows its components to be used on all mobile devices and cross-platform browsers. It does allow for optional rendering using Flash. FusionCharts Suite XT can today be used with any web scripting language to deliver interactive and powerful charts. Using XML and JSON as its data interfaces, FusionCharts Suite XT makes full use of HTML 5 technologies to create compact, interactive, and visually-arresting charts.\n\nBritish book publisher Packt UK has released a guidebook aimed at helping new users learn the basics of the FusionCharts Suite XT.\n"}
{"id": "36873359", "url": "https://en.wikipedia.org/wiki?curid=36873359", "title": "Generalized Lagrangian mean", "text": "Generalized Lagrangian mean\n\nIn continuum mechanics, the generalized Lagrangian mean (GLM) is a formalism – developed by – to unambiguously split a motion into a mean part and an oscillatory part. The method gives a mixed Eulerian–Lagrangian description for the flow field, but appointed to fixed Eulerian coordinates.\n\nIn general, it is difficult to decompose a combined wave–mean motion into a mean and a wave part, especially for flows bounded by a wavy surface: e.g. in the presence of surface gravity waves or near another undulating bounding surface (like atmospheric flow over mountainous or hilly terrain). However, this splitting of the motion in a wave and mean part is often demanded in mathematical models, when the main interest is in the mean motion – slowly varying at scales much larger than those of the individual undulations. From a series of postulates, arrive at the (GLM) formalism to split the flow: into a generalised Lagrangian mean flow and an oscillatory-flow part. \n\nThe GLM method does not suffer from the strong drawback of the Lagrangian specification of the flow field – following individual fluid parcels – that Lagrangian positions which are initially close gradually drift far apart. In the Lagrangian frame of reference, it therefore becomes often difficult to attribute Lagrangian-mean values to some location in space.\n\nThe specification of mean properties for the oscillatory part of the flow, like: Stokes drift, wave action, pseudomomentum and pseudoenergy – and the associated conservation laws – arise naturally when using the GLM method.\n\nThe GLM concept can also be incorporated into variational principles of fluid flow.\n\n"}
{"id": "13683508", "url": "https://en.wikipedia.org/wiki?curid=13683508", "title": "Grothendieck construction", "text": "Grothendieck construction\n\nThe Grothendieck construction (named after Alexander Grothendieck) is a construction used in the mathematical field of category theory.\n\nLet formula_1 be a functor from any small category to the category of small categories. The Grothendieck construction for formula_2 is the category formula_3 (also written formula_4, formula_5 or formula_6), with\nComposition of morphisms is defined by formula_16.\n\n\"The Grothendieck construction takes structured, tabulated data and flattens it by throwing it all into one big space. The projection functor is then tasked with remembering which box each datum originally came from.\" \n\nIf formula_17 is a group, then it can be viewed as a category, formula_18 with one object and all morphisms invertible. Let formula_19 be a functor whose value at the sole object of formula_20 is the category formula_21 a category representing the group formula_22 in the same way. The requirement that formula_2 be a functor is then equivalent to specifying a group homomorphism formula_24 where formula_25 denotes the group of automorphisms of formula_26 Finally, the Grothendieck construction, formula_27 results in a category with one object, which can again be viewed as a group, and in this case, the resulting group is (isomorphic to) the semidirect product formula_28\n\n\n"}
{"id": "5868032", "url": "https://en.wikipedia.org/wiki?curid=5868032", "title": "Homaranismo", "text": "Homaranismo\n\nHomaranismo () is a philosophy developed by L. L. Zamenhof. Based largely on the teachings of Hillel the Elder, Zamenhof originally called it Hillelism. He sought to reform Judaism because he hoped that without the strange dress code and purity requirements, it would no longer be the victim of antisemitic propaganda. The basis of Homaranismo is the sentence known as the Golden Rule: \"One should treat others as one would like others to treat oneself\".\n\nZamenhof said about Homaranismo: With Hillelism we don't mean a new denomination; we mean a new corporate-religious order inside the old Jewish religion, which has existed for a long time. Everybody who lives ethically could take part in this religion with a clear conscience, no matter what the religious views he had before looked like.\n\nBased on this idea, he came to the conclusion that this philosophy could be a bridge between religions, not just a subset of Judaism. Zamenhof subsequently renamed his philosophy Homaranismo.\n\nWhile many different motivations drew early Esperantists to that movement, for Zamenhof Esperanto was always a means by which to facilitate improved human relations, especially beyond boundaries of race, language and culture. Zamenhof's daughter Lidia embraced this philosophy and taught it alongside Esperanto and her adopted religion, the Bahá'í Faith.\n\nDespite his entire Esperanto language project, Zamenhof astonishingly said of Homaranismo, \"It is indeed the object of my whole life. I would give up everything for it.\" \n\nZamenhof developed his ideas on Homaranismo in two works: \"Hilelismo\" (1901) and \"Homaranismo\" (1913).\n\n\n"}
{"id": "22216899", "url": "https://en.wikipedia.org/wiki?curid=22216899", "title": "Hyperthymic temperament", "text": "Hyperthymic temperament\n\nHyperthymic temperament, or hyperthymia, from Greek \"hyper\" (\"over\", meaning here \"excessive\") + θυμός (\"spirited\"), is a proposed personality type characterized by an exceptionally positive mood and disposition. It is generally defined by increased energy, vividness and enthusiasm for life activities as opposed to dysthymia. Hyperthymia is similar to but more stable than hypomania with complete absence of irritability or negative mood effects.\n\nCharacteristics of the hyperthymic temperament include:\n\nThe clinical, psychiatric understanding of hyperthymia is evolving. Studies have shown that hyperthymic temperament promotes efficient performance of complex tasks under time pressure or extreme conditions. Despite this positive characterization, hyperthymia can be complicated with depressive episodes manifesting as a softer form of bipolar illness. Research also suggests a familial genetic connection of the temperament to bipolar I.\n\nAside from references in historical and more recent writings on the spectrum of mood disorders, further literature on the temperament is lacking. There is a lack of agreement on its definition, implications or whether it is pathological. It is not known where to place hyperthymia on the affective spectrum.\n\nHyperthymia manifesting intermittently or in an unusual way may mask hypomania or another psychiatric disorder. Hyperthymia can be most accurately diagnosed by a psychologist or psychiatrist with the help of a patient's family and/or close friends.\n\n\n"}
{"id": "4845297", "url": "https://en.wikipedia.org/wiki?curid=4845297", "title": "Infinitism", "text": "Infinitism\n\nInfinitism is the view that knowledge may be justified by an infinite chain of reasons. It belongs to epistemology, the branch of philosophy that considers the possibility, nature, and means of knowledge.\n\nSince Gettier, \"knowledge\" is no longer widely accepted as meaning \"justified true belief\" only. However, some epistemologists still consider knowledge to have a justification condition. Traditional theories of justification (foundationalism and coherentism) and indeed some philosophers consider an infinite regress not to be a valid justification. In their view, if \"A\" is justified by \"B\", \"B\" by \"C\", and so forth, then either \n\nInfinitism, the view, for example, of Peter D. Klein, challenges this consensus, referring back to work of Paul Moser (1984) and John Post (1987). In this view, the evidential ancestry of a justified belief must be infinite and non-repeating, which follows from the conjunction two principles that Klein sees as having straightforward intuitive appeal: \"The Principle of Avoiding Circularity\" and \"The Principle of Avoiding Arbitrariness.\"\n\nThe Principle of Avoiding Circularity (PAC) is stated as follows: \"For all x, if a person, S, has a justification for x, then for all y, if y is in the evidential ancestry of x for S, then x is not in the evidential ancestry of y for S.\" PAC says that the proposition to be justified cannot be a member of its own evidential ancestry, which is violated by coherence theories of justification.\n\nThe Principle of Avoiding Arbitrariness (PAA) is stated as follows: \"For all x, if a person, S, has a justification for x, then there is some reason, r1, available to S for x; and there is some reason, r2, available to S for r1; etc.\" PAA says that in order to avoid arbitrariness, for any proposition \"x\" to be justified for an epistemological agent, there must be some reason \"r\" available to the agent; this reason will in turn require the same structure of justification, and so on \"ad infinitum\". Foundationalist theories can only avoid arbitrariness by claiming that some propositions are self-justified. But if a proposition is its own justification (e.g. coherentism), then it is a member of its own evidential ancestry, and the structure of justification is circular.\n\nIn this view, the conjunction of both PAC and PAA leaves infinitism as the only alternative to skepticism.\n\nThe Availability of Reasons: Klein also relies on the notion of \"availability\". In other words, a reason must be available to the subject in order for it to be a candidate for justification. There are two conditions that need to be satisfied in order for a reason to be available: objectively and subjectively.\n\nAn objectively available reason is stated as follows: \"a belief, r, is objectively available to S as a reason for p if (1) r has some sufficiently high probability and the conditional probability of p given r is sufficiently high; or (2) an impartial, informed observer would accept r as a reason for p; or (3) r would be accepted in the long run by an appropriately defined set of people; or (4) r is evident for S and r makes p evident for S; or (5) r accords with S's deepest epistemic commitments; or (6) r meets the appropriate conversational presuppositions; or (7) an intellectually virtuous person would advance r as a reason for p.\" Any of these conditions are sufficient to describe objectively available reasons and are compatible with infinitism. Klein concedes that, ultimately, the proper characterization of objectively available need be a member of this list, but, for the scope of Klein's defense of infinitism, he need not provide a fully developed account of objectively available reasons. Objective availability could be best understood, at least as a working definition, as an existing, truth-apt reason not dependant on the subject.\n\nA subjectively available reason is stated as follows: \"S must be able to call on r.\" (Subjectively available is comparatively straightforward compared to objectively available.) The subject must be able to evoke the reason in their own mind and use the reason in the process of justification. In essence, the reason must be \"properly hooked up with S's own beliefs\" in order to be subjectively available.\n\nA reason that is both objectively and subjectively available to a subject is a candidate for justification according to infinitism (or, at least for Klein).\n\nObjection to Infinitism: Klein addresses an objection to infinitism.\n\nThe finite mind objection (attributed to John Williams): The human mind is finite and has a limited capacity. \"It is impossible to consciously believe an infinite number of propositions (because to believe something takes some time) and it is impossible to \"unconsciously believe\"...an infinite number of propositions because the candidate beliefs are such that some of them \"defeat human understanding.\" It is simply an impossibility that a subject has an infinite chain of reasons which justify their beliefs because the human mind is finite. Klein concedes that the human mind is finite and cannot contain an infinite number of reasons, but the infinitist, according to Klein, is not committed to a subject actually possessing infinite reasons. \"The infinitist is not claiming that in any finite period of time...we can consciously entertain an infinite number of thoughts. It is rather that there are an infinite number of propositions such that each one of them would be consciously thought were the appropriate circumstances to arise.\" So, an infinite chain of reasons need not be present in the mind in order for a belief to be justified rather it must merely be possible to provide an infinite chain of reasons. There will always be another reason to justify the preceding reason if the subject felt compelled to make the inquiry and had subjective access to that reason.\n\n\n"}
{"id": "14887172", "url": "https://en.wikipedia.org/wiki?curid=14887172", "title": "Inter-African Committee on Traditional Practices Affecting the Health of Women and Children", "text": "Inter-African Committee on Traditional Practices Affecting the Health of Women and Children\n\nThe Inter-African Committee on Traditional Practices Affecting the Health of Women and Children (IAC) is a non-governmental organization (NGO) which seeks to change social values and raise consciousness towards eliminating female genital mutilation (FGM) and other traditional practices which affect the health of women and children in Africa.\n\nThe IAC began at a seminar in Dakar in 1984 with a focus on fighting harmful practices relating to female genital mutilation (FGM), childbirth, nutrition and food, early marriage; and promoting traditional practices considered beneficial, such as breastfeeding and baby massage. Fighting FGM is the main focus of their work. Now based in Addis Ababa, the IAC also has 32 national branches (known as National Committees) in 28 countries in Africa. It has a liaison office in Geneva and 15 affiliates in Europe, Canada, Japan, New Zealand and USA.\n\nIn 1990, the IAC adopted the term \"female genital mutilation\" to describe the procedure previously referred to as \"female circumcision\". According to a 1995 publication, the main focus of their strategy for eliminating FGM is through education.\n\nThe IAC considers that legislative change related to FGM in Burkina Faso, Côte d'Ivoire, Djibouti, Egypt, Ghana, Guinea, Senegal, Tanzania and Togo is a result of the lobbying work carried out by the IAC as well as by other NGOs.\n\n\n"}
{"id": "55931580", "url": "https://en.wikipedia.org/wiki?curid=55931580", "title": "Jane Edward Schilling", "text": "Jane Edward Schilling\n\nJane Edward Schilling (October 8, 1930 – September 13, 2017) was an American activist, historian, and university administrator who served as founding Vice President of Martin University in Indianapolis, Indiana.\n\nBorn Nancy Mary Schilling in 1930 in the lake resort town of Minocqua, Wisconsin, Jane Schilling was the eldest of five children of Lyle Franklin Schilling, a dentist, and wife, Rosalie Julia Wolk Schilling, a homemaker. Early on, Nancy excelled in athletics and scholarship. Finding that her high school did not offer the courses she needed to take in order to become a dentist like her father, she moved to Green Bay, Wisconsin to live with two aunts to attend St. Joseph’s Academy for junior and senior high school. During this period, she found that she had a vocation to follow in the footsteps of her teachers and become a Sister of St. Joseph of Carondolet.\n\nDuring her formation with the Sisters of St. Joseph, she received the name Sister Jane Edward, a combination of her younger sister’s and brother’s names. An avid scholar, she received her bachelor’s degree in European and American History at Fontbonne University in Saint Louis and her Master’s of Ancient History at Loyola University in Chicago. Following her first assignment as a teacher in St. Rita’s School in St. Louis, she was next assigned to St. Matthew’s School in the inner city. Here, she developed a passion for civil rights and social justice. She assisted with curriculum development for students at the Saint Louis hospital for black residents, Homer G. Phillips, and assisted in ministering to ex-convicts at nearby Dismas House, established by Father Charles \"Dismas\" Clark and Morris Shenker.\n\nIn 1964, Schilling's was assigned to teach at Holy Angels Catholic School in Indianapolis, Indiana, a school that had transitioned to a majority black student population. She embraced this role with high energy, establishing a drum and bugle corps to increase school pride and visibility within the community. After she was named principal, she engaged in implementing educational reforms of the time, such as open classrooms, right/left brain teaching, and psychomotor approaches for teaching reading.\n\nShortly after her arrival at Holy Angels, Schilling's life was radically changed when a new Associate Pastor at Holy Angels Parish, Boniface Hardin, arrived on the scene. The two shared a commitment to education and social change, a bond that created a partnership that would last for the remainder of their lives.\n\nWorking together, Schilling and Hardin became activists in church and community reform. They fought police brutality and targeting of black citizens, de facto school segregation, lack of representation of black clergy and traditions within the Catholic Church, poverty, and unfair housing practices. A key focus became the fight to prevent a major highway, Interstate 65, from bifurcating the predominately black northwest neighborhood surrounding Holy Angels Parish.\n\nWhen police pressure on the Archbishop of Indianapolis, Paul Schulte, triggered a decision to remove Hardin from Holy Angels Parish in 1969, parishioners rose up and staged a nationally publicized demonstration in Saints Peter and Paul Cathedral where the Archbishop was presiding at Easter services. Although the Archbishop rescinded his order, Hardin left Holy Angels to found Martin Center, an educational and social justice center, at the close of 1969. Within a year, Schilling received permission from her religious community to work full-time at Martin Center as Education Coordinator.\n\nMartin Center was named for Martin Luther King Jr. and St. Martin de Porres, patron saint, within the Catholic Church, of poor and mixed race people. Its mission evolved from an initial goal of educating clergy and white people about discriminatory attitudes and practices to include celebrating black cultural heritage and engaging black community members in activism and self-identity. While Hardin traveled as a speaker and consultant to raise funds for the Center, Schilling became the day-to-day administrator.\n\nDrawing on her background as a history scholar, Schilling did the research and production of designs and materials for workshops, speeches, and activities of Martin Center. Soon, the mission of the Center expanded to include the Martin Sickle Cell Center, which received major national funding to educate the community and screen for this disease, and the Afro-American Institute, which focused on African and African-American culture and achievements. Schilling served as Director of Community Education at the Sickle Cell Center from 1970 to 1977 and received its award for 25 Years of Dedication to Sickle Cell and Visionary Leadership.\n\nThrough the Afro-American Institute, Martin Center housed a library of materials and artifacts, created and acquired by Schilling and Hardin. They also produced a regular scholarly periodical, the \"Afro-American Journal\" (1973–78); two full-length TV documentaries—\"The Kingdom Builders\" and \"For Love of Freedom\"—for the local NBC affiliate in Indianapolis; a weekly radio program, \"The Afro-American in Indiana\" (1971-1991) for WIAN, the local public radio station; and a weekly television show, \"Afro-American\" (1974–79), for public television. Schilling co-hosted these programs and was the major researcher behind the productions.\n\nAs Martin Center expanded its educational offerings to the community, it collaborated with Indiana University Purdue University-Indianapolis to create courses for college credit. This venture led Schilling and Hardin to found Indiana’s only minority serving institution, Martin University.\n\nFrom the start, Schilling's role in the creation and growth of Martin University was chief academic officer, strategist, and educational developer. As Founding Vice President for Academic Affairs, she was a key voice in articulating the philosophy behind the institution, inspired by the concept of “andragogy” advanced by Malcolm Knowles. The approach emphasized drawing on the strengths and past experience of adult learners, the major population of the university. Through her hiring decisions and curriculum and faculty development efforts, Schilling collaborated with Hardin to become the guiding force behind the school’s educational direction.\n\nSchilling presided over Academic Affairs at Martin University from its early beginnings with a handful of students in 1977 as Martin Center College, through 1979 as Martin College became a separate entity from Martin Center, and finally through 1990, when the addition of graduate programs enabled the change to Martin University, a school with nearly 1000 students. She was the key architect of successful accreditation and expansion proposals to the North Central Association of Colleges and Schools (changed in 2014 to the Higher Learning Commission). She became known at Martin for her sense of humor and the compassion she showed students through acts such as serving soup to those who came directly from work to classes.\n\nWhile Vice President of Martin University, Schilling participated in numerous initiatives within the Indianapolis community, including serving on the Crispus Attucks Museum Committee and acting as consultant and workshop facilitator for the Indianapolis Public Schools. She continued to guide the Martin Center, serving as its Executive Director from 1984 to 1988.\n\nSchilling received a number of Martin University Awards. These included the Mary McLeod Bethune Award and the Martin University Board of Trustees Wind Under Our Wings Award. In 2005, she received the Honorary Doctor of Laws degree from Martin University. After 30 years of service, Schilling retired from Martin University in 2007. She died on September 13, 2017 at Nazareth Living House, Sisters of St. Joseph of Carondolet, St. Louis.\n\nWIAN-FM Outstanding Service Award\n\nLeadership in Education Award, Indianapolis Education Association\n\nDr. Martin Luther King, Jr. Drum Major Award, Indiana Christian Leadership Conference\n\nDr. Martin Luther King, Jr. 1995 Individual Award, Madame Walker Institute, Indianapolis\n\nDiamond Award, United to Serve America\n\nService to the Black Community, King-Walker-Wilkins-Young Awards Committee\n\nPaul Harris Fellow, Rotary International\n\nHeroism Award, American Red Cross\n\nSagamore of the Wabash, Governor of Indiana\n\nRole Modelship Award, Wheeler Boys and Girls Club\n\nMother of the Year, Nur-Allah Islamic Center, Indianapolis\n\n100 Heros, United Way of Central Indiana\n"}
{"id": "6043401", "url": "https://en.wikipedia.org/wiki?curid=6043401", "title": "Josephine Meckseper", "text": "Josephine Meckseper\n\nJosephine Meckseper is a German-born contemporary commercial artist based in New York City. Her large-scale installations and films have been shown at various international biennials and museums.\n\nJosephine Meckseper grew up in Worpswede, Germany, a utopian artist colony founded at the beginning of the 20th century. Meckseper’s maternal great-grand-uncle, Heinrich Vogeler (1872–1942) is said to have resided there. Meckseper’s father is German artist Friedrich Meckseper (born 1936).\n\nJosephine Meckseper studied at Berlin University of the Arts in Germany from 1986–1990, and received a MFA from the California Institute of the Arts in 1992.\n\nMeckseper’s work is politically-informed and strongly influenced by Situationist International and Angry Brigade ideology.\n\nIn 1994, Meckseper founded \"FAT Magazine\", privately distributed at supermarkets, galleries and museums, sometimes heroically stuck on walls in homage Jean-Paul Marat. Four issues have come out since 1994.\n\nMeckseper’s installations, sculptures, photographs, and videos use industrial forms of presentation such as vitrines, window displays, and magazines to demonstrate inextricable influences of consumer culture on society and cultural production. Meckseper melds the aesthetics of modernism with the formal language of commercial display, combining them with images and artifacts of historical and political events. Often contained within Meckseper’s signature displays are paintings that nod to 20th century European modernist art, such as Russian constructivism, as well as photographs and video taken by Meckseper at present-day protests.\n\nManhattan Oil Project\n\nIn 2012, Meckseper presented the public project Manhattan Oil Project, installing two monumental kinetic sculptures modeled after mid-20th century oil pumps on the corner of 46th Street and 8th Avenue in New York City. These 25 feet tall sculptures were inspired by oil pumps that the artist discovered in Electra, a boarded-up town once famous for being the pump jack capital of Texas. Each sculpture was fully motorized to simulate the motions of a working oil pump. Placed in a vacant lot next to Times Square, the pump jacks recalled the ruins of ghost towns, forgotten monuments of America's decaying industrial past.\n\nPellea[s]\n\nMeckseper's film \"Pellea[s]\" is a narrative film released in 2018 that expresses through cinema the narratives and relationships contained within the universe within her glass and mirror vitrines. Meckseper explains, \"\"Pellea[s]\" expands on this historical discourse through cinema and acted out narratives. It is a modern adaptation of Maurice Maeterlinck’s play \"Pelléas et Mélisande\", conflated with the current political realities in the US.\"\n\n\n\n\n\n"}
{"id": "16864", "url": "https://en.wikipedia.org/wiki?curid=16864", "title": "Karma", "text": "Karma\n\nKarma (; , ; ) means action, work or deed; it also refers to the spiritual principle of cause and effect where intent and actions of an individual (cause) influence the future of that individual (effect). Good intent and good deeds contribute to good karma and future happiness, while bad intent and bad deeds contribute to bad karma and future suffering. \n\nThe philosophy of karma is closely associated with the idea of rebirth in many schools of Indian religions (particularly Hinduism, Buddhism, Jainism and Sikhism) as well as Taoism. In these schools, karma in the present affects one's future in the current life, as well as the nature and quality of future lives - one's \"saṃsāra\".\n\"Karma\" is the executed \"deed\", \"work\", \"action\", or \"act\", and it is also the \"object\", the \"intent\". Wilhelm Halbfass explains karma (karman) by contrasting it with another Sanskrit word \"kriya\". The word \"kriya\" is the activity along with the steps and effort in action, while \"karma\" is (1) the executed action as a consequence of that activity, as well as (2) the intention of the actor behind an executed action or a planned action (described by some scholars as metaphysical residue left in the actor). A good action creates good karma, as does good intent. A bad action creates bad karma, as does bad intent.\n\nKarma, also refers to a conceptual principle that originated in India, often descriptively called the principle of karma, sometimes as the karma theory or the law of karma. In the context of theory, karma is complex and difficult to define. Different schools of Indologists derive different definitions for the karma concept from ancient Indian texts; their definition is some combination of (1) causality that may be ethical or non-ethical; (2) ethicization, that is good or bad actions have consequences; and (3) rebirth. Other Indologists include in the definition of karma theory that which explains the present circumstances of an individual with reference to his or her actions in past. These actions may be those in a person's current life, or, in some schools of Indian traditions, possibly actions in their past lives; furthermore, the consequences may result in current life, or a person's future lives. The law of karma operates independent of any deity or any process of divine judgment.\n\nDifficulty in arriving at a definition of \"karma\" arises because of the diversity of views among the schools of Hinduism; some, for example, consider karma and rebirth linked and simultaneously essential, some consider karma but not rebirth essential, and a few discuss and conclude karma and rebirth to be flawed fiction. Buddhism and Jainism have their own karma precepts. Thus karma has not one, but multiple definitions and different meanings. It is a concept whose meaning, importance and scope varies between Hinduism, Buddhism, Jainism and other traditions that originated in India, and various schools in each of these traditions. O'Flaherty claims that, furthermore, there is an ongoing debate regarding whether karma is a theory, a model, a paradigm, a metaphor, or a metaphysical stance.\n\nKarma theory as a concept, across different Indian religious traditions, shares certain common themes: causality, ethicization and rebirth.\n\nA common theme to theories of karma is its principle of causality. One of the earliest association of karma to causality occurs in the Brihadaranyaka Upanishad of Hinduism. For example, at 4.4.5-6, it states:\n\nThe relationship of karma to causality is a central motif in all schools of Hindu, Jain and Buddhist thought. The theory of karma as causality holds that (1) executed actions of an individual affects the individual and the life he or she lives, and (2) the intentions of an individual affects the individual and the life he or she lives. Disinterested actions, or unintentional actions do not have the same positive or negative karmic effect, as interested and intentional actions. In Buddhism, for example, actions that are performed, or arise, or originate without any bad intent such as covetousness, are considered non-existent in karmic impact or neutral in influence to the individual.\n\nAnother causality characteristic, shared by Karmic theories, is that like deeds lead to like effects. Thus good karma produces good effect on the actor, while bad karma produces bad effect. This effect may be material, moral or emotional — that is, one's karma affects one's happiness and unhappiness. The effect of karma need not be immediate; the effect of karma can be later in one's current life, and in some schools it extends to future lives.\n\nThe consequence or effects of one's karma can be described in two forms: \"phalas\" and \"samskaras\". A \"phala\" (literally, fruit or result) is the visible or invisible effect that is typically immediate or within the current life. In contrast, \"samskaras\" are invisible effects, produced inside the actor because of the karma, transforming the agent and affecting his or her ability to be happy or unhappy in this life and future ones. The theory of karma is often presented in the context of \"samskaras\".\n\nKarmic principle can be understood, suggests Karl Potter, as a principle of psychology and habit. Karma seeds habits (vāsanā), and habits create the nature of man. Karma also seeds self perception, and perception influences how one experiences life events. Both habits and self perception affect the course of one's life. Breaking bad habits is not easy: it requires conscious karmic effort. Thus psyche and habit, according to Potter and others, link karma to causality in ancient Indian literature. The idea of karma may be compared to the notion of a person's \"character\", as both are an assessment of the person and determined by that person's habitual thinking and acting.\n\nThe second theme common to karma theories is ethicization. This begins with the premise that every action has a consequence, which will come to fruition in either this or a future life; thus, morally good acts will have positive consequences, whereas bad acts will produce negative results. An individual's present situation is thereby explained by reference to actions in his present or in previous lifetimes. Karma is not itself \"reward and punishment\", but the law that produces consequence. Halbfass notes, good karma is considered as \"dharma\" and leads to \"punya\" (merit), while bad karma is considered \"adharma\" and leads to \"pāp\" (demerit, sin).\n\nReichenbach suggests that the theories of karma are an ethical theory. This is so because the ancient scholars of India linked intent and actual action to the merit, reward, demerit and punishment. A theory without ethical premise would be a pure causal relation; the merit or reward or demerit or punishment would be same regardless of the actor's intent. In ethics, one's intentions, attitudes and desires matter in the evaluation of one's action. Where the outcome is unintended, the moral responsibility for it is less on the actor, even though causal responsibility may be the same regardless. A karma theory considers not only the action, but also actor's intentions, attitude, and desires before and during the action. The karma concept thus encourages each person to seek and live a moral life, as well as avoid an immoral life. The meaning and significance of karma is thus as a building block of an ethical theory.\n\nThe third common theme of karma theories is the concept of reincarnation or the cycle of rebirths (\"saṃsāra\"). Rebirth is a fundamental concept of Hinduism, Buddhism, Jainism and Sikhism. The concept has been intensely debated in ancient literature of India; with different schools of Indian religions considering the relevance of rebirth as either essential, or secondary, or unnecessary fiction. Karma is a basic concept, rebirth is a derivative concept, so suggests Creel; Karma is a fact, asserts Yamunacharya, while reincarnation is a hypothesis; in contrast, Hiriyanna suggests rebirth is a necessary corollary of karma.\n\nRebirth, or \"saṃsāra\", is the concept that all life forms go through a cycle of reincarnation, that is a series of births and rebirths. The rebirths and consequent life may be in different realm, condition or form. The karma theories suggest that the realm, condition and form depends on the quality and quantity of karma. In schools that believe in rebirth, every living being's soul transmigrates (recycles) after death, carrying the seeds of Karmic impulses from life just completed, into another life and lifetime of karmas. This cycle continues indefinitely, except for those who consciously break this cycle by reaching \"moksa\". Those who break the cycle reach the realm of gods, those who don't continue in the cycle.\n\nThe theory of \"karma and rebirth\" raises numerous questions—such as how, when, and why did the cycle start in the first place, what is the relative Karmic merit of one karma versus another and why, and what evidence is there that rebirth actually happens, among others. Various schools of Hinduism realized these difficulties, debated their own formulations, some reaching what they considered as internally consistent theories, while other schools modified and de-emphasized it, while a few schools in Hinduism such as Charvakas, Lokayatana abandoned \"karma and rebirth\" theory altogether. Schools of Buddhism consider karma-rebirth cycle as integral to their theories of soteriology.\n\nThe Vedic Sanskrit word (nominative ') means \"work\" or \"deed\", often used in the context of Srauta rituals.\nIn the Rigveda, the word occurs some 40 times. In Satapatha Brahmana 1.7.1.5, sacrifice is declared as the \"greatest\" of \"works\"; Satapatha Brahmana 10.1.4.1 associates the potential of becoming immortal (\"amara\") with the \"karma\" of the agnicayana sacrifice.\n\nThe earliest clear discussion of the karma doctrine is in the Upanishads. For example, the causality and ethicization is stated in Bṛhadāraṇyaka Upaniṣad 3.2.13 (\"Truly, one becomes good through good \"deeds\", and evil through evil \"deeds\".\")\n\nSome authors state that the \"samsara\" (transmigration) and karma doctrine may be non-Vedic, and the ideas may have developed in the \"shramana\" traditions that preceded Buddhism and Jainism. Others state that some of the complex ideas of the ancient emerging theory of karma flowed from Vedic thinkers to Buddhist and Jain thinkers. The mutual influences between the traditions is unclear, and likely co-developed.\n\nMany philosophical debates surrounding the concept are shared by the Hindu, Jain and Buddhist traditions, and the early developments in each tradition incorporated different novel ideas. For example, Buddhists allowed karma transfer from one person to another and sraddha rites, but had difficulty defending the rationale. In contrast, Hindu schools and Jainism would not allow the possibility of karma transfer.\n\nThe concept of karma in Hinduism developed and evolved over centuries. The earliest Upanishads began with the questions about how and why man is born, and what happens after death. As answers to the latter, the early theories in these ancient Sanskrit documents include \"pancagni vidya\" (the five fire doctrine), \"pitryana\" (the cyclic path of fathers) and \"devayana\" (the cycle-transcending, path of the gods). Those who do superficial rituals and seek material gain, claimed these ancient scholars, travel the way of their fathers and recycle back into another life; those who renounce these, go into the forest and pursue spiritual knowledge, were claimed to climb into the higher path of the gods. It is these who break the cycle and are not reborn. With the composition of the Epics - the common man's introduction to Dharma in Hinduism - the ideas of causality and essential elements of the theory of karma were being recited in folk stories. For example:\nIn the thirteenth book of the Mahabharata, also called the Teaching Book (Anushasana Parva), sixth chapter opens with Yudhishthira asking Bhishma: \"Is the course of a person's life already destined, or can human effort shape one's life?\" The future, replies Bhishma, is both a function of current human effort derived from free will and past human actions that set the circumstances. Over and over again, the chapters of Mahabharata recite the key postulates of karma theory. That is: intent and action (karma) has consequences; karma lingers and doesn't disappear; and, all positive or negative experiences in life require effort and intent. For example:\nOver time, various schools of Hinduism developed many different definitions of karma, some making karma appear quite deterministic, while others make room for free will and moral agency. Among the six most studied schools of Hinduism, the theory of karma evolved in different ways, as their respective scholars reasoned and attempted to address the internal inconsistencies, implications and issues of the karma doctrine. According to Halbfass,\n\nThe above six schools illustrate the diversity of views, but are not exhaustive. Each school has sub-schools in Hinduism, such as Vedanta school's nondualism and dualism sub-schools. Furthermore, there are other schools of Hinduism such as Charvaka, Lokayata (the materialists) who denied the theory of karma-rebirth as well as the existence of God; to this school of Hindus, the properties of things come from the nature of things. Causality emerges from the interaction, actions and nature of things and people, determinative principles such as karma or God are unnecessary.\n\n\"Karma\" and \"karmaphala\" are fundamental concepts in Buddhism. The concepts of \"karma\" and \"karmaphala\" explain how our intentional actions keep us tied to rebirth in \"samsara\", whereas the Buddhist path, as exemplified in the Noble Eightfold Path, shows us the way out of \"samsara\". \"Karmaphala\" is the \"fruit\", \"effect\" or \"result\" of \"karma\". A similar term is \"karmavipaka\", the \"maturation\" or \"cooking\" of \"karma\". The cycle of rebirth is determined by \"karma\", literally \"action\". In the Buddhist tradition, \"karma\" refers to actions driven by \"intention\" (\"cetanā\"), a deed done deliberately through body, speech or mind, which leads to future consequences. The \"Nibbedhika Sutta\", Anguttara Nikaya 6.63:\n\nHow these intentional actions lead to rebirth, and how the idea of rebirth is to be reconciled with the doctrines of impermanence and no-self, is a matter of philosophical inquiry in the Buddhist traditions, for which several solutions have been proposed. In early Buddhism no explicit theory of rebirth and karma is worked out, and \"the karma doctrine may have been incidental to early Buddhist soteriology.\" In early Buddhism, rebirth is ascribed to craving or ignorance.\nThe Buddha's teaching of karma is not strictly deterministic, but incorporated circumstantial factors, unlike that of the Jains. It is not a rigid and mechanical process, but a flexible, fluid and dynamic process. There is no set linear relationship between a particular action and its results. The karmic effect of a deed is not determined solely by the deed itself, but also by the nature of the person who commits the deed, and by the circumstances in which it is committed. \"Karmaphala\" is not a \"judgement\" enforced by a God, Deity or other supernatural being that controls the affairs of the Cosmos. Rather, \"karmaphala\" is the outcome of a natural process of cause and effect.\nWithin Buddhism, the real importance of the doctrine of karma and its fruits lies in the recognition of the urgency to put a stop to the whole process. The \"Acintita Sutta\" warns that \"the results of kamma\" is one of the four incomprehensible subjects, subjects that are beyond all conceptualization and cannot be understood with logical thought or reason.\nNichiren Buddhism teaches that transformation and change through faith and practice changes adverse karma—negative causes made in the past that result in negative results in the present and future—to positive causes for benefits in the future. \n\nIn Jainism, \"karma\" conveys a totally different meaning from that commonly understood in Hindu philosophy and western civilization. Jain philosophy is the oldest Indian philosophy that completely separates body (matter) from the soul (pure consciousness). In Jainism, karma is referred to as karmic dirt, as it consists of very subtle particles of matter that pervade the entire universe. \"Karmas\" are attracted to the karmic field of a soul due to vibrations created by activities of mind, speech, and body as well as various mental dispositions. Hence the \"karmas\" are the subtle matter surrounding the consciousness of a soul. When these two components (consciousness and karma) interact, we experience the life we know at present.\nJain texts expound that seven \"tattvas\" (truths or fundamentals) constitute reality. These are:\n\nAccording to Padmanabh Jaini,This emphasis on reaping the fruits only of one's own karma was not restricted to the Jainas; both Hindus and Buddhist writers have produced doctrinal materials stressing the same point. Each of the latter traditions, however, developed practices in basic contradiction to such belief. In addition to \"shrardha\" (the ritual Hindu offerings by the son of deceased), we find among Hindus widespread adherence to the notion of divine intervention in ones fate, while Buddhists eventually came to propound such theories like boon-granting bodhisattvas, transfer of merit and like. Only Jainas have been absolutely unwilling to allow such ideas to penetrate their community, despite the fact that there must have been tremendous amount of social pressure on them to do so.\nThe key points where the theory of karma in Jainism can be stated as follows:\n\nIn Sikhism, all living beings are described as being under the influence of \"maya's\" three qualities. Always present together in varying mix and degrees, these three qualities of \"maya\" bind the soul to the body and to the earth plane. Above these three qualities is the eternal time. Due to the influence of three modes of Maya's nature, \"jivas\" (individual beings) perform activities under the control and purview of the eternal time. These activities are called \"karma\". The underlying principle is that karma is the law that brings back the results of actions to the person performing them.\n\nThis life is likened to a field in which our karma is the seed. We harvest exactly what we sow; no less, no more. This infallible law of karma holds everyone responsible for what the person is or is going to be. Based on the total sum of past karma, some feel close to the Pure Being in this life and others feel separated. This is the Gurbani's (Sri Guru Granth Sahib) law of karma. Like other Indian and oriental schools of thought, the Gurbani also accepts the doctrines of karma and reincarnation as the facts of nature.\n\nInterpreted as \"Musubi\", a view of karma is recognized in Shintoism as a means of enriching, empowering and life affirming.\n\nKarma is an important concept in Taoism. Every deed is tracked by deities and spirits. Appropriate rewards or retribution follow karma, just like a shadow follows a person.\n\nThe karma doctrine of Taoism developed in three stages. In the first stage, causality between actions and consequences was adopted, with supernatural beings keeping track of everyone's karma and assigning fate (\"ming\"). In the second phase, transferability of karma ideas from Chinese Buddhism were expanded, and a transfer or inheritance of Karmic fate from ancestors to one's current life was introduced. In the third stage of karma doctrine development, ideas of rebirth based on karma were added. One could be reborn either as another human being or another animal, according to this belief. In the third stage, additional ideas were introduced; for example, rituals, repentance and offerings at Taoist temples were encouraged as it could alleviate Karmic burden.\n\nOwnby (2008) claims that Falun Gong differs from Buddhism in its definition of the term \"karma\" in that it is taken not as a process of award and punishment, but as an exclusively negative term. The Chinese term \"de\" or \"virtue\" is reserved for what might otherwise be termed \"good karma\" in Buddhism. Karma is understood as the source of all suffering - what Buddhism might refer to as \"bad karma\". Li says, \"A person has done bad things over his many lifetimes, and for people this results in misfortune, or for cultivators it's karmic obstacles, so there's birth, aging, sickness, and death. This is ordinary karma.\"\n\nFalun Gong teaches that the spirit is locked in the cycle of rebirth, also known as samsara due to the accumulation of karma. This is a negative, black substance that accumulates in other dimensions lifetime after lifetime, by doing bad deeds and thinking bad thoughts. Falun Gong states that karma is the reason for suffering, and what ultimately blocks people from the truth of the universe and attaining enlightenment. At the same time, karma is also the cause of one's continued rebirth and suffering. Li says that due to accumulation of karma the human spirit upon death will reincarnate over and over again, until the karma is paid off or eliminated through cultivation, or the person is destroyed due to the bad deeds he has done.\n\nOwnby regards the concept of karma as a cornerstone to individual moral behaviour in Falun Gong, and also readily traceable to the Christian doctrine of \"one reaps what one sows\". Others say Matthew 5:44 means no unbeliever will not fully reap what they sow until they are Judged by God after death in Hell. Ownby says Falun Gong is differentiated by a \"system of transmigration\", though, \"in which each organism is the reincarnation of a previous life form, its current form having been determined by karmic calculation of the moral qualities of the previous lives lived.\" Ownby says the seeming unfairness of manifest inequities can then be explained, at the same time allowing a space for moral behaviour in spite of them. In the same vein of Li's monism, matter and spirit are one, karma is identified as a black substance which must be purged in the process of cultivation.\n\nLi says that \"Human beings all fell here from the many dimensions of the universe. They no longer met the requirements of the Fa at their given levels in the universe, and thus had to drop down. Just as we have said before, the heavier one's mortal attachments, the further down one drops, with the descent continuing until one arrives at the state of ordinary human beings.\" He says that in the eyes of higher beings, the purpose of human life is not merely to be human, but to awaken quickly on Earth, a \"setting of delusion\", and return. \"That is what they really have in mind; they are opening a door for you. Those who fail to return will have no choice but to reincarnate, with this continuing until they amass a huge amount of karma and are destroyed.\"\n\nOwnby regards this as the basis for Falun Gong's apparent \"opposition to practitioners' taking medicine when ill; they are missing an opportunity to work off karma by allowing an illness to run its course (suffering depletes karma) or to fight the illness through cultivation.\" Benjamin Penny shares this interpretation. Since Li believes that \"karma is the primary factor that causes sickness in people\", Penny asks: \"if disease comes from karma and karma can be eradicated through cultivation of \"xinxing\", then what good will medicine do?\" Li himself states that he is not forbidding practitioners from taking medicine, maintaining that \"What I'm doing is telling people the relationship between practicing cultivation and medicine-taking\". Li also states that \"An everyday person needs to take medicine when he gets sick.\" Schechter quotes a Falun Gong student who says \"It is always an individual choice whether one should take medicine or not.\"\n\nOne of the significant controversies with the karma doctrine is whether it always implies destiny, and its implications on free will. This controversy is also referred to as the moral agency problem; the controversy is not unique to karma doctrine, but also found in some form in monotheistic religions.\n\nThe free will controversy can be outlined in three parts: (1) A person who kills, rapes or commits any other unjust act, can claim all his bad actions were a product of his karma: he is devoid of free will, he can not make a choice, he is an agent of karma, and he merely delivers necessary punishments his \"wicked\" victims deserved for their own karma in past lives. Are crimes and unjust actions due to free will, or because of forces of karma? (2) Does a person who suffers from the unnatural death of a loved one, or rape or any other unjust act, assume a moral agent is responsible, that the harm is gratuitous, and therefore seek justice? Or, should one blame oneself for bad karma over past lives, and assume that the unjust suffering is fate? (3) Does the karma doctrine undermine the incentive for moral education--because all suffering is deserved and consequence of past lives, why learn anything when the balance sheet of karma from past lives will determine one's action and sufferings?\n\nThe explanations and replies to the above free will problem vary by the specific school of Hinduism, Buddhism and Jainism. The schools of Hinduism, such as Yoga and Advaita Vedanta, that have emphasized current life over the dynamics of karma residue moving across past lives, allow free will. Their argument, as well of other schools, are threefold: (1) The theory of karma includes both the action and the intent behind that action. Not only is one affected by past karma, one creates new karma whenever one acts with intent - good or bad. If intent and act can be proven beyond reasonable doubt, new karma can be proven, and the process of justice can proceed against this new karma. The actor who kills, rapes or commits any other unjust act, must be considered as the moral agent for this new karma, and tried. (2) Life forms not only receive and reap the consequence of their past karma, together they are the means to initiate, evaluate, judge, give and deliver consequence of karma to others. (3) Karma is a theory that explains some evils, not all (see moral evil versus natural evil).\n\nOther schools of Hinduism, as well as Buddhism and Jainism that do consider cycle of rebirths central to their beliefs and that karma from past lives affects one's present, believe that both free will (\"Cetanā\") and karma can co-exist; however, their answers have not persuaded all scholars.\n\nAnother issue with the theory of karma is that it is psychologically indeterminate, suggests Obeyesekere. That is, (1) if no one can know what their karma was in previous lives, and (2) if the karma from past lives can determine one's future, then the individual is psychologically unclear what if anything he or she can do now to shape the future, be more happy, or reduce suffering. If something goes wrong such as sickness or failure at work the individual is unclear if karma from past lives was the cause, or the sickness was caused by curable infection and the failure was caused by something correctable.\n\nThis psychological indeterminacy problem is also not unique to the theory of karma; it is found in every religion adopting the premise that God has a plan, or in some way influences human events. As with the karma-and-free-will problem above, schools that insist on primacy of rebirths face the most controversy. Their answers to the psychological indeterminacy issue are the same as those for addressing the free will problem.\n\nSome schools of Asian religions, particularly Popular Theravada Buddhism, allow transfer of karma merit and demerit from one person to another. This transfer is an exchange of non-physical quality just like an exchange of physical goods between two human beings. The practice of karma transfer, or even its possibility, is controversial. Karma transfer raises questions similar to those with substitutionary atonement and vicarious punishment. It defeats the ethical foundations, and dissociates the causality and ethicization in the theory of karma from the moral agent. Proponents of some Buddhist schools suggest that the concept of karma merit transfer encourages religious giving, and such transfers are not a mechanism to transfer bad karma (i.e., demerit) from one person to another.\n\nIn Hinduism, Sraddha rites during funerals have been labelled as karma merit transfer ceremonies by a few scholars, a claim disputed by others. Other schools in Hinduism, such as the Yoga and Advaita Vedantic philosophies, and Jainism hold that karma can not be transferred.\n\nThere has been an ongoing debate about karma theory and how it answers the problem of evil and related problem of theodicy. The problem of evil is a significant question debated in monotheistic religions with two beliefs: (1) There is one God who is absolutely good and compassionate (omnibenevolent), and (2) That one God knows absolutely everything (omniscient) and is all powerful (omnipotent). The problem of evil is then stated in formulations such as, \"why does the omnibenevolent, omniscient and omnipotent God allow any evil and suffering to exist in the world?\" Max Weber extended the problem of evil to Eastern traditions.\n\nThe problem of evil, in the context of karma, has been long discussed in Eastern traditions, both in theistic and non-theistic schools; for example, in Uttara Mīmāṃsā Sutras Book 2 Chapter 1; the 8th century arguments by Adi Sankara in \"Brahmasutrabhasya\" where he posits that God cannot reasonably be the cause of the world because there exists moral evil, inequality, cruelty and suffering in the world; and the 11th century theodicy discussion by Ramanuja in \"Sribhasya\". Epics such as the Mahabharata, for example, suggests three prevailing theories in ancient India as to why good and evil exists one being that everything is ordained by God, another being karma, and a third citing chance events (\"yadrccha\", यदृच्छा). The Mahabharata, which includes Hindu deity Vishnu in the form of Krishna as one of the central characters in the Epic, debates the nature and existence of suffering from these three perspectives, and includes a theory of suffering as arising from an interplay of chance events (such as floods and other events of nature), circumstances created by past human actions, and the current desires, volitions, dharma, adharma and current actions (\"purusakara\") of people. However, while karma theory in the Mahabharata presents alternative perspectives on the problem of evil and suffering, it offers no conclusive answer.\n\nOther scholars suggest that nontheistic Indian religious traditions do not assume an omnibenevolent creator, and some theistic schools do not define or characterize their God(s) as monotheistic Western religions do and the deities have colorful, complex personalities; the Indian deities are personal and cosmic facilitators, and in some schools conceptualized like Plato’s Demiurge. Therefore, the problem of theodicy in many schools of major Indian religions is not significant, or at least is of a different nature than in Western religions. Many Indian religions place greater emphasis on developing the karma principle for first cause and innate justice with Man as focus, rather than developing religious principles with the nature and powers of God and divine judgment as focus. Some scholars, particularly of the Nyaya school of Hinduism and Sankara in \"Brahmasutra bhasya\", have posited that karma doctrine implies existence of god, who administers and affects the person's environment given that person's karma, but then acknowledge that it makes karma as violable, contingent and unable to address the problem of evil. Arthur Herman states that karma-transmigration theory solves all three historical formulations to the problem of evil while acknowledging the theodicy insights of Sankara and Ramanuja.\n\nSome theistic Indian religions, such as Sikhism, suggest evil and suffering are a human phenomenon and arises from the karma of individuals. In other theistic schools such as those in Hinduism, particularly its Nyaya school, karma is combined with dharma and evil is explained as arising from human actions and intent that is in conflict with dharma. In nontheistic religions such as Buddhism, Jainism and the Mimamsa school of Hinduism, karma theory is used to explain the cause of evil as well as to offer distinct ways to avoid or be unaffected by evil in the world.\n\nThose schools of Hinduism, Buddhism and Jainism that rely on karma-rebirth theory have been critiqued for their theological explanation of suffering in children by birth, as the result of his or her sins in a past life. Others disagree, and consider the critique as flawed and a misunderstanding of the karma theory.\n\nWestern culture, influenced by Christianity, holds a notion similar to karma, as demonstrated in the phrase \"what goes around comes around\".\n\nMary Jo Meadow suggests karma is akin to \"Christian notions of sin and its effects.\" She states that the Christian teaching on a Last Judgment according to one's charity is a teaching on karma. Christianity also teaches morals such as one reaps what one sows (Galatians 6:7) and live by the sword, die by the sword (Matthew 26:52). Most scholars, however, consider the concept of Last Judgment as different from karma, with karma as an ongoing process that occurs every day in one's life, while Last Judgment, by contrast, is a one-time review at the end of life.\n\nThere is a concept in Judaism called in Hebrew \"midah k'neged midah\", which literally translates to \"value against value,\" but carries the same connotation as the English phrase \"measure for measure.\" The concept is used not so much in matters of law, but rather, in matters of ethics, i.e. how one's actions effects the world will eventually come back to that person in ways one might not necessarily expect. David Wolpe compared \"midah k'neged midah\" to karma.\n\nJung once opined on unresolved emotions and the synchronicity of karma;\nPopular methods for negating cognitive dissonance include meditation, metacognition, counselling, psychoanalysis, etc., whose aim is to enhance emotional self-awareness and thus avoid negative karma. This results in better emotional hygiene and reduced karmic impacts. Permanent neuronal changes within the amygdala and left prefrontal cortex of the human brain attributed to long-term meditation and metacognition techniques have been proven scientifically. This process of emotional maturation aspires to a goal of Individuation or self-actualisation. Such peak experiences are hypothetically devoid of any karma (nirvana or moksha).\n\nThe idea of karma was popularized in the Western world through the work of the Theosophical Society. In this conception, karma was a precursor to the Neopagan \"law of return\" or \"Threefold Law,\" the idea that the beneficial or harmful effects one has on the world will return to oneself. Colloquially this may be summed up as 'what goes around comes around.'\n\nThe Theosophist I. K. Taimni wrote, \"Karma is nothing but the Law of Cause and Effect operating in the realm of human life and bringing about adjustments between an individual and other individuals whom he has affected by his thoughts, emotions and actions.\" Theosophy also teaches that when humans reincarnate they come back as humans only, not as animals or other organisms.\n"}
{"id": "30860454", "url": "https://en.wikipedia.org/wiki?curid=30860454", "title": "Kenneth J. Gergen", "text": "Kenneth J. Gergen\n\nKenneth J. Gergen (born 1935) is an American psychologist and emeritus professor at Swarthmore College. He obtained his Bachelor of Arts from Yale University (1957) and his PhD from Duke University (1962).\n\nThe son of John Jay Gergen, the Chair of the Mathematics Department at Duke University, and Aubigne Munger (née Lermond), Gergen grew up in Durham, North Carolina. He had three brothers, one of whom is David Gergen, the prominent political analyst. After completing public schooling, he attended Yale University. Graduating in 1957, he subsequently became an officer in the U.S. Navy. He then returned to graduate school at Duke University, where he received his PhD in psychology in 1963. His dissertation advisor was Edward E. Jones. Gergen went on to become an Assistant Professor in the Department of Social Relations at Harvard University, where he also became the Chairman of the Board of Tutors and Advisors for the department and representative to the university's Council on Educational Policy.\n\nIn 1967, Gergen took a position as Chair of the Department of Psychology at Swarthmore College, a position he held for ten years. At various intervals, he served as visiting professor at the University of Heidelberg, the University of Marburg, the Sorbonne, the University of Rome, Kyoto University, and Adolfo Ibanez University. At Swarthmore, he spearheaded the development of the academic concentration in interpretation theory. In an attempt to link his academic work to societal practices, he collaborated with colleagues to create the Taos Institute in 1996. He is currently Gil and Frank Mustin Professor Emeritus of Psychology and Senior Research Professor at Swarthmore, the Chairman of the Board of the Taos Institute, and an adjunct professor at Tilburg University.\n\nGergen is married to Mary M. Gergen, Professor Emeritus at Penn State University, and a major contributor to feminist psychology and performance inquiry. She is the author of over 50 articles and is the co-author (with Ken Gergen) of \"Social Construction\". They publish the Positive Aging Newsletter with a readership of around 20,000\n\nGergen's earliest studies challenged the presumption of a unified or coherent self. He then raised questions about the value of altruism, by exploring the ways in which helping others leads to the recipient's resentment and alienation. \n\nA major point in Gergen's career was his 1973 article \"Social Psychology as History\". In the article, he argues that the laws and principles of social interaction are variable over time, and that the scientific knowledge generated by social psychologists actually influences the phenomena it is meant to passively describe. For example, studying obedience to authority may reduce the likelihood of obedience. He argued therefore that social psychology was not fundamentally a cumulative science, but was effectively engaged in the recording and transformation of cultural life. The article proved contentious, receiving criticism, such as from Barry R. Schlenker. The developing dispute became known as the \"Gergen-Schlenker debate\" and touched topics around the metatheory of social psychology. Karl E. Weick later took Warren Thorngate's contribution to that dispute to formulate Thorngate's postulate of commensurate complexity, a theorem revolving around research methodology in social sciences.\n\nAlso contributing to what was called \"the crisis in social psychology\" was Gergen's subsequent publication on generative theory. Here he proposed that, because theoretical suppositions were not so much recordings of social life as creators, theories should not be judged by their accuracy so much as their potential to open new spaces of action.\n\nCombining these ideas with developments in literary and critical theory, along with the history of science, Gergen went on to develop a radical view of socially constructed knowledge. This view was proposed as a successor project to what Gergen considered an inherently flawed empiricist conception of knowledge. From Gergen's perspective, all human intelligibility (including claims to knowledge) is generated within relationships. It is from relationships that humans derive their conceptions of what is real, rational, and good. From this perspective, scientific theories, like all other reality posits, should not be assessed in terms of truth, but in terms of pragmatic outcomes. Such assessments are inevitably wedded to values, and thus all science is morally and politically weighted in implication. As he saw it, this same form of assessment also applies to social constructionist theory. The question is not its accuracy, but its potentials for humankind.\n\nThis latter conclusion informed most of Gergen's subsequent work, in areas including therapy and counseling, education, organizational change, technology, conflict reduction, civil society, and qualitative inquiry. In one form or another, this work is concerned with transforming social life. For the most part, his preferred direction of change is toward more collaborative and participatory relationships. Additionally, he has been concerned with fostering a \"relational\" view of the self, where the \"traditional emphasis on the individual mind is replaced by a concern with the relational processes from which rationality and morality emerge.\" He is also known for his comment \"I am linked therefore I am\" as an answer to Descartes' proposition \"I think, therefore I am\". Most of these developments are summarized in \"Relational Being, Beyond the Individual and Community,\" which attempts to demonstrate that what are considered mental processes are not so much \"in the head\" as in relationships. It also attempts to answer charges of moral relativism with a non-foundational morality of collaborative practice, and to outline a way to bring science together with concerns for the sacred.\n\nGergen's work is associated with social constructionism. Other major interests in his diverse works include analyzing the effects of technology on social life, examining connections between social construction and theology, and promoting a more optimistic model of aging.\n\nConcepts that Gergen has written about include:\n\nGergen has received research grants from the National Science Foundation, the Deutsche Forschungsgemeinschaft, and the Barra Foundation. His work has merited awards from the American Psychological Association, the National Communication Association, the Constructivist Psychology Network, the University of Buenos Aires, and Adolfo Ibanez University in Santiago. He has received fellowships from the Guggenheim Foundation, the Fulbright Foundation, and the Alexander Humboldt foundation. He also holds honorary degrees from Tilburg University, Saybrook Graduate School, and the University of Athens.\n\n\n\n"}
{"id": "232883", "url": "https://en.wikipedia.org/wiki?curid=232883", "title": "Law of Demeter", "text": "Law of Demeter\n\nThe Law of Demeter (LoD) or principle of least knowledge is a design guideline for developing software, particularly object-oriented programs. In its general form, the LoD is a specific case of loose coupling. The guideline was proposed by Ian Holland at Northeastern University towards the end of 1987, and can be succinctly summarized in each of the following ways:\n\n\nThe fundamental notion is that a given object should assume as little as possible about the structure or properties of anything else (including its subcomponents), in accordance with the principle of \"information hiding\". It may be viewed as a corollary to the principle of least privilege, which dictates that a module possess only the information and resources necessary for its legitimate purpose.\n\nIt is so named for its origin in the Demeter Project, an adaptive programming and aspect-oriented programming effort. The project was named in honor of Demeter, “distribution-mother” and the Greek goddess of agriculture, to signify a bottom-up philosophy of programming which is also embodied in the law itself.\n\nWhen applied to object-oriented programs, the Law of Demeter can be more precisely called the “Law of Demeter for Functions/Methods” (LoD-F). In this case, an object codice_1 can request a service (call a method) of an object instance codice_2, but object codice_1 should not \"reach through\" object codice_2 to access yet another object, codice_5, to request its services. Doing so would mean that object codice_1 implicitly requires greater knowledge of object codice_2's internal structure.\nInstead, codice_2's interface should be modified if necessary so it can directly serve object codice_1's request, propagating it to any relevant subcomponents. Alternatively, codice_1 might have a direct reference to object codice_5 and make the request directly to that. If the law is followed, only object codice_2 knows its own internal structure.\n\nMore formally, the Law of Demeter for functions requires that a method codice_13 of an object codice_14 may only invoke the methods of the following kinds of objects:\n\nIn particular, an object should avoid invoking methods of a member object returned by another method. For many modern object oriented languages that use a dot as field identifier, the law can be stated simply as \"use only one dot\". That is, the code codice_21 breaks the law where codice_22 does not. As an analogy, when one wants a dog to walk, one does not command the dog's legs to walk directly; instead one commands the dog which then commands its own legs.\n\nThe advantage of following the Law of Demeter is that the resulting software tends to be more maintainable and adaptable. Since objects are less dependent on the internal structure of other objects, object containers can be changed without reworking their callers.\n\nBasili et al. published experimental results in 1996 suggesting that a lower \"Response For a Class\" (RFC, the number of methods potentially invoked in response to calling a method of that class) can reduce the probability of software bugs. Following the Law of Demeter can result in a lower RFC. However, the results also suggest that an increase in \"Weighted Methods per Class\" (WMC, the number of methods defined in each class) can increase the probability of software bugs. Following the Law of Demeter can also result in a higher WMC; see Disadvantages.\n\nA multilayered architecture can be considered to be a systematic mechanism for implementing the Law of Demeter in a software system.\nIn a layered architecture, code within each layer can only make calls to code within the layer and code within the next layer down.\n\"Layer skipping\" would violate the layered architecture.\n\nAlthough the LoD increases the adaptiveness of a software system, it may (but not necessarily will) result in having to write many wrapper methods to propagate calls to components; in some cases, this can add noticeable time and space overhead.\n\nAt the method level, the LoD leads to narrow interfaces, giving access to only as much information as it needs to do its job, as each method needs to know about a small set of methods of closely related objects. On the other hand, at the class level, the LoD leads to wide (i.e. enlarged) interfaces, because the LoD requires introducing many auxiliary methods instead of digging directly into the object structures . One solution to the problem of enlarged class interfaces is the aspect-oriented approach, where the behavior of the method is specified as an aspect at a high level of abstraction. This is done by having an adaptive method that encapsulates the behaviour of an operation into a place, with which the scattering problem is solved. It also abstracts over the class structure that results in avoiding the tangling problem. The wide interfaces are managed through a language that specifies implementations. Both the traversal strategy and the adaptive visitor use only a minimal set of classes that participate in the operation, and the information about the connections between these classes is abstracted out.\n\nSince the LoD exemplifies a specific type of coupling, and does not specify a method of addressing this type of coupling, it is more suited as a metric for code smell as opposed to a methodology for building loosely coupled systems.\n\n\n"}
{"id": "160970", "url": "https://en.wikipedia.org/wiki?curid=160970", "title": "Literal and figurative language", "text": "Literal and figurative language\n\nLiteral and figurative language is a distinction within some fields of language analysis, in particular stylistics, rhetoric, and semantics. \n\nLiteral usage confers meaning to words, in the sense of the meaning they have by themselves, outside any figure of speech. It maintains a consistent meaning regardless of the context, with \"the intended meaning corresponding exactly to the meaning\" of the individual words. Figurative use of language is the use of words or phrases that \"implies a non-literal meaning which does make sense or that could [also] be true\".\n\nAristotle and later the Roman Quintilian were among the early analysts of rhetoric who expounded on the differences between literal and figurative language.\n\nIn 1769, Frances Brooke's novel \"The History of Emily Montague\" was used in the earliest \"Oxford English Dictionary\" citation for the figurative sense of \"literally\"; the sentence from the novel used was, \"He is a fortunate man to be introduced to such a party of fine women at his arrival; it is literally \"to feed among the lilies\".\" This citation was also used in the OED's 2011 revision.\n\nWithin literary analysis, such terms are still used; but within the fields of cognition and linguistics, the basis for identifying such a distinction is no longer used.\n\nFigurative language can take multiple forms, such as simile or metaphor. \"Merriam-Webster's Encyclopedia Of Literature\" says that figurative language can be classified in five categories: resemblance or relationship, emphasis or understatement, figures of sound, verbal games, and errors. \n\nA simile is a comparison of two things, indicated by some connective, usually \"like\", \"as\", \"than\", or a verb such as \"resembles\" to show how they are similar.\n\nA metaphor is a figure of speech in which two \"essentially unlike things\" are shown to have a type of resemblance or create a new image. The similarities between the objects being compared may be implied rather than directly stated.\n\nAn extended metaphor is a metaphor that is continued over multiple sentences.\n\nOnomatopoeia is a word designed to be an imitation of a sound.\n\nPersonification is the attribution of a personal nature or character to inanimate objects or abstract notions, especially as a rhetorical figure.\n\nAn oxymoron is a figure of speech in which a pair of opposite or contradictory terms is used together for emphasis.\n\nA paradox is a statement or proposition which is self-contradictory, unreasonable, or illogical.\n\nHyperbole is a figure of speech which uses an extravagant or exaggerated statement to express strong feelings.\n\nAllusion is a reference to a famous character or event.\n\nAn idiom is an expression that has a figurative meaning unrelated to the literal meaning of the phrase.\n\nA pun is an expression intended for a humorous or rhetorical effect by exploiting different meanings of words.\n\nPrior to the 1980s, the \"standard pragmatic\" model of comprehension was widely believed. In that model, it was thought the recipient would first attempt to comprehend the meaning as if literal, but when an appropriate literal inference could not be made, the recipient would shift to look for a figurative interpretation that would allow comprehension. Since then, research has cast doubt on the model. In tests, figurative language was found to be comprehended at the same speed as literal language; and so the premise that the recipient was first attempting to process a literal meaning and discarding it before attempting to process a figurative meaning appears to be false.\n\nBeginning with the work of Michael Reddy in his 1979 work \"The Conduit Metaphor\", many linguists now reject that there is a valid way to distinguish between a \"literal\" and \"figurative\" mode of language.\n\n"}
{"id": "89792", "url": "https://en.wikipedia.org/wiki?curid=89792", "title": "Mitochondrial Eve", "text": "Mitochondrial Eve\n\nIn human genetics, the Mitochondrial Eve (also \"mt-Eve, mt-MRCA\") is the matrilineal most recent common ancestor (MRCA) of all currently living humans, i.e., the most recent woman from whom all living humans descend in an unbroken line purely through their mothers, and through the mothers of those mothers, back until all lines converge on one woman.\n\nIn terms of mitochondrial haplogroups, the mt-MRCA is situated at the divergence of macro-haplogroup L into L0 and L1–6. As of 2013, estimates on the age of this split ranged at around 150,000 years ago, \nconsistent with a date later than the speciation of \"Homo sapiens\" but earlier than the recent Out-of-Africa dispersal.\n\nThe male analog to the \"Mitochondrial Eve\" is the \"Y-chromosomal Adam\" (or Y-MRCA), the individual from whom all living humans are patrilineally descended. As the identity of both matrilineal and patrilineal MRCAs is dependent on genealogical history (pedigree collapse), they need not have lived at the same time.\nAs of 2013, estimates for the age Y-MRCA are subject to substantial uncertainty, with a wide range of times from 180,000 to 580,000 years ago (with an estimated age of between 120,000 and 156,000 years ago, roughly consistent with the estimate for mt-MRCA.).\n\nThe name \"Mitochondrial Eve\" alludes to biblical Eve. This led to repeated misrepresentations or misconceptions in journalistic accounts on the topic. Popular science presentations of the topic usually point out such possible misconceptions by emphasizing the fact that the position of mt-MRCA is neither fixed in time (as the position of mt-MRCA moves forward in time as mitochondrial DNA (mtDNA) lineages become extinct), nor does it refer to a \"first woman\", nor the only living female of her time, nor the first member of a \"new species\".\n\nEarly research using molecular clock methods was done during the late 1970s to early 1980s.\nAllan Wilson, Mark Stoneking, Rebecca L. Cann and Wesley M. Brown found that mutation in human mtDNA was unexpectedly fast, at 0.02 substitution per base (1%) in a million years, which is 5–10 times faster than in nuclear DNA.\nRelated work allowed for an analysis of the evolutionary relationships among gorillas, chimpanzees (common chimpanzee and bonobo) and humans.\nWith data from 21 human individuals, Brown published the first estimate on the age of the mt-MRCA at 180,000 years ago in 1980.\nA statistical analysis published in 1982 was taken as evidence for recent African origin (a hypothesis which at the time was competing with Asian origin of \"H. sapiens\").\n\nBy 1985, data from the mtDNA of 145 women of different populations, and of two cell lines, HeLa and GM 3043, derived from a Black American and a !Kung respectively, was available. After more than 40 revisions of the draft, the manuscript was submitted to \"Nature\" in late 1985 or early 1986 and published on 1 January 1987. The published conclusion was that all current human mtDNA originated from a single population from Africa, at the time dated to between 140,000 and 200,000 years ago.\n\nThe dating for \"Eve\" was a blow to the multiregional hypothesis, which was being controversially discussed at the time, and a boost to the theory of the recent origin model.\n\nCann, Stoneking and Wilson did not use the term \"Mitochondrial Eve\" or even the name \"Eve\" in their original paper; it appears to originate with a 1987 article in \"Science\" by Roger Lewin, headlined \"The Unmasking of Mitochondrial Eve.\"\nThe biblical connotation was very clear from the start. The accompanying research news in \"Nature\" had the title \"Out of the garden of Eden.\" \nWilson himself preferred the term \"Lucky Mother\" and thought the use of the name Eve \"regrettable.\"\nBut the concept of Eve caught on with the public and was repeated in a \"Newsweek\" cover story (11 January 1988 issue featured a depiction of Adam and Eve on the cover, with the title \"The Search for Adam and Eve\"), and a cover story in \"Time\" on 26 January 1987.\n\nShortly after the 1987 publication, criticism of its methodology and secondary conclusions was published.\nBoth the dating of mt-Eve and the relevance of the age of the purely matrilineal descent for population replacement was controversially discussed during the 1990s;\nAlan Templeton (1997) asserted that the study did \"not support the hypothesis of a recent African origin for all of humanity following a split between Africans and non-Africans 100,000 years ago\" and also did \"not support the hypothesis of a recent global replacement of humans coming out of Africa.\"\n\n's placement of a relatively small population of humans in sub-Saharan Africa was consistent with the hypothesis of Cann (1982) and lent considerable support for the \"recent out-of-Africa\" scenario.\n\nIn 1999 Krings et al. eliminated problems in molecular clocking postulated by Nei (1992) when it was found that the mtDNA sequence for the same region was substantially different from the MRCA relative to any human sequence.\n\nAlthough the original research did have analytical limitations, the estimate on the age of the mt-MRCA has proven robust. More recent age estimates have remained consistent with the 140–200 kya estimate published in 1987: A 2013 estimate dated Mitochondrial Eve to about 160 kya (within the reserved estimate of the original research) and Out of Africa II to about 95 kya.\nAnother 2013 study (based on genome sequencing of 69 people from 9 different populations) reported the age of Mitochondrial Eve between 99 to 148 kya and that of the Y-MRCA between 120 and 156 kya.\n\nWithout a DNA sample, it is not possible to reconstruct the complete genetic makeup (genome) of any individual who died very long ago. By analysing descendants' DNA, however, parts of ancestral genomes are estimated by scientists. Mitochondrial DNA (mtDNA) and Y-chromosome DNA are commonly used to trace ancestry in this manner. mtDNA is generally passed un-mixed from mothers to children of both sexes, along the maternal line, or matrilineally. Matrilineal descent goes back to our mothers, to their mothers, until all female lineages converge.\n\nBranches are identified by one or more unique markers which give a mitochondrial \"DNA signature\" or \"haplotype\" (e.g. the CRS is a haplotype). Each marker is a DNA base-pair that has resulted from an SNP mutation. Scientists sort mitochondrial DNA results into more or less related groups, with more or less recent common ancestors. This leads to the construction of a DNA family tree where the branches are in biological terms clades, and the common ancestors such as Mitochondrial Eve sit at branching points in this tree. Major branches are said to define a haplogroup (e.g. CRS belongs to haplogroup H), and large branches containing several haplogroups are called \"macro-haplogroups\".\n\nThe mitochondrial clade which Mitochondrial Eve defines is the species \"\" itself, or at least the current population or \"chronospecies\" as it exists today. In principle, earlier Eves can also be defined going beyond the species, for example one who is ancestral to both modern humanity and Neanderthals, or, further back, an \"Eve\" ancestral to all members of genus \"\" and chimpanzees in genus \"\". According to current nomenclature,\nMitochondrial Eve's haplogroup was within mitochondrial haplogroup L because this macro-haplogroup contains all surviving human mitochondrial lineages today, and she must predate the emergence of L0.\n\nThe variation of mitochondrial DNA between different people can be used to estimate the time back to a common ancestor, such as Mitochondrial Eve. This works because, along any particular line of descent, mitochondrial DNA accumulates mutations at the rate of approximately one every 3,500 years per nucleotide. A certain number of these new variants will survive into modern times and be identifiable as distinct lineages. At the same time some branches, including even very old ones, come to an end, when the last family in a distinct branch has no daughters.\n\nMitochondrial Eve is the most recent common matrilineal ancestor for all modern humans. Whenever one of the two most ancient branch lines dies out, the MRCA will move to a more recent female ancestor, always the most recent mother to have more than one daughter with living maternal line descendants alive today. The number of mutations that can be found distinguishing modern people is determined by two criteria: firstly and most obviously, the time back to her, but secondly and less obviously by the varying rates at which new branches have come into existence and old branches have become extinct. By looking at the number of mutations which have been accumulated in different branches of this family tree, and looking at which geographical regions have the widest range of least related branches, the region where Eve lived can be proposed.\n\n\"Newsweek\" reported on Mitochondrial Eve based on the Cann \"et al.\" study in January 1988, under a heading of \"Scientists Explore a Controversial Theory About Man's Origins\". The edition sold a record number of copies.\n\nThe popular name \"mitochondrial Eve\", of 1980s coinage, has contributed to a number of popular misconceptions. At first, the announcement of a \"mitochondrial Eve\" was even greeted with endorsement from young earth creationists, who viewed the theory as a validation of the biblical creation story.\n\nDue to such misunderstandings, authors of popular science publications since the 1990s have been emphatic in pointing out that the name is merely a popular convention, and that the mt-MRCA was not in any way the \"first woman\". Her position is purely the result of genealogical history of human populations later, and as matrilineal lineages die out, the position of mt-MRCA keeps moving forward to younger individuals over time.\n\nIn \"River Out of Eden\" (1995), Richard Dawkins discussed human ancestry in the context of a \"river of genes\", including an explanation of the concept of Mitochondrial Eve.\n\"The Seven Daughters of Eve\" (2002) presented the topic of human mitochondrial genetics to a general audience.\n\"The Real Eve: Modern Man's Journey Out of Africa\" by Stephen Oppenheimer (2003) was adapted into a Discovery Channel documentary.\n\nOne common misconception surrounding mitochondrial Eve is that since all women alive today descended in a direct unbroken female line from her, she must have been the only woman alive at the time. However, nuclear DNA studies indicate that the size of the ancient human population never dropped below tens of thousands. Other women living during Eve's time may have descendants alive today but not in a direct female line.\n\nThe definition of mitochondrial Eve is fixed, but the woman in prehistory who fits this definition can change. That is, not only can our knowledge of when and where Mitochondrial Eve lived change due to new discoveries, but the actual mitochondrial Eve can change. The mitochondrial Eve can change, when a mother-daughter line comes to an end by chance. It follows from the definition of Mitochondrial Eve that she had at least two daughters who both have unbroken \"female\" lineages that have survived to the present day. In every generation mitochondrial lineages end – when a woman with unique mtDNA dies with no daughters. When the mitochondrial lineages of daughters of mitochondrial Eve die out, then the title of \"Mitochondrial Eve\" shifts forward from the remaining daughter through her matrilineal descendants, until the first descendant is reached who had two or more daughters who together have all living humans as their matrilineal descendants. Once a lineage has died out it is irretrievably lost and this mechanism can thus only shift the title of \"Mitochondrial Eve\" forward in time.\n\nBecause mtDNA mapping of humans is very incomplete, the discovery of living mtDNA lines which predate our current concept of \"Mitochondrial Eve\" could result in the title moving to an earlier woman. This happened to her male counterpart, \"Y-chromosomal Adam,\" when older Y lines from Africa were discovered.\n\nSometimes mitochondrial Eve is assumed to have lived at the same time as Y-chromosomal Adam (from whom all living people are descended patrilineally), and perhaps even met and mated with him. Even if this were true, which is currently regarded as highly unlikely, this would only be a coincidence. Like mitochondrial \"Eve\", Y-chromosomal \"Adam\" probably lived in Africa. A recent study (March 2013) concluded however that \"Eve\" lived much later than \"Adam\" – some 140,000 years later. (Earlier studies considered, conversely, that \"Eve\" lived earlier than \"Adam\".) More recent studies indicate that mitochondrial Eve and Y-chromosomal Adam may indeed have lived around the same time.\n\nMitochondrial Eve is the most recent common \"matrilineal\" ancestor, not the \"most recent common ancestor\". Since the mtDNA is inherited maternally and recombination is either rare or absent, it is relatively easy to track the ancestry of the lineages back to a MRCA; however, this MRCA is valid only when discussing mitochondrial DNA. An approximate sequence from newest to oldest can list various important points in the ancestry of modern human populations:\n\n\n\n"}
{"id": "52510", "url": "https://en.wikipedia.org/wiki?curid=52510", "title": "Mores", "text": "Mores\n\nMores ( sometimes ; from Latin \"mōrēs\", , plural form of singular \"mōs\", meaning 'manner, custom, usage, or habit') was introduced from English into American English by William Graham Sumner (1840–1910), an early U.S. sociologist, to refer to social norms that are widely observed and are considered to have greater moral significance than others. Mores include an aversion for societal taboos, such as incest. The mores of a society usually predicate legislation prohibiting their taboos. Often, countries will employ specialized vice squads or vice police engaged in suppressing specific crimes offending the societal mores.\n\nFolkways, in sociology, are norms for routine or casual interaction. This includes ideas about appropriate greetings and proper dress in different situations.\n\nIn short, mores \"distinguish the difference between right and wrong, while folkways draw a line between right and rude\".\n\nBoth \"mores\" and \"folkways\" are terms coined by William Graham Sumner in 1906.\n\nThe English word morality comes from the same Latin root \"mōrēs\", as does the English noun \"moral\". However, mores do not, as is commonly supposed, necessarily carry connotations of morality. Rather, morality can be seen as a subset of mores, held to be of central importance in view of their content, and often formalized in some kind of moral code.\n\nThe Greek terms equivalent to Latin \"mores\" are \"ethos\" (ἔθος, ἦθος, 'character') or \"nomos\" (νόμος, 'law'). As with the relation of \"mores\" to \"morality\", \"ethos\" is the basis of the term \"ethics\", \"nomos\" give the suffix \"-onomy\", as in astronomy.\n\nThe meaning of all these terms extend to all customs of proper behavior in a given society, both religious and profane, from more trivial conventional aspects of custom, etiquette or politeness—\"folkways\" enforced by gentle social pressure, but going beyond mere \"folkways\" or conventions in including moral codes and notions of justice—down to strict taboos, behavior that is unthinkable within the society in question, very commonly including incest and murder, but also the commitment of outrages specific to the individual society such as blasphemy. Such religious or sacral customs may vary.\n\nWhile cultural universals are by definition part of the \"mores\" of every society (hence also called \"empty universals\"), the customary norms specific to a given society are a defining aspect of the cultural identity of an ethnicity or a nation. Coping with the differences between two sets of cultural conventions is a question of intercultural competence.\n\nDifferences in the \"mores\" of various nations are at the root of ethnic stereotype, or in the case of reflection upon one's own \"mores\", autostereotypes.\n\n"}
{"id": "46286632", "url": "https://en.wikipedia.org/wiki?curid=46286632", "title": "Onion model", "text": "Onion model\n\nThe onion model is a graph-based diagram template for describing an expanding or extending relationship between several concepts. The name is a metaphor of the layered shells that become visible when you cut open an onion. The outer layers in the model typically add size or complexity incrementally to the central layers.\n\nThe onion diagram can be presented as an Euler diagram or a stacked Venn diagram. For the record, a stacked Venn contains a series of sets A...A where each set A is a strict subset of A (and by recursion, of all A where m > n). However, as the onion is often used as a metaphor, it doesn't necessarily make sense to interpret the contents of an onion diagram literally or mathematically. \n\nThis diagram format is supported e.g. by Microsoft PowerPoint's SmartArt wizard under the name of \"stacked Venn\".\n\nThe onion model in computing is used as a metaphor for the complex structure of information systems. The system is split into layers to make it easier to understand. A simple example is to start with the program, operating system and hardware layers. Each of these layers can then be subdivided. \n\n"}
{"id": "42994803", "url": "https://en.wikipedia.org/wiki?curid=42994803", "title": "Perceptual load theory", "text": "Perceptual load theory\n\nNilli Lavie presented the perceptual load theory in the mid-nineties as a potential resolution to the early/late selection debate. This debate can be summated through two questions, firstly; when in the information processing stream does attention select target information? Secondly; to what degree do distractor stimuli get processed? Prior to Lavie’s theory there were several other suggestions as to how targets are perceived amongst distractor stimuli.\n\nResearcher’s such as Donald Broadbent argued that selection occurs during the early stages of processing by suggesting that information has to go through a sensory filter, and as that filter has a limited capacity all information that is not directly attended to will decay. Whilst researchers such as Deutsch and Deutsch argued that this filtering of irrelevant stimuli occurs in the late stages of processing, in that, all of the information is processed on a sensory level but just before the level of working memory the semantic content of the message is the filter. \nLavie attempts to resolve this debate by stating that both early and late selection occur varying on the stimulus presented.\n\nFrom the perspective of perceptual load theory stimulus variation means whether the stimulus has high or low perceptual load. Perceptual load refers to the complexity of the physical stimuli, particularly the distractor stimuli e.g. a square surrounded by circles is a scene with low perceptual load whereas a square surrounded by lots of different shapes has high perceptual load. Due to the assumed limited capacity of attentional resources and that distractors have to be processed before the target it is suggested that, in high load tasks the targets attentional resources are depleted faster therefore being able to attend to the target sooner compared to a low load task. This is because the low load task needs to process more of the distractors to exhaust mental resources, therefore the distractors cause a greater inference in finding the target. This demonstrates that selection occurs both in the early stages of processing (high load condition) when the degree of inference is low as the majority of the resources process the target and enables the individual to ignore distractors. As well as the late stages (low load condition) when the distractors are perceived because they take up fewer attentional resources and as such spill over to the distractors which results in them being perceived, causing an interference.\n\nPerceptual load theory makes three main assumptions, these are;\n\n\nTherefore, if the task-relevant stimulus uses all of the attentional resources then none of the task-irrelevant stimuli (distractors) will be processed.\n\nIn spite of the collection of research that has accumulated over the 90’s and early 2000’s there has been a counter argument posited by Lavie’s PhD supervisor, Tsal Yehoshua. However, it should be noted that in spite of the relevance of Tsal’s critique some of the first critiques to the perceptual load theory pointed out how a visual cue can eliminate the inference effect supposedly created by perceptual load.\n\nPrimarily; the critique that Tsal makes is that perceptual load theory is not a solution to the early selection versus late selection debate but rather is purely an early selection model. The suggested reason that causes the inference rates to change between simple versus complex displays is dilution not load. Meaning that the high load condition has lower inference because the higher number/more complex distractors, not because of perceptual load. This was tested in a series of experiments which took the classic perceptual load experiments and added a new condition, the dilution condition. The way this condition varied is that it makes the distractors in the task the same colour, and making that colour differ from the target letter. This creates a condition that is low in load, and high in dilution and thus isolates dilution as a variable. The result of this manipulation was not that of a higher inference rate in low perceptual load conditions comparative to high as seen in the original perceptual load experiments. Rather that inference levels were significantly lower in the low load and dilution conditions compared to the high load.\n\nAnother proposed theory to explain results attained by Lavie’s original experiments is that of distractor salience. As the title suggests this theory concerns the salience, or prominence, of a distractor as being the primary factor in inducing these results instead of load. By manipulating the onset versus offset of the distractor, research displayed the effect of salience on selective information. In this research onset and offset differed in terms of when the distractor was presented, either simultaneously with the singleton search task (onset) or having it appear with a fixation point before the task (offset). This resulted in an inference effect on reaction times when searching for the target in the onset condition regardless of whether the trial was a high load trial or a low load trial. This demonstrates that the effect seen in Lavie’s work is not as a result of load manipulation, but of distractor salience.\n\nThere are also some crucial methodological issues with perceptual load theory research pertaining to experimental design. Specifically, the use of a blocked design compared to a mixed design in the experiments. In this case, blocked experimental design is when all of the trials with either low or high perceptual load are carried out sequentially within a block of trials. Whereas, a mixed experimental design has combination of both low and high perceptual load trials that are randomly intermixed within a block of trials. The issue with using a blocked design is that the repetition of the same experimental condition can allow for attention to be localised in one particular spot. Research has shown that when conducting a perceptual load task under a mixed design there is no significant difference in interference between low load and high load conditions. Therefore, suggesting that when the trials are blocked it is not perceptual load that causes the difference in interference rather how localised the participants field of attention was. This has since been expanded and developed by and be coined as ‘Attentional Zoom’.\n\nAs previously discussed attentional zoom was coined by researchers Zhe Chen and Kyle Cave as an alternative explanation to the results seen in perceptual load theory. The pair also critique other attempts into understanding the data presented by perceptual load theory, such as dilution. Attentional zoom theory states that participants can process distractors when they are within their attentional focus. So when an individual is induced to have a small attentional focus and the distractors fall outside of them. Likewise for a larger attentional focus that incorporates distractors a higher level of inference is seen. This can be demonstrated as separate from dilution as in dilution through luminance decrease had no effect on distractor processing whilst being cued as to whether a target would appear in either one of two locations or one of six did. According to dilution theory the two trials should be show similar levels of inference regardless of cueing, however, what this experiment reveals is that when cued for two locations the attentional focus of the participants narrowed, thus reducing the effect of the distractor as it was outside the attentional view. Whereas, when the target was cued for six the attentional focus was forced to widen and as such the distractor could be processed causing an inference effect.\n\n"}
{"id": "229146", "url": "https://en.wikipedia.org/wiki?curid=229146", "title": "Propositional function", "text": "Propositional function\n\nIn propositional calculus, a propositional function is a sentence expressed in a way that would assume the value of true or false, except that within the sentence there is a variable (\"x\") that is not defined or specified, which leaves the statement undetermined. The sentence may contain several such variables (e.g. \"n\" variables, in which case the function takes \"n\" arguments).\n\nAs a mathematical function, \"A\"(\"x\") or \"A\"(\"x\", \"x\", ..., \"x\"), the propositional function is abstracted from predicates or propositional forms. As an example, let's imagine the predicate, \"x is hot\". The substitution of any entity for \"x\" will produce a specific proposition that can be described as either true or false, even though \"\"x\" is hot\" on its own has no value as either a true or false statement. However, when you assign \"x\" a value, such as lava, the function then has the value \"true\"; while if you assign \"x\" a value like ice, the function then has the value \"false\".\n\nPropositional functions are useful in set theory for the formation of sets. For example, in 1903 Bertrand Russell wrote in The Principles of Mathematics (page 106):\n\nLater Russell examined the problem of whether propositional functions were predicative or not, and he proposed two theories to try to get at this question: the zig-zag theory and the ramified theory of types.\n\nA Propositional Function, or a predicate, in a variable \"x\" is a sentence \"p\"(\"x\") involving \"x\" that becomes a proposition when we give \"x\" a definite value from the set of values it can take.\n\nAccording to Clarence Lewis, \"A proposition is any expression which is either true or false; a propositional function is an expression, containing one or more variables, which becomes a proposition when each of the variables is replaced by some one of its values.\" Lewis used the notion of propositional functions to introduce relations, for example, a propositional function of \"n\" variables is a relation of arity \"n\". The case of \"n\" = 2 corresponds to binary relations, of which there are homogeneous relations (both variables from the same set) and heterogeneous relations.\n\n"}
{"id": "41496", "url": "https://en.wikipedia.org/wiki?curid=41496", "title": "Pseudo bit error ratio", "text": "Pseudo bit error ratio\n\nPseudo bit error ratio (PBER) in adaptive high-frequency (HF) radio, is a bit error ratio derived by a majority decoder that processes redundant transmissions. \n\n\"Note:\" In adaptive HF radio automatic link establishment, PBER is determined by the extent of error correction, such as by using the fraction of non-unanimous votes in the 2-of-3 majority decoder. \n"}
{"id": "28074705", "url": "https://en.wikipedia.org/wiki?curid=28074705", "title": "Ribbon theory", "text": "Ribbon theory\n\nRibbon theory is a strand of mathematics within topology that has seen particular application as regards DNA.\n\n\nWork by Călugăreanu, White and Brock Fuller led to the Călugăreanu–White–Fuller theorem that Link = Writhe + Twist.\n\n\n"}
{"id": "46373766", "url": "https://en.wikipedia.org/wiki?curid=46373766", "title": "Rubicon model (psychology)", "text": "Rubicon model (psychology)\n\nIn psychological theories of motivation, the Rubicon model, more completely the Rubicon model of action phases, makes a distinction between motivational and volitional processes. The Rubicon model \"defines clear boundaries between motivational and action phases\". The first boundary \"separates the motivational process of the predecisional phase from the volitional processes of postdecisional phase.\" Another boundary is that between initiation and conclusion of an action. A self-regulatory feedback model incorporating these interfaces was proposed later by others, as illustrated in the figure.\n\nThe name \"Rubicon model\" derives from the tale of Caesar's crossing the Rubicon River, a point of no return, thereby revealing his intentions. According to the Rubicon model, every action includes such a point of no return at which the individual moves from goal setting to goal striving.\n\nThe Rubicon model addresses four questions, as identified by Achtziger and Gollwitzer:\n\nThe study of these issues is undertaken by both the fields of cognitive neuroscience and social psychology. A possible connection between these approaches is brain imaging work attempting to relate volition to neuroanatomy.\n\nHuman action coordinates such aspects of human behavior as perception, thought, emotion, and skills to classify goals as attainable or unattainable and then to engage or disengage in trying to attain these goals. According to Heckhausen & Heckhausen, \"Research based on the Rubicon model of action phases has provided a wealth of empirical evidence for mental and behavioral resources being orchestrated in this manner.\" Engagement and disengagement with goals affects personal distress over the unachievable. \"By having new goals available, and reengaging in those new goals, a person can reduce distress...while continuing to derive a sense of purpose in life by finding other pursuits of value.\"\n\n"}
{"id": "27004907", "url": "https://en.wikipedia.org/wiki?curid=27004907", "title": "Sabine Pigalle", "text": "Sabine Pigalle\n\nSabine Pigalle is a French photographer and an artist. She was born in Rouen in France in 1963, and now lives and works in Paris. Sabine studied at Sorbonne University and worked with Helmut Newton for 4 years focusing on fashion photography before moving on to more personal project.\nMost of her work concentrates on the reinterpretation of myths. Religious history, mythology, Flemish primitives painters and also mannerism provide both the varied sources of her inspiration and the raw materials for artistic explorations.\nSabine Pigalle produces hybrid photographs in different series, mainly dedicated to the art of portraiture, that combine the contemporary with references to ancient art.\n\nFind below of the different exhibitions held by Sabine Pigalle:\n\n\n\n"}
{"id": "3975854", "url": "https://en.wikipedia.org/wiki?curid=3975854", "title": "Sensory neuroscience", "text": "Sensory neuroscience\n\nSensory neuroscience is a subfield of neuroscience which explores the anatomy and physiology of neurons that are part of sensory systems such as vision, hearing, and olfaction. Neurons in sensory regions of the brain respond to stimuli by firing one or more nerve impulses (action potentials) following stimulus presentation. How is information about the outside world encoded by the rate, timing, and pattern of action potentials? This so-called neural code is currently poorly understood and sensory neuroscience plays an important role in the attempt to decipher it. Looking at early sensory processing is advantageous since brain regions that are \"higher up\" (e.g. those involved in memory or emotion) contain neurons which encode more abstract representations. However, the hope is that there are unifying principles which govern how the brain encodes and processes information. Studying sensory systems is an important stepping stone in our understanding of brain function in general. \n\nA typical experiment in sensory neuroscience involves the presentation of a series of relevant stimuli to an experimental subject while the subject's brain is being monitored. This monitoring can be accomplished by noninvasive means such as functional magnetic resonance imaging (fMRI) or electroencephalography (EEG), or by more invasive means such as electrophysiology, the use of electrodes to record the electrical activity of single neurons or groups of neurons. fMRI measures changes in blood flow which related to the level of neural activity and provides low spatial and temporal resolution, but does provide data from the whole brain. In contrast,\nElectrophysiology provides very high temporal resolution (the shapes of single spikes can be resolved) and data can be obtained from single cells. This is important since computations are performed within the dendrites of individual neurons.\n\nIn most of the central nervous system, neurons communicate exclusively by sending each other action potentials, colloquially known as \"spikes\". It is therefore thought that all of the information a sensory neuron encodes about the outside world can be inferred by the pattern of its spikes. Current experimental techniques cannot measure individual spikes noninvasively.\n\nA typical single neuron experiment will consist of isolating a neuron (that is, navigating the neuron until the experimentor finds a neuron which spikes in response to the type of stimulus to be presented, and (optionally) determining that all of the spikes observed indeed come from a single neuron), then presenting a stimulus protocol. Because neural responses are inherently variable (that is, their spiking pattern may depend on more than just the stimulus which is presented, although not all of this variability may be true noise, since factors other than the presented stimulus may affect the sensory neuron under study), often the same stimulus protocol is repeated many times to get a feel for the variability a neuron may have. One common analysis technique is to study the neuron's average time-varying firing rate, called its post stimulus time histogram or PSTH.\n\nOne major goal of sensory neuroscience is to try to estimate the neuron's receptive field; that is, to try to determine which stimuli cause the neuron to fire in what ways. One common way to find the receptive field is to use linear regression to find which stimulus characteristics typically caused neurons to become excited or depressed. Since the receptive field of a sensory neuron can vary in time (i.e. latency between the stimulus and the effect it has on the neuron) and in some spatial dimension (literally space for vision and somatosensory cells, but other \"spatial\" dimensions such as the frequency of a sound for auditory neurons), the term spatio temporal receptive field or STRF is often used to describe these receptive fields.\n\nOne recent trend in sensory neuroscience has been the adoption of natural stimuli for the characterization of sensory neurons. There is good reason to believe that there has been evolutionary pressure on sensory systems to be able to represent natural stimuli well, so sensory systems may exhibit the most relevant behaviour in response to natural stimuli. The adoption of natural stimuli in sensory neuroscience has been slowed by the fact that the mathematical descriptions of natural stimuli tend to be more complex than of simplified artificial stimuli such as simple tones or clicks in audition or line patterns in vision. Free software is now available to help neuroscientists interested in estimating receptive fields cope with the difficulty of using natural stimuli.\n\nSensory neuroscience is also used as a bottom-up approach to studying consciousness. For example, visual sense and representation has been studied by Crick and Koch (1998), and experiments have been suggested in order to test various hypotheses in this research stream.\n\n"}
{"id": "26984740", "url": "https://en.wikipedia.org/wiki?curid=26984740", "title": "SmartDraw", "text": "SmartDraw\n\nSmartDraw is a diagram tool used to make flowcharts, organization charts, mind maps, project charts, and other business visuals. SmartDraw has two versions: an online edition and a downloadable edition for Windows desktop.\n\nSmartDraw integrates with Microsoft Office products including Word, PowerPoint, and Excel and G Suite applications like Google Docs and Google Sheets. \n\nSmartDraw also has apps for Atlassian's Confluence, Jira, and Trello.\n\nSmartDraw is compatible with Google Drive, Dropbox, Box, and OneDrive.\n\nThe following file extensions are specific to SmartDraw:\n\n"}
{"id": "316058", "url": "https://en.wikipedia.org/wiki?curid=316058", "title": "Subjective theory of value", "text": "Subjective theory of value\n\nThe subjective theory of value is a theory of value which advances the idea that the value of a good is not determined by any inherent property of the good, nor by the amount of labor necessary to produce the good, but instead value is determined by the importance an acting individual places on a good for the achievement of his desired ends. The modern version of this theory was created independently and nearly simultaneously by William Stanley Jevons, Léon Walras, and Carl Menger in the late 19th century.\n\nAccording to the subjective theory of value, voluntary trades between individuals imply that both parties to the trade subjectively perceive the goods, labour or money they receive as being of higher value to the goods, labour or money they give away. The subjective-value theory holds that one can create value simply by transferring ownership of a thing to someone who values it more highly, without necessarily modifying that thing. Where wealth is understood to refer to individuals' subjective valuation of their possessions, voluntary trades may increase the total wealth in society.\n\nIndividuals will tend to obtain diminishing levels of satisfaction, or marginal utility from acquiring additional units of a good. They will initially prioritise obtaining the goods they most need, such as sufficient food, but once their need for food is satisfied up to a certain level, their desire for other goods will start to assume more relative importance, and they will seek to bring satisfaction of their need for food into satisfaction of their need for other goods.\n\nIn a free market, competition between individuals seeking to trade goods they possess and services they can provide for goods they perceive as being of higher value to them results in a market equilibrium set of prices emerging. \n\nClassical economists such as David Ricardo believed that individual people obtain different levels of utility or 'value in use' from a service, but did not effectively connect those with market prices, or 'value in exchange', seeing them as separately derived from the quantity of labour input and other production factors. \nCarl Menger argued that production was simply another case of the theory of marginal utility. Labourers' wage-earning potential is set by the value of their work to others rather than subsistence costs, and they work because they value remuneration more highly than inactivity.\n\nAlbert Einstein disagreed saying, \"The economic anarchy of capitalist society as it exists today is, in my opinion, the real source of [society's] evil... The owner of the means of production is in a position to purchase the labor power of the worker. By using the means of production, the worker produces new goods which become the property of the capitalist. The essential point about this process is the relation between what the worker produces and what he is paid, both measured in terms of real value. In so far as the labor contract is \"free,\" what the worker receives is determined not by the real value of the goods he produces, but by his minimum needs and by the capitalists' requirements for labor power in relation to the number of workers competing for jobs. It is important to understand that even in theory the payment of the worker is not determined by the value of his product.\"\n\nThe development of the subjective theory of value was partly motivated by the need to solve the value-paradox which had puzzled many classical economists. This paradox, also referred to descriptively as the diamond-water paradox, arose when value was attributed to things such as the amount of labor that went into the production of a good or alternatively to an objective measure of the usefulness of a good. The theory that it was the amount of labor that went into producing a good that determined its value proved equally futile because someone could stumble upon the discovery of a diamond while out for a hike, for example, which would require minimal labor, but yet the diamond could still be valued higher than water.\n\nThe subjective theory of value was able to solve this paradox by realizing that value is not determined by individuals choosing between entire abstract classes of goods, such as all the water in the world versus all the diamonds in the world. Rather an acting individual is faced with the choice between definite quantities of goods, and the choice made by such an actor is determined by which good of a specified quantity will satisfy the individual's highest subjectively ranked preference, or most desired end.\n\n"}
{"id": "44282667", "url": "https://en.wikipedia.org/wiki?curid=44282667", "title": "Symbolic self-completion theory", "text": "Symbolic self-completion theory\n\nThe theory of symbolic self-completion is a psychological theory which holds that individuals seek to acquire and display symbols that are strongly related to what they perceive as the ideal self. For example, relatively effeminate boys who want to appear macho may use products associated with manliness—such as a strong cologne or a silver watch—in hopes of symbolically fulfilling their self-definitions, i.e. becoming manly. Such cases of symbolic self-completion are seen in internet communication, marketing and advertising, and consumer behavior.\n\nThe theory of symbolic self-completion has its origins in the symbolic interactionist school of thought. As expressed by George Mead in \"Mind, Self and Society\", symbolic interactionism suggests that the self is defined by the way that society responds to the individual. This idea helped shape the central ideas put forth in the book \"Symbolic Self-Completion\", which states that individuals tend to define themselves using symbols of accomplishment and that they use symbols to communicate their self-definitions to society. Depending on the area of self-definition to which these symbols pertain, a different self-definition is thus exhibited.\n\n\"Self-definitional symbols\" are the objects that individuals use to communicate their self-definitions to society. Symbols can be both material and non-material, including anything ranging from utterances, behaviors, and socially recognized markers such as material possessions and social status. They are defined as \"any facet of the person that has the potential to signal to others (who understand the symbol as related to the identity) that one possesses the identity in question.\" Because it is through these symbols that individuals build their self-definitions around and communicate them to society, symbols are “the building blocks of self-definition.” Thus, symbols are meaningful to individuals only insofar as they adequately represent individuals’ self-definitions, regarding the status of accomplishment in the areas individuals believe are important to their self-definitions. When individuals lack symbols to express their self-definitions, they seek to “display alternative symbols of attainment.”\n\nResearch has shown that when individuals are deficient in any self-definitional area, this deficiency produces a state of tension and a sense of incompleteness in their self-definitions. Individuals are motivated to reduce this tension by using alternate symbols of accomplishment in the relevant self-definitional area. In the study “Symbolic Self-completion, Attempted Influence, and Self-Deprecation,” Robert Wicklund, Peter Gollwitzer and James Hilton asked participants to 1) write an essay teaching people how to perform an activity important to them and then 2) indicate how many people should be required to revise their essays. Results of this study showed that the fewer the years of education or experience participants seemed to have in their respective activities, the higher the number of people participants thought should be required to revise their essays. The higher this number was, the more participants put themselves in a position to influence others; researchers interpreted this relationship as a means of symbolic compensation for lacking the relevant self-definitional area.\n\nAn additional part of this study asked a group of men to make a statement about their ability in the self-definitional area. Results of this part of the study showed that the less education and experience the men had, the less willing they were to provide a negative evaluation of themselves. This behavior remained consistent, even when the men were told that the attractive female confederate preferred men who were critical of themselves. This finding shows people are willing to self-symbolize even when they know the self-symbolizing behavior will be negatively received by society. Such findings indicate that individuals are more concerned with whether their behaviors will be reflective of their self-definitions than with whether the behaviors induce positive or negative judgments from others. Altogether, these findings indicate that “influencing others, as well as positive self-descriptions, can further the individual’s sense of having a complete self-definition.”\n\nIndividuals' self-definitions can change for purposes of self-esteem protection and maintenance. These changes are likely to occur in consideration of the \"relative performance and the psychological\nsimilarity (closeness) and dissimilarity (distance) of others.\" Certain dimensions of individuals' self-definitions can become \"less self-definitional\" when others who are psychologically similar to them outperforms them in those areas. As such, self-definitions lend themselves to change—however, individuals may opt to strengthen their self-definitions in the face of self-definitional threats. \"Self-definitional threat\" refers to a situation in which individuals feel their identities are uncertain or threatened or they feel insecure in an identity they are committed to. In such cases, individuals are more likely to value symbols that reinforce those identities.\n\nThe study “Reactions to self-discrepant feedback: Feminist attitude and symbolic self-completion” shows how a threat to one’s identity also motivates individuals to engage in symbolic self-completion as a means of reducing the tension it causes. The researchers Rudolf Schiffmann and Doris Nelkenbrecher asked a group of feminist participants to subscribe to a feminist journal after being given feedback on their feminist attitudes. The women who were described as less feminist were more likely to subscribe to the feminist journal as a means of symbolically “completing” their self-definition.\n\nRelated to this study is \"Psychological Antecedents of Conspicuous Consumption\" by Ottmar L. Braun and Wicklund. This study was conducted in six separate studies, the first of which involved interviews of law students and attorneys. This first part of the study found that law students were more likely than practicing attorneys to think that it is important to have the \"outward manifestations of an attorney,\" supporting the idea that individuals \"striving toward a particular identity\" and are \"more inexperienced in that identity realm\" are more prone to claim that they \"can be recognized as belonging to that identity.\"\n\nMore recent studies have shown how symbolic self-completion influences individuals' communication in online media platforms. For example, Cindy and Eddie Harmon-Jones and Brandon Schmeichel have shown how individuals’ need for self-definition affects whether they share symbols of self-definitional attainment online. These researchers examined academic web pages and email signature files to see what types of academic departments and professors were more likely to enlist professional titles. The researchers found that the lower an academic department was ranked within National Research Council Rankings, the higher the number of professional titles the professors in that department displayed in their websites. Similarly, the lower the annual rate of publications and citations professors seemed to have, the higher the number of professional titles they enlisted in their email signatures. These correlations suggest that the enlistment of professional titles online serve as alternate symbols of accomplishment in their self-definitional areas; the more they felt they were lacking in a certain area, the more likely they were to engage in symbolic self-completion online regarding that particular area.\n\nThe theory of symbolic self-completion has direct application in the advertisement industry. The media leads consumers to equate advertised products targeting their feelings of “incompleteness” with self-definitional symbols to make up for that incompleteness. Although the symbols that each consumer ascribes to may be different in every case, these symbols as a whole can nonetheless be used to improve the individual consumers' perception of themselves. The product-symbols give some consumers a sense of completeness, since “self-perceptions are influenced by product use/ownership when the product has a strong user image and the consumer does not have a well formed self-image.” For example, a deodorant advertisement may appeal to a male consumer's self-definitional need for masculinity, by suggesting that he will become more masculine if he uses the deodorant advertised. The Old Spice brand famously uses phrases such as \"smell like a man, man\" when advertising their products. The \"Smell Like A Man, Man\" campaign led to Old Spice becoming the number one brand of deodorant. By displaying these product-symbols, consumers improve their sense of self and feel more confident about how others might perceive them.\n\nBraun and Wicklund suggest that there is a \"compensatory relation between person's security\" and certain kinds of conspicuous consumption, but that these relations cannot exist without individuals' perceived \"incompleteness [of]\" and \"commitment to the identity in question.\" Thus, much of what is colloquially referred to as the “mid-life crisis” can be explained by the theory of symbolic self-completion. A classic example of the mid-life crisis is a 40-year-old man buying a red sports car. The man is unsure as to whether he has made the right choices in his life and if he has been leading a successful career. The man then counters his insecurity by purchasing a material object that functions as a status symbol, something that both he and others will recognize as a mark of success.\n\nThe relationship between self-completion theory and materialism is further shown through individuals' tendency to externalize their concerns about their lives by acquiring symbol-objects that reinforce and improve their self-definitions. In terms of goods/objects as individuals' status symbols, greater emphasis is placed on tangible, material objects, as they can be recognized and understood as status symbols by a wider audience than are intangible and abstract ideas. In the same vein, materialism reinforces symbolic self-completion particularly in a societies that are structure in such a way that the consumption of prestigious objects is seen as the best remedy for insecurity. This reinforcement is due to the fact that in such societies, individuals see material wealth as the best source of comforting reassurance to counter insecurity\n"}
{"id": "49605051", "url": "https://en.wikipedia.org/wiki?curid=49605051", "title": "The Circumplex Model of Group Tasks", "text": "The Circumplex Model of Group Tasks\n\nThe Circumplex Model is a graphical representation of emotional states. Fundamentally, it is a circle with pleasant on the left, unpleasant on the right, activation on the top, and deactivation on the bottom. All the other emotions are placed around the circle as combinations of these four basic states. It is based on the theory that people experience emotions as overlapping and ambiguous. Group dynamics are the distinctive behaviors and attitudes observed by people in groups, and the study thereof. It is of most interest in the business world, the workforce, or any other setting where the performance of a group is important. Joseph E McGrath enlarged the circumplex model to include group dynamics, based on the work of Shaw, Carter, Hackman, Steiner, Shiflett, Taylor, Lorge, Davis, Laughlin, and others. There are four quadrants in this model representing: generating a task, choosing correct procedure, conflict resolution, and execution, and again there are subtypes distributed around the circle. He used this model as a research tool to evaluate group task performance.\n\nGroup dynamics involve the influential actions, processes and changes that exist both within and between groups. Group dynamics also involve the scientific study of group processes. Through extensive research in the field of group dynamics, it is now well known that all groups, despite their innumerable differences, possess common properties and dynamics. Social psychological researchers have attempted to organize these commonalities, in order to further understand the genuine nature of group processes.\n\nFor instance, social psychological research indicates that there are numerous goal-related interactions and activities that groups of all sizes undertake . These interactions have been categorized by Robert F. Bales, who spent his entire life attempting to find an answer to the question, \"What do people do when they are in groups?\". To simplify the understanding of group interactions, Bales concluded that all interactions within groups could be categorized as either a \"relationship interaction\" (or socioemotional interaction) or a \"task interaction\".\n\nJust as Bales was determined to identify the basic types of interactions involved in groups, Joseph E. McGrath was determined to identify the various goal-related activities that are regularly displayed by groups. McGrath contributed greatly to the understanding of group dynamics through the development of his circumplex model of group tasks. As intended, McGrath's model effectively organizes all group-related activities by distinguishing between four basic group goals. These goals are referred to as the circumplex model of group task's four quadrants, which are categorized based on the dominant performance process involved in a group's task of interest.\n\nThe four quadrants are as follows: \n\nTo further differentiate the various goal-related group activities, McGrath further sub-divides these four categories, resulting in eight categories in total. The breakdown of these categories is as follows:\n\n1. \"Generating ideas or plans\"\n2. \"Choosing a solution\"\n3. \"Negotiating a solution to a conflict\" \n4. \"Executing a task\" \n\nAccording to McGrath and Kravitz (1982), the four most commonly represented tasks in the group dynamics literature are intellective tasks, decision-making tasks, cognitive conflict tasks and mixed-motive tasks.\n\nThe circumplex model of group tasks takes the organization of goal-related activities a step further by distinguishing between tasks that involve cooperation between group members, cooperation tasks (Types 1, 2, 3 and 8) and tasks that often lead to conflict between group members, conflict tasks (Types 4, 5, 6 and 7). Additionally, McGrath's circumplex model of group tasks also distinguishes between tasks that require action (behavioural tasks) and tasks that require conceptual review (conceptual tasks). 'Behavioural tasks' include Types 1, 6, 7 and 8, while 'conceptual tasks' include Types 2, 3, 4 and 5.\n\nThe circumplex model of group tasks is, evidently, a very detailed and complex model. To allow for a more thorough understanding of its properties, a visual representation of the model has been developed. (Need a diagram of the model)\n\nSince the circumplex model of group tasks is quite detailed and complex, numerous social psychological researchers have attempted to describe the model in various ways to ensure readers obtain an optimal understanding of the model. For instance, according to Stratus and McGrath (1994), the four quadrants and the various task types with which they contain all relate to one another within a two-dimensional space. More specifically, Stratus and McGrath (1994) states that the horizontal dimension of the circumplex model of group tasks visual representation reflect the extent to which a task entails cognitive versus behavioural performance requirements. Likewise, the vertical dimension of the circumplex model of group tasks visual representation reflects the extent and form of interdependence among members.\n"}
{"id": "3017748", "url": "https://en.wikipedia.org/wiki?curid=3017748", "title": "Types of fiction with multiple endings", "text": "Types of fiction with multiple endings\n\nMultiple endings refer to a case in entertainment where the story could end in different ways.\n\n\n\n\nDVDs may include an alternate ending as a special feature. These are usually not considered canon.\n\nFilms which include multiple endings within the main cut of the film:\n\n\n\n"}
{"id": "182369", "url": "https://en.wikipedia.org/wiki?curid=182369", "title": "Whitelisting", "text": "Whitelisting\n\nWhitelisting is the practice of identifying entities that are provided a particular privilege, service, mobility, access or recognition. Entities on the list will be accepted, approved and/or recognized. Whitelisting is the reverse of blacklisting, the practice of identifying entities that are denied, unrecognised, or ostracised.\n\nSpam filters that come with email clients have both whitelists and blacklists of senders and keywords to look for in emails. If a spam filter keeps a whitelist, mail from the listed email addresses, domains email from being deleted or sent to the junk mail folder by the spam filter. Usually, only end-users would set a spam filter to delete all emails from sources not on the whitelist, not Internet service providers or email services.\n\nUsing whitelists and blacklists can assist in blocking unwanted messages and allowing wanted messages to get through, but they are not perfect. Email whitelists are used to reduce the incidence of false positives, often based on the assumption that most legitimate mail will be from a relatively small and fixed set of senders. To block a high percentage of spam, email filters have to be continuously updated as email spam senders create new email addresses to email from or new keywords to use in their email which allows the email to slip through.\n\nAmazon.com uses whitelists to limit access to its Kindle e-reader devices. Besides Amazon itself, only e-mail addresses whitelisted by the device's registered owner can send content (\"personal documents\") to that device.\n\nNon-commercial whitelists are operated by various non-profit organisations, ISPs and others interested in blocking spam. Rather than paying fees, the sender must pass a series of tests; for example, his email server must not be an open relay and have a static IP address. The operator of the whitelist may remove a server from the list if complaints are received.\n\nCommercial whitelists are a system by which an Internet service provider allows someone to bypass spam filters when sending email messages to its subscribers, in return for a pre-paid fee, either an annual or a per-message fee. A sender can then be more confident that his messages have reached their recipients without being blocked, or having links or images stripped out of them, by spam filters. The purpose of commercial whitelists is to allow companies to reliably reach their customers by email.\n\nCommercial providers include Return Path Certification, eco's Certified Senders Alliance, and the Spamhaus Whitelist.\n\nOne of the most well-publicized and controversial commercial whitelists services at present is \"CertifiedEmail\" by Goodmail Systems, which has made headlines since February 2006 when AOL and Yahoo announced plans to implement it. AOL has stated that mail from senders who qualified as legitimate senders and who have prepaid 0.10 cents per message will be delivered directly to users' mailboxes without being subject to spam filters. AOL has announced that it will pay the fee for non-profits. The messages will be clearly identified to the user as having come from a trusted source. These senders must pass a system of accreditation with Goodmail, and their messages must only be sent to people who have a pre-existing business relationship with the sender. If a sender sends a message to a user who has not previously agreed to receive it, AOL may entirely block the sender.\n\nAOL asserts that free email on AOL's service will continue to work as it always has, and a user will continue to receive all messages from a sender whom he has whitelisted. AOL subscribers will not be charged for sending or receiving email, and senders who do not prepay AOL will have their messages subject to the same spam filters as before.\n\nMoveOn organized a protest of AOL's use of commercial whitelists. It characterizes the program as an \"email tax\", and claims that AOL is giving spammers a direct route into users' mailboxes, while attempting to move more people to paid email by causing a larger amount of legitimate unpaid email to be rejected by the spam filters.\n\nCertifiedEmail has been adopted by seven of the top 10 ISPs in the USA: AOL, AT&T, Comcast, Cox, Road Runner, Verizon, and Yahoo.\n\nAccording to Comcast, Goodmail has ceased operations and as of February 4, 2011 Comcast will no longer use the service.\n\nA common form of whitelisting has emerged through internet advertisements and ad blockers. Many websites rely on ads as a source of revenue. A famous example of requiring an advertisement whitelist is Forbes. When clicking on an article from Forbes, if an ad-blocker is enabled on the browser, they require it to be disabled. In other words, Forbes requires readers to whitelist them via ad-blockers.\n\nAnother use for whitelists is local area network (LAN) security. Many network admins set up MAC address whitelists, or a MAC address filter, to control who is allowed on their networks. This is used when encryption is not a practical solution or in tandem with encryption. However, it's sometimes ineffective because a MAC address can be faked.\n\nSome firewalls can be configured to only allow data-traffic from/ to certain (ranges of) IP-addresses.\n\nIf an organization keeps a whitelist of software, only titles on the list will be accepted for use. The benefits of whitelisting in this instance are that the organization can ensure itself that users will not be able to download and/or use programs that have not been deemed appropriate for use.\n\nAn emerging approach in combating viruses and malware is to whitelist software which is considered safe to run, blocking all others. The approach was first implemented in a modern operating system by Dr. John Harrison, an American computer scientist. Some deem this superior to the standard signature-based, anti-virus approach of blocking/removing known harmful software (essentially blacklisting), as the standard approach generally means that exploits are already in the wild. Leading providers of application whitelisting technology include Bit9,Velox,McAfee, and Lumension.\n\nThese products may provide administrative control over program whitelists in addition to preventing introduction of new malware.\n\nAmong Unix Operating system variants, HP-UX has introduced a feature called \"HP-UX Whitelisting\" on 11iv3 version. HP-UX Whitelisting (WLI) offers file and system resource protection based on RSA encryption technology. WLI is complementary to the traditional UNIX discretionary access controls (DAC) based on user, group, and file permissions. The more granular DAC access control list (ACL) permissions available on VxFS and HFS file systems are likewise not affected.\n\nAmong Windows Operating systems, Microsoft has introduced a new feature in Windows 7 and Windows Server 2008 R2 called \"Windows AppLocker\". Windows AppLocker allows administrators to control which executable files are denied or allowed to execute. With AppLocker, administrators are able to create rules based on file names, publishers or file location that will allow certain files to execute. Rules can apply to individuals or groups. Policies are used to group users into different enforcement levels. For example, some users can be added to report only policy that will allow administrators to understand the impact before moving that user to a higher enforcement level.\n\nHowever, application level whitelisting is still vulnerable to a variety of attacks including those that make use of PowerShell or cross site scripting to launch scripts or inject malicious .DLLs onto an endpoint. Lower level whitelisting approaches that can monitor the specific processes and API calls are the deepest and strongest whitelist based cybersecurity solutions available today.\n\n\n"}
{"id": "41100800", "url": "https://en.wikipedia.org/wiki?curid=41100800", "title": "Writing assessment", "text": "Writing assessment\n\nWriting assessment refers to an area of study that contains theories and practices that guide the evaluation of a writer's performance or potential through a writing task. Writing assessment can be considered a combination of scholarship from composition studies and measurement theory within educational assessment. Writing assessment can also refer to the technologies and practices used to evaluate student writing and learning.\n\nWriting assessment began as a classroom practice during the first two decades of the 20th century, though high-stakes and standardized tests also emerged during this time. During the 1930s, College Board shifted from using direct writing assessment to indirect assessment because these tests were more cost-effective and were believed to be more reliable. Starting in the 1950s, more students from diverse backgrounds were attending colleges and universities, so administrators made use of standardized testing to decide where these students should be placed, what and how to teach them, and how to measure that they learned what they needed to learn. The large-scale statewide writing assessments that developed during this time combined direct writing assessment with multiple-choice items, a practice that remains dominant today across U.S. large scale testing programs, such as the SAT and GRE. These assessments usually take place outside of the classroom, at the state and national level. However, as more and more students were placed into courses based on their standardized testing scores, writing teachers began to notice a conflict between what students were being tested on—grammar, usage, and vocabulary—and what the teachers were actually teaching—writing process and revision. Because of this divide, educators began pushing for writing assessments that were designed and implemented at the local, programmatic and classroom levels. As writing teachers began designing local assessments, the methods of assessment began to diversify, resulting in timed essay tests, locally designed rubrics, and portfolios. In addition to the classroom and programmatic levels, writing assessment is also hugely influential on writing centers for writing center assessment, and similar academic support centers.\n\nBecause writing assessment is used in multiple contexts, the history of writing assessment can be traced through examining specific concepts and situations that prompt major shifts in theories and practices. Writing assessment scholars do not always agree about the origin of writing assessment.\n\nIn \"Looking Back as We Look Forward: Historicizing Writing Assessment as a Rhetorical Act,\" Kathleen Blake Yancey offers a history of writing assessment by tracing three major shifts in methods used in assessing writing. She describes the three major shifts through the metaphor of overlapping waves: \"with one wave feeding into another but without completely displacing waves that came before\". In other words, the theories and practices from each wave are still present in some current contexts, but each wave marks the prominent theories and practices of the time.\n\nThe first wave of writing assessment (1950-1970) sought objective tests with indirect measures of assessment. The second wave (1970-1986) focused on holistically scored tests where the students' actual writing began to be assessed. And the third wave (since 1986) shifted toward assessing a collection of student work (i.e. portfolio assessment) and programmatic assessment.\n\nBob Broad in \"What We Really Value\" points to the publication of \"Factors in Judgments of Writing Ability\" in 1961 by Diederich, French, and Carlton as the birth of modern writing assessment. Diederich, French, and Carlton based much of their book on research conducted through the Educational Testing Service (ETS) for the previous decade. This book is an attempt to standardize the assessment of writing and, according to Broad, created a base of research in writing assessment.\n\nYancey traces the major shifts in writing assessment by pointing toward each wave's swing toward or away from the concepts of validity and reliability. Peggy O'Neill, Cindy Moore, and Brian Huot explain in \"A Guide To College Writing Assessment\" that reliability and validity are the most important terms in discussing best practices in writing assessment.\n\nIn the first wave of writing assessment, the emphasis is on reliability: reliability confronts questions over the consistency of a test. In this wave, the central concern was to assess writing with the best predictability with the least amount of cost and work.\n\nThe shift toward the second wave marked a move toward considering principles of validity. Validity confronts questions over a test's appropriateness and effectiveness for the given purpose. Methods in this wave were more concerned with a test's construct validity: whether the material prompted from a test is an appropriate measure of what the test purports to measure. Teachers began to see an incongruence between the material being prompted to measure writing and the material teachers were asking students to write. Holistic scoring, championed by Edward M. White, emerged in this wave. It is one method of assessment where students' writing is prompted to measure their writing ability.\n\nThe third wave of writing assessment emerges with continued interest in the validity of assessment methods. This wave began to consider an expanded definition of validity that includes how portfolio assessment contributes to learning and teaching. In this wave, portfolio assessment emerges to emphasize theories and practices in Composition and Writing Studies such as revision, drafting, and process.\n\nIndirect writing assessments typically consist of multiple choice tests on grammar, usage, and vocabulary. Examples include high-stakes standardized tests such as the ACT, SAT, and GRE, which are most often used by colleges and universities for admissions purposes. Other indirect assessments, such as Compass and Accuplacer, are used to place students into remedial or mainstream writing courses. Direct writing assessments, like the timed essay test, require at least one sample of student writing and\nare viewed by many writing assessment scholars as more valid than indirect tests because they are assessing actual samples of writing. Portfolio assessment, which generally consists of several pieces of student writing written over the course of a semester, began to replace timed essays during the late 1980s and early 1990s. Portfolio assessment is viewed as being even more valid than timed essay tests because it focuses on multiple samples of student writing that have been composed in the authentic context of the classroom. Portfolios enable assessors to examine multiple samples of student writing and multiple drafts of a single essay.\n\nMethods of writing assessment vary depending on the context and type of assessment. The following is an incomplete list of writing assessments frequently administered:\n\nPortfolio assessment is typically used to assess what students have learned at the end of a course or over a period of several years. Course portfolios consist of multiple samples of student writing and a reflective letter or essay in which students describe their writing and work for the course. \"Showcase portfolios\" contain final drafts of student writing, and \"process portfolios\" contain multiple drafts of each piece of writing. Both print and electronic portfolios can be either showcase or process portfolios, though electronic portfolios typically contain hyperlinks from the reflective essay or letter to samples of student work and, sometimes, outside sources.\n\nTimed essay tests were developed as an alternative to multiple choice, indirect writing assessments. Timed essay tests are often used to place students into writing courses appropriate for their skill level. These tests are usually proctored, meaning that testing takes place in a specific location in which students are given a prompt to write in response to within a set time limit. The SAT and GRE both contain timed essay portions.\n\nA rubric is a tool used in writing assessment that can be used in several writing contexts. A rubric consists of a set of criteria or descriptions that guides a rater to score or grade a writer. The origins of rubrics can be traced to early attempts in education to standardize and scale writing in the early 20th century. Ernest C Noyes argues in November 1912 for a shift toward assessment practices that were more science-based. One of the original scales used in education was developed by Milo B. Hillegas in \"A Scale for the Measurement of Quality in English Composition by Young People\". This scale is commonly referred to as the Hillegas Scale. The Hillegas Scale and other scales used in education were used by administrators to compare the progress of schools.\n\nIn 1961, Diederich, French, and Carlton from the Educational Testing Service (ETS) publish Factors in Judgments for Writing Ability a rubric compiled from a series of raters whose comments were categorized and condensed into a five-factor rubric:\n\n\nAs rubrics began to be used in the classroom, teachers began to advocate for criteria to be negotiated with students to have students stake a claim in the how they would be assessed. Scholars such as Chris Gallagher and Eric Turley, Bob Broad, and Asao Inoue (among many) have advocated that effective use of rubrics comes from local, contextual, and negotiated criteria.\n\nMultiple-choice tests contain questions about usage, grammar, and vocabulary. Standardized tests like the SAT, ACT, and GRE are typically used for college or graduate school admission. Other tests, such as Compass and Accuplacer, are typically used to place students into remedial or mainstream writing courses.\n\nAutomated essay scoring (AES) is the use of non-human, computer-assisted assessment practices to rate, score, or grade writing tasks.\n\nSome scholars in writing assessment focus their research on the influence of race on the performance on writing assessments. Scholarship in race and writing assessment seek to study how categories of race and perceptions of race continues to shape writing assessment outcomes. However, scholars in writing assessment recognize that racism in the 21st century is no longer explicit, but point out that writing assessment practices are silently racist. Nicholas Behm and Keith D. Miller in \"Challenging the Frameworks of Color-Blind Racism: Why We Need a Fourth Wave of Writing Assessment Scholarship\" advocate for the recognition of another wave after the three that Yancey offers. Behm and Miller advocate for a wave where the intersections of race and writing assessment are brought to the forefront of assessment practices. As the authors explain, racial inequalities in writing assessment are typically justified with non-racial reasons.\n\n"}
