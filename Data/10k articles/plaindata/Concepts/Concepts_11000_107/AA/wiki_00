{"id": "27344508", "url": "https://en.wikipedia.org/wiki?curid=27344508", "title": "Abstract elementary class", "text": "Abstract elementary class\n\nIn model theory, a discipline within mathematical logic, an abstract elementary class, or AEC for short, is a class of models with a partial order similar to the relation of an elementary substructure of an elementary class in first-order model theory. They were introduced by Saharon Shelah.\n\nformula_1, for formula_2 a class of structures in some language formula_3, is an AEC if it has the following properties:\n\nNote that we usually do not care about the models of size less than the Löwenheim–Skolem number and often assume that there are none (we will adopt this convention in this article). This is justified since we can always remove all such models from an AEC without influencing its structure above the Löwenheim–Skolem number.\n\nA formula_2-embedding is a map formula_39 for formula_40 such that formula_41 and formula_42 is an isomorphism from formula_7 onto formula_44. If formula_2 is clear from context, we omit it.\n\nThe following are examples of abstract elementary classes:\n\n\nAECs are very general objects and one usually make some of the assumptions below when studying them:\n\n\nNote that in elementary classes, joint embedding holds whenever the theory is complete, while amalgamation and no maximal models are well-known consequences of the compactness theorem. These three assumptions allow us to build a universal model-homogeneous monster model formula_67, exactly as in the elementary case.\n\nAnother assumption that one can make is tameness.\n\nShelah introduced AECs to provide a uniform framework in which to generalize first-order classification theory. Classification theory started with Morley's categoricity theorem, so it is natural to ask whether a similar result holds in AECs. This is Shelah's eventual categoricity conjecture. It states that there should be a Hanf number for categoricity:\n\nFor every AEC \"K\" there should be a cardinal formula_36 depending only on formula_35 such that if \"K\" is categorical in \"some\" formula_70 (i.e. \"K\" has exactly one (up to isomorphism) model of size formula_71), then \"K\" is categorical in formula_72 for \"all\" formula_73.\n\nShelah also has several stronger conjectures: The threshold cardinal for categoricity is the Hanf number of psedo elemtary classes in a language of cardinality LS(K). More specifically when the class is in a countable language and axiomaziable by an formula_74 sentence the threshold number for categoricity is formula_75. This conjecture dates back to 1976.\n\nSeveral approximations have been published (see for example the results section below), assuming set-theoretic assumptions (such as the existence of large cardinals or variations of the generalized continuum hypothesis), or model-theoretic assumptions (such as amalgamation or tameness). As of 2014, the original conjecture remains open.\n\nThe following are some important results about AECs. Except for the last, all results are due to Shelah.\n\n\n\n"}
{"id": "51779652", "url": "https://en.wikipedia.org/wiki?curid=51779652", "title": "Access to Information Day", "text": "Access to Information Day\n\nThe International Day for the Universal Access to Information (commonly called the Access to Information Day) is an international day of recognition designated by the UNESCO General Conference to be held on September 28. The day was inaugurated in November 2015 and was first held on September 28, 2016.\n\nThe day had been recognised as International Right to Know Day since 2002 and was developed by international civil society advocates into its current form beginning in 2012. The UNESCO resolution creating the day was pushed by African civil society groups seeking greater information transparency.\n\nCurrently only 17 African Union member states have adopted national right to information laws, and groups like Open Government Partnership hope that the recognition of the right to information will \"provide an important platform for all stakeholders at national level to discuss the adoption and effective implementation of national right to information laws in line with continental and international standards and obligations.\"\n\nHowever, African civil society groups like MISA Zimbabwe have noted that states like Zimbabwe which do have Right to Information laws still have a long way to go to ensure they improve governance. In 2016, MISA Zimbabwe used Access to Information Day to criticise Zimbabwe's poor information transparency provisions, noting that, \"While Zimbabwe was one of the first African countries to adopt an access to information law in the form of the Access to Information and Protection of Privacy Act (AIPPA), the law in question is a far cry from its purported import and impact.\"\n"}
{"id": "30862640", "url": "https://en.wikipedia.org/wiki?curid=30862640", "title": "Acid throwing", "text": "Acid throwing\n\nAcid throwing, also called an acid attack, a vitriol attack or vitriolage, is a form of violent assault defined as the act of throwing acid or a similarly corrosive substance onto the body of another \"with the intention to disfigure, maim, torture, or\nkill\". Perpetrators of these attacks throw corrosive liquids at their victims, usually at their faces, burning them, and damaging skin tissue, often exposing and sometimes dissolving the bones.\n\nThe most common types of acid used in these attacks are sulfuric and nitric acid. Hydrochloric acid is sometimes used, but is much less damaging. Aqueous solutions of strongly alkaline materials, such as caustic soda (sodium hydroxide), are used as well, particularly in areas where strong acids are controlled substances.\n\nThe long term consequences of these attacks may include blindness, as well as permanent scarring of the face and body, along with far-reaching social, psychological, and economic difficulties.\n\nToday, acid attacks are reported in many parts of the world, though more likely in developing countries. Since the 1990s, Bangladesh has been reporting the highest number of attacks and highest incidence rates for women, with 3,512 Bangladeshi people acid attacked between 1999 and 2013, and in Pakistan and India acid attacks are at an all-time high and increasing every year. Although acid attacks occur all over the world, this type of violence is most common in South Asia. The UK has one of the highest rates of acid attacks per capita in the world, according to Acid Survivors Trust International (ASTI). In 2016 there were over 601 acid attacks in the UK based on ASTI figures. Over 1,200 cases were recorded over the past five years. From 2011 to 2016 there were 1,464 crimes involving acid or corrosive substance in London alone.\nThe intention of the attacker is often to humiliate rather than to kill the victim. In Britain such attacks, particularly those against men, are believed to be underreported, and as a result many of them do not show up in official statistics.\nSome of the most common motivations of perpetrators include:\n\nAcid attacks often occur as revenge against a woman who rejects a proposal of marriage or a sexual advance. Gender inequality and women's position in the society, in relation to men, plays a significant role in these types of attacks.\nAttacks against individuals based on their religious beliefs or social or political activities also occur. These attacks may be targeted against a specific individual, due to their activities, or may be perpetrated against random persons merely because they are part of a social group or community. In Europe, Konstantina Kouneva, currently a member of the European Parliament, had acid thrown on her in 2008, in what was described as \"the most severe assault on a trade unionist in Greece for 50 years.\" Female students have had acid thrown in their faces as a punishment for attending school. Acid attacks due to religious conflicts have been also reported. Both males and females have been victims of acid attacks for refusing to convert to another religion.\n\nConflicts regarding property issues, land disputes, and inheritance have also been reported as motivations of acid attacks. Acid attacks related to conflicts between criminal gangs occur in many places, including the UK, Greece, and Indonesia.\n\nAccording to researchers and activists, countries typically associated with acid assault include Bangladesh, India, Nepal, Cambodia, Vietnam, Laos, China, United Kingdom, Kenya, South Africa, Uganda, Pakistan, and Afghanistan. However, acid attacks have been reported in countries around the world, including:\n\nAdditionally, anecdotal evidence for acid attacks exists in other regions of the world such as South America, Central and North Africa, the Middle East, and Central Asia. However, South Asian countries maintain the highest incidence of acid attacks.\n\nPolice in the United Kingdom have noted that many victims are afraid to come forward to report attacks, meaning the true scale of the problem may be unknown.\n\nAn accurate estimate of the gender ratio of victims and perpetrators is difficult to establish because many acid attacks are not reported or recorded by authorities. According to a 2010 study in \"The Lancet\", there are \"no reliable statistics\" on the prevalence of acid attacks in Pakistan.\n\nA 2007 literature review analyzed 24 studies in 13 countries over the past 40 years, covering 771 cases. According to the London-based charity Acid Survivors Trust International 60% of acid attacks are on women, and acid assaults are grossly under-estimated. In some regions, assaults perpetrated on female victims by males are often driven by the mentality \"If I can't have you, no one shall.\"\n\nIn Bangladesh, throwing acid has been labeled as a \"gender crime\", as there is a dominance of female victims who are assaulted by males, for the reason of refusing to marry, or refusing sexual advances from male perpetrators In Jamaica, women throwing acid on other women in relation to fights over male partners is a common cause. In the UK, the majority of victims are men, and many of these attacks are related to gang violence.\n\nAnother factor that puts victims at increased risk for an acid assault is their socioeconomic status, as those living in poverty are more likely to be attacked. , the three nations with the most noted incidence of acid attacks – Bangladesh, India, and Cambodia – were ranked 75th, 101st, and 104th, respectively, out of 136 countries on the Global Gender Gap Index, a scale that measures equality in opportunities between men and women in nations.\n\nThe UK has one of highest rates of acid attacks in the world, according to the police. An average of two attacks a day are recorded by forces across the country. 2017 was the worst year for acid attacks in London according to London Metropolitan Police showed a sharp rise in attacks, with 465 recorded in 2017, up from 395 the previous year and 255 in 2015. Mark van Dongen was the victim of an attack during the early hours of 23 September 2015.\n\nIn 2016, the Metropolitan Police in London recorded 454 attacks involving corrosive fluids in the city, with 261 in the previous year, indicating a rise of 36%. A rise of 30% was also recorded in the UK as a whole. Between 2005–06 and 2011–12 the number of assaults involving acid throwing and other corrosive substances tripled in England, official records show. NHS hospital figures record 144 assaults in 2011–12 involving corrosive substances, which can include petrol, bleach and kerosene. Six years earlier, 56 such episodes were noted. One British expert says she believes many of the cases involving acid are linked to communities of immigrants from Asia, with women attacked by their husbands or punished for refusing forced marriages. Muhammed Nawshad Kamal, 32, was left blind after an acid attack in Walthamstow by a moped thief on 4 November 2017.\nAcid attacks in London continued to rise in 2017. In July 2017, the BBC's George Mann reported that police statistics showed that: \"Assaults involving corrosive substances have more than doubled in England since 2012. The vast majority of cases were in London.\" According to \"Time\" magazine, motives included organized crime, revenge, and domestic violence. According to Newham police there is no trend of using acid in hate crimes. \n\nAccording to data from the \"London Metropolitan Police\", a demographic breakdown of known suspects in London attacks for the period (2002–2016) showed White Europeans comprising 32% of suspects, African Caribbeans 38% and Asian 6%. Victims for the same period were 45% White Europeans, 25% African Caribbeans and 19% Asian. Known suspects were overwhelmingly male, 77% of known suspects were male and just 2% of suspects female. Four out of five victims in 2016 were male in contrast to other countries where women are most frequently victimized by men.\n\nOn April 2017, a man named Arthur Collins, the ex-boyfriend of Ferne McCann, threw acid inside a nightclub across terrified clubbers in east London forcing a mass evacuation of 600 partygoers flooding into the street. 14 people were injured in the attack. Collins was sentenced to 20 years for the attack. Another similar attack is the Beckton acid attack. Katie Piper was also attacked with acid by her ex-boyfriend and an accomplice.\n\nOn 3 October 2017, the UK government announced that sales of acids to under 18s would be banned.\n\nIn January 2018, CNN reported that acid attacks in London increased six-fold between 2012 and 2017 and that 71% of attackers and 72% of victims were male.\n\nVictor Riesel was a broadcast journalist, specializing in labor issues, who was attacked while leaving Lindy's restaurant in midtown Manhattan in the early morning of 5 April 1956. Riesel was left blind as a result. The attack was motivated by Riesel's reporting on the influence of organized crime on certain corrupt labor unions.\n\nIn 1959, American attorney Burt Pugach hired a man to throw lye in the face of his ex-girlfriend Linda Riss. Riss suffered blindness and permanent scarring. Pugach served 14 years in prison for the incident.\n\nGabrielle White, a 22-year-old single mother living in Detroit, was attacked on 26 August 2006 by a stranger. She was left with third and fourth degree burns on her face, throat, and arms, leaving her blind and without one ear. She also miscarried her unborn child. A 25-year-old nursing student at Merritt College was the victim of an acid attack.\n\nDrug cartels such as the Los Zetas are known to use acid on civilians. For example, In the 2011 San Fernando massacre, Los Zetas members took away children from their mothers, and shot the rest of the civilians in a bus. The women were taken to a warehouse where many other women were held captive. Inside a dark room, the women were reportedly raped and beaten. Screams of the women and of the children being put in acid were also heard.\n\nIn South Asia, acid attacks have been used as a form of revenge for refusal of sexual advances, proposals of marriage and demands for dowry. Scholars Taru Bahl and M.H. Syed say that land/property disputes are another leading cause.\n\nIn Bangladesh, such attacks are relatively common.\nBangladesh has the highest reported incidence of acid assault in the world. According to the Acid Survivors Foundation in Bangladesh, the country has reported 3000 acid attack victims since 1999, peaking at 262 victims for the year of 2002. Rates have been steadily decreasing by 15% to 20% since 2002, with the amount of acid attack victims reported at 91 in Bangladesh as recently as 2011. Bangladesh acid attacks shows the most gendered discrimination, with one study citing a male to female victim ratio of 0.15:1 and another reporting that 82% of acid attack survivors in Bangladesh are women. Younger women were especially prone to attack, with a recent study reporting that 60% of acid assault survivors are between the ages of 10 and 19. According to Mridula Bandyopadhyay and Mahmuda Rahman Khan, it is a form of violence primarily targeted at women. They describe it as a relatively recent form of violence, with the earliest record in Bangladesh from 1983.\n\nAcid attacks are often referred to as a \"crime of passion\", fueled by jealousy and revenge. Actual cases though, show that they are usually the result of rage at a woman who rebuffs the advances of a male. For the country of Bangladesh, such passion is often rooted in marriage and relationships. One study showed that refusal of marriage proposals accounted for 55% of acid assaults, with abuse from a husband or other family member (18%), property disputes (11%) and refusal of sexual or romantic advances (2%) as other leading causes. Additionally, the use of acid attacks in dowry arguments has been reported in Bangladesh, with 15% of cases studied by the Acid Survivors Foundation citing dowry disputes as the motive. The chemical agents most commonly used to commit these attacks are hydrochloric acid and sulfuric acid.\n\nAcid attacks in India, like Bangladesh, have a gendered aspect to them: analyses of news reports revealed at least 72% of reported attacks included at least one female victim. However, unlike Bangladesh, India's incidence rate of chemical assault has been increasing in the past decade, with a high 27 reported cases in 2010. Altogether, from January 2002 to October 2010, 153 cases of acid assault were reported in Indian print media while 174 judicial cases were reported for the year of 2000.\n\nThe motivation behind acid attacks in India mirrors those in Bangladesh: a study of Indian news reports from January 2002 to October 2010 uncovered that victims’ rejected sex or marriage proposals motivated attacks in 35% of the 110 news stories providing a motive for the attack. Notable cases of acid attacks are Sonali Mukherjee's case of 2003 and Laxmi Agarwal in 2005.\n\nDuring the 2002 riots in Gujarat, targeted violence against Muslim women and children documented by civil society groups reported \"mass rapes, live burials and burnings, acid attacks, impaling, and other brutal forms of torture that was deeply gendered, and linked violence against women with violence on their children – both born and unborn\". In the 2008 Kandhamal Riots, more than 100 Christians were gang-raped, disemboweled, burned alive and had acid thrown to their faces by Hindu extremists for refusing to convert. Parikhit Nayak, a Dalit Christian Protestant convert from Hinduism who was tortured to death in front of his wife, Kanak. He was burnt with acid, castrated and finally disemboweled. Acid attacks were also used in the 1984 anti-Sikh riots, where people were dragged from their houses and had acid thrown to their faces.\n\nPolice in India are also known to use acid on individuals, particularly on their eyes, causing blindness to the victims. A well known such case is the Bhagalpur blindings, where police blinded 31 individuals under trial (or convicted criminals, according to some versions) by pouring acid into their eyes. The incident was widely discussed, debated and acutely criticized by several human rights organizations. The Bhagalpur blinding case had made criminal jurisprudence history by becoming the first in which the Indian Supreme Court ordered compensation for violation of basic human rights.\n\nAccording to \"New York Times\" reporter Nicholas D. Kristof, acid attacks are at an all-time high in Pakistan and increasing every year. The Pakistani attacks he describes are typically the work of husbands against their wives who have \"dishonored them.\" Statistics compiled by the Human Rights Commission of Pakistan (HRCP) show that 46 acid attacks occurred in Pakistan during 2004 and decreased with only 33 acid assaults reported for 2007. According to a \"New York Times\" article, in 2011 there were 150 acid attacks in Pakistan, up from 65 in 2010. However, estimates by the Human Rights Watch and the HRCP cite the number of acid attack victims to be as high 400–750 per year. Motivation behind acid assaults range from marriage proposal rejections to religious fundamentalism.\n\nThe Mong Kok acid attacks were incidents in 2008, 2009, and 2010 where plastic bottles filled with corrosive liquid (drain cleaner) were thrown onto shoppers on Sai Yeung Choi Street South, Hong Kong, a pedestrian street and popular shopping area. A reward, originally HK$100,000, for information about the perpetrator or perpetrators, was raised to HK$300,000 following the second incident, and cameras were to be installed in the area following the December incident. The third incident occurred the very day the cameras were turned on. The fifth incident happened after Hong Kong government announced its new strategies against the incident. 130 people were injured in these attacks.\n\nRecent studies on acid attacks in Cambodia found the victims were almost equally likely to be men or women (48.4% men, 51.6% women). As with India, rates of acid attacks in Cambodia have generally increased in the past decades, with a high rate of 40 cases reported for 2000 that started the increasing trend. According to the Cambodian Acid Survivors Charity, 216 acid attacks were reported from 1985 to 2009, with 236 reported victims. Jealousy and hate is the biggest motivator for acid attacks in Cambodia, as 28% of attacks reported those emotions as the cause. Such assaults were not only perpetrated by men—some reports suggest women attack other women occur more frequently than men do. Such incidents usually occur between a husband's wife and mistress to attain power and socioeconomic security.\n\nA particularly high-profile case of this nature was the attack on Cambodian teenager Tat Marina in 1999, allegedly carried out by the jealous wife of a government official (the incident prompted a rash of copycat crimes that year, raising the number from seven in 1998 to 40 in 1999). One third of the victims are bystanders. In Cambodia, there is only one support center that is aiming to help acid attack survivors. There they can receive medical and legal support.\n\nAcid attacks are common in Vietnam although not to the level of countries such as Pakistan and India. An example of an acid attack in Vietnam is the Ho Chi Minh City acid attack where four people were injured. Most of Vietnam's acid attack victims spend their lives isolated and ignored and also blamed for their agony.\n\nIran\n\nAccording to Afshin Molavi, in the early years of the revolution and following the mandating of the covering of hair by women in Iran, some women were threatened with acid attacks by Islamic vigilantes for failing to wear hijab.\n\nRecently, acid assault in Iran has been met with increased sanctions. The Sharia \"code of qisas\", or equivalence justice, required a caught perpetrator of acid violence to pay a fine and may be blinded with acid in both eyes. Under Iranian law, victims or their families can ask a court's permission to enact \"qisas\" either by taking the perpetrator's life in murder cases or afflicting an equal injury to his or her body. One victim, Ameneh Bahrami, sentenced her attacker to be blinded in 2008. However, as of July 31, 2011, she pardoned her attacker, thereby absolving Majid Movahedi of his crime and halting the retributive justice of Qisas.\n\nIn October 2014, a series of acid attacks on women occurred in the city of Isfahan, resulting in demonstrations and arrests of journalists who had covered the attacks. The attacks were thought by many Iranians to be the work of conservative Islamist vigilantes, but the Iranian government denies this.\n\nAfghanistan\n\nSuch attacks or threats against women who failed to wear hijab, dress \"modestly\" or otherwise threaten traditional norms have been reported in Afghanistan. In November 2008, extremists subjected girls to acid attacks for attending school.\n\nIsrael, West Bank and Gaza Strip\n\nIn 1983 acid attacks were reported to be carried out by Mujama al-Islamiya against men and woman who spoke out against the Mujama in the Islamic University of Gaza. Additional attacks by Mujama al-Islamiya were reported through 1986. During the First Intifada, Hamas and other Islamist factions conducted an organized intimidation of women to dress \"modestly\" or wear the hijab. Circulars were distributed specifying proper modest dress and behavior. Women who did not conform to these expectations, or to \"morality expectations\" of secular factions, were vulnerable to attacks which included pouring acid on their bodies, rock pelting, threats, and even rape. B'Tselem has also documented additional attacks with acid in specific attacks involving women in a collaboration context.\n\nIn 2006-7, as part of a wider campaign to enforce Islamist moral conduct, the al-Qaida affiliated \"Suyuf al-Haq\" (Swords of Righteousness) claimed to have thrown acid on the faces of \"immodestly\" dressed woman in Gaza as well as engaging in intimidation via threats. Following 2014 Israel–Gaza conflict Amnesty International has claimed that Hamas used acid during interrogations as a torture technique. Hamas denies this claim. In 2016, during a teacher's strike, unknown assailants hurled acid in the face of a striking Palestinian teacher in Hebron.\n\nThere have also been recorded incidents of acid use against Israelis. In December 2014, a Palestinian hurled acid (concentrated vinegar which contains a high percentage of acetic acid and can cause burns) into a car containing a Jewish family of six and a hitchhiker at a checkpoint between Beitar Illit and Husan in the West Bank, causing serious face injuries to the father and lightly injuring other occupants, including children. In September 2008 a Palestinian woman carried out two separate acid attacks against soldiers at Huwwara checkpoint, blinding one soldier.\n\nMoshe Hirsch was the leader of the anti-Zionist Neturei Karta group in Jerusalem. Hirsch had one glass eye due to an injury sustained when someone threw acid in his face. According to his cousin, journalist Abraham Rabinovich, the incident had no link with Hirsch's political activities but was connected to a real estate dispute.\n\nHigh incidence of acid assaults have been reported in some African countries, including Nigeria, Uganda, and South Africa. Unlike occurrences in South Asia, acid attacks in these countries show less gender discrimination. In Uganda, 57% of acid assault victims were female and 43% were male. A study focusing on chemical burns in Nigeria revealed a reversal in findings—60% of the acid attack patients were male while 40% were female. In both nations, younger individuals were more likely to suffer from an acid attack: the average age in the Nigeria study was 20.6 years, while Ugandan analysis shows 59% of survivors were 19–34 years of age.\n\nMotivation for acid assault in these African countries is similar to that of Cambodia. \"Relationship conflicts\" caused 35% of acid attacks in Uganda in 1985–2011, followed by property conflicts at 8%, and business conflicts at 5%. Disaggregated data was not available in the Nigeria study, but they reported that 71% of acid assaults resulted from an argument with either a jilted lover, family member, or business partner. As with the other nations, researchers believe these statistics to be under-representative of the actual scope and magnitude of acid attacks in African nations.\n\nIn August 2013, two Jewish women volunteer teachers—Katie Gee and Kirstie Trup from the UK—were injured by an acid attack by men on a moped near Stone Town in Tanzania.\n\nOn January 17, 2013, Russian ballet dancer Sergei Filin was attacked with acid by an unknown assailant, who cornered him outside of his home in Moscow. He suffered third-degree burns to his face and neck. While it was initially reported that he was in danger of losing his eyesight, his physicians stated on January 21, 2013 that he would retain eyesight in one eye.\n\nAn unidentified Russia woman allegedly attacked men on public transportation for \"manspreading\". Pictures exist of a woman pouring a clear substance on the crotch of men on public transportation, though the contents of the liquid are unknown, it was allegedly a mixture of water and bleach. It was later revealed that the \"attacks\" were staged by paid actors, in order to spread disinformation and stir anti-feminist sentiment. \n\nOn July 31, 2018, Kateryna Handziuk, an anti-corruption activist and political advisor from the southern Ukrainian city of Kherson, was attacked with sulfuric acid outside her home by an unknown attacker. She died of her injuries on November 3, 2018. She was 33 years old. \n\nColombia\nThough comprehensive statistics on acid attacks in South America are sparse, a recent study investigating acid assault in Bogota, Colombia, provides some insight for this region. According to the article, the first identified survivor of acid violence in Bogota was attacked 15 years ago. Since then reported cases have been increasing with time. The study also cited the Colombian Forensics Institute, which reported that 56 women complained of aggression by acid in 2010, 46 in 2011, and 16 during the first trimester of 2012. The average age of survivors was about 23 years old, but ranged from 13 to 41 years.\n\nThe study reported a male:female victim ratio of 1:30 for acid assault in Bogota, Colombia, although recent reports show the ratio is closer to 1:1. Reasons behind these attacks usually stemmed from poor interpersonal relationships and domestic intolerance toward women. Moreover, female victims usually came from low socioeconomic classes and had low education. The authors state that the prevalence of acid attacks in other areas of South America remains unknown due to significant underreporting.\n\nOn March 27, 2014, a woman named Natalia Ponce de León was assaulted by Jonathan Vega, who threw a liter of sulphuric acid on her face and body. Vega, a former neighbor, was reported to have been \"obsessed\" with Ponce de León and had been making death threats against her after she turned down his proposal for a relationship. 24% of her body was severely burned as a result of the attack. Ponce de León has undergone 15 reconstruction surgeries on her face and body since the attack.\n\nThree years before the attack took place, Colombia reported one of the highest rates of acid attacks per capita in the world. However, there was not an effective law in place until Ponce de León's campaign took off in the months after her attack. The new law, which is named after her, defines acid attacks as a specific crime and increases maximum sentences to 50 years in jail for convicted offenders. The law also aims to provide victims with better state medical care including reconstructive surgery and psychological therapy. Ponce de León expressed hope that the new law would act as a deterrent against future attacks.\n\nThe most notable effect of an acid attack is the lifelong bodily disfigurement. According to the Acid Survivors Foundation in Pakistan, there is a high survival rate amongst victims of acid attacks. Consequently, the victim is faced with physical challenges, which require long-term surgical treatment, as well as psychological challenges, which require in-depth intervention from psychologists and counselors at each stage of physical recovery. These far-reaching effects on their lives impact their psychological, social and economic viability in communities.\n\nThe medical effects of acid attacks are extensive. As a majority of acid attacks are aimed at the face, several articles thoroughly reviewed the medical implications for these victims. The severity of the damage depends on the concentration of the acid and the time before the acid is thoroughly washed off with water or neutralized with a neutralizing agent. The acid can rapidly eat away skin, the layer of fat beneath the skin, and in some cases even the underlying bone. Eyelids and lips may be completely destroyed and the nose and ears severely damaged. Though not exhaustive, Acid Survivors Foundation Uganda findings included:\n\nIn addition to these above-mentioned medical effects, acid attack victims face the possibility of septicemia, renal failure, skin depigmentation, and even death.\n\nA 2015 attack that involved throwing sulfuric acid on a man's face and body while he lay in bed caused him, among other serious injuries, to become paralyzed from the neck down.\n\nAcid assault survivors face many mental health issues upon recovery. One study showed that when compared to published Western norms for psychological well-being, non-Caucasian acid attack victims reported higher levels of anxiety, depression, and scored higher on the Derriford appearance scale, which measures psychological distress due to one's concern for their appearance. Additionally, female victims reported lowered self-esteem according to the Rosenberg scale and increased self-consciousness, both in general and in the social sphere.\n\nIn addition to medical and psychological effects, many social implications exist for acid survivors, especially women. For example, such attacks usually leave victims handicapped in some way, rendering them dependent on either their spouse or family for everyday activities, such as eating and running errands. These dependencies are increased by the fact that many acid survivors are not able to find suitable work, due to impaired vision and physical handicap. This negatively impacts their economic viability, causing hardships on the families/spouses that care for them. As a result, divorce rates are high, with abandonment by husbands found in 25% of acid assault cases in Uganda (compared to only 3% of wives abandoning their disfigured husbands). Moreover, acid survivors who are single when attacked almost certainly become ostracized from society, effectively ruining marriage prospects. Some media outlets overwhelmingly avoid reporting acid attack violence, or the description of the attack is laconic or often implies that the act was inevitable or even justified.\n\nTreatment for burn victims remains inadequate in many developing nations where incidence is high. Medical underfunding has resulted in very few burn centers available for victims in countries such as Uganda, Bangladesh, and Cambodia. For example, Uganda has one specialized burn center in the entire nation, which opened in 2003; likewise, Cambodia has only one burn facility for victims, and scholars estimate that only 30% of the Bangladeshi community has access to health care.\n\nIn addition to inadequate medical capabilities, many acid assault victims fail to report to the police due to a lack of trust in the force, a sense of hopelessness due to the attackers' impunity, and a fear of male brutality in dealing with their cases. Most of the female victims suffer more because of police apathy in dealing with cases of harassment as safety issues as victims refused to register a police case despite being attacked thrice before meriting police aid after an acid attack.\n\nThese problems are exacerbated by a lack of knowledge of how to treat burns: many victims applied oil to the acid, rather than rinsing thoroughly and completely with water for 30 minutes or longer to neutralize the acid. Such home remedies only serve to increase the severity of damage, as they do not counteract the acidity.\n\nResearch has prompted many solutions to the increasing incidence of acid attacks in the world. Many countries look to Bangladesh, whose rates of attack have been decreasing, as a model, following their lead in many legislative reforms. However, several reports highlighted the need for an increased, legal role of NGOs to offer rehabilitation support to acid survivors. Additionally, nearly all research stressed the need for stricter regulation of acid sales to combat this social issue.\n\nMany non-governmental organizations (NGOs) have been formed in the areas with the highest occurrence of acid attacks to combat such attacks. Bangladesh has its Acid Survivors Foundation, which offers acid victims legal, medical, counseling, and monetary assistance in rebuilding their lives. Similar institutions exist in Uganda, which has its own Acid Survivors Foundation, and in Cambodia which uses the help of Cambodian Acid Survivors Charity. NGOs provide rehabilitation services for survivors while acting as advocates for social reform, hoping to increase support and awareness for acid assault.\n\nIn Bangladesh, the Acid Survivors Foundation, Nairpokkho, Action Aid, and the Bangladesh Rural Advancement Committee's Community Empowerment & Strengthening Local Institutions Programme assist survivors. The Depilex Smileagain Foundation and The Acid Survivors Foundation in Pakistan operates in Islamabad, offering medical, psychological and rehabilitation support. The Acid Survivors Foundation in Uganda operates in Kampala and provides counseling and rehabilitation treatment to victims, as well as their families. The LICADHO, the Association of the Blind in Cambodia, and the Cambodian Acid Survivors Charity assist survivors of acid attacks. The Acid Survivors Foundation India operates from different centres with national headquarters at Kolkata and chapters at Delhi and Mumbai.\n\nAcid Survivors Trust International (UK registered charity no. 1079290) provides specialist support to its sister organizations in Africa and Asia. Acid Survivors Trust International is the only international organisation whose sole purpose is to end acid violence. The organisation was founded in 2002 and now works with a network of six Acid Survivors Foundations in Bangladesh, Cambodia, India, Nepal, Pakistan and Uganda that it has helped to form. Acid Survivors Trust International has helped to provide medical expertise and training to partners, raised valuable funds to support survivors of acid attacks and helped change laws. A key role for ASTI is to raise awareness of acid violence to an international audience so that increased pressure can be applied to governments to introduce stricter controls on the sale and purchase of acid.\n\nIndian acid attack survivor Shirin Juwaley founded the Palash Foundation to help other survivors with psychosocial rehabilitation. She also spearheads research into social norms of beauty and speaks publicly as an advocate for the empowerment of all victims of disfigurement and discrimination. In 2011, the principal of an Indian college refused to have Juwaley speak at her school for fear that Juwaley's story of being attacked by her husband would make students \"become scared of marriage\".\n\nA positive correlation has been observed between acid attacks and ease of acid purchase. Sulfuric, nitric, and hydrochloric acid are most commonly used and are all cheap and readily available in many instances. For example, often acid throwers can purchase a liter of concentrated sulfuric acid at motorbike mechanic shops for about 40 U.S. cents. Nitric acid costs around $1.50 per liter and is available for purchase at gold or jewelry shops, as polishers generally use it to purify gold and metals. Hydrochloric acid is also used for polishing jewelry, as well as for making soy sauce, cosmetics, and traditional medicine/amphetamine drugs.\n\nDue to such ease of access, many organizations call for a stricter regulation on the acid economy. Specific actions include required licenses for all acid traders, a ban on concentrated acid in certain areas, and an enhanced system of monitoring for acid sales, such as the need to document all transactions involving acid. However, some scholars have warned that such stringent regulation may result in black market trading of acid, which law enforcements must keep in mind.\nAcid has been used in metallurgy and for etching since ancient times. The rhetorical and theatrical term \"La Vitrioleuse\" was coined in France after a \"wave of vitriolage\" occurred according to the popular press where, in 1879, 16 cases of vitriol attacks were widely reported as crimes of passion perpetrated predominantly by women against other women. Much was made of the idea that women, no matter how few, had employed such violent means to an end. On October 17, 1915, acid was fatally thrown on Prince Leopold Clement of Saxe-Coburg and Gotha, heir to the House of Koháry, by his distraught mistress, Camilla Rybicka, who then killed herself. Sensationalizing such incidents made for lucrative newspaper sales.\n\nThe use of acid as a weapon began to rise in many developing nations, specifically those in South Asia. The first recorded acid attacks in South Asia occurred in Bangladesh in 1967, India in 1982, and Cambodia in 1993. Since then, research has witnessed an increase in the quantity and severity of acid attacks in the region. However, this can be traced to significant underreporting in the 1980s and 1990s, along with a general lack of research on this phenomenon during that period.\n\nResearch shows acid attacks increasing in many developing nations, with the exception of Bangladesh which has observed a decrease in incidence in the past few years.\n\nMany countries have begun pushing for legislation addressing acid attacks, and a few have recently employed new laws against this crime. Under the Qisas law of Pakistan, the perpetrator may suffer the same fate as the victim, and may be punished by having drops of acid placed in their eyes. This law is not binding and is rarely enforced according to a \"New York Times\" report. In Pakistan, the Lower House of Parliament unanimously passed the Acid Control and Acid Crime Prevention Bill on May 10, 2011. As punishment, according to the bill individuals held responsible for acid attacks face harsh fines and life in prison. However, the country with the most specific, effective legislation against acid attacks is Bangladesh, and such legal action has resulted in a steady 20–30% decrease in acid violence for the past few years. In 2013, India introduced an amendment to the Indian Penal Code through the Criminal Law (Amendment) Act, 2013, making acid attacks a specific offence with a punishment of imprisonment not less than 10 years and which can extend to life imprisonment and with fine.\n\nIndia's top court ruled that authorities must regulate the sale of acid. The Supreme Court's ruling on July 16, 2013, came after an incident in which four sisters suffered severe burns after being attacked with acid by two men on a motorbike. Acid which is designed to clean rusted tools is often used in the attacks can be bought across the counter. But the judges said the buyer of such acids should in future have to provide a photo identity card to any retailer when they make a purchase. The retailers must register the name and address of the buyer. In 2013, section 326 A of Indian Penal Code was enacted by the Indian Parliament to ensure enhanced punishment for acid throwing.\n\nIn 2002, Bangladesh introduced the death penalty for acid attacks and laws strictly controlling the sale, use, storage, and international trade of acids. The acids are used in traditional trades carving marble nameplates, conch bangles, goldsmiths, tanneries, and other industries, which have largely failed to comply with the legislation. Salma Ali of the Bangladesh National Women Lawyers' Association derided these laws as ineffective. The names of these laws are the Acid Crime Control Act (ACCA) and the Acid Control Act (ACA), respectively.\n\nThe ACCA directly impacts the criminal aspect of acid attacks, and allows for the death penalty or a level of punishment corresponding to the area of the body affected. If the attack results in a loss of hearing or sight or damages the victim's face, breasts, or sex organs then the perpetrator faces either the death penalty or life sentencing. If any other part of the body is maimed, then the criminal faces 7–14 years of imprisonment in addition to a fine of US$700. Additionally, throwing or attempting to throw acid without causing any physical or mental harm is punishable by this law and could result in a prison term of 3–7 years along with a US$700 fine. Furthermore, conspirators that aid in such attacks assume the same liability as those actually committing the crime.\n\nThe ACA regulates the sale, usage, and storing of acid in Bangladesh through the creation of the National Acid Control Council (NACC). The law requires that the NACC implement policies regarding the trade, misuse, and disposal of acid, while also undertaking initiatives that raise awareness about the dangers of acid and improve victim treatment and rehabilitation. The ACA calls for district-level committees responsible for enacting local measures that enforce and further regulate acid use in towns and cities.\n\nUnder the Qisas law of Pakistan, the perpetrator could suffer the same fate as the victim, if the victim or the victim's guardian chooses. It may be punished by having drops of acid placed in their eyes.\n\nSection 336B of Pakistan Penal Code states: \"Whoever causes hurt by corrosive substance shall be punished with imprisonment for life or imprisonment of either description which shall not be less than fourteen years and a minimum fine of one million rupees.\" Additionally, section 299 defines \"Qisas\" and states: \"\"Qisas\" means punishment by causing similar hurt at the same part of the body of the convict as he has caused to the victim or by causing his death if he has committed qatl-iamd (intentional manslaughter) in exercise of the right of the victim or a Wali (the guardian of the victim).\"\n\nAfter a spate of attacks in London in 2017, the Home Office said it would consider changes in laws and measures regarding sales of acid, as well as changes in prosecution and sentencing guidelines. As of 2017, it is unlawful to carry acid with the intent to cause harm. Attacks are prosecuted as acts of actual bodily harm and grievous bodily harm. Three quarters of police investigations do not end in prosecution, either because the attacker could not be found, or because the victim is unwilling to press charges. According to ASTI, of the 2,078 acid attack crimes recorded for the years 2011-2016 in UK, only 414 of those crimes resulted in charges being brought. Most acid attack crimes happened in London, where over 1,200 cases were recorded over the past five years. From 2011–2016 there were 1,464 crimes involving acid or corrosive substance. Northumbria recorded the second highest with 109 recorded attacks, Cambridgeshire had 69 attacks, Hertfordshire 67, Greater Manchester 57 and Humberside 52.\n\n\n\nVitriolage is the deliberate splashing of a person or object with acid, also known as vitriol, in order to deface or kill. A female who engages in such an act is known as a vitrioleuse. There are instances of this act throughout history and in modern times, often in places where honor killings are also common.\n\n\n\n"}
{"id": "52306262", "url": "https://en.wikipedia.org/wiki?curid=52306262", "title": "Alexander Funeral Home", "text": "Alexander Funeral Home\n\nThe Alexander Funeral Home is the oldest African American owned business in Mecklenburg County, North Carolina.\n\nAlexander Funeral Home was founded by Zechariah Alexander in 1914 when Alexander bought half of Coles and Smith Undertakes. In 1927 Alexander purchased the remaining part of the business and changed the name to the Alexander Funeral Home. The business passed through the family with Kelly Alexander Sr and Zechariah Alexander Jr both making careers out of the business.\n\nThe funeral home became a sort of gathering place for civil rights activists and leaders in the community. Frederick Alexander became the first African American on the Charlotte City Council, Kelly Alexander Sr served as Chairman of the NAACP, Louis Alexander worked with the United States Postal Service and Kelly Alexander Jr became a North Carolina Senator.\n\nToday the business is locally owned with members of the Alexander family overseeing the running of the company.\n\n"}
{"id": "1634942", "url": "https://en.wikipedia.org/wiki?curid=1634942", "title": "Alternative set theory", "text": "Alternative set theory\n\nGenerically, an alternative set theory is an alternative mathematical approach to the concept of set. It is a proposed alternative to the standard set theory. \n\nSome of the alternative set theories are:\n\n\nSpecifically, Alternative Set Theory (or AST) refers to a particular set theory developed in the 1970s and 1980s by Petr Vopěnka and his students. It builds on some ideas of the theory of semisets, but also introduces more radical changes: for example, all sets are \"formally\" finite, which means that sets in AST satisfy the law of mathematical induction for set-formulas (more precisely: the part of AST that consists of axioms related to sets only is equivalent to the Zermelo–Fraenkel (or ZF) set theory, in which the axiom of infinity is replaced by its negation). However, some of these sets contain subclasses that are not sets, which makes them different from Cantor (ZF) finite sets and they are called infinite in AST.\n\n\n"}
{"id": "39766716", "url": "https://en.wikipedia.org/wiki?curid=39766716", "title": "Anti-war movement", "text": "Anti-war movement\n\nAn anti-war movement (also \"antiwar\") is a social movement, usually in opposition to a particular nation's decision to start or carry on an armed conflict, unconditional of a maybe-existing just cause. The term can also refer to pacifism, which is the opposition to all use of military force during conflicts. Many activists distinguish between anti-war movements and peace movements. Anti-war activists work through protest and other grassroots means to attempt to pressure a government (or governments) to put an end to a particular war or conflict.\nSubstantial opposition to British war intervention in America led the British House of Commons on 27 February 1782 to vote against further war in America, paving the way for the Second Rockingham ministry and the Peace of Paris.\n\nSubstantial anti-war sentiment developed in the United States during the period roughly falling between the end of the War of 1812 and the commencement of the Civil War, or what is called the antebellum era (A similar movement developed in England during the same period). The movement reflected both strict pacifist and more moderate non-interventionist positions. Many prominent intellectuals of the time, including Ralph Waldo Emerson, Henry David Thoreau (\"see\" \"Civil Disobedience\") and William Ellery Channing contributed literary works against war. Other names associated with the movement include William Ladd, Noah Worcester, Thomas Cogswell Upham and Asa Mahan. Many peace societies were formed throughout the United States, the most prominent of which being the American Peace Society. Numerous periodicals (e.g., The Advocate of Peace) and books were also produced. The \"Book of Peace\", an anthology produced by the American Peace Society in 1845, must surely rank as one of the most remarkable works of anti-war literature ever produced.\n\nA recurring theme in this movement was the call for the establishment of an international court which would adjudicate disputes between nations. Another distinct feature of antebellum anti-war literature was the emphasis on how war contributed to a moral decline and brutalization of society in general.\n\nA key event in the early history of the modern anti-war stance in literature and society was the American Civil War, where it culminated in the candidacy of George McClellan for President of the United States as a \"Peace Democrat\" against incumbent President Abraham Lincoln. The outlines of the anti-war stance are seen: the argument that the costs of maintaining the present conflict are not worth the gains which can be made, the appeal to end the horrors of war, and the argument that war is being waged for the profit of particular interests. During the war, the New York Draft Riots were started as violent protests against Abraham Lincoln's \"Enrollment Act of Conscription\" plan to draft men to fight in the war. The outrage over conscription was augmented by the ability to \"buy\" your way out; the amount of which could only be afforded by the wealthy. After the war, \"The Red Badge of Courage\" described the chaos and sense of death which resulted from the changing style of combat: away from the set engagement, and towards two armies engaging in continuous battle over a wide area.\n\nWilliam Thomas Stead formed an organization against the Second Boer War: the Stop the War Committee.\n\nIn Britain, in 1914, the Public Schools Officers' Training Corps annual camp was held at Tidworth Pennings, near Salisbury Plain. Head of the British Army Lord Kitchener was to review the cadets, but the immenence of the war prevented him. General Horace Smith-Dorrien was sent instead. He surprised the two-or-three thousand cadets by declaring (in the words of Donald Christopher Smith, a Bermudian cadet who was present) \"that war should be avoided at almost any cost, that war would solve nothing, that the whole of Europe and more besides would be reduced to ruin, and that the loss of life would be so large that whole populations would be decimated. In our ignorance I, and many of us, felt almost ashamed of a British General who uttered such depressing and unpatriotic sentiments, but during the next four years, those of us who survived the holocaust-probably not more than one-quarter of us – learned how right the General's prognosis was and how courageous he had been to utter it.\" Having voiced these sentiments did not hinder Smith-Dorrien's career, or prevent him from carrying out his duty in the First World War to the best of his abilities.\n\nWith the increasing mechanization of war, opposition to its horrors grew, particularly in the wake of the First World War. European avant-garde cultural movements such as Dada were explicitly anti-war.\n\nThe Espionage Act of 1917 and the Sedition Act of 1918 gave the American authorities the right to close newspapers and jailed individuals for having anti-war views.\n\nOn June 16, 1918, Eugene V. Debs made an anti-war speech and was arrested under the Espionage Act of 1917. He was convicted, sentenced to serve ten years in prison, but President Warren G. Harding commuted his sentence on December 25, 1921.\n\nIn 1924 Ernst Friedrich published \"Krieg dem Krieg!\" (\"War Against War!\"): an album of photographs drawn from German military and medical archives from the first world war. In \"Regarding the pain of others\" Sontag describes the book as 'photography as shock therapy' that was designed to 'horrify and demoralize'.\n\nIt was in the 1930s that the Western anti-war movement took shape, to which the political and organizational roots of most of the existing movement can be traced. Characteristics of the anti-war movement included opposition to the corporate interests perceived as benefiting from war, to the status quo which was trading the lives of the young for the comforts of those who are older, the concept that those who were drafted were from poor families and would be fighting a war in place of privileged individuals who were able to avoid the draft and military service, and to the lack of input in decision making that those who would die in the conflict would have in deciding to engage in it.\n\nIn 1933, the Oxford Union resolved in its Oxford Pledge, \"That this House will in no circumstances fight for its King and Country.\"\n\nMany war veterans, including US General Smedley Butler, spoke out against wars and war profiteering on their return to civilian life.\n\nVeterans were still extremely cynical about the motivations for entering World War I, but many were willing to fight later in the Spanish Civil War, indicating that pacifism was not always the motivation. These trends were depicted in novels such as \"All Quiet on the Western Front\", \"For Whom the Bell Tolls\" and \"Johnny Got His Gun\".\n\nOpposition to World War II was most vocal during its early period, and stronger still before it started while appeasement and isolationism were considered viable diplomatic options. Communist-led organizations, including veterans of the Spanish Civil War, opposed the war during the period of the Hitler-Stalin pact but then turned into hawks after Germany invaded the Soviet Union.\n\nThe war seemed, for a time, to set anti-war movements at a distinct social disadvantage; very few, mostly ardent pacifists, continued to argue against the war and its results at the time. However, the Cold War followed with the post-war realignment, and the opposition resumed. The grim realities of modern combat, and the nature of mechanized society ensured that the anti-war viewpoint found presentation in \"Catch-22\", \"Slaughterhouse-Five\" and \"The Tin Drum\". This sentiment grew in strength as the Cold War seemed to present the situation of an unending series of conflicts, which were fought at terrible cost to the younger generations.\n\nOrganized opposition to U.S. involvement in the Vietnam War began slowly and in small numbers in 1964 on various college campuses in the United States and quickly as the war grew deadlier. In 1967 a coalition of antiwar activists formed the National Mobilization Committee to End the War in Vietnam which organized several large anti-war demonstrations between the late-1960s and 1972. Counter-cultural songs, organizations, plays and other literary works encouraged a spirit of nonconformism, peace, and anti-establishmentarianism. This anti-war sentiment developed during a time of unprecedented student activism and right on the heels of the Civil Rights Movement, and was reinforced in numbers by the demographically significant baby boomers. It quickly grew to include a wide and varied cross-section of Americans from all walks of life. The anti-Vietnam war movement is often considered to have been a major factor affecting America's involvement in the war itself. Many Vietnam veterans, including the former Secretary of State and former U.S. Senator John Kerry and disabled veteran Ron Kovic, spoke out against the Vietnam War on their return to the United States.\n\nOpposition to the South African Border War spread to a general resistance to the apartheid military. Organizations such as the End Conscription Campaign and Committee on South African War Resisters, were set up. Many opposed the war at this time.\n\nThere was initially little opposition to the 2001 Afghanistan War in the United States and the United Kingdom, which was seen as a response to the September 11, 2001, terrorist attacks and was supported by a majority of the American public. Most vocal opposition came from pacifist groups and groups promoting a leftist political agenda; in the United States, the group A.N.S.W.E.R. was one of the most visible organizers of anti-war protests, although that group faced considerable controversy over allegations it was a front for the extremist Stalinist Workers World Party. Over time, opposition to the war in Afghanistan has grown more widespread, partly as a result of weariness with the length of the conflict, and partly as a result of a conflating of the conflict with the unpopular war in Iraq.\n\nThe anti-war position gained renewed support and attention in the buildup to the 2003 invasion of Iraq by the U.S. and its allies. Millions of people staged mass protests across the world in the immediate prelude to the invasion, and demonstrations and other forms of anti-war activism have continued throughout the occupation. The primary opposition within the U.S. to the continued occupation of Iraq has come from the grassroots. Opposition to the conflict, how it had been fought, and complications during the aftermath period divided public sentiment in the U.S., resulting in majority public opinion turning against the war for the first time in the spring of 2004, a turn which has held since. Many American writers against the war, like Naomi Wolf, were labeled conspiratorial due to their opposition, with others choosing to post their anti-war writings anonymously, such as the anonymous conspiracy author Sorcha Faal. The financial website Zero Hedge offered its anti-war writers the protection of the anonymous pseudonym Tyler Durden for those exposing war profiteering. The American country music band Dixie Chicks opposition to the war caused many radio stations to stop playing their records, but who were supported in their anti-war stance by the equally anti-war country music legend Merle Haggard, who in the summer of 2003 released a song critical of US media coverage of the Iraq War. Anti-war groups protested during both the Democratic National Convention and 2008 Republican National Convention protests held in St. Paul, Minnesota in September 2008.\n\nOrganised opposition to a possible future military attack against Iran by the United States is known to have started during 2005–2006. Beginning in early 2005, journalists, activists and academics such as Seymour Hersh, Scott Ritter, Joseph Cirincione and Jorge E. Hirsch began publishing claims that United States' concerns over the alleged threat posed by the possibility that Iran may have a nuclear weapons program might lead the US government to take military action against that country in the future. These reports, and the concurrent escalation of tensions between Iran and some Western governments, prompted the formation of grassroots organisations, including Campaign Against Sanctions and Military Intervention in Iran in the US and the United Kingdom, to advocate against potential military strikes on Iran. Additionally, several individuals, grassroots organisations and international governmental organisations, including the Director-General of the International Atomic Energy Agency, Mohamed ElBaradei, a former United Nations weapons inspector in Iraq, Scott Ritter, Nobel Prize winners including Shirin Ebadi, Mairead Corrigan-Maguire and Betty Williams, Harold Pinter and Jody Williams, Campaign for Nuclear Disarmament, Code Pink, the Non-Aligned Movement of 118 states, and the Arab League, have publicly stated their opposition to a would-be attack on Iran.\n\nAnti-war/Putin demonstrations took place in Moscow \"opposing the War in Donbass\", i.e., in the Eastern Ukraine.\n\nEnglish poet Robert Southey's 1796 poem After Blenheim is an early modern example of anti-war literature — it was written generations after the Battle of Blenheim, but at a time when England was again at war with France.\n\nWorld War I produced a generation of poets and writers influenced by their experiences in the war. The work of poets including Wilfred Owen and Siegfried Sassoon exposed the contrast between the realities of life in the trenches and how the war was seen by the British public at the time, as well as the earlier patriotic verse penned by Rupert Brooke. German writer Erich Maria Remarque penned All Quiet on the Western Front, which, having been adapted for several mediums, has become of the most often cited pieces of anti-war media.\n\nPablo Picasso's 1937 painting \"Guernica\", on the other hand, used abstraction rather than realism to generate an emotional response to the loss of life from the fascist bombing of Guernica during the Spanish Civil War. American author Kurt Vonnegut used science fiction themes in his 1969 novel Slaughterhouse-Five, depicting the bombing of Dresden in World War II (which Vonnegut witnessed).\n\nThe second half of the 20th century also witnessed a strong anti-war presence in other art forms, including anti-war music such as \"Eve of Destruction\" and One Tin Soldier and films such as \"M*A*S*H\" and \"Die Brücke\", opposing the Cold War in general, or specific conflicts such as the Vietnam War. The current American war in Iraq has also generated significant artistic anti-war works, including filmmaker Michael Moore's \"Fahrenheit 9/11\", which holds the box-office record for documentary films, and Canadian musician Neil Young's 2006 album \"Living with War\".\n\nVarious people have discussed the philosophical question of whether war is inevitable, and how much it can be avoided, as well as how this can be achieved i.e. what are the necessities of peace. Various people have discussed it from an intellectual and philosophical point of view. Various intellectuals not only have discussed in public but have participated or led anti-war campaigns despite it is different to their main areas of expertise. They went out of their professional comfort zone to warn against or fight against wars.\n\n\nHere is a list of people who outside this field have authority and used their influence and intellectual rigor favour of in the cause of enlightening against the warmongers.\n\n\n\n"}
{"id": "6320392", "url": "https://en.wikipedia.org/wiki?curid=6320392", "title": "Arlene Raven", "text": "Arlene Raven\n\nArlene Raven (\"Arlene Rubin\": July 12, 1944, Baltimore, Maryland – August 1, 2006, Brooklyn, New York) was a feminist art historian, author, critic, educator, and curator. Raven was a co-founder of numerous feminist art organizations in Los Angeles in the 1970s.\n\nArlene Raven's parents were Joseph and Annette Rubin, middle-class Jewish-American parents, in Baltimore, Maryland. Her father was a bar owner, and her mother a homemaker.\n\nRaven earned an Artium Baccalaureatus from Hood College in Maryland in 1965, then went on to complete graduate study. She earned an MFA in painting from George Washington University and completed a PhD in art history from Johns Hopkins University in 1975.\n\nRaven was a major figure in the Feminist Art Movement and was part of an effort to educate women artists and provide them with opportunities to make and show work that was specifically about their experiences as women. In 1973, Raven co-founded the Feminist Studio Workshop with Judy Chicago and Sheila Levrant de Bretteville. The goal of the Feminist Studio Workshop, an independent art school ultimately housed in the Los Angeles Woman's Building, was to \"come together as a community of working individuals whose work grows out of our shared experiences as women and our shared social context,\" and an emphasis was put on \"cooperation, collaboration, and sisterhood.\" That same year, Raven co-founded The Center for Feminist Art Historical Studies with fellow Johns Hopkins-educated art historian Ruth Iskin. The Center was dedicated to serious research on women artists, developing a feminist art historical methodology, and creating a slide archive of work by women. Raven also co-founded and edited the women's culture magazine \"Chrysalis.\" In 1976, she was a founding member of The Lesbian Art Project; she herself was a lesbian as well. Members explored lesbianism through artwork, researched lesbian artists of the past, such as the painter Romaine Brooks, and questioned the cultural meaning of the very term \"lesbian.\" She was also a founder of the Women’s Caucus for Art.\n\nIn addition to the Feminist Studio Workshop, Raven also taught at the California Institute of the Arts, Maryland Institute College of Art, Parsons The New School for Design, UCLA, University of Southern California and The New School for Social Research. In the 1980s she became the chief art critic for the \"Village Voice.\"\n\nShe curated ten exhibitions, including ones for the Baltimore Museum of Art and the Long Beach Museum of Art. One notable exhibition was \"At Home,\" \"which brought together many of the artists and ideas she had championed for the previous decade.\"\n\nIn 2000, Raven became critic-in-residence at the Rinehart School of Sculpture at the Maryland Institute College of Art. In 2002, she received the Frank Jewett Mather Award for art criticism from the College Art Association.\n\nRaven died of cancer at her home in Brooklyn, New York on August 1, 2006, aged 62. She was survived by her father, her sister Phyllis [Gelman], and Nancy Grossman, her life partner of 23 years.\n\nRaven authored nine books, including:\n\nMonographs:\n\n"}
{"id": "46543281", "url": "https://en.wikipedia.org/wiki?curid=46543281", "title": "Baha'i perspective on international human rights", "text": "Baha'i perspective on international human rights\n\nBahá’u’lláh, the prophet-founder of the Bahá’í Faith, called for global agreement on human rights protection nearly eighty years before the adoption of the Universal Declaration of Human Rights (UDHR) in 1948. He taught that an “equal standard of human rights must be recognized and adopted.” \nBahá’u’lláh called for governments to protect the human rights of their populations and to ensure their welfare. To safeguard human rights, He urged global leaders to establish a world commonwealth that would include a system of collective security to protect populations against tyranny and oppression.\n\nThe Bahá’í Writings make clear that human rights are not merely a political or social concept that is contingent on recognition by governments. Rather, the Bahá’í perspective is that human rights exist with or without governments; indeed, they are a divine endowment flowing from the creation of all human beings with the potential to reflect the attributes of God. All human beings have for this reason an equal spiritual dignity. Accordingly, governments have a moral obligation to respect this divine endowment, an obligation that would exist even in the absence of treaties or customary legal norms obligating them to do so. Bahá’u’lláh impressed upon rulers this sacred duty: “For is it not your clear duty to restrain the tyranny of the oppressor, and to deal equitably with your subjects, that your high sense of justice may be fully demonstrated to all mankind? God hath committed into your hands the reins of the government of the people, that ye may rule with justice over them, safeguard the rights of the down-trodden, and punish the wrong-doers.” These are divinely-ordained responsibilities that no government can legitimately shirk.\nBahá’u’lláh also teaches that because of this equal spiritual dignity, all human beings are members of a single human family that should be unified. This means that all should treat one another as brothers and sisters, and in turn honor and respect the rights of all other human beings, not only as co-equals, but as spiritual relatives. He declares, “Ye are the fruits of one tree, and the leaves of one branch.” Recognition of this fundamental connectedness is a precondition, according to the Bahá’í teachings, for the full realization of human rights. Bahá’u’lláh asserts in this connection: “The well-being of mankind, its peace and security, are unattainable unless and until its unity is firmly established.” Human Rights will remain no more than a morally \nadmirable concept so long as they are not anchored in such an appreciation for human unity. That unity provides the impetus, the motivation, the will, to uphold and defend the rights of others. And it implies that human rights are the concern of everyone, not just governments.\n\nThe earliest use of the terminology of human rights in publications by Bahá’í institutions coincided with the inception of their official relationship with the United Nations. Three of the first four documents submitted to the newly established international organization in 1947 and 1948 were statements on various aspects of human rights intended as contributions to the preparatory work on the UDHR. The first of these was an eight-page statement entitled “A Bahá’í Declaration of Human Obligations and Rights” which was presented to the Human Rights Commission in February 1947 on behalf of eight national Bahá’í administrative bodies.\nThe Bahá’í International Community (BIC) explains that concern for human rights can be found throughout the Bahá’í Writings. Bahá’u’lláh, urged the rulers of the earth to “rule with justice ... safeguard the rights of the down-trodden, and punish the wrong-doers.” He taught that “there shall be an equality of rights and prerogatives for all mankind.”\n\nShoghi Effendi, the authorized interpreter of Baha’u’llah’s teachings, states that:\n“[t]he unity of the human race, as envisaged by Bahá’u’lláh, implies the establishment of a world commonwealth in which ... the autonomy of its state members and the personal freedom and initiative of the individuals that compose them are definitely and completely safeguarded. This commonwealth must, as far as we can visualize it, consist of a world legislature, whose members will, as the trustees of the whole of mankind, ultimately control the entire resources of all the component nations, and will enact such laws as shall be required to regulate the life, satisfy the needs and adjust the relationships of all races and peoples.”\n\nMoreover, in \"The Promise of World Peace\", the Universal House of Justice (the supreme governing institution of the Faith) underscores the importance of the UDHR and its related conventions, asserting that “all such measures, if courageously enforced and expanded, will advance the day when the specter of war will have lost its power to dominate international relations.”\n\nBahá’í views on human rights are based on the concept that every person is essentially a spiritual being endowed by the Creator with talents and capacities, and that the purpose of life is to realize that potential for the benefit of society as well as the individual concerned. The equal dignity of all human beings and the need for both solidarity and legal equality among them are clearly posited in many passages of the Bahá’í sacred scriptures. These ideas are encapsulated in the concept of the “oneness of mankind”, which is described as the “pivot round which all the teachings of Bahá’u’lláh revolve”.\n\nThe Bahá’í community plays an active role in enhancing a culture of human rights. Scores of statements on various aspects of human rights have been released since the presentation of “A Bahá’í Declaration of Human Obligations and Rights” in 1947. The Bahá’í community is dedicated to the integration of human rights in every aspect of global community life and favours education as the main approach to the promotion and protection of human rights.\n\nGender equality is a fundamental principle of the Bahá’í Faith. Baha’i belief states that the equality of the sexes is a spiritual and moral standard that is essential for the unification of the planet and the unfoldment of peace. The Bahá'í teachings note the importance of implementing the principle in individual, family, and community life. \nThe BIC has released various statements on gender equality and particularly the role of women. In 1947, a statement entitled “Elimination of Discrimination Against women” was presented to the 25th session of United Nations Commission on Human Rights on the Status of Women. As part of the statement, the BIC emphasized that the Baha'i Writings stress the principle of equality of education for men and women, as well as that of compulsory universal education, and elaborate the responsibilities of parents and of Bahá’í institutions to ensure equal opportunities in the education of children. In fact it is stated that if parents are not able to educate both boy and girl, the girl should be given preference because she is the future mother and first educator of the child.\n\nFor the International Women's Year in 1975, the BIC released a pamphlet entitled “Equality of Men and Woman: A New Reality” which stated that equality of the sexes is, for Bahá’ís, a spiritual and moral standard essential for the unification of the planet and the unfoldment of world order. Without the qualities, talents, and skills of both women and men, full economic and social development of the planet becomes impossible. For \"[t]he world of humanity is possessed of two wings — the male and the female. So long as these two wings are not equivalent in strength the bird will not fly. Until womankind reaches the same degree as man, until she enjoys the same arena of activity, extraordinary attainment for humanity will not be realized; humanity cannot wing its way to heights of real attainment.\"\n\nIn a statement in 2008 entitled “Eradicating Poverty: Moving Forward as One”, the BIC offered two principles as guides for efforts in the realm of poverty eradication: justice and unity. They emphasised that these principles underlie a vision of development in which material progress serves as a vehicle for the moral and cultural advancement of humanity. Justice provides the means capable of harnessing human potential to eradicate poverty from our midst, through the implementation of laws, the adjustment of economic systems, the redistribution of wealth and opportunity, and unfailing adherence to the highest ethical standards in private and public life. Unity assures that progress is systemic and relational, that a concern for the integrity of the family unit and the local, national, and global community must guide poverty alleviation efforts.\n\nFurthermore, in 2010 in their contribution to the 18th session of United Nations Commission on Human Rights on sustainable development, Bahá’í International Community (BIC) challenged the assumption that human beings are slaves to self-interest and consumerism. In the statement “Rethinking Prosperity: Forging Alternatives to a Culture of Consumerism”, they state that the transition to sustainable consumption and production is part of a global enterprise which enables all individuals to fulfill their dual purpose, namely to develop their inherent potentialities and to contribute to the betterment of the wider community. It is not enough to conceive of sustainable consumption and production in terms of creating opportunities for those living in poverty to meet their basic needs. Rather, with the understanding that each individual has a contribution to make to the construction of a more just and peaceful social order, these processes must be arranged in a way that permits each to play his or her rightful role as a productive member of society. Within such a framework, sustainable consumption and production could be characterized as processes that provide for the material, social and spiritual needs of humanity across generations and enable all peoples to contribute to the ongoing advancement of society.\n\n"}
{"id": "20852369", "url": "https://en.wikipedia.org/wiki?curid=20852369", "title": "Citizen Armed Force Geographical Unit", "text": "Citizen Armed Force Geographical Unit\n\nThe Citizen Armed Force Geographical Unit, variously called Citizens Armed Forces Geographical Unit, Civilian Armed Forces Geographical Unit and commonly referred to by its acronym CAFGU (pronounced \"kahf-goo\") is an irregular auxiliary force of the Armed Forces of the Philippines.\n\nThe CAFGU was created on July 25, 1987 when President Corazon C. Aquino signed Executive Order No. 264 entitled \"Providing for the Citizen Armed Force\". The creation of the unit was based on the \"clear, consolidate, hold and develop\" strategy adopted by then-Defense Secretary Fidel V. Ramos in dealing with insurgent-infiltrated villages.\n\nCAFGU units are components of the AFP Ready Reserve detailed to Military Auxiliary Service. Article X, Sec. 61, sub-paragraph 2 of Republic Act 7077 describes this manner of service as follows:\nMilitary auxiliary service entails services rendered in meeting local insurgency threat. Reservists serving under this category will be organized into Ready Reserve units. They must be issued and allowed to carry firearms: Provided, That these reservists will be utilized only for the defense of their respective localities and will not be employed outside their localities. Elected/appointed local government officials are expected to perform their duties and responsibilities in their respective peace and order council levels or similar organizations efficiently and effectively to enhance a total integrated system approach against threats to national security. The Secretary of National Defense shall prescribe the rules and regulations to implement this section in coordination with the Secretary of the Interior and Local Government.\nCAFGU units are administered by, and under the operational control of, regular units of the Armed Forces of the Philippines. Philippine Army infantry battalions assigned to this function are also referred to as \"Cadre Battalions\". Deactivation of CAFGU units assigned to these battalions result in the return of their status as regular infantry battalions.\n\nThe CAFGU units are tasked to prevent the re-infiltration of insurgents into communities that have already been cleared of their influence by combat operations conducted by regular units of the Armed Forces of the Philippines.\n\nThe CAFGU units are issued small arms; typically M1 Garand, M-14, or M-16 rifles, and receive a monthly stipend of Php 2,700.00 (about US$57).\n\nIn 1993, the Philippine government considered deactivating the CAFGU units due to allegations of human rights abuses; 60 CAFGU units comprising 10,000 troops were disbanded. However, in 1996, the government halted its program to completely disband the CAFGU units. As of 2007, an estimated 60,000 CAFGU troopers are active in the country, taking part in military operations alongside regular soldiers of the AFP.\n\nThe Commission on Human Rights' records show that as of 2000, 853 human rights abuse cases have been filed against 1,070 CAFGU members.\n\n\n"}
{"id": "5683120", "url": "https://en.wikipedia.org/wiki?curid=5683120", "title": "Classic of Filial Piety", "text": "Classic of Filial Piety\n\nThe Classic of Filial Piety, also known by its Chinese name as the Xiaojing, is a Confucian classic treatise giving advice on filial piety: that is, how to behave towards a senior such as a father, an elder brother, or ruler.\n\nThis document probably dates to the 4th century BC. It is not known who actually wrote the document. It is attributed to a conversation between Confucius and his disciple Zengzi. A 12th-century author named He Yin claimed: \"The \"Classic of Filial Piety\" was not made by Zengzi himself. When he retired from his conversation (or conversations) with Kung-ne on the subject of Filial Piety, he repeated to the disciples of his own school what (the master) had said, and they classified the sayings, and formed the treatise.\"\n\nAs the title suggests, the text elaborates on filial piety, which is a core Confucian value. The text argues that if a person loves and serves their parents then they will do the same for their rulers, leading to a harmonious society. For example,\n\nThe \"Classic of Filial Piety\" occupied an important position in classical education as one of the most popular foundational texts through to late imperial China. The text was used in elementary and moral education together with the Analects, Elementary Learning, and the Biographies of Exemplary Women. Study of the text was also mentioned in epitaphs as an indication of a person's good character. It was a practice to read aloud the text when mourning one's parents. The text was also important politically, partly because filial piety was both a means of demonstrating moral virtue and entering officialdom for those with family connections to the imperial court. The text was important in Neo-Confucianism, being quoted by the influential Song figure Zhu Xi.\n\nMany Japanese translations of the \"Xiaojing\" exist. The following are the primary Western language translations.\n\n\n\n\n"}
{"id": "3272320", "url": "https://en.wikipedia.org/wiki?curid=3272320", "title": "Component diagram", "text": "Component diagram\n\nIn Unified Modeling Language (UML), a component diagram depicts how components are wired together to form larger components or software systems.\nThey are used to illustrate the structure of arbitrarily complex systems.\n\nA component is something required to execute a stereotype function. Examples of stereotypes in components include executables, documents, database tables, files, and library files.\nComponents are wired together by using an \"assembly connector\" to connect the required interface of one component with the provided interface of another component. This illustrates the \"service consumer - service provider\" relationship between the two components.\n\nAn \"assembly connector\" is a \"connector between two components that defines that one component provides the services that another component requires. An assembly connector is a connector that is defined from a required interface or port to a provided interface or port.\"\n\nWhen using a component diagram to show the internal structure of a component, the provided and required interfaces of the encompassing component can delegate to the corresponding interfaces of the contained components.\n\nA \"delegation connector\" is a \"connector that links the external contract of a component (as specified by its ports) to the internal realization of that behavior by the component’s parts.\"\n\nThe example above illustrates what a typical insurance policy administration system might look like. Each of the components depicted in the above diagram may have other component diagrams illustrating its internal structure.\n\nIn the arthurian approach the system is analyzed from above not emphasizing any specific component. This approach allows for the usage of a smaller number of less detailed diagrams that still describe the system fairly accurately. It is very useful in the early stages of a project given that these diagrams are easier to change as the project develops and matures.\n\nA \"component\" is represented by a rectangle with either the keyword \"component\" or a stereotype in the top right corner: a small rectangle with two even smaller rectangles jutting out on the left.\n\nThe lollipop, a small circle on a stick, represents an implemented or provided interface. The socket symbol is a semicircle on a stick that can fit around the lollipop. This socket is a dependency or needed interface.\n\n"}
{"id": "15234652", "url": "https://en.wikipedia.org/wiki?curid=15234652", "title": "Construct (philosophy)", "text": "Construct (philosophy)\n\nA construct in the philosophy of science is an \"ideal\" object, where the existence of the thing may be said to depend upon a subject's mind. This contrasts with a \"real\" object, where existence does not seem to depend on the existence of a mind.\n\nIn a scientific theory, particularly within psychology, a hypothetical construct is an explanatory variable which is not directly observable. For example, the concepts of \"intelligence\" and \"motivation\" are used to explain phenomena in psychology, but neither is directly observable. A hypothetical construct differs from an intervening variable in that it has properties and implications which have not been demonstrated in empirical research. These serve as a guide to further research. An intervening variable, on the other hand, is a summary of observed empirical findings.\n\nThe creation of constructs is a part of operationalization, especially the creation of theoretical definitions. The usefulness of one conceptualization over another depends largely on construct validity. To address the non-observability of constructs, U.S. federal agencies such as the National Institutes of Health National Cancer Institute has created a construct database termed Grid-Enabled Measures (GEM) to improve construct use and reuse.\n\nConcepts that are considered \"constructs\" by this definition include that which is designated by the symbol \"\"3\" or the word \"liberty\"\". Scientific hypotheses and theories (e.g. evolutionary theory, gravitational theory), as well as classifications (e.g. in biological taxonomy) are also conceptual entities considered to be \"constructs\".\n\nSimple examples of real objects (that are not constructs) include silver fish and undershirts.\n\nCronbach and Meehl (1955) define a hypothetical construct as a concept for which there is not a single observable referent, which cannot be directly observed, and for which there exist multiple referents, but none all-inclusive. For example, according to Cronbach and Meehl a fish is not a hypothetical construct because, despite variation in species and varieties of fish, there is an agreed upon definition for a fish with specific characteristics that distinguish a fish from a bird. Furthermore, a fish can be directly observed. On the other hand, a hypothetical construct has no single referent; rather, hypothetical constructs consist of groups of functionally related behaviors, attitudes, processes, and experiences. Instead of seeing intelligence, love, or fear we see indicators or manifestations of what we have agreed to call intelligence, love, or fear.\nMcCorquodale and Meehl (1948) discussed the distinction between what they called intervening variables and these hypothetical constructs. McCorquodale and Meehl (1948) describe hypothetical constructs as containing surplus meaning, as they imply more than just the operations by which they are measured.\n\nIn the positivist tradition, Boring (1923) described intelligence as whatever the intelligence test measures. As a reaction to such operational definitions, Cronbach and Meehl (1955) emphasized the necessity of viewing constructs like intelligence as hypothetical constructs. They asserted that there is no adequate criterion for the operational definition of constructs like abilities and personality. Thus, according to Cronbach and Meehl (1955), a useful construct of intelligence or personality should imply more than simply test scores. Instead these constructs should predict a wide range of behaviors.\n\nBoring, E.G. (1923) \"Intelligence as the tests test it\", \"New Republic\" 36:35-37.\n\nCronbach, L.J., and Meehl, P.E. (1955) \"Construct validity in psychological tests\", \"Psychological Bulletin\" 52:281-302.\n\nMacCorquodale, K.,& Meehl, P.E. (1948). \"On a distinction between hypothetical constructs and intervening variables\", \"Psychological Review\" 55:95-107.\n"}
{"id": "39062628", "url": "https://en.wikipedia.org/wiki?curid=39062628", "title": "Creative Education Foundation", "text": "Creative Education Foundation\n\nFounded in 1954, CEF is a non profit US-American membership organization based in Buffalo (New York).\n\nThe organization was established in 1954 by the advertising specialist and creative professional Alex F. Osborn, who was known as the inventor of the term and the creativity technique of Brainstorming. As an early contribution according to its mission statement the organization held in 1955 the first annual Creative Problem Solving Institute (CPSI), an international creativity conference, at the University of Buffalo.\n\nFor years the organization had been directed by Alex Osborn together with the creativity theorist and education researcher Sid Parnes. When Alex Osborn died in 1966, Parnes took over the initiative and the chair. He installed the lifetime creative achievement award which was granted upon suggestion to persons who earned outstanding merits in the field of applied creativity. Also he installed a media-program of CEF-publications.\n\nIn 1987 John Meyerhoff took over as the CEO. He expanded CEF’s educational perspective to include business training.\n\nFurther CEOs added partnership programs and VIP-days and reinstalled CEF consulting and training programs.\n\nIn the beginning the focus relied on organizing the annual conference, evolving and applying creativity tools and techniques which can be used professionally and personally, conducting research in the field of applied creativity, problem solving and innovation, publishing books and teaching materials, and in the development of a comprehensive educational program which includes creativity specifically for scholars and young people.\n\nAs a part of its research aspirations, in 1967, the organization launched the Journal of Creative Behavior (JCB), a peer-reviewed first research publication devoted to the science of creativity, published by Wiley-Blackwell. Later, in 1972 it was followed by Creativity in Action, CEF’s monthly newsletter.\n\nSince 1979 the CPSI-conference has offered four major program streams: Springboard for novices, Leadership Development Program, CPSI YouthWise, and Extending sessions for exploratory studies.\n\nSince 1989 the organization sponsored creativity conferences in the CPSI-sense on different continents promote creativity and creative education; it started with the first Australian CPSI and was later followed by the South African ACRE-conference (since 1994) and the European CREA-conference (since 2003).\n\nIn 2003 the CEF YouthWise-program was launched in South Africa, and in 2011 the Creativity in the 21st Century Classroom course enhanced the CPSI program.\n\nToday the goals of CEF span a range of fostering creativity and giftedness including dialogue, serious play and training programs, conferences, programs, publications and other services in order to pursue the idea of creativity as human capacity which can be developed and nurtured.\n\nCentral to the Creative Education Foundation is their belief in the CPS Process. The steps are clarify, ideate, develop and implement; while the core principles include convergent and divergent thinking must be balanced, ask problems as questions, suspend judgement, and focus on \"yes and...\" rather than \"no, but...\". \n\nThe Journal of Creative Behavior:\nCEF publishes a quarterly academic citing research in creative thinking titled, \"The Journal of Creative Behavior\". Edited by Ronald A. Beghetto from the University of Connecticut, the journal deals with methods to foster creative productivity, giftedness, management of creative personnel, testing, creativity in business and industry, development of creative curricula, creativity in the arts and sciences, and reviews of literature on creativity and problem solving. The content also focuses on the creative process. After self-publishing 45 volumes since 1967, the Journal of Creative Behavior moved to Wiley-Blackwell, a commercial publisher of academic journals.\n\n\n"}
{"id": "48373223", "url": "https://en.wikipedia.org/wiki?curid=48373223", "title": "Gender empowerment", "text": "Gender empowerment\n\nGender empowerment is the empowerment of people of any gender. While conventionally being reduced to its aspect of empowerment of women, the concept stresses the distinction between biological sex and gender as a role, also referring to other marginalized genders in a particular political or social context.\n\nGender empowerment has become a significant topic of discussion in regard to development and economics. Entire nations, businesses, communities, and groups can benefit from the implementation of programs and policies that adopt the notion of women empowerment. Empowerment is one of the main procedural concerns when addressing human rights and development. The Human Development and Capabilities Approach, The Millennium Development Goals, and other credible approaches/goals point to empowerment and participation as a necessary step if a country is to overcome the obstacles associated with poverty and development.\n\nGender empowerment can be measured through the Gender Empowerment Measure, or the GEM. The GEM shows women's participation in a given nation, both politically and economically. Gem is calculated by tracking \"the share of seats in parliament held by women; of female legislators, senior officials and managers; and of female profession and technical workers; and the gender disparity in earned income, reflecting economic independence.\" It then ranks countries given this information. Other measures that take into account the importance of female participation and equality include: the Gender Parity Index and the Gender Development Index (GDI).\n\n"}
{"id": "41678745", "url": "https://en.wikipedia.org/wiki?curid=41678745", "title": "Globoid (botany)", "text": "Globoid (botany)\n\nA globoid is a spherical crystalline inclusion in a protein body found in seed tissues that contains phytate and other nutrients for plant growth. These are found in several plants, including wheat and the genus \"Cucurbita\". These nutrients are eventually completely depleted during seedling growth. In \"Cucurbita maxima\", globoids form as early as the 3rd day of seedling growth. They are located in conjunction with a larger crystalloid. They are electron–dense and vary widely in size.\n"}
{"id": "13912", "url": "https://en.wikipedia.org/wiki?curid=13912", "title": "Hollow Earth", "text": "Hollow Earth\n\nThe Hollow Earth is a historical concept proposing that the planet Earth is entirely hollow or contains a substantial interior space. \nNotably suggested by Edmond Halley in the late 17th century, the notion was tentatively disproven by Pierre Bouguer in 1740, and definitely by Charles Hutton (1778).\n\nIt was still occasionally defended in the early-to-mid 19th century, notably by John Cleves Symmes Jr. and Jeremiah N. Reynolds, but by this time was part of popular pseudoscience and no longer a scientifically viable hypothesis.\n\nThe concept of a hollow Earth still recurs in folklore and as the premise for subterranean fiction, and a subgenre of adventure fiction (\"Journey to the Center of the Earth\", \"At the Earth's Core\").\n\nIn ancient times, the concept of a subterranean land inside the Earth appeared in mythology, folklore and legends. The idea of subterranean realms seemed arguable, and became intertwined with the concept of \"places\" of origin or afterlife, such as the Greek underworld, the Nordic Svartálfaheimr, the Christian Hell, and the Jewish Sheol (with details describing inner Earth in Kabalistic literature, such as the Zohar and Hesed L'Avraham). The idea of a subterranean realm is also mentioned in Tibetan Buddhist belief. According to one story from Tibetan Buddhist tradition, there is an ancient city called Shamballa which is located inside the Earth.\n\nAccording to the Ancient Greeks, there were caverns under the surface which were entrances leading to the underworld, some of which were the caverns at Tainaron in Lakonia, at Troezen in Argolis, at Ephya in Thesprotia, at Herakleia in Pontos, and in Ermioni. In Thracian and Dacian legends, it is said that there are underground chambers occupied by an ancient god called Zalmoxis. In Mesopotamian religion there is a story of a man who, after traveling through the darkness of a tunnel in the mountain of \"Mashu\", entered a subterranean garden.\n\nIn Celtic mythology there is a legend of a cave called \"Cruachan\", also known as \"Ireland's gate to Hell\", a mythical and ancient cave from which according to legend strange creatures would emerge and be seen on the surface of the Earth. There are also stories of medieval knights and saints who went on pilgrimages to a cave located in Station Island, County Donegal in Ireland, where they made journeys inside the Earth into a place of purgatory. In County Down, Northern Ireland there is a myth which says tunnels lead to the land of the subterranean Tuatha Dé Danann, a group of people who are believed to have introduced Druidism to Ireland, and then went back underground.\n\nIn Hindu mythology, the underworld is referred to as Patala. In the Bengali version of the Hindu epic Ramayana, it has been depicted how Rama and Lakshmana were taken by the king of the underworld Ahiravan, brother of the demon king Ravana. Later on they were rescued by Hanuman. The Angami Naga tribes of India claim that their ancestors emerged in ancient times from a subterranean land inside the Earth. The Taino from Cuba believe their ancestors emerged in ancient times from two caves in a mountain underground.\n\nNatives of the Trobriand Islands believe that their ancestors had come from a subterranean land through a cavern hole called \"Obukula\". Mexican folklore also tells of a cave in a mountain five miles south of Ojinaga, and that Mexico is possessed by devilish creatures who came from inside the Earth.\n\nIn the middle ages, an ancient German myth held that some mountains located between Eisenach and Gin Germany hold a portal to the inner Earth. A Russian legend says the Samoyeds, an ancient Siberian tribe, traveled to an underground cavern city to live inside the Earth. The Italian writer Dante describes a hollow earth in his well-known 14th century work \"Inferno\", in which the fall of Lucifer from heaven caused an enormous funnel to appear in a previously solid and spherical earth, as well as an enormous mountain opposite it, \"Purgatory\".\n\nIn Native American mythology, it is said that the ancestors of the Mandan people in ancient times emerged from a subterranean land through a cave at the north side of the Missouri River. There is also a tale about a tunnel in the San Carlos Apache Indian Reservation in Arizona near which is said to lead inside the Earth to a land inhabited by a mysterious tribe. It is also the belief of the tribes of the Iroquois that their ancient ancestors emerged from a subterranean world inside the Earth. The elders of the Hopi people believe that a Sipapu entrance in the Grand Canyon exists which leads to the underworld.\n\nBrazilian Indians, who live alongside the Parima River in Brazil, claim that their forefathers emerged in ancient times from an underground land, and that many of their ancestors still remained inside the Earth. Ancestors of the Inca supposedly came from underground caves which are located east of Cuzco, Peru.\n\nEdmond Halley in 1692 put forth the idea of Earth consisting of a hollow shell about thick, two inner concentric shells and an innermost core. Atmospheres separate these shells, and each shell has its own magnetic poles. The spheres rotate at different speeds. Halley proposed this scheme in order to explain anomalous compass readings. He envisaged the atmosphere inside as luminous (and possibly inhabited) and speculated that escaping gas caused the Aurora Borealis.\n\nDe Camp and Ley have claimed (in their \"Lands Beyond\") that Leonhard Euler also proposed a hollow-Earth idea, getting rid of multiple shells and postulating an interior sun across to provide light to advanced inner-Earth civilizations but they provide no references; indeed, Euler did not propose a hollow-Earth, but there is a slightly related thought experiment.\n\nDe Camp and Ley also claim that Sir John Leslie expanded on Euler's idea, suggesting two central suns named Pluto and Proserpine (this was unrelated to the planet Pluto, which was discovered and named a century later). Leslie did propose a hollow Earth in his 1829 \"Elements of Natural Philosophy\" (pp. 449–53), but does not mention interior suns. Jules Verne alludes to the Pluto-Proserpine theory, which he attributes to \"an English captain\", in \"Journey to the Center of the Earth.\"\n\nLe Clerc Milfort in 1781 led a journey with hundreds of Creek Indians to a series of caverns near the Red River above the junction of the Mississippi River. According to Milfort the original Creek Indian ancestors are believed to have emerged out to the surface of the Earth in ancient times from the caverns. Milfort also claimed the caverns they saw \"could easily contain 15,000 – 20,000 families.\"\n\nIn 1818, John Cleves Symmes, Jr. suggested that the Earth consisted of a hollow shell about thick, with openings about across at both poles with 4 inner shells each open at the poles. Symmes became the most famous of the early Hollow Earth proponents, and Hamilton, Ohio, even has a monument to him and his ideas. He proposed making an expedition to the North Pole hole, thanks to efforts of one of his followers, James McBride.\n\nJeremiah Reynolds also delivered lectures on the \"Hollow Earth\" and argued for an expedition. Reynolds went on an expedition to Antarctica himself but missed joining the Great U.S. Exploring Expedition of 1838–1842, even though that venture was a result of his agitation.\n\nThough Symmes himself never wrote a book about his ideas, several authors' published works discussing his ideas. McBride wrote \"Symmes' Theory of Concentric Spheres\" in 1826. It appears that Reynolds has an article that appeared as a separate booklet in 1827: \"Remarks of Symmes' Theory Which Appeared in the American Quarterly Review.\" In 1868, a professor W.F. Lyons published \"The Hollow Globe\" which put forth a Symmes-like Hollow Earth hypothesis, but failed to mention Symmes himself. Symmes's son Americus then published \"The Symmes' Theory of Concentric Spheres\" in 1878 to set the record straight.\n\nWilliam Fairfield Warren, in his book \"Paradise Found–The Cradle of the Human Race at the North Pole,\" (1885) presented his belief that humanity originated on a continent in the Arctic called Hyperborea. This influenced some early Hollow Earth proponents. According to Marshall Gardner, both the Eskimo and Mongolian peoples had come from the interior of the Earth through an entrance at the North pole.\n\n\"NEQUA or The Problem of the Ages\", first serialized in a newspaper printed in Topeka, Kansas in 1900 and considered an early feminist utopian novel, mentions John Cleves Symmes' theory as an explanation for the hollow Earth they sail into.\n\nAn early twentieth-century proponent of hollow Earth, William Reed, wrote \"Phantom of the Poles\" in 1906. He supported the idea of a hollow Earth, but without interior shells or inner sun.\n\nThe spiritualist writer Walburga, Lady Paget in her book \"Colloquies with an unseen friend\" (1907) was an early writer to mention the hollow Earth hypothesis. She claimed that cities exist beneath a desert, which is where the people of Atlantis moved. She said an entrance to the subterranean kingdom will be discovered in the 21st century.\n\nMarshall Gardner wrote \"A Journey to the Earth's Interior\" in 1913 and published an expanded edition in 1920. He placed an interior sun in the Earth and built a working model of the Hollow Earth which he patented (). Gardner made no mention of Reed, but did criticize Symmes for his ideas. Around the same time, Vladimir Obruchev wrote a novel titled \"Plutonia\", in which the Hollow Earth possessed an inner Sun and was inhabited by prehistoric species. The interior was connected with the surface by an opening in the Arctic.\n\nThe explorer Ferdynand Ossendowski wrote a book in 1922 titled \"Beasts, Men and Gods\". Ossendowski said he was told about a subterranean kingdom that exists inside the Earth. It was known to Buddhists as Agharti.\n\nGeorge Papashvily in his \"Anything Can Happen\" (1940) claimed the discovery in the Caucasus mountains of a cavern containing human skeletons \"with heads as big as bushel baskets\" and an ancient tunnel leading to the centre of the Earth. One man entered the tunnel and never returned.\n\nNovelist Lobsang Rampa in his book \"The Cave of the Ancients\" said an underground chamber system exists beneath the Himalayas of Tibet, filled with ancient machinery, records and treasure. Michael Grumley, a cryptozoologist, has linked Bigfoot and other hominid cryptids to ancient tunnel systems underground.\n\nAccording to the ancient astronaut writer Peter Kolosimo a robot was seen entering a subterranean tunnel below a monastery in Mongolia. Kolosimo also claimed a light was seen from underground in Azerbaijan. Kolosimo and other ancient astronaut writers such as Robert Charroux linked these activities to UFOs.\n\nA book by a \"Dr. Raymond Bernard\" which appeared in 1964, \"The Hollow Earth\", exemplifies the idea of UFOs coming from inside the earth, and adds the idea that the Ring Nebula proves the existence of hollow worlds, as well as speculation on the fate of Atlantis and the origin of flying saucers. An article by Martin Gardner revealed that Walter Siegmeister used the pseudonym \"Bernard\", but not until the 1989 publishing of Walter Kafton-Minkel's \"Subterranean Worlds: 100,000 Years of Dragons, Dwarfs, the Dead, Lost Races & UFOs from Inside the Earth\" did the full story of Bernard/Siegmeister become well known.\n\nThe science fiction pulp magazine \"Amazing Stories\" promoted one such idea from 1945 to 1949 as \"the Shaver Mystery\". The magazine's editor, Ray Palmer, ran a series of stories by Richard Sharpe Shaver, claiming that a superior pre-historic race had built a honeycomb of caves in the Earth, and that their degenerate descendants, known as \"Dero\", live there still, using the fantastic machines abandoned by the ancient races to torment those of us living on the surface. As one characteristic of this torment, Shaver described \"voices\" that purportedly came from no explainable source. Thousands of readers wrote to affirm that they, too, had heard the fiendish voices from inside the Earth. The writer David Hatcher Childress authored \"Lost Continents and the Hollow Earth\" (1998) in which he reprinted the stories of Palmer and defended the Hollow Earth idea based on alleged tunnel systems beneath South America and Central Asia.\n\nHollow Earth proponents have claimed a number of different locations for the entrances which lead inside the Earth. Other than the North and South poles, entrances in locations which have been cited include: Paris in France, Staffordshire in England, Montreal in Canada, Hangchow in China, and the Amazon Rainforest.\n\nInstead of saying that humans live on the outside surface of a hollow planet—sometimes called a \"convex\" Hollow Earth hypothesis—some have claimed humans live on the \"inside\" surface of a hollow spherical world, so that our universe itself lies in that world's interior. This has been called the \"concave\" Hollow Earth hypothesis or skycentrism.\n\nCyrus Teed, a doctor from upstate New York, proposed such a concave Hollow Earth in 1869, calling his scheme \"Cellular Cosmogony\". Teed founded a group called the Koreshan Unity based on this notion, which he called Koreshanity. The main colony survives as a preserved Florida state historic site, at Estero, Florida, but all of Teed's followers have now died. Teed's followers claimed to have experimentally verified the concavity of the Earth's curvature, through surveys of the Florida coastline making use of \"rectilineator\" equipment.\n\nSeveral twentieth-century German writers, including Peter Bender, Johannes Lang, Karl Neupert, and Fritz Braut, published works advocating the Hollow Earth hypothesis, or \"Hohlweltlehre\". It has even been reported, although apparently without historical documentation, that Adolf Hitler was influenced by concave Hollow Earth ideas and sent an expedition in an unsuccessful attempt to spy on the British fleet by pointing infrared cameras up at the sky.\n\nThe Egyptian mathematician Mostafa Abdelkader wrote several scholarly papers working out a detailed mapping of the Concave Earth model.\n\nIn one chapter of his book \"On the Wild Side\" (1992), Martin Gardner discusses the Hollow Earth model articulated by Abdelkader. According to Gardner, this hypothesis posits that light rays travel in circular paths, and slow as they approach the center of the spherical star-filled cavern. No energy can reach the center of the cavern, which corresponds to no point a finite distance away from Earth in the widely accepted scientific cosmology. A drill, Gardner says, would lengthen as it traveled away from the cavern and eventually pass through the \"point at infinity\" corresponding to the center of the Earth in the widely accepted scientific cosmology. Supposedly no experiment can distinguish between the two cosmologies.\n\nGardner notes that \"most mathematicians believe that an inside-out universe, with properly adjusted physical laws, is empirically irrefutable\". Gardner rejects the concave Hollow Earth hypothesis on the basis of Occam's razor.\n\nPurportedly verifiable hypotheses of a \"Concave Hollow Earth\" need to be distinguished from a thought experiment\nwhich defines a coordinate transformation such that the interior of the Earth becomes \"exterior\" and the exterior becomes \"interior\". (For example, in spherical coordinates, let radius \"r\" go to \"R\"/\"r\" where \"R\" is the Earth's radius.) The transformation entails corresponding changes to the forms of physical laws. This is not a hypothesis but an illustration of the fact that any description of the physical world can be equivalently expressed in more than one way.\n\nThe picture of the structure of the Earth that has been arrived at through the study of seismic waves is quite different from the Hollow Earth hypothesis. The time it takes for seismic waves to travel through and around the Earth directly contradicts a hollow sphere. The evidence indicates that the Earth is filled with solid rock (mantle and crust), liquid nickel-iron alloy (outer core), and solid nickel-iron (inner core).\n\nAnother set of scientific arguments against a Hollow Earth or any hollow planet comes from gravity. Massive objects tend to clump together gravitationally, creating non-hollow spherical objects such as stars and planets. The solid sphere is the best way in which to minimize the gravitational potential energy of a physical object; having hollowness is unfavorable in the energetic sense. In addition, ordinary matter is not strong enough to support a hollow shape of planetary size against the force of gravity; a planet-sized hollow shell with the known, observed thickness of the Earth's crust would not be able to achieve hydrostatic equilibrium with its own mass and would collapse.\n\nBased upon the size of the Earth and the force of gravity on its surface, the average density of the planet Earth is 5.515 g/cm, and typical densities of surface rocks are only half that (about 2.75 g/cm). If any significant portion of the Earth were hollow, the average density would be much lower than that of surface rocks. The only way for Earth to have the force of gravity that it does is for much more dense material to make up a large part of the interior. Nickel-iron alloy under the conditions expected in a non-hollow Earth would have densities ranging from about 10 to 13 g/cm, which brings the average density of Earth to its observed value.\n\nDrilling holes does not provide direct evidence against the hypothesis. The deepest hole drilled to date is the Kola Superdeep Borehole, with a true vertical drill-depth of more than 7.5 miles (12 kilometers). However, the distance to the center of the Earth is nearly 4,000 miles (6,400 kilometers). Oil wells with longer depths are not vertical wells; the total depths quoted are measured depth (MD) or equivalently, along-hole depth (AHD) as these wells are deviated to horizontal. Their true vertical depth (TVD) are typically less than 4000 m.\n\nThe idea of a hollow Earth is a common element of fiction, appearing as early as Ludvig Holberg's 1741 novel \"Nicolai Klimii iter subterraneum\" (Niels Klim's Underground Travels), in which Nicolai Klim falls through a cave while spelunking and spends several years living on a smaller globe both within and the inside of the outer shell.\n\nOther notable pre-20th century examples include Giacomo Casanova's 1788 \"Icosaméron\", a 5-volume, 1,800-page story of a brother and sister who fall into the Earth and discover the subterranean utopia of the Mégamicres, a race of multicolored, hermaphroditic dwarves; \"\" by a \"Captain Adam Seaborn\" (1820) which reflected the ideas of John Cleves Symmes, Jr.; Edgar Allan Poe's 1838 novel \"The Narrative of Arthur Gordon Pym of Nantucket;\" Jules Verne's 1864 novel \"Journey to the Center of the Earth,\" which described a prehistoric subterranean world; and George Sand's 1864 novel \"Laura, Voyage dans le Cristal\" where unseen and giant crystals could be found in the interior of the Earth.\n\nIn William Henry Hudson's 1887 romance, \"A Crystal Age\", the protagonist falls down a hill into a Utopian, asexual, pastoral paradise; since he falls into this world, it is sometimes classified as a hollow Earth story; although the hero himself thinks he may have traveled forward in time by millennia.\n\nThe idea was used by Edgar Rice Burroughs, the creator of Tarzan, in the seven-novel \"Pellucidar\" series, beginning with \"At the Earth's Core\" (1914). Using a mechanical drill, his heroes discover a prehistoric world, called Pellucidar, 500 miles below the surface, that is lit by an inner sun. The 1915 novel \"Plutonia \"by Vladimir Obruchev uses the concept of the hollow Earth to take the reader through various geological epochs.\n\nIn recent decades, the idea has become a staple of the science fiction and adventure genres, appearing in print; in film, notably as the premise for the creatures in \"\"; on television programs such as \"Sanctuary\", where Hollow Earth formed the core of the story arcs of the third and fourth seasons; in comics; in role-playing games, such as the Hollow World Campaign Set for Dungeons & Dragons; in video games like \"Gears of War\", where humans live on an Earth-like planet with a mostly hollow interior; and in many animated works, such as Torin's Passage, where the hero must travel to the \"lands below\" to rescue his family.\n\n\n\n"}
{"id": "205834", "url": "https://en.wikipedia.org/wiki?curid=205834", "title": "Humiliation", "text": "Humiliation\n\nHumiliation is the abasement of pride, which creates mortification or leads to a state of being humbled or reduced to lowliness or submission. It is an emotion felt by a person whose social status, either by force or willingly, has just decreased. It can be brought about through intimidation, physical or mental mistreatment or trickery, or by embarrassment if a person is revealed to have committed a socially or legally unacceptable act. Whereas humility can be sought alone as a means to de-emphasize the ego, humiliation must involve other person(s), though not necessarily directly or willingly. \n\nHumiliation is currently an active research topic, and is now seen as an important – and complex – core dynamic in human relationships, having implications at intrapersonal, interpersonal, institutional and international levels.\n\nA person who suffers from severe humiliation could experience major depressions, suicidal states, and severe anxiety states such as post-traumatic stress disorder. The loss of status, like losing a job or being labeled as a liar or discredited unfairly, could cause people inability to behave normally in their communities. Humiliated individuals could be provoked and crave for revenge, and some people could feel worthless, hopeless and helpless, creating suicidal thoughts if justice is not met. It also can lead to new insights, activism and a new kinship with marginalized groups.\n\nFeelings of humiliation can produce 'humiliated fury' which, when turned inward can result in apathy and depression, and when turned outward can give rise to paranoia, sadistic behaviour and fantasies of revenge. Klein explains, \"When it is outwardly directed, humiliated fury unfortunately creates additional victims, often including innocent bystanders ... . When it is inwardly directed, the resulting self-hate renders victims incapable of meeting their own needs, let alone having energy available to love and care for others.\" He goes on to say, \"In either case, those who are consumed by humiliated fury are absorbed in themselves or their cause, wrapped in wounded pride...\" \n\nA study by researchers at the University of Michigan revealed that “the same regions of the brain that become active in response to painful sensory experiences are activated during intense experiences of social rejection.” In other words, humiliation and isolation are experienced as intensely as physical pain.\n\nHumiliating of one person by another (the humiliator) is often used as a way of asserting power over them, and is a common form of oppression or abuse used in a police, military, or prison context during legal interrogations or illegal torture sessions. Many now-obsolete public punishments were deliberately designed to be humiliating, e.g. tarring and feathering lawbreakers, pillory, \"mark of shame\" (stigma) as a means of \"making an example\" of a person and presenting a deterrent to others. Some practices, such as tarring and feathering, became tools of unofficial mob justice. In folk customs such as the English skimmington rides and rough music (and their continental equivalents, such as the French Charivari), dramatic public demonstrations of moral disapproval were enacted to humiliate transgressors and drive them out of the community.\n\nSome U.S. states have experimented with humiliating or shaming lawbreakers by publishing their names and indicating their offense (e.g., with soliciting prostitutes or drinking and driving). In 2010, there was public outcry about reports showing police in Dongguan and Guangdong in China leading a parade of arrested prostitutes for the purpose of humiliating them. The national Ministry of Public Security reprimanded the local police and affirmed that such punishments are not allowed.\nDonald Klein described humiliation as \"a powerful factor in human affairs that has, for a variety of reasons, been overlooked by students of individual and collective behavior. It is a pervasive and all too destructive influence in the behavior of individuals, groups, organizations, and nations.\"\n\nThough it is a subjective emotion, humiliation has a universal aspect which applies to all human beings: \"it is the feeling of being put down, made to feel less than one feels oneself to be.\"\n\nA society that suffers from humiliation is an unstable one. The cognitive dissonance between the way in which the society is perceived and the way in which it sees itself can be so great that violence can result on a massive scale against people belonging to an out group. According to Jonathan Sacks, \"By turning the question 'What did we do wrong?' into 'Who did this to us?', [hate against an out group] restores some measure of self-respect and provides a course of action. In psychiatry, the clinical terms for this process are splitting and projection; it allows people to define themselves as victims.\"\n\n\n"}
{"id": "3952243", "url": "https://en.wikipedia.org/wiki?curid=3952243", "title": "Involuntary memory", "text": "Involuntary memory\n\nInvoluntary memory, also known as involuntary explicit memory, involuntary conscious memory, involuntary aware memory, and most commonly, involuntary autobiographical memory, is a subcomponent of memory that occurs when cues encountered in everyday life evoke recollections of the past without conscious effort. Voluntary memory, its binary opposite, is characterized by a deliberate effort to recall the past.\nThere appear to be at least three different contexts within which involuntary memory arises, as described by J.H. Mace in his book \"Involuntary Memory\". These include those that occur in everyday life, those that occur during the processes of voluntary and involuntary recall, and those that occur as part of a psychiatric syndrome.\n\nThese include involuntary memories as they arise in everyday mental functioning, comprising the most common occurrences. They are characterized by their element of surprise, as they appear to come into conscious awareness spontaneously. They are the products of common every-day experiences such as eating a piece of cake, bringing to mind a past experience evoked by the taste. The term \"precious fragments\" was coined by Marigold Linton, a pioneer in the study of autobiographical memory research.\n\nThese are less common, and appear to be the result of voluntary/involuntary retrieval. Characteristic of such occurrences is the triggering effect this has, as one involuntary memory leads to another and so on. Again, Linton describes her own experiences with such memories as \"...coming unbidden sometimes when my mind is silent, but also as by-products of searches for other information\".\n\nFinally, some involuntary memories arise from traumatic experiences, and as such are fairly rare compared to other involuntary memories. Subjects describe them as salient, repetitive memories of traumatic events. The troubling nature of such memories makes these occurrences important to clinical researchers in their studies of psychiatric syndromes such as post-traumatic stress disorder.\n\nBorn in Bremen, Germany in 1850, Hermann Ebbinghaus is recognized as the first to apply the principles of experimental psychology to studying memory. He is especially well known for his introduction and application of nonsense syllables in studying memory. Nonsense syllables are combinations of letters that do not follow grammatical rules, and are meant to lack any meaning. Ebbinghaus designed the use of them to study his own memory by memorizing lists of nonsense syllables and testing his own recall after specified time intervals. From this he discovered the forgetting curve and the spacing effect, two of his most well-known contributions. Ebbinghaus was also the first to attempt a description of involuntary memory, stating that, 'Often, even after years, mental states once present in consciousness return to it with apparent spontaneity and without any act of the will; that is, they are reproduced involuntarily. Here, also, in the majority of cases we at once recognize the returned mental state as one that has already been experienced; that is, we remember it. Under certain conditions, however, this accompanying consciousness is lacking, and we know only indirectly that the \"now\" must be identical with the \"then\"; yet we receive in this way a no less valid proof for its existence during the intervening time. As more exact observation teaches us, the occurrence of these involuntary reproductions is not an entirely random and accidental one. On the contrary they are brought about through the instrumentality of other immediately present mental images. Moreover, they occur in certain regular ways that, in general terms, are described under the so-called \"laws of association\".'\n\nMarcel Proust was the first person to coin the term involuntary memory, in his novel \"À la Recherche du Temps Perdu\" (\"In Search of Lost Time\" or \"Remembrance of Things Past\"). Proust did not have any psychological background, and worked primarily as a writer.\n\nProust viewed involuntary memory as containing the \"essence of the past\", claiming that it was lacking from voluntary memory. In his novel, he describes an incident where he was eating tea soaked cake, and a childhood memory of eating tea soaked cake with his aunt was \"revealed\" to him. From this memory, he then proceeded to be reminded of the childhood home he was in, and even the town itself. This becomes a theme throughout \"In Search of Lost Time\", with sensations reminding Proust of previous experiences. He dubbed these \"involuntary memories\".\n\nOne idea that has recently become the subject of studies on involuntary memory is chaining. This is the concept that involuntary memories have the tendency to trigger other involuntary memories that are related. Typically, it is thought to be the contents of involuntary memories that are related to one another, thereby causing the chaining effect.\n\nIn a diary study done by J.H Mace, participants reported that frequently, when one involuntary memory arose, it would quickly trigger a series of other involuntary memories. This was recognized as the cueing source for involuntary memories.\n\nIn work by Bernsten, the diary method was also applied to the study of involuntary memory chaining. The main hypothesis was that chaining would also occur on autobiographical memory tasks. Participants were asked to report the presence of involuntary memories while performing an autobiographical memory task. Results showed that participants did experience involuntary memory recall when they were recalling the past deliberately (also known as voluntary memory). This implies that involuntary memory production occurs as a product of chaining from voluntary memory—deliberate recall of the past.\n\nA common question in the study of involuntary memory is related to priming; what is it that activates such a memory? Various studies have been conducted in recent years to observe the conditions under which involuntary memories are primed.\n\nMace, in one of his recent studies, wanted to test the notion that basic cognitive activities, such as thinking about the past, may prime involuntary memories. To test this idea, Mace set up a diary method study in which participants recorded involuntary memories they experienced during a two-week period, in a diary. During this two-week period, participants also had to come into a laboratory at intervals, and were instructed to recall memories from certain life periods (e.g., high school, first five years of marriage). Following this, comparing their involuntary memories to a control condition found that a significant number of their involuntary memories related to the time period they were instructed to recall. Such findings suggest that involuntary memories may be primed by even the simplest of cognitive tasks—namely, reminiscing and recalling the past.\n\nResearch studies regarding the neurological functions of involuntary memory have been few in number. Thus far, only two neuroimaging studies have been conducted comparing involuntary memories to voluntary memories using Positron Emission Tomography (PET).\n\nThe first study found that involuntary memory retrieval is mediated by the hippocampus, which is known to be associated with successful episodic memory retrieval. In addition, activity in areas such as the left inferior frontal gyrus, left superior temporal gyrus, left hippocampus, and right superior occipital cortex, have been implicated in involuntary memory when dealing with involuntary word recognition tasks. Areas implicated with executive control processes such as right dorsolateral prefrontal cortex, and bilateral medial/lateral parietal cortex were more active during voluntary word recognition tasks.\n\nThe second study found that the medial temporal lobe, the posterior cingulate gyrus, and the precunueus, are activated during retrieval success with or without executive control seen within right dorsolateral prefrontal cortex. This implies that involuntary memories are successfully retrieved using the same system as voluntary memory when retrieving perceptual information. Voluntary and involuntary recall were both associated with increased activations in the posterior cingulated gyrus, left precuneus, and right parahippocampal gyrus. In addition, right dorsolateral prefrontal cortex, and left precuneus were more active during voluntary recall, while left dorsolateral prefrontal cortex was more active during involuntary recall. It is suggested that the activation seen in left dorsolateral prefrontal cortex during involuntary memory recall reflects the attempt to prevent the recollected material from interfering with the semantic judgment task.\n\nWhile age plays a role in memory capabilities, it has been found that general strategies used to encode (to remember) memories is more important. Those that are better at memorizing information are more likely to have more involuntary memories. \nIn younger children (ages 10 and under), it has also been found that inducing involuntary memory during testing produced significantly better results than using voluntary memory. This can be accomplished by posing a vague, mildly related question or sentence prior to the actual test question. In older children (aged 14 and above), the opposite holds, with strictly voluntary memory leading to better test results.\n\nThe reminiscence bump is the phenomenon where in memories formed during adolescence and early adulthood are more commonly remembered than those throughout other periods in life. This is due to the formation of self-identity or the development of cognitive abilities across the lifespan. It has been found that this is true for both voluntary and involuntary memories. Age has been found to have a difference on the amount of memories recalled, but no age differences were found in the specificity of involuntary memories.\n\nEmotion plays a strong role in relation to memory. It has been found that memories associated with stronger emotions (e.g.: being happy at your wedding) are more easily remembered and quickly recalled, as are those formed during moments of intense stress. The same holds true for involuntary memories, with happy involuntary memories occurring twice as often as unhappy or neutral involuntary memories.\n\nOften people who have been the victims of some type of trauma describe vivid memories that intrude on their thoughts spontaneously and without warning. Such mental intrusions, if maintained over time compose the hallmark symptom of posttraumatic stress disorder (PTSD).\n\nThe \"DSM-IV\" defines a trauma as an event in which someone experiences, or witnesses' severe injury to themselves or others or a threat to their integrity. The person must also have responded with fear, helplessness or horror at the time of the trauma. The main psychological consequences of this include re-experiencing the traumatic event (through both intrusive thoughts and images), avoidance of trauma-related stimuli, and increased arousal levels.\n\nWhen it comes to involuntary memory, researchers are mainly interested in the concept of these trauma-related intrusions, which generally involved some form of re-experiencing the event, including a sensory component (e.g., imagery in any modality be it visual, auditory etc.). These intrusions, often termed \"flashbacks\", make the victim feel as though they are reliving the trauma, and cause high levels of emotional arousal, and the sense of an impending threat. Typically, they are parts of the traumatic event that were most salient at the time, known as \"hotspots\" and have the definitive feature that they cause high levels of emotional distress, and may be difficult to recall deliberately. Although this is a defining feature of PTSD, intrusive memories are also frequently encountered in anxiety-based disorders, psychotic disorders and even within the general population. Regardless of the context in which they are encountered, intrusions tend to have the same central feature; that the stored information is being recalled involuntarily. It is thought that intrusions arise when an individual encounters stimuli similar to the stimuli that were processed and stored during the trauma, thus triggering the memory into the conscious mind. A common example is one in which someone who has the victim of a car crash, upon hearing the screeching of tires experiences a flashback of their own collision, as if they are back at the original event.\n\nStressful and traumatic events, which may manifest as involuntary memories called \"flashbacks\", may trigger a wide range of anxiety-based and psychotic disorders. Social phobia, bipolar disorder, depression, and agoraphobia, are a few examples of disorders that have influences from flashbacks.\n\nPsychosis is defined as a range of perceptual presentations, with the associated symptoms frequently referred to as either \"positive\" or \"negative\". Positive symptoms are delusional, and may include hallucinations, while negative symptoms are characterized by a \"lack\" of functioning, which may include a lack of affect (emotional feeling) and loss of motivation. One study found that there was a high prevalence of trauma in patients with severe mental illness. However, only a small percentage had been diagnosed with PTSD when displaying PTSD-like symptoms. Therefore, the more complex symptoms of psychosis may prevent the clinical detection required when diagnosing PTSD. In addition, those who have been diagnosed with PTSD and have an identified form of trauma show positive symptoms of psychosis such as delusions and/or hallucinations. Finally, it has been suggested that individuals suffering from psychosis may be more vulnerable to intrusions.\n"}
{"id": "31940598", "url": "https://en.wikipedia.org/wiki?curid=31940598", "title": "Kebony", "text": "Kebony\n\nKebony is a Norwegian wood producer. The company has its roots in Wood Polymer Technologies (WPT), which was founded in 1996 and changed its name to Kebony in 2007. Kebony has a factory in Skien (Norway) and offices in Oslo (Norway).\n\nKebony has developed an environmental technology which provides an alternative to threatened and endangered tropical hardwoods, and traditional impregnated wood. In the process, a liquid byproduct of the sugar industry, furfuryl alcohol, is used to treat the wood. Using pressure, vacuum and heat treatment, the liquid transforms to furan resin and is tied together with the cell structure of the wood in order to improve the wood's abilities permanently. The woods used are FSC-certified, PEFC-certified and carry the Nordic Ecolabel \"the Swan\".\n\nThe technology has been described in multiple articles in media such as CNN, BBC, The Economist and Financial Times.\nCNBC Business has listed Kebony as one of Europe's 25 most creative companies.\n\n"}
{"id": "55501325", "url": "https://en.wikipedia.org/wiki?curid=55501325", "title": "Layle Lane", "text": "Layle Lane\n\nLayle Lane (November 27, 1893 – February 2, 1976) was an African American educator and civil rights activist.\n\nLane was born in Marietta, Georgia in 1893 to Reverend Calvin Lane and Alice Virginia Clark Lane. She was their fourth child. Her father was a Congregationalist minister and her mother was a teacher. Her family left Georgia after her father was threatened to be lynched. The family resettled in Knoxville, Tennessee, and three years later in Vineland, New Jersey. In Vineland, Lane attended Vineland High School, where she was the first black graduate of the school. Lane never married. In 1976, she died in Cuernavaca, Mexico.\n\nLane graduated from Howard University in 1916. After being unable to receive a job as a teacher in a New York public school, she returned to school earned a second undergraduate degree at Hunter College. She received her master's degree from Columbia University.\n\nLane became a high school teacher, teaching social studies in a New York high school. Lane was heavily involved in activism throughout her life, and participated in many protests for African American rights and workers' rights. She became an early member of the Teachers Union, and later the Teachers Guild. She served on the executive board of the Teacher's Guild.\n\nLane was elected the first black female American Federation of Teachers vice president. She ran five times as a candidate in the Socialist Party for public office. Three of those times were for Congress. Lane served on the National Committee for Rural Schools. She helped to plan and organize the March on Washington for Jobs and Freedom in 1941. Lane ran a summer camp on her Pennsylvania farm for impoverished black children from the inner-city.\n\n"}
{"id": "9895310", "url": "https://en.wikipedia.org/wiki?curid=9895310", "title": "Legal anthropology", "text": "Legal anthropology\n\nLegal anthropology, also known as the anthropology of laws, is a sub-discipline of anthropology which specializes in \"the cross-cultural study of social ordering\". The questions that Legal Anthropologists seek to answer concern how is law present in cultures? How does it manifest? How may anthropologists contribute to understandings of law?\n\nEarlier legal anthropological research focused more narrowly on conflict management, crime, sanctions, or formal regulation. Bronisław Malinowski's 1926 work, \"Crime and Custom in Savage Society\", explored law, order, crime, and punishment among the Trobriand Islanders. The English lawyer Sir Henry Maine is often credited with founding the study of Legal Anthropology through his book \"Ancient Law\" (1861), and although his evolutionary stance has been widely discredited within the discipline, his questions raised have shaped the subsequent discourse of the study. This ethno-centric evolutionary perspective was pre-eminent in early Anthropological discourse on law, evident through terms applied such as ‘pre-law’ or ‘proto-law’ and applied by so-called armchair anthropologists. However, a turning point was presented in the 1926 publication of \"Crime and Custom in Savage Society\" by Malinowski based upon his time with the Trobriand Islanders. Through emphasizing the order present in acephelous societies, Malinowski proposed the cross-cultural examining of law through its established functions as opposed to a discrete entity. This has led to multiple researchers and ethnographies examining such aspects as order, dispute, conflict management, crime, sanctions, or formal regulation, in addition (and often antagonistically) to law-centred studies, with small-societal studies leading to insightful self-reflections and better understanding of the founding concept of law.\n\nLegal anthropology remains a lively discipline with modern and recent applications including issues such as human rights, legal pluralism, Islamophobia and political uprisings.\n\nLegal Anthropology provides a definition of law which differs from that found within modern legal systems. Hoebel (1954) offered the following definition of law: \"“A social norm is legal if its neglect or infraction is regularly met, in threat or in fact, by the application of physical force by an individual or group possessing the socially recognized privilege of so acting”\"\n\nMaine argued that human societies passing through three basic stages of legal development, from a group presided over by a senior agnate, through stages of territorial development and culminating in an elite forming normative laws of society, stating that \"“what the juristical oligarchy now claims is to monopolize the knowledge of the laws, to have the exclusive possession of the principles by which quarrels are decided”\"\n\nThis evolutionary approach, as has been stated, was subsequently replaced within the anthropological discourse by the need to examine the manifestations of law’s societal function. As according to Hoebel, law has four functions:\n\n1) to identify socially acceptable lines of behaviour for inclusion in the culture. \n2) To allocate authority and who may legitimately apply force.\n3) To settle trouble cases.\n4) To redefine relationships as the concepts of life change.\n\nLegal theorist H. L. A. Hart, however, stated that law is a body of rules, and is a union of two sets of rules: \n\nWithin modern English Theory, law is a discrete and specialized topic. Predominantly positivist in character, it is closely linked to notions of a rule-making body, the judiciary and enforcement agencies. The centralized state organisation and isolates are essentials to the attributes of rules, courts and sanctions. To learn more on this view, see Hobbes. 1651 Leviathan, part 2, chapter 26 or Salmond, J. 1902 Jurisprudence.\n\nHowever, this view of law is not applicable everywhere. There are many acephelous societies around the world where the above control mechanisms are absent. There are no conceptualized and isolated set of normative rules – these are instead embodied in everyday life. Even when there may be a discrete set of legal norms, these are not treated similarly to the English Legal System’s unequivocal power and unchallenged pre-eminence. Shamans, fighting and supernatural means are all mechanisms of superimposing rules within other societies. For example, within Rasmussen’s work of Across Arctic America (1927) he recounts Eskimo nith-songs being used as a public reprimand by expressing the wrongdoing of someone guilty.\n\nThus, instead of focusing upon the explicit manifestations of law, legal anthropologists have taken to examining the functions of law and how it is expressed. A view expressed by Leopold Pospisil and encapsulated by Bronislaw Malinowski:\n\n\"“In such primitive communities I personally believe that law ought to be defined by function and not by form, that is we ought to see what are the arrangements, the sociological realities, the cultural mechanisms which act for the enforcement of law”\"\n\nThus, law has been studied in ways that may be categorized by as:\n\n1) prescriptive rules\n2) observable regularities\n3) Instances of dispute.\n\nOrder and regulatory behaviour are required if social life is to be maintained. The scale and shade of this behaviour depends on the values and beliefs held by a society deriving from implicit understandings of the norm developed through socialization. There are socially constructed norms with varying degrees of explicitness and levels of order. Conflict may not be interpreted as an extreme pathological event but as a regulatory acting force.\n\nThis processual understanding of conflict and dispute became apparent and subsequently heavily theorized upon by the anthropological discipline within the latter half of the nineteenth century as a gateway to the law and order of a society. Disputes have become to be recognised as necessary and constructive over pathological whilst the stated rules of law only explain some aspects of control and compliance. The context and interactions of a dispute are more informative about a culture than the rules.\n\nClassic studies deriving theories of order from disputes include Evans-Pritchard work Witchcraft, Oracles and Magic among the Azande which focused upon functional disputes surrounding sorcery and witchcraft practices, or Comaroff and Roberts (1981) work among the Tswana which examine the hierarchy of disputes, the patterns of contact and the effect norms affect the course of dispute as norms important to dispute are rarely \"“especially organised for jural purpose”\" \n\nOther examples include:\n\nLeach, 1954. Political Systems of Highland Burma.\nBarth, 1959. Political Leadership among Swat Pathans.\n\nWithin the history of Legal Anthropology there have been various methods of data gathering adopted; ranging from literature review of traveller/missionary accounts, consulting informants and lengthy participant observation.\n\nFurthermore, when evaluating any research it is appropriate to have a robust methodology capable of scientifically analysing the topic at hand.\n\nThe broad method of study by legal anthropologists prevails upon the Case Study Approach first developed by Llewellyn and Hoebel in The Cheyenne Way (1941) not as \"“a philosophy but a technology”\" \n\nThis methodology is applied to situations of cross-cultural conflict and the correlating resolution, which can have sets of legal notions and jural regularities extracted from them \n\nThis method may be safe-guarded against accusations of imposing western ideological structures as it is often an emic sentiment: for example,\n\n\"“The Tiv drove me to the case method…what they were interested in. They put a lot of time and effort into cases”\"\n\nRegarding law, in Anthropology’s characteristically self-conscious manner, the comparative analysis inherent to Legal Anthropology has been speculated upon and most famously debated by Paul Bohannan and Max Gluckman. The discourse highlights one of the primary differences between British and American Anthropology regarding fieldwork approaches and concerns the imposition of Western terminology as ethnological categories of differing societies.\n\nEach author’s uses the Case Study Approach, however, the data’s presentation in terms of achieving comparativeness is a point of contention between them.\n\nPaul Bohannan promotes the use of native terminology presented with ethnographic meaning as opposed to any Universal categories, which act as barriers to understanding the true nature of a culture’s legal system.\n\nAdvocating that it is better to appreciate native terms in their own medium, Bohannan critiques Gluckman’s work for its inherent bias.\n\nGluckman has argued that Bohannan’s excessive use of native terminology creates barriers when attempting to achieve comparative analysis. He in turn has suggested that in order to further the cross-cultural comparative study of law, we should use English terms and concepts of law which will aid in the refinement of dispute facts and interrelations Thus, all native terms should be described and translated into an Anglo-American conceptual equivalent for the purpose of comparison.\n\nAs disputes and order began to be recognised as categories worthy of study, interest in the inherent aspects of conflicts emerged within legal anthropology. The processes and actors involved within the events became an object of study for ethnographers as they embraced conflict as a data-rich source.\n\nOne example of such an interest is expressed by Philip Gulliver, 1963, Social Control in an African Society in which the intimate relations between disputes are postulated as being important. He examines the patterns of alliance between actors of a dispute and the strategies that develop as a result, the roles of mediators and the typologies for intervention.\n\nSee \"Lyon, 2002 Local arbitration and conflict deferment in Punjab, Pakistan\" or \"Engel, D. 1980. Legal pluralism in an American community: perspectives on a civil trial court.\"\n\nPolitical anthropologists have had much to say about the UDHR(Universal Declaration of Human Rights). Original critiques, most notably by the AAA(American Anthropological Association), argued that cultural ideas of rights and entitlement differ between societies. They warned that any attempt to endorse one set of values above all others amounted to a new western imperialism, and would be counter to ideas of cultural relativism. Most anthropologists now agree that universal human rights have a useful place in today's world. Zechenter (1997) argues there are practices, such as Indian 'sati' (the burning of a widow on her husband's funeral pyre) that can be said to be wrong, despite justifications of tradition. This is because such practices are about much more than a culturally established world view, and frequently develop or revive as a result of socio-economic conditions and the balance of power within a community. As culture is not bounded and unchanging, there are multiple discourses and moral viewpoints within any community and among the various actors in such events (Merry 2003). Cultural relativists risk supporting the most powerfully asserted position at the expense of those who are subjugated under it.\n\nMore recent contributions to the question of universal human rights include analysis of their use in practice, and how global discourses are translated into local contexts (Merry 2003). Anthropologists such as Merry (2006) note how the legal framework of the UNDHR is not static but is actively used by communities around the globe to construct meaning. As much as the document is a product of western Enlightenment thinking, communities have the capacity to shape its meaning to suit their own agendas, incorporating its principles in ways that empower them to tackle their own local and national discontents.\n\nFemale genital cutting (FGC), also known as female circumcision or female genital mutilation remains a hotly debated, controversial issue contested particularly among legal anthropologists and human rights activists. Through her ethnography (1989) on the practice of pharonic circumcision among the Hofriyat of Sudan (1989) Boddy maintains that understanding local cultural norms is of crucial importance when considering intervention to prevent the practice. Human rights activists attempting to eradicate FGC using the legal framework of the Universal Declaration of Human Rights (UNDHR) as their justification, run the risk of imposing a set of ideological principles, alien to the culture attempting to be helped, potentially facing hostile reactions. Moreover, the UNDHR as a legal document, is contested by some as being restrictive in its prescription of what is and is not deemed a violation of a human right (Ross 2003) and overlooks local customary justifications which operate outside of an international legalistic framework (Ross 2003). Increasingly (FGC) is becoming a global issue due to increased mobility. What was once deemed a largely African practice has seen a steady increase in European countries such as Britain. Although made illegal in 1985 there have as yet been no convictions and girls as old as nine continue to have the procedure. Legislation has now also been passed in Sweden, the United States and France where there have been convictions. Black, J. A. and Debelle, G. D. (1995) \"Female Genital Mutilation in Britain\" \"British Medical Journal\".\n\nThere are a number of useful introductions to the field of legal anthropology, Sally Falk Moore, a leading legal anthropologist, held both a law degree and a PhD in anthropology. An increasing number of legal anthropologists hold both JDs and advanced degrees in anthropology, and some teach in law schools while maintaining scholarly connections within the field of legal anthropology; examples include Rebecca French, John Conley, Elizabeth Mertz, and Annelise Riles. Such combined expertise has also been turned to more applied anthropological pursuits such as tribal advocacy and forensic ethnography by practitioners. There is a growing interest in the intersection of legal and linguistic anthropology.\n\nIf looking for Anthropology departments with faculty specializing in legal anthropology in North America, try the following schools and professors:\nUniversity of California, Berkeley (Laura Nader), University of California, Irvine (Susan Bibler Coutin, Bill Maurer), University of Chicago (Justin B. Richland), Duke University (William M. O'Barr), Princeton University (Lawrence Rosen, Carol J. Greenhouse), State University of New York at Buffalo (Rebecca French), New York University (Sally Engle Merry), Harvard University (Jean Comaroff and John Comaroff) and Cornell University (Annelise Riles), and George Mason University (Susan Hirsch).\n\nIn Europe, the following scholars and schools will be good resources:\nVanja Hamzić (SOAS University of London), Jane Cowan (University of Sussex), Ann Griffiths and Toby Kelly (University of Edinburgh), Sari Wastell (Goldsmiths, University of London), Harri Englund and Yael Navaro (University of Cambridge), and Richard Rottenburg (Martin-Luther Universität).\n\nThe Association for Political and Legal Anthropology (APLA), a section of the American Anthropological Association, is the primary professional association in the U.S. for legal anthropologists and also has many overseas members. It publishes \"PoLAR: Political and Legal Anthropology Review\", the leading U.S. journal in the field of legal anthropology, which is accessible via http://polarjournal.org/ or http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1555-2934\n\n'Allegra: a Virtual Laboratory of Legal Anthropology' is an online experiment by a new generation of legal anthropologists designated to facilitate scholarly collaboration and awareness of the sub-discipline.\n\n\n\n"}
{"id": "28248242", "url": "https://en.wikipedia.org/wiki?curid=28248242", "title": "Lemnian deeds", "text": "Lemnian deeds\n\nA Lemnian deed is the cruel slaughter of someone as revenge. There are two possible origins for this term: the epic of Jason and the Argonauts, where Pelasgian women killed their men, and that of Herodotus narrative where the Pelasgians killed captive mothers and children.\n\nAs is usual in other nationalistic epics as well, other people and tribes are deemed to have barbaric tendencies. Besides, Pelasgians of Lemnos spoke pre-Greek Lemnian, and were technologically inferior (as can be seen from the weapons found in burials), which further promoted their primitive nature.\n\nIt is said that Pelasgian women decided to kill their men, due to the men's cheating with the mainland Thracian women. In anger, the women slaughtered the men in their sleep and lived without men for many years, until Jason and the Argonauts arrived during The Quest for the Golden Fleece.\nThey mingled with the women and created a new race: the Minyae.\n\nMichael Stewart relates the story of Herodotus thus:\nThe historian, Herodotus, relates the story that when the Pelasgians were driven from Attika (Attica) they kidnapped a number of Athenian women and took them to Lemnos; the women were defiant and taught their children to act and speak like Athenians; the Pelasgians would not accept such rebellious attitudes and killed the captive mothers and children and thus the term Lemnian Deeds became an enduring insult to the honor and manhood of the inhabitants.\n"}
{"id": "50114266", "url": "https://en.wikipedia.org/wiki?curid=50114266", "title": "MAC address anonymization", "text": "MAC address anonymization\n\nMAC address anonymization performs a one-way function on a MAC address so that the result may be used in tracking systems for reporting and the general public, while making it nearly impossible to obtain the original MAC address from the result. The idea is that this process allows companies like Google, Apple and iInside - which track users movements via computer hardware to simultaneously preserve the identities of the people they are tracking, as well as the hardware itself.\n\nAn example of MAC address anonymization would be to use a simple hash algorithm. Given an address of codice_1, the MD5 hash algorithm produces codice_2 (32 hexadecimal digits).\n\nAn address only one character different (codice_3) produces codice_4, an entirely different hash due to the avalanche effect.\n\nTracking companies rely on the assumption that address anonymization is akin to encryption. Given a message, and an encryption method that is well known to both the encoder and potential decryptor, modern encryption methods (such as Advanced Encryption Standard (AES) or RSA) will yield a result that is unbreakable in practice.\n\nThe problem lies in the fact that there are only 2 (281,474,976,710,656) possible MAC addresses. Given the encoding algorithm, an index can easily be created for each possible address.\n\nSeveral years ago, the building of such an index would have been difficult due to the compute time involved. With modern, parallel, cloud computing, the index generation can be easily divided among the number of processors desired.\n\nOn a 2.5 GHz processor, a C# program was able to produce the following results: \n\nThus, a million processors could create the entire index in just over five minutes, and 100,000 processors in less than 85 hours. Once the rainbow table is complete, conversions of \"anonymized\" addresses to their actual addresses is almost instantaneous.\n\nOne common way of mitigating such brute force attacks is to append a random salt into the MAC address before hashing. A salt is a secret string of characters that makes the search space for attackers larger. The effect is that the brute force attack can no longer target the valid range of MAC addresses. Lists of salted and hashed MAC addresses would be impossible to translate, given that the salt is long enough and created in a way that is difficult to guess.\n\nThe entity holding the secret salt can still perform deanonymization by attacking the hashed MAC using the technique in the previous chapter. Attackers could also obtain the secret salt through social engineering, phishing or other means.\n\nWhere data protection law requires anonymization, the method used should exclude any possibility of the original MAC address to be identified. Some companies truncate IPv4 addresses by removing the final octet, thus in effect retaining information about the user's ISP or subnet, but not directly identifying the individual. The activity could then originate from any of 254 IP addresses. This may not always be enough to guarantee anonymization.\n"}
{"id": "49309", "url": "https://en.wikipedia.org/wiki?curid=49309", "title": "Mootness", "text": "Mootness\n\nIn law, the terms moot and mootness have different meanings in British English and American English.\n\nIn the legal system of the United States, a matter is moot if further legal proceedings with regard to it can have no effect, or events have placed it beyond the reach of the law. Thereby the matter has been deprived of practical significance or rendered purely academic. The U.S. development of this word stems from the practice of moot courts, in which hypothetical or fictional cases were argued as a part of legal education. These purely academic issues led the U.S. courts to describe cases where developing circumstances made any judgment ineffective as \"moot\". The doctrine can be compared to the ripeness doctrine, another judge-made rule, that holds that judges should not rule on cases based entirely on anticipated disputes or hypothetical facts. Similar doctrines prevent the federal courts of the United States from issuing advisory opinions.\n\nThis is different from the usage in the British legal system, where the term \"moot\" has the meaning of \"debatable\". The shift in usage was first observed in the United States.\n\nIn the U.S. federal judicial system, a moot case must be dismissed, there being a constitutional limitation on the jurisdiction of the federal courts. The reason for this is that Article Three of the United States Constitution limits the jurisdiction of all federal courts to \"cases and controversies\". Thus, a civil action or appeal in which the court's decision will not affect the rights of the parties is ordinarily beyond the power of the court to decide, provided it does not fall within one of the recognized exceptions.\n\nA textbook example of such a case is the United States Supreme Court case \"DeFunis v. Odegaard\", . The plaintiff was a student who had been denied admission to law school, and had then been provisionally admitted during the pendency of the case. Because the student was slated to graduate within a few months at the time the decision was rendered, and there was no action the law school could take to prevent that, the Court determined that a decision on its part would have no effect on the student's rights. Therefore, the case was dismissed as moot.\n\nHowever, there is disagreement as to both the source of the standards, and their application in the courts. Some courts and observers opine that cases \"must\" be dismissed because this is a constitutional bar, and there is no \"case or controversy\"; others have rejected the pure constitutional approach and adopted a so-called \"prudential\" view, where dismissal \"may\" depend upon a host of factors, whether the particular person has lost a viable interest in the case, or whether the issue itself survives outside the interests of the particular person, whether the circumstance are likely to recur, etc. In actual practice, the U.S. federal courts have been uneven in their decisions, which has led to the accusation that determinations are \"ad hoc\" and 'result-oriented.'\n\nThere are four major exceptions to this mootness rule. These are cases of \"voluntary cessation\" on the part of the defendant; questions that involve secondary or collateral legal consequences; questions that are \"capable of \"repetition,\" yet evading review\"; and questions involving class actions where the named party ceases to represent the class.\n\nWhere a defendant is acting wrongfully, but ceases to engage in such conduct once a litigation has been threatened or commenced, the court will still not deem this correction to moot the case. Obviously, a party could stop acting improperly just long enough for the case to be dismissed and then resume the improper conduct. For example, in \"Friends of the Earth, Inc. v. Laidlaw Environmental Services, Inc.\", , the Supreme Court held that an industrial polluter, against whom various deterrent civil penalties were being pursued, could not claim that the case was moot, even though the polluter had ceased polluting and had closed the factory responsible for the pollution. The court noted that so long as the polluter still retained its license to operate such a factory, it could open similar operations elsewhere if not deterred by the penalties sought.\n\nAnother example occurs when a court dismisses as \"moot\" a legal challenge to an existing law, where the law being challenged is either amended or repealed through legislation before the court case could be settled. A recent instance of this occurred in \"Moore v. Madigan,\" when Illinois Attorney General Lisa Madigan declined to appeal a ruling of the Seventh Circuit United States Court of Appeals striking down Illinois handgun carry ban to the United States Supreme Court, as Illinois subsequently passed a law legalizing concealed carry with a state-issued license, which rendered the case moot.\n\n\"The obvious fact of life is that most criminal convictions do in fact entail adverse collateral legal consequences. The mere possibility that this will be the case is enough to preserve a criminal case from ending ignominiously in the limbo of mootness.\" Sibron v. New York.\n\nA court will allow a case to go forward if it is the type for which persons will frequently be faced with a particular situation, but will likely cease to be in a position where the court can provide a remedy for them in the time that it takes for the justice system to address their situation. The most frequently cited example is the 1973 United States Supreme Court case of \"Roe v. Wade\", , which challenged a Texas law forbidding abortion in most circumstances. The state argued that the case was moot because plaintiff Roe was no longer pregnant by the time the case was heard. As Justice Blackmun wrote in the majority opinion:\n\nThe normal 266-day human gestation period is so short that the pregnancy will come to term before the usual appellate process is complete. If that termination makes a case moot, pregnancy litigation seldom will survive much beyond the trial stage, and appellate review will be effectively denied. Our law should not be that rigid.\n\nNorma McCorvey, whose alias was Roe, became a pro-life advocate and attempted to have the decision of \"Roe v. Wade\" reversed and in \"McCorvey v. Hill\", 2004, the case failed to proceed based on being moot, without standing and out of time.\n\nThe Court cited \"Southern Pacific Terminal Co. v. ICC\", , which had held that a case was not moot when it presented an issue that was \"capable of repetition, yet evading review\". Perhaps in response to increasing workloads at all levels of the judiciary, the recent trend in the Supreme Court and other U.S. courts has been to construe this exception rather narrowly.\n\nMany cases fall under the \"capable of repetition\" doctrine; however, because there is a review process available under most circumstances, the exception to declaring mootness did not apply to such cases. In \"Memphis Light, Gas & Water Div. v. Craft\", 436 U. S. 1, 8–9 (1978), the court noted that claims for damages save cases from mootness.\n\nWhere a class action lawsuit is brought, with one named plaintiff actually representing the interests of many others, the case will not become moot even if the named plaintiff ceases to belong to the class that is seeking a remedy. In \"Sosna v. Iowa\", , the plaintiff represented a class that was challenging an Iowa law that required persons to reside there for a year before seeking a divorce in Iowa's courts. The Supreme Court held that, although the plaintiff successfully divorced in another state, her attorneys could continue to competently advance the interests of other members of the class.\n\nThe U.S. state courts are not subject to the Article III limitations on their jurisdiction, and some state courts are permitted by their local constitutions and laws to render opinions in moot cases where the establishment of a legal precedent is desirable. They may also establish exceptions to the doctrine. For instance, in some state courts the prosecution can lodge an appeal after a defendant is acquitted: although the appellate court cannot set aside a not-guilty verdict due to double jeopardy, it can issue a ruling as to whether a trial court's ruling on a particular issue during the trial was erroneous. This opinion will then be binding on future cases heard by the courts of that state.\n\nSome U.S. states also accept certified questions from the federal courts or the courts of other states. Under these procedures, state courts can issue opinions, usually for the purpose of clarifying or updating state law, in cases not actually pending in those courts.\n\nAlthough free from the U.S. Constitutional limitation, Canada has recognized that considerations of judicial economy and comity with the legislative and executive branch may justify a decision to dismiss an allegedly moot case, as deciding hypothetical controversies is tantamount to legislating. Considerations of the effectiveness of advocacy involved in the adversarial system and the possibility of recurrence of an alleged constitutional violation may sway the court. Additionally, the federal and provincial governments can ask for advisory opinions in hypothetical scenarios, termed reference questions, from their respective highest courts.\n\nThe phrase moot point refers (in American English) to an issue that is irrelevant to a subject being discussed or, in British English, one that is debatable. Due to the relatively uncommon usage of the word moot, and because \"moot\" and \"mute\" are homophones in some pronunciations, this is sometimes erroneously rendered as \"mute point\".\n\n"}
{"id": "827158", "url": "https://en.wikipedia.org/wiki?curid=827158", "title": "Moral imperative", "text": "Moral imperative\n\nA moral imperative is a strongly-felt principle that compels that person to act. It is a kind of categorical imperative, as defined by Immanuel Kant. Kant took the imperative to be a dictate of pure reason, in its practical aspect. Not following the moral law was seen to be self-defeating and thus contrary to reason. Later thinkers took the imperative to originate in conscience, as the divine voice speaking through the human spirit. The dictates of conscience are simply right and often resist further justification. Looked at another way, the experience of conscience is the basic experience of encountering the right.\n\nAn example of not following a moral imperative is making a promise that you do not intend to keep in order to get something.\n\nToby Ord Explores a moral imperative driven by a utilitarian view in relation to economics and global health. A hypothetical example he gives is that a group has $40,000 dollars to spend on blindness. The money could be spent to provide one U.S. person with a seeing eye dog and training or could be used to reverse the effects of 2,000 cases of trachoma in Africa through surgery. The utilitarian answer would be to help more people.\n\nToby also provides some real-world examples. Some real-world examples provide data on the cost to prevent or treat AIDS. Analyzing the cost-effectiveness of these methods of treatment and prevention is a moral imperative because the most effective use of funds can save more lives.\n\nGary Locke and Angel Gurria stated cases for economic moral imperatives related to corruption and anti-bribery laws. Water provides 40 percent of the world's food requirement and in developing countries there can be a 30 percent premium on water. Thomas Pogge argues that this corruption is strongly encouraged by the existing international rules as the rulers of these countries have much to gain from these larger countries and corporations.\n\n"}
{"id": "36726853", "url": "https://en.wikipedia.org/wiki?curid=36726853", "title": "Natural genetic engineering", "text": "Natural genetic engineering\n\nNatural genetic engineering (NGE) is a class of process proposed by molecular biologist James Shapiro to account for novelty created in the course of biological evolution. Shapiro developed this work in several peer-reviewed publications from 1992 onwards, and later in his 2011 book Evolution: A View from the 21st Century. He uses NGE to account for several proposed counterexamples to the central dogma of molecular biology (the subsequently partly rejected proposal of 1970 that the direction of the flow of sequence information is only from DNA to DNA or DNA to RNA to proteins, and never the reverse). Shapiro drew from work as diverse as the adaptivity of the mammalian immune system, ciliate macronuclei and epigenetics. The work gained some measure of notoriety after being championed by proponents of Intelligent Design, despite Shapiro's explicit repudiation of that movement.\n\nShapiro first laid out his ideas of natural genetic engineering in 1992 and has continued to develop them in both the primary scientific literature and in work directed to wider audiences, culminating in the 2011 publication of \"Evolution: A View from the 21st Century\".\n\nNatural genetic engineering is a reaction against the modern synthesis and the central dogma of molecular biology. The modern synthesis was formulated before the elucidation of the double-helix structure of DNA and the establishment of molecular biology in its current status of prominence. Given what was known at the time a simple, powerful model of genetic change through undirected mutation (loosely described as \"random\") and natural selection, was seen as sufficient to explain evolution as observed in nature. With the discovery of the nature and roles of nucleic acids in genetics, this model prompted Francis Crick's so-called Central Dogma of Molecular Biology: \"[Sequential] information cannot be transferred back from protein to either protein or nucleic acid.\"\n\nShapiro points out that multiple cellular systems can affect DNA in response to specific environmental stimuli. These \"directed\" changes stand in contrast to both the undirected mutations in the modern synthesis and (in Shapiro's interpretation) the ban on information flowing from the environment into the genome.\n\nIn the 1992 \"Genetica\" paper that introduced the concept, Shapiro begins by listing three lessons from molecular genetics:\nFrom these, Shapiro concludes:\n\n[I]t can be argued that much of genome change in evolution results from a genetic engineering process utilizing the biochemical systems for mobilizing and reorganizing DNA structures present in living cells.\nIn a 1997 Boston Review article, Shapiro lists\nfour categories of discoveries made in molecular biology that, in his\nestimation, are not adequately accounted for by the Modern Synthesis: genome organization, cellular repair capabilities, mobile genetic elements and cellular information processing. Shapiro concludes:\nWhat significance does an emerging interface between biology and information\nscience hold for thinking about evolution? It opens up the possibility of\naddressing scientifically rather than ideologically the central issue so hotly\ncontested by fundamentalists on both sides of the Creationist-Darwinist debate:\nIs there any guiding intelligence at work in the origin of species displaying\nexquisite adaptations that range from lambda prophage repression and the Krebs\ncycle through the mitotic apparatus and the eye to the immune system, mimicry,\nand social organization?\nWithin the context of the article in particular and Shapiro's work on Natural\nGenetic Engineering in general, the \"guiding intelligence\" is to be found\nwithin the cell. (For example, in a Huffington Post essay entitled\nCell Cognition and Cell Decision-Making Shapiro\ndefines cognitive actions as those that are \"knowledge-based and involve decisions appropriate\nto acquired information,\" arguing that cells meet this criteria.) However,\nthe combination of disagreement with the Modern Synthesis and discussion of\na creative intelligence has brought his work to the attention of advocates\nof Intelligent Design.\n\nNatural genetic engineering has been cited as a legitimate scientific controversy (in contrast to the controversies raised by various branches of creationism). While Shapiro considers the questions raised by Intelligent Design to be interesting, he parts ways with creationists by considering these problems to be scientifically tractable (specifically by understanding how NGE plays a role in the evolution of novelty).\n\nWith the publication of \"Evolution: A View from the 21st Century\",\nShapiro's work again came under discussion in the Intelligent design community.\nIn a conversation with Shapiro, William Dembski asked for Shapiro's\nthoughts on the origins of natural genetic engineering systems. Shapiro replied that \"where they come from in the first place is not a question we can realistically answer right now.\"\nWhile Dembski sees this position as at least not inconsistent with Intelligent\nDesign, Shapiro has explicitly and repeatedly rejected both creationism in\ngeneral and Intelligent Design in particular.\n\nWhile Shapiro developed NGE in the peer-reviewed literature, the idea attracted far more attention when he summarized his work in his book \"Evolution: A View from the 21st Century\".\n\nShapiro responded to the review in \"Evolutionary Intelligence\".\n"}
{"id": "47357235", "url": "https://en.wikipedia.org/wiki?curid=47357235", "title": "Neural efficiency hypothesis", "text": "Neural efficiency hypothesis\n\nThe neural efficiency hypothesis is the phenomenon where smarter individuals show lower (more efficient) brain activation than less bright individuals on cognitive tests of low to moderate difficulty. For tasks of higher difficulty, however, smarter individuals show higher brain activation.\n"}
{"id": "42877", "url": "https://en.wikipedia.org/wiki?curid=42877", "title": "Ninety-ninety rule", "text": "Ninety-ninety rule\n\nIn computer programming and software engineering, the ninety-ninety rule is a humorous aphorism that states:\n\nThis adds up to 180%, in a wry allusion to the notoriety of software development projects significantly over-running their schedules (see software development effort estimation). It expresses both the rough allocation of time to easy and hard portions of a programming project and the cause of the lateness of many projects as failure to anticipate the hard parts. In other words, it takes both more time and more coding than expected to complete a project.\n\nThe rule is attributed to Tom Cargill of Bell Labs and was made popular by Jon Bentley's September 1985 \"Programming Pearls\" column in \"Communications of the ACM\", in which it was titled the \"Rule of Credibility\".\n\nIn some agile software projects, this rule also surfaces when a task is portrayed as \"relatively done\". This indicates a common scenario where planned work is completed but cannot be signed off, pending a single final activity which may not occur for a substantial amount of time.\n\n"}
{"id": "8787159", "url": "https://en.wikipedia.org/wiki?curid=8787159", "title": "Objections to evolution", "text": "Objections to evolution\n\nObjections to evolution have been raised since evolutionary ideas came to prominence in the 19th century. When Charles Darwin published his 1859 book \"On the Origin of Species\", his theory of evolution (the idea that species arose through descent with modification from a single common ancestor in a process driven by natural selection) initially met opposition from scientists with different theories, but eventually came to receive overwhelming acceptance in the scientific community. The observation of evolutionary processes occurring (as well as the modern evolutionary synthesis explaining that evidence) has been uncontroversial among mainstream biologists since the 1940s.\n\nSince then, most criticisms and denials of evolution have come from religious groups, rather than from the scientific community. Although many religious groups have found reconciliation of their beliefs with evolution, such as through theistic evolution, other religious groups continue to reject evolutionary explanations in favor of creationism, the belief that the universe and life were created by supernatural forces. The U.S.-centered creation–evolution controversy has become a focal point of perceived conflict between religion and science.\n\nSeveral branches of creationism, including creation science, neo-creationism, and intelligent design, argue that the idea of life being directly designed by a god or intelligence is at least as scientific as evolutionary theory, and should therefore be taught in public education. Such arguments against evolution have become widespread and include objections to evolution's evidence, methodology, plausibility, morality, and scientific acceptance. The scientific community does not recognize such objections as valid, pointing to detractors' misinterpretations of such things as the scientific method, evidence, and basic physical laws.\n\nEvolutionary ideas came to prominence in the early 19th century with the theory of the transmutation of species put forward by Jean-Baptiste Lamarck. Evolution was at first opposed among the scientific community, notably by Georges Cuvier, and religious grounds. The idea that laws control nature and society gained vast popular audiences with George Combe's \"The Constitution of Man\" of 1828 and the anonymous \"Vestiges of the Natural History of Creation\" of 1844. When Charles Darwin published his 1859 book \"On the Origin of Species\", he convinced most of the scientific community that new species arise through descent through modification in a branching pattern of divergence from common ancestors, but while most scientists accepted that natural selection is a valid and empirically testable hypothesis, Darwin's view that it is the primary mechanism of evolution was rejected by some.\n\nDarwin's contemporaries eventually came to accept the transmutation of species based upon fossil evidence, and the X Club was formed to defend evolution against the church and wealthy amateurs. At that time the specific evolutionary mechanism which Darwin provided of natural selection was actively disputed by scientists in favour of alternative theories such as Lamarckism and orthogenesis. Darwin's gradualistic account was also opposed by saltationism and catastrophism. Lord Kelvin led scientific opposition to gradualism on the basis of his thermodynamic calculations that the Earth was between 24 and 400 million years old, and own views favoured a version of theistic evolution accelerated by divine guidance. This age of the earth was disputed by geological estimates, which gained strength in 1907 when radioactive dating of rocks showed that the Earth was billions of years old. The specific hereditary mechanism Darwin hypothesized of pangenesis that supported gradualism also lacked any supporting evidence and was disputed by the empirical tests of Francis Galton. Although evolution was unchallenged, uncertainties about the mechanism in the eclipse of Darwinism persisted from the 1880s until the 1930s inclusion of Mendelian inheritance and the rise of the modern evolutionary synthesis. The modern synthesis rose to universal acceptance among biologists with the help of new evidence, such as genetics, which confirmed Darwin's predictions and refuted the competing theories.\n\nProtestantism, especially in America, broke out in \"acrid polemics\" and argument about evolution from 1860 to the 1870s—with the turning point possibly marked by the death of Louis Agassiz in 1873—and by 1880 a form of \"Christian evolution\" was becoming the consensus. In Britain, while publication of \"The Descent of Man\" by Darwin in 1871 reinvigorated debate from the previous decade, Sir Henry Chadwick notes a steady acceptance of evolution \"among more educated Christians\" between 1860 and 1885. As a result, evolutionary theory was \"both permissible and respectable\" by 1876. Frederick Temple's lectures on \"The Relations between Religion and Science\" (1884) on how evolution was not \"antagonistic\" to religion highlighted this trend. Temple's appointment as Archbishop of Canterbury in 1896 demonstrated the broad acceptance of evolution within the church hierarchy.\n\nFor decades the Roman Catholic Church avoided official refutation of evolution. However, it would rein in Catholics who proposed that evolution could be reconciled with the Bible, as this conflicted with the First Vatican Council's (1869–70) finding that everything was created out of nothing by God, and to deny that finding could lead to excommunication. In 1950, the encyclical \"Humani generis\" of Pope Pius XII first mentioned evolution directly and officially. It allowed one to enquire into the concept of humans coming from pre-existing living matter, but not to question Adam and Eve or the creation of the soul. In 1996, Pope John Paul II said that evolution is \"more than a hypothesis\" and acknowledged the large body of work accumulated in its support, but reiterated that any attempt to give a material explanation of the human soul is \"incompatible with the truth about man.\" Pope Benedict XVI has reiterated the conviction that human beings \"are not some casual and meaningless product of evolution. Each of us is the result of a thought of God. Each of us is willed, each of us is loved, each of us is necessary.\" At the same time, he has promoted the study of the relationship between the concepts of creation and evolution, based on the conviction that there cannot be a contradiction between faith and reason. Along these lines, the research project Thomistic Evolution, run by a team of Dominican scholars, endeavours to reconcile the scientific evidence on evolution with the teaching of Thomas Aquinas.\n\nMuslim reaction ranged from those believing in literal creation from the Quran to many educated Muslims who subscribed to a version of theistic or guided evolution in which the Quran reinforced rather than contradicted mainstream science. This occurred relatively early, as medieval madrasahs taught the ideas of Al-Jahiz, a Muslim scholar from the 9th century, who proposed concepts similar to natural selection. However, acceptance of evolution remains low in the Muslim world, as prominent figures reject evolution's underpinning philosophy of materialism as unsound to human origins and a denial of Allah. Further objections by Muslim authors and writers largely reflect those put forward in the Western world.\n\nRegardless of acceptance from major religious hierarchies, early religious objections to Darwin's theory are still used in opposition to evolution. The ideas that species change over time through natural processes and that different species share common ancestors seemed to contradict the Genesis account of Creation. Believers in Biblical infallibility attacked Darwinism as heretical. The natural theology of the early 19th century was typified by William Paley's watchmaker analogy, an argument from design still used by the creationist movement. Natural theology included a range of ideas and arguments from the outset, and when Darwin's theory was published, ideas of theistic evolution were presented in which evolution is accepted as a secondary cause open to scientific investigation, while still holding belief in God as a first cause with a non-specified role in guiding evolution and creating humans. This position has been adopted by denominations of Christianity and Judaism in line with modernist theology which views the Bible and Torah as allegorical, thus removing the conflict between evolution and religion.\n\nHowever, in the 1920s Christian fundamentalists in the United States developed their literalist arguments against modernist theology into opposition to the teaching of evolution, with fears that Darwinism had led to German militarism and was a threat to religion and morality. This opposition developed into the creation–evolution controversy involving Christian literalists in the United States objecting to the teaching of evolution in public schools. Although early objectors dismissed evolution as contradicting their interpretation of the Bible, this argument was legally invalidated when the Supreme Court ruled in \"Epperson v. Arkansas\" in 1968 that forbidding the teaching of evolution on religious grounds violated the Establishment Clause.\n\nSince then creationists have developed more nuanced objections to evolution, alleging variously that it is unscientific, infringes on creationists' religious freedoms, or that the acceptance of evolution is a religious stance. Creationists have appealed to democratic principles of fairness, arguing that evolution is controversial and that science classrooms should therefore \"Teach the Controversy.\" These objections to evolution culminated in the intelligent design movement in the 1990s and early 2000s that unsuccessfully attempted to present itself as a scientific alternative to evolution.\n\nOne of the main sources of confusion and ambiguity in the creation–evolution debate is the definition of \"evolution\" itself. In the context of biology, evolution is genetic changes in populations of organisms over successive generations. The word also has a number of different meanings in different fields, from evolutionary computation to molecular evolution to sociocultural evolution to stellar and galactic evolution. When biological evolution is conflated with other evolutionary processes, this can cause errors such as the claim that modern evolutionary theory says anything about abiogenesis or the Big Bang.\n\n\"Evolution\" in colloquial contexts can refer to any sort of progressive development or gradual improvement, and a process that results in greater quality or complexity. When misapplied to biological evolution this common meaning leads to frequent misunderstandings. For example, the idea of devolution (\"backwards\" evolution) is a result of erroneously assuming that evolution is directional or has a specific goal in mind (cf. orthogenesis). In reality, the evolution of an organism has no \"objective\" and is only showing increasing ability of successive generations to survive and reproduce in its environment; and increased suitability is only defined in relation to this environment. Biologists do not consider any one species, such as humans, to be more \"highly evolved\" or \"advanced\" than another. Certain sources have been criticized for indicating otherwise due to a tendency to evaluate nonhuman organisms according to anthropocentric standards rather than more objective ones.\n\nEvolution also does not require that organisms become more complex. Although the history of life shows an apparent trend towards the evolution of biological complexity; there is a question if this appearance of increased complexity is real, or if it comes from neglecting the fact that the majority of life on Earth has always consisted of prokaryotes. In this view, complexity is not a necessary consequence of evolution, but that specific circumstances of evolution on Earth frequently made greater complexity advantageous and thus naturally selected for. Depending on the situation, organisms' complexity can either increase, decrease, or stay the same, and all three of these trends have been observed in evolution.\n\nCreationist sources frequently define evolution according to a colloquial, rather than scientific, meaning. As a result, many attempts to rebut evolution do not address the findings of evolutionary biology (see straw man argument). This also means that advocates of creationism and evolutionary biologists often simply speak past each other.\n\nCritics of evolution assert that evolution is \"just a theory,\" which emphasizes that scientific theories are never absolute, or misleadingly presents it as a matter of opinion rather than of fact or evidence. This reflects a difference of the meaning of \"theory\" in a scientific context: whereas in colloquial speech a \"theory\" is a conjecture or guess, in science a theory is an explanation whose predictions have been verified by experiments or other evidence. \"Evolutionary theory\" refers to an explanation for the diversity of species and their ancestry which has met extremely high standards of scientific evidence. An example of evolution as theory is the modern synthesis of Darwinian natural selection and Mendelian inheritance. As with any scientific theory, the modern synthesis is constantly debated, tested, and refined by scientists, but there is an overwhelming consensus in the scientific community that it remains the only robust model that accounts for the known facts concerning evolution.\n\nCritics also state that evolution is not a fact. In science a fact is a verified empirical observation while in colloquial contexts a fact can simply refer to anything for which there is overwhelming evidence. For example, in common usage theories such as \"the Earth revolves around the Sun\" and \"objects fall due to gravity\" may be referred to as \"facts,\" even though they are purely theoretical. From a scientific standpoint, therefore, evolution may be called a \"fact\" for the same reason that gravity can: under the scientific definition, evolution is an observable process that occurs whenever a population of organisms genetically changes over time. Under the colloquial definition, the theory of evolution can also be called a fact, referring to this theory's well-established nature. Thus, evolution is widely considered both a theory and a fact by scientists.\n\nSimilar confusion is involved in objections that evolution is \"unproven,\" since no theory in science is known to be absolutely true, only verified by empirical evidence. This distinction is an important one in philosophy of science, as it relates to the lack of absolute certainty in all empirical claims, not just evolution. Strict proof is possible only in formal sciences such as logic and mathematics, not natural sciences (where terms such as \"validated\" or \"corroborated\" are more appropriate). Thus, to say that evolution is not proven is trivially true, but no more an indictment of evolution than calling it a \"theory.\" The confusion arises in that the colloquial meaning of \"proof\" is simply \"compelling evidence,\" in which case scientists would indeed consider evolution \"proven.\"\n\nAn objection is often made in the teaching of evolution that evolution is controversial or contentious. Unlike past creationist arguments which sought to abolish the teaching of evolution altogether, this argument makes the weaker claim that evolution should be presented alongside alternative views since it is controversial, and students should be allowed to evaluate and choose between the options on their own.\n\nThis objection forms the basis of the \"Teach the Controversy\" campaign by the Discovery Institute, a think tank based in Seattle, Washington, to promote the teaching of intelligent design in U.S. public schools. This goal followed the Institute's \"wedge strategy,\" an attempt to gradually undermine evolution and ultimately to \"reverse the stifling dominance of the materialist worldview, and to replace it with a science consonant with Christian and theistic convictions.\" Several other attempts were made to insert intelligent design or creationism into the U.S. public school curriculum, including the failed Santorum Amendment in 2001.\n\nScientists and U.S. courts have rejected this objection on the grounds that science is not based on appeals to popularity, but on evidence. The scientific consensus of biologists determines what is considered acceptable science, not popular opinion or fairness, and although evolution is controversial in the public arena, it is entirely uncontroversial among experts in the field.\n\nIn response, creationists have disputed the level of scientific support for evolution. The Discovery Institute has gathered over 761 scientists as of August 2008 to sign \"A Scientific Dissent From Darwinism\" in order to show that there are a number of scientists who dispute what they refer to as \"Darwinian evolution.\" This statement did not profess outright disbelief in evolution, but expressed skepticism as to the ability of \"random mutation and natural selection to account for the complexity of life.\" Several counter-petitions have been launched in turn, including \"A Scientific Support for Darwinism\", which gathered over 7,000 signatures in four days, and Project Steve, a tongue-in-cheek petition that has gathered the signatures of 1,393 (as of May 24, 2016) evolution-supporting scientists named \"Steve\" (or any similar variation thereof—Stephen, Stephanie, Esteban, etc.).\n\nCreationists have argued for over a century that evolution is a \"theory in crisis\" that will soon be overturned, based on objections that it lacks reliable evidence or violates natural laws. These objections have been rejected by most scientists, as have claims that intelligent design, or any other creationist explanation, meets the basic scientific standards that would be required to make them scientific alternatives to evolution. It is also argued that even if evidence against evolution exists, it is a false dilemma to characterize this as evidence \"for\" intelligent design.\n\nA similar objection to evolution is that certain scientific authorities—mainly pre-modern ones—have doubted or rejected evolution. Most commonly, it is argued that Darwin \"recanted\" on his deathbed, a false anecdote originating from Lady Hope's story. These objections are generally rejected as appeals to authority.\n\nA common neo-creationist objection to evolution is that evolution does not adhere to normal scientific standards—that it is not genuinely scientific. It is argued that evolutionary biology does not follow the scientific method and therefore should not be taught in science classes, or at least should be taught alongside other views (i.e., creationism). These objections often deal with the very nature of evolutionary theory, the scientific method, and philosophy of science.\n\nCreationists commonly argue that \"evolution is a religion; it is not a science.\" The purpose of this criticism is to reframe the debate from one between science (evolution) and religion (creationism) to between two religious beliefs—or even to argue that evolution is religious while intelligent design is not. Those that oppose evolution frequently refer to supporters of evolution as \"evolutionists\" or \"Darwinists.\"\n\nThe arguments for evolution being a religion generally amount to arguments by analogy: it is argued that evolution and religion have one or more things in common, and that therefore evolution is a religion. Examples of claims made in such arguments are statements that evolution is based on faith, and that supporters of evolution dogmatically reject alternative suggestions out-of-hand. These claims have become more popular in recent years as the neo-creationist movement has sought to distance itself from religion, thus giving it more reason to make use of a seemingly anti-religious analogy.\n\nSupporters of evolution have argued in response that no scientist's claims are treated as sacrosanct, as shown by the aspects of Darwin's theory that have been rejected or revised by scientists over the years to form first neo-Darwinism and later the modern evolutionary synthesis. The claim that evolution relies on faith is likewise rejected on the grounds that evolution has strong supporting evidence, and therefore does not require faith.\n\nThe argument that evolution is religious has been rejected in general on the grounds that \"religion\" is not defined by how dogmatic or zealous its adherents are, but by its spiritual or supernatural beliefs. Evolutionary supporters point out evolution is neither dogmatic nor based on faith, and they accuse creationists of equivocating between the strict definition of \"religion\" and its colloquial usage to refer to anything that is enthusiastically or dogmatically engaged in. United States courts have also rejected this objection:\n\nAssuming for the purposes of argument, however, that evolution is a religion or religious tenet, the remedy is to stop the teaching of evolution, not establish another religion in opposition to it. Yet it is clearly established in the case law, and perhaps also in common sense, that evolution is not a religion and that teaching evolution does not violate the Establishment Clause, Epperson v. Arkansas, supra, Willoughby v. Stever, No. 15574-75 (D.D.C. May 18, 1973); aff'd. 504 F.2d 271 (D.C. Cir. 1974), cert. denied , 420 U.S. 924 (1975); Wright v. Houston Indep. School Dist., 366 F. Supp. 1208 (S.D. Tex 1978), aff.d. 486 F.2d 137 (5th Cir. 1973), cert. denied 417 U.S. 969 (1974).\n\nA related claim is that evolution is atheistic (see the Atheism section below); creationists sometimes merge the two claims and describe evolution as an \"atheistic religion\" (cf. humanism). This argument against evolution is also frequently generalized into a criticism of all science; it is argued that \"science is an atheistic religion,\" on the grounds that its methodological naturalism is as unproven, and thus as \"faith-based,\" as the supernatural and theistic beliefs of creationism.\n\nA statement is considered falsifiable if there is an observation or a test that could be made that would demonstrate that the statement is false. Statements that are not falsifiable cannot be examined by scientific investigation since they permit no tests that evaluate their accuracy. Creationists such as Henry M. Morris have claimed that any observation can be fitted into the evolutionary framework, so it is impossible to demonstrate that evolution is wrong and therefore evolution is non-scientific.\n\nSupporters of evolution argue that evolution could be falsified by many conceivable lines of evidence, such as the fossil record showing no change over time, confirmation that mutations are prevented from accumulating in a population, or observation of organisms being created supernaturally or spontaneously. J. B. S. Haldane, when asked what hypothetical evidence could disprove evolution, replied \"fossil rabbits in the Precambrian era.\" Numerous other potential ways to falsify evolution have also been proposed. For example, the fact that humans have one fewer pair of chromosomes than the great apes offered a testable hypothesis involving the fusion or splitting of chromosomes from a common ancestor. The fusion hypothesis was confirmed in 2005 by discovery that human chromosome 2 is homologous with a fusion of two chromosomes that remain separate in other primates. Extra, inactive telomeres and centromeres remain on human chromosome 2 as a result of the fusion. The assertion of common descent could also have been disproven with the invention of DNA sequencing methods. If true, human DNA should be far more similar to chimpanzees and other great apes, than to other mammals. If not, then common descent is falsified. DNA analysis has shown that humans and chimpanzees share a large percentage of their DNA (between 95% to 99.4% depending on the measure). Also, the evolution of chimpanzees and humans from a common ancestor predicts a (geologically) recent common ancestor. Numerous transitional fossils have since been found. Hence, human evolution has passed several falsifiable tests.\n\nMany of Darwin's ideas and assertions of fact have been falsified as evolutionary science has developed, but these amendments and falsifications have uniformly confirmed his central concepts. In contrast, creationist explanations involving the direct intervention of the supernatural in the physical world are not falsifiable, because any result of an experiment or investigation could be the unpredictable action of an omnipotent deity.\n\nIn 1976, the philosopher Karl Popper said that \"Darwinism is not a testable scientific theory but a metaphysical research programme.\" He later changed his mind and argued that Darwin's \"theory of natural selection is difficult to test\" with respect to other areas of science.\n\nIn his 1982 book, \"Abusing Science: The Case Against Creationism\", philosopher of science Philip Kitcher specifically addresses the \"falsifiability\" question by taking into account notable philosophical critiques of Popper by Carl Gustav Hempel and Willard Van Orman Quine and provides a definition of theory other than as a set of falsifiable statements. As Kitcher points out, if one took a strictly Popperian view of \"theory,\" observations of Uranus when it was first discovered in 1781 would have \"falsified\" Isaac Newton's celestial mechanics. Rather, people suggested that another planet influenced Uranus' orbit—and this prediction was indeed eventually confirmed. Kitcher agrees with Popper that \"there is surely something right in the idea that a science can succeed only if it can fail.\" But he insists that we view scientific theories as consisting of an \"elaborate collection of statements,\" some of which are not falsifiable, and others—what he calls \"auxiliary hypotheses,\" which are.\n\nA related claim to the supposed unfalsifiability of evolution is that natural selection is tautological. Specifically, it is often argued that the phrase \"survival of the fittest\" is a tautology, in that fitness is defined as ability to survive and reproduce. This phrase was first used by Herbert Spencer in 1864 but is rarely used by biologists. Additionally, fitness is more accurately defined as the state of possessing traits that make survival more likely; this definition, unlike simple \"survivability,\" avoids being trivially true.\n\nSimilarly, it is argued that evolutionary theory is circular reasoning, in that evidence is interpreted as supporting evolution, but evolution is required to interpret the evidence. An example of this is the claim that geological strata are dated through the fossils they hold, but that fossils are in turn dated by the strata they are in. However, in most cases strata are not dated by their fossils, but by their position relative to other strata and by radiometric dating, and most strata were dated before the theory of evolution was formulated.\n\nObjections to the evidence that evolution occurs tend to be more concrete and specific, often involving direct analysis of evolutionary biology's methods and claims.\n\nA common claim of creationists is that evolution has never been observed. Challenges to such objections often come down to debates over how evolution is defined (see the Defining evolution section above). Under the conventional biological definition of \"evolution\", it is a simple matter to observe evolution occurring. Evolutionary processes, in the form of populations changing their genetic composition from generation to generation, have been observed in different scientific contexts, including the evolution of fruit flies, mice, and bacteria in the laboratory, and of tilapia in the field. Such studies on experimental evolution, particularly those using microorganisms, are now providing important insights into how evolution occurs, especially in the case of antibiotic resistance.\n\nIn response to such examples, creationists say there are two major subdivisions of evolution to be considered, microevolution and macroevolution, and it is questionable if macro-evolution has been physically observed to occur. Most creationist organizations do not dispute the occurrence of short-term, relatively minor evolutionary changes, such as that observed even in dog breeding. Rather, they dispute the occurrence of major evolutionary changes over long periods of time, which by definition cannot be directly observed, only inferred from microevolutionary processes and the traces of macroevolutionary ones.\n\nAs biologists define \"macroevolution\", both microevolution and macroevolution have been observed. Speciations, for example, have been directly observed many times. Additionally, the modern evolutionary synthesis draws no distinction in the processes described by the theory of evolution when considering macroevolution and microevolution as the former is simply at the species level or above and the latter is below the species level. An example of this is ring species.\n\nAdditionally, past macroevolution can be inferred from historical traces. Transitional fossils, for example, provide plausible links between several different groups of organisms, such as \"Archaeopteryx\" linking birds and non-avian dinosaurs, or the \"Tiktaalik\" linking fish and limbed amphibians. Creationists dispute such examples, from asserting that such fossils are hoaxes or that they belong exclusively to one group or the other, to asserting that there should be far more evidence of obvious transitional species. Darwin himself found the paucity of transitional species to be one of the greatest weaknesses of his theory: Why then is not every geological formation and every stratum full of such intermediate links? Geology assuredly does not reveal any such finely graduated organic chain and this, perhaps, is the most obvious and gravest objection which can be urged against my theory. The explanation lies, as I believe, in the extreme imperfection of the geological record. Darwin appealed to the limited collections then available, the extreme lengths of time involved, and different rates of change with some living species differing very little from fossils of the Silurian period. In later editions he added \"that the periods during which species have been undergoing modification, though very long as measured by years, have probably been short in comparison with the periods during which these same species remained without undergoing any change.\" The number of clear transitional fossils has increased enormously since Darwin's day, and this problem has been largely resolved with the advent of the theory of punctuated equilibrium, which predicts a primarily stable fossil record broken up by occasional major speciations.\n\nAs more and more compelling direct evidence for inter-species and species-to-species evolution has been gathered, creationists have redefined their understanding of what amounts to \"created kinds,\" and have continued to insist that more dramatic demonstrations of evolution be experimentally produced. One version of this objection is \"Were you there?,\" popularized by young Earth creationist Ken Ham. It argues that because no one except God could directly observe events in the distant past, scientific claims are just speculation or \"story-telling.\" DNA sequences of the genomes of organisms allow an independent test of their predicted relationships, since species which diverged more recently will be more closely related genetically than species which are more distantly related; such phylogenetic trees show a hierarchical organization within the tree of life, as predicted by common descent.\n\nIn fields such as astrophysics or meteorology, where direct observation or laboratory experiments are difficult or impossible, the scientific method instead relies on observation and logical inference. In such fields, the test of falsifiability is satisfied when a theory is used to predict the results of new observations. When such observations contradict a theory's predictions, it may be revised or discarded if an alternative better explains the observed facts. For example, Newton's theory of gravitation was replaced by Albert Einstein's theory of general relativity when the latter was observed to more precisely predict the orbit of Mercury.\n\nA related objection is that evolution is based on unreliable evidence, claiming that evolution is not even well-evidenced. Typically, this is either based on the argument that evolution's evidence is full of frauds and hoaxes, that current evidence for evolution is likely to be overturned as some past evidence has been, or that certain types of evidence are inconsistent and dubious.\n\nArguments against evolution's reliability are thus often based on analyzing the history of evolutionary thought or the history of science in general. Creationists point out that in the past, major scientific revolutions have overturned theories that were at the time considered near-certain. They thus claim that current evolutionary theory is likely to undergo such a revolution in the future, on the basis that it is a \"theory in crisis\" for one reason or another.\n\nCritics of evolution commonly appeal to past scientific hoaxes such as the Piltdown Man forgery. It is argued that because scientists have been mistaken and deceived in the past about evidence for various aspects of evolution, the current evidence for evolution is likely to also be based on fraud and error. Much of the evidence for evolution has been accused of being fraudulent at various times, including \"Archaeopteryx\", peppered moth melanism, and Darwin's finches; these claims have been subsequently refuted.\n\nIt has also been claimed that certain former pieces of evidence for evolution which are now considered out-of-date and erroneous, such as Ernst Haeckel's 19th-century comparative drawings of embryos, used to illustrate his recapitulation theory (\"ontogeny recapitulates phylogeny\"), were not merely errors but frauds. Molecular biologist Jonathan Wells criticizes biology textbooks by alleging that they continue to reproduce such evidence after it has been debunked. In response, the National Center for Science Education notes that none of the textbooks reviewed by Wells makes the claimed error, as Haeckel's drawings are shown in a historical context with discussion about why they are wrong, and the accurate modern drawings and photos used in the textbooks are misrepresented by Wells.\n\nCreationists claim that evolution relies on certain types of evidence that do not give reliable information about the past. For example, it is argued that radiometric dating technique of evaluating a material's age based on the radioactive decay rates of certain isotopes generates inconsistent and thus unreliable results. Radiocarbon dating based on the carbon-14 isotope has been particularly criticized. It is argued that radiometric decay relies on a number of unwarranted assumptions such as the principle of uniformitarianism, consistent decay rates, or rocks acting as closed systems. Such arguments have been dismissed by scientists on the grounds that independent methods have confirmed the reliability of radiometric dating as a whole; additionally, different radiometric dating methods and techniques have independently confirmed each other's results.\n\nAnother form of this objection is that fossil evidence is not reliable. This is based on a much wider range of claims. These include that there are too many \"gaps\" in the fossil record, that fossil-dating is circular (see the Unfalsifiability section above), or that certain fossils, such as polystrate fossils, are seemingly \"out of place.\" Examination by geologists have found polystrate fossils to be consistent with \"in situ\" formation. It is argued that certain features of evolution support creationism's catastrophism (cf. Great Flood), rather than evolution's gradualistic punctuated equilibrium, which some assert is an \"ad hoc\" theory to explain the fossil gaps.\n\nSome of the oldest and most common objections to evolution dispute whether evolution can truly account for all the apparent complexity and order in the natural world. It is argued that evolution is too unlikely or otherwise lacking to account for various aspects of life, and therefore that an intelligence, such as God of the Abrahamic religions, must at the very least be appealed to for those specific features.\n\nA common objection to evolution is that it is simply too unlikely for life, in its complexity and apparent \"design,\" to have arisen \"by chance.\" It is argued that the odds of life having arisen without a deliberate intelligence guiding it are so astronomically low that it is unreasonable \"not\" to infer an intelligent designer from the natural world, and specifically from the diversity of life. A more extreme version of this argument is that evolution cannot create complex structures (see the Creation of complex structures section below). The idea that it is simply too implausible for life to have evolved is often wrongly encapsulated with a quotation that the \"probability of life originating on Earth is no greater than the chance that a hurricane, sweeping through a scrapyard, would have the luck to assemble a Boeing 747\"—a claim attributed to astrophysicist Fred Hoyle and known as Hoyle's fallacy. Hoyle was a Darwinist, atheist and anti-theist, but advocated the theory of panspermia, in which abiogenesis begins in outer space and primitive life on Earth is held to have arrived via natural dispersion.\n\nViews superficially similar, but unrelated to Hoyle's, are thus invariably justified with arguments from analogy. The basic idea of this argument for a designer is the teleological argument, an argument for the existence of God based on the perceived order or purposefulness of the universe. A common way of using this as an objection to evolution is by appealing to the 18th-century philosopher William Paley's watchmaker analogy, which argues that certain natural phenomena are analogical to a watch (in that they are ordered, or complex, or purposeful), which means that, like a watch, they must have been designed by a \"watchmaker\"—an intelligent agent. This argument forms the core of intelligent design, a neo-creationist movement seeking to establish certain variants of the design argument as legitimate science, rather than as philosophy or theology, and have them be taught alongside evolution.\n\nThis objection is fundamentally an argument by lack of imagination, or argument from incredulity: a certain explanation is seen as being counterintuitive, and therefore an alternate, more intuitive explanation is appealed to instead. Supporters of evolution generally respond by arguing that evolution is not based on \"chance,\" but on predictable chemical interactions: natural processes, rather than supernatural beings, are the \"designer.\" Although the process involves some random elements, it is the non-random selection of survival-enhancing genes that drives evolution along an ordered trajectory. The fact that the results are ordered and seem \"designed\" is no more evidence for a supernatural intelligence than the appearance of complex natural phenomena (e.g. snowflakes). It is also argued that there is insufficient evidence to make statements about the plausibility or implausibility of abiogenesis, that certain structures demonstrate poor design, and that the implausibility of life evolving exactly as it did is no more evidence for an intelligence than the implausibility of a deck of cards being shuffled and dealt in a certain random order.\n\nIt has also been noted that arguments against some form of life arising \"by chance\" are really objections to nontheistic abiogenesis, not to evolution. Indeed, arguments against \"evolution\" are based on the misconception that abiogenesis is a component of, or necessary precursor to, evolution. Similar objections sometimes conflate the Big Bang with evolution.\n\nChristian apologist and philosopher Alvin Plantinga, a supporter of intelligent design, has formalized and revised the improbability argument as the evolutionary argument against naturalism, which asserts that it is irrational to reject a supernatural, intelligent creator because the apparent probability of certain faculties evolving is so low. Specifically, Plantinga claims that evolution cannot account for the rise of reliable reasoning faculties. Plantinga argues that whereas a God would be expected to create beings with reliable reasoning faculties, evolution would be just as likely to lead to unreliable ones, meaning that if evolution is true, it is irrational to trust whatever reasoning one relies on to conclude that it is true. This novel epistemological argument has been criticized similarly to other probabilistic design arguments. It has also been argued that rationality, if conducive to survival, is more likely to be selected for than irrationality, making the natural development of reliable cognitive faculties more likely than unreliable ones.\n\nA related argument against evolution is that most mutations are harmful. However, the vast majority of mutations are neutral, and the minority of mutations which are beneficial or harmful are often situational; a mutation that is harmful in one environment may be helpful in another.\n\nIn addition to complex structures and systems, among the phenomena that critics variously claim evolution cannot explain are consciousness, hominid intelligence, instincts, emotions, metamorphosis, photosynthesis, homosexuality, music, language, religion, morality, and altruism (see altruism in animals). Most of these, such as hominid intelligence, instinct, emotion, photosynthesis, language, and altruism, have been well-explained by evolution, while others remain mysterious, or only have preliminary explanations. Supporters of evolution further contend that no alternative explanation has been able to adequately explain the biological origin of these phenomena either.\n\nCreationists argue against evolution on the grounds that it cannot explain certain non-evolutionary processes, such as abiogenesis, the Big Bang, or the meaning of life. In such instances, \"evolution\" is being redefined to refer to the entire history of the universe, and it is argued that if one aspect of the universe is seemingly inexplicable, the entire body of scientific theories must be baseless. At this point, objections leave the arena of evolutionary biology and become general scientific or philosophical disputes.\n\nAstronomers Fred Hoyle and Chandra Wickramasinghe have argued in favor of cosmic ancestry, and against abiogenesis and evolution.\n\nThis class of objections is more radical than the above, claiming that a major aspect of evolution is not merely unscientific or implausible, but rather impossible, because it contradicts some other law of nature or is constrained in such a way that it cannot produce the biological diversity of the world.\n\nModern evolutionary theory posits that all biological systems must have evolved incrementally, through a combination of natural selection and genetic drift. Both Darwin and his early detractors recognized the potential problems that could arise for his theory of natural selection if the lineage of organs and other biological features could not be accounted for by gradual, step-by-step changes over successive generations; if all the intermediary stages between an initial organ and the organ it will become are not all improvements upon the original, it will be impossible for the later organ to develop by the process of natural selection alone. Complex organs such as the eye had been presented by William Paley as exemplifying the need for design by God, and anticipating early criticisms that the evolution of the eye and other complex organs seemed impossible, Darwin noted that:\n\n[R]eason tells me, that if numerous gradations from a perfect and complex eye to one very imperfect and simple, each grade being useful to its possessor, can be shown to exist; if further, the eye does vary ever so slightly, and the variations be inherited, which is certainly the case; and if any variation or modification in the organ be ever useful to an animal under changing conditions of life, then the difficulty of believing that a perfect and complex eye could be formed by natural selection, though insuperable by our imagination, can hardly be considered real.\n\nSimilarly, ethologist and evolutionary biologist Richard Dawkins said on the topic of the evolution of the feather in an interview for the television program \"The Atheism Tapes\":\nThere's got to be a series of advantages all the way in the feather. If you can't think of one, then that's your problem not natural selection's problem... It's perfectly possible feathers began as fluffy extensions of reptilian scales to act as insulators... The earliest feathers might have been a different approach to hairiness among reptiles keeping warm.\nCreationist arguments have been made such as \"What use is half an eye?\" and \"What use is half a wing?\". Research has confirmed that the natural evolution of the eye and other intricate organs is entirely feasible. Creationist claims have persisted that such complexity evolving without a designer is inconceivable and this objection to evolution has been refined in recent years as the more sophisticated irreducible complexity argument of the intelligent design movement, formulated by Michael Behe. Biochemist Michael Behe has argued that current evolutionary theory cannot account for certain complex structures, particularly in microbiology. On this basis, Behe argues that such structures were \"purposely arranged by an intelligent agent.\"\n\nIrreducible complexity is the idea that certain biological systems cannot be broken down into their constituent parts and remain functional, and therefore that they could not have evolved naturally from less complex or complete systems. Whereas past arguments of this nature generally relied on macroscopic organs, Behe's primary examples of irreducible complexity have been cellular and biochemical in nature. He has argued that the components of systems such as the blood clotting cascade, the immune system, and the bacterial flagellum are so complex and interdependent that they could not have evolved from simpler systems.\n\nIn the years since Behe proposed irreducible complexity, new developments and advances in biology such as an improved understanding of the evolution of flagella, have already undermined these arguments The idea that seemingly irreducibly complex systems cannot evolve has been refuted through evolutionary mechanisms, such as exaptation (the adaptation of organs for entirely new functions) and the use of \"scaffolding,\" which are initially necessary features of a system that later degenerate when they are no longer required. Potential evolutionary pathways have been provided for all of the systems Behe used as examples of irreducible complexity.\n\nThe Cambrian explosion was the relatively rapid appearance around of most major animal phyla as demonstrated in the fossil record, and many more phyla now extinct. This was accompanied by major diversification of other organisms. Prior to the Cambrian explosion most organisms were simple, composed of individual cells occasionally organized into colonies. Over the following 70 or 80 million years the rate of diversification accelerated by an order of magnitude and the diversity of life began to resemble that of today, although they did not resemble the species of today.\n\nThe basic problem with this is that natural selection calls for the slow accumulation of changes, where a new phyla would take longer than a new class which would take longer than a new order, which would take longer than a new family, which would take longer than a new genus would take longer than emergence of a new species but the apparent occurrence of high-level taxa without precedents is perhaps implying unusual evolutionary mechanisms.\n\nThere is general consensus that many factors helped trigger the Cambrian explosion, but there is no generally accepted consensus about the combination and the Cambrian explosion continues to be an area of controversy and research over why so rapid, why at the phylum level, why so many phyla then and none since, and even if the apparent fossil record is accurate.\n\nAn example of opinions involving the commonly cited rise in oxygen Great Oxidation Event from biologist PZ Myers summarizes: \"What it was was environmental changes, in particular the bioturbation revolution caused by the evolution of worms that released buried nutrients, and the steadily increasing oxygen content of the atmosphere that allowed those nutrients to fuel growth; ecological competition, or a kind of arms race, that gave a distinct selective advantage to novelties that allowed species to occupy new niches; and the evolution of developmental mechanisms that enabled multicellular organisms to generate new morphotypes readily.\" The increase in molecular oxygen (O) also may have allowed the formation of the protective ozone layer (O) that helps shield Earth from lethal UV radiation from the Sun.\n\nA recent objection of creationists to evolution is that evolutionary mechanisms such as mutation cannot generate new information. Creationists such as William A. Dembski, Werner Gitt, and Lee Spetner have attempted to use information theory to dispute evolution. Dembski has argued that life demonstrates specified complexity, and proposed a law of conservation of information that extremely improbable \"complex specified information\" could be conveyed by natural means but never originated without an intelligent agent. Gitt asserted that information is an intrinsic characteristic of life and that an analysis demonstrates the mind and will of their Creator.\n\nThese claims have been widely rejected by the scientific community which asserts that new information is regularly generated in evolution whenever a novel mutation or gene duplication arises. Dramatic examples of entirely new and unique traits arising through mutation have been observed in recent years, such as the evolution of nylon-eating bacteria which developed new enzymes to efficiently digest a material that never existed before the modern era. There is no need to account for the creation of information when an organism is considered together with the environment it evolved in. The information in the genome forms a record of how it was possible to survive in a particular environment. The information is gathered from the environment through trial and error as mutating organisms either reproduce or fail.\n\nAnother objection is that evolution violates the second law of thermodynamics. The law states that \"the entropy of an isolated system not in equilibrium will tend to increase over time, approaching a maximum value at equilibrium\". In other words, an isolated system's entropy (a measure of the dispersal of energy in a physical system so that it is not available to do mechanical work) will tend to increase or stay the same, not decrease. Creationists argue that evolution violates this physical law by requiring a decrease in entropy, or disorder, over time.\n\nThe claims have been criticized for ignoring that the second law only applies to isolated systems. Organisms are open systems as they constantly exchange energy and matter with their environment: for example animals eat food and excrete waste, and radiate and absorb heat. It is argued that the Sun-Earth-space system does not violate the second law because the enormous increase in entropy due to the Sun and Earth radiating into space dwarfs the local decrease in entropy caused by the existence and evolution of self-organizing life.\n\nSince the second law of thermodynamics has a precise mathematical definition, this argument can be analyzed quantitatively. This was done by physicist Daniel F. Styer, who concluded: \"Quantitative estimates of the entropy involved in biological evolution demonstrate that there is no conflict between evolution and the second law of thermodynamics.\"\n\nIn a published letter to the editor of \"The Mathematical Intelligencer\" titled \"How anti-evolutionists abuse mathematics,\" mathematician Jason Rosenhouse stated:\nThe fact is that natural forces routinely lead to local decreases in entropy. Water freezes into ice and fertilised eggs turn into babies. Plants use sunlight to convert carbon dioxide and water into sugar and oxygen, but [we do] not invoke divine intervention to explain the process [...] thermodynamics offers nothing to dampen our confidence in Darwinism.\n\nOther common objections to evolution allege that evolution leads to objectionable results, including bad beliefs, behaviors, and events. It is argued that the teaching of evolution degrades values, undermines morals, and fosters irreligion or atheism. These may be considered appeals to consequences (a form of logical fallacy), as the potential ramifications of belief in evolutionary theory have nothing to do with its objective empirical reality.\n\nIn biological classification humans are animals, a basic point which has been known for more than 2,000 years. Aristotle already described man as a political animal and Porphyry defined man as a rational animal, a definition accepted by the Scholastic philosophers in the Middle Ages. The creationist J. Rendle-Short asserted in \"Creation\" magazine that if people are taught evolution they can be expected to behave like animals: since animals behave in all sorts of different ways, this is meaningless. In evolutionary terms, humans are able to acquire knowledge and change their behaviour to meet social standards, so humans behave in the manner of other humans.\n\nIn 1917, Vernon Kellogg published \"Headquarters Nights: A Record of Conversations and Experiences at the Headquarters of the German Army in France and Belgium\", which asserted that German intellectuals were totally committed to might-makes-right due to \"whole-hearted acceptance of the worst of Neo-Darwinism, the \"Allmacht\" of natural selection applied rigorously to human life and society and \"Kultur\".\" This strongly influenced the politician William Jennings Bryan, who saw Darwinism as a moral threat to America and campaigned against evolutionary theory; his campaign culminated in the Scopes Trial, which effectively prevented teaching of evolution in most public schools until the 1960s.\n\nR. Albert Mohler, Jr., president of the Southern Baptist Theological Seminary in Louisville, Kentucky, wrote August 8, 2005, in NPR's \"Taking Issue\" essay series, that \"Debates over education, abortion, environmentalism, homosexuality and a host of other issues are really debates about the origin — and thus the meaning — of human life. ...evolutionary theory stands at the base of moral relativism and the rejection of traditional morality.\"\n\nHenry M. Morris, engineering professor and founder of the Creation Research Society and the Institute of Creation Research, claims that evolution was part of a pagan religion that emerged after the Tower of Babel, was part of Plato's and Aristotle's philosophies, and was responsible for everything from war to pornography to the breakup of the nuclear family. He has also claimed that perceived social ills like crime, teenage pregnancies, homosexuality, abortion, immorality, wars, and genocide are caused by a belief in evolution.\n\nRev. D. James Kennedy of The Center for Reclaiming America for Christ and Coral Ridge Ministries claims that Darwin was responsible for Adolf Hitler's atrocities. In Kennedy's documentary and the accompanying pamphlet with the same title, \"Darwin's Deadly Legacy\", Kennedy states that \"To put it simply, no Darwin, no Hitler.\" In his efforts to expose the \"harmful effects that evolution is still having on our nation, our children, and our world,\" Kennedy also states that, \"We have had 150 years of the theory of Darwinian evolution, and what has it brought us? Whether Darwin intended it or not, millions of deaths, the destruction of those deemed inferior, the devaluing of human life, increasing hopelessness.\" The Discovery Institute's Center for Science and Culture fellow Richard Weikart has made similar claims, as have other creationists. The claim was central to the documentary film \"\" (2008) promoting intelligent design creationism. The Anti-Defamation League describes such claims as outrageous misuse of the Holocaust and its imagery, and as trivializing the \"...many complex factors that led to the mass extermination of European Jewry. Hitler did not need Darwin or evolution to devise his heinous plan to exterminate the Jewish people, and Darwin and evolutionary theory cannot explain Hitler's genocidal madness. Moreover, anti-Semitism existed long before Darwin ever wrote a word.\"\n\nYoung Earth creationist Kent Hovind blames communism, socialism, World War I, World War II, racism, the Holocaust, Stalin's war crimes, the Vietnam War, and Pol Pot's Killing Fields on evolution, as well as the increase in crime, unwed mothers, and other social ills. Hovind's son Eric Hovind claims that evolution is responsible for tattoos, body piercing, premarital sex, unwed births, sexually transmitted diseases (STDs), divorce, and child abuse.\n\nSupporters of evolution dismiss such criticisms as counterfactual, and some argue that the opposite seems to be the case. A study published by the author and illustrator Gregory S. Paul found that religious beliefs, including belief in creationism and disbelief in evolution, are positively correlated with social ills like crime. The Barna Group surveys find that Christians and non-Christians in the U.S. have similar divorce rates, and the highest divorce rates in the U.S. are among Baptists and Pentecostals, both sects which reject evolution and embrace creationism.\n\nMichael Shermer argued in \"Scientific American\" in October 2006 that evolution supports concepts like family values, avoiding lies, fidelity, moral codes and the rule of law. He goes on to suggest that evolution gives more support to the notion of an omnipotent creator, rather than a tinkerer with limitations based on a human model, the more common image subscribed to by creationists. Careful analysis of the creationist charges that evolution has led to moral relativism and the Holocaust yields the conclusion that these charges appear to be highly suspect. Such analyses conclude that the origins of the Holocaust are more likely to be found in historical Christian anti-Semitism than in evolution.\n\nEvolution has been used to justify Social Darwinism, the exploitation of so-called \"lesser breeds without the law\" by \"superior races,\" particularly in the nineteenth century. Typically strong European nations that had successfully expanded their empires could be said to have \"survived\" in the struggle for dominance. With this attitude, Europeans except for Christian missionaries rarely adopted any customs and languages of local people under their empires.\n\nAnother charge leveled at evolutionary theory by creationists is that belief in evolution is either tantamount to atheism, or conducive to atheism. It is commonly claimed that all proponents of evolutionary theory are \"materialistic atheists.\" On the other hand, Davis A. Young argues that creation science \"itself\" is harmful to Christianity because its bad science will turn more away than it recruits. Young asks, \"Can we seriously expect non-Christians to develop a respect for Christianity if we insist on teaching the brand of science that creationism brings with it?\" However, evolution neither requires nor rules out the existence of a supernatural being. Philosopher Robert T. Pennock makes the comparison that evolution is no more atheistic than plumbing. H. Allen Orr, professor of biology at University of Rochester, notes that:\n\nIn addition, a wide range of religions have reconciled a belief in a supernatural being with evolution. Molleen Matsumura of the National Center for Science Education found that \"of Americans in the twelve largest Christian denominations, 89.6% belong to churches that support evolution education.\" These churches include the \"United Methodist Church, National Baptist Convention USA, Evangelical Lutheran Church in America, Presbyterian Church (USA), National Baptist Convention of America, African Methodist Episcopal Church, the Roman Catholic Church, the Episcopal Church, and others.\" A poll in 2000 done for People for the American Way found that 70% of the American public felt that evolution was compatible with a belief in God. Only 48% of the people polled could choose the correct definition of evolution from a list, however.\n\nOne poll reported in the journal \"Nature\" showed that among American scientists (across various disciplines), about 40 percent believe in both evolution and an active deity (theistic evolution). This is similar to the results reported for surveys of the general American public. Also, about 40 percent of the scientists polled believe in a God that answers prayers, and believe in immortality. While about 55% of scientists surveyed were atheists, agnostics, or nonreligious theists, atheism is far from universal among scientists who support evolution, or among the general public that supports evolution. Very similar results were reported from a 1997 Gallup Poll of the American public and scientists.\n\nTraditionalists still object to the idea that diversity in life, including human beings, arose through natural processes without a need for supernatural intervention, and they argue against evolution on the basis that it contradicts their literal interpretation of creation myths about separate \"created kinds.\" However, many religions, such as Catholicism, have reconciled their beliefs with evolution through theistic evolution.\n\n\n\n"}
{"id": "20082214", "url": "https://en.wikipedia.org/wiki?curid=20082214", "title": "Obsessive–compulsive disorder", "text": "Obsessive–compulsive disorder\n\nObsessive–compulsive disorder (OCD) is a mental disorder where people feel the need to check things repeatedly, perform certain routines repeatedly (called \"rituals\"), or have certain thoughts repeatedly (called \"obsessions\"). People are unable to control either the thoughts or the activities for more than a short period of time. Common activities include hand washing, counting of things, and checking to see if a door is locked. Some may have difficulty throwing things out. These activities occur to such a degree that the person's daily life is negatively affected. This often takes up more than an hour a day. Most adults realize that the behaviors do not make sense. The condition is associated with tics, anxiety disorder, and an increased risk of suicide.\nThe cause is unknown. There appear to be some genetic components with both identical twins more often affected than both non-identical twins. Risk factors include a history of child abuse or other stress-inducing event. Some cases have been documented to occur following infections. The diagnosis is based on the symptoms and requires ruling out other drug related or medical causes. Rating scales such as the Yale–Brown Obsessive Compulsive Scale (Y-BOCS) can be used to assess the severity. Other disorders with similar symptoms include anxiety disorder, major depressive disorder, eating disorders, tic disorders, and obsessive–compulsive personality disorder.\nTreatment involves counseling, such as cognitive behavioral therapy (CBT), and sometimes antidepressants such as selective serotonin reuptake inhibitors (SSRIs) or clomipramine. CBT for OCD involves increasing exposure to what causes the problems while not allowing the repetitive behavior to occur. While clomipramine appears to work as well as SSRIs, it has greater side effects so is typically reserved as a second line treatment. Atypical antipsychotics may be useful when used in addition to an SSRI in treatment-resistant cases but are also associated with an increased risk of side effects. Without treatment, the condition often lasts decades.\nObsessive–compulsive disorder affects about 2.3% of people at some point in their life. Rates during a given year are about 1.2%, and it occurs worldwide. It is unusual for symptoms to begin after the age of 35, and half of people develop problems before 20. Males and females are affected about equally. In English, the phrase \"obsessive–compulsive\" is often used in an informal manner unrelated to OCD to describe someone who is excessively meticulous, perfectionistic, absorbed, or otherwise fixated.\nOCD can present with a wide variety of symptoms. Certain groups of symptoms usually occur together. These groups are sometimes viewed as dimensions or clusters that may reflect an underlying process. The standard assessment tool for OCD, the Yale–Brown Obsessive Compulsive Scale (Y-BOCS), has 13 predefined categories of symptoms. These symptoms fit into three to five groupings. A meta analytic review of symptom structures found a four factor structure (grouping) to be most reliable. The observed groups included a \"symmetry factor\", a \"forbidden thoughts factor\", a \"cleaning factor\", and a \"hoarding factor\". The \"symmetry factor\" correlated highly with obsessions related to ordering, counting, and symmetry, as well as repeating compulsions. The \"forbidden thoughts factor\" correlated highly with intrusive and distressing thoughts of a violent, religious, or sexual nature. The \"cleaning factor\" correlated highly with obsessions about contamination and compulsions related to cleaning. The \"hoarding factor\" only involved hoarding related obsessions and compulsions, and was identified as being distinct from other symptom groupings.\n\nWhile OCD has been considered a homogenous disorder from a neuropsychological perspective, many of the putative neuropsychological deficits may be due to comorbid disorders. Furthermore, some subtypes have been associated with improvement in performance on certain tasks such as pattern recognition (washing subtype) and spatial working memory (obsessive thought subtype). Subgroups have also been distinguished by neuroimaging findings and treatment response. Neuroimaging studies on this have been too few, and the subtypes examined have differed too much to draw any conclusions. On the other hand, subtype dependent treatment response has been studied, and the hoarding subtype has consistently responded least to treatment.\n\nObsessions are thoughts that recur and persist, despite efforts to ignore or confront them. People with OCD frequently perform tasks, or compulsions, to seek relief from obsession-related anxiety. Within and among individuals, the initial obsessions, or intrusive thoughts, vary in their clarity and vividness. A relatively vague obsession could involve a general sense of disarray or tension accompanied by a belief that life cannot proceed as normal while the imbalance remains. A more intense obsession could be a preoccupation with the thought or image of someone close to them dying or intrusions related to \"relationship rightness\". Other obsessions concern the possibility that someone or something other than oneself—such as God, the Devil, or disease—will harm either the person with OCD or the people or things that the person cares about. Other individuals with OCD may experience the sensation of invisible protrusions emanating from their bodies, or have the feeling that inanimate objects are ensouled.\n\nSome people with OCD experience sexual obsessions that may involve intrusive thoughts or images of \"kissing, touching, fondling, oral sex, anal sex, intercourse, incest, and rape\" with \"strangers, acquaintances, parents, children, family members, friends, coworkers, animals, and religious figures\", and can include \"heterosexual or homosexual content\" with persons of any age. As with other intrusive, unpleasant thoughts or images, some disquieting sexual thoughts at times are normal, but people with OCD may attach extraordinary significance to the thoughts. For example, obsessive fears about sexual orientation can appear to the person with OCD, and even to those around them, as a crisis of sexual identity. Furthermore, the doubt that accompanies OCD leads to uncertainty regarding whether one might act on the troubling thoughts, resulting in self-criticism or self-loathing.\n\nMost people with OCD understand that their notions do not correspond with reality; however, they feel that they must act as though their notions are correct. For example, an individual who engages in compulsive hoarding might be inclined to treat inorganic matter as if it had the sentience or rights of living organisms, while accepting that such behavior is irrational on a more intellectual level. There is a debate as to whether or not hoarding should be considered with other OCD symptoms.\n\nOCD sometimes manifests without overt compulsions, referred to as Primarily Obsessional OCD. OCD without overt compulsions could, by one estimate, characterize as many as 50 percent to 60 percent of OCD cases.\n\nSome people with OCD perform compulsive rituals because they inexplicably feel they have to, while others act compulsively so as to mitigate the anxiety that stems from particular obsessive thoughts. The person might feel that these actions somehow either will prevent a dreaded event from occurring or will push the event from their thoughts. In any case, the individual's reasoning is so idiosyncratic or distorted that it results in significant distress for the individual with OCD or for those around them. Excessive skin picking, hair-pulling, nail biting, and other body-focused repetitive behavior disorders are all on the obsessive–compulsive spectrum. Some individuals with OCD are aware that their behaviors are not rational, but feel compelled to follow through with them to fend off feelings of panic or dread.\n\nSome common compulsions include hand washing, cleaning, checking things (e.g., locks on doors), repeating actions (e.g., turning on and off switches), ordering items in a certain way, and requesting reassurance. Compulsions are different from tics (such as touching, tapping, rubbing, or blinking) and stereotyped movements (such as head banging, body rocking, or self-biting), which usually aren't as complex and aren't precipitated by obsessions. It can sometimes be difficult to tell the difference between compulsions and complex tics. About 10% to 40% of individuals with OCD also have a lifetime tic disorder.\n\nPeople rely on compulsions as an escape from their obsessive thoughts; however, they are aware that the relief is only temporary, that the intrusive thoughts will soon return. Some people use compulsions to avoid situations that may trigger their obsessions. Although some people do certain things over and over again, they do not necessarily perform these actions compulsively. For example, bedtime routines, learning a new skill, and religious practices are not compulsions. Whether or not behaviors are compulsions or mere habit depends on the context in which the behaviors are performed. For example, arranging and ordering DVDs for eight hours a day would be expected of one who works in a video store, but would seem abnormal in other situations. In other words, habits tend to bring efficiency to one's life, while compulsions tend to disrupt it.\n\nIn addition to the anxiety and fear that typically accompanies OCD, sufferers may spend hours performing such compulsions every day. In such situations, it can be hard for the person to fulfil their work, family, or social roles. In some cases, these behaviors can also cause adverse physical symptoms. For example, people who obsessively wash their hands with antibacterial soap and hot water can make their skin red and raw with dermatitis.\n\nPeople with OCD can use rationalizations to explain their behavior; however, these rationalizations do not apply to the overall behavior but to each instance individually. For example, a person compulsively checking the front door may argue that the time taken and stress caused by one more check of the front door is much less than the time and stress associated with being robbed, and thus checking is the better option. In practice, after that check, the person is \"still\" not sure and deems it is \"still\" better to perform one more check, and this reasoning can continue as long as necessary.\n\nThe DSM-V contains three specifiers for the level of insight in OCD. Good or fair insight is characterized by the acknowledgment that obsessive-compulsive beliefs are or may not be true. Poor insight is characterized by the belief that obsessive-complsive beliefs are probably true. Absence of insight make obsessive-compulsive beliefs delusional thoughts, and occurs in about 4% of people with OCD.\n\nSome people with OCD exhibit what is known as \"overvalued ideas\". In such cases, the person with OCD will truly be uncertain whether the fears that cause them to perform their compulsions are irrational or not. After some discussion, it is possible to convince the individual that their fears may be unfounded. It may be more difficult to do ERP therapy on such people because they may be unwilling to cooperate, at least initially. There are severe cases in which the person has an unshakeable belief in the context of OCD that is difficult to differentiate from psychotic disorders.\n\nA 2013 meta-analysis reported that people with OCD to have mild but wide-ranging cognitive deficits; significantly regarding spatial memory, to a lesser extent with verbal memory, fluency, executive function, and processing speed, while auditory attention was not significantly affected. People with OCD show impairment in formulating an organizational strategy for coding information, set-shifting, and motor and cognitive inhibition.\n\nSpecific subtypes of symptom dimensions in OCD have been associated with specific cognitive deficits. For example, the results of one meta-analysis comparing washing and checking symptoms reported that washers outperformed checkers on eight out of ten cognitive tests. The symptom dimension of contamination and cleaning may be associated with higher scores on tests of inhibition and verbal memory.\n\nApproximately 1–2% of children are affected by OCD. Obsessive–compulsive disorder symptoms tend to develop more frequently in children that are 10–14 years of age, with males displaying symptoms at an earlier age and a more severe level than the females. In children, symptoms can be grouped into at least 4 types.\n\nThe cause is unknown. Both environmental and genetic factors are believed to play a role. Risk factors include a history of child abuse or other stress-inducing event.\n\nThere appear to be some genetic components with identical twins more often affected than non-identical twins. Further, individuals with OCD are more likely to have first-degree family members exhibiting the same disorders than do matched controls. In cases where OCD develops during childhood, there is a much stronger familial link in the disorder than cases in which OCD develops later in adulthood. In general, genetic factors account for 45–65% of the variability in OCD symptoms in children diagnosed with the disorder. A 2007 study found evidence supporting the possibility of a heritable risk for OCD.\n\nA mutation has been found in the human serotonin transporter gene, hSERT, in unrelated families with OCD.\n\nA systematic review found that while neither allele was associated with OCD overall, in caucasians the L allele was associated with OCD. Another meta analysis observed an increased risk in those with the homozygous S allele, but found the LS genotype to be inversely associated with OCD.\n\nA genome wide association study found OCD to be linked with SNPs near BTBD3 and two SNPs in DLGAP1 in a trio-based analysis, but no SNP reached significance when analyzed with case-control data.\n\nOne meta analysis found a small but significant association between a polymorphism in SLC1A1 and OCD.\n\nThe relationship between OCD and COMT has been inconsistent, with one meta analysis reporting a significant association, albeit only in men, and another meta analysis reporting no association.\n\nIt has been postulated by evolutionary psychologists that moderate versions of compulsive behavior may have had evolutionary advantages. Examples would be moderate constant checking of hygiene, the hearth or the environment for enemies. Similarly, hoarding may have had evolutionary advantages. In this view OCD may be the extreme statistical \"tail\" of such behaviors, possibly due to a high amount of predisposing genes.\n\nA controversial hypothesis is that some cases of rapid onset of OCD in children and adolescents may be caused by a syndrome connected to Group A streptococcal infections, known as pediatric autoimmune neuropsychiatric disorders associated with streptococcal infections (PANDAS).\n\nA review of studies examining anti-basal ganglia antibodies in OCD found an increased risk of having anti-basal ganglia antibodies in those with OCD versus the general population.\n\nFunctional neuroimaging during symptom provocation has observed abnormal activity in the orbitofrontal cortex, left dorsolateral prefrontal cortex, right premotor cortex, left superior temporal gyrus, globus pallidus externus, hippocampus and right uncus. Weaker foci of abnormal activity were found in the left caudate, posterior cingulate cortex and superior parietal lobule. However, an older meta analysis of functional neuroimaging in OCD reported the only consistent functional neuroimaging findings have been increased activity in the orbital gyrus and head of the caudate nucleus, while ACC activation abnormalities were too inconsistent. A meta analysis comparing affective and non affective tasks observed differences with controls in regions implicated in salience, habit, goal ditected behavior, self-referential thinking and cognitive control. For non affective tasks, hyperactivity was observed in the insula, ACC, and head of the caudate/putamen, while hypoactivity was observed in the medial prefrontal cortex(mPFC) and posterior caudate. Affective tasks were observed to relate to increased activation in the precuneus and posterior cingulate cortex(PCC), while decreased activation was found in the pallidum, ventral anterior thalamus and postetior caudate. The involvement of the cortico-striato-thalamo-cortical loop in OCD as well as the high rates of comorbidity between OCD and ADHD have led some to draw a link in their mechanism. Observed similarities include dysfunction of the anterior cingulate cortex, and prefrontal cortex, as well as shared deficits in executive functions. The involvement of the orbitofrontal cortex and dorsolateral prefrontal cortex in OCD is shared with Bipolar Disorder and may explain their high degree of comorbidity. Decreased volumes of the dorsolateral prefrontal cortex related to executive function has also been observed in OCD.\n\nPeople with OCD evince increased grey matter volumes in bilateral lenticular nuclei, extending to the caudate nuclei, with decreased grey matter volumes in bilateral dorsal medial frontal/anterior cingulate gyri. These findings contrast with those in people with other anxiety disorders, who evince decreased (rather than increased) grey matter volumes in bilateral lenticular / caudate nuclei, as well as decreased grey matter volumes in bilateral dorsal medial frontal/anterior cingulate gyri. Increased white matter volume and decreased fractional anisotropy in anterior midline tracts has been observed in OCD, possibly indicating increased fiber crossings.\n\nGenerally two categories of models for OCD have been postulated, the first involving deficits in executive function, and the second involving deficits in modulatory control. The first category of executive dysfunction is based on the observed structural and functional abnormalities in the dlPFC, striatum, and thalamus. The second category involving dysfunctional modulatory control primarily relies on observed functional and structural differences in the ACC, mPFC and OFC.\n\nOne proposed model suggests that dysfunction in the OFC leads to improper valuation of behaviors and decreased behavioral control, while the observed alterations in amygdala activations leads to exaggerated fears and representations of negative stimuli.\n\nDue to the heterogeneity of OCD symptoms, studies differentiating between symptoms have been performed. Symptom specific neuroimaging abnormalities include the hyperactivity of caudate and ACC in checking rituals, while finding increased activity of cortical and cerebellar regions in contamination related symptoms. Neuroimaging differentiating between content of intrusive thoughts have found differences between aggressive as opposed to taboo thoughts, finding increased connectivity of the amygdala, ventral striatum, and ventromedial prefrontal cortex in aggressive symptoms, while observing increased connectivity between the ventral striatum and insula in sexual/religious intrusive thoughts.\n\nAnother model proposes that affective dysregulation links excessive reliance on habit based action selection with compulsions. This is supported by the observation that those with OCD demonstrate decreased activation of the ventral striatum when anticipating monetary reward, as well as increase functional connectivity between the VS and the OFC. Furthermore, those with OCD demonstrate reduced performance in pavlovian fear extinction tasks, hyper responsiveness in the amygdala to fearful stimuli, and hypo-resonsiveness in the amygdala when exposed to positively valanced stimuli. Stimulation of the nucleus accumbens has also been observed to effectively alleviate both obsessions and compulsions, supporting the role of affective dysregulation in generating both.\n\nFrom the observation of the efficacy of antidepressants in OCD, a serotonin hypothesis of OCD has been formulated. Studies of peripheral markers of serotonin, as well as challenges with proserotonergic compounds have yielded inconsistent results, including evidence pointing towards basal hyperactivity of serotonergic systems. Serotonin receptor and transporter binding studies have yielded conflicting results, including higher and lower serotonin receptor 5-HT2A and serotonin transporter binding potentials that were normalized by treatment with SSRIs. Despite inconsistencies in the types of abnormalities found, evidence points towards dysfunction of serotonergic systems in OCD. Orbitofrontal cortex overactivity is attenuated in people who have successfully responded to SSRI medication, a result believed to be caused by increased stimulation of serotonin receptors 5-HT2A and 5-HT2C. A complex relationship between dopamine and OCD has been observed. Although antipsychotics, which act by antagonizing dopamine receptors may improve some cases of OCD, they frequently exacerbate others. Antipsychotics, in the low doses used to treat OCD, may actually increased the release of dopamine in the prefrontal cortex, through inhibiting autoreceptors. Further complicating things is the efficacy of amphetamines, decreased dopamine transporter activity observed in OCD, and low levels of D2 binding in the striatum. Furthermore, increased dopamine release in the nucleus accumbens after deep brain stimulation correlates with improvement in symptoms, pointing to reduced dopamine release in the striatum playing a role in generating symptoms.\n\nAbnormalities in glutaminergic neurotransmission have implicated in OCD. Findings such as increased cerebrospinal glutamate, less consistent abnormalities observed in neuroimaging studies, and the efficacy of some glutaminergic drugs such as riluzole have implicated glutamate in OCD. OCD has been associated with reduced N-Acetylaspartic acid in the mPFC, which is thought to reflect neuron density or functionality, although the exact interpretation has not been established.\n\nFormal diagnosis may be performed by a psychologist, psychiatrist, clinical social worker, or other licensed mental health professional. To be diagnosed with OCD, a person must have obsessions, compulsions, or both, according to the Diagnostic and Statistical Manual of Mental Disorders (DSM). The Quick Reference to the 2000 edition of the DSM states that several features characterize clinically significant obsessions and compulsions. Such obsessions, the DSM says, are recurrent and persistent thoughts, impulses or images that are experienced as intrusive and that cause marked anxiety or distress. These thoughts, impulses or images are of a degree or type that lies outside the normal range of worries about conventional problems. A person may attempt to ignore or suppress such obsessions, or to neutralize them with some other thought or action, and will tend to recognize the obsessions as idiosyncratic or irrational.\n\nCompulsions become clinically significant when a person feels driven to perform them in response to an obsession, or according to rules that must be applied rigidly, and when the person consequently feels or causes significant distress. Therefore, while many people who do not suffer from OCD may perform actions often associated with OCD (such as ordering items in a pantry by height), the distinction with clinically significant OCD lies in the fact that the person who suffers from OCD \"must\" perform these actions, otherwise they will experience significant psychological distress. These behaviors or mental acts are aimed at preventing or reducing distress or preventing some dreaded event or situation; however, these activities are not logically or practically connected to the issue, or they are excessive. In addition, at some point during the course of the disorder, the individual must realize that their obsessions or compulsions are unreasonable or excessive.\n\nMoreover, the obsessions or compulsions must be time-consuming (taking up more than one hour per day) or cause impairment in social, occupational or scholastic functioning. It is helpful to quantify the severity of symptoms and impairment before and during treatment for OCD. In addition to the peron's estimate of the time spent each day harboring obsessive-compulsive thoughts or behaviors, concrete tools can be used to gauge the people’s condition. This may be done with rating scales, such as the Yale–Brown Obsessive Compulsive Scale (Y-BOCS). With measurements like these, psychiatric consultation can be more appropriately determined because it has been standardized.\n\nOCD is sometimes placed in a group of disorders called the obsessive–compulsive spectrum.\n\nOCD is often confused with the separate condition obsessive–compulsive personality disorder (OCPD). OCD is egodystonic, meaning that the disorder is incompatible with the sufferer's self-concept. Because ego dystonic disorders go against a person's self-concept, they tend to cause much distress. OCPD, on the other hand, is egosyntonic—marked by the person's acceptance that the characteristics and behaviours displayed as a result are compatible with their self-image, or are otherwise appropriate, correct or reasonable.\n\nAs a result, people with OCD are often aware that their behavior is not rational, are unhappy about their obsessions but nevertheless feel compelled by them. By contrast people with OCPD are not aware of anything abnormal; they will readily explain why their actions are rational, it is usually impossible to convince them otherwise, and they tend to derive pleasure from their obsessions or compulsions.\n\nA form of psychotherapy called \"cognitive behavioral therapy\" (CBT) and psychotropic medications are first-line treatments for OCD. Other forms of psychotherapy, such as psychodynamic and psychoanalysis may help in managing some aspects of the disorder, but in 2007 the American Psychiatric Association (APA) noted a lack of controlled studies showing their effectiveness \"in dealing with the core symptoms of OCD\". The fact that many individuals do not seek treatment may be due in part to stigma associated with OCD.\n\nThe specific technique used in CBT is called exposure and response prevention (ERP) which involves teaching the person to deliberately come into contact with the situations that trigger the obsessive thoughts and fears (\"exposure\"), without carrying out the usual compulsive acts associated with the obsession (\"response prevention\"), thus gradually learning to tolerate the discomfort and anxiety associated with not performing the ritualistic behavior. At first, for example, someone might touch something only very mildly \"contaminated\" (such as a tissue that has been touched by another tissue that has been touched by the end of a toothpick that has touched a book that came from a \"contaminated\" location, such as a school.) That is the \"exposure\". The \"ritual prevention\" is not washing. Another example might be leaving the house and checking the lock only once (exposure) without going back and checking again (ritual prevention). The person fairly quickly habituates to the anxiety-producing situation and discovers that their anxiety level drops considerably; they can then progress to touching something more \"contaminated\" or not checking the lock at all—again, without performing the ritual behavior of washing or checking.\n\nERP has a strong evidence base, and it is considered the most effective treatment for OCD. However, this claim was doubted by some researchers in 2000 who criticized the quality of many studies.\n\nIt has generally been accepted that psychotherapy, in combination with psychiatric medication, is more effective than either option alone.\n\nThe medications most frequently used are the selective serotonin reuptake inhibitors (SSRIs). Clomipramine, a medication belonging to the class of tricyclic antidepressants, appears to work as well as SSRIs but has a higher rate of side effects.\n\nSSRIs are a second line treatment of adult obsessive compulsive disorder (OCD) with mild functional impairment and as first line treatment for those with moderate or severe impairment. In children, SSRIs can be considered as a second line therapy in those with moderate-to-severe impairment, with close monitoring for psychiatric adverse effects. SSRIs are efficacious in the treatment of OCD; people treated with SSRIs are about twice as likely to respond to treatment as those treated with placebo. Efficacy has been demonstrated both in short-term (6–24 weeks) treatment trials and in discontinuation trials with durations of 28–52 weeks.\n\nIn 2006, the National Institute of Clinical and Health Excellence (NICE) guidelines recommended antipsychotics for OCD that does not improve with SSRI treatment. For OCD there is tentative evidence for risperidone and insufficient evidence for olanzapine. Quetiapine is no better than placebo with regard to primary outcomes, but small effects were found in terms of YBOCS score. The efficacy of quetiapine and olanzapine are limited by the insufficient number of studies. A 2014 review article found two studies that indicated that aripiprazole was \"effective in the short-term\" and found that \"[t]here was a small effect-size for risperidone or anti-psychotics in general in the short-term\"; however, the study authors found \"no evidence for the effectiveness of quetiapine or olanzapine in comparison to placebo.\" While quetiapine may be useful when used in addition to an SSRI in treatment-resistant OCD, these drugs are often poorly tolerated, and have metabolic side effects that limit their use. None of the atypical antipsychotics appear to be useful when used alone. Another review reported that no evidence supports the use of first generation antipsychotics in OCD.\n\nA guideline by the APA suggested that dextroamphetamine may be considered by itself after more well supported treatments have been tried.\n\nElectroconvulsive therapy (ECT) has been found to have effectiveness in some severe and refractory cases.\n\nSurgery may be used as a last resort in people who do not improve with other treatments. In this procedure, a surgical lesion is made in an area of the brain (the cingulate cortex). In one study, 30% of participants benefitted significantly from this procedure. Deep-brain stimulation and vagus nerve stimulation are possible surgical options that do not require destruction of brain tissue. In the United States, the Food and Drug Administration approved deep-brain stimulation for the treatment of OCD under a humanitarian device exemption requiring that the procedure be performed only in a hospital with specialist qualifications to do so.\n\nIn the United States, psychosurgery for OCD is a treatment of last resort and will not be performed until the person has failed several attempts at medication (at the full dosage) with augmentation, and many months of intensive cognitive–behavioral therapy with exposure and ritual/response prevention. Likewise, in the United Kingdom, psychosurgery cannot be performed unless a course of treatment from a suitably qualified cognitive–behavioral therapist has been carried out.\n\nTherapeutic treatment may be effective in reducing ritual behaviors of OCD for children and adolescents. Similar to the treatment of adults with OCD, CBT stands as an effective and validated first line of treatment of OCD in children. Family involvement, in the form of behavioral observations and reports, is a key component to the success of such treatments. Parental interventions also provide positive reinforcement for a child who exhibits appropriate behaviors as alternatives to compulsive responses. In a recent meta-analysis of evidenced-based treatment of OCD in children, family-focused individual CBT was labeled as \"probably efficacious\", establishing it as one of the leading psychosocial treatments for youth with OCD. After one or two years of therapy, in which a child learns the nature of his or her obsession and acquires strategies for coping, that child may acquire a larger circle of friends, exhibit less shyness, and become less self-critical.\n\nAlthough the causes of OCD in younger age groups range from brain abnormalities to psychological preoccupations, life stress such as bullying and traumatic familial deaths may also contribute to childhood cases of OCD, and acknowledging these stressors can play a role in treating the disorder.\n\nObsessive–compulsive disorder affects about 2.3% of people at some point in their life. Rates during a given year are about 1.2% and it occurs worldwide. It is unusual for symptoms to begin after the age of thirty five and half of people develop problems before twenty. Males and females are affected about equally.\n\nPeople with OCD may be diagnosed with other conditions, as well as or instead of OCD, such as the aforementioned obsessive–compulsive personality disorder, major depressive disorder, bipolar disorder, generalized anxiety disorder, anorexia nervosa, social anxiety disorder, bulimia nervosa, Tourette syndrome, autism spectrum disorder, attention deficit hyperactivity disorder, dermatillomania (compulsive skin picking), body dysmorphic disorder and trichotillomania (hair pulling). More than 50 percent of people experience suicidal tendencies, and 15 percent have attempted suicide. Depression, anxiety and prior suicide attempts increase the risk of future suicide attempts.\n\nIndividuals with OCD have also been found to be affected by delayed sleep phase syndrome at a substantially higher rate than the general public. Moreover, severe OCD symptoms are consistently associated with greater sleep disturbance. Reduced total sleep time and sleep efficiency have been observed in people with OCD, with delayed sleep onset and offset and an increased prevalence of delayed sleep phase disorder.\n\nBehaviorally, there is some research demonstrating a link between drug addiction and the disorder as well. For example, there is a higher risk of drug addiction among those with any anxiety disorder (possibly as a way of coping with the heightened levels of anxiety), but drug addiction among people with OCD may serve as a type of compulsive behavior and not just as a coping mechanism. Depression is also extremely prevalent among people with OCD. One explanation for the high depression rate among OCD populations was posited by Mineka, Watson and Clark (1998), who explained that people with OCD (or any other anxiety disorder) may feel depressed because of an \"out of control\" type of feeling.\n\nSomeone exhibiting OCD signs does not necessarily have OCD. Behaviors that present as (or seem to be) obsessive or compulsive can also be found in a number of other conditions as well, including obsessive–compulsive \"personality\" disorder (OCPD), autism spectrum disorder, disorders where perseveration is a possible feature (ADHD, PTSD, bodily disorders or habit problems) or sub-clinically.\n\nSome with OCD present with features typically associated with Tourette's syndrome, such as compulsions that may appear to resemble motor tics; this has been termed \"tic-related OCD\" or \"Tourettic OCD\".<ref name=\"10.1176/appi.neuropsych.21.1.59\"></ref>\n\nA myth propagated by Sigmund Freud regarding above-average intelligence in OCD was recently refuted.\n\nOCD frequently co-occurs with both bipolar disorder and major depressive disorder. Between 60–80% of those with OCD experience a major depressive episode in their lifetime. Comorbidity rates have been reported at between 19–90% due to methodological differences. Between 9–35% of those with bipolar disorder also have OCD, compared to the 1–2% in the general population. Around 50% of those with OCD experience cyclothymic traits or hypomanic episodes. OCD is also associated with anxiety disorders. Lifetime comorbidity for OCD has been reported at 22% for specific phobia, 18% for social anxiety disorder, 12% for panic disorder, and 30% for generalized anxiety disorder. The comorbidity rate for OCD and ADHD has been reported as high as 51%.\n\nQuality of life is reduced across all domains in OCD. While psychological or pharmacological treatment can lead to a reduction of OCD symptoms and an increase in QoL, symptoms may persist at moderate levels even following adequate treatment courses, and completely symptom-free periods are uncommon. In pediatric OCD, around 40% still have the disorder in adulthood, and around 40% qualify for remission.\n\nIn the seventh century AD, John Climacus records an instance of a young monk plagued by constant and overwhelming \"temptations to blasphemy\" consulting an older monk, who told him, \"My son, I take upon myself all the sins which these temptations have led you, or may lead you, to commit. All I require of you is that for the future you pay no attention to them whatosever.\" \"The Cloud of Unknowing\", a Christian mystical text from the late fourteenth century, recommends dealing with recurring obsessions by first attempting to ignore them, and, if that fails, \"cower under them like a poor wretch and a coward overcome in battle, and reckon it to be a waste of your time for you to strive any longer against them\", a technique now known as \"emotional flooding\".\n\nFrom the 14th to the 16th century in Europe, it was believed that people who experienced blasphemous, sexual or other obsessive thoughts were possessed by the Devil. Based on this reasoning, treatment involved banishing the \"evil\" from the \"possessed\" person through exorcism. The vast majority of people who thought they were possessed by the Devil did not suffer from hallucinations or other \"spectacular symptoms\", but \"complained of anxiety, religious fears, and evil thoughts.\" In 1584, a woman from Kent, England named Mrs. Davie, described by a justice of the peace as \"a good wife\", was nearly burned at the stake after she confessed that she experienced constant, unwanted urges to murder her family.\n\nThe English term obsessive-compulsive comes from the translated term used to describe the first conceptions of OCD by Carl Westphal, \"zwangsvorstellung\". Westphal's description went on to influence Pierre Janet who further documented features of OCD. In the early 1910s, Sigmund Freud attributed obsessive–compulsive behavior to unconscious conflicts that manifest as symptoms. Freud describes the clinical history of a typical case of \"touching phobia\" as starting in early childhood, when the person has a strong desire to touch an item. In response, the person develops an \"external prohibition\" against this type of touching. However, this \"prohibition does not succeed in abolishing\" the desire to touch; all it can do is repress the desire and \"force it into the unconscious\". Freudian psychoanalysis remained the dominant treatment for OCD until the mid-1980s, even though medicinal and therapeutical treatments were known and available, because it was widely thought that these treatments would be detrimental to the effectiveness of the psychotherapy. In the mid-1980s, psychiatry made a sudden \"about-face\" on the subject and began treating OCD primarily through medicine and practical therapy rather than psychoanalysis.\n\nJohn Bunyan (1628–1688), the author of \"The Pilgrim's Progress\", displayed symptoms of OCD (which had not yet been named). During the most severe period of his condition, he would mutter the same phrase over and over again to himself while rocking back and forth. He later described his obsessions in his autobiography \"Grace Abounding to the Chief of Sinners\", stating, \"These things may seem ridiculous to others, even as ridiculous as they were in themselves, but to me they were the most tormenting cogitations.\" He wrote two pamphlets advising those suffering from similar anxieties. In one of them, he warns against indulging in compulsions: \"Have care of putting off your trouble of spirit in the wrong way: by promising to reform yourself and lead a new life, by your performances or duties\".\n\nBritish poet, essayist and lexicographer Samuel Johnson (1709–1784) also suffered from OCD. He had elaborate rituals for crossing the thresholds of doorways, and repeatedly walked up and down staircases counting the steps. He would touch every post on the street as he walked past, only step in the middles of paving stones, and repeatedly perform tasks as though they had not been done properly the first time. The American aviator and filmmaker Howard Hughes is known to have had OCD. Friends of Hughes have also mentioned his obsession with minor flaws in clothing. This was conveyed in \"The Aviator\" (2004), a film biography of Hughes.\n\nMovies and television shows often portray idealized representations of disorders such as OCD. These depictions may lead to increased public awareness, understanding and sympathy for such disorders.\n\n\nThe naturally occurring sugar inositol has been suggested as a treatment for OCD.\n\nNutrition deficiencies may also contribute to OCD and other mental disorders. Vitamin and mineral supplements may aid in such disorders and provide nutrients necessary for proper mental functioning.\n\nμ-Opioids, such as hydrocodone and tramadol, may improve OCD symptoms. Administration of opiate treatment may be contraindicated in individuals concurrently taking CYP2D6 inhibitors such as fluoxetine and paroxetine.\n\nMuch current research is devoted to the therapeutic potential of the agents that affect the release of the neurotransmitter glutamate or the binding to its receptors. These include riluzole, memantine, gabapentin, N-acetylcysteine, topiramate and lamotrigine.\n\n"}
{"id": "39364059", "url": "https://en.wikipedia.org/wiki?curid=39364059", "title": "Paternal care", "text": "Paternal care\n\nIn biology, paternal care is parental investment provided by a male or female animal to their own offspring. Paternal care may provided in concert with the mother (biparental care) or, more rarely, by the male alone (so called exclusive paternal care).\n\nThe provision of care, by either males or females, is presumed to increase growth rates, quality, and/or survival of young, and hence ultimately increase the inclusive fitness of parents. In a variety of vertebrate species (e.g., about 80% of birds and about 6% of mammals), both males and females invest heavily in their offspring. Many of these biparental species are socially monogamous, so individuals remain with their mate for at least one breeding season.\n\nExclusive paternal care has evolved multiple times in a variety of organisms, including invertebrates, fishes, and amphibians.\n\nMale mammals may invest heavily in reproduction through efforts to enhance reproductive success (e.g., courtship displays, intrasexual combat) or to provide paternal care. However, the costs of paternal care have rarely been studied in mammals, in large part because only 5-10% of mammals exhibit such care. Nonetheless, in those species in which males do provide extensive care for their offspring (i.e., biparental species, including humans), indirect evidence suggests that its costs can be substantial. For example, mammalian fathers that care for their young may undergo systematic changes in body mass and in circulating or excreted concentrations of a number of hormones (e.g., androgens, glucocorticoids, leptin) as a function of reproductive status, and several of these hormones have important effects on body composition, metabolism, and organismal performance. Nonetheless, the energetic and performance consequences of male parental investment have rarely been investigated directly in mammals.\n\nIn mammals, paternal care is found most commonly in primates, rodents and canids.\n\nHuman cultures and societies vary widely in the expression of paternal care. Some cultures recognize paternal care via celebration of Father's Day. According to CARTA , human paternal care is a derived characteristic (evolved in humans or our recent ancestors) and one of the defining characteristics of \"Homo sapiens\". Different aspects of human paternal care (direct, indirect, fostering social or moral development) may have evolved at different points in our history, and together they form a unique suite of behaviors as compared with the great apes.\nOne study of humans has found evidence suggesting a possible evolutionary trade-off between mating success and parenting involvement; specifically, fathers with smaller testes tend to be more involved in care of their children.\n\nResearch on the effects of paternal care on human happiness have yielded conflicting results. However, one recent study concluded that fathers generally report higher levels of happiness, positive emotion, and meaning in life as compared with non-fathers.\n\nAccording to the United States Census Bureau, approximately one third of children in the U.S. grow up without their biological father in their home. Numerous studies have documented negative consequences of being raised in a home that lacks a father, including increased likelihood of living in poverty, having behavioral problems, committing crimes, spending time in prison, abusing drugs or alcohol, becoming obese, and dropping out of school.\n\nPaternal care is rare in non-human primates.\n\nSeveral species of rodents have been studied as models of paternal care, including prairie voles (\"Microtus ochrogaster\"), Campbell's dwarf hamster, the Mongolian gerbil, and the African striped mouse. The California mouse (\"Peromyscus californicus\") is a monogamous rodent that exhibits extensive and essential paternal care, and hence has been studied as a model organism for this phenomenon. One study of this species found that fathers had larger hindlimb muscles than did non-breeding males. Quantitative genetic analysis has identified several genomic regions that affect paternal care.\n\nFathers contribute equally with mothers to the care of offspring in as many as 90% of bird species, sometimes including incubating the eggs. Most paternal care is associated with biparental care in socially monogamous mating systems (about 81% of species), but in approximately 1% of species, fathers provide all care after eggs are laid. The unusually high incidence of paternal care in birds compared to other vertebrate taxa is often assumed to stem from the extensive resource requirements for production of flight-capable offspring. By contrast, in bats (the other extant flying vertebrate lineage), care of offspring is provided by females (although males may help guard pups in some species). In contrast to the large clutch sizes found in many bird species with biparental care, bats typically produce single offspring, which may be a limitation related to lack of male help. It has been suggested, though not without controversy, that paternal care is the ancestral form of parental care in birds.\n\nPaternal care occurs in a number of species of anuran amphibians, including glass frogs.\n\nPaternal care occurs in perhaps as many as half of the known species of certain families of teleost fish. One well-known example of paternal care is in seahorses, where males brood the eggs in a brood pouch until they are ready to hatch. \n\nMales from the Centrarchidae (sunfish) family exhibit paternal parental care of their eggs and fry through a variety of behaviors such as nest guarding and nest fanning (aerating eggs).\n\nIn jawfish, the female lays the eggs and the male then takes them in his mouth. A male can have up to 400 eggs in his mouth at one time. The male can't feed while he hosts the young, but as the young get older, they spend more time out of the mouth. This is sometimes termed mouthbrooding.\n\nDuring the breeding season, male three-spined sticklebacks defend nesting territories. Males attract females to spawn in their nests and defend their breeding territory from intruders and predators. After spawning, the female leaves the male's territory and the male is solely responsible for the care of the eggs. During the ~6-day incubation period, the male 'fans' (oxygenates) the eggs, removes rotten eggs and debris, and defends the territory. Even after embryos hatch, father sticklebacks continue to tend their newly hatched offspring for ~7 days, chasing and retrieving fry that stray from the nest and spitting them back into the nest.\n\nPaternal care is rare in arthropods, but occurs in some species, including the giant water bug and the arachnid \"Iporangaia pustulosa\", a harvestman. In several species of crustaceans, males provide care of offspring by building and defending burrows or other nest sites. Exclusive paternal care, where males provide the sole investment after egg-laying, is the rarest form, and is known in only 13 taxa: giant water bugs, sea spiders, two genera of leaf-footed bugs, two genera of assassin bugs, three genera of phlaeothripid thrips, three genera of harvestmen, and in millipedes of the family Andrognathidae.\n\nMathematical models related to the prisoner's dilemma suggest that when female reproductive costs are higher than male reproductive costs, males cooperate with females even when they do not reciprocate. In this view, paternal care is an evolutionary achievement that compensates for the higher energy demands that reproduction typically involves for mothers.\n\nOther models suggest that basic life-history differences between males and females are adequate to explain the evolutionary origins of maternal, paternal, and bi-parental care. Specifically, paternal care is more likely if male adult mortality is high, and maternal care is more likely to evolve if female adult mortality is high. Basic life-history differences between the sexes can also cause evolutionary transitions among different sex-specific patterns of parental care.\n\nCare by fathers can have important consequences for survival and development of offspring in both humans and other species. Mechanisms underlying such effects may include protecting offspring from predators or environmental extremes (e.g., heat or cold), feeding them or, in some species, direct teaching of skills. Moreover, some studies indicate a potential epigenetic germline inheritance of\npaternal effects.\n\nThe effects of paternal care on offspring can be studied in various ways. One way is to compare species that vary in the degree of paternal care. For example, an extended duration of paternal care occurs in the gentoo penguin, as compared with other \"Pygoscelis\" species. It was found that their fledging period, the time between a chick's first trip to sea and its absolute independence from the group, was longer than other penguins of the same genus. The authors hypothesized that this was because it allowed chicks to better develop their foraging skills before becoming completely independent from their parents. By doing so, a chick may have a higher chance of survival and increase the population's overall fitness.\n\nThe proximate mechanisms of paternal care are not well understood for any organism. In vertebrates, at the level of hormonal control, vasopressin apparently underlies the neurochemical basis of paternal care; prolactin and testosterone may also be involved. As with other behaviors that affect Darwinian fitness, reward pathways in the brain may reinforce the expression of paternal care and may be involved in the formation of attachment bonds.\n\nThe mechanisms that underlie the onset of parental behaviors in female mammals have been characterized in a variety of species. In mammals, females undergo endocrine changes during gestation and lactation that \"prime\" mothers to respond maternally towards their offspring.\n\nPaternal males do not undergo these same hormonal changes and so the proximate causes of the onset of parental behaviors must differ from those in females. There is little consensus regarding the processes by which mammalian males begin to express parental behaviors. In humans, evidence ties oxytocin to sensitive care-giving in both women and men, and with affectionate infant contact in women and stimulatory infant contact in men. In contrast, testosterone decreases in men who become involved fathers and testosterone may interfere with aspects of paternal care.\n\nPlacentophagia (the behavior of ingesting the afterbirth after parturition) has been proposed to have physiological consequences that could facilitate a male's responsiveness to offspring Non-genomic transmission of paternal behavior from fathers to their sons has been reported to occur in laboratory studies of the biparental California mouse, but whether this involves (epigenetic) modifications or other mechanisms is not yet known.\n\n\n"}
{"id": "24732429", "url": "https://en.wikipedia.org/wiki?curid=24732429", "title": "Peshotanu (punishment)", "text": "Peshotanu (punishment)\n\nA Peshotanu, meaning \"one who pays with his body\", according to Avestan terminology, is a person who had either been condemned to or previously subjected to two hundred stripes with the \"Aspahe-astra\" and the \"Sraosho-karana\". Two hundred flogs with a whip was a capital punishment in Ancient Persia next only to death. A Peshotanu was also designated margarzan or \"worthy of death\".\n"}
{"id": "12242679", "url": "https://en.wikipedia.org/wiki?curid=12242679", "title": "Ping-pong scheme", "text": "Ping-pong scheme\n\nAlgorithms said to employ a Ping-Pong scheme exist in different fields of Software Engineering. They are characterized by an alternation between two entities. In the examples described below, these entities are communication partners, network paths or file blocks.\n\nIn most database management systems durable database transactions are supported through a log file. However, multiple writes to the same page of that file can produce a slim chance of data loss. Assuming for simplicity that the log file is organized in pages whose size matches the block size of its underlying medium, the following problem can occur:\n\nIf the very last page of the log file is only partially filled with data and has to be written to permanent storage in this state, the very same page will have to be overwritten during the next write operation. If a crash happens during that later write operation, previously stored log data may be lost.\n\nThe Ping-Pong scheme described in \"Transaction Processing\" eliminates this problem by alternately writing the contents of said (logical) last page to two different physical pages inside the log file (the actual last page \"i\" and its empty successor \"i+1\"). Once said logical log page is no longer the last page (i.e. it is completely filled with log data), it is written one last time to the regular physical position (\"i\") inside the log file.\n\nThis scheme requires the usage of time stamps for each page in order to distinguish the most recent version of the logical last page one from its predecessor.\n\nA functionality which lets a computer A find out whether a computer B is reachable and responding is built into the Internet Control Message Protocol (ICMP). Through an \"echo request\" Computer A asks B to send back an \"Echo response\". These two messages are also sometimes called \"ping\" and \"pong\".\n\nIn Routing, a Ping-Pong scheme is a simple algorithm for distributing data packets across\ntwo paths.\n\nIf you had two paths codice_1 and codice_2, then the algorithm\nwould randomly start with one of the paths and then switch back and forth \nbetween the two.\n\nIf you were to get the next path from a function call, it would look like\nthis in Python:\n"}
{"id": "25714505", "url": "https://en.wikipedia.org/wiki?curid=25714505", "title": "Professional abuse", "text": "Professional abuse\n\nThere are several definitions for professional abuse and distinctions are usually pronounced in definitions according to professional fields. One of the general descriptions, however, that sought to bridge the variations was put forward by the National Council of Psychotherapists, which explained professional abuse as a violation of an organization's code of ethics. Some sources refer to this as standards of behavior, which include the maintenance of professional boundaries and the treatment of people with respect and dignity. A more comprehensive version of this description states that this type of abuse is \"a pattern of conduct in which a person abuses, violates, or takes advantage of a victim within the context of the abuser's profession.\"\n\nProfessional abusers are the individuals who prey on the weaknesses of others in their workplaces or in other places related to economical strands of society. Their fundamental behavior is based in the following actions:\n\n\nThere are many forms of abuse. It may be:\n\nProfessional abuse always involves:\n\nProfessionals can abuse in three ways:\n\nThere are several strategies available to organizations seeking to address professional abuse. A study, for instance, revealed that this problem often arises when there is an extreme power imbalance between the professional and the victim. A framework based on different grades of client empowerment and ways of strengthening it can help solve the problem. Those who have been subjected to professional abuse could also pursue any of the following courses of actions: lodging a complaint; reporting abuse to the police; and, taking legal action.\n\nThere are also organizations that can help those who are victimized learn more about their rights and the options available to them.\n\n\n"}
{"id": "26754386", "url": "https://en.wikipedia.org/wiki?curid=26754386", "title": "Randomized rounding", "text": "Randomized rounding\n\nWithin computer science and operations research,\nmany combinatorial optimization problems are computationally intractable to solve exactly (to optimality).\nMany such problems do admit fast (polynomial time) approximation algorithms—that is, algorithms that are guaranteed to return an approximately optimal solution given any input.\n\nRandomized rounding\n\nis a widely used approach for designing and analyzing such approximation algorithms. \nThe basic idea is to use the probabilistic method\nto convert an optimal solution of a relaxation\nof the problem into an approximately optimal solution to the original problem.\n\nThe basic approach has three steps:\n\n(Although the approach is most commonly applied with linear programs,\nother kinds of relaxations are sometimes used.\nFor example, see Goeman's and Williamson's semi-definite programming-based\nMax-Cut approximation algorithm.)\n\nThe challenge in the first step is to choose a suitable integer linear program.\nFamiliarity with linear programming is required, in particular, familiarity with\nhow to model problems using linear programs and integer linear programs.\nBut, for many problems, there is a natural integer linear program that works well,\nsuch as in the Set Cover example below. (The integer linear program should have a small\nintegrality gap;\nindeed randomized rounding is often used to prove bounds on integrality gaps.)\n\nIn the second step, the optimal fractional solution can typically be computed\nin polynomial time\nusing any standard linear programming algorithm.\n\nIn the third step, the fractional solution must be converted into an integer solution\n(and thus a solution to the original problem).\nThis is called \"rounding\" the fractional solution.\nThe resulting integer solution should (provably) have cost\nnot much larger than the cost of the fractional solution.\nThis will ensure that the cost of the integer solution\nis not much larger than the cost of the optimal integer solution.\n\nThe main technique used to do the third step (rounding) is to use randomization,\nand then to use probabilistic arguments to bound the increase in cost due to the rounding\n(following the probabilistic method from combinatorics).\nThere, probabilistic arguments are used to show the existence of discrete structures with\ndesired properties. In this context, one uses such arguments to show the following:\n\nFinally, to make the third step computationally efficient,\none either shows that formula_3 approximates formula_1\nwith high probability (so that the step can remain randomized)\nor one derandomizes the rounding step,\ntypically using the method of conditional probabilities.\nThe latter method converts the randomized rounding process\ninto an efficient deterministic process that is guaranteed\nto reach a good outcome.\n\nThe randomized rounding step differs from most applications of the probabilistic method in two respects:\n\nThe following example illustrates how randomized rounding can be used to design an approximation algorithm for the Set Cover problem.\n\nFix any instance formula_14 of set cover over a universe formula_15.\n\nFor step 1, let IP be the standard integer linear program for set cover for this instance.\n\nFor step 2, let LP be the linear programming relaxation of IP,\nand compute an optimal solution formula_16 to LP\nusing any standard linear programming algorithm.\n\n(The feasible solutions to LP are the vectors formula_1\nthat assign each set formula_18\na non-negative weight formula_19,\nsuch that, for each element formula_20,\nformula_3 \"covers\" formula_22\n-- the total weight assigned to the sets containing formula_22\nis at least 1, that is,\nThe optimal solution formula_16\nis a feasible solution whose cost\nis as small as possible.)\nNote that any set cover formula_27 for formula_28\ngives a feasible solution formula_1\n(where formula_30 for formula_31,\nformula_32 otherwise).\nThe cost of this formula_27 equals the cost of formula_1, that is,\nIn other words, the linear program LP is a relaxation\nof the given set-cover problem.\n\nSince formula_16 has minimum cost among feasible solutions to the LP,\n\"the cost of formula_16 is a lower bound on the cost of the optimal set cover\".\n\nHere is a description of the third step—the rounding step,\nwhich must convert the minimum-cost fractional set cover formula_16\ninto a feasible integer solution formula_3 (corresponding to a true set cover).\n\nThe rounding step should produce an formula_3 that, with positive probability,\nhas cost within a small factor of the cost of formula_16.\nThen (since the cost of formula_16 is a lower bound on the cost of the optimal set cover),\nthe cost of formula_3 will be within a small factor of the optimal cost.\n\nAs a starting point, consider the most natural rounding scheme:\n\nWith this rounding scheme,\nthe expected cost of the chosen sets is at most formula_48,\nthe cost of the fractional cover.\nThis is good. Unfortunately the coverage is not good.\nWhen the variables formula_49 are small,\nthe probability that an element formula_22 is not covered is about\n\nSo only a constant fraction of the elements will be covered in expectation.\n\nTo make formula_3 cover every element with high probability,\nthe standard rounding scheme\nfirst \"scales up\" the rounding probabilities\nby an appropriate factor formula_53.\nHere is the standard rounding scheme:\n\nScaling the probabilities up by formula_59\nincreases the expected cost by formula_59,\nbut makes coverage of all elements likely.\nThe idea is to choose formula_59 as small\nas possible so that all elements are provably\ncovered with non-zero probability.\nHere is a detailed analysis.\n\n(Note: with care the formula_65\ncan be reduced to formula_67.)\n\nThe output formula_3 of the random rounding scheme has the desired properties\nas long as none of the following \"bad\" events occur:\n\nThe expectation of each formula_75 is at most formula_76.\nBy linearity of expectation,\nthe expectation of formula_69\nis at most formula_78.\nThus, by Markov's inequality, the probability of the first bad event\nabove is at most formula_79.\n\nFor the remaining bad events (one for each element formula_22), note that,\nsince formula_81 for any given element formula_22,\nthe probability that formula_22 is not covered is\n\n(This uses the inequality formula_85,\nwhich is strict for formula_86.)\n\nThus, for each of the formula_87 elements,\nthe probability that the element is not covered is less than formula_88.\n\nBy the naive union bound,\nthe probability that one of the formula_89 bad events happens\nis less than formula_90.\nThus, with positive probability there are no bad events\nand formula_3 is a set cover of cost at most formula_71.\nQED\n\nThe lemma above shows the \"existence\" of a set cover\nof cost formula_93).\nIn this context our goal is an efficient approximation algorithm,\nnot just an existence proof, so we are not done.\n\nOne approach would be to increase formula_59\na little bit, then show that the probability of success is at least, say, 1/4.\nWith this modification, repeating the random rounding step a few times\nis enough to ensure a successful outcome with high probability.\n\nThat approach weakens the approximation ratio.\nWe next describe a different approach that yields\na deterministic algorithm that is guaranteed to\nmatch the approximation ratio of the existence proof above.\nThe approach is called the method of conditional probabilities.\n\nThe deterministic algorithm emulates the randomized rounding scheme:\nit considers each set formula_44 in turn,\nand chooses formula_96.\nBut instead of making each choice \"randomly\" based on formula_16,\nit makes the choice \"deterministically\", so as to\n\"keep the conditional probability of failure, given the choices so far, below 1\".\n\nWe want to be able to set each variable formula_75 in turn\nso as to keep the conditional probability of failure below 1.\nTo do this, we need a good bound on the conditional probability of failure.\nThe bound will come by refining the original existence proof.\nThat proof implicitly bounds the probability of failure\nby the expectation of the random variable\nwhere\nis the set of elements left uncovered at the end.\n\nThe random variable formula_101 may appear a bit mysterious,\nbut it mirrors the probabilistic proof in a systematic way.\nThe first term in formula_101 comes from applying Markov's inequality\nto bound the probability of the first bad event (the cost is too high).\nIt contributes at least 1 to formula_101 if the cost of formula_3 is too high.\nThe second term\ncounts the number of bad events of the second kind (uncovered elements).\nIt contributes at least 1 to formula_101 if formula_3 leaves any element uncovered.\nThus, in any outcome where formula_101 is less than 1,\nformula_3 must cover all the elements\nand have cost meeting the desired bound from the lemma.\nIn short, if the rounding step fails, then formula_109.\nThis implies (by Markov's inequality) that\n\"formula_110 is an upper bound on the probability of failure.\"\nNote that the argument above is implicit already in the proof of the lemma,\nwhich also shows by calculation that formula_111.\n\nTo apply the method of conditional probabilities,\nwe need to extend the argument to bound the \"conditional\" probability of failure\nas the rounding step proceeds.\nUsually, this can be done in a systematic way,\nalthough it can be technically tedious.\n\nSo, what about the \"conditional\" probability of failure as the rounding step iterates through the sets?\nSince formula_109 in any outcome where the rounding step fails,\nby Markov's inequality, the \"conditional\" probability of failure\nis at most the \"conditional\" expectation of formula_101.\n\nNext we calculate the conditional expectation of formula_101,\nmuch as we calculated the unconditioned expectation of formula_101 in the original proof.\nConsider the state of the rounding process at the end of some iteration formula_116.\nLet formula_117 denote the sets considered so far\n(the first formula_116 sets in formula_28).\nLet formula_120 denote the (partially assigned) vector formula_3\n(so formula_122 is determined only if formula_123).\nFor each set formula_124,\nlet formula_125\ndenote the probability with which formula_75 will be set to 1.\nLet formula_127 contain the not-yet-covered elements.\nThen the conditional expectation of formula_101,\ngiven the choices made so far, that is, given formula_120, is\n\nNote that formula_131 is determined only after iteration formula_116.\n\nTo keep the conditional probability of failure below 1,\nit suffices to keep the conditional expectation of formula_101 below 1.\nTo do this, it suffices to keep the conditional expectation of formula_101 from increasing.\nThis is what the algorithm will do.\nIt will set formula_75 in each iteration to ensure that\n(where formula_137).\n\nIn the formula_116th iteration,\nhow can the algorithm set formula_139\nto ensure that formula_140?\nIt turns out that it can simply set formula_139\nso as to \"minimize\" the resulting value of formula_142.\n\nTo see why, focus on the point in time when iteration formula_116 starts.\nAt that time, formula_144 is determined,\nbut formula_142 is not yet determined\n--- it can take two possible values depending on how formula_139\nis set in iteration formula_116.\nLet formula_148 denote the value of formula_149.\nLet formula_150 and formula_151,\ndenote the two possible values of formula_142,\ndepending on whether formula_139 is set to 0, or 1, respectively.\nBy the definition of conditional expectation,\nSince a weighted average of two quantities\nis always at least the minimum of those two quantities,\nit follows that\nThus, setting formula_139\nso as to minimize the resulting value of\nformula_131\nwill guarantee that\nformula_158.\nThis is what the algorithm will do.\n\nIn detail, what does this mean?\nConsidered as a function of formula_139\nformula_131\nis a linear function of formula_139,\nand the coefficient of formula_139 in that function is\n\nThus, the algorithm should set formula_139 to 0 if this expression is positive,\nand 1 otherwise. This gives the following algorithm.\n\ninput: set system formula_28, universe formula_15, cost vector formula_167\n\noutput: set cover formula_3 (a solution to the standard integer linear program for set cover)\n\nThe algorithm ensures that the conditional expectation of formula_101,\nformula_185, does not increase at each iteration.\nSince this conditional expectation is initially less than 1 (as shown previously),\nthe algorithm ensures that the conditional expectation stays below 1.\nSince the conditional probability of failure\nis at most the conditional expectation of formula_101,\nin this way the algorithm\nensures that the conditional probability of failure stays below 1.\nThus, at the end, when all choices are determined,\nthe algorithm reaches a successful outcome.\nThat is, the algorithm above returns a set cover formula_3\nof cost at most formula_183 times\nthe minimum cost of any (fractional) set cover.\n\nIn the example above, the algorithm was guided by the conditional expectation of a random variable formula_101.\nIn some cases, instead of an exact conditional expectation,\nan \"upper bound\" (or sometimes a lower bound)\non some conditional expectation is used instead.\nThis is called a pessimistic estimator.\n\n\n\n"}
{"id": "8125101", "url": "https://en.wikipedia.org/wiki?curid=8125101", "title": "Reality–virtuality continuum", "text": "Reality–virtuality continuum\n\nThe virtuality continuum is a continuous scale ranging between the completely virtual, a virtuality, and the completely real, reality. The reality–virtuality continuum therefore encompasses all possible variations and compositions of real and virtual objects. It has been described as a concept in new media and computer science, but in fact it could be considered a matter of anthropology. The concept was first introduced by Paul Milgram.\n\nThe area between the two extremes, where both the real and the virtual are mixed, is called mixed reality. This in turn is said to consist of both augmented reality, where the virtual augments the real, and augmented virtuality, where the real augments the virtual.\n\nThis continuum has been extended into a two-dimensional plane of \"virtuality\" and \"mediality\". Taxonomy of reality, virtuality, mediality. The origin R denotes unmodified reality. A continuum across the virtuality axis, V, includes reality augmented with graphics (augmented reality), as well as graphics augmented by reality (augmented virtuality). However, the taxonomy also includes modification of reality or virtuality or any combination of these. \n\nThe mediality axis denotes changes The modification is denoted by moving up the mediality axis. Further up this axis, for example, we can find mediated reality, mediated virtuality, or any combination of these. Further up and to the right, we have virtual worlds that are responsive to a severely modified version of reality. \n\nAugmented reality and mixed reality are now sometimes used as synonyms.\n\nThe virtuality continuum has grown and progressed past labels such as computer science and new media. As the concept has much to do with the way in which humans continue to change how they communicate; the way in which identities form and the way in which they interact to and within the world; it is more accurately described as a subject within anthropology.\n\nChanges in attitudes towards and the increase in availability of technology and media have changed and progressed the way it is used. One to one (SMS), one to many (email), and many to many (chat rooms), have become ingrained in society. The use of such items have made once clear distinctions like \"online\" and \"offline\" obsolete, and the distinctions between reality and virtuality have become blurred as people are incorporating and relying heavily upon virtuality within their everyday personal realities.\n\nDaniel Miller and Don Slater are prominent researchers pursuing the concept of the virtuality continuum and the media and its effect on communities, especially in the Caribbean, most notably Trinidad and Jamaica.\n\nSteve Woolgar is another researcher who has established four rules of virtuality. These are:\n\n\n"}
{"id": "1274310", "url": "https://en.wikipedia.org/wiki?curid=1274310", "title": "Schwa (art)", "text": "Schwa (art)\n\nSchwa is the underground conceptual artwork of Bill Barker (born 1957). Barker draws deceptively simple black and white stick figures and oblong alien ships. However the artwork is not about the aliens: it is about how people react to the presence of the aliens and branding and Barker uses them as a metaphor for foreign and unknown ideas. Schwa became an underground hit in the 1990s.\n\nIn linguistics, a schwa is an unstressed and toneless neutral vowel sound in any language, often but not necessarily a mid-central vowel (rounded or unrounded). Such vowels are often transcribed with the symbol ə, regardless of their actual phonetic value. An example in English is the \"a\" in \"about\".\n\nFor Barker, Schwa is alternately his pseudonym, a fictitious omnipresent corporation, a religion, or a resistance movement against corporate conspiracies and aliens. Often it's a combination of all four at once.\n\nSchwa artwork is black and white, with very precise stick-figures and ovoid alien faces and ships. The aliens themselves are rarely seen by the human stick figures, their presence is more often felt by their distant ships. The people are almost always either very frightened, or very complacent with their lot in life. Barker combines aliens, corporations, religions, media, and even the passage of time in his drawings.\n\nThe black and white drawings lead to a very hypnotic and very stark landscape. The world of Schwa is consistent throughout his work, and all the drawings and books combine to paint a single picture of a futuristic world run by large corporate and religious conglomerates who are possibly in league with omnipresent aliens. The media has become a marketing machine for these overseers, and they continually saturate the world with alien logos and messages like \"In the future, everything will work\", and, \"Stop domesticating yourself\".\n\nSchwa began in 1992 when Barker, a former advertising art director, was looking for a way to express himself with a single art style when he was given a copy of \"The Secret Government\", a conspiracy book that tells of aliens controlling the government. Barker did not like the idea of art exhibitions, which he saw as just a pretentious form of merchandising, so he decided to sell merchandise directly to consumers by mail-order. Barker started selling trinkets like necklaces and stickers, and his first book, \"ə\", exclusively through this home-grown business. Schwa cartoons also appeared in \"The Sagebrush\", the University of Nevada, Reno student newspaper.\n\nAlthough Barker might not have been the first person to conceive of the ovoid alien face, his version quickly became the best-known. His book was an underground hit, and received praise from Terry Gilliam, Ivan Stang, and Noam Chomsky. He bundled the book along with several trinkets as the \"Complete Schwa Kit\" (), and put out another book with trinkets as \"Complete Counter-Schwa Kit\" ().\n\nEventually his popularity led to a book deal with Chronicle Books, and in 1997 published \"Schwa: World Operations Manual\" () a reference manual for world control that included postcards, stickers, warranties, contracts, and charts.\n\nBarker also created and ran a (now defunct) labyrinthine website early in the days of the World Wide Web. He described it as \"an experiment in building an online science fiction environment in HTML.\" Instead of simply showcasing his printed artwork, the website became another medium for Schwa fans to explore.\n\nBarker teamed up with AOL to create an odd online game exclusively for AOL members. He worked with the now defunct Orbital Studios to create a game about conspiracies, corporations, and aliens. The initial instructions set the tone of the game:\n\nThe player was a stick figure right in the middle of the darkened and conspiratorial world of Schwa. The player worked his way up the pyramid by collecting power through media, corporations, government, and labor, to eventually dominate the world.\n\nThe game launched on March 9, 1998. A follow-up game called Schwa Conspiracy was announced for later that year, but was never finished.\n\nAlthough a growing hit, Bill Barker disappeared from the public (and underground) eye sometime in late September 2001. His long-running website is dead and the post office box he had used for years now returns his mail unread.\n\nIn April 2008 a Schwa trademark was re-registered (assigned by Compuwatcher, Inc.) and a small series of websites were launched; this new Schwa business has no affiliation with Bill Barker or his artwork.\n\nIn March 2012 Barker created a Facebook page under the name alaVoid, which does not seem to be updated anymore.\n\n\n"}
{"id": "1955818", "url": "https://en.wikipedia.org/wiki?curid=1955818", "title": "Season (society)", "text": "Season (society)\n\nThe social season, or season, refers to the traditional annual period when it is customary for members of a social elite of society to hold balls, dinner parties and charity events. Until World War I, it was also the appropriate time to be resident in the city rather than in the country in order to attend such events.\n\nIn modern times in the United Kingdom, \"the Season\" is known to encompass various prestigious events that take place during the spring and summer. According to Sloaney Season, it starts with Cheltenham Festival (March), and includes Grand National (April), Badminton Horse Trials (May), Chelsea Flower Show (May), Epsom Derby, Royal Ascot, Henley Royal Regatta (July), and others.\n\nThe London social season evolved in the 17th and 18th centuries, and in its traditional form it peaked in the 19th century. In this era the British elite was dominated by landowning aristocratic and gentry families who generally regarded their country house as their main home, but spent several months of the year in the capital to socialise and to engage in politics. The most exclusive events were held at the town mansions of leading members of the aristocracy. Exclusive public venues such as Almack's played a secondary role. The Season coincided with the sitting of parliament and began some time after Christmas and ran until midsummer, roughly late June.\n\nThe social season played a role in the political life of the country: the members of the two Houses of Parliament were almost all participants in the season. But the Season also provided an opportunity for the children of marriageable age of the nobility and gentry to be launched into society. Debutantes were formally introduced into society by presentation to the monarch at royal court until it was abolished by Queen Elizabeth II in 1958. \n\nThe traditional Season went into decline after the First World War, when many aristocratic families gave up their London mansions. From this time on an increasing number of society events took place at public venues, making it harder to maintain social exclusivity.\n\nMany events that take place far from central London came to be regarded as part of the social season, including Royal Ascot and the Henley Royal Regatta. The events that now constitute the London social season are increasingly hosted or sponsored by large companies (i.e. \"corporate hospitality\"). Western dress codes still apply to certain events in the season, especially where the Queen maintains an official role.\n\nAccording to the peerage guide Debrett's, the traditional social season runs from April to August. The Sloaney runs a detailed guide to the British Social Season, known as Sloaney Season . \n\n\n\n\n\n\nAlthough several of these events are not actually held in London, such as the Hurlingham Polo Association at Guards Polo Club, the organisers of most events attempt to avoid date clashes, so it is generally possible to visit all of them in the same year.\n\nThe traditional end of the London Season is the Glorious Twelfth of August, which marks the beginning of the shooting season. Society would retire to the country to shoot birds during the autumn and hunt foxes during the winter before coming back to London again with the spring.\n\nMany events of the season have traditional expectations with regard to Western dress codes.\n\nLondon is the capital of shops and of speculation, the government is made there. The aristocracy inscribes itself there only during sixty days, it there takes its orders, it inspects the government kitchen, it passes in review its daughters to marry, and equipages to sell, it says good-day and goes away promptly ; - it is so little amusing that it supports itself only for the few days called the season.\n\n"}
{"id": "3501587", "url": "https://en.wikipedia.org/wiki?curid=3501587", "title": "Shift rule", "text": "Shift rule\n\nThe shift rule is a mathematical rule for sequences and series.\n\nHere formula_1 and formula_2 are natural numbers. \n\nFor sequences, the rule states that if formula_3 is a sequence, then it converges if and only if formula_4 also converges, and in this case both sequences always converge to the same number.\n\nFor series, the rule states that the series formula_5 converges to a number if and only if formula_6 converges.\n"}
{"id": "44390130", "url": "https://en.wikipedia.org/wiki?curid=44390130", "title": "Socioeconomic status and memory", "text": "Socioeconomic status and memory\n\nMemory is one of the brain’s most critical functions. It has the infinite ability to store information about events and experiences that occur constantly. Experiences shape the way memories form, so major stressors on socioeconomic status can impact memory development. Socioeconomic status (SES) is a measurement of social standing based on income, education, and other factors. Socioeconomic status can differ cross-culturally, but is also commonly seen within cultures themselves. It influences all spectrums of a child’s life, including cognitive development, which is in a crucial and malleable state during early stages of childhood. In Canada, most children grow up in agreeable circumstances, however an unfortunate 8.1% are raised in households that fall into the category of low socioeconomic status. These children are at risk for many disadvantages in life, including deficits in memory processing, as well as problems in language development.\n\nWorking memory is a temporary storage system that is essential for the successful performance of the task at hand.\n\nWhen creating new memories, the hippocampus and related structures of the brain play a key role in consolidation. Memory consolidation is the transformation of short-term memories to long-term memories, which is crucial in the acquisition of new ideas. Until they can be stored more permanently, these memories are temporarily kept in the hippocampus in a process known as Standard Consolidation Theory. From childhood the hippocampus is developing, and it continues to mature beyond adolescents. A major barrier when it comes to studying working memory development in childhood is that much of the data come from adults who recall on past events of their childhood, and not from the children themselves. This creates a problem in memory recall of those events that occurred when the hippocampus was still developing, and the working memory wasn’t completely consolidated at the time. As people recall a former memory, the door to memory reconsolidation is opened. Reconsolidation refers to the retrieval of a memory from long-term storage to short-term working memory, where it is unstable and vulnerable to alteration. As reported by Staff et al. (2012), socioeconomic status measured early in childhood reared a significant difference in hippocampal size in adulthood, suggesting that there is in fact an impact on brain and cognitive development. Spatial memory is another specialized function of the brain, and more specifically, the hippocampus. Spatial memory refers to experiences that are recognized by their surrounding environment. Many of hippocampal neurons are in fact place cells. Place cells are neurons that are activated by certain locations or environments. If a child is constantly in a maladaptive environment, their hippocampal neurons may be performing poorly, and memory development may be sacrificed.\n\nThe amygdala is another structure of the brain that is involved memory development. The amygdala’s role in memory formation is to extract the emotional significance of experiences, which may be positive or negative emotions. Children who grow up in positive households, develop to convey more positive emotions, than children who group up in negative households. Lower socioeconomic status generally increases tension and negative emotions within a household, which may impact the emotional memory development of the children via the amygdala. A lack of positive emotional development may impact memory development as well as continual cognitive development in other areas, such as sociability and depression. \nChild development and socioeconomic status (SES) are positively correlated, especially with regards to the child’s working memory. Low socioeconomic status environments with a high stress factor can increase the memory processing for a particular unpleasant event. However, just because memory processes are firing, it doesn’t mean that the information stored is valid or accurate. Stressful environments impair a child’s memories and increase the probability for reconsolidation and contamination of false information. False memories are recollections of events that did not truly occur. Older children are most likely to confabulate these false memories and illusions, than younger children. This may be because their memory and learning processes are more developed than younger children’s’, which allows them to reconstruct memories based on real events as well as imaginary ones.\n\nLearning and memory go hand-in-hand, as one cannot occur without the other. Learning involves experiences and how they alter the brain, while memory focuses on how those changes in the brain are stored and recalled. Lower socioeconomic status environments yield lower cognitive and intellectual development in children. Since children cannot choose the environments that they are raised in, parental influence can greatly aid or inhibit a child’s cognitive development. Low socioeconomic status due to poverty is a leading cause in hindered cognitive development in growing children. A constant inadequate diet throughout early childhood deprives the brain of the nourishment it requires to develop and function successfully. Also affecting cognitive development is access to health care. Families with a low socioeconomic status cannot always afford necessary or beneficial health care for their children, which can hinder brain development, especially in later years when the brain is less likely to self-correct potential risk factors. A lack of intellectual stimulation can also decrease cognitive development in children, which can occur in households with a low income, that cannot afford supplementary activities or programs for their children’s developing minds. One of the most dynamic inhibitors of cognitive development by parental influence however, is parental violence and negativity. Children who live in high-risk environments of parental abuse express fluctuations in their ability of attentional skills due to constant fear or safety concerns. Disturbance in attention can decrease both working memory and retrieval of long-term memories. If concentration is disturbed during recall, the memories that surface may be susceptible to reconsolidation, and the false memories that are created, due to lack of concentration, may solidify into inaccurate long-term memories. In a research model that looked at children living in environments of domestic violence and their relationship with memory, researchers found that children exposed to familial trauma displayed a poorer performance of working memory.\n\nLow working memory is becoming more of an issue today with children in the public school system. The education system plays a substantial part in developing the children’s mind for working memory. However, families who are in the low socio-economic status can’t always afford private school to provide the children with the highest quality of teachers and learning. A disadvantage to having children in public school system is that educators don’t have time, the right tools or proper techniques to train the children to develop better working memory. Public schools are at a disadvantage when it comes to receiving the best education for working memory. Children who live in a low SES homes have difficulty learning how to develop and train the working memory. Working memory has slowly decreased over the growing years. Therefore, students become less motivated and have learning difficulties later on. Low working memory results in frustration, anger, being disruptive and failure to complete tasks. Some effects to students having a low working memory is they can be very easily distracted, low attention span, as well as forgetfulness. Children that grow up in a higher SES, can afford to have a better education.\n\nWorking memory gives the ability to keep languages, vocabulary and apt symbols readily available for communication with others and organization of thoughts. All of human kind utilizes language, and thus it has been widely recognized that children from areas of socioeconomic disadvantage are at high risk of delayed language development. Parents from higher SES tend to be of higher education and therefore understand more about child development and the necessities for proper growth. For this reason, parents from high SES homes are more likely to see themselves as teacher figures and their children as students ready to learn.\n\nSocioeconomic disadvantages have created unequal differences among educational attainments for children and families from various socioeconomic backgrounds. Differences between parent to child dialogue differs in homes of Low to High SES families. In homes of low SES children, there tends to be less direct conversation with the child, fewer opportunities of book reading and much less time shared between child and parent about the same subject or event. This lack of dialogue slows the understanding of Syntax as children receive less opportunities to learn and understand the arrangement of their language. In homes of high SES children, mothers tend to speak more freely with their children about emotions and feelings, as well as attempt to directly follow up with what their children are saying. This proper and consistent verbal stimulation may add to a stronger verbal development than children from low SES families.\n\nConsidering language development is key for children to begin to convey themselves, grow and eventually detach from parents, it is important to display the differences among different socio-economic standings. In environments where children are spoken to and pushed practice words, first words tend to develop between 10–15 months. North American Children are some of the most typically studied families, they come from middle class families with mothers who influence language development. Mothers from these families often use object-labelling for their infants. This allows children to use phonological reference by giving meaning and association to the words spoken by their mothers.\n\nChildren from low SES families who have had the unfair disadvantage of starting behind in language development do not tend to catch up, the delays may stay stable or increase in strength with age. In adolescence these delays are still present in children from Low SES families. Studies with 13-14 year olds from High and Low SES areas have indeed suggested that delayed language development is still very apparent in children from low SES families. Studies also found that children in areas of low SES were more likely than High SES children to have undetected language difficulties. Considering children from low SES families may never catch up to children in High SES families it is important to detect language difficulties much earlier than adolescents. In adolescents language growth has slowed and dramatic language accomplishments are less likely to occur.\n\nBilingualism refers to the ability to use and understand two simultaneous languages. A bilingual person can for instance speak and understand both French and English. In 2011, Canadians recorded having 17% of the population being bilingual with 20% of them speaking a language other than French or English prior to learning French or English. In relation to working memory and cognitive control, bilingual children have been found to achieve much higher scores than those of monolingual children. Monolingual children have however outperformed bilinguals in standard vocabulary assessments. Past research with High SES children suggests that both languages are constantly present in bilinguals and that this may account for the reduced efficiency in either language abilities. Similar to monolinguals, Low SES bilingual children are at risk of under performing at one or both languages, however there are exceptions, few outliers of Low SES children tend to achieve high proficiency scores in both languages. Low SES children show preferential strength towards ethnic languages spoken at home. Language development is largely dependent on parental interaction, therefore children with monolingual parents struggle learning the second language due to a home environment which is restricted to their ethnic language. However if the parents are bilingual in the same languages, children are likely to out perform all bilingual children regardless of SES. Middle to High SES bilingual children have also been found to underachieve linguistically compared to Monolingual children of the same SES. Middle to High SES children however show consistent higher proficiency than Low SES children at either language.\n\nThe main diagnoses for children with Autism Spectrum Disorder (ASD) have issues with communication skills, social interactions and patterns of activity. Children with high-functioning autism as well as low-functioning autism have impairments to their working memory, both verbal and non-verbal domains as well as language development. Families with a child with ASD, and that are also in a higher socio-economic status (SES) often can provide more funding for the child to receive the proper treatment to help the child develop. Families with a higher SES have access to better health care and behavior intervention programs to help the child develop normally. One of the treatments would include a program to help improve short-term, long-term and also, working memory. When children with ASD are at the early stages of development, working memory impairments is not always recognizable, consequently they do not get the appropriate training right away. Parents of children with ASD and are in the low SES group, they generally don’t have the education or the resources to help the child with working memory impairment and language deficits. Result of children with ASD had difficulties with short-term working memory, spatial working memory and also complex verbal memory.\n\nDr. Maureen Durkin, who is involved in the health sciences department at the University of Wisconsin, did a cross-sectional study to see if there was any correlation between children who are born with autism and socioeconomic status. This study was designed to see if socioeconomic status has any association with children who are born with autism spectrum disorder. Durkin and associates discovered that children born in low SES family and the births of autistic children are increasing. Although, there were some limitations to this study; ADDM Network surveillance system. Durkin et al based their research on this system, it's a system where children with disabilities have access to diagnostic services. Therefore, autistic children in low SES, may not have access to the same. Another limitation this study has is that this study took part in children that were eight years old rather than when they were first diagnosed. This would have an effect on the outcome as some families who might be in a high SES, may use all the funds to help the child towards intervention programs and may leave the family in a low SES in the long run. Families that are in high SES, are well educated, and have the financial resources to pay for the highest quality of education for their child. Durkin et al also found that good or low SES had to do with race and ethnicity.\n\nScores on working memory measures have determined a strong association between working memory and language learning disabilities. These measures are very useful in measuring a child’s working memory and or learning disabilities. Research shows studies of working memory can predict a child’s scholastic abilities for up to three years later. Considering low SES is largely related to learning and language disabilities it is important to validate whether measures for such topics are free of socioeconomic influences.\n\nThe phonological loop is used by working memory to acquire and associate new vocabulary with existing vocabulary knowledge. Use of non-word repetition to measure the phonological loop has proven a strong predictor of learning disabilities in children learning language. These standardized language tests may pose more problems for children coming from Low SES families than children from Normal to High SES. Parent interaction, or the role of a caregiver in the home are of utmost important when developing vocabulary knowledge and strengthening the phonological loop. Typically, in low SES homes parent interaction, extracurriculars and social environment are limited, this slows the child’s development of vocabulary compared to children of normal to high SES. Working memory involves the memory system, which actively attends to gathering and organizing new information. It is a constant running memory system that aids memory storage and association. Learning languages makes use of the working memory, however the strength of the working memory does not determine one’s ability for vocabulary knowledge. To distinguish children’s scores between assessments, which study vocabulary, and those that study working memory, studies have had cohorts from both low SES and high SES families complete a battery of working memory measures. Indeed measurements of children’s vocabulary knowledge reinforced past research on the impact a child’s environment can have on their language learning. Measurements for non-word repetition and digit recall however showed no difference among scores between children of either High or Low SES. These findings dictate that measurements purely involved in working memory and not associated with vocabulary are free of socioeconomic influence. Working memory is unaffected by SES, however learning disabilities are still largely associated with Low SES. Researchers can assume that working memory measurements are not biased to SES and can properly assess language development and other learning problems. The applicability of this knowledge proves especially useful in determining needs for early intervention in children’s learning environments.\n"}
{"id": "1112217", "url": "https://en.wikipedia.org/wiki?curid=1112217", "title": "Strict scrutiny", "text": "Strict scrutiny\n\nStrict scrutiny is the most stringent standard of judicial review used by United States courts. It is part of the hierarchy of standards that courts use to determine which is weightier, a constitutional right or principle or the government's interest against observance of the principle. The lesser standards are rational basis review and exacting or intermediate scrutiny. These standards are used to test statutes and government action at all levels of government within the United States.\n\nThe notion of \"levels of judicial scrutiny\", including strict scrutiny, was introduced in Footnote 4 of the U.S. Supreme Court decision in \"United States v. Carolene Products Co.\" (1938), one of a series of decisions testing the constitutionality of New Deal legislation. The first and most notable case in which the Supreme Court applied the strict scrutiny standard and found the government's actions constitutional was \"Korematsu v. United States\" (1944), in which the Court upheld the exclusion of Japanese Americans from designated areas during World War II.\n\nU.S. courts apply the strict scrutiny standard in two contexts: when a fundamental constitutional right is infringed, particularly those found in the Bill of Rights and those the court has deemed a fundamental right protected by the Due Process Clause or \"liberty clause\" of the 14th Amendment, or when a government action applies to a \"suspect classification\", such as race or national origin. \n\nTo pass strict scrutiny, the law or policy must satisfy three tests:\n\n\nLegal scholars, including judges and professors, often say that strict scrutiny is \"strict in theory, fatal in fact\" since popular perception is that most laws subjected to the standard are struck down. However, an empirical study of strict scrutiny decisions in the federal courts found that laws survive strict scrutiny more than 30% of the time. In one area of law, religious liberty, laws that burden religious liberty survived strict scrutiny review in nearly 60% of cases. However, a discrepancy was found in the type of religious liberty claim, with most claims for exemption from law failing and no allegedly discriminatory laws surviving. See also the cases cited below, however; several appear to permit the exemption from laws based upon religious liberty.\n\nThe compelling state interest test is distinguishable from the rational basis test, which involves claims that do not involve a suspect class and involve a liberty interest rather than a fundamental right. It is also important to note that unlike the rational basis test, the burden of proof falls on the state, in cases that require strict scrutiny or intermediate scrutiny.\n\nThe Supreme Court has established standards for determining whether a statute or policy's classification requires the use of strict scrutiny. The class must have experienced a history of discrimination, must be definable as a group based on \"obvious, immutable, or distinguishing characteristics,\" be a minority or \"politically powerless,\" and its characteristics must have little relationship to the government's policy aims or the ability of the group's members to contribute to society.[Citations needed.]\n\nThe Court has consistently found that classifications based on race, national origin, and alienage require strict scrutiny review. The Supreme Court held that all race-based classifications must be subjected to strict scrutiny in \"Adarand Constructors v. Peña,\" 515 U.S. 200 (1995), overruling \"Metro Broadcasting, Inc. v. FCC\" (89-453), 497 U.S. 547 (1990), which had briefly allowed the use of intermediate scrutiny to analyze the Equal Protection implications of race-based classifications in the narrow category of affirmative-action programs established by the federal government in the broadcasting field.\n\nAs applied in \"Korematsu v. United States\", which upheld the race-based exclusion order and internment during World War II of Japanese Americans who had resided on the West Coast of the United States, strict scrutiny was limited to instances of \"de jure\" discrimination, where a racial classification is written into the language of a statute.\n\nThe Supreme Court's decision in \"Village of Arlington Heights v. Metropolitan Housing Development Corp.\" provided further definition to the concept of intent and clarified three particular areas in which intent of a particular administrative or legislative decision becomes apparent, the presence of any of which demands the harsher equal protection test. The Court must use strict scrutiny if one of these tests, among others, is met:\n\n\n"}
{"id": "13690547", "url": "https://en.wikipedia.org/wiki?curid=13690547", "title": "Structuralist theory of mythology", "text": "Structuralist theory of mythology\n\nIn structural anthropology, Claude Lévi-Strauss, a French anthropologist, makes the claim that \"myth is language\". Through approaching mythology as language, Lévi-Strauss suggests that it can be approached the same way as language can be approached by the same structuralist methods used to address language. Thus, Lévi-Strauss offers a structuralist theory of mythology; he clarifies, \"Myth is language, functioning on an especially high level where meaning succeeds practically at 'taking off' from the linguistic ground on which it keeps rolling.\" \n\nLévi-Strauss breaks down his argument into three main parts. Meaning is not isolated within the specific fundamental parts of the myth, but rather within the composition of these parts. Although myth and language are of similar categories, language functions differently in myth. Finally, language in myth exhibits more complex functions than in any other linguistic expression. From these suggestions, he draws the conclusion that myth can be broken down into constituent units, and these units are different from the constituents of language. Finally, unlike the constituents of language, the constituents of a myth, which he labels “mythemes,” function as \"bundles of relations.\" \n\nThis approach is a break from the “symbolists”, such as Carl Jung, who dedicate themselves to find meaning solely within the constituents rather than their relations. For instance, Lévi-Strauss uses the example of the Oedipus myth and breaks it down to its component parts:\n\nReading it in sequence from left to right, top to bottom, the myth is categorized sequentially and by similarities. Through analyzing the commonalities between the “mythemes” of the Oedipus story, understandings can be wrought from its categories. \n\nThus, a structural approach towards myths is to address all of these constituents. Furthermore, a structural approach should account for all versions of a myth, as all versions are relevant to the function of the myth as a whole. This leads to what Lévi-Strauss calls a spiral growth of the myth which is continuous while the structure itself is not. The growth of the myth only ends when the \n“intellectual impulse which has produced it is exhausted.” \n\nMyths are primarily acknowledged as oral traditions, while literature is in the form of written text. Still, anthropologists and literary critics would both acknowledge the links between myths and relatively more contemporary literature. Therefore, many literary critics take the same Lévi-Straussian structuralist, as it is coined, approach to literature. This approach is, again, similar to Symbolist critics’ approach to literature. There is a search for the lowest constituent of the story. But as with the myth, Lévi-Straussian structuralism then analyzes the relations between these constituent parts in order to compare even greater relations between versions of stories as well as among stories themselves. \n\nFurthermore, Lévi-Strauss suggests that the structural approach and mental processes dedicated towards analyzing the myth are similar in nature to those in science. This connection between myth and science is further elaborated in his books, “Myth and Meaning” and \"The Savage Mind\". He suggests that the foundation of structuralism is based upon an innate understanding of the scientific process, which seeks to break down complex phenomena into its component parts and then analyze the relations between them. The structuralist approach to myth is precisely the same method, and as a method this can be readily applied to literature.\n\n"}
{"id": "30350", "url": "https://en.wikipedia.org/wiki?curid=30350", "title": "TWERPS", "text": "TWERPS\n\nTWERPS (The World's Easiest Role-Playing System) is a minimalist role-playing game (RPG) originally created by Reindeer Games (whose sole product was the \"TWERPS\" line) and distributed by Gamescience. Presented as a parody of the complicated RPG systems which were prevalent at the time while still being a playable game in its own right, its simple structure and humorous nature gave it unexpected popularity. \"TWERPS\" was originally created, written and illustrated (in a distinctive cartoony style) by \"Jeff & 'Manda Dee\", Jeff Dee being a noted game illustrator and co-writer of \"Villains and Vigilantes\".\n\n\"TWERPS\" was designed by Jeff Dee and 'Manda Dee, and published by Reindeer Games in 1987 as a digest-sized 8-page pamphlet, with four cardstock sheets.\n\n\"TWERPS\" is a humorous universal system of minimalist rules; \"TWERPS\" stands for \"The World's Easiest Role-Playing System\". Characters have only one ability, Strength. Rules sections cover Strength, Combat, and \"How to Do Everything.\" The game includes a sample character sheet, a combat hex sheet, cardstock miniatures, and an introductory micro-mini-scenario.\n\nThe actual rules of the game are indeed extremely simple. Characters are defined by a single attribute, \"Strength\", which is used for determining all traditional role-playing elements, such as whether or not the character successfully hits in combat, how fast they can move and how much damage they can take before dying. A de facto skill system exists in the form of \"character classes\" which give numerical bonuses to certain activities if their role called for it (for instance, a pilot having a +1 modifier on their roll to fly an aircraft).\n\nOriginally each installment of the \"TWERPS\" system was sold in a small plastic bag containing an 8-page leaflet, a sheet of cardstock counters to be cut apart, little cardstock hex-maps and a tiny ten-sided die, each being a down-sized imitation of elements often found in larger, more elaborate games. The initial run of titles was printed at low cost with black ink on various colored papers to distinguish the various titles (the main rules were on pink paper, the kung-fu rules were on yellow, and so on).\n\n\nAs the game grew in popularity, the supplements were re-printed in expanded form with more pages and multi-color printing. New supplements covering new genres and specific objects of parody were also added. These expansions and later supplements were mainly written by Norman F. Morin Jr., Brian Rayburn, Jon Hancock and Niels Erickson rather than Jeff & 'Manda Dee. The tone of these second edition titles was noticeably one of more overt humor and silliness, peppering the text with puns (and even calling on fans to mail in suggested puns of their own for future supplements).\n\n\n\n"}
{"id": "4495335", "url": "https://en.wikipedia.org/wiki?curid=4495335", "title": "Tautology (logic)", "text": "Tautology (logic)\n\nIn logic, a tautology (from the Greek word ταυτολογία) is a formula or assertion that is true in every possible interpretation. A simple example is \"(x equals y) or (x does not equal y)\" (or as a less abstract example, \"The ball is green or the ball is not green\").\n\nPhilosopher Ludwig Wittgenstein first applied the term to redundancies of propositional logic in 1921. (It had been used earlier to refer to rhetorical tautologies, and continues to be used in that alternative sense.) A formula is satisfiable if it is true under at least one interpretation, and thus a tautology is a formula whose negation is unsatisfiable. Unsatisfiable statements, both through negation and affirmation, are known formally as contradictions. A formula that is neither a tautology nor a contradiction is said to be logically contingent. Such a formula can be made either true or false based on the values assigned to its propositional variables. The double turnstile notation formula_1 is used to indicate that \"S\" is a tautology. Tautology is sometimes symbolized by \"V\"pq\"\", and contradiction by \"O\"pq\"\". The tee symbol formula_2 is sometimes used to denote an arbitrary tautology, with the dual symbol formula_3 (falsum) representing an arbitrary contradiction; in any symbolism, a tautology may be substituted for the truth value \"true,\" as symbolized, for instance, by \"1.\"\n\nTautologies are a key concept in propositional logic, where a tautology is defined as a propositional formula that is true under any possible Boolean valuation of its propositional variables. A key property of tautologies in propositional logic is that an effective method exists for testing whether a given formula is always satisfied (or, equivalently, whether its negation is unsatisfiable).\n\nThe definition of \"tautology\" can be extended to sentences in predicate logic, which may contain quantifiers, unlike sentences of propositional logic. In propositional logic, there is no distinction between a tautology and a logically valid formula. In the context of predicate logic, many authors define a tautology to be a sentence that can be obtained by taking a tautology of propositional logic and uniformly replacing each propositional variable by a first-order formula (one formula per propositional variable). The set of such formulas is a proper subset of the set of logically valid sentences of predicate logic (which are the sentences that are true in every model).\n\nThe word \"tautology\" was used by the ancient Greeks to describe a statement that was asserted to be true merely by virtue of saying the same thing twice, a pejorative meaning that is still used for rhetorical tautologies. Between 1800 and 1940, the word gained new meaning in logic, and is currently used in mathematical logic to denote a certain type of propositional formula, without the pejorative connotations it originally possessed.\n\nIn 1800, Immanuel Kant wrote in his book \"Logic\":\nHere \"analytic proposition\" refers to an analytic truth, a statement in natural language that is true solely because of the terms involved.\n\nIn 1884, Gottlob Frege proposed in his \"Grundlagen\" that a truth is analytic exactly if it can be derived using logic. But he maintained a distinction between analytic truths (those true based only on the meanings of their terms) and tautologies (statements devoid of content).\n\nIn 1921, in his \"Tractatus Logico-Philosophicus\", Ludwig Wittgenstein proposed that statements that can be deduced by logical deduction are tautological (empty of meaning) as well as being analytic truths. Henri Poincaré had made similar remarks in \"Science and Hypothesis\" in 1905. Although Bertrand Russell at first argued against these remarks by Wittgenstein and Poincaré, claiming that mathematical truths were not only non-tautologous but were synthetic, he later spoke in favor of them in 1918:\nHere \"logical proposition\" refers to a proposition that is provable using the laws of logic.\n\nDuring the 1930s, the formalization of the semantics of propositional logic in terms of truth assignments was developed. The term \"tautology\" began to be applied to those propositional formulas that are true regardless of the truth or falsity of their propositional variables. Some early books on logic (such as \"Symbolic Logic\" by C. I. Lewis and Langford, 1932) used the term for any proposition (in any formal logic) that is universally valid. It is common in presentations after this (such as Stephen Kleene 1967 and Herbert Enderton 2002) to use \"tautology\" to refer to a logically valid propositional formula, but to maintain a distinction between \"tautology\" and \"logically valid\" in the context of first-order logic (see below).\n\nPropositional logic begins with propositional variables, atomic units that represent concrete propositions. A formula consists of propositional variables connected by logical connectives, built up in such a way that the truth of the overall formula can be deduced from the truth or falsity of each variable. A valuation is a function that assigns each propositional variable either T (for truth) or F (for falsity). So, for example, using the propositional variables \"A\" and \"B\", the binary connectives formula_4 and formula_5 representing disjunction and conjunction respectively, and the unary connective formula_6 representing negation, the following formula can be obtained::formula_7.\nA valuation here must assign to each of \"A\" and \"B\" either T or F. But no matter how this assignment is made, the overall formula will come out true. For if the first conjunction formula_8 is not satisfied by a particular valuation, then one of \"A\" and \"B\" is assigned F, which will cause the corresponding later disjunct to be T.\n\nA formula of propositional logic is a tautology if the formula itself is always true regardless of which valuation is used for the propositional variables.\n\nThere are infinitely many tautologies. Examples include:\n\nA minimal tautology is a tautology that is not the instance of a shorter tautology.\n\nThe problem of determining whether a formula is a tautology is fundamental in propositional logic. If there are \"n\" variables occurring in a formula then there are 2 distinct valuations for the formula. Therefore, the task of determining whether or not the formula is a tautology is a finite, mechanical one: one need only evaluate the truth value of the formula under each of its possible valuations. One algorithmic method for verifying that every valuation causes this sentence to be true is to make a truth table that includes every possible valuation.\n\nFor example, consider the formula\nThere are 8 possible valuations for the propositional variables \"A\", \"B\", \"C\", represented by the first three columns of the following table. The remaining columns show the truth of subformulas of the formula above, culminating in a column showing the truth value of the original formula under each valuation.\n\nBecause each row of the final column shows \"T\", the sentence in question is verified to be a tautology.\n\nIt is also possible to define a deductive system (proof system) for propositional logic, as a simpler variant of the deductive systems employed for first-order logic (see Kleene 1967, Sec 1.9 for one such system). A proof of a tautology in an appropriate deduction system may be much shorter than a complete truth table (a formula with \"n\" propositional variables requires a truth table with 2 lines, which quickly becomes infeasible as \"n\" increases). Proof systems are also required for the study of intuitionistic propositional logic, in which the method of truth tables cannot be employed because the law of the excluded middle is not assumed.\n\nA formula \"R\" is said to tautologically imply a formula \"S\" if every valuation that causes \"R\" to be true also causes \"S\" to be true. This situation is denoted formula_19. It is equivalent to the formula formula_20 being a tautology (Kleene 1967 p. 27).\n\nFor example, let \"S\" be formula_21. Then \"S\" is not a tautology, because any valuation that makes \"A\" false will make \"S\" false. But any valuation that makes \"A\" true will make \"S\" true, because formula_22 is a tautology. Let \"R\" be the formula formula_23. Then formula_19, because any valuation satisfying \"R\" makes \"A\" true and thus makes \"S\" true.\n\nIt follows from the definition that if a formula \"R\" is a contradiction then \"R\" tautologically implies every formula, because there is no truth valuation that causes \"R\" to be true and so the definition of tautological implication is trivially satisfied. Similarly, if \"S\" is a tautology then \"S\" is tautologically implied by every formula.\n\nThere is a general procedure, the substitution rule, that allows additional tautologies to be\nconstructed from a given tautology (Kleene 1967 sec. 3). Suppose that \"S\" is a tautology and for\neach propositional variable \"A\" in \"S\" a fixed sentence \"S\" is chosen. Then the\nsentence obtained by replacing each variable \"A\" in \"S\" with the corresponding sentence \"S\" is also a tautology.\n\nFor example, let \"S\" be the tautology \nLet \"S\" be formula_26 and let \"S\" be formula_27.\nIt follows from the substitution rule that the sentence\nis a tautology, too. In turn, a tautology may be substituted for the truth value \"true\".\n\nAn axiomatic system is complete if every tautology is a theorem (derivable from axioms). An axiomatic system is sound if every theorem is a tautology.\n\nThe problem of constructing practical algorithms to determine whether sentences with large numbers of propositional variables are tautologies is an area of contemporary research in the area of automated theorem proving.\n\nThe method of truth tables illustrated above is provably correct – the truth table for a tautology will end in a column with only \"T\", while the truth table for a sentence that is not a tautology will contain a row whose final column is \"F\", and the valuation corresponding to that row is a valuation that does not satisfy the sentence being tested. This method for verifying tautologies is an effective procedure, which means that given unlimited computational resources it can always be used to mechanistically determine whether a sentence is a tautology. This means, in particular, the set of tautologies over a fixed finite or countable alphabet is a decidable set.\n\nAs an efficient procedure, however, truth tables are constrained by the fact that the number of valuations that must be checked increases as 2, where \"k\" is the number of variables in the formula. This exponential growth in the computation length renders the truth table method useless for formulas with thousands of propositional variables, as contemporary computing hardware cannot execute the algorithm in a feasible time period.\n\nThe problem of determining whether there is any valuation that makes a formula true is the Boolean satisfiability problem; the problem of checking tautologies is equivalent to this problem, because verifying that a sentence \"S\" is a tautology is equivalent to verifying that there is no valuation satisfying formula_29. It is known that the Boolean satisfiability problem is NP complete, and widely believed that there is no polynomial-time algorithm that can perform it. Consequently tautology is co-NP-complete. Current research focuses on finding algorithms that perform well on special classes of formulas, or terminate quickly on average even though some inputs may cause them to take much longer.\n\nThe fundamental definition of a tautology is in the context of propositional logic. The definition can be extended, however, to sentences in first-order logic (see Enderton (2002, p. 114) and Kleene (1967 secs. 17–18)). These sentences may contain quantifiers, unlike sentences of propositional logic. In the context of first-order logic, a distinction is maintained between logical validities, sentences that are true in every model, and tautologies, which are a proper subset of the first-order logical validities. In the context of propositional logic, these two terms coincide.\n\nA tautology in first-order logic is a sentence that can be obtained by taking a tautology of propositional logic and uniformly replacing each propositional variable by a first-order formula (one formula per propositional variable). For example,\nbecause formula_30 is a tautology of propositional logic, formula_31 is a tautology in first order logic. Similarly, in a first-order language with a unary relation symbols \"R\",\"S\",\"T\", the following sentence is a tautology:\nIt is obtained by replacing formula_33 with formula_34, formula_35 with formula_36, and formula_37 with formula_38 in the propositional tautology formula_39.\n\nNot all logical validities are tautologies in first-order logic. For example, the sentence\nis true in any first-order interpretation, but it corresponds to the propositional sentence formula_41 which is not a tautology of propositional logic.\n\nIn natural languages, some apparent tautologies may have non-tautological meanings in practice. In English, \"it is what it is\" is used to mean 'there is no way of changing it'. In Tamil, \"vantaalum varuvaan\" literally means 'if he comes, he will come', but really means 'he just may come'.\n\n\n\n"}
{"id": "46385484", "url": "https://en.wikipedia.org/wiki?curid=46385484", "title": "The Most Good You Can Do", "text": "The Most Good You Can Do\n\nThe Most Good You Can Do: How Effective Altruism Is Changing Ideas About Living Ethically is a 2015 Yale University Press book by moral philosopher and bioethicist Peter Singer describing and arguing for the ideas of effective altruism. It is a follow-up to his earlier book \"The Life You Can Save\" (TLYCS). While TLYCS was focused on making the moral argument for donating money to improve the lives of people in extreme poverty (building on ideas in Famine, Affluence and Morality), the new book focuses on the broader question of how to do the most good.\n\nOliver Milman interviewed Peter Singer about the book for \"The Guardian\" shortly before the book's release. Hamilton Nolan interviewed Singer for \"Gawker\" a week after the release. Singer was also interviewed on ABC Online (an Australian media network) about his book. He also did a longer interview with the Melbourne radio channel of the network.\n\nSinger also participated in an Ask Me Anything on Reddit, fielding questions about his book, on April 14, 2015 (a week after the book's release).\n\nNicholas Kristof reviewed the book for \"The New York Times\", beginning with a discussion of the earning to give strategy. Kristof had three reservations about the book: (1) it's not clear where to draw the line with respect to altruism, (2) in addition to humanitarian motives, loyalty is also important and many give to universities or the arts out of loyalty, (3) the idea of taking a job solely because it is well-paying made him flinch. Kristof concluded on a positive note: \"Singer’s argument is powerful, provocative and, I think, basically right. The world would be a better place if we were as tough-minded in how we donate money as in how we make it.\"\n\nUniversity of Chicago Law School professor Eric Posner reviewed the book for \"Slate Magazine\", concluding: \"So what’s an effective altruist to do? The utilitarian imperative to search out and help the people with the highest marginal utility of money around the world is in conflict with our limited knowledge about foreign cultures, which makes it difficult for us to figure out what the worst-off people really need.* For this reason, donations to Little League and other local institutions you are familiar with may not be a bad idea. The most good you can do may turn out to be—not much.\" Posner wrote a follow-up post on his personal blog, stressing that in his view Singer's main weakness was that he didn't spend enough time working through the ramifications of the importance of institutions.\n\nMinal Bopaiah wrote a blog post favorably reviewing the book for PSI Impact, a website maintained by Population Services International. PSI was one of many charities discussed by Singer in his book as potentially effective places to donate to.\n\nJohn Abdulla reviewed the book on Oxfam's blog, concluding: \"And so the question that remains for me, as I think more about the ideas laid out in this book, is how can I challenge myself to do more good in this world?\"\n\nGlenn C. Altschuler, professor of American Studies at Cornell University, reviewed the book for Philly.com, concluding: \"Singer opens up worthwhile conversations (and practical applications) related to ethical ideals. At minimum, The Most Good You Can Do can stimulate donors to insist that charitable organizations provide persuasive proof of their effectiveness.\"\n"}
{"id": "14222005", "url": "https://en.wikipedia.org/wiki?curid=14222005", "title": "Timeline of reproductive rights legislation", "text": "Timeline of reproductive rights legislation\n\nTimeline of reproductive rights legislation, a chronological list of laws and legal decisions affecting human reproductive rights. Reproductive rights are a sub-set of human rights pertaining to issues of reproduction and reproductive health. These rights may include some or all of the following: the right to legal or safe abortion, the right to birth control, the right to access quality reproductive healthcare, and the right to education and access in order to make reproductive choices free from coercion, discrimination, and violence. Reproductive rights may also include the right to receive education about contraception and sexually transmitted infections, and freedom from coerced sterilization, abortion, and contraception, and protection from gender-based practices such as female genital cutting (FGC) and male genital mutilation (MGM).\n\n\n\n\n\n"}
{"id": "27585945", "url": "https://en.wikipedia.org/wiki?curid=27585945", "title": "Trajectory (fluid mechanics)", "text": "Trajectory (fluid mechanics)\n\nIn fluid mechanics, meteorology and oceanography, a trajectory traces the motion of a single point, often called a parcel, in the flow.\n\nTrajectories are useful for tracking atmospheric contaminants, such as smoke plumes, and as constituents to Lagrangian simulations, such as contour advection or semi-Lagrangian schemes.\n\nSuppose we have a time-varying flow field, formula_1. The motion of a fluid parcel, or trajectory, is given by the following system of ordinary differential equations:\n\nWhile the equation looks simple, there are at least three concerns when attempting to solve it numerically. The first is the integration scheme. This is typically a Runge-Kutta, although others can be useful as well, such as a leapfrog. The second is the method of determining the velocity vector, formula_3 at a given position, formula_4, and time, \"t\". Normally, it is not known at all positions and times, therefore some method of interpolation is required. If the velocities are gridded in space and time, then bilinear, trilinear or higher-dimensional linear interpolation is appropriate. Bicubic, tricubic, etc., interpolation is used as well, but is probably not worth the extra computational overhead.\n\nVelocity fields can be determined by measurement, e.g. from weather balloons, from numerical models or especially from a combination of the two, e.g. assimilation models.\n\nThe final concern is metric corrections. These are necessary for geophysical fluid flows on a spherical Earth. The differential equations for tracing a two-dimensional, atmospheric trajectory in longitude-latitude coordinates are as follows:\n\nwhere, formula_7 and formula_8 are, respectively, the longitude and latitude in radians, \"r\" is the radius of the Earth, \"u\" is the zonal wind and \"v\" is the meridional wind.\n\nOne problem with this formulation is the polar singularity: notice how the denominator in the first equation goes to zero when the latitude is 90 degrees—plus or minus. One means of overcoming this is to use a locally Cartesian coordinate system close to the poles. Another is to perform the integration on a pair of Azimuthal equidistant projections—one for the N. Hemisphere and one for the S. Hemisphere.\n\nTrajectories can be validated by balloons in the atmosphere and buoys in the ocean.\n\n"}
{"id": "279690", "url": "https://en.wikipedia.org/wiki?curid=279690", "title": "Type inference", "text": "Type inference\n\nType inference refers to the automatic detection of the data type of an expression in a programming language.\n\nIt is a feature present in some strongly statically typed languages. It is often characteristic of functional programming languages in general. Some languages that include type inference include C++11, C# (starting with version 3.0), Chapel, Clean, Crystal, D, F#, FreeBASIC, Go, Haskell, Java (starting with version 10), Julia, Kotlin, ML, Nim, OCaml, Opa, RPython, Rust, Scala, Swift, Vala and Visual Basic (starting with version 9.0). \nThe majority of them use a simple form of type inference, while especially those ones who use the Hindley-Milner type system provide a more complete type inference. The ability to infer types automatically makes many programming tasks easier, leaving the programmer free to omit type annotations while still permitting type checking.\n\nIn some programming languages, all values have a data type explicitly declared at compile time, limiting the values a particular expression can take on at run-time. Increasingly, just-in-time compilation renders the distinction between run time and compile time moot. However, historically, if the type of a value is known only at run-time, these languages are dynamically typed. In other languages, the type of an expression is known only at compile time; these languages are statically typed. In most statically typed languages, the input and output types of functions and local variables ordinarily must be explicitly provided by type annotations. For example, in C:\n\nThe signature of this function definition, codice_1, declares that codice_2 is a function that takes one argument, an integer, and returns an integer. codice_3 declares that the local variable codice_4 is an integer. In a hypothetical language supporting type inference, the code might be written like this instead:\n\nThis is identical to how code is written in the language Dart, except that it is subject to some added constraints as described below. It would be possible to \"infer\" the types of all the variables at compile time. In the example above, the compiler would infer that codice_4 and codice_6 have type integer since the constant codice_7 is type integer, and hence that codice_2 is a function codice_9. The variable codice_10 isn't used in a legal manner, so it wouldn't have a type.\n\nIn the imaginary language in which the last example is written, the compiler would assume that, in the absence of information to the contrary, codice_11 takes two integers and returns one integer. (This is how it works in, for example, OCaml.) From this, the type inferencer can infer that the type of codice_12 is an integer, which means codice_4 is an integer and thus the return value of codice_2 is an integer. Similarly, since codice_11 requires both of its arguments be of the same type, codice_6 must be an integer, and thus, codice_2 accepts one integer as an argument.\n\nHowever, in the subsequent line, \"result2\" is calculated by adding a decimal codice_18 with floating-point arithmetic, causing a conflict in the use of codice_6 for both integer and floating-point expressions. The correct type-inference algorithm for such a situation has been known since 1958 and has been known to be correct since 1982. It revisits the prior inferences and uses the most general type from the outset: in this case floating-point. This can however have detrimental implications, for instance using a floating-point from the outset can introduce precision issues that would have not been there with an integer type.\n\nFrequently, however, degenerate type-inference algorithms are used that cannot backtrack and instead generate an error message in such a situation. This behavior may be preferable as type inference may not always be neutral algorithmically, as illustrated by the prior floating-point precision issue.\n\nAn algorithm of intermediate generality implicitly declares \"result2\" as a floating-point variable, and the addition implicitly converts codice_6 to a floating point. This can be correct if the calling contexts never supply a floating point argument. Such a situation shows the difference between \"type inference\", which does not involve type conversion, and implicit type conversion, which forces data to a different data type, often without restrictions.\n\nFinally, a significant downside of complex type-inference algorithm is that the resulting type inference resolution is not going to be obvious to humans (notably because of the backtracking), which can be detrimental as code is primarily intended to be comprehensible to humans.\n\nThe recent emergence of just-in-time compilation allows for hybrid approaches where the type of arguments supplied by the various calling context is known at compile time, and can generate a large number of compiled versions of the same function. Each compiled version can then be optimized for a different set of types. For instance, JIT compilation allows there to be at least two compiled versions of \"addone\":\n\nType inference is the ability to automatically deduce, either partially or fully, the type of an expression at compile time. The compiler is often able to infer the type of a variable or the type signature of a function, without explicit type annotations having been given. In many cases, it is possible to omit type annotations from a program completely if the type inference system is robust enough, or the program or language is simple enough.\n\nTo obtain the information required to infer the type of an expression, the compiler either gathers this information as an aggregate and subsequent reduction of the type annotations given for its subexpressions, or through an implicit understanding of the type of various atomic values (e.g. true : Bool; 42 : Integer; 3.14159 : Real; etc.). It is through recognition of the eventual reduction of expressions to implicitly typed atomic values that the compiler for a type inferring language is able to compile a program completely without type annotations.\n\nIn complex forms of higher-order programming and polymorphism, it is not always possible for the compiler to infer as much, and type annotations are occasionally necessary for disambiguation. For instance, type inference with polymorphic recursion is known to be undecidable. Furthermore, explicit type annotations can be used to optimize code by forcing the compiler to use a more specific (faster/smaller) type than it had inferred.\n\nRelative to program analysis, type inference is a special case of points-to analysis that uses a type abstraction on pointer targets.\n\nAs an example, the Haskell function codice_21 applies a function to each element of a list, and may be defined as:\nType inference on the codice_21 function proceeds as follows. codice_21 is a function of two arguments, so its type is constrained to be of the form codice_24. In Haskell, the patterns codice_25 and codice_26 always match lists, so the second argument must be a list type: codice_27 for some type codice_28. Its first argument codice_29 is applied to the argument codice_30, which must have type codice_28, corresponding with the type in the list argument, so codice_32 (codice_33 means \"is of type\") for some type codice_34. The return value of codice_35, finally, is a list of whatever codice_29 produces, so codice_37.\n\nPutting the parts together leads to codice_38. Nothing is special about the type variables, so it can be relabeled as\nIt turns out that this is also the most general type, since no further constraints apply. As the inferred type of codice_21 is parametrically polymorphic, the type of the arguments and results of codice_29 are not inferred, but left as type variables, and so codice_21 can be applied to functions and lists of various types, as long as the actual types match in each invocation.\n\nThe algorithm first used to perform type inference is now informally termed the Hindley–Milner algorithm, although the algorithm should properly be attributed to Damas and Milner.\n\nThe origin of this algorithm is the type inference algorithm for the simply typed lambda calculus that was devised by Haskell Curry and Robert Feys in 1958.\nIn 1969 J. Roger Hindley extended this work and proved that their algorithm always inferred the most general type.\nIn 1978 Robin Milner, independently of Hindley's work, provided an equivalent algorithm, Algorithm W.\nIn 1982 Luis Damas finally proved that Milner's algorithm is complete and extended it to support systems with polymorphic references.\n\nBy design, type inference, especially correct (backtracking) type inference will introduce use of the most general type appropriate, however this can have implications as more general types may not always be algorithmically neutral, the typical cases being:\n\nType inference algorithms have been used to analyze natural languages as well as programming languages. Type inference algorithms are also used in some grammar induction and constraint-based grammar systems for natural languages.\n\n"}
{"id": "1705511", "url": "https://en.wikipedia.org/wiki?curid=1705511", "title": "World Reference Base for Soil Resources", "text": "World Reference Base for Soil Resources\n\nThe World Reference Base for Soil Resources (WRB) is an international soil classification system for naming soils and creating legends for soil maps. The currently valid version is the Update 2015 of the third edition 2014. It is edited by a working group of the International Union of Soil Sciences (IUSS).\n\nSince the 19 century, several countries developed national soil classification systems. During the 20 century, the need for an international soil classification system became more and more obvious. \n\nFrom 1971 to 1981, the Food and Agriculture Organization (FAO) and UNESCO published the Soil Map of the World, 10 volumes, scale 1 : 5 M. The Legend for this map, published in 1974 under the leadership of Rudi Dudal, became the FAO soil classification. Many ideas from national soil classification systems were brought together in this worldwide-applicable system, among them the idea of diagnostic horizons as established in the ‘7 approximation to the USDA soil taxonomy’ from 1960. The next step was the Revised Legend of the Soil Map of the World, published in 1988.\n\nIn 1982, the International Soil Science Society (ISSS; now: International Union of Soil Sciences, IUSS) established a working group named International Reference Base for Soil Classification (IRB). Chair of this working group was Ernst Schlichting. Its mandate was to develop an international soil classification system that should better consider soil-forming processes than the FAO soil classification. Drafts were presented in 1982 and 1990.\n\nIn 1992, the IRB working group decided to develop a new system named World Reference Base for Soil Resources (WRB) that should further develop the Revised Legend of the FAO soil classification and include some ideas of the more systematic IRB approach. Otto Spaargaren (International Soil Reference and Information Centre) and Freddy Nachtergaele (FAO) were nominated to prepare a draft. This draft was presented at the 15 World Congress of Soil Science in Acapulco in 1994. At the same congress, the WRB was established as an ISSS working group replacing the IRB. At the 16 World Congress of Soil Science in Montpellier in 1998, the first edition of the WRB was published. At the same congress, the ISSS endorsed the WRB as its correlation system for soil classification. (In 2014, the USDA soil taxonomy also received the status of a correlation system.) At the 18 World Congress of Soil Science in Philadelphia in 2006, the second edition of the WRB was presented, and at the 20 World Congress of Soil Science in Jeju in 2014, the third edition. An update of the third edition was issued in 2015. Whereas the second edition was only suitable for naming soils, the third edition can additionally be used for creating map legends.\n\nThe WRB has only two hierarchical levels (see below) and has in that sense a similar approach as the French référencial pédologique (1992, 1995, 2008). Contrary to that, the USDA soil taxonomy is strongly hierarchical and has six levels. The classification in WRB is based mainly on soil morphology (field and laboratory data) as an expression of pedogenesis. Another difference with USDA soil taxonomy is that soil climate is regarded only as a soil-forming factor and not as a soil characteristic. The WRB is not meant to replace national soil classification systems, which, for their area, may be more detailed than the WRB.\n\nThe WRB is edited by a working group of the International Union of Soil Sciences (IUSS). The current chair of the working group is Peter Schad (Technical University of Munich, Germany, since 2010). The current vice-chair is Stephan Mantel (International Soil Reference and Information Centre, The Netherlands, since 2018). \n\nChairs of the WRB working group and responsible first authors of the WRB editions are: Seppe Deckers (Belgium, 1 edition 1998), Erika Michéli (Hungary, 2 edition 2006) and Peter Schad (Germany, 3 edition 2014). \n\nThe WRB working group has a homepage that is currently hosted by the Chair of Soil Science of the Technical University of Munich. It provides the following: \n\n\nThe classification is based on diagnostic horizons, diagnostic properties and diagnostic materials, altogether called diagnostics. Diagnostic materials are materials that significantly influence soil-forming processes (pedogenesis). They are either inherited from the parent material or the result of soil-forming processes. Diagnostic properties are typical results of soil-forming processes or reflect specific conditions of soil formation. Diagnostic horizons are typical results of soil-forming processes that show a minimum thickness and therefore a horizontal appearance. \n\nThe diagnostics have names (e. g. argic horizon, stagnic properties, fluvic material), The WRB does not use horizons symbols (A horizons, B horizons). Therefore, horizons that are not diagnostic, do not have names. Instead, WRB recommends using the horizon symbols provided by the FAO Guidelines for Soil Description (2006). \n\nThe classification comprises two levels: \n\nThe first level has 32 Reference Soil Groups (RSGs).\n\nAt the second level, for further differentiation a set of qualifiers is added to the name of the RSG. There are 185 qualifiers in total. For every RSG, there is a list of available qualifiers, which are subdivided into two types: \n\n\nThe names of the RSGs and the qualifiers start with capital letters. They must be given in English and must not be translated into any other language in order to guarantee that a certain soil has the same name all over the world. \n\nA key is used for allocating a soil to a certain RSG. In a defined sequence, the key asks for the presence or absence of certain diagnostics in a certain depth range. In addition, the key asks for single characteristics, e. g., a certain clay content or a certain base saturation. The soil belongs to the first RSG, for which it fulfils the set of criteria.\n\nThe qualifiers available for use with a particular RSG are listed in the key, along with the RSG. Their number is from 35 to 68. All applying qualifiers must be added to the soil name. The principal qualifiers are added before the name of the RSG. The sequence is from right to left, i.e. the uppermost qualifier in the list is placed closest to the name of the RSG. The supplementary qualifiers are added in brackets after the name of the RSG and are separated from each other by commas. The sequence is from left to right, i.e. the first qualifier according to the alphabet is placed closest to the name of the RSG. If no other principal qualifier applies, the Haplic qualifier is used. If two or more qualifiers in the list are separated by a slash (/) only one of them can be used. The slash signifies that these qualifiers are either mutually exclusive (e.g. Dystric and Eutric) or one of them is redundant with the redundant qualifier(s) listed after the slash(es). In the soil name, supplementary qualifiers are always placed in the order of the alphabet, even if their position in the list differs from alphabetical sequence due to the use of the slash. It is a general rule that qualifiers conveying redundant information are not used. Example: If a soil has the Calcaric qualifier (carbonates present) the Eutric qualifier (high base saturation) is not used.\n\nQualifiers may be combined with specifiers (e.g. Epi-, Proto-) to form subqualifiers (e.g. Epiarenic, Protocalcic). The depth-related specifiers are of special importance, although their use is optional:\n\n\nThe number of qualifiers used in a map legend depends on the scale. The WRB distinguishes four map scale levels: \n\n\nCorrelating the map scale levels with concrete scales (e.g. fourth map scale level from 1 : 250 000 to 1 : 1 000 000) is difficult because selecting a map scale level depends very much from the homogeneity/heterogeneity of the landscape.\n\nThe principal qualifiers are added before the name of the RSG following the rules explained for naming a soil. Depending on the purpose of the map or according to national traditions, at any scale level, further qualifiers may be added optionally. They may be additional principal qualifiers from further down the list and not already used in the soil name, or they may be supplementary qualifiers. They are placed using the above-mentioned rules for supplementary qualifiers; principal qualifiers first, then supplementary qualifiers.\n\nThe WRB recommends that on a map unit not just one soil is indicated but an association of soils. For this purpose, WRB uses the following nomenclature: \n\n\nFor codominant and associated soils, it is allowed to use less principal qualifiers than would correspondent to the used map scale level. The use of specifiers is not recommended due to the generalization that is required when making maps. In map legends, the names of the RSGs are given in plural; in all other cases they are given in singular. \n\nThe WRB Manual comprises five chapters and four annexes. \n\nChapter 1 reports on background and basics. It includes tables of the diagnostic horizons and of the RSGs. The latter is given below. Chapter 2 provides the rules for classifying soils and creating map legends. It is highly recommended to read this short chapter before using the WRB. Chapter 3 presents the diagnostic horizons, properties and materials, each with a general description, the diagnostic criteria and some additional information. For the decision, whether a diagnostic is present or absent in a soil, only the diagnostic criteria are relevant. Chapter 4 provides the key to the RSGs and for every RSG a list with the available principal and supplementary qualifiers. Chapter 5 gives the definitions of the qualifiers. These five chapters are concluded with a list of references. \n\nThey are followed by four annexes. Annex 1 briefly describes the 32 RSGs. Annex 2 lists the laboratory methods. This is only a list; it is not a laboratory manual. Annex 3 gives the codes for the RSGs, the qualifiers and the specifiers and the rules for the sequence of the codes for naming soils and creating map legends. Annex 4 provides a texture triangle, in which the ranges of the texture-related qualifiers are marked with different grey shades. \n\nThis is the list of the 32 Reference Soil Groups in the sequence of the key (Chapter 4 of the WRB Manual), including the codes (Annex 3 of the WRB Manual). This list is mainly taken from Table 2 (Chapter 1) of the WRB Manual.\n\nSoils with thick organic layers \n\n\nSoils with strong human influence \n\n\nSoils with limitations to root growth \n\n\nSoils distinguished by Fe/Al chemistry \n\n\nPronounced accumulation of organic matter in the mineral topsoil \n\n\nAccumulation of moderately soluble salts or non-saline substances \n\n\nSoils with clay-enriched subsoil \n\n\nSoils with little or no profile differentiation \n\n\nOur example soil has the following characteristics: \n\nField characteristics: A soil developed from loess shows a marked clay increase in around 60 cm depth and clay coatings in the clay-richer horizon. According to the landscape setting, we presume that high-activity clays dominate. In the field, a pH value of 6 is measured in the subsoil. The lower part of the clay-poorer topsoil is bleached. In the clay-richer horizon, we observe a mottling; the oximorphic and the reductimorphic colours sum up to 30% of the exposed area, the intensive colours in the interiors of the aggregates. In spring time, reducing conditions occur. The soil is ploughed regularly. Organic matter concentrations in the topsoil are small.\n\nLaboratory characteristics: The laboratory analyses confirm the high cation exchange capacity per kg clay in the clay-richer horizon and the high base saturation in the subsoil. In the topsoil, we find 20% clay, 10% sand and 70% silt, in the subsoil 35% clay, 10% sand and 55% silt. \n\nThe naming of the soil consists of four steps. \n\nQuestion 1: Does the soil have diagnostic horizons, properties and materials? \n\nThe soil has the following diagnostics: \n\n\nQuestion 2: To which RSG does the soil belong? \n\nWe have to go through the key RSG for RSG. This soil is not a Histosol, not an Anthrosol, not a Technosol etc. Finally, we end up with the Luvisols. This is the first RSG in the key, the criteria of which our soil completely fulfils. \n\nQuestion 3: Which qualifiers apply? \n\nFrom the list of the principal qualifiers, Stagnic (stagnic properties und reducing conditions) and Albic (light colours) apply. Stagnic is found further up in the list. Therefore, the soil has to be named up till now Albic Stagnic Luvisol. From the list of the supplementary qualifiers, Siltic (silty from 0 to 60 cm), Loamic (loamy from 60 cm downwards), Aric (ploughed), Cutanic (clay coatings) und Ochric (small concentrations of organic carbon) apply. Bringing the supplementary qualifiers into the alphabetical order, the soil is an Albic Stagnic Luvisol (Aric, Cutanic, Loamic, Ochric, Siltic). \n\nQuestion 4: Which specifiers can be used to form subqualifiers? \n\nThe soil is Siltic from 0 to 60 cm and Loamic from 60 cm downwards. We can use the depth-related specifiers Ano- and Endo- to construct the subqualifiers Anosiltic and Endoloamic. The stagnic properties occur only in the subsoil and the albic material only around 50 cm. This means that we can use the subqualifiers Endostagnic and Amphialbic. \n\nNow, the soil name is: Amphialbic Endostagnic Luvisol (Aric, Cutanic, Endoloamic, Ochric, Anosiltic). \n\nUsing the codes of Annex 3 of the WRB Manual gives us the following short name: LV-stn.abm-ai.ct.lon.oh.sia. \n\nLet’s say that our example soil Amphialbic Endostagnic Luvisol (Aric, Cutanic, Endoloamic, Ochric, Anosiltic) covers 60% of the area of a map unit. The other 40% are covered by a Eutric Endoluvic Amphialbic Stagnosol (Humic, Endoloamic, Anosiltic). The map unit will be named as follows: \n\nFirst map scale level: \n\n\nSecond map scale level: \n\n\nThird map scale level: \n\n\nFourth map scale level: \n\n\nRemarks: The use of the depth-related specifiers is not recommended in map legends, where generalization is required. The fourth scale level would allow three principal qualifiers, but the dominant soil in our example has only two. \n\nAt every scale level, optional qualifiers may be added. If one wants to give information about organic carbon, one can do that even at the first map scale level and write: \n\n\nIf somebody wants to give additional information on soil genesis, this can also be done on the first map scale level: \n\n\nBoth in combination would read, e. g., at the second map scale level: \n\n\n\n\n"}
{"id": "30004632", "url": "https://en.wikipedia.org/wiki?curid=30004632", "title": "Yun Chi-wang", "text": "Yun Chi-wang\n\nGeneral Yun Chi-wang (윤치왕, 尹致旺) (February 17 1895 – December 21 1982) was a South Korean politician, soldier and gynecologist. He was the half brother of Yun Chi-ho, uncle of Yun Poson (who was the fourth president of South Korea), and cousin of Yun Chi-Young. His nickname was Nampho (남포, 南圃), and his courtesy name was Sungun (성운, 聖雲). \nYun Chi-wang's father was Yun Ung-nyeol (1840–1911); his mother was Kim Jung-soon (1876–1959), his father's concubine. He had a half-brother Yun Chi-ho (1865–1945), some thirty years his elder, whose mother was their father's wife, Lee Jung-Mu (1844~1936).\nIn 1911, he entered Suwan Agricultural High School, but in 1912 he dropped out, and in 1913 went to participate in independent activities in China. In 1914, on Kim Kyu-sik's advice, he went to study at the University of Glasgow.\nFrom 1927 to 1944 he worked at Severance Hospital in his homeland, and in 1938 became its second Director. He was also Chairman of Korea's Maternity Society.\nIn 1948 he enlisted in the South Korean Army as a medical officer with the rank of lieutenant colonel. In 1950, he participated in the Korean War. In March 1959 he retired with the rank of lieutenant general, and took full retirement in 1960.\n\n\n"}
