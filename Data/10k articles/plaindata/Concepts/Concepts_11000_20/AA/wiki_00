{"id": "440930", "url": "https://en.wikipedia.org/wiki?curid=440930", "title": "Amorality", "text": "Amorality\n\nAmorality is an absence of, indifference towards, or disregard for morality.\n\nMorality and amorality in humans and animals is a subject of dispute among scientists and philosophers. If morality is intrinsic to humanity, then amoral human beings either do not exist or are only deficiently human. If morality is extrinsic to humanity, then amoral human beings can both exist and be fully human, and as such be amoral either by nature or by choice.\n\nAmoral should not be confused with \"immoral\", which refers to an agent doing or thinking something he or she knows or believes to be wrong.\n\nAny entity that is not sapient may be considered categorically amoral. For example, a rock may be used (by rational agents) for good or bad purposes, but the rock itself is neither good nor bad. In ontological philosophy, the ancient gnostic concept that the material world was inherently evil applied morality to existence itself and was a point of concern in early Christianity in the form of Docetism, as it opposed the notion that creation is good, as stated in The Book of Genesis. In modern science, however, the matter of the universe is often observed amorally for objective purposes.\n\nAnimals have long been thought to be amoral entities. However, research into the evolution of morality, including sociality and altruism in animals, has sparked new debate amongst many philosophers. Many animals display behavior that is analogous to human moral behavior, such as caring for the young, protecting kin, and sharing the spoils of the hunt. Generally speaking, if this behavior is a voluntary response to ethical norms, then animals do have morality. If animals are involuntarily following innate instinct, then they are amoral.\n\nSome people consider corporations to be intrinsically amoral entities.\n\n"}
{"id": "2235265", "url": "https://en.wikipedia.org/wiki?curid=2235265", "title": "Anna Karenina principle", "text": "Anna Karenina principle\n\nThe Anna Karenina principle states that a deficiency in any one of a number of factors dooms an endeavor to failure. Consequently, a successful endeavor (subject to this principle) is one where every possible deficiency has been avoided.\n\nThe name of the principle derives from Leo Tolstoy's book \"Anna Karenina\", which begins:\n\nAll happy families are alike; each unhappy family is unhappy in its own way.In other words: in order to be happy, a family must be successful on \"each and every one\" of \"a\" \"range\" of criteria e.g.: sexual attraction, money issues, parenting, religion, in-laws. Failure on only \"one\" of these counts leads to \"un\"happiness. Thus there are more ways for a family to be unhappy than happy.\n\nIn statistics, the term \"Anna Karenina principle\" is used to describe significance tests: there are any number of ways in which a dataset may violate the null hypothesis and only one in which all the assumptions are satisfied.\n\nThe Anna Karenina principle was popularized by Jared Diamond in his book \"Guns, Germs and Steel\". Diamond uses this principle to illustrate why so few wild animals have been successfully domesticated throughout history, as a deficiency in any one of a great number of factors can render a species undomesticable. Therefore, all successfully domesticated species are not so because of a particular positive trait, but because of a lack of any number of possible negative traits. In chapter 9, six groups of reasons for failed domestication of animals are defined:\n\n\nMoore describes applications of the \"Anna Karenina principle\" in ecology:\n\nSuccessful ecological risk assessments are all alike; every unsuccessful ecological risk assessment fails in its own way. Tolstoy posited a similar analogy in his novel Anna Karenina : \"Happy families are all alike; every unhappy family is unhappy in its own way.\" By that, Tolstoy meant that for a marriage to be happy, it had to succeed in several key aspects. Failure on even one of these aspects, and the marriage is doomed . . . the Anna Karenina principle also applies to ecological risk assessments involving multiple stressors.\n\nMuch earlier, \"Aristotle\" states the same principle in the \"Nicomachean Ethics\" (Book 2):\n\nAgain, it is possible to fail in many ways (for evil belongs to the class of the unlimited, as the Pythagoreans conjectured, and good to that of the limited), while to succeed is possible only in one way (for which reason also one is easy and the other difficult – to miss the mark easy, to hit it difficult); for these reasons also, then, excess and defect are characteristic of vice, and the mean of virtue; For men are good in but one way, but bad in many.\n\nMany experiments and observations of groups of humans, animals, trees, grassy plants, stockmarket prices, and changes in the banking sector proved the modified Anna Karenina principle.\n\nBy studying the dynamics of correlation and variance in many systems facing external, or environmental, factors, we can typically, even before obvious symptoms of crisis appear, predict when one might occur, as correlation between individuals increases, and, at the same time, variance (and volatility) goes up... All well-adapted systems are alike, all non-adapted systems experience maladaptation in their own way... But in the chaos of maladaptation, there is an order. It seems, paradoxically, that as systems become more different they actually become more correlated within limits.\n\nThis effect is proved for many systems: from the adaptation of healthy people to a change in climate conditions to the analysis of fatal outcomes in oncological and cardiological clinics. The same effect is found in the stock market. The applicability of these two statistical indicators of stress, simultaneous increase of variance and correlations, for diagnosis of social stress in large groups was examined in the prolonged stress period preceding the 2014 Ukrainian economic and political crisis. There was a simultaneous increase in the total correlation between the 19 major public fears in the Ukrainian society (by about 64%) and also in their statistical dispersion (by 29%) during the pre-crisis years.\n\nVladimir Arnold in his book \"Catastrophe Theory\" describes \"The Principle of Fragility of Good Things\" which in a sense supplements the Principle of Anna Karenina: good systems must meet simultaneously a number of requirements; therefore, they are more fragile:\n\n... for systems belonging to the singular part of the stability boundary a small change of the parameters is more likely to send the system into the unstable region than into the stable region. This is a manifestation of a general principle stating that all good things (e.g. stability) are more fragile than bad things. It seems that in good situations a number of requirements must hold simultaneously, while to call a situation bad even one failure suffices. \n"}
{"id": "38454300", "url": "https://en.wikipedia.org/wiki?curid=38454300", "title": "Assisted colonization", "text": "Assisted colonization\n\nAssisted colonization, also known as assisted migration or managed relocation, is the act of deliberately moving plants or animals to a different habitat. The destination habitat may have either historically held the species or it may not have hosted the species, but the habitat provides the bioclimatic requirements to support it. Assisted colonization may also supplement an existing population in a site where their numbers are dwindling. All species have some natural capacity to disperse into new habitats and adapt to change, but ongoing climate change is so rapid that many species are unable to keep pace naturally. In order to prevent extinctions, some scientists and practitioners are considering assisting the dispersal of species that have poor natural dispersal ability. This idea has sparked intense debate over the potential benefits, including avoiding many species extinctions, and the risks, including accidentally introducing new invasive species and diseases. Although the debate remains primarily conceptual with few real-world applications, scientists and land managers have already begun to consider several specific assisted colonization projects.\n\nClimate change is expected to drive many species out of parts of their current ranges while creating new suitable habitats elsewhere. In order to avoid population declines and extinction due to climate change, many species will need to adapt or colonize newly suitable areas. Using a niche modeling approach, scientists have predicted that failure to migrate or adapt would result in eventual extinction of about a quarter of the world’s species this century under moderate climate change. The natural dispersal rates of many species are far slower than those needed to keep pace with projected habitat shifts in many regions of the world. Prehistoric climatic changes have resulted in massive global extinctions, and the rate of warming projected for the near future is many times faster than changes in the past 10,000 years, likely resulting in high rates of extinction by the end of this century in the absence of management. The inability of species to migrate in response to human-caused climate change has led some to consider exploring assisted colonization as a means for preventing extinctions.\n\nAssisted colonization is a specific type of species introduction. An introduction is any act of establishing a species in a habitat it does not currently occupy. It often refers to a long-distance relocation, such as the accidental introduction of an invasive species from one continent to another, or the intentional relocation of a species in decline to a habitat where it can persist. By contrast, assisted colonization acknowledges that the natural dispersal rate of many species may be too slow to naturally respond to rapid human-caused environmental change and asks, “if this species could disperse fast enough to keep pace with the changing environment, where would it establish?” Assisted colonization practitioners consider helping the species disperse into such sites, which are often immediately adjacent to the species’ historical range. Assisted colonization thus represents a small artificial boost to an otherwise natural process, acknowledging that the threat—rapid human-caused environmental change—was produced by humans in the first place. Confusion of assisted colonization with species introduction in general—often much larger in scale and with greater risk of adverse impacts—may be the principal reason why some are reluctant to consider assisted colonization (see Controversy, below).\n\nWhen first proposed, the idea was referred to as “assisted migration”. The terminology was later criticized for being reminiscent of natural, cyclic animal migrations in response to changing seasons. It was renamed “assisted colonization,” as colonization more accurately describes the natural phenomenon that management would seek to assist. Others have sought to further distinguish this idea from any natural process by referring to it as “managed relocation.” No specific name has yet been unanimously adopted, but within the scientific and conservation community, “assisted migration,” “managed relocation,” and “assisted colonization” are often used interchangeably and are understood to refer to the same idea.\n\nEven under rapid climate change, dispersal into new areas may not be necessary for some species to persist. Instead of tracking climate shifts through space, some species may be able to survive in their present locations by developing tolerance to new conditions through acclimatization and/or adaptation. The potential for acclimatization or adaptation to allow persistence in the face of climate change varies by species and is generally poorly understood. One study determined that evolution of higher temperature tolerance in some species of amphibians and reptiles will likely occur fast enough to allow these species to survive a 3 °C temperature increase over 100 years, consistent with low- to mid-range projections of global warming. By contrast, many species, such as most temperate trees, have longer generation times and therefore may adapt more slowly; they may take thousands of years to evolve a similar increase in temperature tolerance. Adaptation this slow would be insufficient for keeping up with expected future global warming if colonization of new habitats is not an option.\n\nGenerally speaking, there are three accepted ways that assisted colonization can take place, each one of them with specific benefits and situations in which it applies. They can be defined as reintroduction, introduction and augmentation processes.\n\nIn augmentation, a population is identified with a small number of mating individuals. This can lead to many problems, including inbreeding depression, and often leads to a dwindling number of individuals. Further complicating matters, with such a small population and consistent inbreeding depression, genetic drift is of worry as well, leading to high levels of homozygosity. To combat these problems, individuals are reintroduced to the population. This can be done via \"ex situ\" breeding of individuals or by physically relocating a separate population to join the identified, problematic population.\n\nIn introduction, a species is brought to a habitat in which it has never before existed. This can be done for a number of reasons, ranging from climate change associated habitat loss to the introduction of predator species that cannot be controlled. Generally speaking, this is the type of assisted colonization that contains the most potential for harmful effects, like those described elsewhere in this article. Currently, a number of introductions of endangered populations from Australia have been made with varying degrees of success to small islands near the mainland where the only reason that the population had not dispersed before was due to the physical waterway.\n\nReintroductions involve restoring a species to its native range. The species may no longer be found there due to any number of reasons, though most common is often the introduction of predators or habitat loss due to either climate change or other human factors. This is generally done to broaden the range of threatened populations and to reconnect fragmented populations.\n\nSignificant controversy has developed around the idea of assisted colonization since it was first put forth in the scientific literature in 2007. The two sides can be separated roughly as follows. Supports generally believe that the expected benefits of assisted colonization, including saving and strengthening species, outweighs the potential harm of any project. Detractors generally believe that other conservation techniques which do not include the high risk of invasive species are not only better suited but are also more likely to succeed. This debate continues throughout the literature generally due to a lack of real-world applications and follow-ups. Though these conservation efforts are becoming increasingly common, few long term looks at their success have been conducted.\n\nPerhaps the principal concern scientists have expressed over assisted colonization is the potential for relocated species to be invasive in their new habitats, driving out native species. The fear that assisted colonization will facilitate invasions stems mostly from observations of the vast numbers of species that have become invasive outside their native ranges by (often inadvertent) introduction by humans. Although most agree that assisted colonization efforts, unlike accidental introductions, should involve detailed planning and risk assessment, for some, any threat of introducing invasive species, no matter how small, disqualifies assisted colonization as a viable management response to climate change.\n\nThose who wish to keep assisted colonization on the table often note that the vast majority of historical species invasions have resulted from continent-to-continent or continent-to-island transportation of species and that very few invasions have resulted from the comparatively short-distance, within-continent movement of species proposed for assisted colonization. For example, Mueller and Hellman reviewed 468 documented species invasions and found that only 14.7% occurred on the same continent where the species originated. Of the 14.7%, the vast majority were fish and crustaceans. Terrestrial species that became invasive on the same continent where they originated were often transported across large biogeographic barriers, such as mountain ranges. These long-distance, within-continent translocations are unlike expected uses of assisted colonization, which generally involve helping species colonize habitats immediately adjacent to their current ranges.\n\nTo identify populations at risk and locate new potential habitats, conservationists often use Niche models. These models predict the suitability of habitats in the future based on how closely their climates resemble the climate currently inhabited by the species. Though useful for describing broad trends, these models make a number of unrealistic assumptions that restrict the usefulness of their predictions. For instance, they do not consider the possibility that species may be able to develop tolerance of new climates through acclimatization or adaptation.<ref name=\"doi10.1111/j.1461-0248.2005.00792.x\"></ref> Further, they do not account for the fact that a given species may perform better (e.g., become invasive) or worse (e.g., fail to establish) in a new habitat than in its current range if the community of competitor, predator, and mutualist species is different there. Additionally, because different climate variables (e.g., minimum January temperature, average annual precipitation) rarely shift in unison, it is possible that few areas will exactly match the historical climates of species threatened by climate change. Such multi-directional climate shifts will make it especially difficult to determine the species that are at greatest risk of habitat loss due to climate change and to predict future suitable habitat. The uncertainties in predictions of future suitable habitat limits confidence in assisted colonization decisions and has led some to reject assisted colonization entirely.\n\nDespite the uncertainty inherent in predictions of future suitable habitat, some studies have demonstrated that predictions can be quite accurate. A study of Hesperia comma butterflies in Britain identified unoccupied habitat sites that were likely to support the species under a warmer climate based on their similarity to occupied sites. As the climate warmed, the butterfly colonized many of the sites; most of the sites it did not colonize were located far from existing populations, suggesting they were uncolonized because the butterfly could not reach them on its own. The data suggested that the suitable, uncolonized sites could be good targets for assisted colonization. The results suggested that if investigators can demonstrate their model makes reliable predictions with real-world data, models might be trusted for informing assisted colonization decisions.\n\nThe science is clear that climate change will drive many species extinct, and a traditional, land-preservation ethic will not prevent extinctions. Those wary of moving species instead suggest expanding networks of habitat corridors, allowing species to naturally migrate into newly suitable areas. Under the rates of climate change projected for the coming decades, however, even perfectly connected habitats will probably be insufficient. Species that cannot naturally keep pace with shifting climates will be at risk regardless of habitat connectivity. Evidence suggests that slowly evolving and slowly dispersing species (including species that are dispersal-limited due to habitat fragmentation) will decline or go extinct in the absence of assisted colonization programs.\n\nIn their rejection of assisted colonization, Ricciardi and Simberloff cite the precautionary principle, stating that any unknown risk, no matter how small, of assisted colonization resulting in the creation of new invasive species is enough to require that it not be undertaken. Many scientists reject this position, however, noting that in many cases where extinctions due to climate change are likely, the risks of extinction from not facilitating colonization are probably far worse than the risks of facilitating colonization. They argue that the precautionary principle cuts both ways, and the risks of inaction must be compared against the risks of action. Others note that the ethics of assisting colonization will depend on the values of the stakeholders involved in a specific decision rather than the position of scientists on assisted colonization in general. At the very least, some note, scientists should conduct further research into assisted colonization and improve our capacity to predict specific outcomes instead of outright rejecting it.\n\nBecause confidence in expected outcomes is often greater in the short-term (e.g., 20 years) than the long-term future, it may be more reasonable to use short-term projections to guide actions. However, it is also important to consider whether the climate will remain suitable long enough for colonizing species to mature and reproduce, if that is the management goal.\n\nDue to climate change, accidental species introductions, and other global changes, there is nowhere on the planet free of human disturbance. Thus, the idea that land managers should refrain from creating human-altered communities through assisted colonization may be moot given that all communities have been altered by humans to some degree whether managers undertake assisted colonization or not. Given the reality of global change, it will be impossible to maintain past ecological communities indefinitely. Many therefore believe we should strive to maintain biodiversity and functioning ecosystems in the face of climate change, even if it means actively moving species beyond their native ranges. In the absence of assisted colonization, climate change is already causing many highly mobile species, such as butterflies, to colonize areas they have not previously inhabited. Through assisted colonization, managers could help rare or less-mobile species keep pace, possibly preventing future extinctions due to a their inability to colonize new areas fast enough. Though some argue that nature often responds to challenges more effectively in the absence of human intervention, others note that current climate change, itself, is a human intervention. Many species that would have been effective dispersers under slower, natural climate change may be left behind by more mobile species under current rates of human-caused climate change. Thus, through changing the climate, humans may already be artificially segregating species even without actively relocating them.\n\nCritics may also have major concerns about different genetic issues when considering assisted colonization such as maladaptation to novel environmental conditions and hybridization with similar species. These often depend on the genetic structure and level of genetic variation in the source populations. The environmental conditions in which these populations are being introduced must also be taken into account. In order to enhance genetic variation, and thus adaptive potential, material could be sourced from multiple populations. This is known as composite provenancing. However, if the environmental gradient is well known, such as predictable changes in elevation or aridity, source populations should be ‘genetically matched’ to recipient sites as best as possible to ensure that the translocated individuals ae not maladapted. This strategy of moving species beyond their current range has been suggested for those that are severely threatened or endangered. By moving them outside their native range, hopefully the immediate threats of predation, disease, and habitat loss can be avoided. However, these species are usually already suffering from some sort of genetic issue resulting from low effective population size such as inbreeding depression, loss in genetic diversity, or maladaptation. Therefore, caution must be taken with what few individuals remain and rapid population growth must be the primary goal. In the case of some species, this can be accomplished with a captive breeding program \n\nThe British Columbia Ministry of Forests, Lands, and Natural Resource Operations has acknowledged that climate change will likely threaten the health of the millions of trees that are planted in the province every year, with potential environmental and economic consequences:\nApproximately 300 million tree seedlings are planted in the western USA, British Columbia (BC) and Yukon each year. Many climatologists are predicting that the climate could be 3–4°C warmer when those trees are harvested 60-80 years after planting. These changes to climate will expose trees to increased stress and health risks, compromising the many goods and services from our forests.\n\nIn response to this threat, the Ministry has initiated a large-scale study to determine the long-term health of seedlings of 16 tree species planted beyond their native ranges, into areas expected to become suitable due to changes in climate this century. Results from the study will be used to develop guidelines for when and how assisted colonization of trees should be conducted.\n\nIn 2009, British Columbia also altered guidelines for selecting seeds for replanting forests after a timber harvest. Previously, foresters were required to use seeds from within 200 meters downhill and 300 meters uphill, but the new policy allows foresters to obtain seeds from up to 500 meters downhill, taking advantage of the fact that populations in warmer habitats downhill may be better adapted to the future climate of the restoration site.\n\nAlthough not actively engaging in assisted colonization, the Dixon National Tallgrass Prairie Seed Bank seeks to collect seeds from populations of species expected to decline or disappear due to climate change. They prioritize collections from populations at greatest risk of disappearance and for which suitable habitat is projected to occur elsewhere in the general region, keeping open the possibility of using collected seeds for assisted colonization projects in the future.\n\n"}
{"id": "39045480", "url": "https://en.wikipedia.org/wiki?curid=39045480", "title": "Automate This", "text": "Automate This\n\nAutomate This: How Algorithms Came to Rule Our World is a book written by Christopher Steiner and published by Penguin Group. Steiner begins his study of algorithms on Wall Street in the 1980s but also provides examples from other industries. For example, he explains the history of Pandora Radio and the use of algorithms in music identification. He expresses concern that such use of algorithms may lead to the homogenization of music over time. Steiner also discusses the algorithms that eLoyalty (now owned by Mattersight Corporation following divestiture of the technology) was created by dissecting 2 million speech patterns and can now identify a caller's personality style and direct the caller with a compatible customer support representative.\n\nSteiner's book shares both the warning and the opportunity that algorithms bring to just about every industry in the world, and the pros and cons of the societal impact of automation (e.g. impact on employment).\n\n"}
{"id": "6784", "url": "https://en.wikipedia.org/wiki?curid=6784", "title": "Citizenship", "text": "Citizenship\n\nCitizenship is the status of a person recognized under the custom or law as being a legal member of a sovereign state or belonging to a nation.\n\nA person may have multiple citizenships. A person who does not have citizenship of any state is said to be stateless, while one who lives on state borders whose territorial status is uncertain is a border-lander.\n\nNationality is often used as a synonym for citizenship in English – notably in international law – although the term is sometimes understood as denoting a person's membership of a nation (a large ethnic group). In some countries, e.g. the United States, the United Kingdom, nationality and citizenship can have different meanings (for more information, see Nationality versus citizenship).\n\nEach country has its own policies, regulations and criteria as to who is entitled to its citizenship. A person can be recognized or granted citizenship on a number of bases. Usually citizenship based on circumstances of birth is automatic, but in other cases an application may be required.\n\n\nMany thinkers point to the concept of citizenship beginning in the early city-states of ancient Greece, although others see it as primarily a modern phenomenon dating back only a few hundred years and, for humanity, that the concept of citizenship arose with the first laws. \"Polis\" meant both the political assembly of the city-state as well as the entire society. Citizenship has generally been identified as a western phenomenon. There is a general view that citizenship in ancient times was a simpler relation than modern forms of citizenship, although this view has come under scrutiny. The relation of citizenship has not been a fixed or static relation, but constantly changed within each society, and that according to one view, citizenship might \"really have worked\" only at select periods during certain times, such as when the Athenian politician Solon made reforms in the early Athenian state.\n\nHistorian Geoffrey Hosking in his 2005 \"Modern Scholar\" lecture course suggested that citizenship in ancient Greece arose from an appreciation for the importance of freedom. Hosking explained:\n\nSlavery permitted slaveowners to have substantial free time, and enabled participation in public life. Polis citizenship was marked by exclusivity. Inequality of status was widespread; citizens (πολίτης \"politēs\" < πόλις 'city') had a higher status than non-citizens, such as women, slaves, and resident foreigners (metics). The first form of citizenship was based on the way people lived in the ancient Greek times, in small-scale organic communities of the polis. Citizenship was not seen as a separate activity from the private life of the individual person, in the sense that there was not a distinction between public and private life. The obligations of citizenship were deeply connected into one's everyday life in the polis. These small-scale organic communities were generally seen as a new development in world history, in contrast to the established ancient civilizations of Egypt or Persia, or the hunter-gatherer bands elsewhere. From the viewpoint of the ancient Greeks, a person's public life was not separated from their private life, and Greeks did not distinguish between the two worlds according to the modern western conception. The obligations of citizenship were deeply connected with everyday life. To be truly human, one had to be an active citizen to the community, which Aristotle famously expressed: \"To take no part in the running of the community's affairs is to be either a beast or a god!\" This form of citizenship was based on obligations of citizens towards the community, rather than rights given to the citizens of the community. This was not a problem because they all had a strong affinity with the polis; their own destiny and the destiny of the community were strongly linked. Also, citizens of the polis saw obligations to the community as an opportunity to be virtuous, it was a source of honour and respect. In Athens, citizens were both ruler and ruled, important political and judicial offices were rotated and all citizens had the right to speak and vote in the political assembly.\n\nIn the Roman Empire, citizenship expanded from small-scale communities to the entire empire. Romans realized that granting citizenship to people from all over the empire legitimized Roman rule over conquered areas. Roman citizenship was no longer a status of political agency, as it had been reduced to a judicial safeguard and the expression of rule and law. Rome carried forth Greek ideas of citizenship such as the principles of equality under the law, civic participation in government, and notions that \"no one citizen should have too much power for too long\", but Rome offered relatively generous terms to its captives, including chances for lesser forms of citizenship. If Greek citizenship was an \"emancipation from the world of things\", the Roman sense increasingly reflected the fact that citizens could act upon material things as well as other citizens, in the sense of buying or selling property, possessions, titles, goods. One historian explained:\n\nRoman citizenship reflected a struggle between the upper-class patrician interests against the lower-order working groups known as the plebeian class. A citizen came to be understood as a person \"free to act by law, free to ask and expect the law's protection, a citizen of such and such a legal community, of such and such a legal standing in that community\". Citizenship meant having rights to have possessions, immunities, expectations, which were \"available in many kinds and degrees, available or unavailable to many kinds of person for many kinds of reason\". The law itself was a kind of bond uniting people. Roman citizenship was more impersonal, universal, multiform, having different degrees and applications.\n\nDuring the European Middle Ages, citizenship was usually associated with cities and towns, and applied mainly to middle class folk. Titles such as burgher, grand burgher (German \"Großbürger\") and bourgeoisie denoted political affiliation and identity in relation to a particular locality, as well as membership in a mercantile or trading class; thus, individuals of respectable means and socioeconomic status were interchangeable with citizens.\n\nDuring this era, members of the nobility had a range of privileges above commoners (see aristocracy), though political upheavals and reforms, beginning most prominently with the French Revolution, abolished privileges and created an egalitarian concept of citizenship.\n\nDuring the Renaissance, people transitioned from being subjects of a king or queen to being citizens of a city and later to a nation. Each city had its own law, courts, and independent administration. And being a citizen often meant being subject to the city's law in addition to having power in some instances to help choose officials. City dwellers who had fought alongside nobles in battles to defend their cities were no longer content with having a subordinate social status, but demanded a greater role in the form of citizenship. Membership in guilds was an indirect form of citizenship in that it helped their members succeed financially. The rise of citizenship was linked to the rise of republicanism, according to one account, since independent citizens meant that kings had less power. Citizenship became an idealized, almost abstract, concept, and did not signify a submissive relation with a lord or count, but rather indicated the bond between a person and the state in the rather abstract sense of having rights and duties.\n\nThe modern idea of citizenship still respects the idea of political participation, but it is usually done through \"elaborate systems of political representation at a distance\" such as representative democracy. Modern citizenship is much more passive; action is delegated to others; citizenship is often a constraint on acting, not an impetus to act. Nevertheless, citizens are usually aware of their obligations to authorities, and are aware that these bonds often limit what they can do.\n\nFrom 1790 until the mid-twentieth century, United States law used racial criteria to establish citizenship rights and regulate who was eligible to become a naturalized citizen. The Naturalization Act of 1790, the first law in U.S. history to establish rules for citizenship and naturalization, barred citizenship to all people who were not of European descent, stating that \"any alien being a free white person, who shall have resided within the limits and under the jurisdiction of the United States for the term of two years, may be admitted to become a citizen thereof.\"\n\nUnder early U.S. laws, African Americans were not eligible for citizenship. In 1857, these laws were upheld in the US Supreme Court case Dred Scott v. Sandford, which ruled that \"a free negro of the African race, whose ancestors were brought to this country and sold as slaves, is not a 'citizen' within the meaning of the Constitution of the United States,\" and that \"the special rights and immunities guarantied to citizens do not apply to them.\"\n\nIt was not until the abolition of slavery following the American Civil War that African Americans were granted citizenship rights. The 14th Amendment to the U.S. Constitution, ratified on July 9, 1868, stated that \"all persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside.\" Two years later, the Naturalization Act of 1870 would extend the right to become a naturalized citizen to include \"aliens of African nativity and to persons of African descent\".\n\nDespite the gains made by African Americans after the Civil War, Native Americans, Asians, and others not considered \"free white persons\" were still denied the ability to become citizens. The 1882 Chinese Exclusion Act explicitly denied naturalization rights to all people of Chinese origin, while subsequent acts passed by the US Congress, such as laws in 1906, 1917, and 1924, would include clauses that denied immigration and naturalization rights to people based on broadly defined racial categories. Supreme Court cases such as Ozawa v. United States (1922) and U.S. v. Bhagat Singh Thind (1923), would later clarify the meaning of the phrase \"free white persons,\" ruling that ethnically Japanese, Indian, and other non-European people were not \"white persons\", and were therefore ineligible for naturalization under U.S. law.\n\nNative Americans were not granted full US citizenship until the passage of the Indian Citizenship Act in 1924. However, even well into the 1960s some state laws prevented Native Americans from exercising their full rights as citizens, such as the right to vote. In 1962, New Mexico became the last state to enfranchise Native Americans.\n\nIt was not until the passage of the Immigration and Nationality Act of 1952 that the racial and gender restrictions for naturalization were explicitly abolished. However, the act still contained restrictions regarding who was eligible for US citizenship, and retained a national quota system which limited the number of visas given to immigrants based on their national origin, to be fixed \"at a rate of one-sixth of one percent of each nationality's population in the United States in 1920\". It was not until the passage of the Immigration and Nationality Act of 1965 that these immigration quota systems were drastically altered in favor of a less discriminatory system.\n\nThe 1918 constitution of revolutionary Russia granted citizenship to any foreigners who were living within Russia, so long as they were \"engaged in work and [belonged] to the working class.\" It recognized \"the equal rights of all citizens, irrespective of their racial or national connections\" and declared oppression of any minority group or race \"to be contrary to the fundamental laws of the Republic.\" The 1918 constitution also established the right to vote and be elected to soviets for both men and women \"irrespective of religion, nationality, domicile, etc. [...] who shall have completed their eighteenth year by the day of election.\" The later constitutions of the USSR would grant universal Soviet citizenship to the citizens of all member republics in concord with the principles of non-discrimination laid out in the original 1918 constitution of Russia.\n\nNational Socialism or \"Nazism\", the German variant of twentieth century fascism whose precepts were laid out in Adolf Hitler's Mein Kampf, classified inhabitants of the nation into three main hierarchical categories, each of which would have different rights and duties in relation to the state: citizens, subjects, and aliens. The first category, citizens, were to possess full civic rights and responsibilities. Citizenship would be conferred only on males of German (or so-called \"Aryan\") heritage who had completed military service, and could be revoked at any time by the state. The Reich Citizenship Law of 1935 established racial criteria for citizenship in the German Reich, and because of this law Jews and others who could not prove \"German\" racial heritage were stripped of their citizenship.\n\nThe second category, subjects, referred to all others who were born within the nation's boundaries who did not fit the racial criteria for citizenship. Subjects would have no voting rights, could not hold any position within the state, and possessed none of the other rights and civic responsibilities conferred on citizens. All women were to be conferred \"subject\" status upon birth, and could only obtain \"citizen\" status if they worked independently or if they married a German citizen (see women in Nazi Germany).\n\nThe final category, aliens, referred to those who were citizens of another state, who also had no rights.\n\nCitizenship status, under social contract theory, carries with it both rights and duties. In this sense, citizenship was described as \"a bundle of rights -- primarily, political participation in the life of the community, the right to vote, and the right to receive certain protection from the community, as well as obligations.\" Citizenship is seen by most scholars as culture-specific, in the sense that the meaning of the term varies considerably from culture to culture, and over time. In China, for example, there is a cultural politics of citizenship which could be called \"peopleship\". \n\nHow citizenship is understood depends on the person making the determination. The relation of citizenship has never been fixed or static, but constantly changes within each society. While citizenship has varied considerably throughout history, and within societies over time, there are some common elements but they vary considerably as well. As a bond, citizenship extends beyond basic kinship ties to unite people of different genetic backgrounds. It usually signifies membership in a political body. It is often based on, or was a result of, some form of military service or expectation of future service. It usually involves some form of political participation, but this can vary from token acts to active service in government. \n\nCitizenship is a status in society. It is an ideal state as well. It generally describes a person with legal rights within a given political order. It almost always has an element of exclusion, meaning that some people are not citizens, and that this distinction can sometimes be very important, or not important, depending on a particular society. Citizenship as a concept is generally hard to isolate intellectually and compare with related political notions, since it relates to many other aspects of society such as the family, military service, the individual, freedom, religion, ideas of right and wrong, ethnicity, and patterns for how a person should behave in society. When there are many different groups within a nation, citizenship may be the only real bond which unites everybody as equals without discrimination—it is a \"broad bond\" linking \"a person with the state\" and gives people a universal identity as a legal member of a specific nation.\n\nModern citizenship has often been looked at as two competing underlying ideas:\n\n\nScholars suggest that the concept of citizenship contains many unresolved issues, sometimes called tensions, existing within the relation, that continue to reflect uncertainty about what citizenship is supposed to mean. Some unresolved issues regarding citizenship include questions about what is the proper balance between duties and rights. Another is a question about what is the proper balance between political citizenship versus social citizenship. Some thinkers see benefits with people being absent from public affairs, since too much participation such as revolution can be destructive, yet too little participation such as total apathy can be problematic as well. Citizenship can be seen as a special elite status, and it can also be seen as a democratizing force and something that everybody has; the concept can include both senses. According to sociologist Arthur Stinchcombe, citizenship is based on the extent that a person can control one's own destiny within the group in the sense of being able to influence the government of the group. One last distinction within citizenship is the so-called consent descent distinction, and this issue addresses whether citizenship is a fundamental matter determined by a person choosing to belong to a particular nation––by his or her consent––or is citizenship a matter of where a person was born––that is, by his or her descent.\n\nSome intergovernmental organizations have extended the concept and terminology associated with citizenship to the international level, where it is applied to the totality of the citizens of their constituent countries combined. Citizenship at this level is a secondary concept, with rights deriving from national citizenship.\n\nThe Maastricht Treaty introduced the concept of citizenship of the European Union. Article 17 (1) of the Treaty on European Union stated that: Citizenship of the Union is hereby established. Every person holding the nationality of a Member State shall be a citizen of the Union. Citizenship of the Union shall be additional to and not replace national citizenship.\n\nAn agreement known as the amended EC Treaty established certain minimal rights for European Union citizens. Article 12 of the amended EC Treaty guaranteed a general right of non-discrimination within the scope of the Treaty. Article 18 provided a limited right to free movement and residence in Member States other than that of which the European Union citizen is a national. Articles 18-21 and 225 provide certain political rights.\n\nUnion citizens have also extensive rights to move in order to exercise economic activity in any of the Member States which predate the introduction of Union citizenship.\n\nThe concept of \"Commonwealth Citizenship\" has been in place ever since the establishment of the Commonwealth of Nations. As with the EU, one holds Commonwealth citizenship only by being a citizen of a Commonwealth member state. This form of citizenship offers certain privileges within some Commonwealth countries:\n\nAlthough Ireland was excluded from the Commonwealth in 1949 because it declared itself a republic, Ireland is generally treated as if it were still a member. Legislation often specifically provides for equal treatment between Commonwealth countries and Ireland and refers to \"Commonwealth countries and Ireland\". Ireland's citizens are not classified as foreign nationals in the United Kingdom.\n\nCanada departed from the principle of nationality being defined in terms of allegiance in 1921. In 1935 the Irish Free State was the first to introduce its own citizenship. However, Irish citizens were still treated as subjects of the Crown, and they are still not regarded as foreign, even though Ireland is not a member of the Commonwealth. The Canadian Citizenship Act of 1947 provided for a distinct Canadian Citizenship, automatically conferred upon most individuals born in Canada, with some exceptions, and defined the conditions under which one could become a naturalized citizen. The concept of Commonwealth citizenship was introduced in 1948 in the British Nationality Act 1948. Other dominions adopted this principle such as New Zealand, by way of the British Nationality and New Zealand Citizenship Act of 1948.\n\nCitizenship most usually relates to membership of the nation state, but the term can also apply at the subnational level. Subnational entities may impose requirements, of residency or otherwise, which permit citizens to participate in the political life of that entity, or to enjoy benefits provided by the government of that entity. But in such cases, those eligible are also sometimes seen as \"citizens\" of the relevant state, province, or region. An example of this is how the fundamental basis of Swiss citizenship is citizenship of an individual commune, from which follows citizenship of a canton and of the Confederation. Another example is Åland where the residents enjoy a special provincial citizenship within Finland, \"hembygdsrätt\".\n\nThe United States has a federal system in which a person is a citizen of their specific state of residence, such as New Jersey or California, as well as a citizen of the United States. State constitutions may grant certain rights above and beyond what are granted under the United States Constitution and may impose their own obligations including the sovereign right of taxation and military service; each state maintains at least one military force subject to national militia transfer service, the state's national guard, and some states maintain a second military force not subject to nationalization.\n\n\"Active citizenship\" is the philosophy that citizens should work towards the betterment of their community through economic participation, public, volunteer work, and other such efforts to improve life for all citizens. In this vein, citizenship education is taught in schools, as an academic subject in some countries. By the time children reach secondary education there is an emphasis on such unconventional subjects to be included in academic curriculum. While the diagram on citizenship to the right is rather facile and depth-less, it is simplified to explain the general model of citizenship that is taught to many secondary school pupils. The idea behind this model within education is to instill in young pupils that their actions (i.e. their vote) affect collective citizenship and thus in turn them.\n\nIt is taught in the Republic of Ireland as an exam subject for the Junior Certificate. It is known as Civic, Social and Political Education (CSPE). A new Leaving Certificate exam subject with the working title 'Politics & Society' is being developed by the National Council for Curriculum and Assessment (NCCA) and is expected to be introduced to the curriculum sometime after 2012.\n\nCitizenship is offered as a General Certificate of Secondary Education (GCSE) course in many schools in the United Kingdom. As well as teaching knowledge about democracy, parliament, government, the justice system, human rights and the UK's relations with the wider world, students participate in active citizenship, often involving a social action or social enterprise in their local community.\n\nThere are two kinds of criticism of citizenship education in schools. Firstly, some philosophers of education argue that most governments and mainstream policies stimulate and advocate questionable approaches of citizenship education. These approaches aim to develop specific dispositions in students, dispositions conducive to political participation and solidarity. But there are radically different views on the nature of good citizenship and education should involve and develop autonomy and open-mindedness. Therefore, it requires a more critical approach than is possible when political participation and solidarity are conceived of as goals of education. Secondly, some educationalists argue that merely teaching children about the theory of citizenship is ineffective, unless schools themselves reflect democratic practices by giving children the opportunity to have a say in decision making. They suggest that schools are fundamentally undemocratic institutions, and that such a setting cannot instill in children the commitment and belief in democratic values that is necessary for citizenship education to have a proper impact. Some educationalists relate this criticism to John Dewey (see critical comments on this interpretation of Dewey: Van der Ploeg, 2016).\n\n\n\n\n"}
{"id": "307342", "url": "https://en.wikipedia.org/wiki?curid=307342", "title": "Civil liberties in the United States", "text": "Civil liberties in the United States\n\nCivil liberties in the United States are certain unalienable rights retained by (as opposed to privileges granted to) citizens of the United States under the Constitution of the United States, as interpreted and clarified by the Supreme Court of the United States and lower federal courts. Civil liberties are simply defined as individual legal and constitutional protections from entities more powerful than an individual, for example, parts of the government, other individuals, or corporations. The liberties explicitly defined, make up the Bill of Rights, including freedom of speech, the right to bear arms, and the right to privacy. There are also many liberties of people not defined in the Constitution, as stated in the Ninth Amendment: \"The enumeration in the Constitution, of certain rights, shall not be construed to deny or disparage others retained by the people.\" \n\nThe extent of civil liberties and the periphery of the population of the United States who had access to these liberties has expanded over time. For example, the Constitution did not originally define who was eligible to vote, allowing each state to determine who was eligible. In the early history of the U.S., most states allowed only white male adult property owners to vote (about 6% of the population). The 'Three-Fifths Compromise' allowed the southern slaveholders to consolidate power and maintain slavery in America for eighty years after the ratification of the Constitution. And the Bill of Rights had little impact on judgements by the courts for the first 130 years after ratification.\n\nThe text of Amendment I to the United States Constitution, ratified December 15, 1791, states that:\n\nThe text of Amendment I to the United States Constitution, ratified December 15, 1791, states that:\n\nThe text of Amendment I to the United States Constitution, ratified December 15, 1791, states that:\n\nThe text of Amendment I to the United States Constitution, ratified December 15, 1791, states that:\n\nThe text of Amendment I to the United States Constitution, ratified December 15, 1791, states that:\n\nThe following types of speech are not protected constitutionally: defamation or false statements, child pornography, obscenity, damaging the national security interests, verbal acts, and fighting words. Because these categories fall outside of the First Amendment privileges, the courts can legally restrict or criminalize any expressive act within them. Other expressions, including threat of bodily harm or publicizing illegal activity, may also be ruled illegal.\n\nThe text of Amendment II to the United States Constitution, ratified December 15, 1791, states that:\n\nThe concept of sexual freedom includes a broad range of different rights that are not mentioned in the U.S. Constitution. The idea of sexual freedom has sprung more from the popular opinion of society in more recent years, and has had very little Constitutional backing. The following liberties are included under sexual freedom: sexual expression, sexual choices, sexual education, reproductive justice, and sexual health. Sexual freedom in general is considered an implied procedure, and is not mentioned in the Constitution. \n\nSexual freedoms include the freedom to have consensual sex with whomever a person chooses, at any time, for any reason, provided the person is of the age of majority. Marriage is not required, nor are there any requirements as to the gender or number of people you have sex with. Sexual freedom includes the freedom to have private consensual homosexual sex (\"Lawrence v. Texas\").\n\nEqual protection prevents the government from creating laws that are discriminatory in application or effect.\n\nThe text of Amendment XIV to the United States Constitution, ratified July 9, 1868, states that:\n\nThe text of Amendment XV to the United States Constitution, ratified February 3, 1870, states that:\n\nThe text of Amendment XIX to the United States Constitution, ratified August 18, 1919, states that:\n\nThe text of Amendment XXIII to the United States Constitution, ratified January 23, 1964, states that:\n\nThe text of Amendment XXVI to the United States Constitution, ratified July 1, 1971, states that:\n\nIn the 1967 United States Supreme Court ruling in the case of \"Loving v. Virginia\" found a fundamental right to marriage, regardless of race. In the 2015 United States Supreme Court ruling in the case of \"Obergefell v. Hodges\" found a fundamental right to marriage, regardless of gender.\n\n"}
{"id": "1364686", "url": "https://en.wikipedia.org/wiki?curid=1364686", "title": "Cognitive liberty", "text": "Cognitive liberty\n\nCognitive liberty, or the \"right to mental self-determination\", is the freedom of an individual to control his or her own mental processes, cognition, and consciousness. It has been argued to be both an extension of, and the principle underlying, the right to freedom of thought. Though a relatively recently defined concept, many theorists see cognitive liberty as being of increasing importance as technological advances in neuroscience allow for an ever-expanding ability to directly influence consciousness. Cognitive liberty is not a recognized right in any international human rights treaties, but has gained a limited level of recognition in the United States, and is argued to be the principle underlying a number of recognized rights.\n\nThe term \"cognitive liberty\" was coined by neuroethicist Dr. Wrye Sententia and legal theorist and lawyer Richard Glen Boire, the founders and directors of the non-profit Center for Cognitive Liberty and Ethics (CCLE). Sententia and Boire define cognitive liberty as \"the right of each individual to think independently and autonomously, to use the full power of his or her mind, and to engage in multiple modes of thought.\"\n\nSententia and Boire conceived of the concept of cognitive liberty as a response to the increasing ability of technology to monitor and manipulate cognitive function, and the corresponding increase in the need to ensure individual cognitive autonomy and privacy. Sententia divides the practical application of cognitive liberty into two principles:\n\n\nThese two facets of cognitive liberty are reminiscent of Timothy Leary's \"Two Commandments for the Molecular Age\", from his 1968 book \"The Politics of Ecstasy\":\n\nSupporters of cognitive liberty therefore seek to impose both a negative and a positive obligation on states: to refrain from non-consensually interfering with an individual's cognitive processes, and to allow individuals to self-determine their own \"inner realm\" and control their own mental functions.\n\nThis first obligation, to refrain from non-consensually interfering with an individual's cognitive processes, seeks to protect individuals from having their mental processes altered or monitored without their consent or knowledge, \"setting up a defensive wall against unwanted intrusions\". Ongoing improvements to neurotechnologies such as transcranial magnetic stimulation and electroencephalography (or \"brain fingerprinting\"); and to pharmacology in the form of selective serotonin reuptake inhibitors (SSRIs), Nootropics, Modafinil and other psychoactive drugs, are continuing to increase the ability to both monitor and directly influence human cognition. As a result, many theorists have emphasized the importance of recognizing cognitive liberty in order to protect individuals from the state using such technologies to alter those individuals’ mental processes: \"states must be barred from invading the inner sphere of persons, from accessing their thoughts, modulating their emotions or manipulating their personal preferences.\"\n\nThis element of cognitive liberty has been raised in relation to a number of state-sanctioned interventions in individual cognition, from the mandatory psychiatric 'treatment' of homosexuals in the US before the 1970s, to the non-consensual administration of psychoactive drugs to unwitting US citizens during CIA Project MKUltra, to the forcible administration of mind-altering drugs on individuals to make them competent to stand trial. Futurist and bioethicist George Dvorsky, Chair of the Board of the Institute for Ethics and Emerging Technologies has identified this element of cognitive liberty as being of relevance to the debate around the curing of autism spectrum conditions. Duke University School of Law Professor Nita Farahany has also proposed legislative protection of cognitive liberty as a way of safeguarding the protection from self-incrimination found in the Fifth Amendment to the US Constitution, in the light of the increasing ability to access human memory.\n\nThough this element of cognitive liberty is often defined as an individual’s freedom from \"state\" interference with human cognition, Jan Christoph Bublitz and Reinhard Merkel among others suggest that cognitive liberty should also prevent other, non-state entities from interfering with an individual’s mental \"inner realm\". Bublitz and Merkel propose the introduction of a new criminal offense punishing \"interventions severely interfering with another’s mental integrity by undermining mental control or exploiting pre-existing mental weakness.\" Direct interventions that reduce or impair cognitive capacities such as memory, concentration, and willpower; alter preferences, beliefs, or behavioral dispositions; elicit inappropriate emotions; or inflict clinically identifiable mental injuries would all be \"prima facie\" impermissible and subject to criminal prosecution. Sententia and Boire have also expressed concern that corporations and other non-state entities might utilize emerging neurotechnologies to alter individuals' mental processes without their consent.\n\nWhere the first obligation seeks to protect individuals from interference with cognitive processes by the state, corporations or other individuals, this second obligation seeks to ensure that individuals have the freedom to alter or enhance their own consciousness. An individual who enjoys this aspect of cognitive liberty has the freedom to alter their mental processes in any way they wish to; whether through indirect methods such as meditation, yoga or prayer; or through direct cognitive intervention through psychoactive drugs or neurotechnology.\n\nAs psychotropic drugs are a powerful method of altering cognitive function, many advocates of cognitive liberty are also advocates of drug law reform; claiming that the \"war on drugs\" is in fact a \"war on mental states\". The CCLE, as well as other cognitive liberty advocacy groups such as Cognitive Liberty UK, have lobbied for the re-examination and reform of prohibited drug law; one of the CCLE's key guiding principles is that: \"governments should not criminally prohibit cognitive enhancement or the experience of any mental state\". Calls for reform of restrictions on the use of prescription cognitive-enhancement drugs (also called smart drugs or nootropics) such as Prozac, Ritalin and Adderall have also been made on the grounds of cognitive liberty.\n\nThis element of cognitive liberty is also of great importance to proponents of the transhumanist movement, a key tenet of which is the enhancement of human mental function. Dr Wrye Sententia has emphasized the importance of cognitive liberty in ensuring the freedom to pursue human mental enhancement, as well as the freedom to choose against enhancement. Sententia argues that the recognition of a \"right to (and not to) direct, modify, or enhance one's thought processes\" is vital to the free application of emerging neurotechnology to enhance human cognition; and that something beyond the current conception of freedom of thought is needed. Sententia claims that \"cognitive liberty's strength is that it protects those who do want to alter their brains, but also those who do not\".\n\nCognitive liberty is not currently recognized as a human right by any international human rights treaty. While freedom of thought is recognized by Article 18 of the Universal Declaration of Human Rights (UDHR), freedom of thought can be distinguished from cognitive liberty in that the former is concerned with protecting an individual’s freedom to think \"whatever\" they want, whereas cognitive liberty is concerned with protecting an individual’s freedom to think \"however\" they want. Cognitive liberty seeks to protect an individual’s right to determine their own state of mind and be free from external control over their state of mind, rather than just protecting the content of an individuals’ thoughts. \nIt has been suggested that the lack of protection of cognitive liberty in previous human rights instruments was due to the relative lack of technology capable of directly interfering with mental autonomy at the time the core human rights treaties were created. As the human mind was considered invulnerable to direct manipulation, control or alteration, it was deemed unnecessary to expressly protect individuals from unwanted mental interference. With modern advances in neuroscience and in anticipation of its future development however, it is argued that such express protection is becoming increasingly necessary.\n\nCognitive liberty then can be seen as an extension of or an \"update\" to the right to freedom of thought as it has been traditionally understood. Freedom of thought should now be understood to include the right to determine one’s own mental state as well as the content of one’s thoughts. However, some have instead argued that cognitive liberty is already an inherent part of the international human rights framework as the principle underlying the rights to freedom of thought, expression and religion. The freedom to think in whatever manner one chooses is a \"necessary precondition to those guaranteed freedoms.\" Daniel Waterman and Casey William Hardison have argued that cognitive liberty is fundamental to Freedom of Thought because it encompasses the ability to have certain types of experiences, including the right to experience altered or non-ordinary states of consciousness. It has also been suggested that cognitive liberty can be seen to be a part of the inherent dignity of human beings as recognized by Article 1 of the UDHR.\n\nMost proponents of cognitive liberty agree however that cognitive liberty should be expressly recognized as a human right in order to properly provide protection for individual cognitive autonomy.\n\nRichard Glen Boire of the Center for Cognitive Liberty and Ethics filed an \"amicus\" brief with the US Supreme Court in the case of \"Sell v. United States\", in which the Supreme Court examined whether the court had the power to make an order to forcibly administer antipsychotic medication to an individual who had refused such treatment, for the sole purpose of making them competent to stand trial.\n\nIn the case of \"R v Hardison\", the defendant, charged with eight counts under the Misuse of Drugs Act 1971 (MDA), including the production of DMT and LSD, claimed that cognitive liberty was safeguarded by Article 9 of the European Convention on Human Rights. Hardison argued that \"individual sovereignty over one's interior environment constitutes the very core of what it means to be free\", and that as psychotropic drugs are a potent method of altering an individual's mental process, prohibition of them under the MDA was in opposition to Article 9. The court however disagreed, calling Hardison's arguments a \"portmanteau defense\" and relying upon the UN Drug Conventions and the earlier case of \"R v Taylor\" to deny Hardison's right to appeal to a superior court. Hardison was convicted and given a 20-year prison sentence, though he was released on 29 May 2013 after nine years in prison.\n\nWhile there has been little publicized criticism of the concept of cognitive liberty itself, drug policy reform and the concept of human enhancement, both closely linked to cognitive liberty, remain highly controversial issues. The risks inherent in removing restrictions on controlled cognitive-enhancing drugs, including of widening the gap between those able to afford such treatments and those unable to do so, have caused many to remain skeptical about the wisdom of recognizing cognitive liberty as a right. Political philosopher and Harvard University professor Michael J. Sandel, when examining the prospect of memory enhancement, wrote that \"some who worry about the ethics of cognitive enhancement point to the danger of creating two classes of human beings – those with access to enhancement technologies, and those who must make do with an unaltered memory that fades with age.\" Cognitive liberty then faces opposition obliquely in these interrelated debates.\n"}
{"id": "884309", "url": "https://en.wikipedia.org/wiki?curid=884309", "title": "Confiscation", "text": "Confiscation\n\nConfiscation (from the Latin \"confiscare\" \"to consign to the \"fiscus\", i.e. transfer to the treasury\") is a legal form of seizure by a government or other public authority. The word is also used, popularly, of spoliation under legal forms, or of any seizure of property as punishment or in enforcement of the law.\n\nAs a punishment, it differs from a fine in that it is not primarily meant to match the crime but rather reattributes the criminal's ill-gotten spoils (often as a complement to the actual punishment for the crime itself; still common with various kinds of contraband, such as protected living organisms) to the community or even aims to rob them of their socio-economic status, in the extreme case reducing them to utter poverty, or if he or she is condemned to death even denies them inheritance to the legal heirs.\n\nMeanwhile, limited confiscation is often in function of the crime, the rationale being that the criminal must be denied the fruits of their fault, while the crime itself is rather punished in some other, independent way, such as physical punishments or even a concurring fine.\n\nOften, police will auction items confiscated via police auction or asset forfeiture and keep the proceeds. Theoretically, it is possible for owners to buy back confiscated items. \n\nIn airports, potentially dangerous items (such as hazardous chemicals, weapons, and sharp objects) are usually confiscated at inspections. Other items, such as certain food, may also be confiscated, depending on importation laws. Depending on the nature of the items, some may be returned at the end of the flight, while most are discarded or auctioned off. The musical comedian Anna Russell had an Irish harp confiscated by the U.S. Customs Service.\n\nOriginally, in Roman law, confiscation was the seizure and transfer of private property to the \"fiscus\" (treasury) by the emperor; hence the appropriation, under legal authority, of private property to the state.\n\nIn modern English law, confiscation embraces forfeiture in the case of goods, and escheat in the case of lands, for crime or in default of heirs (see also Eminent domain). Goods may also be confiscated by the state for breaches of statutes relating to customs, excise or explosives. In the United Kingdom a confiscation order is a court order made under part 2 (England & Wales), part 3 (Scotland) or part 4 (Northern Ireland) of the Proceeds of Crime Act 2002 requiring a convicted defendant to pay a specified sum of money to the state by a specified date.\n\nDuring the American Revolution, customs racketeering became a serious problem. By harshly enforcing customs laws, particularly the more obscure regulations, corrupt customs officials could seize property almost with impunity. This caused significant conflict between the United States and Great Britain.\n\nIn the United States among the \"war measures\" during the American Civil War, acts were passed in 1861 and 1862 confiscating, respectively, property used for \"insurrectionary purposes\" and the property generally of those engaged in rebellion.\n\nThere was from the late 1980s onwards a resurgence of interest in confiscation as crime prevention tool, which went hand in hand with the interest in the criminalization of money laundering. A number of international instruments, starting with the 1988 Vienna Convention, have strongly suggested the enactment of legal provisions enabling confiscation of proceeds of crime. The 40 recommendations of the FATF have also stated its importance as a crime prevention tool.\n\nA further trend has been the reversal of the burden of proof for the purpose of facilitating confiscation. To the surprise of many, it is actually quite legal for law enforcement agencies to take property from people who haven't been convicted of a crime yet as civil asset forfeiture, a practice which brings in millions of dollars of revenue each year, disproportionately affecting people without means or access to a lawyer. \n\n\n"}
{"id": "35297513", "url": "https://en.wikipedia.org/wiki?curid=35297513", "title": "Culturagram", "text": "Culturagram\n\nA culturagram is a family assessment tool used in the practice of social work which was first introduced by Fordham University professor, Dr. Elaine Congress.\n\nIn social work and other fields, cultural competence is an important skill. As the number and diversity of immigrants has increased dramatically in the United States (Camarota, 2007) there is increased need for clinicians to understand the cultural backgrounds of their clients. A culturagram is a family assessment tool that provides a graphical representation of various aspects of an individual and family's culture.\n\nIt can be helpful in assessment and intervention planning for culturally diverse families. This tool grew out of the recognition that families are becoming increasingly culturally diverse and social workers must be able to understand cultural differences between and within families. When attempting to understand culturally diverse families, families needed to be understood within a cultural context. Assessing a family only in terms of a specific cultural identity, however, may lead to overgeneralization and stereotyping (Congress & Kung, 2013). A Puerto Rican family in which all members are American citizens and have lived in the United States for 20 years is very different from an undocumented Mexican family that emigrated last month. Yet both families are considered Hispanic/Latino. Even within the same family group, each member has had a different immigration and acculturation experience, as often family members immigrate at different times and some members may be U.S. citizens, while others are undocumented. Furthermore, family members who regularly work or attend school in the larger community may be more acculturated than those who stay at home.\n\nWhile the eco-map (Hartman, 1995) and genogram (McGoldrick, Gerson, & Perry, 2008) are useful tools in assessing the family, neither emphasize the important role of culture in understanding the family. The culturagram was developed to help in understanding the cultural background of culture in families (Congress, 1994, 1997; Congress & Kung, 2013). This tool has been applied to work with people of color (Lum, 2004), battered women (Congress & Brownell, 2007), children (Congress, 2001), older people (Brownell & Fenley, 2009), families in crisis (Congress, 2000), Mexican families (Congress, 2004a), Latino and Asian families (Congress & Kung, 2005), immigrant families with health problems (Congress, 2004b; Congress, 2013) and in family development theory (Congress, 2008).\n\nThe culturagram represents an attempt to individualize culturally diverse families (Congress & Kung, 2013). Completing a culturagram on a family can help a clinician develop a better understanding of the family. First developed in 1994 and then revised in 2000 and again in 2009, the culturagram examines the following areas:\n\nThe culturagram has been seen as an essential tool in helping social workers work more effectively with families from many different cultures. Not only does it help the social worker achieve greater understanding of the culture of a family, it can also point the way toward future treatment. The culturagram can be useful in arriving at decisions about treatment planning and intervention. While using the culturagram the practitioner is required to look at the family in the here and now. Sometimes it is helpful, however, to construct the culturagram at different points of time, first at the beginning of intervention and then at a future point. In constructing the culturagram a retrospective approach is also useful. To truly understand immigrant families learning about an immigrant’s history is important. For example, the social worker can study what was the immigrants’ experience in their country of origin and in transit. Often a developmental approach that looks at three stages of immigration (pre-migration, transit, and current situation) is helpful in working with immigrants. (Drachman, 2004). For example, refugees may have had particularly traumatic experiences in their country of origin and undocumented immigrants through the transit period that may affect their current psychological well being in the United States.\nCurrent practice looks to evidence that specific interventions are effective. Students and practitioners have used the culturagram in their professional practice with families and reported that it is helpful in engaging families in a nonthreatening way. In the use of the culturagram culture is viewed through a multidimensional lens, rather than as a monolithic entity. Initial evaluation of the culturagram has been positive, and there are further plans to assess further its effectiveness in promoting culturally competent practice.\n\nWith the increased number of immigrants in the United States, there will be greater demand for culturally competent practice with immigrant clients and families. Social workers will need to study what methods and models are the most effective. The culturagram emerges as a useful method to better understand and plan interventions with immigrant families\n\n\n"}
{"id": "19176602", "url": "https://en.wikipedia.org/wiki?curid=19176602", "title": "Double mass analysis", "text": "Double mass analysis\n\nDouble mass analysis is a commonly used data analysis approach for investigating the behaviour of records made of hydrological or meteorological data at a number of locations. It is used to determine whether there is a need for corrections to the data - to account for changes in data collection procedures or other local conditions. Such changes may result from a variety of things including changes in instrumentation, changes in observation procedures, or changes in gauge location or surrounding conditions. Double mass analysis for checking consistency of a hydrological or meteorological record is considered to be an essential tool before taking it for analysis purpose. This method is based on the hypothesis that each item of the recorded data of a population is consistent.\n\nAn example of a double mass analysis is a \"double mass plot\", or \"double mass curve\". For this, points and/or a joining line are plotted where the x- and y- coordinates are determined by the running totals of the values observed at two stations. If both stations are affected to the same extent by the same trends then a double mass curve should follow a straight line. A break in the slope of the curve would indicate that conditions have changed at one location but not at another.\nThis technique is based on the principle that when each recorded data comes from the same parent population, they are consistent.\n\n\n"}
{"id": "652109", "url": "https://en.wikipedia.org/wiki?curid=652109", "title": "Edge case", "text": "Edge case\n\nAn edge case is a problem or situation that occurs only at an extreme (maximum or minimum) operating parameter. For example, a stereo speaker might noticeably distort audio when played at maximum volume, even in the absence of any other extreme setting or condition.\n\nAn edge case can be expected or unexpected. In engineering, the process of planning for and gracefully addressing edge cases can be a significant task, and yet this task may be overlooked or underestimated.\n\nNon-trivial edge cases can result in the failure of an object that is being engineered. They may not have been foreseen during the design phase. And they may not have been thought possible during normal use of the object. For this reason, attempts to formalize good engineering standards often include information about edge cases.\n\nIn programming, an edge case typically involves input values that require special handling in an algorithm behind a computer program. As a measure for validating the behavior of computer programs in such cases, unit tests are usually created; they are testing boundary conditions of an algorithm, function or method. A series of edge cases around each \"boundary\" can be used to give reasonable coverage and confidence using the assumption that if it behaves correctly at the edges, it should behave everywhere else.\n\nFor example, a function that divides two numbers might be tested using both very large and very small numbers. This assumes that if it works for both ends of the magnitude spectrum, it should work correctly in between.\n\n"}
{"id": "8738170", "url": "https://en.wikipedia.org/wiki?curid=8738170", "title": "English-medium education", "text": "English-medium education\n\nAn \"English-medium education\" system is one that uses English as the primary medium of instruction—particularly where English is not the mother tongue of the students.\n\nInitially associated with the expansion of English from its homeland in England and the lowlands of Scotland and its spread to the rest of Great Britain and Ireland, the rise of the British Empire increased the language's spread, as has the increased economic and cultural influence of the United States since World War II.\n\nA working knowledge of English is perceived as being valuable; for example, English is very dominant in the world of computing. As a result, many states throughout the world where English is not the predominant language encourage or mandate the use of English as the normal medium of instruction.\n\nEducation is a provincial matter under the Canadian constitution, section 92. French language rights have been guaranteed in the province of Quebec since the Treaty of Paris 1763, French outside of Quebec and all other minority languages have faced laws against them at one time or another. English-only education laws were gradually rolled out across Canada during the nineteenth and twentieth century, culminating in the Manitoba Schools Question 1896 and Regulation 17 in Ontario in 1912, which both attacked French and other European minority languages, and the Indian residential schools system which attacked Aboriginal languages.\n\nThese policies were gradually abolished in the wake of Canada's adoption of official bilingualism (French/English) in 1969 and multiculturalism in 1971, but English remains the predominant language of education outside of Quebec and New Brunswick.\n\nThe Laws in Wales Acts 1535–1542, passed by the Parliament of England, annexing Wales to the Kingdom of England are sometimes known as the \"Acts of Union.\"\n\nAn often quoted example of the effects on the Welsh language is the first section of the 1535 Act, which states: \"the people of the same dominion have and do daily use a speche nothing like ne consonant to the naturall mother tonge used within this Realme\" and then declares the intention \"utterly to extirpe alle and singular sinister usages and customs\" belonging to Wales.\n\nSection 20 of the 1535 Act makes English the only language of the law courts and that those who used Welsh would not be appointed to any public office in Wales: \nAn effect of this language clause was to lay the foundation for creating a thoroughly Anglicised ruling class of landed gentry in Wales, which would have many consequences.\n\nThe parts of the 1535 Act relating to language were definitively repealed only in 1993, by the Welsh Language Act 1993, though annotations on the Statute Law Database copy of the act reads that sections 18–21 were repealed by the Statute Law Revision Act 1887.\n\nIn July 1846, the British Government appointed three commissioners to enquire into the state of education in Wales; the Commissioners were all monoglot English-speakers.\n\nThe Commissioners reported to the Government on 1 July 1847 in three large blue-bound volumes. This report quickly became known as \"Brad y Llyfrau Gleision\" (The Treachery of the Blue Books) as, apart from documenting the state of education in Wales, the Commissioners were also free with their comments disparaging the language, Non-conformity, and the morals of the Welsh people in general. An immediate effect of the report was for a belief to take root in the minds of ordinary people that the only way for Welsh people to get on in the world was through the medium of English, and an inferiority complex developed about the Welsh language whose effects have not yet been completely eradicated. The historian Professor Kenneth O. Morgan referred to the significance of the report and its consequences as \"the Glencoe and the Amritsar of Welsh history\".\n\nThe poet Edmund Spenser wrote in (1596) a recommendation that \"the Irish ... be educated in English, in grammar and in science ... for learning hath that wonderful power of itself that it can soften and temper the most stern and savage nature.\"\n\nThe setting up of 'Royal Schools' in Ireland, was proclaimed in 1608 by James I, with the intended purpose \"that there shall be one Free School at least appointed in every County, for the education of youth in learning and religion.\"\n\nThese schools provided an English-medium education to the sons of landed settlers in Ireland, most of whom were of Scottish or English descent.\n\nHowever, only five such schools were actually set up; The Royal School, Armagh in County Armagh, Portora Royal School in County Fermanagh, The Cavan Royal School in County Cavan, The Royal School Dungannon in Tyrone and The Royal and Prior School in County Donegal.\n\nThe \"National Education System\" (sic) was founded in 1831, by the British Government, under the direction of the Chief Secretary, E.G. Stanley. Some 2,500 national schools were established in Ulster in the period 1832–1870, built with the aid of the Commissioners of National Education and local trustees.\n\nProf. S. Ó Buachalla states:\n\nDuring the first four decades of their existence, there is no mention of the Irish language in the programme of regulations of the Commissioners of National Education; furthermore no provision whatsoever was made in 1831 when the original scheme was drawn up for education of those children who spoke Irish only. According to the official opinion of later Commissioners, expressed in a formal reply to the Chief Secretary in 1884, \" the anxiety of the promoters of the National Scheme was to encourage the cultivation of the English language.\n\nThe Irish patriot P.H. Pearse published a series of studies of the English-medium education system in Ireland. His article entitled The Murder Machine embodies an article which appeared in the Irish Review for February 1913.\n\nPearse wrote in his pamphlet the following:\n\nAnd English education in Ireland has seemed: to some like the bed of Procustes, the bed on which all men that passed that way must lie, be it never so big for them, be it never so small for them: the traveller for whom it was too large had his limbs stretched until he filled it; the traveller for whom it was too small had his limbs chopped off until he fitted into it—comfortably. It was a grim jest to play upon travellers. The English have done it to Irish children not by way of jest, but with a purpose. Our English-Irish systems took, and take, absolutely no cognisance of the differences between individuals, of the differences between localities, of the: differences between urban and rural communities, of the differences springing from a different ancestry, Gaelic or Anglo-Saxon.\n\nAttempts were made by legislation, in the later medieval and early modern period, to establish English at first among the aristocracy and increasingly amongst all ranks by education acts and parish schools. The Parliament of Scotland passed some ten such acts between 1494 and 1698.\n\nIn 1609 nine Gaelic chieftains were abducted and forced to sign the Statutes of Iona, which would seem to have been designed specifically to Anglicize leaders and institutions of Gaelic society, in order to bring it under control of central government.\n\nAmong the items listed in this agreement was the \"planting of the gospell among these rude, barbarous, and uncivill people\" by Protestant churches; the outlawing of bards who were traditionally on circuit between the houses of noblemen; the requirement that all men of wealth send their heirs to be educated in Lowland schools where they would be taught to \"speik, reid, and wryte Inglische.\"\n\nThe then King James VI, followed this by the School Establishment Act 1616, which sought to establish schools in every parish in the Scottish Highlands so that \"the youth be exercised and trayned up in civilitie, godlines, knawledge, and learning, that the vulgar Inglische toung be universallie plantit, and the Irische language, whilk is one of the chief and principall causes of the continewance of barbaritie and incivilitie amongis the inhabitantis of the Ilis and Heylandis, may be abolisheit and removeit.\"\n\nIn 1709 the Society in Scotland for Propagating Christian Knowledge (SSPCK) was established in order to further funding sources for Highland church schools. All manner of incentives and punishments were used to stop children from speaking Scottish Gaelic. The SSPCK had five schools by 1711, 25 by 1715, 176 by 1758 and 189 by 1808, by then with 13,000 pupils attending. At first the SSPCK avoided using the Gaelic language with the result that pupils ended up learning by rote without understanding what they were reading. In 1741 the SSPCK introduced a Gaelic-English vocabulary, then in 1766 brought in a New Testament with facing pages of Gaelic and English texts for both languages to be read alongside one another, with more success. After a number of years of unsuccessful attempts at English-only teaching methods, it was realized that literacy in Gaelic was a much more effective means of teaching and a bridge towards fluency in English.\n\nSince 1918 education acts have provided for teaching Gaelic in Gaelic-speaking areas, but development was very slow until Gaelic\nbecame an initial teaching medium in the Gaelic areas of Inverness-shire and Ross-shire from 1958. In 1975 the newly created Western Isles education authority introduced bilingual primary education shortly followed by Highland Region in Skye. Gaelic-medium primary education commenced with two schools in 1985, growing to 42 units by 1993/94.\n\nIn secondary education, Gaelic has long been taught as a subject—often through the medium of English, even to native speakers. A move towards bilingual secondary education in the Western Isles was frustrated by a change of government in the 1979 United Kingdom general election. Gaelic-medium secondary education has developed less satisfactorily. Gaelic-medium streams followed on from primary in Glasgow and Inverness, with some experimentation in the Western Isles, but the sector is hampered by acute teacher shortage, and an Ofsted inspectorate report of 1994 regarded Gaelic-medium secondary education as divisive and inappropriate.\n\nThird level provision through Gaelic is provided by Sabhal Mòr Ostaig (literally: \"the great barn at Ostaig\") a Gaelic-medium college based in Sleat, on the Isle of Skye in north west Scotland. It is part of the University of the Highlands and Islands, and also has a campus on Islay known as Ionad Chaluim Chille Ìle.\n\nIn 2004, Prince Charles, Duke of Rothesay, (who is patron of the College) stated that:\n\nThe beauty of Gaelic music and song is inescapable. But without the living language, it risks becoming an empty shell. That is why an education system, up to the level represented by the college here in Skye, is so important – to ensure fluency and literacy which will continue to renew the health and creativity of the language.\n\nThe Gaelic Language (Scotland) Act 2005 is the first piece of legislation to give formal recognition to the Gaelic language in Scotland. It recognises Gaelic as an official language of Scotland, commanding \"equal respect\" with English.\n\nEducation Minister Peter Peacock, who has ministerial responsibility for Gaelic, said: \"This is a momentous day for Gaelic as we open a new chapter in the language's history. We have come a long way since the dark days of 1616 when an Act of Parliament ruled that Gaelic should be 'abolishit and removit' from Scotland.\"\n\n In the Prayer Book rebellion of 1549, where the English state sought to suppress Cornish language speaking with the introduction of the Book of Common Prayer, which was made available only in English. In replacing Latin with English, and under the guise of suppressing Catholicism, English was effectively imposed as the language of the Church, with the intent of it becoming the language of the people. At the time people in many areas of Cornwall did not speak or understand English.\n\nThe forced introduction of English to church services in Cornwall provided a major reason for the rebellion. The articles of the rebels states: \"and we the cornyshe men (whereof certen of vs vnderstande no Englysh) vtterly refuse thys new English.\"\n\nBritish records show that indigenous education was widespread in the 18th century, with a school for every temple, mosque or village in most regions of the country. Subjects taught included Reading, Writing, Arithmetic, Theology, Law, Astronomy, Metaphysics, Ethics, Medical Science and Religion. The schools were attended by students from all classes of society. Gandhi is said to have described the traditional educational system as a beautiful tree that was destroyed by British rule.\n\nThe Charter Act of 1813 decreed that English would be taught in the Indian education system although not as a replacement for indigenous languages. Instead, it was anticipated that English would co-exist with Oriental studies as a means by which moral law could be reinforced.\n\nThe 1817 publication of James Mill's \"History of British India\" proved to be a defining text in the theories of how education policies should be formed (ed. Horace Hayman Wilson: London, Piper, Stephenson and Spence, 1858). Mill advocated the introduction of European knowledge to counter balance Indian traits judged to be irrational. Instilling ideals of reason would accordingly 'reform' Indians by the example of Western systems of thought and outlook. His ideas discredited Indian culture, language and literature even as its assumptions of moral superiority authorised and justified the presence of the British in India.\n\nThe current system of education, was introduced and funded by the British in the 19th century, following recommendations by Thomas Babington Macaulay. Traditional structures were not recognized by the British government and have been on the decline since.\n\nThomas MacAulay's infamous 'Minute On Indian Education' (1835) encapsulates both the overt and covert agendas for such a policy.\n\nThe term 'Macaulay's Children' is used to refer to people born of Indian ancestry who adopt Western culture as a lifestyle. It is usually used in a derogatory fashion, and the connotation is one of disloyalty to one's country and one's heritage.\n\nThe passage to which the term refers is from his 'Minute on Indian Education' delivered in 1835. It reads:\n\nIt is impossible for us, with our limited means, to attempt to educate the body of the people. We must at present do our best to form a class who may be interpreters between us and the millions whom we govern; a class of persons, Indian in blood and colour, but English in taste, in opinions, in morals, and in intellect. To that class we may leave it to refine the vernacular dialects of the country, to enrich those dialects with terms of science borrowed from the Western nomenclature, and to render them by degrees fit vehicles for conveying knowledge to the great mass of the population.\n\nIn 1835 Lord William Bentninck revitalised the earlier Charter Act with his New Education Policy which determined that English should be the official language of the courts, diplomacy and administration. Prior to this Persian had been the accepted language of diplomacy. Bentninck's motive was ostensibly to \"regenerate\" society, but the ramifications were boundless. From this moment on only those with Western style education and a knowledge of English were eligible for government employment or for a career in public life.\n\nIn 1854 Sir Charles Wood published his Education Dispatch which was aimed at widening the availability of Western oriented knowledge. Universities were established under the London examining model in Calcutta, Bombay, and Madras.\n\nLord Ripon's Hunter Commission of 1882 somewhat belatedly advocated that there should be increased provision of education at primary level and for women. The theory was that there would be a subsequent rise in the calibre of applicants for third level entry.\n\nThe inevitable result was that an Indian-based education was viewed as being second rate in comparison to an English-medium education.\n\nPrivate English medium schools are gaining popularity throughout India as urban middle class Indians who feel that English is the global language send their children to these schools. Increasingly, many poor families too are sending their children to English medium schools due the poor quality of education in Government run vernacular medium schools.\n\nUp until 1981 in West Malaysia (and some years later in East Malaysia), there were English-medium schools set up by the former British colonial government and Christian missionaries. However, following the implementation of the 1967 National Language Act which stipulated the conversion of all English-medium schools to Malay-medium schools; all English-medium schools were definitely phased out. The policy has now caused many newly graduates to become unemployed as they cannot find jobs especially in the private sector due to the lack of English proficiency; with the graduates can only depends on public sector jobs provided by the government. This led to a criticism over the policy by local governments from the East Malaysian sides who are now feel the impacts to their younger generations caused by the federal government policy who have been too long sidelined the importance to mastering the universal language of English. By 2016, Sarawak began to support the re-establishment of English-medium schools, and request for the approval of more English-medium schools in the state from the federal government using its autonomy in education. The move was followed by Sabah in 2017 when a minister from the state also urging the return of English-medium schools, which grows with more supports from other ministers.\n\nEnglish medium school in Indonesia consists of International school and National Plus school. A National Plus school in Indonesia refers to a school that offers education beyond the minimum requirements of the national Indonesian accreditation authorities. National Plus school offers some subjects taught in English and may provide some native English speakers on staff or may offer international curriculum such as from Cambridge International Examinations (CIE) or the International Baccalaureate Organisation (IBO).\nNational Plus schools can typically be differentiated from international schools by their core market. International schools tend to primarily exist to serve the needs of expatriate students and national plus schools for Indonesian students; however there is significant overlap on both sides.\n\nThe Government of Pakistan has recently announced the introduction of English lessons on a phased basis to all schools across the country. This new policy states that \"English language has been made compulsory from Class-1 onwards\" and the \"Introduction of English as medium of instruction for science, mathematics, computer science and other selected subjects like economics and geography in all schools in a graduated manner.\" Caretaker Minister for Education Mr. Shujaat Ali Beg declared 25 January 2008 that 18 colleges of the city of Karachi would be made \"Model English Medium Colleges,\"\n\nIn Bangladesh the system of education is divided into three different branches. Students are free to choose anyone of them provided that they have the means. These branches are: The English Medium, The Bengali Medium, and The Religious Branch. In the English Medium system, courses are all taught in English using English books with the exception for Bengali and Arabic. English medium schools are mainly private and thus traditionally were reserved for the upper and upper middle class. However huge demand in urban areas has resulted in large number of English-medium schools mushrooming. This has caused a fall in quality. O and A level exams are arranged through the British Council in Dhaka.\n\nIn the Union of Myanmar, the education system is based on the British Colonial model, due to nearly a century of British and Christian presences. Nearly all schools are government-operated, and also there has been a recent increase in privately funded English language schools.\n\nThe United States of America won the Philippine–American War (1898–1901), and declared the Philippines a US colony. US imperial rule followed. Mac Síomóin quotes the Filipino scholar E. San Juan who made the following comment regarding the use made by the US administration of the English language to rule his country:\n\nIts conquest of hegemony or consensual rule was literally accomplished through the deployment of English as the official medium of business, schooling and government. This pedagogical strategy was designed to cultivate an intelligencia, a middle stratum divorced from its roots in the plebeian masses, who would service the ideological apparatus of Anglo-Saxon supremacy. Americanization was mediated through English, sanctioned as the language of prestige and aspiration.\nEnglish is used for instruction at the University of the Philippines.\n\nUniversity of Ljubljana teaches at least 100 courses in English. In \"Where to Invade Next\", Michael Moore interviews several American citizens studying at the university who were taking courses taught in English.\n\nThe earliest European schools in South Africa were established in the Cape Colony in the late seventeenth century by Dutch Reformed Church elders committed to biblical instruction, which was necessary for church confirmation. In rural areas, itinerant teachers (meesters) taught basic literacy and math skills. British mission schools proliferated after 1799, when the first members of the London Missionary Society arrived in the Cape Colony.[8]\n\nLanguage soon became a sensitive issue in education. At least two dozen English-language schools operated in rural areas of the Cape Colony by 1827, but their presence rankled among devout Afrikaners, who considered the English language and curriculum irrelevant to rural life and Afrikaner values. Throughout the nineteenth century, Afrikaners resisted government policies aimed at the spread of the English language and British values, and many educated their children at home or in the churches.\n\nIn order to anglicize the Transvaal area during the Anglo Boer war, Lord Milner set out to influence British Education in the area for the English-speaking populations. He founded a series of schools known as the \"Milner Schools\" in South Africa. These schools consist of modern day Pretoria High School for Girls, Pretoria Boys High School, Potchefstroom High School for Boys, Hamilton Primary School, and St. Marys DSG.\n\nA number of universities are involved English-medium education by International Scholarly Exchange Curriculum program (ISEC program). ISEC program establishes a platform for those universities to communicate with other international institutions who use English-medium education. Other famous universities that offer English-medium education (China-Foreign cooperative universities), such as University of Nottingham Ningbo, China, United International College, Xi’an Jiaotong-Liverpool University, Shanghai Newyork University and Wenzhou-Kean University.\n\n\n\n"}
{"id": "21482288", "url": "https://en.wikipedia.org/wiki?curid=21482288", "title": "Equality of sacrifice", "text": "Equality of sacrifice\n\nEquality of sacrifice is a term used in political theory and political philosophy to refer to the perceived fairness of a coercive policy.\n\nJohn Stuart Mill noticed that citizens often view taxation laws as being fair, as long as taxation is also applied equally to everyone else in society. Political theorist Margaret Levi applied the term to the perceived fairness of conscription in democracies, to which citizens may consent as long as conscription is enforced as a universal duty – as opposed to elitist and exceptionalist policies, as it will sometimes occur in partial mobilization.\n\nThe term was also adopted by Lee Iacocca who, as the president of Chrysler, lowered his salary to less than a dollar a year before asking union members for radical wage cuts in order to deal with the company's financial difficulties. During the financial crisis of 2007–2010, Iacocca's example has often been mentioned in opposition to \"unconditional\" government bail-out of failing companies. In a letter to the leaders of the big three U.S. automakers, Senator Chuck Grassley said that before receiving a government bailout executives should follow the example of former Chrysler head Lee Iacocca and cut their own pay:\n\nSome economists believe that the minimum wage laws in the United States lead to less equality because young black males are less likely to be able to get a job when the minimum wage is increased; this inequality exists primarily because young black workers typically live in urban areas where the food and drink industry, who mainly pay their workers minimum wage, are prevalent.\n"}
{"id": "1132140", "url": "https://en.wikipedia.org/wiki?curid=1132140", "title": "Estimated sign", "text": "Estimated sign\n\nThe estimated sign, ℮, also referred to as the e-mark or \"quantité estimée\" (Unicode U+212E), is a mark that can be found on some pre-packed goods in Europe. The estimated sign indicates that the packaging fulfils European Union Directive 2009/34/EC.\n\nThe scope of the directive is limited to packaging that has a predetermined nominal quantity of to or to , is filled without the purchaser present and of which the quantity cannot be altered without opening or destroying the packing material.\n\nThe estimated sign indicates that:\n\nThe tolerable negative error is related to the nominal quantity and varies between 9% on packages nominally or or less, to 1.5% on packages nominally or or more. The tolerable error decreases as nominal quantity increases, and is done by alternating intervals where there is a percentage error and intervals where there is a fixed error (and thus over those intervals the \"percentage\" error decreases).\n\nThe mark looks like a stylised lowercase \"e\" and its shape, ℮, is precisely defined by an EU directive. It must be placed in the same field of vision as the nominal quantity. The sign has been added to the Unicode list of characters at position U+212E.\n\nThe estimated sign may be printed on a package if:\n\nError tolerance decreases as nominal quantity increases, by alternating intervals of a given \"percentage\" error with intervals of a given \"amount\" error: these interpolate between the stepwise decreases in percentage error.\n\nThe estimated sign indicates that the average quantity of product in a batch of packages shall not be less than the nominal quantity stated on the label.\nWhen using the table, the values of the tolerable negative errors shown as percentages in the table, calculated in units of weight or volume, shall be rounded up to the nearest 0.1 g or 0.1 ml.\n\n"}
{"id": "58332394", "url": "https://en.wikipedia.org/wiki?curid=58332394", "title": "Financial Monitoring Service (Azerbaijan)", "text": "Financial Monitoring Service (Azerbaijan)\n\nThe Financial Monitoring Service of Azerbaijan is a public legal entity whose role is policy coordination, overall regulation, and supervision in the sphere of anti-money laundering and counter-terrorism financing in the country of Azerbaijan. According to its website, the Financial Monitoring Service was established by the Decree #66 of the President of the Republic of Azerbaijan, dated 23 February 2009. The Financial Monitoring Service is the authority that implements the powers identified by the legislation on the prevention of illegally obtained funds and other property's use in the financing of terrorism in accordance with international standard. \n\nThe major purpose of the Financial Monitoring Service is to supervise compliance over the requirements of prevention of criminally obtained funds or other property and the financing of terrorism, as determined by the law of Azerbaijan. It also focuses on implementing policy and overall regulation in the relevant field as well as coordinate the activity of monitoring entities, other persons involved in monitoring, supervision authorities and other state authorities, overall providing for transparency and effectiveness.\n\nFMS fulfils following functions in accordance with the scope of activities set forth by this Charter:\n\n\n\nThe FMS is managed by the Executive Board, which carries out the management and supervision. The Executive Board consists of three persons – Chair of the Executive Board, two deputies appointed and dismissed by the President of the Republic of Azerbaijan. The term of the Executive Board is five years.\n\nThe Executive Board carries out the following duties:\n\n\n"}
{"id": "14162696", "url": "https://en.wikipedia.org/wiki?curid=14162696", "title": "Fluid Concepts and Creative Analogies", "text": "Fluid Concepts and Creative Analogies\n\nFluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought is a 1995 book by Douglas Hofstadter and other members of the Fluid Analogies Research Group exploring the mechanisms of intelligence through computer modeling. It contends that the notions of analogy and fluidity are fundamental to explain how the human mind solves problems and to create computer programs that show intelligent behavior. It analyzes several computer programs that members of the group have created over the years to solve problems that require intelligence.\n\nIt was the first book ever sold by Amazon.com.\n\nThe book is a collection of revised articles that appeared in precedence, each preceded by an introduction by Hofstadter.\nThey describe the scientific work by him and his collaborators in the 1980s and 1990s.\nThe project started in the late 1970s at Indiana University.\nIn 1983 he took a sabbatical year at MIT, working in Marvin Minsky's Artificial Intelligence Lab.\nThere he met and collaborated with Melanie Mitchell, who then became his doctoral student.\nSubsequently, Hofstadter moved to the University of Michigan, where the FARG (Fluid Analogies Research Group) was founded.\nEventually he returned to Indiana University in 1988, continuing the FARG research there.\nThe book was written during a sabbatical year at the Istituto per la Ricerca Scientifica e Tecnologica in Trento, Italy.\n\nUpon publication, Jon Udell, a BYTE senior technical editor-at-large said:\nFifteen years ago, \"Gödel, Escher, Bach: An Eternal Golden Braid\" exploded on the literary scene, earning its author a Pulitzer prize and a monthly column in \"Scientific American\". Douglas Hofstadter's exuberant synthesis of math, music, and art, and his inspired thought experiments with \"tangled hierarchy,\" recursion, pattern recognition, figure/ground reversal, and self-reference, delighted armchair philosophers and AI theorists. But in the end, many people believed that these intellectual games yielded no useful model of cognition on which to base future AI research. Now \"Fluid Concepts and Creative Analogies\" presents that model, along with the computer programs Hofstadter and his associates have designed to test it. These programs work in stripped-down yet surprisingly rich microdomains.\n\nOn April 3, 1995, \"Fluid Concepts and Creative Analogies\" became the first book ordered online by an Amazon.com customer.\n\n\nThe first AI project by Hofstadter stemmed from his teenage fascination with number sequences.\nWhen he was 17, he studied the way that triangular and square numbers interleave, and eventually found a recursive relation describing it.\nIn his first course on AI, he set to the students and to himself the task of writing a program that could extrapolate the rule by which a numeric sequence is generated.\nHe discusses breadth-first and depth-first techniques, but eventually concludes that the results represent expert systems that incarnate a lot of technical knowledge but don't shine much light on the mental processes that humans use to solve such puzzles.\n\nInstead he devised a simplified version of the problem, called SeekWhence, where sequences are based on very simple basic rules not requiring advanced mathematical knowledge.\nHe argues that pattern recognition, analogy, and fluid working hypotheses are fundamental to understand how humans tackle such problems.\n\nJumbo is a program to solve jumbles, word puzzles consisting in five or six scrambled letters that need to be anagrammed to form an English word.\nThe resulting word does not need to be a real one but just to a plausible, that is, to consists of a sequence of letters that is normal in English.\n\nThe constituent elements of Jumbo are the following:\nA \"temperature\" is associated to the present state of the cytoplasm; it determines how probable it is that a destructive codelet is executed.\nThere is a \"freezing\" temperature at which no destruction can occur anymore: a solution has been found.\n\nNumbo is a program by Daniel Defays that tries to solve numerical problems similar to those used in the French game \"Le compte est bon\". The game consists in combining some numbers called \"bricks\", using the operations of multiplication, addition, and subtraction, to obtain a given result.\n\nThe program is modeled on Jumbo and Copycat and uses a permanent network of known mathematical facts, a working memory in the form of a cytoplasm, and a coderack containing codelets to produce free associations of bricks in order to arrive at the result.\n\nThe chapter subtitle \"A Critique of Artificial-intelligence Methodology\" indicates that this is a polemical article, in which David Chalmers, Robert French, and Hofstadter criticize most of the research going on at that time (the early '80s) as exaggerating results and missing the central features of human intelligence.\n\nSome of these AI projects, like the structure mapping engine (SME), claimed to model high faculties of the human mind and to be able to understand literary analogies and to rediscover important scientific breakthroughs.\nIn the introduction, Hofstadter warns about the Eliza effect that leads people to attribute understanding to a computer program that only uses a few stock phrases.\nThe authors claim that the input data for such impressive results are already heavily structured in the direction of the intended discovery and only a simple matching task is left to the computer.\n\nTheir main claim is that it is impossible to model high-level cognition without at the same time modeling low-level perception.\nWhile cognition is necessarily based on perception, they argue that it in turn influences perception itself.\nTherefore, a sound AI project should try to model the two together.\nIn a slogan repeated several times throughout the book: \"cognition is recognition\".\n\nSince human perception is too complex to be modelled by available technology, they favor the restriction of AI projects to limited domains like the one used for the Copycat project.\n\nThis chapter presents, as stated in the full title, \"A Model of Mental Fluidity and Analogy-making\".\nIt is a description of the architecture of the Copycat program, developed by Hofstadter and Melanie Mitchell.\nThe field of application of the program is a domain of short alphabetic sequences.\nA typical puzzle is: \"If abc were changed to abd, how would you change ijk in the same way?\".\nThe program tries to find an answer using a strategy supposedly similar to the way the human mind tackles the question.\n\nCopycat has three major components:\nThe resulting software displays emergent properties.\nIt works according to a \"parallel terraced scan\" that runs several possible processes at the same time.\nIt shows mental fluidity in that concepts may \"slip\" into similar ones.\nIt emulates human behavior in tending to find the most obvious solutions most of the time but being more satisfied (as witnessed by low temperature) by more clever and deep answers that it finds more rarely.\n\nThis chapter compares Copycat with other recent (at the time) work in artificial intelligence.\nSpecifically, it matches it with the claimed results from the structure mapping engine SME and the Analogical Constraint Mapping Engine (ACME).\nThe authors' judgment is that those programs suffer from two defects: Their input is pre-structured by the developers to highlight the analogies that the software is supposed to find; and the general architecture of the programs is serial and deterministic rather than parallel and stochastic like Copycat's, which they consider psychologically more plausible.\n\nSevere criticism is put on the claim that these tools can solve \"real-life\" problems.\nIn fact, only the terms used in the example suggest that the input to the programs comes from a concrete situation.\nThe logical structures don't actually imply any meaning for the term.\n\nFinally a more positive assessment is given to two other projects: Indurkhya' PAN model and Kokinov's AMBR system.\n\nThis chapter looks at those aspects of human creativity that are not yet modeled by Copycat and lays down a research plan for a future extension of the software.\nThe main missing element is the mind's ability to observe itself and reflect on its own thinking process.\nAlso important is the ability to learn and to remember the results of the mental activity.\n\nThe creativity displayed in finding analogies should be applicable at ever higher levels: making analogies between analogies (expression inspired by the title of a book by Stanislaw Ulam), analogies between these second-order analogies, and so on.\n\nAnother of Hofstadter's students, Robert French, was assigned the task of applying the architecture of Copycat to a different domain, consisting in analogies between objects lying on a table in a coffeehouse.\nThe resulting program was named Tabletop.\n\nThe authors present a different and vaster domain to justify the relevance of attacking such a trivial-seeming project.\nThe alternative domain is called Ob-Platte and consists in discovering analogies between geographical locations in different regions or countries.\n\nOnce again arguments are offered against a brute-force approach, which would work on the small Tabletop domain but would become unfeasible on the larger Ob-Platte domain.\nInstead a parallel non-deterministic architecture is used, similar to the one adopted by the Copycat project.\n\nIn the premise to the chapter, title \"The Knotty Problem of Evaluating Research\", Hofstadter considers the question of how research in AI should be assessed.\nHe argues against a strict adherence to a match between the results of an AI program with the average answer of human test subjects.\nHe gives two reasons for his rejection: the AI program is supposed to emulate creativity, while an average of human responses will delete any original insight by any of the single subjects; and the architecture of the program should be more important that its mere functional description.\n\nIn the main article, the architecture of Tabletop is described: it is strongly inspired by that of Copycat and consists of a Slipnet, a Workspace, and a Corerack.\n\nThis last chapter is about a more ambitious project that Hofstadter started with student Gary McGraw.\nThe microdomain used is that of grid fonts: typographic alphabets constructed using a rigid system of small rigid components.\nThe goal is to construct a program that, given only a few or just one letter from the grid font, can generate the whole alphabet \"in the same style\".\nThe difficulty lies in the ambiguity and undefinability of \"style\".\nThe projected program would have a structure very similar to that of Jumble, Numble, Copycat, and Tabletop.\n\nIn the concluding part of the book, Hofstadter analyses some AI projects with a critical eye.\nHe finds that today's AI is missing the gist of human creativity and is making exaggerated claims.\nThe project under scrutiny are the following.\n\nAARON, a computer artist that can draw images of people in outdoor settings in a distinctive style reminiscent of that of a human artist; criticism: the program doesn't have any understanding of the objects it draws, it just uses some graphical algorithms with some randomness thrown in to generate different scenes at every run and to give the style a more natural feel.\n\nRacter, a computer author that wrote a book entitled \"The Policeman's Beard Is Half Constructed\".\nAlthough some of the prose generated by the program is quite impressive, due in part to the Eliza effect, the computer does not have any notion of plot or of the meaning of the words it uses. Furthermore, the book is made up of selected texts from thousands produced by the computer over several years.\n\nAM, a computer mathematician that generates new mathematical concepts. It managed to produce by itself the notion of prime number and the Goldbach conjecture. As with Racter, the question is how much the programmer filtered the output of the program, keeping only the occasional interesting output.\nAlso, mathematics being a very specialized domain, it is doubtful whether the techniques used can be abstracted to general cognition.\n\nAnother mathematical program, called Geometry, was celebrated for making an insightful discovery of an original proof that an isosceles triangle has equal base angles. The proof is based on seeing the triangle in two different ways. However, the program generates all possible ways of seeing the triangle, not even knowing that it is the same triangle.\n\nHofstadter concludes with some methodological remarks on the Turing Test.\nIn his opinion it is still a good definition and he argues that by interacting with a program, a human may be able to have insight not just on its behaviour but also on its structure.\nHowever, he criticises the use that is made of it at present: it encourages the development of fancy natural-language interfaces instead of the investigation of deep cognitive faculties.\n"}
{"id": "532101", "url": "https://en.wikipedia.org/wiki?curid=532101", "title": "Free migration", "text": "Free migration\n\nFree migration or open immigration is the position that people should be able to migrate to whatever country they choose.\n\nAlthough the two are not the same issue, free migration is similar in spirit to the concept of free trade, and both are advocated by free market economists on the grounds that economics is not a zero-sum game and that free markets are, in their opinion, the best way to create a fairer and balanced economic system, thereby increasing the overall economic benefits to all concerned parties.\n\nNotwithstanding noteworthy differences among these political ideologies, many libertarians, liberals, socialists, and anarchists advocate open immigration, as do Objectivists.\n\nSome free market economists believe that competition is the essence of a healthy economic system, and that any short-term negative impact on individual economic factors that is caused by free migration is more than justified by the prospects of long-term growth for the economy as a whole.\n\nFrom a human-rights perspective, free migration may be seen to complement Article 13 of the Universal Declaration on Human Rights:\n\nArguments against free immigration are usually economical, cultural or security-related. Some arguments are nationalistic or what some critics claim to be \"xenophobic\", or ones similar to arguments against free trade, favouring protectionism.\n\nWar-related chaos can lead to the breakdown of borders and allow for \"de facto\" free immigration. The natural attempts to flee strife, or escape a conquering enemy, can quickly lead to millions of refugees. Even where border controls are in place they can be overwhelmed by the sheer numbers of people. Once settled into refugee camps, these reluctant immigrants may take decades to be either repatriated back or naturalized into their new country. This has been the situation with the Palestinians in Jordan.\n\nDuring the Cold War, a migration paradox arose in which some of the communist states forbade emigration, while the \"Free World\" would freely accept the defectors. This policy persists for Cubans and the Hmong, who are both allowed particular forms of free immigration to the United States based on their automatic refugee status.\n\n\nAll people regardless of citizenship are allowed to live and work in Svalbard without a visa or residence permit, as long as they demonstrate they are able to support themselves.\n\nThrough numerous situations and encounters, immigration can be a test of mental fortitude rather than physical ability. In Buddhism, a bodhisattva is considered to be a guide to awakening and to the Pure Lands. \"The Buddha declares that we are all bodhisattvas destined to attain full Awakening. It seems that each of us, then, is engaged in 'spiritual immigration'. The Buddha asserts that everyone is a bodhisattva, or a 'spiritual immigrant', who must attain various virtues which ultimately leads to \"prajnaparamita\", or 'transcendent wisdom'. The existence of Buddhas and Mahasattvas'great beings' who have achieved a high level on the path to awakeninghave created various branches of belief like Mahayana Buddhism, which is a form of 'spiritual immigration'. \"Buddhism is a type of immigration from the world of suffering to nirvana...We are all immigrants who, paradoxically, are seeking to and the land in which we already dwell\". In terms of 'spiritual immigration', the path of the bodhisattva is a change of mental capacity rather than cosmic location.\n\nAccording to Buddhist teaching, the purpose of a 'spiritual immigration' is to help guide the individual onto their future path. The Pure Land is the state of untainted mind: reaching this land of purity requires persistent effort and practice. Along the journey, individuals learn to envision their future as a land of opportunity. The intention of the pure land is to assure that the individual achieves their personal goals in lifethe betterment of oneself in order to reach nirvana. Alongside these goals, practitioners also learn about the relationship of 'self' and 'others', resulting in the renewal of all beings. The concept of the pure lands enforces the idea of 'spiritual immigration' as a form of mental encouragement.\n\nMigration is a spiritual journey that establishes a point of communication between the human and divine. Religious figures migrate from one place to another as immigrants: \"In Christianity, God migrated to this world in the form of human Jesus; the Hindu God Krishna descended to earth to become a charioteer, a human being (Bhagavad Gita 1:20-47); and the Buddha 'becomes Awakened' when he became a wanderer and a stranger\". Adherents believe that religious figures have travelled from an unpurified state to a purified state: Buddha traveled from his privileged life to a life of poverty to gain divinity and knowledge; therefore divine figures like Gautam Buddha viewed migration as purification. The Qur’an states that \"they could migrate from their oppressed positions to another land of God\". \n\nThe doctrine of \"Hijrah\" suggest that freedom of movement is a human right as well as a duty to God. Globalization affects religious perspectives on migration which seek to prevent the \"destruction to the sanctity of human life and dignity\". Religious figures like Buddha and Jesus practised \"a theology of migration\". According to adherents, immigrants should have the same rights as legal residents because world religions believe everyone is divine. It is also mentioned in the Qur’an that \"strangers are entitled to the equal distribution of wealth\". Despite the acquisition of wealth in verse 8:41, the Qur’an states that \"know that one-fifth of your battle gains belongs to the God and the messenger, to close relatives and orphans or to the needy and travellers (strangers).”\n\nAccording to Collier and Strain, the Roman Catholic Church has been helping migrants for decades. The Christian faith receives a sense of justice for migrants from Abrahamic faith traditions. Catholics follow these guidelines to help immigrants: \"for all persons on the move\". The reasons to help those on the move were established in 1952 when leaders of the Roman Catholic Church published written material that reinforced the teachings of the church. One of the quotes from the Bible used to justify hospitality is \"when an alien resides with you in your land, you shall not oppress the alien. The alien who resides with you shall be to you as a citizen among you; you shall love the alien as yourself, for you were aliens in the land of Egypt: I am the Lord your God\" (Leviticus 19:33). \n\nStrangers or those on the move should be treated equally, no less than anyone else. The modern nation state should open its borders because people may be migrating due to unfavorable circumstances. The Catholic Church believes everyone has a right to migrate to support their families; this idea of free migration allows \"the human person [to precede] the state\".” In some circumstances, the Church provides assistance to migrants and refugees. Some Catholic organizations offer educational activities on the legal process of immigration to the United States. Other types of aid include spiritual companionship, ESL classes for those who want to learn to speak better English, basic hygiene, and food. The Roman Catholic Church believes that helping those in need enables the growth of the human spirit.\n\nBefore the Columbian exchange, there was an open border policy in the Americas that gave Native Americans access to travel freely and have open trade with other cultures. There was widespread trade among many First Nations that created free movement and travel for many foreigners. At the time, there was little border control which allowed migrants to travel to various areas to settle. Immigration policy shifted towards control and nationalism after 1492. In the 20th century, immigration policy solidified borders in America, but many Native Americans advocated free movement and hospitality towards strangers. Native Americans historically have welcomed strangers with hospitality, sometimes making them relatives through an informal adoption system. Migration in America can be understood through the religious and cultural perspectives of Native American. \n\nMost Native American groups have shown hospitality towards strangers, and guests are given gifts from the host, which are known as 'give-aways'. Hospitality to visitors and other members of one's community is a value of many Native Americans groups, and they consider their belongings and other possessions as blessings. The concept of borders and walls (both artificial and real) were not practised in pre-Columbian times when Native Americans inhabited present day Canada, Central Amaerica, Mexico, and the U.S. Instead, hospitality and gift giving were the traditions that were honored and shared among visitors and other people.\n\nMany nation states have agreed and disagreed on the topic of open borders and free migration, with some countries allowing people to travel freely from country to country and state to state without the risk of deportation or punishment. The consensus within the open borders debate is to “establish a view of migration that reflects the liberal commitment to the equal moral worth of all people which applies to a truly global view of migration.” Various ideas have been applied to a global view of migration, such as the ideas of other journalists such as Johnathan Wolff and Avnir De-Shalit to migration. Wolff and De-Shalit’s state that the use of law and ethics is a positive factor in the debate over free migration. The debate of free migration does not apply to a specific country but extends beyond, and continues on to a broader spectrum for introducing a freedom of movement amongst all people, for all countries. However, this concept is especially significant to the places that experience the most migration-including both host and receiving countries or states. Free migration is not limited to a certain time period, but has been more relevant and controversial in recent years, especially in the United States. In the U.S., it has become a more controversial topic since 9/11.\n\nFree migration is a concept to consider when comparing basic human rights and migration. \"Constraining movement in most cases is therefore, unjustified and immoral\". The topic of free migration is not a matter to be only exclusively debated amongst national governments of varying nations, but a worldwide discussion for all people of all nations on the debate of open borders and free migration. In that case, nations and people from all over the world can learn from each other where everyone is involved in the attempt to come to a just conclusion and solution to the problems surrounding both immigration and free migration alike. Free Migration has been slowly restricted throughout recent history due to the inevitable progression of society, causing more independent societies to create tighter laws, policies, and regulations concerning immigration. With nations closing themselves off and shutting their borders from non-residents, it is difficult for free migration to become secure, as well as having members of society prioritize an institutional issue such as this.\n\nImmigration officers and agents must maintain a code of conduct based on policy to provide equal treatment to any and all immigrants. Officers must put their political views behind them and revert to policy law; leaving behind their personal moral conflicts and ethics to abide by law and policy. Political philosophers focus on free movement as a human right and aid for those in poverty or serious global inequality. Although there is not a necessary definition for something considered to be morally, ethically, or legally accepted in a society, everyone has an individual connection to what may be considered good for society and what may be considered bad for society. The United States government has placed many strict laws on immigration that it proposes will produce a better immigration system. Other countries, through United Nations consensus, allow a minimum two year system for refugee relocation, with other countries such as Canada and Switzerland operating within a four year system.\n\nAccording to John Kennan’s (2012) data simulations (collected in multiple countries to simulate the effects of open borders), there would be large economic gains between Mexico and the United States of America through the implementation of open borders. Liberal economic reasoning advocates for open borders to prevent economic inequality between countries where country A is more efficient than country B due to restrictions on immigration creating production efficiency gaps between the two countries. Labor share data estimates that there would be more economic gains through free migration between countries. These gains are expressed through the economic and labor growth in the country along with economic gain for foreign and resident workers in that country. Economic simulations show that migration lowers the real wage for both countries receiving and sending immigrants; however, the effect of this decrease is based on the goods and services consumed by an individual. According to Kennan “these gains are associated with a relatively small reduction in the real wage in developed countries, and even this effect disappears as the capital–labor ratio adjusts over time.” Therefore, the number of workers in both receiving and sending countries would double by the current population of workers.\n\nAccording to Mirko Bagaric and John Morss (2005), nations discriminate against immigrants through certain immigration policies like the Immigration and Naturalization Act (INA), the body of law governing current immigration policy, which provides for an annual worldwide limit of 675,000 permanent immigrants, with certain exceptions for close family members. Nations such as: North/South America, Europe and Australia use their power to regulate migration control by selecting individuals and placing them where they may not be able to succeed. “Nation states have the right to determine which people are permitted to enter within their geographical borders.” This causes people to choose places they did not want to go, making them displaced persons. Over the past decade, there have been 12-18 million displaced persons. Countries usually put restrictions on migrants because they could be a security risk. “The most persuasive argument in favour of strict immigration controls is expressed by the view that ‘we made it and own it and don’t want it ruined by others.’” \n\nSome nations discriminate against immigrants wanting to come in because many citizens have a preconceived notion that the ones coming in are criminals who want to abuse government funding. “Unless we radically loosen migration controls we must accept that we are endorsing a racist policy.” Multiple nations spend billions of dollars every year on border security. Many nations do not realize how much immigrants can benefit their nation. They perform tasks that most individuals may not want to do, such as low paying jobs that involve hard labor. Ultimately, immigrants can benefit every nation, if they were given the chance to prove themselves and really show who they are. Free migration means migrants can choose whatever country they wish to go to. If strict migration laws and border security shut people out, then they do not have a chance for a new life.\n\n\n\n"}
{"id": "1494654", "url": "https://en.wikipedia.org/wiki?curid=1494654", "title": "Hamstringing", "text": "Hamstringing\n\nHamstringing is a method of crippling a person or animal so that they cannot walk properly by severing the hamstring tendons in the thigh of the individual. It is used as a method of torture, or to incapacitate the victim.\n\nHamstringing is used primarily to incapacitate a human or animal and render them incapable of effective movement. The severing of the hamstring muscles results not only in the crippling of the leg, but also in tremendous pain common to heavy laceration.\n\nIn humans, the hamstring extends between the hip and knee joints. The hamstring muscle group is made up of the biceps femoris, semitendinosus muscle, and the semimembranosus. It facilitates both the flexing of the knee and hip extension, making it a vital contributor to normal leg movement. By severing these muscles or the tendons involved in this process, normal leg movement is disrupted. In addition to sustaining massive bleeding, the injured leg becomes useless and the victim is rendered lame. The severing of the hamstring is usually accomplished through use of a blade such as a knife or sword.\n\nDue to a lack of research in the field of critical hamstring injuries, the current injury management is quite limited. Management of the injury is based solely \"on clinical experience, anecdotal evidence and the knowledge of the biological basis of tissue repair.\" These injuries are difficult to control or repair, leading often to permanent injury or even death by exsanguination.\n\nSources from late antiquity indicate that hamstringing was commonly used to incapacitate combatants and prisoners.\n\nLiterally, to \"hamstring\" an individual is to sever the tissues of their hamstring. As a metaphor to be \"hamstrung\" suggests being limited, by external imposition or not, in a way that prevents full freedom of movement or utilization of resources.\n\nRendering chariot horses lame by hamstringing is mentioned in the Bible, called \"houghing\" in the King James Version, from an old spelling of \"hock\". In the Bible, this is seen as a positive use of hamstringing because it prevents the horses from being used in warfare.\n"}
{"id": "25807721", "url": "https://en.wikipedia.org/wiki?curid=25807721", "title": "Holzer Permaculture", "text": "Holzer Permaculture\n\nThe Holzer Permaculture is a branch of permaculture developed independently from the mainstream permaculture in Austria by Sepp Holzer. It is particularly noteworthy because it grew out of practical application and was relatively detached from the scientific community.\n\nSepp Holzer started reorganising his father's property according to ecological patterns in the early 1960s after he took over the farm. As an adolescent he conducted layman experiments with plants native to the area and learned from his own observations.\n\nSince having taken over his father's property, he has expanded it from 24 to 45 hectares. according to his methods together with his wife.\n\nHis expanded farm now spans over 45 hectares of forest gardens, including 70 ponds, and is said to be the most consistent example of permaculture worldwide. In the past he has experimented with many different animals. As a result of these experiments, there is a huge role for animals in the Holzer Permaculture.\n\nHe has created some of the world's best examples of using ponds as reflectors to increase solar gain for passive solar heating of structures, and of using the microclimate created by rock outcrops to effectively change the hardiness zone for nearby plants. He has also done original work in the use of Hügelkultur and natural branch development instead of pruning (see Fruit tree pruning) to allow fruit trees to survive high altitudes and harsh winters.\n\nIt is difficult to make out differences between the methods and practices of Sepp Holzer in contrast to the more scientific and theoretical permacultural mainstream. Nevertheless, here are some major points to consider:\n\n\nSituated in Ramingstein on the slopes of Mount Schwarzenberg his farm (Krameterhof) lies at varying elevations ranging from 1100 to 1500 metres above sea level.\nThe exceptionally harsh climatic conditions in the area are generally considered inappropriate for farming. Nevertheless, he has managed to cultivate a variety of crops and even exotic plants like Kiwis and Sweet Chestnut.\n\nThe Krameterhof is less an operational enterprise, in terms of crop-yield (although it does provide numerous sorts of produce for the community), and more a fully functional showcase or research station for permaculture.\n\nEndangered livestock species and rare alpine- and cultural plant species are integrated into the farm.\n\nMost of Holzer's books are published in German through Leopold Stocker Verlag, an Austrian publisher in Graz.\n\n\n"}
{"id": "41738745", "url": "https://en.wikipedia.org/wiki?curid=41738745", "title": "Ikshana", "text": "Ikshana\n\nIkshana (Sanskrit: \"īkṣaṇa\") is a noun which means sight, care and superintendence but also refers to eye, sight, look, seeing, viewing, aspect, caring for, looking after, regarding.\n\nIn the \"Mahabharata\", Brahma is said to have become the Ikshana (eye), in the form of this mobile and immobile universe, of all entities that took birth; in the phrase \"Vrishbhekshana\", \"Virishbha\" implies the \"Vedas\" and ikshana, the eye. Kalidasa, in the phrase मदिरेक्षणे appearing in passage II.72 of his Abhigyanashakuntalam, has also used the word Ikshana to mean the eye, which phrase Sankara explains is – \"madira\" ('wine') as applied to the eye (ikshana), - eye as equivalent to 'beautiful', \"madirekhshane\" means the one whose eyes intoxicate like wine or is the wine-eyed.\n\nIkshana is a technical term used in Vedanta to show how creation took place by the beholding of Para-brahman as an intelligent and a personal act of the creator; it means revelation of the created. Parabrahman is essentially \"citta\" who produces his self as Shabda Brahman (Logos) by \"ikshana\" ('beholding').\n\nBadarayana states:-\n\nAdi Shankara, in his commentary on this \"sutra\", states that the object of \"ikshana\" ('seeing') is the supreme Self, Brahman, and not Hiranyagarbha, the inferior Brahman. He says that the term \"ikshati-karma\" means the object covered by the act of seeing. The all-pervading entity (Purusa) that is to be seen can be seen to be \"higher than the high one\" meditated. Pippalada tells Satyakama, son of Sibi, that he by the \"Sama\" hymns is elevated to the \"Brahmaloka\", he from this \"jivanghata\" ('the Macrocosmic Soul') beholds the supreme Being – एतस्माज्जीवघ्नात्परात्परं पुरिशयं पुरुषुमीक्षति - Prashna Upanishad V.5.\n\nThe statement – \"uho nama vi-tarkoktih pra-vicharekshanatmakah\", the terms \"Vitarka\" and \"Tarka\" are used interchangeably, \"tarka\" occurs after speech, mind and prana have been restrained immediately before Samadhi, vitarka consists of advanced thought and observation (ikshana); it is through discernment (\"uha\") that one leaves the lower plane of \"savikalpa\" and gets uplifted.\n\nThe Vedic concept of tapas and the Upanishadic concept of ikshana to the effect that consciousness and force are ultimately the same and every will has an aspect of force, helped Sri Aurobindo to conclude that the fact is only a partial reflection of the Idea which has created it and that it is the idea which expresses itself in matter and takes to itself bodies, and formulate the 'Theory of ideas as forces'.\n\nIt was through \"ekacittekshana-samyukta-prajna\" the supreme perfect knowledge was realized (\"abhisambodha\") by Gautama Buddha, that converted \"Boddhisattva\" to \"Buddha\"; \"ekacittekshana\" refers to \"Prajna\" exercised in unison with 'one-thought-viewing' when there is no separation between 'knower' and the 'known', all are viewed in one thought and enlightenment is the outcome.\n"}
{"id": "31428210", "url": "https://en.wikipedia.org/wiki?curid=31428210", "title": "Imitation (art)", "text": "Imitation (art)\n\nImitation is the doctrine of artistic creativity according to which the creative process should be based on the close imitation of the masterpieces of the preceding authors. This concept was first formulated by Dionysius of Halicarnassus in the first century BCE as \"imitatio\", and has since dominated for almost two thousand years the Western history of the arts and classicism; in the 18th century, Romanticism reversed it with the creation of the institution of romantic originality. In the 20th century, the modernist and postmodern movements in turn discarded the romantic idea of creativity, and heightened the practice of imitation, copying, plagiarism, rewriting, appropriation and so on as the central artistic device.\n\n"}
{"id": "160990", "url": "https://en.wikipedia.org/wiki?curid=160990", "title": "Infinitesimal", "text": "Infinitesimal\n\nIn mathematics, infinitesimals are things so small that there is no way to measure them. The insight with exploiting infinitesimals was that entities could still retain certain specific properties, such as angle or slope, even though these entities were quantitatively small. The word \"infinitesimal\" comes from a 17th-century Modern Latin coinage \"infinitesimus\", which originally referred to the \"infinite-th\" item in a sequence. \nInfinitesimals are a basic ingredient in the procedures of infinitesimal calculus as developed by Leibniz, including the law of continuity and the transcendental law of homogeneity. In common speech, an infinitesimal object is an object that is smaller than any feasible measurement, but not zero in size—or, so small that it cannot be distinguished from zero by any available means. Hence, when used as an adjective, \"infinitesimal\" means \"extremely small\". To give it a meaning, it usually must be compared to another infinitesimal object in the same context (as in a derivative). Infinitely many infinitesimals are summed to produce an integral.\n\nThe concept of infinitesimals was originally introduced around 1670 by either Nicolaus Mercator or Gottfried Wilhelm Leibniz. Archimedes used what eventually came to be known as the method of indivisibles in his work \"The Method of Mechanical Theorems\" to find areas of regions and volumes of solids. In his formal published treatises, Archimedes solved the same problem using the method of exhaustion. The 15th century saw the work of Nicholas of Cusa, further developed in the 17th century by Johannes Kepler, in particular calculation of area of a circle by representing the latter as an infinite-sided polygon. Simon Stevin's work on decimal representation of all numbers in the 16th century prepared the ground for the real continuum. Bonaventura Cavalieri's method of indivisibles led to an extension of the results of the classical authors. The method of indivisibles related to geometrical figures as being composed of entities of codimension 1. John Wallis's infinitesimals differed from indivisibles in that he would decompose geometrical figures into infinitely thin building blocks of the same dimension as the figure, preparing the ground for general methods of the integral calculus. He exploited an infinitesimal denoted 1/∞ in area calculations.\n\nThe use of infinitesimals by Leibniz relied upon heuristic principles, such as the law of continuity: what succeeds for the finite numbers succeeds also for the infinite numbers and vice versa; and the transcendental law of homogeneity that specifies procedures for replacing expressions involving inassignable quantities, by expressions involving only assignable ones. The 18th century saw routine use of infinitesimals by mathematicians such as Leonhard Euler and Joseph-Louis Lagrange. Augustin-Louis Cauchy exploited infinitesimals both in defining continuity in his \"Cours d'Analyse\", and in defining an early form of a Dirac delta function. As Cantor and Dedekind were developing more abstract versions of Stevin's continuum, Paul du Bois-Reymond wrote a series of papers on infinitesimal-enriched continua based on growth rates of functions. Du Bois-Reymond's work inspired both Émile Borel and Thoralf Skolem. Borel explicitly linked du Bois-Reymond's work to Cauchy's work on rates of growth of infinitesimals. Skolem developed the first non-standard models of arithmetic in 1934. A mathematical implementation of both the law of continuity and infinitesimals was achieved by Abraham Robinson in 1961, who developed non-standard analysis based on earlier work by Edwin Hewitt in 1948 and Jerzy Łoś in 1955. The hyperreals implement an infinitesimal-enriched continuum and the transfer principle implements Leibniz's law of continuity. The standard part function implements Fermat's adequality.\n\nVladimir Arnold wrote in 1990:\n\nThe notion of infinitely small quantities was discussed by the Eleatic School. The Greek mathematician Archimedes (c.287 BC–c.212 BC), in \"The Method of Mechanical Theorems\", was the first to propose a logically rigorous definition of infinitesimals. His Archimedean property defines a number \"x\" as infinite if it satisfies the conditions |\"x\"|>1, |\"x\"|>1+1, |\"x\"|>1+1+1, ..., and infinitesimal if \"x\"≠0 and a similar set of conditions holds for \"x\" and the reciprocals of the positive integers. A number system is said to be Archimedean if it contains no infinite or infinitesimal members.\n\nThe English mathematician John Wallis introduced the expression 1/∞ in his 1655 book \"Treatise on the Conic Sections\". The symbol, which denotes the reciprocal, or inverse, of ∞, is the symbolic representation of the mathematical concept of an infinitesimal. In his \"Treatise on the Conic Sections\" Wallis also discusses the concept of a relationship between the symbolic representation of infinitesimal 1/∞ that he introduced and the concept of infinity for which he introduced the symbol ∞. The concept suggests a thought experiment of adding an infinite number of parallelograms of infinitesimal width to form a finite area. This concept was the predecessor to the modern method of integration used in integral calculus. The conceptual origins of the concept of the infinitesimal 1/∞ can be traced as far back as the Greek philosopher Zeno of Elea, whose Zeno's dichotomy paradox was the first mathematical concept to consider the relationship between a finite interval and an interval approaching that of an infinitesimal-sized interval.\n\nInfinitesimals were the subject of political and religious controversies in 17th century Europe, including a ban on infinitesimals issued by clerics in Rome in 1632.\n\nPrior to the invention of calculus mathematicians were able to calculate tangent lines using Pierre de Fermat's method of adequality and René Descartes' method of normals. There is debate among scholars as to whether the method was infinitesimal or algebraic in nature. When Newton and Leibniz invented the calculus, they made use of infinitesimals, Newton's \"fluxions\" and Leibniz' \"differential\". The use of infinitesimals was attacked as incorrect by Bishop Berkeley in his work \"The Analyst\". Mathematicians, scientists, and engineers continued to use infinitesimals to produce correct results. In the second half of the nineteenth century, the calculus was reformulated by Augustin-Louis Cauchy, Bernard Bolzano, Karl Weierstrass, Cantor, Dedekind, and others using the (ε, δ)-definition of limit and set theory. \nWhile the followers of Cantor, Dedekind, and Weierstrass sought to rid analysis of infinitesimals, and their philosophical allies like Bertrand Russell and Rudolf Carnap declared that infinitesimals are \"pseudoconcepts\", Hermann Cohen and his Marburg school of neo-Kantianism sought to develop a working logic of infinitesimals. The mathematical study of systems containing infinitesimals continued through the work of Levi-Civita, Giuseppe Veronese, Paul du Bois-Reymond, and others, throughout the late nineteenth and the twentieth centuries, as documented by Philip Ehrlich (2006). In the 20th century, it was found that infinitesimals could serve as a basis for calculus and analysis; see hyperreal number.\n\nIn extending the real numbers to include infinite and infinitesimal quantities, one typically wishes to be as conservative as possible by not changing any of their elementary properties. This guarantees that as many familiar results as possible are still available. Typically \"elementary\" means that there is no quantification over sets, but only over elements. This limitation allows statements of the form \"for any number x...\" For example, the axiom that states \"for any number \"x\", \"x\" + 0 = \"x\"\" would still apply. The same is true for quantification over several numbers, e.g., \"for any numbers \"x\" and \"y\", \"xy\" = \"yx\".\" However, statements of the form \"for any \"set\" \"S\" of numbers ...\" may not carry over. Logic with this limitation on quantification is referred to as first-order logic.\n\nThe resulting extended number system cannot agree with the reals on all properties that can be expressed by quantification over sets, because the goal is to construct a non-Archimedean system, and the Archimedean principle can be expressed by quantification over sets. One can conservatively extend any theory including reals, including set theory, to include infinitesimals, just by adding a countably infinite list of axioms that assert that a number is smaller than 1/2, 1/3, 1/4 and so on. Similarly, the completeness property cannot be expected to carry over, because the reals are the unique complete ordered field up to isomorphism.\n\nWe can distinguish three levels at which a nonarchimedean number system could have first-order properties compatible with those of the reals:\n\n\nSystems in category 1, at the weak end of the spectrum, are relatively easy to construct, but do not allow a full treatment of classical analysis using infinitesimals in the spirit of Newton and Leibniz. For example, the transcendental functions are defined in terms of infinite limiting processes, and therefore there is typically no way to define them in first-order logic. Increasing the analytic strength of the system by passing to categories 2 and 3, we find that the flavor of the treatment tends to become less constructive, and it becomes more difficult to say anything concrete about the hierarchical structure of infinities and infinitesimals.\n\nAn example from category 1 above is the field of Laurent series with a finite number of negative-power terms. For example, the Laurent series consisting only of the constant term 1 is identified with the real number 1, and the series with only the linear term \"x\" is thought of as the simplest infinitesimal, from which the other infinitesimals are constructed. Dictionary ordering is used, which is equivalent to considering higher powers of \"x\" as negligible compared to lower powers. David O. Tall refers to this system as the super-reals, not to be confused with the superreal number system of Dales and Woodin. Since a Taylor series evaluated with a Laurent series as its argument is still a Laurent series, the system can be used to do calculus on transcendental functions if they are analytic. These infinitesimals have different first-order properties than the reals because, for example, the basic infinitesimal \"x\" does not have a square root.\n\nThe Levi-Civita field is similar to the Laurent series, but is algebraically closed. For example, the basic infinitesimal x has a square root. This field is rich enough to allow a significant amount of analysis to be done, but its elements can still be represented on a computer in the same sense that real numbers can be represented in floating point.\n\nThe field of transseries is larger than the Levi-Civita field. An example of a transseries is:\n\nwhere for purposes of ordering \"x\" is considered infinite.\n\nConway's surreal numbers fall into category 2. They are a system designed to be as rich as possible in different sizes of numbers, but not necessarily for convenience in doing analysis. Certain transcendental functions can be carried over to the surreals, including logarithms and exponentials, but most, e.g., the sine function, cannot. The existence of any particular surreal number, even one that has a direct counterpart in the reals, is not known a priori, and must be proved.\n\nThe most widespread technique for handling infinitesimals is the hyperreals, developed by Abraham Robinson in the 1960s. They fall into category 3 above, having been designed that way so all of classical analysis can be carried over from the reals. This property of being able to carry over all relations in a natural way is known as the transfer principle, proved by Jerzy Łoś in 1955. For example, the transcendental function sin has a natural counterpart *sin that takes a hyperreal input and gives a hyperreal output, and similarly the set of natural numbers formula_2 has a natural counterpart formula_3, which contains both finite and infinite integers. A proposition such as formula_4 carries over to the hyperreals as formula_5 .\n\nThe superreal number system of Dales and Woodin is a generalization of the hyperreals. It is different from the super-real system defined by David Tall.\n\nIn linear algebra, the dual numbers extend the reals by adjoining one infinitesimal, the new element ε with the property ε = 0 (that is, ε is nilpotent). Every dual number has the form \"z\" = \"a\" + \"b\"ε with \"a\" and \"b\" being uniquely determined real numbers.\n\nOne application of dual numbers is automatic differentiation. This application can be generalized to polynomials in n variables, using the Exterior algebra of an n-dimensional vector space.\n\nSynthetic differential geometry or smooth infinitesimal analysis have roots in category theory. This approach departs from the classical logic used in conventional mathematics by denying the general applicability of the law of excluded middle – i.e., \"not\" (\"a\" ≠ \"b\") does not have to mean \"a\" = \"b\". A \"nilsquare\" or \"nilpotent\" infinitesimal can then be defined. This is a number \"x\" where \"x\" = 0 is true, but \"x\" = 0 need not be true at the same time. Since the background logic is intuitionistic logic, it is not immediately clear how to classify this system with regard to classes 1, 2, and 3. Intuitionistic analogues of these classes would have to be developed first.\n\nCauchy used an infinitesimal formula_6 to write down a unit impulse, infinitely tall and narrow Dirac-type delta function formula_7 satisfying formula_8 in a number of articles in 1827, see Laugwitz (1989). Cauchy defined an infinitesimal in 1821 (Cours d'Analyse) in terms of a sequence tending to zero. Namely, such a null sequence becomes an infinitesimal in Cauchy's and Lazare Carnot's terminology.\n\nModern set-theoretic approaches allow one to define infinitesimals via the ultrapower construction, where a null sequence becomes an infinitesimal in the sense of an equivalence class modulo a relation defined in terms of a suitable ultrafilter. The article by Yamashita (2007) contains a bibliography on modern Dirac delta functions in the context of an infinitesimal-enriched continuum provided by the hyperreals.\n\nThe method of constructing infinitesimals of the kind used in nonstandard analysis depends on the model and which collection of axioms are used. We consider here systems where infinitesimals can be shown to exist.\n\nIn 1936 Maltsev proved the compactness theorem. This theorem is fundamental for the existence of infinitesimals as it proves that it is possible to formalise them. A consequence of this theorem is that if there is a number system in which it is true that for any positive integer \"n\" there is a positive number \"x\" such that 0 < \"x\" < 1/\"n\", then there exists an extension of that number system in which it is true that there exists a positive number \"x\" such that for any positive integer \"n\" we have 0 < \"x\" < 1/\"n\". The possibility to switch \"for any\" and \"there exists\" is crucial. The first statement is true in the real numbers as given in ZFC set theory : for any positive integer \"n\" it is possible to find a real number between 1/\"n\" and zero, but this real number depends on \"n\". Here, one chooses \"n\" first, then one finds the corresponding \"x\". In the second expression, the statement says that there is an \"x\" (at least one), chosen first, which is between 0 and 1/\"n\" for any \"n\". In this case \"x\" is infinitesimal. This is not true in the real numbers (R) given by ZFC. Nonetheless, the theorem proves that there is a model (a number system) in which this is true. The question is: what is this model? What are its properties? Is there only one such model?\n\nThere are in fact many ways to construct such a one-dimensional linearly ordered set of numbers, but fundamentally, there are two different approaches:\n\nIn 1960, Abraham Robinson provided an answer following the first approach. The extended set is called the hyperreals and contains numbers less in absolute value than any positive real number. The method may be considered relatively complex but it does prove that infinitesimals exist in the universe of ZFC set theory. The real numbers are called standard numbers and the new non-real hyperreals are called nonstandard.\n\nIn 1977 Edward Nelson provided an answer following the second approach. The extended axioms are IST, which stands either for Internal set theory or for the initials of the three extra axioms: Idealization, Standardization, Transfer. In this system we consider that the language is extended in such a way that we can express facts about infinitesimals. The real numbers are either standard or nonstandard. An infinitesimal is a nonstandard real number that is less, in absolute value, than any positive standard real number.\n\nIn 2006 Karel Hrbacek developed an extension of Nelson's approach in which the real numbers are stratified in (infinitely) many levels; i.e., in the coarsest level there are no infinitesimals nor unlimited numbers. Infinitesimals are in a finer level and there are also infinitesimals with respect to this new level and so on.\n\nCalculus textbooks based on infinitesimals include the classic \"Calculus Made Easy\" by Silvanus P. Thompson (bearing the motto \"What one fool can do another can\") and the German text \"Mathematik fur Mittlere Technische Fachschulen der Maschinenindustrie\" by R Neuendorff. Pioneering works based on Abraham Robinson's infinitesimals include texts by Stroyan (dating from 1972) and Howard Jerome Keisler (). Students easily relate to the intuitive notion of an infinitesimal difference 1-\"0.999...\", where \"0.999...\" differs from its standard meaning as the real number 1, and is reinterpreted as an infinite terminating extended decimal that is strictly less than 1.\n\nAnother elementary calculus text that uses the theory of infinitesimals as developed by Robinson is \"Infinitesimal Calculus\" by Henle and Kleinberg, originally published in 1979. The authors introduce the language of first order logic, and demonstrate the construction of a first order model of the hyperreal numbers. The text provides an introduction to the basics of integral and differential calculus in one dimension, including sequences and series of functions. In an Appendix, they also treat the extension of their model to the \"hyperhyper\"reals, and demonstrate some applications for the extended model.\n\nIn a related but somewhat different sense, which evolved from the original definition of \"infinitesimal\" as an infinitely small quantity, the term has also been used to refer to a function tending to zero. More precisely, Loomis and Sternberg's \"Advanced Calculus\" defines the function class of infinitesimals, formula_9, as a subset of functions formula_10 between normed vector spaces by formula_11, as well as two related classes formula_12 (see Big-O notation) by formula_13, andformula_14.The set inclusions formula_15generally hold. That the inclusions are proper is demonstrated by the real-valued functions of a real variable formula_16, formula_17, and formula_18: formula_19 but formula_20 and formula_21.As an application of these definitions, a mapping formula_22 between normed vector spaces is defined to be differentiable at formula_23 if there is a formula_24 [i.e, a bounded linear map formula_25] such that formula_26in a neighborhood of formula_6. If such a map exists, it is unique; this map is called the \"differential\" and is denoted by formula_28, coinciding with the traditional notation for the classical (though logically flawed) notion of a differential as an infinitely small \"piece\" of \"F\". This definition represents a generalization of the usual definition of differentiability for vector-valued functions of (open subsets of) Euclidean spaces.\n\nLet formula_29 be a probability space and let formula_30. An array formula_31 of random variables is called infinitesimal if for every formula_32, we have:\nThe notion of infinitesimal array is essential in some central limit theorems and it is easily seen by monotonicity of the expectation operator that any array satisfying Lindeberg's condition is infinitesimal, thus playing an important role in Lindeberg's Central Limit Theorem (a generalization of the central limit theorem).\n\n"}
{"id": "51251625", "url": "https://en.wikipedia.org/wiki?curid=51251625", "title": "Infinitum AS", "text": "Infinitum AS\n\nInfinitum AS, former Norsk Resirk AS, is a corporation that operates the national paid recycling scheme for bottles and cans marked with the official \"recyclable\" or \"deposit\" (Pant in Norwegian) logo in Norway. The beverages containers included in the program are the ones made of aluminum, steel and plastic (PET) produced in or imported to the country. The deposit scheme for certain one-way containers is mandatory in Norway by law.\n\nThe company was established in 1999 and is owned by companies and organizations in beverage industry and food trading (giant chain stores). The company aims to ensure the highest possible return in deposit recycling packaging for beverages at the lowest cost and environmental impact, for the time being, Infinitum managed to reach 95% return rate for one-way containers in Norway.\n"}
{"id": "9457857", "url": "https://en.wikipedia.org/wiki?curid=9457857", "title": "James A. Dombrowski", "text": "James A. Dombrowski\n\nJames Anderson Dombrowski (January 17, 1897 - May 2, 1983) was a southern white Methodist minister and intellectual who was active in the Civil Rights Movement of the 1950s and 1960s. He lived in New Orleans from 1946 until his death but was involved in public affairs across the country.\n\nJames Dombrowski was born in Tampa, Florida, to William Dombrowski and the former Isabella Skinner. He attended public schools in Tampa and Newark, New Jersey. He obtained a bachelor's degree from Methodist-affiliated Emory University in Atlanta, Georgia, in 1923. Dombrowski also attended Union Theological Seminary and Columbia University, both in New York City. He received his Ph.D. from Columbia in 1933. Dombrowski studied under Reinhold Niebuhr and the liberal Methodist clergyman Harry F. Ward.\n\nDombrowski enlisted in the United States Army Air Forces during World War I, and served from October 1917 to March 1919 as an airplane mechanic near Paris. He obtained the rank of sergeant.\n\nHe was the first secretary of the Emory University Alumni Association and the founding editor of \"Emory Alumnus\". In 1926, he became the assistant pastor of a Methodist church in Berkeley, California. He married the former Ellen Krida of New York, the daughter of Arthur Krida and the former Johanna Kunkel. There were no children.\n\nDombrowski was cofounder with Myles Horton and educator Don West of the Highlander Folk School in Monteagle in Grundy County in southeastern Tennessee. He was an administrator at Highlander from 1933 to 1942. This institution took an early lead in the civil rights movement, and Martin Luther King, Jr., and Rosa Parks obtained instruction there during the 1950s. So did various southern leaders in organized labor. Highlander was a particular \"bête noire\" to segregationists, who claimed that it was a communist-oriented organization. In 1957, a photograph was taken of an audience at the school, which showed King sitting on the front row next to Abner Berry, the correspondent for the communist newspaper, the \"Daily Worker\". King's enemies posted the photograph on billboards across the South in an attempt to discredit the civil rights movement.\n\nDombrowski also founded the Conference of Younger Churchmen of the South, established in 1934. He was executive director of both the Southern Conference for Human Welfare from 1942 to 1946 and the Southern Conference Educational Fund from 1946 to 1966. He edited the liberal journal \"Southern Patriot\" from 1942 to 1966. He was the founder of the Southern Organizing Committee for Economic and Social Justice from 1975 until his death.\n\nDombrowski was the primary defendant in a landmark civil liberties case decided in 1965 by the United States Supreme Court. In \"Dombrowski v. Pfister\", the court struck down a Louisiana law that attempted to force members of anti-segregation groups to register as pro-communist subversives. Dombrowski briefly joined the Socialist Party in the 1930s but then became a Democrat during U.S. President Franklin D. Roosevelt's New Deal. He denied charges of being communist, and he had left the Highlander School before segregationists challenged it for loyalty.\n\nUnder Dombrowski's leadership, a number of white southerners joined the Southern Conference Educational Fund and labored to end segregation and the disfranchisement of blacks in the South.\n\nDombrowski wrote \"The Early Days of Christian Socialism in America\" (1937). He was also an engraver and artist. Some of his paintings were donated to the University of New Orleans.\n\nHe died in New Orleans. His body was cremated.\n\n\n</ref>\n"}
{"id": "4361011", "url": "https://en.wikipedia.org/wiki?curid=4361011", "title": "Kröger–Vink notation", "text": "Kröger–Vink notation\n\nKröger–Vink notation is a set of conventions that are used to describe electric charge and lattice position for point defect species in crystals. It is primarily used for ionic crystals and is particularly useful for describing various defect reactions. It was proposed by F. A. Kröger and H. J. Vink.\n\nA Schottky defect is an intrinsic point defect that creates vacancies on both the cation and anion sublattices. This defect occurs in ionic crystals when one (positively charged) cation and one (negatively charged) anion leave the lattice simultaneously, resulting in two vacant lattice sites. Because the mass, site, and charge must remain balanced, these vacancies always occur in stoichiometric ratios. However, due to the loss of ions within the crystal lattice, these Schottky defects tend to lead to a decrease in the density of the material because vacancies have been created.\n\nSimilarly to a Schottky defect, a Frenkel defect is an intrinsic point defect that produces a vacancy site on either the cation or anion sublattice along with an interstitial site on that same lattice. In an ionic crystal, this occurs when a cation or anion leaves its site in the sublattice, creating the vacancy, and moves to another location to create an interstitial. These Frenkel defect pairs maintain a balanced mass, site, and charge ratio throughout the relocation of the ions. Since the movement remains within the material's single lattice, the density remains the same.\n\nThe notation follows the scheme:\n\n\n\nWhen using Kröger–Vink notation for both intrinsic and extrinsic defects, it is imperative to keep all masses, sites, and charges balanced in each reaction. If any piece is unbalanced, the reactants and the products do not equal the same entity and therefore all quantities are not conserved as they should be. The first step in this process is determining the correct type of defect and reaction that comes along with it; Schottky and Frenkel defects begin with a null reactant (∅) and produce either cation and anion vacancies (Schottky) or cation/anion vacancies and interstitials (Frenkel). Otherwise, a compound is broken down into its respective cation and anion parts for the process to begin on each lattice. From here, depending on the required steps for the desired outcome, several possibilities occur. For example, the defect may result in an ion on its own ion site or a vacancy on the cation site. To complete the reactions, the proper number of each ion must be present (mass balance), an equal number of sites must exist (site balance), and the charges of the reactants and products must also be equivalent (charge balance).\n\n\nAssume that the cation C has +1 charge and anion A has −1 charge.\n\n\nThe following oxidation–reduction tree of an ionic species shows the various ways in which a substance can be broken down. Depending on the cation-to-anion ratio, the species can either be reduced and therefore classified as n-type, or if the converse is true, the ionic species is classified as p-type. Below, the tree is shown for a further explanation of the pathways and results of each breakdown of the substance. (A is a cation and X is an anion.)\n\nFrom the chart above, there are total of four possible chemical reactions using Kröger–Vink Notation depending on the intrinsic deficiency of atoms within the material. Assume the chemical composition is AX, with A being the cation and X being the anion. (The following assumes that X is a diatomic gas, namely, oxygen and therefore A has a +2 charge as a cation. Note that this could be used to make an oxygen sensor.)\n\n\nUsing the law of mass action, defect concentration can be related to its Gibbs free energy of formation, and the energy terms (enthalpy of formation) can be calculated given the defect concentration or vice versa.\n\nFor a Schottky reaction in MgO, the Kröger–Vink defect reaction can be written as follows:\n\nNote that the vacancy on the Mg sublattice site has a −2 effective charge, and the vacancy on the oxygen sublattice site has a +2 effective charge. Using the law of mass action, the reaction equilibrium constant can be written as (square brackets indicating concentration):\n\nAccording to the reaction, the stoichiometric relation is as follows,\n\nAlso, the equilibrium constant can be related to the Gibbs free energy of formation Δ\"G\" according to the following relations,\n\nRelating equations and , we get:\n\nUsing equation , the formula can be simplified into the following form where the enthalpy of formation can be directly calculated:\n\nTherefore, given a temperature and the formation energy of Schottky defect, the intrinsic Schottky defect concentration can be calculated from the above equation.\n"}
{"id": "1722373", "url": "https://en.wikipedia.org/wiki?curid=1722373", "title": "Locard's exchange principle", "text": "Locard's exchange principle\n\nIn forensic science, Locard's exchange principle holds that the perpetrator of a crime will bring something into the crime scene and leave with something from it, and that both can be used as forensic evidence. Dr. Edmond Locard (13 December 1877 – 4 May 1966) was a pioneer in forensic science who became known as the Sherlock Holmes of France. He formulated the basic principle of forensic science as: \"Every contact leaves a trace\". Paul L. Kirk expressed the principle as follows:\n\nFragmentary or trace evidence is any type of material left at (or taken from) a crime scene, or the result of contact between two surfaces, such as shoes and the floor covering or soil, or fibers from where someone sat on an upholstered chair.\n\nWhen a crime is committed, fragmentary (or trace) evidence needs to be collected from the scene. A team of specialized police technicians goes to the scene of the crime and seals it off. They record video and take photographs of the crime scene, victim/s (if there are any) and items of evidence. If necessary, they undertake ballistics examinations. They check for foot, shoe, and tire mark impressions, plus hair as well as examine any vehicles and check for fingerprints - whole or partial.\n\nThe case studies below show how prevalent Locard's Exchange Principle is in each and every crime. The examples using Locard's Principle show not only how the transfer of trace evidence can tell the tale of what happened, but also how much care is required when collecting and evaluating trace evidence.\n\nKarola and Melanie Weimar, aged 5 and 7, lived with their parents, Reinhard and Monika, in Germany. They were reported missing on 4 August 1986. Their bodies were found on 7 August. They had been murdered.\n\nMonika first said the children had breakfast, then went to a playground. Three weeks later she said they were already dead when she returned home the previous night: Reinhard was sitting on the edge of Karola's bed, weeping and confused; he then disposed of the bodies.\n\nBoth parents were suspected, but Monika was having an affair, and was seen where Melanie's body was later found. She was convicted, but after serving her sentence, was released in 2006.\n\nInvestigators determined what clothes Monika was wearing on 3 and 4 August, but not Reinhard's clothes, so only fibers from her clothing were identified on the children's bodies, yet they were also constantly in contact with him.\n\nThe bedding contained 14 fibers from Karola's T-shirt. Frictionless tests, simulating a dead child, matched that figure better than the friction tests, simulating a live child, so Karola could have lain lifelessly in bed wearing her T-shirt, as stated by her mother.\n\n35 fibers from Monika's blouse were found on the back of Melanie's T-shirt, but only one on her bed sheet. In tests, between 6 and 10 fibers remained on the sheet. These higher numbers were thought to disprove Monika's claim that she gave her child a goodbye hug the previous day. However, there are several likely explanations. For example, the bedding was put in one bag, so fibers from the sheet could have been transferred to the cover and pillow. Only the central area of the top of the sheet was taped: it might have originally contained more than one blouse fiber, the others could have been transferred to the back or sides while in the bag.\n\nThe blouse fibers on Melanie's clothing were distributed evenly, not the clusters expected from carrying the body.\n\n265 fibers from the family car’s rear seat covers were found on Melanie's panties and the inside of her trousers, but only a small number of fibers from the front seats was found on the children. This helped disprove the theory that they were killed on the front seats.\n\nMelanie's clothes and hair were covered in 375 clinging fruits of goosegrass. As some of these itchy things were on the inside of her trousers and on her panties, the trousers must have been put on her after death.\n\nNo sand was found on the bodies or clothing (including socks and sandals) of either child, making the morning playground story unlikely.\n\nDanielle van Dam, aged 7, lived with her parents and brothers in San Diego, California. She was reported missing on 2 February 2002; her body was discovered on 27 February. Neighbor David Westerfield was almost immediately suspected, as he had gone camping in his RV, and he was convicted of her kidnapping and murder.\n\nHairs consistent with the van Dams’ dog were found in his RV, also carpet fibers consistent with Danielle's bedroom carpet. Danielle's nightly ritual was to wrestle with the dog after getting into her pajamas. The prosecution argued that those hairs and fibers got onto her pajamas through that contact, and were then carried on the pajamas to first Westerfield's house and then to his RV, when he kidnapped her from her bed. The alternative scenario is that they got onto her daytime clothes, and those of her mother and younger brother, and were carried to his house when they visited him earlier that week selling cookies. He said his laundry was out during that visit, so trace evidence from them could have got on it, and then been transferred to his bedroom and his RV (secondary Locard transfer). Also, his RV was often parked, sometimes unlocked, in the neighborhood streets, so Danielle could have sneaked inside, leaving behind that evidence.\n\nNo trace of Westerfield was found in the van Dam house.\n\n14 hairs consistent with Danielle's were found in his environment. All but one were compared on only mitochondrial DNA, so they might have come from her mother or a sibling. Most (21) of the hairs were in a dryer lint ball in his trash can, so they might have got in his laundry before the kidnapping.\n\nThere were 5 carpet fibers in his RV, but none in his house, suggesting those were deposited by someone going directly from her house to his RV, or they may have come from another house in that development.\n\nNo Danielle pajama or bedding fibers were reported in his environment. There was no trace evidence in his SUV (which casts doubt on the belief that she was transported from his house to his RV in his SUV). He vacuumed his RV after the kidnapping, but no trace evidence was in the vacuum cleaner.\n\nOne orange fiber with her body was consistent with about 200 in his house and 20 in his SUV (none in his RV), while 21 blue fibers with her body were consistent with 10 in his house and 46 in his RV (none in his SUV). Contrary to media reports, only a few items from her house were tested so that can’t be excluded as the source. In particular, the clothes of Danielle and her family during the cookie sale were not determined and eliminated. There were apparently two different types of the orange fibers, dull and very bright (so the number which matched might have been much less than 200). There were red fibers with her fingernails, and many other fibers with her body, which could not be matched to his environment. The only non-Danielle hair found with her body wasn’t his, nor was any desert sand reported with the body, and no soil or vegetation from the dump site was reported on his shoes, laundry, shovel or RV.\n\nTo explain why so much expected evidence was missing, the prosecution argued that he went on a cleaning frenzy, and tossed out evidence.\n\nIt is also mentioned in an episode of \"Hawaii Five-O\"\n\n"}
{"id": "6620824", "url": "https://en.wikipedia.org/wiki?curid=6620824", "title": "Lydian alphabet", "text": "Lydian alphabet\n\nLydian script was used to write the Lydian language. Like other scripts of Anatolia in the Iron Age, the Lydian alphabet is related to the East Greek alphabet, but it has unique features.\n\nThe first modern codification of the Lydian alphabet was made by Roberto Gusmani in 1964, in a combined lexicon, grammar, and text collection.\n\nEarly Lydian texts were written either from left to right or from right to left. Later texts all run from right to left. One surviving text is in the bi-directional boustrophedon manner. Spaces separate words except in one text that uses dots instead. Lydian uniquely features a quotation mark in the shape of a right triangle.\n\nThe Lydian alphabet is closely related to the other alphabets of Asia Minor as well as to the Greek alphabet. It contains letters for 26 sounds. Some are represented by more than one symbol, which is considered one \"letter.\" Unlike the Carian alphabet, which had an \"f\" derived from Φ, the Lydian \"f\" has the peculiar \"8\" shape also found in the Etruscan alphabet.\nIn addition two digraphs, \"aa\" and \"ii\", appear to be allophones of [a] and [i] under speculative circumstances, such as lengthening from stress. A schwa was evidently not written: \"dctdid, kśbλtok-\".\n\n (Image: ) - Ora - \"Month\"\n\nThe Lydian alphabet was added to the Unicode Standard in April, 2008 with the release of version 5.1. It is encoded in Plane 1 (Supplementary Multilingual Plane).\n\nThe Unicode block for Lydian is U+10920–U+1093F:\n\n\n"}
{"id": "323033", "url": "https://en.wikipedia.org/wiki?curid=323033", "title": "Metaphysics of presence", "text": "Metaphysics of presence\n\nThe concept of the metaphysics of presence is an important consideration in deconstruction. Deconstructive interpretation holds that the entire history of Western philosophy with its language and traditions has emphasized the desire for immediate access to meaning, and thus built a metaphysics or ontotheology based on privileging presence over absence.\n\nIn \"Being and Time\" (1927; transl. 1962), Martin Heidegger argues that the concept of time prevalent in all Western thought has largely remained unchanged since the definition offered by Aristotle in the \"Physics\". Heidegger says, \"Aristotle's essay on time is the first detailed Interpretation of this phenomenon [time] which has come down to us. Every subsequent account of time, including Henri Bergson's, has been essentially determined by it.\" Aristotle defined time as \"the number of movement in respect of before and after\". By defining time in this way Aristotle privileges what is present-at-hand, namely the \"presence\" of time. Heidegger argues in response that \"entities are grasped in their Being as 'presence'; this means that they are understood with regard to a definite mode of time – the 'Present'\". Central to Heidegger's own philosophical project is the attempt to gain a more authentic understanding of time. Heidegger considers time to be the unity of three ecstases: the past, the present, and the future. \n\nDeconstructive thinkers, like Jacques Derrida, describe their task as the questioning or \"deconstruction\" of this metaphysical tendency in Western philosophy. Derrida writes, \"Without a doubt, Aristotle thinks of time on the basis of ousia as parousia, on the basis of the now, the point, etc. And yet an entire reading could be organized that would repeat in Aristotle's text both this limitation and its opposite.\" This argument is largely based on the earlier work of Heidegger, who in \"Being and Time\" claimed that the theoretical attitude of pure presence is parasitical upon a more originary involvement with the world in concepts such as the ready-to-hand and being-with.\n\nThe presence to which Heidegger refers is both a presence as in a \"now\" and also a presence as in an eternal present, as one might associate with God or the \"eternal\" laws of science. This hypostatized (underlying) belief in presence is undermined by novel phenomenological ideas, such that presence itself does not subsist, but comes about primordially through the action of our futural projection, our realization of finitude and the reception or rejection of the traditions of our time.\n"}
{"id": "2210028", "url": "https://en.wikipedia.org/wiki?curid=2210028", "title": "Mirror image rule", "text": "Mirror image rule\n\nIn the law of contracts, the mirror image rule, also referred to as an unequivocal and absolute acceptance requirement, states that an offer must be accepted exactly with no modifications. The offeror is the master of one's own offer. An attempt to accept the offer on different terms instead creates a counter-offer, and this constitutes a rejection of the original offer.\n\nThe English common law established the concepts of \"consensus ad idem\", offer, acceptance and counter-offer. The leading case on counter-offer is \"Hyde v Wrench\" [1840]. The phrase \"Mirror-Image Rule\" is rarely (if at all) used by English lawyers; but the concept remains valid, as in \"Gibson v Manchester City Council\" [1979], and \"Butler Machine Tool v Excello\".\n\nThis position is adhered to in Australia (New South Wales). If a person were to accept an offer, but make a modification, then they are actually rejecting the offer presented to them and are proposing a counter-offer: \"Masters v Cameron\" (1954) 91 CLR 353. That modifying party is then the one making a new offer, and the original offeror is now the one who has to accept.\n\nIn the United States, this rule still exists at common law. However, the Uniform Commercial Code (\"UCC\") dispenses with it in § 2-207. (but it can also be argued that § 2-207(1) enforces the mirror image rule) Therefore, its applicability depends upon what law governs. Most states have adopted the UCC, which governs transactions in goods. Contracts for services or land, for example, would not be governed by the UCC. The 2nd restatement of contracts also provides that when parties have not agreed to an essential term, \"a term which is reasonable in the circumstances is supplied by the court.\" However, it may not be possible for a reasonable term to be supplied by the court.\n"}
{"id": "11934923", "url": "https://en.wikipedia.org/wiki?curid=11934923", "title": "Natural topology", "text": "Natural topology\n\nIn any domain of mathematics, a space has a natural topology if there is a topology on the space which is \"best adapted\" to its study within the domain in question. In many cases this imprecise definition means little more than the assertion that the topology in question arises \"naturally\" or \"canonically\" (see mathematical jargon) in the given context.\nNote that in some cases multiple topologies seem \"natural\". For example, if \"Y\" is a subset of a totally ordered set \"X\", then the induced order topology, i.e. the order topology of the totally ordered \"Y\", where this order is inherited from \"X\", is coarser than the subspace topology of the order topology of \"X\".\n\n\"Natural topology\" does quite often have a more specific meaning, at least given some prior contextual information: the natural topology is a topology which makes a natural map or collection of maps continuous. This is still imprecise, even once one has specified what the natural maps are, because there may be many topologies with the required property. However, there is often a finest or coarsest topology which makes the given maps continuous, in which case these are obvious candidates for \"the\" natural topology.\n\nThe simplest cases (which nevertheless cover \"many\" examples) are the initial topology and the final topology (Willard (1970)). The initial topology is the coarsest topology on a space \"X\" which makes a given collection of maps from \"X\" to topological spaces \"X\" continuous. The final topology is the finest topology on a space \"X\" which makes a given collection of maps from topological spaces \"X\" to \"X\" continuous.\n\nTwo of the simplest examples are the natural topologies of subspaces and quotient spaces.\n\nAnother example is that any metric space has a natural topology induced by its metric.\n\n\n"}
{"id": "48768665", "url": "https://en.wikipedia.org/wiki?curid=48768665", "title": "Non-malleable codes", "text": "Non-malleable codes\n\nThe notion of non-malleable codes was introduced in 2010 by Dziembowski, Pietrzak, and Wichs, for relaxing the notion of error-correction and error-detection. Informally, a code is non-malleable if the message contained in a modified code-word is either the original message, or a completely unrelated value. Non-malleable codes provide a useful and meaningful security guarantee in situations where traditional error-correction and error-detection is impossible; for example, when the attacker can completely overwrite the encoded message. Although such codes do not exist if the family of \"tampering functions\" F is completely unrestricted, they are known to exist for many broad tampering families F.\n\nTo know the operation schema of non-malleable code, we have to have a knowledge of the basic experiment it based on. The following is the three step method of tampering experiment.\n\nThe tampering experiment can be used to model several interesting real-world settings, such as data transmitted over a noisy channel, or adversarial tampering of data stored in the memory of a physical device. Having this experimental base, we would like to build special encoding/decoding procedures formula_12, which give us some meaningful guarantees about the results of the above tampering experiment, for large and interesting families formula_13 of tampering functions. The following are several possibilities for the type of guarantees that we may hope for.\n\nOne very natural guarantee, called error-correction, would be to require that for any tampering function and any \"source-message s\", the tampering experiment always produces the correct decoded message formula_14.\n\nA weaker guarantee, called error-detection, requires that the tampering-experiment always results in either the correct value formula_14 or a special symbol formula_16 indicating that tampering has been detected. This notion of error-detection is a weaker guarantee than error-correction, and achievable for larger F of tampering functions.\n\nA non-malleable code ensures that either the tampering experiment results in a correct decoded-message formula_14, or the decoded-message formula_10 is completely independent of and unrelated to the \"source-message\" formula_1. In other word, the notion of non-malleability for codes is similar, in spirit, to notions of non-malleability for cryptographic primitives (such as encryption2, commitments and zero-knowledge proofs), introduced by the seminal work of Dolev, Dwork and Naor.\n\nCompared to error correction or error detection, the \"right\" formalization of non-malleable codes is somewhat harder to define. Let formula_20 be a random variable for the value of the decoded-message, which results when we run the tampering experiment with source-message formula_1 and tampering-function formula_22, over the randomness of the encoding procedure. Intuitively, we wish to say that the distribution of formula_20 is independent of the encoded message formula_1. Of course, we also want to allow for the case where the tampering experiment results in formula_14 (for example, if the tampering function is identity), which clearly depends on formula_1.\n\nThus, we require that for every tampering-function formula_5, there exists a distribution formula_28 which outputs either concrete values formula_10 or a special same formula_30 symbol, and faithfully models the distribution of formula_20 for all formula_1 in the following sense: for every source message formula_1, the distributions of formula_20 and formula_28 are statistically close when the formula_30 symbol is interpreted as formula_1. That is, formula_28 correctly simulates the \"outcome\" of the tampering-experiment with a function formula_5 without knowing the source-messages formula_1, but it is allowed some ambiguity by outputting a same formula_30 symbol to indicate that the decoded-message should be the same as the source-message, without specifying what the exact value is. The fact that formula_28 depends on only formula_22 and not on formula_1, shows that the outcome of formula_20 is independent of formula_1, exempting equality.\n\nNotice that non-malleability is a weaker guarantee than error correction/detection; the latter ensure that any change in the code-word can be corrected or at least detected by the decoding procedure, whereas the former does allow the message to be modified, but only to an unrelated value. However, when studying error correction/detection we usually restrict ourselves to limited forms of tampering which preserve some notion of distance (e.g., usually hamming distance) between the original and tampered code-word. \nFor example, it is already impossible to achieve error correction/detection for the simple family of functions formula_47 which, for every constant formula_6, includes a \"constant\" function formula_49 that maps all inputs to formula_6. There is always some function in formula_47 that maps everything to a valid code-word formula_6. In contrast, it is trivial to construct codes that are non-malleable w.r.t formula_47, as the output of a constant function is clearly independent of its input. The prior works on non-malleable codes show that one can construct non-malleable codes for highly complex tampering function families formula_13 for which error correction/detection can not be achievable.\n\nAs one very concrete example, we study non-malleability with respect to the family of functions formula_22 which specify, for each bit of the code-word formula_3, whether to keep it as is, flip it, set it to 0, set it to 1. That is, each bit of the code-word is modified arbitrarily but independently of the value of the other bits of the code-word. We call this the “bit-wise independent tampering” family formula_57. Note that this family contains constant functions formula_47 and constant-error functions formula_59 as subsets. Therefore, as we have mentioned, error-correction and error-detection cannot be achieved w.r.t. this family. Nevertheless, the following can show an efficient non-malleable code for this powerful family.\n\nWith formula_57 we denote the family which contains all tampering functions that tamper every bit independently. Formally, this family contains all functions <math>f_i: \\left\\\n"}
{"id": "33197556", "url": "https://en.wikipedia.org/wiki?curid=33197556", "title": "Nuremberg International Human Rights Award", "text": "Nuremberg International Human Rights Award\n\nThe Nuremberg International Human Rights Award is a German award founded on September 17, 1995. The date chosen is significant; 60 years earlier, the Nuremberg Race Laws were adopted. Also, on September 17, 1939, Poland was invaded by the Soviet Union, soon after the German invasion that marked the beginning of World War II\n\nThe winner is endowed with 15,000 euros (20,235 USD).\n\n"}
{"id": "31374246", "url": "https://en.wikipedia.org/wiki?curid=31374246", "title": "Parable of the Poisoned Arrow", "text": "Parable of the Poisoned Arrow\n\nThe parable of the arrow (or 'Parable of the poisoned arrow') is a Buddhist parable that illustrates the skeptic and pragmatic themes of the \"Cula-Malunkyovada Sutta\" (The Shorter Instructions to Malunkya) which is part of the middle length discourses (Majjhima Nikaya), one of the five sections of the Sutta Pitaka. The Pāli text contains a number of \"hapax legomena\" or otherwise obscure archery terms and these are generally poorly dealt with in English translations.\n\nThe sutta begins at Jetavana where the monk Malunkyaputta is troubled by Gautama Buddha's silence on the fourteen unanswerable questions, which include queries about the nature of the cosmos and life after the death of a Buddha. Malunkyaputta then meets with Gautama Buddha and asks him for the answers to these questions, he says that if he fails to respond, Malunkya will renounce his teachings. Gautama responds by first stating that he never promised to reveal ultimate metaphysical truths such as those and then uses the story of a man who has been shot with a poisoned arrow to illustrate that those questions are irrelevant to his teachings. \n\nThích Nhất Hạnh comments on the way the parable of the poisoned arrow illustrates Gautama Buddha's anti-metaphysical views:\n\nSangharakshita notes that \"The important thing is to get rid of the arrow, not to enquire where it came from.\"\n\nThe parable is considered a teaching on being practical and dealing with the situation at hand.\n\nThe story is also preserved in two Chinese translations of Prakrit sources. \n\nEach of these uses different translation strategies. T 1.26 transposes the various archery terms into items and materials familiar to a Chinese audience; while T 1.94 uses transliterated Indic terms that do not match the Pāli in most cases. Thus the obscure Pāli terms remain largely obscure for now. A third Chinese text, \"Mahāprajñāpāramitāupadeśa\" (T 1509 at T XXV 170a8-b1) contains a paraphrase of this text.\n\n"}
{"id": "24702", "url": "https://en.wikipedia.org/wiki?curid=24702", "title": "Peace", "text": "Peace\n\nPeace is the concept of harmonious well-being and freedom from hostile aggression. In a social sense, peace is commonly used to mean a lack of conflict (such as war) and freedom from fear of violence between individuals or heterogeneous (relatively foreign or distinct) groups.\n\nThroughout history some of the most extraordinary and benevolent leaders have used peace talks to establish a certain type of behavioral restraint that has resulted in the establishment of regional peace or economic growth through various forms of agreements or peace treaties. Such behavioral restraint has often resulted in de-escalation of rhetorical and physical conflicts, greater economic interactivity, and consequently substantial prosperity. The avoidance of war or violent hostility can be the result of thoughtful active listening and communication that enables greater genuine mutual understanding and therefore compromise. Leaders often benefit tremendously from the prestige of peace talks and treaties that can result in substantially enhanced popularity.\n\n“Psychological peace” (such as a peaceful thinking and emotions) is perhaps less well defined yet often a necessary precursor to establishing \"behavioral peace.\" Peaceful behavior sometimes results from a \"peaceful inner disposition.\" Some have expressed the belief that peace can be initiated with a certain quality of inner tranquility that does not depend upon the uncertainties of daily life for its existence. The acquisition of such a \"peaceful internal disposition\" for oneself and others can contribute to resolving of otherwise seemingly irreconcilable competing interests.\n\nBecause psychological peace can be important to Behavioral peace, leaders sometimes de-escalate conflicts through compliments and generosity. Small gestures of rhetorical and actual generosity have been shown in psychological research to often result in larger levels of reciprocal generosity (and even virtuous circles of generosity). Such benevolent selfless behavior can eventually become a pattern that may become a lasting basis for improved relations between individuals and groups of people. Peace talks often start without preconditions and preconceived notions, because they are more than just negotiating opportunities. They place attention on peace itself over and above what may have been previously perceived as the competing needs or interests of separate individuals or parties to elicit peaceful feelings and therefore produce benevolent behavioral results. Peace talks are sometimes also uniquely important learning opportunities for the individuals or parties involved.\n\nThe term-'peace' originates most recently from the Anglo-French \"pes,\" and the Old French \"pais\", meaning \"peace, reconciliation, silence, agreement\" (11th century). But, \"Pes\" itself comes from the Latin \"pax\", meaning \"peace, compact, agreement, treaty of peace, tranquility, absence of hostility, harmony.\" The English word came into use in various personal greetings from c.1300 as a translation of the Hebrew word shalom, which, according to Jewish theology, comes from a Hebrew verb meaning 'to be complete, whole'. Although 'peace' is the usual translation, however, it is an incomplete one, because 'shalom,' which is also cognate with the Arabic \"salaam\", has multiple other meanings in addition to peace, including justice, good health, safety, well-being, prosperity, equity, security, good fortune, and friendliness, as well as simply the greetings, \"hello\" and \"goodbye\". At a personal level, peaceful behaviors are kind, considerate, respectful, just, and tolerant of others' beliefs and behaviors — tending to manifest goodwill.\n\nThis latter understanding of peace can also pertain to an individual's introspective sense or concept of her/himself, as in being \"at peace\" in one's own mind, as found in European references from c.1200. The early English term is also used in the sense of \"quiet\", reflecting calm, serene, and meditative approaches to family or group relationships that avoid quarreling and seek tranquility — an absence of disturbance or agitation.\n\nIn many languages, the word for peace is also used as a greeting or a farewell, for example the Hawaiian word aloha, as well as the Arabic word \"salaam\". In English the word peace is occasionally used as a farewell, especially for the dead, as in the phrase \"rest in peace\".\n\nWolfgang Dietrich in his research project which led to the book \"The Palgrave International Handbook of Peace Studies\" (2011) maps the different meanings of peace in different languages and from different regions across the world. Later, in his \"Interpretations of Peace in History and Culture\" (2012), he groups the different meanings of peace into five peace families: Energetic/Harmony, Moral/Justice, Modern/Security, Postmodern/Truth, and Transrational, a synthesis of the positive sides of the four previous families and the society.\n\nReligious beliefs often seek to identify and address the basic problems of human life, including the conflicts between, among, and within persons and societies. In ancient Greek-speaking areas the virtue of peace was personified as the goddess Eirene, and in Latin-speaking areas as the goddess Pax. Her image was typically represented by ancient sculptors as that of a full-grown woman, usually with a horn of plenty and scepter and sometimes with a torch or olive leaves.\n\nChristians, who believe Jesus of Nazareth to be the Jewish Messiah called Christ (meaning Anointed One), interpret Isaiah 9:6 as a messianic prophecy of Jesus in which he is called the \"Prince of Peace.\" In the Gospel of Luke, Zechariah celebrates his son John: And you, child, will be called prophet of the Most High, for you will go before the Lord to prepare his ways, to give his people knowledge of salvation through the forgiveness of their sins, because of the tender mercy of our God by which the daybreak from on high will visit us to shine on those who sit in darkness and death's shadow, to guide our feet into the path of peace.\n\nNumerous pontifical documents on the Holy Rosary document a continuity of views of the Popes to have confidence in the Holy Rosary as a means to foster peace. Subsequently, to the Encyclical Mense maio,1965, in which he urged the practice of the Holy Rosary, \"the prayer so dear to the Virgin and so much recommended by the Supreme Pontiffs,\" and as reaffirmed in the encyclical Christi Matri, 1966, to implore peace, Pope Paul VI stated in the apostolic Recurrens mensis, October 1969, that the Rosary is a prayer that favors the great gift of peace.\n\nIslam derived from the root word salam which literally means peace. Muslims are called followers of Islam. Quran clearly stated \"Those who have believed and whose hearts are assured by the remembrance of Allah. Unquestionably, by the remembrance of Allah, hearts are assured\" and stated \"O you who have believed, when you are told, \"Space yourselves\" in assemblies, then make space; Allah will make space for you. And when you are told, \"Arise,\" then arise; Allah will raise those who have believed among you and those who were given knowledge, by degrees. And Allah is Acquainted with what you do.\" \n\nBuddhists believe that peace can be attained once all suffering ends. They regard all suffering as stemming from cravings (in the extreme, greed), aversions (fears), or delusions. To eliminate such suffering and achieve personal peace, followers in the path of the Buddha adhere to a set of teachings called the Four Noble Truths — a central tenet in Buddhist philosophy.\n\nHindu texts contain the following passages:\n\nPsychological or inner peace (i.e. peace of mind) refers to a state of being internally or spiritually at peace, with sufficient knowledge and understanding to keep oneself calm in the face of apparent discord or stress. Being internally \"at peace\" is considered by many to be a healthy mental state, or homeostasis and to be the opposite of feeling stressful, mentally anxious, or emotionally unstable. Within the meditative traditions, the psychological or inward achievement of \"peace of mind\" is often associated with bliss and happiness.\n\nPeace of mind, serenity, and calmness are descriptions of a disposition free from the effects of stress. In some meditative traditions, inner peace is believed to be a state of consciousness or enlightenment that may be cultivated by various types of meditation, prayer, t'ai chi ch'uan (太极拳, tàijíquán), yoga, or other various types of mental or physical disciplines. Many such practices refer to this peace as an experience of knowing oneself. An emphasis on finding one's inner peace is often associated with traditions such as Buddhism, Hinduism, and some traditional Christian contemplative practices such as monasticism, as well as with the New Age movement.\n\nSatyagraha ( ) is a philosophy and practice of nonviolent resistance developed by Mohandas Karamchand Gandhi. He deployed satyagraha techniques in campaigns for Indian independence and also during his earlier struggles in South Africa.\n\nThe word \"satyagraha\" itself was coined through a public contest that Gandhi sponsored through the newspaper he published in South Africa, 'Indian Opinion', when he realized that neither the common, contemporary Hindu language nor the English language contained a word which fully expressed his own meanings and intentions when he talked about his nonviolent approaches to conflict. According to Gandhi's autobiography, the contest winner was Maganlal Gandhi (presumably no relation), who submitted the entry 'sadagraha', which Gandhi then modified to 'satyagraha'. Etymologically, this Hindic word means 'truth-firmness', and is commonly translated as 'steadfastness in the truth' or 'truth-force'.\nSatyagraha theory also influenced Martin Luther King Jr. during the campaigns he led during the civil rights movement in the United States. The theory of satyagraha sees means and ends as inseparable. Therefore, it is contradictory to try to use violence to obtain peace. As Gandhi wrote: \"They say, 'means are, after all, means'. I would say, 'means are, after all, everything'. As the means so the end...\" A contemporary quote sometimes attributed to Gandhi, but also to A. J. Muste, sums it up: 'There is no way to peace; peace is the way.'\n\nSince classical times, it has been noted that peace has sometimes been achieved by the victor over the vanquished by the imposition of ruthless measures. In his book \"Agricola\" the Roman historian Tacitus includes eloquent and vicious polemics against the rapacity and greed of Rome. One, that Tacitus says is by the Caledonian chieftain Calgacus, ends \"Auferre trucidare rapere falsis nominibus imperium, atque ubi solitudinem faciunt, pacem appellant.\" (To ravage, to slaughter, to usurp under false titles, they call empire; and where they make a desert, they call it peace. — Oxford Revised Translation).\n\nDiscussion of peace is therefore at the same time a discussion on the form of such peace. Is it simple absence of mass organized killing (war) or does peace require a particular morality and justice? (\"just peace\").\nA peace must be seen at least in two forms: \n\nMore recently, advocates for radical reform in justice systems have called for a public policy adoption of non-punitive, non-violent Restorative Justice methods, and many of those studying the success of these methods, including a United Nations working group on Restorative Justice, have attempted to re-define justice in terms related to peace. From the late 2000s on, a Theory of Active Peace has been proposed which conceptually integrates justice into a larger peace theory.\n\nThe longest continuing period of neutrality among currently existing states is observed in Switzerland, which has had an official policy of neutrality and general peace since 1815 (for years as of 20). This was made possible partly by the periods of relative peace in Europe and the world known as Pax Britannica (1815-1914), Pax Europaea/Pax Americana (since 1950s), and Pax Atomica (also since the 1950s).\n\nOther examples of long periods of peace are:\n\nPacifism is the categorical opposition to the behaviors of war or violence as a means of settling disputes or of gaining advantage. Pacifism covers a spectrum of views ranging from the belief that international disputes can and should all be resolved via peaceful behaviors; to calls for the abolition of various organizations which tend to institutionalize aggressive behaviors, such as the military, or arms manufacturers; to opposition to any organization of society that might rely in any way upon governmental force. Such groups which sometimes oppose the governmental use of force include anarchists and libertarians. Absolute pacifism opposes violent behavior under all circumstance, including defense of self and others.\n\nPacifism may be based on moral principles (a deontological view) or pragmatism (a consequentialist view). Principled pacifism holds that all forms of violent behavior are inappropriate responses to conflict, and are morally wrong. Pragmatic pacifism holds that the costs of war and inter-personal violence are so substantial that better ways of resolving disputes must be found. Pacifists in general reject theories of Just War. Pacifism tends to place its initial focus on the need for a \"peaceful behavior\" ahead of any focus on the need for a \"peaceful inner disposition.\"\n\nThe United Nations (UN) is an international organization whose stated aims are to facilitate cooperation in international law, international security, economic development, social progress, human rights, and achieving world peace. The UN was founded in 1945 after World War II to replace the League of Nations, to stop wars between countries, and to provide a platform for dialogue.\n\nThe UN, after approval by the Security Council, sends peacekeepers to regions where armed conflict has recently ceased or paused to enforce the terms of peace agreements and to discourage combatants from resuming hostilities. Since the UN does not maintain its own military, peacekeeping forces are voluntarily provided by member states of the UN. The forces, also called the \"Blue Helmets\", who enforce UN accords are awarded United Nations Medals, which are considered international decorations instead of military decorations. The peacekeeping force as a whole received the Nobel Peace Prize in 1988.\n\nThe principal forerunner of the United Nations was the League of Nations. It was created at the Paris Peace Conference of 1919, and emerged from the advocacy of Woodrow Wilson and other idealists during World War I. The Covenant of the League of Nations was included in the Treaty of Versailles in 1919, and the League was based in Geneva until its dissolution as a result of World War II and replacement by the United Nations. The high hopes widely held for the League in the 1920s, for example amongst members of the League of Nations Union, gave way to widespread disillusion in the 1930s as the League struggled to respond to challenges from Nazi Germany, Fascist Italy, and Japan.\n\nOne of the most important scholars of the League of Nations was Sir Alfred Zimmern. Like many of the other British enthusiasts for the League, such as Gilbert Murray and Florence Stawell - the so-called \"Greece and peace\" set - he came to this from the study of the classics.\n\nThe creation of the League of Nations, and the hope for informed public opinion on international issues (expressed for example by the Union for Democratic Control during World War I), also saw the creation after World War I of bodies dedicated to understanding international affairs, such as the Council on Foreign Relations in New York and the Royal Institute of International Affairs at Chatham House in London. At the same time, the academic study of international relations started to professionalize, with the creation of the first professorship of international politics, named for Woodrow Wilson, at Aberystwyth, Wales, in 1919.\n\nThe late 19th century idealist advocacy of peace which led to the creation of the Nobel Peace Prize, the Rhodes Scholarships, the Carnegie Endowment for International Peace, and ultimately the League of Nations, also saw the re-emergence of the ancient Olympic ideal. Led by Pierre de Coubertin, this culminated in the holding in 1896 of the first of the modern Olympic Games.\n\nThe highest honour awarded to peace maker is the Nobel Prize in Peace, awarded since 1901 by the Norwegian Nobel Committee. It is awarded annually to internationally notable persons following the prize's creation in the will of Alfred Nobel. According to Nobel's will, the Peace Prize shall be awarded to the person who \"...shall have done the most or the best work for fraternity between nations, for the abolition or reduction of standing armies and for the holding and promotion of peace congresses.\"\n\nIn creating the Rhodes Scholarships for outstanding students from the United States, Germany and much of the British Empire, Cecil Rhodes wrote in 1901 that 'the object is that an understanding between the three great powers will render war impossible and educational relations make the strongest tie'. This peace purpose of the Rhodes Scholarships was very prominent in the first half of the 20th century, and became prominent again in recent years under Warden of the Rhodes House Donald Markwell, a historian of thought about the causes of war and peace. This vision greatly influenced Senator J. William Fulbright in the goal of the Fulbright fellowships to promote international understanding and peace, and has guided many other international fellowship programs, including the Schwarzman Scholars to China created by Stephen A. Schwarzman in 2013.\n\nThe International Gandhi Peace Prize, named after Mahatma Gandhi, is awarded annually by the Government of India. It is launched as a tribute to the ideals espoused by Gandhi in 1995 on the occasion of the 125th anniversary of his birth. This is an annual award given to individuals and institutions for their contributions towards social, economic and political transformation through non-violence and other Gandhian methods. The award carries Rs. 10 million in cash, convertible in any currency in the world, a plaque and a citation. It is open to all persons regardless of nationality, race, creed or sex.\n\nThe Student Peace Prize is awarded biennially to a student or a student organization that has made a significant contribution to promoting peace and human rights.\n\nThe Culture of Peace News Network, otherwise known simply as CPNN, is a UN authorized interactive online news network, committed to supporting the global movement for a culture of peace.\n\nEvery year in the first week of November, the Sydney Peace Foundation presents the Sydney Peace Prize. The Sydney Peace Prize is awarded to an organization or an individual whose life and work has demonstrated significant contributions to:\nThe achievement of peace with justice locally, nationally or internationally\nThe promotion and attainment of human rights\nThe philosophy, language and practice of non violence\n\nA peace museum is a museum that documents historical peace initiatives. Many peace museums also provide advocacy programs for nonviolent conflict resolution. This may include conflicts at the personal, regional or international level.\n\nSmaller institutions:\n\nThe following are monuments to peace:\n\nMany different theories of \"peace\" exist in the world of peace studies, which involves the study of de-escalation, conflict transformation, disarmament, and cessation of violence. The definition of \"peace\" can vary with religion, culture, or subject of study.\n\nOne definition is that peace is a state of balance and understanding in yourself and between others, where respect is gained by the acceptance of differences, tolerance persists, conflicts are resolved through dialog, people's rights are respected and their voices are heard, and everyone is at their highest point of serenity without social tension.\n\nThe \"Peace & War Game\" is an approach in game theory to understand the relationship between peace and conflicts.\n\nThe iterated game hypotheses was originally used by academic groups and computer simulations to study possible strategies of cooperation and aggression.\n\nAs peace makers became richer over time, it became clear that making war had greater costs than initially anticipated. One of the well studied strategies that acquired wealth more rapidly was based on Genghis Khan, i.e. a constant aggressor making war continually to gain resources. This led, in contrast, to the development of what's known as the \"provokable nice guy strategy\", a peace-maker until attacked, improved upon merely to win by occasional forgiveness even when attacked.\n\nThere exists a strategy of multiple players who can continue to gain wealth cooperating with each other while bleeding a constantly aggressive player. \n\nThe classical \"realist\" position is that the key to promoting order between states, and so of increasing the chances of peace, is the maintenance of a balance of power between states - a situation where no state is so dominant that it can \"lay down the law to the rest\". Exponents of this view have included Metternich, Bismarck, Hans Morgenthau, and Henry Kissinger. A related approach - more in the tradition of Hugo Grotius than Thomas Hobbes - was articulated by the so-called \"English school of international relations theory\" such as Martin Wight in his book \"Power Politics\" (1946, 1978) and Hedley Bull in \"The Anarchical Society\" (1977).\n\nAs the maintenance of a balance of power could in some circumstances require a willingness to go to war, some critics saw the idea of a balance of power as promoting war rather than promoting peace. This was a radical critique of those supporters of the Allied and Associated Powers who justified entry into World War I on the grounds that it was necessary to preserve the balance of power in Europe from a German bid for hegemony.\n\nIn the second half of the 20th century, and especially during the cold war, a particular form of balance of power - mutual nuclear deterrence - emerged as a widely held doctrine on the key to peace between the great powers. Critics argued that the development of nuclear stockpiles increased the chances of war rather than peace, and that the \"nuclear umbrella\" made it \"safe\" for smaller wars (e.g. the Vietnam war and the Soviet invasion of Czechoslovakia to end the Prague Spring), so making such wars more likely.\n\nThe democratic peace theory holds that democracies will never go to war with one another.\n\nIt was a central tenet of classical liberalism, for example among English liberal thinkers of the late 19th and early 20th century, that free trade promoted peace. For example, the Cambridge economist John Maynard Keynes (1883-1946) said that he was \"brought up\" on this idea and held it unquestioned until at least the 1920s. During the economic globalization in the decades leading up to World War I, writers such as Norman Angell argued that the growth \nof economic interdependence between the great powers made war between them futile and therefore unlikely. He made this argument in 1914.\n\nThese ideas have again come to prominence among liberal internationalists during the globalization of the late 20th and early 21st century. These ideas have seen capitalism as consistent with, even conducive to, peace.\n\nSocialist, communist, and left-wing liberal writers of the 19th and 20th centuries (e.g., Lenin, J.A. Hobson, John Strachey) argued that capitalism caused war (e.g. through promoting imperial or other economic rivalries that lead to international conflict). This led some to argue that international socialism was the key to peace.\n\nHowever, in response to such writers in the 1930s who argued that capitalism caused war, the economist John Maynard Keynes (1883-1946) argued that managed capitalism could promote peace. This involved international coordination of fiscal/monetary policies, an international monetary system that did not pit the interests of countries against each other, and a high degree of freedom of trade. These ideas underlay Keynes's work during World War II that led to the creation of the International Monetary Fund and the World Bank at Bretton Woods in 1944, and later of the General Agreement on Tariffs and Trade (subsequently the World Trade Organization).\n\nBorrowing from the teachings of Norwegian theorist Johan Galtung, one of the pioneers of the field of Peace Research, on 'Positive Peace', and on the writings of Maine Quaker Gray Cox, a consortium of theorists, activists, and practitioners in the experimental John Woolman College initiative have arrived at a theory of \"active peace\". This theory posits in part that peace is part of a triad, which also includes justice and wholeness (or well-being), an interpretation consonant with scriptural scholarly interpretations of the meaning of the early Hebrew word \"shalom\". Furthermore, the consortium have integrated Galtung's teaching of the meanings of the terms peacemaking, peacekeeping, and peacebuilding, to also fit into a triadic and interdependent formulation or structure. Vermont Quaker John V. Wilmerding posits five stages of growth applicable to individuals, communities, and societies, whereby one transcends first the 'surface' awareness that most people have of these kinds of issues, emerging successively into acquiescence, pacifism, passive resistance, active resistance, and finally into \"active peace\", dedicating themselves to peacemaking, peacekeeping or peace building.\n\nOne of the most influential theories of peace, especially since Woodrow Wilson led the creation of the League of Nations at the Paris Peace Conference of 1919, is that peace will be advanced if the intentional anarchy of states is replaced through the growth of international law promoted and enforced through international organizations such as the League of Nations, the United Nations, and other functional international organizations. One of the most important early exponents of this view was Sir Alfred Zimmern, for example in his 1936 book \"The League of Nations and the Rule of Law\".\n\nMany \"idealist\" thinkers about international relations - e.g. in the traditions of Kant and Karl Marx - have argued that the key to peace is the growth of some form of solidarity between peoples (or classes of people) spanning the lines of cleavage between nations or states that lead to war.\n\nOne version of this is the idea of promoting international understanding between nations through the international mobility of students - an idea most powerfully advanced by Cecil Rhodes in the creation of the Rhodes Scholarships, and his successors such as J. William Fulbright.\n\nAnother theory is that peace can be developed among countries on the basis of active management of water resources.\n\nFollowing Wolfgang Dietrich, Wolfgang Sützl and the Innsbruck School of Peace Studies, some peace thinkers have abandoned any single and all-encompassing definition of peace. Rather, they promote the idea of \"many peaces\". They argue that since no singular, correct definition of peace can exist, peace should be perceived as a plurality. This post-modern understanding of peace(s) was based on the philosophy of Jean Francois Lyotard. It served as a fundament for the more recent concept of trans-rational peace(s) and elicitive conflict transformation.\n\nIn 2008 Dietrich enlarged his approach of the \"many peaces\" to the so-called \"five families\" of peace interpretations: the energetic, moral, modern, post-modern and trans-rational approach. Trans-rationality unites the rational and mechanistic understanding of modern peace in a relational and culture-based manner with spiritual narratives and energetic interpretations. The systemic understanding of trans-rational peaces advocates a client-centred method of conflict transformation, the so-called elicitive approach.\n\n\n\"Peace and conflict studies\" is an academic field which identifies and analyses violent and nonviolent behaviours, as well as the structural mechanisms attending violent and non violent social conflicts. This is to better understand the processes leading to a more desirable human condition. One variation,\n\"Peace studies\" (irenology), is an interdisciplinary effort aiming at the prevention, de-escalation, and solution of conflicts. This contrasts with war studies (polemology), directed at the efficient attainment of victory in conflicts. Disciplines involved may include political science, geography, economics, psychology, sociology, international relations, history, anthropology, religious studies, and gender studies, as well as a variety of other disciplines.\n\nAlthough peace is widely perceived as something intangible, various organizations have been making efforts to quantify and measure it. The Global Peace Index produced by the Institute for Economics and Peace is a known effort to evaluate peacefulness in countries based on 23 indicators of the absence of violence and absence of the fear of violence.\n\nThe last edition of the Index ranks 163 countries on their internal and external levels of peace. According to the 2017 Global Peace Index, Iceland is the most peaceful country in the world while Syria is the least peaceful one. Fragile States Index (formerly known as the Failed States Index) created by the Fund for Peace focuses on risk for instability or violence in 178 nations. This index measures how fragile a state is by 12 indicators and subindicators that evaluate aspects of politics, social economy, and military facets in countries. The 2015 Failed State Index reports that the most fragile nation is South Sudan, and the least fragile one is Finland. University of Maryland publishes the Peace and Conflict Instability Ledger in order to measure peace. It grades 163 countries with 5 indicators, and pays the most attention to risk of political instability or armed conflict over a three-year period. The most recent ledger shows that the most peaceful country is Slovenia on the contrary Afghanistan is the most conflicted nation. Besides indicated above reports from the Institute for Economics and Peace, Fund for Peace, and University of Maryland, other organizations including George Mason University release indexes that rank countries in terms of peacefulness.\n\n"}
{"id": "1942806", "url": "https://en.wikipedia.org/wiki?curid=1942806", "title": "Plot point", "text": "Plot point\n\n\"For the role-playing games concept see Plot point (role-playing games)\"\n\nIn television and film, a plot point is a significant event within a plot that spins the action around in another direction. \n\nNoted screenwriting teacher Syd Field discusses plot points in his paradigm, popularized in his book \"Screenplay: The Foundations of Screenwriting.\" There he proposes that a well-structured movie has two plot points within a three-act structure. The first plot point occurs 20 to 30 minutes into the film (assuming a standard 120-minute running time), and the second one occurs 80 to 90 minutes into the film. The first plot point ends Act I and propels the story into Act II; likewise, the second plot point ends Act II and propels the story into Act III.\n\n"}
{"id": "6320637", "url": "https://en.wikipedia.org/wiki?curid=6320637", "title": "Rosa Peace", "text": "Rosa Peace\n\nThe Peace rose, formally \"Rosa\" 'Madame A. Meilland', is a well-known and successful garden rose. By 1992, over one hundred million plants of this hybrid tea had been sold. The cultivar has large flowers of a light yellow to cream color, slightly flushed at the petal edges with crimson-pink. It is hardy and vigorous and relatively resistant to disease, making it popular in gardens as well as in the floral trade.\n\nIt was developed by French horticulturist Francis Meilland in the years 1935 to 1939. When Meilland foresaw the German invasion of France, he sent cuttings to friends in Italy, Turkey, Germany, and the United States to protect the new rose. It is said that it was sent to the US on the last plane available before the German invasion, where it was safely propagated by the Conard Pyle Co. during the war.\n\nThe cultivar was hybridized in 1935, receiving the number 3-35-40 (the third hybridization in 1935, and the 40th cultivar selected for test proliferation). As those first tests produced beautiful flowers in autumn of 1936, the first no. 3-35-40 were grown in Meilland's rose fields in June 1939. That summer, cuttings were sent to partners in other countries. According to Meilland's records, 'Madame A. Meilland' was hybridized from the hybrid tea 'Margaret McGredy' and an unnamed seedling.\nBecause Meilland had sent out his cuttings just before the war, communication between the cultivators was not possible, which is why the rose received different names. In France, Francis and Alain Meilland decided to call the cultivar 'Madame A. Meilland', in honor of Francis' deceased mother, Alain Meilland's wife Claudia. This is the formal cultivar name. Other names are considered by the International Code of Nomenclature for Cultivated Plants as trade or selling names. In Italy it was called (Italian for \"joy\"), in Germany (Latin for \"glory of God\") and in the US, Sweden, and Norway .\n\nThe rose eventually became known as . In early 1945 rose grower Meilland wrote to Field Marshal Alan Brooke (later Viscount Alanbrooke) to thank him for his key part in the liberation of France and to ask if Brooke would give his name to the rose. Brooke declined saying that, though he was honored to be asked, his name would soon be forgotten and a much better and more enduring name would be \"Peace\".\n\nThe adoption of the trade name \"Peace\" was publicly announced in the United States on 29 April 1945 by the introducers, Conard Pyle Co. This was the very day that Berlin fell, a day considered a turning point in the Second World War in Europe. Later that year Peace roses were given to each of the delegations at the inaugural meeting of the United Nations in San Francisco, each with a note that read:\n\nPeter Beales, English rose grower and expert, said in his book \"Roses\":\n\n'Mme A. Meilland' forms elegant buds that open to large, cupped flowers with a high-centered form and an average diameter of . Their color is a combination of pale yellow and crimson edges that depends on the location, the weather and changes as the flower fades. The durable flowers are very full, with 40 to 43 petals, survive rainy periods, and have a sweet and fruity fragrance that varies in its strength from mild to strong. The cultivar flowers continuously throughout the season up to the first frost.\n\nThe vigorous shrub grows high and wide, is winter hardy down to (USDA zone 6), half-shade tolerant, and disease resistant. The large, glossy leaves are very dark and leathery. 'Mme A. Meilland' is very versatile—it is used as cut rose and as garden rose, solitarily or in groups, as standard rose to high, or in containers.\n\n'Mme A. Meilland' has been granted numerous awards, starting with the selection as \"Most Beautiful French Rose\" in Lyon in 1942, gold medals in Lyon (1942), Portland (1944), The Hague (1965) and from the Royal National Rose Society in 1947. In 1944, it was included in the All-America Rose Selection.\n\nIn 1976, it was the first cultivar to be granted the highest award a rose can be granted when it was selected as \"World's Favorite Rose\" and included into the Rose Hall of Fame.\n\nAs an often cultivated plant, several sports of 'Mme A. Meilland' are known. 'Climbing Peace' (Kordes 1951) has slightly bigger flowers but flowers less well, 'Chicago Peace' (Johnston 1962) differs mainly in its richer colors with a mixture of crimson and apricot, while 'Kronenbourg' (syn. 'Flaming Peace', McGredy 1966) has red petals with yellow backs, creating an interesting contrast.\n\nIt is also used in the hybridization of new cultivars, and played a role in the development of well known cultivars such as 'Garden Party' (Swim, 1959), 'Super Star' (Tantau, 1960), and 'Pullman Orient Express' (Lim & Twomey, 1991).\n\n"}
{"id": "49141682", "url": "https://en.wikipedia.org/wiki?curid=49141682", "title": "Scale (analytical tool)", "text": "Scale (analytical tool)\n\nIn the study of complex systems and hierarchy theory, the concept of scale refers to the combination of (1) the level of analysis (for example, analyzing the whole or a specific component of the system); and (2) the level of observation (for example, observing a system as an external viewer or as an internal participant). The scale of analysis encompasses both the analytical choice of how to observe a given system or object of study, and the role of the observer in determining the identity of the system. This analytical tool is central to multi-scale analysis (see for example, MuSIASEM, land-use analysis).\n\nFor example, on at the scale of analysis of a given population of zebras, the number of predators (e.g. lions) determines the number of preys that survives after hunting, while at the scale of analysis of the ecosystem, the availability of preys determines how many predators can survive in a given area. The semantic categories of \"prey\" and \"predator\" are not given, but are defined by the observer.\n\n"}
{"id": "36173953", "url": "https://en.wikipedia.org/wiki?curid=36173953", "title": "Seattle Freeze", "text": "Seattle Freeze\n\nThe term Seattle Freeze refers to a widely held belief that it is especially difficult to make new friends in the city of Seattle, Washington, particularly for transplants from other cities. A 2005 \"Seattle Times\" article appears to be the first known use of the term, though a 1946 \"Seattle Daily Times\" excerpt also describes the phenomenon.\n\nNewcomers to the area have described Seattleites as being standoffish, cold, distant, and distrustful, while in settings such as bars and parties, people from Seattle tend to mainly interact with their particular clique. One author described the aversion to strangers as that \"people are very polite but not particularly friendly.\" While some residents dispute the existence of the Seattle Freeze, a 2008 peer-reviewed study published in \"Perspectives on Psychological Science\" found that among all 50 states, Washington residents ranked 48th in the personality trait extroverted. In 2014 a similar report by the Seattle CityClub ranked the population 48th out of 50 similarly-sized cities in activities such as \"talking with neighbors frequently\". The rapid growth of Amazon and its accompanying influx of largely young, male technology workers may have exacerbated the problem.\n\nIt has been speculated that the origin of the phenomenon could stem from the reserved personalities of the city's early Nordic and Asian immigrants. Other reasons may include the emotional effects of the climate (such as Seasonal Affective Disorder), or the region's history of independent-minded pioneers.\n\n"}
{"id": "57315219", "url": "https://en.wikipedia.org/wiki?curid=57315219", "title": "Secular arm", "text": "Secular arm\n\nSecular arm, in ecclesiastical law, refers to the legal authority of the civil power, the State, or any lay authority, invoked by the Church to punish offenders in cases properly belonging to the jurisdiction of the Church. In the Middle Ages especially in Inquisition trials for heresy, or grave immorality, ecclesiastical courts delivered convicted clerical and lay offenders over to the secular arm to administer severe capital punishments. The phrase \"relaxed to the secular arm\" was used by the Spanish Inquistion to describe the handover of the condemned heretic.\n\nThe medieval Latin phrase 'brachium seculare' was translated first into late Middle English. \n\nIntroduced circa 1180–1250 at the time of the Albigensian Crusade, the church inquisitors delivered a Cathar heretic, or any heretic, to the secular arm, to be burnt at the stake. \nUnder canon law church tribunals had no jurisdiction to impose penalties involving mutilation or death.\nNotably the contrary circumstance of appeal by individuals to the secular authorities to interfere with, or hinder, the process of ecclesiastical jurisdiction was until recently punished in the Roman Catholic Church by excommunication.\n\nCatholic Culture\nThe Oxford Dictionary of Phrase and Fable, Religion\n"}
{"id": "12664042", "url": "https://en.wikipedia.org/wiki?curid=12664042", "title": "Sex-limited genes", "text": "Sex-limited genes\n\nSex-limited genes are genes that are present in both sexes of sexually reproducing species but are expressed in only one sex and remain 'turned off' in the other. In other words, sex-limited genes cause the two sexes to show different traits or phenotypes, despite having the same genotype. This term is restricted to autosomal traits, and should not be confused with sex-linked characteristics, which have to do with genetic differences on the sex chromosomes (see sex-determination system). Sex-limited genes are also distinguished from sex-influenced genes, where the same gene will show differential expression in each sex. Sex-influenced genes commonly show a dominant/recessive relationship, where the same gene will have a dominant effect in one sex and a recessive effect in the other (for example, male pattern baldness).\n\nSex-limited genes are responsible for sexual dimorphism, which is a phenotypic (directly observable) difference between males and females of the same species. These differences can be reflected in size, color, behavior (ex: levels of aggression), and morphology. An example of sex-limited genes are genes which instruct the male elephant seals to grow big and fight, at the same time instructing female seals to grow small and avoid fights. These genes are also responsible for some female beetles' inability to grow exaggerated mandibles, research that is discussed in detail later in this article.\n\nThe overall point of sex-limited genes is to resolve intralocus sexual conflict. In other words, these genes try to resolve the \"push-pull\" between males and females over trait values for optimal phenotype. Without these genes, organisms would be forced to settle on an \"average \"trait value, incurring costs on both sexes. With these genes, it is possible to 'turn off' the genes in one sex, allowing both sexes to attain (or at least, approach very closely) their optimal phenotypes.\n\nUnsurprisingly, the idea of sex-limited genes was initially developed by Charles Darwin himself in 1871 in his book \"The Descent of Man and Selection in Relation to Sex.\" He does not distinguish between sex-limited, sex-linked, and sex-influenced genes, but refers to any gene that expresses differently between sexes as sex-limited. While this concept was still in its infancy, Darwin catalyzed the further development of sex-related selection. Thomas Hunt Morgan, fully aware of this confusing terminology, published an article in \"The American Naturalist \"in 1914 titled \"Sex-Linked and Sex-Limited Inheritance.\" This article directly acknowledges that Darwin applied the term sex-limited whenever a characteristic seemed specific to one sex. Morgan proposes the definitions for sex-linked genes and sex-limited genes that we still use today (and that were defined in the introduction above). This paper helped to distinguish between these two similar concepts and clarify much confusion in the scientific community at the time. Morgan's paper was followed by several others involving sex-limited genes and their expression as traits. One of the more notable examples is John H. Gerould's \"Inheritance of White Wing Color, a Sex-Limited (Sex-Controlled) Variation in Yellow Pierid Butterflies,\" published in \"Genetics \"in 1923 (and edited slightly in 1924). Gerould observed that in this species of butterfly, females naturally occur as yellow or white, while males only occur with yellow coloration. He extensively explores this apparently sex-limited trait from a genetic perspective in this ground-breaking 50 page paper. To conclude the notable advancements in the early stages of the development of sex-limited genes, a brief discussion of R. A. Fisher is necessary. Commonly hailed as one of the best evolutionary biologists of his time, Fisher was also a talented geneticist. His book \"The Genetical Theory of Natural Selection\", published in 1930, over 20 years before the double-helix shape of DNA was discovered, was the first attempt to explain Darwin's theories within the foundation of genetics. Chapter 6 of this book is titled \"Sexual Reproduction and Sexual Selection\" and includes a genetic interpretation of Darwin's initial idea of sex-limited genes. After these groundbreaking works, papers continue to be published further exploring the causes, mechanisms, evolutionary advantages, and more of sex-limited genes.\n\nMany studies have been published exploring the genetic basis of sex-limited genes. One paper, published in \"Evolution\", evaluates the hypothesis that sex-limited traits can arise in two ways. The alleles responsible for sexual dimorphism can be limited to expression in only one sex when they first appear, or the alleles could begin by being expressed in both sexes then become modified (repressed or promoted) in one sex by modifier genes or regulatory elements. The concept of this study was to examine female hybrids from species where males displayed different types of ornamental traits (elongated feathers, wattles, color patches). The assumption is that different hypotheses about male-specific expression will yield different results in female hybrids. The methods and materials of the experiment are discussed in detail in the paper, but the important result that emerged was that NO female hybrids expressed any of the ornamental traits found in the parent males. Two interpretations of these results are possible: the dimorphic alleles were initially only expressed in males, or the alleles were initially expressed in both and then were suppressed in females or became limited to males by regulatory regions that are \"completely dominant\" in hybrids. The most likely genomic explanation for initial expression in both species then modification is involvement of \"cis\"-dominance, where the factors that modify the gene are located next to the gene on the chromosome. (This is in contrast to \"trans\"-dominance, where mobile products that can affect distant genes are produced.) These factors can be in the form of promoter regions, which can be either be suppressed or activated by hormones. This experiment also demonstrates that these alleles come under regulatory control very quickly. This is because none of the ornamentation seen in males is seen in the \"very next \"generation. These conclusions make it likely that at least some male-specific (thus, sex-limited) genes cue their expression by hormone levels - the absence of estrogen or the presence of testosterone.\n\nBecause sex-limited genes are present in both sexes but only expressed in one, this allows the unexpressed genes to be hidden from selection. On a short-term scale, this means that during one generation, only the sex that expresses the sex-limited trait(s) of interest will be affected by selection. The remaining half of the gene pool for these traits will be unaffected by selection because they are hidden (unexpressed) in the genes of the other sex. Since a portion of the alleles for these sex-limited traits are hidden from selection, this occurrence has been termed 'storage-effect'. On a long-term scale, this storage effect can have significant effects on selection, especially if selection is fluctuating over a long period of time. It is inarguable that selection will fluctuate over time with varying levels of environmental stability. For example, fluctuations in population density can drive selection on sex-limited traits. In less dense populations, females will have less opportunity to choose between males for reproduction. In this case, attractive males may experience both reduced reproductive success and increased predation pressure. Thus, selection on males for sex-limited traits such as increased size (elephant seals) and weaponry (claws on fiddler crabs, horns on rhinoceros beetles) will change direction with fluctuation in population density.\n\nJohn Parsch and Hans Ellegren defined \"genes that differ in expression between females and males\" as sex-biased genes. While this definition is more broad, sex-limited genes are certainly included in this category. One of the key principles of sex-biased gene expression that Parsch and Ellegren stressed in their paper in February 2013 is that of rapid evolution. They assert that a gene's sex bias can vary among different types of tissues throughout the body or throughout development, making the level of sex bias a fluid, rather than static, property. This makes it possible, then, that the rapid evolution seen in sex-biased genes is not an inherent property of their sex bias, but a property of some other feature. The paper offers expression breadth, the number of tissue types in which the genes are expressed, as an example of a feature correlated to sex-biased genes. It is known that genes with limited expression (in only one type of tissue) generally evolve faster than those with a higher expression breadth, and sex-biased genes are often restricted in their expression, such as to only the testes or ovaries. Thus, it is likely that sex-biased (including sex-limited) genes will evolve faster than the average genetic information. Parsch and Ellegren also assert that \"sex-biased genes expressed only in sex-limited reproductive tissues evolve faster than unbiased genes that are expressed only in a single, non-reproductive tissue.\" That is, genes that have a bias toward any kind of reproductive tissue (testes or ovaries) seem to show faster evolution than genes expressed in non-gonadal tissues, despite the number of tissues in which they are expressed. This makes sense in the context of genes with reproductive function evolving more quickly, a generally observed pattern in evolutionary biology.\n\nSexual antagonism occurs when two species have conflicting optimal fitness strategies concerning reproduction (see link in introduction paragraph). Multiple matings is a classic example of competing optimal strategies. Males, who typically have a much lower overall investment in reproduction, may benefit from more frequent matings. Females, however, invest much more in reproduction and can be endangered, harmed, or even killed by multiple matings.\n\nIn 2010, Hosken et al. completed an important study exploring the effects of sexually antagonistic selection on sex-limited trait expression. They asked if sex-specific trait selection always resolved intralocus conflict, as it was believed to do. By using a species of flour beetle, \"Gnatocerus cornutus\", exhibiting sex-limited traits in the form of exaggerated mandible size, they were able to test this hypothesis. Exaggerated mandibles are \"only \"developed in males; females never develop exaggerated mandibles. The point of this experiment was to determine how mandibles affect fitness. If these sex-limited genes are truly quelling intralocus sexual conflict, male mandible size should have no effect on female fitness. After selecting for males with exaggerated mandibles (full materials and methods can be found within the paper), it was experimentally determined that males with exaggerated mandibles had a higher fitness - they experienced increased fighting and mating success. It was also found, however, that females found in the populations of males with exaggerated mandibles had lower fitness (as determined by lifetime reproductive success, LRS) relative to the fitness of females in populations with males with smaller mandibles. Since this male sex-limited trait affects female fitness, intralocus sexual conflict has \"not \"been resolved. This highlights the importance of sexual conflict to evolution, because it cannot simply be defused by sex-limited trait expression.\n\nLater the same year, a paper in \"Evolution \"also came to the same conclusions about sexual antagonism in relation to sex-limited genes. They developed a mathematical model to show that the fitness costs of sexual antagonism, even when rare, will usually overwhelm the benefits of sexually concordant selection. (Sexually concordant selection occurs when selection favors the same alleles in both sexes but differs in relative strength between them.) Through several advanced calculations, they concluded that even a small relative amount of sexual antagonism will overwhelm any benefit harvested from sexually concordant selection. Coming to the same conclusion as Hosken et al., they demonstrated mathematically that when sex-limited gene expression attempts to resolve sexual antagonism, it is likely to produce negative long-term fitness consequences. This result is seen in the experiment with beetles above, where the females demonstrate reduced fitness in response to males selected for larger mandibles. So, with mathematical support and a lack of support for strong fitness benefits as a result of sexually concordant selection, the paper concludes that sex-specific selection is more likely to incur costs than benefits to sexually reproducing species.\n\nAnimal behavior (see ethology) encompasses so many disciplines that it is impossible not to see it in some capacity in almost all primary literature involving live animals. While the examples above certainly contain aspects of animal behavior, a more overt example of it in relation to sex-limited traits is detailed in a Teplitsky et al. paper (2010) centering on breeding time in red-billed gulls. This experiment deals with breeding time, an aspect of reproductive biology. Reproduction and sexual behavior are two key aspects of animal behavior, as they are universally expressed in some way throughout the animal kingdom.\n\nBreeding time in red-billed gulls is expressed only in females, because only females lay eggs. Male care, however, affects female breeding performance substantially. This qualifies breeding time as a sex-limited trait because it is expressed only in one sex but can be affected by both (similarly to Hosken's beetle experiment above). By following a natural population of red-billed gulls for 46 years, Teplitsky et al. came to an unexpected conclusion - while laying date (aka breeding time) is only expressed in females, the trait is only heritable in males. This is atypical because sex-limited traits are almost always heritable within the sex in which they are expressed.\n\nFor this species, the timing of egg-laying has much to do with male behavior. Males can affect female reproductive success so strongly because for the 20 days up to egg-laying, females spend up to 80% of their time in the nest. This leaves males with the responsibility of providing food regularly and securing (and maintaining) a high-quality territory for nesting. This phenomenon of the genetics of one individual affecting those of another individual is known as \"indirect genetic effects\". For this population, at least, possible explanations for this atypical heritability pattern exist. While controlling female health and safety, males are responsible for the timing of the start of courtship feeding, as well. These populations also typically have excesses of females, allowing males to exert even further choice in the form of mate choice. These factors in combination give males a great opportunity to express their \"laying date genotype\". In spite of the presence of directional selection and significant male heritability for breeding time, no advancement of breeding time was seen during the 46 years of this experiment. This does not discount the significance of the paper's other results however - one of the most significant being that here a \"female trait (laying date) is largely determined by genetic characteristics of its mate\".\n\nEpigenetics is the inheritance of additional marks to the genome without changes in its sequence. These factors epigenetic factors may also be sex-limited. Genomic imprinting for example, silencing of one parental allele by DNA methylation, for which sex-limited imprinting has been proposed to resolve intralocus conflict. Genomic imprinting has been shown to be indistinguishable from non-imprinted systems at the population level in some cases, having equivalent evolutionary models. However, this does not hold for sex-limited models of sex-limited imprinting which behave differently depending on which sex imprinting occurs and the parental sex of imprinted allele. Specifically, this affects whether alleles are imprinted in consecutive generations with different evolutionary trajectories (under the same selection fitnesses) arising purely due to sex-limited epigenetics. Thus sex-limited epigenetic traits may have played a pivotal role in the evolution of mammals and other species, particularly as a mechanism to ameliorate intralocus conflict between the sexes.\n\nOverall, sex-limited genes carry with them several complex cost to benefit ratios which call for further analysis. For example, while they allow for greater opportunities of sexual dimorphism so both sexes can reach much closer to their optimal phenotypes, they also incur fitness costs on sexually reproducing species. Since Charles Darwin's revolutionary book was published in 1871, there have been many studies done on the nature of these genes. The scientific literature dealing with the concepts of sexual dimorphism and sex-limited genes extends far past what has been listed here. The genetic and mechanistic details of these genes are still being discovered through ongoing research today. It is becoming apparent that a deeper understanding sex-limited genes will be increasingly important as the fields of evolutionary biology and genetics advance.\n\n"}
{"id": "11291009", "url": "https://en.wikipedia.org/wiki?curid=11291009", "title": "Social identity theory", "text": "Social identity theory\n\nSocial identity is the portion of an individual's self-concept derived from perceived membership in a relevant social group. As originally formulated by social psychologists Henri Tajfel and John Turner in the 1970s and the 1980s, social identity theory introduced the concept of a social identity as a way in which to explain intergroup behaviour.\n\nSocial identity theory is described as a theory that predicts certain intergroup behaviours on the basis of perceived group status differences, the perceived legitimacy and stability of those status differences, and the perceived ability to move from one group to another. This contrasts with occasions where the term \"social identity theory\" is used to refer to general theorizing about human social selves. Moreover, and although some researchers have treated it as such, social identity theory was never intended to be a general theory of social categorization. It was awareness of the limited scope of social identity theory that led John Turner and colleagues to develop a cousin theory in the form of self-categorization theory, which built on the insights of social identity theory to produce a more general account of self and group processes. The term social identity \"approach\", or social identity \"perspective\", is suggested for describing the joint contributions of both social identity theory and self-categorization theory. Social identity theory suggests that an organization can change individual behaviors if it can modify their self-identity or part of their self-concept that derives from the knowledge of, and emotional attachment to the group.\n\nSocial identity theory states that social behavior will vary along a continuum between interpersonal behavior and intergroup behaviour. Completely interpersonal behaviour would be behaviour determined solely by the individual characteristics and interpersonal relationships that exists between only two people. Completely intergroup behaviour would be behaviour determined solely by the social category memberships that apply to more than two people.\n\nThe authors of social identity theory state that purely interpersonal or purely intergroup behaviour is unlikely to be found in realistic social situations. Rather, behaviour is expected to be driven by a compromise between the two extremes. The cognitive nature of personal vs. social identities, and the relationship between them, is more fully developed in self-categorization theory. Social identity theory instead focuses on the social structural factors that will predict which end of the spectrum will most influence an individual's behaviour, along with the forms that that behavior may take.\n\nA key assumption in social identity theory is that individuals are intrinsically motivated to achieve positive distinctiveness. That is, individuals \"strive for a positive self-concept\". As individuals to varying degrees may be defined and informed by their respective social identities (as per the interpersonal-intergroup continuum) it is further derived in social identity theory that \"individuals strive to achieve or to maintain positive social identity\". It should be noted that the precise nature of this strive for positive self-concept is a matter of debate (see the self-esteem hypothesis).\n\nBoth the interpersonal-intergroup continuum and the assumption of positive distinctiveness motivation arose as outcomes of the findings of minimal group studies. In particular, it was found that under certain conditions individuals would endorse resource distributions that would maximize the positive distinctiveness of an ingroup in contrast to an outgroup at the expense of personal self-interest.\n\nBuilding on the above components, social identity theory details a variety of strategies that may be invoked in order to achieve positive distinctiveness. The individual's choice of behaviour is posited to be dictated largely by the perceived intergroup relationship. In particular the choice of strategy is an outcome of the perceived permeability of group boundaries (e.g., whether a group member may pass from a low status group into a high status group), as well as the perceived stability and legitimacy of the intergroup status hierarchy. The self-enhancing strategies detailed in social identity theory are detailed below. Importantly, although these are viewed from the perspective of a low status group member, comparable behaviours may also be adopted by high status group members.\n\nIt is predicted that under conditions where the group boundaries are considered permeable individuals are more likely to engage in individual mobility strategies. That is, individuals \"disassociate from the group and pursue individual goals designed to improve their personal lot rather than that of their ingroup\".\n\nWhere group boundaries are considered impermeable, and where status relations are considered reasonably stable, individuals are predicted to engage in social creativity behaviours. Here, low-status ingroup members are still able to increase their positive distinctiveness without necessarily changing the objective resources of the ingroup or the outgroup. This may be achieved by comparing the ingroup to the outgroup on some new dimension, changing the values assigned to the attributes of the group, and choosing an alternative outgroup by which to compare the ingroup.\n\nHere an ingroup seeks positive distinctiveness via direct competition with the outgroup in the form of ingroup favoritism. It is considered competitive in that in this case favoritism for the ingroup occurs on a value dimension that is shared by all relevant social groups (in contrast to social creativity scenarios). Social competition is predicted to occur when group boundaries are considered impermeable, and when status relations are considered to be reasonably unstable. Although not privileged in the theory, it is this positive distinctiveness strategy that has received the greatest amount of attention.\n\nThe term 'social identity theory' achieved academic currency only in the late 1970s, but the basic underlying concepts associated with it had emerged by the early twentieth century. William G. Sumner, writing in 1906, captures the primary dynamics in this excerpt from his influential work \"Folkways: A Study of the Sociological Importance of Usages, Manners, Customs, Mores, and Morals\": \n\nBy the late 1920s the collectivist perspective had all but disappeared from mainstream social psychology. Over fifty years later, around the time of the first formal use of the term 'social identity theory,' Tajfel wrote this on the state of social psychology:\n\nThus, social identity theory in part reflects a desire to reestablish a more collectivist approach to social psychology of the self and social groups.\n\nIn-group favoritism (also known as \"ingroup bias\", despite Turner's objections to the term) is an effect where people give preferential treatment to others when they are perceived to be in the same ingroup. Social identity attributes the cause of ingroup favoritism to a psychological need for positive distinctiveness and describes the situations where ingroup favoritism is likely to occur (as a function of perceived group status, legitimacy, stability, and permeability). It has been shown via the minimal group studies that ingroup favoritism may occur for both arbitrary ingroups (e.g. a coin toss may split participants into a 'heads' group and a 'tails' group) as well as non-arbitrary ingroups (e.g. ingroups based on cultures, genders, sexual orientation, and first languages).\n\nContinued study into the relationship between social categorization and ingroup favoritism has explored the relative prevalences of the ingroup favoritism vs. outgroup discrimination, explored different manifestations of ingroup favoritism, and has explored the relationship between ingroup favoritism and other psychological constraints (e.g., existential threat).\n\nSocial identities are a valued aspect of the self, and people will sacrifice their pecuniary self-interest to maintain the self-perception that they belong to a given social group. Political partisans and fans of sports teams (e.g., Republicans and Democrats, or MLB, NFL, NCAA fans) are reluctant to bet against the success of their party or team because of the diagnostic cost such a bet would incur to their identification with it. As a result, partisans and fans will reject even very favorable bets against identity-relevant desired outcomes. More than 45% of N.C.A.A. basketball and hockey fans, for example, turned down a free, real chance to earn $5 if their team lost its upcoming game.\n\nSocial identity theory proposes that people are motivated to achieve and maintain positive concepts of themselves. Some researchers, including Michael Hogg and Dominic Abrams, thus propose a fairly direct relationship between positive social identity and self-esteem. In what has become known as the \"self-esteem hypothesis\", self-esteem is predicted to relate to in-group bias in two ways. Firstly, successful intergroup discrimination elevates self-esteem. Secondly, depressed or threatened self-esteem promotes intergroup discrimination. Empirical support for these predictions has been mixed.\n\nSome social identity theorists, including John Turner, consider the self-esteem hypothesis as not canonical to social identity theory. In fact, the self-esteem hypothesis is argued to be conflictual with the tenets of the theory. It is argued that the self-esteem hypothesis misunderstands the distinction between a social identity and a personal identity. Along those lines, John Turner and Penny Oakes argue against an interpretation of positive distinctiveness as a straightforward need for self-esteem or \"quasi-biological drive toward prejudice\". They instead favour a somewhat more complex conception of positive self-concept as a reflection of the ideologies and social values of the perceiver. Additionally, it is argued that the self-esteem hypothesis neglects the alternative strategies to maintaining a positive self-concept that are articulated in social identity theory (i.e., individual mobility and social creativity).\n\nIn what has been dubbed the Positive-Negative Asymmetry Phenomenon, researchers have shown that punishing the out-group benefits self-esteem less than rewarding the in-group. From this finding it has been extrapolated that social identity theory is therefore unable to deal with bias on negative dimensions. Social identity theorists, however, point out that for ingroup favouritism to occur a social identity \"must be psychologically salient\", and that negative dimensions may be experienced as a \"less fitting basis for self-definition\". This important qualification is subtly present in social identity theory, but is further developed in self-categorization theory. Empirical support for this perspective exist. It has been shown that when experiment participants can self-select negative dimensions that define the ingroup no positive–negative asymmetry is found.\n\nIt has been posited that social identity theory suggests that similar groups should have an increased motivation to differentiate themselves from each other. Subsequently, empirical findings where similar groups are shown to possess increased levels of intergroup attraction and decreased levels of in-group bias have been interpreted as problematic for the theory. Elsewhere it has been suggested that this apparent inconsistency may be resolved by attending to social identity theory's emphasis on the importance of the perceived stability and legitimacy of the intergroup status hierarchy.\n\nSocial identity theory has been criticised for having far greater explanatory power than predictive power. That is, while the relationship between independent variables and the resulting intergroup behaviour may be consistent with the theory in retrospect, that particular outcome is often not that which was predicted at the outset. A rebuttal to this charge is that the theory was never advertised as the definitive answer to understanding intergroup relationships. Instead it is stated that social identity theory must go hand in hand with sufficient understanding of the specific social context under consideration. The latter argument is consistent with the explicit importance that the authors of social identity theory placed on the role of \"objective\" factors, stating that in any particular situation \"the effects of [social identity theory] variables are powerfully determined by the previous social, economic, and political processes\".\n\nSome researchers interpret social identity theory as drawing a direct link between identification with a social group and ingroup favoritism. For example, Charles Stangor and John Jost state that \"a main premise of social identity theory is that ingroup members will favour their own group over other groups\". This interpretation is rejected by other researchers. For example, Alex Haslam states that \"although vulgarized versions of social identity theory argue that 'social identification leads automatically to discrimination and bias', in fact…discrimination and conflict are anticipated only in a limited set of circumstances\". The likening of social identity theory with social competition and ingroup favouritism is partly attributable to the fact that early statements of the theory included empirical examples of ingroup favouritism, while alternative positive distinctiveness strategies (e.g., social creativity) were at that stage theoretical assertions. Regardless, in some circles the prediction of a straightforward identification-bias correlation has earned the pejorative title \"social identity theory-lite\".\n\n\n"}
{"id": "51366424", "url": "https://en.wikipedia.org/wiki?curid=51366424", "title": "Strachey Love Letter algorithm", "text": "Strachey Love Letter algorithm\n\nChristopher Strachey wrote a combinatory love letter algorithm for the Manchester Mark 1 computer in 1952. The poems it generated have been seen as the first piece of digital literature and a queer critique of heteronormative expressions of love.\n\nRather than modeling writing as a creative process, the love letter algorithm represents the writing of love letters as formulaic and \"without\" creativity. The algorithm has the following structure:\n\n\nThe lists of words were compiled by Strachey from a Roget's Thesaurus. Although the list of words included several variations on the word \"love\", none of these variations made it into any of the widely circulated letters generated by Strachey's procedure.\n\n"}
{"id": "8286675", "url": "https://en.wikipedia.org/wiki?curid=8286675", "title": "System", "text": "System\n\nA system is a regularly interacting or interdependent group of units forming an integrated whole. Every system is delineated by its spatial and temporal boundaries, surrounded and influenced by its environment, described by its structure and purpose and expressed in its functioning.\n\nThe term \"system\" comes from the Latin word \"systēma\", in turn from Greek \"systēma\": \"whole concept made of several parts or members, system\", literary \"composition\".\n\nAccording to Marshall McLuhan,\n\n\"System\" means \"something to look at\". You must have a very high visual gradient to have systematization. But in philosophy, prior to Descartes, there was no \"system\". Plato had no \"system\". Aristotle had no \"system\".\nIn the 19th century the French physicist Nicolas Léonard Sadi Carnot, who studied thermodynamics, pioneered the development of the concept of a \"system\" in the natural sciences. In 1824 he studied the system which he called the \"working substance\" (typically a body of water vapor) in steam engines, in regards to the system's ability to do work when heat is applied to it. The working substance could be put in contact with either a boiler, a cold reservoir (a stream of cold water), or a piston (to which the working body could do work by pushing on it). In 1850, the German physicist Rudolf Clausius generalized this picture to include the concept of the surroundings and began to use the term \"working body\" when referring to the system.\n\nThe biologist Ludwig von Bertalanffy (1901–1972) became one of the pioneers of the general systems theory. In 1945 he introduced \"models, principles, and laws that apply to generalized systems or their subclasses, irrespective of their particular kind, the nature of their component elements, and the relation or 'forces' between them.\"\n\nNorbert Wiener (1894–1964) and Ross Ashby (1903–1972), who pioneered the use of mathematics to study systems, carried out significant development in the concept of a \"system\".\n\nIn the 1980s John Henry Holland (1929–2015), Murray Gell-Mann (1929–) and others coined the term \"complex adaptive system\" at the interdisciplinary Santa Fe Institute.\n\n\n\n\n\n\nA \"subsystem\" is a set of elements, which is a system itself, and a component of a larger system.\n\nA subsystem description is a system object that contains information defining the characteristics of an operating environment controlled by the system.\n\nEvidently, there are many kinds of systems that can be analyzed both quantitatively and qualitatively. For example, in an analysis of urban systems dynamics, A .W. Steiss defined five intersecting systems, including the physical subsystem and behavioral system. For sociological models influenced by systems theory, where Kenneth D. Bailey defined systems in terms of conceptual, concrete, and abstract systems, either isolated, closed, or open. Walter F. Buckley defined systems in sociology in terms of mechanical, organic, and process models. Bela H. Banathy cautioned that for any inquiry into a system understanding its kind is crucial, and defined \"natural\" and \"designed\", i. e. artificial, systems.\n\nArtificial systems inherently have a major defect: they must be premised on one or more fundamental assumptions upon which additional knowledge is built. These fundamental assumptions are not inherently deleterious, but they must by definition be assumed as true, and if they are actually false then the system is not as structurally integral as is assumed. For example, in geometry this is very evident in the postulation of theorems and extrapolation of proofs from them.\n\nIt is important not to confuse these abstract definitions. Theorists include in natural systems subatomic systems, living systems, the solar system, galaxies, and the Universe. Artificial systems include our physical structures, hybrids of natural and artificial systems, and conceptual knowledge. The human elements of organization and functions are emphasized with their relevant abstract systems and representations. A cardinal consideration in making distinctions among systems is to determine how much freedom the system has to select its purpose, goals, methods, tools, etc. and how wide is the freedom to select itself as distributed or concentrated.\n\nGeorge J. Klir maintained that no \"classification is complete and perfect for all purposes\", and defined systems as abstract, real, and conceptual physical systems, bounded and unbounded systems, discrete to continuous, pulse to hybrid systems, etc. The interactions between systems and their environments are categorized as relatively closed and open systems. It seems most unlikely that an absolutely closed system can exist or, if it did, that it could be known by man. Important distinctions have also been made between \"hard\" systems – technical in nature and amenable to methods such as systems engineering, operations research, and quantitative systems analysis – and \"soft\" systems that involve people and organisations, commonly associated with concepts developed by Peter Checkland and Brian Wilson through Soft Systems Methodology (SSM) involving methods such as action research and emphasis of participatory designs. Where hard systems might be identified as more \"scientific\", the distinction between them is often elusive.\n\nA cultural system may be defined as the interaction of different elements of culture. While a cultural system is quite different from a social system, sometimes both together are referred to as a \"sociocultural system\". A major concern of the social sciences is the problem of order.\n\nAn economic system is a mechanism (social institution) which deals with the production, distribution and consumption of goods and services in a particular society. The economic system is composed of people, institutions and their relationships to resources, such as the convention of property. It addresses the problems of economics, like the allocation and scarcity of resources.\n\nThe international sphere of interacting states is described and analysed in systems terms by several international relations scholars, most notably in the neorealist school. This systems mode of international analysis has however been challenged by other schools of international relations thought, most notably the constructivist school, which argues that an over-large focus on systems and structures can obscure the role of individual agency in social interactions. Systems-based models of international relations also underlies the vision of the international sphere held by the liberal institutionalist school of thought, which places more emphasis on systems generated by rules and interaction governance, particularly economic governance.\n\nSystems modeling is generally a basic principle in engineering and in social sciences. The system is the representation of the entities under concern. Hence inclusion to or exclusion from system context is dependent on the intention of the modeler.\n\nNo model of a system will include all features of the real system of concern, and no model of a system must include all entities belonging to a real system of concern.\n\nIn computer science and information science, system is a software system which has components as its structure and observable inter-process communications as its behavior. Again, an example will illustrate: There are systems of counting, as with Roman numerals, and various systems for filing papers, or catalogues, and various library systems, of which the Dewey Decimal Classification is an example. This still fits with the definition of components which are connected together (in this case to facilitate the flow of information).\n\nSystem can also refer to a framework, aka platform, be it software or hardware, designed to allow software programs to run.\n\nIn engineering and physics, a physical system is the portion of the universe that is being studied (of which a thermodynamic system is one major example). Engineering also has the concept of a system referring to all of the parts and interactions between parts of a complex project. Systems engineering is the branch of engineering that studies how this type of system should be planned, designed, implemented, built, and maintained.\n\nSocial and cognitive sciences recognize systems in human person models and in human societies. They include human brain functions and mental processes as well as normative ethics systems and social/cultural behavioral patterns.\n\nIn management science, operations research and organizational development (OD), human organizations are viewed as systems (conceptual systems) of interacting components such as subsystems or system aggregates, which are carriers of numerous complex business processes (organizational behaviors) and organizational structures. Organizational development theorist Peter Senge developed the notion of organizations as systems in his book \"The Fifth Discipline\".\n\nSystems thinking is a style of thinking/reasoning and problem solving. It starts from the recognition of system properties in a given problem. It can be a leadership competency. Some people can \"think globally while acting locally\". Such people consider the potential consequences of their decisions on other parts of larger systems. This is also a basis of systemic coaching in psychology.\n\nOrganizational theorists such as Margaret Wheatley have also described the workings of organizational systems in new metaphoric contexts, such as quantum physics, chaos theory, and the self-organization of systems.\n\nThere is also such a thing as a logical system. The most obvious example is the calculus developed simultaneously by Leibniz and Isaac Newton. Another example is George Boole's Boolean operators. Other examples have related specifically to philosophy, biology, or cognitive science. Maslow's hierarchy of needs applies psychology to biology by using pure logic. Numerous psychologists, including Carl Jung and Sigmund Freud have developed systems which logically organize psychological domains, such as personalities, motivations, or intellect and desire. Often these domains consist of general categories following a corollary such as a theorem. Logic has been applied to categories such as taxonomy, ontology, assessment, and hierarchies.\n\nIn 1988, military strategist, John A. Warden III introduced the Five Ring System model in his book, \"The Air Campaign\", contending that any complex system could be broken down into five concentric rings. Each ring—Leadership, Processes, Infrastructure, Population and Action Units—could be used to isolate key elements of any system that needed change. The model was used effectively by Air Force planners in the First Gulf War. In the late 1990s, Warden applied his model to business strategy.\n\n\n"}
{"id": "38615", "url": "https://en.wikipedia.org/wiki?curid=38615", "title": "The Myth of Sisyphus", "text": "The Myth of Sisyphus\n\nThe Myth of Sisyphus () is a 1942 philosophical essay by Albert Camus. The English translation by Justin O'Brien was first published in 1955.\n\nIn the essay Camus introduces his philosophy of the absurd, man's futile search for meaning, unity, and clarity in the face of an unintelligible world devoid of God and eternal truths or values. Does the realization of the absurd require suicide? Camus answers, \"No. It requires revolt.\" He then outlines several approaches to the absurd life. The final chapter compares the absurdity of man's life with the situation of Sisyphus, a figure of Greek mythology who was condemned to repeat forever the same meaningless task of pushing a boulder up a mountain, only to see it roll down again. The essay concludes, \"The struggle itself ... is enough to fill a man's heart. One must imagine Sisyphus happy\".\n\nThe work can be seen in relation to other absurdist works by Camus: the novel \"The Stranger\" (1942), the plays \"The Misunderstanding\" (1942) and \"Caligula\" (1944), and especially the essay \"The Rebel\" (1951).\n\nThe essay is dedicated to Pascal Pia and is organized in four chapters and one appendix.\n\nCamus undertakes the task of answering what he considers to be the only question of philosophy that matters: Does the realization of the meaninglessness and absurdity of life necessarily require suicide?\n\nHe begins by describing the absurd condition: we build our life on the hope for tomorrow, yet tomorrow brings us closer to death and is the ultimate enemy; people live their lives as if they weren't aware of the certainty of death. Once stripped of its common romanticism, the world is a foreign, strange and inhuman place; true knowledge is impossible and rationality and science cannot explain the world: their stories ultimately end in meaningless abstractions, in metaphors. This is the absurd condition and \"from the moment absurdity is recognized, it becomes a passion, the most harrowing of all.\"\n\nIt is not the world that is absurd, nor human thought: the absurd arises when the human need to understand meets the unreasonableness of the world, when \"my appetite for the absolute and for unity\" meets \"the impossibility of reducing this world to a rational and reasonable principle.\"\n\nHe then characterizes a number of philosophies that describe and attempt to deal with this feeling of the absurd, by Heidegger, Jaspers, Shestov, Kierkegaard, and Husserl. All of these, he claims, commit \"philosophical suicide\" by reaching conclusions that contradict the original absurd position, either by abandoning reason and turning to God, as in the case of Kierkegaard and Shestov, or by elevating reason and ultimately arriving at ubiquitous Platonic forms and an abstract god, as in the case of Husserl.\n\nFor Camus, who set out to take the absurd seriously and follow it to its final conclusions, these \"leaps\" cannot convince. Taking the absurd seriously means acknowledging the contradiction between the desire of human reason and the unreasonable world. Suicide, then, also must be rejected: without man, the absurd cannot exist. The contradiction must be lived; reason and its limits must be acknowledged, without false hope. However, the absurd can never be accepted: it requires constant confrontation, constant revolt.\n\nWhile the question of human freedom in the metaphysical sense loses interest to the absurd man, he gains freedom in a very concrete sense: no longer bound by hope for a better future or eternity, without a need to pursue life's purpose or to create meaning, \"he enjoys a freedom with regard to common rules\".\n\nTo embrace the absurd implies embracing all that the unreasonable world has to offer. Without a meaning in life, there is no scale of values. \"What counts is not the best living but the most living.\"\n\nThus, Camus arrives at three consequences from fully acknowledging the absurd: revolt, freedom, and passion.\n\nHow should the absurd man live? Clearly, no ethical rules apply, as they are all based on higher powers or on justification. \"Integrity has no need of rules.\" 'Everything is permitted' \"is not an outburst of relief or of joy, but rather a bitter acknowledgment of a fact.\"\n\nCamus then goes on to present examples of the absurd life. He begins with Don Juan, the serial seducer who lives the passionate life to the fullest. \"There is no noble love but that which recognizes itself to be both short-lived and exceptional.\"\n\nThe next example is the actor, who depicts ephemeral lives for ephemeral fame. \"He demonstrates to what degree appearing creates being.\" \"In those three hours he travels the whole course of the dead-end path that the man in the audience takes a lifetime to cover.\"\n\nCamus's third example of the absurd man is the conqueror, the warrior who forgoes all promises of eternity to affect and engage fully in human history. He chooses action over contemplation, aware of the fact that nothing can last and no victory is final.\n\nHere Camus explores the absurd creator or artist. Since explanation is impossible, absurd art is restricted to a description of the myriad experiences in the world. \"If the world were clear, art would not exist.\" Absurd creation, of course, also must refrain from judging and from alluding to even the slightest shadow of hope.\n\nHe then analyzes the work of Dostoevsky in this light, especially \"The Diary of a Writer\", \"The Possessed\" and \"The Brothers Karamazov\". All these works start from the absurd position, and the first two explore the theme of philosophical suicide. However, both \"The Diary\" and his last novel, \"The Brothers Karamazov\", ultimately find a path to hope and faith and thus fail as truly absurd creations.\n\nIn the last chapter, Camus outlines the legend of Sisyphus who defied the gods and put Death in chains so that no human needed to die. When Death was eventually liberated and it came time for Sisyphus himself to die, he concocted a deceit which let him escape from the underworld. After finally capturing Sisyphus, the gods decided that his punishment would last for all eternity. He would have to push a rock up a mountain; upon reaching the top, the rock would roll down again, leaving Sisyphus to start over. Camus sees Sisyphus as the absurd hero who lives life to the fullest, hates death, and is condemned to a meaningless task.\n\nCamus presents Sisyphus's ceaseless and pointless toil as a metaphor for modern lives spent working at futile jobs in factories and offices. \"The workman of today works every day in his life at the same tasks, and this fate is no less absurd. But it is tragic only at the rare moments when it becomes conscious.\"\n\nCamus is interested in Sisyphus' thoughts when marching down the mountain, to start anew. After the stone falls back down the mountain Camus states that \"It is during that return, that pause, that Sisyphus interests me. A face that toils so close to stones is already stone itself! I see that man going back down with a heavy yet measured step toward the torment of which he will never know the end.\" This is the truly tragic moment, when the hero becomes conscious of his wretched condition. He does not have hope, but \"there is no fate that cannot be surmounted by scorn.\" Acknowledging the truth will conquer it; Sisyphus, just like the absurd man, keeps pushing. Camus claims that when Sisyphus acknowledges the futility of his task and the certainty of his fate, he is freed to realize the absurdity of his situation and to reach a state of contented acceptance. With a nod to the similarly cursed Greek hero Oedipus, Camus concludes that \"all is well,\" indeed, that \"one must imagine Sisyphus happy.\"\n\nThe essay contains an appendix titled \"Hope and the Absurd in the work of Franz Kafka\". While Camus acknowledges that Kafka's work represents an exquisite description of the absurd condition, he maintains that Kafka fails as an absurd writer because his work retains a glimmer of hope.\n\n\n\n"}
{"id": "53256704", "url": "https://en.wikipedia.org/wiki?curid=53256704", "title": "Threatcasting", "text": "Threatcasting\n\nThreatcasting is a conceptual framework used to help multidisciplinary groups envision future scenarios. It is also a process that enables systematic planning against threats ten years in the future. Utilizing the threatcasting process, groups explore possible future threats and how to transform the future they desire into reality while avoiding undesired futures. Threatcasting is a continuous, multiple-step process with inputs from social science, technical research, cultural history, economics, trends, expert interviews, and science fiction storytelling. These inputs inform the exploration of potential visions of the future.\n\nOnce inputs are explored for impact and application, participants create a science fiction story (Science Fiction Prototyping) based ten years in the future to add context around human activity. Science Fiction Prototyping consists of a future story about a person in a place doing a thing. The threatcasting process results in creation of many potential futures scenarios - some futures are desirable while others are not. Identifying both types of futures (desirable and undesirable) will help the participant recognize which future to aim toward, and which to avoid. Utilizing the scenarios, participants plot actions necessary in the present and at various intervals working toward the ten year future scenario. These actions will help participants understand how to empower or disrupt the target future scenario. Flags (warning events) are also determined in order to map societal indicators onto the recommended path toward the targeted future. When identified flags appear in society, threatcasting participants map these back to the original forecast to see whether or not they are on track toward the target future scenario.\n\nThe notion of threatcasting can be traced back to Brian David Johnson, an applied futurist, who first began using threatcasting, also referred to as futurecasting, in 2011 and to George Hemingway of the Stratalis Group, who pioneered notion of futurecasting for corporate strategy and innovation industrial markets, including mining in the same year. Early adopters of threatcasting include the United States Air Force Academy, the Government of California, and the Army Cyber Institute at West Point Military Academy. Official use of the term threatcasting is attributed to Brian David Johnson in a 2014 Gazette article “Drones, smart hydrants considered by experts looking at future of firefighting.”\n\nThreatcasting is fundamentally different from traditional strategic planning and scenario building processes due to the identification of specific actions, indicators and concrete steps that can be taken today to disrupt, mitigate and recover from future threats.\n\nThe Army Cyber Institute at West Point in conjunction with Arizona State University's Global Securities Initiative and the School for the Future of Innovation in Society have established a Threatcasting Lab to host and manage a Cyber Threatcasting Project which looks to envision future cyber threats ten years in the future. The first session of this collaborative group was held at West Point, NY in August 2016.\n\n\n"}
{"id": "2223034", "url": "https://en.wikipedia.org/wiki?curid=2223034", "title": "Upper ten thousand", "text": "Upper ten thousand\n\nUpper Ten Thousand, or simply, \"The Upper Ten\", is a 19th-century phrase referring to wealthiest 10,000 residents of New York City. The phrase was coined in 1844 by American poet and author Nathaniel Parker Willis. Soon, the term came to be used to describe the upper circles not only of New York, but also those of other major cities.\n\nIn 1852, Charles Astor Bristed published a collection of sketches on New York Society entitled \"The Upper Ten Thousand\" in \"Fraser Magazine\". In 1854, George Lippard serialized his book \"New York: Its Upper Ten and Lower Million\". The phrase also appeared in British fiction in \"The Adventures of Philip\" (1861–62) by William Thackeray, whose eponymous hero contributed weekly to a fashionable New York journal entitled “The Gazette of the Upper Ten Thousand”. \nThe general acceptance of the term seems to be attested by its use in the title of Edward Abbott's 1864 cookery book, \"The English and Australian Cookery Book: Cookery for the Many as Well as the 'Upper Ten Thousand\"'.\n\nIn 1875, both Adam Bissett Thom and Kelly's Directory published books entitled \"The Upper Ten Thousand\", which listed members of the aristocracy, the gentry, officers in the British Army and Navy, members of Parliament, Colonial administrators, and members of the Church of England. The usage of this term was a response to the broadening of the British ruling class which had been caused by the Industrial Revolution.\n\nMost of the people listed in \"Kelly's Handbook to the Upper Ten Thousand\" were among the 30,000 descendants of Edward III, King of England, tabulated in the Marquis of Ruvigny and Raineval's \"Plantagenet Roll of the Blood Royal\". Most also appeared in Walford's \"County Families\" and Burke's \"Landed Gentry\".\n\n\n"}
{"id": "45138441", "url": "https://en.wikipedia.org/wiki?curid=45138441", "title": "Vivian Conley", "text": "Vivian Conley\n\nshe also like people\n\nIn addition to her civil rights work, for twenty years she served as the education coordinator for Trinity United Methodist Church. She also founded Ball State University's Nontraditional Student Association. She herself attended Ball State University at the same time as her own daughter and three of her grandsons.\n\nThe Conley Library on Centennial Avenue in Muncie, which has closed, was named in her honor. The Vivian Conley Award is named after her, as is the Vivian Conley Memorial Scholarship Fund (a \"Ball State University scholarship for nontraditional, part-time students who demonstrate a commitment to the betterment of our community.\") The Vivian Conley Award is given to women who work in art, business, community service, education, environment, health, humanitarian aid, and religion.\n"}
{"id": "22709409", "url": "https://en.wikipedia.org/wiki?curid=22709409", "title": "Workplace deviance", "text": "Workplace deviance\n\nWorkplace deviance, in group psychology, may be described as the deliberate (or intentional) desire to cause harm to an organization – more specifically, a workplace. The concept has become an instrumental component in the field of organizational communication. More accurately, it can be seen as \"voluntary behavior that violates institutionalized norms and in doing so threatens the well-being of the organization\".\n\nEmployees often create a set of expectations about their workplace; people tend to make psychological contracts with their organizations. When his or her expectations are not met, the employee may \"perceive a psychological contract breach by their employers\". This \"breach\" of the psychological contract then presents potential problems, particularly in the workplace.\n\nWorkplace deviance may arise from the worker's perception that their organization has mistreated him or her in some manner. Employees then resort to misbehaving (or acting out) as a means of avenging their organization for the perceived wrongdoing. Workplace deviance may be viewed as a form of negative reciprocity. \"A negative reciprocity orientation is the tendency for an individual to return negative treatment for negative treatment\". In other words, the maxim \"an eye for an eye\" is a concept that some employees strongly feel is a suitable approach to their problem. However, what is critical in understanding employee deviance is that the employee perceives being wronged, whether or not mistreatment actually occurred.\n\nWorkplace deviance is also closely related to abusive supervision. Abusive supervision is defined as the \"subordinates' perceptions of the extent to which their supervisors engage in the sustained display of hostile verbal and nonverbal behaviors\". This could be when supervisors ridicule their employees, give them the silent treatment, remind them of past failures, fail to give proper credit, wrongfully assign blame or blow up in fits of temper. It may seem like employees who are abused by their supervisor will either directly retaliate or withdraw by quitting the job but in reality many strike out against their employer by engaging in organizational deviant behaviors. Since employees control many of the organization's resources, they often use, or abuse anything they can. This abuse of resources may come in the form of time, office supplies, raw materials, finished products or the services that they provide. This usually occurs in two steps. First step is that commitment is destroyed and employees stop caring about the welfare of the employer. The second step is that the abused employee will get approval (normally implied) of their coworkers to commit deviant acts.\n\nWorkplace experiences may fuel the worker to act out. Research has been conducted demonstrating that the perception of not being respected is one of the main causes for workplace deviance; workplace dissatisfaction is also a factor. According to Bolin and Heatherly, \"dissatisfaction results in a higher incidence of minor offenses, but does not necessarily lead to severe offense\". An employee who is less satisfied with his or her work may become less productive as their needs are not met. In the workplace, \"frustration, injustices and threats to self are primary antecedents to employee deviance\". Although workplace deviance does occur, the behavior is not universal. There are two preventive measures that business owners can use to protect themselves. The first is strengthening the employee's commitment by reacting strongly to abusive supervision so that the employee knows that the behavior is not accepted. Holding the employee at high esteem by reminding them of their importance, or setting up programs that communicate concern for the employee may also strengthen employee commitment. Providing a positive ethical climate can also help. Employers can do this by having a clear code of conduct that is applied to both managers and employees alike.\n\nWorkplace deviance may be expressed in various ways. Employees can engage in minor, extreme, nonviolent or violent behavior, which ultimately leads to an organization's decline in productivity. Interpersonal and organizational deviance are two forms of workplace deviance which are directed differently; however, both cause harm to an organization.\n\nInterpersonal deviance can occur when misconduct \"target(s) specific stakeholders such as coworkers\". Behavior falling within this subgroup of employee deviance includes gossiping about coworkers and assigning blame to them. These minor (but unhealthy) behaviors, directed at others, are believed to occur as some employees perceive \"a sense of entitlement often associated with exploitation\". In other words, they feel the need to misbehave in ways that will benefit them.\n\nDeviant behavior typically aimed directly at the organization is often referred to as organizational deviance. Organizational deviance encompasses production and property deviance. Workplace-deviant behavior may be expressed as tardiness or excessive absenteeism. These behaviors have been cited by some researchers as \"withdraw(al) behaviors…such behaviors allow employees to withdraw physically and emotionally from the organization\".\n\nEmployee silence is also considered a deviant behavior in the workplace, falling into the realms of both interpersonal and organizational deviance. Silence becomes employee deviance when \"an employee intentionally or unintentionally withholds any kind of information that might be useful to the organization\". The problem occurs if an employee fails to disclose important information, which detrimentally affects the effectiveness of the organization due to poor communication.\n\nCoworker backstabbing occurs to some degree in many workplaces. It consists of an employee's doing something to another employee to get a \"leg up\" on the other employee. Strategies used for backstabbing include dishonesty, blame (or false accusation), discrediting others and taking credit for another's work. Motives for backstabbing include disregarding others' rights in favor of one's own gain, self-image management, revenge, jealousy, and personal reasons.\n\nA novel form of workplace deviance has emerged in recent years, as technology becomes a bigger part of people's work lives. Internet workplace deviance (or \"cyber loafing\") has become another way for employees to avoid the tasks at hand. This includes surfing the web and doing non-work-related tasks on the internet such as chatting on social-networking sites, online shopping and other activities.\n\nAll behaviors in which deviant employees partake ultimately have a negative impact on the overall productivity of the organization. For this reason, all are considered production deviance. Production deviance is \"behavior that violates formally prescribed organizational norms with respect to minimal quality and quantity of work to be accomplished as part of one's job\".\n\nMore serious cases of deviant behavior harmful to an organization concern property deviance. Property deviance is \"where employees either damage or acquire tangible assets…without authorization\". This type of deviance typically involves theft but may include \"sabotage, intentional errors in work, misusing expense accounts\", among other examples.\n\nDeviant behavior can be much more extreme, involving sexual harassment and even violence. All these deviant behaviors create problems for the organization. It is costly for an organization to pay employees who are not working efficiently.\n\nThe relationships employees have with their organization are crucial, as they can play an important role in the development of workplace deviance. Employees who perceive their organization or supervisor(s) as more caring (or supportive) have been shown to have a reduced incidence of workplace-deviant behaviors. Supervisors, managers and organizations are aware of this, and \"assess their own behaviors and interactions with their employees and understand while they may not intend to abuse their employees they may be perceived as doing so…\".\n\nOrganizational justice and the organizational climate are also critical, since the quality of the work experience can impact employee behavior in the workplace. Organizational justice may be organized into three subcategories: procedural, distributive and interactional justice.\n\n\nResearch indicates that procedural justice (combined with interactional justice) is beneficial in reducing workplace-deviant behavior. Employees who are consulted (and given an opportunity to be involved in the decision-making processes at their organization) are less likely to act out, since their voices are valued.\n\nWorkplace deviance is a phenomenon which occurs frequently within an organization. Ultimately, it is the managers' and the organization's responsibility to uphold the norms to which the organization wishes to adhere; it is the organization's job to create an ethical climate. If organizations have authority figures who demonstrate their ethical values, a healthier workplace environment is created. \"Research has suggested that managers' behavior influences employee ethical decision-making\". Employees who perceive themselves as being treated respectfully and valued are those less likely to engage in workplace deviance.\n\n\n"}
