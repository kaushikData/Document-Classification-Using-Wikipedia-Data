{"id": "1545608", "url": "https://en.wikipedia.org/wiki?curid=1545608", "title": "Anaerobic digestion", "text": "Anaerobic digestion\n\nAnaerobic digestion is a collection of processes by which microorganisms break down biodegradable material in the absence of oxygen. The process is used for industrial or domestic purposes to manage waste or to produce fuels. Much of the fermentation used industrially to produce food and drink products, as well as home fermentation, uses anaerobic digestion.\n\nAnaerobic digestion occurs naturally in some soils and in lake and oceanic basin sediments, where it is usually referred to as \"anaerobic activity\". This is the source of marsh gas methane as discovered by Alessandro Volta in 1776.\n\nThe digestion process begins with bacterial hydrolysis of the input materials. Insoluble organic polymers, such as carbohydrates, are broken down to soluble derivatives that become available for other bacteria. Acidogenic bacteria then convert the sugars and amino acids into carbon dioxide, hydrogen, ammonia, and organic acids. These bacteria convert these resulting organic acids into acetic acid, along with additional ammonia, hydrogen, and carbon dioxide. Finally, methanogens convert these products to methane and carbon dioxide. The methanogenic archaea populations play an indispensable role in anaerobic wastewater treatments.\n\nAnaerobic digestion is used as part of the process to treat biodegradable waste and sewage sludge. As part of an integrated waste management system, anaerobic digestion reduces the emission of landfill gas into the atmosphere. Anaerobic digesters can also be fed with purpose-grown energy crops, such as maize.\n\nAnaerobic digestion is widely used as a source of renewable energy. The process produces a biogas, consisting of methane, carbon dioxide, and traces of other ‘contaminant’ gases. This biogas can be used directly as fuel, in combined heat and power gas engines or upgraded to natural gas-quality biomethane. The nutrient-rich digestate also produced can be used as fertilizer.\n\nWith the re-use of waste as a resource and new technological approaches that have lowered capital costs, anaerobic digestion has in recent years received increased attention among governments in a number of countries, among these the United Kingdom (2011), Germany and Denmark (2011).\n\nMany microorganisms affect anaerobic digestion, including acetic acid-forming bacteria (acetogens) and methane-forming archaea (methanogens). These organisms promote a number of chemical processes in converting the biomass to biogas.\n\nGaseous oxygen is excluded from the reactions by physical containment. Anaerobes utilize electron acceptors from sources other than oxygen gas. These acceptors can be the organic material itself or may be supplied by inorganic oxides from within the input material. When the oxygen source in an anaerobic system is derived from the organic material itself, the 'intermediate' end products are primarily alcohols, aldehydes, and organic acids, plus carbon dioxide. In the presence of specialised methanogens, the intermediates are converted to the 'final' end products of methane, carbon dioxide, and trace levels of hydrogen sulfide. In an anaerobic system, the majority of the chemical energy contained within the starting material is released by methanogenic bacteria as methane.\n\nPopulations of anaerobic microorganisms typically take a significant period of time to establish themselves to be fully effective. Therefore, common practice is to introduce anaerobic microorganisms from materials with existing populations, a process known as \"seeding\" the digesters, typically accomplished with the addition of sewage sludge or cattle slurry.\n\nThe four key stages of anaerobic digestion involve hydrolysis, acidogenesis, acetogenesis and methanogenesis.\nThe overall process can be described by the chemical reaction, where organic material such as glucose is biochemically digested into carbon dioxide (CO) and methane (CH) by the anaerobic microorganisms.\nIn most cases, biomass is made up of large organic polymers. For the bacteria in anaerobic digesters to access the energy potential of the material, these chains must first be broken down into their smaller constituent parts. These constituent parts, or monomers, such as sugars, are readily available to other bacteria. The process of breaking these chains and dissolving the smaller molecules into solution is called hydrolysis. Therefore, hydrolysis of these high-molecular-weight polymeric components is the necessary first step in anaerobic digestion. Through hydrolysis the complex organic molecules are broken down into simple sugars, amino acids, and fatty acids.\n\nAcetate and hydrogen produced in the first stages can be used directly by methanogens. Other molecules, such as volatile fatty acids (VFAs) with a chain length greater than that of acetate must first be catabolised into compounds that can be directly used by methanogens.\n\nThe biological process of acidogenesis results in further breakdown of the remaining components by acidogenic (fermentative) bacteria. Here, VFAs are created, along with ammonia, carbon dioxide, and hydrogen sulfide, as well as other byproducts. The process of acidogenesis is similar to the way milk sours.\n\nThe third stage of anaerobic digestion is acetogenesis. Here, simple molecules created through the acidogenesis phase are further digested by acetogens to produce largely acetic acid, as well as carbon dioxide and hydrogen.\n\nThe terminal stage of anaerobic digestion is the biological process of methanogenesis. Here, methanogens use the intermediate products of the preceding stages and convert them into methane, carbon dioxide, and water. These components make up the majority of the biogas emitted from the system. Methanogenesis is sensitive to both high and low pHs and occurs between pH 6.5 and pH 8. The remaining, indigestible material the microbes cannot use and any dead bacterial remains constitute the digestate.\n\nAnaerobic digesters can be designed and engineered to operate using a number of different configurations and can be categorized into batch vs. continuous process mode, mesophilic vs. thermophilic temperature conditions, high vs. low portion of solids, and single stage vs. multistage processes. More initial build money and a larger volume of the batch digester is needed to handle the same amount of waste as a continuous process digester. Higher heat energy is demanded in a thermophilic system compared to a mesophilic system and has a larger gas output capacity and higher methane gas content. For solids content, low will handle up to 15% solid content. Above this level is considered high solids content and can also be known as dry digestion. In a single stage process, one reactor houses the four anaerobic digestion steps. A multistage process utilizes two or more reactors for digestion to separate the methanogenesis and hydrolysis phases.\n\nAnaerobic digestion can be performed as a batch process or a continuous process. In a batch system, biomass is added to the reactor at the start of the process. The reactor is then sealed for the duration of the process. In its simplest form batch processing needs inoculation with already processed material to start the anaerobic digestion. In a typical scenario, biogas production will be formed with a normal distribution pattern over time. Operators can use this fact to determine when they believe the process of digestion of the organic matter has completed. There can be severe odour issues if a batch reactor is opened and emptied before the process is well completed. A more advanced type of batch approach has limited the odour issues by integrating anaerobic digestion with in-vessel composting. In this approach inoculation takes place through the use of recirculated degasified percolate. After anaerobic digestion has completed, the biomass is kept in the reactor which is then used for in-vessel composting before it is opened As the batch digestion is simple and requires less equipment and lower levels of design work, it is typically a cheaper form of digestion. Using more than one batch reactor at a plant can ensure constant production of biogas.\n\nIn continuous digestion processes, organic matter is constantly added (continuous complete mixed) or added in stages to the reactor (continuous plug flow; first in – first out). Here, the end products are constantly or periodically removed, resulting in constant production of biogas. A single or multiple digesters in sequence may be used. Examples of this form of anaerobic digestion include continuous stirred-tank reactors, upflow anaerobic sludge blankets, expanded granular sludge beds, and internal circulation reactors.\n\nThe two conventional operational temperature levels for anaerobic digesters determine the species of methanogens in the digesters:\n\nA limit case has been reached in Bolivia, with anaerobic digestion in temperature working conditions of less than 10 °C. The anaerobic process is very slow, taking more than three times the normal mesophilic time process. In experimental work at University of Alaska Fairbanks, a 1,000 litre digester using psychrophiles harvested from \"mud from a frozen lake in Alaska\" has produced 200–300 litres of methane per day, about 20 to 30% of the output from digesters in warmer climates. Mesophilic species outnumber thermophiles, and they are also more tolerant to changes in environmental conditions than thermophiles. Mesophilic systems are, therefore, considered to be more stable than thermophilic digestion systems. In contrast, while thermophilic digestion systems are considered less stable, their energy input is higher, with more biogas being removed from the organic matter in an equal amount of time. The increased temperatures facilitate faster reaction rates, and thus faster gas yields. Operation at higher temperatures facilitates greater pathogen reduction of the digestate. In countries where legislation, such as the Animal By-Products Regulations in the European Union, requires digestate to meet certain levels of pathogen reduction there may be a benefit to using thermophilic temperatures instead of mesophilic.\n\nAdditional pre-treatment can be used to reduce the necessary retention time to produce biogas. For example, certain processes shred the substrates to increase the surface area or use a thermal pretreatment stage (such as pasteurisation) to significantly enhance the biogas output. The pasteurisation process can also be used to reduce the pathogenic concentration in the digesate leaving the anaerobic digester. Pasteurisation may be achieved by heat treatment combined with maceration of the solids.\n\nIn a typical scenario, three different operational parameters are associated with the solids content of the feedstock to the digesters:\n\nHigh solids (dry) digesters are designed to process materials with a solids content between 25 and 40%. Unlike wet digesters that process pumpable slurries, high solids (dry – stackable substrate) digesters are designed to process solid substrates without the addition of water. The primary styles of dry digesters are continuous vertical plug flow and batch tunnel horizontal digesters. Continuous vertical plug flow digesters are upright, cylindrical tanks where feedstock is continuously fed into the top of the digester, and flows downward by gravity during digestion. In batch tunnel digesters, the feedstock is deposited in tunnel-like chambers with a gas-tight door. Neither approach has mixing inside the digester. The amount of pretreatment, such as contaminant removal, depends both upon the nature of the waste streams being processed and the desired quality of the digestate. Size reduction (grinding) is beneficial in continuous vertical systems, as it accelerates digestion, while batch systems avoid grinding and instead require structure (e.g. yard waste) to reduce compaction of the stacked pile. Continuous vertical dry digesters have a smaller footprint due to the shorter effective retention time and vertical design. Wet digesters can be designed to operate in either a high-solids content, with a total suspended solids (TSS) concentration greater than ~20%, or a low-solids concentration less than ~15%.\n\nHigh solids (wet) digesters process a thick slurry that requires more energy input to move and process the feedstock. The thickness of the material may also lead to associated problems with abrasion. High solids digesters will typically have a lower land requirement due to the lower volumes associated with the moisture. High solids digesters also require correction of conventional performance calculations (e.g. gas production, retention time, kinetics, etc.) originally based on very dilute sewage digestion concepts, since larger fractions of the feedstock mass are potentially convertible to biogas.\n\nLow solids (wet) digesters can transport material through the system using standard pumps that require significantly lower energy input. Low solids digesters require a larger amount of land than high solids due to the increased volumes associated with the increased liquid-to-feedstock ratio of the digesters. There are benefits associated with operation in a liquid environment, as it enables more thorough circulation of materials and contact between the bacteria and their food. This enables the bacteria to more readily access the substances on which they are feeding, and increases the rate of gas production.\n\nDigestion systems can be configured with different levels of complexity. In a single-stage digestion system (one-stage), all of the biological reactions occur within a single, sealed reactor or holding tank. Using a single stage reduces construction costs, but results in less control of the reactions occurring within the system. Acidogenic bacteria, through the production of acids, reduce the pH of the tank. Methanogenic bacteria, as outlined earlier, operate in a strictly defined pH range. Therefore, the biological reactions of the different species in a single-stage reactor can be in direct competition with each other. Another one-stage reaction system is an anaerobic lagoon. These lagoons are pond-like, earthen basins used for the treatment and long-term storage of manures. Here the anaerobic reactions are contained within the natural anaerobic sludge contained in the pool.\n\nIn a two-stage digestion system (multistage), different digestion vessels are optimised to bring maximum control over the bacterial communities living within the digesters. Acidogenic bacteria produce organic acids and more quickly grow and reproduce than methanogenic bacteria. Methanogenic bacteria require stable pH and temperature to optimise their performance.\n\nUnder typical circumstances, hydrolysis, acetogenesis, and acidogenesis occur within the first reaction vessel. The organic material is then heated to the required operational temperature (either mesophilic or thermophilic) prior to being pumped into a methanogenic reactor. The initial hydrolysis or acidogenesis tanks prior to the methanogenic reactor can provide a buffer to the rate at which feedstock is added. Some European countries require a degree of elevated heat treatment to kill harmful bacteria in the input waste. In this instance, there may be a pasteurisation or sterilisation stage prior to digestion or between the two digestion tanks. Notably, it is not possible to completely isolate the different reaction phases, and often some biogas is produced in the hydrolysis or acidogenesis tanks.\n\nThe residence time in a digester varies with the amount and type of feed material, and with the configuration of the digestion system. In a typical two-stage mesophilic digestion, residence time varies between 15 and 40 days, while for a single-stage thermophilic digestion, residence times is normally faster and takes around 14 days. The plug-flow nature of some of these systems will mean the full degradation of the material may not have been realised in this timescale. In this event, digestate exiting the system will be darker in colour and will typically have more odour.\n\nIn the case of an upflow anaerobic sludge blanket digestion (UASB), hydraulic residence times can be as short as 1 hour to 1 day, and solid retention times can be up to 90 days. In this manner, a UASB system is able to separate solids and hydraulic retention times with the use of a sludge blanket. Continuous digesters have mechanical or hydraulic devices, depending on the level of solids in the material, to mix the contents, enabling the bacteria and the food to be in contact. They also allow excess material to be continuously extracted to maintain a reasonably constant volume within the digestion tanks.\n\nThe anaerobic digestion process can be inhibited by several compounds, affecting one or more of the bacterial groups responsible for the different organic matter degradation steps. The degree of the inhibition depends, among other factors, on the concentration of the inhibitor in the digester. Potential inhibitors are ammonia, sulfide, light metal ions (Na, K, Mg, Ca, Al), heavy metals, some organics (chlorophenols, halogenated aliphatics, N-substituted aromatics, long chain fatty acids), etc.\n\nThe most important initial issue when considering the application of anaerobic digestion systems is the feedstock to the process. Almost any organic material can be processed with anaerobic digestion; however, if biogas production is the aim, the level of putrescibility is the key factor in its successful application. The more putrescible (digestible) the material, the higher the gas yields possible from the system.\n\nFeedstocks can include biodegradable waste materials, such as waste paper, grass clippings, leftover food, sewage, and animal waste. Woody wastes are the exception, because they are largely unaffected by digestion, as most anaerobes are unable to degrade lignin. Xylophalgeous anaerobes (lignin consumers) or using high temperature pretreatment, such as pyrolysis, can be used to break lignin down. Anaerobic digesters can also be fed with specially grown energy crops, such as silage, for dedicated biogas production. In Germany and continental Europe, these facilities are referred to as \"biogas\" plants. A codigestion or cofermentation plant is typically an agricultural anaerobic digester that accepts two or more input materials for simultaneous digestion.\n\nThe length of time required for anaerobic digestion depends on the chemical complexity of the material. Material rich in easily digestible sugars breaks down quickly, whereas intact lignocellulosic material rich in cellulose and hemicellulose polymers can take much longer to break down. Anaerobic microorganisms are generally unable to break down lignin, the recalcitrant aromatic component of biomass.\n\nAnaerobic digesters were originally designed for operation using sewage sludge and manures. Sewage and manure are not, however, the material with the most potential for anaerobic digestion, as the biodegradable material has already had much of the energy content taken out by the animals that produced it. Therefore, many digesters operate with codigestion of two or more types of feedstock. For example, in a farm-based digester that uses dairy manure as the primary feedstock, the gas production may be significantly increased by adding a second feedstock, e.g., grass and corn (typical on-farm feedstock), or various organic byproducts, such as slaughterhouse waste, fats, oils and grease from restaurants, organic household waste, etc. (typical off-site feedstock).\n\nDigesters processing dedicated energy crops can achieve high levels of degradation and biogas production. Slurry-only systems are generally cheaper, but generate far less energy than those using crops, such as maize and grass silage; by using a modest amount of crop material (30%), an anaerobic digestion plant can increase energy output tenfold for only three times the capital cost, relative to a slurry-only system.\n\nA second consideration related to the feedstock is moisture content. Drier, stackable substrates, such as food and yard waste, are suitable for digestion in tunnel-like chambers. Tunnel-style systems typically have near-zero wastewater discharge, as well, so this style of system has advantages where the discharge of digester liquids are a liability. The wetter the material, the more suitable it will be to handling with standard pumps instead of energy-intensive concrete pumps and physical means of movement. Also, the wetter the material, the more volume and area it takes up relative to the levels of gas produced. The moisture content of the target feedstock will also affect what type of system is applied to its treatment. To use a high-solids anaerobic digester for dilute feedstocks, bulking agents, such as compost, should be applied to increase the solids content of the input material. Another key consideration is the carbon:nitrogen ratio of the input material. This ratio is the balance of food a microbe requires to grow; the optimal C:N ratio is 20–30:1. Excess N can lead to ammonia inhibition of digestion.\n\nThe level of contamination of the feedstock material is a key consideration. If the feedstock to the digesters has significant levels of physical contaminants, such as plastic, glass, or metals, then processing to remove the contaminants will be required for the material to be used. If it is not removed, then the digesters can be blocked and will not function efficiently. It is with this understanding that mechanical biological treatment plants are designed. The higher the level of pretreatment a feedstock requires, the more processing machinery will be required, and, hence, the project will have higher capital costs.\n\nAfter sorting or screening to remove any physical contaminants from the feedstock, the material is often shredded, minced, and mechanically or hydraulically pulped to increase the surface area available to microbes in the digesters and, hence, increase the speed of digestion. The maceration of solids can be achieved by using a chopper pump to transfer the feedstock material into the airtight digester, where anaerobic treatment takes place.\n\nSubstrate composition is a major factor in determining the methane yield and methane production rates from the digestion of biomass. Techniques to determine the compositional characteristics of the feedstock are available, while parameters such as solids, elemental, and organic analyses are important for digester design and operation. Methane yield can be estimated from the elemental composition of substrate along with an estimate of its degradability (the fraction of the substrate that is converted to biogas in a reactor). In order to predict biogas composition (the relative fractions of methane and carbon dioxide) it is necessary to estimate carbon dioxide partitioning between the aqueous and gas phases, which requires additional information (reactor temperature, pH, and substrate composition) and a chemical speciation model.\n\nUsing anaerobic digestion technologies can help to reduce the emission of greenhouse gases in a number of key ways:\n\nAnaerobic digestion is particularly suited to organic material, and is commonly used for industrial effluent, wastewater and sewage sludge treatment. Anaerobic digestion, a simple process, can greatly reduce the amount of organic matter which might otherwise be destined to be dumped at sea, dumped in landfills, or burnt in incinerators.\n\nPressure from environmentally related legislation on solid waste disposal methods in developed countries has increased the application of anaerobic digestion as a process for reducing waste volumes and generating useful byproducts. It may either be used to process the source-separated fraction of municipal waste or alternatively combined with mechanical sorting systems, to process residual mixed municipal waste. These facilities are called mechanical biological treatment plants.\n\nIf the putrescible waste processed in anaerobic digesters were disposed of in a landfill, it would break down naturally and often anaerobically. In this case, the gas will eventually escape into the atmosphere. As methane is about 20 times more potent as a greenhouse gas than carbon dioxide, this has significant negative environmental effects.\n\nIn countries that collect household waste, the use of local anaerobic digestion facilities can help to reduce the amount of waste that requires transportation to centralized landfill sites or incineration facilities. This reduced burden on transportation reduces carbon emissions from the collection vehicles. If localized anaerobic digestion facilities are embedded within an electrical distribution network, they can help reduce the electrical losses associated with transporting electricity over a national grid.\n\nIn developing countries, simple home and farm-based anaerobic digestion systems offer the potential for low-cost energy for cooking and lighting.\nFrom 1975, China and India have both had large, government-backed schemes for adaptation of small biogas plants for use in the household for cooking and lighting. At present, projects for anaerobic digestion in the developing world can gain financial support through the United Nations Clean Development Mechanism if they are able to show they provide reduced carbon emissions.\n\nMethane and power produced in anaerobic digestion facilities can be used to replace energy derived from fossil fuels, and hence reduce emissions of greenhouse gases, because the carbon in biodegradable material is part of a carbon cycle. The carbon released into the atmosphere from the combustion of biogas has been removed by plants for them to grow in the recent past, usually within the last decade, but more typically within the last growing season. If the plants are regrown, taking the carbon out of the atmosphere once more, the system will be carbon neutral. In contrast, carbon in fossil fuels has been sequestered in the earth for many millions of years, the combustion of which increases the overall levels of carbon dioxide in the atmosphere.\n\nBiogas from sewage sludge treatment is sometimes used to run a gas engine to produce electrical power, some or all of which can be used to run the sewage works. Some waste heat from the engine is then used to heat the digester. The waste heat is, in general, enough to heat the digester to the required temperatures. The power potential from sewage works is limited – in the UK, there are about 80 MW total of such generation, with the potential to increase to 150 MW, which is insignificant compared to the average power demand in the UK of about 35,000 MW. The scope for biogas generation from nonsewage waste biological matter – energy crops, food waste, abattoir waste, etc. - is much higher, estimated to be capable of about 3,000 MW. Farm biogas plants using animal waste and energy crops are expected to contribute to reducing CO emissions and strengthen the grid, while providing UK farmers with additional revenues.\n\nSome countries offer incentives in the form of, for example, feed-in tariffs for feeding electricity onto the power grid to subsidize green energy production.\n\nIn Oakland, California at the East Bay Municipal Utility District’s main wastewater treatment plant (EBMUD), food waste is currently codigested with primary and secondary municipal wastewater solids and other high-strength wastes. Compared to municipal wastewater solids digestion alone, food waste codigestion has many benefits. Anaerobic digestion of food waste pulp from the EBMUD food waste process provides a higher normalized energy benefit, compared to municipal wastewater solids: 730 to 1,300 kWh per dry ton of food waste applied compared to 560 to 940 kWh per dry ton of municipal wastewater solids applied.\n\nBiogas grid-injection is the injection of biogas into the natural gas grid. The raw biogas has to be previously upgraded to biomethane. This upgrading implies the removal of contaminants such as hydrogen sulphide or siloxanes, as well as the carbon dioxide. Several technologies are available for this purpose, the most widely implemented being pressure swing adsorption (PSA), water or amine scrubbing (absorption processes) and, in recent years, membrane separation.\nAs an alternative, the electricity and the heat can be used for on-site generation, resulting in a reduction of losses in the transportation of energy. Typical energy losses in natural gas transmission systems range from 1–2%, whereas the current energy losses on a large electrical system range from 5–8%.\n\nIn October 2010, Didcot Sewage Works became the first in the UK to produce biomethane gas supplied to the national grid, for use in up to 200 homes in Oxfordshire. By 2017, UK electricity firm Ecotricity plan to have digester fed by locally sourced grass fueling 6000 homes\n\nAfter upgrading with the above-mentioned technologies, the biogas (transformed into biomethane) can be used as vehicle fuel in adapted vehicles. This use is very extensive in Sweden, where over 38,600 gas vehicles exist, and 60% of the vehicle gas is biomethane generated in anaerobic digestion plants.\n\nThe solid, fibrous component of the digested material can be used as a soil conditioner to increase the organic content of soils. Digester liquor can be used as a fertiliser to supply vital nutrients to soils instead of chemical fertilisers that require large amounts of energy to produce and transport. The use of manufactured fertilisers is, therefore, more carbon-intensive than the use of anaerobic digester liquor fertiliser. In countries such as Spain, where many soils are organically depleted, the markets for the digested solids can be equally as important as the biogas.\n\nBy using a bio-digester, which produces the bacteria required for decomposing, cooking gas is generated. The organic garbage like fallen leaves, kitchen waste, food waste etc. are fed into a crusher unit, where the mixture is conflated with a small amount of water. The mixture is then fed into the bio-digester, where the bacteria decomposes it to produce cooking gas. This gas is piped to kitchen stove. A 2 cubic meter bio-digester can produce 2 cubic meter of cooking gas. This is equivalent to 1 kg of LPG. The notable advantage of using a bio-digester is the sludge which is a rich organic manure.\n\nThe three principal products of anaerobic digestion are biogas, digestate, and water.\n\nBiogas is the ultimate waste product of the bacteria feeding off the input biodegradable feedstock (the methanogenesis stage of anaerobic digestion is performed by archaea, a micro-organism on a distinctly different branch of the phylogenetic tree of life to bacteria), and is mostly methane and carbon dioxide,\nwith a small amount hydrogen and trace hydrogen sulfide. (As-produced, biogas also contains water vapor, with the fractional water vapor volume a function of biogas temperature). Most of the biogas is produced during the middle of the digestion, after the bacterial population has grown, and tapers off as the putrescible material is exhausted. The gas is normally stored on top of the digester in an inflatable gas bubble or extracted and stored next to the facility in a gas holder.\n\nThe methane in biogas can be burned to produce both heat and electricity, usually with a reciprocating engine or microturbine often in a cogeneration arrangement where the electricity and waste heat generated are used to warm the digesters or to heat buildings. Excess electricity can be sold to suppliers or put into the local grid. Electricity produced by anaerobic digesters is considered to be renewable energy and may\nattract subsidies. Biogas does not contribute to increasing atmospheric carbon dioxide concentrations because the gas is not released directly into the atmosphere and the carbon dioxide comes from an organic source with a short carbon cycle.\n\nBiogas may require treatment or 'scrubbing' to refine it for use as a fuel. Hydrogen sulfide, a toxic product formed from sulfates in the feedstock, is released as a trace component of the biogas. National environmental enforcement agencies, such as the U.S. Environmental Protection Agency or the English and Welsh Environment Agency, put strict limits on the levels of gases containing hydrogen sulfide, and, if the levels of hydrogen sulfide in the gas are high, gas scrubbing and cleaning equipment (such as amine gas treating) will be needed to process the biogas to within regionally accepted levels. Alternatively, the addition of ferrous chloride FeCl to the digestion tanks inhibits hydrogen sulfide production.\n\nVolatile siloxanes can also contaminate the biogas; such compounds are\nfrequently found in household waste and wastewater. In digestion facilities accepting these materials as a component of the feedstock, low-molecular-weight siloxanes volatilise into biogas. When this gas is combusted in a gas engine, turbine, or boiler, siloxanes are converted into silicon dioxide (SiO), which deposits internally in the machine, increasing wear and tear. Practical and cost-effective technologies to remove siloxanes and other biogas contaminants are available at the present time. In certain applications, \"in situ\" treatment can be used to increase the methane purity by reducing the offgas carbon dioxide content, purging the majority of it in a secondary reactor.\n\nIn countries such as Switzerland, Germany, and Sweden, the methane in the biogas may be compressed for it to be used as a vehicle transportation fuel or input directly into the gas mains. In countries where the driver for the use of anaerobic digestion are renewable electricity subsidies, this route of treatment is less likely, as energy is required in this processing stage and reduces the overall levels available to sell.\n\nDigestate is the solid remnants of the original input material to the digesters that the microbes cannot use. It also consists of the mineralised remains of the dead bacteria from within the digesters. Digestate can come in three forms: fibrous, liquor, or a sludge-based combination of the two fractions. In two-stage systems, different forms of digestate come from different digestion tanks. In single-stage digestion systems, the two fractions will be combined and, if desired, separated by further processing.\n\nThe second byproduct (acidogenic digestate) is a stable, organic material consisting largely of lignin and cellulose, but also of a variety of mineral components in a matrix of dead bacterial cells; some plastic may be present. The material resembles domestic compost and can be used as such or to make low-grade building products, such as fibreboard.\nThe solid digestate can also be used as feedstock for ethanol production.\n\nThe third byproduct is a liquid (methanogenic digestate) rich in nutrients, which can be used as a fertiliser, depending on the quality of the material being digested. Levels of potentially toxic elements (PTEs) should be chemically assessed. This will depend upon the quality of the original feedstock. In the case of most clean and source-separated biodegradable waste streams, the levels of PTEs will be low. In the case of wastes originating from industry, the levels of PTEs may be higher and will need to be taken into consideration when determining a suitable end use for the material.\n\nDigestate typically contains elements, such as lignin, that cannot be broken down by the anaerobic microorganisms. Also, the digestate may contain ammonia that is phytotoxic, and may hamper the growth of plants if it is used as a soil-improving material. For these two reasons, a maturation or composting stage may be employed after digestion. Lignin and other materials are available for degradation by aerobic microorganisms, such as fungi, helping reduce the overall volume of the material for transport. During this maturation, the ammonia will be oxidized into nitrates, improving the fertility of the material and making it more suitable as a soil improver. Large composting stages are typically used by dry anaerobic digestion technologies.\n\nThe final output from anaerobic digestion systems is water, which originates both from the moisture content of the original waste that was treated and water produced during the microbial reactions in the digestion systems. This water may be released from the dewatering of the digestate or may be implicitly separate from the digestate.\n\nThe wastewater exiting the anaerobic digestion facility will typically have elevated levels of biochemical oxygen demand (BOD) and chemical oxygen demand (COD). These measures of the reactivity of the effluent indicate an ability to pollute. Some of this material is termed 'hard COD', meaning it cannot be accessed by the anaerobic bacteria for conversion into biogas. If this effluent were put directly into watercourses, it would negatively affect them by causing eutrophication. As such, further treatment of the wastewater is often required. This treatment will typically be an oxidation stage wherein air is passed through the water in a sequencing batch reactors or reverse osmosis unit.\n\nThe history of anaerobic digestion is a long one, beginning as early as tenth century BCE in Assyria where biogas was used to heat bath water. Reported scientific interest in the manufacturing of gas produced by the natural decomposition of organic matter dates from the 17th century, when Robert Boyle (1627-1691) and Stephen Hales (1677-1761) noted that disturbing the sediment of streams and lakes released flammable gas. In 1778, the Italian physicist Alessandro Volta (1745-1827), the father of Electrochemistry, scientifically identified that gas as methane.\n\nIn 1808 Sir Humphry Davy proved the presence of methane in the gases produced by cattle manure. The first known anaerobic digester was built in 1859 at a leper colony in Bombay in India. In 1895, the technology was developed in Exeter, England, where a septic tank was used to generate gas for the sewer gas destructor lamp, a type of gas lighting. Also in England, in 1904, the first dual-purpose tank for both sedimentation and sludge treatment was installed in Hampton, London. \n\nBy the early 20th century, anaerobic digestion systems began to resemble the technology as it appears today. In 1906, Karl Imhoff created the Imhoff tank; an early form of anaerobic digester and model wastewater treatment system throughout the early 20th century. After 1920, closed tank systems began to replace the previously common use of anaerobic lagoons- covered earthen basins used to treat volatile solids. Research on anaerobic digestion began in earnest in the 1930s.\n\nAround the time of World War I, production from biofuels slowed as petroleum production increased and its uses were identified. While fuel shortages during World War II re-popularized anaerobic digestion, interest in the technology decreased again after the war ended. Similarly, the 1970s energy crisis sparked interest in anaerobic digestion. In addition to high energy prices, factors affecting the adoption of Anaerobic Digestion systems include receptivity to innovation, pollution penalties, policy incentives, and the availability of subsidies and funding opportunities.\n\nToday, anaerobic digesters are commonly found alongside farms to reduce nitrogen run-off from manure, or wastewater treatment facilities to reduce the costs of sludge disposal. Agricultural anaerobic digestion for energy production has become most popular in Germany, where there were 8,625 digesters in 2014. In the United Kingdom, there were 259 facilities by 2014, and 500 projects planned to become operational by 2019. In the United States, there were 191 operational plants across 34 states in 2012. Policy may explain why adoption rates are so different across these countries.\n\nFeed-in tariffs in Germany were enacted in 1991, also known as FIT, providing long-term contracts compensating investments in renewable energy generation. Consequently, between 1991 and 1998 the number of anaerobic digester plants in Germany grew from 20 to 517. In the late 1990s, energy prices in Germany varied and investors became unsure of the market’s potential. The German government responded by amending FIT four times between 2000 and 2011, increasing tariffs and improving the profitability of anaerobic digestion, and resulting in reliable returns for biogas production and continued high adoption rates across the country.\n\n\n"}
{"id": "43838560", "url": "https://en.wikipedia.org/wiki?curid=43838560", "title": "Arthur Asa Berger", "text": "Arthur Asa Berger\n\nArthur Asa Berger (born 1933) is Professor Emeritus in Broadcast and Electronic Communication Arts at San Francisco State University.\n\nHe received a \"Catholic\" education in his public high school despite the fact that he is Jewish. Most of his teachers were Catholics who were educated at Boston College or College of the Holy Cross. He gradually developed interest in writing and drawing.\nHe got a B.A. in literature and philosophy at the University of Massachusetts in 1954, assuming that a good education would fit him for any job. Then he applied to graduate school in journalism, thinking that he liked to write and might find journalism an interesting career. He was accepted into the University of California Berkeley journalism school and started there in the summer of 1954 but transferred to the University of Iowa where he could work with people like Marguerite Young. He was also able to take a couple of philosophy courses with Gustav Bergmann from the Vienna Circle. He was drafted in the summer of 1956, eleven days after he received his MA. He got out of the Army in 1958 and went to Europe for a year.\n\nA year after he came back from Europe, he enrolled at the University of Minnesota’s program for a Ph.D in American Studies. In time, he ended up teaching in the Broadcast and Electronic Communication Arts department at San Francisco State University where he taught courses on writing and media criticism. Berger has published more than 130 articles and more than 70 books in the course of his career. He spent 1963-64 as a Fulbright scholar at the University of Milan and has also taught at Jinan University and Tsing Hua university in China, spent a month as a Fulbright Senior Specialist lecturing on semiotics in Argentina and lectured in more than a dozen universities in various countries. His works have been cited thousands of times by international academics.\n\nBerger is married to Philis Berger and they have two children. Their son Gabriel went to Harvard for his BA and has a Ph.D. in\nmathematics from Columbia. He works for Google now. Their daughter Nina has a doctorate from an institute that trains psychoanalysts and is a psychoanalyst. Jason Berger was his brother. He manages his personal weblog named \"Decoder Man\".\n\n"}
{"id": "3228429", "url": "https://en.wikipedia.org/wiki?curid=3228429", "title": "Auto-destructive art", "text": "Auto-destructive art\n\nAuto-Destructive Art (ADA) is a form of art coined by Gustav Metzger, an artist born in Bavaria that moved to Britain in 1939. Taking place after World War II, Metzger wanted to showcase the destruction created from the war through his artwork. This movement took place in England and was launched by Metzger in 1959. This term was invented in the early 1960s and put into circulation by his article \"Machine, Auto-Creative and Auto-Destructive Art\" in the summer 1962 issue of the journal \"Ark\".\n\nThis movement sparked after World War I. Before World War I, artists approached art very traditionally, with paint and paper. As seen in Impressionism and Expressionism, artwork before war was inspired by everyday life. After World War I, artists began to introduce new styles of art that used different medias and techniques. Cubism and Dadaism were at the heart of these new techniques. Auto-Destructive Art follows these newer techniques by taking everyday objects and causing damage. Destructive art is similar to Dadaism in the way it rejects past concepts in order to not only redefine art, but also to bring light to issues. Although similar to Dadaism, ADA was a movement of its own due to the style and time period. After World War II, many artists turned to Abstract Expressionism, but ADA differed with its focus on destruction.\n\nAuto-Destructive Art was highly influenced by World War II. After the many casualties and mass destruction, people around the world were distraught and horrified. In comparison to World War I, World War II had a different influence on art due to the extensive use of aircraft and the introduction of nuclear weapons. These weapons greatly inspired artists to approach art using new means such as corrosion, stress, or heat. ADA represents the war and its casualties. Artists in this time period wanted to explore issues in new ways. In order to explore these issues in the industrial society, Metzger encouraged artists to work with scientists and engineers.\n\nAuto-Destructive Art’s purpose was to draw attention to the destruction of previous beliefs. By allowing stress and natural forces to create damage after an initial mark, the art is auto-created. This represents how man sparked and created destruction. The destruction also represents the chaos caused by the government. Politics was a major driving force of ADA artists. In interviews, Metzger expressed his dislike of politics and commercialism. Metzger believed the “aesthetic of revulsion” would add to the idea of the corrupt, capitalist system. By damaging the art itself, Metzger is able to question the idea of what art is. He goes against the idea of egocentrism in the artistic world. Metzger believed that in order to bring light to the corruption in politics, he must remove himself and his work from the art. He even states in his manifesto that “Auto-destructive art mirrors the compulsive perfectionism of arms manufacture - polishing to destruction point.” This excerpt reflects the idea that many ADA artists shared. They wanted to withdraw from mass production, commercialism, and manufacturing.\n\nGustav Metzger grew up during the Holocaust, which greatly inspired his artwork. In 1943, Metzger lost his parents to Nazi attacks. Metzger quotes “Facing up to the Nazis and the powers of the Nazi state coloured my life as an artist,”. Metzger would spark the damage of the art piece to represent mankind’s destruction. He then allowed natural forces to take over which symbolized how mankind’s spark can result in much more destruction than intended. Metzger later used his art to speak out against the violence we do to each other and nature. In his 2009 piece, \"Flailing Trees\", Metzger uprooted and overturned a series of trees to symbolize the brutalization done to the natural world.\nAlong with Metzger, John Latham was another influential destructive artist. Latham had an interest in “temporality” and “time based” destruction. His most recognized piece was the \"Skoob Tower Ceremonies\". Latham used stacks of books to create towers that he then set on fire. This demonstration was controversial due to the recent Nazi attacks and book burnings that took place. Latham noted that he was not against the content in the books, but rather the idea that books are the only source of knowledge. \n\nArtist Jean Tinguely was also a powerful figure in destructive art with his use of mechanics in 1953. Later in his work, Tinguely wanted to focus on “dematerialization” by creating machines that would eventually destroy themselves. One very significant piece was \"Homage to New York\". This piece included a machine that created noise, paintings, and smoke before being stopped by a firefighter. The piece was meant to self-destruct and although was not able to complete its actions, still succeeded as an art piece. Tinguely believed this piece symbolized a freeing from material because once the performance was over, it was cleaned up and there was nothing left. After this piece, Tinguely was able to construct two more successful machines that did self-destruct.\nNot only was destructive art seen in traditional art, but also performance art. Jeff Keen, a film-maker, included forms of destruction in his “collaged films”. Keen would cut and edit scenes from pop culture, comics, and other films to create “multi-screen projections”. His films were seen as disconnected and jumbled which confused viewers. Keen symbolizes destruction in his cut and edit skills of previous works. By using other sources and editing them together, Keen has destructed the old and created something new.\n\nMany strategies were used to create, or rather destroy art. Metzger used bricks, cloth, and other objects as a base for his work. He then used multiple types of harming materials such as acid or fire to create the destruction. For one piece, Metzger used a nylon sheet and then threw hydrochloric acid on it. Metzger noted that while the acid did destroy the sheet, it also created shapes. This piece did not have a name for it, but was later recreated in 2004 as part of the \"Tate Britain exhibition, Art and the Sixties: This was Tomorrow.\" Other artists explored the use of everyday objects such as books or mechanics. The use of everyday objects added to the concept of how materialism and manufacturing should be destroyed.\n\nOne impact of ADA was the creation of the “Destruction in Art Symposium”(DIAS). Metzger was against the art dealer system and aimed to get Auto-Destructive Art publicly funded, but the government would not provide funding. Metzger was against art dealing because dealers were uninterested in the “fundamental technical change”. This resulted in Metzger and John Sharkey to organize DIAS in 1966, which was a volunteer based event that showcased different art forms from diverse individuals across the world. One significant performance at this event was Yoko Ono’s “Cut” piece. In this piece, presented at the Museum of Modern Art in 1971, Ono sat and allowed the audience to cut away pieces of her clothing. Allowing the audience to cut away her clothing not only represented female vulnerability but also destroyed the traditional relationship between the viewer and the artist. Pete Townshend of The Who would later relate destroying his guitar on stage to auto-destructive art. Band member Keith Moon dramatically followed suit by placing explosives into his drums (at some points nearly blowing himself to pieces). In 2013, Hirshhorn Museum and Sculpture Garden in Washington, D.C., would open an exhibit giving focus to destruction in art. The exhibit “Damage Control: Art and Destruction since 1950”, included a range of art that demonstrates how destruction has impacted art today.\nAlthough not highly recognized or taught, Auto-Destructive Art still makes an impact on all types of artists to this day. It continues to inspire artists to disconnect from traditional art styles in order to bring attention to worldly issues.\n\n\n"}
{"id": "1531487", "url": "https://en.wikipedia.org/wiki?curid=1531487", "title": "Behavior modification facility", "text": "Behavior modification facility\n\nA behavior modification facility (or youth residential program) is a residential educational and treatment institution enrolling adolescents who are perceived as displaying antisocial behavior, in an attempt to alter their conduct. As of 2008 there were about 650 nongovernmental, residential programs in the United States offering treatment services for adolescents. Some similar institutions are operated as components of governmental education or correctional systems.\n\nPractices and service quality in such program vary greatly. The behavior modification methodologies used vary, but a combination of positive and negative reinforcement is typically used. Often these methods are delivered in a contingency management format such as a point system or level system. Such methodology has been found to be highly effective in the treatment of disruptive disorders (see meta-analysis of Chen & Ma (2007).\n\nPositive reinforcement mechanisms include points, rewards and signs of status, while punishment procedures may include time-outs, point deductions, reversal of status, prolonged stays at a facility, physical restraint, or even corporal punishment. Research showed that time out length was not a factor and suggestions were made to limit time out to five minute durations. A newer approach uses graduated sanctions. Staff appear easily trained in behavioral intervention, such training is maintained and does lead to improved consumer outcomes, as well as reduce turn over. More restrictive punishment procedures in general are less appealing to staff and administrators.\n\nBehavioral programs were found to lessen the need for medication Several studies have found that gains made in residential treatment programs are maintained from 1–5 years post discharge. Therapeutic boarding schools are boarding schools based on the therapeutic community model that offers an educational program together with specialized structure and supervision for students with emotional and behavioral problems, substance abuse problems, or learning difficulties. Some schools are accredited as Residential treatment centers. \n\nBehavioral residential treatment became so popular in the 1970s and 1980s that a journal was formed called \"Behavioral residential Treatment\", which later changed its name to \"Behavioral Intervention.\" Behavioral Intervention continues to be published today.\n\nIn the late 1960s, behavior modification or practice referred to as applied behavior analysis began to move rapidly into residential treatment facilities. The goal was to redesign the behavioral architecture around delinquent teens to lessen chances of recidivism and improve academics Harold Cohen and James Filipczak (1971) published a book hailing the successes of such programs in doubling learning rates and reducing recidivism. This book even contained an introduction from the leading behaviorist at the time, B.F. Skinner hailing the achievements. Independent analysis of multiple sites with thousands of adolescents found behavior modification to be more effective than treatment as usual, a therapeutic milieu, and as effective as more psychologically intense programs such as transactional analysis with better outcomes on behavioral measures; however, these authors found that behavior modification was more prone to leading to poor relationships with the clients. Over time interest faded in Cohen's CASE project Other studies found that in proper supervision of staff in behavior modification facilities could lead to greater use of punishment procedures.\n\nUnder the leadership of Montrose Wolf, Achievement place, the first Teaching Family Home became the prototype for behavioral programs. Achievement place opened in 1967. Each home has from 6-8 boys in it with two \"parents\" trained in behavior modification principles. The token system for the program was divided into 3 levels. Outcome studies have found that Achievement place and other teaching family homes reduce recidivism and increase pro-social behavior, as well as self-esteem. While initial research suggested the effects of the program only lasted for one year post discharge, recent review of the data suggests the program lasts longer in effect.\n\nGradually, behavior modification /applied behavior analysis within the penal system including residential facilities for delinquent youth lost popularity in the 1970s-1980s due to a large number of abuses (see Cautilli & Weinberg (2007) ), but recent trends in the increase in U.S. crime and recent focus on reduction of recidivism have given such programs a second look . Indeed, because of societal needs the number of youth residential facilities has grown over recent years to close to 39,950 in 2000. The use of functional analysis has been shown to be teachable to staff and able to reduce use of punishment procedures. Rutherford's (2009) review from interviews and archival materials documents the decline from treatment of behavior analysis with criminal justice populations.\n\nWhile boot camp type programs have not been shown to be successful, largely because they represent punishment devoid of context (unlike in the military, where passing boot camp initiates one into the service), programs such as teaching family homes based on the Teaching-Family Model have been extensively researched and show positive gains. Research shows that they can be used to reduce delinquency while adolescents are in the home and post release {see Kingsley (2006) }. In general, these types of programs take a behavioral engineering approach to reducing problem behavior and building skills.\n\nIn general, behavior modification programs that are used in facilities or in the natural environment have the largest effect size and lead to an estimated 15% reduction in recidivism. While this reduction appears to be modest, it holds potention in the U.S. given the large number of people in the prison system. Increasingly behavior modification models based on the principles of applied behavior analysis are being developed to model and reduce delinquency\n\nThis industry is not without controversy, however. The U.S. Surgeon General (1999) discussed the need to clarify admission criteria to residential treatment programs. Included in the same report was the call for more updated research as most of the residential research had been completed in the 1960s and 1970s.. Disability rights organizations, such as the Bazelon Center for Mental Health Law, oppose placement in such programs and call into question the appropriateness and efficacy of such group placements, the failure of such programs to address problems in the child’s home and community environment, the limited or no mental health services offered and substandard educational programs.\n\nBazelon promotes community-based services on the basis that it considers more effective and less costly than residential placement. While the behavior modification programs can be delivered as easily in residential programs as in community-based programs overall community-based programs continue to lack empirical support especially with respect to long term outcomes for severe cases with the notable exception of Hinckley and Ellis (1985). Even with this said, in 1999 the surgeon general clearly stated \"...it is premature to endorse the effectiveness of residential treatment for adolescents.\".\n\nFrom late 2007 through 2008, a broad coalition of grass roots efforts, prominent medical and psychological organizations that including members of Alliance for the Safe, Therapeutic and Appropriate use of Residential Treatment (ASTART) and the Community Alliance for the Ethical Treatment of Youth (CAFETY), provided testimony and support that led to the creation of the \"Stop Child Abuse in Residential Programs for Teens Act of 2008\" by the United States Congress Committee on Education and Labor.\n\nJon Martin-Crawford and Kathryn Whitehead of CAFETY testified at a hearing of the United States Congress Committee on Education and Labor on April 24, 2008, where they described abusive practices they had experienced at the Family Foundation School and Mission Mountain School, both therapeutic boarding schools.\n\nOne recent acknowledgement has been that long term care does not equate with better outcomes.\nTo reduce the tendency for abuse, a strong push has occurred to certify or license behavior modifiers or to have such practices limited to licensed psychologists. In particular psychologists with behavioral training American psychological association offers a diplomat (post Ph.D. and licensed certification) in behavioral psychology.\n\nOften the practice of behavior modification in facilities comes into question (see recent interest in Judge Rotenberg Educational Center, Aspen Education Group and the World Wide Association of Specialty Programs and Schools). Often these types of restrictive issues are discussed as part of ethical and legal standards (see Professional practice of behavior analysis). Recent research has identified some best practices for use in such facilities In general policies in such facilities require the presence of a treatment team to ensure that abuses do not occur especially if facilities are attempting to use punishment programs.\n\nIn the U.S. residential treatment programs are all monitored at the state level and many are JACHO accredited. States vary in requirements to open such centers. Due to the absence of regulation of these programs by the federal government and because many are not subject to state licensing or monitoring, the Federal Trade Commission has issued a guide for parents considering such placement \n\nResidential therapist who are behavior modifiers should join professional organizations and be professionally affiliated. Many organizations exist for behavior therapists around the world. The World Association for Behavior Analysis offers a certification in behavior therapy In the United States, the American Psychological Association's Division 25 is the division for behavior analysis. The Association for Contextual Behavior Therapy is another professional organization. ACBS is home to many clinicians with specific interest in third generation behavior therapy. The Association for Behavioral and Cognitive Therapies (formerly the Association for the Advancement of Behavior Therapy) is for those with a more cognitive orientation. Internationally, most behavior therapists find a core intellectual home in the International Association for Behavior Analysis (ABA:I) .\n\n\n"}
{"id": "18359852", "url": "https://en.wikipedia.org/wiki?curid=18359852", "title": "Clan badge", "text": "Clan badge\n\nA clan badge, sometimes called a plant badge, is a badge or emblem, usually a sprig of a specific plant, that is used to identify a member of a particular Scottish clan. They are usually worn in a bonnet behind the Scottish crest badge, or attached at the shoulder of a lady's tartan sash. According to popular lore clan badges were used by Scottish clans as a means of identification in battle. An authentic example of plants being used in this way (though not by a clan) were the sprigs of oats used by troops under the command of Montrose during the sack of Aberdeen. Similar items are known to have been used by military forces in Scotland, like paper, or the \"White Cockade\" (a bunch of white ribbon) of the Jacobites.\n\nDespite popular lore, many clan badges attributed to Scottish clans would be completely impractical for use as a means of identification. Many would be unsuitable, even for a modern clan gathering, let alone a raging clan battle. Also, a number of the plants (and flowers) attributed as clan badges are only available during certain times of year. Even though it is maintained that clan badges were used long before the Scottish crest badges used today, according to a former Lord Lyon King of Arms the oldest symbols used at gatherings were heraldic flags such as the banner, standard and pinsel.\n\nThere is much confusion as to why some clans have been attributed more than one clan badge. Several 19th century writers variously attributed plants to clans, many times contradicting each other. It has been claimed by one writer that if a clan gained new lands it may have also acquired that district's \"badge\" and used it along with their own clan badge. It is clear however, that there are several large groups of clans which share badges and also share a historical connection. The Clan Donald group (clans \"Macdonald\", \"Macdonald of Clanranald\", \"Macdonell of Glengarry\", \"MacDonald of Keppoch\") and clans/septs which have been associated with Clan Donald (like certain \"MacIntyres\" and the \"Macqueens\" of Skye) all have common heath attributed as their badge. Another large group is the Clan Chattan group (clans \"Mackintosh\", \"Macpherson\", \"Macgillivray\", \"Macqueen\", \"Macbain\", \"Farquharson\", \"Davidson\") which have been attributed red whortleberry (sometimes called cranberry in Scotland), or bearberry, or boxwood. The leaves of these three plants are very similar, and at least one writer has claimed that whatever plant which happened to be available was used. One group, the Siol Alpin group, of clans are said to have claimed or are thought to share a common descent. The Siol Alpin clans (clans \"Grant\", \"Gregor\", \"MacAulay\", \"Macfie\", \"Macnab\", \"Mackinnon\", \"Macquarrie\") are all attributed the clan badge of pine (Scots fir). In some cases, clan badges are derived from the heraldry of clan chiefs. For example, the Farquharsons have pine attributed as a clan badge of theirs (pine also appears on the uniforms of the Invercauld Highlanders). Pine was actually used in the Invercauld Arms as a mark of cadencing to the basic Shaw-Mackintosh Arms.\n\n\n"}
{"id": "908981", "url": "https://en.wikipedia.org/wiki?curid=908981", "title": "Cocktail party", "text": "Cocktail party\n\nA cocktail party is a party at which cocktails are served. It is sometimes called a cocktail reception. A cocktail party organized for purposes of social or business networking is called a mixer.\n\nA cocktail hour is sometimes used by managers of hotels and restaurants as a means of attracting patrons between 4 pm and 6 pm.\n\nSome events, such as wedding receptions, are preceded by a cocktail hour. During the cocktail hour, guests socialize while drinking and eating appetizers. Organizers of these events use the cocktail hour to occupy guests between related events and to reduce the number of guests who arrive late.\n\nAlthough it has been said that the inventor of the cocktail party was Alec Waugh of London, an article in the \"St. Paul Pioneer Press\" in May 1917 credited its invention to a certain Mrs. Julius S. Walsh Jr. of St. Louis, Missouri. Mrs. Walsh invited 50 guests to her house on a Sunday at high noon for a one-hour affair. \"The party scored an instant hit,\" the newspaper declared, and stated that within weeks cocktail parties had become \"a St. Louis institution\". \n\nAlec Waugh noted that the first cocktail party in England was hosted in 1924 by war artist Christopher Nevinson.\n\nWomen who attend a cocktail party may usually wear a cocktail dress. A cocktail hat is sometimes worn as a fashion statement.\n\n"}
{"id": "3038539", "url": "https://en.wikipedia.org/wiki?curid=3038539", "title": "Composite gravity", "text": "Composite gravity\n\nIn theoretical physics, composite gravity refers to models that attempted to derive general relativity in a framework where the graviton is constructed as a composite bound state of more elementary particles, usually fermions. A theorem by Steven Weinberg and Edward Witten shows that this is not possible in Lorentz covariant theories: massless particles with spin greater than one are forbidden. The AdS/CFT correspondence may be viewed as a loophole in their argument. However, in this case not only the graviton is emergent; a whole spacetime dimension is emergent, too.\n\n"}
{"id": "53537603", "url": "https://en.wikipedia.org/wiki?curid=53537603", "title": "Compulsion loop", "text": "Compulsion loop\n\nA compulsion loop or a core loop is a habitual, designed chain of activities that will be repeated to gain a neurochemical reward such as the release of dopamine. Compulsion loops are deliberately used in video game design as an extrinsic motivation for players, but may also result from other activities that unintentionally create such loops.\n\nCompulsion loops can be used as a replacement for game content, especially in grinding and freemium game experience models. The opposite of rewarding predictable, tedious and repetitive tasks are reward action contingency based systems, where players overcome game challenges with clear signals of progress.\n\nPlayers perform an action, are rewarded, another possibility opens and the cycle repeats. The positive reinforcement effect can be strengthened by adding a variable ratio schedule, where each response has a chance of producing a reward. Another strategy is an avoidance schedule, where the players work to postpone a negative consequence.\n\nA well-known example of a compulsion loop in video games is the \"Monster Hunter\" series by Capcom. Players take the role of a monster hunter, using a variety of weapons and armor to slay or trap the creatures. By doing so, they gain monster parts and other loot that can be used to craft new weapons and equipment. The loop presents itself that players use their current equipment to hunt monsters with a given difficulty level that provide parts that can be used to craft improved equipment. This then lets them face more difficult monsters that provide parts for even better gear. This is aided by the random nature of the drops, sometimes requiring players to repeat quests several times to get the right parts.\n\nAnother type of compulsion loop are offered through many games in the form of a loot box or similar term, depending on the game. Loot boxes are earned progressively by continuing to play the game; this may be as a reward for winning a match, purchasable through in-game currency that one earns in game, or through microtransactions with real-world funds. Loot boxes contain a fixed number of randomly chosen in-game items, with at least one guaranteed to be of a higher rarity than the others. For many games, these items are simply customization options for the player's avatar that has no direct impact on gameplay, but they may also include gameplay-related items, or additional in-game currency. Loot boxes work under the psychology principle of variable rate reinforcement, which causes dopamine production at higher rates due to the unpredictable nature of the reward in contrast to fixed rewards. In many games, opening a loot box is accompanied by visuals and audios to heighten the excitement and further this response. Overall, a loot box system can encourage the player to continue to play the game, and potentially spend real-world funds to gain loot boxes immediately.\n\nIt is hypothesized that OCD symptoms arise from a compulsion loop and an obsession loop.\n\nEncouraging players to return to the game world can lead to video game addiction. Internet addiction disorder can also result from a compulsion loop created by users in checking email, websites, and social media to see the results of their actions.\n"}
{"id": "1435066", "url": "https://en.wikipedia.org/wiki?curid=1435066", "title": "Convention on the Elimination of All Forms of Discrimination Against Women", "text": "Convention on the Elimination of All Forms of Discrimination Against Women\n\nThe Convention on the Elimination of all Forms of Discrimination Against Women (CEDAW) is an international treaty adopted in 1979 by the United Nations General Assembly.\nDescribed as an international bill of rights for women, it was instituted on 3 September 1981 and has been ratified by 189 states. Over fifty countries that have ratified the Convention have done so subject to certain declarations, reservations, and objections, including 38 countries who rejected the enforcement article 29, which addresses means of settlement for disputes concerning the interpretation or application of the Convention. Australia's declaration noted the limitations on central government power resulting from its federal constitutional system. The United States and Palau have signed, but not ratified the treaty. The Holy See, Iran, Somalia, Sudan, and Tonga are not signatories to CEDAW.\n\nThe CEDAW Chairperson position is currently held by Dalia Leinarte.\n\nThe Convention has a similar format to the Convention on the Elimination of All Forms of Racial Discrimination, \"both with regard to the scope of its substantive obligations and its international monitoring mechanisms\". The Convention is structured in six parts with 30 articles total.\n\nArticle 1 defines discrimination against women in the following terms:Any distinction, exclusion or restriction made on the basis of sex which has the effect or purpose of impairing or nullifying the recognition, enjoyment or exercise by women, irrespective of their marital status, on a basis of equality of men and women, of human rights and fundamental freedoms in the political, economic, social, cultural, civil or any other field.Article 2 mandates that states parties ratifying the Convention declare intent to enshrine gender equality into their domestic legislation, repeal all discriminatory provisions in their laws, and enact new provisions to guard against discrimination against women. States ratifying the Convention must also establish tribunals and public institutions to guarantee women effective protection against discrimination, and take steps to eliminate all forms of discrimination practiced against women by individuals, organizations, and enterprises.\n\nArticle 3 requires states parties to guarantee basic human rights and fundamental freedoms to women \"on a basis of equality with men\" through the \"political, social, economic, and cultural fields.\"\n\nArticle 4 notes that \"[a]doption...of special measures aimed at accelerating de facto equality between men and women shall not be considered discrimination.\" It adds that special protection for maternity is not regarded as gender discrimination.\n\nArticle 5 requires states parties to take measures to seek to eliminate prejudices and customs based on the idea of the inferiority or the superiority of one sex or on stereotyped role for men and women. It also mandates the states parties \"[t]o ensure...the recognition of the common responsibility of men and women in the upbringing and development of their children.\"\n\nArticle 6 obliges states parties to \"take all appropriate measures, including legislation, to suppress all forms of trafficking in women and exploitation of prostitution of women.\"\n\nArticle 7 guarantees women equality in political and public life with a focus on equality in voting, participation in government, and participation in \"non-governmental organizations and associations concerned with the public and political life of the country.\"\n\nArticle 8 provides that states parties will guarantee women's equal \"opportunity to represent their Government at the international level and to participate in the work of international organizations.\"\n\nArticle 9 mandates state parties to \"grant women equal rights with men to acquire, change or retain their nationality\" and equal rights \"with respect to the nationality of their children.\"\n\nArticle 10 necessitates equal opportunity in education for female students and encourages coeducation. It also provides equal access to athletics, scholarships and grants as well as requires \"reduction in female students' drop out rates.\"\n\nArticle 11 outlines the right to work for women as \"an unalienable right of all human beings.\" It requires equal pay for equal work, the right to social security, paid leave and maternity leave \"with pay or with comparable social benefits without loss of former employment, seniority or social allowances.\" Dismissal on the grounds of maternity, pregnancy or status of marriage shall be prohibited with sanction.\n\nArticle 12 creates the obligation of states parties to \"take all appropriate measures to eliminate discrimination against women in the field of healthcare in order to ensure...access to health care services, including those related to family planning.\"\n\nArticle 13 guarantees equality to women \"in economic and social life,\" especially with respect to \"the right to family benefits, the right to bank loans, mortgages and other forms of financial credit, and the right to participate in recreational activities, sports and all aspects of cultural life.\"\n\nArticle 14 provides protections for rural women and their special problems, ensuring the right of women to participate in development programs, \"to have access to adequate health care facilities,\" \"to participate in all community activities,\" \"to have access to agricultural credit\" and \"to enjoy adequate living conditions.\"\n\nArticle 15 obliges states parties to guarantee \"women equality with men before the law,\" including \"a legal capacity identical to that of men.\" It also accords \"to men and women the same rights with regard to the law relating to the movement of persons and the freedom to choose their residence and domicile.\"\n\nArticle 16 prohibits \"discrimination against women in all matters relating to marriage and family relations.\" In particular, it provides men and women with \"the same right to enter into marriage, the same right freely to choose a spouse,\" \"the same rights and responsibilities during marriage and at its dissolution,\" \"the same rights and responsibilities as parents,\" \"the same rights to decide freely and responsibly on the number and spacing of their children,\" \"the same personal rights as husband and wife, including the right to choose a family name, a profession and an occupation\" \"the same rights for both spouses in respect of the ownership, acquisition, management, administration, enjoyment and disposition of property, whether free of charge or for a valuable consideration.\"\n\nArticles 17 - 24 These articles describe the composition and procedures of the CEDAW Committee,like the hierarchical structure and rules and regulations of systematic procedure of the relationship between CEDAW and national and international legislation and the obligation of States to take all steps necessary to implement CEDAW in full form.\n\nArticles 25 - 30 (Administration of CEDAW)\n\nThese articles describe the general administrative procedures concerning enforcement of CEDAW, ratification and entering reservations of concerned states.\n\nResolutions 1325 10th anniversary events highlight use of CEDAW mechanisms\n\nThe 10th anniversary of Resolution 1325 in October 2010 highlighted the increasing demand for accountability to UN Security Council Resolution 1325 on Women, Peace and Security. Many expressed concern about the fact that only 22 Member States out of 192 have adopted national action plans. Women are still underrepresented, if not totally absent, in most official peace negotiations and sexual violence in peacetime and in conflict continue to increase.\n\nThese realities emphasized the need to use external legal mechanisms to strengthen the implementation of SCR 1325, particularly CEDAW. The well-established mechanisms of CEDAW – the Member States compliance report and the civil society shadow reporting process were cited as possible instruments to ensure accountability.\n\nSeveral regional and international meetings including the High Level Seminar \"1325 in 2020: Looking Forward…Looking Back,\" organized by the African Center for the Constructive Resolution of Disputes, and the \"Stockholm International Conference 10 years with 1325 – What now?\" called for the use of CEDAW to improve 1325 implementation.\n\nIntersection between SCR 1325 and CEDAW\nWhile CEDAW and UN Security Council Resolutions 1325 and 1820 on Women, Peace and Security are important international instruments on their own, there is also an intersection among the three standards that can be used to enhance their implementation and impact.\n\nResolutions 1325 and 1820 broaden the scope of CEDAW application by clarifying its relevance to all parties in conflict, whereas CEDAW provides concrete strategic guidance for actions to be taken on the broad commitments outlined in the two Resolutions.\n\nCEDAW is a global human rights treaty that should be incorporated into national law as the highest standard for women's rights. It requires the UN Member States that have ratified it (185 to date) to set in place mechanisms to fully realize women's rights.\n\nResolution 1325 is an international law unanimously adopted by the Security Council that mandates the UN Member States to engage women in all aspects of peacebuilding including ensuring women's participation on all levels of decision–making on peace and security issues.\n\nResolution 1820 links sexual violence as a tactic of war with the maintenance of international peace and security. It also demands a comprehensive report from the UN Secretary-General on implementation and strategies for improving information flow to the Security Council; and the adoption of concrete protection and prevention measures to end sexual violence.\n\nResolutions 1325 and 1820, and CEDAW share the following agenda on women's human rights and gender equality:\n\n\nA General Comment from the CEDAW committee could strengthen women’s advocacy for the full implementation of Resolutions 1325 and 1820 at the country and community levels. Conversely, CEDAW’s relevance to conflict-affected areas will be underscored further by the two Resolutions. In other words, all three international instruments will reinforce each other and be much more effective if used together in leveraging women’s human rights.\n\nThe six UN member states that have not ratified or acceded to the convention are Iran, Palau, Somalia, Sudan, Tonga, and the United States.\n\nThe one UN non-member state that had not acceded to the convention is the Holy See/Vatican City.\n\nThe Republic of China (Taiwan) in 2007 has also ratified the treaty in its legislature, but is unrecognized by the United Nations and is a party to the treaty only unofficially.\n\nThe latest state to have acceded the convention was South Sudan on 30 April 2015.\n\nWithin the United States, over 40 cities and local governments have adopted CEDAW ordinances or resolutions. \n\nMany reservations have been entered against certain articles of the Convention. There are also some reservations that are not specific to an article within the Convention but rather a general reservation to all aspects of the Convention that would violate a stated principle. For example, Mauritania made a reservation stating it approved the Convention \"in each and every one of its parts which are not contrary to Islamic Sharia.\" A number these reservations, especially those entered by Islamic states parties, are subject to much debate.\n\nArticle 28 of the Convention states that \"a reservation incompatible with the object and purpose of the present Convention shall not be permitted.\" As a result, many states parties have entered objections to the reservations of other states parties. Specifically, many Nordic states parties were concerned that some of the reservations were \"undermining the integrity of the text.\" Over the years, some states parties have withdrawn their reservations.\n\nAs of May 2015, sixty-two states parties have entered reservations against some part of the Convention. Twenty-four states parties have entered objections to at least one of these reservations. The most reserved article is Article 29, concerning dispute resolution and interpretation of the Convention, with thirty-nine reservations. Because reservations to Article 29 are expressly allowed by the Convention itself, these reservations were not very controversial. Article 16, concerning the equality of women in marriage and family life is subject to twenty-three reservations. The Committee, in General Recommendation No. 28, specifically stated that reservations to Article 2, concerning general non-discrimination, are impermissible. However, Article 2 has seventeen reservations.\n\nThe Committee on the Elimination of Discrimination Against Women is the United Nations (U.N.) treaty body that oversees the Convention on the Elimination of All Forms of Discrimination Against Women (CEDAW). The formation of this committee was outlined in Article 17 of the CEDAW, which also established the rules, purpose, and operating procedures of the committee. Throughout its years of operation the committee has held multiple sessions to ensure the rules outlined in the CEDAW are being followed. Over time the practices of the committee have evolved due to an increased focus on women's rights issues.\n\nThe Committee on the Elimination of Discrimination Against Women was formed on 3 September 1981 after the CEDAW received the 20 ratifications required for it to enter into force. Article 17 of the CEDAW established the committee in order to ensure that the provisions of the CEDAW were followed by the countries that had signed and agreed to be bound by it. The first regular session of the committee was held from 18–22 October 1982. In this session the first officers of the committee were elected by simple majority, with Ms. L. Ider of Mongolia becoming chairperson. Other officers elected were three vice-chairpersons: M. Caron of Canada, Z. Ilic of Yugoslavia and L. Mukayiranga of Rwanda. The final officer elected was D. P. Bernard of Guyana as rapporteur of the committee. During this session, the committee also unanimously approved to adopt its rules of procedure.\n\nThe rules regarding where and when the committee can hold sessions are laid out in their rules of procedure.\n\nThe committee is allowed to hold as many meetings as are required to perform their duties effectively, with the states party to the CEDAW and the Secretary-General of the United Nations authorizing the number of regular sessions held. In addition, special sessions can be held at the request of either a state party to the convention or the majority of the members serving on the committee. Fifty-three sessions have been held to date, with the most recent taking place from 1 October 2012 to 19 October 2012. The first thirty-nine sessions were held at the United Nations headquarters building in New York City, with the fortieth session and alternating sessions following it held in the Palais des Nations in Geneva. During each of its regular sessions the committee hears reports from states party to the CEDAW on their progress in adhering to CEDAW and implementing its ideas in their countries. The committee also holds pre-sessional work groups to discuss the issues and questions that the committee should deal with during the following session.\n\nUnder article 18 of the CEDAW states must report to the committee on the progress they have made in implementing the CEDAW within their state. As most of the information the committee works with comes from these reports, guidelines have been developed to help states prepare accurate and useful reports. Initial reports discussing the current picture of discrimination against women in the reporting states are required to specifically deal with each article of the CEDAW, and consist of no more than one-hundred pages. States are required to prepare and present these initial reports within one year of ratifying the CEDAW. Periodic reports detailing the state's progress in adhering to the articles of the CEDAW should be no more than seventy-five pages in length and should focus on the specific period of time since the state's last report. States party to the CEDAW are typically required to provide periodic reports every four years, but if the committee is concerned about the situation in that state they can request a report at any time.\n\nThe committee chooses which reports addressing by considering factors such as the amount of time the report has been pending, whether the report is initial or periodic (with more priority given to initial reports), and from which region the report originates. Eight states are invited to give their reports during each session and it is required a representative from the state is in attendance when the report is presented. The committee focuses on constructive dialogue when a report is presented and appreciates careful time management on the part of the state presenting its report. Due to the high backlog of overdue reports the committee has encouraged states to combine all of their outstanding reports into one document and sends reminders to states who have reports that are five years overdue. The CEDAW also requires that the committee provide an annual report that includes its activities, comments relating to the reports provided by states, information relating to the Optional Protocol of the CEDAW, and any other general suggestions or recommendations the committee has made. This report is given to the United Nations General Assembly through the Economic and Social Council. All reports, agendas and other official documents pertaining to the committee, including the reports provided by the states, are provided to the public unless otherwise decided by the committee.\n\nAlong with issuing its annual report and offering advice to reporting states, the committee has the ability to issue general recommendations that elaborate on its views of the obligations imposed by CEDAW. To date, the committee has issued thirty-two general recommendations, the latest dealing with the gender related dimensions of refugee status, asylum, nationality and statelessness of women. The recommendations issued by the committee in its first decade were short and dealt mainly with the content of states’ reports and reservations to the convention. Since 1991, however, recommendations have been focused on guiding states’ application of the CEDAW in specific situations. The formulation of a general recommendation begins with dialogue between the committee on the topic in the recommendation with various non-governmental organizations and other U.N. bodies. The recommendation is then drafted by a member of the committee and discussed and revised in the next session, and finally adopted in the following session.\n\nCurrently the Committee is working on the General Recommendation Trafficking in women and girls in the context of global migration.\n\nFor the first ten years the committee operated significantly differently from now. The only form of censure given to the committee by the CEDAW was their general recommendations and concluding comments following a report. Due to the emergence of the Global Campaign for Women's Human Rights in 1991 more attention was given to the CEDAW, reviving the committee. The committee made changes to the CEDAW that allowed it to meet more than once a year, and have taken advantage of this by meeting at least twice a year since 1997. The committee originally only met for two weeks in its annual sessions, but that has now been changed to meeting multiple times a year in eighteen-day sessions. CEDAW also gained new complaint and inquiry proceedings allowing the committee to initiate inquiry proceedings if it believes a state is in severe violation of the articles of the CEDAW.\n\nDespite evolving since the committee was first formed, members believe there are ways in which the committee can better meet the goals outlined in the CEDAW. One of the committee's main goals moving forward is expanding its information base, allowing it to more effectively deal with issues that arise concerning the CEDAW. The committee is authorized in Article 22 of the CEDAW to invite specialized U.N. agencies such as the United Nations Development Programme to deliver reports discussing women's rights issues in the state under discussion. Another method for gathering information is requesting reports from non-governmental organizations dealing with discrimination against women that are operating in the country under discussion. This is recommended to insure that the committee is receiving the full, unbiased picture of affairs within the reporting state.\n\nAnother recommendation for improvement involves interpreting and clarifying the language used in the CEDAW in order to make the document as useful as it can be. A third improvement that has been suggested is improving the efficiency of the committee. Due to the backlog in reports faced by the committee it has been suggested that the government officials who prepare reports presented to the committee should be trained, in order to make all reports uniform and more easily processed. A final suggestion for improvement is the implementation of a right of petition in the CEDAW, allowing the committee to hear complaints from citizens of a state against the state, increasing the committee's strength and direct impact on the problem of discrimination against women.\n\nThe official languages of the committee are English, Arabic, French, Russian, and Spanish, with any statement made in one of the official languages translated into the other four. A speaker who does not speak one of the official languages provides a translator. All formal decisions and documents issued by the committee are provided in each of the official languages. The original rules of procedure adopted by the committee did not include Arabic as an official language, but the rule was amended in the committees second session to include Arabic.\n\nTwenty-three members serve on the committee, described as experts for their experience and expertise in women's issues. The members are nominated by their national governments and elected through a secret ballot by states party to the convention. Upon winning the election and taking up their responsibilities the members of the committee recite the following statement, known as the solemn declaration, \"I solemnly declare that I shall perform my duties and exercise powers as a member of the Committee on the Elimination of Discrimination Against Women honourably, faithfully, impartially and conscientiously\". The members come from a wide range of occupations including doctors, lawyers, diplomats and educators, providing various viewpoints to the committee due to their diversity. Many members continue to hold full-time jobs outside the committee and receive little monetary payment for their work on the committee.\n\nTo insure that the nationality of members encompasses all the diverse states who have signed the CEDAW, members are elected according to regions divided into Latin America and the Caribbean, Africa, Asia, Western Europe, and Eastern Europe. The members of the committee differ from those of other treaty bodies of the United Nations in that they have all been women with only one exception. In the event a member of the committee is unable to continue serving on the committee before her term is up the state that had nominated the resigning member shall nominate another expert from their country to fill in her seat. Committee members and experts also attend an annual luncheon, hosted by the NGO Committee on the Status of Women, NY (NGO CSW/NY), where key issues are discusses and the efforts of the committee are honored.\n\nOfficers of the Committee\n\nThe officers of the committee are composed of a chairperson, three vice-chairpersons and a rapporteur. Officers of the committee are nominated by another member of the committee, as opposed to a government which nominates members for the committee. All officers are elected by majority vote to a two-year term of office, and remain eligible for re-election after their term expires. The chairperson's duties include declaring a meeting to be open or closed, directing the discussion in a session, announcing decisions made by the committee, preparing agendas in consultation with the secretary-general, designating the members of pre-sessional working groups and representing the committee at United Nations meetings which the committee is invited to participate in. In the case the chairperson is unable to perform any her duties she designates one of the three vice-chairpersons to take over her role. If the chairperson fails to designate a vice-chairperson prior to her absence then the vice-chairperson with the first name in English alphabetical order takes over. In the event an officer is unable to continue serving on the committee before her term expires a new officer from the same region as the original officer shall be nominated, elected and will take over the vacated office.\nAs of May 2015, the 23 members are:\n\nThe Optional Protocol to the Convention on the Elimination of All Forms of Discrimination against Women is a side-agreement to the Convention which allows its parties to recognise the competence of the Committee on the Elimination of Discrimination Against Women to consider complaints from individuals.\n\nThe Optional Protocol was adopted by the UN General Assembly on 6 October 1999 and entered into force on 22 December 2000. Currently it has 80 signatories and 109 parties.\n\nControversy around CEDAW comes from two opposite directions: social and religious conservatives which claim that CEDAW is seeking to impose a liberal, progressive, feminist standard on countries, in detriment of traditional values; and radical feminists, who are skeptical of the power, or even desire, of CEDAW to radically transform societies and truly liberate women, and claim that CEDAW adheres to a form of weak liberal feminism similar to other mainstream organizations.\n\n\n\n"}
{"id": "2002497", "url": "https://en.wikipedia.org/wiki?curid=2002497", "title": "Critical race theory", "text": "Critical race theory\n\nCritical race theory (CRT) is a theoretical framework in the social sciences that uses critical theory to examine society and culture as they relate to categorizations of race, law, and power. It began as a theoretical movement within American law schools in the mid- to late 1980s as a reworking of critical legal studies on race issues and is loosely unified by two common themes: First, CRT proposes that white supremacy and racial power are maintained over time, and in particular, that the law may play a role in this process. Second, CRT work has investigated the possibility of transforming the relationship between law and racial power, and more broadly, pursues a project of achieving racial emancipation and anti-subordination. Scholars important to the theory include Derrick Bell, Patricia Williams, Kimberlé Williams Crenshaw, and Mari Matsuda. By 2002, over 20 American law schools and at least three law schools in other countries offered critical race theory courses or classes which covered the issue centrally. Critical race theory is taught and innovated in the fields of education, political science, women's studies, ethnic studies, communication, and American studies.\n\nCritics of CRT, including Richard Posner and Alex Kozinski, take issue with its foundations in postmodernism and reliance on moral relativism, social constructionism, and other tenets contrary to classical liberalism.\n\nAccording to the UCLA School of Public Affairs:\nCRT recognizes that racism is engrained in the fabric and system of the American society. The individual racist need not exist to note that institutional racism is pervasive in the dominant culture. This is the analytical lens that CRT uses in examining existing power structures. CRT identifies that these power structures are based on white privilege and white supremacy, which perpetuates the marginalization of people of color.\n\nLegal scholar Roy L. Brooks has defined CRT as \"a collection of critical stances against the existing legal order from a race-based point of view\", and says\n\nit focuses on the various ways in which the received tradition in law adversely affects people of color not as individuals but as a group. Thus, CRT attempts to analyze law and legal traditions through the history, contemporary experiences, and racial sensibilities of racial minorities in this country. The question always lurking in the background of CRT is this: What would the legal landscape look like today if people of color were the decision-makers?\n\nKimberlé Crenshaw, Neil T. Gotanda, Gary Peller, and Kendall Thomas argue that two events were vital to the emergence of CRT: the 1981 Alternative Course on race at Harvard Law School, taught with Derrick Bell, and the 1987 Critical Legal Studies Conference on silence and race.\n\nCritical race theory draws on the priorities and perspectives of both critical legal studies and conventional civil rights scholarship, while sharply contesting both of these fields. Angela P. Harris describes CRT as sharing \"a commitment to a vision of liberation from racism through right reason\" with the civil rights tradition. It deconstructs some premises and arguments of legal theory and simultaneously holds that legally constructed rights are incredibly important. In Angela P. Harris' view, as described by Derrick Bell, critical race theory is committed to \"radical critique of the law (which is normatively deconstructionist) and ... radical emancipation by the law (which is normatively reconstructionist).\"\n\nCRT's theoretical elements are provided by a variety of sources.\n\nRichard Delgado and Jean Stefancic have documented the following major themes as characteristic of work in critical race theory:\n\nCheryl I. Harris and Gloria Ladson-Billings add the theoretical element of whiteness as property. They describe whiteness as the ultimate property which whites alone can possess. It is valuable and is property. The 'property functions of whiteness'—rights to disposition, rights to use and enjoyment, reputation and status property, and the absolute right to exclude—make the American dream a more likely and attainable reality for whites as citizens. For a CRT critic, the white skin color that some Americans possess is like owning a piece of property. It grants privileges to the owner that a renter (or a person of color) would not be afforded.\n\nKaren Pyke documents the theoretical element of internalized racism or internalized racial oppression. The victims of racism begin to believe the ideology that they are inferior and white people and white culture are superior. The internalizing of racism is not due to any weakness, ignorance, inferiority, psychological defect, gullibility, or other shortcomings of the oppressed. Instead, it is how authority and power in all aspects of society contributes to feelings of inequality.\n\nCamara Phyllis Jones defines institutionalized racism as the structures, policies, practices, and norms resulting in differential access to the goods, services, and opportunities of society by race. Institutionalized racism is normative, sometimes legalized and often manifests as inherited disadvantage. It is structural, having been absorbed into our institutions of custom, practice and law, so there need not be an identifiable offender. Indeed, institutionalized racism is often evident as inaction in the face of need. Institutionalized racism manifests itself both in material conditions and in access to power. With regard to material conditions, examples include differential access to quality education, sound housing, gainful employment, appropriate medical facilities and a clean environment.\n\nAs a movement that draws heavily from critical theory, critical race theory shares many intellectual commitments with critical legal studies, critical theory, feminist jurisprudence and postcolonial theory. Though some authors like Tommy J. Curry have pointed out that such epistemic convergences with critical legal studies, critical theory, etc. are emphasized because of the idealist turn in critical race theory which is interested in discourse (how we speak about race) and the theories of white Continental philosophers, over and against the structural and institutional accounts of white supremacy which were at the heart of the realist analysis of racism introduced in Derrick Bell's early works articulated through Black thinkers like W. E. B. Du Bois, Paul Robeson, and Judge Robert L. Carter.\nWill Oremus wrote in \"Slate\"that CRT was radical \"in the sense that it questions fundamental assumptions... And unlike some strands of academic and legal thought, critical race theory has an open and activist agenda, with an emphasis on storytelling and personal experience. It's about righting wrongs, not just questing after knowledge\" and that CRT is not \"radical today in the sense of being outside the mainstream: Critical race theory is widely taught and studied.\"\n\nRecent developments in critical race theory include work relying on updated social psychology research on unconscious bias to justify affirmative action and work relying on law and economics methodology to examine structural inequality and discrimination in the workplace.\n\nThe framework of Latino critical race theory (LatCRT) suggests that the social construction of race is central to how people of color are constrained in society. Tara J. Yosso discusses constraint of people of color can be defined in \"Critical Race Counterstories along the Chicana/Chicano Educational Pipeline\". These tenets are what make LatCrt different because it looks at the differences between Chicano/a students. These tenets are: The \"inter\"centricity of race and racism; the challenge of dominant Ideology; the commitment to social justice; the centrality of experience knowledge; and the interdisciplinary perspective.\n\nRace scholars developed the LatCRT as a critical response to the \"problem of the color line\" first explained by W. E. B. Du Bois. CRT focused on the Black–White paradigm, but LatCRT has moved to consider other racial groups, mainly Chicana/Chicanos. These groups include Latinos/as, Asians, LGBTQ, Native Americans/First Nations, and women of color.\n\nLatCRTs main focus is to advocate for social justice for people who live in marginalized communities, specifically Chicana/Chicano individuals. These marginalized communities are guided by structural arrangements that disadvantage people of color. Social institutions function as dispossessions, disenfranchisement, and discrimination over minority groups, but the LatCRT seeks to give voice to those who are victimized. In order to give voice to those that are disenfranchised, LatCRT has created two common themes.\n\nFirst, CRT proposes that white supremacy and racial power are maintained over time and that the law plays a central role in this process. Different racial groups lack the voice to speak in this civil society. For this reason, the CRT has introduced a new critical form of expressions, called the \"voice of color\". The \"voice of color\" is narratives and storytelling monologues used as devices for conveying personal racial experiences. The \"voices of color\" are also used to counter metanarratives that continue to maintain racial inequality. Thus, the experiences of the oppressed are important aspects for developing a LatCRT analytical approach. Not since the rise of slavery have we seen an institution that so fundamentally shapes the life opportunities of those who bear the label of criminal.\n\nSecond, LatCRT work has investigated the possibility of transforming the relationship between law enforcement and racial power, and more broadly, pursues a project of achieving racial emancipation and anti-subordination. The CRT finds the experiential knowledge of people of color and draws explicitly from these lived experiences as data. The CRT presents research findings through storytelling, chronicles, scenarios, narratives, and parables.\n\nScholars in critical race theory have focused with some particularity on the issues of hate crime and hate speech. In response to the US Supreme Court's opinion in the hate speech case of \"R. A. V. v. City of St. Paul\" (1992), in which the Court struck down an anti-bias ordinance as applied to a teenager who had burned a cross, Mari Matsuda and Charles Lawrence argued that the Court had paid insufficient attention to the history of racist speech and the actual injury produced by such speech.\n\nCritical race theorists have also paid particular attention to the issue of affirmative action. Many scholars have argued in favor of affirmative action on the argument that so-called merit standards for hiring and educational admissions are not race-neutral for a variety of reasons, and that such standards are part of the rhetoric of neutrality through which whites justify their disproportionate share of resources and social benefits.\n\nSome legal scholars have criticized CRT on a number of grounds, such as CRT scholars' reliance on narrative and storytelling, or CRT's critique of objectivity. Judge Richard Posner of the United States Seventh Circuit Court of Appeals has \"label[ed] critical race theorists and postmodernists the 'lunatic core' of 'radical legal egalitarianism.'\" He writes,\nWhat is most arresting about critical race theory is that...it turns its back on the Western tradition of rational inquiry, forswearing analysis for narrative. Rather than marshal logical arguments and empirical data, critical race theorists tell stories — fictional, science-fictional, quasi-fictional, autobiographical, anecdotal—designed to expose the pervasive and debilitating racism of America today. By repudiating reasoned argumentation, the storytellers reinforce stereotypes about the intellectual capacities of nonwhites.\n\nJudge Alex Kozinski of the Ninth Circuit Court of Appeals writes that critical race theorists have constructed a philosophy which makes a valid exchange of ideas between the various disciplines unattainable.\nThe radical multiculturalists' views raise insuperable barriers to mutual understanding. Consider the \"Space Traders\" story. How does one have a meaningful dialogue with Derrick Bell? Because his thesis is utterly untestable, one quickly reaches a dead end after either accepting or rejecting his assertion that white Americans would cheerfully sell all blacks to the aliens. The story is also a poke in the eye of American Jews, particularly those who risked life and limb by actively participating in the civil rights protests of the 1960s. Bell clearly implies that this was done out of tawdry self-interest. Perhaps most galling is Bell's insensitivity in making the symbol of Jewish hypocrisy the little girl who perished in the Holocaust—as close to a saint as Jews have. A Jewish professor who invoked the name of Rosa Parks so derisively would be bitterly condemned—and rightly so.\n\nDaniel Farber and Suzanna Sherry have argued that critical race theory, along with critical feminism and critical legal studies, has antisemitic and anti-Asian implications, has worked to undermine notions of democratic community and has impeded dialogue.\n\nHenry Louis Gates Jr. has written a critical evaluation of CRT. Gates emphasizes how campus speech codes and anti-hate speech laws have been applied to anti-white speech, contrary to the intentions of CRT theorists: \"During the year in which Michigan's speech code was enforced, more than twenty blacks were charged—by whites—with racist speech. As Trossen notes, not a single instance of white racist speech was punished.\"\n\nJeffrey J. Pyle wrote in the \"Boston College Law Review\":Critical race theorists attack the very foundations of the [classical] liberal legal order, including equality theory, legal reasoning, Enlightenment rationalism and neutral principles of constitutional law. These liberal values, they allege, have no enduring basis in principle, but are mere social constructs calculated to legitimate white supremacy. The rule of law, according to critical race theorists, is a false promise of principled government, and they have lost patience with false promises.\n\nPeter Wood considers CRT a \"grievance ideology\" and an \"absurdity\". He sees the central tenet of \"white racism in the American legal system\" to be shown false because of items such as the 14th Amendment, the Voting Rights Acts and \"Brown v. Board of Education\".\n\nWithin critical race theory, various sub-groupings have emerged to focus on issues that fall outside the black-white paradigm of race relations as well as issues that relate to the intersection of race with issues of gender, sexuality, class and other social structures. See for example, critical race feminism (CRF), Latino critical race studies (LatCrit) Asian American critical race studies (AsianCrit), South Asian American critical race studies (DesiCrit), and American Indian critical race studies (sometimes called TribalCrit). CRT methodology and analytical framework have also been applied to the study of white immigrant groups.\n\nCritical race theory has also begun to spawn research that looks at understandings of race outside the United States.\n\nCritical race theory has stirred controversy since the 1980s over such issues as its deviation from the ideal of color blindness, promotion of the use of narrative in legal studies, advocacy of \"legal instrumentalism\" as opposed to ideal-driven uses of the law, analysis of the Constitution and existing law as constructed according to and perpetuating racial power, and encouraging legal scholars to be partial on the side of ending racial subordination.\n\nConservative opponents of political appointees including Lani Guinier have included a general critique of critical race theory in their criticism of these figures' actions on racial issues.\n\nCritics including George Will saw resonances between critical race theory's use of storytelling and insistence that race poses challenges to objective judgments in the US and the acquittal of O. J. Simpson.\n\nIn 2012, Matt de la Peña's young adult novel \"Mexican WhiteBoy\", about a boy who wants to grow up to become a baseball player, was banned from being taught in class and the Mexican-American studies program in Tucson, Arizona, was disbanded in part because of their connection to CRT, which was seen to be in violation of a recently passed state law that \"prohibits schools from offering courses that 'advocate ethnic solidarity instead of the treatment of pupils as individuals'.\"\n"}
{"id": "18779407", "url": "https://en.wikipedia.org/wiki?curid=18779407", "title": "Crystal Waters, Queensland", "text": "Crystal Waters, Queensland\n\nCrystal Waters (also known as Crystal Waters Permaculture Village and Crystal Waters Ecovillage) is an 85 Lot Body Corporate housing development situated in Conondale in the Sunshine Coast hinterland of Queensland, Australia.\n\nIn 1996, the village of Crystal Waters was a finalist in the World Habitat Awards by the Building and Social Housing Foundation for its \"pioneering work in demonstrating new ways of low impact, sustainable living\". In 1998, the village of Crystal Waters was included in the \"World's Best Practices\" database of the United Nations organization.\n"}
{"id": "5031680", "url": "https://en.wikipedia.org/wiki?curid=5031680", "title": "Dating violence", "text": "Dating violence\n\nDating abuse or dating violence is defined as the perpetration or threat of an act of violence by at least one member of an unmarried couple on the other member within the context of dating or courtship. It is also when one partner tries to maintain power and control over the other through abuse/violence. This abuse/violence can take a number of forms: sexual assault, sexual harassment, threats, physical violence, verbal, mental, or emotional abuse, social sabotage, and stalking. It can include psychological abuse, emotional blackmail, sexual abuse, physical abuse and psychological manipulation.\n\nDating violence crosses all racial, age, economic and social lines. The Center for Relationship Abuse Awareness describes dating abuse as a \"pattern of abusive and coercive behaviors used to maintain power and control over a former or current intimate partner.\" The Family & Community Development support group at eCitizen in Singapore has described what it calls tell-tale signs of an abusive relationship.\n\nIndividuals of all walks of life can find themselves in an abusive relationship. Abuse can occur regardless of the couple's age, race, income, or other demographic traits. There are, however, many traits that abusers and victims share in common. \n\nThe Centre for Promoting Alternatives to Violence describes abusers as being obsessively jealous and possessive, overly confident, having mood swings or a history of violence or temper, seeking to isolate their partner from family, friends and colleagues, and having a tendency to blame external stressors.\n\nMeanwhile, victims of relationship abuse share many traits as well, including: physical signs of injury, missing time at work or school, slipping performance at work or school, changes in mood or personality, increased use of drugs or alcohol, and increasing isolation from friends and family. Victims may blame themselves for any abuse that occurs or may minimize the severity of the crime. This often leads to victims choosing to stay in abusive relationships.\n\nStrauss (2005) argues that while men inflict the greater share of injuries in domestic violence, researchers and society at large must not overlook the substantial minority of injuries inflicted by women. Additionally, Strauss notes that even relatively minor acts of physical aggression by women are a serious concern:\n\nSimilarly, Deborah Capaldi reports that a 13-year longitudinal study found that a woman's aggression towards a man was equally important as the man's tendency towards violence in predicting the likelihood of overall violence: \"Since much IPV [Intimate Partner Violence] is mutual and women as well as men initiate IPV, prevention and treatment approaches should attempt to reduce women's violence as well as men's violence. Such an approach has a much higher chance of increasing women's safety.\" However, Capaldi's research only focused on at-risk youth, not women in general, and, therefore, may not apply to the entire population.\n\n\n\n\n\n\n\n\n"}
{"id": "10129659", "url": "https://en.wikipedia.org/wiki?curid=10129659", "title": "Ducci sequence", "text": "Ducci sequence\n\nA Ducci sequence is a sequence of \"n\"-tuples of integers, sometimes known as \"the Diffy game\", because it is based on sequences.\n\nGiven an \"n\"-tuple of integers formula_1, the next \"n\"-tuple in the sequence is formed by taking the absolute differences of neighbouring integers:\n\nAnother way of describing this is as follows. Arrange \"n\" integers in a circle and make a new circle by taking the difference between neighbours, ignoring any minus signs; then repeat the operation. Ducci sequences are named after Enrico Ducci (1864 - 1940), the Italian mathematician who discovered this in the 1930s.\n\nDucci sequences are also known as the Ducci map or the n-number game. Open problems in the study of these maps still remain.\n\nFrom the second \"n\"-tuple onwards, it is clear that every integer in each \"n\"-tuple in a Ducci sequence is greater than or equal to 0 and is less than or equal to the difference between the maximum and minimum members of the first \"n\"-tuple. As there are only a finite number of possible \"n\"-tuples with these constraints, the sequence of n-tuples must sooner or later repeat itself. Every Ducci sequence therefore eventually becomes periodic.\n\nIf \"n\" is a power of 2 every Ducci sequence eventually reaches the \"n\"-tuple (0,0...,0) in a finite number of steps.\n\nIf \"n\" is \"not\" a power of two, a Ducci sequence will either eventually reach an \"n\"-tuple of zeros or will settle into a periodic loop of 'binary' \"n\"-tuples; that is, \"n\"-tuples of form formula_3, formula_4 is a constant, and formula_5.\n\nAn obvious generalisation of Ducci sequences is to allow the members of the \"n\"-tuples to be any real numbers rather than just integers. The properties presented here do not always hold for these generalisations. For example, a Ducci sequence starting with the \"n\"-tuple (1, \"q\", \"q\", \"q\") where \"q\" is the (irrational) positive root of the cubic formula_6 does not reach (0,0,0,0) in a finite number of steps, although in the limit it converges to (0,0,0,0).\n\nDucci sequences may be arbitrarily long before they reach a tuple of zeros or a periodic loop. The 4-tuple sequence starting with (0, 653, 1854, 4063) takes 24 iterations to reach the zeros tuple.\n\nformula_7\nformula_8\n\nThis 5-tuple sequence enters a period 15 binary 'loop' after 7 iterations.\n\nformula_9\n\nThe following 6-tuple sequence shows that sequences of tuples whose length is not a power of two may still reach a tuple of zeros:\n\nformula_10\n\nIf some conditions are imposed on any \"power of two\"-tuple Ducci sequence, it would take that power of two or lesser iterations to reach the zeros tuple. It is hypothesized that these sequences conform to a rule.\n\nWhen the Ducci sequences enter binary loops, it is possible to treat the sequence in modulo two. That is:\nThis forms the basis for proving when the sequence vanish to all zeros.\n\nThe linear map in modulo 2 can further be identified as the cellular automata denoted as rule 102 in Wolfram code and related to rule 90 through the Martin-Odlyzko-Wolfram map. Rule 102 reproduces the Sierpinski triangle.\n\nThe Ducci map is an example of a difference equation, a category that also include non-linear dynamics, chaos theory and numerical analysis. Similarities to cyclotomic polynomials have also been pointed out. While there are no practical applications of the Ducci map at present, its connection to the highly applied field of difference equations led to conjecture that a form of the Ducci map may also find application in the future.\n\n"}
{"id": "24155699", "url": "https://en.wikipedia.org/wiki?curid=24155699", "title": "Duplicate bridge movements", "text": "Duplicate bridge movements\n\nA duplicate bridge movement is a scheme used in a duplicate bridge tournament to arrange which competitors play which opponents when, and which boards they play. The arrangement has to satisfy a number of constraints which often conflict to some extent, and compromises may be required. The resolution of these compromises is to a considerable extent a matter of taste, and if possible the players should be consulted as to their preferences.\n\nMovements are categorized by the type of event—Individual, Pairs, or Teams.\n\nThe requirements for the movement are as follows:\n\n\nIt is important that once the movement is selected, it should be completed: uncompleted movements are likely to be unbalanced. Thus a movement should be selected which has a high probability of being completed.\n\nIn two-winner movements, the NS pairs play the EW pairs, but never other NS pairs. There are thus two \"fields\" competing separately. If the average standard of the NS and EW pairs is different, this can give an unfair result.\n\nIn one-winner movements at certain points NS pairs play as EW and EW pairs play as NS, e.g. through an arrow switch (reversing the polarity of tables during some rounds). This creates a one-winner movement.\n\nThe number of rounds which are arrow switched affects the fairness of the result. Normally between one-eighth and one-quarter of the rounds are arrow switched. The English Bridge Union (EBU) recommends one eighth. So in a 7 or 8 round movement, you would arrow switch the last round.\n\nThere are two basic types of pair movements—Mitchell and Howell. Mitchell movements can be two-winner or one-winner. Howell and variants of Mitchell are one-winner.\n\nIn a standard Mitchell movement (also known as \"straight Mitchell\"), there are two separate groups of players—one group always sits North-South, and the other always sits East-West. North-South players remain at the same table throughout all rounds of play. After each round, boards move to the next lower numbered table (from table 1, boards go to the highest numbered table), and East-West pairs move to the next higher number table (at the highest numbered table, pairs move to table 1). Pairs are typically identified by the direction they are sitting, coupled with the table number they start at.\n\nThis arrangement can be followed without modification when there is an odd number of tables, with no additional pairs left over (no half-tables). Modifications to the straight Mitchell movement must be made whenever there is an even number of tables, or a half-table.\n\nA straight Mitchell movement requires that the number of rounds played R is equal to or less than the number of tables T. Hence, if there are 8 tables and time to play 24 boards, a maximum of 8 rounds can be played and there will be 3 boards per round.\n\nIf it is desired to play one or two rounds more than the number of tables, a Hesitation Mitchell or Double Hesitation Mitchell movement may be used if feasible. Alternatively, a Howell type movement may be adopted.\n\nIn a straight Mitchell with an even number of tables, after half of the rounds have been completed the East-West pairs will arrive at a table with boards that they have already played. To avoid this problem, there are two basic options -- \"Skip Mitchell\" and \"Bye-Stand Mitchell\" (the latter is called a \"Share and Relay Mitchell\" in the UK).\n\nIn a Skip Mitchell, after the number of rounds played equals the number of tables divided by 2, in moving for the next round the East-West pairs must \"skip\" a table. The director must take care to announce the special movement when that round arrives, and North-South pairs should confirm that their new-arriving opponents did skip a table. This choice is far simpler for the director to manage and is simpler to adjust if a late pair must be accommodated, but has the slight drawback that each East-West pair misses the chance to play one set of boards. The Skip Mitchell requires that the number of tables is at least one greater than the number of rounds played, e.g. with 10 tables up to 9 rounds can be played, but with 8 tables the maximum is 7, otherwise EW pairs would encounter NS pairs more than once.\n\nIn a bye-stand Mitchell, there are two modifications needed to the basic table setup. First, table 1 must be set up near the highest numbered table, because throughout the game, those two tables will share boards—after playing a board at one table it must be passed to the other to play. Second, a \"bye stand\" or \"relay table\" must be set up halfway between the first and last tables—for example, in an eight-table movement, the bye stand must be set up between tables 4 and 5. When moving boards after each round, boards at the table just above the bye stand go to the bye stand; the boards on the bye stand go to the table just below the bye stand. In the eight-table example, boards go from table 5 to the bye stand, and from the bye stand to table 4. This movement allows all pairs to play all boards, but the drawbacks are that the sharing of boards between two tables tends to slow down the movement, mistakes can be made with both the bye stand placement and the movement of boards to the bye stand, and late pairs are harder to accommodate.\n\nAdjustments to the straight Mitchell for half tables depend on whether the number of full tables is odd or even.\n\nIn this case the adjustment is a \"sit out\". This involves setting up the movement as if there were an odd number of tables and then running a straight Mitchell. In an 8-1/2 table game, set up 9 tables with boards and assign North-South players to tables 1-8; East-West pairs are assigned to tables 1-9. The movement proceeds exactly as in a straight Mitchell, when East-West pairs arrive at table 9 they simply do not play that round.\n\nIn this case the adjustment can be either \n\nThe sit out with Skip Mitchell has the disadvantage that one East-West pair will skip the sit out table. This is not a problem if the number of tables is greater than the number of rounds.\n\nFor a Bye Stand Mitchell, the East-West pair arriving at the highest numbered table (which normally shares boards with table 1) sits out. If desired and permitted, they may kibitz the deals at table 1 while they are sitting out. This is the best movement if the number of tables and rounds are equal, because it eliminates the share usually required.\n\nFor a North-South Bump, all but one pair are assigned to tables as in a straight Mitchell. The remaining pair is a \"Rover\", that moves according to a schedule that differs depending on the number of full tables. The Rover pair does not play the first round, at each subsequent round they move to a table according to their schedule and replace the North-South pair at that table for that round—the North-South pair at that table have been \"bumped\" and sit out that round. If desired and permitted, the bumped pair can kibitz the table they have been bumped from. Also, because the Rover pair does not play the first round, it can be a very good choice for handling a late-arriving pair.\n\nIn a Hesitation Mitchell, the EW pair arriving at the highest numbered table rotate to sit NS at that table on the next round, and then move to Table 1. With an odd number of tables, this allows one more round to be played than the number of tables. For example, with 24 boards and seven tables, eight rounds can be played. A bye stand table will also be needed opposite the hesitation table; in this case between tables 3 and 4.\n\nIn a Double Hesitation Mitchell, there are two points where EW move to NS, though not normally at directly rotating tables. With an even number of tables, this allows two more rounds to be played than the number of tables. For example, with 24 boards and 6 tables, eight rounds can be played. Two bye stand tables will also be needed. The position of the rotations and bye stand tables must be chosen precisely, otherwise a conflict will arise, so table cards are needed.\n\nIn a Howell movement, pairs move according to a schedule that varies depending on the number of tables. Pairs are identified by a pair number that identifies the position they sit for the first round. Traditionally, the highest numbered pair sits North-South at table 1 and does not move from that position; the other pairs move from table to table, sometimes sitting North-South and sometimes East-West. In moving according to the schedule, each pair will arrive at table 1 and sit East-West in the round corresponding to their pair number. Directions are placed on each table telling each player what table and position they move to for the next round.\n\nThe Howell movement is better suited for smaller numbers of tables—as the number of tables grows, the number of rounds that must be played to have every pair play at every position becomes too large. For T tables, there will be (2T-1) rounds, e.g. 7 rounds for 4 tables, but 13 rounds for 7 tables. For larger games where a Howell-type movement is desired, \"3/4 Howell\" or \"Part Howell\" movements exist that provide balanced comparisons, accomplished in part by having in addition to the stationary pair at table one, pairs that remain at some higher numbered tables, but who may sit North-South in some rounds and East-West in others.\n\nSome suggestions for movements of from 3 up to 7 tables are as follows:\n\n\n\n\n\nStarting positions: Table 1: 9v1; Table 2: 5v6; Table 3: 2v8; Table 4: 4v7.\n\nPair 3 sits out on first round. Pair 9 is stationary.\nTwo relays between tables 3 and 4. Phantom table 5, plus one relay between tables 5 and 1.\n\n\n\n\n\nStarting positions: Table 1: 5v4; Table 2: 7v11; Table 3: 2v9; Table 4: sit-out table (with relay; pair 12 starts here);Table 5:3v6: Table 6: 13 (stationary) v 1; Table 7: 10 v 8\n\nOne relay between tables 6 and 7.\n\n\n\nWeb movements are a modern improvement over the standard Mitchell in some circumstances. The main advantage of Web movements is they can allow large single sections with a fixed number of boards. Each pair plays the same set of boards, which increases the overall fairness of the competition. Web movements can require additional sets of boards, which is facilitated by automatic dealing machines (now common in larger clubs).\n\nThere are two basic types of Individual movements—Shomate and Rainbow. Shomate movements are similar in concept to Howell movements for pairs—for smaller numbers of tables, a single individual is stationary and all other players move from place to place, sitting at different tables/positions each round. Rainbow movements are similar in concept to Mitchell movements. A key difference for Rainbow movements is that they require the number of tables to be a prime number, and there must be at least 5 tables. In a Rainbow movement, North players remain stationary throughout the game. All other players move after each round. Typically, boards move to the next lower table; South players move to the next higher table; East players move to the 2nd next higher tables (for example, moving from table 1 to table 3); and West players move to the 2nd lower table (for example, moving from table 3 to 1). It is common for the player moving two tables lower to carry boards to the next lower table on the way to their next seat. In a rainbow movement, if it is desired to increase the number of players a person has played with and against, this can be accomplished by having players at each table change positions at the same table within a round. For example, if the movement calls for two boards per round, after playing one board, the South and West players at each table could exchange seats for the 2nd board. If this is done, the players must remember to move back to their original position when moving at the end of the round. In a movement with 3 boards per round, East, South, and West can move clockwise after each board (skipping the North seat).\n\nTeams movements are different from pairs movements as they have an extra requirement; not only do teams need to play all or most of the other teams and not play the same boards twice, each pair also has to play the same boards as their other pair against the same team, but in different rounds (this requirement can be avoided by using multiple copies of computer dealt boards).\n\nThe most common team movement, known as the American Whist League (AWL) movement, is again similar to the Mitchell movement, and requires an odd number of teams. Each team starts sitting together at its home table. For the first round, each team prepares the boards on its home table, and then its E-W pair moves down two tables and carries the boards with them, dropping them off at the first lower numbered table (for example, team 3's E-W pair would carry boards from table 3 to table 2, and then go sit at table 1). This movement of boards one lower, E-W two lower, continues every round; when the E-W pairs arrive back at their home tables the movement is complete.\n\nFor an even number of tables, things become more difficult. A simple solution is to use an American Whist movement with an even number of rounds but with one or more teams not playing each other, which is not ideal. One or two of the moves between rounds will be different, to avoid board/team conflicts. There are alternative movements which are better balanced but more complex, see EBU Movements Manual.\n\nBecause the AWL movement is a round-robin movement (each team plays a match against all other teams), when the number of teams is large the number of boards per match must be small. When this is not desirable, some other form of arranging competitors to play must be used. The most common are Knockouts and Swiss. In both of these, teams play head-to-head matches of a convenient number of boards in each round. In Knockouts, match winners advance to the next round; the losers are eliminated from the event. In Swiss, after each round, the tournament director examines the record of each team and assigns pairs of teams with similar records, but that have not played against each other, to oppose each other in the next round. In either form, if there is an odd number of teams, one or more round-robins involving 3 teams must be used. In knockouts, if a round robin is used, the number of boards in each match must be half the number used in the head-to-head matches (a \"half-match\"), to allow all competitors to finish a round in approximately the same amount of time. In Swiss, it is possible to use either the half-match technique (in which case the subsequent pairings need to give less weight to the half-match results), or, to have the teams involved play the full number of boards, in which case the results will not be known until the other competitors have completed two matches. This means that the number of rounds must be even. Also, because the teams involved will not have results to compare for future pairings for two rounds, in the later rounds it is desirable to avoid assigning the leading teams to the round robin.\n\n\n"}
{"id": "996739", "url": "https://en.wikipedia.org/wiki?curid=996739", "title": "Frances Power Cobbe", "text": "Frances Power Cobbe\n\nFrances Power Cobbe (4 December 1822 – 5 April 1904) was an Irish writer, social reformer, anti-vivisection activist, and leading women's suffrage campaigner. She founded a number of animal advocacy groups, including the National Anti-Vivisection Society (NAVS) in 1875, and the British Union for the Abolition of Vivisection (BUAV) in 1898, and was a member of the executive council of the London National Society for Women's Suffrage.\n\nShe was the author of a number of books and essays, including \"The Intuitive Theory of Morals\" (1855), \"On the Pursuits of Women\" (1863), \"Cities of the Past\" (1864), \"Criminals, Idiots, Women and Minors\" (1869), \"Darwinism in Morals\" (1871), and \"Scientific Spirit of the Age\" (1888).\n\nFrances was a member of the prominent Cobbe family, descended from Archbishop Charles Cobbe, Primate of Ireland. She was born in Newbridge House in the family estate in what is now Donabate, Co. Dublin.\n\nCobbe worked at the Red Lodge Reformatory and lived with the owner, Mary Carpenter, from 1858 to 1859, but a turbulent relationship between the two meant that Cobbe left the school and moved out.\n\nCobbe formed a relationship with the Welsh sculptor Mary Lloyd (1819-1896), whom she met in Rome in 1861 and lived with from 1864 until Lloyd's death. That death, in 1896, affected Cobbe badly. Her friend, the writer Blanche Atkinson, writing, “The sorrow of Miss Lloyd’s death changed the whole aspect of existence for Miss Cobbe. The joy of life had gone. It had been such a friendship as is rarely seen – perfect in love, sympathy, and mutual understand.” Around 1891 and in danger of losing their home at Hengwrt, in which Lloyd had inherited a share on the death of her parents, the couple were relieved by a legacy of over £25,000 from the widow of Richard Vaughan Yates. They are buried together at Saint Illtud Church Cemetery, Llanelltyd, Gwynedd, Wales. In letters and published writing, Cobbe referred to Lloyd alternately as \"husband,\" wife,\" and \"dear friend.\"\n\nCobbe founded the Society for the Protection of Animals Liable to Vivisection (SPALV) in 1875, the world's first organisation campaigning against animal experiments, and in 1898 the BUAV, two groups that remain active. She was a member of the executive council of the London National Society for Women's Suffrage and writer of editorial columns for London newspapers on suffrage, property rights for women, and opposition to vivisection. Around 1880, with Louise Twining, she founded Homes for Workhouse Girls.\nCobbe met the Darwin family during 1868. Emma Darwin liked her, \"Miss Cobbe was very agreeable.\" Frances persuaded Charles Darwin to read Immanuel Kant's \"Metaphysics of Ethics\". She met him again during 1869 in Wales, and apparently interrupted him when he was quite ill, and tried to persuade him to read John Stuart Mill—and indeed Darwin had read Frances's review of Mill's book, \"The Subjection of Women\". She then lost his trust when without permission she edited and published a letter he'd written to her. Her critique of Darwin's \"Descent of Man\", \"Darwinism in Morals\" was published in \"The Theological Review\" in April 1871.\n\nCobbe's activism for women's rights included advocating for women to be allowed to take university examinations and therefore earn a degree at Oxford and Cambridge. She presented a paper at the Social Science Congress in 1862 to argue the issue \n\nA portrait of her is included in the mural of heroic women by Walter P. Starmer unveiled in 1921 in the church of St Jude-on-the-Hill in Hampstead Garden Suburb, London.\n\nHer name and picture (and those of 58 other women's suffrage supporters) are on the plinth of the statue of Millicent Fawcett in Parliament Square, London, unveiled in 2018.\n\nHer name is listed on the south face of the Reformers Memorial in Kensal Green Cemetery in London.\n\n\n\n"}
{"id": "396575", "url": "https://en.wikipedia.org/wiki?curid=396575", "title": "Fσ set", "text": "Fσ set\n\nIn mathematics, an F set (said F-sigma set) is a countable union of closed sets. The notation originated in France with F for \"fermé\" (\"French\": closed) and σ for \"somme\" (\"French\": sum, union).\n\nIn metrizable spaces, every open set is an F set. The complement of an F set is a G set. In a metrizable space, any closed set is a G set.\n\nThe union of countably many F sets is an F set, and the intersection of finitely many F sets is an F set. F is the same as formula_1 in the Borel hierarchy.\n\nEach closed set is an F set.\n\nThe set formula_2 of rationals is an F set. The set formula_3 of irrationals is not a F set.\n\nIn a Tychonoff space, each countable set is an F set, because a point formula_4 is closed.\n\nFor example, the set formula_5 of all points formula_6 in the Cartesian plane such that formula_7 is rational is an F set because it can be expressed as the union of all the lines passing through the origin with rational slope:\n\nwhere formula_2, is the set of rational numbers, which is a countable set.\n\n"}
{"id": "10385519", "url": "https://en.wikipedia.org/wiki?curid=10385519", "title": "Galactocentrism", "text": "Galactocentrism\n\nIn astronomy, Galactocentrism is the theory that the Milky Way Galaxy, home of Earths Solar System, is at or near the center of the Universe. \n\nObservations by William Herschel in 1785 suggested that the Milky Way was a disk-shaped galaxy with the sun in a central position. Although heliocentric, Herschel's observations were the first attempt at an observational cosmology. \n\nHerschel's heliocentric theory was overthrown by astronomer Harlow Shapley's work on globular clusters in 1918. Shapley's research marked the transition from heliocentrism to galactocentrism, placing the Galactic Center of the Milky Way Galaxy far away from the sun, towards Sagittarius. Heber Doust Curtis and Edwin Hubble further refuted the heliocentric view of the universe by showing that spirals are themselves far-flung galactic systems. By 1925, the galactocentric model was established.\n\nThe theory of Galactocentrism was an important step in the development of cosmological models as speculation on the existence of other galaxies, comparable in size and structure to our own, placed the earth in its proper perspective with respect to the rest of the universe. Shifts from heliocentrism to galactocentrism and later acentrism have been compared in significance to the Copernican Revolution.\n\nWork by Thomas Wright and Kant indicated that fuzzy patches of light called nebulae were actually distant \"island universes\" consisting of many stellar systems. The shape of our own galaxy was expected to resemble that of the nebulae. \nIn 1783, amateur astronomer William Herschel attempted to determine the shape of the galaxy by examining stars through his handmade telescopes. Herschel was the first to propose a model of the galaxy based on observation and measurement. He concluded that it was in the shape of a disk, but incorrectly assumed that the sun was in the center of the disk.\n\nSeeing that the stars belonging to the Milky Way galaxy appeared to encircle the Earth, Herschel carefully counted stars of given apparent magnitudes, and after finding the numbers were the same in all directions, concluded Earth must be close to the center of the galaxy. However, there were two flaws in Herschel's methodology: magnitude is not a reliable index to the distance of stars, and some of the areas that he mistook for empty space were actually dark, obscuring nebulae that blocked his view toward the center of the Milky Way.\n\nThe Herschel model remained relatively unchallenged for the next hundred years, with minor refinements. Jacobus Kapteyn introduced motion, density, and luminosity to Herschel's star counts, which still implied a near-central location of the Sun.\n\nIn 1918, as Kapteyn was refining his model, Herschel's heliocentric theory was overthrown by astronomer Harlow Shapley's work on globular clusters. \nShapley's observational cosmology marked a transition from Heliocentrism to Galactocentrism.\n\nShapley had been studying the asymmetrical distribution of globular clusters, estimating the distance and location of individual objects by using variable stars as standard candles. Globular clusters contain many cepheid variable stars, whose precise relationship between luminosity and variability period was established by Henrietta Leavitt in 1908. Using cepheid and RR Lyrae variables to systematically chart the distribution of globular clusters, Shapley discovered that the stars in the Milky Way orbited a common center thousands of light years away from the Sun. The galactic center was determined to be in the direction of the Sagittarius constellation, approximately 50,000 light-years from us.\nIn 1920 Heber Doust Curtis and Harlow Shapley participated in the Great Debate on the nature of nebulae and galaxies, and the size of the universe. Shapley believed that distant nebulae were relatively small and lay within the Milky Way galaxy. Curtis advocated the now-accepted view that nebulae were farther away, and that other galaxies apart from the Milky Way therefore existed.\nBy 1925, Edwin Hubble had confirmed that many objects previously thought to be clouds of dust and gas and classified as \"nebulae\" were actually galaxies beyond the Milky Way.\n\nWhen astronomers realized that starlight can be absorbed by clouds of gas and dust, infrared radiation was used to penetrate the dust clouds.\nEstimates dating after 2000 locate our solar system within the range from the Galactic Center of the Milky Way galaxy.\n"}
{"id": "102559", "url": "https://en.wikipedia.org/wiki?curid=102559", "title": "Gay panic defense", "text": "Gay panic defense\n\nThe gay panic defense is an attempted legal defense, usually against charges of assault or murder. A defendant using the defense claims they acted in a state of violent temporary insanity because of unwanted same-sex sexual advances. The defendant alleges to find the same-sex sexual advances so offensive and frightening that it brings on a psychotic state characterized by unusual violence.\n\nTrans panic is a similar defense applied in cases of assault, manslaughter, or murder of a transgender individual, with whom the assailant(s) engaged in sexual relations unaware that the victim is transgender until seeing them naked, or further into or post sexual activity.\n\nIn Australia, it is known as the homosexual advance defense (HAD). Of the status of the HAD in Australia, Kent Blore wrote:Although the homosexual advance defence cannot be found anywhere in legislation, its entrenchment in case law gives it the force of law. [...] Several Australian states and territories have either abolished the umbrella defence of provocation entirely or excluded non-violent homosexual advances from its ambit. Of those that have abolished provocation entirely, Tasmania was the first to do so in 2003.\n\nVictoria passed similar reforms in 2005, followed by Western Australia in 2008 and Queensland in 2017 (with a clause to allow it in 'exceptional circumstances' to be determined by a magistrate). In a differing approach, New South Wales, the ACT and Northern Territory have implemented changes to stipulate that non-violent sexual advances (of any kind, including homosexual) aren't a valid defence.\n\nSouth Australia was the first Australian jurisdiction to legalise consensual homosexual acts in 1975; however, it was the only Australian jurisdiction not to have repealed or overhauled the gay panic defence. In 2015 the South Australian state government was awaiting, the report from the South Australian Law Reform Institute and the outcome of the appeal to the High Court from the Court of Criminal Appeal of South Australia. In 2011 Andrew Negre was killed by Michael Lindsay bashing and stabbing him. Lindsay's principle defence was that he stabbed Negre in the chest and abdomen but Negre's death was the result of someone else slitting Negre's throat. The secondary defence was that Lindsay's action in stabbing Negre was because he had lost self-control after Negre made sexual advances towards him and offered to pay Lindsay for sex. The jury convicted Lindsay of murder and he was sentenced to life imprisonment with a 23-year non-parole period. The Court of Criminal Appeal upheld the conviction finding that the directions to the jury on the gay panic defence were flawed, but that every reasonable jury would have found that an ordinary person could not have to lost self-control and acted in the way Lindsay did. The High Court held that a properly instructed jury might have found that an offer of money for sex made by a Caucasian man to an Aboriginal man in the latter's home and in the presence of his wife and family may have had a pungency that an unwelcome sexual advance made by one man toward another in other circumstances would not have. Lindsay was re-tried and was again convicted of murder. The Court of Criminal Appeal upheld the conviction, and an application for special leave to appeal to the High Court was dismissed. In April 2017 the South Australian Law Reform Institute recommended that the law of provocation be reformed to remove discrimination on the basis of sexual orientation and / or gender, but that the removal of a non-violent sexual advance as a partial defence to murder be deferred until stage 2 of the report was produced.\n\n\nGuidance given to counsel by the Crown Prosecution Service of England and Wales states: \"The fact that the victim made a sexual advance on the defendant does not, of itself, automatically provide the defendant with a defence of self-defence for the actions that they then take.\" In the UK, it has been known for decades as the \"Portsmouth defence\" or the \"guardsman's defence\". (The latter term was used in a 1980 episode of \"Rumpole of the Bailey\".)\n\nThe gay panic defense in the United States has been banned explicitly only within California, Rhode Island and Illinois, but the American Bar Association suggested in 2013 that other states follow their lead.\n\nIn 2006, California amended its penal code to include jury instructions to ignore bias, sympathy, prejudice, or public opinion in making their decision, and a directive was made to educate district attorneys' offices about panic strategies and how to prevent bias from affecting trial outcomes. On September 27, 2014, Governor Jerry Brown signed Assembly Bill No. 2501, making California the first state in the US to ban the gay and trans panic defense. AB 2501 states that discovery of, knowledge about, or potential disclosure of the victim's actual or perceived gender, gender identity, gender expression, or sexual orientation does not, by itself, constitute sufficient provocation to justify a lesser charge of voluntary manslaughter.\n\nIn August 2017, Bruce Rauner, Governor of Illinois, signed a bill eliminating the gay and trans panic defenses in that state.\n\nIn June 2018, a bill to repeal the gay and trans panic defense passed the Rhode Island Assembly (House vote 68–2 passed and Senate voice vote 27-0 passed). The Governor of Rhode Island signed the bill into law a month later in July 2018. The law went into effect immediately.\n\nThe gay panic defense is generally invoked in cases where the guilt of the defendant is unquestioned, but only to strengthen a more \"traditional criminal law defense such as insanity, diminished capacity, provocation, or self-defense\" and is not meant to provide justification of the crime on its own. While using the gay panic defense to explain insanity has typically not been successful in winning a complete acquittal, diminished capacity, provocation, and self-defense have all been used successfully to reduce charges and sentences. Historically, in US courts, use of the gay panic defense has not typically resulted in the acquittal of the defendant; instead, the defendant was usually found guilty, but on lesser charges, or judges and juries may have cited homosexual solicitation as a mitigating factor, resulting in reduced culpability and sentences.\n\nThe most famous case in which this occurred was the \"Jenny Jones\" case, in which Jonathan Schmitz was tried for the first-degree murder of Scott Amedure and was instead found guilty of the lesser offense of second-degree murder. Some instances where the gay panic defense has been invoked include:\n\n\n\n\n"}
{"id": "54244", "url": "https://en.wikipedia.org/wiki?curid=54244", "title": "Gravitational singularity", "text": "Gravitational singularity\n\nA gravitational singularity or spacetime singularity is a location in spacetime where the gravitational field of a celestial body becomes infinite in a way that does not depend on the coordinate system. The quantities used to measure gravitational field strength are the scalar invariant curvatures of spacetime, which includes a measure of the density of matter. Since such quantities become infinite within the singularity, the laws of normal spacetime cannot exist.\n\nGravitational singularities are mainly considered within general relativity, where density apparently becomes infinite at the center of a black hole, and within astrophysics and cosmology as the earliest state of the universe during the Big Bang. Physicists are undecided whether the prediction of singularities means that they actually exist (or existed at the start of the Big Bang), or that current knowledge is insufficient to describe what happens at such extreme densities.\n\nGeneral relativity predicts that any object collapsing beyond a certain point (for stars this is the Schwarzschild radius) would form a black hole, inside which a singularity (covered by an event horizon) would be formed. The Penrose–Hawking singularity theorems define a singularity to have geodesics that cannot be extended in a smooth manner. The termination of such a geodesic is considered to be the singularity.\n\nThe initial state of the universe, at the beginning of the Big Bang, is also predicted by modern theories to have been a singularity. In this case the universe did not collapse into a black hole, because currently-known calculations and density limits for gravitational collapse are usually based upon objects of relatively constant size, such as stars, and do not necessarily apply in the same way to rapidly expanding space such as the Big Bang. Neither general relativity nor quantum mechanics can currently describe the earliest moments of the Big Bang, but in general, quantum mechanics does not permit particles to inhabit a space smaller than their wavelengths.\n\nMany theories in physics have mathematical singularities of one kind or another. Equations for these physical theories predict that the ball of mass of some quantity becomes infinite or increases without limit. This is generally a sign for a missing piece in the theory, as in the Ultraviolet Catastrophe, re-normalization, and instability of a hydrogen atom predicted by the Larmor formula.\n\nSome theories, such as the theory of loop quantum gravity suggest that singularities may not exist. This is also true for such classical unified field theories as the Einstein–Maxwell–Dirac equations. The idea can be stated in the form that due to quantum gravity effects, there is a minimum distance beyond which the force of gravity no longer continues to increase as the distance between the masses becomes shorter, or alternatively that interpenetrating particle waves mask gravitational effects that would be felt at a distance.\n\nThere are different types of singularities, each with different physical features which have characteristics relevant to the theories in which they originally emerged from, such as the different shape of the singularities, \"conical and curved\". They have also been hypothesized to occur without Event Horizons, structures which delineate one spacetime section from another in which events cannot affect past the horizon; these are called \"naked.\"\n\nA conical singularity occurs when there is a point where the limit of every diffeomorphism invariant quantity is finite, in which case spacetime is not smooth at the point of the limit itself. Thus, spacetime looks like a cone around this point, where the singularity is located at the tip of the cone. The metric can be finite everywhere if a suitable coordinate system is used.\n\nAn example of such a conical singularity is a cosmic string and a Schwarzschild black hole.\n\nSolutions to the equations of general relativity or another theory of gravity (such as supergravity) often result in encountering points where the metric blows up to infinity. However, many of these points are completely regular, and the infinities are merely a result of using an inappropriate coordinate system at this point. In order to test whether there is a singularity at a certain point, one must check whether at this point diffeomorphism invariant quantities (i.e. scalars) become infinite. Such quantities are the same in every coordinate system, so these infinities will not \"go away\" by a change of coordinates.\n\nAn example is the Schwarzschild solution that describes a non-rotating, uncharged black hole. In coordinate systems convenient for working in regions far away from the black hole, a part of the metric becomes infinite at the event horizon. However, spacetime at the event horizon is regular. The regularity becomes evident when changing to another coordinate system (such as the Kruskal coordinates), where the metric is perfectly smooth. On the other hand, in the center of the black hole, where the metric becomes infinite as well, the solutions suggest a singularity exists. The existence of the singularity can be verified by noting that the Kretschmann scalar, being the square of the Riemann tensor i.e. formula_1, which is diffeomorphism invariant, is infinite.\n\nWhile in a non-rotating black hole the singularity occurs at a single point in the model coordinates, called a \"point singularity\", in a rotating black hole, also known as a Kerr black hole, the singularity occurs on a ring (a circular line), known as a \"ring singularity\". Such a singularity may also theoretically become a wormhole.\n\nMore generally, a spacetime is considered singular if it is geodesically incomplete, meaning that there are freely-falling particles whose motion cannot be determined beyond a finite time, being after the point of reaching the singularity. For example, any observer inside the event horizon of a non-rotating black hole would fall into its center within a finite period of time. The classical version of the Big Bang cosmological model of the universe contains a causal singularity at the start of time (\"t\"=0), where all time-like geodesics have no extensions into the past. Extrapolating backward to this hypothetical time 0 results in a universe with all spatial dimensions of size zero, infinite density, infinite temperature, and infinite spacetime curvature.\n\nUntil the early 1990s, it was widely believed that general relativity hides every singularity behind an event horizon, making naked singularities impossible. This is referred to as the cosmic censorship hypothesis. However, in 1991, physicists Stuart Shapiro and Saul Teukolsky performed computer simulations of a rotating plane of dust that indicated that general relativity might allow for \"naked\" singularities. What these objects would actually look like in such a model is unknown. Nor is it known whether singularities would still arise if the simplifying assumptions used to make the simulation were removed. However, it is hypothesized that light entering a singularity would similarly have its geodesics terminated, thus making the naked singularity look like a black hole.\n\nDisappearing event horizons exist in the Kerr metric, which is a spinning black hole in a vacuum. Specifically, if the angular momentum is high enough, the event horizons could disappear. Transforming the Kerr metric to Boyer–Lindquist coordinates, it can be shown  that the  coordinate (which is not the radius) of the event horizon is, formula_2, where formula_3, and formula_4. In this case, \"event horizons disappear\" means when the solutions are complex for formula_5, or formula_6.\n\nDisappearing event horizons can also be seen with the Reissner–Nordström geometry of a charged black hole. In this metric, it can be shown that the singularities occur at formula_7, where formula_3, and formula_9. Of the three possible cases for the relative values of formula_10 and formula_11, the case where formula_12 causes both formula_5 to be complex. This means the metric is regular for all positive values of formula_14, or in other words, the singularity has no event horizon.\n\nBefore Stephen Hawking came up with the concept of Hawking radiation, the question of black holes having entropy had been avoided. However, this concept demonstrates that black holes can radiate (perhaps, negative) energy, which conserves entropy and solves the incompatibility problems with the second law of thermodynamics. Entropy, however, implies heat and therefore temperature. The loss of energy also suggests that black holes do not last forever, but rather evaporate or decay slowly. Small black holes tend to be hotter whereas larger ones tend to be colder. All known black hole candidates are so large that their temperature is far below that of the cosmic background radiation, so they all tend to gain entropical energy, and they will not begin to lose their energy until a cosmological redshift of more than one million is reached, rather than the thousand or so since the background radiation formed.\n\n\n\n"}
{"id": "50736740", "url": "https://en.wikipedia.org/wiki?curid=50736740", "title": "Ilan Manouach", "text": "Ilan Manouach\n\nIlan Manouach (born July 11, 1980) is a conceptual artist, a musician and a book publisher. He is mostly known for creating Shapereader, a tactile language specifically designed for the production of literary works for and from the visually impaired.\n\nIlan Manouach holds a BFA from in Brussels. Since 2003, he has published more than a dozen bookworks under the catalogue of a small publishing house based in Brussels, . He has curated four anthologies bringing together contributions from artists, critics, lawyers and different professionals of the book industry. His work has been described as covering a range of different experimentation within the tradition of comics, from narratives, to rip-offs and appropriations and recently to the invention of a new language, Shapereader.\n\nHis first book, published in 2003, was \"Les lieux et les choses qui entouraient les gens désormais\". According to comics critic Thierry Groensteen, « […] It is not surprising that Manouach is also a jazz musician. His storytelling is entirely built as a succession of drone sounds, melodic lines, disjunctions, syncopations and improvisations and variations around a main theme ».\n\nIn several later projects such as The Horse-Headed Statue, designed for an international architecture symposium in Greece in 2007, \"Écologie Forcée\", a work commissioned by the in 2010 and \"Both Sides of a Wall\", produced for the in 2011, he uses exhibition space as a way to engage the spectator as the reader. Along with , he is also the director of the anthology \"Le Coup de Grâce\", a book that collects artists' contributions to book's call for the creation of undetermined, deliberately evasive, and irredeemably idiosyncratic narratives.\n\nHis books have received support on different occasions from the in France and the French Community of Belgium. He is a Fellow and an alumnus of the Koneen Säätiö in Finland.\n\nHe has also contributed to several anthologies, such as , , Glomp and Multitudes and has produced a few commissions for newspapers such as The New York Times and .\n\nHe is known for the unsigned comics appropriations, and the manifestos supplementing these editions.\n\nHe has published illegal appropriations of existing comics, and reinjected the detournements in the book market.\n\nIlan Manouach is probably the author of the famous rip-off, \"Katz\". \"Katz\" is a pirated edition of Art Spiegelman's seminal graphic novel \"Maus\". \"Katz\" is an exact copy of the French edition of \"Maus\", with the difference that all the animal characters, have been redrawn as cats. The book was printed on November 2011 and it was seen in public for the first time in January 2012 during the Angoulême International Comics Festival that ran under Spiegelman’s presidency.\n\n\"Noirs\" is a fac-simile of the original edition of Les Schroumpfs Noirs, with all printed colors replaced with blue. The book has been compared to certain appropriations from Carmelo Bene's, specifically \"Romeo e Giulietta : storia di Shakespeare secondo Carmelo Bene\"\".\"\n\nShapereader is a tactile language specifically designed to allow the creation of narrative works of tactile literature for, and from a visually impaired readership. While it has been mainly created for the purposes of a blind community, the Shapereader repertoire can also be experienced by the acquainted regular user. The Shapereader consists of a repertoire of anaglyph shapes called tactigrams designed to provide haptic equivalents for objects, actions, affections, characters and so on.\n\nThe Shapereader has been presented during the International Comics Festival of Angoulême, at the Onassis Cultural Center in Athens and workshops have been conducted in Athens, Tel Aviv and France.\n\n\n\n"}
{"id": "297755", "url": "https://en.wikipedia.org/wiki?curid=297755", "title": "Impermanence", "text": "Impermanence\n\nImpermanence, also called Anicca, Aanicca, Anitcha or Anitya, is one of the essential doctrines and a part of three marks of existence in Buddhism. The doctrine asserts that all of conditioned existence, without exception, is \"transient, evanescent, inconstant\". All temporal things, whether material or mental, are compounded objects in a continuous change of condition, subject to decline and destruction. The concept of impermanence is also found in various schools of Hinduism and Jainism.\n\nAnicca or impermanence is understood in Buddhism as the first of three marks of existence, the other two being dukkha (suffering, pain, unsatisfactoriness) and anatta (non-self, non-soul, no essence).\n\nAll physical and mental events, states Buddhism, come into being and dissolve. Human life embodies this flux in the aging process, the cycle of repeated birth and death (Samsara), nothing lasts, and everything decays. This is applicable to all beings and their environs, including beings who have reincarnated in deva (god) and naraka (hell) realms. This is in contrast to nirvana, the reality that is \"Nicca\", or knows no change, decay or death.\n\nImpermanence is intimately associated with the doctrine of anatta, according to which things have no essence, permanent self, or unchanging soul. The Buddha taught that because no physical or mental object is permanent, desires for or attachments to either causes suffering (dukkha). Understanding \"Anicca\" and \"Anatta\" are steps in the Buddhist’s spiritual progress toward enlightenment.\n\nThe Pali word \"anicca\" is a compound word consisting of \"a\" meaning non-, and \"nicca\" meaning \"constant, continuous, permanent\". While 'Nicca' is the concept of continuity and permanence, 'Anicca' refers to its exact opposite; the absence of permanence and continuity.\n\nThe term appears in the Rigveda, and is synonymous with \"Anitya\" (a + nitya). The term appears extensively in the Pali canon.\n\nAnicca doctrine is one of the foundational premises of Buddhism, which asserts that all physical and mental events are not metaphysically real, that they are not constant or permanent, they come into being and dissolve. Impermanence is one of \"trilakshana\" (three marks) of existence. It appears in Pali texts as, \"sabbe sankhara anicca, sabbe sankhara dukkha, sabbe dhamma anatta\", which Szczurek translates as, \"all conditioned things are impermanent, all conditioned things are painful, all dhammas are without Self\".\n\nEverything, whether physical or mental, is a formation (Saṅkhāra), has a dependent origination and is impermanent. It arises, changes and disappears.\n\nAccording to Buddhism, everything in human life, all objects, as well as all beings whether in heavenly or hellish or earthly realms in Buddhist cosmology, is always changing, inconstant, undergoes rebirth and redeath (Samsara). This impermanence is a source of \"Dukkha\". This is in contrast to nirvana, the reality that is \"Nicca\", or knows no change, decay or death.\n\nThe term \"Anitya\" (अनित्य), in the sense of impermanence of objects and life, appears in verse 1.2.10 of the Katha Upanishad, one of the Principal Upanishads of Hinduism. It asserts that everything in the world is impermanent, but impermanent nature of things is an opportunity to obtain what is permanent (\"nitya\") as the Hindu scripture presents its doctrine about Atman (soul). The term Anitya also appears in the Bhagavad Gita in a similar context.\n\nBuddhism and Hinduism share the doctrine of \"Anicca\" or \"Anitya\", that is \"nothing lasts, everything is in constant state of change\"; however, they disagree on the \"Anatta\" doctrine, that is whether soul exists or not. Even in the details of their respective impermanence theories, state Frank Hoffman and Deegalle Mahinda, Buddhist and Hindu traditions differ. Change associated with \"Anicca\" and associated attachments produces sorrow or \"Dukkha\" asserts Buddhism and therefore need to be discarded for liberation (\"nibbana\"), while Hinduism asserts that not all change and attachments lead to \"Dukkha\" and some change – mental or physical or self-knowledge – leads to happiness and therefore need to be sought for liberation (\"moksha\"). The \"Nicca\" (permanent) in Buddhism is anatta (non-soul), the \"Nitya\" in Hinduism is atman (soul).\n\n\n\n"}
{"id": "318580", "url": "https://en.wikipedia.org/wiki?curid=318580", "title": "International Date Line", "text": "International Date Line\n\nThe International Date Line (IDL) is an imaginary line of demarcation on the surface of Earth that runs from the North Pole to the South Pole and demarcates the change of one calendar day to the next. It passes through the middle of the Pacific Ocean, roughly following the 180° line of longitude but deviating to pass around some territories and island groups.\n\nThe IDL is roughly based on the meridian of 180° longitude, roughly down the middle of the Pacific Ocean, and halfway around the world from the Greenwich meridian. In many places, the IDL follows the 180° meridian exactly. In other places, however, the IDL deviates east or west away from that meridian. These various deviations generally accommodate the political and/or economic affiliations of the affected areas.\n\nProceeding from north to south, the first deviation of the IDL from 180° is to pass to the east of Wrangel Island and the Chukchi Peninsula, the easternmost part of Russian Siberia. (Wrangel Island lies directly on the meridian at 71°32′N 180°0′E, also noted as 71°32′N 180°0′W.) It then passes through the Bering Strait between the Diomede Islands at a distance of from each island at 168°58′37″ W. It then bends considerably west of 180°, passing west of St. Lawrence Island and St. Matthew Island.\n\nThe IDL crosses between the U.S. Aleutian Islands (Attu Island being the westernmost) and the Commander Islands, which belong to Russia. It then bends southeast again to return to 180°. Thus, all of Russia is to the west of the IDL, and all of the United States is to the east except for the insular areas of Guam, the Northern Mariana Islands, and Wake Island.\n\nThe IDL remains on the 180° meridian until passing the equator. Two US-owned uninhabited atolls, Howland Island and Baker Island, just north of the equator in the central Pacific Ocean (and ships at sea between 172.5°W and 180°), have the latest time on Earth ( hours).\n\nThe IDL circumscribes Kiribati by swinging far to the east, almost reaching the 150°W meridian. Kiribati's easternmost islands, the southern Line Islands south of Hawaii, have the most advanced time on Earth, UTC+14 hours. South of Kiribati, the IDL returns westwards but remains east of 180°, passing between Samoa and American Samoa.\n\nIn much of this area, the IDL follows the 165°W meridian. Accordingly, Samoa, Tokelau, Wallis and Futuna, Fiji, Tonga, Tuvalu and New Zealand's Kermadec Islands and Chatham Islands are all west of the IDL and have the same date. American Samoa, the Cook Islands, Niue, and French Polynesia are east of the IDL and one day behind.\n\nThe IDL then bends southwest to return to 180°. It follows that meridian until reaching Antarctica, which has multiple time zones. Conventionally, the IDL is not drawn into Antarctica on most maps. (See below.)\n\nA person who goes around the world from east to west (the same direction as Magellan's voyage) would gain or set their clock back one hour for every 15° of longitude crossed, and would gain 24 hours for one circuit of the globe from east to west if they did not compensate by setting their clock forward one day when they crossed the IDL. In contrast, a west-to-east circumnavigation of the globe loses an hour for every 15° of longitude crossed but gains back a day when crossing the IDL. The IDL must therefore be observed in conjunction with the Earth's time zones: on crossing it in either direction, the calendar \"date\" is adjusted by one day.\n\nFor the two hours between 10:00 and 11:59 UTC each day, three different calendar dates are observed at the same time in different places on Earth. For example, at 10:15 UTC Thursday, it is 23:15 Wednesday in American Samoa (), Thursday in most of the world, and 00:15 Friday in Kiritimati ().\n\nDuring the first hour (UTC 10:00–10:59), all three calendar dates include inhabited places. During the second hour (UTC 11:00–11:59) one of the calendar dates is limited to an uninhabited maritime time zone twelve hours behind UTC (UTC−12).\n\nAccording to the clock, the first areas to experience a new day and a New Year are islands that use UTC+14. These include portions of the Republic of Kiribati, including Millennium Island in the Line Islands, as well as Samoa during the southern summer. The first major cities to experience a new day are Auckland and Wellington, New Zealand (; with daylight saving time).\n\nA 1995 realignment of the IDL made Caroline Island one of the first points of land on Earth to reach January 1, 2000 on the calendar (UTC+14). As a result, this atoll was renamed Millennium Island.\n\nThe areas that are the first to see the daylight of a new day vary by the season. Around the June solstice, the first area would be anyplace within the Kamchatka Time Zone (UTC+12) that is far enough north to experience midnight sun on the given date. At the equinoxes, the first place to see daylight would be the uninhabited Millennium Island in Kiribati, which is the easternmost land located west of the IDL.\n\nNear the December solstice, the first places would be Antarctic research stations using New Zealand Time (UTC+13) during summer that experience midnight sun. These include Amundsen-Scott South Pole Station, McMurdo Station, Scott Base and Mario Zucchelli Station.\n\nThere are two ways time zones and thereby the location of the International Date Line are determined, one on land and adjacent territorial waters, and the other on open seas.\n\nAll nations unilaterally determine their standard time zones, applicable only on land and adjacent territorial waters. This date line can be called \"de facto\" since it is not based on international law, but on national laws. These national zones do not extend into international waters.\n\nThe nautical date line, not the same as the IDL, is a \"de jure\" construction determined by international agreement. It is the result of the 1917 Anglo-French Conference on Time-keeping at Sea, which recommended that all ships, both military and civilian, adopt hourly standard time zones on the high seas. The United States adopted its recommendation for U.S. military and merchant marine ships in 1920. This date line is implied but not explicitly drawn on time zone maps. It follows the 180° meridian except where it is interrupted by territorial waters adjacent to land, forming gaps—it is a pole-to-pole dashed line. The 15° gore that is offset from UTC by 12 hours is bisected by the nautical date line into two 7.5° gores that differ from UTC by ±12 hours.\n\nShips are supposed to adopt the standard time of a country if they are within its territorial waters within of land, then revert to international time zones (15° wide pole-to-pole gores) as soon as they leave. In reality, ships use these time zones only for radio communication and similar purposes. For internal purposes, such as work and meal hours, ships use a time zone of their own choosing.\n\nThe IDL on the map on this page and all other maps is based on the \"de facto\" line and is an artificial construct of cartographers, as the precise course of the line in international waters is arbitrary. The IDL does not extend into Antarctica on the world time zone maps by the United States Central Intelligence Agency (CIA) or the United Kingdom's Her Majesty's Nautical Almanac Office (HMNAO). The IDL on modern CIA maps now reflects the most recent shifts in the IDL (see below). The current HMNAO map does not draw the IDL in conformity with recent shifts in the IDL; it draws a line virtually identical to that adopted by the UK's Hydrographic Office about 1900. Instead, HMNAO labels island groups with their time zones, which do reflect the most recent IDL shifts. This approach is consistent with the principle of national and nautical time zones: the islands of eastern Kiribati are actually \"islands\" of Asian date (west side of IDL) in a sea of American date (east side of IDL).\n\nNo international organization, nor any treaty between nations, has fixed the IDL drawn by cartographers: the 1884 International Meridian Conference explicitly refused to propose or agree to any time zones, stating that they were outside its purview. The conference resolved that the Universal Day, midnight-to-midnight Greenwich Mean Time (now known as Coordinated Universal Time, or UTC), which it did agree to, \"shall not interfere with the use of local or standard time where desirable\". From this comes the utility and importance of UTC or \"Z (Zulu)\" time: it permits a single universal reference for time that is valid for all points on the globe at the same moment.\n\nAs part of New Spain, the Philippines long had its most important communication with Acapulco in Mexico and was accordingly on the \"east\" side of the IDL despite being at the far western edge of the Pacific Ocean. From 1521 to 1844, the Philippines was one day behind its Asian neighbors (Saturday, was the first European visit, when Ferdinand Magellan claimed the area for Spain; colonization began on Friday, ). After Mexico gained its independence from Spain in 1821, Philippine trade interests turned to Imperial China, the Dutch East Indies and adjacent areas, so the Philippines decided to shift back to the west side of the IDL by removing Tuesday, from its calendar. The change was also applied to Mariana Islands, Guam and Caroline Islands since they also belonged to Spain. Because of this change, New Year's Eve happened on Monday, . Effective Wednesday, , the Philippines, Guam, Mariana Islands and Caroline Islands switched back to Asian date. Western publications were generally unaware of this change until the early 1890s, so erroneously gave the International Date Line a large western bulge for the next half century.\n\nThe Russian Empire settled northwest North America from Siberia, from the west with its own Julian calendar (it did not adopt the Gregorian calendar until 1918). The United States purchased Russian America while based in the contiguous United States, from the east with its own Gregorian calendar (adopted in 1752 while several British colonies). The transfer ceremony occurred on the day that the commissioners appointed by the governments of Russia and the United States for that purpose arrived via the at New Archangel (Sitka), the capital of Russian America. The United States recorded this date as Friday, (Gregorian), now known as Alaska Day, whereas the Russian governor, who had remained in New Archangel, would have recorded it as Saturday, (Julian). Senator Charles Sumner stated during his three-hour ratification speech (an encyclopedic discussion of Russian America) on Tuesday, , that this day of the week and calendar discord should be changed. Because the transfer of ownership officially occurred at Sitka mean solar time (time zones were not yet in use), that was the date and time that Alaska changed from an Asian and Julian date to an American and Gregorian date. If the transfer had occurred at the preceding midnight then Friday, (Julian) would have been followed by Friday, (Gregorian), a duplicate day with a 12-day difference appropriate both for changing from an Asian date to an American date (equivalent to moving the IDL from the east to the west of Alaska) and for changing from the Julian calendar to the Gregorian calendar during the 19th century.\n\nThe Samoan Islands, now divided into Samoa and American Samoa, were on the west side of the IDL until 1892. In that year, King Malietoa Laupepa was persuaded by American traders to adopt the American date (three hours behind California) to replace the former Asian date (four hours ahead of Japan). The change was made by repeating , American Independence Day.\n\nIn 2011, Samoa shifted back to the west side of the IDL by removing Friday, from its calendar. This changed the timezone from to . Samoa made the change because Australia and New Zealand have become its biggest trading partners, and also have large communities of expatriates. Being 21 hours behind made business difficult because having weekends on backward days meant only four days of the week were shared workdays.\n\nThe IDL now passes between Samoa and American Samoa, which remains on the east (American) side of the line.\n\nTokelau is a territory of New Zealand north of Samoa whose principal transportation and communications links with the rest of the world pass through Samoa. For that reason, Tokelau crossed the IDL along with Samoa in 2011.\n\nKwajalein atoll, like the rest of the Marshall Islands, passed from Spanish to German to Japanese control during the nineteenth and twentieth centuries. During that period it was west of the IDL. Although Kwajalein formally became part of the Trust Territory of the Pacific Islands with the rest of the Marshalls after World War II, the United States established a military installation there. Because of that, Kwajalein used the Hawaiian date, so was effectively east of the International Date Line (unlike the rest of the Marshalls). Kwajalein returned to the west side of the IDL by removing Saturday, from its calendar to match the dates used by the rest of the Marshall Islands, at the request of its government. Along with the shift, Kwajalein's work week was changed to Tuesday through Saturday to match the Hawaiian work week of Monday through Friday on the other side of the IDL.\n\nAs a British colony, the now-Republic of Kiribati was centered in the Gilbert Islands, just west of the IDL of the time. Upon independence in 1979, it acquired the Phoenix and Line Islands, east of the IDL, from the United States. As a result, the country straddled the IDL. Government and commercial concerns on opposite sides of the line could only conduct routine business by radio or telephone on the four days of the week which were weekdays on both sides. To eliminate this anomaly, Kiribati introduced a change of date for its eastern half by removing Saturday, from its calendar. After the change, the IDL in effect moved eastwards to go around the entire country. Strictly legal, the 1917 nautical IDL convention is still valid. When the land time zone says it's Monday, these islands would form enclaves of Monday in an ocean which has Sunday. Maps are usually not drawn this way.\n\nAs a consequence of the 1994 change, Kiribati's easternmost territory, the Line Islands, including the inhabited island of Kiritimati (Christmas Island), started the year 2000 before any other country, a feature the Kiribati government capitalized upon as a potential tourist draw.\n\nGenerally, the Christian calendar and Christian churches recognize the IDL. Christmas for example, is celebrated on 25 December (according to either the Gregorian or the Julian calendar, depending upon which of the two is used by the particular church) as that date falls in countries located on either side of the Date Line. Thus, whether it is Western Christmas or Orthodox Christmas, Christians in Samoa, immediately west of the Date Line, will celebrate the holiday a day before Christians in \"American\" Samoa, which is immediately \"east\" of the Date Line.\n\nA problem with the general rule above arises in certain Christian churches that solemnly observe a Sabbath day as a particular day of the week, when those churches are located in countries near the Date Line. Notwithstanding the difference in dates, the same sunrise happened over American Samoa as happens over Samoa a few minutes later, and the same sunset happens over Samoa as happened over American Samoa a few minutes earlier. In other words, the secular days are \"legally\" different but they are \"physically\" the same; and that causes questions to arise under religious law.\n\nBecause the Date Line was an arbitrary imposition, the question can arise as to which Saturday on either side of the Date Line (or, more fundamentally, on either side of 180 degrees longitude) is the \"real\" Saturday. This issue (which also arises in Judaism) is a particular problem for Seventh Day Adventists, Seventh Day Baptists, and similar churches located in countries near the Date Line.\n\nIn Tonga, Seventh Day Adventists (who usually observe Saturday, the seventh-day Sabbath) observe Sunday due to their understanding of the International Date Line, as Tonga lies east of the 180° meridian. Sunday as observed in Tonga (as with Kiribati, Samoa, and parts of Fiji and Tuvalu) is considered by the Seventh-day Adventist Church to be the same day as Saturday observed in most other places.\n\nMost Seventh Day Adventists in Samoa planned to observe Sabbath on Sunday after Samoa's crossing the date line in December 2011, but SDA groups in Samatau village and other places (approx. 300 members) decided to accept the IDL adjustment and observe the Sabbath on Saturday. Debate continues within the Seventh-day Adventist community in the Pacific as to which day is really the seventh-day Sabbath.\n\nThe Samoan Independent Seventh-day Adventist Church, which is not affiliated to the worldwide Seventh-day Adventist Church, has decided to continue worshiping on Saturday, after a six-day week at the end of 2011.\n\nSimilarly, the Islamic calendar and Muslim communities recognize the convention of the IDL. In particular, the day for holding the \"Jumu'ah\" prayer appears to be local Friday everywhere in the world.\n\nThe IDL is not a factor in the start and end of Islamic lunar months. These depend solely on sighting the new crescent moon. As an example, the fasts of the month of Ramadan begin the morning after the crescent is sighted. That this day may vary in different parts of the world is well known in Islam. (See .)\n\nThe concept of an international date line in Jewish law is first mentioned by 12th-century decisors. But it was not until the introduction of improved transportation and communications systems in the 20th century that the question of an international date line truly became a question of practical Jewish law.\n\nAs a practical matter, the conventional International Date Line—or another line in the Pacific Ocean close to it—serves as a \"de facto\" date line for purposes of Jewish law, at least in existing Jewish communities. For example, residents of the Jewish communities of Japan, New Zealand, Hawaii, and French Polynesia all observe Shabbat on local Saturday. However, there is not unanimity as to how Jewish law reaches that conclusion. For this reason, some authorities rule that certain aspects of Sabbath observance are required on Sunday (in Japan and New Zealand) or Friday (in Hawaii and French Polynesia) in addition to Saturday. Additionally, there are differences of opinion as to which day or days individual Jews traveling in the Pacific region away from established Jewish communities should observe Shabbat.\n\nFor individuals crossing the date line, the change of calendar date influences some aspects of practice under Jewish law. Yet other aspects depend on an individual's experience of sunsets and sunrises to count days, notwithstanding the calendar date.\n\nThe date line is a central factor in Umberto Eco's book \"The Island of the Day Before\" (1994), in which the protagonist finds himself on a becalmed ship, with an island close at hand on the other side of the IDL. Unable to swim, the protagonist indulges in increasingly confused speculation regarding the physical, metaphysical and religious import of the date line.\n\nThe concept behind the IDL (though not the IDL itself, which did not yet exist) appears as a plot device in Jules Verne's book \"Around the World in Eighty Days\" (1873). The main protagonist, Phileas Fogg, travels eastward around the world. He had bet with his friends that he could do it in 80 days. To win the wager, Fogg must return by 8:45 pm on Saturday, 21 December 1872. However, the journey suffers a series of delays and when Fogg reaches London, it's 8:50 pm on Friday, 20 December, although he believes it's Saturday, 21 December and that he has lost the wager by a margin of only five minutes. The next day, however, it is revealed that the day is Saturday, not Sunday, and Fogg arrives at his club just in time to win the bet. Verne explains:\n\nIn journeying eastward he [Fogg] had gone towards the sun, and the days therefore diminished for him as many times four minutes as he crossed degrees in this direction. There are three hundred and sixty degrees on the circumference of the earth; and these three hundred and sixty degrees, multiplied by four minutes, gives precisely twenty-four hours—that is, the day unconsciously gained. In other words, while Phileas Fogg, going eastward, saw the sun pass the meridian eighty times, his friends in London only saw it pass the meridian seventy-nine times.\n\nFogg had thought it was one day more than it actually was, because he had forgotten this simple fact. During his journey, he had added a full day to his clock, at the rhythm of an hour per fifteen degrees, or four minutes per degree, as Verne writes. At the time, the concept of a \"de jure\" International Date Line did not exist. If it did, he would have been made aware that it would be a day less than it used to be once he reached this line. Thus, the day he would add to his clock throughout his journey would be thoroughly removed upon crossing this imaginary line. But a \"de facto\" date line did exist since the UK, India and the US had the same calendar with different local times, and he should have noticed when he arrived to the US that the local date was not the same as in his diary (his servant Jean Passepartout kept his clock in London time, despite the tips of his surroundings).\n\nCeremonies aboard ships to mark a sailor's or passenger's first crossing of the Equator, as well as crossing the International Date Line, have been long-held traditions in navies and in other maritime services around the world.\n\nThe need for a temporal discontinuity on the globe can be described mathematically as following from the Borsuk-Ulam Theorem in dimension 1: It is a topological fact that there does not exist any continuous, one-to-one function mapping from a \"circle\" onto an \"interval.\"\n"}
{"id": "46907915", "url": "https://en.wikipedia.org/wiki?curid=46907915", "title": "International Day of Action for Women's Health", "text": "International Day of Action for Women's Health\n\nThe International Day of Action for Women's Health is an international observance celebrated on May 28 every year since 1987.\n\n\n"}
{"id": "6470153", "url": "https://en.wikipedia.org/wiki?curid=6470153", "title": "Japanese invasion of Taiwan (1874)", "text": "Japanese invasion of Taiwan (1874)\n\nThe Japanese punitive expedition to Taiwan in 1874, referred to in Japan as the and in Taiwan and mainland China as the Mudan incident (), was a punitive expedition launched by the Japanese in retaliation for the murder of 54 Ryukyuan sailors by Paiwan aborigines near the southwestern tip of Taiwan in December 1871. The success of the expedition, which marked the first overseas deployment of the Imperial Japanese Army and Imperial Japanese Navy, revealed the fragility of the Qing dynasty's hold on Taiwan and encouraged further Japanese adventurism. Diplomatically, Japan's embroilment with China in 1874 was eventually resolved by a British arbitration under which Qing China agreed to compensate Japan for property damage. Some ambiguous wording in the agreed terms were later argued by Japan to be confirmation of Chinese renunciation of suzerainty over the Ryukyu Islands, paving the way for \"de facto\" Japanese incorporation of Ryukyu in 1879.\n\nIn December 1871 a Ryukyuan vessel was shipwrecked near the southern tip of Taiwan. Fifty-four members of its crew of 66 were beheaded by the Paiwan aborigines. The remaining 12 crewmen were rescued by Han Chinese and were transferred to Tainan in southern Taiwan. The local Qing Chinese government officials transferred them to Fujian province in mainland China. From there, the Qing government arranged to send them back home.\n\nWhen Japan sought compensation from Qing China, the court rejected the demand on the grounds that the \"wild\"/\"unsubjugated\" aboriginals () were outside its jurisdiction. This open renunciation of sovereignty led to the Taiwan Expedition of 1874 by the Japanese.\n\nThe Meiji government of Japan demanded that the Qing government of China punish leaders of the Taiwanese aborigines responsible for the murders of the Ryukyuan crew. The Japanese foreign minister Soejima Taneomi went to Beijing in June 1873, and was received in an audience by the Tongzhi Emperor (in itself a diplomatic triumph); however, his request for compensation was first rejected because China considered it an internal affair since Taiwan was part of Fujian Province of China and the Ryūkyū Kingdom had a tributary relationship with China. When Soejima Taneomi claimed four of the victims murdered were from Oda Prefecture, present-day Okayama Prefecture, Japan and asked for compensation again, Chinese officials refused him on the grounds that most of the Taiwanese aboriginals were outside effective Chinese control, and were thus sometimes exempt from judicial action. Charles Le Gendre, the French-born American military advisor to the Japanese government, as well as Gustave Emile Boissonade, legal advisor, urged that Japan take the matter into its own hands.\n\nThe Japanese government agreed, and sent an expedition of 3,600 soldiers led by Saigō Tsugumichi in May 1874. The Japanese won a decisive victory at the Battle of Stone Gate on 22 May. Thirty Taiwan tribesmen were either killed or mortally wounded in the battle, and a considerably greater number wounded. Japanese casualties were 6 killed and 30 wounded.\n\nIn November 1874 the Japanese forces withdrew from Taiwan after the Qing government agreed to an indemnity of 500,000 Kuping taels, or about silver. Sir Harry Parkes, the British minister to Japan, characterised this transaction as \"China's willingness to pay to be invaded\".\n\nIn 1875, the Qing authorities unsuccessfully attempted to bring the southeast coastal region of Taiwan under their control, despatching a column of 300 soldiers against the Paiwan. The Chinese troops were ambushed and routed by the Paiwan and their well-armed fighters. 250 Chinese soldiers were killed, and the 50 survivors retreated to Takow (Kaohsiung).\n\nAlthough launched ostensibly to punish the local tribesmen for their murder of 54 Ryukyuan merchants, the 1874 punitive expedition to Taiwan served a number of purposes for Japan's new Meiji government. Japan had for some time begun claiming suzerainty, and later sovereignty, over the Ryūkyū Kingdom, whose traditional suzerain had been China. The expedition demonstrated that China was not in effective control of Taiwan, let alone the Ryukyu Islands. Japan was emboldened to more forcefully assert its claim to speak for the Ryukyuan islanders. The settlement in 1874, brokered by the British, included a reference to Chinese recognition that the Japanese expedition was \"in protection of civilians\", a reference that Japan later pointed towards as Chinese renunciation of its rights over Ryukyu. In 1879 Japan referred the dispute to British arbitration, and the British confirmed Japanese sovereignty over the Ryukyus, a result which was not recognised by China. Nevertheless, Japan used this as the justification for taking \"de facto\" control over Ryukyu, moving the king of Ryukyu to Japan and incorporating Ryukyu as a prefecture of Japan. The ensuing Chinese protest led to the matter being submitted to US President Ulysses S. Grant as arbitrator, during which Japan offered to split Ryukyu between Japan and China. This was refused by China, but a weakened China was unable in practice to stop the Japanese annexation of the Ryukyus.\n\nThe surrendering aborigines were given Japanese flags to fly over their villages that they viewed as a symbol of peace with Japan and protection from rival tribes, however, the Japanese viewed them as a symbol of jurisdiction over the aborigines. The expedition also served as a useful rehearsal for future Japanese imperial ambitions. Taiwan was already being viewed as a potential Japanese colony in some circles in Japan.\n\nDomestically, the action also mollified those within the Meiji government who were pushing for a more aggressive foreign policy, and who were enraged by the government's refusal in 1873 to attack Korea. It is significant that the expedition took place shortly after the Saga Rebellion, and was led by Saigō Jūdō (Saigō Takamori's younger brother) and consisted largely of former Satsuma and Saga \"samurai\".\n\nMore generally, the Japanese incursion into Taiwan in 1874 and the feeble Chinese response was a blatant revelation of Chinese weakness and an invitation to further foreign encroachment in Taiwan. In particular, the success of the Japanese incursion was among the factors influencing the French decision to invade Taiwan in October 1884, during the Sino-French War. The Qing court belatedly attempted to strengthen its hold on Taiwan, and the Chinese imperial commissioner Shen Pao-chen made some improvements to the island's coastal defences during the second half of the 1870s. Further substantial improvements were made by the Chinese governor Liu Ming-ch'uan in the 1880s, in the wake of the French capture of Keelung during the Sino-French War. However, little was done to improve the poor quality of the Qing garrison of Taiwan, and both the French in 1884 and the Japanese in 1895 were able to land successfully in Taiwan.\n\n\n"}
{"id": "901593", "url": "https://en.wikipedia.org/wiki?curid=901593", "title": "Lambda cube", "text": "Lambda cube\n\nIn mathematical logic and type theory, the λ-cube is a framework for exploring the axes of refinement in Thierry Coquand's calculus of constructions, starting from the simply typed lambda calculus (written as λ→ in the cube diagram) as the vertex of a cube placed at the origin, and the calculus of constructions (higher-order dependently typed polymorphic lambda calculus; written as λPω in the diagram) as its diametrically opposite vertex. Each axis of the cube represents a new form of abstraction:\n\nAll eight calculi include the most basic form of abstraction, values depending on values, ordinary functions as in the simply typed lambda calculus. The richest calculus in the cube, with all three abstractions, is the calculus of constructions. All eight calculi are strongly normalizing.\n\nSubtyping however is not represented in the cube, even though systems like formula_1, known as higher-order bounded quantification, which combines subtyping and polymorphism are of practical interest, and can be further generalized to bounded type operators. Further extensions to formula_1 allow the definition of purely functional objects; these systems were generally developed after the lambda cube paper was published.\n\nThe idea of the cube is due to the mathematician Henk Barendregt (1991). The framework of pure type systems generalizes the lambda cube in the sense that all corners of the cube, as well as many other systems can be represented as instances of this general framework. This framework predates the lambda cube by a couple of years. In his 1991 paper, Barendregt also defines the corners of the cube in this framework.\n\nIn his Habilitation à diriger les recherches \"Lambda-Prolog de A à Z... ou presque\" , Olivier Ridoux gives a cut-out template of the Lambda cube (p. 70) and also a dual representation of the cube as an octahedron, where the 8 vertices are replaced by faces, as well as a dual representation as a dodecahedron, where the 12 edges are replaced by faces.\n\n\n\n\n"}
{"id": "611460", "url": "https://en.wikipedia.org/wiki?curid=611460", "title": "Localization of a category", "text": "Localization of a category\n\nIn mathematics, localization of a category consists of adding to a category inverse morphisms for some collection of morphisms, constraining them to become isomorphisms. This is formally similar to the process of localization of a ring; it in general makes objects isomorphic that were not so before. In homotopy theory, for example, there are many examples of mappings that are invertible up to homotopy; and so large classes of homotopy equivalent spaces. Calculus of fractions is another name for working in a localized category.\n\nA category \"C\" consists of objects and morphisms between these objects. The morphisms reflect relations between the objects. In many situations, it is meaningful to replace \"C\" by another category \"C\"' in which certain morphisms are forced to be isomorphisms. This process is called localization.\n\nFor example, in the category of \"R\"-modules (for some fixed commutative ring \"R\") the multiplication by a fixed element \"r\" of \"R\" is typically (i.e., unless \"r\" is a unit) not an isomorphism: \nThe category that is most closely related to \"R\"-modules, but where this map \"is\" an isomorphism turns out to be the category of formula_2-modules. Here formula_2 is the localization of \"R\" with respect to the (multiplicatively closed) subset \"S\" consisting of all powers of \"r\",\nformula_4\nThe expression \"most closely related\" is formalized by two conditions: first, there is a functor\nsending any \"R\"-module to its localization with respect to \"S\". Moreover, given any category \"C\" and any functor \nsending the multiplication map by \"r\" on any \"R\"-module (see above) to an isomorphism of \"C\", there is a unique functor\nsuch that formula_8.\n\nThe above examples of localization of \"R\"-modules is abstracted in the following definition. In this shape, it applies in many more examples, some of which are sketched below.\n\nGiven a category \"C\" and some class \"W\" of morphisms in \"C\", the localization \"C\"[\"W\"] is another category which is obtained by inverting all the morphisms in \"W\". More formally, it is characterized by a universal property: there is a natural localization functor \"C\" → \"C\"[\"W\"] and given another category \"D\", a functor \"F\": \"C\" → \"D\" factors uniquely over \"C\"[\"W\"] if and only if \"F\" sends all arrows in \"W\" to isomorphisms.\n\nThus, the localization of the category is unique, provided that it exists. One construction of the localization is done by declaring that its objects are the same as those in \"C\", but the morphisms are enhanced by adding a formal inverse for each morphism in \"W\". Under suitable hypotheses on \"W\", the morphisms between two objects \"X\", \"Y\" are given by \"roofs\"\n(where \"X\"' is an arbitrary object of \"C\" and \"f\" is in the given class \"W\" of morphisms), modulo certain equivalence relations. These relations turn the map going in the \"wrong\" direction into an inverse of \"f\". This procedure, however, in general yields a proper class of morphisms between \"X\" and \"Y\". Typically, the morphisms in a category are only allowed to form a set. Some authors simply ignore such set-theoretic issues.\n\nA rigorous construction of localization of categories, avoiding these set-theoretic issues, was one of the initial reasons for the development of the theory of model categories: a model category \"M\" is a category in which there are three classes of maps; one of these classes is the class of weak equivalences. The homotopy category Ho(\"M\") is then the localization with respect to the weak equivalences. The axioms of a model category ensure that this localization can be defined without set-theoretical difficulties.\n\nSome authors also define a \"localization\" of a category \"C\" to be an idempotent and coaugmented functor. A coaugmented functor is a pair \"(L,l)\" where \"L:C → C\" is an endofunctor and \"l:Id → L\" is a natural transformation from the identity functor to \"L\" (called the coaugmentation). A coaugmented functor is idempotent if, for every \"X\", both maps \"L(l),l:L(X) → LL(X)\" are isomorphisms. It can be proven that in this case, both maps are equal.\n\nThis definition is related to the one given above as follows: applying the first definition, there is, in many situations, not only a canonical functor formula_10, but also a functor in the opposite direction,\nFor example, modules over the localization formula_2 of a ring are also modules over \"R\" itself, giving a functor\nIn this case, the composition\nis a localization of \"C\" in the sense of an idempotent and coaugmented functor.\n\nSerre introduced the idea of working in homotopy theory \"modulo\" some class \"C\" of abelian groups. This meant that groups \"A\" and \"B\" were treated as isomorphic, if for example \"A/B\" lay in \"C\". Later Dennis Sullivan had the bold idea instead of using the localization of a topological space, which took effect on the underlying topological spaces.\n\nIn the theory of modules over a commutative ring \"R\", when \"R\" has Krull dimension ≥ 2, it can be useful to treat modules \"M\" and \"N\" as \"pseudo-isomorphic\" if \"M/N\" has support of codimension at least two. This idea is much used in Iwasawa theory.\n\nThe derived category of an abelian category is much used in homological algebra. It is the localization of the category of chain complexes (up to homotopy) with respect to the quasi-isomorphisms.\n\nAn isogeny from an abelian variety \"A\" to another one \"B\" is a surjective morphism with finite kernel. Some theorems on abelian varieties require the idea of \"abelian variety up to isogeny\" for their convenient statement. For example, given an abelian subvariety \"A\" of \"A\", there is another subvariety \"A\" of \"A\" such that\n\nis \"isogenous\" to \"A\" (Poincaré's theorem: see for example \"Abelian Varieties\" by David Mumford). To call this a direct sum decomposition, we should work in the category of abelian varieties up to isogeny.\n\nThe localization of a topological space produces another topological space whose homology is a localization of the homology of the original space.\n\nA much more general concept from homotopical algebra, including as special cases both the localization of spaces and of categories, is the \"Bousfield localization\" of a model category. Bousfield localization forces certain maps to become weak equivalences, which is in general weaker than forcing them to become isomorphisms.\n\n"}
{"id": "44825512", "url": "https://en.wikipedia.org/wiki?curid=44825512", "title": "Manana (reflection)", "text": "Manana (reflection)\n\nManana (Sanskrit: मनन) is the deep state of thinking without joy or grief.Yajnavalkya in the context of the \"mahavakya\" – \"Tat Tvam Asi\", told Paingala that whereas \"shravana\" ('hearing') is the inquiry into the real significance of this \"vākya\", to inquire in solitude into the significance of \"shravana\" is \"manana\" (consideration or reflection). Patanjali terms \"manana\" as \"dharana\", the unshakeable mental conviction.\nIn Advaita Vedanta, \"manana\", the deep reflection on what is heard from the teacher, is a part of the three-fold process of \"shravana-manana-nididhyasana\", the three stages of religious life which combined acting as the path of knowledge, lead to the attainment of \"moksha\". According to the Pasupatas belonging to the cult of Shiva, \"manana\" is a \"satmaka\" or mastery over the power of seeing and acting; \"manana\" is the supernormal knowing of objects of thoughts.\n\n\"Manana\" means – 'thinking', 'reflection', 'meditation', 'cogitation'; Panchadasi (Sloka I.53) reads as follows:-\n\nIn this context, Vidyaranya had previously stated that the Self is untouched by doubts about the presence or absence of associates etc; that are superimposed on it phenomenally. In the afore-cited sloka, Swami Swahananda in his commentary explains that whatever be the relation between two \"vikalpas\" ('alternatives'), relation itself has to be understood which even though not an attribute is to be related, for the domain of \"bheda\" ('difference') is riddled with contradictions. Vedanta considers vikalpa as \"kalpana\" or 'contrary imagination' that invariably leads to anavastha ('infinite regress'). The identity alluded to by the great sayings (\"mahavakyas\") conveyed by a Guru to his disciples i.e. sown in the mind of his sisya, have logical support for their validity which support is revealed through manana which process reveals true knowledge.\n\nIt is through deep meditation that the knowledge of Brahman is gained, and Katha Upanishad (I.iii.15) declares that one becomes free from the jaws of death by knowing that which is ever constant; Badarayana states that what is mentioned in that Upanishad is meant for deep meditation on Purusha - आध्यानाय प्रयोजनाभावात् (Brahma Sutras III.iii.14), during which process the differing attributes are not to be combined but only non-different attributes which exist collectively in all the contexts.\n"}
{"id": "54329231", "url": "https://en.wikipedia.org/wiki?curid=54329231", "title": "Maria Yoon", "text": "Maria Yoon\n\nMaria Yoon (born 1971), a.k.a. Maria the Korean Bride, is a New York-based performance artist and filmmaker. She is best known for her extended performance art project and film where in the course of nine years, she gets married in all 50 of the United States, Puerto Rico, the District of Columbia and the US Virgin Islands.\n\nBorn in Seoul, the oldest of three, Yoon's family immigrated to the US when she was seven. She grew up in Queens, the Bronx, and Staten Island, New York, and attended Cooper Union for her Bachelor of Fine Arts. She attended Skowhegan School of Painting and Sculpture in 1994.\n\nYoon felt an inordinate pressure from her parents and the Korean American community to marry after turning 30. She first responded by making a calendar full of bachelors who wanted to propose to her to start a conversation with her father. The \"Marriage Proposal Series 2003 Calendar\" sold out of its first printing at the New Museum bookstore. Yoon, however, felt the project reinforced stereotypical male roles.\n\nShe took the hanbok her mother had given her for her 30th birthday and decided to make a further art project out of it. She started by marrying two people in Las Vegas on a friend's vacation trip. She married in Hawaii in a traditional wedding ceremony. In Detroit, she married an artist dressed as Death. When she experienced racism in Wisconsin, she married a shirt representing the company where she experienced the incident. Her final wedding was held in Times Square in New York City, officiated by Jimmy McMillan, of the Rent is Too Damn High party. Yoon selected her husband from a raffle.\n\nYoon writes the all vows herself and never smiles out of cultural respect and to honor Korean wedding ceremony custom. She has expressed that Wyoming was her favorite experience in the U.S. for the change of scenery it offered and people's friendliness. Though awarded a number of grants and donations, the project was largely self-funded.\n\nThe film version has been screened at ATA Gallery in San Francisco, MTS Gallery in Anchorage, the Manifest in Honolulu, UT Austin, Stony Brook University, and various film festivals like the FEM Cine of Santiago, Chile and in Atlanta, Sarasota, Florida and Naperville, Illinois, among other places. The 2013 New York City premiere, held at the BMCC Tribeca Performing Arts Center, sold out.\n\nIn Montana, the minister, a recent newlywed, said \"She’s asking some really good questions about the institution.\" In New Hampshire Yoon got lectured by a minister on the project and there have been people who have bowed out of the project because of her support of gay marriage.\n\nAfter learning about police in northwest China charging a man with murdering two women with mental disabilities, alleging that he wanted to sell their corpses to be used in so-called \"ghost weddings\" on BBC.com, Yoon took an interest in incorporating the old practice of marrying the dead into her work. In July 2017, after a local Taoist priest had an omen that marrying a deceased man would be unlucky, Yoon married an imaginary husband at a Taoist temple in the Xizhi District of New Taipei City, Taiwan. She wore a pink \"hanbok\" with her wrist tied with a red string to a memorial tablet representing the fake individual. Still, many Taiwanese avoided attending the filming of the performance out of superstition, and the priest ritually cleansed the film crew with incense.\n\nShe did a one-woman show at the Collective Unconscious in downtown Manhattan in 2007 and at the Abrons Art Center the next year. She was included in the show \"Me Love You Long Time\" that travelled from Newark's Aljira Center for Contemporary Art to Mills Gallery at the Boston Center for the Arts in 2013.\n\nYoon is also a master storyteller who has presented at the American Museum of Natural History, Newark Museum, and the Korea Society. Currently she teaches and lectures at the Metropolitan Museum of Art and the Morgan Library & Museum in New York City.\n\nSmith College, Scripps College, Otis College of Art and Design, Museum of Modern Art, Temple University, Wellesley College's Book Art Collection, Haverford College, University of Melbourne Library, and private collections.\n\nShe lives and works in Tribeca in New York City.\n\n\n\n"}
{"id": "36076964", "url": "https://en.wikipedia.org/wiki?curid=36076964", "title": "Maternal sensitivity", "text": "Maternal sensitivity\n\nMaternal sensitivity is a mother's ability to perceive and infer the meaning behind her infant's behavioural signals, and to respond to them promptly and appropriately. Maternal sensitivity affects child development at all stages through life, from infancy, all the way to adulthood. In general, more sensitive mothers have healthier, more socially and cognitively developed children than those who are not as sensitive. Also, maternal sensitivity has been found to affect the person psychologically even as an adult. Adults who experienced high maternal sensitivity during their childhood were found to be more secure than those who experienced less sensitive mothers. Once the adult becomes a parent themselves, their own understanding of maternal sensitivity will affect their own children's development. Some research suggests that adult mothers display more maternal sensitivity than adolescent mothers who may in turn have children with a lower IQ and reading level than children of adult mothers.\n\nThere are different ways of assessing maternal sensitivity, such as through the use of naturalistic observation, the Strange Situation, maternal-synchrony, and maternal mind-mindedness. There are also a number of ways of measuring maternal sensitivity in the scientific world, which include Ainsworth's Maternal Sensitivity Scale (AMSS), the Maternal Behaviour Q-sort (MBQS), and the Pederson and Moran Sensitivity Q-Sort.\n\nMaternal sensitivity was first defined by Mary Ainsworth as \"a mother's ability to perceive and interpret accurately her infant's signals and communications and then respond appropriately\". It was later revised by Karl and Broom in 1995 as \"a mother's ability to recognize infant cues consistently and act on those cues, and the ability to monitor and accurately interpret infant cues, as evidenced by mother–child interactions that are contingent, reciprocal and affectively positive\". It can be generally defined as a broad concept combining a variety of behavioral care giving attributes.\n\nThe research on maternal sensitivity follows earlier work in psychoanalytics and is especially rooted in attachment theory. As the focus of psychoanalytics shifted from individuals (particularly adults) to children, research studies on mother–infant dyads, on the effects of early childhood on development, and on pregnancy became wider. A psychologist named John Bowlby eventually developed the attachment theory in 1969. Mary Ainsworth, who worked with Bowlby, along with her colleagues created the concept of maternal sensitivity in 1978 in order to describe early mother–infant interaction observed in her empirical studies.\n\nThere are four important aspects of maternal sensitivity: dynamic process involving maternal abilities, reciprocal give-and-take with the infant, contingency on the infant's behavior, and quality of maternal behaviors.\n\nMaternal sensitivity is dynamic, elastic and can change over time. A sensitive mother needs to be able to perceive the cues and signals her baby gives her, interpret them correctly and act appropriately. The three most positive affecting factors for the baby are a mother's social support, maternal–fetal attachment and high self-esteem. The three most negative affecting factors are maternal depression, maternal stress, and maternal anxiety. Recent studies have shown that maternal posttraumatic stress disorder (PTSD) can negatively impact a mother's sensitivity during stressful moments with her child that serve as traumatic reminders and that this quite likely has a neural basis in the maternal brain.\n\nMaternal sensitivity is most commonly assessed during naturalistic observation of free play interactions between mother and child. There are several factors surrounding assessment during observation that may cause differences in results, including the setting (home vs laboratory), the context (free play vs structured task), the length of observation and the frequency of observation. While some observational studies focus strictly on the relationship between mother and child during close interaction such as feeding or free play, other studies look into how well the maternal figure divides her attention between the baby and other everyday activities. The latter was demonstrated in an experiment conducted by Atkinson et al. where mothers were given a questionnaire to act as a \"distractor task\", and were assessed on their ability to effectively divide their attention between the \"distractor task\" and their child. In regards to length of observation, some studies require no more than a one-time 10-minute assessment, while other studies used a much lengthier time.\n\nThe Strange Situation was developed by Mary Ainsworth in the 1970s to assess attachment relationships between caregivers and children between 9 and 18 months old. Because maternal sensitivity is an indicator of attachment relationship, researchers sometimes use the Strange Situation to observe attachment so that they may use the results to predict and infer the level of maternal sensitivity.\n\nIn the Strange Situation, the toddler's behavior and stress is observed during a 21-minute free-play session through a one-way glass window as the caregiver and strangers come into and leave the room. The specific sequence of events is as follows:\n\n\nThe children are observed and categorized into one of the four attachment patterns – secure attachment, anxious-ambivalent attachment, anxious-avoidant attachment, or disorganized attachment – based on the infant's separation anxiety, willingness to explore, stranger anxiety, and reunion behavior.\n\nTwo related qualitative concepts that are correlated with maternal sensitivity are \"mother–infant synchrony\" and \"maternal mind-mindedness\".\n\nIn mother–infant synchrony, the mother and infant's ability to change their own behaviour based on the other's response is taken into consideration. Infant affect (vocal and facial) and maternal stimulation (vocal and tactile) are good indicators of mother–infant synchrony. Zentall et al. found that infants' rhythm was stronger and interactions were led better at 5 months than at 3 months. According to the study, an infant's ability to send signals and a mother's ability to perceive them increase with synchrony over time. Studies have shown that mother–infant synchrony will result in the infant's development of self-control and other self-regulating behaviours later on in life.\n\nThe related concept of maternal mind-mindedness assesses the mother's ability to understand and verbalize the infant's mind: thoughts, desires, intentions and memories. Maternal mind-mindedness has been found to be related to some developmental results, such as attachment security. A caregiver's comment is deemed an \"appropriate\" mind-related comment if the comment was deemed to match the infant's behaviour by the independent coder, if the comment associated the infant's current activity to past activities, and/or if the comment encouraged the infant to go on with his or her intentions when the conversation paused. This correlates to high maternal mind-mindedness. If the caregiver assigns the wrong internal state to the baby's behaviour, if the comment about the current activity is not insufficiently associated with a past event, if the comment deters the infant from proceeding with the current activity, and/or if the comment is unclear, it is deemed a \"in-appropriate\" mind-related comment and correlates to low mind-mindedness.\n\nInfants whose mothers are more sensitive are more likely to display secure attachment relationships. Because the maternal figure is generally accessible and responsive to the infant's needs, the infant is able to form expectations of the mother's behaviour. Once expectations are met and the infant feels a consistency in the mother's sensitivity, the infant is able to find security in the maternal figure. Those infants whose mothers do not respond to the signals from their children or respond inappropriately to their children's cries for attention will form insecure and anxious attachments because the infants are unable to consistently depend on the maternal figures for predictable and safe responses.\n\nIn order for the infant to feel that the maternal figure is accessible and responsive, a certain amount of interaction must occur. Though the most research has been done on face-to-face interaction, studies have found that bodily interaction is also important in sensitivity and development. It is not how often the baby is held that reflects attachment, but \"how\" the baby is held and whether or not the baby desires to be held that matters in attachment development. Another factor that is important is sensitivity to the infant's feeding signals. There lies some controversy in whether infants who form insecure attachment relationships with their mothers do so because the mother is particularly insensitive to her child's needs or because of differences in their personality (i.e. their temperament) and due to life situations.\n\nThere is a crucial interplay between parenting and child characteristics such as health, temperament, development and cognition. The children with the most sensitive, consistent mothers are the ones who are generally most healthy, happy and well adapted.\n\nMaternal sensitivity even in the first few months of mother–child relationships are an important factor to health in childhood, especially with obesity. A study using data from the National Institute of Child Health and Human Development's Study of Early Child Care and Youth Development assessed mother–child interactions and categorized them in one of two groups: sensitive or insensitive. Their child's growth (height and weight) was monitored throughout their childhood, from 24 months all the way to grade six, and body mass index was calculated. As the children grew, the percentage of overweight or obese grew too. From 24 months the overall overweight-obese percentage was 15.58% and by grade six, 34.34% of the children were classified as overweight or obese. More interesting is the difference between the maternal sensitive group and the maternal insensitive group. The children with the sensitive mothers started out with an overweight-obese percentage of 14.96% (24 months) and ended the research with 29.54% (grade six). The children classified with insensitive mothers had an overweight-obese percentage of 16.16% at 24 months and 39.28% at grade six. This shows a significant correlation between the mother's sensitivity and the child's risk for overweight-obesity during their elementary years. This is very important for obesity prevention programs for children.\n\nCurrent studies have shown a correlation between maternal sensitivity or insensitivity, negative discipline and childhood aggression. An experiment sampling 117 mother–child pairs showed a unique relationship between the mother's sensitivity and the use of discipline and the child's temperament level. Observations (of the mother's sensitivity to the child's needs, the child's aggression and temperament level and the relationship between the two) were made when the children on average were 26.71 months old (range of 13.58 to 41.91 months). The data were collected again a year later. Results show a year later that negative discipline is correlated with child aggression, but only when that mother is insensitive.\n\nA study by Jay Belsky and R.M. Pasco Fearon tested the correlation between childhood development and the sensitivity of the mother. The hypotheses were:\nThe children were tested in five developmental categories: problem behavior, social competence, expressive\nlanguage, receptive language and school readiness. Results highly support the hypothesis (i.e. maternal sensitivity and childhood development are positively correlated.) This is an important issue as it shows how influential the early experience of a child affects their future development.\n\nMothers who were found to display higher sensitivity towards their children from preschool to first grade were found to have higher achieving children than those who displayed lower maternal sensitivity. The children of maternally sensitive mothers scored higher in math and phoneme knowledge than those who had a history of lower maternal sensitivity.\n\nMaternal sensitivity has been shown to teach infants attentional skills, which are necessary later in life for emotional control, and other more complex cognitive processes.\n\nIn families with more than one child (twins or triplets), it has been found that maternal sensitivity is lower, as there are more needs to be taken care of by the mother and less time to form a unique bond, which in turn results in decreased cognitive development in the infants (relative to if the child were raised alone). Furthermore, in the newborn period, women who displayed high maternal sensitivity had children who were able to regulate their emotions and who had higher symbolic and cognitive skills. In the case of the triplets, the child that received the least maternal sensitivity was the one that showed the poorest outcomes cognitively and had the most medical problems.\n\nMaternal sensitivity has been shown to have an effect on children's socialization skills. In particular, some research suggests that children of more sensitive caregivers have high levels of effortful (i.e. emotional and behavioural) control. Such control is proposed to have been fostered from the infancy stage when the a sensitive mother's quick and appropriate responses to the baby's distress teaches the baby to adjust his/her arousal. This speedy regulation of arousal is then adapted into childhood resulting in the ability to regulate emotion and behaviour well.\n\nCaregiver sensitivity has also been found to have a connection with empathy in children. Generally, securely attached children have been found to be more empathetic compared with insecurely attached children. The reasoning suggested for this result is that because securely attached children receive more empathy from caregivers during times that they themselves are distressed, they are more likely to show empathy in a situation where someone else is distressed.\n\nAdults' own understanding of maternal sensitivity affects their sensitivity towards their own children. Adults who had insensitive mothers during infancy were found to not be able to remember specific childhood events or their importance. They were not able to present an accurate description of their parents by use of memories, they were found to idealize experiences and are more likely to remember situations in which they were rejected. Adults who experienced higher maternal sensitivity during both infancy and adulthood were found to be less dismissive and more secure than those who did not. Adults who are preoccupied were found to also try to please their parents as they were young, and have a sense of anger towards them. About half of the adults who were found more preoccupied than others were found to have experienced divorce between their parents earlier in life, as well as other negative life events such as death of a parent or sexual abuse. These life events cause the security of attachment between mother and child to decrease as the mother's availability, as well as responsiveness may decrease, no matter the maternal sensitivity experienced prior to these events. Male adults were found to have experienced less maternal sensitivity earlier in life than females and were more likely to be classified as dismissive than females were.\n\nMaternal sensitivity has been found to be greater for adult mothers than for adolescent mothers. The level and quality of mind-mindedness, which refers to how prone the mother is to comment about the infant's mental activity during interaction, is higher in adult mothers, and has been related to greater maternal sensitivity. The comments made by adult mothers were found to be more positive than those made by adolescent mothers. Adolescent mothers used almost no positive comments, but instead negative comments. This causes the adolescent mother to be more insensitive to their baby's needs, possibly because of lack of need understanding, and therefore have lower maternal sensitivity and a less secure attachment to their infants.\n\nMaternal sensitivity in adolescent mothers can be predicted prenatally. Mothers who talked lively and positively about their future relationship with the child were found to display higher maternal sensitivity than those who did not (classified as autonomous mothers). Autonomous mothers were also found to have infants with a more secure attachment. Adolescent mothers who were not classified as autonomous were found to have anxiously attached infants. Furthermore, adolescent mothers were found to have children four–eight years old with lower IQs and a below-average reading level, than did adult mothers.\n\nAlthough adolescent mothers have been found to display lower maternal sensitivity, there is no evidence that maternal age itself has a negative effect on child development, as other factors at that age such as education and financial status may play a role in the insensitivity of the mother towards the child as well.\n\nMary Ainsworth developed Ainsworth's Maternal Sensitivity Scale (AMSS) to use as a measure in her Baltimore longitudinal study (1963). The scale is based on naturalistic observations completed by Ainsworth over a period of several hours and thus has no short procedure outline. Her method uses a nine-point scale (nine being very high and one being very low) in a number of important maternal traits. In order for this measurement to be accurate, it is essential that the researcher has developed good observations and insight into the behaviour of the caregiver.\n\n\nMaternal Behaviour Q-sort (MBQS) was developed by David Pederson, Greg Moran and Sandi Bento to measure maternal sensitivity. It has been used to measure a variety of studies including home based and video-recorded observations. The measures are defined using q-factor analyses. The standard version of the Q-sort consists of 90 items that measure maternal sensitivity with regards to accessibility, responsiveness and promptness to the child's needs and there are many variations. In order to measure sensitivity, observers sort the items into nine piles of ten based on correspondence between the observed behaviour and the item. The maternal sensitivity score is calculated by comparing the descriptive sort and the criterion sort (prototypical sensitive mother). Pederson and Moran based their Q-sort on the Waters Attachment Q-Set, which is an assessment of the behavior of children.\n\nThe Pederson and Moran Sensitivity Q-Sort was developed by Pederson D.R., Moran G., Sitko C., Campbell K., and Ghesquire K. in 1990. Similar to Ainsworth's Maternal Sensitivity Scales, the Pederson and Moran Sensitivity Q-Sort was designed to detect changes in maternal sensitivity with relation to infant behaviour.\n\nThe Atypical Maternal Behavior Instrument for Assessment and Classification (AMBIANCE) scale was developed by Elisa Bronfman, Elizabeth Parsons and Karlen Lyons-Ruth. It was developed to measure the extent to which the parent failed to follow into the intentional or affective direction of the baby’s communications by engaging in contradictory responses to infant cues or failing to respond to infant cues altogether. AMBIANCE has the following five dimensions:\n"}
{"id": "30858327", "url": "https://en.wikipedia.org/wiki?curid=30858327", "title": "Name of the Father", "text": "Name of the Father\n\nThe name of the father (French ) is a concept that Jacques Lacan developed from his seminar \"The Psychoses\" (1955–1956) to cover the role of the father in the Symbolic Order. \n\nLacan plays with the similar sounds in French of ' (the name of the father), ' (the no of the father), and \"\" (the non-dupes err) to emphasize with the first two phrases the legislative and prohibitive functions of the father and to emphasize with the last phrase that \"those who do not let themselves be caught in the symbolic deception/fiction and continue to believe their eyes are the ones who err most\".\n\nLacan's concept draws on the mythical father of Freud's \"Totem and Taboo\"; and was used by him as a strategic move in his opposition to what he saw as the over-emphasis of object relations theory on the exclusive relationship of the individual and his/her mother as a dual pair. \n\nLacan emphasised instead the importance of the third party in the Oedipus complex – what he called \"the place that she [the mother] reserves for the Name-of-the Father in the promulgation of the law\". He saw this as a vital element in helping each new member of the human race to move from an exclusive, primary relation to the mother[er] to a wider engagement with the outside, cultural world – the symbolic order.\n\nAnthony Stevens has similarly argued that \"Traditionally, the father's orientation is centrifugal, i. e., towards the outside world...his is the primary responsibility for facilitating the transition from home to society'. Likewise the family therapist Robin Skynner sees the father (or fatherer) playing an essential role in the process whereby \"the toddler has got to see that Mum isn't God as a first step to seeing that Dad isn't God, and that...\"he's\" part of something bigger too\". \n\nFor Lacan, that bigger context could be seen as \"the chain of discourse...in which an entire family, an entire coterie, an entire camp, an entire nation or half the world will be caught\". The internalisation of the Name of the Father with the passing of the Oedipus complex ensured for Lacan participation in that wider chain of discourse, and was for him an essential element of human sanity.\n\nLacan distinguishes between the Symbolic, the Imaginary and the Real father: \"It is in the \"name of the father\" that we must recognise the support of the symbolic function which, from the dawn of history, has identified his person with the figure of the law\" – as distinct from \"the narcissistic relations, or even from the real relations, which the subject sustains with the image and action of the person who embodies it\". This paternal function imposes the law and regulates desire in the Oedipus complex, intervening in the imaginary dual relationship between mother and child to introduce a necessary symbolic distance between them (Dylan Evans). 'The true function of the Father is fundamentally to unite (and not to set in opposition) a desire and the Law' (Écrits), and the Symbolic Father is thus not an actual subject but a position in the Symbolic Order.\n\nBy contrast the Imaginary Father is an imago, the composite of all the imaginary constructs that the subject builds up in fantasy around the figure of the father; and may be construed either as an ideal father or as the opposite, the bad father – what Slavoj Zizek referred to as \"the \"reverse\" of the father, the \"anal father\" who lurks behind the Name-of-the-Father \"qua\" bearer of the symbolic law\". \n\nAs to the real father, Lacan stresses how \"the ravaging effects of the paternal figure are to be observed with particular frequency in cases where the father really has the function of a legislator...with too many opportunities of being in a position of undeserving, inadequacy, even of fraud, and, in short, of excluding the Name-of-the-Father from its position in the signifier\".\n\nPsychosis for Lacanians is the exact opposite of the Name of the Father – the absence of that identification with the symbolic order which ensures our place in the shared intersubjective world of common sense. The Name-of-the-Father is thus the fundamental signifier which permits signification to proceed normally. It not only confers identity and position on the subject within the symbolic order, but also signifies the Oedipal prohibition (the \"no\" of the incest taboo). \n\nIf this signifier is foreclosed, in the sense of being excluded from the Symbolic Order, the result is psychosis. Psychotics have not been properly separated from their mother[er] by the fixed name-of-the-father, and hence relate to speech and language differently from neurotics.\n\nIn \"On a Question Preliminary to Any Possible Treatment of Psychosis\" (1957), Lacan represents the Oedipus complex as \"the metaphor of the Name-of-the-Father, that is, the metaphor that substitutes this Name in the place first symbolized by the operation of the absence of the mother\". All paternity thus involves metaphoric substitution. \n\nLacan originally presents the 'paternal metaphor' in his Seminar \"La relation d'objet\" (1956–1957): it is the fundamental metaphor on which all signification depends (all signification is phallic). If the Name-of-the-Father is foreclosed, as in psychosis, there can be no paternal metaphor and hence no phallic signification.\n\nIn his late seminars, Lacan downplayed the hitherto central importance of the Name-of-the-Father and the Oedipus complex as well, considering them either irrelevant or misleading in terms of his then-current concerns.\n\n\n"}
{"id": "565176", "url": "https://en.wikipedia.org/wiki?curid=565176", "title": "Narration", "text": "Narration\n\nNarration is the use of a written or spoken commentary to convey a story to an audience. Narration encompasses a set of techniques through which the creator of the story presents their story, including:\n\nA \"narrator\" is a personal character or a non-personal voice that the creator (author) of the story develops to deliver information to the audience, particularly about the plot. In the case of most written narratives (novels, short stories, poems, etc.), the narrator typically functions to convey the story in its entirety. The narrator may be a voice devised by the author as an anonymous, non-personal, or stand-alone entity; as the author as a character; or as some other fictional or non-fictional character appearing and participating within their own story. The narrator is considered \"participant\" if he/she is a character within the story, and \"non-participant\" if he/she is an implied character or an omniscient or semi-omniscient being or voice that merely relates the story to the audience without being involved in the actual events. Some stories have multiple narrators to illustrate the storylines of various characters at the same, similar, or different times, thus allowing a more complex, non-singular point of view.\n\nNarration encompasses not only \"who\" tells the story, but also \"how\" the story is told (for example, by using stream of consciousness or unreliable narration). In traditional literary narratives (such as novels, short stories, and memoirs), narration is a required story element; in other types of (chiefly non-literary) narratives, such as plays, television shows, video games, and films, narration is merely optional.\n\nNarrative point of view or narrative perspective describes the position of the narrator, that is, the character of the storyteller, in relation to the story being told. It can be thought of as a camera mounted on the narrator's shoulder that can also look back inside the narrator's mind.\n\nWith the \"first-person\" point of view, a story is revealed through a narrator who is also explicitly a character within his or her own story. In a first person narrative, the narrator can create a close relationship between the reader and the writer. Therefore, the narrator reveals the plot by referring to this viewpoint character with forms of \"I\" (that is, the narrator is a person who openly acknowledges his or her own existence) or, when part of a larger group, \"we\". Frequently, the narrator is the protagonist, whose inner thoughts are expressed to the audience, even if not to any of the other characters. A conscious narrator, as a human participant of past events, is an incomplete witness by definition, unable to fully see and comprehend events in their entirety as they unfurl, not necessarily objective in their inner thoughts or sharing them fully, and furthermore may be pursuing some hidden agenda. Forms include temporary first-person narration as a story within a story, wherein a narrator or character observing the telling of a story by another is reproduced in full, temporarily and without interruption shifting narration to the speaker. The first-person narrator can also be the focal character.\n\nThe \"second-person\" point of view is a point of view where the audience is made a character. This is done with the use of the pronouns \"you\", \"your\", and \"yours.\" The narrator is trying to address the audience, not necessarily directly, but rather to administer more of a connection. Stories and novels in second person are comparatively rare. Examples include the short fiction of Lorrie Moore and Junot Díaz. An example in contemporary literature is Jay McInerney's \"Bright Lights, Big City,\" in which the second-person narrator is observing his life from a distance as a way to cope with a trauma he keeps hidden from readers for most of the book.\n\"You are not the kind of guy who would be at a place like this at this time of the morning. But here you are, and you cannot say that the terrain is entirely unfamiliar, although the details are fuzzy.\"—Opening lines of Jay McInerney's \"Bright Lights, Big City\" (1984)\n\nIn the \"third-person\" narrative mode, characters are referred to by the narrator as \"he\", \"she\", or \"they\", but never as \"I\" or \"we\" (first-person), or \"you\" (second-person). This makes it clear that the narrator is an unspecified entity or uninvolved person who conveys the story and is not a character of any kind within the story, or at least is not referred to as such.\n\nTraditionally, third-person narration is the most commonly used narrative mode in literature. It does not require that the narrator's existence be explained or developed as a particular character, as with a first-person narrator. It thus allows a story to be told without detailing any information about the teller (narrator) of the story. Instead, a third-person narrator is often simply some disembodied \"commentary\" or \"voice\", rather than a fully developed character. Sometimes, third-person narration is called the \"he/she\" perspective.\n\nThe third-person modes are usually categorized along two axes. The first is the subjectivity/objectivity axis, with \"third person subjective\" narration describing one or more character's personal feelings and thoughts, and \"third person objective\" narration not describing the feelings or thoughts of any characters but, rather, just the exact facts of the story. The second axis is the omniscient/limited axis, a distinction that refers to the knowledge held by the narrator. A \"third person omniscient\" narrator has, or seems to have, access to knowledge of all characters, places, and events of the story, including any given characters' thoughts; however, a \"third person limited \" narrator, in contrast, knows information about, and within the minds of, only a limited number of characters (often just one character). A limited narrator cannot describe anything outside of a focal character's particular knowledge and experiences.\n\nWhile the tendency for novels (or other narrative works) is to adopt a single point of view throughout the entire novel, some authors have experimented with other points of view that, for example, alternate between different narrators who are all first-person, or alternate between a first- and a third-person narrative perspective. The ten books of the \"\" adventure series, by D. J. MacHale, switch back and forth between a first-person perspective (handwritten journal entries) of the main character along his journey and the disembodied third-person perspective of his friends back home. Margaret Atwood's \"Alias Grace\" provides one character's viewpoint from first-person as well as another character's from third-person limited. Often, a narrator using the first person will try to be more objective by also employing the third person for important action scenes, especially those in which they are not directly involved or in scenes where they are not present to have viewed the events in firsthand. This mode is found in Barbara Kingsolver's \"The Poisonwood Bible\".\n\nAudrey Niffenegger's \"The Time Traveler's Wife\" is a love story, told in alternating first person. This novel alternates between an art student named Clare, and a librarian named Henry. Henry’s disorder called Chronic-Displacement causes him to be put in the wrong time. He is then put in emotional parts from his past and future, going back and forth in time. John Green & David Levithan's novel \"Will Grayson, Will Grayson\" rotates between two boys both named Will Grayson. It alternates between both boys telling their part of the story, how they meet and how their lives then come together. Nick Hornby's \"A Long Way Down\" has four narrators who also, are its main characters. These four characters meet at the top of a tall building known as “the suicide spot” and begin to talk instead of jumping. They then form a group, and continue to meet up.\n\nThe narrative voice is essential for story telling, because it's setting up the story for the reader, for example, by \"viewing\" a character's thought processes, reading a letter written for someone, retelling a character's experiences, etc.\n\nA \"stream of consciousness\" gives the (typically first-person) narrator's perspective by attempting to replicate the thought processes—as opposed to simply the actions and spoken words—of the narrative character. Often, interior monologues and inner desires or motivations, as well as pieces of incomplete thoughts, are expressed to the audience but not necessarily to other characters. Examples include the multiple narrators' feelings in William Faulkner's \"The Sound and the Fury\" and \"As I Lay Dying\", and the character Offred's often fragmented thoughts in Margaret Atwood's \"The Handmaid's Tale\". Irish writer James Joyce exemplifies this style in his novel \"Ulysses\".\n\nOne of the most common narrative voices, used especially with first- and third-person viewpoints, is the \"character voice\", in which a conscious \"person\" (in most cases, a living human being) is presented as the narrator; this character is called a \"viewpoint character\". In this situation, the narrator is no longer an unspecified entity; rather, the narrator is a more relatable, realistic character who may or may not be involved in the actions of the story and who may or may not take a biased approach in the storytelling. If the character is directly involved in the plot, this narrator is also called the viewpoint character. The viewpoint character is not necessarily the focal character: examples of supporting viewpoint characters include Doctor Watson, Scout in \"To Kill a Mockingbird\", and Nick Carraway of \"The Great Gatsby\".\n\nThe unreliable narrative voice involves the use of an untrustworthy narrator. This mode may be employed to give the audience a deliberate sense of disbelief in the story or a level of suspicion or mystery as to what information is meant to be true and what is meant to be false. The narrator of Poe's \"The Tell-Tale Heart,\" for example, is significantly biased, unknowledgeable, ignorant, childish, or is perhaps purposefully trying to deceive the audience. Unreliable narrators are usually first-person narrators; however, a third-person narrator may be unreliable.\n\nThe \"epistolary narrative voice\" uses a (usually fictional) series of letters and other documents to convey the plot of the story. Although epistolary works can be considered multiple-person narratives, they also can be classified separately, as they arguably have no narrator at all—just an author who has gathered the documents together in one place. One example is Mary Shelley's \"Frankenstein,\" which is a story written in a sequence of letters. Another is Bram Stoker's \"Dracula\", which tells the story in a series of diary entries, letters and newspaper clippings. \"Les Liaisons dangereuses (Dangerous Liaisons), \"by Pierre Choderlos de Laclos, is again made up of the correspondence between the main characters, most notably the Marquise de Merteuil and the Vicomte de Valmont. Langston Hughes does the same thing in a shorter form in his story \"Passing\", which consists of a young man's letter to his mother.\n\nThe third-person narrative voices are narrative-voice techniques employed solely under the category of the third-person view.\n\nHistorically, the \"third-person omniscient\" (or simply \"omniscient\") perspective has been the most commonly used in narrative writing; it is seen in countless classic novels, including works by Charles Dickens, Leo Tolstoy, and George Eliot. A story in this narrative mode is presented by a narrator with an overarching point of view, seeing and knowing everything that happens within the world of the story, including what each of the characters is thinking and feeling. It sometimes even takes a subjective approach. One advantage of omniscience is that this mode enhances the sense of objective reliability (that is, truthfulness) of the plot. The third-person omniscient narrator is the least capable of being unreliable – although the character of omniscient narrator can have its own personality, offering judgments and opinions on the behavior of the story characters.\n\nIn addition to reinforcing the sense of the narrator as reliable (and thus of the story as true), the main advantage of this mode is that it is eminently suited to telling huge, sweeping, epic stories, and/or complicated stories involving numerous characters. The disadvantage of this mode is the increased distance between the audience and the story, and the fact that – when used in conjunction with a sweeping, epic \"cast-of-thousands\" story – characterization tends to be limited, thus reducing the reader's ability to identify with or sympathize with the characters. A classic example of both the advantages and disadvantages of this mode is J. R. R. Tolkien's \"The Lord of the Rings\".\n\nThe \"third-person subjective\" is when the narrator conveys the thoughts, feelings, and opinions of one or more characters. If there is just one character, it can be termed \"third-person limited\", in which the reader is \"limited\" to the thoughts of some particular character (often the protagonist) as in the first-person mode, except still giving personal descriptions using \"he\", \"she\", \"it\", and \"they\", but not \"I\". This is almost always the main character (for example, Gabriel in James Joyce's \"The Dead\", Nathaniel Hawthorne's \"Young Goodman Brown\", or Santiago in Hemingway's \"The Old Man and the Sea\"). Certain third-person omniscient modes are also classifiable as \"third person, subjective\" modes that switch between the thoughts and feelings of all the characters.\n\nThis style, in both its limited and omniscient variants, became the most popular narrative perspective during the 20th century. In contrast to the broad, sweeping perspectives seen in many 19th-century novels, third-person subjective is sometimes called the \"over the shoulder\" perspective; the narrator only describes events perceived and information known by a character. At its narrowest and most subjective scope, the story reads as though the viewpoint character were narrating it; dramatically this is very similar to the first person, in that it allows in-depth revelation of the protagonist's personality, but it uses third-person grammar. Some writers will shift perspective from one viewpoint character to another, such as in Robert Jordan's \"The Wheel of Time\", or George R. R. Martin's \"A Song of Ice and Fire\".\n\nThe focal character, protagonist, antagonist, or some other character's thoughts are revealed through the narrator. The reader learns the events of the narrative through the perceptions of the chosen character.\n\nThe \"third-person objective\" employs a narrator who tells a story without describing any character's thoughts, opinions, or feelings; instead, it gives an objective, unbiased point of view. Often the narrator is self-dehumanized in order to make the narrative more neutral. This type of narrative mode, outside of fiction, is often employed by newspaper articles, biographical documents, and scientific journals. This narrative mode can be described as a \"fly-on-the-wall\" or \"camera lens\" approach that can only record the observable actions but does not interpret these actions or relay what thoughts are going through the minds of the characters. Works of fiction that use this style emphasize characters acting out their feelings observably. Internal thoughts, if expressed, are given voice through an aside or soliloquy. While this approach does not allow the author to reveal the unexpressed thoughts and feelings of the characters, it does allow the author to reveal information that not all or any of the characters may be aware of. A typical example of this so-called \"camera-eye perspective\" is \"Hills Like White Elephants\" by Ernest Hemingway.\n\nThis narrative mode is also called the \"third-person dramatic\" because the narrator, like the audience of a drama, is neutral and ineffective toward the progression of the plot—merely an uninvolved onlooker. It was also used around the mid-20th century by French novelists writing in the \"nouveau roman\" tradition.\n\nThe third person indirect style or free indirect style is a method of presenting a character's voice freely and spontaneously in the middle of an otherwise third-person non-personal narrator.\n\nMany stories, especially in literature, alternate between the third person limited and third person omniscient. In this case, an author will move back and forth between a more omniscient third-person narrator to a more personal third-person limited narrator. Typically, like the \"A Song of Ice and Fire\" series and the books by George R. R. Martin, a switch of third-person limited viewpoint on some character is done only at chapter boundaries. \"The Home and the World\", written in 1916 by Rabindranath Tagore, is another example of a book switching among just three characters at chapter boundaries. In \"The Heroes of Olympus\" series the point of view changes between characters at intervals.The \"Harry Potter\" series is told in \"third person limited\" (in which the reader is \"limited\" to the thoughts of some particular character) for much of the seven novels. However, it deviates to omniscient on occasions, particularly during the opening chapters of later novels in the series, which switch from the limited view of the eponymous Harry to other characters (for example, Snape).\n\nThe \"narrative tense\" or \"narrative time\" determines the grammatical tense of the story, meaning whether it is presented as occurring before, during, or after the time of narration, that is, in the past, present, or future. In narration using the past tense, the events of the plot are depicted as occurring before the time at which the narrative was constructed or expressed to an audience or before the present moment; this is by far the most common tense in which stories are expressed. In the present tense, the events of the plot are depicted as occurring now—at the current moment—in real time. In English, this tense, also known as the \"historical present\", is more common in spontaneous conversational narratives than in written literature, though it is sometimes used in literature to give a sense of immediacy of the actions. A recent example of novels narrated in the present tense are those of the \"Hunger Games\" trilogy by Suzanne Collins. The future tense is the most rare, portraying the events of the plot as occurring some time after the present moment, in a time-period yet to come. Often, these upcoming events are described such that the narrator has foreknowledge (or supposed foreknowledge) of the future, so many future-tense stories have a prophetic tone.\n\n\"Narration\" has more than one meaning. In its broadest sense, narration encompasses all forms of storytelling, fictional or not: personal anecdotes, \"true crime\", and historical narratives all fit here, along with many other non-fiction forms. More narrowly, however, the term \"narration\" refers to all written fiction. In its most restricted sense, narration is the fiction-writing mode whereby the narrator communicates directly to the reader.\n\nAlong with exposition, argumentation, and description, narration (broadly defined) is one of four rhetorical modes of discourse. In the context of rhetorical modes, the purpose of narration is to tell a story or to narrate an event or series of events. Narrative may exist in a variety of forms: biographies, anecdotes, short stories, or novels. In this context, all written fiction may be viewed as narration.\n\nNarrowly defined, narration is the fiction-writing mode whereby the narrator is communicating directly to the reader. But if the broad definition of narration includes all written fiction, and the narrow definition is limited merely to that which is directly communicated to the reader, then what comprises the rest of written fiction? The remainder of written fiction would be in the form of any of the other fiction-writing modes. Narration, as a fiction-writing mode, is a matter for discussion among fiction writers and writing coaches.\n\nThe ability to use the different points of view is one measure of a person's writing skill. The writing mark schemes used for National Curriculum assessments in England reflect this: they encourage the awarding of marks for the use of viewpoint as part of a wider judgment.\n\nIn literature, \"person\" is used to describe the viewpoint from which the narrative is presented. Although second-person perspectives are occasionally used, the most commonly encountered are first and third person. \"Third person omniscient\" specifies a viewpoint in which readers are provided with information not available to characters within the story; without this qualifier, readers may or may not have such information.\n\nIn movies and video games first- and third-person describe camera viewpoints. The first-person is from a character's own perspective, and the third-person is the more familiar, \"general\" camera showing a scene. A so-called second-person may also be used to show a main character from a secondary character's perspective.\n\nFor example, in a horror film, the first-person perspective of an antagonist could become a second-person perspective on a potential victim's actions. A third-person shot of the two characters could be used to show the narrowing distance between them.\n\nIn video games, a first-person perspective is used most often in the first-person shooter genre, such as in \"Doom\", or in simulations (racing games, flight simulation games, and such). Third-person perspectives on characters are typically used in all other games. Since the arrival of 3D computer graphics in games it is often possible for the player to switch between first- and third-person perspectives at will; this is usually done to improve spatial awareness, but can also improve the accuracy of weapons use in generally third-person games such as the \"Metal Gear Solid\" franchise.\n\nText-based interactive fiction conventionally has descriptions written in the second person (though exceptions exist), telling the character what they are seeing and doing, such as Zork. This practice is also encountered occasionally in text-based segments of graphical games, such as those from Spiderweb Software which make ample use of second person flavor text in pop up text boxes with character and location descriptions. Charles Stross's novel Halting State was written in second person as an allusion to this style.\n\n\n"}
{"id": "407044", "url": "https://en.wikipedia.org/wiki?curid=407044", "title": "Negative (photography)", "text": "Negative (photography)\n\nIn photography, a negative is an image, usually on a strip or sheet of transparent plastic film, in which the lightest areas of the photographed subject appear darkest and the darkest areas appear lightest. This reversed order occurs because the extremely light-sensitive chemicals a camera film must use to capture an image quickly enough for ordinary picture-taking are darkened, rather than bleached, by exposure to light and subsequent photographic processing.\n\nIn the case of color negatives, the colors are also reversed into their respective complementary colors. Typical color negatives have an overall dull orange tint due to an automatic color-masking feature that ultimately results in improved color reproduction.\n\nNegatives are normally used to make positive prints on photographic paper by projecting the negative onto the paper with a photographic enlarger or making a contact print. The paper is also darkened in proportion to its exposure to light, so a second reversal results which restores light and dark to their normal order.\n\nNegatives were once commonly made on a thin sheet of glass rather than a plastic film, and some of the earliest negatives were made on paper.\n\nIt is incorrect to call an image a negative solely because it is on a transparent material. Transparent prints can be made by printing a negative onto special positive film, as is done to make traditional motion picture film prints for use in theaters. Some films used in cameras are designed to be developed by reversal processing, which produces the final positive, instead of a negative, on the original film. Positives on film or glass are known as transparencies or diapositives, and if mounted in small frames designed for use in a slide projector or magnifying viewer they are commonly called slides.\n\nA positive image is a normal image. A negative image is a total inversion, in which light areas appear dark and vice versa. A negative color image is additionally color-reversed, with red areas appearing cyan, greens appearing magenta, and blues appearing yellow, and vice versa.\n\nFilm negatives usually have less contrast, but a wider dynamic range, than the final printed positive images. The contrast typically increases when they are printed onto photographic paper. When negative film images are brought into the digital realm, their contrast may be adjusted at the time of scanning or, more usually, during subsequent post-processing.\n\nFilm for cameras that use the 35 mm still format is sold as a long strip of emulsion-coated and perforated plastic spooled in a light-tight cassette. Before each exposure, a mechanism inside the camera is used to pull an unexposed area of the strip out of the cassette and into position behind the camera lens. When all exposures have been made the strip is rewound into the cassette. After the film is chemically developed, the strip shows a series of small negative images. It is usually then cut into sections for easier handling. Medium format cameras use 120 film, which yields a strip of negatives 60 mm wide, and large format cameras capture each image on a single sheet of film which may be as large as 20 x 25 cm (8 x 10 inches) or even larger. Each of these photographed images may be referred to as a negative and an entire strip or set of images may be collectively referred to as \"the negatives\". They are the master images, from which all positive prints will derive, so they are handled and stored with special care.\n\nMany photographic processes create negative images: the chemicals involved react when exposed to light, so that during development they produce deposits of microscopic dark silver particles or colored dyes in proportion to the amount of exposure. However, when a negative image is created from a negative image (just like multiplying two negative numbers in mathematics) a positive image results. This makes most chemical-based photography a two-step process, which uses negative film and ordinary processing. Special films and development processes have been devised so that positive images can be created directly on the film; these are called positive, or slide, or (perhaps confusingly) reversal films and reversal processing.\n\nDespite the market's evolution away from film, there is still a desire and market for products which allow fine art photographers to produce negatives from digital images for their use in alternative processes such as cyanotypes, gum bichromate, platinum prints, and many others.\n\n"}
{"id": "7108905", "url": "https://en.wikipedia.org/wiki?curid=7108905", "title": "Negative return (finance)", "text": "Negative return (finance)\n\nThe term negative return is used in business or finance to describe a loss, i.e., a negative return on investment. By extension the term is also used for a project that is not worthwhile, even in a non-economic sense.\n"}
{"id": "669692", "url": "https://en.wikipedia.org/wiki?curid=669692", "title": "Nulle terre sans seigneur", "text": "Nulle terre sans seigneur\n\nIn feudal law, Nulle terre sans seigneur is the principle that one provides services to the sovereign (usually serving in his army) for the right to receive land from the sovereign. Originally a maxim of feudal law, it applies in modern form to paying rates or land tax for land of former feudal or feudal-like origin such as land with modern fee simple title, as opposed to land with allodial or udal title.\n\nIn the original French the expression means \"No land without a lord\" though the legal sense might be more akin to \"no property without a liege\" since it was at the basis of the link between the infeodated or feal and his liege, in the feudal system.\n\n"}
{"id": "2620499", "url": "https://en.wikipedia.org/wiki?curid=2620499", "title": "Obsolete German units of measurement", "text": "Obsolete German units of measurement\n\nThe obsolete units of measurement of German-speaking countries consist of a variety of units, with varying local standard definitions. Some of these units are still used in everyday speech and even in stores and on street markets as shorthand for similar amounts in the metric system. For example, some customers ask for one pound (\"ein Pfund\") of something when they want 500 grams.\n\nThe metric system became compulsory on 1 January 1872, in Germany and on 1 January 1876, in Austria.\n\nSome obsolete German units have names similar to units that were traditionally used in other countries, and that are still used in the United Kingdom (imperial units) and the United States (United States customary units).\n\nBefore the introduction of the metric system in German, almost every town had its own definitions of the units shown below. Often towns posted local definitions on a wall of the city hall. For example, the front wall of the old city hall of Rudolstädt (still standing) has two marks which show the \"Rudolstädter Elle\", the proper length of the Elle in that city. Supposedly by 1810 there were 112 different standards for the Elle around Germany. \n\nA German geographic mile (\"geographische Meile\") is defined as equatorial degrees, equal to . A common German mile, land mile, or post mile (\"Gemeine deutsche Meile\", \"Landmeile\", \"Postmeile\") was defined in various ways at different places and different times. After the introduction of the metric system in the 19th century, the \"Landmeile\" was generally fixed at (the \"Reichsmeile\"), but before then there were many local and regional variants (of which some are shown below): \n\nThe Rute or \"Ruthe\" is of Carolingian origin, and was used as a land measure. Many different kinds of Ruthe were used at various times in various parts of the German-speaking world. They were subdivided into differing numbers of local Fuß, and were of many different lengths. One source from 1830 lists the following:\nOne hour's travel, used up to the 19th century. In Germany  Meile or . After 1722 in Saxony  post mile = 1000 Dresden rods = 4531 m. In Switzerland .\n\nOriginally 6 feet, after introduction of the metric system 10 feet. Regional variants from in Baden to in Switzerland.\n\nThe \"Lachter\" was the most common unit of length used in mining in German-speaking areas. Its exact length varied from place to place but was roughly between .\n\nDistance between elbow and fingertip. In the North, often 2 feet, In Prussia  feet, in the South variable, often  feet. The smallest known German \"Elle\" is , the longest .\n\nThe Fuß or German foot varied widely from place to place in the German-speaking world, and also with time. In some places, more than one type of Fuß was in use. One source from 1830 gives the following values:\n\nUsually foot, but also and .\n\nUsually  inch, but also .\n\nFor firewood, \n\nIn general, the \"Nösel\" (also spelled \"Össel\") was a measure of liquid volume equal to half a \"Kanne\" (\"jar,\" \"jug,\" \"bottle,\" \"can\"). Volume often varied depending on whether it was beer or wine. Its subdivisions were the \"Halbnösel\" (\"Half-Nösel\") and the \"Viertelnösel\" (\"Quarter-Nösel). \n\nActual volumes so measured, however, varied from one state or even one city to another. Within Saxony, for example, the \"Dresden jar\" held approximately , so a nösel in Dresden was about . The full volume of a \"Leipzig jar\" measured ; the Leipzig nösel was therefore .\n\nThe nösel was used in minor commerce, as well as in the household to measure meal, grain, and such. These units of measure were officially valid in Saxony until 1868, when the metric system was introduced. Nevertheless, the old measures have continued in private use for decades.\n\nOne interesting modification was introduced in Thuringia. There, the nösel was, by extension, also a measure of area; namely, the area of land which could be sown with one nösel of seed — or about \n\n\n\n"}
{"id": "53729379", "url": "https://en.wikipedia.org/wiki?curid=53729379", "title": "Ophelia complex", "text": "Ophelia complex\n\nOphelia complex is the term used by Gaston Bachelard to refer to the links between femininity, liquids, and drowning which he saw as symbolised in the fate of Shakespeare's Ophelia.\n\nBachelard traced in Romanticism a nexus of ideas linking the dissolution of the self - male or female - with immersion in the feminine element of water, as symbolised by Ophelia's drowning.\n\nFederico García Lorca explored the image of water and a despairing sexuality, epitomised in the Ophelia complex, throughout his writings.\n\nA later, and unconnected use of the terms Ophelia complex/Ophelia syndrome was introduced by Mary Pipher in her \"Reviving Ophelia\" of 1994. There she argued for a view of Shakespeare's character as lacking inner direction, and externally defined by men (father/ brother); and suggested that similar external pressures were currently faced by post-pubescent girls. The danger of the Ophelia syndrome was that of abandoning a rooted childhood self, for an apparently more sophisticated but over-externalised facade self.\n\nG. Bachelard, \"L'Eau et les reves\" (Paris 1942)\n\n"}
{"id": "7260569", "url": "https://en.wikipedia.org/wiki?curid=7260569", "title": "Outline of thought", "text": "Outline of thought\n\nThe following outline is provided as an overview of and topical guide to thought (thinking):\n\nThought (also called thinking) – the mental process in which beings form psychological associations and models of the world. Thinking is manipulating information, as when we form concepts, engage in problem solving, reason and make decisions. Thought, the act of thinking, produces thoughts. A thought may be an idea, an image, a sound or even an emotional feeling that arises from the brain.\n\nThought (or thinking) can be described as all of the following:\n\n\nListed below are types of thought, also known as thinking processes.\n\nHuman thought\n\n\nEmotional intelligence\n\nProblem solving\n\nReasoning\n\nOrganizational thought (thinking by organizations)\n\n\nAspects of the thinker which may affect (help or hamper) his or her thinking:\n\n\nHistory of reasoning\n\nNootropic\nSubstances that improve mental performance:\n\n\n\n\n\n\n\n\n\n\n\nMiscellaneous\n\nThinking \n\nLists\n\n"}
{"id": "21706476", "url": "https://en.wikipedia.org/wiki?curid=21706476", "title": "Polyphase sequence", "text": "Polyphase sequence\n\nIn mathematics, a polyphase sequence is a sequence whose terms are complex roots of unity:\n\nwhere \"x\" is an integer.\n\nPolyphase sequences are an important class of sequences and play important roles in synchronizing sequence design.\n\n"}
{"id": "26446075", "url": "https://en.wikipedia.org/wiki?curid=26446075", "title": "Post-convergent", "text": "Post-convergent\n\nVirtual worlds are an example of an early 21st-century post-convergent medium. Virtual worlds present a complex matrix of interdependent relationships among such media elements as sound, vision, network, time, interactivity, and other prior technologies. In this view, no individual media element comprising virtual worlds exists without the others and all affect each other, albeit not equally. Although this complex system contains many types of media, a user may choose to focus on only a single aspect, such as streaming an audio file. The potential for a rich engagement within and between agents within a medium that is best characterized as Gilles Deleuze’s network of relations between differential velocities that are not distinguished by form or functionality and Anna Munster’s differential relations between embodiment and technics, in which both artist/composer and user become nodes in this interdependent network, satisfying Luciano Floridi’s test of successful observability and backward and forward presence at different Levels of Abstraction.\n\n"}
{"id": "86368", "url": "https://en.wikipedia.org/wiki?curid=86368", "title": "Puzzle", "text": "Puzzle\n\nA puzzle is a game, problem, or toy that tests a person's ingenuity or knowledge. In a puzzle, the solver is expected to put pieces together in a logical way, in order to arrive at the correct or fun solution of the puzzle. There are different genres of puzzles, such as crossword puzzles, word-search puzzles, number puzzles, relational puzzles, or logic puzzles.\n\nPuzzles are often created to be a form of entertainment but they can also arise from serious mathematical or logistical problems. In such cases, their solution may be a significant contribution to mathematical research.\n\nThe 1989 edition of the \"Oxford English Dictionary\" dates the word \"puzzle\" (as a verb) to the end of the 16th century. Its first documented use (to describe a new type of game) was in a book titled \"The Voyage of Robert Dudley...to the West Indies, 1594–95, narrated by Capt. Wyatt, by himself, and by Abram Kendall, master\" (published circa 1595). The word later came to be used as a noun.\n\nThe word puzzle comes from \"pusle\", meaning \"bewilder, confound\", which is a frequentive of the obsolete verb \"pose\" (from Medieval French \"aposer\") in the sense of \"perplex\". The use of the word to mean \"a toy contrived to test one's ingenuity\" is relatively recent (within mid-19th century).\n\nPuzzles can be divided into categories. For example, a maze is a type of tour puzzle. Some other categories are construction puzzles, stick puzzles, tiling puzzles, disentanglement puzzles, lock puzzles, folding puzzles, combination puzzles, and mechanical puzzles.\n\n\nSolutions of puzzles often require the recognition of patterns and the adherence to a particular kind of ordering. People with a high level of inductive reasoning aptitude may be better at solving such puzzles than others. But puzzles based upon inquiry and discovery may be solved more easily by those with good deduction skills. Deductive reasoning improves with practice. Mathematical puzzles often involves BODMAS. BODMAS is an acronym and it stands for Bracket, Of, Division, Multiplication, Addition and Subtraction. In certain regions, PEDMAS (Parentheses, Exponents, Division, Multiplication, Addition and Subtraction) is the synonym of BODMAS. It explains the order of operations to solve an expression. Some mathematical puzzle requires Top to Bottom convention to avoid the ambiguity in the order of operations. It is an elegantly simple idea that relies, as sudoku does, on the requirement that numbers appear only once starting from top to bottom as coming along. \n\nPuzzle makers are people who make puzzles.\n\nSome notable creators of puzzles are:\n\n\nJigsaw puzzles are perhaps the most popular form of puzzle. Jigsaw puzzles were invented around 1760, when John Spilsbury, a British engraver and cartographer, mounted a map on a sheet of wood, which he then sawed around the outline of each individual country on the map. He then used the resulting pieces as an aid for the teaching of geography.\n\nAfter becoming popular among the public, this kind of teaching aid remained the primary use of jigsaw puzzles until about 1820.\n\nThe largest puzzle (40,320 pieces) is made by German game company Ravensburger. The smallest puzzle ever made was created at LaserZentrum Hannover. It is only five square millimetres, the size of a sand grain.\n\nBy the early 20th century, magazines and newspapers had found that they could increase their readership by publishing puzzle contests, beginning with crosswords and in modern days sudoku.\n\nThere are organizations and events that cater to puzzle enthusiasts, such as:\n\n\n\n"}
{"id": "1667068", "url": "https://en.wikipedia.org/wiki?curid=1667068", "title": "Ragging", "text": "Ragging\n\nRagging is the term used for the so-called \"initiation ritual\" practiced in higher education institutions in South Asian countries, including India, Bangladesh and Sri Lanka. The practice is similar to hazing in North America, bizutage in France, praxe in Portugal and other similar practices in educational institutions across the world. Ragging involves abuse, humiliation or harassment of new entrants or junior students by their seniors. It often takes a malignant form wherein the newcomers may be subjected to psychological or physical torture.\nIn 2009 the University Grants Commission of India imposed regulations upon Indian universities to help curb ragging, and launched a toll-free 'anti-ragging helpline'.\n\nInception of ragging can be pleasant at first, hence the name 'Mal Samaya'. During this week or so, all newcomers are ordered to memorize the name and hometown of their peers. The objective of this exercise is said to be increasing the friendship among batch mates (locally termed as \"batch fit\").\n\nThe freshmen are asked to dress in a specific dress code for a particular period of time. The dress code prescribed is generally unusual, e.g. dressing completely in white or black with the hair oiled and combed in a particular style, dressing shirts that do not contain stripes, dressing long skirts for girls. Dress code ragging may make freshmen feel uncomfortable, as it often brings them unnecessary attention from everybody else.\n\nVerbal torture involves indulging in loose talks. The freshmen may be asked to sing the lyrics of any vulgar song or use abusive language in the presence of a large number of peers. During this time, seniors assign an abusive and demeaning nickname, known as \"card\" to the juniors and they have to be called by that name throughout their entire university life. In some universities, this nickname is changed to a less vulgar name after the ragging period. These aliases are used primarily as a means of preventing the university authorities identifying the students who are involved in ragging and other unlawful activities. The form of verbal ragging differs from one institution to another. In some universities, students have to memorize poems made up of filth and recite them in front of others.\n\nThe freshers are asked to do various tasks, such as sit-ups or push-ups, sitting in the murga pose, being forced to call seniors as sir, or removing their shirts. On an attempt to resist carrying out the activities, they may beat the fresher with baseball bats or slap them. \n\nThough, in India, if a complaint is lodged against that senior, they (and others who were present that time) will be given a strict punishment such as expulsion from university, imprisonment for a year etc.\n\nThe seniors may attempt to harass or threaten the junior to complete their assignments, bunk classes, not to take part in any activities or be a part of clubs etc. \n\nAlthough, it comes under extreme cases of ragging and on complaint will lead to strict punishment to the seniors\n\nHighly reputed Indian colleges have a history of ragging especially medical colleges. It has become increasingly unpopular due to several complaints of serious injury to the victims and stringent laws pertaining to ragging. Ragging is now defined as an act that violates or is perceived to violate an individual student's dignity.\n\nFollowing Supreme Court orders, a National Anti-Ragging Helpline was launched by the Indian government.\n\nA high-level committee in 2009, which probed the death of Aman Kachroo, revealed that alcohol was the main reason leading to serious form of ragging and violence in the campus.\n\nA report from 2007 highlights 42 instances of physical injury, and reports on ten deaths purportedly the result of ragging: Ragging has reportedly caused at least 30–31 deaths in the last seven years. In the 2007 session, approximately seven ragging deaths have been reported. In addition, a number of freshmen were severely traumatised to the extent that they were admitted to mental institutions.\nRagging in India commonly involves serious abuses and clear violations of human rights. Often media reports and others unearth that it goes on, in many institutions, in the infamous Abu Ghraib style: and on innocent victims.\n\nHowever, the Anti-Ragging NGO, Society Against Violence in Education (SAVE) has supported that ragging is also widely and dangerously prevalent in engineering and other institutions, mainly in the hostels.\n\nFollowing a Supreme Court Order, a National Anti-Ragging Helpline was created which helps the victims and take action in cases of ragging, by informing the head of the institution and the local police authorities of the ragging complaint from the college. The main feature of the helpline is that the complaints can be registered even without disclosing the name by the victim, through email at helpline@antiragging.in, or through phone at 1800-180-5522.\n\nIndia's National Anti-Ragging Helpline started working in June 2009 to help students in distress due to ragging. It consists of an email id and a 24-hour toll-free number. Provision for anonymous complaints was considered of utmost important at the time of establishment of the helpline, since the victim after making the complaint remains with or close to the culprits, away from a fully secure environment. Since many ragging deaths, like Aman Kachroo's, occurred due to seniors taking a revenge of the complaint made, anonymous complaints were equally allowed at the helpline.\n\nAs per UGC regulations, it is mandatory for a college to register an F.I.R. with police against the culprits if any violence, physical abuse, sexual harassment, confinement etc. takes place with any fresher. After receiving any such complaint from the helpline, it becomes the duty of the head of the institution to register the F.I.R. with police within 24 hours. In 2013, a police case was registered against the director, dean and registrar of a reputed college in Delhi for, among other charges, not informing the police and registering F.I.R. within 24 hours of receiving the ragging complaint. (failing to inform a public authority, IPC 176).\n\nThe database of the Anti-Ragging Helpline indicates that it has been to an extent successful in ensuring a safer environment in colleges from where it registered the complaints. In many a cases though, it forwarded the complaint to the University Grants Commission (UGC) for an action against those colleges which refused to take any action against the culprits.\n\nA major concern that was highlighted against the helpline was that it registered a minuscule percentage (0.1%) of the total phone calls it received, and that meant it registered complaint in one out of one thousand calls it received. Specifically, the toll-free helpline (1800-180-5522) received calls in the three months of November 2012 to January 2013, hence 77 calls an hour and at least a call a minute. But, only 190 complaints were registered in this period. In its defence, the helpline said that most of the calls it received were of inquiry in nature, of the eager students to know whether the helpline number worked or not. Many a times students changed their minds also midway not to register the complaint. It also said that many of the calls were hoaxes as it was a toll-free number.\n\nIn 1997, the state of Tamil Nadu first passed laws related to ragging. Subsequently, a\nmajor boost to anti-ragging efforts was given by a landmark judgement of the Supreme Court of India in May 2001, in response to a Public Interest Litigation filed by the Vishwa Jagriti Mission.\n\nThe Ministry of Human Resources Development (MHRD), following a directive by the Supreme court, appointed a seven-member panel headed by ex-CBI director Dr. R. K. Raghavan to recommend anti-ragging measures.\nThe Raghavan Committee report,\nsubmitted to the court in May 2007, includes a proposal to include ragging as a special section under the Indian Penal Code. The Supreme Court of India interim order (based on the recommendations) dated 16 May 2007 makes it obligatory for academic institutions to file official First Information Reports with the police in any instance of a complaint of ragging. This would ensure that all cases would be formally investigated under\ncriminal justice system, and not by the academic institutions own ad-hoc bodies.\n\nThe Indian Supreme Court has taken a strong stand to prevent ragging. In 2006, the court directed the H.R.D. Ministry of the Govt. of India to form a panel which will suggest guidelines to control ragging.\n\nThe panel, headed by the former director of CBI Dr. R.K.Raghavan, met victims, guardians and others across the country. The Raghavan committee has placed its recommendation to the Hon'ble Supreme Court, which has given its order on the issue.\n\nWelcoming the Supreme Court's recent judgment on ragging Dr. Raghavan, the former CBI director, who is the chairman, Monitoring Committee for the Prevention of Ragging, said, \"there are finally signs that the recommendations to prevent ragging in colleges will be taken seriously.\"\n\nSupreme Court in 2007 directed that all the higher educational institutions should include information about all the ragging incidents in their brochures/prospectus of admission.\n\nIn 2009, in the wake of Aman Kachroo's death, University Grants Commission (UGC) passed UGC regulation on curbing the menace of ragging in higher educational institutions, 2009. These regulation mandate every college responsibilities to curb the menace of ragging, including strict pre-emptive measures, like lodging freshers in a separate hostel, surprise raids especially at nights by the anti-ragging squad and submission of affidavits by all senior students and their parents taking oath not to indulge in ragging.\n\nSubsequently, UGC has made few amendments to the Regulation. As per these,\n\n\nWith the situation of ragging worsening yearly, there is emerging a spontaneous anti-ragging movement in India. Several voluntary organisations have emerged, who conduct drives for public awareness and arrange for support to victims.\n\nOnline groups like Coalition to Uproot Ragging from Education (CURE), Stopragging, No Ragging Foundation became the major anti-ragging groups on the Internet. Among them, the No Ragging Foundation has transformed into a complete NGO and got registered as Society Against Violence in Education (SAVE) which is India's first registered anti-ragging nonprofit organisation (NGO).\n\nThe Indian media has been playing a crucial role by exposing ragging incidents and the indifference of many concerned institutions towards curbing the act. The Supreme Court of India has directed, in its interim judgement, that action may be taken even against negligent institutions.\n\nRagging is widely prevalent in Sri Lanka.\n\nThere is no record to suggest that ragging is an indigenous phenomenon or was present in the ancient Sri Lankan educational institutions such as Mahavihara or Abhayagiri Vihara. It is widely considered to have been introduced during the post World War II era as a result of British colonialism in Sri Lanka. Sri Lankan soldiers returning from war re-entered the college educational system and brought with them the tradition and techniques of military style ragging. These techniques were used in the military as a mechanism of breaking down an individual so that success was achieved through team effort rather than personal goals or motivation. As fewer military persons entered the universities, ragging devolved into a violent and hazardous exercise that has been largely utilized for political purposes and thuggery.\n\nRagging continues in most government universities and several private institutions with some efforts being made to contain the problem although there is hesitation from administrations to get involved. These efforts have been largely hindered by students themselves who consider ragging as a rite of passage. The creation of 'safe spaces' and travelling in larger groups are just some techniques employed by a growing movement of students trying to combat ragging. \nTraditionally, ragging would entail seniors mocking or jeering at freshers within a dedicated period of time – usually the first few months of an undergraduates university life. This period is known as the 'ragging period'. In Sri Lanka, several variations of ragging can be observed.\n\nRagging has been frequently associated with a broad spectrum of physical, behavioral, emotional and social problems among victims and is attributed to the increased risk of suicide and drop-outs among students attending Sri Lankan universities. Ragging at private universities and higher education institutes are at a minimum as compared to government universities which has prompted many students with financial means to enroll in private establishments. \nRagging is not merely a sociolegal problem and has a certain psychological basis too. Many senior students state they do not wish to rag juniors but succumb to peer pressure.\n\n\nThe human rights of citizens of Sri Lanka are protected in terms of the Constitution of the Democratic Socialist Republic of Sri Lanka which is the supreme law in the country. According to this Constitution, any citizen can produce a petition to the Supreme Court in terms of the article 126 of the Constitution in case of a human right violation or a case closer to the infringement. The Constitution further highlights ruthless, brutal or contemptuous treatment to any party by another as a violation of human rights. University students are also considered as citizens and are subjugated to the Common Law that prevails in the country. Accordingly, the constitutional constrains specified above are equally applicable to university students. Any form of civil or criminal offence executed by them are liable to be punished and in an instance of violation of such rights committed by university students, they shall be produced before the relevant court and subject to suitable punishment that followed by the trial. After the series of ragging-related incidents happened in 1997, \"Prohibition of Ragging and Other Forms of Violence in Educational Institutions Act, No. 20 of 1998\" was passed in the Sri Lankan parliament. As specified in the detailed note of the Act, it is identified as an Act to eliminate ragging and other forms of violent and cruel inhuman and degrading treatment from educational institutions. The Act specifies the relevant Higher Educational Institutions coming under the Act and that includes all the Higher Educational Institutions established under the Universities Act No. 16 of 1978.\n\nUnlike in India, there is no official anti-ragging movement in Sri Lanka. But with the situation of ragging worsening yearly, there is a spontaneously emerging anti-ragging movement in each and every faculty of the universities that ragging exists. In the case of University of Peradeniya, the largest university in Sri Lanka, anti-ragging movement emerged in the year 1996. Prior to that, there was no movement against ragging, but certain individuals managed escape from the ragging. In the mean time, anti-ragging movements started to appear in all other universities. Several faculties in several universities have become rag-free due to these movements, strengthened laws as well as practical difficulties in conducting ragging such as not providing accommodation facilities to the first-year students. Internal clashes have erupted several times due to the friction between ragging and anti-ragging movements, best example being Samantha Vithanage, a third-year management student at the University of Sri Jayewardenepura, who pioneered an anti-ragging campaign that was killed at a meeting while in a discussion about ragging. The higher education minister at the time, S. B. Dissanayake, stressed that firm action will be taken against those who are found guilty of such activities in future and would be expelled from the university. In December 2011, he claimed that the levels of ragging has gone down drastically in the recent times and \"only Peradeniya and Ruhuna are still affected by this 'malaise'\".\n\n\n"}
{"id": "1211026", "url": "https://en.wikipedia.org/wiki?curid=1211026", "title": "Rainbow/PUSH", "text": "Rainbow/PUSH\n\nRainbow/PUSH is a non-profit organization formed as a merger of two non-profit organizations founded by Jesse Jackson — Operation PUSH (People United to Save Humanity) and the National Rainbow Coalition. The organizations pursue social justice, civil rights and political activism.\n\nIn December 1971, Jackson resigned from Operation Breadbasket after clashing with Rev. Ralph Abernathy and founded Operation PUSH. Jackson founded the National Rainbow Coalition in 1984 which merged with PUSH in 1996. The combined organization keeps its national headquarters on the South Side of Chicago and has branches in Washington, D.C., New York City, Los Angeles, Detroit, Houston, Atlanta, the Silicon Valley, New Orleans and Boston.\n\nOperation PUSH was successful at raising public awareness to initiate corporate action and government sponsorship. The National Rainbow coalition became a prominent political organization that raised public awareness on numerous political issues and consolidated a large voting block. The merged entity has undertaken numerous social initiatives.\n\nOperation PUSH, an acronym for People United to Save (later Serve) Humanity, was an organization which advocated black self-help and achieved a broad audience for its liberal stances on issues of social justice and civil rights.\n\nThe origins of Operation PUSH can be traced to a factional split in Operation Breadbasket, an affiliate of the Southern Christian Leadership Conference. In 1966, Martin Luther King Jr., the head of the SCLC, appointed Jackson to head the Chicago chapter of Operation Breadbasket, which became a coalition of black ministers and entrepreneurs.\n\nAfter 1968, Jackson increasingly clashed with King's successor at SCLC, Rev. Ralph Abernathy. The break became complete in December 1971 when Abernathy suspended Jackson for \"administrative improprieties and repeated acts of violation of organizational policy.\" Jackson resigned from Operation Breadbasket, called together his allies, and Operation PUSH was born.\n\nFrom its inception, Jackson referred to its membership as a \"Rainbow Coalition.\" The name \"Rainbow Coalition\" was originated in 1968 by Chicago Black Panther leader Fred Hampton to describe the multi-ethnic revolutionary federation he founded. Jackson was not part of the Hampton Rainbow Coalition, and had a difficult relationship with the Panthers. Some former members of Hampton's coalition are resentful of Jackson appropriating the name, partly because Jackson's politics are reformist, and partly because Jackson copyrighted the name, preventing others from using it.\n\nAlthough money was a problem at first, initial backing came from Manhattan Borough President Percy Sutton, Gary, Indiana Mayor Richard Hatcher, Aretha Franklin, Jim Brown, and Ossie Davis.\nThe organizational meeting of PUSH was in the Chicago home of Dr. T.R.M. Howard, a prominent black doctor and community leader on the South Side. Before he moved to Chicago in 1956, Howard had developed a national reputation as a Mississippi civil rights leader, surgeon, and entrepreneur. Howard served on PUSH's board of directors and chaired the finance committee.\n\nThrough PUSH Jackson was able to continue pursuit of the same economic objectives that Operation Breadbasket had pursued. In addition, his new organization was able to expand into areas of social and political development for blacks in Chicago and across the nation. The 1970s saw various tactics to pursue the organization's objectives including direct action campaigns, weekly radio broadcasts,\nand awards through which Jackson protected black homeowners, workers, and businesses, and honored prominent blacks in the US and abroad.\n\nHe also started a push campaign against the legalization of abortion after the Roe vs Wade decision in 1973. The organization was concerned with minority youth reading, and it championed education through PUSH-Excel, a spin-off program that emphasized keeping inner-city youths in school while assisting them with job placement. The program, which persuaded inner city youth to pledge in writing to study two hours per night and which involves parental monitoring, impressed Jimmy Carter whose administration became a large sponsor after Secretary of Health, Education, and Welfare Joseph Califano and Secretary of Labor Ray Marshall courted Jackson.\nThe organization was very successful at committing major corporations with large presences in the black community to adopt affirmative action programs in which they hired more black executives and supervisors and to buy from black suppliers, wholesalers, and distributors. The organization employed prayer vigils as a technique to call attention to issues. The organization opposed Ronald Reagan's workfare initiative to compel that welfare recipients work for part of their benefits.\n\nThe organization staged several boycotts including early 1980s boycotts of Anheuser Busch and Coca-Cola as well as a 1986 boycott of CBS television affiliates. The boycotts became so well known that at one point David Duke supporters referred to a boycott of Nike, Inc. as if whites were being oppressed by blacks. Nike spokesperson, Michael Jordan, disavowed the Nike boycott. The boycotts of Budweiser, and Coke as well as one against Kentucky Fried Chicken were touted for having won minority job concessions from white businesses.\n\nThe National Rainbow Coalition (Rainbow Coalition for short) was a political organization that grew out of Jesse Jackson's 1984 presidential campaign. During the campaign, Jackson began speaking about a \"Rainbow Coalition\", an idea created by Fred Hampton, regarding the disadvantaged and welcomed voters from a broad spectrum of races and creeds. The goals of the campaign were to demand social programs, voting rights, and affirmative action for all groups that had been neglected by Reaganomics.\n\nJackson's campaign blamed President Ronald Reagan's policies for reduction of government domestic spending, causing new unemployment and encouraging economic investment outside of the inner cities, while they discouraged the rebuilding of urban industry. The industrial layoffs caused by these policies hit the Black and other minority populations particularly hard.\n\nAt the 1984 Democratic National Convention on July 18, 1984, in San Francisco, California, Jackson delivered an address entitled \"The Rainbow Coalition\". The speech called for Arab Americans, Native Americans, Asian Americans, youth, disabled veterans, small farmers, lesbians and gays to join with African Americans and Jewish Americans for political purpose. Whereas the purpose of PUSH had been to fight for economic and educational opportunities, the Rainbow Coalition was created to address political empowerment and public policy issues.\n\nAfter his unsuccessful bid for the Democratic nomination in 1984, Jackson attempted to build a broad base of support among groups that \"were hurt by Reagan administration policies\" - racial minorities, the poor, small farmers, working mothers, the unemployed, some labor union members, gays, and lesbians.\n\nJackson moved from Chicago to Washington, D.C. to serve as shadow senator from 1991 to 1996. When he returned to Chicago in 1996 he merged his organizations. The merged entity advocates for African Americans, Hispanics, Native Americans, other minorities, and women. Its main economic goal is to have more minorities on the payrolls, in the boardrooms, and on the supplier lists of major corporations. The industries it most aggressively pursues are the financial sector on Wall Street, the telecommunications field and high-tech firms in Silicon Valley.\n\nThe Wall Street activities are organized under sub-organization \"The Wall Street Project\". The organization has been active in pursuit of increase minority representation in other industries, most notably the broadcast media, the entertainment industry, and the automobile industry. It has also sought increased representation by minority administrators in college and professional sports under the leadership of Jesse Jackson, Jr. For Hispanic issues the merged entity works closely with the League of United Latin American Citizens and the National Council of La Raza.\n\nIn 1998 the organization attacked Freddie Mac for its lending and employment practices, which led to its pledge to earmark $1 billion in mortgage loans specifically for minorities, to donate more than $1 million directly to Rainbow/PUSH and to become a sponsor of Jackson's annual Wall Street Project. In 2000, the organization investigated the case of Raynard Johnson, who was found hanged by a belt from a tree in front of his home in Kokomo, Mississippi. Jackson labelled it a \"lynching\", although two autopsies both concluded that the death was a suicide.\n\nIn the early 2000s (decade), Rainbow/PUSH worked with NASCAR to increase the number of minorities involved in auto racing, through direct financial support and projects to find talented African-American racing drivers. This initiative was ended in 2003, after the racing sanctioning body was criticized by conservative groups for the partnership. Among the smaller campaigns it has undertaken are the HIV/AIDS Initiative for funding for AIDS programs; the National Field Department support of \"constructive agitation to bring about societal change\"; and the Prison Outpost project, whose ultimate goal is \"to eliminate the need for prisons.\"\n\nThrough his organization and its predecessors Jackson has advocated universal health care, a war on drugs, direct peace negotiations between Palestinians and Israelis, ending apartheid in South Africa and advancing democracy in Haiti. The following is the organization's list of major issues:\n\n\nFormer congressman Mel Reynolds, who served a sentence in prison for sexual assault and bank fraud, was hired by Rainbow/PUSH as its resident scholar on prison reform after his release in 2001. The organization is a member of several anti-war coalitions including Win Without War, United for Peace and Justice, and After Downing Street.\n\nIn 2006, Jesse Jackson promised the Rainbow/Push Coalition would pay the college tuition for Crystal Mangum. Mangum made rape allegations against members of Duke University's men's lacrosse team who had hired her as a stripper. The charges were later dropped due to lack of evidence. Jackson said it would not matter what the outcome of the trial, the tuition offer would still be good.\n\n\n"}
{"id": "38444587", "url": "https://en.wikipedia.org/wiki?curid=38444587", "title": "Seating plan", "text": "Seating plan\n\nA seating plan is a diagram or a set of written or spoken instructions that determines where people should take their seats. It is widely used on diverse occasions. \n\nSeating plans have a wide range of purposes. At formal dinners, they are usually used to avoid chaos and confusion upon entrance and to follow the etiquette. In this case, it is customary to arrange the host and hostess at the opposite sides of the table, and alternate male and female guests throughout. Place cards can be used to direct guests. State dinners have their own protocol and arrangements are made so that the most distinguished guests can have the possibility to engage in conversation. Plans are also made for airplanes, where the objective is to differentiate passengers between the various travel classes and ensure everybody has a place. Similarly, theatres or cinemas may allow spectators to choose their seats beforehand. A seating plan is of crucial importance for musical ensembles or orchestras, where every type of instrument is allocated a specific section.\n\n"}
{"id": "221308", "url": "https://en.wikipedia.org/wiki?curid=221308", "title": "Self-assessment", "text": "Self-assessment\n\nIn social psychology, self-assessment is the process of looking at oneself in order to assess aspects that are important to one's identity. It is one of the motives that drive self-evaluation, along with self-verification and self-enhancement. Sedikides (1993) suggests that the self-assessment motive will prompt people to seek information to confirm their uncertain self-concept rather than their certain self-concept and at the same time people use self-assessment to enhance their certainty of their own self-knowledge. However, the self-assessment motive could be seen as quite different from the other two self-evaluation motives. Unlike the other two motives through self-assessment people are interested in the accuracy of their current self view, rather than improving their self-view. This makes self-assessment the only self-evaluative motive that may cause a person's self-esteem to be damaged.\n\nIn educational psychology and education, self-assessment \"involves a wide variety of mechanisms and techniques through which students describe (i.e., assess) and possibly assign merit or worth to (i.e., evaluate) the qualities of their own learning processes and products\" (Panadero, Brown & Strijbos, 2016 p. 804). The educational research has identified different types of self-assessment implementations, considering different features. Over the years, there has been a focus for \"summative\" purposes of self-assessment (e.g. students \"guessing\" their score that was compared to the teacher's or peer's). However, especially for the last two decades since the inception of formative assessment, more attention has been paid to formative purposes, where the focus is on using self-assessment to increase students' learning and self-regulated learning. Currently, two meta-analyses support the effect of self-assessment interventions in achievement and self-regulated learning and self-efficacy.\n\nIf through self-assessing there is a possibility that a person's self-concept, or self-esteem is going to be damaged why would this be a motive of self-evaluation, surely it would be better to only self-verify and self-enhance and not to risk damaging self-esteem? Trope in his paper \"Self-Enhancement and Self Assessment in Achievement Behaviour\" suggests that self-assessment is a way in which self-esteem can be enhanced in the future. For example, self-assessment may mean that in the short-term self-assessment may cause harm to a person's self-concept through realising that they may not have achieved as highly as they may like; however in the long term this may mean that they work harder in order to achieve greater things in the future, and as a result their self-esteem would be enhanced further than where it had been before self-assessment.\n\nWithin the self-evaluation motives however there are some interesting interactions. Self-assessment is found a lot of the time to be associated with self-enhancement as the two motives seem to contradict each other with opposing aims; whereas the motive to self-assess sees it as important to ensure that the self-concept is accurate the motive to self-enhance sees it as important to boost the self-concept in order to protect it from any negative feedback.\n\nIn 1993, Constantine Sedikides performed an experiment investigating the roles of each of the self-evaluation motives, investigated if one was stronger and held more weight than others and tried to draw out specifically the self-assessment and self-verification motives. The first experiment conducted the results showed that when choosing what questions they wanted to be asked they were more likely to request those that would verify their self-concept rather than assess it. This finding supports the idea that certain traits are more central to a person's self-concept, however shows little support for the self-assessment motive. When considering the interaction between how strong and how central certain traits are to a person's self-concept Sedikides again found evidence in support of the self-verification and self-enhancement motives, though again none for the self-assessment motive.\n\nThe second experiment conducted by Sedikides (1993) investigated the possibility that the ability for greater reflection than experiment one may show greater levels of self-assessment in the participants. However the results of this experiment showed that though through some analysis there was evidence of some self-verification there was no real evidence pointing towards self-assessment and all the results supported self-enhancement. The third experiment again tried to draw out evidence for self-verification and self-assessment and though, as with experiment two, there was some evidence to support the self-verification motive most of the results pointed towards the self-enhancement method and not self-assessment.\n\nIn experiment four Sedikides suggests that the reason past experiments have not supported self-assessment is because participants reflect more on the central traits than peripheral traits, which are generally ones that are assessed so as to be able to improve at the same time as not harming the self-concept too much. This experiment therefore looked at whether this was true and whether it was the central traits that were being looked at in this study rather than peripheral. The results showed exactly what Sedikides expected, though because of this the results of the other parts of the experiment gave support to the self-enhancement motive rather than self-assessment of self-verification.\n\nThe fifth experiment carried out by Sedikides suggests that in the past experiments the possibility of self-assessing was less likely than self-verification or self-enhancement as the participants would not have been objective in their self-evaluation. For this experiment therefore the experimental group were asked to approach their reflections in an objective way, as if they were approaching their self-concept as a scientist, bringing each of their traits under scrutiny. Results of this study showed that those subjects who were asked to be objective in their assessment strove more for accuracy than those not asked to be specifically objective. The authors then conducted one final experiment looking at the validation of self-enhancement when reflecting on the self.\n\nSedikides and Strube (1997) reviewed past research into the self-assessment motive and looked at whether participants would be more attracted to tasks that were high or low in accuracy about their characteristics, whether they would choose to take part in tasks that were more or less accurate and if they would prefer to create highly or less accurate tasks. This review showed that people are more attracted to taking part in tasks that are more accurate about them than those that are less accurate and would prefer to take part in higher accuracy tests. However, when only being asked if they would like to take part in high or low accuracy tasks does not give a complete accurate view of self-assessment; if there is no threat of actually taking part in the tasks the participants may not be as honest as if they actually had to take part. Brown therefore showed that self-assessment is can be seen when participants are asked to actually take part in tasks that will be high in their accuracy or low in their accuracy of a person's characteristics. This research found that participants were more likely to choose to take part in tasks that were higher in accuracy about their characteristics. The last area of self-assessment Sedikides and Strube reviewed was whether participants would want to construct highly or less accurate tasks and if participants would be more persistent or more likely to succeed if they were taking part in highly or less accurate tasks. The review showed that participants would prefer to make highly accurate tasks which measured their abilities; however they will be more persistent in tasks which are lower in accuracy. The review also showed though that participants were more likely to succeed on tasks that they were told were high in accuracy. It is suggested that this is because when completing tasks that are highly accurate about a person's characteristics there is more to gain from succeeding in a task as it will therefore give more information about the person's characteristics than if it was low in accuracy.\n\nA wide view on approaches and practices on self-assessment of competence in Adult education is offered by a European project \"VINTAGE - online tool for self eValuatIoN of key competences in adulT AGE\" that reports a desk study focused on the acquisition and self-assessment of key competences in adult education in Italy, Austria, Germany, Ireland, Netherlands and Sweden. \nThe VINTAGE self-assessment framework has been tested during seven parallel focus group sessions, in the six partner Countries, involving roughly hundred experts and practitioners at European level. \nThe self-assessment procedure offers an innovative alternative to common knowledge based multiple-choice questionnaires to evaluate competences. It assigns an active role to the user, calling upon reflective abilities, self-assessment competences and self-responsibility. The procedure focuses on the Lifelong Learning approach, aiming to offer a tool for personal empowerment and development, rather than for solely selective or professional purposes.\nVintage assessment framework focuses on actual behavior a person is demonstrating in a realistic context, or rather a reconstruction of a realistic context in a particular situation, evaluating the mastery level and the quality of the performance. This chosen approach towards the assessment of learning outcomes and competences is as well supported by research that highlights the importance of the performance side in demonstrating (key) competence within the field of education and lifelong learning. It is a process that requires involvement and participation by the user and reflection, bringing into play meta-competences typical of the self-assessment process and therefore particularly suited to an adult context. Engaging the user in such an active and responsible way additionally improves the self-assessment competences and aims at raising motivation of the adult learner and supporting the idea of self-directness of lifelong learning.\n\n\nFive different clusters of the chosen key competence are presented. These clusters are well grounded in Vintage research considering projects and publications throughout European countries and Framework. After deciding for a cluster the user is presented a situation in which the key competence in the chosen domain is performed. Again situations, meant to be broad enough to apply to many common experiences, yet specific enough to identify what a performance in a certain key competence and domain requires, meant to refer to daily life settings, support the user in the reflective abilities to relate own experiences and performances to the described situations.\n\n\nThough self-assessment is one of the self-evaluation motives it could be suggested that it may not be the most popular one. Self-enhancement was displayed in each of the experiments conducted by Sedikides and self-assessment, and even self-verification to an extent was only displayed when it was teased out. This is not to say that self-assessment is not a self-evaluation motive, however most of the experiments conducted by Sedikides ended up with the participants reflecting on central traits rather than peripheral traits. This is unsurprising as they are the most important traits to a person's self-concept, however it is not therefore surprising that these are the traits that are enhanced rather than assessed as if someone assessed their central traits and found fault it would be more of an issue than finding a fault with a peripheral trait. The fifth experiment carried out by Sedikides shows that self-assessment does exist and is one of the self-evaluation motives; if people didn't self-assess then even in this experiment there would have been no difference between the reflections of those asked to be objective and those who were not. Self-assessment is a difficult motive to assess, as discovered by Sedikides but it is important to self-evaluation as it means that people are able to realize ways in which to improve themselves.\n\n\n"}
{"id": "36882533", "url": "https://en.wikipedia.org/wiki?curid=36882533", "title": "Spoliation Advisory Panel", "text": "Spoliation Advisory Panel\n\nThe Spoliation Advisory Panel advises the United Kingdom Government on claims for cultural property looted during the Nazi era. \n\nThe Panel is designated by the Secretary of State under Section 3 of the Holocaust (Return of Cultural Objects) Act 2009 to advise on claims made by former owners or their heirs (or in some cases, states or public bodies) for the return of, or compensation for the loss of, items that have come into the effective possession of institutions in the UK, for example artworks in the national collections. It deals with cases where the objects were allegedly lost through seizure or forced sales during the Nazi era, or through looting or other unlawful transactions during the Second World War. It provides non-binding recommendations for return or for ex gratia payments. \n\nThe Panel was established in February 2000 by the Department for Culture, Media and Sport as an advisory non-departmental public body under the Department for Culture, Media and Sport (DCMS). It was chaired by Sir David Hirst until April 2010, when it was reconstituted as a group of expert advisers and Sir Donnell Deeny, a member from the outset, took over as chairman.\n"}
{"id": "37816386", "url": "https://en.wikipedia.org/wiki?curid=37816386", "title": "The Development of the Monist View of History", "text": "The Development of the Monist View of History\n\nThe Development of the Monist View of History is the major work of the Russian philosopher Georgi Plekhanov, published in 1895. Plekhanov gives an account of modern social and philosophical thought as culminating in Georg Wilhelm Friedrich Hegel and Karl Marx and seen through the materialism of Ludwig Feuerbach.\n\nPlekhanov wrote under the pseudonym Beltov and admitted to the use of the \"purposely clumsy\" name \"Monist View\" in order to deceive the censors of the Russian government. The book passed the censors and was legally published in Russia. \"The Development of the Monist View of History\" became a very popular defense of the materialistic conception of history. Vladimir Lenin would later comment that it \"helped educate a whole generation of Russian Marxists.\" Friedrich Engels commented in a January 30, 1895 letter to Vera Zasulich that it had been published at a most opportune time. Tsar Nicholas II had just released a statement on January 29 (or January 17 under the old Russian calendar) that announced that it was fruitless for the \"Zemstvos\", locally elected district councils, to agitate for any more democratic reforms in the Russian government. Nicholas II had decided to return Russia to the absolute Tsarist autocracy of his father, Alexander III. The elected \"Zemstvos\", which formed a local government in the European sectors of the Russian Empire, had been initiated by Nicholas' grandfather, Tsar Alexander II in 1864. Under Nicholas II's re-initiation of absolute autocracy, the \"Zemstvos\" would become superfluous and basically be abolished. Engels expected this announcement would cause an upsurge in popular protest in Russian and Engels thought the timely publication of Plekhanov's book would augment that popular protest.\n\nLater on February 8, 1895, Engels wrote directly to Plekhanov congratulating him on the \"great success\" of getting the book \"published \"inside your country\"\". A German edition was published in Stuttgart in 1896.\n"}
{"id": "145018", "url": "https://en.wikipedia.org/wiki?curid=145018", "title": "Ultrafinitism", "text": "Ultrafinitism\n\nIn the philosophy of mathematics, ultrafinitism (also known as ultraintuitionism, strict formalism, strict finitism, actualism, predicativism, and strong finitism) is a form of finitism. There are various philosophies of mathematics that are called ultrafinitism. A major identifying property common among most of these philosophies is their objections to totality of number theoretic functions like exponentiation over natural numbers.\n\nLike other finitists, ultrafinitists deny the existence of the infinite set N of natural numbers.\n\nIn addition, some ultrafinitists are concerned with acceptance of objects in mathematics that no one can construct in practice because of physical restrictions in constructing large finite mathematical objects.\nThus some ultrafinitists will deny or refrain from accepting the existence of large numbers, for example, the floor of the first Skewes's number, which is a huge number defined using the exponential function as exp(exp(exp(79))), or\nThe reason is that nobody has yet calculated what natural number is the floor of this real number, and it may not even be physically possible to do so. Similarly, formula_2 (in Knuth's up-arrow notation) would be considered only a formal expression which does not correspond to a natural number. The brand of ultrafinitism concerned with physical realizability of mathematics is often called actualism.\n\nEdward Nelson criticized the classical conception of natural numbers because of the circularity of its definition. In classical mathematics the natural numbers are defined as 0 and numbers obtained by the iterative applications of the successor function to 0. But the concept of natural number is already assumed for the iteration. In other words, to obtain a number like formula_2 one needs to perform the successor function iteratively, in fact exactly formula_2 times to 0.\n\nSome versions of ultrafinitism are forms of constructivism, but most constructivists view the philosophy as unworkably extreme. The logical foundation of ultrafinitism is unclear; in his comprehensive survey \"Constructivism in Mathematics\" (1988), the constructive logician A. S. Troelstra dismissed it by saying \"no satisfactory development exists at present.\" This was not so much a philosophical objection as it was an admission that, in a rigorous work of mathematical logic, there was simply nothing precise enough to include.\n\nSerious work on ultrafinitism has been led, since 1959, by Alexander Esenin-Volpin, who in 1961 sketched a program for proving the consistency of Zermelo–Fraenkel set theory in ultrafinite mathematics. Other mathematicians who have worked in the topic include Doron Zeilberger, Edward Nelson, Rohit Jivanlal Parikh, and Jean Paul Van Bendegem. The philosophy is also sometimes associated with the beliefs of Ludwig Wittgenstein, Robin Gandy, Petr Vopenka, and J. Hjelmslev.\n\nShaughan Lavine has developed a form of set-theoretical ultra-finitism that is consistent with classical mathematics.\nLavine has shown that the basic principles of arithmetic such as \"there is no largest natural number\" can be upheld, as Lavine allows for the inclusion of \"indefinitely large\" numbers.\n\nOther considerations of the possibility of avoiding unwieldy large numbers can be based on computational complexity theory, as in Andras Kornai's work on explicit finitism (which does not deny the existence of large numbers) and Vladimir Sazonov's notion of feasible number.\n\nThere has also been considerable formal development on versions of ultrafinitism that are based on complexity theory, like Samuel Buss's Bounded Arithmetic theories, which capture mathematics associated with various complexity classes like P and PSPACE. Buss's work can be considered the continuation of Edward Nelson's work on predicative arithmetic as bounded arithmetic theories like S12 are interpretable in Raphael Robinson's theory Q and therefore are predicative in Nelson's sense. The power of these theories for developing mathematics is studied in Bounded reverse mathematics as can be found in the works of Stephen A. Cook and Phuong The Nguyen. However these researches are not philosophies of mathematics but rather the study of restricted forms of reasoning similar to Reverse Mathematics.\n\n\n\n"}
{"id": "2411585", "url": "https://en.wikipedia.org/wiki?curid=2411585", "title": "Unicase", "text": "Unicase\n\nA unicase or unicameral alphabet is one that has no case for its letters. Kannada, Tamil, Arabic, Old Hungarian, Hebrew, Georgian, and Hangul are unicase alphabets, while (modern) Latin, Greek, Cyrillic, and Armenian are \"bicameral\", as they have two cases for each letter, e.g., B/b, Β/β, Б/б, Բ/բ. Individual characters can also be called unicameral if they are used as letters with a generally bicameral alphabet but have only one form for both cases; for example, ʻokina (), used in Polynesian languages, and glottal stop (ʔ) as used in Nuu-chah-nuulth.\n\nAll alphabets with case were once unicase. Latin, for example, used to be written with a unicase alphabet in imperial Roman times; it was only later that scribes developed new sets of symbols for running text, which became the lower case of the Latin alphabet, while the letterforms of Ancient Rome came to be called capitals or upper case.\n\nThe Georgian alphabet, on the other hand, has developed in the other direction: in the medieval period, Georgian also had two sets of letters available for bicameral writing, but the use of two cases later gave way to a unicameral system. The ecclesiastical form of the Georgian alphabet, Khutsuri, had an upper case called Asomtavruli (like the Ancient Roman capitals) and a lower case called Nuskhuri (like the medieval Latin scribal forms). Out of Nuskhuri came a secular alphabet called Mkhedruli, which is the unicase Georgian alphabet in use today.\n\nA unicase version of the Latin alphabet was proposed by Michael Mann and David Dalby in 1982 as a variation of the Niamey African Reference Alphabet. This version has apparently never been actively used. Another example of unicase Latin alphabet is the Initial Teaching Alphabet. Occasionally some fonts use unicase designs to create an unusual effect; this was particularly popular in the 1960s.\n\nThe International Phonetic Alphabet only uses lowercase Latin (and Greek) letters and some scaled upper-case letters (small caps), effectively making it a unicase alphabet, although it is not used for actual writing of any language.\n\n\n"}
{"id": "46961977", "url": "https://en.wikipedia.org/wiki?curid=46961977", "title": "Web We Want", "text": "Web We Want\n\nWeb We Want is a campaign started by the World Wide Web Foundation to promote discussion on Internet rights.\n"}
{"id": "37494949", "url": "https://en.wikipedia.org/wiki?curid=37494949", "title": "Winterbourne View hospital abuse", "text": "Winterbourne View hospital abuse\n\nThe Winterbourne View hospital inquiry occurred at Winterbourne View, a private hospital at Hambrook, South Gloucestershire, England, owned and operated by Castlebeck. A Panorama investigation broadcast on television in 2011, exposed the physical and psychological abuse suffered by people with learning disabilities and challenging behaviour at the care home. \n\nLocal social services and the English national regulator (Care Quality Commission) had received various warnings but the mistreatment continued. One senior nurse, Terry Bryan, reported his concerns to the management at Winterbourne View and to CQC, but his complaint was not taken up.\n\nThe public funded hospital has been shut down as a result of the abuse that took place.\n\nThe undercover footage showed staff repeatedly assaulting and harshly restraining patients under chairs. Staff gave one patients cold punishment showers, left her outside in near zero temperatures, and later poured mouthwash into her eyes. They pulled patients' hair and forced medication into patients' mouths. Victims were shown screaming and shaking, and one patient was seen trying to jump out of a second floor window to escape the torment, and was then mocked by staff members. One patient was repeatedly poked in the eyes.\n\nA clinical psychologist who reviewed the footage described the abuse as \"torture\".\n\nOn 21 June 2011, 86 people and organisations wrote to the Prime Minister, David Cameron about the revelations, \"We are aware of the various actions currently being taken within and outside government – such as the DH review and CQC internal inquiry. We hope to make submissions to those both individually and collectively. However, on their own these will not be enough and a clear programme is needed to achieve change.\"\n\nThe prime minister responded saying he was “appalled” at the “catalogue of abuses” Panorama uncovered.\n\nIn June 2011 the Association of Supported Living issued a press statement, which was followed up in writing to every member of parliament in the United Kingdom, calling for community based supported living services to replace institutional services for people with learning disabilities.\n\nThe \"Daily Mail\" said \"Without the investigation by the BBC's Panorama, given huge coverage in the Mail, the abuse of patients at Winterbourne View might be continuing to this day. As it is, the secure hospital and two other care homes have been shut down, 11 guilty staff have been brought to justice – and a devastating report now exposes the serial failings of the local NHS, police and health watchdogs. For the past year, the Leveson Inquiry has focused relentlessly on the failings of the media. Never let it be forgotten how much this country owes, in the fight against cruelty and corruption, to its free Press.\"\n\nThe \"Daily Telegraph\" said, \"It is impossible to read the details of what went on at Winterbourne View, a care home for the severely disabled in Gloucestershire, without feeling repelled. In the wake of an exposé from the BBC's Panorama, 11 members of staff were convicted of almost 40 charges of neglect and ill treatment of those in their care.\"\n\nThe national regulator, the CQC did a nationwide check on facilities owned by the same company, Castlebeck Care – as a result three more institutions have been closed. The CQC reported a \"systemic failure to protect people or to investigate allegations of abuse\" and said that Castlebeck Care had \"misled\" the health watchdog.\n\nThe CQC also came under criticism for failing to respond to early warnings of abuse at the care home. It initially blamed Winterbourne managers who, the CQC said, \"effectively misled us by not keeping us informed about incidents\". However, it later emerged that managers had officially alerted the CQC to numerous allegations of staff abusing patients, dating back to February 2008, which were also reported to the police, but did not lead to any convictions.\n\nThe CQC also inspected 132 similar institutions and a Serious Case Review was commissioned – some of the roughly ten local and national enquiries were carried out to examine what went wrong, including one by NHS Southwest which was one of the first to be published and list many of the others.\nThe head of the Care Quality Commission resigned ahead of a critical government report, a report in which Winterbourne View was cited. Mencap published a report warning that similar abuse could be going on elsewhere and calling for the closure of all large institutions far from people's families.\n\nEleven people pleaded guilty to criminal offences of neglect or abuse as a result of evidence from Undercover Care and six of them were jailed. Immediately after the eleventh person pleaded guilty, the Serious Case Review was published, revealing hundreds of previous incidents at the hospital and missed warnings.\n\n\nBBC Panorama produced an investigation documentary depicting the violations at Winterbourne View Hospital titled \"Undercover Care: The Abuse Exposed\".\n\n"}
