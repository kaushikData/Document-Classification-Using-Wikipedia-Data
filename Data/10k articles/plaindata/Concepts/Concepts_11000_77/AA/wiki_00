{"id": "32307667", "url": "https://en.wikipedia.org/wiki?curid=32307667", "title": "Accountable Now", "text": "Accountable Now\n\nAccountable Now is a global platform, founded in 2008 by a group of independent non-profit organisations, which is intended to foster accountability and transparency of civil society organisations (CSOs), as well as stakeholder communication and performance. It supports CSOs to be transparent, responsive to stakeholders and focused on delivering impact. \n\nAccountable Now was founded under the name International NGO Charter of Accountability by eleven leading CSOs, including development, humanitarian, environmental, rights-based and advocacy organisations. As Membership and global collaboration increase, CSOs collective voices are strengthened. Today, 29 Member Organisations are active in more than 150 countries and impact stakeholders all over the world.\n\nCSOs are more important than ever before in framing and influencing social, political and economic environments. On the national level they provide disaster relief and social service, promote self-help and self- governance in developing countries where they are operating. In addition they enhance a strong international Civil Society by creating informal but important normative regimes which are influencing international institutions in their decision-making. This greater involvement of CSOs also raises the question of how they justify their activities.\n\nCSOs have a particular interest in meeting standards on accountability and transparency in view of the responsibilities towards not only the cause which they are meant to serve, but also stakeholders of various types, including donors and sponsors (possibly comprising corporations and governments), intended program beneficiaries, staff and the general public.\n\nAccountable Now is considered a contributing element to underscoring the legitimacy of CSOs.\n\nAt the International Advocacy Non-Government Organisations (IANGO) Workshop hosted by Transparency International in June 2003, the importance of promoting accountability and legitimacy was discussed by its participants. As they recognised their growing involvement in international issues the need of promoting accountability was highlighted. The Hauser Center for Non-Profit Organisations at the Harvard University was asked for a research paper on the topic to provide a foundation for following discussions.\nAt the following annual meetings in 2004 and 2005 the participants analysed their own concepts of accountability, set up an initial draft and with the help of independent consultant specialists revised the draft until a final version was ready to launch.\n\nThe INGO Accountability Charter, signed in June 2006 by eleven leading international NGOs active in the area of human rights, environment and social development, set the course for the establishment of Accountable Now (then known as the INGO Accountability Charter) and it has been referred to as “the first ever set of international and cross-sector guidelines for the NGO sector” and the “first global accountability charter for the non-profit sector”.\n\nThe founding signatories were ActionAid International, Amnesty International, CIVICUS World Alliance for Citizen Participation, Consumers International, Greenpeace International, Oxfam International, International Save the Children Alliance, Survival International, International Federation Terre des Hommes, Transparency International and World YWCA.\n\nThe charter is \"based on ten core principles and aimed at enhancing respect for human rights, good governance, accountability and transparency, encouraging stakeholder communication, promoting inclusion and environmental responsibility, and improving organisational performance and effectiveness\". It documents the commitment of international NGOs to these aims. \n\nIn 2008, the signatory-NGOs decided to found an independent organisation of the same name \"International NGO Accountability Charter Ltd\" in order to organise the reporting and vetting process of the member organisations against the charter commitments and develop them further. Today, the organisation operates under the name Accountable Now and has 29 member organisations. \n\nIn 1997, the One World Trust had created an \"NGO Charter\", a code of conduct comprising commitment to accountability and transparency.\n\n\n"}
{"id": "3408532", "url": "https://en.wikipedia.org/wiki?curid=3408532", "title": "Ajativada", "text": "Ajativada\n\nAjātivāda is the fundamental philosophical doctrine of the Advaita Vedanta philosopher Gaudapada. According to Gaudapada, the Absolute is not subject to birth, change and death. The Absolute is \"aja\", the unborn eternal. The empirical world of appearances is considered unreal, and not absolutely existent.\n\nGaudapada's perspective is based on the \"Mandukya Upanishad\", applying the philosophical concept of \"ajāta\" to the inquiry of Brahman, showing that Brahman wholly transcends the conventional understanding of being and becoming. The concept is also found in Madhyamaka Buddhism, as the theory of nonorigination.\n\nAjātivāda:\n\nTaken together \"ajātivāda\" means \"the Doctrine of no-origination\" or non-creation.\n\nThe concept of \"ajāta\" was borrowed by Gaudapada from Madhyamika Buddhism, which uses the term \"anutpāda\":\n\nTaken together \"anutpāda\" means \"having no origin\", \"not coming into existence\", \"not taking effect\", \"non-production\".\n\n\"Ajātivāda\" is the fundamental philosophical doctrine of Gaudapada. According to Gaudapada, the Absolute is not subject to birth, change and death. The Absolute is \"aja\", the unborn eternal. The empirical world of appearances is considered Maya (unreal as it is transitory), and not absolutely existent.\n\nGaudapada borrowed the concept of \"ajāta\" from Nagajurna's Madhyamaka philosophy. The Buddhist tradition usually uses the term \"anutpāda\" for the absence of an origin or śūnyatā.\n\nBut Gaudapada's perspective is quite different from Nagarjuna. Gaudapada's perspective is based on the \"Mandukya Upanishad\". In the \"Mandukya Karika\", Gaudapada's commentary on the \"Mandukya Upanishad\", Gaudapada sets forth his perspective. According to Gaudapada, Brahman cannot undergo alteration, so the phenomenal world cannot arise independently from Brahman. If the world cannot arise, yet is an empirical fact, than the world has to be an unreal (transitory) appearance of Brahman. And if the phenomenal world is a transitory appearance, then there is no real origination or destruction, only apparent origination or destruction. From the level of ultimate truth (\"paramārthatā\") the phenomenal world is \"māyā\", \"illusion\", apparently existing but ultimately not real.\n\nIn \"Gaudapada-Karika\", chapter III, verses 46-48, he states that Brahman never arises, is never born, is never unborn, it rests in itself:\nThe Ajativada of Gaudapada, states Karmarkar, has nothing in common with the Sunyavada concept in Buddhism. While the language of Gaudapada is undeniably similar to those found in Mahayana Buddhism, Coman states that their perspective is different because unlike Buddhism, Gaudapada is relying on the premise of \"Brahman, Atman or Turiya\" exist and are the nature of absolute reality.\n\nRamana Maharshi gave a translation in Tamil of Gaudapada’s \"Mandukya Upanishad Karika\", chapter two, verse thirty-two:\nAccording to David Godman, the ajata doctrine implies that since the world was never created, there are also no jivas within it who are striving for or attaining liberation. Ramana Maharshi regarded this as \"the ultimate truth.\"\n\nAdvaita took over from the Madhyamika the idea of levels of reality. Usually two levels are being mentioned, namely \"saṃvṛti-satya\", \"the empirical truth\", and \"paramārtha-satya\", \"ultimate truth\". According to Plott, \nThe distinction between the two truths (\"satyadvayavibhāga\") was fully expressed by the Madhyamaka-school. In Nāgārjuna's \"Mūlamadhyamakakārikā\" it is used to defend the identification of dependent origination (\"pratītyasamutpāda\") with emptiness (\"śūnyatā\"):\nShankara uses sublation as the criterion to postulate an ontological hierarchy of three levels:\n\nIt is at the level of the highest truth (\"paramārtha\") that there is no origination. Gaudapada states that, from the absolute standpoint, not even \"non-dual\" exists.\n\nMany scholars, states Richard King, designate Madhyamaka Buddhism as \"Ajativada\". The concept \"Ajati\", he adds, exists in both Vedanta and Buddhism, but they are different in the following way:\nAjativada in Madhyamaka refers to its doctrine that things neither originate nor is there cessation. This is also called the theory of non-origination of Madhyamaka.\n\n\n"}
{"id": "2347010", "url": "https://en.wikipedia.org/wiki?curid=2347010", "title": "Ancient Egyptian units of measurement", "text": "Ancient Egyptian units of measurement\n\nThe ancient Egyptian units of measurement are those used by the dynasties of ancient Egypt prior to its incorporation in the Roman Empire and general adoption of Roman, Greek, and Byzantine units of measurement. The units of length seem to have originally been anthropic, based on various parts of the human body, although these were standardized using cubit rods, strands of rope, and official measures maintained at some temples.\n\nFollowing Alexander the Great's conquest of Persia and subsequent death, his bodyguard and successor Ptolemy assumed control in Egypt, partially reforming its measurements, introducing some new units and hellenized names for others. \n\nEgyptian units of length are attested from the Early Dynastic Period. Although it dates to the 5th dynasty, the Palermo stone recorded the level of the Nile River during the reign of the Early Dynastic pharaoh Djer, when the height of the Nile was recorded as 6 cubits and 1 palm (about ). A 3rd-dynasty diagram shows how to construct an elliptical vault using simple measures along an arc. The ostracon depicting this diagram was found near the Step Pyramid of Saqqara. A curve is divided into five sections and the height of the curve is given in cubits, palms, and digits in each of the sections.\nAt some point, lengths were standardized by cubit rods. Examples have been found in the tombs of officials, noting lengths up to remen. Royal cubits were used for land measures such as roads and fields. Fourteen rods, including one double-cubit rod, were described and compared by Lepsius. Two examples are known from the Saqqara tomb of Maya, the treasurer of Tutankhamun. Another was found in the tomb of Kha (TT8) in Thebes. These cubits are about long and are divided into palms and hands: each palm is divided into four fingers from left to right and the fingers are further subdivided into ro from right to left. The rules are also divided into hands so that for example one foot is given as three hands and fifteen fingers and also as four palms and sixteen fingers.\n\nSurveying and itinerant measurement were undertaken using rods, poles, and knotted cords of rope. A scene in the tomb of Menna in Thebes shows surveyors measuring a plot of land using rope with knots tied at regular intervals. Similar scenes can be found in the tombs of Amenhotep-Sesi, Khaemhat and Djeserkareseneb. The balls of rope are also shown in New Kingdom statues of officials such as Senenmut, Amenemhet-Surer, and Penanhor.\n\nThe digit was also subdivided into smaller fractions of ½, ⅓, ¼, and . Minor units include the Middle Kingdom reed of 2 royal cubits, the Ptolemaic xylon (, .\"timber\") of three royal cubits, the Ptolemaic fathom (, \"orgyiá\"; ; , \"hpot\") of four lesser cubits, and the kalamos of six royal cubits.\n\nRecords of land area also date to the Early Dynastic Period. The Palermo stone records grants of land expressed in terms of \"kha\" and \"setat\". Mathematical papyri also include units of land area in their problems. For example, several problems in the Moscow Mathematical Papyrus give the area of rectangular plots of land in terms of \"setat\" and the ratio of the sides and then require the scribe to solve for their exact lengths.\n\nThe \"setat\" was the basic unit of land measure and may originally have varied in size across Egypt's nomes. Later, it was equal to one square \"khet\", where a \"khet\" measured 100 \"cubits\". The \"setat\" could be divided into strips one \"khet\" long and ten \"cubit\" wide (a \"kha\").\n\nDuring the Old Kingdom:\n\nDuring the Middle and New Kingdom, the \"eighth\", \"fourth\", \"half\", and \"thousand\" units were taken to refer to the \"setat\" rather than the cubit strip:\n\nDuring the Ptolemaic period, the cubit strip square was surveyed using a length of 96 cubits rather than 100, although the \"aroura\" was still figured to compose 2756.25m². A 36sq.cubit area was known as a \"kalamos\" and a 144sq.cubit area as a \"hamma\". The uncommon \"bikos\" may have been 1½\"hammata\" or another name for the cubit strip. The Coptic \"shipa\" () was a land unit of uncertain value, possibly derived from Nubia.\n\nUnits of volume appear in the mathematical papyri. For example, computing the volume of a circular granary in RMP42 involves cubic cubits, khar, heqats, and quadruple heqats. RMP80 divides heqats of grain into smaller henu.\n\nThe oipe was also formerly romanized as the \"apet\".\n\nWeights were measured in terms of deben. This unit would have been equivalent to 13.6 grams in the Old Kingdom and Middle Kingdom. During the New Kingdom however it was equivalent to 91 grams. For smaller amounts the qedet (1/10 of a deben) and the shematy (1/12 of a deben) were used.\n\nThe qedet or kedet is also often known as the \"kite\", from the Coptic form of the same name ( or ). In 19th-century sources, the deben and qedet are often mistakenly transliterated as the \"uten\" and \"kat\" respectively, although this was corrected by the 20th century.\n\nThe former annual flooding of the Nile organized prehistoric and ancient Egypt into three seasons: Akhet (\"Flood\"), Peret (\"Growth\"), and Shemu or Shomu (\"Low Water\" or \"Harvest\").\n\nThe Egyptian civil calendar in place by Dynasty V followed regnal eras resetting with the ascension of each new pharaoh. It was based on the solar year and apparently initiated during a heliacal rising of Sirius following a recognition of its rough correlation with the onset of the Nile flood. It followed none of these consistently, however. Its year was divided into 3 seasons, 12 months, 36 decans, or 360 days with another 5 epagomenal days—celebrated as the birthdays of five major gods but feared for their ill luck—added \"upon the year\". The Egyptian months were originally simply numbered within each season but, in later sources, they acquired names from the year's major festivals and the three decans of each one were distinguished as \"first\", \"middle\", and \"last\". It has been suggested that during the Nineteenth Dynasty and the Twentieth Dynasty the last two days of each decan were usually treated as a kind of weekend for the royal craftsmen, with royal artisans free from work. This scheme lacked any provision for leap year intercalation until the introduction of the Alexandrian calendar by Augustus in the 20s, causing it to slowly move through the Sothic cycle against the solar, Sothic, and Julian years. Dates were typically given in a YMD format.\n\nThe civil calendar was apparently preceded by an observational lunar calendar which was eventually made lunisolar and fixed to the civil calendar, probably in 357. The months of these calendars were known as \"temple months\" and used for liturgical purposes until the closing of Egypt's pagan temples under Theodosius I in the 390s and the subsequent suppression of individual worship by his successors.\n\nSmaller units of time were vague approximations for most of Egyptian history. Hours—known by a variant of the word for \"stars\"—were initially only demarcated at night and varied in length. They were measured using decan stars and by water clocks. Equal 24-part divisions of the day were only introduced in 127. Division of these hours into 60 equal minutes is attested in Ptolemy's 2nd-century works.\n\n\n\n"}
{"id": "460615", "url": "https://en.wikipedia.org/wiki?curid=460615", "title": "British undergraduate degree classification", "text": "British undergraduate degree classification\n\nThe British undergraduate degree classification system is a grading structure for undergraduate degrees or bachelor's degrees and integrated master's degrees in the United Kingdom. The system has been applied (sometimes with significant variations) in other countries and regions.\n\nIn the 16th century, the Regius Professor of Divinity at the University of Cambridge implemented norm referencing to distinguish the top 25% of candidates, the next 50%, and the bottom 25%.\n\nThe classification system as currently used in the United Kingdom was developed in 1918. Honours were then a means to recognise individuals who demonstrated depth of knowledge or originality, as opposed to relative achievement in examination conditions.\n\nRecently, there has been concern over possible grade inflation due to increasing numbers of higher-class honours degrees awarded per annum. The number of first-class honours degrees has reportedly tripled since the 1990s. As with claimed grade inflation of A-levels, prospective employers or educational institutions have observed increased difficulty in selecting candidates. It is, however, unknown whether the rise in the number of first-class degrees is due to grade inflation or whether students are achieving higher levels than in the past. University leaders have also pointed at the higher A-levels attained by students as evidence that higher degree grades should be expected. On the other hand, the practice of degree classification has been criticised for unduly stigmatising students and being unreflective of a graduate's success or potential for success, particularly in the workplace.\n\nA bachelor's degree can be an \"honours degree\" (bachelor's with honours) or an \"ordinary degree\" (bachelor's without honours). Honours degrees are classified, usually based on a weighted average (with higher weight given to marks in the later years of the course, and often zero weight to those in the first year) of the marks gained in exams and other assessments. Grade boundaries can vary by institution, but typical values are given below.\n\n\nStudents who do not achieve honours may be awarded an ordinary degree, sometimes known as a \"pass\". Ordinary degrees, and other exit awards such as the Diploma of Higher Education (DipHE; for completing the first two years of a degree course) and Certificate of Higher Education (CertHE; for completing the first year of a degree course), may be unclassified (pass/fail) or, particularly in Scotland where the ordinary degree is offered as a qualification in its own right, classified into pass, merit and distinction. Foundation degrees are normally classified into pass, merit and distinction.\n\nIntegrated master's degrees are usually classified with honours in the same way as a bachelor's honours degree, although some integrated master's degrees are classified like postgraduate taught master's degrees into pass (usually 50%), merit (60%) and distinction (70%).\n\nAt most institutions, the system allows a small amount of discretion. A candidate may be elevated to the next degree class if his or her average marks are close to (or the median of their weighted marks achieves) the higher class, and if they have submitted several pieces of work worthy of the higher class. However, even students with a high average mark may be unable to take honours if they have failed part of the course and so have insufficient credits.\n\nIn England, Wales and Northern Ireland, a bachelor's degree with honours normally takes three years of full-time study and usually requires 360 credits, of which at least 90 are at level 6 (final year of a bachelor's degree) level, while an ordinary bachelor's degree normally requires 300 credits, of which 60 are at level 6. In Scotland, the honours bachelor's degree takes four years and requires 480 credits with a minimum of 90 at level 10 of the Scottish framework (last year of the honours degree) and 90 at level 9 (penultimate year), while the ordinary degree takes three years and requires 360 credits with a minimum of 60 at level 9 (last year of the ordinary degree).\n\nIn Scotland, it is possible to start university a year younger than in the rest of the United Kingdom, as the Scottish Higher exams are often taken at age 16 or 17 (as opposed to 18), so Scottish students often end a four-year course at the same age as a student from elsewhere in the UK taking a three-year course, assuming no gap years or students skipping the first year (direct entry to 2nd year).\n\nWhen a candidate is awarded a degree with honours, \"(Hons)\" may be suffixed to their designatory letters — for example, BA (Hons), BSc (Hons), BMus (Hons), MA (Hons). An MA (Hons) would generally indicate a degree award from certain Scottish universities (c.f. Scottish MA) and is at the same level as a bachelor's degree. \n\nThe Higher Education Statistics Agency (HESA) has published the number of degrees awarded with different classifications since 1994/5. The relative proportions of different classes have changed over this period, with increasing numbers of students being awarded higher honours. The table below shows the percentage of classified degrees (i.e. not including fails or unclassified degrees such as MBBS) in each class at five year intervals; note that HESA stopped giving statistics separately for third class honours and pass degree after 2003 and that a small number of undivided second class honours degrees (shown under \"other\" along with \"unknown\", which makes up the bulk of this category) were awarded up to 1996.\n\nFirst-class honours, referred to as a \"first\", is the highest honours classification and indicates high academic achievement.\n\nIn 2010 and 2011, the Higher Education Statistics Agency (HESA) reported that approximately 15% of all degree candidates graduated with first-class honours. The percentages of graduates achieving a first vary greatly by university and course studied. For example, students of law are least likely to gain a first, whereas students of mathematical sciences are most likely to gain a first. In 2006–2007 and 2010–2011, 5.8% and 8.1% of law students gained a first, respectively; however, in those years, 28.9% and 30.0% of mathematics students gained a first, respectively.\n\nThe upper division is commonly abbreviated to \"2:1\" or \"II.i\" (pronounced \"two-one\"). The 2:1 is a minimum requirement for entry to many postgraduate courses in the UK. It is also required for the award of a research council postgraduate studentship in the UK, although possession of a master's degree can render a candidate eligible for an award if their initial degree was below the 2:1 standard.\nThe percentage of candidates who achieve upper second-class honours can vary widely by degree subject, as well as by university.\n\nThis is the lower division of second-class degrees and is abbreviated as \"2:2\" or \"II.ii\" (pronounced \"two-two\"). It is also informally known as a \"Desmond\", named after Desmond Tutu.\n\nThird-class honours, referred to as a \"third\", is the lowest honours classification in most modern universities. Historically, the University of Oxford awarded fourth-class honours degrees and, until the late 1970s, did not distinguish between upper and lower second-class honours degrees.\n\nInformally, the third-class honours degree is referred to as a \"gentleman's degree\" (\"cf.\" the \"gentleman's C\" in the U.S.).\n\nApproximately 7.2% of students graduating in 2006 with an honours degree received a third-class honours.\n\nWhile most university bachelor's degree courses lead to honours degrees, some universities offer courses leading to ordinary degrees. Some honours courses permit students who do not gain sufficient credits in a year by a small margin to transfer to a parallel ordinary degree course. Ordinary degrees may also sometimes be awarded to honours degree students who do not pass sufficient credits in their final year to gain an honours degree, but pass enough to earn an ordinary degree.\n\nSome Scottish universities offer three-year ordinary degrees as a qualification in their own right, as well as an honours degree over four years. This is in contrast to English universities that have honours degrees with three years of study. An ordinary degree in Scotland is not a failed honours degree, as in certain English universities. Students can decide, usually at the end of their second or third year, whether or not they wish to complete a fourth honours year. Scottish universities may also award their ordinary degrees with distinction if a student achieves a particularly good grade average, usually 70% or above. A common example of a Scottish ordinary degree is the Bachelor of Laws course taken by graduates of other subjects, as this is sufficient (without honours) for entry into the legal profession. In other countries, Malawi for example, Mzuzu University offers four year ordinary degrees. The degree follows the same classification as those in the United Kingdom. Grades attained in the last two years ( year three and four) including internship and dissertation, contribute to the final degree classification.\n\nAn \"aegrotat\" (; ) degree is an honours or ordinary degree without classification, awarded under the presumption that, had a candidate who was unable to undertake their exams due to illness or even death completed those exams, they would have satisfied the standard required for that degree. \"Aegrotat\" degrees are often qualified with an appended \"(\"aegrotat\")\".\n\nFollowing the introduction of current regulations regarding mitigating circumstances, \"aegrotat\" degrees are less commonly awarded than they previously were.\n\nAt the University of Cambridge, undergraduate Tripos examinations are split into three parts (e.g. Part IA, IB, and II), or two parts (Part I and II). Part II is taken at the end of final year. Each student receives a formal classification for each part (i.e. Class I, II.I, II.II, or III). Typically, the Part II grade that corresponds with final examinations is quoted, but officially a grade simply exists for every Part of the degree, not for the overall degree.\n\nAt the University of Oxford, a formal degree Class is given, and this is typically based on the final examinations. In Oxford, examinations for Prelims or Honour Moderations are also undertaken in first/second year, but these results do not typically affect the final degree classification. Until the 1970s, the four honours divisions in Oxford's moderations and final examinations were named first, second, third and fourth class, but eventually Oxford gave in and adopted the numbering used by other English universities.\n\nAt the University of Cambridge, Triposes were previously split into two parts: Part I and Part II. Attaining First Class Honours in both parts would culminate in graduating with a \"Double First\". Most Triposes were later split into three parts: \"Part IA,\" \"Part IB\" and \"Part II\", or \"Part I\", \"Part IIA\" and \"Part IIB\". Attaining a First Class in all three parts culminates in graduating with a \"Triple First\". The frequency of this honour varies with subject, but typically fewer than 3% of students will achieve this distinction. It is possible in some of the humanities Triposes to be awarded a \"Starred First\", for examination scripts that \"consistently exhibit the qualities of first class answers to an exceptional degree.\" The science Triposes do not award Starred Firsts.\n\nOxford sometimes grants a congratulatory first, which \"The New York Times\" described as \"a highly unusual honor in which the examining professors ask no questions about the candidate's written work but simply stand and applaud\", and Martin Amis described as \"the sort where you are called in for a viva and the examiners tell you how much they enjoyed reading your papers\". A \"double first\" at Oxford usually informally refers to first-class honours in both components of an undergraduate degree, i.e. Moderations/Prelims and the Final Honour School, or in both the bachelor's and master's components of an integrated master's degree.\n\nAt University College London, candidates who perform well beyond the requirements of a standard First Class Honours may be nominated to the Dean's List. This is generated once per year and recognizes outstanding academic achievement in final examinations. There are no set criteria for nomination to the list, but typically only a nominal number of students from each faculty are nominated per year.\n\nThe University of St Andrews gives equivalences between French and British grades for its study-abroad programme. Equivalencies for the purposes of initial teacher training have also been derived by the UK NARIC for 1st, 2:1 and 2:2 degrees, which do not align with St Andrews' table.\nThe South African Qualifications Authority (SAQA) compares international degrees with local degrees before any international student continues their studies in that country. While the British degree accreditation and classification system allows students to go straight from a three-year bachelor's degree onto a master's degree (normally requiring a 1st or a 2:1 – those with a 2:2 or a 3rd usually require appropriate professional experience), South Africa does not do so unless the student has proven research capabilities. South African Honours degrees prepare the students to undertake a research-specific degree (in terms of master's), by spending an in-depth year (up to 5 modules) creating research proposals and undertaking a research project of limited scope. This prepares students for the research degrees later in their academic career.\n\nThe UK NARIC has derived equivalencies for the grades of the Spanish \"grado\" and \"licenciatura\" degrees for purposes of initial teacher training bursaries.\nThe Netherlands organisation for international cooperation in higher education (NUFFIC) has compared UK degree classification to Dutch degree grades. Dutch equivalencies have also been calculated by the UK NARIC.\n\nNUFFIC also noted that the grading culture is different in the Netherlands, so that it is very rare for even the best students in the Netherlands to be awarded a 9 or a 10, which represent near perfection and absolute perfection.\n\nBritish honours degrees are sometimes considered equivalent (by British sources) to a US master's degree, with the US bachelor's degree being equivalent to a British pass degree, due to the much higher degree of specialisation in the UK. However, many British institutions accept US bachelor's degrees for admission to postgraduate study (see below) and US comparison services treat British and American degrees as equivalent. When US bachelor's degrees are compared to British honours degrees, equivalencies can be expressed in terms of either US Grade Point Averages (GPAs) or letter grades.\n\nBritish institutions normally state equivalence in terms of GPAs. Approximate mappings between British classifications and GPAs can be inferred from the graduate admissions criteria used by British universities, which often give international equivalents. For example, University College London (UCL) equates the minimum classification for entrance to GPAs using 1st = 3.6, 2:1 = 3.3 and 2:2 = 3.0. However, different universities convert grades differently: the London School of Economics and Political Science (LSE) considers a GPA (U.S.) of 3.5 or better as equivalent to gaining a 2:1, while the department of English Language and Literature at Oxford considers a GPA of \"about 3.8\" equivalent to a first class degree. Similarly, the UK NARIC gives equivalent GPAs for determining eligibility for teacher training bursaries. In contrast, Durham University's \"North American Undergraduate Guide 2017\" gives a conversion table as a guide to understanding British classifications (rather than for admission to postgraduate study) of 1st = 3.8–4.0, 2:1 = 3.3–3.7, 2:2 = 2.8–3.2 and 3rd = 2.3–2.7. \nThe GPA conversions are summarised in the following table:\n\nLetter grade equivalents are more commonly used by American institutions. World Education Services (WES), a nonprofit organisation which provides qualification conversion services to many universities and employers, gives 1st = A, 2:1 = A-/B+, 2:2 = B, 3rd = B-, Pass = C, which would convert British degrees to higher GPAs than the conversion used by UCL if the guidelines for converting grades to GPA given by Duke University are used. The Fulbright Commission has also created \"an unofficial chart with approximate grade conversions between UK results and US GPA.\"\n\nCanadian academic grades may be given as letters, percentages, 12-point GPAs or 4-point GPAs. The 4-point GPAs are sometimes seen to differ from the US but other sources treat them as equivalent. The Durham conversion specifies GPAs for the US and letter grades/percentages for Canada while the UK NARIC has separate GPA conversions for the four-year bachelor's honours, baccalauréat and professional bachelor's degrees (which differ from their US GPA equivalents by at most 0.1) and the three-year bachelor's degree (which is seen as a lower standard). The \"British Graduate Admissions Fact Sheet\" from McGill University uses the conversion 1st = 4.0; 2:1 = 3.0; 2:2 = 2.7; 3rd = 2.0; Pass = 1.0; Fail = 0.0.\n\nDegrees in the UK are mapped to levels of the Frameworks for Higher Education Qualifications of UK Degree-Awarding Bodies (FHEQ), which includes the Framework for Qualifications of Higher Education Institutes in Scotland (FQHEIS), which has an alternative numbering of levels corresponding to those of the Scottish Credit and Qualifications Framework (SCQF). Bachelor's degrees (including the Scottish MA, but not including medical degrees, dentistry degrees or degrees in veterinary science) attained in the UK are at FHEQ level 6/FQHEIS level 9 (ordinary) or 10 (honours); master's degrees (including integrated master's degrees and first degrees in medicine, dentistry and veterinary science) are at FHEQ level 7/FQHEIS level 11, and doctoral degrees are at FHEQ level 8/FQHEIS level 12. Bachelor's, master's and doctoral degrees map to first, second and third cycle qualifications in the Qualifications Framework of the European Higher Education Area.\n\nRegulations governing the progression of undergraduate degree graduates to postgraduate programmes vary among universities, and are often flexible. A candidate for a postgraduate master's degree is usually required to have at least a 2:2 bachelor honours degree, although candidates with 2:1s are in a considerably stronger position to gain a place in a postgraduate course and to obtain funding, especially in medical and natural sciences. Some institutions specify a 2:1 minimum for certain types of master's program, such as for a Master of Research course.\n\nCandidates with a Third or an Ordinary degree are sometimes accepted, provided they have acquired satisfactory professional experience subsequent to graduation. A candidate for a doctoral programme who does not hold a master's degree is nearly always required to have a First or 2:1 at bachelor's level.\n\nSome universities, such as those in Australia, offer ordinary or pass degrees, (for instance, as a three-year B.A. or a three-year BSc) by default. High-achieving students may be recognised with an honours classification without further coursework or research, as is often the case in engineering, which often contains a research and thesis component, or law. However, other courses (such as humanities, arts, social sciences, and sciences) and other universities may recognise high-achieving students with an honours classification with further coursework or research, undertaken either concurrently with, and as part of or in addition to, a bachelor's course, or after completion of a bachelor's course requirements and attaining adequately competitive grades.\n\nSome graduate degrees have been or are classified; however, under the Australian Qualifications Framework (AQF), no graduate-level degrees (i.e., master's by coursework, master's by research, or higher research degrees) may be classified. To comply with this standard, some institutions have commenced, or will commence, offering high-achieving graduates with \"distinction\". Notably, this is consistent with British graduate degree classification.\n\nIn the United Kingdom, medicine is usually taught as an undergraduate course, with graduates being awarded a master's level qualification: normally the conjoined degrees of Bachelor of Medicine, Bachelor of Surgery (MBBS, BM BCh, MB ChB, etc.) although at Queen's University Belfast (and universities in Ireland) Bachelor in the Art of Obstetrics (BAO) is added, and at some universities only the Bachelor of Medicine is awarded - all of these have equal standing. Unlike most undergraduate degrees, the MBBS is not normally considered an honours degree, and thus is not classified into first class honours, etc. Students may be awarded \"Merits\" and \"Distinctions\" for parts of the course or the whole course (depending on the institution) and \"Honours\" may be awarded at some institutions for exceptional performance throughout the course (as a grade above Distinction).\n\nMedical schools split their year groups into one of 10 deciles. These deciles are the major factor in the calculation of Educational Performance Measure (EPM) points used as part of medical students' Foundation Programme applications, with the top decile receiving 43 points, decreasing by a point for each decile (so the lowest gets 34 points); 7 points can be awarded for other educational achievements (other degrees and publications), and the EPM points are combined with up to 50 points from the Situational Judgement Test to give a total out of 100.\n\nFollowing the recommendation of the Burgess report into the honours degree classification system in 2007, the Higher Education Academy ran a pilot in 2013–2014 in collaboration with 21 institutions delivering higher education (ranging from Russell Group universities to Further Education colleges) to investigate how a Grade Point Average (GPA) system would work best in Britain. Two main weighting systems were tested: an American-style average of all marks, weighted only by credit value, and weighting by \"exit velocity\" in the manner of the honours classification, where modules in the first year are given a low or zero weight and modules in the final year have a higher weight (a third model was only rarely used). Over two thirds of providers preferred exit-velocity weighting to the straight average.\n\nA GPA scale, tied to percentage marks and letter grades, was recommended for use nationally following the study, to run in parallel with the honours degree classification system.\n\n"}
{"id": "5521182", "url": "https://en.wikipedia.org/wiki?curid=5521182", "title": "Buchholz system", "text": "Buchholz system\n\nThe Buchholz system (also spelled Buchholtz) is a ranking or scoring system in chess developed by Bruno Buchholz (died ca. 1958) in 1932, for Swiss system tournaments . It was originally developed as an auxiliary scoring method, but more recently it has been used as a tie-breaking system. It was probably first used in the 1932 Bitterfeld tournament. It was designed to replace the Neustadtl score .\n\nThe method is to give each player a raw score of one point for each win and a half point for each draw. When used as an alternate scoring system, each player's Buchholz score is calculated by adding the raw scores of each of the opponents he played and multiplying this total by the player's raw score . When used for tie-breaking among players with the same raw score, no multiplying is necessary and the sum of the raw scores of the opponents played is used to break ties . When used as a tie-break system, it is equivalent to the Solkoff system.\n\nThe major criticism of this system is that tie-break scores can be distorted by the set of opponents that each player plays (especially in early rounds). To avoid this problem a version of Buchholz, the Median-Buchholz System is sometimes used. In the Median-Buchholz System the best and worst scores of a player's opponents are discarded, and the remaining scores summed.\n\n\n\n"}
{"id": "50775649", "url": "https://en.wikipedia.org/wiki?curid=50775649", "title": "ChartDirector", "text": "ChartDirector\n\nChartDirector is a charting library for software developers to develop applications that contains charts. ChartDirector is developed by Advanced Software Engineering Ltd.\n\nChartDirector supports C++ (command line, Qt and MFC), .NET (C#, VB), Java, PHP, Perl, Python, Ruby, COM, VB6, VBA, VBScript and ColdFusion. In terms of operating systems, ChartDirector supports Windows, Linux, FreeBSD, Mac OS X, Solaris as well as any Java supporting operating systems.\n\nChartDirector can plot a number of chart types, including pie, donut, bar, line, spline, step line, regression, curve-fitting, inter-line filling, area, band, scatter, bubble, floating box, box-whisker, waterfall, contour, heat map, surface, vector, finance, gantt, radar, polar, rose, pyramid, cone and funnel. It can also draw meters and gauges.\n\nChartDirector can be used for command line, GUI, as well as web applications. It can output charts to screen as well as in PDF, SVG and images.\n\nAdvanced Software Engineering Ltd began in 1995 as a software contractor for network management applications, which contained a lot of charts. In 2001, the company decided to package its charting routines into a software library and market it as ChartDirector. Initially a C++ component, ChartDirector has since then been ported to many programming languages and operating systems.\n"}
{"id": "63392", "url": "https://en.wikipedia.org/wiki?curid=63392", "title": "Consensus reality", "text": "Consensus reality\n\nConsensus reality is that which is generally agreed to be reality, based on a consensus view.\n\nThe appeal to consensus arises from the fact that humans do not fully understand or agree upon the nature of knowledge or ontology, often making it uncertain what is real, given the vast inconsistencies between individual subjectivities. We can, however, seek to obtain some form of consensus, with others, of what is real. We can use this consensus as a pragmatic guide, either on the assumption that it seems to approximate some kind of valid reality, or simply because it is more \"practical\" than perceived alternatives. Consensus reality therefore refers to the agreed-upon concepts of reality which people in the world, or a culture or group, believe are real (or treat as real), usually based upon their common experiences as they believe them to be; anyone who does not agree with these is sometimes stated to be \"in effect... living in a different world.\"\n\nThroughout history this has also raised a social question as to the effects of a society in which all individuals do not agree upon the same reality.\n\nChildren have sometimes been described or viewed as \"inexperience[d] with consensus reality,\" though are described as such with the expectation that their perspective will progressively form closer to the consensus reality of their society as they age.\n\nIn considering the nature of reality, two broad approaches exist: the realist approach, in which there is a single, objective, overall reality believed to exist irrespective of the perceptions of any given individual, and the idealistic approach, in which it is considered that an individual can verify nothing except their own \"experience\" of the world, and can never directly know the truth of the world independent of that.\n\nConsensus reality may be understood by studying socially constructed reality, a subject within the sociology of knowledge. (Read page three of \"The Social Construction of Reality\" by Peter L. Berger and Thomas Luckmann.)\n\nConsider this example: consensus reality for people who follow a particular theocentric religion is different from consensus reality for those who follow another theocentric religion, or from those that eschew theocentric religions in favor of science alone, for explaining life and the universe.\n\nIn societies where theocentric religions are dominant, the religious understanding of existence would be the consensus reality, while the religious worldview would remain the non-consensus (or alternative) reality in a predominantly secular society, where the consensus reality is grounded in science alone.\n\nIn this way, different individuals and communities have fundamentally different world views, with fundamentally different comprehensions of the world around them, and of the constructs within which they live. Thus, a society that is, for example, completely secular and one which believes every eventuality to be subject to metaphysical influence will have very different consensus realities, and many of their beliefs on broad issues such as science, slavery, and human sacrifice may differ in direct consequence because of the differences in the perceived nature of the world they live in.\n\nSome idealists (subjective idealists) hold the view that there isn't one particular way things are, but rather that each person's personal reality is unique. Such idealists have the world view which says that we each create our own reality, and while most people may be in general agreement (consensus) about what reality is like, they might live in a different (or nonconsensus) reality.\n\nMaterialists may not accept the idea of there being different possible realities for different people, rather than different beliefs about one reality. So for them only the first usage of the term reality would make sense. To them, someone believing otherwise, where the facts have been properly established, might be considered delusional.\n\nThe connotation of the term \"consensus reality\" is usually disparaging: it is usually employed by idealist, surrealist and other anti-realist theorists opposing or hostile to this \"reality,\" with the implication that this consensus reality is, to a greater or lesser extent, created by those who experience it. (The phrase \"consensus reality\" may be used more loosely to refer to any generally accepted set of beliefs.) However, there are those who use the term approvingly for the practical benefits of all agreeing on a common set of assumptions or experiences.\n\nSingers, painters, writers, theorists and other individuals employing a number of means of action have attempted to oppose or undermine consensus reality while others have declared that they are \"ignoring\" it. For example, Salvador Dalí intended by his paranoiac-critical method to \"systematize confusion thanks to a paranoia and active process of thought and so assist in discrediting completely the world of reality\".\n"}
{"id": "1192111", "url": "https://en.wikipedia.org/wiki?curid=1192111", "title": "Conservation headland", "text": "Conservation headland\n\nA conservation headland is a strip along the edge of an agricultural field, where pesticides is sprayed only in a selective manner. This increases the number and type of weed and insect species present, and benefits the bird species that depend on them. The grey partridge is one such bird.\nConservation headlands were introduced in the 1980s by scientists working for Game & Wildlife Conservation Trust in Great Britain. Trials have taken place in southern Sweden.\n\n\n"}
{"id": "8411", "url": "https://en.wikipedia.org/wiki?curid=8411", "title": "Darwinism", "text": "Darwinism\n\nDarwinism is a theory of biological evolution developed by the English naturalist Charles Darwin (1809–1882) and others, stating that all species of organisms arise and develop through the natural selection of small, inherited variations that increase the individual's ability to compete, survive, and reproduce. Also called Darwinian theory, it originally included the broad concepts of transmutation of species or of evolution which gained general scientific acceptance after Darwin published \"On the Origin of Species\" in 1859, including concepts which predated Darwin's theories. It subsequently referred to the specific concepts of natural selection, the Weismann barrier, or the central dogma of molecular biology. Though the term usually refers strictly to biological evolution, creationists have appropriated it to refer to the origin of life, and it has even been applied to concepts of cosmic evolution, both of which have no connection to Darwin's work. It is therefore considered the belief and acceptance of Darwin's and of his predecessors' work—in place of other theories, including divine design and extraterrestrial origins.\n\nEnglish biologist Thomas Henry Huxley coined the term \"Darwinism\" in April 1860. It was used to describe evolutionary concepts in general, including earlier concepts published by English philosopher Herbert Spencer. Many of the proponents of Darwinism at that time, including Huxley, had reservations about the significance of natural selection, and Darwin himself gave credence to what was later called Lamarckism. The strict neo-Darwinism of German evolutionary biologist August Weismann gained few supporters in the late 19th century. During the approximate period of the 1880s to about 1920, sometimes called \"the eclipse of Darwinism\", scientists proposed various alternative evolutionary mechanisms which eventually proved untenable. The development of the modern synthesis in the early 20th century, incorporating natural selection with population genetics and Mendelian genetics, revived Darwinism in an updated form.\n\nWhile the term \"Darwinism\" has remained in use amongst the public when referring to modern evolutionary theory, it has increasingly been argued by science writers such as Olivia Judson and Eugenie Scott that it is an inappropriate term for modern evolutionary theory. For example, Darwin was unfamiliar with the work of the Moravian scientist and Augustinian friar Gregor Mendel, and as a result had only a vague and inaccurate understanding of heredity. He naturally had no inkling of later theoretical developments and, like Mendel himself, knew nothing of genetic drift, for example. In the United States, creationists often use the term \"Darwinism\" as a pejorative term in reference to beliefs such as scientific materialism, but in the United Kingdom the term has no negative connotations, being freely used as a shorthand for the body of theory dealing with evolution, and in particular, with evolution by natural selection.\n\nWhile the term \"Darwinism\" had been used previously to refer to the work of Erasmus Darwin in the late 18th century, the term as understood today was introduced when Charles Darwin's 1859 book \"On the Origin of Species\" was reviewed by Thomas Henry Huxley in the April 1860 issue of the \"Westminster Review\". Having hailed the book as \"a veritable Whitworth gun in the armoury of liberalism\" promoting scientific naturalism over theology, and praising the usefulness of Darwin's ideas while expressing professional reservations about Darwin's gradualism and doubting if it could be proved that natural selection could form new species, Huxley compared Darwin's achievement to that of Nicolaus Copernicus in explaining planetary motion:\nThese are the basic tenets of evolution by natural selection as defined by Darwin:\n\n\nAnother important evolutionary theorist of the same period was the Russian geographer and prominent anarchist Peter Kropotkin who, in his book \"\" (1902), advocated a conception of Darwinism counter to that of Huxley. His conception was centred around what he saw as the widespread use of co-operation as a survival mechanism in human societies and animals. He used biological and sociological arguments in an attempt to show that the main factor in facilitating evolution is cooperation between individuals in free-associated societies and groups. This was in order to counteract the conception of fierce competition as the core of evolution, which provided a rationalization for the dominant political, economic and social theories of the time; and the prevalent interpretations of Darwinism, such as those by Huxley, who is targeted as an opponent by Kropotkin. Kropotkin's conception of Darwinism could be summed up by the following quote:\n\n\"Darwinism\" soon came to stand for an entire range of evolutionary (and often revolutionary) philosophies about both biology and society. One of the more prominent approaches, summed in the 1864 phrase \"survival of the fittest\" by Herbert Spencer, later became emblematic of Darwinism even though Spencer's own understanding of evolution (as expressed in 1857) was more similar to that of Jean-Baptiste Lamarck than to that of Darwin, and predated the publication of Darwin's theory in 1859. What is now called \"Social Darwinism\" was, in its day, synonymous with \"Darwinism\"—the application of Darwinian principles of \"struggle\" to society, usually in support of anti-philanthropic political agenda. Another interpretation, one notably favoured by Darwin's half-cousin Francis Galton, was that \"Darwinism\" implied that because natural selection was apparently no longer working on \"civilized\" people, it was possible for \"inferior\" strains of people (who would normally be filtered out of the gene pool) to overwhelm the \"superior\" strains, and voluntary corrective measures would be desirable—the foundation of eugenics.\nIn Darwin's day there was no rigid definition of the term \"Darwinism\", and it was used by opponents and proponents of Darwin's biological theory alike to mean whatever they wanted it to in a larger context. The ideas had international influence, and Ernst Haeckel developed what was known as \"Darwinismus\" in Germany, although, like Spencer's \"evolution\", Haeckel's \"Darwinism\" had only a rough resemblance to the theory of Charles Darwin, and was not centered on natural selection. In 1886, Alfred Russel Wallace went on a lecture tour across the United States, starting in New York and going via Boston, Washington, Kansas, Iowa and Nebraska to California, lecturing on what he called \"Darwinism\" without any problems.\n\nIn his book \"Darwinism\" (1889), Wallace had used the term \"pure-Darwinism\" which proposed a \"greater efficacy\" for natural selection. George Romanes dubbed this view as \"Wallaceism\", noting that in contrast to Darwin, this position was advocating a \"pure theory of natural selection to the exclusion of any supplementary theory.\" Taking influence from Darwin, Romanes was a proponent of both natural selection and the inheritance of acquired characteristics. The latter was denied by Wallace who was a strict selectionist. Romanes' definition of Darwinism conformed directly with Darwin's views and was contrasted with Wallace's definition of the term.\n\nThe term \"Darwinism\" is often used in the United States by promoters of creationism, notably by leading members of the intelligent design movement, as an epithet to attack evolution as though it were an ideology (an \"ism\") of philosophical naturalism, or atheism. For example, UC Berkeley law professor and author Phillip E. Johnson makes this accusation of atheism with reference to Charles Hodge's book \"What Is Darwinism?\" (1874). However, unlike Johnson, Hodge confined the term to exclude those like American botanist Asa Gray who combined Christian faith with support for Darwin's natural selection theory, before answering the question posed in the book's title by concluding: \"It is Atheism.\" Creationists use the term \"Darwinism\", often pejoratively, to imply that the theory has been held as true only by Darwin and a core group of his followers, whom they cast as dogmatic and inflexible in their belief. In the 2008 documentary film \"\", which promotes intelligent design (ID), American writer and actor Ben Stein refers to scientists as Darwinists. Reviewing the film for \"Scientific American\", John Rennie says \"The term is a curious throwback, because in modern biology almost no one relies solely on Darwin's original ideas... Yet the choice of terminology isn't random: Ben Stein wants you to stop thinking of evolution as an actual science supported by verifiable facts and logical arguments and to start thinking of it as a dogmatic, atheistic ideology akin to Marxism.\" \n\nHowever, \"Darwinism\" is also used neutrally within the scientific community to distinguish the modern evolutionary synthesis, sometimes called \"neo-Darwinism\", from those first proposed by Darwin. \"Darwinism\" also is used neutrally by historians to differentiate his theory from other evolutionary theories current around the same period. For example, \"Darwinism\" may be used to refer to Darwin's proposed mechanism of natural selection, in comparison to more recent mechanisms such as genetic drift and gene flow. It may also refer specifically to the role of Charles Darwin as opposed to others in the history of evolutionary thought—particularly contrasting Darwin's results with those of earlier theories such as Lamarckism or later ones such as the modern evolutionary synthesis.\n\nIn political discussions in the United States, the term is mostly used by its enemies. \"It's a rhetorical device to make evolution seem like a kind of faith, like 'Maoism,'\" says Harvard University biologist E. O. Wilson. He adds, \"Scientists don't call it 'Darwinism'.\" In the United Kingdom the term often retains its positive sense as a reference to natural selection, and for example British ethologist and evolutionary biologist Richard Dawkins wrote in his collection of essays \"A Devil's Chaplain\", published in 2003, that as a scientist he is a Darwinist.\n\nIn his 1995 book \"Darwinian Fairytales\", Australian philosopher David Stove used the term \"Darwinism\" in a different sense than the above examples. Describing himself as non-religious and as accepting the concept of natural selection as a well-established fact, Stove nonetheless attacked what he described as flawed concepts proposed by some \"Ultra-Darwinists.\" Stove alleged that by using weak or false \"ad hoc\" reasoning, these Ultra-Darwinists used evolutionary concepts to offer explanations that were not valid (e.g., Stove suggested that sociobiological explanation of altruism as an evolutionary feature was presented in such a way that the argument was effectively immune to any criticism). Philosopher Simon Blackburn wrote a rejoinder to Stove, though a subsequent essay by Stove's protegee James Franklin's suggested that Blackburn's response actually \"confirms Stove's central thesis that Darwinism can 'explain' anything.\"\n\n"}
{"id": "4897231", "url": "https://en.wikipedia.org/wiki?curid=4897231", "title": "Dream argument", "text": "Dream argument\n\nThe dream argument is the postulation that the act of dreaming provides preliminary evidence that the senses we trust to distinguish reality from illusion should not be fully trusted, and therefore, any state that is dependent on our senses should at the very least be carefully examined and rigorously tested to determine whether it is in fact reality.\n\nWhile one dreams, one does not normally realize one is dreaming. This has led philosophers to wonder whether it is possible for one ever to be certain, at any given point in time, that one is not in fact dreaming, or whether indeed it could be possible for one to remain in a perpetual dream state and never experience the reality of wakefulness at all.\n\nIn the West, this philosophical puzzle was referred to by Plato (\"Theaetetus\" 158b-d) and Aristotle (\"Metaphysics\" 1011a6). Having received serious attention in René Descartes' \"Meditations on First Philosophy\", the dream argument has become one of the most prominent skeptical hypotheses.\n\nThis type of argument is sometimes referred to as the \"Zhuangzi paradox\":\n\nHe who dreams of drinking wine may weep when morning comes; he who dreams of weeping may in the morning go off to hunt. While he is dreaming he does not know it is a dream, and in his dream he may even try to interpret a dream. Only after he wakes does he know it was a dream. And someday there will be a great awakening when we know that this is all a great dream. Yet the stupid believe they are awake, busily and brightly assuming they understand things, calling this man ruler, that one herdsman—how dense! Confucius and you are both dreaming! And when I say you are dreaming, I am dreaming, too. Words like these will be labeled the Supreme Swindle. Yet, after ten thousand generations, a great sage may appear who will know their meaning, and it will still be as though he appeared with astonishing speed.\n\nOne of the first philosophers to posit the dream argument formally was the Yogachara philosopher Vasubandhu (4th to 5th century C.E.) in his \"Twenty verses on appearance only.\" \n\nThe dream argument came to feature prominently in Mahayana and Tibetan Buddhist philosophy. Some schools of thought (\"e.g.\", Dzogchen) consider \"perceived reality\" to be literally unreal. As Chögyal Namkhai Norbu puts it: \"In a real sense, all the visions that we see in our lifetime are like a big dream . . . .\" In this context, the term 'visions' denotes not only visual perceptions, but also appearances perceived through all senses, including sounds, smells, tastes, and tactile sensations, and operations on perceived mental objects.\n\nA paradox concerning dreams and the nature of reality was described by the British writer Eric Bond Hutton in 1989. As a child Hutton often had lucid dreams, in which everything seemed as real as in waking life. This led him to wonder whether life itself was a dream, even whether he existed only in somebody else's dream. Sometimes he had pre-lucid dreams, in which more often than not he concluded he was awake. Such dreams disturbed him greatly, but one day he came up with a magic formula for use in them: \"If I find myself asking 'Am I dreaming?' it proves I am, for the question would never occur to me in waking life.\" Yet, such is the nature of dreams, he could never recall it when he needed to. Many years later, when he wrote a piece about solipsism and his childhood interest in dreams, he was struck by a contradiction in his earlier reasoning. True, asking oneself \"Am I dreaming?\" \"in a dream\" would seem to prove one is. Yet that is precisely what he had often asked himself in waking life. Therein lay a paradox. What was he to conclude? That it does not prove one is dreaming? Or that life really is a dream?\n\nDreaming provides a springboard for those who question whether our own reality may be an illusion. The ability of the mind to be tricked into believing a mentally generated world is the \"real world\" means at least one variety of simulated reality is a common, even nightly event.\n\nThose who argue that the world is not simulated must concede that the mind—at least the sleeping mind—is not itself an entirely reliable mechanism for attempting to differentiate reality from illusion.\n\nIn the past, philosophers John Locke and Thomas Hobbes have separately attempted to refute Descartes's account of the dream argument. Locke claimed that you cannot experience pain in dreams. Various scientific studies conducted within the last few decades provided evidence against Locke's claim by concluding that pain in dreams can occur but the pain isn't as severe. Philosopher Ben Springett has said that Locke might respond to this by stating that the agonising pain of stepping in to a fire is non-comparable to stepping in to a fire in a dream. Hobbes claimed that dreams are susceptible to absurdity while the waking life is not.\n\nMany contemporary philosophers have attempted to refute dream skepticism in detail (see, e.g., Stone (1984)). Ernest Sosa (2007) devoted a chapter of a monograph to the topic, in which he presented a new theory of dreaming and argued that his theory raises a new argument for skepticism, which he attempted to refute. In \"A Virtue Epistemology: Apt Belief and Reflective Knowledge\", he states: \"in dreaming we do not really believe; we only make-believe.\"\nJonathan Ichikawa (2008) and Nathan Ballantyne & Ian Evans (2010) have offered critiques of Sosa's proposed solution. Ichikawa argued that as we cannot tell whether our beliefs in waking life are truly beliefs and not imaginings, like in a dream, we are still not able to tell whether we are awake or dreaming.\n\nNorman Malcolm in his monograph \"Dreaming\" (published in 1959) elaborated on Wittgenstein's question as to whether it really mattered if people who tell dreams \"really had these images while they slept, or whether it merely seems so to them on waking\". He argues that the sentence \"I am asleep\" is a senseless form of words; that dreams cannot exist independently of the waking impression; and that scepticism based on dreaming \"comes from confusing the historical and dream telling senses...[of]...the past tense\". (page 120). In the chapter: \"Do I Know I Am Awake ?\" he argues that we do not have to say: \"I know that I am awake\" simply because it would be absurd to deny that one is awake.\n\nThe dream hypothesis is also used to develop other philosophical concepts, such as Valberg's personal horizon: what this world would be internal to if \"this\" were all a dream.\n\n\n\nMalcolm, N. (1959) Dreaming London: Routledge & Kegan Paul, 2nd Impression 1962.\n"}
{"id": "38090349", "url": "https://en.wikipedia.org/wiki?curid=38090349", "title": "EdgeRank", "text": "EdgeRank\n\nEdgeRank is the name commonly given to the algorithm that Facebook uses to determine what articles should be displayed in a user's News Feed. As of 2011, Facebook has stopped using the EdgeRank system and uses a machine learning algorithm that, as of 2013, takes more than 100,000 factors into account.\n\nEdgeRank was developed and implemented by Serkan Piantino.\n\nIn 2010, a simplified version of the EdgeRank algorithm was presented as:\n\nwhere:\n\n\nSome of the methods that Facebook uses to adjust the parameters are proprietary and not available to the public.\n\nEdgeRank and its successors have a broad impact on what users actually see out of what they ostensibly follow: for instance, the selection can produce a filter bubble (if users are exposed to updates which confirm their opinions etc.) or alter people's mood (if users are shown a disproportionate amount of positive or negative updates).\n\nAs a result, for Facebook pages, the typical engagement rate is less than 1 % (or less than 0.1 % for the bigger ones) and organic reach 10 % or less for most non-profits.\n\nAs a consequence, for pages it may be nearly impossible to reach any significant audience without paying to promote their content.\n\n\n"}
{"id": "87233", "url": "https://en.wikipedia.org/wiki?curid=87233", "title": "Electronic tagging", "text": "Electronic tagging\n\nElectronic tagging is a form of surveillance which uses an electronic device, fitted to the person. For example, an ankle monitor is used for people who have been sentenced to electronic monitoring by a court, or are required to wear a tag upon release from prison. It is also used in healthcare settings with people with dementia and in immigration contexts in some jurisdictions. If the device is based on GPS technology, it is usually attached to a person by a probation officer, law enforcement or a private monitoring services company field officer, and is capable of tracking the wearer's location wherever there is the satellite signal to do so. Electronic monitoring tags can be also used in combination with curfews to confine defendants or offenders to their home as a condition of bail, as a stand-alone order or as a form of early release from prison. The combination of electronic monitoring with a curfew usually relies on radio frequency (RF) technology, which differs from GPS technology.\n\nThe use of home detention as a means of confinement and control within the home can be traced back to biblical times when the Romans placed Paul the Apostle, under house arrest.\nIn the 18th century, the English philosopher and social theorist Jeremy Bentham designed the Panopticon, a hypothetical prison. Inside the Panopticon (the name is derived from the Greek word for \"all-seeing\"), the prisoners are arranged in a ring of cells surrounding their guard, who is concealed in a tower in the center. The idea is that the guard controls the prisoners through his presumed observation: they constantly imagine his eyes on them, even when he's looking elsewhere.\n\nBentham promoted the concept of the Panopticon for much the same reasons that spur criminal-justice innovation today—a ballooning prison population and the need for a cheap solution with light manpower demands. when the modern prison emerged, it, too, was promoted as a reform, a positive replacement for corporal or capital punishment.\n\nEarly prison reformers—many of them Quakers bent on repentance and redemption— had suggested that cutting people off from the rest of the world would bring them closer to God. (The word \"penitentiary\" comes, of course, from \"penitence.\") Whereas the guard in Bentham's day had only two eyes, today's watcher can be virtually all-seeing, thanks to GPS monitoring technology.\n\nIn 1964, Ralph Kirkland Schwitzgebel (family name later shortened to \"Gable\") headed a research team at the Science Committee on Psychological Experimentation at Harvard University. The technologies of electronic monitoring have their roots in his (1968) experiments with prototype electronic monitoring devices. Schwitzgebel and William S. Hurd were granted patent #3,478,344 and published an article informing how such monitoring devices could be used.\nHe developed a one-kilogram Radio Telemetry Device that could be worn by a person. The device transmitted signals to a modified missile-tracking unit up to 400 metres away, which determined the wearer's location on a screen. The Harvard researchers invented and assessed a prototype monitoring system to use upon juvenile offenders. The public responded unfavorably on the whole, fearing that the devices were overly intrusive.\n\nEven in 1966 it was noted that, in theory, the system could be modified to gather and transmit physiological data such as pulse rates, blood alcohol levels, brain waves, or information on other bodily functions of the wearer and, conversely, that information or stimulation could be sent back to the person wearing the transmitting device. It could also be easily adapted to serve as a listening device or two-way radio. The system was tested on volunteers who included students, parolees and mental patients, and experiments along these lines exploring its possibilities were conducted. in 1969 Schwitzgebel was granted a patent in relation to the system.\n\nIn 1978, in diversion from its criminal justice application, a company called BI Incorporated began selling systems that allowed dairy farmers to dispense feed to their cows automatically. The company fitted a radio-frequency tag on each cow's ear so that when the cow approached the feed dispenser, a sensor in the latter caused it to drop a ration of fodder. If the same cow returned, the sensor recognized the unique signal of the tag and prevented the cow from getting a second helping until after enough time had passed for her to digest the first.\n\nIn 1981, writer Tom Stacey took to the British Home Office a proposal for the electronic tagging of offenders to track their movements, or fix a home curfew, using cellular radio telephone technology. Stacey had been briefly imprisoned abroad in his former role as a foreign correspondent and had for several years served as a \"Prison Visitor\" in England. In a letter to \"The Times\" on 6 October 1982 he outlined the proposal and immediate founded the \"Offender's Tag Association\", composed of electronic scientists, penologists and prominent citizens. The term 'tagging' thus entered the British English vocabulary in the penal context. \nIn March 1983, the \"Offender's Tag Association\" held a national press conference.\n\nLater in 1983, a district court judge in Albuquerque, New Mexico, Jack Love, persuaded Michael Goss, a computer salesperson, to develop a system to monitor five offenders. He sentenced offenders in what is considered the first court-sanctioned use of electronic monitoring at home. Judge Love was supposedly inspired to act based upon a storyline in a \"Spider-Man\" comic, specifically the newspaper comic strip version where the Kingpin puts an electronic bracelet on the superhero primarily to follow his movements.\n\nUntil the widespread adoption of cellular and broadband Internet networks in the US in the mid-1990s, electronic monitoring devices were typically home-based, dependent on a dedicated land line, and able to report only whether or not the criminal being tracked, was remaining at home. This was useful for criminals on work-release, parole, or probation, for example DWI offenders who were allowed to leave home to go to work during daytime hours but had to return home and remain there after a certain time of the evening.\n\nSince the mid-1990s, more recent technology such as GPS and cellular networks have permitted courts to order more specific restrictions, such as permitting a registered child sex offender to leave his home at any time of day, but alerting authorities if they come within 100 metres of a school, park, or playground.\n\nTrilateration is the process of determining absolute or relative locations of points by measurement of distances, using the geometry of circles, spheres or triangles.\n\nIf someone in the United States completely lost track of where he last was, asked directions in a nearby town and a local tells that he was 625 miles from Boise, Idaho, he could be anywhere on a circle around Boise that has a radius of 625 miles. If he then asked another person and was told that he was 690 miles from Minneapolis, Minnesota, he could combine this with the Boise information in two circles that intersect. He would know that he was at one of the two intersection points. If a third person told him that he was 615 miles from Tucson, Arizona, he could then eliminate the other options, because the third circle would only intersect with one of these points. The same concept works in three-dimensional space, as well, where there is only spheres instead of circles.\nIf someone knows he is 10 miles from satellite A in the sky, he could be anywhere on the surface of a huge, imaginary sphere with a 10-mile radius. If he also knows he is 15 miles from satellite B, he could overlap the first sphere with another, larger sphere. If he then also knows the distance to a third satellite, he could get a third sphere, which intersects with this circle at two points.\n\nThe Earth itself can act as a fourth sphere—only one of the two possible points will actually be on the surface of the planet, so one can eliminate the sphere in space. The GPS receiver figures both of these things out by analyzing high-frequency, low-power radio signals from the GPS satellites.\n\nRadio waves are electromagnetic energy, which means they travel at the speed of light (about 186,000 miles per second, 300,000 km per second in a vacuum). The receiver can figure out how far the signal has traveled by timing how long it took the signal to arrive.\n\nThe correct time value will cause all of the signals that the receiver is receiving to align at a single point in space. So the receiver sets its clock to that time value, and it then has the same time value that all the atomic clocks in all of the satellites have. When you measure the distance to four located satellites, you can draw four spheres that all intersect at one point. Three spheres will intersect even if your numbers are way off, but four spheres will not intersect at one point if you've measured incorrectly. The receiver does this constantly whenever it's on, which means it is nearly as accurate as the expensive atomic clocks in the satellites.\n\nIn order for the distance information to be of any use, the receiver also has to know where the satellites actually are. Things like the pull of the moon and the sun do change the satellites' orbits very slightly, but the Department of Defense constantly monitors their exact positions and transmits any adjustments to all GPS receivers as part of the satellites' signals.\n\nFor one thing, this method assumes the radio signals will make their way through the atmosphere at a consistent speed, the speed of light. Problems can also occur when radio signals bounce off large objects, such as skyscrapers, giving a receiver the impression that a satellite is farther away than it actually is. The station then broadcasts a radio signal to all DGPS-equipped receivers in the area, providing signal correction information for that area.\n\nThe most essential function of a GPS receiver is to pick up the transmissions of at least four satellites and combine the information in those transmissions with information in an electronic almanac, all in order to figure out the receiver's position on Earth.\n\nOnce the receiver makes this calculation, it can compute the latitude, longitude and altitude (or some similar measurement) of its current position.\nOne can use maps stored in the receiver's memory, connect the receiver to a computer, which can hold more detailed maps in its memory, or one can on a detailed map of an area find one´s way using the receiver's latitude and longitude readouts. A standard GPS receiver will not only place one´s position on a map at any particular location, but also trace one´s path across a map as one moves. If the receiver is switched on, it can stay in constant communication with GPS satellites to see how one´s location is changing.\n\nThe portable device is operatively coupled to a monitoring system through a wireless telephone network. The portable device transmits periodically encrypted location information as well as status information across the wireless network to the monitoring system. The monitoring system tracks the location of the individual and alerts the appropriate authorities when the individual violates a rule, such as a condition for parole. The portable device increases the time between transmissions when the individual is within a specified home location and reduces the time between transmissions when outside the specified location.\n\nAs a fail-safe against any technological glitch, whether accidental or malicious, a leading Electronic Monitoring operator is immensely proud of its backup systems, which boast an ultra-secure data room and extreme redundancy: For example, if a toxic-gas cloud were to wipe out the town of Anderson, the last act of the staff there would be to flip the switches diverting all call traffic to BI's corporate office in Boulder, Colorado, where a team capable of taking over instantly in case of disaster is always on duty.\n\nThe use of electronic monitoring in medical practice, especially as it relates to the tagging of the elderly and people with dementia, is capable of generating controversy, and media attention. Elderly people in care homes can be tagged with the same electronic monitors used to keep track of young offenders. For persons suffering from dementia, electronic monitoring might be beneficially used to prevent them from wandering away. The controversy in its medical use relates to two arguments, one as to the safety of the patients, and the other, as to their privacy and human rights. At over 40%, there is a high prevalence of wandering amongst patients with dementia. Of the several methods deployed to keep them from wandering, it is reported that 44% of wanderers with dementia have been kept behind closed doors at some point. Other solutions have included constant surveillance, use of makeshift alarms and, the use of various drugs that carry the risk of adverse effects.\n\nOpinions as to the propriety of electronic tagging of the elderly and persons with dementia vary. Carers welcome the idea of electronic tracking devices so long as it allows wanderers to be found more quickly. Some persons argue that a little liberty can be sacrificed in order to achieve safety and any concern about privacy only has force when we imagine that the person involved is trying to hide. The thinking behind this argument is that, for wandering persons with severe dementia, being electronically tagged and monitored carries less stigma than being found half dressed, in the middle of the night, on a highway. On the other side of the argument, it is contended that even in mild dementia, the need to protect a patient's right to privacy must be maintained. Even though electronic tagging and monitoring increases liberty, in a sense, it may potentially decrease the autonomy of the patient. Tracking may only settle the anxiety of Carers and family without necessarily attending to the needs of the person with dementia. What is important is to determine if persons with dementia have the capacity to make decisions, and if they do, their decisions should be respected. Where the person lacks the capacity, decisions need to be made in their best interest. Best interest in this sense does not simply mean the person's best medical interest. Deciding on their best interest will require careful inquiry, negotiation, and judgment.\n\nOn an iPhone, \"Location Services\" allows location-based apps and websites (including Maps, Camera, Safari, and other Apple and third-party apps) to use information from Global Positioning System (GPS) networks to determine your approximate location.\n\nA company in Japan has created GPS enabled uniforms and backpacks. School children in distress would be able to hit a button, immediately summoning a security agent to their location. Other similar applications in the U.S. have included mobile phones enabled with GPS tracking, to allow parents to track their school children.\n\nPublic transit vehicles are outfitted with electronic monitoring devices that talk to GPS systems tracking their locations. App developers have integrated this technology with mobile-phone apps. Now, passengers are able to receive accurate public transit timetables.\n\nThe use of ankle bracelets, or other electronic monitoring devices, have proven to be effective in research studies and even deterred crime. As such, they benefit society. When applied early, they may save otherwise habitual offenders from a life of crime.\n\nSeveral factors have been identified as necessary to render electronic monitoring effective: appropriately selecting offenders, robust and appropriate technology, fitting tags promptly, responding to breaches promptly, and communication between the criminal justice system and contractors.The Quaker Council for European Affairs thinks that for electronic monitoring to be effective, it should serve to halt a developing criminal career.\n\nThe National Audit Office in England and Wales commissioned a survey to examine the experiences of electronically monitored offenders and the members of their family. The survey revealed that there was common agreement amongst survey respondents that electronic monitoring was a more effective punitive measure than fines, and that it was generally more effective than community service. An interviewed offender is credited with saying: ‘You learn more about other crimes [in prison] and I think it gives you a taste to do other crimes because you've sat listening to other people'.\n\nIn 2006, Kathy Padgett, William Bales and Thomas Bloomberg conducted a well–controlled, large scale evaluation of 75,661 Florida offenders placed on home detention from 1998 to 2002., a small percentage of whom were made to wear an electronic monitoring device, which allowed comparison between those who were electronically monitored and those who were not. The study controlled for factors thought to influence the success or failure of community supervision: the type of placement, type of electronic monitoring device (GPS or radio frequency), criminal history, offender characteristics, type of primary offence committed by each offender, court- ordered conditions of supervision, the number of weeks absconded, weeks in treatment etc. with a total of 62 variables. The researchers incorporated time-varying independent variables in the estimation of maximum-likelihood coefficients, and also applied proportional-hazards survival analysis to adjust for right-censoring. As of 2010, compared to other studies, no previous study of electronic monitoring controlled such an array of variables nor involved such a large sample.\n\nRegarding their rate of compliance, violent offenders monitored by GPS were 91.2% less likely to abscond than those offenders not monitored at all. Electronic monitoring also effectively prevented offenders from committing new offences while being monitored: monitored offenders were 94.7% less likely to commit new offences than unmonitored offenders. The researchers found ‘no clear evidence that, overall, the decision to monitor offenders on home confinement with enhanced electronic control mechanisms results in ‘front-end' net-widening. In other words, offenders sentenced to home confinement with EM seem to have posed a significantly higher risk to public safety and would have had a higher likelihood of receiving a prison sentence if not for the availability of EM as an enhanced control mechanism.' In the end, GPS monitored offenders are 90.2% less likely than offenders on home confinement without EM to be revoked for a technical violation.\n\nAnother major advantage is the fact that wide deployment of electronic monitoring may lead to reduced prison populations. This is most likely where monitoring is used as an alternative to prison, rather than to enhance existing non-custodial orders. Major cost savings may be achieved through building fewer prisons as well as reducing the cost of administering custodial sentences.\n\nAnother is the possibility of improving rehabilitation and reintegration of offenders. Electronic monitoring may allow more offenders to maintain employment and contact with their families. It also avoids any negative psychological effects of incarceration, although of course the wearing of a device carries its own psychological pressures.\n\nIn late 2009, satellite-positioning receivers for a new navigation system at Newark airport in New Jersey were suffering brief daily breaks in reception. Something was interfering with the signals from orbiting global positioning system (GPS) satellites. A driver who passed by on the nearby New Jersey Turnpike each day used a cheap GPS jammer in his truck. Jammers prevent tracking devices from determining (and then reporting) its location.\n\nSome truck companies use fleet management software integrated with GPS in vehicles to monitor whether their drivers ever break speed limits, and in response, some delivery drivers buy illegal GPS jammers to subvert the system.\n\nA number of criticisms of the technology exist - some \"Tough on Crime\" groups argue that electronic tagging perceived as lenient, while other groups argue that the technology enables Net-widening, where non-prison bound individuals are subject to increased monitoring.\n\nElectronic monitoring does not physically restrain a person and dangerous offenders are still able to offend before authorities can intervene. Home detention with electronic monitoring is perceived by some people as lenient.\n\nAs early as 1988, the Penal Affairs Committee of the Religious Society of Friends (Quakers), wrote a briefing in its Green Paper strongly opposing the adoption of electronic monitoring in England and Wales. The Committee noted all the claims made in favour of electronic monitoring but insisted that all such claims could be ‘either demolished or rendered invalid' by arguments against it. The major argument or criticism against it was that on the basis of past experience, electronic monitoring would not absolutely be used on people at risk of custody, but on people who would otherwise have been granted probation or community service. This would lead to a widening of the net of control rather than reducing prison population; it would undermine constructive and supportive interventions. The Penal Committee concluded that the degrading monitoring of fellow human beings, electronically, was morally wrong and unacceptable. They argued that the system was inherently ‘retributive and punitive' and the wearing of an ankle monitor would be stigmatizing for women offenders.\n\nIn the US in 1990, Ronald Corbett and Gary T. Marx criticised the use of electronic monitoring in a paper presented at the Annual Meeting of the American Society of Criminology, Baltimore. In the paper, which was later published in the Justice Quarterly, the authors described ‘the new surveillance' technology as sharing some ethos and the information-gathering techniques found in maximum-security prisons thereby allowing them to diffuse into the broader society. They remarked that ‘we appear to be moving toward, rather than away from, becoming a \"maximum-security society.\"' The authors acknowledged the data-mining capacity of electronic monitoring devices when they stated that ‘data in many different forms, from widely separated geographical areas, organizations, and time periods, can easily be merged and analyzed.'\n\nIn 2013, it was reported that many electronic-monitoring programs throughout the US were not staffed appropriately. George Drake, a consultant who worked on improving the systems said ‘Many times when an agency is budgeted for electronic-monitoring equipment, it is only budgeted for the devices themselves.' He added that the situation was ‘like buying a hammer and expecting a house to be built. It's simply a tool, and it requires a professional to use that tool and run the program.' Drake warned that programs can get out of control if officials don't develop stringent protocols for how to respond to alerts and don't manage how alerts are generated: ‘I see agencies with so many alerts that they can't deal with them,' Drake said. ‘They end up just throwing their hands up and saying they can't keep up with them.' In Colorado, a review of alert and event data, obtained from the Colorado Department of Corrections under an open-records request, was conducted by matching the names of parolees who appeared in that data with those who appeared in jail arrest records. The data revealed that 212 parole officers were saddled with the duty of responding to nearly 90,000 alerts and notification generated by electronic monitoring devices in the six months reviewed.\n\nAccording to an analysis in the Journal of Law and Policy, most of those placed on electronic monitors haven't committed serious or violent offenses and, were it not for monitoring, \"at least some of these populations would not in fact be incarcerated or otherwise under physical control.\" Eighty-nine percent of probation officers surveyed by the Justice Department felt that \"offenders' relationships with their significant others changed because of being monitored.\" Both officers and those monitored observed that the ankle band had a distinct impact on children. As one parent testified, \"When it beeps, the kids worry about whether the probation officer is coming to take me to jail. The kids run for it when it beeps.\"\n\nAs a condition for her bail, Gabrielle Baillieux, the protagonist in Peter Carey's \"Amnesia\", had to wear an ankle monitor. Later a colleague took it off. The device was transferred to a dog, whose movements were instead tracked.\n\nIn \"The Good Wife\", (\"Bang\") season 1 episode 15, Peter had been imprisoned for several months after being convicted of charges of corruption. He is allowed to return home under house arrest while his appeal is considered. Peter must wear an ankle monitor and cannot leave the apartment or communicate with the outside world.\n\nIn the 2007 American mystery horror-thriller movie, \"Disturbia\", a 17-year-old high school student, Kale Brecht (Shia LaBeouf), is charged with aggravated assault after his teacher made a personal remark about his dad, who had died in a car accident, and Kale is sentenced to three months of house arrest. He is secured with an ankle monitor and allowed only 100 feet from his house.\n\nEnglish professional footballer Jermaine Pennant played a Premier League match in 2005 while wearing an electronic tag; he had received the tag for drink-driving and driving while disqualified.\n\nLindsay Lohan failed to appear at a mandatory hearing, and a warrant was issued for her arrest. The judge ordered Lohan to wear a SCRAM bracelet, an electronic device that monitors the bloodstream for alcohol and drugs and alerts authorities if prohibited substances are consumed.\n\nRoman Polanski, one of the most famous fugitives from American justice in the world was finally arrested in Switzerland. The terms of his release included $4.5 million bail, house arrest wearing an ankle bracelet at his chalet, known as Milky Way, in the Swiss ski resort of Gstaad, after having spent sixty-seven days in a Zurich detention centre.\n\nBernard Madoff, the financier accused in a $50 billion fraud case before trial was ordered under house arrest, with electronic monitoring, and posting $10 million bail against his $7 million Manhattan apartment, and against his wife's homes in Montauk, N.Y., and Palm Beach, Fla.\n\nDominique Strauss-Kahn, former International Monetary Fund chief, charged with trying to rape a hotel maid May 14, 2011. On release from jail, arranged for house arrest, with a private security company that kept him under armed guard and electronic monitoring as conditions of his bail. Prosecutors estimated the cost at $200,000 a month, which he was responsible for paying.\n\nDr. Dre in 1992, the rapper was arrested for assaulting record producer Damon Thomas and later pleaded guilty to assault on a police officer, eventually serving house arrest and wearing a police-monitoring ankle bracelet.\n\nThe U.S. correctional system is overwhelmed by the over-incarceration of nonviolent offenders such as drug users. Private-prison corporations themselves have begun to expand into the \"alternatives\" industry. The GEO Group now has an array of \"community reëntry services\" and treatment programs. In 2011, it acquired the country's largest electronic-monitoring firm, BI Incorporated, for $415 million. For the most part, these companies deal not with felony probationers (\"probation\" as it is usually understood) but with people whose offenses are often too minor to merit jail time. The system is known as \"offender-funded\" justice.\n\nJack Long, a Georgia attorney, filed a habeas petition on behalf of a client who, after stealing a two-dollar can of beer from a convenience store, was ordered to spend a year wearing an ankle bracelet operated by a company called Sentinel Offender Services. The man wound up owing more than a thousand dollars to the company in fees and late-payment penalties, and started selling his blood plasma to keep pace. Dozens of probationers are jailed because of electronic-monitoring bills, most of which were not authorized by any legal statute.\n\nElectronic monitoring of a curfew has become an integral part of the criminal justice system in the United Kingdom, used at various stages of criminal cases used to monitor compliance with a curfew, requiring the curfewee to remain in their home for a specified number of hours a day or exclusion from specified areas (such as victim's homes and football grounds).\n\nThose subject to electronic monitoring may be given curfews as part of Bail conditions, sentenced under the Criminal Justice Act 2003 in England and Wales (with separate legislation applying in Scotland). Alternatively offenders may be released from a prison on a Home Detention Curfew. Released prisoners under home detention allowed out during curfew hours only for:\n\nAdditionally, electronic monitoring may be used for those subject to a curfew given under the Terrorism Prevention and Investigation Measures Act 2011 (previously known as Control order under the Prevention of Terrorism Act 2005)\n\nSince electronically monitored curfews were rolled out throughout England and Wales their use has increased sharply, from 9,000 cases in 1999-2000 to 53,000 in 2004-05. In 2004-05, the Home Office spent £102.3 million on the electronic monitoring of curfews and electronically monitored curfews are considered cheaper than custody. Ninety days in custody (e.g., a prison) costs approximately five times more than the same amount of time on an electronically monitored curfew order.\n\nTypically, offenders are fitted with an electronic tag around their ankle which sends a regular signal to a receiver unit installed in their home. Some systems are connected to a fixed telephone line in the case where a GSM signal is not available, whilst most arrangements utilise the mobile phone system to communicate with the monitoring company. If the tag is not functioning or within range of the base station during curfew hours, or if the base is disconnected from the power supply, or the base station is moved then the monitoring company are alerted, who in turn, notify the appropriate authority such as the Law enforcement in the United Kingdom, National Probation Service or Prison.\n\nIn 2012, the Policy Exchange thinktank examined the use of electronic monitoring in England and Wales and made comparisons with technologies and models seen in other jurisdictions, particularly the United States. The report was critical of the Ministry of Justice's model of a fully privatised service - which gave little scope for police or probation services to make use of electronic monitoring. The report, Future of Corrections, also criticised the cost of the service, highlighting an apparent differential between what the UK taxpayer was charged and what could be found in the United States. At the time of publication the Ministry of Justice was completing a procurement exercise for a new generation of GPS tags - and the report described the exercise as flawed, calling on electronic monitoring to be commissioned locally via Police and Crime Commissioners.\n\nSubsequently, there were a number of scandals in relation to electronic monitoring in England and Wales, with a criminal investigation opened by the Serious Fraud Office into the activities of Serco and G4S. As a result of the investigation, Serco agreed to repay £68.5 million to the taxpayer and G4S agreed to repay £109 million. The duopoly were subsequently stripped of their contract, with Capita taking over the contract. In 2017, another criminal investigation saw police make a number of arrests in relation to allegations that at least 32 criminals on tag had paid up to £400 to Capita employees in order to have 'loose' tags fitted, allowing them to remove their tags.\n\nThe monitoring of sex offenders via electronic tagging is currently in debate due to certain rights offenders have in England and Wales.\n\nElectronic tagging has begun being used on psychiatric patients, prompting concern from mental health advocates who state that the practice is demeaning.\n\nIn Scotland, those convicted of a serious sexual or violent crime, and are determined to pose a serious danger to the community, are to be given a sentence, known as an Order for Lifelong Restriction, which means that the offender will be detained indefinitely, until the Parole Board for Scotland determines that the offender no longer poses a risk to the safety of others. If the offender is released on parole, he or she is to be electronically tagged and kept under close supervision by the Scottish Parole Board for the remainder of the offender's life.\n\nIn Western Australia, The Bail Act 1982 (WA) specifically provides for electronic monitoring at the pre-trial stage. The Act allows only judicial officers to impose a home detention. This is done after first obtaining a suitability report, from a corrections officer, on accused persons aged over 17. The accused person may then be required to wear a device or permit the installation of a device in the place where he/she is required to remain.\n\nIn most Australian jurisdictions, the generally broad discretion available when imposing bail conditions may permit electronic monitoring. For instance, in section 11(2) of the South Australian Bail Act 1985, the bail authority may 'impose a condition requiring an accused person to remain at his or her residence except for authorised activities such as employment.' The Supreme Court of South Australia, it is thought, may have interpreted this as authority to order electronically monitored bail, at least where the applicant is willing.\n\nThe Northern Territory and Western Australia have laws that specifically authorize electronic monitoring as a primary sentencing option for home detention. The \"Sentencing Act 1995\", of the Northern Territory, provides that a 'court which sentences an offender to a term of imprisonment may make an order suspending the sentence on the offender entering into a home detention order'. Such offenders may be required to 'wear or have attached an approved monitoring device in accordance with the directions of the Commissioner, and allow the placing, or installation in, and retrieval from, the premises or place specified in the order of such machine, equipment or device necessary for the efficient operation of the monitoring device'.\n\nIn Western Australia, the \"Sentencing Act 1995\" provides that a court may impose an intensive supervision order with a curfew requirement. The offender is required to submit to surveillance or monitoring as ordered; wear a device or have a device installed in his or her home. Electronic monitoring 'may only be imposed for a term of six months or less'.\n\nIn New South Wales, although the law does not specifically authorise electronic monitoring, the Crimes (Sentencing Procedure) Act 1999 (NSW), however, grants the court the power to 'impose such conditions as it considers appropriate on any home detention order made by it'. In practice, electronic monitoring is used to enforce these home detention orders. The general powers of court may also allow electronic monitoring in other States and Territories.\n\nIn August 2010, Brazil awarded a GPS Offender Monitoring contract to kick start its monitoring of offenders and management of the Brazilian governments early release programme\n\nElectronic monitoring as a pilot project was started in March 2012, involving 150 offenders, mostly prisoners serving life terms. The project was rolled out to reduce the South Africa's prison population. It consequently would also reduce the taxpayer's burden on correctional facilities. South Africa locks up more people than any other country on the continent.\n\n\n"}
{"id": "54831792", "url": "https://en.wikipedia.org/wiki?curid=54831792", "title": "Elizabeth Bender Roe Cloud", "text": "Elizabeth Bender Roe Cloud\n\nElizabeth Bender Roe Cloud (April 2, 1887 – September 16, 1965) was an Ojibwe activist and educator. A product of the Native American Boarding School System, she graduated with teaching credentials from the Hampton Institute and taught from 1908 though 1916. She then joined her husband and helped administer the American Indian Institute of Wichita, Kansas for twenty-five years. In the 1940s, she founded the Oregon Trails Women's Club with tribe members from the Umatilla Indian Reservation. She served as the National Chair of Indian Welfare for the General Federation of Women's Clubs for eight years, the first American Indian to hold the post. Roe Cloud received the National Mother of the Year award in 1950 and in 1952, she was honored as the \"Outstanding Indian\" of the year by the American Indian Exposition of Anadarko, Oklahoma. She is noted for having used her influence as an educated indigenous woman to advocate for Native American self-determination.\n\nElizabeth Georgiana Bender (native name: Equay Zaince) was born on April 2, 1887 on the White Earth Indian Reservation in northwestern Minnesota to Pay show de o quay (Mary née Razor or Razier), of the Mississippi Chippewa band and Albertus Bliss Bender, a German immigrant. Her father was a logger and after he and Mary married, he lived on her allotment, continued to log, and also hunted and fished. Bender's mother was an herbalist and healer, who served as a midwife to her tribe. One of eleven children born to the couple, Elizabeth was the sixth child and one of five who attended Hampton Institute. Her older sister Anna was also an educator and two of her older brothers John and Charles Albert \"Chief\" Bender were noted baseball players. Chief was inducted into the Baseball Hall of Fame in 1953.\n\nBender attended boarding schools in Minnesota, beginning her studies at around age nine at the Catholic Sisters School in St. Joseph, Minnesota. After her first year, she transferred to the Catholic Sisters School closer to home, in White Earth, for another year. Between 1898 and 1902, she took courses at the Pipestone Boarding School for half a day and then performed manual labor for the other half-day. She went on to join her sister Anna and further her education at the normal school of the Hampton Institute in 1903. Both she and her sister Anna participated in the work-away summer programs, where they were paid for performing domestic services. In 1904, they were placed in separate houses near Boston, which allowed them to spend time together, as well as making a trip to watch their brother Chief play baseball. Completing her studies in 1907, she remained at Hampton taking post-graduate courses in teaching and domestic science.\n\nIn 1908, Bender was sent to the Blackfeet Reservation in Browning, Montana, where she would teach for two years. In 1910, she returned east and completed a nursing course in Philadelphia at Hahnemann Hospital. In 1912, she returned to the Blackfeet Reservation. The following year, she moved on to the school at the Fort Belknap Indian Reservation in Montana, where she remained until 1914. At both of the reservations, she not only taught, but served as housemother to the boarders, occasionally as their cook, and even treated the students for trachoma. She returned to Hampton to complete a Home Economics course in 1914 and 1915. During this same time frame, she attended the Fourth Annual Conference of the Society of American Indians held between October 6 and 11, 1914 in Madison, Wisconsin. Bender had joined the organization when she graduated and it was at this meeting that she would meet Henry Roe Cloud, a full-blood Winnebago tribe member. The two immediately began a relationship, which continued even after Bender finished her studies at Hampton and went to teach at Carlisle Indian Industrial School in 1915. Simultaneously, Roe Cloud went to Wichita, Kansas and founded the Roe Institute, later known as the American Indian Institute, a college preparatory school for indigenous men. While she was at Carlisle, Bender formed a Camp Fire Girls program, to help girls learn domestic and artistic skills. On 12 June 1916, Bender married Roe Cloud at her brother Chief's home in Philadelphia.\n\nThe couple made their home in Wichita, where Elizabeth worked at the American Indian Institute (AII), serving as matron and financial manager. Because Henry had no prior experience teaching, she often served as an advisor and took an active part in running the school for twenty years. Unlike other Native American schools, the curriculum of AII included courses on indigenous cultures, in addition to the academic lessons. Over the next several years, their family grew to include Elizabeth Marion (born 1917), Anne Woesha (born 1918), Lillian Alberta (born 1920), Ramona Clark (born 1922) and Henry Jr. (1926–1929). When Henry Jr. died, they adopted Jay Hunter, a family friend, who was not orphaned, but joined their family as was customary among the Winnebago. In 1931, Henry took a job with the Bureau of Indian Affairs and began traveling as an investigator researching conditions, such as education, health and poverty, among Native American communities. He was often absent from the school and Elizabeth supervised it during those absences. In 1932, she returned to school, taking courses at Wichita University part time, where she eventually earned her bachelor's degree. Henry had been appointed as the superintendent of the Haskell Institute in 1933 and would work in Lawrence for the next two years. Elizabeth resigned from her duties at AII in 1934, but continued to live in Wichita so that the children could finish their schooling and herself took graduate courses at the University of Kansas. In 1937, fire destroyed the school and after struggling to remain open for two years, the decision was made to close the school in 1939. That same year, Elizabeth was asked by President Franklin D. Roosevelt to serve as a delegate to represent minorities for the White House Conference on Children and Youth, examining children and the role of democracy. At the conference, she met Sadie Orr Dunbar, who was the current president of the General Federation of Women's Clubs (GFWC).\n\nIn 1940, the family relocated to the Umatilla Indian Reservation, where Henry became superintendent of the agency there. Elizabeth became involved in the Woman's club movement, founding the Oregon Trails Women's Club from women on the reservation. Joining the Oregon State Federation of Women's Clubs, she was appointed to serve as chair for the state organization's Indian Welfare Committee in 1948. Her duties were to implement the club's outreach to Native American women and to help the club members implement the goals of equal citizenship for indigenous people. Henry died of heart failure in 1950, before Elizabeth won the Golden Rule Foundation's Mother of the Year award for 1950. In part, the award was given because all four of her daughters had gone on to earn university educations. Marion had been the first American Indian to graduate from Wellesley College, Anne Woesha was the first indigenous woman to graduate from Vassar, Lillian completed her education at the University of Kansas and Ramona graduated from Vassar. The award propelled her to national speaking and writing engagements and to head the national Indian Affairs Division for the GFWC. She was the first Native American to be named mother of the year, as well as the first to head the GFWC's Indian Affairs Division, which she led for eight years. Developing a \"Point Four Program\", which included desegregating Indian populations from mainstream schools and opportunities, providing leadership training, expanding cultural programs, and conducting studies. She urged each affiliated club to develop Indian Affairs committees and by 1951 had offices in forty state affiliates. She also pressed for state organizations to offer educational scholarships for Native children. In regard to the last item, Roe Cloud traveled over 22,000 miles over the next two years assessing conditions for tribes in twenty-two states and the Territory of Alaska. Simultaneously, she began participating as a field officer of the National Congress of American Indians (NCAI). She had directed a two-week summer stragegy workshop, held in Brigham City, Utah in 1951 and began working as a co-director, with D'Arcy McNickle for the American Indian Development Project.\n\nRoe Cloud used her voice as an advocate for indigenous people, arguing that though Native Americans could learn self-sufficiency, the government had to cease efforts to victimize tribes by usurping their power, their natural resources, and their customs. She proposed a Charter of Indian Rights, developed in the AID Project to the GFWC, which was adopted in 1952. In part, the plan called for the government to speed up its efforts to help tribes eliminate poverty and illiteracy, provide adequate health and resource safeguards, and allow Native communities the autonomy to manage their own affairs once they had shown an ability to do so. She saw the role of the AID Project as one of advising and assisting in developing strategy, but allowing communities to establish their own goals and management processes. That same year, she was selected as the \"Outstanding Indian\" of the year by the American Indian Exposition of Anadarko, Oklahoma. When Helen Peterson became the executive director of NCAI in 1953, Roe Cloud helped her transition into the job and took her to reservations throughout Indian country to make assessments of the various tribes and establish networking contacts. With the passage of House concurrent resolution 108, designed to implement the Indian termination policy to discharge federal trustee responsibility for Indian lands and force the tribes into assimilating to mainstream culture, Roe Cloud pressed the GFWC to oppose legislation aimed at terminating tribes. The GFWC leadership joined the American Civil Liberties Union, the American Legion, other organizations, and the Native American community in opposition to termination, ultimately defeating the policy in the 1960s.\n\nRoe Cloud died on September 16, 1965 in Portland, Oregon. Her ability to straddle two worlds, during the contentious decades of the Indian termination policies, allowed her to serve as a role model for generations which followed her activism. Rather than adopt the position of GFWG's first Indian Welfare Committee Chair, Stella Atwood, who backed American Indian rights, but proclaimed, \"I will work \"for\" the Indians but not with them,\" Roe Cloud tried to involve indigenous people in creating their own solutions and reforms. Her daughter, Anne Woesha, would become an activist after her mother's death, participating in the Occupation of Alcatraz.\n\n"}
{"id": "37940820", "url": "https://en.wikipedia.org/wiki?curid=37940820", "title": "Emotion perception", "text": "Emotion perception\n\nEmotion perception refers to the capacities and abilities of recognizing and identifying emotions in others, in addition to biological and physiological processes involved. Emotions are typically viewed as having three components: subjective experience, physical changes, and cognitive appraisal; emotion perception is the ability to make accurate decisions about another's subjective experience by interpreting their physical changes through sensory systems responsible for converting these observed changes into mental representations. The ability to perceive emotion is believed to be both innate and subject to environmental influence and is also a critical component in social interactions. How emotion is experienced and interpreted depends on how it is perceived. Likewise, how emotion is perceived is dependent on past experiences and interpretations. Emotion can be accurately perceived in humans. Emotions can be perceived visually, audibly, through smell and also through bodily sensations and this process is believed to be different from the perception of non-emotional material.\n\nEmotions can be perceived through visual, auditory, olfactory, and physiological sensory processes. Nonverbal actions can provide social partners with information about subjective and emotional states. This nonverbal information is believed to hold special importance and sensory systems and certain brain regions are suspected to specialize in decoding emotional information for rapid and efficient processing.\n\nThe visual system is the primary mode of perception for the way people receive emotional information. People use emotional cues displayed by social partners to make decisions regarding their affective state. Emotional cues can be in the form of facial expressions, which are actually a combination of many distinct muscle groups within the face, or bodily postures (alone or in relation to others), or found through the interpretation of a situation or environment known to have particular emotional properties (i.e., a funeral, a wedding, a war zone, a scary alley, etc.). While the visual system is the means by which emotional information is gathered, it is the cognitive interpretation and evaluation of this information that assigns it emotional value, garners the appropriate cognitive resources, and then initiates a physiological response. This process is by no means exclusive to visual perception and in fact may overlap considerably with other modes of perception, suggesting an emotional sensory system comprising multiple perceptual processes all of which are processed through similar channels.\n\nA great deal of research conducted on emotion perception revolves around how people perceive emotion in others' facial expressions. Whether the emotion contained in someone's face is classified categorically or along dimensions of valence and arousal, the face provides reliable cues to one's subjective emotional state. As efficient as humans are in identifying and recognizing emotion in another's face, accuracy goes down considerably for most emotions, with the exception of happiness, when facial features are inverted (i.e., mouth placed above eyes and nose), suggesting that a primary means of facial perception includes the identification of spatial features that resemble a prototypical face, such that two eyes are placed above a nose which is above a mouth; any other formation of features does not immediately constitute a face and requires extra spatial manipulation to identify such features as resembling a face.\n\nResearch on the classification of perceived emotions has centered around the debate between two fundamentally distinct viewpoints. One side of the debate posits that emotions are separate and discrete entities whereas the other side suggests that emotions can be classified as values on the dimensions of valence (positive versus negative) and arousal (calm/soothing versus exciting/agitating). Psychologist Paul Ekman supported the discrete emotion perspective with his groundbreaking work comparing emotion perception and expression between literate and preliterate cultures. Ekman concluded that the ability to produce and perceive emotions is universal and innate and that emotions manifest categorically as basic emotions (anger, disgust, fear, happiness, sadness, contempt, surprise, and possibly contempt). The alternative dimensional view garnered support from psychologist James Russell, who is best known for his contributions toward the circumplex of emotion. Russell described emotions as constructs which lie on the dimensions of valence and arousal and it is the combination of these values which delineate emotion. Psychologist Robert Plutchik sought to reconcile these views and proposed that certain emotions be considered \"primary emotions\" which are grouped either positively or negatively and can then be combined to form more complex emotions, sometimes considered \"secondary emotions\", such as remorse, guilt, submission, and anticipation. Plutchik created the \"wheel of emotions\" to outline his theory.\n\nCulture plays a significant role in emotion perception, most notably in facial perception. Although the features of the face convey important information, the upper (eyes/brow) and lower (mouth/nose) regions of the face have distinct qualities that can provide both consistent and conflicting information. As values, etiquette, and quality of social interactions vary across cultures, facial perception is believed to be moderated accordingly. In western cultures, where overt emotion is ubiquitous, emotional information is primarily obtained from viewing the features of the mouth, which is the most expressive part of the face. However, in eastern cultures, where overt emotional expression is less common and therefore the mouth plays a lesser role in emotional expression, emotional information is more often obtained from viewing the upper region of the face, primarily the eyes. These cultural differences suggest a strong environmental and learned component in emotion expression and emotion perception.\n\nAlthough facial expressions convey key emotional information, context also plays an important role in both providing additional emotional information and modulating what emotion is actually perceived in a facial expression. Contexts come in three categories: stimulus-based context, in which a face is physically presented with other sensory input that has informational value; perceiver-based context, in which processes within the brain or body of a perceiver can shape emotion perception; and cultural contexts that affect either the encoding or the understanding of facial actions.\n\nThe auditory system can provide important emotional information about the environment. Voices, screams, murmurs, and music can convey emotional information. Emotional interpretations of sounds tend to be quite consistent. Traditionally, emotion perception in the voice has been determined through research studies analyzing, via prosodic parameters such as pitch and duration, the way in which a speaker expresses an emotion, known as encoding. Alternatively, a listener who attempts to identify a particular emotion as intended by a speaker can decode emotion. More sophisticated methods include manipulating or synthesizing important prosodic parameters in speech signal (e.g., pitch, duration, loudness, voice quality) in both natural and simulated affective speech. Pitch and duration tend to contribute more to emotional recognition than loudness. Music has long been known to have emotional qualities and is a popular strategy in emotion regulation. When asked to rate emotions present in classical music, music professionals could identify all six basic emotions with happiness and sadness the most represented, and in decreasing order of importance, anger, fear, surprise, and disgust. The emotions of happiness, sadness, fear, and peacefulness can be perceived in a short length of exposure, as little as 9–16 seconds including instrumental-only music selections.\n\nAromas and scents also influence mood, for example through aromatherapy, and humans can extract emotional information from scents just as they can from facial expressions and emotional music. Odors may be able to exert their effects through learning and conscious perception, such that responses typically associated with particular odors are learned through association with their matched emotional experiences. In-depth research has documented that emotion elicited by odors, both pleasant and unpleasant, affects the same physiological correlates of emotion seen with other sensory mechanisms.\n\nTheories on emotion have focused on perception, subjective experience, and appraisal. Predominant theories of emotion and emotion perception include what type of emotion is perceived, how emotion is perceived somatically, and at what stage of an event emotion is perceived and translated into subjective, physical experience.\n\nFollowing the influence of René Descartes and his ideas regarding the split between body and mind, in 1884 William James proposed the theory that it is not that the human body acts in response to our emotional state, as common sense might suggest, but rather, we interpret our emotions on the basis of our already present bodily state. In the words of James, \"we feel sad because we cry, angry because we strike, afraid because we tremble, and neither we cry, strike, nor tremble because we are sorry, angry, or fearful, as the case may be.\" James believed it was particular and distinct physical patterns that map onto specific experienced emotions. Contemporaneously, psychologist Carl Lange arrived at the same conclusion about the experience of emotions. Thus, the idea that felt emotion is the result of perceiving specific patterns of bodily responses is called the James-Lange theory of emotion.\nIn support of the James-Lange theory of emotion, Silvan Tomkins proposed the facial feedback hypothesis in 1963; he suggested that facial expressions actually trigger the experience of emotions and not the other way around. This theory was tested in 1974 by James Laird in an experiment where Laird asked participants to hold a pencil either between their teeth (artificially producing a smile) or between their upper lip and their nose (artificially producing a frown) and then rate cartoons. Laird found that these cartoons were rated as being funnier by those participants holding a pencil in between their teeth. In addition, Paul Ekman recorded extensive physiological data while participants posed his basic emotional facial expressions and found that heart rate raised for sadness, fear, and anger yet did not change at al for happiness, surprise, or disgust, and skin temperature raised when participants posed anger but not other emotions. While contemporary psychologists still agree with the James-Lange theory of emotion, human subjective emotion is complex and physical reactions or antecedents do not fully explain the subjective emotional experience.\n\nWalter Bradford Cannon and his doctoral student Philip Bard agreed that physiological responses played a crucial role in emotions, but did not believe that physiological responses alone could explain subjective emotional experiences. They argued that physiological responses were too slow relative to the relatively rapid and intense subjective awareness of emotion and that often these emotions are similar and imperceptible to people at such a short timescale. Cannon proposed that the mind and body operate independently in the experience of emotions such that differing brain regions (cortex versus subcortex) process information from an emotion-producing stimulus independently and simultaneously resulting in both an emotional and a physical response. This is best illustrated by imagining an encounter with a grizzly bear; you would simultaneously experience fear, begin to sweat, experience an elevated heart rate, and attempt to run. All of these things would happen at the same time.\n\nStanley Schachter and his doctoral student Jerome Singer formulated their theory of emotion based on evidence that without an actual emotion-producing stimulus, people are unable to attribute specific emotions to their bodily states. They believed that there must be a cognitive component to emotion perception beyond that of just physical changes and subjective feelings. Schachter and Singer suggested that when someone encounters such an emotion-producing stimulus, they would immediately recognize their bodily symptoms (sweating and elevated heart rate in the case of the grizzly bear) as the emotion fear. Their theory was devised as a result of a study in which participants were injected with either a stimulant (adrenaline) that causes elevated heart rate, sweaty palms and shaking, or a placebo. Participants were then either told what the effects of the drug were or were told nothing, and were then placed in a room with a person they did not know who, according to the research plan, would either play with a hula hoop and make paper airplanes (euphoric condition) or ask the participant intimate, personal questions (angry condition). What they found was that participants who knew what the effects of the drug were attributed their physical state to the effects of the drug; however, those who had no knowledge of the drug they received attributed their physical state to the situation with the other person in the room. These results led to the conclusion that physiological reactions contributed to emotional experience by facilitating a focused cognitive appraisal of a given physiologically arousing event and that this appraisal was what defined the subjective emotional experience. Emotions were thus a result of a two-stage process: first, physiological arousal in a response to an evoking stimulus, and second, cognitive elaboration of the context in which the stimulus occurred.\n\nEmotion perception is primarily a cognitive process driven by particular brain systems believed to specialize in identifying emotional information and subsequently allocating appropriate cognitive resources to prepare the body to respond. The relationship between various regions is still unclear, but a few key regions have been implicated in particular aspects of emotion perception and processing including areas suspected of being involved in the processing of faces and emotional information.\n\nThe fusiform face area, part of the fusiform gyrus is an area some believe to specialize in the identification and processing of human faces, although others suspect it is responsible for distinguishing between well known objects such as cars and animals. Neuroimaging studies have found activation in this area in response to participants viewing images of prototypical faces, but not scrambled or inverted faces, suggesting that this region is specialized for processing human faces but not other material. This area has been an area of increasing debate and while some psychologists may approach the fusiform face area in a simplistic manner, in that it specializes in the processing of human faces, more likely this area is implicated in the visual processing of many objects, particularly those familiar and prevalent in the environment. Impairments in the ability to recognize subtle differences in faces would greatly inhibit emotion perception and processing and have significant implications involving social interactions and appropriate biological responses to emotional information.\n\nThe hypothalamic-pituitary-adrenal (HPA) axis plays a role in emotion perception through its mediation of the physiological stress response. This occurs through the release of hypothalamic corticotropin-releasing factor, also known as corticotropin-releasing hormone (CRH), from nerve terminals in the median eminence arising in the paraventricular nucleus, which stimulates adrenocorticotropin release from the anterior pituitary that in turn induces the release of cortisol from the adrenal cortex. This progressive process culminating in the release of glucocorticoids to environmental stimuli is believed to be initiated by the amygdala, which evaluates the emotional significance of observed phenomena. Released glucocorticoids provide negative feedback on the system and also the hippocampus, which in turn regulates the shutting off of this biological stress response. It is through this response that information is encoded as emotional and bodily response is initiated, making the HPA axis an important component in emotion perception.\n\nThe amygdala appears to have a specific role in attention to emotional stimuli. The amygdala is a small, almond-shaped region within the anterior part of the temporal lobe. Several studies of non-human primates and of patients with amygdala lesions, in addition to studies employing functional neuroimaging techniques, have demonstrated the importance of the amygdala in face and eye-gaze identification. Other studies have emphasized the importance of the amygdala for the identification of emotional expressions displayed by others, in particular threat-related emotions such as fear, but also sadness and happiness. In addition, the amygdala is involved in the response to non-facial displays of emotion, including unpleasant auditory, olfactory and gustatory stimuli, and in memory for emotional information. The amygdala receives information from both the thalamus and the cortex; information from the thalamus is rough in detail and the amygdala receives this very quickly, while information from the cortex is much more detailed but is received more slowly. In addition, the amygdala's role in attention modulation toward emotion-specific stimuli may occur via projections from the central nucleus of the amygdala to cholinergic neurons, which lower cortical neuronal activation thresholds and potentiate cortical information processing.\n\nThere is great individual difference in emotion perception and certain groups of people display abnormal processes. Some disorders are in part classified by maladaptive and abnormal emotion perception while others, such as mood disorders, exhibit mood-congruent emotional processing. Whether abnormal processing leads to the exacerbation of certain disorders or is the result of these disorders is yet unclear, however, difficulties or deficits in emotion perception are common among various disorders.\n\nResearch investigating face and emotion perception in autistic individuals is inconclusive. Past research has found atypical, piecemeal face-processing strategies among autistic individuals and a better memory for lower versus upper regions of the face and increased abilities to identify partly obscured faces. Autistic individuals tend to display deficits in social motivation and experience that may decrease overall experience with faces and this in turn may lead to abnormal cortical specialization for faces and decreased processing efficiency. However, these results have not been adequately replicated and meta-analyses have found little to no differential face processing between typically-developing and autistic individuals although autistic people reliably display worse face memory and eye perception which could mediate face and possibly emotion perception.\nIndividuals with schizophrenia also have difficulties with all types of facial emotion expression perception, incorporating contextual information in making affective decisions, and indeed, facial perception more generally. Neuropathological and structural neuroimaging studies of these patients have demonstrated abnormal neuronal cell integrity and volume reductions in the amygdala, insula, thalamus and hippocampus and studies employing functional neuro-imaging techniques have demonstrated a failure to activate limbic regions in response to emotive stimuli, all of which may contribute to impaired psychosocial functioning.\n\nIn patients with major depressive disorder, studies have demonstrated either generalized or specific impairments in the identification of emotional facial expressions, or a bias towards the identification of expressions as sad. Neuro-pathological and structural neuroimaging studies in patients with major depressive disorder have indicated abnormalities within the subgenual anterior cingulate gyrus and volume reductions within the hippocampus, ventral striatal regions and amygdala.\n\nSimilarly, anxiety has been commonly associated with individuals being able to perceive threat when in fact none is present, and orient more quickly to threatening cues than other cues. Anxiety has been associated with an enhanced orienting toward threat, a late-stage attention maintenance toward threat, or possibly vigilance-avoidance, or early-stage enhanced orienting and later-stage avoidance. As a form of anxiety, post-traumatic stress disorder (PTSD) has also been linked with abnormal attention toward threatening information, in particular, threatening stimuli which relates to the personally relevant trauma, making such a bias in that context appropriate, but out of context, maladaptive. Such processing of emotion can alter an individuals' ability to accurately assess others' emotions as well. Mothers with violence-related PTSD have been noted to show decreased medial prefrontal cortical activation in response to seeing their own and unfamiliar toddlers in helpless or distressed states of mind that is also associated with maternal PTSD symptom severity, self-reported parenting stress, and difficulty in identifying emotions and which, in turn, impacts sensitive caregiving. Moreover, child maltreatment and child abuse have been associated with emotion processing biases as well, most notably toward the experience-specific emotion of anger. Research has found that abused children exhibit attention biases toward angry faces such that they tend to interpret even ambiguous faces as angry versus other emotions and have a difficulty disengaging from such expressions while other research has found abused children to demonstrate an attentional avoidance of angry faces. \nIt is believed to be adaptive to attend to angry emotion as this may be a precursor to danger and harm and quick identification of even mild anger cues can facilitate the ability for a child to escape the situation, however, such biases are considered maladaptive when anger is over-identified in inappropriate contexts and this may result in the development of psychopathology.\n\nResearchers employ several methods designed to examine biases toward emotional stimuli to determine the salience of particular emotional stimuli, population differences in emotion perception, and also attentional biases toward or away from emotional stimuli. Tasks commonly utilized include the modified Stroop task, the dot probe task, visual search tasks, and spatial cuing tasks. \nThe Stroop task, or modified Stroop task, displays different types of words (e.g., threatening and neutral) in varying colors. The participant is then asked to identify the color of the word while ignoring the actual semantic content. Increased response time to indicate the color of threat words relative to neutral words suggests an attentional bias toward such threat. The Stroop task, however, has some interpretational difficulties in addition to the lack of allowance for the measurement of spatial attention allocation. To address some of the limitations of the Stroop task, the dot probe task displays two words or pictures on a computer screen (either one at the top or left and the other on the bottom or right, respectively) and after a brief stimuli presentation, often less than 1000ms, a probe appears in the location of one of the two stimuli and participants are asked to press a button indicating the location of the probe. Different response times between target (e.g., threat) and neutral stimuli infer attentional biases to the target information with shorter response times for when the probe is in the place of the target stimuli indicating an attention bias for that type of information. In another task that examines spatial attentional allocation, the visual search task asks participants to detect a target stimulus embedded in a matrix of distractors (e.g., an angry face among several neutral or other emotional faces or vice versa). Faster detection times to find emotional stimuli among neutral stimuli or slower detection times to find neutral stimuli among emotional distractors infer an attentional bias for such stimuli. The spatial cuing task asks participants to focus on a point located between two rectangles at which point a cue is presented, either in the form of one of the rectangles lighting up or some emotional stimuli appearing within one of the rectangles and this cue either directs attention toward or away from the actual location of the target stimuli. Participants then press a button indicating the location of the target stimuli with faster response times indicating an attention bias toward such stimuli.\n\n"}
{"id": "10543101", "url": "https://en.wikipedia.org/wiki?curid=10543101", "title": "Engineering analysis", "text": "Engineering analysis\n\nEngineering analysis involves the application of scientific analytic principles and processes to reveal the properties and state of a system, device or mechanism under study. Engineering analysis is decompositional: it proceeds by separating the engineering design into the mechanisms of operation or failure, analyzing or estimating each component of the operation or failure mechanism in isolation, and re-combining the components according to basic physical principles and natural laws.\n\nEngineering analysis is the primary method for predicting and handling issues with remote systems such as satellites and rovers. Engineering analysis for remote systems must be ongoing since the health and safety of the remote system can only be affected remotely (and because any failure could have fatal consequences). The capabilities of engineering analysis therefore must incorporate trending as well as analysis. Trending should be proactive, predictive, comprehensive and automated. Analysis must be reactive, investigative, targeted and hands-on. Together trending and analysis allow operators to both predict potential situations and identify anomalous events that threaten a remote system.\n\n"}
{"id": "54993244", "url": "https://en.wikipedia.org/wiki?curid=54993244", "title": "Environmental personhood", "text": "Environmental personhood\n\nEnvironmental personhood is a legal concept which designates certain environmental entities the status of a legal person. This assigns to these entities, the rights, protections, privileges, responsibilities and legal liability of a legal personality. Environmental personhood emerged from the evolution of legal focus in pursuit of the protection of nature. Over time, focus has evolved from human interests in exploiting nature, to protecting nature for future human generations, to conceptions that allow for nature to be protected as intrinsically valuable. This concept can be used as a vehicle for recognising Indigenous peoples' relationships to natural entities, such as rivers. Environmental personhood, which assigns nature (or aspects of it) certain rights, concurrently provides a means to individuals or groups such as Indigenous peoples to fulfill their human rights.\n\nThe United States Professor Christopher D. Stone first discussed the idea of attributing legal personality to natural objects in the 1970s, in his article \"Should trees have standing? Towards legal rights for natural objects\". A legal person cannot be owned; therefore, no ownership can be attributed to an environmental entity with established legal personality. Standing (law) is directly related to legal personality. Entities with standing, or locus standi, have the right or capacity to bring action or appear in court. Environmental entities cannot themselves bring action or appear in court. However, this action or standing can be achieved on behalf of the entity by a representing legal guardian. Representation could increase protection of culturally significant aspects of the natural environment, or areas vulnerable to exploitation and pollution.\n\nIn 2014, Te Urewera National Park was declared \"Te Urewera\", an environmental legal entity. The area encompassed by \"Te Urewera\" ceased to be a government-owned national park and was transformed into freehold, inalienable land owned by itself.\n\nFollowing the same trend, New Zealand’s Whanganui River was declared to be a legal person in 2017. This new legal entity was named \"Te Awa Tupua\" and is now recognised as “an indivisible and living whole from the mountains to the sea, incorporating the Whanganui River and all of its physical and metaphysical elements.” The river would be represented by two guardians, one from the Whanganui iwi and the other from the Crown.\n\nThe Ganges and Yamuna Rivers are now considered legal persons in an effort to combat pollution. The rivers are sacred to Hindu culture for their healing powers and attraction of pilgrims who bathe and scatter the ashes of their dead. The rivers have been heavily polluted by 1.5 billion litres of untreated sewage and 500 million litres of industrial waste entering the rivers daily.\nThe High Court in the northern Indian state of Uttarakhand ordered in March 2017 that the Ganges and its main tributary, the Yamuna, be assigned the status of legal entities. The rivers would gain “all corresponding rights, duties and liabilities of a living person.” This decision meant that polluting or damaging the rivers is equivalent to harming a person. The court cited the example of the New Zealand Whanganui River, which was also declared to possess full rights of a legal person.\n\nThis development of environmental personhood has been met with scepticism as merely announcing that the Ganges and Yamuna are living entities will not save them from significant, ongoing pollution. There is a possible need to change long-held cultural attitudes towards the Ganges, which hold that the river has self-purifying properties.\n\nThere is further criticism that the guardianship of the rivers was only granted to Uttarakhand, a region in northern India which houses a small part of the rivers’ full extent. The Ganges flows for 2,525km through Uttarakhand, Uttar Pradesh, Bihar, Jharkhand and West Bengal, with only a 96km stretch running through Uttarakhand. Only a small section of the 1,376km Yamuna tributary runs through Uttarakhand – which also crosses through the states of Haryana, Himachal Pradesh, Delhi and Uttar Pradesh.\n\nRegardless of scepticism surrounding the decision of the Uttarakhand High Court, proclaiming these vulnerable rivers as legal entities invokes a movement of change towards environmental and cultural rights protection. The decisions may be built upon as a foundation for future environmental legislative change. \n\nIn 2006, a small community in Pennsylvania called Tamaqua Borough worked with a rights of nature group called Community Environmental Legal Defense Fund. Together, the groups drafted legislation to protect the community and its environment from the dumping of toxic sewage. Since 2006, CELDF has assisted with over 30 communities in ten states across the United States to develop local laws codifying the rights of nature. CELDF also assisted in the drafting of Ecuador's 2008 constitution following a national referendum.\n\nThe rights of nature “to exist, persist, maintain and regenerate its vital cycles” have been proclaimed under Ecuador’s 2008 constitution. This occurred after a national referendum in 2008, allowing the Ecuador constitution to reflect rights for nature, a world first. Every person and community has the right to advocate on nature's behalf. The Constitution proclaims that the “State shall give incentives to natural persons and legal entities and to communities to protect nature and to promote respect for all the elements comprising an ecosystem.”\n\nThe first successful case of the rights of nature implementation under Ecuador constitutional law was presented before the Provincial Court of Justice of Loja in 2011. This case involved the Vilcabamba River as the plaintiff, representing itself with its own rights to ‘exist’ and ‘maintain itself’ – as it attempted to halt construction of a government highway project interfering with the natural health of the river.This case was brought before court by two individuals, Richard Frederick Wheeler and Eleanor Geer Huddle, as legal guardians acting in favour of nature – specifically the Vilcabamba River. A constitutional injunction was granted in favour of the Vilcabamba River and against the Provincial government of Loja, attempting to conduct the environmentally-harmful project. The project was forced to be halted and the area was to be rehabilitated.\n\nThe constitutional change in Ecuador was followed legislatively by Bolivia in 2010, passing the ‘Law of the Rights of Mother Earth’ (\"Ley de Derechos de la Madre Tierra\"). This legislation designates Mother Earth the character of ‘a collective subject of public interest’ with inherent rights specified in the law. The Law of the Rights of Mother Earth give aspects of legal personhood to the natural environment. Judicial action can be taken for infringements against individuals and groups as part of Mother Earth as ‘a collective subject of public interest’. The legislation states that “Mother Earth is the dynamic living system made up of the indivisible community of all living systems, living, interrelated, interdependent and complementary, sharing a common destiny.” \n\nThe Colombia Constitutional Court found in November 2016 that the Atrato River basin possesses rights to \"protection, conservation, maintenance, and restoration.\" This ruling came about as a result of degradation to the river basin from mining, impacting nature and harming of Indigenous peoples and their culture. The court referred to the New Zealand declaration of the Whanganui River as a legal person holding environmental personhood. The court ordered that joint guardianship would be undertaken in the representation of the Atrato River basin. Similarly to the New Zealand declaration, the representatives would come from the national government and the Indigenous people living in the basin.\n\nThe court stated:\n\nThe recognition of the Whanganui River as a legal entity in New Zealand (\"Te Awa Tupua\") encompassed a vivid sense of cultural “inalienable connection” to the local iwi and hapu of the river. Maori culture considers natural features such as the Whanganui River as ancestors and iwi hold deep connections with them as living entities. This inalienable connection of indigenous culture to their natural surroundings is apparent in other parts of the world such as Colombia where a similar environmental personhood declaration was made for the Atrato River basin.\n\nThe lead negotiator for the Whanganui iwi, Gerrard Albert, said “we consider the river an ancestor and always have…treating the river as a living entity is the correct way to approach it, as an indivisible whole, instead of the traditional model for the last 100 years of treating it from a perspective of ownership and management.” James D K Morris and Jacinta Ruru suggest that giving “legal personality to rivers is one way in which the law could develop to provide a lasting commitment to reconciling with Maori.” This was the longest-running legal dispute in New Zealand. The Whanganui iwi had been fighting to assert their rights in harmony with the river since the 1870s.\n\nThis is a fundamental step forward for cultural rights as the environmental personhood status of the river means that if there was harm committed to the river, the law now sees no differentiation between harming the Whanganui iwi or harming the river as they are the same indivisible entity. The Whanganui iwi have a proverb which reads \"Ko au te Awa, ko te Awa ko au\": I am the River and the River is me - the iwi and hapu of the Whanganui River have an inalienable connection with, and responsibility to, \"Te Awa Tupua\" and its health and well-being.\n\n\n"}
{"id": "4947153", "url": "https://en.wikipedia.org/wiki?curid=4947153", "title": "Experiments in Art and Technology", "text": "Experiments in Art and Technology\n\nExperiments in Art and Technology (E.A.T.) was a non-profit and tax-exempt organization established to develop collaborations between artists and engineers. The group operated by facilitating person-to-person contacts between artists and engineers, rather than defining a formal process for cooperation. E.A.T. initiated and carried out projects that expanded the role of the artist in contemporary society and helped explore the separation of the individual from technological change.\n\nE.A.T. was officially launched in 1967 by the engineers Billy Klüver and Fred Waldhauer and the artists Robert Rauschenberg and Robert Whitman. These men had previously collaborated in 1966 when they together organized \"\", a series of performance art presentations that united artists and engineers. 10 New York artists worked with 30 engineers and scientists from the world-renowned Bell Telephone Laboratories to create groundbreaking performances that incorporated new technology. Artists involved with \"9 Evenings: Theatre and Engineering\" include: John Cage, Lucinda Childs, Öyvind Fahlström, Alex Hay, Deborah Hay, Steve Paxton, Yvonne Rainer, Robert Rauschenberg, David Tudor, and Robert Whitman. Notable engineers involved include: Bela Julesz, Billy Klüver, Max Mathews, John Pierce, Manfred Schroeder, and Fred Waldhauer.\n\nVideo projection, wireless sound transmission, and Doppler sonar had never been seen in the art of the 1960s. These art performances still resonate today as forerunners of the close and rapidly evolving relationship between artists and technology. The performances were held in New York City's 69th Regiment Armory, on Lexington Avenue between 25th and 26th Streets as an homage to the original and historical 1913 Armory show.\n\nThe pinnacle of E.A.T. activity is generally considered to be the Pepsi Pavilion at Expo '70 at Osaka Japan where E.A.T. artists and engineers collaborated to design and program an immersive dome that included a fog sculpture by Fujiko Nakaya. Organized by E.A.T. founders Billy Klüver and Robert Whitman, the project was led by a core design team that also included Robert Breer, Frosty Myers, David Tudor, and a group of over 75 artists and engineers from the US and Japan. The original structure consisted of a Buckminster Fuller-style geodesic dome covered by a water vapor cloud sculpture, designed by Fujiko Nakaya, to which the architect John Pearce had devised a way to fit a Mylar mirror inside the structure.\n\nThe optical effect in the spherical mirror produced real images resembling that of a hologram. Due to the size of the mirror, a spectator looking at an image could walk around it and see it from all sides. On the terrace surrounding the Pepsi Pavilion were seven of Robert Breer’s \"Floats\", six-foot high kinetic sculptures that moved around at less than 2 feet per minute, while emitting sounds. When a \"Float\" hit an obstacle or was pushed it would reverse direction. \n\nTwenty-eight regional E.A.T. chapters were established throughout the U.S. in the late 1960s to promote collaborations between artists and engineers and expand the artist’s role in social developments related to new technologies. In 2002 the University of Washington hosted a reunion to celebrate the history of these regional liaisons and consider the legacy of E.A.T. for artists working with new technologies in the 21st century.\n\nE.A.T. activity has entered the canons of performance art, experimental noise music and theater, bridging the gap from the eras of Dada, Fluxus and the Happenings/Actions of the 1960s, through the current generation of digital artists for whom multimedia and technology are the norm. The lineage from E.A.T. experimentations in the 1960s which led to media-art explorations of the 1990s and beyond, is the same historical pathway that has led to the ArtScience movement of the 2000s -- the latter an amalgamation of E.A.T., the environmental/ecology movements, and the expanding ontological impact scientific practice has on society. Most recently, E.A.T. included a collaboration with singer songwriter Beatie Wolfe for its 50 year anniversary, which involved the artist releasing her album as the world's first live 360˚ Augmented reality stream, from the Bell Labs anechoic chamber.\n\nIn 1972 Billy Klüver, Barbara Rose and Julie Martin edited the book \"Pavilion\", that documented the design and construction of the E.A.T. Pepsi Pavilion for Expo '70 in Osaka, Japan.\n\nIn 2001 Billy Klüver produced an exhibition of photo and text panels entitled \"The Story of E.A.T.: Experiments in Art and Technology, 1960 – 2001 by Billy Klüver.\" It was first shown in Rome and then again at Sonnabend Gallery in 2002. The exhibition went to Lafayette College in the spring 2002, then to the Evolution Festival in Leeds, England, and University of Washington, in Seattle. In 2003 it traveled to San Diego State University in San Diego, California and then to a gallery in Santa Maria, California run by Ardison Phillips – who was the artist who managed the Pepsi Pavilion in 1970. From April to June 2003 a Japanese version was shown at a large exhibition at the NTT Intercommunication Center (ICC) in Tokyo which also included a number of object/artifacts and documents and E.A.T. posters, as well as works of art that Klüver and E.A.T. were involved in. A similar showing took place in Norrköping Museum of Art, Norrköping, Sweden in September 2004; and a small version of the panels were presented in 2008 at Stevens Institute of Technology as part of a celebration of Experiments in Art and Technology. \nIn November 2017, the E.A.T. projects were part of the \"VARIATION ArtJaws media art fair and exhibition\" at the Cité Internationale des Arts in Paris: All the panels and some of the below mentioned documentaries were exhibited.\n\nThe DVD Series (director: Barbro Schultz Lundestam) is an important documentation of the collaborations between the artists and engineers that produced innovative works using these emerging technologies.\n\n\n\n\n"}
{"id": "40073004", "url": "https://en.wikipedia.org/wiki?curid=40073004", "title": "Flexenclosure", "text": "Flexenclosure\n\nFlexenclosure AB is a Sweden-based developer of hybrid power systems and pre-fabricated data centres.\n\nFounded in 1989, Flexenclosure is a former subsidiary of Pharmadule Emtunga AB. It became an independent company in 2007. Flexenclosure is privately owned. Its major shareholders are Industrifonden, a Swedish investment fund; Pegroco Invest, a privately owned Swedish investment company; Andra AP-fonden (AP2), a Swedish pension fund; and International Finance Corporation (IFC), a private sector global development institution which is a member of the World Bank Group. In May 2013 IFC invested US$24 million in Flexenclosure.\nFlexenclosure’s headquarters are in Stockholm, with design and manufacturing facilities at Vara in southern Sweden, with subsidiaries in Kenya and India, and overseas offices in Nigeria, Malaysia, Pakistan and the UAE.\n\neSite is a hybrid power management system that can work as a standalone unit with a backup generator, or with any combination of grid and renewable energy sources to power telecom base station sites.\neCentre is a pre-fabricated data centre brand. eCentre is a pre-equipped, self-contained, technical, modular facility for housing and powering data and telecom equipment.\n\nAn eCentre can comprise one or a number of different elements including a data centre, switching centre, energy centre, sub-station and Network Operations Centre (NOC).\n\neCentres are custom-designed and manufactured at Flexenclosure’s research, development, design and production facility at Vara, in the south of Sweden, before being transported to their intended location for final assembly and commissioning. eCentres have mostly been installed in West, Central and North African countries such as Nigeria and Mozambique.\n"}
{"id": "314412", "url": "https://en.wikipedia.org/wiki?curid=314412", "title": "Form of the Good", "text": "Form of the Good\n\nPlato describes the \"Form of the Good\", or more literally \"the idea of the good\" (), in his dialogue the \"Republic\" (508e2–3), speaking through the character of Socrates. Plato introduces several forms in his works, but identifies the Form of the Good as the superlative. This form is the one that allows a philosopher-in-training to advance to a philosopher-king. It cannot be clearly seen or explained, but once it is recognized, it is the form that allows one to realize all the other forms.\n\nThe first references that are seen in \"The Republic\" to the Form of the Good are within the conversation between Glaucon and Socrates (454 c–d). When trying to answer such difficult questions pertaining to the definition of justice, Plato identifies that we should not \"introduce every form of difference and sameness in nature\" instead we must focus on \"the one form of sameness and difference that was relevant to the particular ways of life themselves\" which is the form of the Good. This form is the basis for understanding all other forms, it is what allows us to understand everything else. Through the conversation between Socrates and Glaucon (508 a–c), Plato analogizes the form of the Good with the sun as it is what allows us to see things. Here, Plato describes how the sun allows for sight. But he makes a very important distinction, \"sun is not sight\" but it is \"the cause of sight itself.\" As the sun is in the visible realm, the form of Good is in the intelligible realm. It is \"what gives truth to the things known and the power to know to the knower\". It is not only the \"cause of knowledge and truth, it is also an object of knowledge\".\nPlato identifies how the form of the Good allows for the cognizance to understand such difficult concepts as justice. He identifies knowledge and truth as important, but through Socrates (508d–e) says, \"good is yet more prized\". He then proceeds to explain \"although the good is not being\" it is \"superior to it in rank and power\", it is what \"provides for knowledge and truth\" (508e).\n\nPlato writes that the Form (or Idea) of the Good is the ultimate object of knowledge, although it is not knowledge itself, and from the Good, things that are just, gain their usefulness and value. Humans are compelled to pursue the good, but no one can hope to do this successfully without philosophical reasoning. According to Plato, true knowledge is conversant, not about those material objects and imperfect intelligences which we meet within our daily interactions with all mankind, but rather it investigates the nature of those purer and more perfect patterns which are the models after which all created beings are formed. Plato supposes these perfect types to exist from all eternity and calls them the \"Forms\" or \"Ideas\". As these Forms cannot be perceived by human senses, whatever knowledge we attain of the Forms must be seen through the mind's eye (cf. \"Parmenides\" 132a), while ideas derived from the concrete world of flux are ultimately unsatisfactory and uncertain (see the \"Theaetetus\"). He maintains that degree of skepticism which denies all permanent authority to the evidence of sense. In essence, Plato suggests that justice, truth, equality, beauty, and many others ultimately derive from the Form of the Good.\n\nAristotle discusses the Forms of Good in critical terms several times in both of his major surviving ethical works, the \"Eudemian\" and \"Nicomachean Ethics\". Aristotle argues that Plato's Form of the Good does not apply to the physical world, for Plato does not assign \"goodness\" to anything in the existing world. Because Plato's Form of the Good does not explain events in the physical world, humans have no reason to believe that the Form of the Good exists and the Form of the Good is thereby irrelevant to human ethics.\n\nPlato's Form of the Good is often criticized as too general. Plato's Form of the Good does not define things in the physical world that are good, and therefore lacks connectedness to reality. Because Plato's Form of the Good lacks instruction, or ways for the individual to be good, Plato's Form of the Good is not applicable to human ethics since there is no defined method for which goodness can be pursued. Through Socrates in \"The Republic\", Plato acknowledges the Form of the Good as an elusive concept and proposes that the Form of the Good be accepted as a hypothesis, rather than criticized for its weaknesses. According to Socrates in \"The Republic\", the only alternative to accepting a hypothesis is to refute all the objections against it, which is counterproductive in the process of contemplation.\n\nAristotle along with other scholars sees the Form of the Good as synonymous with the idea of One. Plato claims that Good is the highest Form, and that all objects aspire to be good. Since Plato does not define good things, interpreting Plato's Form of the Good through the idea of One allows scholars to explain how Plato's Form of the Good relates to the physical world. According to this philosophy, in order for an object to belong to the Form of the Good, it must be One and have the proper harmony, uniformity, and order to be in its proper form.\n\nPhilosopher Rafael Ferber dismissed Aristotle's view that the 'Good' is 'One' and wrote that the Form of the Good is self-contradictory. Ferber claimed that Plato's Form of the Good could be simultaneously defined and unknown, and be in a state of both \"being\" and \"not being\".\n\nPlato's Forms are also critiqued for being treated as the reason for all things, as opposed to being an essence in itself. Some scholars also believe that Plato intended the Form to be the essence of which things come into existence. These different interpretations of Plato's intention for the Form may be attributed to the idea that Plato did not have a systematic definition of the Form itself.\n\nPlato's writings on the meaning of virtue and justice permeate through the Western philosophical tradition. Plotinus, the founder of Neoplatonism, had principles that were heavily influenced by the Good. His concept of 'the One' is equivalent to 'the Good' because it describes an ultimate ontological truth. 'The One' is both 'self-caused' and the cause of being for everything else in the universe. Plotinus compared his principle of 'the One' to an illuminating light, as Plato did with the Form of the Good. As a result of Plotinus' school of Neoplatonism, the bulk of understanding of Platonic philosophy until the 19th Century came through Plotinus' interpretation of it. The early theologies of Judaism, Christianity and Islam looked to the ideas of Platonism through the lens of Plotinus.\n\nAmphis, a comic playwright of Athens, has one of his characters say: \"And as for the good that you are likely to get on her account, I know no more about it, master, than I do of the good of Plato.\" There is an ancient anecdotal tradition that Plato gave a public lecture entitled \"On the Good\" which so confused the audience that most walked out. At the end of the lecture Plato said to those hearers who remained: 'The Good is the One\".\n\n"}
{"id": "29638170", "url": "https://en.wikipedia.org/wiki?curid=29638170", "title": "Fundamental theorem of software engineering", "text": "Fundamental theorem of software engineering\n\nThe fundamental theorem of software engineering (FTSE) is a term originated by Andrew Koenig to describe a remark by Butler Lampson attributed to the late David J. Wheeler:\nThe theorem does not describe an actual theorem that can be proven; rather, it is a general principle for managing complexity through abstraction.\n\nThe theorem is often expanded by the humorous clause \"…except for the problem of too many levels of indirection,\" referring to the fact that too many abstractions may create intrinsic complexity issues of their own. For example, the use of protocol layering in computer networks, which today is ubiquitous, has been criticized in ways that are typical of more general disadvantages of abstraction. Here, the adding of extra levels of indirection may cause higher layers to duplicate the functionality of lower layers, leading to inefficiency, and functionality at one layer may need data present only at another layer, which fundamentally violates the goal of separation into different layers.\n\n"}
{"id": "22769766", "url": "https://en.wikipedia.org/wiki?curid=22769766", "title": "Global information system", "text": "Global information system\n\nThere are a variety of definitions and understandings of a global information system (GIS, GLIS), such as \n\n\nCommon to this class of information systems is that the context is a global setting, either for its use or development process. This means that it highly relates to distributed systems / distributed computing where the distribution is global. The term also incorporates aspects of global software development and there outsourcing (when the outsourcing locations are globally distributed) and offshoring aspects. A specific aspect of global information systems is the case (domain) of global software development. A main research aspect in this field concerns the coordination of and collaboration between virtual teams. Further important aspects are the internationalization and language localization of system components.\n\nCritical tasks in designing global information systems are \n\nA variety of examples can be given. Basically every multi-lingual website can be seen as a global information system. However, mostly the term GLIS is used to refer to a specific system developed or used in a global context.\n\nSpecific examples are \n\n"}
{"id": "81680", "url": "https://en.wikipedia.org/wiki?curid=81680", "title": "Gordian Knot", "text": "Gordian Knot\n\nThe Gordian Knot is a legend of Phrygian Gordium associated with Alexander the Great. It is often used as a metaphor for an intractable problem (disentangling an \"impossible\" knot) solved easily by finding a loophole or thinking creatively (\"cutting the Gordian knot\"):\nThe Phrygians were without a king, but an oracle at Telmissus (the ancient capital of Lycia) decreed that the next man to enter the city driving an ox-cart should become their king. A peasant farmer named Gordias drove into town on an ox-cart and was immediately declared king. Out of gratitude, his son Midas dedicated the ox-cart to the Phrygian god Sabazios (whom the Greeks identified with Zeus) and tied it to a post with an intricate knot of cornel bark (\"Cornus mas\"). The knot was later described by Roman historian Quintus Curtius Rufus as comprising “several knots all so tightly entangled that it was impossible to see how they were fastened.” \n\nThe ox-cart still stood in the palace of the former kings of Phrygia at Gordium in the fourth century BC when Alexander arrived, at which point Phrygia had been reduced to a satrapy or province of the Persian Empire. An oracle had declared that any man who could unravel its elaborate knots was destined to become ruler of all of Asia. Alexander wanted to untie the knot but struggled to do so without success. He then reasoned that it would make no difference \"how\" the knot was loosed, so he drew his sword and sliced it in half with a single stroke. In an alternative version of the story, Alexander loosed the knot by pulling the linchpin from the yoke.\n\nSources from antiquity agree that Alexander was confronted with the challenge of the knot, but his solution is disputed. Both Plutarch and Arrian relate that, according to Aristobulus, Alexander pulled the knot out of its pole pin, exposing the two ends of the cord and allowing him to untie the knot without having to cut through it. Some classical scholars regard this as more plausible than the popular account. Literary sources of the story include Alexander's propagandist Arrian (\"Anabasis Alexandri \"2.3), Quintus Curtius (3.1.14), Justin's epitome of Pompeius Trogus (11.7.3), and Aelian's \"De Natura Animalium\" 13.1.\n\nAlexander later went on to conquer Asia as far as the Indus and the Oxus, thus fulfilling the prophecy.\n\nThe knot may have been a religious knot-cipher guarded by Gordian/Midas's priests and priestesses. Robert Graves suggested that it may have symbolised the ineffable name of Dionysus that, knotted like a cipher, would have been passed on through generations of priests and revealed only to the kings of Phrygia.\n\nUnlike fable, true myth has few completely arbitrary elements. This myth taken as a whole seems designed to confer legitimacy to dynastic change in this central Anatolian kingdom: thus Alexander's \"brutal cutting of the knot... ended an ancient dispensation.\" The ox-cart suggests a longer voyage, rather than a local journey, perhaps linking Gordias/Midas with an attested origin-myth in Macedon, of which Alexander is most likely to have been aware. Based on the myth, the new dynasty was not immemorially ancient, but had widely remembered origins in a local, but non-priestly \"outsider\" class, represented by Greek reports equally as an eponymous peasant \"Gordias\" or the locally attested, authentically Phrygian \"Midas\" in his ox-cart. Other Greek myths legitimize dynasties by right of conquest (compare Cadmus), but the legitimising oracle stressed in this myth suggests that the previous dynasty was a race of priest-kings allied to the unidentified oracle deity.\n\n"}
{"id": "41856558", "url": "https://en.wikipedia.org/wiki?curid=41856558", "title": "Incomplete Nature", "text": "Incomplete Nature\n\nIncomplete Nature: How Mind Emerged from Matter is a 2011 book by biological anthropologist Terrence Deacon. The book covers topics in biosemiotics, philosophy of mind, and the origins of life. Broadly, the book seeks to naturalistically explain \"aboutness\", that is, concepts like intentionality, meaning, normativity, purpose, and function; which Deacon groups together and labels as ententional phenomena.\n\nDeacon's first book, \"The Symbolic Species\" focused on the evolution of human language. In that book, Deacon notes that much of the mystery surrounding language origins comes from a profound confusion on the nature of semiotic processes themselves. Accordingly, the focus of \"Incomplete Nature\" shifts from human origins to the origin of life and semiosis. \"Incomplete Nature\" can be viewed as a sizable contribution to the growing body of work positing that the problem of consciousness and the problem of the origin of life are inexorably linked. Deacon tackles these two linked problems by going back to basics. The book expands upon the classical conceptions of work and information in order to give an account of ententionality that is consistent with eliminative materialism and yet does not seek to explain away or pass off as epiphenominal the non-physical properties of life.\n\nA central thesis of the book is that absence can still be efficacious. Deacon makes the claim that just as the concept of zero revolutionized mathematics, thinking about life, mind, and other ententional phenomena in terms of constraints (i.e., what is absent) can similarly help us overcome the artificial dichotomy of the mind body problem. A good example of this concept is the hole that defines the hub of a wagon wheel. The hole itself is not a physical thing, but rather a source of constraint that helps to restrict the conformational possibilities of the wheel's components, such that, on a global scale, the property of rolling emerges. Constraints which produce emergent phenomena may not be a process which can be understood by looking at the make-up of the constituents of a pattern. Emergent phenomena are difficult to study because their complexity does not necessarily decompose into parts. When a pattern is broken down, the constraints are no longer at work; there is no hole, no absence to notice. Imagine a hub, a hole for an axle, produced only when the wheel is rolling, thus breaking the wheel may not show you how the hub emerges.\n\nDeacon notes that the apparent patterns of causality exhibited by living systems seem to be in some ways the inverse of the causal patterns of non-living systems. In an attempt to find a solution to the philosophical problems associated with teleological explanations, Deacon returns to Aristotle's four causes and attempts to modernize them with thermodynamic concepts.\n\nOrthograde changes are caused internally. They are spontaneous changes. That is, orthograde changes are generated by the spontaneous elimination of asymmetries in a thermodynamic system in disequilibrium. Because orthograde changes are driven by the internal geometry of a changing system, orthograde causes can be seen as analogous to Aristotle's formal cause. More loosely, Aristotle's final cause can also be considered orthograde, because goal oriented actions are caused from within.\n\nContragrade changes are imposed from the outside. They are non-spontaneous changes. Contragrade change is induced when one thermodynamic system interacts with the orthograde changes of another thermodynamic system. The interaction drives the first system into a higher energy, more asymmetrical state. Contragrade changes do work. Because contragrade changes are driven by external interactions with another changing system, contragrade causes can be seen as analogous to Aristotle's efficient cause.\n\nMuch of the book is devoted to expanding upon the ideas of classical thermodynamics, with an extended discussion about how consistently far from equilibrium systems can interact and combine to produce novel emergent properties. \nDeacon defines three hierarchically nested levels of thermodynamic systems: Homeodynamic systems combine to produce morphodynamic systems which combine to produce teleodynamic systems. Teleodynamic systems can be further combined to produce higher orders of self organization.\n\nHomeodynamic systems are essentially equivalent to classical thermodynamic systems like a gas under pressure or solute in solution, but the term serves to emphasize that homeodynamics is an abstract process that can be realized in forms beyond the scope of classic thermodynamics. For example, the diffuse brain activity normally associated with emotional states can be considered to be a homeodynamic system because there is a general state of equilibrium which its components (neural activity) distribute towards. In general, a homeodynamic system is any collection of components that will spontaneously eliminate constraints by rearranging the parts until a maximum entropy state (disorderliness) is achieved.\n\nA morphodynamic system consists of a coupling of two homeodynamic systems such that the constraint dissipation of each complements the other, producing macroscopic order out of microscopic interactions. Morphodynamic systems require constant perturbation to maintain their structure, so they are relatively rare in nature. The paradigm example of a morphodynamic system is a Rayleigh–Bénard cell. Other common examples are snowflake formation, whirlpools and the stimulated emission of laser light.\nMaximum entropy production: The organized structure of a morphodynamic system forms to facilitate maximal entropy production. In the case of a Rayleigh–Bénard cell, heat at the base of the liquid produces an uneven distribution of high energy molecules which will tend to diffuse towards the surface. As the temperature of the heat source increases, density effects come into play. Simple diffusion can no longer dissipate energy as fast as it is added and so the bottom of the liquid becomes hot and more buoyant than the cooler, denser liquid at the top. The bottom of the liquid begins to rise, and the top begins to sink - producing convection currents.\n\nTwo systems: The significant heat differential on the liquid produces two homeodynamic systems. The first is a diffusion system, where high energy molecules on the bottom collide with lower energy molecules on the top until the added kinetic energy from the heat source is evenly distributed. The second is a convection system, where the low density fluid on the bottom mixes with the high density fluid on the top until the density becomes evenly distributed. The second system arises when there is too much energy to be effectively dissipated by the first, and once both systems are in place, they will begin to interact.\n\nSelf organization: The convection creates currents in the fluid that disrupt the pattern of heat diffusion from bottom to top. Heat begins to diffuse into the denser areas of current, irrespective of the vertical location of these denser portions of fluid. The areas of the fluid where diffusion is occurring most rapidly will be the most viscous because molecules are rubbing against each other in opposite directions. The convection currents will shun these areas in favor of parts of the fluid where they can flow more easily. And so the fluid spontaneously segregates itself into cells where high energy, low density fluid flows up from the center of the cell and cooler, denser fluid flows down along the edges, with diffusion effects dominating in the area between the center and the edge of each cell.\n\nSynergy and constraint: What is notable about morphodynamic processes is that order spontaneously emerges explicitly because the ordered system that results is more efficient at increasing entropy than a chaotic one. In the case of the Rayleigh–Bénard cell, neither diffusion nor convection on their own will produce as much entropy as both effects coupled together. When both effects are brought into interaction, they constrain each other into a particular geometric form because that form facilitates minimal interference between the two processes. The orderly hexagonal form is stable as long as the energy differential persists, and yet the orderly form more effectively degrades the energy differential than any other form. This is why morphodynamic processes in nature are usually so short lived. They are self organizing, but also self undermining.\n\nA teleodynamic system consists of coupling two morphodynamic systems such that the self undermining quality of each is constrained by the other. Each system prevents the other from dissipating all of the energy available, and so long term organizational stability is obtained. Deacon claims that we should pinpoint the moment when two morphodynamic systems reciprocally constrain each other as the point when ententional qualities like function, purpose and normativity emerge.\n\nDeacon explores the properties of teleodynamic systems by describing a chemically plausible model system called an autogen. Deacon emphasizes that the specific autogen he describes is not a proposed description of the first life form, but rather a description of the kinds of thermodynamic synergies that the first living creature likely possessed.\n\nReciprocal catalysis: An autogen consists of two self catalyzing cyclical morphodynamic chemical reactions, similar to a chemoton. In one reaction, organic molecules react in a looped series, the products of one reaction becoming the reactants for the next. This looped reaction is self amplifying, producing more and more reactants until all the substrate is consumed. A side product of this reciprocally catalytic loop is a lipid that can be used as a reactant in a second reaction. This second reaction creates a boundary (either a microtubule or some other closed capsid like structure), that serves to contain the first reaction. The boundary limits diffusion; it keeps all of the necessary catalysts in close proximity to each other. In addition, the boundary prevents the first reaction from completely consuming all of the available substrate in the environment.\n\nThe first self: Unlike an isolated morphodynamic process whose organization rapidly eliminates the energy gradient necessary to maintain its structure, a teleodynamic process is self-limiting and self preserving. The two reactions complement each other, and ensure that neither ever runs to equilibrium - that is completion, cessation, and death. So, in a teleodynamic system there will be structures that embody a preliminary sketch of a biological function. The internal reaction network functions to create the substrates for the boundary reaction, and the boundary reaction functions to protect and constrain the internal reaction network. Either process in isolation would be abiotic but together they create a system with a normative status dependent on the functioning of its component parts.\n\nAs with other concepts in the book, in his discussion of work Deacon seeks to generalize the Newtonian conception of work such that the term can be used to describe and differentiate mental phenomena - to describe \"that which makes daydreaming effortless but metabolically equivalent problem solving difficult.\" Work is generally described as \"activity that is necessary to overcome resistance to change. Resistance can be either active or passive, and so work can be directed towards enacting change that wouldn't otherwise occur or preventing change that would happen in its absence.\" Using the terminology developed earlier in the book, work can be considered to be \"the organization of differences between orthograde processes such that a locus of contragrade process is created. Or, more simply, work is a spontaneous change inducing a non-spontaneous change to occur.\"\n\nA thermodynamic systems capacity to do work depends less upon the total energy of the system and more upon the geometric distribution of its components. A glass of water at 20 degrees Celsius will have the same amount of energy as a glass divided in half with the top fluid at 30 degrees and the bottom at 10, but only in the second glass will the top half have the capacity to do work upon the bottom. This is because work occurs at both macroscopic and microscopic levels. Microscopically, there is constant work being performed on one molecule by another when they collide. But the potential for this microscopic work to additively sum to macroscopic work depends on there being an asymmetric distribution of particle speeds, so that the average collision pushes in a focused direction. Microscopic work is necessary but not sufficient for macroscopic work. A global property of asymmetric distribution is also required.\n\nBy recognizing that asymmetry is a general property of work - that work is done as asymmetric systems spontaneously tend towards symmetry, Deacon abstracts the concept of work and applies it to systems whose symmetries are vastly more complex than those covered by classical thermodynamics. In a morphodynamic system, the tendency towards symmetry produces not global equilibrium, but a complex geometric form like a hexagonal Benard cell or the resonant frequency of a flute. This tendency towards convolutedly symmetric forms can be harnessed to do work on other morphodynamic systems, if the systems are properly coupled.\n\nResonance example: A good example of morphodynamic work is the induced resonance that can be observed by singing or playing a flute next to a string instrument like a harp or guitar. The vibrating air emitted from the flute will interact with the taut strings. If any of the strings are tuned to a resonant frequency that matches the note being played, they too will begin to vibrate and emit sound.\n\nContragrade change: When energy is added to the flute by blowing air into it, there is a spontaneous (orthograde) tendency for the system to dissipate the added energy by inducing the air within the flute to vibrate at a specific frequency. This orthograde morphodynamic form generation can be used to induce contragrade change in the system coupled to it - the taught string. Playing the flute does work on the string by causing it to enter a high energy state that could not be reached spontaneously in an uncoupled state.\n\nStructure and form: Importantly, this is not just the macro scale propagation of random micro vibrations from one system to another. The global geometric structure of the system is essential. The total energy transferred from the flute to the string matters far less than the patterns it takes in transit. That is, the amplitude of the coupled note is irrelevant, what matters is its frequency. Notes that have a higher or lower frequency than the resonant frequency of the string will not be able to do morphodynamic work.\n\nWork is generally defined to be the interaction of two orthograde changing systems such that contragrade change is produced. In teleodynamic systems, the spontaneous orthograde tendency is not to equilibriate (as in homeodynamic systems), nor to self simplify (as in morphodynamic systems) but rather to tend towards self-preservation. Living organisms spontaneously tend to heal, to reproduce and to pursue resources towards these ends. Teleodynamic work acts on these tendencies and pushes them in a contragrade, non-spontaneous direction. \nEvolution as work: Natural selection, or perhaps more accurately, adaptation, can be considered to be a ubiquitous form of teleodynamic work. The othograde self-preservation and reproduction tendencies of individual organisms tends to undermine those same tendencies in conspecifics. This competition produces a constraint that tends to mold organisms into forms that are more adapted to their environments – forms that would otherwise not spontaneously persist.\n\nFor example, in a population of New Zealand wrybill who make a living by searching for grubs under rocks, those that have a bent beak gain access to more calories. Those with bent beaks are able to better provide for their young, and at the same time they remove a disproportionate quantity of grubs from their environment, making it more difficult for those with straight beaks to provide for their own young. Throughout their lives, all the wrybills in the population do work to structure the form of the next generation. The increased efficiency of the bent beak causes that morphology to dominate the next generation. Thus an asymmetry of beak shape distribution is produced in the population - an asymmetry produced by teleodynamic work.\n\nThought as work: Mental problem solving can also be considered teleodynamic work. Thought forms are spontaneously generated, and task of problem solving is the task of molding those forms to fit the context of the problem at hand. Deacon makes the link between evolution as teleodynamic work and thought as teleodynamic work explicit. \"The experience of being sentient is what it feels like to \"be\" evolution.\"\n\nBy conceiving of work in this way, Deacon claims \"we can begin to discern \"a basis for a form of causal openness\" in the universe.\" While increases in complexity in no way alter the laws of physics, by juxtaposing systems together, pathways of spontaneous change can be made available that were inconceivably improbable prior to the systems coupling. The causal power of any complex living system lies not solely in the underlying quantum mechanics but also in the global arrangement of its components. A careful arrangement of parts can constrain possibilities such that phenomena that were formerly impossibly rare can become improbably common.\n\nOne of the central purposes of Incomplete Nature is to articulate a theory of biological information. The first formal theory of information was articulated by Claude Shannon in 1948 in his work A Mathematical Theory of Communication. Shannon's work is widely credited with ushering in the information age, but somewhat paradoxically, it was completely silent on questions of meaning and reference, i.e., what the information is \"about.\" As an engineer, Shannon was concerned with the challenge of reliably transmitting a message from one location to another. The meaning and content of the message was largely irrelevant. So, while Shannon information theory has been essential for the development of devices like computers, it has left open many philosophical questions regarding the nature of information. Incomplete Nature seeks to answer some of these questions.\n\nShannon's key insight was to recognize a link between entropy and information. Entropy is often defined as a measurement of disorder, or randomness, but this can be misleading. For Shannon's purposes, the entropy of a system is the number of possible states that the system has the capacity to be in. Any one of these potential states can constitute a message. For example, a typewritten page can bear as many different messages as there are different combinations of characters that can be arranged on the page. The information content of a message can only be understood against the background context of all of the messages that could have been sent, but weren't. Information is produced by a reduction of entropy in the message medium. \nShannon's information based conception of entropy should be distinguished from the more classic thermodynamic conception of entropy developed by Ludwig Boltzmann and others at the end of the nineteenth century. While Shannon entropy is static and has to do with the set of all possible messages/states that a signal bearing system might take, Boltzmann entropy has to do with the tendency of all dynamic systems to tend towards equilibrium. That is, there are many more ways for a collection of particles to be well mixed than to be segregated based on velocity, mass, or any other property. Boltzmann entropy is central to the theory of work developed earlier in the book because entropy dictates the direction in which a system will spontaneously tend.\n\nDeacon's addition to Shannon information theory is to propose a method for describing not just how a message is transmitted, but also how it is interpreted. Deacon weaves together Shannon entropy and Boltzmann entropy in order to develop a theory of interpretation based in teleodynamic work. Interpretation is inherently normative. Data becomes information when it has significance for its interpreter. Thus interpretive systems are teleodynamic - the interpretive process is designed to perpetuate itself. \"The interpretation of something as information indirectly reinforces the capacity to do this again.\"\n\n"}
{"id": "2629527", "url": "https://en.wikipedia.org/wiki?curid=2629527", "title": "Kankoh-maru", "text": "Kankoh-maru\n\nThe is the name of a proposed vertical takeoff and landing (VTVL), single-stage-to-orbit (SSTO), reusable launch system (rocket-powered spacecraft).\n\nThe concept was created by the in 1993. This development cost was estimated ¥2.67 trillion ($28 billion) in 1995.\n\nThe name \"Kankō Maru\" is derived from the first steam-powered vessel in Edo-era Japan.\n\n\n"}
{"id": "8075308", "url": "https://en.wikipedia.org/wiki?curid=8075308", "title": "Kasner metric", "text": "Kasner metric\n\nThe Kasner metric (developed by and named for the American mathematician Edward Kasner in 1921) is an exact solution to Einstein's theory of general relativity. It describes an anisotropic universe without matter (i.e., it is a vacuum solution). It can be written in any spacetime dimension formula_1 and has strong connections with the study of gravitational chaos.\n\nThe metric in formula_1 spacetime dimensions is\n\nand contains formula_4 constants formula_5, called the \"Kasner exponents.\" The metric describes a spacetime whose equal-time slices are spatially flat, however space is expanding or contracting at different rates in different directions, depending on the values of the formula_5. Test particles in this metric whose comoving coordinate differs by formula_7 are separated by a physical distance formula_8.\n\nThe Kasner metric is an exact solution to Einstein's equations in vacuum when the Kasner exponents satisfy the following \"Kasner conditions,\"\n\nThe first condition defines a plane, the \"Kasner plane,\" and the second describes a sphere, the \"Kasner sphere.\" The solutions (choices of formula_5) satisfying the two conditions therefore lie on the sphere where the two intersect (sometimes confusingly also called the Kasner sphere). In formula_12 spacetime dimensions, the space of solutions therefore lie on a formula_13 dimensional sphere formula_14.\n\nThere are several noticeable and unusual features of the Kasner solution:\n\n\n\n\n"}
{"id": "9744210", "url": "https://en.wikipedia.org/wiki?curid=9744210", "title": "League of peace", "text": "League of peace\n\nLeague of peace (Latin: foedus pacificum) is an expression coined by Immanuel Kant in his work \"\". The league of peace should be distinguished from a peace treaty (\"pactum pacis\") because a peace treaty prevents or terminates only one war, while the league of peace seeks to end all wars forever. This league does not hold any power of the state, but only exists for \"the maintenance and security of the freedom of the state and of other states in league with it, without there being any need for them to submit to civil laws and their compulsion, as men in a state of nature must submit.\"\n\n"}
{"id": "24640055", "url": "https://en.wikipedia.org/wiki?curid=24640055", "title": "List of rampage killers (workplace killings)", "text": "List of rampage killers (workplace killings)\n\nThe first part of this section of the list of rampage killers contains those mass murders where the perpetrators predominantly targeted their (former) co-workers, while the second part focuses on cases where soldiers willfully killed their own comrades.\n\nA rampage killer has been defined as follows:\n\nThis list should contain every case with at least one of the following features:\n\nAll abbreviations used in the tables are explained below.\n\nW – A basic description of the weapons used in the murders\n"}
{"id": "52973276", "url": "https://en.wikipedia.org/wiki?curid=52973276", "title": "Live streaming crime", "text": "Live streaming crime\n\nThe live streaming of crimes is a phenomenon arising in the 2010s in which criminals deliberately commit crimes while live streaming the act on social media. Due to the act being published to social media for others to see, it is often impossible to protect the privacy of the victims of these crimes.\n\nIn April 2016, Marina Lonina (18) and Raymond Gates (29) were arrested in Ohio on charges that Gates raped an underage friend of Marina's while Lonina live-streamed the crime on Periscope. The prosecutor pointed out that Lonina, who was taken advantage of by a much older man, had gotten \"caught up\" in her excitement over the number of \"likes\" she was getting, and is shown on screen \"laughing and giggling.\" Joss Wright of the Oxford Internet Institute pointed out that \"[given the] volume of content being created and uploaded every day [ . . . there] is almost no practical way to prevent content like this being uploaded and shared.\"\n\nBy May \"The New York Times\" was including the Ohio Periscope rape as one of a series of recent cases in which crimes were live streamed, including one in which a young woman in Égly, France speaks via Periscope about her distress and suicidal thoughts and is apparently encouraged by viewers to kill herself, which she does by throwing herself under a train, and the case of two teenagers who live stream themselves bragging and laughing as they beat up a drunken man in a bar in Bordeaux, France.\n\n\n\n\n\n"}
{"id": "31680083", "url": "https://en.wikipedia.org/wiki?curid=31680083", "title": "Map symbolization", "text": "Map symbolization\n\nMap symbolization is the characters, letters, or similar graphic representations used on a map to indicate an object or characteristic in the real world.\n\nIn cartography, the principles of cognition are important since they explain why certain map symbols work. In the past, mapmakers did not care why they worked. This behaviorist view treats the human brain like a black box. Modern cartographers are curious why certain symbols are the most effective. This should help develop a theoretical basis for how brains recognize symbols and, in turn, provide a platform for creating new symbols.\n\nTopographic maps show the shape of Earth’s surface by using contour lines, the lines on the map that join points of equal elevation. They are among the most well-known symbols on modern maps as they are self-explanatory and accurately represent their phenomena. They make it possible to the depict height, depth, and even slope. Contour lines will be closer together or spaced apart to show the steepness of the area. If the line is spaced closer together, it means that there is a steeper slope. If they are farther apart, the area has a low slope. An area of low slope generally uses contour intervals of 10 feet or less. Areas that contain mountain or other high slope can use an interval of 100 feet.\n\nApart from showing just contour lines, topographic maps also use a lot of map symbols to represent its features. Features are represented by using point, line, and area symbols. Individual features, such as houses, are shown as point symbols like a small dot or square. However, a cluster of houses or neighborhood can be shown as a shaded area or polygon. Areas of importance or landmarks may receive special symbols that represent what they are. For instance, a church may be symbolized as a picture of a little church or cross or the town hall may have a special color or symbol.\n\nMany of the symbol feature on maps of the earth will be shown by straight, curved, dashed, or solid lines. They may also be colored to represent different classes of information. The typical color standard for topographic maps depicts contours in brown, bodies of water in blue, boundaries in black, and grids and roads in red. Topographic maps may use different colors to represent area features. Most topographic maps will use green for vegetation or national parks and wildlife management areas. They will also use blue for rivers, lakes, or other bodies of water. Red may also be used to represent areas of significant importance.\n\nA map is a smaller representation of an area on the earth’s surface; therefore, map symbols are used to represent real objects. Without symbols, maps would not be possible. Both shapes and colors can be used for symbols on maps. A small circle may mean a point of interest, with a brown circle meaning recreation, red circle meaning services, and green circle meaning rest stop. Colors may cover larger areas of a map, such as green representing forested land and blue representing waterways. To ensure that a person can correctly read a map, a map legend is a key to all the symbols used on a map. It is like a dictionary so you can understand the meaning of what the map represents/\n\nThere are certain rules to follow with map symbols. The representative symbols should always be placed on the left and defined to the right. This allows for the reader to view the symbol first, then its definition, which is customary in English dictionaries. In most cases, representative symbols should be vertically displayed and the symbols should be horizontally centred. The symbols should be vertically centred with the definitions. The definitions are supposed to be horizontally centred to the left.\n\nSymbols are used to represent geographic phenomena. Most phenomena can be represented by using point, line, or area symbols. It is necessary to consider the spatial arrangement of the phenomena to determine what kind of symbolization it will require. Discrete phenomena occur at isolated points, whereas continuous phenomena occur everywhere. Both of these can also be broken down into either smooth or abrupt. For example, rainfall and taxes for states are both continuous in nature, but rainfall is smooth because it does not vary at state boundaries, leaving the tax to be considered abrupt. It is important to distinguish between real world and the data we use to represent it.\nThere are basically five types of spatial dimensions that are used to classify phenomena for map symbolization. Point phenomena are assumed to have no spatial extent and are said to be zero-dimensional. These use point symbols on a map to indicate their location. An example of these would be fire hydrants or trees in a park. Linear phenomena are one-dimensional and have a length. This would include any line feature on a map like roads or sidewalks. Areal phenomena are 2-D that has both a length and a width. The best example of this would be a lake or other body of water. When volume comes into consideration, it is broken down into two types, 2 ½ dimensions and 3-D. A good example of 2 ½ D would be the elevation of a place above sea level, while 3-D being any three-dimensional objects.\n\nAn important factor in map symbols is the order in which they are ranked according to their relative importance. This is known as intellectual hierarchy. The most important hierarchy is the thematic symbols and type labels that are directly related to the theme. Next comes the title, subtitle, and legend. The map must also contain base information, such as boundaries, roads, and place names. Data source and notes should be on all maps. Lastly, the scale, neat lines, and north arrow are the least important of the hierarchy of the map. From this we see that the symbols are the single most important thing to build a good visual hierarchy that shows proper graphical representation. When producing a map with good visual hierarchy, thematic symbols should be graphically emphasized. A map with a visual hierarchy that is effective attracts the map user’s eyes to the symbols with the most important aspects of the map first and to the symbols with the lesser importance later.\n\nThe legend of the map also contains important information and all of the thematic symbols of the map. Symbol that need no explanation, or do not coincide with the theme of the map, are normally omitted from the map legend. Thematic symbols directly represent the maps theme and should stand out.\n\nChoropleth mapping is commonly used to show data for counties, states, or other enumeration units. Data collected for choropleth maps is usually grouped into separate classes based on attributes or other forms of classification. The classes are given a specific color or shading based on their values and what they are trying to portray. Choropleth maps are most effective when the data or classes change abruptly at each enumerated boundary.\n\nA proportional symbol map is better than choropleth maps for showing raw data totals. A proportional symbols map uses symbols that are proportional to the data that they are representing with point locations. These symbols can be true points or conceptual points. True points represent real objects or the exact location of a tangible object. This could be an oil well or fire hydrant. A conceptual point represents the center of the enumeration unit, such as a corn field. The raw data on proportional symbol maps go hand in hand with the data shown on choropleth maps.\n\nIsopleth maps use isolines that connect points of equal values. A good example of isolines is connecting areas with similar temperatures. As with choropleth maps, Isopleth maps require standardized data to be appropriately contoured.\n\nDot maps use one single dot to represent where a single phenomenon is the most likely to occur. The total amount of dots can cover a single area or multiple areas. The density of the dots is interpreted by the user as areas of high value. This method is more accurate than proportional and Isopleth maps.\n"}
{"id": "1148564", "url": "https://en.wikipedia.org/wiki?curid=1148564", "title": "Marginal concepts", "text": "Marginal concepts\n\nIn economics, marginal concepts are associated with a \"specific change\" in the quantity used of a good or service, as opposed to some notion of the over-all significance of that class of good or service, or of some total quantity thereof.\n\nConstraints are conceptualized as a \"border\" or \"margin\". The location of the margin for any individual corresponds to his or her \"endowment\", broadly conceived to include opportunities. This endowment is determined by many things including physical laws (which constrain how forms of energy and matter may be transformed), accidents of nature (which determine the presence of natural resources), and the outcomes of past decisions made both by others and by the individual himself or herself.\n\nA value that holds true given particular constraints is a \"marginal\" value. A change that would be affected as or by a specific loosening or tightening of those constraints is a \"marginal\" change, as large as the smallest relevant division of that good or service. For reasons of tractability, it is often assumed in neoclassical analysis that goods and services are continuously divisible. In such context, a marginal change may be an infinitesimal change or a limit. However, strictly speaking, the smallest relevant division may be quite large.\n\nThe marginal use of a good or service is the specific use to which an agent would put a given increase, or the specific use of the good or service that would be abandoned in response to a given decrease.\n\nThe marginal utility of a good or service is the utility of the specific use to which an agent would put a given increase in that good or service, or of the specific use that would be abandoned in response to a given decrease. In other words, marginal utility is the utility of the marginal use.\n\nThe marginal rate of substitution is the rate of substitution is the least favorable rate, at the margin, at which an agent is willing to exchange units of one good or service for units of another.\n\nA marginal benefit is a benefit (howsoever ranked or measured) associated with a marginal change.\n\nThe term “marginal cost” may refer to an opportunity cost at the margin, or to marginal \"pecuniary\" cost — that is to say marginal cost measured by forgone money.\n\nOther marginal concepts include (but are not limited to):\n\nMarginalism is the use of marginal concepts to explain economic phenomena.\n\nThe related concept of elasticity is the ratio of the incremental percentage change in one variable with respect to an incremental percentage change in another variable.\n"}
{"id": "34393613", "url": "https://en.wikipedia.org/wiki?curid=34393613", "title": "Mental factors (Buddhism)", "text": "Mental factors (Buddhism)\n\nMental factors (; ; Tibetan Wylie: \"sems byung\"), in Buddhism, are identified within the teachings of the Abhidhamma (Buddhist psychology). They are defined as aspects of the mind that apprehend the quality of an object, and that have the ability to color the mind. Within the Abhidhamma, the mental factors are categorized as formations () concurrent with mind (). Alternate translations for mental factors include \"mental states\", \"mental events\", and \"concomitants of consciousness\".\n\nMental factors are aspects of the mind that apprehend the quality of an object and have the ability to color the mind. Geshe Tashi Tsering explains:\n\nThe relationship between the main mind (Sanskrit: citta) and the mental factors can be described by the following metaphors:\n\nTraleg Rinpoche states that the main distinction between the mind and mental factors is that the mind apprehends an object as a whole, whereas mental factors apprehend an object in its particulars.\n\nWithin Buddhism, there are many different systems of abhidharma (commonly referred to as Buddhist psychology), and each system contains its own list of the most significant mental factors. These lists vary from system to system both in the number of mental factors listed, and in the definitions that are given for each mental factor. These lists are not considered to be exhaustive; rather they present significant categories and mental factors that are useful to study in order to understand how the mind functions.\n\nSome of the main commentaries on the Abhidharma systems that are studied today include:\n\nIn Mahavibhasa and Abhidharma-kosa, 46 mental factors have been listed as below:\nThe ten mahā-bhūmika are common to all consciousness.\n\nThe ten kuśala-mahā-bhūmikādharmāḥ accompany the wholesome consciousnesses (kusala citta).\n\nThese six one would accompany with kleśa.\n\nWithin the Theravāda tradition, the Abhidhammattha-sangaha enumerates the fifty-two mental factors listed below:\n\nNote that this list is not exhaustive; there are other mental factors mentioned in the Theravada teachings. This list identifies fifty-two important factors that help to understand how the mind functions.\n\nThe seven universal mental factors (\"sabbacittasādhāraṇa cetasikas\") are common (\"sādhāraṇa\") to all consciousness (\"sabbacitta\"). Bhikkhu Bodhi states: \"These factors perform the most rudimentary and essential cognitive functions, without which consciousness of an object would be utterly impossible.\"\n\nThese seven factors are:\n\nThe six occasional or particular mental factors (\"pakiṇṇaka cetasikas\") are ethically variable mental factors found only in certain consciousnesses. They are:\n\nThe unwholesome mental factors (\"akusala cetasikas\") accompany the unwholesome consciousnesses (\"akusala citta\").\n\nBhikkhu Bodhi states:\n\nThe fourteen unwholesome mental factors are:\n\nThe beautiful mental factors (\"sobhana cetasikas\") accompany the wholesome consciousnesses (\"kusala citta\").\n\nBhikkhu Bodhi states:\n\nThe twenty-five beautiful mental factors (\"sobhana cetasikas\") are:\n\nAbhidharma studies in the Mahayana tradition are based on the Sanskrit Sarvāstivāda abhidharma system. Within this system, the Abhidharma-samuccaya identifies fifty-one mental factors:\n\nThe five universal mental factors (\"sarvatraga\") are:\n\nThese five mental factors are referred to as \"universal\" or \"omnipresent\" because they operate in the wake of every mind situation. If any one of these factors is missing, then the experience of the object is incomplete. For example:\n\nThe five object-determining mental factors (\"viṣayaniyata\") are:\n\nThe five factors are referred to as \"object-determining\" is because these factors each grasp the specification of the object. When they are steady, there is certainty concerning each object.\n\nThe eleven virtuous (\"kuśala\") mental factors are:\n\nThe six root unwholesome factors (\"mūlakleśa\") are:\n\nThe twenty secondary unwholesome factors (\"upakleśa\") are:\n\nThe four changeable mental factors (\"aniyata\") are:\n\nAlternate translations for the term \"mental factors\" (Sanskrit: \"caitasika\") include:\n\n\n\nMahayana mental factors:\n\nTheravada mental factors:\n\nTheravada Abhidharma:\n\nDefinitions for \"caitikas\" or \"cetisakas\"\n"}
{"id": "994704", "url": "https://en.wikipedia.org/wiki?curid=994704", "title": "Mental model", "text": "Mental model\n\nA mental model is an explanation of someone's thought process about how something works in the real world. It is a representation of the surrounding world, the relationships between its various parts and a person's intuitive perception about his or her own acts and their consequences. Mental models can help shape behaviour and set an approach to solving problems (similar to a personal algorithm) and doing tasks.\n\nA mental model is a kind of internal symbol or representation of external reality, hypothesized to play a major role in cognition, reasoning and decision-making. Kenneth Craik suggested in 1943 that the mind constructs \"small-scale models\" of reality that it uses to anticipate events.\n\nJay Wright Forrester defined general mental models as:\nThe image of the world around us, which we carry in our head, is just a model. Nobody in his head imagines all the world, government or country. He has only selected concepts, and relationships between them, and uses those to represent the real system (Forrester, 1971).\n\nIn psychology, the term \"mental models\" is sometimes used to refer to mental representations or mental simulation generally. At other times it is used to refer to and to the mental model theory of reasoning developed by Philip Johnson-Laird and Ruth M.J. Byrne.\n\nThe term \"mental model\" is believed to have originated with Kenneth Craik in his 1943 book \"The Nature of Explanation\". in \"Le dessin enfantin\" (Children's drawings), published in 1927 by Alcan, Paris, argued that children construct internal models, a view that influenced, among others, child psychologist Jean Piaget.\n\nPhilip Johnson-Laird published \"Mental Models: Towards a Cognitive Science of Language, Inference and Consciousness\" in 1983. In the same year, Dedre Gentner and Albert Stevens edited a collection of chapters in a book also titled \"Mental Models\". The first line of their book explains the idea further: \"One function of this chapter is to belabor the obvious; people's views of the world, of themselves, of their own capabilities, and of the tasks that they are asked to perform, or topics they are asked to learn, depend heavily on the conceptualizations that they bring to the task.\" (see the book: \"Mental Models\").\n\nSince then, there has been much discussion and use of the idea in human-computer interaction and usability by researchers including Donald Norman and Steve Krug (in his book \"Don't Make Me Think\"). Walter Kintsch and Teun A. van Dijk, using the term \"situation model\" (in their book \"Strategies of Discourse Comprehension\", 1983), showed the relevance of mental models for the production and comprehension of discourse.\n\nOne view of human reasoning is that it depends on mental models. In this view, mental models can be constructed from perception, imagination, or the comprehension of discourse (Johnson-Laird, 1983). Such mental models are similar to architects' models or to physicists' diagrams in that their structure is analogous to the structure of the situation that they represent, unlike, say, the structure of logical forms used in formal rule theories of reasoning. In this respect, they are a little like pictures in the picture theory of language described by philosopher Ludwig Wittgenstein in 1922. Philip Johnson-Laird and Ruth M.J. Byrne developed a theory of mental models which makes the assumption that reasoning depends, not on logical form, but on mental models (Johnson-Laird and Byrne, 1991).\n\nMental models are based on a small set of fundamental assumptions (axioms), which distinguish them from other proposed representations in the psychology of reasoning (Byrne and Johnson-Laird, 2009). Each mental model represents a possibility. A mental model represents one possibility, capturing what is common to all the different ways in which the possibility may occur (Johnson-Laird and Byrne, 2002). Mental models are iconic, i.e., each part of a model corresponds to each part of what it represents (Johnson-Laird, 2006). Mental models are based on a principle of truth: they typically represent only those situations that are possible, and each model of a possibility represents only what is true in that possibility according to the proposition. However, mental models can represent what is false, temporarily assumed to be true, for example, in the case of counterfactual conditionals and counterfactual thinking (Byrne, 2005).\n\nPeople infer that a conclusion is valid if it holds in all the possibilities. Procedures for reasoning with mental models rely on counter-examples to refute invalid inferences; they establish validity by ensuring that a conclusion holds over all the models of the premises. Reasoners focus on a subset of the possible models of multiple-model problems, often just a single model. The ease with which reasoners can make deductions is affected by many factors, including age and working memory (Barrouillet, et al., 2000). They reject a conclusion if they find a counterexample, i.e., a possibility in which the premises hold, but the conclusion does not (Schroyens, et al. 2003; Verschueren, et al., 2005).\n\nScientific debate continues about whether human reasoning is based on mental models, versus formal rules of inference (e.g., O'Brien, 2009), domain-specific rules of inference (e.g., Cheng & Holyoak, 2008; Cosmides, 2005), or probabilities (e.g., Oaksford and Chater, 2007). Many empirical comparisons of the different theories have been carried out (e.g., Oberauer, 2006).\n\nA mental model is generally:\n\nMental models are a fundamental way to understand organizational learning. Mental models, in popular science parlance, have been described as \"deeply held images of thinking and acting\". Mental models are so basic to understanding the world that people are hardly conscious of them.\n\nS.N. Groesser and M. Schaffernicht (2012) describe three basic methods which are typically used:\nThese methods allow showing a mental model of a dynamic system, as an explicit, written model about a certain system based on internal beliefs. Analyzing these graphical representations has been an increasing area of research across many social science fields. Additionally software tools that attempt to capture and analyze the structural and functional properties of individual mental models such as Mental Modeler, \"a participatory modeling tool based in fuzzy-logic cognitive mapping\", have recently been developed and used to collect/compare/combine mental model representations collected from individuals for use in social science research, collaborative decision-making, and natural resource planning.\n\nIn the simplification of reality, creating a model can find a sense of reality, seeking to overcome systemic thinking and system dynamics.\n\nThese two disciplines can help to construct a better coordination with the reality of mental models and simulate it accurately. They increase the probability that the consequences of how to decide and act in accordance with how to plan.\n\n\nAfter analyzing the basic characteristics, it is necessary to bring the process of changing the mental models, or the process of learning. Learning is a back-loop process, and feedback loops can be illustrated as: single-loop learning or double-loop learning.\n\nMental models affect the way that people work with information, and also how they determine the final decision. The decision itself changes, but the mental models remain the same. It is the predominant method of learning, because it is very convenient.\n\nDouble-loop learning (\"see diagram below\") is used when it is necessary to change the mental model on which a decision depends. Unlike single loops, this model includes a shift in understanding, from simple and static to broader and more dynamic, such as taking into account the changes in the surroundings and the need for expression changes in mental models.\n\n\n\n"}
{"id": "48799123", "url": "https://en.wikipedia.org/wiki?curid=48799123", "title": "Nancy Flanagan", "text": "Nancy Flanagan\n\nAnne (Nancy) Flanagan (born 1929) is a local community worker and rights activist, living in the Vauxhall area of Liverpool. Flanagan worked to improve the health, social and living conditions within the Vauxhall area for over 40 years, starting when she became chairperson of the Vauxhall Project in 1969. Flanagan held the position for three years. In 1984 she became chairperson of the Vauxhall Neighbourhood Council and as of 2015 was still active, as well as being chairperson of the Heriot Street Residents Association. Throughout her 50 years of public service, Flanagan did not take a salary and contributed her time voluntarily.\n\nFlanagan was involved in the campaign to build the Vauxhall Health Centre in Limekiln Lane and other projects, like the Vauxhall Health Forum. As well as these causes, Flanagan was involved with the establishing of the Vauxhall Neighbourhood Council's day nursery, the Merseyside Accredited Childcare Training and Assessment Centre (MACTAC), VNC Lifeline and Vauxhall Sure Start. Her work was recognised in 2004, when Flanagan was awarded the MBE for her endeavours within her local community.\n\nFlanagan lives alone in the home she shared with her late husband Joe Flanagan and their five children and as of 2015 is still active in local initiatives.\n"}
{"id": "851927", "url": "https://en.wikipedia.org/wiki?curid=851927", "title": "Obscurantism", "text": "Obscurantism\n\nObscurantism ( and ) is the practice of deliberately presenting information in an imprecise and recondite manner, often designed to forestall further inquiry and understanding. There are two historical and intellectual denotations of \"Obscurantism\": (1) the deliberate restriction of knowledge—opposition to disseminating knowledge; and, (2) deliberate obscurity—an abstruse style (as in literature and art) characterized by deliberate vagueness.\n\nThe term \"obscurantism\" derives from the title of the 16th-century satire \"Epistolæ Obscurorum Virorum\" (1515–19, \"Letters of Obscure Men\"), that was based upon the intellectual dispute between the German humanist Johann Reuchlin and the monk Johannes Pfefferkorn of the Dominican Order, about whether or not all Jewish books should be burned as un-Christian heresy. Earlier, in 1509, the monk Pfefferkorn had obtained permission from Maximilian I, Holy Roman Emperor (1486–1519), to burn all copies of the Talmud (Jewish law and Jewish ethics) known to be in the Holy Roman Empire (AD 926–1806); the \"Letters of Obscure Men\" satirized the Dominican arguments for burning \"un-Christian\" works.\n\nIn the 18th century, Enlightenment philosophers applied the term \"obscurantist\" to any enemy of intellectual enlightenment and the liberal diffusion of knowledge. In the 19th century, in distinguishing the varieties of obscurantism found in metaphysics and theology from the \"more subtle\" obscurantism of the critical philosophy of Immanuel Kant, and of modern philosophical skepticism, Friedrich Nietzsche said: \"The essential element in the black art of obscurantism is not that it wants to darken individual understanding, but that it wants to blacken our picture of the world, and darken our idea of existence.\"\n\nIn restricting knowledge to an élite ruling class of \"the few\", obscurantism is fundamentally anti-democratic, because its component anti-intellectualism and elitism exclude the people as intellectually unworthy of knowing the facts and truth about the government of their City-State. In 18th century monarchic France, the Marquis de Condorcet, as a political scientist, documented the aristocracy's obscurantism about the social problems that provoked the French Revolution (1789–99) that deposed them and their King, Louis XVI of France.\n\nIn 18th century monarchic France, the Marquis de Condorcet, as a political scientist, documented the aristocracy's obscurantism about the social problems that provoked the French Revolution (1789–99) that deposed them and their King, Louis XVI of France.\n\nIn the 19th century, the mathematician William Kingdon Clifford, an early proponent of Darwinism, devoted some writings to uprooting obscurantism in England, after hearing clerics—who privately agreed with him about evolution—publicly denounce evolution as un-Christian. Moreover, in the realm of organized religion, obscurantism is a distinct strain of thought independent of theologic allegiance. The distinction is that fundamentalism presupposes sincere religious belief, whereas obscurantism is based upon minority manipulation of the popular faith as political praxis; cf. Censorship.\n\nIn the 20th century, the American conservative political philosopher Leo Strauss, for whom philosophy and politics intertwined, and his Neo-conservative adherents adopted the notion of government by the enlightened few as political strategy. He noted that intellectuals, dating from Plato, confronted the dilemma of either an informed populace \"interfering\" with government, or if it were possible for good politicians to be truthful and still govern to maintain a stable society—hence the Noble Lie necessary in securing public acquiescence. In \"The City and Man\" (1964), he discusses the myths in \"The Republic\" that Plato proposes effective governing requires, among them, the belief that the country (land) ruled by the State belongs to it (despite some having been conquered from others), and that citizenship derives from more than the accident of birth in the City-State. Thus, in the \"New Yorker\" magazine article \"Selective Intelligence\", Seymour Hersh observes that Strauss endorsed the \"Noble Lie\" concept: the myths politicians use in maintaining a cohesive society.\n\nShadia Drury criticized Strauss's acceptance of dissembling and deception of the populace as \"the peculiar justice of the wise\", whereas Plato proposed the Noble Lie as based upon moral good. In criticizing \"Natural Right and History\" (1953), she said that \"Strauss thinks that the superiority of the ruling philosophers is an intellectual superiority and not a moral one ... [he] is the only interpreter who gives a sinister reading to Plato, and then celebrates him.\"\n\nLeo Strauss also was criticized for proposing the notion of \"esoteric\" meanings to ancient texts, obscure knowledge inaccessible to the \"ordinary\" intellect. In \"Persecution and the Art of Writing\" (1952), he proposes that some philosophers write esoterically to avert persecution by the political or religious authorities, and, per his knowledge of Maimonides, Al Farabi, and Plato, proposed that an esoteric writing style is proper for the philosophic text. Rather than explicitly presenting his thoughts, the philosopher's esoteric writing compels the reader to think independently of the text, and so learn. In the \"Phædrus\", Socrates notes that writing does not reply to questions, but invites dialogue with the reader, thereby minimizing the problems of grasping the written word. Strauss noted that one of writing's political dangers is students' too-readily accepting dangerous ideas—as in the trial of Socrates, wherein the relationship with Alcibiades was used to prosecute him.\n\nFor Leo Strauss, philosophers' texts offered the reader lucid \"exoteric\" (salutary) and obscure \"esoteric\" (true) teachings, which are concealed to the reader of ordinary intellect; emphasizing that writers often left contradictions and other errors to encourage the reader's more scrupulous (re-)reading of the text. In observing and maintaining the \"exoteric – esoteric\" dichotomy, Strauss was accused of obscurantism, and for writing esoterically. \n\nIn the \"Wired\" magazine article, \"Why the Future Doesn't Need Us\" (April 2000), the computer scientist Bill Joy, then a Sun Microsystems chief scientist, in the sub-title proposed that: \"Our most powerful twenty-first-century technologies—robotics, genetic engineering, and nanotech[nology]—are threatening to make humans an endangered species\"; in the body, he posits that:\n\nJoy's proposal for limiting the dissemination of \"certain\" knowledge, in behalf of preserving society, was quickly likened to obscurantism. A year later, the American Association for the Advancement of Science, in the \"Science and Technology Policy Yearbook 2001\", published the article \"A Response to Bill Joy and the Doom-and-Gloom Technofuturists\", wherein the computer scientists John Seely Brown and Paul Duguid countered his proposal as technological tunnel vision, and the predicted technologically derived problems as infeasible, for disregarding the influence of non-scientists upon such societal problems.\n\nIn the essay \"Why I Am Not a Conservative\" (1960), the economist Friedrich von Hayek said that political conservatism is ideologically unrealistic, because of the conservative person’s inability to adapt to changing human realities and refusal to offer a positive political program that benefits everyone in a society. In that context, Hayek used the term \"obscurantism\" differently, to denote and describe the denial of the empirical truth of scientific theory, because of the disagreeable moral consequences that might arise from acceptance of fact.\n\nThe second sense of \"obscurantism\" denotes making knowledge abstruse, that is, difficult to grasp. In the 19th and 20th centuries obscurantism became a polemical term for accusing an author of deliberately writing obscurely, in order to hide his or her intellectual vacuousness. Philosophers who are neither empiricists nor positivists often are considered obscurantists when describing the abstract concepts of their disciplines. For philosophic reasons, such authors might modify or reject verifiability, falsifiability, and logical non-contradiction. From that perspective, obscure (clouded, vague, abstruse) writing does not necessarily indicate that the writer has a poor grasp of the subject, because unintelligible writing sometimes is purposeful and philosophically considered.\n\nIn contemporary discussions of virtue ethics, Aristotle's \"Nicomachean Ethics\" (\"The Ethics\") stands accused of ethical obscurantism, because of the technical, philosophic language and writing style, and their purpose being the education of a cultured governing elite.\n\nImmanuel Kant employed technical terms that were not commonly understood by the layman. Arthur Schopenhauer contended that post-Kantian philosophers such as Johann Gottlieb Fichte, Friedrich Wilhelm Joseph Schelling, and Georg Wilhelm Friedrich Hegel deliberately imitated the abstruse style of writing practiced by Kant.\n\nG. W. F. Hegel's philosophy, and the philosophies of those he influenced, especially Karl Marx, have been accused of obscurantism. Analytic and positivistic philosophers, such as A. J. Ayer, Bertrand Russell, and the critical-rationalist Karl Popper, accused Hegel and Hegelianism of being obscure. About Hegel's philosophy, Schopenhauer wrote that it is: \"... a colossal piece of mystification, which will yet provide posterity with an inexhaustible theme for laughter at our times, that it is a pseudo-philosophy paralyzing all mental powers, stifling all real thinking, and, by the most outrageous misuse of language, putting in its place the hollowest, most senseless, thoughtless, and, as is confirmed by its success, most stupefying verbiage. ...\"\n\nNevertheless, biographer Terry Pinkard notes \"Hegel has refused to go away, even in analytic philosophy, itself.\" Hegel was aware of his obscurantism, and perceived it as part of philosophical thinking: to accept and transcend the limitations of quotidian (everyday) thought and its concepts. In the essay \"Who Thinks Abstractly?\", he said that it is not the philosopher who thinks abstractly, but the layman, who uses concepts as givens that are immutable, without context. It is the philosopher who thinks concretely, because he transcends the limits of quotidian concepts, in order to understand their broader context. This makes philosophical thought and language appear obscure, esoteric, and mysterious to the layman.\n\nIn his early works, Karl Marx criticized German and French philosophy, especially German Idealism, for its traditions of German irrationalism and ideologically motivated obscurantism. Later thinkers whom he influenced, such as the philosopher György Lukács and social theorist Jürgen Habermas, followed with similar arguments of their own. However, philosophers such as Karl Popper and Friedrich Hayek in turn criticized Marx and Marxist philosophy as obscurantist (however, see above for Hayek's particular interpretation of the term).\n\nMartin Heidegger, and those influenced by him, such as Jacques Derrida and Emmanuel Levinas, have been labeled obscurantists by critics from analytic philosophy and the Frankfurt School of critical theory. Of Heidegger, Bertrand Russell wrote, \"his philosophy is extremely obscure. One cannot help suspecting that language is here running riot. An interesting point in his speculations is the insistence that nothingness is something positive. As with much else in Existentialism, this is a psychological observation made to pass for logic.\" That is Russell's complete entry on Heidegger, and it expresses the sentiments of many 20th-century analytic philosophers concerning Heidegger.\n\nIn their obituaries, \"Jacques Derrida, Abstruse Theorist, Dies at 74\" (10 October 2004) and \"Obituary of Jacques Derrida, French intellectual\" (21 October 2004), \"The New York Times\" newspaper and \"The Economist\" magazine, described Derrida as a deliberately obscure philosopher.\n\nIn \"Contingency, Irony, and Solidarity\" (1989), Richard Rorty proposed that in \"The Post Card: From Socrates to Freud and Beyond\" (1978), Jacques Derrida purposefully used undefinable words (e.g. Différance), and used defined words in contexts so diverse that they render the words unintelligible, hence, the reader is unable to establish a context for his literary self. In that way, the philosopher Derrida escapes metaphysical accounts of his work. Since the work ostensibly contains no metaphysics, Derrida has, consequently, escaped metaphysics.\n\nDerrida's philosophic work is especially controversial among American and British academics, as when the University of Cambridge awarded him an honorary doctorate, despite opposition from among the Cambridge philosophy faculty and analytical philosophers worldwide. In opposing the decision, philosophers including Barry Smith, W. V. O. Quine, David Armstrong, Ruth Barcan Marcus, René Thom, and twelve others, published a letter of protestation in \"The Times\" of London, arguing that \"his works employ a written style that defies comprehension ... [thus] Academic status based on what seems to us to be little more than semi-intelligible attacks upon the values of reason, truth, and scholarship is not, we submit, sufficient grounds for the awarding of an honorary degree in a distinguished university.\"\n\nIn the \"New York Review of Books\" article \"An Exchange on Deconstruction\" (February 1984), John Searle comments on Deconstruction: \"... anyone who reads deconstructive texts with an open mind is likely to be struck by the same phenomena that initially surprised me: the low level of philosophical argumentation, the deliberate obscurantism of the prose, the wildly exaggerated claims, and the constant striving to give the appearance of profundity, by making claims that seem paradoxical, but under analysis often turn out to be silly or trivial.\"\n\nJacques Lacan was an intellectual who defended obscurantism to a degree. To his students' complaint about the deliberate obscurity of his lectures, he replied: \"The less you understand, the better you listen.\" In the 1973 seminar \"Encore\", he said that his \"Écrits\" (\"Writings\") were not to be understood, but would effect a meaning in the reader, like that induced by mystical texts. The obscurity is not in his writing style, but in the repeated allusions to Hegel, derived from Alexandre Kojève's lectures on Hegel, and similar theoretic divergences.\n\nThe Sokal Affair (1996) was a publishing hoax that the professor of physics Alan Sokal perpetrated on the editors and readers of \"Social Text\", an academic journal of post-modern cultural studies that was not then a peer-reviewed publication. In 1996, as an experiment testing editorial integrity (fact-checking, verification, peer review, etc.), Sokal submitted \"Transgressing the Boundaries: Towards a Transformative Hermeneutics of Quantum Gravity\", a pseudoscientific article proposing that physical reality is a social construct, in order to learn if \"Social Text\" would \"publish an article liberally salted with nonsense if: (a) it sounded good, and, (b) it flattered the editors' ideological preconceptions\". Sokal's fake article was published in the Spring/Summer 1996 issue of \"Social Text\", which was dedicated to the Science Wars about the conceptual validity of scientific objectivity and the nature of scientific theory, among scientific realists and postmodern critics in American universities.\n\nSokal's \"raison de guerre\" (\"war reason\") for publication of a false article was that postmodernist critics questioned the objectivity of science, by criticising the scientific method and the nature of knowledge, usually in the disciplines of cultural studies, cultural anthropology, feminist studies, comparative literature, media studies, and science and technology studies. Whereas the scientific realists countered that objective scientific knowledge exists, riposting that postmodernist critics almost knew nothing of the science they criticized. In the event, editorial deference to \"Academic Authority\" (the Author-Professor) prompted the editors of \"Social Text\" not to fact-check Sokal's manuscript by submitting it to peer review by a scientist.\n\nLater, concerning the lack of editorial integrity shown by the publication of his fake article in \"Social Text\" magazine, Sokal addressed the matter in the May 1996 edition of the \"Lingua Franca\" journal, in the article \"A Physicist Experiments With Cultural Studies\", in which he (Sokal) announced that his transformative hermeneutics article was a parody, submitted \"to test the prevailing intellectual standards\", and concluded that, as an academic publication, \"Social Text\" ignored the requisite intellectual rigor of verification and \"felt comfortable publishing an article on quantum physics without bothering to consult anyone knowledgeable in the subject\".\n\nMoreover, as a public intellectual, Sokal said his hoax was an action protesting against the contemporary tendency towards obscurantism—abstruse, esoteric, and vague writing in the social sciences:\n\nIn short, my concern over the spread of subjectivist thinking is both intellectual and political. Intellectually, the problem with such doctrines is that they are false (when not simply meaningless). There is a real world; its properties are not merely social constructions; facts and evidence do matter. What sane person would contend otherwise? And yet, much contemporary academic theorizing consists precisely of attempts to blur these obvious truths—the utter absurdity of it all being concealed through obscure and pretentious language.\n\nMoreover, independent of the hoax, as a pseudoscientific opus, the article \"Transgressing the Boundaries: Towards a Transformative Hermeneutics of Quantum Gravity\" is described as an exemplar \"pastiche of left-wing cant, fawning references, grandiose quotations, and outright nonsense, centered on the claim that physical reality is merely a social construct.\"\n\n\n\n"}
{"id": "4227727", "url": "https://en.wikipedia.org/wiki?curid=4227727", "title": "Panopticism", "text": "Panopticism\n\nPanopticism is a social theory named after the Panopticon, originally developed by French philosopher Michel Foucault in his book \"Discipline and Punish.\" The \"panopticon\" refers to an experimental laboratory of power in which behaviour could be modified, and Foucault viewed the panopticon as a symbol of the disciplinary society of surveillance.\n\nJeremy Bentham proposed the panopticon as a circular building with an observation tower in the centre of an open space surrounded by an outer wall. This wall would contain cells for occupants. This design would increase security by facilitating more effective surveillance. Residing within cells flooded with light, occupants would be readily distinguishable and visible to an official invisibly positioned in the central tower. Conversely, occupants would be invisible to each other, with concrete walls dividing their cells. Due to the bright lighting emitted from the watch tower, occupants would not be able to tell if and when they are being watched, making discipline a passive rather than an active action. Strangely, the cell-mates act in matters as if they are being watched, though they cannot be certain eyes are actually on them. There is a type of invisible discipline that reigns through the prison, for each prisoner self-regulates, in fear that someone is watching their every move. Although usually associated with prisons, the panoptic style of architecture might be used in other institutions with surveillance needs, such as schools, factories, or hospitals.\n\nIn \"Discipline and Punish\", Michel Foucault builds on Bentham's conceptualization of the panopticon as he elaborates upon the function of disciplinary mechanisms in such a prison and illustrates the function of discipline as an apparatus of power. The ever-visible inmate, Foucault suggests, is always \"the object of information, never a subject in communication\". He adds that,\n\n\"He who is subjected to a field of visibility, and who knows it, assumes responsibility for the constraints of power; he makes them play spontaneously upon himself; he inscribes in himself the power relation in which he simultaneously plays both roles; he becomes the principle of his own subjection\" (202-203).\n\nFoucault offers still another explanation for the type of \"anonymous power\" held by the operator of the central tower, suggesting that, \"We have seen that anyone may come and exercise in the central tower the functions of surveillance, and that this being the case, he can gain a clear idea of the way the surveillance is practiced\". By including the anonymous \"public servant,\" as part of the built-in \"architecture\" of surveillance, the disciplinary mechanism of observation is decentered and its efficacy improved.\n\nAs hinted at by the architecture, this panoptic design can be used for any \"population\" that needs to be kept under observation or control, such as: prisoners, schoolchildren, medical patients, or workers: \"If the inmates are convicts, there is no danger of a plot, an attempt at collective escape, the planning of new crimes for the future, bad reciprocal influences; if they are patients, there is no danger of contagion; if they are madmen there is no risk of their committing violence upon one another; if they are schoolchildren, there is no copying, no noise, no chatter, no waste of time; if they are workers, there are no disorders, no theft, no coalitions, none of those distractions that slow down the rate of work, make it less perfect or cause accidents\". By individualizing the subjects and placing them in a state of constant visibility, the efficiency of the institution is maximized. Furthermore, it guarantees the function of power, even when there is no one actually asserting it. It is in this respect that the Panopticon functions automatically. Foucault goes on to explain that this design is also applicable for a laboratory. Its mechanisms of individualization and observation give it the capacity to run many experiments simultaneously. These qualities also give an authoritative figure the \"ability to penetrate men’s behavior\" without difficulty. This is all made possible through the ingenuity of the geometric architecture. In light of this fact Foucault compares jails, schools, and factories in their structural similarities.\n\nA central idea of Foucault’s panopticism concerns the systematic ordering and controlling of human populations through subtle and often unseen forces. Such ordering is apparent in many parts of the modernized and now, increasingly digitalized, world of information. Contemporary advancements in technology and surveillance techniques have perhaps made Foucault’s theories more pertinent to any scrutiny of the relationship between the state and its population.\n\nHowever, while on one hand, new technologies, such as CCTV or other surveillance cameras, have shown the continued utility of panoptic mechanisms in liberal democracies, it could also be argued that electronic surveillance technologies are unnecessary in the original \"organic\" or \"geometric\" disciplinary mechanisms as illustrated by Foucault. Foucault argues, for instance, that Jeremy Bentham's Panopticon provides us with a model in which a self-disciplined society has been able to develop. These apparatuses of behavior control are essential if we are to govern ourselves, without the constant surveillance and intervention by an \"agency\" in every aspect of our lives. The Canadian historian Robert Gellately has observed, for instance, that because of the widespread willingness of Germans to inform on each other to the Gestapo that Germany between 1933-45 was a prime example of Panopticism.\n\nPanoptic theory has other wide-ranging impacts for surveillance in the digital era as well. Kevin Haggerty and Richard Ericson, for instance, have hinted that technological surveillance \"solutions\" have a particularly \"strong cultural allure\" in the West. Increasingly visible data, made accessible to organizations and individuals from new data-mining technologies, has led to the proliferation of “dataveillance,” which may be described as a mode of surveillance that aims to single out particular transactions through routine algorithmic production. In some cases, however, particularly in the case of mined credit card information, dataveillance has been documented to have led to a greater incidence of errors than past surveillance techniques.\n\nAccording to the tenets of Foucault's panopticism, if discursive mechanisms can be effectively employed to control and/or modify the body of discussion within a particular space (usually to the benefit of a particular governing class or organization), then there is no longer any need for an \"active agent\" to display a more overtly coercive power (i.e., the threat of violence). Since the beginning of the Information Age, there exists a debate over whether these mechanisms are being refined or accelerated, or on the other hand, becoming increasingly redundant, due to new and rapid technological advancements.\n\nFoucault also relates panopticism to capitalism:\n\"[The] peculiarity of the disciplines [elements of Panopticism] is that they try to define in relation to the multiplicities a tactics of power that fulfils three criteria: firstly, to obtain the exercise of power at the lowest possible cost (economically, by the low expenditure it involves; politically, by its discretion, its low exteriorization, its relative invisibility, the little resistance it arouses); secondly, to bring the effects of this social power to their maximum intensity and to extend them as far as possible, without either failure or interval; thirdly, to link this 'economic' growth of power with the output of the apparatuses (educational, military, industrial or medical) within which it is exercised; in short, to increase both the docility and the utility of all elements of the system\" (218).\n\n\"If the economic take-off of the West began with the techniques that made possible the accumulation of capital, it might perhaps be said that the methods for administering the accumulation of men made possible a political take-off in relation to the traditional, ritual, costly, violent forms of power [i.e. torture, public executions, corporal punishment, etc. of the middle ages], which soon fell into disuse and were superseded by a subtle, calculated technology of subjection. In fact, the two processes - the accumulation of men and the accumulation of capital - cannot be separated; it would not be possible to solve the problem of the accumulation of men without the growth of an apparatus of production capable of both sustaining them and using them; conversely, the techniques that made the cumulative multiplicity of men useful accelerated the accumulation of capital ... The growth of the capitalist economy gave rise to the specific modality of disciplinary power, whose general formulas, techniques of submitting forces and bodies, in short, 'political anatomy', could be operated in the most diverse political régimes, apparatuses or institutions\" (220-221).\n\nBuilding onto Foucault's Panopticism and Bentham's original Panopticon, Shoshana Zuboff applies the Panoptical theory in a technological context in her book, \"In the Age of the Smart Machine.\" In chapter nine, Zuboff provides a very vivid portrayal of the Information Panopticon as a means of surveillance, discipline and, in some cases, punishment in a work environment. The Information Panopticon embodies Bentham's idea in a very different way. Information Panopticons do not rely on physical arrangements, such as building structures and direct human supervision. Instead, a computer keeps track of a worker’s every move by assigning him or her specific tasks to perform during their shift. Everything, from the time a task is started to the time it is completed, is recorded. Workers are given a certain amount of time to complete the task based on its complexity. All this is monitored by supervision from a computer. Based on the data, the supervisor can monitor a worker’s performance and take any necessary action when needed.\n\nThe Information Panopticon can be defined as a form of centralized power that uses information and communication technology as observational tools and control mechanisms. Unlike the Panopticon envisioned by Bentham and Foucault, in which those under surveillance were unwilling subjects, Zuboff’s work suggests that the Information Panopticon is facilitated by the benefits it offers to willing participants.\n\nIn chapter ten of “In the Age of the Smart Machine,” Zuboff provides the example of DIALOG, a computer conferencing system used at a pharmaceutical corporation in the 1970s. The conferencing system, originally intended to facilitate communication among the corporation’s many branches, quickly became popular with employees. Users of DIALOG found that the system facilitated not only innovation and collaboration, but also relaxation, as many employees began to use the system to joke with one another and discuss non-work related topics. Employees widely reported that using the system was a positive experience because it created a culture of shared information and discussion, which transcended the corporation’s norms of formality and hierarchy that limited the spread of information between divisions and employees of different ranks. This positive culture was enabled by the privacy seemingly offered by the conferencing system, as discussion boards could be made to allow access only to those who were invited to participate. The Panoptic function of the conferencing system was revealed, however, when managers were able to gain access to the informal discussion boards where employees posted off-color jokes. Messages from the discussion were posted around the office to shame contributors, and many of DIALOG’s users, now knowing there was a possibility that their contributions could be read by managers and fearing they would face disciplinary action, stopped using the system. Some users, however, kept using the system, raising the question of whether remaining users modified their behavior under the threat of surveillance, as prisoners in Bentham’s Panopticon would, or whether they believed that the benefits offered by the system outweighed the possibility of punishment.\n\nZuboff’s work shows the dual nature of the Information Panopticon – participants may be under surveillance, but they may also use the system to conduct surveillance of others by monitoring or reporting other users’ contributions. This is true of many other information and communication technologies with Panoptic functions – cellphone owners may be tracked without their knowledge through the phones’ GPS capabilities, but they may also use the device to conduct surveillance of others. Thus, compared to Bentham’s Panopticon, the Information Panopticon is one in which everyone has the potential to be both a prisoner and a guard.\n\nIt is argued by Foucault that industrial management has paved the way for a very disciplinary society. A society that values objectivity over everything else. The point of this is to get as much productivity from the workers as possible. Contrasting with Bentham's model prison, workers within the Information Panopticon know they are being monitored at all times. Even if a supervisor is not physically there, the computer records their every move and all this data is at the supervisor's finger tips at all times. The system's objectivity can have a psychological impact on the workers. Workers feel the need to conform and satisfy the system rather than doing their best work or expressing concerns they might have.\n\nThe Information Panopticon diverts from Jeremy Bentham's model prison by adding more levels of control. While the Bentham's model prison system is made up of inmates at the lowest level monitored by a guard, the Information Panopticon can have various levels. A company or firm can have various satellite locations, each monitored by a supervisor, and then a regional supervisor monitoring the supervisors below him or her. Depending on the structure and size of a firm, information Panopticons can have several levels, each monitoring all the levels beneath it.\n\nNow, the efficiency of the Information Panopticon is in question. Does it really lead to a better work place and higher productivity, or does it simply put unnecessary stress on the people being monitored? A major criticism of the system is its objectivity. It is solely based on numbers, therefore not allowing for human error. According to Zuboff, some people find the system to be highly advantageous, while others think it is very flawed because it does not account for the effort a worker puts into a task or things outside of a worker's control. Furthermore, the lack of direct supervision only adds to a potentially precarious situation.\n\nTheoretical arguments in favor of rejecting the Foucauldian model of Panopticism may be considered under five general headings:\n\n\nThe first point concerns Zygmunt Bauman’s argument that the leading principle of social order has moved from Panopticism to seduction. This argument is elaborated in his 1998 essay ‘On postmodern uses of sex’.\n\nThe second argument concerns surveillance redundance, and it is increasingly relevant in the age of Facebook and online self-disclosure. Is the metaphor of a panopticon appropriate for voluntary surrender of privacy?\n\nThe third argument for post-Panopticism, concerning action before the fact, is articulated by William Bogard:\n\nThe figure of the Panopticon is already haunted by a parallel figure of simulation. Surveillance, we are told, is discreet, unobtrusive, camouflaged, unverifiable – all elements of artifice designed into an architectural arrangement of spaces to produce real effects of discipline. Eventually this will lead, by its means of perfection, to the elimination of the Panopticon itself . . . surveillance as its own simulation. Now it is no longer a matter of the speed at which information is gained to defeat an enemy. . . . Now, one can simulate a space of control, project an indefinite number of courses of action, train for each possibility, and react immediately with pre-programmed responses to the actual course of events . . . with simulation, sight and foresight, actual and virtual begin to merge. . . . Increasingly the technological enlargement of the field of perceptual control, the erasure of distance in the speed of electronic information has pushed surveillance beyond the very limits of speed toward the purest forms of anticipation.\n\nThis kind of anticipation is particularly evident in emergent surveillance technologies such as social network analysis.\n\nThe ‘Synopticon’ concerns the surveillance of the few by the many. Examples of this kind of surveillance may include the theatre, the Coliseum, and celebrity tabloid reporting. This “reversal of the Panoptical polarity may have become so marked that it finally deconstructs the Panoptical metaphor altogether”.\n\nFinally, the fifth point concerns the self-defeating nature of Panoptical regimes. The failure of surveillance states is illustrated by examples such as “prison riots, asylum sub-cultures, ego survival in Gulag or concentration camp, [and] retribalization in the Balkans.”\n\nIn their 2007 article, Dobson and Fisher lay out an alternative model of post-panopticism as they identify three panoptic models. Panopticism I refers to Jeremy Bentham’s original conceptualization of the panopticon, and is it the model of panopticism that Foucault responds to in his 1975 Discipline and Punish. Panopticism II refers to an Orwellian ‘Big Brother’ ideal of surveillance. Panopticism III, the final model of panopticism, refers to the high-technology human tracking systems that are emergent in this 21st century. These geographical information systems (GIS) include technologies such as cellphone GPS, RFIDs (radio-frequency identification tags), and geo-fences. Panopticism III is also distinguished by its costs:\n\nPanopticon III is affordable, effective, and available to anyone who wants to use it. Initial purchase prices and monthly service fees are equivalent to cell-phone costs. In less than five years, the cost of continuous surveillance of a single individual has dropped from several hundred thousand dollars per year to less than $500 per year. Surveillance formerly justified solely for national security and high-stakes commerce is readily available to track a spouse, child, parent, employee, neighbor, or stranger.\n\nThe Cornell University professor and information theorist Branden Hookway introduced the concept of a Panspectrons in 2000: an evolution of the panopticon to the effect that it does not define an object of surveillance more, but everyone and everything is monitored. The object is defined only in relation to a specific issue.\n\nParis School academic Didier Bigo coined the term 'Banopticon' to describe a situation where profiling technologies are used to determine who to place under surveillance.\n\n\n"}
{"id": "45290075", "url": "https://en.wikipedia.org/wiki?curid=45290075", "title": "Punya (Hinduism)", "text": "Punya (Hinduism)\n\nPunya (Sanskrit: पुण्य) is a difficult word to translate; there is no equivalent English word to convey its exact intended meaning. It is generally taken to mean 'saintly', virtue, 'holy', 'sacred', 'pure', 'good', 'meritorious', 'virtuous', 'righteous', 'just', 'auspicious', 'lucky', 'favourable', 'agreeable', 'pleasing', 'lovely', 'beautiful', 'sweet', 'fragrant', 'solemn' or 'festive', according to the context it is used. \n\n\"Punya\" (पुण्य,) is referred to as good \"karma\" or a virtue that contributes benefits in this and the next birth and can be acquired by appropriate means and also accumulated. In Vedanta terms \"punya\" is the invisible wealth, a part of \"dharma\", the third human goal; the other two goals being \"artha\" and \"kama\". \"Punya\" and \"pāpa\" are the seeds of future pleasure and pain, the former, which sows merits, exhausts itself only through pleasure and the latter, which sows demerits, exhausts itself only through pain; but \"Jiwan mukti\" ends all karmic debts consisting of and signified by these two dynamics. \n\nDuring the Vedic period, \"brahmacharya\" practiced by the Brahmins was believed to ensure the desired gain of eternal life but owing to the changes in living patterns and increase in the demands of life, people veered towards Brahmaloka which the accumulation of merits of \"punya-karma\" ('good deeds or actions') seemed to promise and opted for the \"deva-yāna\" or 'the path of the gods'. The dynamics of \"karma\" played a large role in the development of Buddhist thought. The Buddhists believe that \"karma\" determines one’s nature and life-pattern but to them \"karma\" is \"chetnā\", a mental drive, a psychological phenomenon rather than a law governing substantial existence. The Buddhists consider Punya as the extraordinary force that confers happiness, as a spiritual merit which is one of the ten forms of balas (sources of strength) to a bodhisattva. They hold the belief that charity leads to the accumulation of punya or a happier rebirth on earth or a long sojourn in heaven. Buddha-knowledge (enlightenment) transcends even the law of karma.\n\nThe principle of \"Sthiti Bandha\" (duration-quality bondage), according to Jainism, involves attachment of \"karmic matter\" to the soul through \"anubhava bandha\" or \"rasa bandha\" which refers to the determination of the fruits of actions of the soul that such an attachment produces at the time of attachment of \"karmic matter\" or through \"pradesha bandha\" that deals with the quantum of \"karmic matter\" drawn towards the soul as determined by the soul’s actions. The \"karmic matter\" produced due to good activities of the mind, body and speech is the pleasant \"punya\" ('virtuous') \"karmic matter\" and that produced due to evil activities is the unpleasant \"pāpa\" ('sinful') \"karmic matter\". These \"karmas\" have to exhaust themselves to produce their results. \n\nThe Nyāya School understands \"dharma\" and \"adharma\" to refer to \"punya\" and \"pāpa\", with \"punya\" relating to one’s own or others’ well-being and \"pāpa\" relating to harm done to others, or in terms of doing one’s duties and their violation; it connects \"dharma\" to well-being and duty.\n\nThe concept of Karma, with the idea of rebirth as the background, was effectively introduced into Indian thought by Yajnavalkya in the course of his discussion with Jāratkārva Ārtabhāga who wanted to know about what happens after death (Brihadaranyaka Upanishad III.ii.13), whether present actions matter in respect of the experience of the after-death state and how human efforts and \"karma\" are inter-related. The Vedic people were multi-religious and believed in the existence of heaven and hell and in the transmigration of souls. For them the performance of \"yajna\" was important, and no \"yajna\" was complete or fruitful without \"dakshina\" i.e. the fee to the priests, and \"dāna\" i.e. charity, both deemed meritorious acts or \"punya-karma\"; they accepted the philosophy of sin (\"pāpa\") and merit (\"punya\"). \n\"Punya\" is a very ancient Sanskrit word which appears in the Rig veda. For instance, in a prayer to Kapinjala Ivendro Devata, Rishi Gutsamada, while describing the qualities of an \"upadeshaka\" ('teacher') states:\nin which \"mantra\" the word, \"punya\", is used to mean - 'good' or 'auspicious' or 'happy'. Many other Vedic texts, such as Chandogya Upanishad (VIII.ii.6) – पुण्यजितो लोकः (in which phrase \"aja\" refers to the Brahmaloka), have used it as meaning 'agreeable' or 'happy'. Otherwise, in Sanskrit literature, this word is used to indicate 'advantageous', 'good', 'convenient', 'beneficent' or 'purifying'; Manusmṛti also uses it meaning the same; however, the opposite of \"punya\" is \"apunya\", which means that the word, \"punya\" cannot at all places be translated as 'merit' or 'meritorious', more so because the word \"pāpa\" is most often translated as 'sin'. \n\nAdi Shankara exclaims:-\n\nIn his commentary on this stanza, Śri Candraśekhara Bhāratī of Śringeri explains that \"punya\" is the outcome of doing prescribed works, and \"pāpa\", the prohibited. All works pertaining to the body, to the mind and to speech are \"karma\", the good and bad with reference to actions make for \"punya\" and \"pāpa\" respectively; all actions and their outcome relate to the mind or to the body with form possessing sense-organs. The infinite bliss that Shankara speaks of is the \"sukha\" not generated by connection with sense-objects and therefore, in its experience there is no grief, no superimposition and no imagination whatsoever. During the Vedic period speaking untruth was a sin, and false accusers were the real sinners; performance of \"yajna\" washed away all such sins, which means ritual acts were associated with morality. Untruth and impurity could be washed away by water or wiped away by Darbha grass. Along with the concept of Rta (righteousness) there was the more prominent concept of \"anrta\", the opposite of righteousness or untruth; terms for good and evil were developed and a wicked person was called \"pāpa\", where after from the term, \"sādhu\" denoting what was right, was the concept of \"punya\" developed. Yajnavalkya explains – \n\nIn his commentary, Shankara states that the 'doing good' referred to here is the prescribed conduct (scriptural injunctions and prohibitions), actions are not prescribed for acts, good or evil prompted by desire and the cause of identification and transmigration, do not require habitual performance.\n"}
{"id": "197740", "url": "https://en.wikipedia.org/wiki?curid=197740", "title": "Pyrrhic victory", "text": "Pyrrhic victory\n\nA Pyrrhic victory ( ) is a victory that inflicts such a devastating toll on the victor that it is tantamount to defeat. Someone who wins a Pyrrhic victory has also taken a heavy toll that negates any true sense of achievement. \n\n\"Pyrrhic victory\" is named after King Pyrrhus of Epirus, whose army suffered irreplaceable casualties in defeating the Romans at the Battle of Heraclea in 280 BC and the Battle of Asculum in 279 BC, during the Pyrrhic War. After the latter battle, Plutarch relates in a report by Dionysius:\n\nIn both Epirote victories, the Romans suffered greater casualties but they had a much larger pool of replacements, so the casualties had less impact on the Roman war effort than the losses of King Pyrrhus.\n\nThe report is often quoted as\nor \nIronically enough, it can never fairly be said that Pyrrhus of Epirus ever incurred such a \"victory\", having handily defeated the Romans in each of their engagements by a large margin, all the while suffering substantially fewer casualties (see, for example, the Battle of Heraclea). The term entered the English vernacular due to popular misconceptions of the magnitude of Pyrrhus's losses: beginning before the 1800s, Latin history teaching books said that Pyrrhus suffered losses in the tens of thousands.\n\nThis list comprises examples of battles that ended in a Pyrrhic victory. It is not intended to be complete but to illustrate the concept.\n\n\nThe term is used as an analogy in business, politics and sport to describe struggles that end up ruining the victor. Theologian Reinhold Niebuhr commented on the necessity of coercion in preserving the course of justice by warning,\n\nIn \"Beauharnais v. Illinois\", a 1952 U.S. Supreme Court decision involving a charge proscribing group libel, Associate Justice Black alluded to Pyrrhus in his dissent,\n\nA related expression is \"winning a battle but losing the war\". This describes a poor strategy that wins a lesser objective but overlooks and loses the larger objective.\n\nA \"hollow victory\" or \"empty victory\" is one in which the victor gains little or nothing. Examples include:\n"}
{"id": "23843989", "url": "https://en.wikipedia.org/wiki?curid=23843989", "title": "Recycling cooperative", "text": "Recycling cooperative\n\nA recycling cooperative is an industrial cooperative, co-owned and maintained by either workers or consumers, which specializes in the recycling of various materials. Such cooperatives are either non-profit or not-for-profit; a major theoretical benefit of mass co-ownership is that raw recycled materials can become increasingly and equally distributed among the membership population at a low cost, be it for reusage at home or for reusage in the manufacturing of newer goods or versions of goods to be sold to customers at cheaper prices than would be possible with freshly obtained raw materials. A subset is the business recycling cooperative, which, according to the Northeast Recycling Council, is a group of business in a particular region, which separate recyclable waste, usually produced by their own functions, for prearranged collection by a shared hauler.\n"}
{"id": "42611352", "url": "https://en.wikipedia.org/wiki?curid=42611352", "title": "Reproductive rights in Latin America", "text": "Reproductive rights in Latin America\n\nWhile feminist movements became prevalent in Europe and North America in the 1960s and 1970s, the women of Latin America were gathering to oppose dictatorships and civil wars. As democracy began to spread across the region, feminist movements gradually began to push for more reproductive rights.\n\nIn the 1990s, many of the groups that made up the women's movement began to evolve in order to adapt to a changing political climate. These groups focused on specific policy issues, such as abortion, and were not composed exclusively of civil society actors. During this same time period, anti-abortion activism was also beginning to gain momentum. The Vatican replaced hundreds of progressive clergy and summarily repressed discussions of reproductive issues. Groups continuing to fight for legal abortion across the region have faced a strong resistance from the Catholic church as well as the religious right in the United States. Although a majority of countries within the region are officially secular, the church continues to have an extensive influence within the region due to Latin America being the largest Catholic region in the world. The religious right in the United States holds substantial clout over the political right in its own country, which has resulted in the United States banning federal funding for international NGOs. Considerably damaging to groups in Latin America was Ronald Reagan's 1984 Global Gag Rule which prohibited international organizations receiving US federal funds from performing or promoting abortion as a method of family planning.\n\nLatin America is home to some of the few countries of the world with a complete ban on abortion, without an exception for saving maternal life.\n\nDuring the Cold War, reproductive restrictions were directed at controlling overpopulation through technocratic regulatory mechanisms and vertical population control campaigns. The United Nations International Conference on Population and Development of 1994 held in Cairo, Egypt established the first global agenda for sexual and reproductive health and rights. The agreement marked a paradigm shift away from a narrow approach based on delivery of services and numbers rather than well-being. It placed rights at the center of population and development and defined reproductive health as \"a state of complete, physical, mental and social well-being and not merely the absence of disease of infirmity, in all matters relating to the reproductive system and to its functions and processes.\" This broader approach to reproductive health moved the Cairo Agenda into political and economic debates over access and rights to knowledge, resources, and appropriate services.\n\nThus, women and health movements in civil society and their allies in the United Nations and national bureaucracies have undertaken strong campaigns to link public health, gender equality, and development policy. By understanding reproductive rights in the broader context of human rights, governments are able to create a standard of health that ensures development. Similarly, this broader understanding of reproductive health places a certain level of responsibility on the government in ensuring this aspect of health for its citizens.\n\nThis cross-cultural consensus focuses on the importance of one particular capability, that of bodily health. Recognizing the many areas reproductive health has influence over serves to exemplify its importance as well as gives some understanding as to what necessary improvements need to be made to a society.\n\nReproductive health also encompasses knowledge production and knowledge consumption. In order to obtain reproductive rights, quality information and services must be made available to all citizens of a society.\n\nThe 1994 International Conference on Population and Development defined reproductive health as noted above. It also defined strategies and goals for advancing such reproductive health and rights in Latin America through what is called the Cairo Programme of Action (CPA). The CPA has three quantitative targets: (1) Reducing overall mortality, which implies an increase in life expectancy, reducing specific mortalities (2) Universal access to education, especially for girls (3) Universal access to reproductive health services, including family planning. Adopted by the region at the conference, some improvements have been seen since the adoption of the CPA. Reproductive rights have become recognized in the constitutions of Bolivia, Ecuador and Venezuela. The Environmental Commission for Latin America and the Caribbean Ad Hoc Committee on Population and Development is responsible for official follow-up to the implementation of the CPA in Latin America as well as the Caribbean.\n\nThe Millennium Development Goals are a descriptive framework by which to monitor response to eight specific goals. They were announced in the Millennium Declaration in September 2000. Whether or not a country is on track to meeting these goals—in the case of Latin America—is tracked by the Economic Commission for Latin America and the Caribbean (ECLAC). One particular goal in regard to reproductive health, Goal 5, seeks to improve maternal health within the region. The first target of Goal 5 is to reduce the maternal mortality ratio by three quarters between 1990 and 2015. In order to assess the progress towards this goal, ECLAC monitors maternal mortality ratios and the proportion of births attended by skilled health personnel. The second target of Goal 5 is to achieve universal access to reproductive health by 2015. This target is assessed by viewing contraceptive prevalence rates, adolescent birth rates, antenatal care coverage and percentages of unmet need for family planning. In order to achieve these goals, many actions have been taken, including the growing institutionalization of deliveries and the increased number of personnel trained to provide care during childbirth and emergency obstetric care.\n\nAccording to the World Health Organization (WHO) in 2010, about 9,200 women are dying annually from pregnancy-related causes. These deaths have a variety of causes that can occur as a result of complications during and following pregnancy and childbirth. The World Health Organization estimates that around 80% of all maternal deaths are a result of severe bleeding, infections, high blood pressure during pregnancy and unsafe abortions. According to a report by the Guttmacher Institute, more than 20% of women who gave birth in 2008 did not make the recommended four antenatal visits and 13% did not deliver in a health facility.\n\nNone of the Latin American countries will reach the Millennium Development goal target specifically for maternal mortality, as well as it continues to be both a health and social challenge in Latin America. Research indicates that the numbers are disproportionately high within the indigenous and afro-descendant populations among the very poor. For indigenous populations as well as adolescents and young people, the rate of unmet family planning need also remains high. Latin America has the second highest fertility rates among adolescents and the highest unsafe abortion rates in the world.\n\nOverall, the maternal mortality rate in Latin America is relatively low compared to other regions with a rate of 80 deaths per 100,000 live births. However, if one were to break down the region's mortality rate by country, one could easily demonstrate that there exists a large disparity between affluent and poor countries. For example, in Haiti the rate was closer to 350 deaths per 100,000 live births. The disparity between wealthy and poor areas likely exists due to the differences in access to services and skilled professionals. Women in the highest income quintile have far easier access to such health services than women in the lowest income quintile. The same class-based disparity exists when analyzing the use of contraceptive methods.\n\nProtecting the health of adolescents is an important public health priority. Increased investment in adolescent reproductive health contributes to improving the overall status of women as well as the reduction in poverty among families. Adolescent health must be contextualized within reproductive health and thus public health. Latin American government as a whole did not recognize early pregnancy in adolescents to be an issue until 1984 during the International Conference on Population in Mexico City.\n\nIn Latin America, 38% of women become pregnant before the age of 20 and almost 20% of births are to teenage mothers. Each year there are estimated to be 1.2 million unintended pregnancies among adolescent women living in Latin America and the Caribbean. Although overall fertility rates have largely dropped within the region, adolescent maternity is following an opposite trend. The Gender Equality Observatory for Latin America and the Caribbean reports that as of 2011, in Nicaragua approximately 2 in 10 women between the ages of 15 and 19 is a mother. In places such as Chile, Mexico, Paraguay and Peru the percentage is close to 12% while in Belize, Venezuela, Colombia, Guatemala and El Salvador reach percentages close to 15%. Inequality is also present in the issue of adolescent maternity, with pregnancy rates being three to five times higher among poor adolescents. While an overall universal trend towards earlier average age of menstruation can be seen, the mean age of marriage has declined. This implies that adolescents who are coerced into marriage are unprotected in terms of reproductive rights for longer periods of time.\n\nAccording to the UN Population Fund, education and access to information and services young people need in order to make responsible decisions remains insufficient. The importance of education is exemplified by how girls in Latin America who have completed only up to primary education or less have a higher probability of adolescent pregnancy. Further, many young girls are dying because their bodies cannot support pregnancies. The same fund reports that the risk of complications during pregnancy and delivery for girls aged 15 to 19 is double the rate for women in their 20s, and five times as high for girls under 15. \nResearch reveals that there are several major barriers that young people face to accessing contraception, primarily with acquiring services. For example, facilities are frequently in areas inaccessible to young individuals. Due to a lack of information, adolescents often incorrectly use or do not use contraceptives at all. For the purpose of privacy from their communities and families, young persons often seek services from facilities not located directly in their own neighborhoods. \nThere are also legal barriers preventing youth's access. Many policies limit or prohibit confidential services for youths.\n\nThere is also a swath of data that is not collected by hospitals on abortions that are particularly \"clandestine\" / \"backstreet\". Studies have shown that in several Latin American countries, young single women are at a high risk for abortion which is not reflected by the amount of married, older women who were hospitalized for abortions.\n\nAside from a lack of information, young people who seek contraception are often denied by health workers acting out of their own moral convictions. It is clear that religious attitudes are very much present in society, which often deters young persons from seeking reproductive services and contraception.\n\nUse of modern contraceptives has increased to 62.5% (CITE: Population action) giving the region as a whole the highest contraceptive prevalence rate in the developing world. The increased uptake of sexual and reproductive health and family planning services has resulted in a marked drop in total fertility rates from approximately 4.6 children per woman in the 1970s to about 2.5 in 2013. \nIn Latin America, multiple court decisions have granted personhood to fertilized eggs. These court decisions have been responsible for the extreme restrictions on access to emergency contraception within the region. \nThe legal status of oral contraception in Latin America varies by country. In 2009 Honduras banned the free distribution and sale of emergency contraceptives That same year, the Constitutional Court of Peru ordered the Health Ministry to refrain from distributing emergency contraceptives to the public sector. In Costa Rica, where emergency contraceptives are not blatantly prohibited, the popular emergency contraceptive levonorgestrel is not registered as a product, which impedes access to the drug from within the public health system as well as the private market. \nAlthough the remaining countries in the region allow for the free distribution of emergency contraceptives, they do not have uniform regulations. In Chile, Colombia and Ecuador, the right to have access to emergency contraceptives is recognized. In Nicaragua and Bolivia, the protocols of their respective health ministries are essentially law. In Argentina and Brazil, the distribution of emergency contraceptives is not legally recognized except in protocols and informative guides.\n\nAbortion is a highly controversial aspect of reproductive rights. While every country in Latin America has differing laws and regulations regarding abortion, the general sentiment is that of disapproval. Abortions in Latin America have had a history of being unsafe and illegal (especially for poor women), with recent improvements in both of those areas. Most of these improvements can be attributed to modern contraception, emergency care, as well as education. Similarly, advocacy and national conflict has grown surrounding abortion rights in Latin America. The region has seen a steady increase of feminist abortion activists, despite religion making the issue taboo. Even when legislation has become more lenient (as has been the case recently with Mexico City and Chile), women often face institutional barriers to gaining access to abortions. When it comes to reporting data on abortions in Latin America, estimated abortion levels are often heterogeneous and highly variable due to legal frameworks and social stigmas.\n\nAccording to the World Health Organization, in 2008, approximately \"4.2 million abortions were conducted in Latin America and the Caribbean, almost three-fourths of them in South America. Virtually all these procedures were illegal and many were unsafe.\"\n\nIn 2011, the number of unsafe abortions in Latin America rose to 4.2 million annually. Unsafe abortions account for a large proportion of maternal deaths. For example, in Argentina unsafe abortions account for 31% of the maternal mortality rate.\n\nIn Latin America abortion is:\n\nOnly two countries within Latin America allow for legal abortion without restriction. However, these countries are home to less than 5% of women between the ages of 15-44. According to a report released by the Guttmacher Institute, 95% of abortions in Latin America are unsafe. Nearly one million women are hospitalized each year because of complications from unsafe abortion. Overall, Latin American rates of death related to illegal abortions rank among the highest in the world.\n\nStrict abortion laws are accompanied by strict punishments. In El Salvador, for example, a woman can be jailed for up to 40 years for aborting while in Mexico, she could be jailed for up to 50 years. These punishments do not take into consideration the cause of the pregnancy, due to the fact that many of the imprisoned women were raped or had involuntary abortions\n\nInternational legislations also have an effect on abortion rights in Latin America. When U.S. President Donald Trump reinstated the Global Gag Rule on January 23, 2017, he prohibited all U.S. federal money from funding international organizations such as NGOs that \"perform or actively promote abortion as a method of family planning\". Due to the fact that abortion regulations are already extremely strict in Latin America, this legislation disproportionately affects Latin American organizations that try to provide abortion services to women either legally, or illegally.\n\nIn 2012 a report presented to the Inter-American Commission on Human Rights (IACHR) found that access to information remains a significant roadblock to sexual and reproductive health, particularly in Latin America.(CITE HR BRIEF) The report noted that even when a state has a comprehensive legal framework guaranteeing access to information, in practice the individual's health is endangered by uninformed decisions made by individuals and policymakers based on inadequate information regarding sexual and reproductive health. In 2011, IACHR issued a report on access to information on reproductive health and found that the situation is compounded when women are poor, indigenous, of African descent, live in a rural area, or are a migrant.\n\nIn 2008, the region adopted \"Miniseria Declaration, 'Prevention through Education,'\" in response to a lack of comprehensive sexuality education. While there have been some setbacks and delays regarding implementation, there have also been key improvements. In 2013, the ministries of health and education of Guatemala reaffirmed their commitment to working together in order to ensure the goals of the Ministerial Declaration are the met. In addition, the government of Guatemala is implementing a comprehensive sexuality education program for young people in nine regions of the country. Actions aimed at promoted comprehensive sexual education can be seen in multiple areas of the region, demonstrating that leaders are indeed dedicated to making such improvements. Earlier in 2012, Costa Rica adopted a national sexuality program for the first time in history. The curriculum approaches human sexuality in a comprehensive way; it includes lessons on human rights, gender equality, power, interpersonal communication, respect for diversity and pleasure. Also making a critical first step that year was El Salvador with its General Youth Act, legislation which recognizes and guarantees the right of young persons to receive comprehensive sex education. Implementation will be an ongoing challenge, however, recognition is important step toward meeting the needs of youth.\n\nReligion in Latin America is characterized by the predominance of Roman Catholicism, although there is also increasing Protestant influence (especially in Central America and Brazil) as well as by the presence of other world religions. Catholicism was introduced in Latin America with the Spanish colonization of the Americas and continued through the independence movements of the Spanish-American colonies up to the present day. Critics of the restrictive abortion laws of Latin America argue that this situation is created by the strong influence of the Catholic church in the region. El Salvador and Nicaragua have drawn international attention for strong enforcement of their complete bans on abortion. In 2017, Chile relaxed its total ban, allowing abortion to be performed when the woman's life is in danger, when a fetus is unviable, or in cases of rape.\n\nWhile many of Latin America's reforms in regards to reproductive rights have happened internally, the broader international community plays an important role as well. The Center for Reproductive Rights, for example, has used international litigation as a way to reinforce national legislation surrounding reproductive rights. Legal policy plays an important role in establishing a standard of reproductive rights internationally as well as within Latin America itself. This implies that over time, reproductive rights will be integrated into a broader framework of human rights.\n\n"}
{"id": "12642693", "url": "https://en.wikipedia.org/wiki?curid=12642693", "title": "Scott Bullock", "text": "Scott Bullock\n\nScott G. Bullock is an American lawyer who focuses on property rights issues such as eminent domain and civil forfeiture. He is President and General Counsel at the Institute for Justice, a nonprofit libertarian public interest law firm. He represented Susette Kelo in \"Kelo v. City of New London\", an eminent domain case decided by the Supreme Court in 2005.\n\nBullock was born in Guantanamo Bay, Cuba, and grew up outside of Pittsburgh, Pennsylvania. He received his B.A. in economics and philosophy from Grove City College and his law degree from the University of Pittsburgh School of Law. Bullock joined the Institute for Justice at its founding in 1991.\n\nBullock was lead co-counsel in the 2005 Supreme Court case \"Kelo v. City of New London\". After the decision by the high court to allow the City of New London to seize the homes and businesses of current residences to make room for a \"90-acre office, hotel, and housing complex\", Bullock said that it was \"a sad day for the country and a sad day for the Constitution.\"\n\nBullock has advocated against government use of civil forfeiture. He has said that when the police pull drivers over for minor traffic infractions and seize their cash, they do not \"respect fundamental notions of due process.\" He represented Russ Caswell when the police tried to seize Caswell's motel in Tewksbury, Massachusetts after incidents of illegal drug activity on the premises. He called the practice of equitable sharing, in which state and federal law enforcement share the proceeds of seized assets, a violation of federalism. He has been involved in First Amendment and commercial speech cases. He is an advocate for parental rights. He has shared his views on constitutional issues in publications such as \"The New York Times\" and \"The Wall Street Journal\" as well as in broadcast media such as \"60 Minutes\", \"ABC Nightly News\", and National Public Radio.\n\n"}
{"id": "2212371", "url": "https://en.wikipedia.org/wiki?curid=2212371", "title": "Simon effect", "text": "Simon effect\n\nIn psychology, the Simon effect is the finding that reaction times are usually faster, and reactions are usually more accurate, when the stimulus occurs in the same relative location as the response, even if the stimulus location is irrelevant to the task. It is named for J. R. Simon who first published the effect in the late 1960s. Simon's original explanation for the effect was that there is \"an innate tendency to respond toward the source of stimulation\".\n\nAccording to the simple models of information processing that existed at the time, there are three stages of processing: stimulus identification, response selection, and response execution or the motor stage. The Simon Effect is generally thought to involve interference which occurs in the response-selection stage. This is similar to, yet distinct from, the interference that produces the better-known Stroop effect.\n\nIn Simon's original study, two lights (the stimulus) were placed on a rotating circular panel. This device would be rotated at varying degrees (away from the horizontal plane). Simon wished to see if an alteration of the spatial relationship, relative to the response keys, affected performance. Age was also a probable factor in reaction time. As predicted the reaction time of the groups increased based on the relative position of the light stimulus (age was not a factor). The reaction time increased by as much as 30%. (Simon & Wolf, 1963).\n\nHowever, what is usually seen as the first genuine demonstration of the effect that became known as the Simon effect is by Simon & Rudell (1967). Here, they had participants respond to the words \"left\" and \"right\" that were randomly presented to the left or right ear. Although the auditory location was completely irrelevant to the task, participants showed marked increases in reaction latency if the location of the stimulus was not the same as the required response (if, for example, they were to react left to a word that was presented in the right ear).\n\nA typical demonstration of the Simon effect involves placing a participant in front of a computer monitor and a panel with two buttons on it, which he or she may press. The participant is told that they should press the button on the right when they see something red appear on the screen, and the button on the left when they see something green. Participants are usually told to ignore the location of the stimulus and base their response on the task-relevant color.\n\nParticipants typically react faster to red lights that appear on the right hand side of the screen by pressing the button on the right of their panel (congruent trials). Reaction times are typically slower when the red stimulus appears on the left hand side of the screen and the participant must push the button on the right of their panel (incongruent trials). The same, but vice versa, is true for the green stimuli.\n\nThis happens despite the fact that the position of the stimulus on the screen relative to the physical position of the buttons on the panel is irrelevant to the task and not correlated with which response is correct. The task, after all, requires the subject to note only the colour of the object (i.e., red or green) by pushing the corresponding button, and not its position on the screen.\n\nAccording to Simon himself (1969), the location of the stimulus, although irrelevant to the task, directly influences response-selection due to an automatic tendency to 'react towards the source of the stimulation'. Although other accounts have been suggested (cf. Hommel, 1993), explanations for the Simon effect generally refer back to the interference that occurs in the response-selection stage of decision making. Neurologically there could be involvement of the dorsolateral prefrontal cortex, as well as the Anterior cingulate cortex, which is thought to be responsible for conflict monitoring. The Simon Effect shows that location information cannot be ignored and will affect decision making, even if the participant knows that the information is irrelevant.\n\nLogical argument for response selection:\n\nThe challenge in the Simon effect is said to occur during the response selection stage of judgment. This is due to two factors which eliminate the stimulus identification stage and the execution state. In the stimulus identification stage the participant only needs to be cognitively aware that a stimulus is present. An error would not occur at this stage unless he or she were visually impaired or had some sort of stimulus deficit. As well, an error or delay cannot occur during the execution state because an action has already been decided upon in the previous stage (the response selection stage) and no further decision making takes place (i.e. you cannot make a change to your response without going back to the second stage).\n\nA knowledge of the Simon effect is useful in the design of man-machine interfaces. Aircraft cockpits, for example, require a person to react quickly to a situation. If a pilot is flying a plane and there is a problem with the left engine, an aircraft with a good man-machine interface design (which most have) would position the indicator light for the left engine to the left of the indicator light for the right engine. This interface would display information in a way that matches the types of responses that people should make. If it were the other way around, the pilot might be more likely to respond incorrectly and adjust the wrong engine.\n\n\n"}
{"id": "30413471", "url": "https://en.wikipedia.org/wiki?curid=30413471", "title": "Singapore Kindness Movement", "text": "Singapore Kindness Movement\n\nThe Singapore Kindness Movement is a non-profit organization that executes public education programs aimed at cultivating kindness and graciousness in Singaporean society. It was officially launched in 1997. The movement serves as the successor to the Singapore Courtesy Council that oversaw the National Courtesy Campaign (Singapore) from the 1980s through the 1990s.\n\nThe Singapore Kindness Movement (SKM) was initiated in response to Prime Minister Goh Chok Tong’s call to Singaporeans to develop into a more caring and gracious society in the new century.\n\nIn his 1996 New Year’s address, stated \"We have become a developed economy because we put our minds to it and strive hard to reach our goals. Let us now complement our economic achievements with social, cultural, and spiritual development. Then by the 21st century, Singapore will be a truly successful, mature country, with a developed economy and a gracious society.\"\n\nPM Goh announced the SKM pilot project in July 1996, when he launched the Singapore Courtesy Campaign.Some 2,000 students from the uniformed groups in 20 secondary schools participated in the pilot project.\n\nThe Movement was launched in January 1997, to over 80,000 secondary school students. SKM officially registered as a non-profit society on 31 January 1997. In March 2001, the National Courtesy Campaign was subsumed by the Movement.\n\nSingapore Kindness Movement held the secretariat of the World Kindness Movement. from 2003-2012.\n\nThe mission statement of the SKM is to inspire graciousness through spontaneous acts of kindness, making life more pleasant for everyone.\n\nIts main objectives are:\nTo encourage all Singaporeans to be more kind and considerate.\nTo enhance public awareness of acts of kindness.\nTo influence and raise the standards of social behaviour in our society.\n\nThe SKM organisational structure consists of two main parts: The SKM Council (SKMC) and the SKM Secretariat. The SKM Council comprises members from the private and 19 public sectors. In March 2001, the Singapore Courtesy Council integrated with the SKMC.\n\nThe Movement is supported by the Ministry of Culture, Community and Youth and funded by a government grant. SKM also secures funds through its membership subscriptions and sponsorships.\n\nThe patron of the Movement is Prime Minister Lee Hsien Loong and the current Chairman is Koh Poh Tiong.\n\nThe two strokes and ovals of the Singapore Kindness Movement logo depicts two people—one who does an act of kindness and the other who receives it. The freehand strokes combine to form a heart. Red symbolises love for your fellow man and green represents caring for the environment, tolerance, creativity, and consideration.\n\nSinga the Lion had been the official mascot of the Singapore Kindness Movement until May, 2013. On 15 May 2013, Singa the Lion was retired from the campaign through an open \"resignation letter\" posted on the movement's website.\n"}
{"id": "29089", "url": "https://en.wikipedia.org/wiki?curid=29089", "title": "Snuff film", "text": "Snuff film\n\nA snuff film, or snuff movie, is \"a movie in a purported genre of movies in which a person is actually murdered or commits suicide\". It may or may not be made for financial gain, but is supposedly \"circulated amongst a jaded few for the purpose of entertainment\". Some filmed records of executions and murders exist, but in those cases, the death was not specifically staged for financial gain or entertainment.\n\nThe first known use of the term \"snuff movie\" is in a 1971 book by Ed Sanders, \"The Family: The Story of Charles Manson's Dune Buggy Attack Battalion\". He alleges that The Manson Family was involved in making such a film in California to record their murders.\n\nThe noun \"snuff\" originally meant the part of a candle wick that has already burned; the verb \"snuff\" meant to cut this off, and by extension to extinguish or kill. The word has been used in this sense in English slang for hundreds of years. It was defined in 1874 as a \"term very common among the lower orders of London, meaning to die from disease or accident\".\n\nAccording to Geoffrey O'Brien, \"whether or not commercially distributed 'snuff' movies actually exist, the possibility of such movies is implicit in the stock B-movie motif of the mad artist killing his models, as in \"A Bucket of Blood\" [1959], \"Color Me Blood Red\" [1965], or \"Decoy for Terror\" [1967]\" also known as \"Playgirl Killer\". The concept of \"snuff films\" being made for profit became more widely known with the commercial film \"Snuff\" (1976). This low-budget exploitation horror film, originally titled \"Slaughter\", was directed by Michael and Roberta Findlay. In an interview decades later, Roberta Findlay said the film's distributor Allan Shackleton had read about snuff films being imported from South America and retitled \"Slaughter\" to \"Snuff\", to exploit the idea; he also added a new ending that depicted an actress being murdered on a film set. The promotion of \"Snuff\" on its second release suggested it featured the murder of an actress: \"The film that could only be made in South America... where life is CHEAP\", but that was false advertising. Shackleton put out false newspaper clippings that reported a citizens group's crusading against the film and hired people to act as protesters to picket screenings.\n\nThe first two films in the Japanese \"Guinea Pig\" series are designed to look like snuff films; the video is grainy and unsteady, as if recorded by amateurs. The sixth film in the series, \"Mermaid in a Manhole\", allegedly served as an inspiration for Japanese serial killer Tsutomu Miyazaki, who murdered several preschool girls in the late 1980s.\n\nIn 1991, actor Charlie Sheen became convinced that \"Flower of Flesh and Blood\" (1985), the second film in the series, depicted an actual homicide and contacted the FBI. The Bureau initiated an investigation but closed it after the series' producers released a \"making of\" film demonstrating the special effects used to simulate the murders.\n\nThe Italian director Ruggero Deodato was charged after rumors that the depictions of the killing of the main actors in his film \"Cannibal Holocaust\" (1980) were real. He was able to clear himself of the charges after the actors made an appearance in court.\n\nOther than graphic gore, the film contains several scenes of sexual violence and the genuine deaths of six animals onscreen and one off screen, issues which find \"Cannibal Holocaust\" in the midst of controversy to this day. It has also been claimed that \"Cannibal Holocaust\" is banned in over 50 countries, although this has never been verified. In 2006, \"Entertainment Weekly\" magazine named \"Cannibal Holocaust\" as the 20th most controversial film of all-time.\n\n\nNotes\nFurther reading\n\n"}
{"id": "28297", "url": "https://en.wikipedia.org/wiki?curid=28297", "title": "Soul", "text": "Soul\n\nThe soul, in many religious, philosophical, and mythological traditions, is the incorporeal essence of a living being. Soul or psyche (Ancient Greek: ψυχή \"psūkhḗ\", of ψύχειν \"psū́khein\", \"to breathe\") are the mental abilities of a living being: reason, character, feeling, consciousness, memory, perception, thinking, etc. Depending on the philosophical system, a soul can either be mortal or immortal. In Judeo-Christianity, only human beings have immortal souls (although immortality is disputed within Judaism and may have been influenced by Plato). For example, the Catholic theologian Thomas Aquinas attributed \"soul\" (\"anima\") to all organisms but argued that only human souls are immortal.\n\nOther religions (most notably Hinduism and Jainism) hold that all living things from the smallest bacterium to the largest of mammals are the souls themselves (Atman, jiva) and have their physical representative (the body) in the world. Jain philosophy is the oldest world philosophy that separates body (matter) from the soul (consciousness) completely. The actual self is the soul, while the body is only a mechanism to experience the karma of that life i.e if we see a tiger then there is a self conscious identity residing in it (the soul), and a physical representative (the whole body of tiger which is observable) in the world. Some teach that even non-biological entities (such as rivers and mountains) possess souls. This belief is called animism. Greek philosophers, such as Socrates, Plato, and Aristotle, understood that the soul (ψυχή \"psūchê\") must have a logical faculty, the exercise of which was the most divine of human actions. At his defense trial, Socrates even summarized his teaching as nothing other than an exhortation for his fellow Athenians to excel in matters of the psyche since all bodily goods are dependent on such excellence (\"Apology\" 30a–b).\n\nThe current consensus of modern science is that there is no evidence to support the existence of the soul when traditionally defined as the spiritual breath of the body. In metaphysics, the concept of \"Soul\" may be equated with that of \"Mind\" in order to refer to the consciousness and intellect of the individual.\n\nThe Modern English word \"soul\", derived from Old English \"sáwol, sáwel\", was first attested in the 8th century poem \"Beowulf\" v. 2820 and in the Vespasian Psalter 77.50 . It is cognate with other German and Baltic terms for the same idea, including Gothic \"saiwala\", Old High German \"sêula, sêla\", Old Saxon \"sêola\", Old Low Franconian \"sêla, sîla\", Old Norse \"sála\" and Lithuanian \"siela\". Deeper etymology of the Germanic word is unclear.\n\nThe original concept behind the Germanic root is thought to mean “\"coming from or belonging to the sea\" (or \"lake\")”, because of the Germanic and pre-Celtic belief in souls emerging from and returning to sacred lakes, Old Saxon \"sêola\" (soul) compared to Old Saxon \"sêo\" (sea).\n\nThe Koine Greek Septuagint uses (\"psyche\") to translate Hebrew (\"nephesh\"), meaning \"life, vital breath\", and specifically refers to a mortal, physical life, but in English it is variously translated as \"soul, self, life, creature, person, appetite, mind, living being, desire, emotion, passion\"; an example can be found in :\n\nThe Koine Greek word (\"psychē\"), \"life, spirit, consciousness\", is derived from a verb meaning \"to cool, to blow\", and hence refers to the breath, as opposed to (\"soma\"), meaning \"body\". \"Psychē\" occurs juxtaposed to , as seen in :\n\nPaul the Apostle used ψυχή (\"psychē\") and (\"pneuma\") specifically to distinguish between the Jewish notions of (\"nephesh\") and \"ruah\" (spirit) (also in the Septuagint, e.g. = = \"\" = \"the Spirit of God\").\n\nIn the ancient Egyptian religion, an individual was believed to be made up of various elements, some physical and some spiritual. Similar ideas are found in ancient Assyrian and Babylonian religion. Kuttamuwa, an 8th-century BC royal official from Sam'al, ordered an inscribed stele erected upon his death. The inscription requested that his mourners commemorate his life and his afterlife with feasts \"for my soul that is in this stele\". It is one of the earliest references to a soul as a separate entity from the body. The basalt stele is tall and wide. It was uncovered in the third season of excavations by the Neubauer Expedition of the Oriental Institute in Chicago, Illinois.\n\nThe Bahá'í Faith affirms that \"the soul is a sign of God, a heavenly gem whose reality the most learned of men hath failed to grasp, and whose mystery no mind, however acute, can ever hope to unravel\". Bahá'u'lláh stated that the soul not only continues to live after the physical death of the human body, but is, in fact, immortal. Heaven can be seen partly as the soul's state of nearness to God; and hell as a state of remoteness from God. Each state follows as a natural consequence of individual efforts, or the lack thereof, to develop spiritually. Bahá'u'lláh taught that individuals have no existence prior to their life here on earth and the soul's evolution is always towards God and away from the material world.\n\nBuddhism teaches that all things are in a constant state of flux: all is changing, and no permanent state exists by itself. This applies to human beings as much as to anything else in the cosmos. Thus, a human being has no permanent self. According to this doctrine of \"anatta\" (Pāli; Sanskrit: \"anātman\") – \"no-self\" or \"no soul\" – the words \"I\" or \"me\" do not refer to any fixed thing. They are simply convenient terms that allow us to refer to an ever-changing entity.\n\nThe \"anatta\" doctrine is not a kind of materialism. Buddhism does not deny the existence of \"immaterial\" entities, and it (at least traditionally) distinguishes bodily states from mental states. Thus, the conventional translation of \"anatta\" as \"no-soul\" can be confusing. If the word \"soul\" simply refers to an incorporeal component in living things that can continue after death, then Buddhism does not deny the existence of the soul. Instead, Buddhism denies the existence of a permanent entity that remains constant behind the changing corporeal and incorporeal components of a living being. Just as the body changes from moment to moment, so thoughts come and go, and there is no permanent state underlying the mind that experiences these thoughts, as in Cartesianism. Conscious mental states simply arise and perish with no \"thinker\" behind them. When the body dies, Buddhists believe the incorporeal mental processes continue and are reborn in a new body. Because the mental processes are constantly changing, the being that is reborn is neither entirely different from, nor exactly the same as, the being that died. However, the new being is \"continuous\" with the being that died – in the same way that the \"you\" of this moment is continuous with the \"you\" of a moment before, despite the fact that you are constantly changing.\n\nBuddhist teaching holds that a notion of a permanent, abiding self is a delusion that is one of the causes of human conflict on the emotional, social, and political levels. They add that an understanding of \"anatta\" provides an accurate description of the human condition, and that this understanding allows us to pacify our mundane desires.\n\nVarious schools of Buddhism have differing ideas about what continues after death. The Yogacara school in Mahayana Buddhism said there are Store consciousness which continue to exist after death. In some schools, particularly Tibetan Buddhism, the view is that there are three minds: \"very subtle mind\", which does not disintegrate in death; \"subtle mind\", which disintegrates in death and which is \"dreaming mind\" or \"unconscious mind\"; and \"gross mind\", which does not exist when one is \"sleeping\". Therefore, \"gross mind\" is less permanent than subtle mind, which does not exist in death. \"Very subtle mind\", however, does continue, and when it \"catches on\", or coincides with phenomena, again, a new \"subtle mind\" emerges, with its own personality/assumptions/habits, and \"that\" entity experiences karma in the current continuum.\n\nPlants were said to be non-sentient (無情), but Buddhist monks are required to not cut or burn trees, because some sentient beings rely on them. Some Mahayana monks said non-sentient beings such as plants and stones have Buddha-nature.\n\nCertain modern Buddhists, particularly in Western countries, reject—or at least take an agnostic stance toward—the concept of rebirth or reincarnation. Stephen Batchelor discusses this in his book \"Buddhism Without Beliefs\". Others point to research that has been conducted at the University of Virginia as proof that some people are reborn.\n\nMost Christians understand the soul as an ontological reality distinct from, yet integrally connected with, the body. Its characteristics are described in moral, spiritual, and philosophical terms. Richard Swinburne, a Christian philosopher of religion at Oxford University, wrote that \"it is a frequent criticism of substance dualism that dualists cannot say what souls are. Souls are immaterial subjects of mental properties. They have sensations and thoughts, desires and beliefs, and perform intentional actions. Souls are essential parts of human beings\". According to a common Christian eschatology, when people die, their souls will be judged by God and determined to go to Heaven or to Hell. Though all branches of Christianity – Catholics, Eastern Orthodox, Oriental Orthodox, Church of the East, Evangelical, and mainline Protestants – teach that Jesus Christ plays a decisive role in the Christian salvation process, the specifics of that role and the part played by individual persons or ecclesiastical rituals and relationships, is a matter of wide diversity in official church teaching, theological speculation and popular practice. Some Christians believe that if one has not repented of one's sins and has not trusted in Jesus Christ as Lord and Savior, he/she will go to Hell and suffer eternal damnation or eternal separation from God. Some hold a belief that babies (including the unborn) and those with cognitive or mental impairments who have died will be received into Heaven on the basis of God's grace through the sacrifice of Jesus.\n\nOther Christians understand the soul as the life, and believe that the dead are sleeping (Christian conditionalism). This belief is traditionally accompanied by the belief that the unrighteous soul will cease to exist instead of suffering eternally (annihilationism). Believers will inherit eternal life either in Heaven, or in a Kingdom of God on earth, and enjoy eternal fellowship with God.\n\nThere are also beliefs in universal salvation.\nAugustine, one of western Christianity's most influential early Christian thinkers, described the soul as \"a special substance, endowed with reason, adapted to rule the body\". Some Christians espouse a trichotomic view of humans, which characterizes humans as consisting of a body (\"soma\"), soul (\"psyche\"), and spirit (\"pneuma\"). However, the majority of modern Bible scholars point out how spirit and soul are used interchangeably in many biblical passages, and so hold to dichotomy: the view that each of us is body and soul. Paul said that the \"body wars against\" the soul, \"For the word of God is living and active and sharper than any two-edged sword, and piercing as far as the division of soul and spirit\" (Heb 4:12 NASB), and that \"I buffet my body\", to keep it under control.\nTrichotomy was changed to dichotomy as tenet of Christian faith at the Council of Constantinople in 869 regarded as the 8th Ecumenical Council by Roman Catholics.\n\nThe 'origin of the soul' has provided a vexing question in Christianity. The major theories put forward include soul creationism, traducianism, and pre-existence. According to creationism, each individual soul is created directly by God, either at the moment of conception or some later time. According to traducianism, the soul comes from the parents by natural generation. According to the preexistence theory, the soul exists before the moment of conception. There have been differing thoughts regarding whether human embryos have souls from conception, or there is a point between conception and birth where the fetus acquires a soul, consciousness, and/or personhood. Stances in this question might more or less influence judgements on the morality of abortion.\n\nThe present Catechism of the Catholic Church defines the soul as \"the innermost aspect of humans, that which is of greatest value in them, that by which they are in God's image described as 'soul' signifies the \"spiritual principle\" in man\". All souls living and dead will be judged by Jesus Christ when he comes back to earth. The Catholic Church teaches that the existence of each individual soul is dependent wholly upon God: \"The doctrine of the faith affirms that the spiritual and immortal soul is created immediately by God.\"\n\nProtestants generally believe in the soul's existence, but fall into two major camps about what this means in terms of an afterlife. Some, following Calvin, believe in the immortality of the soul and conscious existence after death, while others, following Luther, believe in the mortality of the soul and unconscious \"sleep\" until the resurrection of the dead. Various new religious movements derived from Adventism—including Christadelphians, Seventh-day Adventists and Jehovah's Witnesses—similarly believe that the dead do not possess a soul separate from the body and are unconscious until the resurrection.\n\nThe Church of Jesus Christ of Latter-day Saints teaches that the spirit and body together constitute the Soul of Man (Mankind). \"The spirit and the body are the soul of man.\" Latter-day Saints believe that the soul is the union of a pre-existing, God-made spirit and a temporal body, which is formed by physical conception on earth. After death, the spirit continues to live and progress in the Spirit world until the resurrection, when it is reunited with the body that once housed it. This reuniting of body and spirit results in a perfect soul that is immortal and eternal and capable of receiving a fulness of joy. Latter-day Saint cosmology also describes \"intelligences\" as the essence of consciousness or agency. These are co-eternal with God, and animate the spirits. The union of a newly created spirit body with an eternally-existing intelligence constitutes a \"spirit birth\" and justifies God's title \"Father of our spirits\".\n\n\"Ātman\" is a Sanskrit word that means inner self or soul. In Hindu philosophy, especially in the Vedanta school of Hinduism, Ātman is the first principle, the \"true\" self of an individual beyond identification with phenomena, the essence of an individual. In order to attain liberation (moksha), a human being must acquire self-knowledge (atma jnana), which is to realize that one's true self (Ātman) is identical with the transcendent self Brahman.\n\nThe six orthodox schools of Hinduism believe that there is Ātman (self, essence) in every being, a major point of difference with Buddhism, which does not believe that there is either soul or self.\n\nIn Hinduism and Jainism, a \"jiva\" (, , alternative spelling \"jiwa\"; , , alternative spelling \"jeev\") is a living being, or any entity imbued with a life force.\n\nIn Jainism, \"jiva\" is the immortal essence or soul of a living organism (human, animal, fish or plant etc.) which survives physical death. The concept of \"Ajiva\" in Jainism means \"not soul\", and represents matter (including body), time, space, non-motion and motion. In Jainism, a \"Jiva\" is either \"samsari\" (mundane, caught in cycle of rebirths) or \"mukta\" (liberated).\n\nThe concept of \"jiva\" in Jainism is similar to \"atman\" in Hinduism. However, some Hindu traditions differentiate between the two concepts, with \"jiva\" considered as individual self, while atman as that which is universal unchanging self that is present in all living beings and everything else as the metaphysical Brahman. The latter is sometimes referred to as \"jiva-atman\" (a soul in a living body).\nAccording to Brahma Kumaris, the soul is an eternal point of light.\n\nThe Quran, the holy book of Islam, distinguishes between the immortal \"rūḥ\" (spirit or \"soul\") and the mortal \"nafs\" (psyche). The immortal rūḥ \"drives\" the mortal nafs, which comprises temporal desires and perceptions necessary for living.\n\nOne of the passages in the Quran that mention \"rûh\" occur in chapters 17 (\"The Night Journey\") and 39 (\"The Throngs\"):\nIn Jainism, every living being, from plant or bacterium to human, has a soul and the concept forms the very basis of Jainism. According to Jainism, there is no beginning or end to the existence of soul. It is eternal in nature and changes its form until it attains liberation.\n\nThe soul \"(Jīva)\" is basically categorized in one of two ways based on its present state.\n\nUntil the time the soul is liberated from the \"saṃsāra\" (cycle of repeated birth and death), it gets attached to one of these bodies based on the karma (actions) of the individual soul. Irrespective of which state the soul is in, it has got the same attributes and qualities. The difference between the liberated and non-liberated souls is that the qualities and attributes are manifested completely in case of \"siddha\" (liberated soul) as they have overcome all the karmic bondages whereas in case of non-liberated souls they are partially exhibited.\n\nConcerning the Jain view of the soul, Virchand Gandhi said\n\nThe Hebrew terms \"nefesh\" (literally \"living being\"), \"ruach\" (literally \"wind\"), \"neshamah\" (literally \"breath\"), \"chayah\" (literally \"life\") and \"yechidah\" (literally \"singularity\") are used to describe the soul or spirit.\n\nIn Judaism the soul was believed to be given by God to Adam as mentioned in Genesis, \n\nJudaism relates the quality of one's soul to one's performance of the commandments (\"mitzvot)\" and reaching higher levels of understanding, and thus closeness to God. A person with such closeness is called a \"tzadik\". Therefore, Judaism embraces the commemoration of the day of one's death, \"nahala\"/\"Yahrtzeit\" and not the birthday as a festivity of remembrance, for only toward the end of life's struggles, tests and challenges could human souls be judged and credited for righteousness. Judaism places great importance on the study of the souls.\n\nKabbalah and other mystic traditions go into greater detail into the nature of the soul. Kabbalah separates the soul into five elements, corresponding to the five worlds:\n\n\nKabbalah also proposed a concept of reincarnation, the \"gilgul\". (See also \"nefesh habehamit\" the \"animal soul\".)\n\nThe Scientology view is that a person does not have a soul, it is a soul. A person is immortal, and may be reincarnated if they wish. The Scientology term for the soul is \"thetan\", derived from the Greek word \"theta\", symbolizing thought. Scientology counselling (called auditing) addresses the soul to improve abilities, both worldly and spiritual.\n\nAccording to Nadya Yuguseva, a shaman from the Altai, \"A woman has 40 souls; men have just one\".\n\nSikhism considers soul (\"atma\") to be part of God (Waheguru). Various hymns are cited from the holy book Guru Granth Sahib (SGGS) that suggests this belief. \"God is in the Soul and the Soul is in the God.\" The same concept is repeated at various pages of the SGGS. For example: \"The soul is divine; divine is the soul. Worship Him with love.\" and \"The soul is the Lord, and the Lord is the soul; contemplating the Shabad, the Lord is found.\"\n\nThe \"atma\" or soul according to Sikhism is an entity or \"spiritual spark\" or \"light\" in our body because of which the body can sustain life. On the departure of this entity from the body, the body becomes lifeless – No amount of manipulations to the body can make the person make any physical actions. The soul is the ‘driver’ in the body. It is the \"roohu\" or spirit or \"atma\", the presence of which makes the physical body alive.\n\nMany religious and philosophical traditions support the view that the soul is the ethereal substance – a spirit; a non material spark – particular to a unique living being. Such traditions often consider the soul both immortal and innately aware of its immortal nature, as well as the true basis for sentience in each living being. The concept of the soul has strong links with notions of an afterlife, but opinions may vary wildly even within a given religion as to what happens to the soul after death. Many within these religions and philosophies see the soul as immaterial, while others consider it possibly material.\n\nAccording to Chinese traditions, every person has two types of soul called hun and po (魂 and 魄), which are respectively yang and yin. Taoism believes in ten souls, \"sanhunqipo\" () \"three \"hun\" and seven \"po\"\". The pò is linked to the dead body and the grave, whereas the hún is linked to the ancestral tablet. A living being that loses any of them is said to have mental illness or unconsciousness, while a dead soul may reincarnate to a disability, lower desire realms, or may even be unable to reincarnate.\n\nIn theological reference to the soul, the terms \"life\" and \"death\" are viewed as emphatically more definitive than the common concepts of \"biological life\" and \"biological death\". Because the soul is said to be transcendent of the \"material existence,\" and is said to have (potentially) eternal life, the death of the soul is likewise said to be an \"eternal death\". Thus, in the concept of divine judgment, God is commonly said to have options with regard to the dispensation of souls, ranging from Heaven (i.e., angels) to hell (i.e., demons), with various concepts in between. Typically both Heaven and hell are said to be eternal, or at least far beyond a typical human concept of lifespan and time.\n\nAccording to Louis Ginzberg, soul of Adam is the image of God. Every soul of human also escapes from the body every night, rises up to heaven, and fetches new life thence for the body of man.\n\nIn Brahma Kumaris, human souls are believed to be incorporeal and eternal. God is considered to be the Supreme Soul, with maximum degrees of spiritual qualities, such as peace, love and purity.\n\nIn Helena Blavatsky's Theosophy, the soul is the field of our psychological activity (thinking, emotions, memory, desires, will, and so on) as well as of the so-called paranormal or psychic phenomena (extrasensory perception, out-of-body experiences, etc.). However, the soul is not the highest, but a middle dimension of human beings. Higher than the soul is the spirit, which is considered to be the real self; the source of everything we call \"good\"—happiness, wisdom, love, compassion, harmony, peace, etc. While the spirit is eternal and incorruptible, the soul is not. The soul acts as a link between the material body and the spiritual self, and therefore shares some characteristics of both. The soul can be attracted either towards the spiritual or towards the material realm, being thus the \"battlefield\" of good and evil. It is only when the soul is attracted towards the spiritual and merges with the Self that it becomes eternal and divine.\n\nRudolf Steiner differentiated three stages of soul development, which interpenetrate one another in consciousness:\n\nIn Surat Shabda Yoga, the soul is considered to be an exact replica and spark of the Divine. The purpose of Surat Shabd Yoga is to realize one's True Self as soul (Self-Realisation), True Essence (Spirit-Realisation) and True Divinity (God-Realisation) while living in the physical body.\n\nSimilarly, the spiritual teacher Meher Baba held that \"Atma, or the soul, is in reality identical with Paramatma the Oversoul — which is one, infinite, and eternal...[and] [t]he sole purpose of creation is for the soul to enjoy the infinite state of the Oversoul consciously.\"\n\nEckankar, founded by Paul Twitchell in 1965, defines Soul as the true self; the inner, most sacred part of each person.\n\nThe ancient Greeks used the word \"ensouled\" to represent the concept of being \"alive\", indicating that the earliest surviving western philosophical view believed that the soul was that which gave the body life. The soul was considered the incorporeal or spiritual \"breath\" that animates (from the Latin, \"anima\", cf. \"animal\") the living organism.\n\nFrancis M. Cornford quotes Pindar by saying that the soul sleeps while the limbs are active, but when one is sleeping, the soul is active and reveals \"an award of joy or sorrow drawing near\" in dreams.\n\nErwin Rohde writes that an early pre-Pythagorean belief presented the soul as lifeless when it departed the body, and that it retired into Hades with no hope of returning to a body.\n\nDrawing on the words of his teacher Socrates, Plato considered the psyche to be the essence of a person, being that which decides how we behave. He considered this essence to be an incorporeal, eternal occupant of our being. Plato says that even after death, the soul exists and is able to think. He believed that as bodies die, the soul is continually reborn in subsequent bodies. However, Aristotle believed that only one part of the soul was immortal namely the intellect (\"logos\"). The Platonic soul consists of three parts:\n\nThe parts are located in different regions of the body:\n\nPlato also compares the three parts of the soul or psyche to a societal caste system. According to Plato's theory, the three-part soul is essentially the same thing as a state's class system because, to function well, each part must contribute so that the whole functions well. Logos keeps the other functions of the soul regulated.\n\nAristotle (384 BCE – 322 BCE) defined the soul, or \"Psūchê\" (ψυχή), as the \"first actuality\" of a naturally organized body, and argued against its separate existence from the physical body. In Aristotle's view, the primary activity, or full actualization, of a living thing constitutes its soul. For example, the full actualization of an eye, as an independent organism, is to see (its purpose or final cause). Another example is that the full actualization of a human being would be living a fully functional human life in accordance with reason (which he considered to be a faculty unique to humanity). For Aristotle, the soul is the organization of the form and matter of a natural being which allows it to strive for its full actualization. This organization between form and matter is necessary for any activity, or functionality, to be possible in a natural being. Using an artifact (non-natural being) as an example, a house is a building for human habituation, but for a house to be actualized requires the material (wood, nails, bricks, etc.) necessary for its actuality (i.e. being a fully functional house). However, this does not imply that a house has a soul. In regards to artifacts, the source of motion that is required for their full actualization is outside of themselves (for example, a builder builds a house). In natural beings, this source of motion is contained within the being itself. Aristotle elaborates on this point when he addresses the faculties of the soul.\n\nThe various faculties of the soul, such as nutrition, movement (peculiar to animals), reason (peculiar to humans), sensation (special, common, and incidental) and so forth, when exercised, constitute the \"second\" actuality, or fulfillment, of the capacity to be alive. For example, someone who falls asleep, as opposed to someone who falls dead, can wake up and live their life, while the latter can no longer do so.\n\nAristotle identified three hierarchical levels of natural beings: plants, animals, and people, having three different degrees of soul: \"Bios\" (life), \"Zoë\" (animate life), and \"Psuchë\" (self-conscious life). For these groups, he identified three corresponding levels of soul, or biological activity: the nutritive activity of growth, sustenance and reproduction which all life shares (\"Bios\"); the self-willed motive activity and sensory faculties, which only animals and people have in common (\"Zoë\"); and finally \"reason\", of which people alone are capable (\"Pseuchë\").\n\nAristotle's discussion of the soul is in his work, \"De Anima\" (\"On the Soul\"). Although mostly seen as opposing Plato in regard to the immortality of the soul, a controversy can be found in relation to the fifth chapter of the third book: In this text both interpretations can be argued for, soul as a whole can be deemed mortal, and a part called \"active intellect\" or \"active mind\" is immortal and eternal. Advocates exist for both sides of the controversy, but it has been understood that there will be permanent disagreement about its final conclusions, as no other Aristotelian text contains this specific point, and this part of \"De Anima\" is obscure. Further, Aristotle states that the soul helps humans find the truth and understanding the true purpose or role of the soul is extremely difficult.\n\nFollowing Aristotle, Avicenna (Ibn Sina) and Ibn al-Nafis, a Persian philosopher, further elaborated upon the Aristotelian understanding of the soul and developed their own theories on the soul. They both made a distinction between the soul and the spirit, and the Avicennian doctrine on the nature of the soul was influential among the Scholastics. Some of Avicenna's views on the soul include the idea that the immortality of the soul is a consequence of its nature, and not a purpose for it to fulfill. In his theory of \"The Ten Intellects\", he viewed the human soul as the tenth and final intellect.\n\nWhile he was imprisoned, Avicenna wrote his famous \"Floating Man\" thought experiment to demonstrate human self-awareness and the substantial nature of the soul. He told his readers to imagine themselves suspended in the air, isolated from all sensations, which includes no sensory contact with even their own bodies. He argues that in this scenario one would still have self-consciousness. He thus concludes that the idea of the self is not logically dependent on any physical thing, and that the soul should not be seen in relative terms, but as a primary given, a substance. This argument was later refined and simplified by René Descartes in epistemic terms, when he stated: \"I can abstract from the supposition of all external things, but not from the supposition of my own consciousness.\"\n\nAvicenna generally supported Aristotle's idea of the soul originating from the heart, whereas Ibn al-Nafis rejected this idea and instead argued that the soul \"is related to the entirety and not to one or a few organs\". He further criticized Aristotle's idea whereby every unique soul requires the existence of a unique source, in this case the heart. al-Nafis concluded that \"the soul is related primarily neither to the spirit nor to any organ, but rather to the entire matter whose temperament is prepared to receive that soul,\" and he defined the soul as nothing other than \"what a human indicates by saying \"I\".\n\nFollowing Aristotle (whom he referred to as \"the Philosopher\") and Avicenna, Thomas Aquinas (1225–74) understood the soul to be the first actuality of the living body. Consequent to this, he distinguished three orders of life: plants, which feed and grow; animals, which add sensation to the operations of plants; and humans, which add intellect to the operations of animals.\n\nConcerning the human soul, his epistemological theory required that, since the knower becomes what he knows, the soul is definitely not corporeal—if it is corporeal when it knows what some corporeal thing is, that thing would come to be within it. Therefore, the soul has an operation which does not rely on a body organ, and therefore the soul can exist without a body. Furthermore, since the rational soul of human beings is a subsistent form and not something made of matter and form, it cannot be destroyed in any natural process. The full argument for the immortality of the soul and Aquinas' elaboration of Aristotelian theory is found in Question 75 of the First Part of the Summa Theologica.\n\nIn his discussions of rational psychology, Immanuel Kant (1724–1804) identified the soul as the \"I\" in the strictest sense, and argued that the existence of inner experience can neither be proved nor disproved.\n\nGilbert Ryle's ghost in the machine argument, which is a rejection of Descartes' mind–body dualism, can provide a contemporary understanding of the soul/mind, and the problem concerning its connection to the brain/body.\n\nPsychologist James Hillman's archetypal psychology is an attempt to restore the concept of the soul, which Hillman viewed as the \"self-sustaining and imagining substrate\" upon which consciousness rests. Hillman described the soul as that \"which makes meaning possible, [deepens] events into experiences, is communicated in love, and has a religious concern\", as well as \"a special relation with death\". Departing from the Cartesian dualism \"between outer tangible reality and inner states of mind\", Hillman takes the Neoplatonic stance that there is a \"third, middle position\" in which soul resides. Archetypal psychology acknowledges this third position by attuning to, and often accepting, the archetypes, dreams, myths, and even psychopathologies through which, in Hillman's view, soul expresses itself.\n\nThe current scientific consensus across all fields is that the existence of any kind of soul in the traditional sense is incompatible with a modern scientific understanding of the human mind, which holds that the human being is merely a complex machine that operates based on the exact same physical laws as all other objects in the universe, according to Julien Musolino, a cognitive scientist and professor at Rutgers University, who states that there is currently no scientific evidence whatsoever to support the existence of the soul and there is considerable evidence that seems to indicate that souls do not exist.\n\nNeuroscience as an interdisciplinary field, and its branch of cognitive neuroscience particularly, operates under the ontological assumption of physicalism. In other words, it assumes—in order to perform its science—that only the fundamental phenomena studied by physics exist. Thus, neuroscience seeks to understand mental phenomena within the framework according to which human thought and behavior are caused solely by physical processes taking place inside the brain, and it operates by the way of reductionism by seeking an explanation for the mind in terms of brain activity.\n\nTo study the mind in terms of the brain several methods of functional neuroimaging are used to study the neuroanatomical correlates of various cognitive processes that constitute the mind. The evidence from brain imaging indicates that all processes of the mind have physical correlates in brain function. However, such correlational studies cannot determine whether neural activity plays a causal role in the occurrence of these cognitive processes (correlation does not imply causation) and they cannot determine if the neural activity is either necessary or sufficient for such processes to occur. Identification of causation, and of necessary and sufficient conditions requires explicit experimental manipulation of that activity. If manipulation of brain activity changes consciousness, then a causal role for that brain activity can be inferred. Two of the most common types of manipulation experiments are loss-of-function and gain-of-function experiments. In a loss-of-function (also called \"necessity\") experiment, a part of the nervous system is diminished or removed in an attempt to determine if it is necessary for a certain process to occur, and in a gain-of-function (also called \"sufficiency\") experiment, an aspect of the nervous system is increased relative to normal. Manipulations of brain activity can be performed with direct electrical brain stimulation, magnetic brain stimulation using transcranial magnetic stimulation, psychopharmacological manipulation, optogenetic manipulation, and by studying the symptoms of brain damage (case studies) and lesions. In addition, neuroscientists are also investigating how the mind develops with the development of the brain.\n\nPhysicist Sean M. Carroll has written that the idea of a soul is incompatible with quantum field theory (QFT). He writes that for a soul to exist: \"Not only is new physics required, but dramatically new physics. Within QFT, there can't be a new collection of 'spirit particles' and 'spirit forces' that interact with our regular atoms, because we would have detected them in existing experiments.\"\n\nQuantum indeterminism has been invoked by some theorists as a solution to the problem of how a soul might interact with the brain, but neuroscientist Peter Clarke found errors with this viewpoint, noting there is no evidence that such processes play a role in brain function; and concluded that a Cartesian soul has no basis from quantum physics.\n\nSome parapsychologists have attempted to establish, by scientific experiment, whether a soul separate from the brain exists, as is more commonly defined in religion rather than as a synonym of psyche or mind. Milbourne Christopher (1979) and Mary Roach (2010) have argued that none of the attempts by parapsychologists have yet succeeded.\n\nIn 1901 Duncan MacDougall conducted an experiment in which he made weight measurements of patients as they died. He claimed that there was weight loss of varying amounts at the time of death; he concluded the soul weighed 21 grams. The physicist Robert L. Park has written that MacDougall's experiments \"are not regarded today as having any scientific merit\" and the psychologist Bruce Hood wrote that \"because the weight loss was not reliable or replicable, his findings were unscientific.\"\n\n\n"}
{"id": "27859", "url": "https://en.wikipedia.org/wiki?curid=27859", "title": "Sphere", "text": "Sphere\n\nA sphere (from Greek σφαῖρα — \"sphaira\", \"globe, ball\") is a perfectly round geometrical object in three-dimensional space that is the surface of a completely round ball (viz., analogous to the circular objects in two dimensions, where a \"circle\" circumscribes its \"disk\").\n\nLike a circle in a two-dimensional space, a sphere is defined mathematically as the set of points that are all at the same distance from a given point, but in a three-dimensional space. This distance is the radius of the ball, which is made up from all points with a distance less than from the given point, which is the center of the mathematical ball. These are also referred to as the radius and center of the sphere, respectively. The longest straight line through the ball, connecting two points of the sphere, passes through the center and its length is thus twice the radius; it is a diameter of both the sphere and its ball.\n\nWhile outside mathematics the terms \"sphere\" and \"ball\" are sometimes used interchangeably, in mathematics the above distinction is made between a \"sphere\", which is a two-dimensional closed surface, embedded in a three-dimensional Euclidean space, and a \"ball\", which is a three-dimensional shape that includes the sphere and everything \"inside\" the sphere (a \"closed ball\"), or, more often, just the points \"inside\", but \"not on\" the sphere (an \"open ball\"). This distinction has not always been maintained and especially older mathematical references talk about a sphere as a solid. This is analogous to the situation in the plane, where the terms \"circle\" and \"disk\" can also be confounded.\n\nIn analytic geometry, a sphere with center and radius is the locus of all points such that\n\nLet be real numbers with and put\nThen the equation\nhas no real points as solutions if formula_4 and is called the equation of an imaginary sphere. If formula_5 the only solution of formula_6 is the point formula_7 and the equation is said to be the equation of a point sphere. Finally, in the case formula_8, formula_6 is an equation of a sphere whose center is formula_10 and whose radius is formula_11.\n\nIf in the above equation is zero then is the equation of a plane. Thus, a plane may be thought of as a sphere of infinite radius whose center is a point at infinity.\n\nThe points on the sphere with radius formula_12 and center formula_13 can be parameterized via\n\nA sphere of any radius centered at zero is an integral surface of the following differential form:\n\nThis equation reflects that position and velocity vectors of a point, and , traveling on the sphere are always orthogonal to each other.\n\nA sphere can also be constructed as the surface formed by rotating a circle about any of its diameters. Since a circle is a special type of ellipse, a sphere is a special type of ellipsoid of revolution. Replacing the circle with an ellipse rotated about its major axis, the shape becomes a prolate spheroid; rotated about the minor axis, an oblate spheroid.\n\nIn three dimensions, the volume inside a sphere (that is, the volume of a ball, but classically referred to as the volume of a sphere) is \nwhere is the radius of the sphere. Archimedes first derived this formula, by showing that the volume inside a sphere is twice the volume between the sphere and the circumscribed cylinder of that sphere (having the height and diameter equal to the diameter of the sphere). This assertion can be obtained from Cavalieri's principle. This formula can also be derived using integral calculus, i.e. disk integration to sum the volumes of an infinite number of circular disks of infinitesimally small thickness stacked side by side and centered along the -axis from to , assuming the sphere of radius is centered at the origin. \n\nAt any given , the incremental volume () equals the product of the cross-sectional area of the disk at and its thickness ():\n\nThe total volume is the summation of all incremental volumes:\n\nIn the limit as approaches zero this equation becomes:\n\nAt any given , a right-angled triangle connects , and to the origin; hence, applying the Pythagorean theorem yields:\n\nUsing this substitution gives\n\nthat can be evaluated to give the result\n\nAlternatively, this formula is found using spherical coordinates, with volume element\nso\nFor most practical purposes, the volume inside a sphere inscribed in a cube can be approximated as 52.4% of the volume of the cube, since , where is the diameter of the sphere and also the length of a side of the cube and  ≈ 0.5236. For example, a sphere with diameter 1 meter has 52.4% the volume of a cube with edge length 1 meter, or about 0.524 m.\n\nThe surface area of a sphere of radius is:\n\nArchimedes first derived this formula from the fact that the projection to the lateral surface of a circumscribed cylinder is area-preserving. Another approach to obtaining the formula comes from the fact that it equals the derivative of the formula for the volume with respect to because the total volume inside a sphere of radius can be thought of as the summation of the surface area of an infinite number of spherical shells of infinitesimal thickness concentrically stacked inside one another from radius 0 to radius . At infinitesimal thickness the discrepancy between the inner and outer surface area of any given shell is infinitesimal, and the elemental volume at radius is simply the product of the surface area at radius and the infinitesimal thickness.\n\nAt any given radius , the incremental volume () equals the product of the surface area at radius () and the thickness of a shell ():\n\nThe total volume is the summation of all shell volumes:\n\nIn the limit as approaches zero this equation becomes:\n\nSubstitute :\n\nDifferentiating both sides of this equation with respect to yields as a function of :\n\nThis is generally abbreviated as:\nwhere is now considered to be the fixed radius of the sphere.\n\nAlternatively, the area element on the sphere is given in spherical coordinates by . In Cartesian coordinates, the area element is\nFor more generality, see area element.\n\nThe total area can thus be obtained by integration:\n\nThe sphere has the smallest surface area of all surfaces that enclose a given volume, and it encloses the largest volume among all closed surfaces with a given surface area. The sphere therefore appears in nature: for example, bubbles and small water drops are roughly spherical because the surface tension locally minimizes surface area.\n\nThe surface area relative to the mass of a ball is called the specific surface area and can be expressed from the above stated equations as\nwhere is the density (the ratio of mass to volume).\n\nA sphere is uniquely determined by four points that are not coplanar. More generally, a sphere is uniquely determined by four conditions such as passing through a point, being tangent to a plane, etc. This property is analogous to the property that three non-collinear points determine a unique circle in a plane.\n\nConsequently, a sphere is uniquely determined by (that is, passes through) a circle and a point not in the plane of that circle.\n\nBy examining the common solutions of the equations of two spheres, it can be seen that two spheres intersect in a circle and the plane containing that circle is called the radical plane of the intersecting spheres. Although the radical plane is a real plane, the circle may be imaginary (the spheres have no real point in common) or consist of a single point (the spheres are tangent at that point).\n\nThe angle between two spheres at a real point of intersection is the dihedral angle determined by the tangent planes to the spheres at that point. Two spheres intersect at the same angle at all points of their circle of intersection. They intersect at right angles (are orthogonal) if and only if the squares of the distance between their centers is equal to the sum of the squares of their radii.\n\nIf and are the equations of two distinct spheres then \nis also the equation of a sphere for arbitrary values of the parameters and . The set of all spheres satisfying this equation is called a pencil of spheres determined by the original two spheres. In this definition a sphere is allowed to be a plane (infinite radius, center at infinity) and if both the original spheres are planes then all the spheres of the pencil are planes, otherwise there is only one plane (the radical plane) in the pencil.\n\nIf the pencil of spheres does not consist of all planes, then there are three types of pencils:\n\nAll the tangent lines from a fixed point of the radical plane to the spheres of a pencil have the same length.\n\nThe radical plane is the locus of the centers of all the spheres that are orthogonal to all the spheres in a pencil. Moreover, a sphere orthogonal to any two spheres of a pencil of spheres is orthogonal to all of them and its center lies in the radical plane of the pencil.\n\nPairs of points on a sphere that lie on a straight line through the sphere's center are called antipodal points. A great circle is a circle on the sphere that has the same center and radius as the sphere and, consequently, divides it into two equal parts. The plane sections of a sphere are called \"spheric sections\". They are all circles and those that are not great circles are called \"small circles\". \n\nThe shortest distance along the surface between two distinct non-antipodal points on the sphere is the length of the smaller of the two arcs on the unique great circle that includes the two points. Equipped with this \"great-circle distance\", a great circle becomes the Riemannian circle.\n\nIf a particular point on a sphere is (arbitrarily) designated as its \"north pole\", then the corresponding antipodal point is called the \"south pole\", and the equator is the great circle that is equidistant to them. Great circles through the two poles are called lines (or meridians) of longitude, and the line connecting the two poles is called the axis of rotation. Circles on the sphere that are parallel to the equator are lines of latitude. This terminology is also used for such approximately spheroidal astronomical bodies as the planet Earth (see geoid).\n\nAny plane that includes the center of a sphere divides it into two equal hemispheres. Any two intersecting planes that include the center of a sphere subdivide the sphere into four lunes or biangles, the vertices of which all coincide with the antipodal points lying on the line of intersection of the planes.\n\nThe antipodal quotient of the sphere is the surface called the real projective plane, which can also be thought of as the northern hemisphere with antipodal points of the equator identified.\n\nThe hemisphere is conjectured to be the optimal (least area) isometric filling of the Riemannian circle.\n\nSpheres can be generalized to spaces of any number of dimensions. For any natural number , an \"-sphere,\" often written as , is the set of points in ()-dimensional Euclidean space that are at a fixed distance from a central point of that space, where is, as before, a positive real number. In particular:\n\nSpheres for are sometimes called hyperspheres.\n\nThe -sphere of unit radius centered at the origin is denoted and is often referred to as \"the\" -sphere. Note that the ordinary sphere is a 2-sphere, because it is a 2-dimensional surface (which is embedded in 3-dimensional space).\n\nThe surface area of the unit ()-sphere is\n\nwhere is Euler's gamma function.\n\nAnother expression for the surface area is\n\nand the volume is the surface area times or\n\nGeneral recursive formulas also exist for the volume of an -ball.\n\nMore generally, in a metric space , the sphere of center and radius is the set of points such that .\n\nIf the center is a distinguished point that is considered to be the origin of , as in a normed space, it is not mentioned in the definition and notation. The same applies for the radius if it is taken to equal one, as in the case of a unit sphere.\n\nUnlike a ball, even a large sphere may be an empty set. For example, in with Euclidean metric, a sphere of radius is nonempty only if can be written as sum of squares of integers.\n\nIn topology, an -sphere is defined as a space homeomorphic to the boundary of an -ball; thus, it is homeomorphic to the Euclidean -sphere, but perhaps lacking its metric.\n\nThe -sphere is denoted . It is an example of a compact topological manifold without boundary. A sphere need not be smooth; if it is smooth, it need not be diffeomorphic to the Euclidean sphere.\n\nThe Heine–Borel theorem implies that a Euclidean -sphere is compact. The sphere is the inverse image of a one-point set under the continuous function . Therefore, the sphere is closed. is also bounded; therefore it is compact.\n\nRemarkably, it is possible to turn an ordinary sphere inside out in a three-dimensional space with possible self-intersections but without creating any crease, in a process called sphere eversion.\n\nThe basic elements of Euclidean plane geometry are points and lines. On the sphere, points are defined in the usual sense. The analogue of the \"line\" is the geodesic, which is a great circle; the defining characteristic of a great circle is that the plane containing all its points also passes through the center of the sphere. Measuring by arc length shows that the shortest path between two points lying on the sphere is the shorter segment of the great circle that includes the points.\n\nMany theorems from classical geometry hold true for spherical geometry as well, but not all do because the sphere fails to satisfy some of classical geometry's postulates, including the parallel postulate. In spherical trigonometry, angles are defined between great circles. Spherical trigonometry differs from ordinary trigonometry in many respects. For example, the sum of the interior angles of a spherical triangle always exceeds 180 degrees. Also, any two similar spherical triangles are congruent.\n\nIn their book \"Geometry and the Imagination\" David Hilbert and Stephan Cohn-Vossen describe eleven properties of the sphere and discuss whether these properties uniquely determine the sphere. Several properties hold for the plane, which can be thought of as a sphere with infinite radius. These properties are:\n\n\n"}
{"id": "455295", "url": "https://en.wikipedia.org/wiki?curid=455295", "title": "Sub-orbital spaceflight", "text": "Sub-orbital spaceflight\n\nA sub-orbital spaceflight is a spaceflight in which the spacecraft reaches outer space, but its trajectory intersects the atmosphere or surface of the gravitating body from which it was launched, so that it will not complete one orbital revolution.\n\nFor example, the path of an object launched from Earth that reaches the Kármán line (at above sea level), and then falls back to Earth, is considered a sub-orbital spaceflight. Some sub-orbital flights have been undertaken to test spacecraft and launch vehicles later intended for orbital spaceflight. Other vehicles are specifically designed only for sub-orbital flight; examples include manned vehicles, such as the X-15 and SpaceShipOne, and unmanned ones, such as ICBMs and sounding rockets.\n\nFlights which attain sufficient velocity to go into low Earth orbit, and then de-orbit before completing their first full orbit, are not considered sub-orbital. Examples of this include Yuri Gagarin's Vostok 1, and flights of the Fractional Orbital Bombardment System.\n\nUsually a rocket is used, but experimental sub-orbital spaceflight has also been achieved with a space gun.\n\nBy one definition a sub-orbital spaceflight reaches an altitude higher than above sea level. This altitude, known as the Kármán line, was chosen by the Fédération Aéronautique Internationale because it is roughly the point where a vehicle flying fast enough to support itself with aerodynamic lift from the Earth's atmosphere would be flying faster than orbital speed. The US military and NASA award astronaut wings to those flying above , although the U.S. State Department appears to not support a distinct boundary between atmospheric flight and spaceflight.\n\nDuring freefall the trajectory is part of an elliptic orbit as given by the orbit equation. The perigee distance is less than the radius of the Earth \"R\" including atmosphere, hence the ellipse intersects the Earth, and hence the spacecraft will fail to complete an orbit. The major axis is vertical, the semi-major axis \"a\" is more than \"R\"/2. The specific orbital energy formula_1 is given by:\n\nformula_2\n\nwhere formula_3 is the standard gravitational parameter.\n\nAlmost always \"a\" < \"R\", corresponding to a lower formula_1 than the minimum for a full orbit, which is formula_5\n\nThus the net extra specific energy needed compared to just raising the spacecraft into space is between 0 and formula_6.\n\nTo minimize the required delta-v (an astrodynamical measure which strongly determines the required fuel), the high-altitude part of the flight is made with the rockets off (this is technically called free-fall even for the upward part of the trajectory). (Compare with Oberth effect.) The maximum speed in a flight is attained at the lowest altitude of this free-fall trajectory, both at the start and at the end of it.\n\nIf one's goal is simply to \"reach space\", for example in competing for the Ansari X Prize, horizontal motion is not needed. In this case the lowest required delta-v, to reach 100 km altitude, is about 1.4 km/s. Moving slower, with less free-fall, would require more delta-v.\n\nCompare this with orbital spaceflights: a low Earth orbit (LEO), with an altitude of about 300 km, needs a speed around 7.7 km/s, requiring a delta-v of about 9.2 km/s. (If there were no atmospheric drag the theoretical minimum delta-v would be 8.1 km/s to put a craft into a 300-km high orbit starting from a stationary point like the South Pole. The theoretical minimum can be up to 0.46 km/s less if launching eastward from near the equator.)\n\nFor sub-orbital spaceflights covering a horizontal distance the maximum speed and required delta-v are in between those of a vertical flight and a LEO. The maximum speed at the lower ends of the trajectory are now composed of a horizontal and a vertical component. The higher the horizontal distance covered, the greater the horizontal speed will be. (The vertical velocity will increase with distance for short distances but will decrease with distance at longer distances.) For the V-2 rocket, just reaching space but with a range of about 330 km, the maximum speed was 1.6 km/s. Scaled Composites SpaceShipTwo which is under development will have a similar free-fall orbit but the announced maximum speed is 1.1 km/s (perhaps because of engine shut-off at a higher altitude).\n\nFor larger ranges, due to the elliptic orbit the maximum altitude can be much more than for a LEO. On a 10,000-km intercontinental flight, such as that of an intercontinental ballistic missile or possible future commercial spaceflight, the maximum speed is about 7 km/s, and the maximum altitude may be more than 1300 km.\nAny spaceflight that returns to the surface, including sub-orbital ones, will undergo atmospheric reentry. The speed at the start of the reentry is basically the maximum speed of the flight. The aerodynamic heating caused will vary accordingly: it is much less for a flight with a maximum speed of only 1 km/s than for one with a maximum speed of 7 or 8 km/s.\n\nWe can calculate the minimum delta-v and the corresponding maximum altitude for a given range, \"d\", assuming a spherical earth of circumference 40 000 km and neglecting the earth's rotation and atmosphere. Let θ be half the angle that the projectile is to go around the earth, so in degrees it is 45°×\"d\"/10 000 km. The minimum-delta-v trajectory corresponds to an ellipse with one focus at the centre of the earth and the other at the point halfway between the launch point and the destination point (somewhere inside the earth). (This is the orbit that minimizes the semi-major axis, which is equal to the sum of the distances from a point on the orbit to the two foci. Minimizing the semi-major axis minimizes the specific orbital energy and thus the delta-v, which is the speed of launch.) Geometrical arguments lead then to the following (with \"R\" being the radius of the earth, about 6370 km):\n\nformula_7\n\nformula_8\n\nformula_9\n\nformula_10\n\nNote that the altitude of apogee is maximized (at about 1320 km) for a trajectory going one quarter of the way around the earth (10 000 km). Longer ranges will have lower apogees in the minimal-delta-v solution.\n\nformula_11\n\nformula_12\n\n(where \"g\" is the acceleration of gravity at the earth's surface). We see that the Δv increases with range, leveling off at 7.9 km/s as the range approaches 20 000 km (halfway around the world). The minimum-delta-v trajectory for going halfway around the world corresponds to a circular orbit just above the surface (of course in reality it would have to be above the atmosphere). See lower for the time of flight.\n\nAn intercontinental ballistic missile is defined as a missile that can hit a target at least 5500 km away, and according to the above formula this requires an initial speed of 6.1 km/s. Increasing the speed to 7.9 km/s to attain any point on Earth requires a considerably larger missile because the amount of fuel needed goes up exponentially with delta-v (see Rocket equation).\n\nThe initial direction of a minimum-delta-v trajectory points halfway between straight up and straight toward the destination point (which is below the horizon). Again, this is the case if we ignore the earth's rotation. It is not exactly true for a rotating planet unless the launch takes place at a pole.\n\nIn a vertical flight of not too high altitudes, the time of the free-fall is both for the upward and for the downward part the maximum speed divided by the acceleration of gravity, so with a maximum speed of 1 km/s together 3 minutes and 20 seconds. The duration of the flight phases before and after the free-fall can vary.\n\nFor an intercontinental flight the boost phase takes 3 to 5 minutes, the free-fall (midcourse phase) about 25 minutes. For an ICBM the atmospheric reentry phase takes about 2 minutes; this will be longer for any soft landing, such as for a possible future commercial flight.\n\nSub-orbital flights can last many hours. Pioneer 1 was NASA's first space probe, intended to reach the Moon. A partial failure caused it to instead follow a sub-orbital trajectory, reentering the Earth's atmosphere 43 hours after launch.\n\nTo calculate the time of flight for a minimum-delta-v trajectory, we first find that, according to Kepler's third law, the period for the entire orbit (if it didn't go through the earth) would be:\n\nformula_13\n\nUsing Kepler's second law, we multiply this by the portion of the area of the ellipse swept by the line from the centre of the earth to the projectile:\n\nformula_14\n\nformula_15\n\nThis gives about 32 minutes for going a quarter of the way around the earth, and 42 minutes for going halfway around. For short distances, this expression is asymptotic to formula_16.\n\nAs one can see from the form involving arccosine, the derivative of the time of flight with respect to \"d\" (or θ) goes to zero as \"d\" approaches 20 000 km (halfway around the world). The derivative of Δv also goes to zero here. So if \"d\" = 19 000 km, the length of the minimum-delta-v trajectory will be about 19 500 km, but it will take only a few seconds less time than the trajectory for \"d\" = 20 000 km (for which the trajectory is 20 000 km long).\n\nWhile there are a great many possible sub-orbital flight profiles, it is expected that some will be more common than others.\n\nThe first sub-orbital vehicles which reached space were ballistic missiles. The very first ballistic missile to reach space was the German V-2, the work of the scientists at Peenemünde, on October 3, 1942 which reached an altitude of . Then in the late 1940s the USA and USSR concurrently developed missiles all of which were based on the V-2 Rocket, and then much longer range Intercontinental Ballistic Missiles (ICBMs). There are now many countries who possess ICBMs and even more with shorter range IRBMs (Intermediate Range Ballistic Missiles).\n\nSub-orbital tourist flights will initially focus on attaining the altitude required to qualify as reaching space. The flight path will probably be either vertical or very steep, with the spacecraft landing back at its take-off site.\n\nThe spacecraft will probably shut off its engines well before reaching maximum altitude, and then coast up to its highest point. During a few minutes, from the point when the engines are shut off to the point where the atmosphere begins to slow down the downward acceleration, the passengers will experience weightlessness.\n\nMegaroc had been planned for sub-orbital spaceflight by the British Interplanetary Society in the 1940s.\n\nIn the autumn of 1945, the group M. Tikhonravov K. and N. G. Chernysheva at NII-4 rocket artillery Academy of Sciences technology on its own initiative the first stratospheric rocket project was developed by BP-190 for vertical flight two pilots to an altitude of 200 km based on captured German ballistic rocket V-2.\n\nIn 2004, a number of companies worked on vehicles in this class as entrants to the Ansari X Prize competition. The Scaled Composites SpaceShipOne was officially declared by Rick Searfoss to have won the competition on October 4, 2004 after completing two flights within a two-week period.\n\nIn 2005, Sir Richard Branson of the Virgin Group announced the creation of Virgin Galactic and his plans for a 9-seat capacity SpaceShipTwo named VSS \"Enterprise\". It has since been completed with eight seats (one pilot, one co-pilot and six passengers) and has taken part in captive-carry tests and with the first mother-ship WhiteKnightTwo, or VMS Eve. It has also completed solitary glides, with the movable tail sections in both fixed and \"feathered\" configurations. The hybrid rocket motor has been fired multiple times in ground-based test stands, and was fired in a powered flight for the second time on 5 September 2013. Four additional SpaceShipTwos have been ordered and will operate from the new Spaceport America. Commercial flights carrying passengers were expected in 2014, but became cancelled due to the disaster during SS2 PF04 flight. Branson stated, \"[w]e are going to learn from what went wrong, discover how we can improve safety and performance and then move forwards together.\"\n\nA major use of sub-orbital vehicles today are as scientific sounding rockets. Scientific sub-orbital flights began in the 1920s when Robert H. Goddard launched the first liquid fueled rockets, however they did not reach space altitude. In the late 1940s, captured German V-2 ballistic missiles were converted into V-2 sounding rockets which helped lay the foundation for modern sounding rockets. Today there are dozens of different sounding rockets on the market, from a variety of suppliers in various countries. Typically, researchers wish to conduct experiments in microgravity or above the atmosphere.\n\nResearch, such as that done for the X-20 Dyna-Soar project suggests that a semi-ballistic sub-orbital flight could travel from Europe to North America in less than an hour.\n\nHowever, the size of rocket, relative to the payload, necessary to achieve this, is similar to an ICBM. ICBMs have delta-v's somewhat less than orbital; and therefore would be somewhat cheaper than the costs for reaching orbit, but the difference is not large.\n\nThus due to the high cost, this is likely to be initially limited to high value, very high urgency cargo such as courier flights, or as the ultimate business jet; or possibly as an extreme sport, or for military fast-response.\n\nThe SpaceLiner is a hypersonic suborbital spaceplane concept that could transport 50 passengers from Australia to Europe in 90 minutes or 100 passengers from Europe to California in 60 minutes. The main challenge lies in increasing the reliability of the different components, particularly the engines, in order to make their use for passenger transportation on a daily basis possible.\n\nSpaceX is planning to use its BFR launch vehicle as a sub-orbital point-to-point transport.\n\n\nAbove at least 100 km in altitude.\nPrivate companies such as Virgin Galactic, XCOR, Armadillo Aerospace (reinvented as Exos Aerospace), Airbus,Blue Origin and Masten Space Systems are taking an interest in sub-orbital spaceflight, due in part to ventures like the Ansari X Prize. NASA and others are experimenting with scramjet based hypersonic aircraft which may well be used with flight profiles that qualify as sub-orbital spaceflight. Non-profit entities like ARCASPACE and Copenhagen Suborbitals also attempt rocket-based launches.\n\n"}
{"id": "4428087", "url": "https://en.wikipedia.org/wiki?curid=4428087", "title": "Udit Raj", "text": "Udit Raj\n\nUdit Raj is an Indian Member of Parliament in the Lok Sabha, representing the North-west Delhi constituency. Raj is also the National Chairman of the All India Confederation of SC/ST Organizations. He is an influential leader from the Bharatiya Janata Party (BJP) as well as nationally as a social activist for marginalised communities like SC/ST. Udit Raj is a member to the BJP National Executive.\nHe was born in Ramnagar, Uttar Pradesh into an ethnic group called Khatik which is recognised as a Scheduled Caste , and studied for BA at Allahabad University. He took admission at Jawaharlal Nehru University, New Delhi in 1980. He was selected for the Indian Revenue Service in 1988 and served as the Deputy Commissioner, Joint Commissioner and Additional Commissioner of Income Tax at New Delhi. On 24 November 2003 he resigned from government service and formed the Indian Justice Party. He is a prominent activist working on behalf of India's SC/ST communities. \n\nHe joined the BJP on 23 February 2014. In the past he had opposed the BJP, but by then regarded it as sympathetic to the aboriginal SC/ST communities.\n\nRaj, a Dalit, converted from Hinduism to Buddhism in 2001.\n\n"}
{"id": "548214", "url": "https://en.wikipedia.org/wiki?curid=548214", "title": "Vested interest (communication theory)", "text": "Vested interest (communication theory)\n\nVested interest (Crano, 1983; Crano & Prislin, 1995; Sivacek & Crano, 1982) is a communication theory that seeks to explain how certain hedonically relevant (Miller & Averbeck, 2013) attitudinal dimensions can influence and consistently predict behavior based on the degree of subjective investment an individual has in a particular attitude object. As defined by William Crano, \"vested interest\" refers to the degree to which an attitude object is deemed hedonically relevant by the attitude holder. According to Crano, \"an attitude object that has important perceived personal consequences for the individual will be perceived as highly vested. Highly vested attitudes will be functionally related to behavior\" (Crano, 1983). Simply put, when people have more at stake with the result of an object (like a law or policy) that will greatly affect them, they will behave in a way that will directly support or defy the object for the sake of their own self-interest.\n\nFor example, a 30-year-old learns that the legal driving age in his state is being raised from 16 to 17. While he may not agree with this proposed change, he is not affected as much as a 15-year-old would be and is unlikely to protest the change. A 15-year-old, however, has much to lose (waiting another year to get a driver license) and is more likely to vehemently oppose the new proposed law. To gather support for his position, a course of action the 15-year-old might take would be to tell other soon-to-be drivers about the new law, so that they collectively have a vested interest in perhaps changing the law. This example illustrates the point that highly vested attitudes concerning issues depend on the situational point of view.\n\nAnother example of vested interest can be found in a study conducted by Berndsen, Spears and van der Pligt, which involves students from a University in Amsterdam where the teaching faculty proposed the use of English to teach the curriculum instead of Dutch. Vested interest, in this case, suggests that students would be opposed to the use of English rather than Dutch simply based on the potential impact lectures conducted in English might have on their grades. \n\nA key factor to consider with vested interest is the level or type of involvement the individual has with a particular attitude object. This can be broken up into three main involvement components: Value-relevant, Impression-relevant, and Outcome-relevant. Value-relevant involvement concerns behaviors which support/reinforce values of the individual. Impression-relevant involvement relates to those behaviors which serve to create or maintain a specific image of the individual. This could, in some ways, be compared to a low-self monitor. Outcome-relevant involvement concerns those behaviors which hold direct personal consequences at a premium for the individual and as a result, corresponds most closely to vested interest.\n\nThe concept of involvement closely relates to collaboration which encompasses value, impression and desired outcome. Vested interest is essential in achieving success in collaboration where two or more individuals have the potential to gain or lose. Organizations who strive for collaborative success benefit from understanding vested interest and that of other collaborators in order to maintain a supportive level of involvement. \n\nThe way people view vested interest as distinct from ego involvement, is a construct that has been the topic of social psychological research for many years. In a study conducted by John Sivacek and William D. Crano, they prove that the aforementioned statement of ego involvement and vested interest are indeed separate. Sivacek and Crano state, \"It was possible to have circumstances that an individual would perceive as involving but that it would not arouse his or her vested interest.\" Ego-involvement’s main focus points are on individual’s psychological attitudes that are experienced as being a part of “me”. The more emotionally connected people are to an idea, concept, or value, minor differences in beliefs can be viewed as significantly large and perhaps make harsh judgments or have stronger reactions. Conversely, a person with less emotional connectivity (low ego-involvement) will have more latitude in their reactions. It is important to note that while highly vested attitudes can be experienced as ego involving, the opposite is not always true. An individual can be ego involved in a certain attitude that has no hedonic consequence. For example, religious or political ideals with little or no hedonic value may still be ego-involved because individuals view those types of beliefs as part of who they are.\n\nEgo-involvement, as it pertains to vested interest, is relative to Social Judgment Theory in that the concept of one’s identity is the primary focus of efforts in continued involvement. Essential to social judgment theory is the idea of ego thus actions or ideas with a varying degree of ego involvement carry a commensurate amount of vested interest to the individual as detailed by Sherif, Kelly, Rogers, Sarup, and Tittler. Sherif, et al. conducted a series of studies to develop “indicators of ego involvement” (p. 311). One of the leading questions they sought to answer was how much ego involvement (vested interest) does an induvial in a situation with no alternatives solutions have and does this ego involvement correlate to the number of options at hand. Sherif et al., suggest the question was answered by Beck and Nebergall in 1967 who stated that individuals with little to no options have corresponding vested interest indicating low ego involvement. \n\nThe factor to consider with vested interest and its application towards attitude-consistent actions is attitude importance. Attitude (or issue) importance concerns not only matters of personal consequence, but also matters of national or international interest. While both of these can fall in line with each other, vested interest and attitude importance are not the same. For example, consider the plight of an African nation that has been ravaged by an influenza epidemic. Although an individual in America may consider this objectively important, because of the low probability of personal consequence—i.e., vested interest — his resultant behavior may not be indicative of his attitude towards the epidemic. In other words, since the issue is of little hedonic relevance to the perceiver, the amount of vested interest is low, and is therefore unlikely to produce attitude-consistent actions. Geographic distance and cultural differences are also a factor in attitude importance. Tragic circumstances halfway around the world or shocking behaviors by members of a culture different from the perceiver, will most likely never result in attitude change. The physical distance or cultural difference of an occurrence directly correlates to the vested interest of the perceiver. Things too far away or customs perceived to be too strange will almost never trigger a vested interest.\n\nIndicators of vested interest can include attitude importance, as detailed by Jon Krosnick who defined this concept by stating that “central, ego-involved, and salient attitudes” often include attitudes significantly important to individual interests. In politics, for example, voters have a vested interest in candidates whose values (policy) align with their own to include attitudes toward these values. Due to the nature of politics, voters come to conclusions about one candidate over another based on perceived attitude importance (object) on these policies rather than vocal support alone placing a high value on this concept as it pertains to vested interest. \n\nAttitude object continuously makes an issue salient which correlates to outcome relevant involvement. Two differences exist between vested interest and outcome relevant involvement where attitude objects remain highly important. Initially, outcome relevant objects retain a high degree of vested interest while not appearing to be. Secondly, outcome relevant involvement suggest interest ends once the goal is achieved whereas vested interest suggests a self-perpetuated interest. \n\nThere are five key components that may diminish or enhance the effects of vested interest on attitude-behavior consistency. These are (a) stake, (b) attitudinal salience, (c) the certainty of the attitude outcome link, (d) the immediacy of attitude-implicated consequences, and (e) the self-efficacy of the individual to perform an attitudinally implicated act. Attitudes affect behavior. However, social psychologists recognize that contextual, interpsychic, and intrapsychic sources of variation can drastically affect the strength of this relation. A factor that has been shown to strongly affect attitude-behavior consistency is self-interest or vested interest. The following sections explain each of these variables in greater detail.\n\nStake refers to the perceived personal consequence of an attitude that is directly related to the intensity of vested interest and influences components that contribute to attitude-behavior consistency. In its basic form, the more that is at stake concerning a particular issue, the stronger the attitude will be. Consequently, as attitude strength increases, the consistency of attitude-based actions also increases.\n\nReferring to the concept of vested interest as it relates to attitude-behavior consistency, stake is an individual’s macro involvement in a particular situation where the consequence is salient. In a situation where stake is operationalized using certainly and immediacy, one found the likely effect of this was behavior relative to the immediate consequence, positive or negative. For instance, in a study conducted to measure the relevance stake has on vested interest, students given a health assessment showed greater enthusiasm for items inquiring about donating blood when saving a life was salient (i.e. a child’s life depends on my donation).\n\nStake may contribute to attitude-behavior consistency by inducing thoughts that support the attitude. This serves as the basis for future behavior. Stake may also strengthen the attitude-behavior relation by indirectly amplifying the awareness of stimuli associated with people's attitudes. Stake is the most powerful impression that comes from all the components of vested interest regarding attitude and behavior. Stake influences perceptions of attitude and action, but also of other action-relevant components as well. When stake is high, people also find the critical issue highly salient. Stake also affects the perception of immediacy. The greater the personal consequence of the issue, the more pressing the issue is perceived to be. Finally, stake was found to affect the perception of immediacy. The greater the personal consequence of the issue, the more pressing it was perceived to be. The phrases, \"the stakes are/were high\" or \"high stakes\", are used when issues of high salience or immediacy are raised, usually in regards to gambling or other high-risk activities involving vested interest.\n\nSalience refers to the perceiver’s awareness of the effects of an attitude upon himself. In other words, the prominence of an issue, as perceived by an individual, shapes the strength of his resulting attitude. Salient attitudes have a greater effect directly on subsequent behavior. Linking this discovery to vested interest, the research concluded that the salience effect was heightened when the attitude had important personal outcomes for someone. When the consequences of the behavior issuing from an attitude are highly salient, attitude-behavior consistency increases. If consequences are not salient, the consistency of the effects of vested interest on attitude behavior will be dramatically reduced. For instance, two people may have negative attitudes towards living near a prison. The first person lost a loved one at the hands of an inmate who escaped during a jailbreak. The second person simply does not like the eyesore the prison building creates in the area around his home. The first person's attitude towards inmates and prisons will probably be more salient than that of the second person who has not experienced a similar trauma. The first person's more salient attitude will foster the operation of vested interest, which will result in greater attitude-behavior consistency.\n\nAttitudes that have been acquired through direct experience, such as the example just given, may be more salient than those acquired through vicarious processes. This greater salience results in greater consistency in attitude behavior. The attitude of someone who is non-salient reduces vested interest and weakens attitude-behavior consistency. The most powerful impression to emerge from all the analyses is the overwhelming effect of stake, or personal consequence, on attitude and behavior. When stake is high, people assume that a person would find the critical issue highly salient. Stake does not interact with, but enhances the perception of, issue salience. This is an important effect, because salience significantly affects actions that are expected to happen.\n\nAdditionally, salience can be described as the most recent and accessible memory associated with a specific object (i.e. idea) in which an individual has developed their own unique attitude. Mortality, for instance, would become salient when faced with a situation where death was probable or the known death of a friend, relative or an experienced event which resulting in someone’s death. This death salience would then influence behavior for a short amount of time following the event.\n\nCertainty refers to perceived likelihood of personal consequences as a result of an attitude or action. Simply stated, if a certain course of action is taken, then the chances of a specific event occurring as a result of this action are evaluated by the perceiver to help shape his resultant attitudes and behaviors. Certainty can be easily applied to situations in which an individual knowingly takes a calculated risk. For instance, let's continue with our aforementioned example of people living near a prison. Although the chance of a prison escape is minimal, particularly in a maximum-security prison, it could occur and crimes against those living close by would increase. Those living further away from the prison might argue that a prison break is unlikely and that there is no real risk. Alternatively, those living close to the prison could make an equally valid argument about the dangers of living near the prison in the event of prisoners escaping. Still others might realize there to be a potential risk to their safety, but would not deem it risky enough to move elsewhere.\n\nCertainty in attitude, relative to vested interest, remains difficult to define without an understanding of two particular concepts. One is the acceptance of truth in the events or idea requiring approximation of occurrence. Two requires that certainty is not dependent on external factors which can undermine its validity. Certainty must be a concept which is pushed onto us much like truth is a certainty beyond our immediate control. \n\nIf the consequences of an attitude consistent act are uncertain, attitude-consistent action is not likely to occur, due to the fact that vested interest will be reduced. An example of this is a person who has a negative attitude towards living near a prison. If the person assumes that the link between living near a prison and being a victim of a violent crime is minimal, then health and safety promoting behaviors consistent with this negative attitude are not likely. However, if someone believes that living near the prison and being a victim of a violent crime is almost certain, that person would be unlikely to move close to the prison, assuming the person has a positive attitude toward safety or a negative attitude toward prisons and inmates.\n\nImmediacy refers to an individual’s perceived amount of time between an action and its resulting consequences. Immediacy can be considered an extension of certainty, however, these two entities are completely separate. For instance, in our prison example, people in opposition to the construction of the prison in their neighborhood may have felt that the amount of time to build the prison to and the eventual housing of prisoners was not long enough to make an informed decision. They may also feel that it is only a matter of time before something negative happened to the local citizens as a result of having a prison nearby.\n\nImmediacy refers to the apparent temporary lag between an attitudinally implicated action and its consequences. If the results of an attitude consistent action are thought to be immediate rather than delayed, the effects of stake, or vested interest, on attitude-behavior consistency will be more dramatic. In other words, if a person living near the prison in the previous example perceives the possibility of a jailbreak could occur at a much later time in life, he may act in manner that is not consistent. This is because the lack of immediate consequences reduces the perception of vested interest. Therefore, immediacy can help explain self-destructive behaviors.\n\nImmediacy, in vested interest, can also be thought of in terms of positive or negative consequence disassociated from a timeline. Vested interest such as organ donation, for example, make life and death salient which brings about the concept of immediacy to decide not necessarily to act. This is seen in a mechanism which allows people to agree to donate organs in the event of their death (i.e. drivers licenses). \n\nAnother example of immediacy is that of marketing companies who implement immediacy to encourage consumers to act or remain inactive. If what they market is something a person is highly vested in and the marketing firm has simultaneously created an immediate need, then they have done their job to get consumers to behave as they desired. This use of immediacy can be both helpful and harmful. Consumers who are not well versed in how marketing works may find themselves situations they did not wish to be in. However, consumers who are cognizant of how marketing works may find this very useful in how they do or do not expend their resources.\n\nSelf-efficacy in regards to vested interest, is the amount that an individual believes that they are capable of performing an action associated with an attitude or advocated position. In short, it is a person's sense of competence in regards to a specific task. Continuing with our prison example, residents with high vested interest that was covered by the other four components would need self-efficacy to protest the location of the new prison. In other words, the residents opposing the prison would have to believe in their abilities to effectively stop the construction. Conversely, if they lacked self-efficacy and therefore believed there was nothing they could do, then they would not act on their held attitude and vested interest will not have been attained. Variations in self-efficacy will produce differences in perceptions of the likelihood of someone working against the opposed plan. Higher levels of manipulated self-efficacy result in higher levels of expected action. However, variations in stake also influence perceptions of self-efficacy. When the stakes are high, people assume higher levels of perceived self-efficacy.\n\nAnother way the concept of self-efficacy can be described is using social cognitive theory to understand the role thought, drive and emotion have on self-efficacy (20). Cognitively, one works to quantify actions, emotion, and drive resulting in self-efficacy. However, this concept remains volatile as a change in one or more of these influences degrades self-efficacy. An example of this would be physical fitness, in that, elevated or decreased self-efficacy will cause one to accept or deny a strenuous task daily.\n\nVarious studies have been conducted to determine the effects of vested interest on attitude strengths. In one such study, Crano and Sivacek visited a university in Michigan and gathered the results of a proposed drinking-age referendum. The referendum sought to increase the legal drinking age from 18 to 21. The respondents were divided into three categories: 1. high vested interest (those who would be significantly and immediately affected as a result of the referendum), 2. low vested interest (those who would be unaffected by the law change at the time of its inception), and 3. moderate vested interest (those who fell between the first two extremes). Although 80% of the subjects were opposed to the referendum, their respective levels of vested interest clearly indicated that the strength of their attitudes significantly affected their resultant behaviors. Half of the highly vested interest groups joined the anti-referendum campaign, but only a quarter of the moderately vested interest group and an eighth of the low vested interest group joined the campaign. These results support Crano's theory of vested interest and reinforce the implications and considerations of stake, salience, certainty, immediacy, and self-efficacy discussed above. It also proves the correlation between vested interest and action, based on what level of involvement the three types of students were willing to participate in.\n\nIn a second study, Sivacek and Crano visited Michigan State University. In this experiment, subjects were informed that the university was considering the addition of a senior comprehensive examination to the graduate prerequisites. Respondents were given the following options:\nThe respondents were grouped into the same three categories as the drinking age study: high, moderate, and low vested interest. The study found that those with the highest levels of vested interest were significantly more inclined to take action based on their attitudes concerning the issue; that is, their resultant behaviors (signing the petition, joining the group, pledging multiple hours with the group) occurred much more consistently and prevalently than that of the other two vested interest groups.\n\nCrano conducted another study to prove that vested interest may affect people's belief that a majority of a population will support their attitude on an issue. This bias is known as false-consensus or assumed-consensus effect. Under the guise of a public opinion survey, Crano created high and low vested interest groups by identifying whether upper- or lower-classmen would pay a surcharge to subsidize lost funding from the government. The class who was selected to pay the surcharge had a high degree of vested interest while the student body not required to pay exhibited a lower degree of vested interest. The study then determined the participants estimate of what percentage of the student body would support their beliefs regardless of impact. Crano found that vested interest influenced assumed consensus and students believed that a majority of the university's population would support their plight even though only half would be affected.\n\nDale Miller and Rebecca Ratner conducted this study utilizing 81 male and female students at the University of Yale. In this experiment the objective was for half of the participants to show their own attitude toward smoking policies and the other half to show their thoughts on others attitudes toward smoking policies. The group with the questionnaire regarding their personal attitude about smoking were asked: 1. if they were a smoker or a nonsmoker, 2. how heavy or light a smoker they were, 3. whether they would support an increase on cigarette tax, 4. would they do away with smoking advertisements, and 5. their thoughts on smoking restrictions in public places. The second half of the participants were asked what percentage they thought smokers would support the previously mentioned policies for smokers or nonsmokers. They were not asked whether or not they smoked. The results of this study replicated Green and Gerkin's 1989 study that nonsmokers had more support for smoking restrictions than did those that smoke. These results supported the hypothesis: \"Smokers in this study were more opposed to policies that regulated smoking than were nonsmokers, but the effect of smoking status on expressed attitudes was significantly less than that predicted by respondents\". The smokers had a higher vested interest in smoking policies because they were directly affected. This study also revealed a direct correlation between vested interest and attitudes.\n\nBarbara Lehman and William Crano conducted a study regarding the persuasive effects of vested interest on attitude concerning political judgment which was published in 2001. In this study, they utilized data from 1976 national election studies concentrating on three areas (e.g. living conditions, health insurance and school integration). Their discoveries were such that self-interest was a significant contributor to values placed on all three areas of concern. Further, outside analysis of the study revealed self-interest had a direct correlation to ideologies, affiliation, and intolerance. Additionally, respondents with vested interest in any one of the three areas were more than likely to endorse candidates whose focus was in that particular area. \n\nVested interest appears to affect people's tendency to overestimate the extent to which others agree with their beliefs, a bias known variously as the false-consensus or assumed-consensus effect.If people tend to overestimate the number of others who share their beliefs, this tendency should be exacerbated in situations involving personally consequential, or highly vested, beliefs. Research supports this expectation. College student participants who thought that a new university policy would disadvantage them personally assumed that the great majority of the student body would evaluate the policy as they had, despite the fact that only half the student population would be similarly disadvantaged.\n\nEach of the five components (stake, salience, certainty, immediacy, and self-efficacy) co-exist within an individual’s realm of conscious judgment. If it creates a sufficiently strong attitude, any of these components can cause an individual to adopt or reject a certain position. All five are considered any time an individual is presented with a message that attempts to influence or persuade him to adopt a certain position or perform an action. The process of evaluating these components can range from almost instantly to taking several years. At any rate, all five are considered (consciously or subconsciously) before making a decision with implications of vested interest.\n\n"}
{"id": "14360911", "url": "https://en.wikipedia.org/wiki?curid=14360911", "title": "Visual control", "text": "Visual control\n\nVisual control is a business management technique employed in many places where information is communicated by using visual signals instead of texts or other written instructions. The design is deliberate in allowing quick recognition of the information being communicated, in order to increase efficiency and clarity. These signals can be of many forms, from different coloured clothing for different teams, to focusing measures upon the size of the problem and not the size of the activity, to kanban, obeya and heijunka boxes and many other diverse examples. In The Toyota Way, it is also known as \"mieruka\".\n\nVisual control methods aim to increase the efficiency and effectiveness of a process by making the steps in that process more visible. The theory behind visual control is that if something is clearly visible or in plain sight, it is easy to remember and keep at the forefront of the mind. Another aspect of visual control is that everyone is given the same visual cues and so are likely to have the same vantage point.\n\nThere are many different techniques that are used to apply visual control in the workplace. Some companies use visual control as an organizational tool for materials. A clearly labeled storage board lets the employee know exactly where a tool belongs and what tools are missing from the display board. Another simple example of a common visual control is to have reminders posted on cubicle walls so that they remain in plain sight. Visual signs and signals communicate information that is needed to make effective decisions. These decisions may be safety oriented or they may give reminders as to what steps should be taken to resolve a problem. Most companies use visual controls in one degree or another, many of them not even realizing that the visual controls that they are making have a name and a function in the workplace. Whether it is recognized by the name of \"visual control\" or not, the fact is that replacing text or number with graphics makes a set of information easier to understand with only a glance, making it a more efficient way of communicating a message. It is also commonly used for internal team communication.\n\nVisual controls are designed to make the control and management of a company as simple as possible. This entails making problems, abnormalities, or deviations from standards visible to everyone. When these deviations are visible and apparent to all, corrective action can be taken to immediately correct these problems.\n\nVisual controls are meant to display the operating or progress status of a given operation in an easy to see format and also to provide instruction and to convey information. A visual control system must have an action component associated with it in the event that the visually represented procedures are not being followed in the real production process. Therefore, visual controls must also have a component where immediate feedback is provided to workers.\n\nThere are two groups and seven types of application in visual controls. Displays group and controls group. \n\n"}
{"id": "2067398", "url": "https://en.wikipedia.org/wiki?curid=2067398", "title": "Wikitorial", "text": "Wikitorial\n\nWikitorial is a term coined by the \"Los Angeles Times\" to describe a traditional editorial that can be edited in the fashion of a wiki (computer software that allows users to edit text and make changes to one document). On June 17, 2005 the \"Los Angeles Times\" wrote the first Wikitorial, entitled \"War and Consequences\", on the subject of the War in Iraq. Below that editorial the paper wrote an invitation to its readers to rewrite the editorial in the wiki fashion. They called the experiment a \"public beta\" and suggested that it might be either a failure or a new form of opinion journalism.\n\nJimmy Wales, head of the Wikimedia Foundation, which governs Wikipedia, was one of the early contributors to the new Wikitorial which inspired a counterpoint editorial, redirections and much discussion.\n\nThe \"L.A. Times\" Wikitorial was closed on June 19, 2005. This was due to a vandal inserting multiple pictures of goatse. Around 4:30 AM local time the vandal was changing the site to pornographic photos and just as quickly, within seconds, a guardian was reverting it to the earlier editorial. Shortly after 5:00 AM the connection was broken and the Wikitorial ceased to be available.\n\nReaders who access the site find this message:\nWhere is the wikitorial?\n\n\"Unfortunately, we have had to remove this feature, at least temporarily, because a few readers were flooding the site with inappropriate material.\"\n\n\"Thanks and apologies to the thousands of people who logged on in the right spirit.\"\nDuring the two days the Wikitorial was available it had changed from the original length (just under eleven hundred words) to just over twenty-seven hundred words. Several experienced Wikipedians offered suggestions for the organization of the Wikitorial.\n\nSouth Dakota's \"Argus Leader\" has inaugurated a new online feature called You Re-Write-It Editorials. It follows the Wikitorial pattern with the main difference from the \"Los Angeles Times\" experiment being that the moderators will check the editorials before posting them to avoid the problems experienced by the \"Los Angeles Times\".\n\n"}
