{"id": "28097533", "url": "https://en.wikipedia.org/wiki?curid=28097533", "title": "African American–Jewish relations", "text": "African American–Jewish relations\n\nAfrican Americans and Jewish Americans have interacted throughout much of the history of the United States. This relationship has included widely publicized cooperation and conflict, and—since the 1970s—has been an area of significant academic research. Cooperation during the Civil Rights Movement was strategic and significant, culminating in the Civil Rights Act of 1964. \n\nThe relationship has also been marred by conflict and controversy related to such topics as the Black Power movement, Zionism, affirmative action, and the role of a small number of American Jews, among a large number of other Americans and others, in the Atlantic slave trade.\n\nDuring the colonial era, Jewish immigrants to British America were generally merchants from London. They settled in cities such as Providence, Rhode Island, Charleston, South Carolina, and Savannah, Georgia, generally becoming part of local societies. They were slaveholders when that was the local practice.\n\nWith major immigration of Ashkenazi Jews from Germany, followed by waves from Eastern Europe in the late 19th and early 20th centuries, Jews and blacks had a greater variety of encounters, and these were markedly different in northern cities and southern areas, many of which were still dominated by agriculture. Jewish immigrants entered northern and midwestern cities in the same period when blacks were migrating in the hundreds of thousands from the rural South in the Great Migration. \n\nMarcus Garvey (1887–1940) was an early promoter of pan-Africanism and African redemption, and led the Universal Negro Improvement Association and African Communities League. His push to celebrate Africa as the original homeland of African Americans, led many Jews to compare Garvey to leaders of Zionism. An example of this was that Garvey wanted World War I peace negotiators to turn over former German colonies in southwest Africa to blacks. In that period stressing self-determination for former colonies, Zionists were promoting a \"return of Jews\" after 2,000 years to the historic homeland of Israel. At the same time, Garvey regularly criticized Jews in his columns in his newspaper \"Negro World,\" for allegedly trying to destroy the black population of America.\n\nThe widely publicized lynching of Leo Frank, a Jew, in Georgia in 1915 by a mob of Southerners caused many Jews to \"become acutely conscious of the similarities and differences between themselves and blacks.\" Some had an increased sense of solidarity with blacks, as the trial exposed widespread anti-Semitism in Georgia. The trial also pitted Jews against blacks because Frank's defense attorneys suggested black janitor Jim Conley was guilty of the murder of the white girl. They called him a \"dirty, filthy, black, drunken, lying, nigger.\" Many historians since the late 20th century have concluded that Jim Conley did murder Phagan.\n\nIn the early 20th century, Jewish daily and weekly publications frequently reported on violence against blacks, and often compared the anti-black violence in the South to the pogroms endured by Jews in the Russian Empire. They were inspired by principles of justice, and by a desire to change racist policies in United States. During the first few decades of the 20th century, the leaders of American Jewry expended time, influence and their economic resources for black endeavors, supporting civil rights, philanthropy, social service, and organizing. Historian Hasia Diner notes that \"they made sure that their actions were well publicized\" as part of an effort to demonstrate increasing Jewish political clout. \n\nJulius Rosenwald was a Jewish philanthropist who donated a large part of his fortune to supporting education of blacks in the South by providing matching funds for construction of schools in rural areas. Jews played a major role in the NAACP in its early decades. Jews involved in the NAACP included Joel Elias Spingarn (the first chairman), Arthur B. Spingarn, and founder Henry Moskowitz. More recently, Jack Greenberg was a leader in the organization.\n\nFollowing the Civil War, Jewish shop-owners and landlords engaged in business with black customers and tenants, often filling a need where white business owners would not venture. This was true in most regions of the South, where Jews were often merchants in its small cities, as well as northern urban cities such as New York, where they settled in high numbers. Jewish shop-owners tended to be more civil than other whites to black customers, treating them with more dignity. Blacks often had more immediate contact with Jews than with other whites.\n\nIn 1903, black historian W. E. B. Du Bois interpreted the role of Jews in the South as successors to the slave-barons:\nBlack novelist James Baldwin (1924–1987) grew up in Harlem in the years between the world wars. He wrote,\nBaldwin wrote other accounts of Jews that were more sympathetic.\nMartin Luther King, Jr. suggested that some black anti-Semitism arose from the tensions of landlord-tenant relations: \n\nJewish producers in the United States entertainment industry produced many works on black subjects in the film industry, Broadway, and the music industry. Many portrayals of blacks were sympathetic, but historian Michael Rogin has discussed how some of the treatments could be considered exploitative.\n\nRogin also analyzes the instances when Jewish actors, such as Al Jolson, portrayed blacks in blackface. He suggests that these were deliberately racist portrayals but adds that they were also expressions of the culture at the time. Blacks could not appear in leading roles in either the theatre or in movies: \"Jewish blackface neither signified a distinctive Jewish racism nor produced a distinctive black anti-Semitism\".\n\nJews often interpreted black culture in film, music, and plays. Historian Jeffrey Melnick argues that Jewish artists such as Irving Berlin and George Gershwin (composer of \"Porgy and Bess\") created the myth that they were the proper interpreters of Black culture, \"elbowing out 'real' Black Americans in the process.\" Despite evidence from Black musicians and critics that Jews in the music business played an important role in paving the way for mainstream acceptance of Black culture, Melnick concludes that, \"while both Jews and African-Americans contributed to the rhetoric of musical affinity, the fruits of this labor belonged exclusively to the former.\"\n\nBlack academic Harold Cruse viewed the arts scene as a white-dominated misrepresentation of black culture, epitomized by works like George Gershwin's folk opera, \"Porgy and Bess\".\n\nSome blacks have criticized Jewish movie producers for portraying blacks in a racist manner. In 1990, at an NAACP convention in Los Angeles, Legrand Clegg, founder of the Coalition Against Black Exploitation, a pressure group that lobbied against negative screen images of African Americans, alleged: \n\nProfessor Leonard Jeffries echoed those comments in a 1991 speech at the Empire State Plaza Black Arts & Cultural Festival in Albany, New York. Jeffries said that Jews controlled the film industry, using it to paint a negative stereotype of blacks.\n\nCooperation between Jewish and African-American organizations peaked after World War II—sometimes called the \"golden age\" of the relationship. Leaders of each group joined in an effective movement for racial equality in the United States, and Jews funded and led some national civil rights organizations. This era of cooperation culminated in the passage of the Civil Rights Act of 1964, which outlawed racial or religious discrimination in schools and other public facilities, and the Voting Rights Act of 1965, which prohibited discriminatory voting practices and authorized the government to oversee and review state practices.\n\nAccording to historian Greenberg, \"It is significant that ... a disproportionate number of white civil rights activists were [Jewish] as well. Jewish agencies engaged with their African American counterparts in a more sustained and fundamental way than did other white groups largely because their constituents and their understanding of Jewish values and Jewish self-interest pushed them in that direction.\"\n\nThe extent of Jewish participation in the civil rights movement often correlated with their branch of Judaism: Reform Jews participated more frequently than did Orthodox Jews. Many Reform Jews were guided by values reflected in the Reform branch's Pittsburgh Platform, which urged Jews to \"participate in the great task of modern times, to solve, on the basis of justice and righteousness, the problems presented by the contrasts and evils of the present organization of society.\"\n\nReligious leaders such as rabbis and Baptist ministers from black churches often played key roles in the civil rights movement, including Abraham Joshua Heschel, who marched with Martin Luther King, Jr. during the Selma to Montgomery marches. Sixteen Jewish leaders were arrested while heeding a call from King to march in St. Augustine, Florida, in June 1964. It was the occasion of the largest mass arrest of rabbis in American history, which took place at the Monson Motor Lodge. Marc Schneier, President of the Foundation for Ethnic Understanding, wrote \"Shared Dreams: Martin Luther King Jr. and the Jewish Community\" (1999), recounting the historic relationship between African and Jewish Americans as a way to encourage a return to strong ties following years of animosity that reached its apex during the Crown Heights riot in Brooklyn, New York.\n\nNorthern Jews often supported desegregation in their communities and schools, even at the risk of diluting their close-knit Jewish communities, which often were a critical component of Jewish life.\n\nThe summer of 1964 was designated the Freedom Summer, and many northern Jews traveled south to participate in a concentrated voter registration effort. Two Jewish activists, Andrew Goodman and Michael Schwerner, and one black activist, James Chaney, were murdered by the Ku Klux Klan near Philadelphia, Mississippi, as a result of their participation. Their deaths were considered martyrdom by some, and temporarily strengthened black-Jewish relations.\n\nMartin Luther King, Jr., said in 1965,\nSome recent scholarship suggests that the \"golden age\" (1955–1966) of the black–Jewish relationship was not as ideal as it is often portrayed.\n\nPhilosopher and activist Cornel West asserts that there was no golden age in which \"blacks and Jews were free of tension and friction\". West says that this period of black–Jewish cooperation is often downplayed by blacks and romanticized by Jews: \"It is downplayed by blacks because they focus on the astonishingly rapid entry of most Jews into the middle and upper middle classes during this brief period—an entry that has spawned... resentment from a quickly growing black impoverished class. Jews, on the other hand, tend to romanticize this period because their present status as upper middle dogs and some top dogs in American society unsettles their historic self-image as progressives with a compassion for the underdog.\"\n\nHistorian Melanie Kaye/Kantrowitz points out that the number of northern Jews that went to the southern states numbered only a few hundred, and that the \"relationship was frequently out of touch, periodically at odds, with both sides failing to understand each other's point of view.\"\n\nPolitical scientist Andrew Hacker wrote: \"It is more than a little revealing that whites who travelled south in 1964 referred to their sojourn as their 'Mississippi summer'. It is as if all the efforts of the local blacks for voter registration and the desegregation of public facilities had not even existed until white help arrived... Of course, this was done with benign intentions, as if to say 'we have come in answer to your calls for assistance'. The problem was... the condescending tone... For Jewish liberals, the great memory of that summer has been the deaths of Andrew Goodman and Michael Schwerner and—almost as an afterthought—James Chaney. Indeed, Chaney's name tends to be listed last, as if the life he lost was worth only three fifths of the others.\"\n\nThe vast majority of civil rights activism by American Jews was undertaken by Jews from the northern states. Jews from the southern states engaged in virtually no organized activity on behalf of civil rights. This lack of participation was puzzling to some northern Jews, due to the \"inability of the northern Jewish leaders to see that Jews ... were not generally victims in the South and that the racial caste system in the south situated Jews favorably in the Southern mind, or 'whitened' them.\" However, there were some southern Jews who participated in civil rights activity as individuals.\n\nRecent decades have shown a greater trend for southern Jews to speak out on civil rights issues, as shown by the 1987 marches in Forsyth County, Georgia.\n\nStarting in 1966, the collaboration between Jews and blacks started to unravel. Jews were increasingly transitioning to middle-class and upper-class status, distancing themselves from blacks. At the same time, many black leaders, including some from the Black Power movement, became outspoken in their demands for greater equality, often criticizing Jews along with other white targets.\n\nIn 1966, the Student Nonviolent Coordinating Committee (SNCC) voted to exclude whites from its leadership, a decision that resulted in the expulsion of several Jewish leaders.\n\nIn 1967, black academic Harold Cruse attacked Jewish activism in his 1967 volume 'The Crisis of the Negro Intellectual' in which he argued that Jews had become a problem for blacks precisely because they had so identified with the Black struggle. Cruse insisted that Jewish involvement in interracial politics impeded the emergence of \"Afro-American ethnic consciousness\". For Cruse, as well as for other black activists, the role of American Jews as political mediator between Blacks and whites was \"fraught with serious dangers to all concerned\" and must be \"terminated by Negroes themselves.\"\n\nBlack Hebrew Israelites are groups of people, mostly of Black American ancestry situated mainly in the Americas who claim to be descendants of the ancient Israelites. Black Hebrews adhere in varying degrees to the religious beliefs and practices of mainstream Judaism. They are generally not accepted as Jews by Orthodox or Conservative Jews, nor are they accepted by the greater Jewish community, due to their degree of divergence from mainstream Judaism.\n\nMany Black Hebrews consider themselves—and not Jews—to be the only authentic descendants of the ancient Israelites. Some groups identify themselves as Hebrew Israelites, other groups identify themselves as Black Hebrews, and other groups identify themselves as Jews. Dozens of Black Hebrew groups were founded in the United States during the late 19th and early 20th centuries.\n\nElijah Muhammad, the founder of the Nation of Islam, claimed that blacks—not whites or Europeanized Jews—are the chosen people. The Nation of Islam's current leader, Louis Farrakhan, has also claimed that African Americans are the chosen people. In a 1985 speech, Farrakhan said \"I have a problem with Jews ... because I am declaring to the world that they are not the chosen people of God. ... You, the black people of America and the Western Hemisphere [are].\"\n\nThe labor movement was another area of the relationship that flourished before WWII, but ended in conflict afterwards. In the early 20th century, one important area of cooperation was attempts to increase minority representation in the leadership of the United Automobile Workers (UAW). In 1943, Jews and blacks joined to request the creation of a new department within the UAW dedicated to minorities, but that request was refused by UAW leaders.\n\nIn the immediate post-World War II period, the Jewish Labor Committee (JLC), which was founded in February 1934 to oppose the rise of Nazism in Germany, formed approximately two dozen local committees to combat racial intolerance in the U.S and Canada. The JLC, which had local offices in a number of communities in North America, helped found the United Farm Workers and campaigned for the passage of California's \"Fair Employment Practices Act,\" and provided staffing and support for the 1963 March on Washington for Jobs and Freedom led by Martin Luther King Jr, A. Philip Randolph and Bayard Rustin.\n\nBeginning in early 1962, allegations were made by NAACP labor director Herbert Hill that since the 1940s, the JLC had also defended the anti-black discriminatory practices of unions in both the garment and building industries. Hill claimed that the JLC changed \"a black white conflict into a Black-Jewish conflict\". He said the JLC defended the Jewish leaders of the International Ladies' Garment Workers' Union (ILGWU) against charges of anti-black racial discrimination, distorted government reports about discrimination, failed to tell union members the truth, and when union members complained, the JLC labeled them antisemites. ILGWU leaders denounced Black members for demanding equal treatment and access to leadership positions.\n\nThe New York City teachers' strike of 1968 also signaled the decline of black-Jewish relations: the Jewish president of the United Federation of Teachers, Albert Shanker, made statements that were seen by some as straining black-Jewish relations by accusing black teachers of antisemitism.\n\nAfter Israel took over the West Bank and Gaza following the 1967 Six-Day War, some American blacks supported the Palestinians and criticized Israel's actions, for example by publicly supporting Palestinian leader Yasser Arafat and calling for the destruction of the Jewish state. Some, such as Muhammad Ali and Malcolm X, also criticized the Zionist movement.\n\nImmediately after the war, the editor of the Student Nonviolent Coordinating Committee's (SNCC) newsletter wrote an article criticizing Israel, and asserting that the war was an effort to regain Palestinian land and that during the 1948 war, \"Zionists conquered the Arab homes and land through terror, force, and massacres\". This article led to conflict between Jews and the SNCC, but black SNCC leaders treated the war as a \"test of their willingness to demonstrate SNCC's break from its civil rights past\". \n\nThe concerns of blacks continued, and in 1993, black philosopher Cornel West wrote in Race Matters: \"Jews will not comprehend what the symbolic predicament and literal plight of Palestinians in Israel means to blacks... Blacks often perceive the Jewish defense of the state of Israel as a second instance of naked group interest, and, again, an abandonment of substantive moral deliberation.\" \n\nThe support of Palestinians is frequently due to the consideration of them as people of color—Andrew Hacker writes: \"The presence of Israel in the Middle East is perceived as thwarting the rightful status of people of color. Some blacks view Israel as essentially a white and European power, supported from the outside, and occupying space that rightfully belongs to the original inhabitants of Palestine.\" Martin Luther King Jr. criticized this position at the 68th Annual Rabbinical Assembly for Conservative Judaism, \"On the Middle East crisis, we have had various responses. The responses of the so-called young militants does not represent the position of the vast majority of Negroes. There are some who are color consumed and see a kind of mystique in being colored, and anything non-colored is condemned. We do not follow that course in the Southern Christian Leadership Conference, and certainly most of the organizations in the civil rights movement do not follow that course.\"\n\nMany blacks have supported government and business affirmative action, while many Jews have not, preferring merit-based systems. Historians believe that this difference contributed to the decline of the black-Jewish alliance in the 1970s, when blacks began seeking ways to build on the civil rights legislation of the 1960s. As blacks continued to face widespread discrimination and struggled to make progress in society, they began to develop an increasing militancy. Greenberg believes that this increased resentment and fear among Jews.\n\nHerbert Hill's survey of affirmative-action lawsuits found that Jewish organizations have generally opposed affirmative-action programs. A widely publicized example of the black-Jewish conflict arose in the 1978 affirmative action case of \"Regents of the University of California v. Bakke,\" when black and Jewish organizations took opposing sides in the case of a white student who sued for admission, claiming that he was unfairly excluded by affirmative action programs.\n\nSome leaders of the black community have publicly made anti-Semitic comments, expressing anti-Semitic opinions held by a wider circle of some blacks, accusing Jews of over-aggressiveness in business relations, loyalty to Israel (rather than loyalty to the United States), alleged participation in the slave trade, and economic oppression. Some analysts attribute black anti-Semitism to resentment or envy \"directed at another underdog who has 'made it' in American society\".\n\nBlack activist Sufi Abdul Hamid led boycotts in 1935 during the Great Depression against certain Harlem merchants and establishments (often owned by Jewish proprietors) which he claimed discriminated against blacks. Some Jews accused him of anti-Semitism for these activities.\n\nIn 1984 presidential candidate Jesse Jackson and former United Nations ambassador Andrew Young made anti-Semitic comments, which were widely publicized. These remarks were thought to have extended the era of African-American and Jewish distrust into the 1980s.\n\nIn 1991 in Brooklyn, a black mob involved in the Crown Heights riot killed Yankel Rosenbaum, an Orthodox Jew, after a car driven by Jews hit and killed a black girl in the neighborhood. Some commentators believed that the unrest was related to anti-Semitism. The two ethnic groups live in close proximity to each other in this neighborhood, and the Orthodox Jewish community has been expanding.\n\nDuring the 1990s, anti-Semitism became widespread in the black communities on college campuses, where new historical studies revealed more data on Jewish participation in the slave trade, with some commentators claiming that they had dominated it. Prof. Leonard Jeffries of the City College of New York was a proponent of this idea, but his conclusions have been disputed by major African-American historians of the slave trade, including David Brion Davis.\n\nAccording to surveys begun in 1964 by the Anti-Defamation League, a Jewish organization, African Americans are significantly more likely than white Americans to hold antisemitic beliefs. There is a strong correlation between higher education levels and the rejection of anti-Semitic stereotypes for all races. Black Americans of all education levels are significantly more likely than whites of the same education level to be anti-Semitic.\n\nIn the 1998 survey, blacks (34%) were nearly four times as likely as whites (9%) to have answers that identified them as being of the most anti-Semitic category (those agreeing with at least 6 of 11 statements that were potentially or clearly antisemitic). Among blacks with no college education, 43% responded as the most anti-Semitic group (vs. 18% for the general population). This percentage fell to 27% among blacks with some college education, and 18% among blacks with a four-year college degree (vs. 5% for the general population).\n\nThe Nation of Islam, a black religious and political group, expressed several anti-Semitic pronouncements in the late 20th century. The group's founder, Elijah Muhammad, targeted whites in general, and he also asserted that whites—as well as Jews—are devils, implicated in the history of racism against blacks. But he did not consider Jews to be any more corrupt or oppressive than other whites.\n\nIn 1993, Nation of Islam spokesman Khalid Abdul Muhammad called Jews \"bloodsuckers\" in a public speech, leading to widespread public condemnation. The Nation of Islam's current leader, Louis Farrakhan, has made several remarks that the Anti-Defamation League and others consider anti-Semitic. He is alleged to have referred to Judaism as a \"dirty religion\" and to have called Adolf Hitler a \"very great man\"; Farrakhan denied these claims but a tape obtained by \"The New York Times\" supports the claim that he did and that he praised Hitler.\n\nDuring the 1990s, much of the Jewish-black conflict centered on allegations of anti-Semitism made against studies of Jewish involvement in the Atlantic slave trade and allegations that they were over-represented as prominent figures in it. Professor Leonard Jeffries said in a 1991 speech that \"rich Jews\" financed the slave trade, citing the role of Jews in slave-trading centers such as Rhode Island, Brazil, the Caribbean, Curaçao, and Amsterdam. His comments drew widespread outrage and calls for his dismissal from his position.\n\nJeffries cited as a source \"The Secret Relationship Between Blacks and Jews\" (1991), published by the Nation of Islam. That book alleges that Jews played a major role in the African slave trade, and it generated considerable controversy. Other scholarly works were published which rebutted its charges. Mainstream scholars of slavery such as David Brion Davis concluded that Jews had little major or continuing impact on the history of New World slavery. Most held fewer slaves than non-Jews in every British territory in North America and the Caribbean. Except in Brazil, Suriname, and Curaçao—they did not play leading roles as financiers, shipowners, or factors in the transatlantic or Caribbean slave trades.\n\nTony Martin of Wellesley College included \"The Secret Relationship between Blacks and Jews\" in the reading list for his classes, leading to charges of anti-Semitism against him in 1993.\n\nHenry Louis Gates Jr. of Harvard University called the book \"the bible of new anti-Semitism\" and added that \"the book massively misinterprets the historical record, largely through a process of cunningly selective quotations of often reputable sources.\"\n\nThe counterpoint to black anti-Semitism is Jewish anti-black racism. Some black customers and tenants felt that Jewish shopkeepers and landlords treated them unfairly and were racist. Hacker quotes James Baldwin's comments about Jewish shopkeepers in Harlem to support his racism claim.\n\nHacker also quoted author Julius Lester, who wrote: \"Jews tend to be a little self-righteous about their liberal record, ... we realize that they were pitying us and wanted our gratitude, not the realization of the principles of justice and humanity... Blacks consider [Jews] paternalistic. Black people have destroyed the previous relationship which they had with the Jewish community, in which we were the victims of a kind of paternalism, which is only a benevolent racism.\"\n\nIn his 1992 essay \"Blacks and Jews: The Uncivil War,\" historian Taylor Branch asserted that Jews had been \"perpetrators of racial hate.\" He noted that 3,000 members of the African Hebrew Israelites of Jerusalem, founded in 1966 in Chicago, were denied citizenship as Jews when they moved \"en masse\" to Israel. The Americans claimed that they had the right of citizenship as Jews under the Israeli Law of Return. Under the law, the only people recognized as Jews are people who are born Jews (having a Jewish mother or maternal grandmother), those with Jewish ancestry (having a Jewish father or grandfather), and people who convert to Orthodox, Reform, or Conservative Judaism. \n\nBranch believed that the rejection of the Chicago group was based on anti-Black sentiment among Israeli Jews. Branch was criticized by Seth Forman, who said the claims seemed baseless. He said that Israel had airlifted thousands of black Ethiopian Jews to Israel in the early 1990s. A group of American civil rights activists led by Bayard Rustin investigated the 1966 case. They concluded that racism was not the cause of the Black Hebrews' rejection in Israel. They were considered a cult rather than a group of historic Jewish descendants.\n\nHistorian Hasia Diner writes: \"Never a relationship of equals, [many blacks] assert, Jews sat on the boards of black organizations and held power in black institutions but never allowed for the reverse. [Jews] gave money to civil rights organizations and demanded the right to make decisions by virtue of the power of their purses.\"\n\n"}
{"id": "4417722", "url": "https://en.wikipedia.org/wiki?curid=4417722", "title": "Alakh Niranjan", "text": "Alakh Niranjan\n\nAlakh Niranjan is a term used by Nath Yogis as a synonym for Creator, and to describe the characteristics of God and the Self, known as the Atman. \"Alakh\" means \"one which cannot be seen (perceived)\" and \"niranjan\" means \"spotfree\". Niranjan is another name of Lord Shiva. Also spelled, \"Alekh\".\n\nThe original Sanskrit term \"Alakhshya\" means \"one that can not be perceived\"\n\nAlakh means A-Lakhshana which means beyond identifying features (lakhshana) or attributes. It refers to Attributeless God or Nirguna Brahman in here. This idea comes from ancient Yoga traditions originating in Swetashwetara Upanishad. This particular Upanishad deals with Yoga, Vedantic Monotheism as well as Shiva as Sat-Chit-Ananda.\nLegend has it, that the slogan or elating cry for the Supreme Being was first coined by Matsyendranath\". Matsyendra is popularly regarded as the 'second Guru' of Nath Yoga Cult after Lord Shiva as Adinath. He first used the words \"Alakh Niranjan\" to denote God as perceived by a Yoga adept in known history. His disciple is known as \"Yogi Gorakhnath\", also known as \"Gorakshanath\", without whose mention, Nath Yoga becomes unimaginable. It is Gorakhnath and Matsyendranath who popularised Kaya Sadhana throughout known limits of India and beyond. \n\nGorakhnath actually organised and assimilated most Yogis of the Hatha Yoga and Tantra Cult into the enormous Nath tradition. The city of Gorakhpur in North India is named after the legendary Yogi. 'Alakh Niranjan' became a very popular name for God all over India during and after Gorakhnath's time. Later first Sikh Guru, Nanak used this holy name to denote God.\n\nADESH ADESH - \nWhenever Yogis or Nath-Yogis meet, they greet each other with the salutation “Adesh-Adesh!” Gorakshanath the Maha Yogi wrote:\n\nThus the yogi in his contact with others expressed only the simple truth in the words, “Adesh-Adesh!” It is a foundation stone on which all spiritual light and attainment must be erected. It is the first truth to attain the First Lord\n\nAlakh Niranjan was adapted into Indian films in 1940, 1950, and in 1975 by Babubhai Mistry.\n"}
{"id": "13629602", "url": "https://en.wikipedia.org/wiki?curid=13629602", "title": "Allegory (category theory)", "text": "Allegory (category theory)\n\nIn the mathematical field of category theory, an allegory is a category that has some of the structure of the category of sets and binary relations between them. Allegories can be used as an abstraction of categories of relations, and in this sense the theory of allegories is a generalization of relation algebra to relations between different sorts. Allegories are also useful in defining and investigating certain constructions in category theory, such as exact completions.\n\nIn this article we adopt the convention that morphisms compose from right to left, so \"RS\" means \"first do \"S\", then do \"R\".\n\nAn allegory is a category in which\nall such that\nHere, we are abbreviating using the order defined by the intersection: \"R\"⊆\"S\" means \"R\" = \"R\"∩\"S\"\".\n\nA first example of an allegory is the category of sets and relations. The objects of this allegory are sets, and a morphism \"X → Y\" is a binary relation between \"X\" and \"Y\". Composition of morphisms is composition of relations; intersection of morphisms is intersection of relations.\n\nIn a category \"C\", a relation between objects \"X\", \"Y\" is a span of morphisms \"X←R→Y\" that is jointly-monic. Two such spans \"X←S→Y\" and \"X←T→Y\" are considered equivalent when there is an isomorphism between S and T that make everything commute, and strictly speaking relations are only defined up to equivalence (one may formalise this either using equivalence classes or using bicategories). If the category \"C\" has products, a relation between \"X\" and \"Y\" is the same thing as a monomorphism into \"X\"×\"Y\" (or an equivalence class of such). In the presence of pullbacks and a proper factorization system, one can define the composition of relations. The composition of \"X←R→Y←S→Z\" is found by first pulling back the cospan \"R→Y←S\" and then taking the jointly-monic image of the resulting span \"X←R←·→S→Z\".\n\nComposition of relations will be associative if the factorization system is appropriately stable. In this case one can consider a category Rel(\"C\"), with the same objects as \"C\", but where morphisms are relations between the objects. The identity relations are the diagonals \"X\"→\"X\"×\"X\".\n\nRecall that a regular category is a category with finite limits and images in which covers are stable under pullback. A regular category has a stable regular epi/mono factorization system. The category of relations for a regular category is always an allegory. Anti-involution is defined by turning the source/target of the relation around, and intersections are intersections of subobjects, computed by pullback.\n\nA morphism \"R\" in an allegory \"A\" is called a map if it is entire (1⊆\"R\"°\"R\") and deterministic (\"RR\"°⊆1). Another way of saying this: a map is a morphism that has a right adjoint in \"A\", when \"A\" is considered, using the local order structure, as a 2-category. Maps in an allegory are closed under identity and composition. Thus there is a subcategory Map(\"A\") of \"A\", with the same objects but only the maps as morphisms. For a regular category \"C\", there is an isomorphism of categories \"C\"≅Map(Rel(\"C\")). In particular, a morphism in Map(Rel(Set)) is just an ordinary set function.\n\nIn an allegory, a morphism \"R:X→Y\" is tabulated by a pair of maps \"f\":\"Z→X\", \"g\":\"Z→Y\" if \"gf\"°=R and \"f\"°\"f\"∩\"g\"°\"g\"=1. An allegory is called tabular if every morphism has a tabulation. For a regular category \"C\", the allegory Rel(\"C\") is always tabular. On the other hand, for any tabular allegory \"A\", the category Map(\"A\") of maps is a locally regular category: it has pullbacks, equalizers and images that are stable under pullback. This is enough to study relations in Map(\"A\") and, in this setting, \"A\"≅Rel(Map(\"A\")).\n\nA unit in an allegory is an object \"U\" for which the identity is the largest morphism \"U→U\", and such that from every other object there is an entire relation to \"U\". An allegory with a unit is called unital. Given a tabular allegory \"A\", the category Map(\"A\") is a regular category (it has a terminal object) if and only if \"A\" is unital.\n\nAdditional properties of allegories can be axiomatized. Distributive allegories have a union-like operation that is suitably well-behaved, and division allegories have a generalization of the division operation of relation algebra. Power allegories are distributive division allegories with additional powerset-like structure. The connection between allegories and regular categories can be developed into a connection between power allegories and toposes.\n"}
{"id": "123564", "url": "https://en.wikipedia.org/wiki?curid=123564", "title": "Application of tensor theory in engineering", "text": "Application of tensor theory in engineering\n\nTensors are frequently used in engineering to describe measured quantities.\n\n\n"}
{"id": "585841", "url": "https://en.wikipedia.org/wiki?curid=585841", "title": "Big push model", "text": "Big push model\n\nThe big push model is a concept in development economics or welfare economics that emphasizes that a firm's decision whether to industrialize or not depends on its expectation of what other firms will do. It assumes economies of scale and oligopolistic market structure and explains when industrialization would happen.\n\nThe originator of this theory was Paul Rosenstein-Rodan in 1943. Further contributions were made later on by Murphy, Shleifer and Robert W. Vishny in 1989. Analysis of this economic model ordinarily involves using game theory.\n\nThe theory of the model emphasizes that underdeveloped countries require large amounts of investments to embark on the path of economic development from their present state of backwardness. This theory proposes that a 'bit by bit' investment programme will not impact the process of growth as much as is required for developing countries. In fact, injections of small quantities of investments will merely lead to a wastage of resources.\nPaul Rosenstein-Rodan approvingly quotes a Massachusetts Institute of Technology study in this regard, \"There is a minimum level of resources that must be devoted to... a development programme if it is to have any chance of success. Launching a country into self-sustaining growth is a little like getting an airplane off the ground. There is a critical ground speed which must be passed before the craft can become airborne...\"\n\nRosenstein-Rodan argued that the entire industry which is intended to be created should be treated and planned as a massive entity (a firm or trust). He supports this argument by stating that the social marginal product of an investment is always different from its private marginal product, so when a group of industries are planned together according to their social marginal products, the rate of growth of the economy is greater than it would have otherwise been.\n\nAccording to Rosenstein-Rodan, there exist three indivisibilities in underdeveloped countries. These indivisibilities are responsible for external economies and thus justify the need for a big push. The indivisibilities are as follows-\n\nIndivisibilities in the production function may be with respect to any of the following:\nThese lead to increasing returns (i.e., economies of scale), and may require a high optimum size of a firm. This can be achieved even in developing countries since at least one optimum scale firm can be established in many industries. But investment in social overhead capital comprises investment in all basic industries (like power, transport or communications) which must necessarily come before directly productive investment activities. Investment in social overhead capital is 'lumpy' in nature. Such capital requirements cannot be imported from other nations. Therefore, heavy initial investment necessarily needs to be made in social overhead capital (this is approximated to be about 30 to 40 percent of the total investment undertaken by underdeveloped countries).\nSocial overhead capital is further characterized by four indivisibilities:\n\nDeveloping countries are characterized by low per-capita income and purchasing power. Markets in these countries are therefore small. In a closed economy, modernization and increased efficiency in a single industry has no impact on the economy as a whole since the output of that industry will fail to find a market. A large number of industries need to be set up simultaneously so that people employed in one industry consume the output of other industries and thus create complementary demand.\n\nTo illustrate this, Rosenstein Rodan gives the example of a shoe industry. If a country makes large investments in the shoe industry, all the disguisedly employed labor from the other industries find work and a source of income, leading to a rise in production of shoes and their own incomes. This increased income will not be expended only on buying shoes. It is conceivable that the increased incomes will lead to increased spending on other products too. However, there is no corresponding supply of these products to satisfy this increased demand for the other goods. Following the basic market forces of demand and supply, the prices of these commodities will rise. To avoid such a situation, investment must be spread out amongst different industries.\n\nThe situation may be different in an open economy as the output of the new industry may replace former imports or possibly find its market by way of exports. But even if the world market acts as a substitute for domestic demand, a big push is still needed (though its required size may now be reduced due to the presence of international trade).\n\nHigh levels of investment require a corresponding high level of savings. We cannot always rely on foreign aid as the huge levels of investments in the different sectors need to be made not only once, but multiple times. Hence domestic savings are a must. But in an underdeveloped economy,this is a challenge due to the low income levels. The marginal rate of savings needs to be increased following the rise in incomes due to higher investment.\n\nConsider a country whose economy is characterized by a large number sectors which are so small that any increase in the productivity of one sector has no impact on the economy as a whole. Each sector can either rely on traditional methods or switch to modern methods of production which would increase its efficiency. Let us assume that there are formula_1 workers in the economy and formula_2 sectors. Each sector therefore has formula_3 workers.\n\n\"Using traditional technology\", a sector would produce formula_3 amount of output, with each worker producing one unit of the commodity.\n\n\"Using modern technology\" a sector would produce more as the productivity would be greater than one unit per worker. However, a modern sector would require some of the workers (say formula_5) to perform administrative tasks.\n\nIn figure 1, the x-axis represents the labor employed and the y-axis represents the level of production. The production in the traditional sector is given by the curve T and the production in the modern sector is given by M. The curve M has a positive intercept on the x-axis, implying that even with zero production, there is a minimum level of formula_5 workers who still remain employed for carrying out administrative activities. With our assumption of formula_7 workers in the economy, the modern sector will have a higher level of productivity than the traditional sector. The production function of the modern sector is steeper than that of the traditional sector because of the higher productivity of workers in the former. The slope of both production functions is formula_8, where formula_9 is the marginal labor required to produce an additional unit of output. This level of formula_9 is lower for the modern sector than it is for the traditional sector.\nAssume that the traditional sector pays workers one unit of output which is subsequently spent equally by them in all sectors. The modern sector pays higher wages to workers. If all the workers are employed by the traditional sector, then the demand generated for the output of each sector is formula_11.\nGovernment intervention in a manner that investment is carried out on those industries that have higher forward and backward linkages.\nWe have two possible cases:\n\n\n\nThe concept of externalities is relevant for the Industrialization of underdeveloped countries, where decisions are to be made regarding distribution of savings among alternative investment opportunities. These arise from the interdependence in market economies.\n\nPecuniary economies are external economies transmitted through the price system, as prices are the signalling device (under conditions of perfect competition in a market economy). They arise in an industry (say industry X) due to internal economies of overcoming technical indivisibilities. This reduces the price of its product, which will benefit another industry (say industry Y) which use this output as an input or a factor of production. Subsequently, the profits of industry Y will rise, leading to its expansion and generating demand for the output of industry X. As a result, industry X's production and profits also expand.\n\nHowever in underdeveloped countries, conditions of perfect competition are not present due to the decentralized and differentiated nature of the market. Prices fail to act as a signalling system in the following ways:\nThis justifies the need for centralized pan-industry planning of investment in Developing countries, as the private sector cannot undertake such planning.\n\nEnlargement of the market size is another important externality which arises from the complementarity of industries. There exists an incentive to expand the scale of operations because the employees of one industry become the customers of another industry. In terms of products too (as in the above example of industries X and Y), one industry generates demand for the output of the other when the scale of operations increase.\n\nMarshallian economies also accrue to a firm within a growing industry, resulting from agglomeration of industrial districts or clusters in a particular area. These occur due to the following advantages of agglomeration identified by Alfred Marshall:\n\nAvailability of skilled labour is an externality which arises when industrialization occurs, as workers acquire better training and skills. This is not achievable by mere establishment of a few industries, but requires a large program of industrial growth. It is one of the most important external economies because absence of skilled labor is a strong impediment to industrialization.\n\nThe large-scale programme of industrialization advocated by this model requires huge investments which are beyond the means of the private sector. The investment in infrastructure and basic industries (like power, transport and communications) is 'lumpy' and has long gestation periods. The role of the state in this theory is therefore critical for investment in social overhead capital. Even if the private sector had the requisite resources to invest in such a programme, it would not do so since it is driven by profit motives. \nMany investments are profitable in terms of social marginal net product but not in terms of private marginal net product. Due to this there is no incentive for individual entrepreneurs to invest and take advantage of external economies.\n\nThe theory has been criticized by Hla Myint and Celso Furtado, among others, primarily on the grounds of the massive effort required to be taken by underdeveloped countries to move along the path of industrialization. Some of the major criticisms are as follows.\n\n\n\n\n"}
{"id": "1830142", "url": "https://en.wikipedia.org/wiki?curid=1830142", "title": "Bijection, injection and surjection", "text": "Bijection, injection and surjection\n\nIn mathematics, injections, surjections and bijections are classes of functions distinguished by the manner in which \"arguments\" (input expressions from the domain) and \"images\" (output expressions from the codomain) are related or \"mapped to\" each other.\n\nA function maps elements from its domain to elements in its codomain. Given a function formula_1\n\n\n\n\nAn injective function need not be surjective (not all elements of the codomain may be associated with arguments), and a surjective function need not be injective (some images may be associated with \"more than one\" argument). The four possible combinations of injective and surjective features are illustrated in the adjacent diagrams.\n\nA function is injective (one-to-one) if each possible element of the codomain is mapped to by at most one argument. Equivalently, a function is injective if it maps distinct arguments to distinct images. An injective function is an injection. The formal definition is the following.\n\n\nA function is surjective (onto) if each possible image is mapped to by at least one argument. In other words, each element in the codomain has non-empty preimage. Equivalently, a function is surjective if its image is equal to its codomain. A surjective function is a surjection. The formal definition is the following.\n\n\nA function is bijective if it is both injective and surjective. A bijective function is a bijection (one-to-one correspondence). A function is bijective if and only if every possible image is mapped to by exactly one argument. This equivalent condition is formally expressed as follow.\n\n\nSuppose you want to define what it means for two sets to \"have the same number of elements\". One way to do this is to say that two sets \"have the same number of elements\" if and only if all the elements of one set can be paired with the elements of the other, in such a way that each element is paired with exactly one element. Accordingly, we can define two sets to \"have the same number of elements\" if there is a bijection between them. We say that the two sets have the same cardinality.\n\nLikewise, we can say that set formula_16 \"has fewer than or the same number of elements\" as set formula_17 if there is an injection from formula_16 to formula_17. We can also say that set formula_16 \"has fewer than the number of elements\" in set formula_17 if there is an injection from formula_16 to formula_17 but not a bijection between formula_16 and formula_17.\n\nIt is important to specify the domain and codomain of each function since by changing these, functions which we think of as the same may have different \"jectivity\". \n\n\n\n\n\n\nIn the category of sets, injections, surjections, and bijections correspond precisely to monomorphisms, epimorphisms, and isomorphisms, respectively.\n\nThis terminology was originally coined by the Bourbaki group.\n\n\n"}
{"id": "9328562", "url": "https://en.wikipedia.org/wiki?curid=9328562", "title": "Boltzmann's entropy formula", "text": "Boltzmann's entropy formula\n\nIn statistical mechanics, Boltzmann's equation is a probability equation relating the entropy \"S\" of an ideal gas to the quantity \"W\", \nthe number of real microstates corresponding to the gas' macrostate:\n\nwhere \"k\" is the Boltzmann constant (also written as simply \"k\") and equal to 1.38065 × 10 J/K.\n\nIn short, the Boltzmann formula shows the relationship between entropy and the number of ways the atoms or molecules of a thermodynamic system can be arranged.\nThe equation was originally formulated by Ludwig Boltzmann between 1872 and 1875, but later put into its current form by Max Planck in about 1900. To quote Planck, \"the logarithmic connection between entropy and probability was first stated by L. Boltzmann in his kinetic theory of gases\".\n\nThe value of was originally intended to be proportional to the \"Wahrscheinlichkeit\" (the German word for probability) of a macroscopic state for some probability distribution of possible microstates—the collection of (unobservable) \"ways\" the (observable) thermodynamic state of a system can be realized by assigning different positions(x) and momenta(p) to the various molecules. Interpreted in this way, Boltzmann's formula is the most general formula for the thermodynamic entropy. However, Boltzmann's paradigm was an ideal gas of \"identical\" particles, of which formula_1 are in the -th microscopic condition (range) of position and momentum. For this case, the probability of each microstate of the system is equal, so it was equivalent for Boltzmann to calculate the number of microstates associated with a macrostate. was historically misinterpreted as literally meaning the number of microstates, and that is what it usually means today. can be counted using the formula for permutations\n\nwhere \"i\" ranges over all possible molecular conditions and denotes factorial. The \"correction\" in the denominator is due to the fact that identical particles in the same condition are indistinguishable. is sometimes called the \"thermodynamic probability\" since it is an integer greater than one, while mathematical probabilities are always numbers between zero and one.\n\nBoltzmann's formula applies to microstates of the universe as a whole, each possible microstate of which is presumed to be equally probable.\n\nBut in thermodynamics it is important to be able to make the approximation of dividing the universe into a system of interest, plus its surroundings; and then to be able to identify the entropy of the system with the system entropy in classical thermodynamics. The microstates of such a thermodynamic system are \"not\" equally probable—for example, high energy microstates are less probable than low energy microstates for a thermodynamic system kept at a fixed temperature by allowing contact with a heat bath.\nFor thermodynamic systems where microstates of the system may not have equal probabilities, the appropriate generalization, called the Gibbs entropy, is:\n\nThis reduces to equation () if the probabilities \"p\" are all equal.\n\nBoltzmann used a formula_2 formula as early as 1866. He interpreted as a density in phase space—without mentioning probability—but since this satisfies the axiomatic definition of a probability measure we can retrospectively interpret it as a probability anyway. Gibbs gave an explicitly probabilistic interpretation in 1878.\n\nBoltzmann himself used an expression equivalent to () in his later work and recognized it as more general than equation (). That is, equation () is a corollary of\nequation ()—and not vice versa. In every situation where equation () is valid,\nequation () is valid also—and not vice versa.\n\nThe term Boltzmann entropy is also sometimes used to indicate entropies calculated based on the approximation that the overall probability can be factored into an identical separate term for each particle—i.e., assuming each particle has an identical independent probability distribution, and ignoring interactions and correlations between the particles. This is exact for an ideal gas of identical particles, and may or may not be a good approximation for other systems.\n\nThe Boltzmann entropy is obtained if one assumes one can treat all the component particles of a thermodynamic system as statistically independent. The probability distribution of the system as a whole then factorises into the product of \"N\" separate identical terms, one term for each particle; and the Gibbs entropy simplifies to the Boltzmann entropy\n\nwhere the summation is taken over each possible state in the 6-dimensional phase space of a \"single\" particle (rather than the 6\"N\"-dimensional phase space of the system as a whole).\n\nThis reflects the original statistical entropy function introduced by Ludwig Boltzmann in 1872. For the special case of an ideal gas it exactly corresponds to the proper thermodynamic entropy.\n\nHowever, for anything but the most dilute of real gases, it leads to increasingly wrong predictions of entropies and physical behaviours, by ignoring the interactions and correlations between different molecules. Instead one must follow Gibbs, and consider the ensemble of states of the system as a whole, rather than single particle states.\n\n\n"}
{"id": "36641157", "url": "https://en.wikipedia.org/wiki?curid=36641157", "title": "California Clay Movement", "text": "California Clay Movement\n\nThe California Clay Movement (or American Clay Revolution) was a school of ceramic art that emerged in California in the 1950s.\nThe movement was part of the larger transition in crafts from \"designer-craftsman\" to \"artist-craftsman\".\nThe editor of \"Craft Horizons\", New York-based Rose Slivka, became an enthusiastic advocate of the movement.\n\nPeter Voulkos was one of the movement's driving forces.\nHe established the Ceramic Center at the Los Angeles County Art Institute (now the Otis College of Art and Design), \nwhere he created massive, abstract ceramic sculptures. He felt that his free-form ceramic works were like jazz compositions: improvisational and free spirited. Voulkos began creating ever larger ceramic works to break away from the conventional arts and crafts of his day. Some of his work, named \"plates\", \"ice buckets\" or \"tea bowls\", were \"deconstructed\" traditional forms of glazed pottery. Others, such as his \"stacks\", were non-utilitarian and purely sculptural. During a career that lasted almost half a century, Voulkos made over 200 \"stacks\", some as much as in height. \nWriting about the clay movement in 1963, a reviewer in \"Time\" said \"Peter Voulkos' rough, ragged monuments are powerful weapons against the slick coffee-table pottery that often passes for modern art, and already a generation of fierce West Coast individualists has joined him at the barricades.\"\n\nVoulkos profoundly influenced John Mason, Kenneth Price and Paul Soldner.\nVoulkos turned the Los Angeles County Art Institute into an important center for ceramic art between 1954 and 1959. Moving to the University of California in Berkeley he and sculptors such as Sidney Gordon and Harold Paris developed an influential school of sculpture. His pupils included Kenneth Price, Billy Al Bengston, Robert Arneson and Stan Bitters. The work of Voulkos, Arneson and others typified Californian art in the 1950s and 1960s, and was featured in many exhibitions.\n\nStephen De Staebler was another influential sculptor working mostly in clay and bronze who has been associated with the California Clay movement. A reviewer said of him that \"He practically invented his own art form by beating and buckling tons of clay into awesome mountainous landscapes, but his human sculptures are also very moving.\" Michael Frimkess is another master of the California clay movement. Frimkess was a student of Peter Voulkos, and adopted the abstract expressionist style of sculpture taught by Voulkos. In 2014, Frimkess received the Career Achievement Award from the Hammer Museum.\n\nVoulkos had huge influence, not just on potters and sculptors but even on painters.\nAwareness of the movement quickly spread. In 1959 the Guyanese artist Donald Locke obtained a grant to study for a master's degree in fine arts at Edinburgh College of Art, a school in the University of Edinburgh. There he met the artists Dave Cohen, Sheldon Kaganof and Dion Myers, who introduced the ideas of the California Clay Movement to Britain. For many years his work reflected their influence.\n\nCitations\n\nSources\n"}
{"id": "7706", "url": "https://en.wikipedia.org/wiki?curid=7706", "title": "Cartesian coordinate system", "text": "Cartesian coordinate system\n\nA Cartesian coordinate system is a coordinate system that specifies each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular directed lines, measured in the same unit of length. Each reference line is called a \"coordinate axis\" or just \"axis\" (plural \"axes\") of the system, and the point where they meet is its \"origin\", at ordered pair . The coordinates can also be defined as the positions of the perpendicular projections of the point onto the two axes, expressed as signed distances from the origin.\n\nOne can use the same principle to specify the position of any point in three-dimensional space by three Cartesian coordinates, its signed distances to three mutually perpendicular planes (or, equivalently, by its perpendicular projection onto three mutually perpendicular lines). In general, \"n\" Cartesian coordinates (an element of real \"n\"-space) specify the point in an \"n\"-dimensional Euclidean space for any dimension \"n\". These coordinates are equal, up to sign, to distances from the point to \"n\" mutually perpendicular hyperplanes.\n\nThe invention of Cartesian coordinates in the 17th century by René Descartes (Latinized name: \"Cartesius\") revolutionized mathematics by providing the first systematic link between Euclidean geometry and algebra. Using the Cartesian coordinate system, geometric shapes (such as curves) can be described by Cartesian equations: algebraic equations involving the coordinates of the points lying on the shape. For example, a circle of radius 2, centered at the origin of the plane, may be described as the set of all points whose coordinates \"x\" and \"y\" satisfy the equation .\n\nCartesian coordinates are the foundation of analytic geometry, and provide enlightening geometric interpretations for many other branches of mathematics, such as linear algebra, complex analysis, differential geometry, multivariate calculus, group theory and more. A familiar example is the concept of the graph of a function. Cartesian coordinates are also essential tools for most applied disciplines that deal with geometry, including astronomy, physics, engineering and many more. They are the most common coordinate system used in computer graphics, computer-aided geometric design and other geometry-related data processing.\n\nThe adjective \"Cartesian\" refers to the French mathematician and philosopher René Descartes who published this idea in 1637. It was independently discovered by Pierre de Fermat, who also worked in three dimensions, although Fermat did not publish the discovery. The French cleric Nicole Oresme, used constructions similar to Cartesian coordinates well before the time of Descartes and Fermat.\n\nBoth Descartes and Fermat used a single axis in their treatments and have a variable length measured in reference to this axis. The concept of using a pair of axes was introduced later, after Descartes' \"La Géométrie\" was translated into Latin in 1649 by Frans van Schooten and his students. These commentators introduced several concepts while trying to clarify the ideas contained in Descartes' work.\n\nThe development of the Cartesian coordinate system would play a fundamental role in the development of the calculus by Isaac Newton and Gottfried Wilhelm Leibniz. The two-coordinate description of the plane was later generalized into the concept of vector spaces.\n\nMany other coordinate systems have been developed since Descartes, such as the polar coordinates for the plane, and the spherical and cylindrical coordinates for three-dimensional space.\n\nChoosing a Cartesian coordinate system for a one-dimensional space that is, for a straight line—involves choosing a point \"O\" of the line (the origin), a unit of length, and an orientation for the line. An orientation chooses which of the two half-lines determined by \"O\" is the positive, and which is negative; we then say that the line \"is oriented\" (or \"points\") from the negative half towards the positive half. Then each point \"P\" of the line can be specified by its distance from \"O\", taken with a + or − sign depending on which half-line contains \"P\".\n\nA line with a chosen Cartesian system is called a number line. Every real number has a unique location on the line. Conversely, every point on the line can be interpreted as a number in an ordered continuum such as the real numbers.\n\nA Cartesian coordinate system in two dimensions (also called a rectangular coordinate system or an orthogonal coordinate system) is defined by an ordered pair of perpendicular lines (axes), a single unit of length for both axes, and an orientation for each axis. The point where the axes meet is taken as the origin for both, thus turning each axis into a number line. For any point \"P\", a line is drawn through \"P\" perpendicular to each axis, and the position where it meets the axis is interpreted as a number. The two numbers, in that chosen order, are the \"Cartesian coordinates\" of \"P\". The reverse construction allows one to determine the point \"P\" given its coordinates.\n\nThe first and second coordinates are called the \"abscissa\" and the \"ordinate\" of \"P\", respectively; and the point where the axes meet is called the \"origin\" of the coordinate system. The coordinates are usually written as two numbers in parentheses, in that order, separated by a comma, as in . Thus the origin has coordinates , and the points on the positive half-axes, one unit away from the origin, have coordinates and .\n\nIn mathematics, physics, and engineering, the first axis is usually defined or depicted as horizontal and oriented to the right, and the second axis is vertical and oriented upwards. (However, in some computer graphics contexts, the ordinate axis may be oriented downwards.) The origin is often labeled \"O\", and the two coordinates are often denoted by the letters \"X\" and \"Y\", or \"x\" and \"y\". The axes may then be referred to as the \"X\"-axis and \"Y\"-axis. The choices of letters come from the original convention, which is to use the latter part of the alphabet to indicate unknown values. The first part of the alphabet was used to designate known values. \n\nA Euclidean plane with a chosen Cartesian coordinate system \"Cartesian plane\". In a Cartesian plane one can define canonical representatives of certain geometric figures, such as the unit circle (with radius equal to the length unit, and center at the origin), the unit square (whose diagonal has endpoints at and ), the unit hyperbola, and so on.\n\nThe two axes divide the plane into four right angles, called \"quadrant\". The quadrants may be named or numbered in various ways, but the quadrant where all coordinates are positive is usually called the \"first quadrant\".\n\nIf the coordinates of a point are , then its distances from the \"X\"-axis and from the \"Y\"-axis are |\"y\"| and |\"x\"|, respectively; where |...| denotes the absolute value of a number.\n\nA Cartesian coordinate system for a three-dimensional space consists of an ordered triplet of lines (the \"axes\") that go through a common point (the \"origin\"), and are pair-wise perpendicular; an orientation for each axis; and a single unit of length for all three axes. As in the two-dimensional case, each axis becomes a number line. For any point \"P\" of space, one considers a plane through \"P\" perpendicular to each coordinate axis, and interprets the point where that plane cuts the axis as a number. The Cartesian coordinates of \"P\" are those three numbers, in the chosen order. The reverse construction determines the point \"P\" given its three coordinates.\n\nAlternatively, each coordinate of a point \"P\" can be taken as the distance from \"P\" to the plane defined by the other two axes, with the sign determined by the orientation of the corresponding axis. \n\nEach pair of axes defines a \"coordinate plane\". These planes divide space into eight trihedra, called \"octants\".\n\nThe coordinates are usually written as three numbers (or algebraic formulas) surrounded by parentheses and separated by commas, as in or . Thus, the origin has coordinates , and the unit points on the three axes are , , and .\n\nThere are no standard names for the coordinates in the three axes (however, the terms \"abscissa\", \"ordinate\" and \"applicate\" are sometimes used). The coordinates are often denoted by the letters \"X\", \"Y\", and \"Z\" (or \"x\", \"y\", and \"z\"), in which case the lines are called the \"X\"-, \"Y\"-, and \"Z\"-axis, respectively. Then the coordinate planes can be referred to as the \"XY\"-, \"YZ\"-, and \"XZ\"-planes.\n\nIn mathematics, physics, and engineering contexts, the first two axes are often defined or depicted as horizontal, with the third axis pointing up. In that case the third coordinate may be called \"height\" or \"altitude\". The orientations are usually chosen so that the 90 degree angle from the first axis to the second axis looks counter-clockwise when seen from the point ; a convention that is commonly called \"the right hand rule\".\n\nA Euclidean plane with a chosen Cartesian system is called a Cartesian plane. Since Cartesian coordinates are unique and non-ambiguous, the points of a Cartesian plane can be identified with pairs of real numbers; that is with the Cartesian product formula_1, where formula_2 is the set of all reals. In the same way, the points in any Euclidean space of dimension \"n\" be identified with the tuples (lists) of \"n\" real numbers, that is, with the Cartesian product formula_3.\n\nThe concept of Cartesian coordinates generalizes to allow axes that are not perpendicular to each other, and/or different units along each axis. In that case, each coordinate is obtained by projecting the point onto one axis along a direction that is parallel to the other axis (or, in general, to the hyperplane defined by all the other axes). In such an oblique coordinate system the computations of distances and angles must be modified from that in standard Cartesian systems, and many standard formulas (such as the Pythagorean formula for the distance) do not hold (see affine plane).\n\nThe Cartesian coordinates of a point are usually written in parentheses and separated by commas, as in or . The origin is often labelled with the capital letter \"O\". In analytic geometry, unknown or generic coordinates are often denoted by the letters (\"x\", \"y\") in the plane, and (\"x\", \"y\", \"z\") in three-dimensional space. This custom comes from a convention of algebra, which uses letters near the end of the alphabet for unknown values (such as were the coordinates of points in many geometric problems), and letters near the beginning for given quantities.\n\nThese conventional names are often used in other domains, such as physics and engineering, although other letters may be used. For example, in a graph showing how a pressure varies with time, the graph coordinates may be denoted \"p\" and \"t\". Each axis is usually named after the coordinate which is measured along it; so one says the \"x-axis\", the \"y-axis\", the \"t-axis\", etc.\n\nAnother common convention for coordinate naming is to use subscripts, as (\"x\", \"x\", ..., \"x\") for the \"n\" coordinates in an \"n\"-dimensional space, especially when \"n\" is greater than 3 or unspecified. Some authors prefer the numbering (\"x\", \"x\", ..., \"x\"). These notations are especially advantageous in computer programming: by storing the coordinates of a point as an array, instead of a record, the subscript can serve to index the coordinates.\n\nIn mathematical illustrations of two-dimensional Cartesian systems, the first coordinate (traditionally called the abscissa) is measured along a horizontal axis, oriented from left to right. The second coordinate (the ordinate) is then measured along a vertical axis, usually oriented from bottom to top. Young children learning the Cartesian system, commonly learn the order to read the values before cementing the \"x\"-, \"y\"-, and \"z\"-axis concepts, by starting with 2D mnemonics (e.g. 'Walk along the hall then up the stairs' akin to straight across the \"x\"-axis then up vertically along the \"y\"-axis).\n\nComputer graphics and image processing, however, often use a coordinate system with the \"y\"-axis oriented downwards on the computer display. This convention developed in the 1960s (or earlier) from the way that images were originally stored in display buffers.\n\nFor three-dimensional systems, a convention is to portray the \"xy\"-plane horizontally, with the \"z\"-axis added to represent height (positive up). Furthermore, there is a convention to orient the \"x\"-axis toward the viewer, biased either to the right or left. If a diagram (3D projection or 2D perspective drawing) shows the \"x\"- and \"y\"-axis horizontally and vertically, respectively, then the \"z\"-axis should be shown pointing \"out of the page\" towards the viewer or camera. In such a 2D diagram of a 3D coordinate system, the \"z\"-axis would appear as a line or ray pointing down and to the left or down and to the right, depending on the presumed viewer or camera perspective. In any diagram or display, the orientation of the three axes, as a whole, is arbitrary. However, the orientation of the axes relative to each other should always comply with the right-hand rule, unless specifically stated otherwise. All laws of physics and math assume this right-handedness, which ensures consistency.\n\nFor 3D diagrams, the names \"abscissa\" and \"ordinate\" are rarely used for \"x\" and \"y\", respectively. When they are, the \"z\"-coordinate is sometimes called the applicate. The words \"abscissa\", \"ordinate\" and \"applicate\" are sometimes used to refer to coordinate axes rather than the coordinate values.\n\nThe axes of a two-dimensional Cartesian system divide the plane into four infinite regions, called quadrants, each bounded by two half-axes. These are often numbered from 1st to 4th and denoted by Roman numerals: I (where the signs of the two coordinates are I (+,+), II (−,+), III (−,−), and IV (+,−). When the axes are drawn according to the mathematical custom, the numbering goes counter-clockwise starting from the upper right (\"north-east\") quadrant.\n\nSimilarly, a three-dimensional Cartesian system defines a division of space into eight regions or octants, according to the signs of the coordinates of the points. The convention used for naming a specific octant is to list its signs, e.g. or . The generalization of the quadrant and octant to an arbitrary number of dimensions is the orthant, and a similar naming system applies.\n\nThe Euclidean distance between two points of the plane with Cartesian coordinates formula_4 and formula_5 is\n\nThis is the Cartesian version of Pythagoras's theorem. In three-dimensional space, the distance between points formula_7 and formula_8 is\n\nwhich can be obtained by two consecutive applications of Pythagoras' theorem.\n\nThe Euclidean transformations or Euclidean motions are the (bijective) mappings of points of the Euclidean plane to themselves which preserve distances between points. There are four types of these mappings (also called isometries): translations, rotations, reflections and glide reflections.\n\nTranslating a set of points of the plane, preserving the distances and directions between them, is equivalent to adding a fixed pair of numbers to the Cartesian coordinates of every point in the set. That is, if the original coordinates of a point are , after the translation they will be\n\nTo rotate a figure counterclockwise around the origin by some angle formula_11 is equivalent to replacing every point with coordinates (\"x\",\"y\") by the point with coordinates (\"x<nowiki>'</nowiki>\",\"y<nowiki>'</nowiki>\"), where\n\nThus:\n\nformula_14\n\nIf are the Cartesian coordinates of a point, then are the coordinates of its reflection across the second coordinate axis (the y-axis), as if that line were a mirror. Likewise, are the coordinates of its reflection across the first coordinate axis (the x-axis). In more generality, reflection across a line through the origin making an angle formula_11 with the x-axis, is equivalent to replacing every point with coordinates by the point with coordinates , where\n\nThus:\nformula_18\n\nA glide reflection is the composition of a reflection across a line followed by a translation in the direction of that line. It can be seen that the order of these operations does not matter (the translation can come first, followed by the reflection).\n\nThese Euclidean transformations of the plane can all be described in a uniform way by using matrices. The result formula_19 of applying a Euclidean transformation to a point formula_20 is given by the formula\n\nwhere \"A\" is a 2×2 orthogonal matrix and is an arbitrary ordered pair of numbers; that is,\n\nwhere\n\nTo be \"orthogonal\", the matrix \"A\" must have orthogonal rows with same Euclidean length of one, that is,\n\nand\n\nThis is equivalent to saying that \"A\" times its transpose must be the identity matrix. If these conditions do not hold, the formula describes a more general affine transformation of the plane provided that the determinant of \"A\" is not zero.\n\nThe formula defines a translation if and only if \"A\" is the identity matrix. The transformation is a rotation around some point if and only if \"A\" is a rotation matrix, meaning that\n\nA reflection or glide reflection is obtained when,\n\nAssuming that translation is not used transformations can be combined by simply multiplying the associated transformation matrices.\n\nAnother way to represent coordinate transformations in Cartesian coordinates is through affine transformations. In affine transformations an extra dimension is added and all points are given a value of 1 for this extra dimension. The advantage of doing this is that point translations can be specified in the final column of matrix \"A\". In this way, all of the euclidean transformations become transactable as matrix point multiplications. The affine transformation is given by:\n\nUsing affine transformations multiple different euclidean transformations including translation can be combined by simply multiplying the corresponding matrices.\n\nAn example of an affine transformation which is not a Euclidean motion is given by scaling. To make a figure larger or smaller is equivalent to multiplying the Cartesian coordinates of every point by the same positive number \"m\". If are the coordinates of a point on the original figure, the corresponding point on the scaled figure has coordinates\n\nIf \"m\" is greater than 1, the figure becomes larger; if \"m\" is between 0 and 1, it becomes smaller.\n\nA shearing transformation will push the top of a square sideways to form a parallelogram. Horizontal shearing is defined by:\n\nShearing can also be applied vertically:\n\nFixing or choosing the \"x\"-axis determines the \"y\"-axis up to direction. Namely, the \"y\"-axis is necessarily the perpendicular to the \"x\"-axis through the point marked 0 on the \"x\"-axis. But there is a choice of which of the two half lines on the perpendicular to designate as positive and which as negative. Each of these two choices determines a different orientation (also called \"handedness\") of the Cartesian plane.\n\nThe usual way of orienting the axes, with the positive \"x\"-axis pointing right and the positive \"y\"-axis pointing up (and the \"x\"-axis being the \"first\" and the \"y\"-axis the \"second\" axis) is considered the \"positive\" or \"standard\" orientation, also called the \"right-handed\" orientation.\n\nA commonly used mnemonic for defining the positive orientation is the \"right-hand rule\". Placing a somewhat closed right hand on the plane with the thumb pointing up, the fingers point from the \"x\"-axis to the \"y\"-axis, in a positively oriented coordinate system.\n\nThe other way of orienting the axes is following the \"left hand rule\", placing the left hand on the plane with the thumb pointing up.\n\nWhen pointing the thumb away from the origin along an axis towards positive, the curvature of the fingers indicates a positive rotation along that axis.\n\nRegardless of the rule used to orient the axes, rotating the coordinate system will preserve the orientation. Switching any two axes will reverse the orientation, but switching both will leave the orientation unchanged.\n\nOnce the \"x\"- and \"y\"-axes are specified, they determine the line along which the \"z\"-axis should lie, but there are two possible directions on this line. The two possible coordinate systems which result are called 'right-handed' and 'left-handed'. The standard orientation, where the \"xy\"-plane is horizontal and the \"z\"-axis points up (and the \"x\"- and the \"y\"-axis form a positively oriented two-dimensional coordinate system in the \"xy\"-plane if observed from \"above\" the \"xy\"-plane) is called right-handed or positive.\n\nThe name derives from the right-hand rule. If the index finger of the right hand is pointed forward, the middle finger bent inward at a right angle to it, and the thumb placed at a right angle to both, the three fingers indicate the relative directions of the \"x\"-, \"y\"-, and \"z\"-axes in a \"right-handed\" system. The thumb indicates the \"x\"-axis, the index finger the \"y\"-axis and the middle finger the \"z\"-axis. Conversely, if the same is done with the left hand, a left-handed system results.\n\nFigure 7 depicts a left and a right-handed coordinate system. Because a three-dimensional object is represented on the two-dimensional screen, distortion and ambiguity result. The axis pointing downward (and to the right) is also meant to point \"towards\" the observer, whereas the \"middle\"-axis is meant to point \"away\" from the observer. The red circle is \"parallel\" to the horizontal \"xy\"-plane and indicates rotation from the \"x\"-axis to the \"y\"-axis (in both cases). Hence the red arrow passes \"in front of\" the \"z\"-axis.\n\nFigure 8 is another attempt at depicting a right-handed coordinate system. Again, there is an ambiguity caused by projecting the three-dimensional coordinate system into the plane. Many observers see Figure 8 as \"flipping in and out\" between a convex cube and a concave \"corner\". This corresponds to the two possible orientations of the coordinate system. Seeing the figure as convex gives a left-handed coordinate system. Thus the \"correct\" way to view Figure 8 is to imagine the \"x\"-axis as pointing \"towards\" the observer and thus seeing a concave corner.\nA point in space in a Cartesian coordinate system may also be represented by a position vector, which can be thought of as an arrow pointing from the origin of the coordinate system to the point. If the coordinates represent spatial positions (displacements), it is common to represent the vector from the origin to the point of interest as formula_33. In two dimensions, the vector from the origin to the point with Cartesian coordinates (x, y) can be written as:\n\nwhere formula_35, and formula_36 are unit vectors in the direction of the \"x\"-axis and \"y\"-axis respectively, generally referred to as the \"standard basis\" (in some application areas these may also be referred to as versors). Similarly, in three dimensions, the vector from the origin to the point with Cartesian coordinates formula_37 can be written as:\n\nwhere formula_39 is the unit vector in the direction of the z-axis.\n\nThere is no \"natural\" interpretation of multiplying vectors to obtain another vector that works in all dimensions, however there is a way to use complex numbers to provide such a multiplication. In a two dimensional cartesian plane, identify the point with coordinates with the complex number . Here, i is the imaginary unit and is identified with the point with coordinates , so it is not the unit vector in the direction of the \"x\"-axis. Since the complex numbers can be multiplied giving another complex number, this identification provides a means to \"multiply\" vectors. In a three dimensional cartesian space a similar identification can be made with a subset of the quaternions.\n\nCartesian coordinates are an abstraction that have a multitude of possible applications in the real world. However, three constructive steps are involved in superimposing coordinates on a problem application. 1) Units of distance must be decided defining the spatial size represented by the numbers used as coordinates. 2) An origin must be assigned to a specific spatial location or landmark, and 3) the orientation of the axes must be defined using available directional cues for all but one axis.\n\nConsider as an example superimposing 3D Cartesian coordinates over all points on the Earth (i.e. geospatial 3D). What units make sense? Kilometers are a good choice, since the original definition of the kilometer was geospatial...10 000 km equalling the surface distance from the Equator to the North Pole. Where to place the origin? Based on symmetry, the gravitational center of the Earth suggests a natural landmark (which can be sensed via satellite orbits). Finally, how to orient X-, Y- and Z-axis directions? The axis of Earth's spin provides a natural direction strongly associated with \"up vs. down\", so positive Z can adopt the direction from geocenter to North Pole. A location on the Equator is needed to define the X-axis, and the prime meridian stands out as a reference direction, so the X-axis takes the direction from geocenter out to [ 0 degrees longitude, 0 degrees latitude ]. Note that with 3 dimensions, and two perpendicular axes directions pinned down for X and Z, the Y-axis is determined by the first two choices. In order to obey the right-hand rule, the Y-axis must point out from the geocenter to [ 90 degrees longitude, 0 degrees latitude ]. So what are the geocentric coordinates of the Empire State Building in New York City? Using [ longitude = −73.985656, latitude = 40.748433 ], Earth radius = 40,000/2π, and transforming from spherical --> Cartesian coordinates, you can estimate the geocentric coordinates of the Empire State Building, [ \"x\", \"y\", \"z\" ] = [ 1330.53 km, –4635.75 km, 4155.46 km ]. GPS navigation relies on such geocentric coordinates.\n\nIn engineering projects, agreement on the definition of coordinates is a crucial foundation. One cannot assume that coordinates come predefined for a novel application, so knowledge of how to erect a coordinate system where there is none is essential to applying René Descartes' ingenious thinking.\n\nWhile spatial apps employ identical units along all axes, in business and scientific apps, each axis may have different units of measurement associated with it (such as kilograms, seconds, pounds, etc.). Although four- and higher-dimensional spaces are difficult to visualize, the algebra of Cartesian coordinates can be extended relatively easily to four or more variables, so that certain calculations involving many variables can be done. (This sort of algebraic extension is what is used to define the geometry of higher-dimensional spaces.) Conversely, it is often helpful to use the geometry of Cartesian coordinates in two or three dimensions to visualize algebraic relationships between two or three of many non-spatial variables.\n\nThe graph of a function or relation is the set of all points satisfying that function or relation. For a function of one variable, \"f\", the set of all points , where is the graph of the function \"f\". For a function \"g\" of two variables, the set of all points , where is the graph of the function \"g\". A sketch of the graph of such a function or relation would consist of all the salient parts of the function or relation which would include its relative extrema, its concavity and points of inflection, any points of discontinuity and its end behavior. All of these terms are more fully defined in calculus. Such graphs are useful in calculus to understand the nature and behavior of a function or relation.\n\n\n\n\n"}
{"id": "2341665", "url": "https://en.wikipedia.org/wiki?curid=2341665", "title": "Charivari", "text": "Charivari\n\nCharivari (or shivaree or chivaree) or Skimmington (or skimmington ride in England; ) are terms for a folk custom in which a mock parade was staged through a community accompanied by a discordant mock serenade. Since the crowd aimed to make as much noise as possible by beating on pots and pans or anything that came to hand these parades are often referred to as rough music. Parades were of three types. In the first, and generally most violent form, a wrongdoer or wrongdoers might be dragged from their home or place of work and paraded by force through a community. In the process they were subject to the derision of the crowd, they might be pelted and frequently a victim or victims were ducked at the end of the proceedings. A safer form involved a neighbour of the wrongdoer impersonating the victim whilst being carried through the streets. The impersonator was obviously not himself punished and he often cried out or sang ribald verses mocking the wrongdoer. In the common form an effigy was employed instead, abused and often burnt at the end of the proceedings.\n\nCommunities used \"rough music\" to express their disapproval of different types of violation of community norms. For example, they might target marriages of which they disapproved such as a union between an older widower and much younger woman, or the too early remarriage by a widow or widower. Villages also used charivari in cases of adulterous relationships, against wife beaters, and unmarried mothers. It was also used as a form of shaming upon husbands who were beaten by their wives and had not stood up for themselves. In some cases, the community disapproved of any remarriage by older widows or widowers. \"Charivari\" is the original French word, and in Canada it is used by both English and French speakers. \"Chivaree\" became the common variant in Ontario, Canada. In the United States, the term \"shivaree\" is more common.\n\nAs species of popular justice rituals Charivaric events were carefully planned and they were often staged at times of traditional festivity thereby blending delivering justice and celebration. Women seem to have been particularly prominent in both organising and participating in such events which usually began with the crowd gathering (pubs or taverns were a common meeting point) and then marching to the homes of the accused.\n\nThe origin of the word \"charivari\" is likely from the Vulgar Latin \"caribaria\", plural of \"caribarium\", already referring to the custom of rattling kitchenware with an iron rod, itself probably from the Greek καρηβαρία (karēbaría), literally \"heaviness in the head\" but also used to mean \"headache\", from κάρα \"head\" and βαρύς \"heavy\". In any case, the tradition has been practised for at least 700 years. An engraving in the early 14th-century French manuscript, \"Roman de Fauvel\", shows a charivari underway.\n\nSo-called \"Rough Music\" practices in England were known by many regional or local designations. In the North the most commonly employed term was \"stang riding\", a stang being a long pole carried on the shoulders of two men between which an object or a person could be mounted. In the South, the term skimmington, or skimmington ride, was most commonly employed, a skimmington being a type of large wooden ladle with which an unruly wife might beat her husband. Other terms include \"lewbelling\", \"tin-panning\", \"ran tanning\", a \"nominey\" or \"wooset\". Where effigies of the \"wrongdoers\" were made they were frequently burned as the climax of the event (as the inscription on the Rampton photograph indicates) or \"ritually drowned\" (thrown into a pond or river).\n\nThe very essence of the practice was public humiliation of the victim under the eyes of their neighbours Rough music practices were irregularly scattered throughout English communities in the nineteenth century. In the twentieth they declined but endured in a few places, such as Rampton, Nottinghamshire (1909), Middleton Cheney (1909) and Blisworth (1920s and 1936), Northamptonshire. There were in fact some examples after the Second World War at West Hoathley in Sussex in 1947 and Copthorne Sussex around 1951 and an attempt at traditional rough music practice was last documented by the folklorist Theo Brown in a Devonshire village around 1973.\n\nNoisy, masked processions were held outside the home of the supposed wrongdoer, involving the cacophonous rattling of bones and cleavers, the ringing of bells, hooting, blowing bull's horns, the banging of frying pans, saucepans, kettles, or other kitchen or barn implements with the intention of creating long-lasting embarrassment to the alleged perpetrator. During a rough music performance, the victim could be displayed upon a pole or donkey (in person or as an effigy), their \"crimes\" becoming the subject of mime, theatrical performances or recitatives, along with a litany of obscenities and insults. Alternatively, one of the participants would \"ride the stang\" (a pole carried between the shoulders of two or more men or youths) while banging an old kettle or pan with a stick and reciting a rhyme (called a \"nominy\") such as the following:\n\nRough music processions are well attested in the medieval period as punishments for violations of the assumed gender norms. Men who had allowed themselves to be dominated by their shrewish wives were liable to be targeted and a frieze from Montecute House, an Eizabethan Manor in Somerset depicts just such an occurrence. However, in the nineteenth century the practice seems to have been somewhat refocused; whilst in the early period rough music was often used against men who had failed to assert their authority over their wives, by the end of the nineteenth century it was mostly targeted against men who had exceeded their authority by beating them. Thus, in contrast to the verses above referring to a shrewish wife there were also songs referring to the use of rough music as a protection for wives.\n\nRough music song originating from South Stoke, Oxfordshire:\n\nThe participants were generally young men temporarily bestowed with the power of rule over the everyday affairs of the community. As above, issues of sexuality and domestic hierarchy most often formed the pretexts for rough music, including acts of domestic violence or child abuse. However, rough music was also used as a sanction against those who committed certain species of economic crimes such as blocking footpaths, preventing traditional gleaning or profiteering at times of poor harvests. Occupational groups, such as butchers, employed rough music against others in the same trade who refused to abide by the commonly agreed labour customs.\n\nRough music practices would often be repeated for three or up to seven nights in a row. Many victims fled their communities and cases of suicide are not unknown. As forms of vigilantism that were likely to lead to public disorder, ran-tanning and similar activities were banned under the Highways Act of 1882.\n\nSkimmingtons are recorded in England in early medieval times and they are recorded in colonial America from around the 1730s. The term is particularly associated with the West Country region of England and, although the etymology is not certain, it has been suggested that it derived from the ladle used in that region for cheesemaking, which was perceived as a weapon used by a woman to beat a weak or henpecked husband. The rationale for a skimmington varied, but one major theme was disapproval of a man for weakness in his relationship with his wife. A description of the custom in 1856 cites three main targets: a man who is worsted by his wife in a quarrel; a cuckolded man who accepts his wife's adultery; and any married person who engages in licentious conduct. To \"ride such a person skimmington\" involved exposing them or their effigy to ridicule on a cart, or on the back of a horse or donkey. Some accounts describe the participants as carrying ladles and spoons with which to beat each other, at least in the case of skimmingtons prompted by marital discord. The noisy parade passed through the neighbourhood, and served as a punishment to the offender and a warning to others to abide by community norms; Roberts suggests that the homes of other potential victims were visited in a pointed manner during a skimmington. According to one citation, a skimmington was broken up by the police in a village in Dorset as late as 1917; and incidents have been reported from the 1930s, the 1950s and perhaps even the 1970s.\n\nThe antiquary and lexicographer Francis Grose described a skimmington as: \"Saucepans, frying-pans, poker and tongs, marrow-bones and cleavers, bulls horns, etc. beaten upon and sounded in ludicrous processions\" \"(A Classical Dictionary of the Vulgar Tongue\", 1796).\n\nIn Warwickshire, the custom was known as \"loo-belling\", and in northern England as \"riding the stang\". Other names given to this or similar customs were \"rough-musicking\" and \"hussitting\" (said to be a reference to the Hussites or followers of John Huss).\n\nDuring the Western Rising of 1628–31, which was a rebellion in south-west England against the enclosure of royal forest lands, the name \"Lady Skimmington\" was adopted by the leader of the protest movement. According to some sources the name was used by a number of men involved with the Western Rising, who dressed in women's clothes not only as a method of disguise, but also in order to symbolise their protest against a breach of the established order.\n\nMany folk customs around the world have involved making loud noises to scare away evil spirits.\n\nTuneless, cacophonous \"rough music\", played on horns, bugles, whistles, tin trays and frying pans, was a feature of the custom known as \"Teddy Rowe's Band\". This had taken place annually, possibly for several centuries, in the early hours of the morning, to herald the start of Pack Monday Fair at Sherborne, Dorset, until it was banned by the police in 1964 because of hooliganism the previous year. The fair is still held, on the first Monday after Old Michaelmas Day (10 October) – St Michael's Day in the Old Style calendar.\n\nThe \"Tin Can Band\" at Broughton, Northamptonshire, a seasonal custom, takes place at midnight on the third Sunday in December. The participants march around the village for about an hour, rattling pans, dustbin lids, kettles and anything else that will make a noise. The council once attempted to stop the tin-canning; participants were summoned and fined, but a dance was organised to raise money to pay the fines and the custom continues. The village is sufficiently proud of its custom for it to feature on the village sign.\n\nEquivalents include the German and , Italian and French .\n\nThe custom has been documented back to the Middle Ages but it is likely that it was traditional before that. It was first recorded in France, as a regular wedding activity to celebrate the nuptials at some point after the vows had been taken. But charivari achieved its greatest importance as it became transformed into a form of community censure against socially unacceptable marriages; for example, the marriage of widows before the end of the customary social period of formal mourning. In the early 17th century at the Council of Tours, the Catholic Church forbade the ritual of charivari and threatened its practitioners with excommunication. It did not want the community taking on the judgment and punishment of parishioners. But the custom continued in rural areas.\n\nThe charivari as celebration was a custom initially practised by the upper classes, but as time went on, the lower classes also participated and often looked forward to the next opportunity to join in. The two main purposes of the charivari in Europe were to facilitate change in the current social structure and to act as a form of censure within the community. The goal was to enforce social standards and to rid the community of socially unacceptable relationships that threatened the stability of the whole.\n\nIn Europe various types of charivari took place that differed from similar practices in other parts of the world. For example, the community might conduct a stag hunt against adulterers by creating a mock chase of human \"stags\" by human \"hounds\". The hounds would pursue the stags (that is, those who were committing the adulterous relationship) and dispense animal blood on their doorsteps. European charivaris were highly provocative, leading to overt public humiliation. The people used them to acknowledge and correct misbehaviour. In other parts of the world, similar public rituals around nuptials were practised mostly for celebration.\n\nHumiliation was the most common consequence of the European charivari. The acts which victims endured were forms of social ostracism often so embarrassing that they would leave the community for places where they were not known. Sometimes the charivari resulted in murder or suicide. Examples from the south of France include five cases of a charivari victim's firing on his accusers: these incidents resulted in two people being blinded and three killed. Some victims committed suicide, unable to recover from the public humiliation and social exclusion.\n\nIt is possible that the blowing of car horns after weddings in France (and indeed in many European countries) today is a holdover from the charivari of the past.\n\nCharivari has been practised in much of the United States, but it was most frequent on the frontier, where communities were small and more formal enforcement was lacking. It was documented into the early 20th century, but was thought to have mostly died out by mid century. In Canada, charivaris have occurred in Ontario, Quebec, and the Atlantic provinces, but not always as an expression of disapproval.\n\nThe early French colonists took the custom of charivari (or \"shivaree\" in the United States) to their settlements in Quebec. Some historians believe the custom spread to English-speaking areas of Lower Canada and eventually into the American South, but it was independently common in English society, so was likely to be part of Anglo-American customs. Charivari is well documented in the Hudson Valley from the earliest days of English settlers through the early 1900s. The earliest documented examples of Canadian charivari were in Quebec in the mid-17th century. One of the most notable was on June 28, 1683. After the widow of François Vézier dit Laverdure remarried only three weeks after her husband’s death, people of Quebec City conducted a loud and strident charivari against the newlyweds at their home.\n\nAs practised in North America, the charivari tended to be less extreme and punitive than the traditional European custom. Each was unique and heavily influenced by the standing of the family involved, as well as who was participating. While embellished with some European traditions, in a North American charivari participants might throw the culprits into horse tanks or force them to buy candy bars for the crowd.\n\nThis account from an American charivari in Kansas exemplifies the North American attitude. In contrast to punitive charivari in small villages in Europe, meant to ostracize and isolate the evildoers, North American charivaris were used as \"unifying rituals\", in which those in the wrong were brought back into the community after what might amount to a minor hazing. In some communities the ritual served as a gentle spoof of the newlyweds, intended to disrupt for a while any sexual activities that might be under way. In parts of the midwest US, such as Kansas, in the mid 1960-1970s, shivaree customs continued as good natured wedding humour along the lines of the musical \"Oklahoma!\". Rituals included wheeling the bride about in a wheelbarrow or tying cowbells under a wedding bed.\n\nIn Tampa, Florida in September 1885, a large chivaree was held on the occasion of local official James T. Magbee's wedding. According to historian Kyle S. Vanlandingham, the party was \"the wildest and noisiest of all the chivaree parties in Tampa's history,\" attended by \"several hundred\" men and lasting \"until near daylight.\" The music produced during the chivaree was reportedly \"hideous and unearthly beyond description.\"\n\nCharivari is believed to have inspired the development of the Acadian tradition of Tintamarre.\n\nThe use of excessive noise was a universal practice in association with variations in the custom. Loud singing and chanting were common in Europe, including England, and throughout North America. For an 1860 English charivari against a wife-beater, someone wrote an original chant which the crowd was happy to adopt:\n\nIn Europe the noise, songs, and chants had special meanings for the crowd. For adulterers, the songs represented the community’s disgust. For a too-early remarriage of a widow or widower, the noises symbolized the scream of the late husband or wife in the night.\n\nPerhaps the most common usage of the word today is in relation to circus performances, where a 'charivari' is a type of show opening that sees a raucous tumble of clowns and other performers into the playing space. This is the most common form of entrance used in today's classical circus, whereas the two and three-ring circuses of the last century usually preferred a parade, or a 'spec'.\n\nCharivari was sometimes called \"riding the 'stang\", when the target was a man who had been subject to scolding, beating, or other abuse from his wife. The man was made to \"ride the 'stang\", which meant that he was placed backwards on a horse, mule or ladder and paraded through town to be mocked, while people banged pots and pans.\n\nThe charivari was used to belittle those who could not or would not consummate their marriage. In the mid-16th century, historic records attest to a charivari against Martin Guerre in the small village of Artigat in the French Pyrenees for that reason. After he married at the age of 14, his wife did not get pregnant for eight years, so villagers ridiculed him. Later in his life, another man took over Guerre's identity and life. The trial against the impostor was what captured the events for history. In the 20th century, the events formed the basis of a French film, \"Le Retour de Martin Guerre\" (1982) and the history, \"The Return of Martin Guerre\", by the American history professor Natalie Zemon Davis.\n\nWith the charivari widely practised among rural villagers across Europe, the term and practice were part of common culture. Over time, the word was applied to other items. In Bavaria, \"charivari\" was adopted as the name for the silver ornaments worn with Lederhosen; the items consist of small trophies from game, like teeth from wild boar, or deer, jaws and fangs from foxes and various marters, feathers and claws from jaybirds and bird of prey. A Bavarian Charivari resembles the so-called \"chatelaine,\" a women's ornament consisting of a silver chain with numerous pendants like a mini silver box of needles, a small pair of scissors, a tiny bottle of perfume, etc..\n\nIn the Philippines, the term \"Charivari\" is used by the Revised Penal Code for a type of criminalised public disorder. Defined in Article 155 as a medley of discordant voices, it is classed under alarm and scandal and is a punishable by a fine.\n\nCharivari would later be taken up by composers of the French Baroque tradition as a 'rustic' or 'pastoral' character piece. Notable examples are those of the renowned viola da gamba virtuoso Marin Marais in his five collections of pieces for the \"basse de viole\" and continuo. Some are quite advanced and difficult and subsequently evoke the title's origins.\n\nThe British period instrument/early music ensemble, Charivari Agréable (founded in 1993), states that their name translates as, \"'pleasant tumult' (from Saint-Lambert’s 1707 treatise on accompaniment)\".\n\n\n\n\n\n\n"}
{"id": "10109665", "url": "https://en.wikipedia.org/wiki?curid=10109665", "title": "Chilton and Colburn J-factor analogy", "text": "Chilton and Colburn J-factor analogy\n\nChilton–Colburn J-factor analogy is a successful and widely used analogy between heat, momentum, and mass transfer. The basic mechanisms and mathematics of heat, mass, and momentum transport are essentially the same. Among many analogies (like Reynolds analogy, Prandtl–Taylor analogy) developed to directly relate heat transfer coefficients, mass transfer coefficients, and friction factors Chilton and Colburn J-factor analogy proved to be the most accurate. \n\nIt is written as follows,\n\nformula_1\n\nThis equation permits the prediction of an unknown transfer coefficient when one of the other coefficients is known. The analogy is valid for fully developed turbulent flow in conduits with \"Re\" > 10000, 0.7 < \"Pr\" < 160, and tubes where \"L\"/\"d\" > 60 (the same constraints as the Sieder–Tate correlation). The wider range of data can be correlated by Friend–Metzner analogy.\n\nRelationship between Heat and Mass;\n\nformula_2\n\n\n\n"}
{"id": "931802", "url": "https://en.wikipedia.org/wiki?curid=931802", "title": "Chunking (psychology)", "text": "Chunking (psychology)\n\nIn cognitive psychology, chunking is a process by which individual pieces of information are bound together into a meaningful whole (Neath & Surprenant, 2003). A chunk is defined as a familiar collection of more elementary units that have been inter-associated and stored in memory repeatedly and act as a coherent, integrated group when retrieved (Tulving & Craik, 2000).\n\nIt is believed that individuals create higher order cognitive representations of the items on the list that are more easily remembered as a group than as individual items themselves. Representations of these groupings are highly subjective, as they depend critically on the individual's perception of the features of the items and the individual's semantic network. The size of the chunks generally ranges anywhere from two to six items, but differs based on language and culture.\n\nThe phenomenon of chunking as a memory mechanism can be observed in the way individuals group numbers and information in the day-to-day life. For example, when recalling a number such as 12101946, if numbers are grouped as 12, 10 and 1946, a mnemonic is created for this number as a day, month and year. Similarly, another illustration of the limited capacity of working memory as suggested by George Miller can be seen from the following example: While recalling a mobile phone number such as 9849523450, we might break this into 98 495 234 50. Thus, instead of remembering 10 separate digits that is beyond the \"seven plus-or-minus two\" memory span, we are remembering four groups of numbers.\n\nA modality effect is present in chunking. That is, the mechanism used to convey the list of items to the individual affects how much \"chunking\" occurs. Experimentally, it has been found that auditory presentation results in a larger amount of grouping in the responses of individuals, as compared to visual presentation. Previous literature, such as George Miller's The Magical Number Seven, Plus or Minus Two: Some Limits on our Capacity for Processing Information (1956) have shown that the probability of recall is greater when the \"chunking\" strategy is used. As stated above, the grouping of the responses occurs as individuals place them into categories according to their inter-relatedness based on semantic and perceptual properties. Lindley (1966) showed that the groups produced have meaning to the participant, therefore; this strategy makes it easier for an individual to recall and maintain information in memory during studies and testing. Therefore, when \"chunking\" is used as a strategy, one can expect a higher proportion of correct recalls.\n\nVarious kinds of memory training systems and mnemonics include training and drill in specially-designed recoding or chunking schemes. Such systems existed before Miller's paper, but there was no convenient term to describe the general strategy or substantive and reliable research. The term \"chunking\" is now often used in reference to these systems. As an illustration, patients with Alzheimer's disease typically experience working memory deficits; chunking is an effective method to improve patients' verbal working memory performance (Huntley, Bor, Hampshire, Owen, & Howard, 2011). Another classic example of chunking is discussed in the \"Expertise and skilled memory effects\" section below.\n\nThe word \"chunking\" comes from a famous 1956 paper by George A. Miller, \"The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information\" (Neisser, 1967). At a time when information theory was beginning to be applied in psychology, Miller observed that some human cognitive tasks fit the model of a \"channel capacity\" characterized by a roughly constant capacity in bits, but short-term memory did not. A variety of studies could be summarized by saying that short-term memory had a capacity of about \"seven plus-or-minus two\" chunks. Miller (1956) wrote, \"With binary items the span is about nine and, although it drops to about five with monosyllabic English words, the difference is far less than the hypothesis of constant information would require (see also, memory span). The span of immediate memory seems to be almost independent of the number of bits per chunk, at least over the range that has been examined to date.\" Miller acknowledged that \"we are not very definite about what constitutes a chunk of information\"\n\nMiller (1956) noted that according to this theory, it should be possible to increase short-term memory for low-information-content items effectively by mentally recoding them into a smaller number of high-information-content items. \"A man just beginning to learn radio-telegraphic code hears each dit and dah as a separate chunk. Soon he is able to organize these sounds into letters and then he can deal with the letters as chunks. Then the letters organize themselves as words, which are still larger chunks, and he begins to hear whole phrases.\" Thus, a telegrapher can effectively \"remember\" several dozen dits and dahs as a single phrase. Naive subjects can remember about only nine binary items, but Miller reports a 1954 experiment in which people were trained to listen to a string of binary digits and (in one case) mentally group them into groups of five, recode each group into a name (for example, \"twenty-one\" for 10101), and remember the names. With sufficient drill, people found it possible to remember as many as forty binary digits. Miller wrote:\n\nIt is a little dramatic to watch a person get 40 binary digits in a row and then repeat them back without error. However, if you think of this merely as a mnemonic trick for extending the memory span, you will miss the more important point that is implicit in nearly all such mnemonic devices. The point is that recoding is an extremely powerful weapon for increasing the amount of information that we can deal with.\n\nStudies have shown that people have better memories when they are trying to remember items with which they are familiar. Similarly, people tend to create chunks with which they are familiar. This familiarity allows them to remember more individual pieces of content, and also more chunks as a whole. One well-known chunking study was conducted by Chase and Ericsson, who worked with an undergraduate student, SF, over two years. Chase and Ericsson wanted to see if a person's digit span could be improved with practice. SF began the experiment with a normal span of 7 digits. SF was a long-distance runner, and chunking strings of digits into race times increased his digit span. By the end of the experiment his digit span had grown to 80 numbers. The book The Brain-Targeted Teaching Model for 21st Century Schools (2012) states that SF later expanded his strategy by incorporating ages and years, but his chunks were always familiar, and thus allowed him to recall the to-be-remembered chunks more easily. It is important to note that a person who does not have knowledge in the expert domain (e.g. being familiar with mile/marathon times) would have difficulty chunking with race times and ultimately be unable to memorize as many numbers using this method.\n\nChunking is a flexible way of learning. Karl Lashley, in his classic paper on serial order (Lashley, 1951), argued that the sequential responses that appear to be organized in a linear and flat fashion concealed an underlying hierarchical structure. This was demonstrated in motor control by Rosenbaum et al. (1983). Thus sequences can consist of sub-sequences and these can in turn consist of sub-sub-sequences. Hierarchical representations of sequences have an edge over linear representations. They combine efficient local action at low hierarchical levels while maintaining the guidance of an overall structure. While the representation of a linear sequence is simple from storage point of view, there can be potential problems during retrieval. For instance, if there is a break in the sequence chain, subsequent elements will become inaccessible. On the other hand, a hierarchical representation would have multiple levels of representation. A break in the link between lower level nodes does not render any part of the sequence inaccessible, since the control nodes (chunk nodes) at the higher level would still be able to facilitate access to the lower level nodes. \nChunks in motor learning are identified by pauses between successive actions (Terrace, 2001). He also suggested that during the sequence performance stage (after learning), participants download list items as chunks during pauses. Terrace also argued for an operational definition of chunks suggesting a distinction between the notions of input and output chunks from the ideas of short-term and long-term memory. Input chunks reflect the limitation of working memory during the encoding of new information (how new information is stored in long-term memory), and how it is retrieved during subsequent recall. Output chunks reflect the organization of over-learned motor programs that are generated on-line in working memory. Sakai et al. (2003) showed that participants spontaneously organize a sequence into a number of chunks across few sets, and that these chunks were distinct among participants tested on the same sequence. Sakai et al. (2003) showed that performance of a shuffled sequence was poorer when the chunk patterns were disrupted than when the chunk patterns were preserved. Chunking patterns also seem to depend on the effectors used.\n\nThis usage derives from Miller's (1956) idea of chunking as grouping, but the emphasis is now on long-term memory rather than only on short-term memory. A chunk can then be defined as \"a collection of elements having strong associations with one another, but weak associations with elements within other chunks\" (Gobet et al., 2001, p. 236). Chase and Simon (1973) and later Gobet, Retschitzki and de Voogt (2004) showed that chunking could explain several phenomena linked to expertise in chess. To be more specific, more skilled chess players have a larger chunk size. Several successful computational models of learning and expertise have been developed using this idea, such as EPAM (Elementary Perceiver and Memorizer) and CHREST (Chunk Hierarchy and REtrieval STructures). Chunking has also been used with models of language acquisition (Barnard, Lieven, & Tomasello, 2009).\n\n\n\n\n"}
{"id": "3331237", "url": "https://en.wikipedia.org/wiki?curid=3331237", "title": "Cognitive elite", "text": "Cognitive elite\n\nThe cognitive elite of a society, according to Richard J. Herrnstein and Charles Murray, are those having higher intelligence levels and thus better prospects for success in life. The development of a cognitive elite during the 20th century is presented in their 1994 book \"The Bell Curve\". In this book, Herrnstein and Murray propose that the cognitive elite has been produced by a more technological society which offers enough high skill jobs for those with a higher intelligence to fill. They also propose that by removing race, gender or class as criteria the main criteria of success in academic and professional life is becoming primarily based on cognitive ability.\n\nEducational psychologist Linda Gottfredson wrote:\nThe book has met with criticism, as has the cognitive elite concept. It has been claimed that the case has been \"wildly exaggerated\", and it is based on an intelligence measure that is also criticized.\n\n"}
{"id": "5007616", "url": "https://en.wikipedia.org/wiki?curid=5007616", "title": "Conical coordinates", "text": "Conical coordinates\n\nConical coordinates are a three-dimensional orthogonal coordinate system consisting of \nconcentric spheres (described by their radius ) and by two families of perpendicular cones, aligned along the - and -axes, respectively.\n\nThe conical coordinates formula_1 are defined by\n\nwith the following limitations on the coordinates\n\nSurfaces of constant are spheres of that radius centered on the origin\n\nwhereas surfaces of constant formula_7 and formula_8 are mutually perpendicular cones\n\nand\n\nIn this coordinate system, both Laplace's equation and the Helmholtz equation are separable.\n\nThe scale factor for the radius is one (), as in spherical coordinates. The scale factors for the two conical coordinates are \n\nand\n\nAn alternative set of (non-orthogonal) conical coordinates have been derived\n\nformula_13 \n\nwhere formula_14 are spherical polar coordinates. The corresponding inverse relations are\n\nformula_15\n\nThe infinitesimal Euclidean distance between two points in these coordinates \n\nformula_17 and formula_18 are orthogonal coordinates on the surface of the cone given by formula_19.\nIf the path between any two points is constrained to this surface, then the geodesic distance between any two points\n\nformula_20 and formula_21 is \n\nformula_22\n\n\n"}
{"id": "55671", "url": "https://en.wikipedia.org/wiki?curid=55671", "title": "Connotation", "text": "Connotation\n\nA connotation is a commonly understood cultural or emotional association that some word or phrase carries, in addition to its explicit or literal meaning, which is its denotation.\n\nA connotation is frequently described as either positive or negative, with regard to its pleasing or displeasing emotional connection. For example, a stubborn person may be described as being either \"strong-willed\" or \"pig-headed\"; although these have the same literal meaning (\"stubborn\"), \"strong-willed\" connotes admiration for the level of someone's will (a positive connotation), while \"pig-headed\" connotes frustration in dealing with someone (a negative connotation).\n\n\"Connotation\" branches into a mixture of different meanings. These could include the contrast of a word or phrase with its primary, literal meaning (known as a denotation), with what that word or phrase specifically denotes. The connotation essentially relates to how anything may be associated with a word or phrase, for example, an implied value judgement or feelings.\n\nIt is often useful to avoid words with strong connotations (especially pejorative or disparaging ones) when striving to achieve a neutral point of view. A desire for more positive connotations, or fewer negative ones, is one of the main reasons for using euphemisms. \n\nIn logic and semantics, \"connotation\" is roughly synonymous with \"intension\". Connotation is often contrasted with \"denotation\", which is more or less synonymous with \"extension\". Alternatively, the connotation of the word may be thought of as the set of all its possible referents (as opposed to merely the actual ones). A word's \"denotation\" is the collection of things it refers to; its connotation is what it implies about the things it is used to refer to. The denotation of dog is (something like) four-legged canine carnivore. So saying, \"You are a dog\" would imply that you were ugly or aggressive rather than stating that you were canine.\n\n"}
{"id": "9274813", "url": "https://en.wikipedia.org/wiki?curid=9274813", "title": "Cutaneous rabbit illusion", "text": "Cutaneous rabbit illusion\n\nThe cutaneous rabbit illusion (also known as cutaneous saltation and sometimes the cutaneous rabbit effect or CRE) is a tactile illusion evoked by tapping two or more separate regions of the skin in rapid succession. The illusion is most readily evoked on regions of the body surface that have relatively poor spatial acuity, such as the forearm. A rapid sequence of taps delivered first near the wrist and then near the elbow creates the sensation of sequential taps hopping up the arm from the wrist towards the elbow, although no physical stimulus was applied between the two actual stimulus locations. Similarly, stimuli delivered first near the elbow then near the wrist evoke the illusory perception of taps hopping from elbow towards wrist. The illusion was discovered by Frank Geldard and Carl Sherrick of Princeton University, in the early 1970s, and further characterized by Geldard (1982) and in many subsequent studies. Geldard and Sherrick likened the perception to that of a rabbit hopping along the skin, giving the phenomenon its name. While the rabbit illusion has been most extensively studied in the tactile domain, analogous sensory saltation illusions have been observed in audition and vision. The word \"saltation\" refers to the leaping or jumping nature of the percept.\n\nFrom the moment of its discovery, the cutaneous rabbit illusion piqued the curiosity of researchers, and many experiments investigating the effect have been conducted, most of them on the forearm. Studies have consistently shown that the rabbit illusion occurs only when successive taps are closely spaced in time; the illusion disappears if the temporal separation between taps exceeds about 0.3 seconds (300 milliseconds). A study showed that attention directed to one skin location reduces the perceptual migration of a tap placed at the attended location. Another study showed that the illusory taps are associated with neural activity in the same area of the brain's sensory map that is activated by real taps to the skin. Nevertheless, the specific neural mechanisms that underlie the rabbit illusion are unknown. Many interesting instantiations of the cutaneous rabbit illusion have been observed. The illusion is not just confined to the \"body\". When subjects supported a stick across their index fingertips and received the taps via the stick, they reported sensing the illusory taps along the stick. This suggests that the cutaneous rabbit effect involves not only the intrinsic somatotopic representation but also the representation of the extended body schema that results from body-object interactions. Research has shown that the illusion can occur across non-contiguous body regions such as the fingers. However, a subpopulation of participants apparently does not experience the effect on the fingertips. The illusion has also been shown to occur both within and across the arms. Visual cues—light flashes placed at particular locations along the arm—can influence the cutaneous rabbit illusion. In addition, auditory and tactile stimuli can interact in the rabbit illusion. In 2009, researchers of Philips Electronics demonstrated a jacket lined with actuator motors and designed to evoke various tactile sensations while watching a movie. The device takes advantage of the cutaneous rabbit illusion to reduce the number of actuators needed. In keeping with the prediction of a Bayesian model, the perceptual attraction between the stimulus points is enhanced when the stimuli are made weaker.\n\nComputational models have been put forward by several authors in an effort to explain the origins of the cutaneous rabbit illusion. A Bayesian perceptual model closely replicates the cutaneous rabbit and other tactile spatiotemporal illusions. According to this model, brain circuitry encodes the expectation, acquired through sensory experience, that tactile stimuli tend to be stationary or to move only slowly. The Bayesian model reaches an optimal probabilistic inference by combining uncertain spatial sensory information with a prior expectation for low-speed movement (a Gaussian prior distribution over velocity, with mean 0). The expectation that stimuli tend to move slowly results in the perceptual conclusion that rapidly successive stimuli are more likely to be closer together on the skin.\n\nThe Bayesian model was further developed and shown to replicate the perception of humans to both simple (e.g., two-tap) and more complex (multi-tap) stimulus sequences, such as the 3-tap tau effect and the 15-tap rabbit illusion. The Bayesian model replicates the effects of selective spatial attention on the rabbit illusion percept and is compatible with both the out-of-body rabbit illusion and crossmodal influences on the rabbit illusion. Perceptual prediction and postdiction are emergent properties of the Bayesian model. A freeware computer program, Leaping Lagomorphs, implements the Bayesian model.\n\nFor the case of two taps to the skin, the Bayesian model perceives the length between taps, \"l*\", to be a function of the actual length, \"l\", and the elapsed time, \"t\":\n\nThis is the \"perceptual length contraction formula\", so-named in analogy with the physical length contraction described in the theory of relativity. Note that, just as observed in rabbit illusion experiments, the formula shows that \"l*\" underestimates \"l\" to a greater extent when \"t\" is made smaller; as \"t\" becomes large, \"l*\" approaches \"l\" and the illusion disappears. The model's parameter, tau (τ), is a time constant for tactile space perception; the value of tau determines how rapidly the perceived length approaches the actual length as the time between stimuli, \"t\", is increased. The perceived length equals one-third the actual length when \"t=τ\", and two-thirds the actual length when \"t=2τ\".\n\nGoldreich and Tong (2013) showed that tau is the ratio of the observer's low-speed expectation and tactile spatial acuity; they estimated the value of tau to be approximately 0.1 s on the forearm. A novel prediction of the Bayesian model, pointed out by Goldreich and Tong (2013), is that the amount of length contraction experienced will depend on the intensity of a tactile stimulus: lighter taps, which are more difficult to localize, should produce larger tau values and therefore more length contraction. Tong et al (2016) confirmed this prediction experimentally.\n\nAn illusion that appears to be closely related to the rabbit illusion is the tau effect. The tau effect arises when an observer judges the distance between consecutive stimuli in a sequence. If the distance from one stimulus to the next is constant, but the time elapsed from one stimulus to the next is not constant, then subjects tend to perceive the interval that is shorter in time as also being shorter in distance. Thus, like the rabbit illusion, the tau effect reveals that stimulus timing affects the perception of stimulus spacing. Goldreich (2007) proposed that the cutaneous rabbit illusion and the tau effect both result from the same low-speed prior expectation. Indeed, the same Bayesian model—characterized by the perceptual length contraction formula above—replicates both effects. Another illusion that is plausibly related to the cutaneous rabbit and the tau effect is the kappa effect. The kappa effect (or perceptual time dilation) is in essence the converse of the tau effect: the longer of two spatial intervals between stimuli is perceived to be longer in time. Goldreich (2007) showed that, under conditions of temporal as well as spatial uncertainty, the Bayesian model produces the kappa effect. The perceptual length contraction formula in that case still applies, but the \"t\" in the formula refers to perceived rather than actual time.\n"}
{"id": "889201", "url": "https://en.wikipedia.org/wiki?curid=889201", "title": "Digital imaging technician", "text": "Digital imaging technician\n\nA digital imaging technician (DIT) works in the motion picture film industry. The DIT position was created in response to the transition from the long established film movie camera medium into the current digital cinema era. The DIT is the camera department crew member who works in collaboration with the cinematographer on workflow, systemization, camera settings, signal integrity and image manipulation to achieve the highest image quality and creative goals of cinematography in the digital realm.\n\nWith the progression of the digitization ever more tasks concerning data management emerged: the position of the Digital Imaging Technician was introduced. The DIT is the connector between on-set time and post production. DITs support the camera team with technical and creative tasks with the digital camera. Their purpose is to ensure the best technical quality possible, as well as production safety. DITs are responsible for tasks during preparation, on-set time and post production. They are also responsible for managing data on set, such as making backups and quality checks of the material. In post production, the DIT hands the recordings to the post production team, possibly after checking the quality of the material and generating working copies.\n\nData backups and quality control are of great significance for the DIT who has to make sure that the original camera data and metadata is backed up at least twice daily, ensuring data integrity with checksum verification. Furthermore, the data has to be backed up on LTO tape which is more sturdy than electronic devices and is used for long-term storage. Another copy must be made on a transfer data carrier that will be sent to post production along with the reports of the content. Again, the data has to be backed up. The data has to be accessible at all times and should be saved in a system where it can be reviewed, displaying the metadata of each clip.\n\nThe DIT's role on-set has become especially prevalent through assisting cinematographers, normally accustomed to film stock, in achieving their desired look digitally. This is accomplished by the DIT through monitoring picture exposure, setting up Color Decision List (CDL) on daily basis and, if requested, \"look up tables\" (LUTs) for the post-production. Additionally, the DIT deals with settings in the digital camera's menu system, such as recording format and outputs.\n\nNext to the DIT, the data wrangler position is created as a support role for managing, transferring and securing all the digital data acquired on-set via the digital cinematography cameras, interacting with the 2nd AC. Depending on the scale of the project, the DIT can be the data wrangler but never the opposite. Additionally, the DIT is responsible for securing the digital audio recorded by the external digital audio recorder operated by the Production Sound Mixer.\n\nPrior to the DIT position, several other positions, such as Video Controller, Video Shader or Video Engineer, performed similar functions of exposure and color control over the live video image. While these positions continue to exist, especially in live broadcast and studio television, the DIT position has become entrenched in Cinema, Commercials and higher end television.\n"}
{"id": "38673678", "url": "https://en.wikipedia.org/wiki?curid=38673678", "title": "EGM: prevention of violence against women and girls", "text": "EGM: prevention of violence against women and girls\n\nThe Expert Group Meeting (EGM): prevention of violence against women and girls was convened as part of the United Nations Commission on the Status of Women's multi-year programme of work for 2010-2014. The \"Elimination and prevention of all forms of violence against women and girls\" forms a priority theme for its fifty-seventh session in 2013 (CSW57).\n\nThe meeting took place in Bangkok, Thailand 17–20 September 2012 and was organised by the United Nations Entity for Gender Equality and the Empowerment of Women (UN Women), in collaboration with the following organisations:\n\n\"EGM note 2\" The report reflects the shared discussion and analysis of the major issues, gaps and challenges identified at the EGM and presents key findings and recommendations. It was intended to build on the individual papers on specific issues provided by experts prior to the meeting, and the background paper prepared by the rapporteur. It provides inputs for the reports of the Secretary-General to the CSW and widely disseminated in preparation to the fifty-seventh session of CSW (CSW57).\n\n\"EGM notes 3 to 5\"\nThe EGM brought together a diverse group of people from different backgrounds and regions including academics, practitioners, representatives from women’s organisations and staff members of the United Nations system.\n\nThe experts elected a drafting committee (including two co-chairs) which was tasked to draft the report of the meeting, P miconclusions and recommendations. The following experts were elected to the drafting committee:\n\n\"EGM note 6\" Experts noted that violence against women and girls is defined as ‘any act of gender-based violence that results in, or is likely to result in, physical, sexual or psychological harm or suffering to women [or girls], including threats of such acts, coercion or arbitrary deprivation of liberty, whether occurring in public or in private life.’ It exists in multiple, interrelated and sometimes recurring forms, and is a manifestation of historically unequal power relations between men and women.\n\n\"EGM note 7\" Experts stressed that we are at a critical moment where international bodies, nation states and civil society can and must come together to solidify commitments to ending violence against women and girls, as fragile and – in many places – deteriorating economic conditions, persistent environmental degradation, internal conflicts and wars, all contribute to the exacerbation of violence against women and girls, and violations of their rights.\n\n\"EGM note 8\" Experts noted that the impacts of the global financial crisis, the economic pressures on Governments to reduce funding to social services and programmes, and the ongoing resource constraints faced by conflict-affected and developing countries, all risk limiting or reducing the investment States will make in preventing and responding to violence against women and girls.\n\n\"EGM note 9\" However, they highlighted the enormous costs violence against women and girls entails to States and societies as a whole, in terms of reduced human capital, decreased productivity, exacerbated social inequalities, lowered overall educational outcomes, and broad strains on public services. Violence diminishes women’s and girls’ ability to gain an education, earn a living and participate in public life, and live a life free of fear. It has significant health impacts, including psychological consequences, physical injuries, sexual/reproductive health issues and death. In war-affected settings, violence against women and girls inhibits efforts towards peace-building and sustainable recovery, contributing to the risk of resurgent conflict. In development settings, it hinders progress towards achievement of several of the Millennium Development Goals (MDGs), including those relating to , , and . It has intergenerational impacts, given that women use disproportionately more of their income toward supporting their families, and because violence diminishes their ability to fully participate in their societies (for example in politics, work or education) they are less able to invest in their children’s futures. One study in Chile found that women’s lost earnings alone as a result of domestic violence cost US$1.56 billion or more than 2 percent of the country’s Gross Domestic Product.\n\n\"EGM note 10\" Violence against women and girls therefore entails massive costs to the State, and has a dragging effect on all other social and economic development efforts, particularly in humanitarian and development contexts. It is only by lowering the incidence of violence against women and girls, preventing recurrence, and responding effectively to existing violence to minimise ongoing impacts, that the overall costs of such violence to any economy will be reduced. Experts noted that, in the face of such evidence, prevention is not only possible, but central to the social and economic advancement of developed and developing countries alike. It was reiterated that all States have not only a responsibility to significantly strengthen their planning and budgeting efforts for prevention of violence against women and girls, but that doing so will contribute to positive social and economic outcomes.\n\n\"EGM note 11\" Experts brought together experiences from across developing and developed countries, and from humanitarian contexts (arising from conflict and natural disasters), demonstrating that violence against women and girls could be prevented regardless of political, social and economic conditions. Levels of violence against women and girls vary across countries that with similar economic status or political systems – a variation that can be attributed to different laws, policies, practices, norms, behaviours and attitudes that contribute to, justify or excuse violence against women and girls. Such factors must be targeted to prevent and reduce violence within and across all settings.\n\n\"EGM note 12\" Across developing and developed countries alike, more comprehensive, multi-sectoral and sustained approaches were recognised as necessary to achieve such change, with investments commensurate to the enormous scale of the abuse and its impacts. While the allocation of more resources to prevention remained high on the priority list for experts, political will was also identified as a key factor. It was noted that organisations and communities in some developing countries have led the way in testing and expanding new models for prevention, however experts did not believe any State was currently meeting its full normative obligations in this area.\n\n\"EGM note 13\" Experts reiterated that violence against women and girls is a pervasive and systematic human rights violation, caused by – and reinforcing – gender inequality and entrenched discrimination. While most violence against women and girls is committed by non-State actors or individuals (usually men known to the victims/survivors, often husbands/intimate partners or other family members), experts were adamant that laws, policies and practices emanating from the State – as well as from traditional or customary practices – could also result in direct violence against women and girls, fail to respond to it, or create an environment where such violence was tolerated, excused or justified.\n\n\"EGM note 14\" To this end, experts noted that the prevention of violence against women and girls could not be achieved without the full implementation of the existing legal obligation on States – under the \"Convention for the Elimination of All Forms of Discrimination against Women (CEDAW)\" to ‘take all appropriate measures to modify the social and cultural patterns of conduct of men and women, with a view to achieving the elimination of prejudices and customary and all other practices which are based on the idea of the inferiority or the superiority of either of the sexes or on stereotyped roles for men and women,’ along with the more detailed obligations relating to the elimination of violence against women and girls outlined in the \"Beijing Declaration and Platform for Action (BPfA)\". Experts emphasised, as central to the latter, the obligation on States to ‘refrain from invoking any custom, tradition or religious consideration to avoid their obligations’ to eliminate violence against women and girls.\n\n\"EGM note 15\" A key message from experts was that the call for greater efforts to prevent violence against women and girls is not a ‘new demand,’ but well supported by international legal and normative frameworks. What is new is the emergence, in recent years, of an unprecedented evidence and practice base that provides concrete guidance on the application of proven and effective strategies, and makes prevention of violence against women and girls a tangible and measurable goal. We now know that to effectively prevent violence against women and girls, efforts must go beyond simple awareness-raising projects and instead work to actively (and measurably) transform discriminatory and violence-supportive attitudes and behaviours, community norms, institutional practices and systems, laws and policies, and society as a whole.\n\n\"EGM note 16\" Experts noted that this holistic and comprehensive approach to prevention has the potential to create numerous benefits for communities beyond reductions in violence, because it also addresses the discrimination, inequality and other violence-supportive practices and behaviours that contribute to a range of social ills. Prevention of violence against women and girls is ultimately about building relationships, communities and organisations that are equal, non-violent and respectful of all individuals. It results in the creation of more peaceful, egalitarian and productive societies where women and girls live free from the discrimination, harassment, violence and fear of violence that can block them from reaching their full human potential.\n\n\"EGM note 17\" The focus of the meeting (and this report) was on prevention of violence against women and girls \"before it occurs\", that is, by identifying and addressing its underlying causes and promoting shifts in the social environment that ultimately reduce the number of new incidents of violence against women and girls.\n\n\"EGM note 18\" Experts noted that prevention of violence against women and girls remains a poorly understood concept across sectors and stakeholders. Prevention is often conflated with early intervention or the response to existing violence, or else limited to awareness raising or social marketing campaigns. Simplistic analyses and programmes aimed at single-cause factors such as alcohol abuse, or placing the responsibility to prevent violence on women and girls themselves (such as self-defence programmes) can in some cases do more harm than good, and are not uncommon. Cynical perceptions that violence against women and girls is somehow an inevitable part of society, and that efforts to prevent it are well-intentioned but ultimately ineffective, are also widespread. There is therefore a need to build not only evidence, but shared understandings of the complexity and causes of violence against women and girls, and of how it can be effectively prevented.\n\n\"EGM note 19\" Experts recognised that this transformative agenda engages all levels of the socio-political system, from policy and legislative development, to the development and delivery of programmes and services ‘on the ground’, and the capacity building of the institutions responsible for implementation. Confronting existing social and gendered realities that continue to use arguments based on culture, customs and ‘traditional’ values and practices to justify discrimination and violence against women and girls, and treat them as subordinate and second-class citizens, remains a major challenge in addressing the social and cultural environments that permit violence against women and girls to flourish with impunity. As the Special Rapporteur on violence against women, its causes and consequences has noted: ‘no form of interpersonal violence against women is devoid of structural violence – as in all places, such abuse is underpinned by beliefs about the perpetrator’s right to harm another, based on societal notions of gender and rights.’\n\n\"EGM note 20\" Experts were particularly keen to convey that, in prevention terms, violence against women and girls in the private sphere and/or perpetrated by non-State actors could \"not\" be considered as something ‘separate’ from the actions of the State. Experts stressed that violence against women and girls – in every context – can be perpetuated by State decision-making mechanisms, laws, policies and practices when these systematically marginalize women and girls and/or fail to promote their rights. These include not only legal policies and programs that fail to criminalize violence against women and girls or adequately punish it, but also State-sanctioned discrimination, for example: excluding women from political participation (such as assemblies, high-level government positions, and key decision-making bodies like constitutional committees); constitutional language that threatens women’s rights (whether existing or developing in emerging State structures); or discriminatory laws, policies and budgets which disproportionately limit women’s and girls’ rights, neglect their voices and concerns, and fail to promote full substantive, as well as formal, equality between men and women.\n\n\"EGM note 21\" State-sanctioned violence and discrimination against women is significantly tied to cultural and social norms that pervade a nation, which are then used to justify, excuse or tolerate violence against women and girls. When laws and policies limit women’s freedoms or deem women as ‘complementary’ instead of ‘equal to’ men, this trickles down to public perception of women and girls and their role in society, and undermines their safety and security within the State. These social and cultural norms are similarly impacted by the respect, or otherwise, of women’s civil and political rights (such as their political participation), and their economic, social and cultural rights (such as their access to work and education). Greater levels of social and economic equality between men and women, for instance, are closely correlated with lower levels of violence against women and girls at the population level. Similarly, greater visibility of women in leadership roles, including in constitution committees, assemblies and high-level posts in government, in peacekeeping troops and in peace-building talks, promotes positive and egalitarian norms and combats gender stereotypes in a way that counters discriminatory and violence-supportive attitudes and the marginalization of women and girls.\n\n\"EGM note 22\" Prevention of violence against women and girls is often conceptualised in terms of awareness raising or community mobilisation, and these are important components. Experts reiterated the importance of grassroots community mobilisation in driving attitudinal and behavioural transformation at the local level. However, in light of the above, experts stressed the more expansive and multi-level nature of effective prevention, in particular the critical role of government to create an ‘enabling environment’ through undertaking policy, legislative and budgetary reform to promote gender equality and women’s empowerment, and actively address the multiple and intersecting forms of discrimination and disadvantage that place women and girls at risk of violence. They emphasised the additional role of States in providing support to women’s and other civil society actors, including women, men and youth community and religious leaders and opinion-makers, in their prevention efforts.\n\n\"EGM note 23\" Experts further stressed the importance of continued investment in an effective \"response\" to existing violence against women and girls – including through improving legislative, police, justice and service systems – as a fundamental ‘building block’ for prevention, establishing accountability and redress, and protecting women and girls from further violence. Effective response systems are also necessary to ensure support of women and girls who may identify violence in their own lives as a direct result of prevention activity and seek help and redress. Experts acknowledged that a separate stream of work on building an effective multi-sectoral response was being undertaken in preparation for CSW.\n\n\"EGM note 24\" Experts recommended that prevention and response strategies be developed and implemented as a holistic and integrated system that upholds the human rights of girls and women to live in societies, communities and families that are free of such violence. However, while essential, experts noted the evidence that an effective response has, in itself, only a limited impact on reducing the number of new incidents of violence. Specific actions to address the foundations of violence – discriminatory and violence-supportive practices, laws, norms, behaviours and attitudes – are also necessary in order to prevent violence against women and girls from happening in the first place, within and across all settings. These are the focus of discussions and recommendations in this Report.\n\n\"EGM note 25\" The emphasis on economic growth in the development agenda globally has led to growing inequalities and a reduced focus on redistribution. The rolling economic crises currently gripping almost all of the world’s countries has resulted in increased unemployment and poverty, a shortage of housing, and cutbacks in social spending including subsidies for health and education. These multiple crises have in turn fuelled communal and ethnic tensions, mass migration and displacement, rendering millions homeless and poor, and more vulnerable to trafficking and diverse forms of exploitation. In most communities, this also results in the heightened vulnerability of women and girls to violence and exploitation.\n\n\"EGM note 26\" Experts noted the evidence that violence against women and girls is intensified and exacerbated in situations of socio-economic stress, conflict and other crisis situations. In addition to the impact of economic crises described above, global warming and associated rising sea levels and severe weather events, as well as environmental degradation and resource depletion, can all contribute to conditions of social and economic vulnerability, including homelessness and mass migrations. They can also lead to the disaster or crisis situations in which violence against women and girls is known to increase.\n\n\"EGM note 27\" As discrimination based on sex and gender continues to dominate social formations even in the 21st century, experts noted that violence against women and girls continues to be perceived as ‘normal’ in many contexts. The pervasive nature of militarization and the growth of all forms of religious fundamentalisms and other forms of extreme nationalism creates cultures where women are reduced to being symbolic ‘bearers’ of their culture and have their mobility and autonomy restricted in many different ways.\n\n\"EGM note 28\" Exacerbated by the conditions described above (and even without them) women and girls experience daily harassment, abuse, discrimination and violence across the numerous settings in which they conduct their lives, from workplaces, schools and other educational institutions, community and faith organisations and groups, market places, shops, on public transport, in social settings, online and via social media, during flight and while displaced as a result of conflict and natural disasters, and above all in their homes.\n\n\"EGM note 29\" Experts also identified emerging contexts and issues that have an impact on violence against women and girls. For example, experts agreed that the role of new media presents a number of layered and complex challenges, as well as opportunities, for the prevention of violence against women and girls. In the first instance, new media is often a platform for the perpetuation of harmful masculinities and the objectification of women and girls. This can take a number of forms from everyday hyper-sexualised, one-dimensional images of women and girls to hard-core pornography which has moved from the peripheries to the mainstream of the pornography industry. Virtual spaces are also utilised to perpetuate direct attacks on women and girls. This can range from cyber-stalking to the posting of inappropriate images / videos of women. For example, women have increasingly reported incidents of footage of them engaged in sexual activity (filmed both with and without consent) being posted on internet sites without their consent. In a number of cases this has included the posting of footage of actual rapes.\n\n\"EGM note 30\" Violence in the virtual space and the wider issues of how women and girls are objectified in the media has particular implications for girls and younger women, who are much more like to engage with social networking sites, instant messaging, etc. Despite the range of violations, incidents can be hard to prosecute, especially as the internet is not limited to nation spaces. There are also real challenges around balancing the right to freedom of expression with the right to be protected from discrimination.\n\"EGM note 31\" Experts also noted with concern the emerging evidence that adolescent girls and young women may also be targeted for sexual violence in the context of serious youth violence (e.g. youth gangs) and/or broader urban violence. They may also be members of gangs themselves and involved in perpetration of violence against other young women and girls within or between gangs. Experts further expressed the concern that adolescent girls and young women were frequently overlooked in policy and programming responses designed for young men, adult women or for children in general, yet the context of their lives may be quite distinct and require specific approaches, particularly given they are the age group at greatest risk of sexual violence.\n\n\"EGM note 32\" In humanitarian crises caused by conflict and/or natural disasters, women and girls are at risk of violence throughout all stages: during crises, during flight from crises, while living in displaced settings, and during and following return. In situations of armed conflict, women and girls can be exposed to violence at the hands of armed actors, including soldiers and military assigned to protect civilians and assist in their safe flight from conflict. They may be recruited into armed groups and serve as sexual slaves to combatants. In some settings women and girls continue to be used as ‘weapons of war,’ subject to sexual assault by all parties to conflict, at times in front of their husbands, children, and other family or community members.\n\n\"EGM note 33\" While much attention has been accorded to sexual violence against women and girls during conflict, they suffer many additional forms of violence in humanitarian emergencies, including sexual exploitation, trafficking, early marriage, and intimate partner violence. Experts noted that all of these forms of violence can be averted or reduced with effective prevention programming from the contingency planning phase through to recovery, and States’ responsibilities to work towards the prevention of this violence are reinforced by a broad normative framework mandating protection of women and girls from sexual and other forms of violence in emergencies. And yet, prevention programming remains weak in virtually every humanitarian setting around the world.\n\n\"EGM note 34\" Experts further noted the evidence that while more than 740,000 men, women, and children die each year as a result of armed violence, the majority of these deaths – 490,000 – occur in countries that are not affected by conflict. The proliferation of small arms increases the vulnerability of women and girls to violence, and exacerbates the seriousness of that violence. This is particularly true in the context of urban/serious youth (e.g. gang) violence (referred to above), but also in the case of violence in the home, where the presence of small arms significantly increases the risk of the victim being killed. The violent deaths of approximately 66,000 women and girls are attributed to armed violence globally each year.\n\n\"EGM note 35\" Experts were finally keen to emphasise that – even within the same geographic or socio-political setting, ‘context’ was not the same thing for different women and girls. Women and girls often experience multiple and intersecting forms of social disadvantage and discrimination (in addition to that based on gender), and this compounds their individual and collective vulnerability to violence. The Special Rapporteur on violence against women, its causes and consequences, has recently noted that theories on violence have often ‘failed to provide a comprehensive understanding of how various forms of discrimination, beyond a male/female gender binary, contextualize, exacerbate, and correlate to high levels of violence in given societies. The lack of an intersectional approach can lead to the reinforcing of one form of discrimination in attempts to alleviate another.’ Factors such as race, ethnicity, caste, class, age, religion, sexual orientation, marital status, geographic location, disability, HIV status or status as a refugee or internally displaced person, will all influence the forms and nature of violence women and girls may suffer, and the relationship of these factors to prevention is discussed in the ‘Key Findings’ section.\n\n\"EGM note 36\" The international community is committed to eliminating violence against women and girls and has recognised – in various global and regional legal and policy instruments – the important role of prevention towards this end.\n\n\"EGM note 37\" Above all, State responsibility for prevention of violence against women and girls through social and behavioural change is supported by the foundational treaty on women’s human rights, the \"Convention on the Elimination of All Forms of Discrimination against Women\" (CEDAW), which establishes signatories’ legal obligation to take ‘all appropriate measures [to] modify the social and cultural patterns of conduct of men and women, with a view to achieving the elimination of prejudices and customary and all other practices which are based on the idea of the inferiority or the superiority of either of the sexes or on stereotyped roles for men and women.’ General Recommendation 19 of the CEDAW Committee defines violence as a form of discrimination against women, and establishes the obligation of States to act with ‘due diligence’ to prevent and respond to violence against women and girls.\n\n\"EGM note 38\" The \"Declaration on the Elimination of Violence against Women\" enhanced the definition of violence against women and also included protection of women from violence committed in the private domain as being an obligation of the state. Responsibilities of the State to prevent violence, abuse and neglect of girls are further supported by the \"Convention on the Rights of the Child\", requiring States parties to ‘take all appropriate legislative, administrative, social and educational measures to protect the child from all forms of physical or mental violence, injury or abuse, neglect or negligent treatment, maltreatment or exploitation, including sexual abuse’ including ‘forms of prevention,’ along with its two Optional Protocols.\n\n\"EGM note 39\" The \"Beijing Declaration and Platform for Action\" (BPfA), adopted at the Fourth World Conference on Women in 1995, recognised the complexity of the underlying causes of violence against women and girls, and the need to link prevention and response activities. Paragraph 118 notes that:\n\n\"EGM notes 40 to 51\" Other global policy and legislative / normative frameworks that are currently in place.\n\n\"EGM note 52\" In conclusion, while the normative framework has clearly developed an obligation for States to take holistic, comprehensive, strategic and well-resourced action to prevent violence against women and girls, and while States have increasingly ratified the relevant treaties and in some cases brought these obligations into their legal frameworks, much work remains to be done before the normative obligations will be fully implemented. Gaps remain in terms of resource allocation, legislative and policy development, and systems and mechanisms for coordinated and sustained action.\n\n\"EGM note 53\" In considering the above analysis, experts believed that a significant global shift in perceptions was necessary towards greater recognition of the widespread and systematic nature of violence against women and girls, deserving of more serious attention by States and the international community. Experts returned to and supported the international definition of violence against women and girls in the \"Declaration\", i.e. as a violation of human rights and a form of discrimination against them, that shall mean all acts of gender-based violence that result in, or are likely to result in, physical, sexual, psychological or economic harm or suffering to women and girls, including threats of such acts, coercion or arbitrary deprivation of liberty, whether occurring in public or in private life.\n\n\"EGM note 54\" However, some experts noted that such violence is not isolated or sporadic, but could be seen as part of a widespread or systematic practice intended to humiliate or degrade an identifiable group. As such, they called for violence against women and girls to be considered a crime against humanity. Others cautioned against linking violence against women and girls to current definitions of crimes against humanity, given the existing limitations of international law and jurisprudence. It was noted that the landmark February 2008 judgement of the Sierra Leone Appeals Chamber of the Special Court in the Armed Forces Revolutionary Council case had set an historic precedent in recognising forced marriage as a distinct category of crimes against humanity in international criminal law. Experts therefore agreed that calling for violence against women and girls to be recognised as a crime against humanity was intended as an aspirational statement and advocacy goal, one which would expand current definitions and understanding of crimes against humanity – in a way similar to the Sierra Leone case – and help drive a global shift in perceptions towards one that recognises the full seriousness of violence against women and girls, and the urgency with which we must prevent it.\n\n\"EGM note 55\" Based on comprehensive discussion at the EGM, review of the papers presented by experts, and an analysis of the global context, normative framework and evidence and practice base, experts agreed on the following key findings. Experts noted the significant development, over recent years, of guidance to States and other stakeholders in the development, implementation and monitoring of policy and programming to prevent violence against women and girls, and again\nreferred to the papers submitted to the EGM as providing further information on current practice. Rather than reiterate that guidance here, experts have confined their findings below to the emerging issues, and those perceived to be of most critical relevance to CSW.\n\n\"EGM note 56\" Experts wished to reiterate, as a finding and central tenet of their recommendations, that prevention of violence against women and girls is a positive endeavour, a precondition for enabling women and men to reach their full potential, and is essential to the creation of healthy, equitable, stable and productive communities, workplaces, schools and universities, faith and cultural institutions, sporting and recreation organisations, and societies as a whole.\n\n\"EGM note 57\" Noting recent research highlighting the unique and catalysing impact of women’s organisations on enduring and effective policy development to end violence against women and girls, experts were unanimous that effective prevention of violence against women and girls was not only often driven by, but \"required\" the involvement of women’s organisations, working in partnership with national, provincial and local Governments, communities, civil society groups, donors, the private sector and other non-state actors.\n\n\"EGM note 58\" Experts emphasized the importance of moving away from short-term, ad hoc sensitisation and awareness raising activities and towards more comprehensive, longer-term prevention efforts that are grounded in communities and work systematically to change unequal power relations between women and men. Such social norm change requires working with a cross section of the community from women and men, young people, religious and cultural leaders, health care providers, police, government officials, the media and others, over time and in varied ways, to challenge norms that perpetuate violence and emphasize the positive benefits of non-violence, justice and equality for individuals, families and the broader community. Civil society plays an essential role in mobilising communities to rethink the acceptability of violence and supporting positive change.\n\n\"EGM note 59\" However, while women’s and other civil society organisations and communities themselves have been at the forefront of developing the practice and evidence base for prevention programming, factors such as time, reach and workforce constraints can prevent many good initiatives from being evaluated, expanded or otherwise scaled-up. Research has also shown that those working to end violence against women and girls can themselves face discrimination, hostility, repudiation and even violence, precisely because they challenge traditional notions of the family and gender that contribute to such violence.\n\n\"EGM note 60\"\nTo maximise the impact and sustainability of such work, therefore, Governments have a key role to play in supporting and creating an enabling environment for women’s organisations and others working to prevent violence against women and girls to continue to drive and innovate prevention programming, safe from violence and discrimination themselves. Governments should also activate their reach and mandate to ensure the scale-up, systematisation and embedding of good practice in laws, policies and through public institutions (e.g. schools, social and health services, media and workplace regulation) for long-term sustainability.\n\n\"EGM note 61\" Experts noted that without States taking their full responsibility for sustained, systematic and coordinated policy, programming and investment for prevention, the transformative social development necessary to end violence against women and girls cannot be achieved. Few States worldwide had implemented their obligations to this end. A 2011 review of National Action Plans on Violence against Women found that most policies were limited to responding to existing violence. Those that did contain specific prevention actions largely focussed on raising awareness of new laws or where to access services, with some containing one-off or single-sector prevention activities such as social marketing campaigns or schools-based programmes. Only one identified plan took a long-term, multi-sectoral and holistic approach to prevention, with appropriate institutional support mechanisms and commensurate investment.\n\n\"EGM note 62\" Importantly, one-off, single-sector or small-scale interventions, while they may have some effectiveness for participating individuals, are unable to change the social norms at the community or society level that have a dampening effect on such attitudinal change. Therefore, they can never in themselves decrease prevalence of violence against women and girls across society as a whole. Broad and sustainable change is only achieved when such activities are implemented in a long-term and cumulative way, mutually reinforced across various settings. These should be linked to a prevention framework which is coordinated to ensure that all levels are appropriately engaged, with evaluation and monitoring for continuous improvement. It is particularly essential that all strategies and interventions are supported by policy and legislative reform that promotes gender equality, challenges discrimination, and provides an effective response to existing violence.\n\n\"EGM notes 63 to 102\" Other key findings from the EGM.\n\n\"Recommendation 103\"\nExperts stressed the critical importance of women’s organisations, civil society, international institutions, donors and States working together to go beyond ‘ad hoc’ approaches to prevention, and for States to take their responsibility for developing long-term and multi-sectoral strategies so that activity can be coordinated, and evidence built, to achieve real results. With an increased commitment from all actors to such an approach, and corresponding investment, many experts believed violence against women and girls could be ended within a generation. To this end, experts have made recommendations (see below) for a coordinated and target-focussed approach to preventing violence against women and girls, driven by two overarching activities – a Global Implementation Plan – framing the work of international, regional and national institutions (including States) toward the goal of ending violence against women and girls, along with a Global Advocacy Campaign – driven by women’s and other civil society organisations to create momentum and provide accountability for the above.\n\n\"Recommendation 104\" Also, given CSW’s specific mandate with regards to implementation of the \"Beijing Declaration and Platform for Action\" experts have made further recommendations for immediate implementation, aligned with the BPfA’s strategic objectives of taking integrated measures to prevent and eliminate violence against women, and studying the causes and consequences of violence against women and the effectiveness of preventive measures. While the BPfA objectives cover both prevention of, and response to, violence against women and girls, and experts supported full implementation of all of these, the recommendations below build on those areas focussing on prevention.\n\n\"Recommendation 105\" Finally, experts identified recommendations arising from emerging issues or gaps in the evidence and practice base regarding prevention of violence against women and girls in certain contexts and settings. These include recommendations for prevention in settings affected by humanitarian crises such as conflict and natural disasters; contexts of serious urban or youth violence; with regards to representation of women and girls in the context of mass media as well as in new social media; and in the context of the global financial crisis and shifting geopolitics. In addition to the broad recommendations below that are relevant to all settings, special attention has been given to certain contexts and settings in order to highlight specific strategies for prevention related to these particular areas of concern. Experts have also chosen to highlight certain recommendations specific to preventing violence against girls, including adolescent girls, and young women, as a frequently overlooked group worthy of special consideration.\n\n\"Recommendation 106\"\nExperts agreed that while an international legal and normative frame work for preventing violence against women and girls is already in place, there are two major barriers to its implementation. The first is that social and cultural norms and customs are often used as a shroud or excuse for laws, practices and behaviours that are either directly violent and discriminatory towards women and girls, or else contribute to and support violence against them. The BPfA clearly calls on States to ‘refrain from invoking any custom, tradition or religious consideration to avoid their obligations with respect to its elimination as set out in the Declaration on the Elimination of Violence against Women,’ and experts were adamant that this entails an active obligation on States to examine their own laws and policies, and challenge the communities, organisations and individuals in their jurisdictions, to eliminate norms and customs that excuse, justify or tolerate violence against women and girls, and which exist in all societies.\n\n\"Recommendation 107\"\nA second barrier to full implementation of existing obligations is the lack of a coordinated, strategic agenda at international, regional and national levels for modifying ‘the social and cultural patterns of conduct of men and women, with a view to achieving the elimination of prejudices and customary and all other practices which are based on the idea of the inferiority or the superiority of either of the sexes or on stereotyped roles for men and women,’ required by CEDAW. This is an essential precondition and support for the sustainable prevention of violence against women and girls. As noted above, such prejudices, practices and stereotypes are rampant in all societies, expressed as much through channels such as media and popular culture, as through institutions more identifiable as the bearers of custom or ‘tradition’ (e.g. faith institutions). A much greater commitment and level of resourcing is required from all States, along with significantly improved coordination of policy, programming and research at global, regional and national levels towards a shared strategic agenda to eliminate these and so meet the legal obligation under CEDAW.\n\n\"Recommendation 108\"\nTo this end, an overarching recommendation from experts was that Member States commit, at CSW in 2013, to develop a Global Implementation Plan to End Violence against Women and Girls, to be launched in 2015, with a particular focus on prevention of violence against women and girls. This Plan should aim to provide vigilance on established international obligations (particularly the overarching BPfA and CEDAW obligations cited above), and serve as the tool for operationalising these norms into national policy and programming in a coordinated and results-based way.\n\n\"Recommendation 109\"\nThe Global Implementation Plan to End Violence against Women and Girls, endorsed and supported by Member States at its launch, would aim to:\n\"Recommendation 110\"\nDevelopment of the plan should be linked to the processes defining the post-2015 development agenda, to ensure that the prevention of violence against women and girls is rightly understood as crucial to the meeting of other internationally agreed development goals, and that targets relating to the prevention of (and response to) such violence are explicitly identified and well situated in the post-2015 development framework.\n\n\"Recommendation 111\"\nDevelopment of the plan would require, among other things:\n\"Recommendation 112\"\nDevelopment of the plan should include the proactive engagement of new partners (such as the private sector, sporting organisations, religious and cultural leaders, the media and entertainment industry), with a critical eye to the internal structures and methods of operation of such partners to ensure they fully support and in no way undermine the human rights of women and girls.\n\n\"Recommendation 113\"\nExperts further recognised the crucial and catalytic role of women’s organisations and called for them to help build support and momentum for the above. A global ‘movement for prevention’ is needed, engaging a critical mass of individuals, groups and institutions working together to create communities and countries that are safe for women and girls and where their rights are respected.\n\n\"Recommendation 114\"\nExperts’ second overarching recommendation was therefore that women’s organisations, in partnership with other civil society organisations and identified willing international and regional institutions, States and other relevant parties, lead a Global Advocacy Campaign to Prevent Violence against Women and Girls, as a crucial accompaniment to the development of the Implementation Plan above. The Advocacy Campaign could include the creation of plain language communications materials, mechanisms to share information and practice, avenues for capacity development, and advocacy strengthening, for example through the training of male and female youth and veteran activists and leaders to monitor progress of nations on international agreements, produce reports, and represent women’s and girls’ priorities and interests in international fora. The aim of the Advocacy Campaign would be to create momentum for the Implementation Plan, ensure the consistent promotion of evidence-informed, rights-based prevention activity, and hold international, regional and national stakeholders accountable to women and girls.\n\n\"Recommendation 115\"\"\nWhile the Global Implementation Plan may take one to two years to develop, there are many areas of work that States have already committed to under the BPfA Strategic Objective D1 – to take integrated measures to prevent and eliminate violence against women – and upon which they can and should take immediate action. Below are recommendations elaborated by the experts in line with the growing evidence and practice base on prevention, in support of these existing commitments.\n\n\"Recommendation 116\"\"\nIn line with BPfA’s Paragraph 124(j), calling on Governments to ‘formulate and implement, at all appropriate levels, plans of action to eliminate violence against women,’and Paragraph 124(p)calling for the allocation of ‘adequate resources within the government budget and mobilis[ation of]community resources for activities related to the elimination of violence against women, including resources for the implementation of plans of action at all appropriate levels,’ experts recommend that States work in partnership with funders, international and regional institutions, women’s and civil society organisations and other stakeholders to develop, implement,\nevaluate and monitor coordinated, multisectoral and sustained prevention strategies, alongside and reinforcing strategies to improve the response to existing violence. Such strategies should\n\n\n"}
{"id": "47664661", "url": "https://en.wikipedia.org/wiki?curid=47664661", "title": "Education inequality in China", "text": "Education inequality in China\n\nEducation inequality in China exists on multiple levels, with significant disparities occurring along gender, geographical, and ethnic divides. More specifically, disparities exist in the distribution of educational resources nationwide, as well as the availability of education on levels ranging from basic to higher education.\n\nShortly after the Chinese Revolution of 1949, the Communist government was confronted with heavy educational disparities across the nation. In the years following the Chinese Revolution, the Chinese government attempted to address these disparities with alternating approaches, creating periods of differing emphasis on opposing educational models. The first model, based on egalitarianism, emphasizes equality across regions of varying economic wealth and development. Conversely, the second model, based on competition, emphasizes individualistic competition, rationalizing any existing educational disparities as a necessary sacrifice for national economic development.\n\nThe Chinese government also focused educational policies on higher education and specialized training, leaving basic education underdeveloped throughout large parts of the country. Government funding for education was reserved for urban areas; rural communities, already at an economic disadvantage, were left to fund their own schools, exacerbating the already existing divide between urban and rural education. When collectivization policies passed in 1955, placing rural families into agricultural cooperatives that distributed income on the basis of labor hours, the importance of education dropped even further within these rural communities, and they were much less likely to fund primary education for the children of their communities.\n\nAlso beginning in the 1950s, the \"hukou\" system assigned the Chinese population into urban and rural regions, exacerbating continuously worsening inequalities within health, employment, housing, and education. Further complicating education policy, people of rural-\"hukou\" status are able to live and work in urban areas without changing their \"hukou\" designation. According to Xiaogang Wu's tabulation, based on figures from the 2000 Chinese Census, an estimated 33% of city residents were actually designated as rural-\"hukou\" holders.\n\nA significant shift in education finance policy occurred in 1982 with the introduction of decentralization, in which provincial governments were now individually in control of financing education within their region. The change in policy sought to capitalize on rapid income growth by funding education from non-governmental sources, and in the 1980s and 1990s, the government share of education expenditures dropped even as total education expenditures increased. As a result, families had to pay increased tuition and fees, and schools turned to surcharges and social contributions to fund themselves. Education for children of poorer families was only attainable with state subsidies, which often did not reach the families who were most in need. Tuition and fees also increase as students move from lower to higher grade levels, so even if these poorer students were able to move through the education system, many were prevented from even completing their compulsory education by economic barriers. Additionally, this shift to a wider financial base for education also coincided with rising interprovincial inequality, significantly impairing education opportunities for children in poorly developed rural provinces.\n\nAlthough basic education policies remain in control of the Communist Party, increased open-mindedness shown by party authorities indicates the possibility of more substantial educational reform, in addition to recent reforms to the national college entrance examination. Although educational inequality has lessened overall, great gaps in educational attainment still exist between populations on multiple divides, affirming the need for a regional focus within reform initiatives.\n\nAlthough recent studies have shown reductions in gender inequality within Chinese education since the 1980s, disparities still remain across different regions of China. Studies have indicated that education in rural areas of China shows significantly greater gender disparity than education in urban areas. Since 1981, the rural illiteracy rate of females has consistently been over twice that of males, despite an overall decrease in illiteracy in rural regions.\n\nHowever, with rapid economic growth, the increase of parental income enables more children to obtain at least a basic education, and this greatly increases chances of girls going to school as well. Previously, it was common for parents to prioritize the education of sons over that of their daughters; with greater opportunities, the demand for female education can be easier satisfied, fueling an increase in the actual demand for female education as well.\n\nThere are a number of factors that contribute to the existing disparities between urban and rural education, with the latter lagging far behind the former as a result of economic, social, and political disparities. In China, the household registration system separates citizens into urban residence and rural residence. The underfunding of rural schools, inadequate government efforts to provide financial aid for rural students, and the current household registration system all contribute to the urban-rural educational divide.\n\nInterprovincial inequality in school funding has increased, along with increased dependence in non-budgeted funding sources. Research indicates that the disparity between provincial primary educational expenditures per student nearly doubled between 1990 and 2000. Additionally, while overall illiteracy rates have dropped since 1980, the disparity between urban and rural illiteracy rates continued to increase, with the rural illiteracy rate double that of urban areas in 2000.\n\nAnother recent problem causing regional education disparity is the migration of a large portion of China's rural population into urban areas. In many rural regions, particularly within smaller rural towns, this decrease in population also creates problems for schools. As a result, to confront drastic increases in enrollment, many schools consolidate students of multiple grade levels into multigrade classes, a practice that not only challenges teachers, but also negatively affects the quality of education that students receive. \n\nAs a result of the vast numbers of rural workers migrating to the cities to find employment opportunities, many children are left behind, keeping these children in rural schools that still lag far behind their urban counterparts. For rural children who do follow their parents to urban areas, the \"hukou\" system bars them from attending urban public schools; these children often must attend private schools that charge higher tuition even while offering subpar education.\n\nThe population of China mainly consists of the Han ethnic majority, with 55 ethnic minorities accounting for around 8% of the total population. However, this small minority population accounts for almost half of China's absolute poor, highlighting the severe income inequality that exists between China's majority Han population and numerous minority groups. At the same time, research indicates that minority education attainment in urban areas, such as Beijing, is on par with Han population attainment. \n\nWhile overall enrollment rates have risen for both the Han Chinese population and the Chinese minority population, minority enrollment rates remain lower than that of the Han majority population. Aside from enrollment rates, ethnic disparities in education have also manifested in the form of cultural marginalization, especially with the emergence of state-sponsored curriculum that enforces assimilation. To preserve individual cultures and languages, many ethnic groups have created multilingual school systems.\n\nEducation heavily influences social and economic mobility, with research indicating that higher levels of parental education positively influence their children's levels of education. This connection is especially significant within rural communities, with education playing a large role in breaking the vicious cycle of poverty.\n\nHowever, Guangjie Ning's contrasting analysis of existing research suggests that income inequality and education equality are mutually reinforcing factors, perpetuating a vicious cycle of their own. Therefore, by Ning's logic, in accordance with the popular perception of education as a means of escape from poverty, children from poorer families theoretically need education the most, yet encounter greater economic barriers that prevent continuation of education.\n\nCurrently, variations in education policy across different levels of schooling continue to contribute to educational inequality. Even within the same region, school attendance and tuition are regulated differently, often causing confusion for families new to the education system.\n\nBeginning in the early 1980s, grades 1-6 have been designated as compulsory education; it was not until the mid-1990s that grades 7-9 were also designated as compulsory. This regulation of earlier education was enhanced by the elimination of tuition for grades 1-9 in the early 2000s, and in recent years, the poor are now able to obtain subsidies for the education of their children. This system of 9 year compulsory education has been partially successful in rural areas, with regions reporting very high primary-level enrollment and completion rates. However, grades 10-12 have not been designated as compulsory, and high secondary-level dropout rates break the 9 year compulsory education cycle even earlier. Additionally, in rural areas, the tuition for public high school is comparatively higher than that of most other developing countries, further discouraging rural households from focusing their income on upper secondary education.\n\nAdditionally, as a result of China’s large population, college enrollment slots are still restricted in availability, with tuition so high that the costs far dwarf the income of a typical family in poverty. Recent efforts to expand college education availability, coupled with increasing emphasis on scholarships and loans, may help counter rising tuition costs (and other income-related barriers to higher education). Despite tuition challenges, more and more students have been able to graduate from college, with the number of college graduates quadrupling in the past decade.\n\nAs an attempt to level the playing field, the \"gaokao\", or Chinese university examination, offered extra points for students of ethnic minority backgrounds, although this was scaled back in recent 2014 reforms to national examination policy after multiple cases of ethnicity alteration prompted national backlash. The new reforms also included provisions for provincial quotas, requiring universities to reserve a designated number of admission seats for students from outside of the university’s region.\n\n"}
{"id": "350966", "url": "https://en.wikipedia.org/wiki?curid=350966", "title": "Emergent materialism", "text": "Emergent materialism\n\nIn the philosophy of mind, emergent (or emergentist) materialism is a theory which asserts that the mind is an irreducible existent in some sense, albeit not in the sense of being an ontological simple, and that the study of mental phenomena is independent of other sciences.\n\nThe view can be divided into emergence which denies mental causation and emergence which allows for causal effect. A version of the latter type has been advocated by John R. Searle, called biological naturalism. \nThe other main group of materialist views in the philosophy of mind can be labeled non-emergent (or non-emergentist) materialism, and includes identity theory (reductive materialism), philosophical behaviorism, functionalism, and eliminativism (eliminative materialism).\n\n\n"}
{"id": "15344883", "url": "https://en.wikipedia.org/wiki?curid=15344883", "title": "Envipco", "text": "Envipco\n\nEnvipco (\"Environmental Products Corporation\") is a global recycling company. Envipco's corporate headquarters are located in Naugatuck, Connecticut. \nEnvipco USA is an American manufacturer and distributor of reverse vending machines and other reverse vending solutions for all size clients - from convenience stores to Redemption Centers and everything in between.\n\nEnvipco products include Reverse vending machines and customized solutions for its clients. Reverse vending machines (RVMs) collect, compact and sort customers' empty beverage containers and, where applicable, issue a voucher redeemable for cash. The Envipco RVMs can also have interactive advertising, couponing and integration with Retailer POS.\nEnvipco's reverse vending machines differ based on the market in which they appear. In deposit-and-return markets, the reverse vending machines use bar code and/or camera technology to identify the product being recycled. In non-deposit markets the reverse vending machines identify the product as being PET or aluminum.In the United States, Envipco machines are most common in the 10 states that require bottle deposits. Envipco's products can be found around the globe in both deposit and non-deposit markets - including USA, Canada, the UK, France, Sweden, Greece, Cyprus, Australia and Japan. \nEnvipco's current flagship product is the Quantum bulk-feed reverse vending machine. The Quantum is the first successful bulk-feed RVM in the industry - a quantum leap in the consumer experience, allowing emptying of entire bags of containers into the machine (no feeding one container at a time). It is the most efficient return of containers in quantities processing over 100 cans and plastic bottles/ minute.\nThe Ultra 48 and HDS product lines are ADA compliant and the mainstay for high volume, single-feed RVMs in the Deposit Market generating a cash voucher for a refund of the deposit paid on the container. \nFor smaller shops and stores, the Flex product is the right model. It is the smallest footprint RVM in Envipco's product portfolio with the lowest price tag. This RVM is best suited for convenience stores, pharmacies, gas stations and other venues where container returns are typically low volume.\nIn states that do not have bottle deposits, as well as outside of the United States, reverse vending machines can generate coupons, prizes or vouchers for donations to schools.\n\nEnvipco's products are also featured in Recycling Centers. The Quantum Outdoor RVM itself can be installed in less than 3 standard parking spaces. It allows storage of approximately 60,000 containers before it needs to be emptied. Envipco's Ultra 48 and Ultra HDS are also featured in outdoor kiosks - especially prolific in the Greek (non-deposit) and Australian (deposit) markets.\n"}
{"id": "2614324", "url": "https://en.wikipedia.org/wiki?curid=2614324", "title": "Exhaustion doctrine under U.S. law", "text": "Exhaustion doctrine under U.S. law\n\nThe exhaustion doctrine, also referred to as the first sale doctrine, is a U.S. common law patent doctrine that limits the extent to which patent holders can control an individual article of a patented product after a so-called authorized sale. Under the doctrine, once an authorized sale of a patented article occurs, the patent holder's exclusive rights to control the use and sale of that article are said to be \"exhausted,\" and the purchaser is free to use or resell that article without further restraint from patent law. However, under the repair and reconstruction doctrine, the patent owner retains the right to exclude purchasers of the articles from making the patented invention anew (i.e., making another article), unless it is specifically authorized by the patentee to do so.\n\nProcedurally, the patent exhaustion doctrine operates as an affirmative defense, shielding authorized purchasers from infringement claims concerning the sale or use (including repair and modification) of a patented product after the patent owner authorized its sale.\n\nBecause only an \"authorized\" sale triggers the doctrine, it may be difficult or at least controversial to determine whether the exhaustion doctrine applies in a particular case: for example, when the patentee purports to restrict or condition the use or resale of the patented article once purchased and in the hands of an end user (post-sale restrictions); or when the patentee licenses another to manufacture and use or sell the patented product only in a particular field. The 2008 Supreme Court decision in \"Quanta Computer, Inc. v. LG Electronics, Inc.\", arguably leaves unclear the extent to which patentees can avoid the exhaustion doctrine by means of so-called limited licenses (licenses limited to a specified field of use). Since its development by the courts in the late 19th century, the patent exhaustion doctrine has raised questions regarding the scope of exclusive rights granted by patents and the extent to which a patent owner may extend those rights to control downstream use and sales of patented articles.\n\nA patent gives the patent owner the right to exclude others from making, using, selling, offering for sale, or importing into the U.S. the patented invention (i.e., a product embodying the invention) during the term of the patent. The constitutional rationale behind providing these exclusive rights is to \"promote the Progress of Science and useful Arts\" by providing inventors the incentive to invest their time, labor, and funds in researching and developing innovative technology. Providing these protections, however, comes with social costs (monopoly rents) and limits the public's ability to freely alienate patented goods. Thus, public policy dictates that the patent owner's exclusive rights be limited in scope. Generally, when a patent owner receives compensation for the use of his or her invention through sale of a patented product, the purpose of patent law is fulfilled with respect to that product. Upon receiving compensation, the patent owner's rights to exclude others are exhausted and \"the patent law affords no basis for restraining the use and enjoyment of the thing sold.\" Accordingly, a patent owner's voluntary introduction of a patented product into commerce without restriction prevents the patent owner from exercising any claimed right to exclude others from using or reselling the sold product.\n\nUnlike the analogous first-sale doctrine in copyright, the patent exhaustion doctrine has not been codified into the patent statute, and is thus still a common law doctrine. It was first explicitly recognized by the Supreme Court in 1873 in \"Adams v. Burke\". In that case, the patentee Adams assigned to another the right to make, use, and sell patented coffin lids only within a ten-mile radius of Boston. Burke (an undertaker), a customer of the assignee, bought the coffin lids from the manufacturer-assignee within the ten-mile radius, but later used (and effectively resold) the patented coffin lids outside of the ten-mile radius, in his trade in the course of burying a person. The patentee Adams sued the undertaker Burke for patent infringement, but the Supreme Court found no infringement liability: Once the coffin lids were lawfully made and sold, \"there is no restriction on their use to be implied for the benefit of the patentee or his assignees or licensees.\" Because the sale was authorized (bought from an authorized seller within the ten-mile radius), the defendant acquired the right to use the coffin lids free from any claim of the patentee, even though he carried it outside the ten-mile radius to use it.\n\nThe exhaustion doctrine is triggered only by a sale authorized by the patent holder. Thus, there are circumstances where it may be difficult to determine whether the exhaustion doctrine is triggered, in light of restrictions that the patentee has purported to place on the sale or use of the patented invention. Two general questions arise in these situations: (1) Was the sale authorized by the patentee? This can often be a complex factual question. (2) Regardless of whether authorized by the patentee, are those restrictions valid and recognizable under the law?\n\nGenerally, these cases involve one or more of the following scenarios: the patent owner: (1) sells one or more components of a multi-component patented product; (2) licenses another to make and sell patented product with certain restrictions on field in which the sale may be made; or (3) sells the article with restrictions directly on the purchasers or end-users (post-sale restraint).\n\nOne scenario in which the exhaustion doctrine may or may not be triggered is when the patent holder sells an incomplete article or precursor or ingredient that does not directly practice or embody the patent in suit. In this situation, exhaustion is triggered by the authorized sale of the incomplete article if: (1) its \"only reasonable and intended use was to practice the patent, and (2) it \"embodies essential features\" of the patented invention. Even if the exhaustion doctrine is applicable to the sale of an incomplete article, however, there is a separate analysis of whether the sale of that article was actually authorized, and therefore whether exhaustion was actually triggered.\n\nThe applicability of exhaustion to the sale of an incomplete article was recognized by the Supreme Court in 1942 in \"United States v. Univis Lens Co.\". In that case, the patent holder sold lens blanks which had to be ground into finished lenses — the patented invention. The Court held that this sale exhausted the patents on the finished lenses because the lens blanks substantially \"embodi[ed] essential features of the patented device and [were] without utility until . . . ground and polished as the finished lens of the patent.\" The Court noted that the grinding process was standard (conventional) and not central to the patents, indicating further that the lens blanks constituted a material part of the patented invention and all but completely practiced the patent, since only conventional further processing steps were needed to complete the invention.\n\nIn \"Quanta\", the Supreme Court applied the same test to determine whether exhaustion is triggered by the licensing of a portfolio of product and method patents. In that case, the patent holder (LGE) authorized the licensee (Intel) by cross-license to manufacture and sell microprocessors and chipsets that (unless licensed) would infringe LGE product and method patents, as well as patents on computer systems containing the licensed microprocessors and chipsets. The Court found that, even though these Intel products did not directly practice the system patents, they sufficiently embodied the inventions of those patents, making the exhaustion doctrine applicable. First, the Court found that there was no reasonable use for the Intel products other than incorporating them into a computer system that practiced the LGE system patents. Second, the Intel products embodied essential features of the patented processes because the only necessary step to practice the patents was the addition of such standard computer parts as memories and buses. In addition, there was nothing inventive about the systems other than that they contained the inventive microprocessors and chipsets. Thus, under the \"Univis\" test, the Intel products sufficiently embodied the patents, making the exhaustion doctrine applicable.\n\nAnother scenario in which it may be difficult to determine if the sale of a patented article was authorized, and therefore if exhaustion is triggered, occurs when the patentee grants a license to make and sell with specific limitations on the field in which the seller may operate, such as sales to particular types of customer, specified territories, or other field-of-use limitations. If these limitations (or \"restrictions\") have been imposed, the licensee's sale to a purchaser exhausts only the patentee's rights to restrict use and resale when the restrictions have not been exceeded (\"violated\"). The theory is that if Alice owns Blackacre but not Whiteacre, she cannot convey good title to Bob by purporting to sell him Whiteacre. She can sell only what she owns. If the license limitations (\"restrictions\") are exceeded (\"violated\"), then exhaustion cannot occur and therefore is not triggered, and the patentee can successfully sue the licensee and any downstream customers for patent infringement.\n\nThe Supreme Court in \"General Talking Pictures Corp. v. Western Electric Co.\" has specifically upheld the legitimacy of field-of-use limitations in patent licenses to manufacture patented products. A licensee who exceeds (\"violates\") a field-of-use limitation by selling an article outside of the permissible field commits patent infringement. The exhaustion doctrine would provide no protection because the \"violation\" makes the sale \"unauthorized\" for the purposes of the exhaustion doctrine.\n\nThe field-of-use limitations on sale (those imposed on the licensee in selling the patented articles) are different from post-sale restrictions or limitations (those that purpose to restrict the use or sale of the patented article once purchased and in the hands of an end user). Patentees can avoid the exhaustion doctrine by imposing the former, but it is questionable that patentees can do so through the latter.\n\nLimitations on sale must very explicitly bind the licensee or seller. For example, in \"Quanta\", LGE licensed Intel to make products using LGE's patents. The license expressly stated that LGE was not licensing third parties to combine licensed products with any non-Intel products (i.e., microprocessors and chipsets purchased from a third party), and LGE required Intel to notify customers of that. Intel sold products to Quanta, who combined the Intel products with non-Intel products. LGE sued Quanta for patent infringement. The Supreme Court found that the licensing agreement failed to explicitly impose a field-of-use limitation, and therefore found that there were no conditions limiting to whom Intel could sell. The sale was thus \"authorized,\" and exhaustion was triggered. In the Court's words, \"The License Agreement authorized Intel to sell products that practiced the patents. No conditions limited Intel's authority to sell products substantially embodying the patents. . . . Intel's authorized sale to Quanta thus took its products outside the scope of the patent monopoly, and as a result, LGE can no longer assert its patent rights against Quanta.\"\n\nBecause the contractual documents in the \"Quanta\" case were insufficiently explicit, the Court applied the exhaustion doctrine, finding the sale \"authorized\" and unconditional, even though LGE attempted to impose some restrictions on use of the products. Therefore, purchasers of the patented product were free to use them without restrictions that the patentee sought to have imposed on them. The Court found that the licensing agreement did not impose any limitations on whom the licensee could sell to. The \"Quanta\" Court did not address, however, whether the restriction in the licensing agreement could be enforced by contract. In fact, the Court pointedly said it was not addressing that issue.\n\nThe most difficult and unsettled area of the law regarding patent exhaustion involves cases in which a patentee purports to impose post-sale restrictions. Post-sale restrictions are those that purport to restrict the use or sale of the patented article once purchased and in the hands of an end user customer, rather than similar limitations on a manufacturer-licensee. Common post-sale restrictions include \"single use only\" and \"refill only with proprietary ink\" notices. Whether violations of such restrictions make a sale \"unauthorized,\" and therefore make patent exhaustion inapplicable, is still unclear or at least controversial.\n\nIn 1992, the Federal Circuit approved the use of post-sale restrictions in \"Mallinckrodt, Inc. v. Medipart, Inc.\". Specifically, the court held that patent owners could condition the sale of patented goods with a restrictive notice and thereby restrict the disposition of the goods by the purchasers, with the exception of such antitrust law violations as price-fixing and tie-in restrictions, or violations of \"some other law or policy.\" The plaintiff in the case owned a patent on a medical device, which it sold to hospitals with a \"single use only\" notice label. The defendant purchased the used devices from hospitals, refurbished them, and resold them to hospitals. The Federal Circuit held that the single-use restriction was enforceable in accordance with the 1926 \"General Electric\" case, because the restriction was \"reasonably within the patent grant. . . .\"\n\nThe Supreme Court did not discuss the \"Mallinckrodt\" case in \"Quanta\". As one commentator noted: \"The Supreme Court, in \"Quanta\", was widely expected to rule on whether \"Mallinckrodt\" was good law. But the Court sidestepped the issue by narrowly interpreting the license agreement so that it was not a conditional license. . . . Because the Supreme Court sidestepped the issue, it remains unclear to what extent a patentee can use a conditional license to impose restrictions on downstream purchasers.\"\n\nAt least two district courts have concluded that \"Mallinckrodt\" is no longer good law after \"Quanta\". In \"Static Control Components, Inc. v. Lexmark Int'l, Inc.\", the court concluded that the Supreme Court's \"Quanta\" decision implicitly overruled \"Mallinckrodt\". At issue in \"Static Control\" was Lexmark's so called \"prebate\" program, in which customers could buy cartridges that were subject to a single use for a 20 percent discounted price. In its original order, before \"Quanta\" was decided, the court rejected Static Control's argument that Lexmark's patent rights were exhausted as a result of the authorized sale of the cartridges. Relying heavily on \"Mallinckrodt\", the court found that the sales were valid post-sale restrictions that avoided exhaustion. After \"Quanta\" was decided, however, the court reversed its original order and concluded that Lexmark's single use restriction was not enforceable under patent law because the court was \"persuaded that Quanta overruled Mallinckrodt sub silentio.\" The court explained, \"The Supreme Court's broad statement of the law of patent exhaustion simply cannot be squared with the position that the \"Quanta\" holding is limited to its specific facts. Further, the Federal Circuit relied in part on \"Mallinckrodt\" in reaching its decision in \"LG Electronics, Inc. v. Bizcom Electronics, Inc.\", 453 F.3d 1364, 1369 (Fed. Cir. 2006), the decision the Supreme Court reversed in \"Quanta\". It is also worth noting that the \"Quanta\" decision did not mention a single Federal Circuit case.\"\n\nThe district court's conclusion, however, that \"Quanta\" overruled \"Mallinckrodt\" reflects the ambiguity in \"Quanta\" itself. The \"Static Control\" court noted that \"[s]ales of Lexmark Prebate cartridges were unconditional\" because \"[n]o potential buyer was required to agree to abide by the Prebate terms before purchasing a cartridge. Thus, sales of Lexmark's Prebate toner cartridges were authorized and unconditional, just like sales of LGE's patented products in \"Quanta\".\"\n\nTherefore, both \"Quanta\" and \"Static Control\" can be seen as either cautionary tales about failed attempts to comply with the General Talking Pictures doctrine or to explicitly condition sales, without need to rule on whether the post-sale restrictions were valid, or as overruling \"Mallinckrodt\"'s approval of post-sale restrictions. Which interpretation is correct remains to be seen. The Federal Circuit's decision in the \"en banc\" reargument of \"Lexmark Int'l v. Impression Prods.\" should provide a more definitive answer, subject of course to possible further review in the Supreme Court.\n\nAn emerging issue is whether U.S. patent exhaustion is international or strictly national. Until recently, or at least since the formation of the Federal Circuit in 1982 until recently, most U.S. courts simply assumed that a sale outside the United States, even if made by the U.S. patent owner or its parent, subsidiary, or affiliate, or by the U.S. patent owner's licensee, did not trigger the exhaustion doctrine within the United States. Usually, the basis for the assumption was (1) the Supreme Court allegedly so held in \"Boesch v. Graff\",; (2) a foreign patent is a different property right that is not the same as a corresponding U.S. patent because foreign patent law is different from U.S. patent law and gives different scope to such a foreign patent; and (3) many cases hold that U.S. patent law has no \"extraterritorial\" application.\n\nNone of these points is on firm, sound ground. In the \"Boesch\" case, a seller entirely unrelated to the U.S. patent owner made the sale in Germany; the German seller had a right to sell the product under German law because it had begun preparation to manufacture the product before the U.S. patent owner applied for its German patent. The U.S. company (the patentee) had no complicity in the sale and did not profit from it, and could not possible be accused of \"double dipping.\" This is quite unlike the usual U.S. situation, such as that in the \"Lexmark\" and \"Jazz\" cases, in which the U.S. patent owner was responsible for the foreign sale, and therefore profited from it. The \"Boesch\" case is therefore not a proper precedent to support the general international exhaustion situation.\n\nWhether foreign patents are comparable to U.S. patents is a factual issue that may differ from case to case, or nation to nation, and cannot be assumed one way or the other. Furthermore, 35 U.S.C. § 119(a), the U.S. patent statute governing when a U.S. patent can be based on a filing of a foreign patent application, provides that the U.S. patent and the corresponding foreign patent must be \"for the same invention.\" Therefore, there may be far more similarity than the cases assume.\n\nFinally, the statement that U.S. patent law is without extraterritorial application occurs universally in cases holding that liability for patent infringement under U.S. law should not be based on acts and conduct occurring outside the United States. And even that generality is suspect, for sometimes patent infringement liability in the United States is based on conduct outside the United States. Applying exhaustion on an international basis does not regulate acts and conduct performed outside the United States; it defines infringement remedies against importation into and sale in the United States on the basis of acts and conduct performed outside the United States.\n\nThe point is now pending decision in the Federal Circuit, because that court has ordered \"en banc\" rehearing on that issue in the \"Lexmark\" case. The reason that the issue has come to the fore is that the Supreme Court, in its recent copyright decision in \"Kirtsaeng v. John Wiley & Sons, Inc.\", held that a foreign sale authorized by the copyright owners exhausts U.S. copyright. The Supreme Court rested its decision mainly on common-law authority, quoting extensively from Coke's Institutes (Coke on Littleton), and saying that this stated the general rule from which any exception must be proved. Some have thought, therefore, that the same principle applies at least as forcefully in patent law as in copyright law, so that patent exhaustion should be international just as copyright exhaustion is.\n\nIn Europe and Japan, a regime of absolute or modified international exhaustion of patent rights is followed. Australia, New Zealand, and Norway also adopt international patent exhaustion.\n\nThe World Trade Organization (WTO) Agreement on Trade Related Aspects of Intellectual Property Rights (TRIPS) explicitly leaves to each member state the freedom to address exhaustion of intellectual property. A World Intellectual Property Organization (WIPO) report in 2010 provides a listing of various countries' statutory provisions on international exhaustion.\n\nAnother emerging issue under the exhaustion doctrine is what persons may assert the exhaustion doctrine as a defense to a claim of patent infringement. In most of the exhaustion cases discussed earlier in this article, the facts of the case follow what may be termed a \"straight line\" pattern: A patentee \"A\" (or its licensee) makes and sells a product \"a\" covered by patent \"P1\" to customer \"C\". \"C\" then does something with \"a\" that \"A\" has ordered (by some sort of agreement or putative agreement) \"C\" not to do. A patent infringement suit, \"A v. C\", follows. Diagrammatically, this fact pattern may be represented as:\n\" A → a (P1) → C \"\nNew information-technology inventions can lead to exhaustion suits following a different fact pattern, because of peculiarities of information technology and present U.S. patent law. An information-technology invention may involve several aspects each of which has a separate stakeholder. For example, a smartphone, TV set, or set-top box may be economically important to both equipment manufacturers and content providers, as well as the end user public (i.e., consumers). A license or sale to one stakeholder may or may not trigger the exhaustion doctrine with respect to conduct by another stakeholder, perhaps depending on how relevant business transactions are structured.\n\nUnder present U.S. patent law, a method claim of a patent is infringed only when a single actor performs each step of the claim. Similarly, induced infringement of a method claim has the same requirement. System claims raise more complicated issues. One can make the system only by placing each element into combination with the others, but it is possible to be liable for using a system invention merely by commercially exploiting the system. Therefore, when both the relevant equipment manufacturer and content provider utilize aspects of the invention in a method claim, whether infringement liability attaches to them may depend on both how the relevant claim is written and how licenses or sales are structured. This is illustrated in pending smartphone litigation, in which structure dictated the legal outcome.\n\nIn \"Helferich Patent Licensing, LLC v. New York Times Co.\", the Federal Circuit overturned a district court's summary dismissal on exhaustion grounds of a patent infringement suit against content providers. The invention concerns methods and systems for alerting smartphone users to content that may be of interest to them, for example, breaking news stories. The way the invention works is along these lines: A content provider such as the New York Times sends a text message to its online subscribers' smartphones. The message might consist of a headline and the lead to a story, together with a hyperlink to the story as stored in the online database of the New York Times. A subscriber interested in reading the story clicks on the link and thus causes the browser for the smartphone to retrieve and display the story.\n\nThe way the claims were drafted is very important to the outcome. There are two relevant types of claim, One set considers only smartphone manufacturers, and the claims describe only acts performed in the smartphone (receiving signals, clicking on hyperlinks, etc.). The other set of claims considers only acts that the content providers perform (sending the text message alert, storing the news story, sending it out over the Internet in response to a hyperlink click, etc.). Thus, it is possible to infringe one set of these single-actor claims without infringing the other.\n\nThe patentee licensed substantially all smartphone manufacturers in the United States under the first set of patents. It then sought to license content providers. When some content providers, including the New York Times, refused to take licenses under the second set of patents, claiming that under the exhaustion doctrine they needed no licenses, the patentee sued them. Instead of the \"straight line\" fact pattern described above for prior exhaustion cases, this case has a different, bi-directional pattern. Diagrammatically, the fact pattern of this type of case is as follows:\n\" P → lic (P1) → A, a \"\n\n\" A → a (P1) → C ← i (P2) ← B \"\nOn appeal from the district court's summary judgment ruling, the Federal Circuit held that the structure of the patent licensing arrangement avoided the exhaustion doctrine. The court ruled that the exhaustion doctrine may be asserted only by an \"authorized acquirer\" — one who purchases the patented article from the patentee or its authorized seller. The court further explained this, using slightly different terminology:\n\n[It is a] core notion that exhaustion lifts legal restrictions on an authorized acquirer. The doctrine has never applied unless, at a minimum, the patentee's allegations of infringement . . . entail infringement of the asserted claims by authorized acquirers . . . Here, as noted, that is not so, because infringement of the content claims has not been . . . shown to require that [the authorized] handset acquirers are practicing those claims.\n\nAs the patentee put it in its brief, and the court accepted, \"the exhaustion doctrine protects only the ability of a purchaser (or other lawful possessor) of an article to use and sell the article.\" The content providers were not parties to the transaction that triggered whatever exhaustion there was — that transaction was the sale of smartphones by manufacturers to consumers. The exhaustion doctrine exists to protect the interests of purchasers, not third parties. The patentee told the Federal Circuit, and it apparently agreed, that the exhaustion doctrine does not immunize the conduct of the content providers, \"regardless of the effect on the amount of licensed content available to their subscribers' handsets.\"\n\nMoreover, the patent claims licensed to the manufacturers (the \"P1\" of the diagram above) are not infringed by the conduct of the content providers accused of infringement. Their conduct infringes the \"P2\" patent claims that were not licensed to the manufacturers. The only sale in the case was by the licensed smartphone manufacturers to the consumer end users, and that sale exhausted only the \"P1\" claims. The Federal Circuit said exhaustion cannot occur as to unrelated patent claims. The court added that the content providers had not shown that the licensed \"P1\" claims embodied substantially the same invention as the \"P2\" patent claims under which the content providers were sued, so that the doctrine of the \"Univis\" and \"Quanta\" cases did not apply to expand the scope of the exhaustion.\n\nThere is another possible way to analyze cases of this type, but the parties did not raise it and the court did not address it. That would be to make an equitable estoppel analysis as to whether smartphone purchasers had reasonable expectations at the time of purchase and whether the result reached in the case unfairly and substantially derogated from the rights the purchasers expected to enjoy, as a result of conduct by the plaintiff. That is an approach similar to one of those that the House of Lords considered in the \"British Leyland\" case.\n\nOther countries recognize legal doctrines comparable to the exhaustion doctrine of U.S. patent law.\n\nIn \"Eli Lilly and Co. v. Apotex Inc.\", the Supreme Court of Canada adopted the principle that sale of a patented article exhausts the patentee's right in that article. In the \"Eli Lilly\" case the Supreme Court also took the position that subsequent purchasers are not bound by any contractual limitations imposed by the patentee, unless they are brought to their attention at the time of sale: \"restrictive conditions imposed by a patentee on a purchaser or licensee do not run with the goods unless they are brought to the attention of the [subsequent] purchaser at the time of their acquisition.\" This principle appears to differ somewhat from U.S. patent law, in which bringing the restriction to the attention of the purchaser is generally immaterial.\n\nApproximately 60 percent of European patent litigation is in German courts. German law has long recognized the exhaustion doctrine. In the \"Fullplastverfahren\" case, the German Federal Supreme Court stated:\n\nThe doctrine [of exhaustion] finds its justification in the argument that the holder of the rights who puts into circulation the product produced under the application of the protected procedure has had the opportunity to avail himself of the advantages granted by the patent.\nA commentator asserts that the decision of the German Federal Supreme Court in the \"Brochure Rock\" case would require a contrary result as to the fact pattern of the U.S. \"Quanta\" case (discussed above). The sale of the chips would \"not\" exhaust the patent rights to the computer systems containing the chips, so that LG in that case would have been entitled to a further royalty payment from Quanta despite LG's license to the chip manufacturer Intel.\n\nA recent decision of the Düsseldorf District Court, however, perhaps points to greater similarity between German and U.S.; patent law. The case had facts almost identical to those of the \"Quanta\" case. The court held that the sale of the component did not exhaust the patent rights on the system because, among other things, the components sold by the suppliers did not make use of the teachings of the system patent.\n\nAs for using the doctrine of the U.S. \"Quanta\" case, the Düsseldorf District Court stated that the rationale for such an \"extended exhaustion doctrine\" could only be to prevent the patent owner from enjoying the advantages of the patent more than once, that is, \"double dipping\" or \"double charging.\" The court said that such a danger of double charging at different stages of the distribution chain and, thus, a rationale for an \"extended exhaustion doctrine,\" might exist if, in one and the same patent, there is a claim to the overall device and a claim to an individual component of the overall device. That was not the case here.\n\nA second basis for an \"extended exhaustion doctrine\" \"might\" exist if the overall device and its individual components are protected by different patents (as here), but only when the inventive concept of the two patents is the same and is substantially embodied in the component. But that was not true here, as it was in the \"Quanta\" case. This is the point of possible similarity to \"Quanta,\" but it is entirely in the form of \"obiter dicta\",\n\nThe court ruled that the fact that the component had no reasonable use except in making the patented system (which was so in the \"Quanta\" case) did not matter, because that raised an implied license issue rather than an exhaustion issue. The component manufacturer's license expressly disclaimed any such implied license as to the system (as in the \"Quanta\" case).\n\n"}
{"id": "3362896", "url": "https://en.wikipedia.org/wiki?curid=3362896", "title": "Family resemblance", "text": "Family resemblance\n\nFamily resemblance () is a philosophical idea made popular by Ludwig Wittgenstein, with the best known exposition given in his posthumously published book \"Philosophical Investigations\" (1953). It argues that things which could be thought to be connected by one essential common feature may in fact be connected by a series of overlapping similarities, where no one feature is common to all of the things. Games, which Wittgenstein used as an example to explain the notion, have become the paradigmatic example of a group that is related by family resemblances. It has been suggested that Wittgenstein picked up the idea and the term from Nietzsche, who had been using it, as did many nineteenth century philologists, when discoursing about language families.\n\nThe first occurrence of the term \"Family resemblance\" is found in a note from 1930, commenting on Spengler's ideas. The notion itself features widely in Wittgenstein's later work, and in the \"Investigations\" it is introduced in response to questions about the general form of propositions and the essence of language – questions which were central to Wittgenstein throughout his philosophical career. This suggests that family resemblance was of prime importance for Wittgenstein's later philosophy; however, like many of his ideas, it is hard to find precise agreement within the secondary literature on either its place within Wittgenstein's later thought or on its wider philosophical significance.\n\nSince the publication of the \"Investigations,\" the notion of family resemblance has been discussed extensively not only in the philosophical literature, but also, for example, in works dealing with classification where the approach is described as \"polythetic\", distinguishing it from the traditional approach known now as \"monothetic\". Prototype theory is a recent development in cognitive science where this idea has also been explored. As the idea gains popularity, earlier instances of its occurrence are rediscovered e.g. in 18th century taxonomy, in the writings of Vygotsky or Tatarkiewicz.\n\nThe local context where the topic of family resemblances appears is Wittgenstein's critique of language. In \"Philosophical Investigations\" §65-71 the plurality of language uses is compared to the plurality of games. Next it is asserted that games have common features but no one feature is found in all of them. The whole argument has become famous under the heading 'language games'.\n\nThe larger context in which Wittgenstein's philosophy is seen to develop considers his uncompromising opposition to essences, mental entities and other forms of idealism which were accepted as a matter of fact in continental philosophy at the turn of the preceding century. In his view, the main cause for such errors is language and its uncritical use. In the received view, concepts, categories or classes are taken to rely on necessary features common to all items covered by them. Abstraction is the procedure which acknowledges this necessity and derives essences, but in the absence of a single common feature, it is bound to fail.\n\nThe term \"Family resemblance\" as feature of Wittgenstein's philosophy owes much to its translation in English. Wittgenstein, who wrote mostly in German, used the compound word 'Familienähnlichkeit', but as he lectured and conversed in English he used 'family likeness' (e.g. \"The Blue Book\", p. 17,33; \"The Brown Book\",§66). However, in the \"Philosophical Investigations\" the separate word 'Ähnlichkeit' has been translated as 'similarity' (§§11,130,185,444) and on two occasions (§§9,90) it is given as 'like'. The German family-word is common and it is found in Grimm's dictionary; a rare occurrence of 'family likeness' has been noted in a lecture by J. F. Moulton in 1877.\n\nGames are the main example considered by Wittgenstein in his text where he also mentions numbers and makes an analogy with a thread. He develops his argument further by insisting that in such cases there is not a clear cut boundary but there arises some ambiguity if this indefiniteness can be separated from the main point.\nIn §66 Wittgenstein invites us to \nThe section mentions card games, board games, ball games, games like ring-a-ring-a-roses and concludes:\n\nThe following §67 begins by stating:\n\nand extends the illustration\n\nThe problem of boundaries begins in §68\nThere are some simple models\nwhich can be derived from the text of §66-9. The most simple one, which fits Wittgenstein's exposition, seems to be the sorites type. It consists in a collection of items \"Item_1\", \"Item_2\", \"Item_3\"... described by features A, B, C, D, ...:\n\n\"Item_1\": A B C D <br>\n\"Item_2\": B C D E <br>\n\"Item_3\": C D E F <br>\n\"Item_4\": D E F G <br>\n\"Item_5\": E F G H <br>\n\nIn this example, which presents an indefinitely extended ordered family, resemblance is seen in shared features: each item shares three features with his neighbors e.g. \"Item_2\" is like \"Item_1\" in respects B, C, D, and like \"Item_3\" in respects C, D, E. Obviously what we call 'resemblance' involves different aspects in each particular case. It is also seen to be of a different 'degree' and here it fades with 'distance': \"Item_1\" and \"Item_5\" have nothing in common.\n\nAnother simple model is described as:\n\n\"Item_1\": A B C <br>\n\"Item_2\": B C D <br>\n\"Item_3\": A C D <br>\n\"Item_4\": A B D <br>\nIt exhibits the presence of a constant degree of resemblance and the\nabsence of a common feature without extending to infinity.\n\nWittgenstein rejects the disjunction of features or 'properties', i.e. the set {A,B,C,D..}, as something shared by all items. He admits that a 'sharing' is common to all but deems that it is only verbal:\n\nWittgenstein's suggestion (PI, §66) about the impossibility of formulating a definition of games portrays a predicament for disciplines, which entail games as their subject matter, because it denies the possibility to know what games are. One possible solution is to point out that Wittgenstein merely acts out his failing attempt to define the concept of game, because he wanted to demonstrate a mechanism of language. He wasn't particularly concerned about games, nor about the concept of 'game', but he was interested in the consequence of a definitory failure. The demonstration aims to show, that there is no reason to search for real definitions, which describe essential attributes of things, but rather nominal definitions, which describe the use of the term in a community. He connected this idea to language games – lingual expressions combined with action – as a more adequate alternative to explain the function of language. Confusing this is his choice to denominate the approach (PI, §7) as 'language games', further fueling the impression that he provides insights about the concept of game. Wittgenstein wasn't interested in games but in language, therefore his theories and examples are only superficially related to academic disciplines with games as subject matter.\n\n\"Philosophical Investigations\" is the primary text used in discussing family resemblances, even though the topic appears also in other works by Wittgenstein, notably \"The Brown Book\". Many contributions to the discussion are by people involved in philosophical research but concerned with more pragmatic questions such as taxonomy or information processing. Hans Sluga has observed that \"the notion of family resemblance... draws on two quite different sets of ideas, two different vocabularies, but treats them as if they were one and the same. The first is the vocabulary of kinship, of descent, of some sort of real and causal connection.. the second is that of similarity, resemblance, affinity and correspondence.\"\n\nThe main focus for criticism is the notion of similarity, which is instrumental for family resemblance. A similarity is always found for two arbitrarily selected objects, or a series of intermediaries can link them into a family. This problem has been known as underdeterminacy or open ended texture. Admittedly infinity is only potential but for any finite family some common element can be pointed out, especially if relational properties are taken into consideration. \nWittgenstein's insistence that boundaries do not really exist but can\nbe traced arbitrarily has been described as conventionalism and more generally the acceptance of his conception has been seen to present a refined nominalism.\n\n\n\n"}
{"id": "36751542", "url": "https://en.wikipedia.org/wiki?curid=36751542", "title": "Flowers of the Four Seasons", "text": "Flowers of the Four Seasons\n\nThe Flowers of the Four Seasons are a group of flowers found in Chinese art and culture which represent the four seasons, consisting of the orchid (spring), the lotus (summer), the chrysanthemum (autumn) and the plum blossom (winter). They contain three of the elements of the Four Gentlemen.\n\n\n"}
{"id": "230846", "url": "https://en.wikipedia.org/wiki?curid=230846", "title": "Futurism", "text": "Futurism\n\nFuturism () was an artistic and social movement that originated in Italy in the early 20th century. It emphasized speed, technology, youth, violence, and objects such as the car, the airplane, and the industrial city. Its key figures were the Italians Filippo Tommaso Marinetti, Umberto Boccioni, Carlo Carrà, Gino Severini, Giacomo Balla, and Luigi Russolo. It glorified modernity and aimed to liberate Italy from the weight of its past. Cubism contributed to the formation of Italian Futurism's artistic style. Important Futurist works included Marinetti's \"Manifesto of Futurism\", Boccioni's sculpture \"Unique Forms of Continuity in Space\", Balla's painting \"Abstract Speed + Sound\", and Russolo's \"The Art of Noises\". Although it was largely an Italian phenomenon, there were parallel movements in Russia, England, Belgium and elsewhere. The Futurists practiced in every medium of art, including painting, sculpture, ceramics, graphic design, industrial design, interior design, urban design, theatre, film, fashion, textiles, literature, music, architecture, and even Futurist meals. To some extent Futurism influenced the art movements Art Deco, Constructivism, Surrealism, Dada, and to a greater degree Precisionism, Rayonism, and Vorticism.\n\nFuturism is an avant-garde movement founded in Milan in 1909 by the Italian poet Filippo Tommaso Marinetti. Marinetti launched the movement in his \"Futurist Manifesto\", which he published for the first time on 5 February 1909 in \"La gazzetta dell'Emilia\", an article then reproduced in the French daily newspaper \"Le Figaro\" on Saturday 20 February 1909. He was soon joined by the painters Umberto Boccioni, Carlo Carrà, Giacomo Balla, Gino Severini and the composer Luigi Russolo. Marinetti expressed a passionate loathing of everything old, especially political and artistic tradition. \"We want no part of it, the past\", he wrote, \"we the young and strong \"Futurists!\"\" The Futurists admired speed, technology, youth and violence, the car, the airplane and the industrial city, all that represented the technological triumph of humanity over nature, and they were passionate nationalists. They repudiated the cult of the past and all imitation, praised originality, \"however daring, however violent\", bore proudly \"the smear of madness\", dismissed art critics as useless, rebelled against harmony and good taste, swept away all the themes and subjects of all previous art, and gloried in science.\n\nPublishing manifestos was a feature of Futurism, and the Futurists (usually led or prompted by Marinetti) wrote them on many topics, including painting, architecture, religion, clothing and cooking.\n\nThe founding manifesto did not contain a positive artistic programme, which the Futurists attempted to create in their subsequent \"Technical Manifesto of Futurist Painting\" (1914). This committed them to a \"universal dynamism\", which was to be directly represented in painting. Objects in reality were not separate from one another or from their surroundings: \"The sixteen people around you in a rolling motor bus are in turn and at the same time one, ten four three; they are motionless and they change places. ... The motor bus rushes into the houses which it passes, and in their turn the houses throw themselves upon the motor bus and are blended with it.\"\n\nThe Futurist painters were slow to develop a distinctive style and subject matter. In 1910 and 1911 they used the techniques of Divisionism, breaking light and color down into a field of stippled dots and stripes, which had been originally created by Giovanni Segantini and others. Later, Severini, who lived in Paris, attributed their backwardness in style and method at this time to their distance from Paris, the centre of avant-garde art. Severini was the first to come into contact with Cubism and following a visit to Paris in 1911 the Futurist painters adopted the methods of the Cubists. Cubism offered them a means of analysing energy in paintings and expressing dynamism.\nThey often painted modern urban scenes. Carrà's \"Funeral of the Anarchist Galli\" (1910–11) is a large canvas representing events that the artist had himself been involved in, in 1904. The action of a police attack and riot is rendered energetically with diagonals and broken planes. His \"Leaving the Theatre\" (1910–11) uses a Divisionist technique to render isolated and faceless figures trudging home at night under street lights.\n\nBoccioni's \"The City Rises\" (1910) represents scenes of construction and manual labour with a huge, rearing red horse in the centre foreground, which workmen struggle to control. His \"States of Mind\", in three large panels, \"The Farewell\", \"Those who Go\", and \"Those Who Stay\", \"made his first great statement of Futurist painting, bringing his interests in Bergson, Cubism and the individual's complex experience of the modern world together in what has been described as one of the 'minor masterpieces' of early twentieth century painting.\" The work attempts to convey feelings and sensations experienced in time, using new means of expression, including \"lines of force\", which were intended to convey the directional tendencies of objects through space, \"simultaneity\", which combined memories, present impressions and anticipation of future events, and \"emotional ambience\" in which the artist seeks by intuition to link sympathies between the exterior scene and interior emotion.\n\nBoccioni's intentions in art were strongly influenced by the ideas of Bergson, including the idea of intuition, which Bergson defined as a simple, indivisible experience of sympathy through which one is moved into the inner being of an object to grasp what is unique and ineffable within it. The Futurists aimed through their art thus to enable the viewer to apprehend the inner being of what they depicted. Boccioni developed these ideas at length in his book, \"Pittura scultura Futuriste: Dinamismo plastico\" (\"Futurist Painting Sculpture: Plastic Dynamism\") (1914).\nBalla's \"Dynamism of a Dog on a Leash\" (1912) exemplifies the Futurists' insistence that the perceived world is in constant movement. The painting depicts a dog whose legs, tail and leash —and the feet of the woman walking it —have been multiplied to a blur of movement. It illustrates the precepts of the \"Technical Manifesto of Futurist Painting\" that, \"On account of the persistency of an image upon the retina, moving objects constantly multiply themselves; their form changes like rapid vibrations, in their mad career. Thus a running horse has not four legs, but twenty, and their movements are triangular.\" His \"Rhythm of the Bow\" (1912) similarly depicts the movements of a violinist's hand and instrument, rendered in rapid strokes within a triangular frame.\n\nThe adoption of Cubism determined the style of much subsequent Futurist painting, which Boccioni and Severini in particular continued to render in the broken colors and short brush-strokes of divisionism. But Futurist painting differed in both subject matter and treatment from the quiet and static Cubism of Picasso, Braque and Gris. Although there were Futurist portraits (e.g. Carrà's \"Woman with Absinthe\" (1911), Severini's \"Self-Portrait\" (1912), and Boccioni's \"Matter\" (1912)), it was the urban scene and vehicles in motion that typified Futurist painting—e.g. Boccioni's \"The Street Enters the House\" (1911), Severini's \"Dynamic Hieroglyph of the Bal Tabarin\" (1912), and Russolo's \"Automobile at Speed\" (1913)\n\nIn 1912 and 1913, Boccioni turned to sculpture to translate into three dimensions his Futurist ideas. In \"Unique Forms of Continuity in Space\" (1913) he attempted to realise the relationship between the object and its environment, which was central to his theory of \"dynamism\". The sculpture represents a striding figure, cast in bronze posthumously and exhibited in the Tate Modern. (It now appears on the national side of Italian 20 eurocent coins). He explored the theme further in \"Synthesis of Human Dynamism\" (1912), \"Speeding Muscles\" (1913) and \"Spiral Expansion of Speeding Muscles\" (1913). His ideas on sculpture were published in the \"Technical Manifesto of Futurist Sculpture\" In 1915 Balla also turned to sculpture making abstract \"reconstructions\", which were created out of various materials, were apparently moveable and even made noises. He said that, after making twenty pictures in which he had studied the velocity of automobiles, he understood that \"the single plane of the canvas did not permit the suggestion of the dynamic volume of speed in depth ... I felt the need to construct the first dynamic plastic complex with iron wires, cardboard planes, cloth and tissue paper, etc.\"\n\nIn 1914, personal quarrels and artistic differences between the Milan group, around Marinetti, Boccioni, and Balla, and the Florence group, around Carrà, Ardengo Soffici (1879–1964) and Giovanni Papini (1881–1956), created a rift in Italian Futurism. The Florence group resented the dominance of Marinetti and Boccioni, whom they accused of trying to establish \"an immobile church with an infallible creed\", and each group dismissed the other as \"passéiste.\"\n\nFuturism had from the outset admired violence and was intensely patriotic. The \"Futurist Manifesto\" had declared, \"We will glorify war —the world's only hygiene —militarism, patriotism, the destructive gesture of freedom-bringers, beautiful ideas worth dying for, and scorn for woman.\" Although it owed much of its character and some of its ideas to radical political movements, it was not much involved in politics until the autumn of 1913. Then, fearing the re-election of Giolitti, Marinetti published a political manifesto. In 1914 the Futurists began to campaign actively against the Austro-Hungarian empire, which still controlled some Italian territories, and Italian neutrality between the major powers. In September, Boccioni, seated in the balcony of the Teatro dal Verme in Milan, tore up an Austrian flag and threw it into the audience, while Marinetti waved an Italian flag. When Italy entered the First World War in 1915, many Futurists enlisted. The experience of the war marked several Futurists, particularly Marinetti, who fought in the mountains of Trentino at the border of Italy and Austria-Hungary, actively engaging in propaganda. The combat experience also influenced Futurist music.\n\nThe outbreak of war disguised the fact that Italian Futurism had come to an end. The Florence group had formally acknowledged their withdrawal from the movement by the end of 1914. Boccioni produced only one war picture and was killed in 1916. Severini painted some significant war pictures in 1915 (e.g. \"War\", \"Armored Train\", and \"Red Cross Train\"), but in Paris turned towards Cubism and post-war was associated with the Return to Order.\n\nAfter the war, Marinetti revived the movement. This revival was called \"il secondo Futurismo\" (Second Futurism) by writers in the 1960s. The art historian Giovanni Lista has classified Futurism by decades: \"Plastic Dynamism\" for the first decade, \"Mechanical Art\" for the 1920s, \"Aeroaesthetics\" for the 1930s.\n\nRussian Futurism was a movement of literature and the visual arts. The poet Vladimir Mayakovsky was a prominent member of the movement. Visual artists such as David Burlyuk, Mikhail Larionov, Natalia Goncharova and Kazimir Malevich found inspiration in the imagery of Futurist writings and were poets themselves. It has also a larger impact on the all suprematism movement. Other poets adopting Futurism included Velimir Khlebnikov and Aleksey Kruchenykh. Poets and painters collaborated on theatre production such as the Futurist opera \"Victory Over the Sun\", with texts by Kruchenykh and sets by Malevich.\n\nThe main style of painting was Cubo-Futurism, adopted in 1913 when Aristarkh Lentulov returned from Paris and exhibited his paintings in Moscow. Cubo-Futurism combines the forms of Cubism with the representation of movement. Like their Italian predecessors the Russian Futurists were fascinated with dynamism, speed and the restlessness of modern urban life.\n\nThe Russian Futurists sought controversy by repudiating the art of the past, saying that Pushkin and Dostoevsky should be \"heaved overboard from the steamship of modernity\". They acknowledged no authority and professed not to owe anything even to Marinetti, whose principles they had earlier adopted, obstructing him when he came to Russia to proselytize in 1914.\n\nThe movement began to decline after the revolution of 1917. Some Futurists died, others emigrated. Mayakovsky and Malevich became part of the Soviet establishment and the Agitprop movement of the 1920s. Khlebnikov and others were persecuted. Mayakovsky committed suicide on April 14, 1930.\n\nThe Futurist architect Antonio Sant'Elia expressed his ideas of modernity in his drawings for \"La Città Nuova\" (The New City) (1912–1914). This project was never built and Sant'Elia was killed in the First World War, but his ideas influenced later generations of architects and artists. The city was a backdrop onto which the dynamism of Futurist life is projected. The city had replaced the landscape as the setting for the exciting modern life. Sant'Elia aimed to create a city as an efficient, fast-paced machine. He manipulates light and shape to emphasize the sculptural quality of his projects. Baroque curves and encrustations had been stripped away to reveal the essential lines of forms unprecedented from their simplicity. In the new city, every aspect of life was to be rationalized and centralized into one great powerhouse of energy. The city was not meant to last, and each subsequent generation was expected to build their own city rather than inheriting the architecture of the past.\n\nFuturist architects were sometimes at odds with the Fascist state's tendency towards Roman imperial-classical aesthetic patterns. Nevertheless, several Futurist buildings were built in the years 1920–1940, including public buildings such as railway stations, maritime resorts and post offices. Examples of Futurist buildings still in use today are Trento's railway station, built by Angiolo Mazzoni, and the Santa Maria Novella station in Florence. The Florence station was designed in 1932 by the \"Gruppo Toscano\" (Tuscan Group) of architects, which included Giovanni Michelucci and Italo Gamberini, with contributions by Mazzoni.\n\nFuturist music rejected tradition and introduced experimental sounds inspired by machinery, and would influence several 20th-century composers.\n\nFrancesco Balilla Pratella joined the Futurist movement in 1910 and wrote a \"Manifesto of Futurist Musicians\" in which he appealed to the young (as had Marinetti), because only they could understand what he had to say. According to Pratella, Italian music was inferior to music abroad. He praised the \"sublime genius\" of Wagner and saw some value in the work of other contemporary composers, for example Richard Strauss, Elgar, Mussorgsky, and Sibelius. By contrast, the Italian symphony was dominated by opera in an \"absurd and anti-musical form\". The conservatories was said to encourage backwardness and mediocrity. The publishers perpetuated mediocrity and the domination of music by the \"rickety and vulgar\" operas of Puccini and Umberto Giordano. The only Italian Pratella could praise was his teacher Pietro Mascagni, because he had rebelled against the publishers and attempted innovation in opera, but even Mascagni was too traditional for Pratella's tastes. In the face of this mediocrity and conservatism, Pratella unfurled \"the red flag of Futurism, calling to its flaming symbol such young composers as have hearts to love and fight, minds to conceive, and brows free of cowardice.\"\n\nLuigi Russolo (1885–1947) wrote \"The Art of Noises\" (1913), an influential text in 20th-century musical aesthetics. Russolo used instruments he called \"intonarumori\", which were acoustic noise generators that permitted the performer to create and control the dynamics and pitch of several different types of noises. Russolo and Marinetti gave the first concert of Futurist music, complete with \"intonarumori\", in 1914. However they were prevented from performing in many major European cities by the outbreak of war.\n\nFuturism was one of several 20th-century movements in art music that paid homage to, included or imitated machines. Ferruccio Busoni has been seen as anticipating some Futurist ideas, though he remained wedded to tradition. Russolo's \"intonarumori\" influenced Stravinsky, Arthur Honegger, George Antheil, Edgar Varèse, Stockhausen and John Cage. In Pacific 231, Honegger imitated the sound of a steam locomotive. There are also Futurist elements in Prokofiev's \"The Steel Step\" and in his Second Symphony.\n\nMost notable in this respect, however, is the American George Antheil. His fascination with machinery is evident in his \"Airplane Sonata\", \"Death of the Machines\", and the 30-minute \"Ballet Mécanique\". The \"Ballet Mécanique\" was originally intended to accompany an experimental film by Fernand Léger, but the musical score is twice the length of the film and now stands alone. The score calls for a percussion ensemble consisting of three xylophones, four bass drums, a tam-tam, three airplane propellers, seven electric bells, a siren, two \"live pianists\", and sixteen synchronized player pianos. Antheil's piece was the first to synchronize machines with human players and to exploit the difference between what machines and humans can play.\n\nOther composers offered more melodic variants of Futurist music, notably Franco Casavola, who was active with the movement at the invitation of Marinetti between 1924 and 1927, and Arthur-Vincent Lourié, the first Russian Futurist musician, and a signatory of the St Petersburg Futurist Manifesto in 1914. His five \"Synthèses\" offer a form of dodecaphony, while \"Formes en l'air\" was dedicated to Picasso and is a Cubo-Futurist concept. Born in Ukraine and raised in New York, Leo Ornstein gave his first recital of 'Futurist Music' at the Steinway Hall in London on 27 March 1914. According to the Daily Sketch newspaper \"one listened with considerable distress. Nothing so horrible as Mr Ornstein's music has been heard so far. Sufferers from complete deafness should attend the next recital.\"\n\nThe Futuristic movement also influenced the concept of dance. Indeed, dancing was interpreted as an alternative way of expressing man's ultimate fusion with the machine. The altitude of a flying plane, the power of a car's motor and the roaring loud sounds of complex machinery were all signs of man's intelligence and excellence which the art of dance had to emphasize and praise. This type of dance is considered futuristic since it disrupts the referential system of traditional, classical dance and introduces a different style, new to the sophisticated bourgeois audience. The dancer no longer performs a story, a clear content, that can be read according to the rules of ballet. One of the most famous futuristic dancers was the Italian . Trained as a classical ballerina, she is known for her \"Aerodanze\" and continued to earn her living by performing in classical and popular productions. She describes this innovative form of dance as the result of a deep collaboration with Marinetti and his poetry. Through these words, she explains: \" I launched this idea of the aerial-futurist poetry with Marinetti, he himself declaiming the poetry. A small stage of a few square meters;... I made myself a satin costume with a helmet; everything that the plane did had to be expressed by my body. It flew and, moreover, it gave the impression of these wings that trembled, of the apparatus that trembled... And the face had to express what the pilot felt.\"\n\nFuturism as a literary movement made its official debut with F.T. Marinetti's \"Manifesto of Futurism\" (1909), as it delineated the various ideals Futurist poetry should strive for. Poetry, the predominate medium of Futurist literature, can be characterized by its unexpected combinations of images and hyper-conciseness (not to be confused with the actual length of the poem). The Futurists called their style of poetry \"parole in libertà\" (word autonomy) in which all ideas of meter were rejected and the word became the main unit of concern. In this way, the Futurists managed to create a new language free of syntax punctuation, and metrics that allowed for free expression.\n\nTheater also has an important place within the Futurist universe. Works in this genre have scenes that are few sentences long, have an emphasis on nonsensical humor, and attempt to discredit the deep rooted traditions via parody and other devaluation techniques.\nThere are a number of examples of Futurist novels from both the initial period of Futurism and the neo-Futurist period, from Marinetti himself to a number of lesser known Futurists, such as Primo Conti, Ardengo Soffici and Giordano Bruno Sanzin (\"Zig Zag, Il Romanzo Futurista\" edited by Alessandro Masi, 1995). They are very diverse in style, with very little recourse to the characteristics of Futurist Poetry, such as 'parole in libertà'. Arnaldo Ginna's 'Le \"locomotive con le calze\"'(Trains with socks on)plunges into a world of absurd nonsense, childishly crude. His brother Bruno Corra wrote in \"Sam Dunn è morto\" (Sam Dunn is Dead) a masterpiece of Futurist fiction, in a genre he himself called 'Synthetic' characterized by compression, and precision; it is a sophisticated piece that rises above the other novels through the strength and pervasiveness of its irony.\n\nWhen interviewed about her favorite film of all times, famed movie critic Pauline Kael stated that the director Dimitri Kirsanoff, in his silent experimental film \"Ménilmontant\" \"developed a technique that suggests the movement known in painting as Futurism\".\n\nMany Italian Futurists supported Fascism in the hope of modernizing a country divided between the industrialising north and the rural, archaic South. Like the Fascists, the Futurists were Italian nationalists, radicals, admirers of violence, and were opposed to parliamentary democracy. Marinetti founded the Futurist Political Party (\"Partito Politico Futurista\") in early 1918, which was absorbed into Benito Mussolini's \"Fasci di combattimento\" in 1919, making Marinetti one of the first members of the National Fascist Party. He opposed Fascism's later exaltation of existing institutions, calling them \"reactionary\", and walked out of the 1920 Fascist party congress in disgust, withdrawing from politics for three years; but he supported Italian Fascism until his death in 1944. The Futurists' association with Fascism after its triumph in 1922 brought them official acceptance in Italy and the ability to carry out important work, especially in architecture. After the Second World War, many Futurist artists had difficulty in their careers because of their association with a defeated and discredited regime.\n\nMarinetti sought to make Futurism the official state art of Fascist Italy but failed to do so. Mussolini chose to give patronage to numerous styles and movements in order to keep artists loyal to the regime. Opening the exhibition of art by the Novecento Italiano group in 1923, he said, \"I declare that it is far from my idea to encourage anything like a state art. Art belongs to the domain of the individual. The state has only one duty: not to undermine art, to provide humane conditions for artists, to encourage them from the artistic and national point of view.\" Mussolini's mistress, Margherita Sarfatti, who was as able a cultural entrepreneur as Marinetti, successfully promoted the rival Novecento group, and even persuaded Marinetti to sit on its board. Although in the early years of Italian Fascism modern art was tolerated and even embraced, towards the end of the 1930s, right-wing Fascists introduced the concept of \"degenerate art\" from Germany to Italy and condemned Futurism.\n\nMarinetti made numerous moves to ingratiate himself with the regime, becoming less radical and avant-garde with each. He moved from Milan to Rome to be nearer the centre of things. He became an academician despite his condemnation of academies, married despite his condemnation of marriage, promoted religious art after the Lateran Treaty of 1929 and even reconciled himself to the Catholic Church, declaring that Jesus was a Futurist.\nAlthough Futurism mostly became identified with Fascism, it had leftist and anti-Fascist supporters. They tended to oppose Marinetti's artistic and political direction of the movement, and in 1924 the socialists, communists and anarchists walked out of the Milan Futurist Congress. The anti-Fascist voices in Futurism were not completely silenced until the annexation of Abyssinia and the Italo-German Pact of Steel in 1939. This association of Fascists, socialists and anarchists in the Futurist movement, which may seem odd today, can be understood in terms of the influence of Georges Sorel, whose ideas about the regenerative effect of political violence had adherents right across the political spectrum.\n\nFuturism expanded to encompass many artistic domains and ultimately included painting, sculpture, ceramics, graphic design, industrial design, interior design, theatre design, textiles, drama, literature, music and architecture.\n\nAeropainting (\"aeropittura\") was a major expression of the second generation of Futurism beginning in 1926. The technology and excitement of flight, directly experienced by most aeropainters, offered aeroplanes and aerial landscape as new subject matter. Aeropainting was varied in subject matter and treatment, including realism (especially in works of propaganda), abstraction, dynamism, quiet Umbrian landscapes, portraits of Mussolini (e.g. Dottori's \"Portrait of il Duce\"), devotional religious paintings, decorative art, and pictures of planes.\n\nAeropainting was launched in a manifesto of 1929, \"Perspectives of Flight\", signed by Benedetta, Depero, Dottori, Fillìa, Marinetti, Prampolini, Somenzi and . The artists stated that \"The changing perspectives of flight constitute an absolutely new reality that has nothing in common with the reality traditionally constituted by a terrestrial perspective\" and that \"Painting from this new reality requires a profound contempt for detail and a need to synthesise and transfigure everything.\" Crispolti identifies three main \"positions\" in aeropainting: \"a vision of cosmic projection, at its most typical in Prampolini's 'cosmic idealism' ... ; a 'reverie' of aerial fantasies sometimes verging on fairy-tale (for example in Dottori ...); and a kind of aeronautical documentarism that comes dizzyingly close to direct celebration of machinery (particularly in Crali, but also in Tato and Ambrosi).\"\n\nEventually there were over a hundred aeropainters. Major figures include Fortunato Depero, Enrico Prampolini, Gerardo Dottori and Crali. Crali continued to produce \"aeropittura\" up until the 1980s.\n\nFuturism influenced many other twentieth-century art movements, including Art Deco, Vorticism, Constructivism, Surrealism, Dada, and much later Neo-Futurism. Futurism as a coherent and organized artistic movement is now regarded as extinct, having died out in 1944 with the death of its leader Marinetti.\n\nNonetheless, the ideals of Futurism remain as significant components of modern Western culture; the emphasis on youth, speed, power and technology finding expression in much of modern commercial cinema and culture. Ridley Scott consciously evoked the designs of Sant'Elia in \"Blade Runner\". Echoes of Marinetti's thought, especially his \"dreamt-of metallization of the human body\", are still strongly prevalent in Japanese culture, and surface in manga/anime and the works of artists such as Shinya Tsukamoto, director of the \"Tetsuo\" (lit. \"Ironman\") films. Futurism has produced several reactions, including the literary genre of cyberpunk—in which technology was often treated with a critical eye—whilst artists who came to prominence during the first flush of the Internet, such as Stelarc and Mariko Mori, produce work which comments on Futurist ideals. and the art and architecture movement Neo-Futurism in which technology is considered a driver to a better quality of life and sustainability values.\n\nA revival of sorts of the Futurist movement in theatre began in 1988 with the creation of the Neo-Futurist style in Chicago, which utilizes Futurism's focus on speed and brevity to create a new form of immediate theatre. Currently, there are active Neo-Futurist troupes in Chicago, New York, San Francisco, and Montreal.\n\nFuturist ideas have been discerned in Western dance music since the 1980s.\n\nJapanese Composer Ryuichi Sakamoto's 1986 album 'Futurista' was inspired by the movement. It features a speech from Tommaso Marinetti in the track 'Variety Show'.\n\nIn 2009, Italian director Marco Bellocchio included Futurist art in his feature film \"Vincere\".\n\nIn 2014, the Solomon R. Guggenheim Museum featured the exhibition \"Italian Futurism, 1909–1944: Reconstructing the Universe\". This was the first comprehensive overview of Italian Futurism to be presented in the United States.\n\nEstorick Collection of Modern Italian Art is a museum in London with a collection centered around Italian futurist artists and their paintings.\n\n\n"}
{"id": "19973692", "url": "https://en.wikipedia.org/wiki?curid=19973692", "title": "Geneva Declaration on Armed Violence and Development", "text": "Geneva Declaration on Armed Violence and Development\n\nThe Geneva Declaration on Armed Violence and Development highlights the role that states and civil society must play in preventing and reducing violence associated with war, crime, and social unrest. The Declaration was adopted on 7 June 2006 and is now endorsed by 113 states. It is the strongest political statement to date that addresses the impact of armed violence within a development context. Regular high-level diplomatic regional meetings and ministerial review conferences take place to assess progress concerning the process and implementation of the Geneva Declaration; the first two ministerial review conferences took place in 2008 and 2011. During 2014 a series of Regional Review Conferences have been organized not only to review the process in implementing the Geneva Declaration but also to reflect and gather support in integrating meaningfully armed violence reduction in national and international development processes, including the post-2015 development agenda.\n\nBy signing the Geneva Declaration states commit to:\n\n\nUnderstanding that the fight against the global scourge of armed violence and the prospects for sustainable development are closely linked, the signatories recognize that armed violence constitutes a major obstacle to the achievement of the Millennium Development Goals. They agree to strengthen their efforts to integrate armed violence reduction and conflict prevention programs into national, regional, and multilateral development frameworks and strategies.\n\nThe approach is based on three pillars:\n\n\nA Core Group of 14 signatory states and affiliated organizations is responsible for steering the process and guiding the implementation of the Geneva Declaration. Affiliated organizations include the Bureau for Crisis Prevention and Recovery (BCPR) of the United Nations Development Programme (UNDP), the Small Arms Survey—which also hosts the Geneva Declaration Secretariat—, the Development Assistance Committee (DAC) of the Organisation for Economic Co-operation and Development (OECD), and the Quaker United Nations Office (QUNO).\n\nCore group member states:\n\n\n\nSignatory states:\n\n\n\n\n\n"}
{"id": "38468625", "url": "https://en.wikipedia.org/wiki?curid=38468625", "title": "Good News Awards", "text": "Good News Awards\n\nGood News Awards are awarded annually to news media organizations with offices in the Upper Peninsula of Michigan, for specific examples of published media that \"affirm the dignity of people, recognize and uphold universally-recognized human values, and uplift and nourish the human spirit.\" The Good News Awards, and related Certificates of Merit, have been given annually since 1998 and are given for works in broadcasting, print or the web.\n\nThe divisions and categories of Good News Awards have changed over time; for the 2012 and 2013 award years there were four divisions for entry:\nThe six categories in each division were:\n\nSubmissions are for works from the previous calendar year, with at most one submission per category per media organization. Submissions are made in February by an editor of the media organization, and Awards are formally to the media organization with credit given to the individual author(s) of the work. Representatives and authors from the winning organizations have been invited to a luncheon and receive a plaque or certificate. The media organization itself receives the award, which is an Upper Peninsula photograph or painting that combines light with evidence of peaceful human works. In 2012, forty-six media professionals were recognized from among twenty Upper Peninsula media organizations that submitted entries.\n\nMaterial receiving awards is expected to uphold values such as community, creativity, tolerance, justice, respect, compassion, perseverance, truth, faith, care for the environment or the dedication to excellence. The awards have been sponsored annually by the religious leaders of the Evangelical Lutheran, Presbyterian, United Methodist, Catholic and Episcopal Churches in the Upper Peninsula region. Although the sponsors have been religious organizations, the award criteria do not involve religious content and topics of award-winning material are generally secular.\n"}
{"id": "4178640", "url": "https://en.wikipedia.org/wiki?curid=4178640", "title": "Hazchem", "text": "Hazchem\n\nHazchem (hazardous chemicals)() is a warning plate system used in Australia, Malaysia, New Zealand, India and the United Kingdom for vehicles transporting hazardous substances, and on storage facilities. The top-left section of the plate gives the Emergency Action Code (EAC) telling the fire brigade what actions to take if there's an accident or fire. The middle-left section containing a 4 digit number gives the UN Substance Identification Number describing the material. The lower-left section gives the telephone number that should be called if special advice is needed. The warning symbol in the top right indicates the general hazard class of the material. The bottom-right of the plate carries a company logo or name.\n\nThere is also a standard null Hazchem plate to indicate the transport of non-hazardous substances. The null plate does not include an EAC or substance identification.\n\nThe National Chemical Emergency Centre (NCEC) in the United Kingdom provides a Free Online Hazchem Guide.\n\nThe Emergency Action Code (EAC) is a three character code displayed on all dangerous goods classed carriers, and provides a quick assessment to first responders and emergency responders (i.e. fire fighters and police) of what actions to take should the carrier carrying such goods become involved in an incident (traffic collision, for example). EAC's are characterised by a single number (1 to 4) and either one or two letters (depending on the hazard).\n\nNCEC was commissioned by the Department for Communities and Local Government (CLG) to edit the EAC List 2013 publication, outlining the application of Hazchem Emergency Actions Codes (EACs) in Britain for 2013. The Dangerous Goods Emergency Action Code (EAC) List is reviewed every two years and is an essential compliance document for all emergency services, local government and for those who may control the planning for, and prevention of, emergencies involving dangerous goods. The current EAC List is 20013. NCEC has been at the heart of the UK EAC system since its inception in the early 1970s, publishing the list on behalf of the UK Government until 1996 and resuming its management in 2008.\n\nThe printed version of the book can be purchased from TSO directly () or downloaded as a PDF file from NCEC’s website.\n \n\nThis number is indicative of what type of fire suppressant should be used to suppress a fire from igniting or extinguish a fire caused by the chemical. The system is designed to rank fire suppression methods in order of usability. For example, a chemical marked with the number 2 or Fog can be attacked with methods 3 (Foam) or 4 (Dry Agent) but not with 1 (Jets). The \"Dry Agent\" method must be used for chemicals that have an undesirable reaction with water and must not be allowed to come in contact with water, therefore 4 is the highest ranking suppression method as all of the other methods use water.\n\nEach EAC contains at least one letter, which determines which category the chemical falls under, and which also highlights the violence of the chemical (i.e. likelihood to spontaneously combust, explode etc.), what personal protective equipment to use while working around the chemical and what action to take when disposing of the chemical.\n\nEach category is assigned a letter to determine what actions are required when handling, containing and disposing of the chemical in question. Eight 'major categories' exist which are commonly denoted by a black letter on a white background. Four subcategories exist which specifically deal with what type of personal protective equipment responders must wear when handling the emergency, denoted by a white letter on a black background. In Australia with the update of the Australian Dangerous Goods Code volume 7 as of 2010, the white letter on a black background has been removed, making BA a requirement at all large incidents regardless of whether the substance is involved in a fire.\n\nIf a category is classed as violent, this means that the chemical can be violently or explosively reactive, either with the atmosphere or water, or both (which could be marked by the Dangerous when Wet symbol).\n\nProtection is divided up into three categories of personal protective equipment, \"Full\", \"BA\" and \"BA for fire only\". Full denotes that full personal protective equipment provisions must be used around and in contact with the chemical, which will usually include a portable breathing apparatus and water tight and chemical proof suit. \"BA\" (acronym for breathing apparatus) specifies that a portable breathing apparatus must be used at all times in and around the chemical, and \"BA for fire only\" specifies that a breathing apparatus is not necessary for short exposure periods to the chemical but is required if the chemical is on alight. \"BA for fire only\" is denoted within the emergency action code as a white letter on a black background, while a black letter on a white background denotes breathing apparatus at all times. <ins>When changing the background colour is not possible (such as with handwriting), the use of brackets means the same as a black background. \"3[Y]E\" means the same as a white letter on a black background.</ins>\n\nSubstance control specifies what to do with the chemical in the event of a spill, either \"dilute\" or \"contain\". Dilute means that the chemical may be washed down the drain with large quantities of water. \"Contain\" requires that the spillage must not come in contact with drains or water courses.\n\nIn the event of a chemical incident, the EAC may specify that an evacuation may be necessary as the chemical poses a public hazard which may extend beyond the immediate vicinity. If evacuation is not possible, advice to stay in doors and secure all points of ventilation may be necessary. This condition is denoted by an E at the end of any emergency action code. It is an optional letter, depending on the nature of the chemical.\n\nA very commonly displayed example is 3YE on petrol tankers. This means that a fire must be fought using foam or dry agent (if a small fire), that it can react violently and is explosive, that fire fighters must wear a portable breathing apparatus at all times, or if a white on black Y, only if there is a fire, and that the run-off needs to be contained. It also indicates to the incident controller that evacuation of the surrounding area may be necessary.\n\nExample:\n\nThere are three substances to be carried as a multi-load, having emergency action codes of 3Y, •2S and 4WE.\n\n1st Character (Number):\nThe first character of the EAC for each of the three substances is 3, 2 and 4. The highest number must be taken as the first character of the code for the multi-load and therefore the first character will be 4. The bullet in •2S is not assigned to the mixed load because other EACs do not include a bullet.\n\n2nd Character (Letter):\nThe second character for the EAC for each of the three substances is Y, S and W. Taking the Y along the top row of the chart and the S along the left hand column, the intersection is at Y and therefore the character for the first two substances would be Y. This resultant character (Y) is then taken along the top row and the character for the third substance (W) is taken along the left hand column. The intersection point is now W. The second character of the code for the three substances is therefore W.\n\nLetter ‘E’:\nThe third substance has an ‘E’ as a third character and therefore the multi-load must also have an ‘E’.\n\nThe resultant Hazchem Code for the three substances carried as a multi-load will therefore be 4WE.\n\n\n"}
{"id": "34060358", "url": "https://en.wikipedia.org/wiki?curid=34060358", "title": "Heat kernel signature", "text": "Heat kernel signature\n\nA heat kernel signature (HKS) is a feature descriptor for use in deformable shape analysis and belongs to the group of spectral shape analysis methods. For each point in the shape, HKS defines its feature vector representing the point's local and global geometric properties. Applications include segmentation, classification, structure discovery, shape matching and shape retrieval.\n\nHKS was introduced in 2009 by Jian Sun, Maks Ovsjanikov and Leonidas Guibas. It is based on heat kernel, which is a fundamental solution to the heat equation. HKS is one of the many recently introduced shape descriptors which are based on the Laplace–Beltrami operator associated with the shape.\n\nShape analysis is the field of automatic digital analysis of shapes, e.g., 3D objects. For many shape analysis tasks (such as shape matching/retrieval), feature vectors for certain key points are used instead of using the complete 3D model of the shape. An important requirement of such feature descriptors is for them to be invariant under certain transformations. For rigid transformations, commonly used feature descriptors include shape context, spin images, integral volume descriptors and multiscale local features, among others. HKS allows isometric transformations which generalizes rigid transformations.\n\nHKS is based on the concept of heat diffusion over a surface. Given an initial heat distribution formula_1 over the surface, the heat kernel formula_2 relates the amount of heat transferred from formula_3 to formula_4 after time formula_5. The heat kernel is invariant under isometric transformations and stable under small perturbations to the isometry. In addition, the heat kernel fully characterizes shapes up to an isometry and represents increasingly global properties of the shape with increasing time. Since formula_6 is defined for a pair of points over a temporal domain, using heat kernels directly as features would lead to a high complexity. HKS instead restricts itself to just the temporal domain by considering only formula_7. HKS inherits most of the properties of heat kernels under certain conditions.\n\nThe heat diffusion equation over a compact Riemannian manifold formula_8 (possibly with a boundary) is given by,\nwhere formula_10 is the Laplace–Beltrami operator and formula_11 is the heat distribution at a point formula_3 at time formula_5. The solution to this equation can be expressed as,\nThe eigen decomposition of the heat kernel is expressed as,\nwhere formula_16 and formula_17 are the formula_18 eigenvalue and eigenfunction of formula_10. The heat kernel fully characterizes a surface up to an isometry: For any surjective map formula_20 between two Riemannian manifolds formula_8 and formula_22, if formula_23 then formula_24 is an isometry, and vice versa. For a concise feature descriptor, HKS restricts the heat kernel only to the temporal domain,\nHKS, similar to the heat kernel, characterizes surfaces under the condition that the eigenvalues of formula_10 for formula_8 and formula_22 are non-repeating. The terms formula_29 can be intuited as a bank of low-pass filters, with formula_16 determining the cutoff frequencies.\n\nSince formula_7 is, in general, a non-parametric continuous function, HKS is in practice represented as a discrete sequence of formula_32 values sampled at times formula_33.\n\nIn most applications, the underlying manifold for an object is not known. The HKS can be computed if a mesh representation of the manifold is available, by using a discrete approximation to formula_10 and using the discrete analogue of the heat equation. In the discrete case, the Laplace–Beltrami operator is a sparse matrix and can be written as,\nwhere formula_36 is a positive diagonal matrix with entries formula_37 corresponding to the area of the triangles in the mesh sharing the vertex formula_38, and formula_39 is a symmetric semi-definite weighting matrix. formula_40 can be decomposed into formula_41, where formula_42 is a diagonal matrix of the eigenvalues of formula_40 arranged in the ascending order, and formula_44 is the matrix with the corresponding orthonormal eigenvectors. The discrete heat kernel is the matrix given by,\nThe elements formula_46 represents the heat diffusion between vertices formula_38 and formula_48 after time formula_5. The HKS is then given by the diagonal entries of this matrix, sampled at discrete time intervals. Similar to the continuous case, the discrete HKS is robust to noise.\n\nThe main property that characterizes surfaces using HKS up to an isometry holds only when the eigenvalues of the surfaces are non-repeating. There are certain surfaces (especially those with symmetry) where this condition is violated. A sphere is a simple example of such a surface.\n\nThe time parameter in the HKS is closely related to the scale of global information. However, there is no direct way to choose the time discretization. The existing method chooses time samples logarithmically which is a heuristic with no guarantees\n\nThe discrete heat kernel requires eigendecomposition of a matrix of size formula_50, where formula_51 is the number of vertices in the mesh representation of the manifold. Computing the eigendecomposition is an expensive operation, especially as formula_51 increases.\nNote, however, that because of the inverse exponential dependence on the eigenvalue, typically only a small (less than 100) eigenvectors are sufficient to obtain a good approximation of the HKS.\n\nThe performance guarantees for HKS only hold for truly isometric transformations. However, deformations for real shapes are often not isometric. A simple example of such transformation is closing of the fist by a person, where the geodesic distances between two fingers changes.\n\nThe (continuous) HKS at a point formula_3, formula_7 on the Riemannian manifold is related to the scalar curvature formula_55 by,\nHence, HKS can as be interpreted as the curvature of formula_3 at scale formula_5.\n\nThe WKS follows a similar idea to the HKS, replacing the heat equation with the Schrödinger wave equation,\nwhere formula_60 is the complex wave function. The average probability of measuring the particle at a point formula_3 is given by,\nwhere formula_63 is the initial energy distribution. By fixing a family of these energy distributions formula_64, the WKS can be obtained as a discrete sequence formula_65. Unlike HKS, the WKS can be intuited as a set of band-pass filters leading to better feature localization. However, the WKS does not represent large-scale features well (as they are \"filtered\" out) yielding poor performance at shape matching applications.\n\nSimilar to the HKS, the GPS is based on the Laplace-Beltrami operator. GPS at a point formula_3 is a vector of scaled eigenfunctions of the Laplace–Beltrami operator computed at formula_3. The GPS is a global feature whereas the scale of the HKS can be varied by varying the time parameter for heat diffusion. Hence, the HKS can be used in partial shape matching applications whereas the GPS cannot.\n\nSGWS provides a general form for spectral descriptors, where one can obtain HKS by specifying the filter function. SGWS is a multiresolution local descriptor that is not only isometric invariant, but also compact, easy to compute and combines the advantages of both band-pass and low-pass filters.\n\nEven though the HKS represents the shape at multiple scales, it is not inherently scale invariant. For example, the HKS for a shape and its scaled version are not the same without pre-normalization. A simple way to ensure scale invariance is by pre-scaling each shape to have the same surface area (e.g. 1). Using the notation above, this means:\n\nformula_68\n\nAlternatively, scale-invariant version of the HKS can also be constructed by generating a Scale space representation. In the scale-space, the HKS of a scaled shape corresponds to a translation up to a multiplicative factor. The Fourier transform of this HKS changes the time-translation into the complex plane, and the dependency on translation can be eliminated by considering the modulus of the transform.\nAn alternative scale invariant HKS can be established by working out its construction through a scale invariant metric, as defined in .\n\nThe HKS is defined for a boundary surface of a 3D shape, represented as a 2D Riemannian manifold. Instead of considering only the boundary, the entire volume of the 3D shape can be considered to define the volumetric version of the HKS. The Volumetric HKS is defined analogous to the normal HKS by considering the heat equation over the entire volume (as a 3-submanifold) and defining a Neumann boundary condition over the 2-manifold boundary of the shape. Volumetric HKS characterizes transformations up to a volume isometry, which represent the transformation for real 3D objects more faithfully than boundary isometry.\n\nThe scale-invariant HKS features can be used in the bag-of-features model for shape retrieval applications. The features are used to construct geometric words by taking into account their spatial relations, from which shapes can be constructed (analogous to using features as words and shapes as sentences). Shapes themselves are represented using compact binary codes to form an indexed collection. Given a query shape, similar shapes in the index with possibly isometric transformations can be retrieved by using the Hamming distance of the code as the nearness-measure.\n"}
{"id": "369116", "url": "https://en.wikipedia.org/wiki?curid=369116", "title": "Hume's fork", "text": "Hume's fork\n\nHume's fork is an explanation, developed by later philosophers, of David Hume's 1730s division of \"relations of ideas\" from \"matters of fact and real existence\". A distinction is made between necessary versus contingent (concerning reality), versus (concerning knowledge), and analytic versus synthetic (concerning language). Relations of abstract ideas align on one side (necessary, \"a priori\", analytic), whereas concrete truths align on the other (contingent, \"a posteriori\", synthetic).\n\nThe \"necessary\" is generally true in all possible worlds—usually by mere logical validity—whereas the \"contingent\" hinges on the way the real world is. The \"a priori\" is knowable before or without, whereas the \"a posteriori\" is knowable only after or through, experience in an area of interest. The \"analytic\" is a statement true by virtue of its terms' meanings, and therefore a tautology—necessarily true but uninformative—whereas the \"synthetic\" is true by its terms' meanings in relation to a state of facts. In other words, analytic propositions are true by virtue of their meaning, while synthetic propositions are true by how their meaning relates to the world. Philosophers have used the terms differently, and there is debate over whether there is a legitimate distinction. \n\nHume's strong empiricism, as in Hume's fork as well as Hume's problem of induction, was taken as a threat to Newton's theory of motion. Immanuel Kant responded with rationalism in his 1781 \"Critique of Pure Reason\", where Kant attributed to the mind a causal role in sensory experience by the mind's aligning the environmental input by arranging those sense data into the experience of space and time. Kant thus reasoned existence of the synthetic \"a priori\"—combining meanings of terms with states of facts, yet known true without experience of the particular instance—replacing the two prongs of Hume's fork with a three-pronged-fork thesis (Kant's pitchfork) and thus saving Newton's law of universal gravitation.\n\nIn 1919, Newton's theory fell to Einstein's general theory of relativity. In the late 1920s, the logical positivists rejected Kant's synthetic \"a priori\" and asserted Hume's fork, so called, while hinging it at language—the analytic/synthetic division—while presuming that by holding to analyticity, they could develop a logical syntax entailing, as a consequence of Hume's fork, both necessity and aprioricity, thus restricting science to claims verifiable as either false or true. In the early 1950s, Willard Van Orman Quine undermined the analytic/synthetic division by explicating ontological relativity, as every term in any statement has its meaning contingent on a vast network of knowledge and belief, the speaker's conception of the entire world. By the early 1970s, Saul Kripke established the necessary \"a posteriori\", since if the Morning Star and the Evening Star are the same star, they are the same star by necessity, but this is known true by a human only through relevant experience.\n\nHume's fork remains basic in Anglo-American philosophy. Many deceptions and confusions are foisted by surreptitious or unwitting conversion of a synthetic claim to an analytic claim, rendered true by necessity but merely a tautology, for instance the \"No true Scotsman\" move. Simply put, Hume's fork has limitations. Related concerns are Hume's distinction of demonstrative versus probable reasoning and Hume's law. Hume makes other, important two-category distinctions, such as beliefs versus desires and as impressions versus ideas.\n\nThe first distinction is between two different areas of human study:\n\nHume's fork is often stated in such a way that statements are divided up into two types:\n\n\nIn modern terminology, members of the first group are known as analytic propositions and members of the latter as synthetic propositions. This terminology comes from Kant (Introduction to \"Critique of Pure Reason\", Section IV).\n\nInto the first class fall statements such as \"all bodies are extended\", \"all bachelors are unmarried\", and truths of mathematics and logic. Into the second class fall statements like \"the sun rises in the morning\", and \"all bodies have mass\".\n\nHume wants to prove that certainty does not exist in science. First, Hume notes that statements of the second type can never be entirely certain, due to the fallibility of our senses, the possibility of deception (see e.g. the modern brain in a vat theory) and other arguments made by philosophical skeptics. It is always logically possible that any given statement about the world is false.\n\nSecond, Hume claims that our belief in cause-and-effect relationships between events is not grounded on reason, but rather arises merely by habit or custom. Suppose one states: \"Whenever someone on earth lets go of a stone it falls.\" While we can grant that in every instance thus far when a rock was dropped on Earth it went down, this does not make it logically necessary that in the future rocks will fall when in the same circumstances. Things of this nature rely upon the future conforming to the same principles which governed the past. But that isn't something that we can know based on past experience—all past experience could tell us is that in the past, the future has resembled the past.\n\nThird, Hume notes that relations of ideas can be used only to prove other relations of ideas, and mean nothing outside of the context of how they relate to each other, and therefore tell us nothing about the world. Take the statement \"An equilateral triangle has three sides of equal length.\" While some earlier philosophers (most notably Plato and Descartes) held that logical statements such as these contained the most formal reality, since they are always true and unchanging, Hume held that, while true, they contain no formal reality, because the truth of the statements rests on the definitions of the words involved, and not on actual things in the world, since there is no such thing as a true triangle or exact equality of length in the world. So for this reason, relations of ideas cannot be used to prove matters of fact.\n\nThe results claimed by Hume as consequences of his fork are drastic. According to him, relations of ideas can be proved with certainty (by using other relations of ideas), however, they don't really mean anything about the world. Since they don't mean anything about the world, relations of ideas cannot be used to prove matters of fact. Because of this, matters of fact have no certainty and therefore cannot be used to prove anything. Only certain things can be used to prove other things for certain, but only things about the world can be used to prove other things about the world. But since we can't cross the fork, nothing is both certain and about the world, only one or the other, and so it is impossible to prove something about the world with certainty.\n\nIf accepted, Hume's fork makes it pointless to try to prove the existence of God (for example) as a matter of fact. If God is not literally made up of physical matter, and does not have an observable effect on the world, making a statement about God is not a matter of fact. Therefore, a statement about God must be a relation of ideas. In this case if we prove the statement \"God exists,\" it doesn't really tell us anything about the world; it is just playing with words. It is easy to see how Hume's fork voids the causal argument and the ontological argument for the existence of a non-observable God. However, this does not mean that the validity of Hume's fork would imply that God definitely does not exist, only that it would imply that the existence of God cannot be proven as a matter of fact without worldly evidence. \n\nHume rejected the idea of any meaningful statement that did not fall into this schema, saying:\nIf we take in our hand any volume; of divinity or school metaphysics, for instance; let us ask, Does it contain any abstract reasoning concerning quantity or number? No. Does it contain any experimental reasoning concerning matter of fact and existence? No. Commit it then to the flames: for it can contain nothing but sophistry and illusion. — \"An Enquiry Concerning Human Understanding\"\n"}
{"id": "29563662", "url": "https://en.wikipedia.org/wiki?curid=29563662", "title": "Kinematic Self-Replicating Machines", "text": "Kinematic Self-Replicating Machines\n\nKinematic Self-Replicating Machines is a 2004 textbook offering a general review of the theoretical and experimental literature pertaining to physical self-replicating systems. The principal focus of the book is on self-replicating machine systems (see also: robot kinematics). Specifically with kinematic self-replicating machines systems in which actual physical objects, not mere patterns of information, undertake their own replication.\n\n\"Kinematic\" was written by Robert Freitas and Ralph Merkle.\n\n\n\n\n"}
{"id": "373299", "url": "https://en.wikipedia.org/wiki?curid=373299", "title": "Language of mathematics", "text": "Language of mathematics\n\nThe language of mathematics is the system used by mathematicians to communicate mathematical ideas among themselves. This language consists of a substrate of some natural language (for example English) using technical terms and grammatical conventions that are peculiar to mathematical discourse (see Mathematical jargon), supplemented by a highly specialized symbolic notation for mathematical formulas.\n\nLike natural languages in general, discourse using the language of mathematics can employ a scala of registers. Research articles in academic journals are sources for detailed theoretical discussions about ideas concerning mathematics and its implications for society.\n\nHere are some definitions of language:\n\nThese definitions describe language in terms of the following components:\n\nEach of these components is also found in the language of mathematics.\n\nMathematical notation has assimilated symbols from many different alphabets and typefaces. It also includes symbols that are specific to mathematics, such as\n\nMathematical notation is central to the power of modern mathematics. Though the algebra of Al-Khwārizmī did not use such symbols, it solved equations using many more rules than are used today with symbolic notation, and had great difficulty working with multiple variables (which using symbolic notation can simply be called formula_2, etc.). Sometimes formulas cannot be understood without a written or spoken explanation, but often they are sufficient by themselves, and sometimes they are difficult to read aloud or information is lost in the translation to words, as when several parenthetical factors are involved or when a complex structure like a matrix is manipulated.\n\nLike any other profession, mathematics also has its own brand of technical terminology. In some cases, a word in general usage has a different and specific meaning within mathematics—examples are group, ring, field, category, term, and factor. For more examples, see .\n\nIn other cases, specialist terms have been created which do not exist outside of mathematics—examples are tensor, fractal, functor. Mathematical statements have their own moderately complex taxonomy, being divided into axioms, conjectures, theorems, lemmas and corollaries. And there are stock phrases in mathematics, used with specific meanings, such as \", \" and \"without loss of generality\". Such phrases are known as mathematical jargon.\n\nThe vocabulary of mathematics also has visual elements. Diagrams are used informally on blackboards, as well as more formally in published work. When used appropriately, diagrams display schematic information more easily. Diagrams also help visually and aid intuitive calculations. Sometimes, as in a visual proof, a diagram even serves as complete justification for a proposition. A system of diagram conventions may evolve into a mathematical notation – for example, the Penrose graphical notation for tensor products.\n\nThe mathematical notation used for formulas has its own grammar, not dependent on a specific natural language, but shared internationally by mathematicians regardless of their mother tongues. This includes the conventions that the formulas are written predominantly left to right, even when the writing system of the substrate language is right-to-left, and that the Latin alphabet is commonly used for simple variables and parameters. A formula such as\nis understood by Chinese and Syrian mathematicians alike.\n\nSuch mathematical formulas can be a part of speech in a natural-language phrase, or even assume the role of a full-fledged sentence. For example, the formula above, an inequation, can be considered a sentence or an independent clause in which the greater than or equal to symbol has the role of a symbolic verb. In careful speech, this can be made clear by pronouncing \"≥\" as \"is greater than or equal to\", but in an informal context mathematicians may shorten this to \"greater or equal\" and yet handle this grammatically like a verb. A good example is the book title \"Why does ?\"; here, the equals sign has the role of an infinitive.\n\nMathematical formulas can be \"vocalized\" (spoken aloud). The vocalization system for formulas has to be learned, and is dependent on the underlying natural language. For example, when using English, the expression \"\"ƒ\"(\"x\")\" is conventionally pronounced \"eff of eks\", where the insertion of the preposition \"of\" is not suggested by the notation per se. The expression \"formula_4\", on the other hand, is commonly vocalized like \"dee-why-dee-eks\", with complete omission of the fraction bar, in other contexts often pronounced \"over\". The book title \"Why does ?\" is said aloud as \"Why does ee equal em see-squared?\".\n\nCharacteristic for mathematical discourse – both formal and informal – is the use of the inclusive first person plural \"we\" to mean: \"the audience (or reader) together with the speaker (or author)\".\n\nAs is the case for spoken mathematical language, in written or printed mathematical discourse, mathematical expressions containing a symbolic verb, like formula_5, are generally treated as clauses (dependent or independent) in sentences or as complete sentences and are punctuated as such by mathematicians and theoretical physicists. In particular, this is true for \"both\" inline and displayed expressions. In contrast, writers in other natural sciences disciplines may try to avoid using equations within sentences and may treat displayed expressions in the same way as figures or schemes.\n\nAs an example, a mathematician might write: \n\nIn this statement, \"formula_6\" (in which formula_6 is read as \"ay en\" or perhaps, more formally, as \"the sequence ay en\") and \"formula_7\" are treated as nouns, while \"formula_8\" (read: the limit of formula_18 as \"n\" tends to infinity equals 'big A'), \"formula_9\", and \"formula_20\" are read as independent clauses, and \"formula_12\" is read as \"the equation formula_22 equals formula_18 plus formula_24\". Moreover, the sentence ends after the displayed equation, as indicated by the period after \"formula_20\". In terms of typesetting conventions, broadly speaking, standard mathematical functions such as and operations such as as well as punctuation symbols including the various brackets are set in while Latin alphabet variables are set in . Matrices, vectors, and other objects made up of components are set in . (There is some disagreement as to whether the standard constants (e.g., , π, i = (–1)) or the \"d\" in should be italicized. Greek letters are also usually set upright instead of slanted.) There are also a number of conventions for the part of the alphabet from which variable names are chosen. For example, , , , , , are usually reserved for integers, and are often used for complex numbers, while , , , α, β, γ are used for real numbers. The letters , , are frequently used for unknowns to be found or as arguments of a function, while , , are used for coefficients and , , are used as names of functions. These conventions are not hard rules.\n\nDefinitions are signaled by words like \"we call\", \"we say\", or \"we mean\" or by statements like \"An [\"object\"] is [\"word to be defined\"] if [\"condition\"]\" (for example, \"A set is closed if it contains all of its limit points.\"). As a special convention, the word \"if\" in such a definition should be interpreted as \"if and only if\".\n\nTheorems have generally a title or label in bold type, and possibly identify the originator (for example, \"\"). This is immediately followed by the statement of the theorem, usually set in italics. The proof of a theorem is usually clearly delimited, starting with the word \"Proof\" while the end of the proof is indicated by a halmos or another symbol, or by the letters Q.E.D..\n\nMathematics is used by mathematicians, who form a global community composed of speakers of many languages. It is also used by students of mathematics. As mathematics is a part of primary education in almost all countries, almost all educated people have some exposure to pure mathematics. There are very few cultural dependencies or barriers in modern mathematics. There are international mathematics competitions, such as the International Mathematical Olympiad, and international co-operation between professional mathematicians is commonplace.\n\nMathematics is used to communicate information about a wide range of different subjects. Here are three broad categories:\n\n\nMathematics can communicate a range of meanings that is as wide as (although different from) that of a natural language. As English mathematician R.L.E. Schwarzenberger says:\n\nSome definitions of language, such as early versions of Charles Hockett's \"design features\" definition, emphasize the spoken nature of language. Mathematics would not qualify as a language under these definitions, as it is primarily a written form of communication (to see why, try reading Maxwell's equations out loud). However, these definitions would also disqualify sign languages, which are now recognized as languages in their own right, independent of spoken language.\n\nOther linguists believe no valid comparison can be made between mathematics and language, because they are simply too different:\n\n\n\n"}
{"id": "29644522", "url": "https://en.wikipedia.org/wiki?curid=29644522", "title": "List of linguistic rights in European constitutions", "text": "List of linguistic rights in European constitutions\n\nLinguistic rights in Europe are stated in constitutions which differ by country. These constitutions usually state the national language or official language, and may or may not explicitly allow for other languages in the country. Most of the linguistic rights stated here are negative rights, which grant freedom of usage of own language and prevents discrimination based on language. Some countries do offer positive rights: for example provision of language education from State funds in Austria, Cyprus, Finland, Hungary, Moldova, Portugal, Romania, Turkey, and Ukraine.\n\nConstitution as adopted on 4 August 1998.<ref name=\"UNESCO 7/10/10\"> Linguistic Rights - National Constitutions, \"UNESCO MOST\", accessed October 7, 2010</ref>\n\nConstitution of Andorra as adopted on 28 April 1993.\n\nConstitution as adopted on 5 July 1995.\n\nConstitution as adopted in 1929.\n\nAustrian State Treaty, signed in 1955 and included in the Constitution\n\nConstitution as of 12 November 1995.\n\nConstitution as adopted on 15 March 1994.\n\nConstitution of 7 February 1831, revised to 17 February 1994.\n\nConstitution as adopted on 1 December 1995.\n\nConstitution as adopted on 12 July 1991.\n\nConstitution as adopted on 22 December 1990.\n\nConstitution as adopted on 6 August 1960.\n\nNeither the Czech Constitution nor the Charter name any official language of the country. Administrative code and Rules of Court Procedure, however, specify Czech language as the language of procedure of public administration and courts respectively. Specific linguistic rights are included in the following Articles of the Charter:\n\nSpecial enactments deal with the aforementioned constitutional rights of minorities. Special treatment is afforded to Slovak language, which may be the language of administrative and other procedure according to a number of specific laws. According to the Act on Rights of Members of Minorities, citizens belonging to minorities, which traditionally and on long-term basis live within the territory of the Czech Republic, enjoy the right to use their language in communication with authorities and in front of the courts of law. Other than Slovak, the languages of officially recognized minorities in the Czech Republic are Bulgarian, Croatian, German, Greek, Hungarian, Polish, Romani, Russian, Rusyn, Serbian and Ukrainian. These are indirectly under constitutional protection of the Charter's Article 25 via the Act on Rights of Minorities and official Government recognition. Unlike in many other European countries, the minorities' linguistic rights are not regionally restricted and may be enjoyed within the territory of the whole country. Among minorities which are as of 2012 seeking the same status are the Vietnamese and the Belorussian.\n\nNational or official languages: Danish, Standard German (regional), Faroese (regional), Greenlandic (regional)\n\nConstitution as adopted on 28 June 1992.\n\nConstitution as adopted on 17 July 1919.\n\nConstitution as adopted on 4 October 1958, and modified up to 25 June 1992.\n\nConstitution as adopted on 24 August 1995.\n\nConstitution as adopted on 23 May 1949 and amended up to 1995.\n\nConstitution as adopted on 11 June 1975.\n\nConstitution as adopted on 20 August 1949, updated to 1996.\n\nDoes not have constitutions or constitutional provisions related to linguistic rights.\n\nConstitution as adopted on 1 July 1937.<ref name=\"UNESCO 8/10/10\"> Linguistic Rights - National Constitutions, \"UNESCO MOST\", accessed October 8, 2010</ref>\n\nConstitution as adopted on 22 December 1947.\n\nThe Constitution of the Republic of Latvia was adopted by the Constitutional Assembly of Latvia on 15 February 1922 and it was last amended on 30 April 2002.\n\nIn addition the State Language Law provides further protection to Livonian language and Latgalian literary tradition and regards all other languages as a foreign. The law was adopted in December 1999 and entered into force on the 1st of September 2000.\n\nConstitution as adopted on 6 October 1921.\n\nConstitution as adopted on 25 October 1992.\n\nConstitution as adopted on 17 October 1868.\n\nConstitution as adopted on 17 November 1991.\n\nConstitution as adopted in 1964.\n\nConstitution as adopted on 29 July 1994.\n\nConstitution as adopted on 24 December 1922.\n\nMontenegrin became the official language of Montenegro with the ratification of a new constitution on 22 October 2007 Next to it, Serbian, Bosnian, Albanian and Croatian are recognized in usage.\n\nNational or official languages: Dutch, Achterhoeks, Drents, Western Frisian, Gronings, Limburgisch, Sinte Romani, Vlax Romani, Sallands, Stellingwerfs, Twents, Veluws, Western Yiddish.\n\nConstitution as adopted on 17 May 1814.\n\nConstitution as adopted on 2 April 1997.\n\nConstitution as adopted on 2 April 1976.\n\nConstitution as adopted on 8 December 1991.\n\nConstitution as adopted on 12 December 1993.\n\nDoes not have constitutions or constitutional provisions related to linguistic rights.\n\nThe official and national language is Serbian.\n\nConstitution as adopted on 3 September 1992.\n\nConstitution as adopted on 23 December 1991.\n\nConstitution as adopted on 29 December 1978.\n\nConstitution as adopted on 1 January 1975.\n\nNational or official languages: French, Standard German, Italian, Romansch.\n\nConstitution of 1982 as amended 17 October 2001.\n\nConstitution as adopted on 28 June 1996.\n\nNational or official languages: English, Welsh, French (regional).\n\nNational or official language: Latin.\n\n"}
{"id": "1882363", "url": "https://en.wikipedia.org/wiki?curid=1882363", "title": "Littlewood's three principles of real analysis", "text": "Littlewood's three principles of real analysis\n\nLittlewood's three principles of real analysis are heuristics of J. E. Littlewood to help teach the essentials of measure theory in mathematical analysis.\n\nLittlewood stated the principles in his 1944 \"Lectures on the Theory of Functions\"\n\nas:\nThe first principle is based on the fact that the inner measure and outer measure are equal for measurable sets, the second is based on Lusin's theorem, and the third is based on Egorov's theorem.\n\nLittlewood's three principles are quoted in several real analysis texts, for example Royden,\nBressoud,\nand Stein & Shakarchi.\n\nRoyden gives the bounded convergence theorem as an application of the third principle. The theorem states that if a uniformly bounded sequence of functions converges pointwise, then their integrals on a set of finite measure converge to the integral of the limit function. If the convergence were uniform this would be a trivial result, and Littlewood's third principle tells us that the convergence is almost uniform, that is, uniform outside of a set of arbitrarily small measure. Because the sequence is bounded, the contribution to the integrals of the small set can be made arbitrarily small, and the integrals on the remainder converge because the functions are uniformly convergent there.\n"}
{"id": "39122142", "url": "https://en.wikipedia.org/wiki?curid=39122142", "title": "Management of domestic violence", "text": "Management of domestic violence\n\nThe management of domestic violence deals with the treatment of victims of domestic violence and preventing repetitions of such violence. The response to domestic violence in Western countries is typically a combined effort between law enforcement, social services and health care. The role of each has evolved as domestic violence has been brought more into public view.\n\nHistorically, domestic violence has been viewed as a private family matter that need not involve the government or criminal justice. Police officers were often reluctant to intervene by making an arrest, and often chose instead to simply counsel the couple and/or ask one of the parties to leave the residence for a period of time. The courts were reluctant to impose any significant sanctions on those convicted of domestic violence, largely because it was viewed as a misdemeanor offense.\n\nThe modern view in industrialized countries is that domestic violence should be viewed as a public matter and all criminal authority should be involved; that once the violence is reported it should be taken seriously. Further, supports need to be put in place to restore the victim's safety and respect, which often includes the efforts of the person who did the harm. \n\nMedical professionals can make a difference in the lives of those who experience abuse. Many cases of spousal abuse are handled solely by physicians and do not involve the police. Sometimes cases of domestic violence are brought into the emergency room, while many other cases are handled by a family physician or other primary care provider. Subspecialist physicians are also increasingly playing an important role. For example, HIV physicians are ideally suited to play an important role in managing abuse given the association between abuse and HIV infection as well as their often lifelong relationships with patients.\n\nMedical professionals are in a position to give advice, and refer them to appropriate services. The health care professional has not always met this role, with uneven quality of care, and in some cases misunderstandings about domestic violence.\n\nCarole Washaw suggests that many doctors prefer not to get involved in people's \"private\" lives. Jenny Clifton, John Jacobs, Jo Tulloch found that training for general practitioners in the United States about domestic violence was very limited or they had no training. Abbott and Williamson found that knowledge and understanding of domestic violence was very limited among health care professionals in a Midlands, United Kingdom county, and that they do not see themselves as being able to play a major role in helping women in regards to domestic violence. Furthermore, in the biomedical model of health care, injuries are often just treated and diagnosed, without regard for the causes. As well, there is substantial reluctance for victims to come forward and broach the issue with their physicians. On average, women experience 35 incidents of domestic violence before seeking treatment.\n\nIn the U. S., the Institute of Medicine recognized the shortcomings of the health care system in its 2002 report entitled Confronting Chronic Neglect and attributed some of the problems cited to a lack of adequate training among health professionals. Health professionals have an ethical responsibility to recognize and address exposure to abuse in their patients, in the health care setting. For example, the American Medical Association's code of medical ethics states that \"Due to the prevalence and medical consequences of family violence, physicians should routinely inquire about physical, sexual, and psychological abuse as part of the medical history. Physicians must also consider abuse in the differential diagnosis for a number of medical complaints, particularly when treating women.\" \n\nIn the 1970s, studies in Europe and North America showed that domestic violence was widespread in many homes, resulting in emotional and physical trauma, and sometimes death. Into the 21st century many countries have taken steps to eradicate domestic violence, such as criminalization of violence against women and other abuses. Organizations have been formed which provide assistance and protection of domestic abuse victims, laws and criminal remedies, and domestic violence courts. In addition, social, legal, psychological, and medical services have been made available for victims of domestic violence.\n\nAlthough acts of domestic violence are criminal and a violation of human rights, safety and dignity, as of 2010 the United Nation has found that it is still often considered a private matter. Some countries with laws against domestic violence may not enforce them and there are many countries that do not criminalize domestic violence. The United Nations published \"Handbook on Effective Responses to Violence against Women\" for police and other first responders to provide guidelines for police intervention.\n\nWhere there are laws against domestic violence, such abuse is often under-reported. The reasons for not reporting may include that the victim does not want to end the relationship, report the violence or pursue legal remedies include:\n\nOf the cases that are reported, they are often under-prosecuted. \nCriminologists suggest that abusers who are employed and have ties to the community may initially fear punishment, though many cases do not make it all the way through the criminal justice process. If the victim is uncooperative during investigation, the prosecutor may choose not to pursue the case. If the case is pursued through the criminal justice system, sometimes the resulting sentence is minor. Subsequently, any fear that the abuser has of punishment may have diminished.\n\nAccording to the United Nations\"'Handbook on effective police responses to violence against women\": \"Without clearly targeted efforts to alter institutional culture and practices and to mainstream the issue of gender in legislation and practice, most legal and political reforms have little positive impact.\" An effective system requires \"cooperative, coordinated and effective\ninvolvement\" of law enforcement, communities, non-governmental organizations (NGOs), courts, and prisons. Way to manage violence against women is to increase the number of female officers in the police force and to offer training programs for officers. Other ways to prevent and manage domestic include the development and implementation of the following law enforcement practices:\n\n\nCommunity programs include the development of shelters for abuse survivors, programs to create a culture that does not condone domestic violence, creation of prevention and victim services programs, and the development of educational programs for the religious and cultural communities.\n\nDue to the extent and prevalence of violence in relationships, counselors and therapists are encouraged to assess every client for domestic violence (both experienced and perpetrated). If the clinician is seeing a couple for couple's counseling, this assessment should be conducted with each individual privately during the initial interview, in order to increase the victim's sense of safety in disclosing any violence in the relationship. In addition to determining whether violence is present, counselors and therapists should also make the distinction between situations where battering may have been a single, isolated incident or an ongoing pattern of control. The therapist must, however, consider that violence may be present even when there has been only a single physical incident as emotional/verbal, economic, and sexual abuse may be more insidious.\n\nAnother important issue in assessing clients for domestic violence lies in differing definitions of abuse – the therapist's definition may differ from that of the client, and paying close attention to the way the client describes their experiences is crucial in developing effective treatment plans. The therapist must determine if it is in the best interest of the client to explain that some behaviors (such as emotional abuse) are considered domestic violence, even if the client did not previously consider them as such.\n\nIf it becomes apparent to the therapist that domestic violence is taking place in a client's relationship, there are several statements the clinician can make that have been shown to be effective in rapport-building and immediate crisis intervention with clients. Firstly, it is essential that the therapist believe the victim's story and validate their feelings. It is recommended that the therapist acknowledge them for taking a risk in disclosing this information, and assure them that any ambivalent feelings they may be having are normal. The therapist should emphasize that the abuse they have experienced is not their fault, but should keep their feelings of ambivalence in mind and refrain from blaming their partner or telling them what to do. It is unreasonable for the therapist to expect that a victim will leave their perpetrator solely because they disclosed the abuse, and the therapist should respect the victim's autonomy and allow them to make their own decisions regarding termination of the relationship. Finally, the therapist must explore options with the client (such as emergency housing in shelters, police involvement, etc.) in order to uphold their obligation to protect the welfare of the client.\n\nA lethality assessment is a tool that can assist in determining the best course of treatment for a client, as well as helping the client to recognize dangerous behaviors and more subtle abuse in their relationship. In a study of victims of attempted domestic violence-related homicide, only about one-half of the participants recognized that their perpetrator was capable of killing them, as many domestic violence victims minimize the true seriousness of their situation. Thus, lethality assessment is an essential first step in assessing the severity of a victim's situation.\n\nSafety planning allows the victim to plan for dangerous situations they may encounter, and is effective regardless of their decision on whether remain with their perpetrator. Safety planning usually begins with determining a course of action if another acute incident occurs in the home. The victim should be given strategies for their own safety, such as avoiding confrontations in rooms where there is only one exit and avoiding certain rooms that contain many potential weapons (such as kitchens, bathrooms, etc.).\n\nThe main goal for counselling for offenders of domestic violence is to have them stop the violence and repair the harms they have created. Such work needs to restore the victims' safety and respect, not necessarily restoring the intimate relationship. Counselling for offenders emphasizes minimizing risk to the victim, and should be modified depending on the offender's history, risk of reoffending, and criminogenic needs. The majority of offender treatment programs are 24–36 weeks in length and are conducted in a group setting with groups not exceeding 12 participants.\n\nGender specific groups (male offenders only or female offenders only) are common in the field. Groups can be helpful to establish group norms that are contrary to the use of violence that, in turn, create a context where offenders are held accountable to their own values in a respectful manner. Successful completion of groups is generally associated with old age, higher levels of education, lower reported drug use, non-violent criminal histories, and longer intimate relationships. \n\nAlong with offering group conversations, others incorporate individual and conjoint conversations to assist in ending the violence and repairing the harms. One such approach, which focuses on restorative justice, is highlighted in the critically acclaimed documentary A Better Man. \"Maclean's\" reported, “The film manages to be simultaneously agonizing and hopeful… it is revelatory to know these kinds of [restorative] conversations are possible.” Film reviewer Miria Bale of Vulture.com heralds the film is a \"Revolutionary documentary.\"\n\nAnger management alone has not been shown to be effective in treating domestic violence offenders because such an approach seldom addresses the societal influences that are influencing offenders choices to perpetrate violence.\n\nAnger management is recommended as a part of an offender program that is based on accountability, along with topics such as recognizing abusive patterns of behavior and re-framing communication skills. Interventions require not only stopping the violence but developing a plan to repair harms. Any corresponding problems should also be addressed as part of domestic violence offender treatment, such as problems with substance abuse or other mental illness.\n\nVictims of domestic violence may require occupational therapy to be able to participate in work and to address a diminished skill-set caused by a prolonged absence from the workforce. Occupational therapists work with individuals to develop the skills needed to acquire desired roles and satisfactorily perform everyday tasks. Occupational therapists can provide services through direct or indirect treatment, advocacy efforts, consultation, or group sessions. They may work with victims of domestic violence and their families in a variety of settings such as hospitals, inpatient and outpatient rehabilitation centers, long-term care facilities, mental health facilities, schools, homes, and in shelters or other community programs.\n\nWithin any of the practice settings, occupational therapists may encounter victims of domestic violence including individuals who have not reported abuse. Occupational therapists are in a position to uncover information that leads to suspicion of violence or identification of abuse that has occurred. As health care professionals, occupational therapists follow state mandated requirements to report abuse. In treatment sessions, they may encounter individuals who have either chosen to remain in or must move on from an intimate relationship where abuse has occurred. Occupational therapists may see patients for complications directly related to abuse, such as physical injuries. On the other hand, occupational therapy services may be requested for unrelated issues but consequences of violence are addressed after the patient reveals abuse to the therapist.\n\nThe consequences of domestic violence may impact the ability to perform daily occupations. Occupational therapy contributes to recovery by enabling victims to create new roles, develop satisfying and productive routines, and gain the self-efficacy necessary to overcome the effects of domestic violence. Occupational therapy interventions may include:\n\nOT interventions with children who are exposed to domestic violence are focused on promoting age appropriate academic, play, and social skills to facilitate proper development and success in school activities. This may include activities to improve organization, study habits, or attention. Adolescents who have seen or experienced domestic abuse may also benefit from occupational therapy to work on relationship and life skills and learn coping strategies.\n\nThere are many community organizations which work to prevent domestic violence by offering safe shelter, crisis intervention, advocacy, and education and prevention programs. Community screening for domestic violence can be more systematic in cases of animal abuse, healthcare settings, emergency departments, behavioral health settings and court systems. Tools are being developed to facilitate domestic violence screening such as mobile apps.\n\nIn 1981, the Duluth Domestic Abuse Intervention Project became the first multi-disciplinary program designed to address the issue of domestic violence. This experiment, conducted in Duluth, Minnesota, frequently referred to as the \"Duluth Project\" because it is constantly evolving through the help of an entire community. The Domestic Abuse Intervention Program has federal, state and local funders who support them. This funding allows DAIP to explore strategies to end violence to communities throughout the United States and around the world.\n\nThe objectives of the Duluth approach:\n\nA news report from California cites a batterer intervention by \"The Center for Violence-Free Relationships\" based on Nonviolent Communication as having demonstrated zero percent recidivism within 5 years, and contrasts this with 40 percent recidivism within 5 years said to have been reported by DAIP for graduates of programs based on the Duluth Model.\n"}
{"id": "7587198", "url": "https://en.wikipedia.org/wiki?curid=7587198", "title": "Media system dependency theory", "text": "Media system dependency theory\n\nMedia system dependency theory (MSD), or simply media dependency, was developed by Sandra Ball-Rokeach and Melvin Defleur in 1976. The theory is grounded in classical sociological literature positing that media and their audiences should be studied in the context of larger social systems. MSD ties together the interrelations of broad social systems, mass media, and the individual into a comprehensive explanation of media effects. At its core, the basic dependency hypothesis states that the more a person depends on media to meet needs, the more important media will be in a person's life, and therefore the more effects media will have on a person. \nDependency on media emerges from three relationships.\n\nAccording to Ball-Rokeach and DeFleur, three media needs determine how important media is to a person at any given moment:\n\nWhen these needs for media are high, the more people turn to media to meet these needs, and therefore the media have a greater opportunity to affect them. That said, none of these media needs are constant over long periods of time. They change based on aspects of our social environment.\n\nMedia dependency theory states two specific conditions under which people's media needs, and consequently people's dependency on media and the potential for media effects, are heightened.\n\nThe first condition of heightened media needs occurs when the number of media and centrality of media functions in a society are high. For instance, in modernized countries like the United States, there are many media outlets and they serve highly centralized social functions. In the United States alone, the media act as a \"fourth branch\" of government, an alarm system during national emergencies, and as a tool for entertainment and escape, whereas in the underdeveloped world the media are not as numerous and serve far fewer functions. As such, the media have a greater opportunity to serve needs and exert effects in contemporary America than in a third world country.\n\nThe second condition of heightened media needs occurs when a society is undergoing social change and conflict. When there is a war or large-scale public protests like during Vietnam or the Arab Spring, a national emergency like the terrorist attacks of September 11, 2001, or a natural disaster like Hurricane Katrina, people turn to media to help understand these important events. Consequently, the media have a greater opportunity to exert effects during these times of social change and conflict.\n\nBall-Rokeach and DeFleur suggests that the cognitive, behavioral and affective consequences of media use\nare premised upon characteristics of both individuals and their social environment.\n\nThere are five types of cognitive effects that will be exerted on audiences, the first of which is the creation and resolution of ambiguity. Ambiguity occurs when audiences receive inadequate or incomplete information about their social world. When there is high ambiguity, stress is created, and audiences are more likely to turn to mass media to resolve ambiguity. Ambiguity might be especially prevalent during times of social change or conflict.\n\nThe second effect is agenda-setting. This is another reason why we might call dependency a \"comprehensive\" theory of media effects – it incorporates the entire theory of agenda-setting within its theoretical framework. Like any other effect, media agenda-setting effects should be heightened during times when the audience's needs and therefore dependency on media are high. So, for instance, if our informational needs and dependency on media was high during the invasion of Iraq in 2003, we would have been more susceptible to agenda-setting effects, and we would have therefore perceived the Iraq War as the most important problem (MIP) facing the United States.\n\nThird is attitude formation. Media exposes us to completely new people, such as political figures and celebrities, not to mention physical objects like birth control pills or car safety mechanisms that we come to form attitudes about. Dependency does not suggest media are monolithic in their ability to influence attitudes, but the theory does suggest that media play a role in selecting objects and people for which people form attitudes about. If a person is experiencing greater media dependency, we would therefore expect that the person will form more (or more complex) attitudes about these attitude-objects than people with low media dependency.\n\nMedia also have the potential cognitive effect of expanding people's belief systems. Media can create a kind of \"enlargement\" of citizen's beliefs by disseminating information about other people, places, and things. Expansion of people's belief systems refers to a broadening or enlarging of beliefs in a certain category. For example, a constant flow of information about global warming will expand people's beliefs about pollution affecting the earth's atmosphere, about cap and trade and other policies, and about personal contributions to global warming. These beliefs meet with and are incorporated into an existing value system regarding religion, free enterprise, work, ecology, patriotism, recreation, and the family.\n\nLast is value clarification and conflict. Media help citizens clarify values (equality, freedom, honesty, forgiveness) often by precipitating information about value conflicts. For instance, during the 1960s the mass media regularly reported on the activities of the Civil Rights movement, presenting conflicts between individual freedoms (e.g., a businessman's property rights to deny blacks entrance) and equality (e.g., human rights). When such conflicts play out in the mass media, the value conflicts are identified, resulting in audiences forming their own value positions. Such a position can be painful to articulate because it can force a choice between mutually incompatible goals and the means for obtaining them. However, in the process of trying to decide which is more important in a particular case, general value priorities can become clarified.\n\nBall-Rokeach and DeFleur mentions several possible affective media effects that are more likely to occur during times of heightened dependency. First is desensitization, which states that prolonged exposure to violent content can have a \"numbing\" effect on audiences, promoting insensitivity or the lack of desire toward helping others when violent encounters happen in real life.\n\nSecond, exposure to news messages or TV dramas that portray crime-ridden cities can increase people's fear or anxiety about living in or even traveling to a city.\n\nMedia can also have effects on morale and feelings of alienation. The degree of positive or negative mass media depictions of social groups can cause fluctuations in people's sense of morale in belonging to that group or in their sense of alienation from that group.\n\nThere are two broad categories of behavioral effects that Ball-Rokeach and DeFleur identify. The first broad category is called \"activation\" effects, which refer to instances in which media audiences do something they would not otherwise have done as a consequence of receiving media messages. Behavioral effects are largely thought to work through cognitive and affective effects. For instance, a woman reading a news story about sexism in the workplace might form an attitude toward sexism that creates a negative emotional state, the culmination of which is joining a women's rights march in her local community.\n\nThe second broad category of behavioral effects is called \"deactivation\", and refers to instances in which audiences would have otherwise done something, but don't do as a consequence of media messages. For example, the primary presidential campaign has become longer and increasingly use more media to target audiences. As such, primary campaigns might elicit negative attitudes toward the electoral process and negative affective states such as boredom or disgust that in turn might make a person not turn out to vote.\n\nIn the MSD view, the media system has two-way resource-dependency relations with individuals (micro-level), groups and organizations (meso-level), and other social systems (macro-level).\n\nMicrolevel, or individual level application, focuses on the relationship between individuals and media. The microlevel dependency, better known as individual level media system dependency (IMD), begins with an assessment of the types of motivation that bring individuals to use the media.\nIn the perspective of IMD, goals are preferred to needs to conceptualize the motivations that affect media behavior. According to Ball-Rokeach and DeFleur, goals are the key dimension of individual motivation. While needs imply both rational and irrational motives, goals imply a problem-solving motivation more appropriate to a theory of media behavior based upon the dependency relation.\n\nThe IMD approach provides a comprehensive conceptualization of three motivational goals: understanding, orientation, and play.\n\nEvery country's media system is interdependent on the country's other social systems (e.g., its economy, its government) for resources, and vice versa. At the macrolevel, dependency theory states these interrelationships influence what kinds of media products are disseminated to the public for consumption, and the range of possible uses people have for media.\n\nThe media depend on a society's economic system for 1) inculcation and reinforcement of free enterprise values, 2) establishing and maintaining linkages between producers and sellers, and 3) controlling and winning internal conflicts, such as between management and unions. In turn, the media is dependent on a society's economic system for 1) profit from advertising revenue, 2) technological developments that reduce costs and compete effectively with other media outlets, and 3) expansion via access to banking and finance services, as well as international trade.\n\nA society's media and political system are also heavily interdependent. Political system rely on the media to 1) inculcate and reinforce political values and norm such as freedom, voting, or obedience to the law, 2) maintain order and social integration, 3) organize and mobilize citizens to carry out essential activities like waging war, and 4) controlling and winning conflicts that develop within political domains (e.g., Watergate). Conversely, the media rely on a country's political system for judicial, executive, and legislative protection, formal and informal resources required to cover the news, and revenue that comes from political advertising and subsidies.\n\nTo a lesser extent, media has established interdependencies with several other social systems. The family is dependent on media for inculcation and reinforcement of family values, recreation and leisure, coping with everyday problems of child rearing, marriage, and financial crises. On the other hand, the media is dependent on the family for consuming their media products.\n\nThe same is true of media and religious systems. Religious systems rely on media for inculcation and reinforcement of religious values, transmitting religious messages to the masses, and successfully competing with other religious or nonreligious philosophies. In turn, the media relies on the religious system to attain profits from religious organizations who purchase space or air time.\n\nThe educational system in a society relies on media for value inculcation and reinforcement, waging successful conflicts or struggles for scarce resources, and knowledge transmission such as in educational media programming. Media depends on the educational system for access to expert information and being able to hire personnel trained in the educational system.\n\nFinally, the military system depends on the media for value inculcation and reinforcement, waging and winning conflicts, and specific organizational goals such as recruitment and mobilization. The media, in turn, depends on the military for access to insider or expert information.\n\nThe consequences of all of these interdependencies, again, are alterations in media products that audiences consume. In this way, the system-level interdependencies control media products, the range of possible social uses for media, the extent to which audiences depend on the media to fulfill needs, and ultimately media effects on audiences. Individual differences due to demographics or personality traits might change what people actually do with media messages or how they interpret media messages, but the messages always begin as the result of interdependent social systems.\n\nBall-Rokeach summarized the major differences between uses and gratification (U&G) theory and media system dependency (MSD) theory.\n\nBoth U&G and MSD theorists view the audience member as active, but the basic conceptions of the audience member differ. U&G theorists focus on psychological and sociodemographic origins of differences in media use. In this perspective, the variability of text interpretation suggests an audience member in charge of the text.\n\nMSD theorists focus on psychological, interpersonal, and sociological origins of differences in micro MSD relations as well as the macro MSD relations that constrain media text production and individual's MSD relations. The responsiveness of micro MSD relations to environmental conditions and the ecological constraints on media production and consumption are important features. In this perspective, the audience member is neither in charge of the text nor controlled by the text. The only way we can predict the effects is the audiences' MSD relations in context of the ecology of macro relations.\n\nU&G theorists emphasize the role of interpersonal communication in the distortion of media messages and of networks as interpretive communities. In this conception, interpersonal networks are regarded as a safety way against the cultural apparatus of the media and its partners. They believe that the interpersonal network contributes to individual \"agency\", and the \"networked\" individual is empowered to manipulate media texts, not to be manipulated by them.\n\nThe MSD conception is compatible with the U&G conception up to a point. Consistent with MSD conceptions of the individual member of the active media audience, the interpersonal networks play major roles in MSD theory. They link the individual to public and they link and influence the nature of the individual's relations with the media system.\n\nU&G theorists in the psychological tradition think of the media system as creators of tentative texts subject to multiple reconstructions. In this perspective, the media system is functional to the extent that it is useful or affords ways for individuals to gratify needs.\n\nThe MSD conception is closer to a macro functionalist version of U&G. MSD shares the macro functionalists' view of the media's interdependence with other social and cultural system. In this view, the function of media is seen as a key structure for vertical and horizontal integration of society. The MSD viewpoints seem to be even closer to cultural studies traditions in that the central concern for structural relations of control over information resources that generate the power to create social realities and to negotiate social conflict and social change.\n\nAlthough both U&G and MSD researchers ask similar questions of individuals, they do so for very different reasons. Those differences are reflected most clearly in (a) the logics of hypothesis formation (b) item and scale construction (c) modes of data analysis, and (d) interpretation of findings.\n\nThe MSD researcher essentially wants to know the micro and macro determinants of stability and change in micro MSD relations to learn something about their cross-level consequences for individuals and their interpersonal networks-the dynamics of their inner worlds and how they live in their social worlds. The U&G theorist wants to learn something about the individual's attraction to media texts and the interaction between text and reader to better understand the contributions of reader characteristics to text processing. The differences between micro U&G and micro MSD are, thus, in their epistemological origins, assumptions, concepts, and missions.\n\nThe characteristics of new media, including social media domain and the unique contents available through participatory use, as adding to the measure of individual dependency relation (IMD), are treated as the mediator. This cognitive process of mediating IMD is called new media dependency (NMD). Age and the popularity of online contents are seen as influential to NMD, in which younger people show higher NMD especially on popular content.\n\nHowever, the communication environment has changed as social media provides more choices for people to actively select information generated by other people, instead of passively receiving from satellites and cable channels.\n\nThree basic factors of MSD – individual characteristics, social environment, and media system activity – are derived from both micro and macro levels in a society, postulating media remained on a single level. However, the functionality of social media has been suggested as crossing those levels. Through social media, users are able to create the story (on the micro level), and the story can be either shared publicly (on the macro level) or not. Thus, social media gain the ability to move across levels.\n\nParticularly, there are lots of MSD studies in online social networking sites ranging from MySpace to Facebook and Twitter. Yet, scholars still have concerns about whether it is appropriate or not to apply MSD for studying the use of social media.\n\nSome believe that MSD accounts for social media, giving reasons that:\nOn the contrary, others challenge that MSD does not fit well with social media studies, because:\n\nBaran and Davis identify four primary criticisms of dependency theory:\n\n"}
{"id": "54259556", "url": "https://en.wikipedia.org/wiki?curid=54259556", "title": "Mongolian units", "text": "Mongolian units\n\nMongolian units are the traditional units of measurement of the Mongolian people.\n\n"}
{"id": "46659238", "url": "https://en.wikipedia.org/wiki?curid=46659238", "title": "Nábrók", "text": "Nábrók\n\nNábrók (calqued as necropants, literally \"corpse trousers/underpants\") are a pair of pants made from the skin of a dead man, which are believed in Icelandic witchcraft to be capable of producing an endless supply of money. It is unlikely these pants ever existed outside of folklore.\n\nThe ritual for making necropants is described as follows:\n"}
{"id": "17449489", "url": "https://en.wikipedia.org/wiki?curid=17449489", "title": "Objective precision", "text": "Objective precision\n\nIn philosophy and second scholasticism, objective precision (Latin \"praecisio obiectiva\") is the \"objective\" aspect of abstraction. Objective precision is the process by which certain features (the differentiae) of the real object of a formal concept are excluded from the comprehension of that concept; the object is thus being intentionally transformed into a universal objective concept. Objective precision is thus a process by which universal objective concepts arise. It is the \"objective\" aspect of the process of (total) abstraction or concept-formation.\n\nObjective precision is distinguished against formal precision. Whereas objective precision is a process on the part of objective \"concepts\" (the objective correlates of the mental acts by means of which something is being conceived) formal precision is the corresponding process on the part of formal concepts or the mental \"acts\" themselves. Objective and formal precision are the two aspects (objective and subjective) of abstraction.\n\nThe two opposing philosophical views on universals, nominalism (or rather conceptualism) and realism can be defined by means of their relation to objective precision: anyone who accepts objective precision, is a philosophical realist; anyone who rejects it, is a conceptualist or nominalist (in a broad sense). In other words, the nominalists reject the idea that our universal mental concepts (formal concepts) require universal intentional objects; thus, according to nominalists, in abstraction only formal precision takes place, no objective precision.\n\nThe schools are divided in their opinion what constitutes the necessary condition on the part of the object in order that objective precision be possible. According to the Thomists a virtual distinction on the part of the object between the excluded differentia and the arising abstracted objective concept is sufficient to make objective precision possible. According to the Scotists, a formal distinction is generally required, although certain Scotists (like Bartolomeo Mastri) regard virtual distinction as sufficient in certain special cases. Suárez defends objective precision but he rejects any distinctions on the part of the object. The nominalists (conceptualists) agree with the Scotists that a formal distinction would be necessary to enable objective precision, but since they regard such a distinction as impossible, they reject objective precision altogether.\n"}
{"id": "199140", "url": "https://en.wikipedia.org/wiki?curid=199140", "title": "Peace through strength", "text": "Peace through strength\n\n\"Peace through strength\" is a phrase which suggests that military power can help preserve peace. It is quite old and has famously been used by many leaders from Roman Emperor Hadrian in the first century AD to former U.S. President Ronald Reagan in the 1980s. The concept has long been associated with realpolitik. The idea has critics: \"'Peace through strength' easily enough becomes 'peace through war,'\" according to Andrew Bacevich.\n\nThe phrase and concept date to ancient times. Roman Emperor Hadrian (AD 76–138) is said to have sought \"peace through strength or, failing that, peace through threat\". Hadrian's Wall was a symbol of this policy.\n\nThe first American President, George Washington, enunciated a policy of peace through strength in his fifth annual message to Congress, the 1793 State of the Union Address. He said:\n\nIn Federalist No. 24, Alexander Hamilton argued for peace through strength, stating that strong garrisons in the west and a navy in the east would protect the Union from the threat of Britain and Spain.\n\n\"Peace Through Strength\" (1952) is the title of a book about a defense plan by Bernard Baruch, a World War II adviser to U.S. President Franklin D. Roosevelt, published by Farrar, Straus and Young. During the 1964 presidential campaign in the United States, the Republican party spent about $5 million on \"Peace through Strength\" TV spots. For supporters of the MX missile in the 1970s, the missile symbolized \"peace through strength\".\n\nIn 1980, Ronald Reagan used the phrase during his election challenge against Jimmy Carter, accusing the incumbent of weak, vacillating leadership that invited enemies to attack the United States and its allies. Reagan later considered it one of the mainstays of his foreign policy as President. In 1986, he explained it thus:\n\nThe approach has been credited for forcing the Soviet Union to lose the arms race and end the Cold War. \"Peace Through Strength\" is the official motto of the \"Nimitz\"-class nuclear-powered aircraft carrier, USS \"Ronald Reagan\" (CVN-76).\n\n\"Peace Through Strength\" appeared in the Republican Party platforms of 1980, 1984, 1988, 1992, 1996, 2000, 2008, 2012, 2016.\n\nOn assuming office in January 2017, President Trump cited the idea of \"Peace Through Strength\" as central to his overall \"America First\" foreign policy.\n\nFor Andrew Bacevich, \"belief in the efficacy of military power almost inevitably breeds the temptation to put that power to work. 'Peace through strength' easily enough becomes 'peace through war.'\"\n\nJim George of Australian National University used the term to describe part of what he argued was the Straussian and neoconservative foreign policy of the George W. Bush administration.\n\nThe mock inversion \"strength through peace\" has been used on occasion to draw criticism to the militaristic system of diplomacy advocated by \"peace through strength\". Ohio Congressman Dennis Kucinich adopted the slogan \"Strength Through Peace\" during his 2008 Presidential run, as part of his platform as a peace candidate in opposition to the Iraq War.\n\nDuring Reagan's presidency, the non-profit American Security Council Foundation (ASCF) and its for-profit direct-mail provider, Communications Corporation of America, sought to influence United States foreign policy by promoting the idea, but after the Soviet collapse of 1991 ASCF fell into obscurity while other organizations continued to promote the slogan. The Heritage Foundation and the Center for Security Policy (CSP) have also used the term in print. The ASCF registered a trademark for the phrase in April 2011. In September 2012, ASCF filed a trademark infringement lawsuit against CSP and Frank Gaffney, prompting the \"Washington City Paper\" to ridicule ASCF's Director of Operations, Gary James, for editing the online encyclopedia Wikipedia article titled 'Peace through strength' so that it was \"drenched in ... ASCF references\". Following a counterclaim by the CSP alleging that the trademark application had been fraudulent, in August 2013 the ACSF announced that it had settled the lawsuit with the CSP and would cancel its trademark claim.\n\n"}
{"id": "57736445", "url": "https://en.wikipedia.org/wiki?curid=57736445", "title": "Planter class", "text": "Planter class\n\nThe planter class, known alternatively in the United States as the Southern aristocracy, was a socio-economic caste of Pan-American society that dominated seventeenth- and eighteenth-century agricultural markets through the forced labor of enslaved Africans. The Atlantic slave trade permitted planters access to inexpensive labor for the planting and harvesting of crops such as cotton, coffee, tea, cocoa, sugar cane, sisal, oil seeds, oil palms, rubber trees, and fruits.\n\nIn the American South, planters maintained a distinct culture characterized by its similarity to the manners and customs of European nobility with an emphasis on chivalry, gentility, and hospitality, the latter becoming a marked trait of modern Southern society.\n\nAfter the American Civil War, many in this class saw their wealth greatly reduced as the enslaved Africans were freed. Union forces under Generals William T. Sherman and Phillip Sheridan had also cut wide swaths of destruction through portions of Virginia, the Carolinas and Georgia destroying crops, killing or confiscating livestock, burning barns and gristmills, and in some cases torching plantation houses themselves in scorched earth tactics designed to starve the Confederacy into submission. After emancipation, many plantations were converted to sharecropping with freed Africans working as sharecroppers on the same land they had worked as slaves before the war. During the Gilded Age many were purchased by wealthy northern industrialists as hunting retreats. Later some plantations became museums, often on the U.S. National Register of Historic Places.\n\nPlanters were prolific throughout the British, Dutch, French, Portuguese and Spanish colonies of North and South America, and the West Indies. Popular characters of this class include William Byrd, Mary Chesnut, Jefferson Davis, Thomas Jefferson, Robert E. Lee, Jacques Villeré, Sallie Ward, George Washington, and the fictional Scarlett O'Hara.\n\nThe search for gold and silver was a constant theme in overseas\nexpansion, but there were other European demands the New World could also\nsatisfy, which contributed to its growing involvement in the Western-dominated\nworld economy. While Spanish America seemed to fulfill dreams of mineral\nwealth, Brazil became the first major plantation colony in 1532, organized to produce a tropical crop – sugar – in great demand and short supply in Europe. The other major powers, England, France and the Netherlands, soon thereafter hoped to establish profitable colonies of their own. Presented with new opportunities, Europeans disenchanted by the rigid social structures of feudalism emigrated to the abundant virginal lands of the colonial frontier.\n\nArriving through the late sixteenth and early seventeenth centuries, settlers landed on the shores of an unspoiled and hostile countryside. Early planters first began as colony farmers providing for the needs of settlements besieged by famine, disease and tribal raids. Native Americans friendly to the colonists taught them to cultivate native plant species including tobacco, sugar and fruits, which within a century would become a global industry itself funding a multinational slave trade. Colonial politics would come to be dominated by wealthy noble landowners interested in commercial development.\n\nIn an effort to reduce the financial burden of continental wars, European governments began instituting land pension systems by which a soldier, typically an officer, would be granted land in the colonies for services rendered. This incentivized military professionals to settle in the Americas and thus contribute to colonial defense against foreign colonists and hostile Natives.\n\nJohn Rolfe, a settler from Jamestown, was the first colonist to grow tobacco in North America. He arrived in Virginia with tobacco seeds procured from an earlier voyage to Trinidad, and in 1612 harvested his inaugural crop for sale on the European market. During the 17th century, the Chesapeake Bay area was immensely hospitable to tobacco cultivation. Ships annually hauled 1.5 million pounds (680,000 kilograms) of tobacco out to the Bay by the 1630s, and about 40 million pounds (18 million kilograms) by the end of the century. Tobacco planters financed their operations with loans from London. When tobacco prices dropped precipitously in the 1750s, many plantations struggled to remain financially solvent. In an effort to combat financial ruin planters either pushed to increase crop yield or, with the depletion of soil nutrients, converted to growing cotton.\n\nIn 1720, coffee was first introduced to the West Indies by French naval officer Gabriel de Clieu, who procured a coffee plant seedling from the Royal Botanical Gardens in Paris and transported it to Martinique. He transplanted it on the slopes of Mount Pelée and was able to harvest his first crop in 1726, or shortly thereafter. Within fifty years there were 18,000 coffee trees in Martinique enabling the spread of coffee cultivation to Saint-Domingue, New Spain and other islands of the Caribbean. The French territory of Saint-Domingue began cultivating coffee in 1734, and by 1788 supplied half the global market. The French colonial plantations relied heavily on African slave laborers. However, the harsh conditions that slaves endured on coffee plantations precipitated the Haitian Revolution. Coffee had a major influence on the geography of Latin America.\n\nAn age of enlightenment dominated the world of ideas in Europe during the eighteenth century. Philosophers began writing pamphlets against slavery and its moral and economic justifications, including Montesquieu in \"The Spirit of the Laws\" (1748) and Denis Diderot in the \"Encyclopédie\". The laws governing slavery in the French West Indies, the \"Code Noir\" of Louis XIV, granted unparalleled rights for slaves to marry, gather publicly, or abstain from work on Sundays. It forbade slave owners to torture or to separate families; and though corporal punishment was sanctioned, masters who killed their slaves or falsely accused a slave of a crime and had the slave put to death would be fined. Masters openly and consistently broke the \"Code\" and passed local legislation that reversed its less desirable articles.\n\nEnlightenment writer Guillaume Raynal attacked slavery in the 1780 edition of his history of European colonization. He also predicted a general slave revolt in the colonies, saying that there were signs of \"the impending storm.\" Sugar production in Saint-Domingue was sustained under especially harsh conditions, including the humid climate of the Caribbean, where diseases such as malaria and yellow fever caused high mortality. White planters and their families, together with the merchants and shopkeepers, lived in fear of slave rebellion. Thus, in the functions of society and efforts to combat dissent, cruelty was noted in the form of overwork, inadequate food and shelter, insufficient clothing and medical care, rape, lashings, castration and burnings. Runaway slaves—called Maroons—hid in the jungles away from civilization, living off the land and what could be stolen in violent raids on the island's sugar and coffee plantations. Although the numbers in these bands grew large (sometimes into the thousands), they generally lacked the leadership and strategy to accomplish large-scale objectives. In April 1791, a massive slave insurgency rose violently against the plantation system, setting a precedent of resistance to slavery.\n\nOn 4 February 1794, during the French Revolution, the National Assembly of the First Republic abolished slavery in France and its colonies. The military successes of the French Republic and Napoleon carried across Europe the ideals of egalitarianism and brought into question the practice of slavery in the colonies of other European powers.\n\nThe legality of slave ownership under English common law was abolished in 1772, but this failed to abolish slavery overseas. British banks continued to finance the commodities and shipping industries in the colonies they had earlier established which still relied upon slavery, despite the legal developments in Great Britain. In 1783, an anti-slavery movement began among the British population, and that same year a group of Quakers founded the first British abolitionist organization. William Wilberforce led the cause of abolition through the parliamentary campaign. His efforts finally abolished the slave trade in the British Empire with the Slave Trade Act 1807. He continued to campaign for the abolition of slavery in the British Empire, which he lived to see in the Slavery Abolition Act 1833.\n\nA plantation house served to group the owner's family, guests and house slaves within one large structure in a central location on the estate. Often starting as a modest abode, the house was enlarged or replaced with a newer, more impressive home as the planter's wealth grew. Commonly seen is the addition of massive Greek Revival columns, curved stairs, semi-detached wings, and other architectural elements popular at the time.\n\nThe French origins of planters in Canada, Louisiana and Saint-Domingue heavily influenced the development of French Colonial architecture, characterized by its wide hipped rooves extending over wrap-around porches, thin wooden columns, and living quarters raised above ground level. Learning building practices from the West Indies, colonists designed practical dwellings for a territory prone to flooding.\n\nA notable loss of plantation homes in Louisiana is attributed to an economic shift from agriculture to industry during the Reconstruction era. Many homes were lost to the predatory lending practices of carpetbaggers in the closing days of the American Civil War, including that of Confederate General P.G.T. Beauregard after his crop of sugar cane was lost to the flood waters of a ruptured levee.\n\nGeorgian architecture was widely disseminated in the English colonies during the Georgian era. American buildings of the Georgian period were very often constructed of wood with clapboards; even columns were made of timber, framed up, and turned on an oversized lathe. At the start of the period the difficulties of obtaining and transporting brick or stone made them a common alternative only in the larger cities, or where they were obtainable locally.\n\nA premier example of Georgian planter architecture is Westover Plantation, built in the mid-eighteenth century as the residence of William Byrd II, founder of the City of Richmond. An elaborate doorway, which is recognized as \"the Westover doorway,\" adorns the main entrance and contrasts an otherwise simple construction. During the American Civil War the house served as the headquarters of Union General Fitz John Porter, protégé of George McClellan, who was stationed at nearby Berkeley Plantation, and purportedly had its East wing stuck by a Confederate cannonball fired from the south side of the James River. The wing caught fire and lay in ruin until Mrs. Clarise Sears Ramsey, a Byrd descendent, purchased the property in 1899. She was instrumental in modernizing the house, rebuilding the East wing and adding hyphens to connect the main house to the previously separate dependencies, thereby creating one long building.\n\nIntroduced to the continent by George Berkeley in the 1720s, Palladian architecture became popular with American society in the construction of colleges and public buildings, while many houses too were built in the Jefferson Paladian style of Monticello. Andrea Palladio developed Palladianism in the sixteenth century, publishing in 1570 \"Quattro Libri\", a treatise on architecture in four volumes and illustrated with woodcuts after Palladio's own drawings.\n\nCovered and columned porches feature prominently in Palladian architecture, in many cases dominating the main facade. Red brick exteriors and either slanted or domed rooves are commonplace among residential buildings.\n\nMonticello, residence of U.S. President Thomas Jefferson, was built in a style unique to Jefferson. This has been emulated in the construction of many colleges, such as The Rotunda of the University of Virginia, as well as churches, court houses, concert halls, and military schools.\n\n"}
{"id": "174806", "url": "https://en.wikipedia.org/wiki?curid=174806", "title": "Red Scare", "text": "Red Scare\n\nA \"Red Scare\" is promotion of widespread fear by a society or state about a potential rise of communism, anarchism, or radical leftism. The term is most often used to refer to two periods in the history of the United States with this name. The First Red Scare, which occurred immediately after World War I, revolved around a perceived threat from the American labor movement, anarchist revolution and political radicalism. The Second Red Scare, which occurred immediately after World War II, was preoccupied with national or foreign communists infiltrating or subverting U.S. society or the federal government.\n\nThe first Red Scare began following the Bolshevik Russian Revolution of 1917 and the intensely patriotic years of World War I as anarchist and left-wing social agitation aggravated national, social, and political tensions. Political scientist, and former member of the Communist Party Murray B. Levin wrote that the Red Scare was \"a nationwide anti-radical hysteria provoked by a mounting fear and anxiety that a Bolshevik revolution in America was imminent—a revolution that would change Church, home, marriage, civility, and the American way of Life\". Newspapers exacerbated those political fears into anti-foreign sentiment because varieties of radical anarchism were becoming popular as possible solutions to poverty, often by recent European immigrants (cf. hyphenated-Americans). When the Industrial Workers of the World (IWW) backed several labor strikes in 1916 and 1917, the press portrayed them as \"radical threats to American society\" inspired by \"left-wing, foreign \"agents provocateurs\"\". Those on the side of the IWW claim that the press \"misrepresented legitimate labor strikes\" as \"crimes against society\", \"conspiracies against the government\", and \"plots to establish communism\". Opponents, on the other hand, saw these as an extension of the radical, anarchist foundations of the IWW, which contends that all workers should be united as a social class and that capitalism and the wage system should be abolished.\nIn April 1919, authorities discovered a plot for mailing 36 bombs to prominent members of the U.S. political and economic establishment: J. P. Morgan Jr., John D. Rockefeller, Supreme Court Justice Oliver Wendell Holmes, U.S. Attorney General Alexander Mitchell Palmer, and immigration officials. On June 2, 1919, in eight cities, eight bombs simultaneously exploded. One target was the Washington, D.C., house of U.S. Attorney General Palmer, where the explosion killed the bomber, who evidence indicated was an Italian-American radical from Philadelphia, Pennsylvania. Afterwards, Palmer ordered the U.S. Justice Department to launch the Palmer Raids (1919–21).\n\nYet, in 1918, before the bombings, President Woodrow Wilson had pressured the Congress to legislate the anti-anarchist Sedition Act of 1918 to protect wartime morale by deporting putatively undesirable political people. Law professor David D. Cole reports that President Wilson's \"federal government consistently targeted alien radicals, deporting them ... for their speech or associations, making little effort to distinguish terrorists from ideological dissidents.\"\n\nInitially, the press praised the raids; \"The Washington Post\" said, \"There is no time to waste on hairsplitting over [the] infringement of liberty\", and \"The New York Times\" said the injuries inflicted upon the arrested were \"souvenirs of the new attitude of aggressiveness which had been assumed by the Federal agents against Reds and suspected-Reds\". In the event, the Palmer Raids were criticized as unconstitutional by twelve publicly prominent lawyers, including (future Supreme Court Justice) Felix Frankfurter, who published \"A Report on the Illegal Practices of The United States Department of Justice\", documenting systematic violations of the Fourth, Fifth, Sixth, and Eighth Amendments to the U.S. Constitution via Palmer-authorized \"illegal acts\" and \"wanton violence\". Defensively, Palmer then warned that a government-deposing left-wing revolution would begin on 1 May 1920 — May Day, the International Workers' Day. When it failed to happen, he was ridiculed and lost much credibility. Strengthening the legal criticism of Palmer was that fewer than 600 deportations were substantiated with evidence, out of the thousands of resident aliens arrested and deported. In July 1920, Palmer's once-promising Democratic Party bid for the U.S. presidency failed. Wall Street was bombed on September 2, 1920, near Federal Hall National Memorial and the JP Morgan Bank. Although both anarchists and Communists were suspected as being responsible for the bombing, ultimately no individuals were indicted for the bombing in which 38 died and 141 were injured.\n\nIn 1919–20, several states enacted \"criminal syndicalism\" laws outlawing advocacy of violence in effecting and securing social change. The restrictions included free speech limitations. Passage of these laws, in turn, provoked aggressive police investigation of the accused persons, their jailing, and deportation for being \"suspected\" of being either communist or left-wing. Regardless of ideological gradation, the Red Scare did not distinguish between communism, anarchism, socialism, or social democracy.\n\nThe second Red Scare occurred after World War II (1939–45), and was popularly known as \"McCarthyism\" after its most famous supporter, Senator Joseph McCarthy. McCarthyism coincided with increased popular fear of communist espionage consequent to a Soviet Eastern Europe, the Berlin Blockade (1948–49), the Chinese Civil War, the confessions of spying for the Soviet Union given by several high-ranking U.S. government officials, and the Korean War.\n\nThe events of the late 1940s, early 1950s - the trial of Ethel and Julius Rosenberg (1953), the trial of Alger Hiss, the Iron Curtain (1945–1991) around Eastern Europe, and the Soviet Union's first nuclear weapon test in 1949 (RDS-1) - surprised the American public, influencing popular opinion about U.S. National Security, that, in turn, connected to fear of the Soviet Union hydrogen-bombing the United States, and fear of the Communist Party of the United States of America (CPUSA).\n\nIn Canada, the 1946 Kellock–Taschereau Commission investigated espionage after top secret documents concerning RDX, radar and other weapons were handed over to the Soviets by a domestic spy-ring.\n\nAt the House Un-American Activities Committee, former CPUSA members and NKVD spies, Elizabeth Bentley and Whittaker Chambers, testified that Soviet spies and communist sympathizers had penetrated the U.S. government before, during and after World War II. Other U.S. citizen spies confessed to their acts of espionage in situations where the statute of limitations on prosecuting them had run out. In 1949, anti–communist fear, and fear of American traitors, was aggravated by the Chinese Communists winning the Chinese Civil War against the Western-sponsored Kuomintang, their founding of the People's Republic of China, and later Chinese intervention in the Korean War (1950–53) against U.S. ally South Korea.\n\nA few of the events during the Red Scare were also due to a power struggle between director of FBI J. Edgar Hoover and the Central Intelligence Agency. Hoover had instigated and aided some of the investigations of members of the CIA with \"leftist\" history, like Cord Meyer. This conflict could also be traced back to the conflict between Hoover and William J. Donovan, going back to the first Red Scare, but especially during World War II. Donovan ran the OSS (CIA's predecessor). They had differing opinions on the nature of the alliance with the Soviet Union, conflicts over jurisdiction, conflicts of personality, the OSS hiring of communists and criminals as agents, etc.\n\nBy the 1930s, communism had become an attractive economic ideology, particularly among labor leaders and intellectual elites. By 1939, the CPUSA had about 50,000 members. In 1940, soon after World War II began in Europe, the U.S. Congress legislated the Alien Registration Act (aka the Smith Act, 18 USC § 2385) making it a crime to \"knowingly or willfully advocate, abet, advise or teach the duty, necessity, desirability or propriety of overthrowing the Government of the United States or of any State by force or violence, or for anyone to organize any association which teaches, advises or encourages such an overthrow, or for anyone to become a member of or to affiliate with any such association\"—and required Federal registration of all foreign nationals. Although principally deployed against communists, the Smith Act was also used against right-wing political threats such as the German-American Bund, and the perceived racial disloyalty of the Japanese-American population, (\"cf.\" hyphenated-Americans).\n\nIn 1941, after Nazi Germany invaded the Soviet Union, the CPUSA's official position became pro-war, opposing labor strikes in the weapons industry and supporting the U.S. war effort against the Axis Powers. With the slogan \"Communism is Twentieth-Century Americanism\", the chairman, Earl Browder, advertised the CPUSA's integration to the political mainstream. In contrast, the Trotskyist Socialist Workers Party opposed U.S. participation in the war and supported labor strikes, even in the war-effort industry. For this reason, James P. Cannon and other SWP leaders were convicted per the Smith Act.\n\nIn March 1947, President Harry S. Truman signed Executive Order 9835, creating the \"Federal Employees Loyalty Program\" establishing political-loyalty review boards who determined the \"Americanism\" of Federal Government employees, and recommended termination of those who had confessed to spying for the Soviet Union, as well as some suspected of being \"Un-American\". It also was the template for several state legislatures' loyalty acts, such as California's Levering Act. The House Committee on Un-American Activities (HUAC) and the committees of Senator Joseph McCarthy (R., Wisc.) conducted character investigations of \"American communists\" (actual and alleged), and their roles in (real and imaginary) espionage, propaganda, and subversion favoring the Soviet Union—in the process revealing the extraordinary breadth of the Soviet spy network in infiltrating the federal government; the process also launched the successful political career of Richard Nixon, and Robert F. Kennedy, as well as that of Joseph McCarthy.\n\nSenator McCarran introduced the McCarran Internal Security Act of 1950 that was passed by the U.S. Congress and which modified a great deal of law to restrict civil liberties in the name of security. President Truman declared the act a \"mockery of the Bill of Rights\" and a \"long step toward totalitarianism\" because it represented a government restriction on the freedom of opinion. He vetoed the act but his veto was overridden by Congress. Much of the bill eventually was repealed.\n\nThe Second Red Scare profoundly altered the temper of American society. Its later characterizations may be seen as contributory to works of feared communist espionage, such as the film \"My Son John\" (1952), about parent's suspicions their son is a spy. Abundant accounts in narrative forms contained themes of the infiltration, subversion, invasion, and destruction of American society by un–American \"thought\". In science fiction movies like \"The Thing\" (1951), tales of alien humanoid beings abounded. Even a baseball team, the Cincinnati Reds, temporarily renamed themselves the \"Cincinnati Redlegs\" to avoid the money-losing and career-ruining connotations inherent in being ball-playing \"Reds\" (communists).\n\nIn 1995, the American government revealed details of the Venona Project, which when combined with the opening of the USSR ComIntern archives, provided substantial validation of intelligence gathering, outright spying, and policy influencing, by Americans on behalf of the Soviet Union, from 1940 through 1980.\n\n\n"}
{"id": "21397214", "url": "https://en.wikipedia.org/wiki?curid=21397214", "title": "Scene statistics", "text": "Scene statistics\n\nScene statistics is a discipline within the field of perception. It is concerned with the statistical regularities related to scenes. It is based on the premise that a perceptual system is designed to interpret scenes.\n\nBiological perceptual systems have evolved in response to physical properties of natural environments. Therefore natural scenes receive a great deal of attention.\n\nNatural scene statistics are useful for defining the behavior of an ideal observer in a natural task, typically by incorporating signal detection theory, information theory, or estimation theory.\n\nOne of the most successful applications of Natural Scenes Statistics Models has been perceptual picture and video quality prediction. For example, the Visual Information Fidelity (VIF) algorithm, which is used to measure the degree of distortion of pictures and videos, is used extensively by the image and video processing communities to assess perceptual quality, often after processing, such as compression, which can degrade the appearance of a visual signal. The premise is that the scene statistics are changed by distortion, and that the visual system is sensitive to the changes in the scene statistics. VIF is heavily used in the streaming television industry. Other popular picture quality models that use natural scene statistics include BRISQUE, and NIQE both of which are no-reference, since they do not require any reference picture to measure quality against.\n\nGeisler (2008) distinguishes between four kinds of domains: (1) Physical environments, (2) Images/Scenes, (3) Neural responses, and (4) Behavior.\n\nWithin the domain of images/scenes, one can study the characteristics of information related to redundancy and efficient coding.\n\nAcross-domain statistics determine how an autonomous system should make inferences about its environment, process information, and control its behavior. To study these statistics, it is necessary to sample or register information in multiple domains simultaneously.\n\n"}
{"id": "33623974", "url": "https://en.wikipedia.org/wiki?curid=33623974", "title": "Snub", "text": "Snub\n\nA snub, cut or slight is a refusal to recognise an acquaintance by ignoring them, avoiding them or pretending not to know them. For example, a failure to greet someone may be considered a snub.\n\n"}
{"id": "182117", "url": "https://en.wikipedia.org/wiki?curid=182117", "title": "Social conflict theory", "text": "Social conflict theory\n\nSocial conflict theory is a Marxist-based social theory which argues that individuals and groups (social classes) within society interact on the basis of conflict rather than consensus. Through various forms of conflict, groups will tend to attain differing amounts of material and non-material resources (e.g. the wealthy vs. the poor). More powerful groups will tend to use their power in order to retain power and exploit groups with less power.\n\nConflict theorists view conflict as an engine of change, since conflict produces contradictions which are sometimes resolved, creating new conflicts and contradictions in an ongoing dialectic. In the classic example of historical materialism, Karl Marx and Friedrich Engels argued that all of human history is the result of conflict between classes, which evolved over time in accordance with changes in society's means of meeting its material needs, i.e. changes in society's mode of production.\n\nConsider the relationship between the owner of a housing complex and a tenant in that same housing complex. A consensus theorist might suggest that the relationship between the owner and the tenant is founded on mutual benefit. In contrast, a conflict theorist might argue the relationship is based on a conflict in which the owner and tenant are struggling against each other. Their relationship is defined by the balance in their abilities to extract resources from each other, e.g. rent payments or a place to live. The bounds of the relationship are set where each is extracting the maximum possible amount of resources out of the other.\n\nConflict can take many forms and involve struggle over many different types of resources, including status. However, formal conflict theory had its foundations in the analysis of class conflict, and the example of the owner and the tenant can be understood in terms of class conflict. In class conflict, owners are likely to have relative advantages over non-owners. For example, the legal system underlying the relationship between the owner and tenant can be biased in favor of the owner. Suppose the owner wishes to keep the tenant's security deposit after that tenant has moved out of the owner's residence. In legal systems based on English common law, the owner is only required to notify the tenant that the security deposit is being withheld. To regain the security deposit, the tenant must file a lawsuit. The tenant bears the burden of proof and is therefore required to prove that the residence was adequately cleaned before move-out. This can be a very difficult or even impossible task.\n\nTo summarize the example, conflict theorists view the relationship between the owner and tenant as being built primarily on conflict rather than harmony. Even though the owner-tenant relationship may often appear harmonious, any visible harmony is only a product of the law and other elements of the superstructure which constrain the relationship and which are themselves a product of an even deeper conflict, class conflict. A conflict theorist would say that conflict theory holds more explanatory power than consensus theory in this situation since consensus theory cannot explain lawsuits between owners and tenants nor the legal foundations of the asymmetrical power relationship between the two.\n\nFrom a social conflict theorist/marxism point of view social class and inequality emerges because the social structure is based on conflict and contradictions. Contradictions in interests and conflict over scarce resources between groups is the foundation of social society, according to the social conflict theory (Engels & Marx, 1848). The higher class will try to maintain their privileges, power, status and social position - and therefore try to influence politics, education, and other institutions to protect and limit access to their forms of capital and resources. Whereas the lower class - in contradiction to the higher class - has very different interests. They do not have specific forms of capital that they need to protect. All they are interested in is in gaining access to the resources and capital of the higher class. For example, education: the lower class will do everything to gain access to the higher class resources based on democratizing and liberalizing education systems because these forms of capital are thought to be of value for future success. The various institutions of society such as the legal and political system are instruments of ruling class domination and serve to further its interests. Marx believed that western society developed through four main epochs—primitive communism, ancient society, feudal society and capitalist society. Primitive communism is represented by the societies of pre-history and provides the only example of the classless society. From then all societies are divided into two major classes—master and slaves in ancient society, lords and serfs in feudal society and capitalist and wage laborers in capitalist society.\n\nWeber sees class in economic terms. He argues that classes develop in market economies in which individuals compete for economic gain. He defines a class as a group of individuals who share a similar position in market economy and by virtue of that fact receive similar economic rewards. Thus a person's class situation is basically his market situation. Those who share a similar class situation also share similar life chances. Their economic position will directly affect their chances of obtaining the things defined as desirable in their society.\n\n\n\n"}
{"id": "4488510", "url": "https://en.wikipedia.org/wiki?curid=4488510", "title": "Timeline of the history of scientific method", "text": "Timeline of the history of scientific method\n\nThis timeline of the history of scientific method shows an overview of the cultural inventions that have contributed to the development of the scientific method. For a detailed account, see History of the scientific method.\n\n\n\n\n\n\n"}
{"id": "31740511", "url": "https://en.wikipedia.org/wiki?curid=31740511", "title": "Transtextuality", "text": "Transtextuality\n\nTranstextuality is defined as the \"textual transcendence of the text\". According to Gérard Genette transtextuality is \"all that sets the text in relationship, whether obvious or concealed, with other texts\" and it \"covers all aspects of a particular text\".Genette described transtextuality as a \"more inclusive term\" than intertextuality.\n\nGenette provided five subtypes of transtextuality, namely: intertextuality, paratextuality, architextuality, metatextuality, and hypertextuality (also known as hypotextuality).\n\nThe following are the descriptions for the five subtypes of transtextuality:\n\n\n"}
{"id": "19795082", "url": "https://en.wikipedia.org/wiki?curid=19795082", "title": "Tree-free paper", "text": "Tree-free paper\n\nTree-free paper or tree-free newsprint describes an alternative to wood-pulp paper by its raw material composition. It is claimed to be more eco-friendly considering the product's entire life cycle.\n\nSources of fiber for tree-free paper include:\n\n\nNon-fibre sources include:\n\n\nPaper manufacturing is highly competitive, with historically tight margins and small operating profits. As a result, the raw materials used to make paper have to be very cost effective, using cheap, scalable renewable resources, coupled with relatively inexpensive ways to deliver large quantities to market. Until recently, commercial tree farming, has been shaped to account for these tight operating margins and supply cost limitations. Virtually all paper, however, requires massive cutting, replanting and re-cutting of wide swaths of forest. These limitations have made wood pulped farm grown supply stock the paper industry's overwhelming scalable raw material of choice.\n\nThe paper industry's answer to \"tree free\" paper has been focused on \"recycled waste paper\" as a tree free alternative even though the vast majority of \"recycled waste paper\" originally started its life cycle from tree grown pulp.\n\nFiber dense agricultural residues, have been known as a pulp substitute for years. Commercial low cost production technology coupled with limited resource abundancy plus low cost transportation to commercial business markets had created a barrier, virtually relegating true \"tree free\" paper from developing into anything more than small niche markets with even smaller niche market players. Furthermore, grasses and annual plants often have high silica contents. Silica is problematic as it consumes pulping chemicals and produces fly ash when burned.\n\n"}
{"id": "59205843", "url": "https://en.wikipedia.org/wiki?curid=59205843", "title": "Women's events and developments in 1919", "text": "Women's events and developments in 1919\n\nThis is a listing of noteworthy historical events relating to the international women's movement which occurred in 1919.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
