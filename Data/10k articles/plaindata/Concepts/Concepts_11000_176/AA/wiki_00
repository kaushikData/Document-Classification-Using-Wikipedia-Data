{"id": "39336901", "url": "https://en.wikipedia.org/wiki?curid=39336901", "title": "Alternative liability", "text": "Alternative liability\n\nAlternative liability is a legal doctrine that allows a plaintiff to shift the burden of proving causation of her injury to multiple defendants, even though only one of them could have been responsible. The typical case showing the principle of alternative liability in action is Summers v. Tice, where the two defendants negligently shot in the direction of the plaintiff and only one of the bullets caused the plaintiff's injury. In the interest of justice, the innocent plaintiff's case is not defeated because she cannot prove which party was the actual cause (but-for cause) of her injury.\n\nThe doctrine requires that the plaintiff bring all possible defendants into court and that the plaintiff show the defendants all breached a duty of reasonable care. The burden then shifts to the defendants to provide evidence of who caused the injury.\n\nThe underpinning of this doctrine is that a plaintiff should not be barred from seeking recovery simply because she does not know who caused her injury. The defendants are usually the parties in the best position to have the relevant information.\n\nDistinguish alternative liability from the smoke-out function of res ipsa loquitur seen in the leading case of Ybarra v. Spangard. In \"Ybarra\", the plaintiff brought all defendants who could have \"possibly\" been negligent (breached a duty of reasonable care) so that they could show which party actually was negligent. Thus, in the smoke-out function of res ipsa, the burden is shifted on the defendants to show \"negligence\", whereas in alternative liability all defendants are all shown to have breached a duty of reasonable care and the plaintiff shifts the burden to show \"causation\".\n"}
{"id": "44748862", "url": "https://en.wikipedia.org/wiki?curid=44748862", "title": "Amanaskata", "text": "Amanaskata\n\nAmanaskatā is the alert state of dynamic fullness of the self (\"atman\"), it is the condition where there is no mind, the mindless state; it is the state when the mind dissolves and the self shines. It is the transmental state which is also called no-mindedness (\"unmani\") and yogic sleep (\"yoga-nidra\") as the prolonged absorption in the formless ecstasy or \"nirvikalpa samadhi\"; it is the state in which the jivanmukta (liberated being) exists experiencing a sense of universality. According to the \"Laya-chintana\" of Antahkarana ('mind'), the mind is absorbed in \"Mahat (\"Buddhi\"), 'Individual Buddhi' is absorbed in the 'Cosmic Buddhi', 'Cosmic Buddhi' in \"Avyakta\" which is Brahman; in other words, the effect is absorbed into cause.\n"}
{"id": "24750413", "url": "https://en.wikipedia.org/wiki?curid=24750413", "title": "Argand system", "text": "Argand system\n\nIn mathematics, an \"n\"th-order Argand system (named after French mathematician Jean-Robert Argand) is a coordinate system constructed around the \"n\"th roots of unity. From the origin, \"n\" axes extend such that the angle between each axis and the axes immediately before and after it is 360/\"n\" degrees. For example, the number line is the 2nd-order Argand system because the two axes extending from the origin represent 1 and −1, the 2nd roots of unity. The complex plane (sometimes called the Argand plane, also named after Argand) is the 4th-order Argand system because the 4 axes extending from the origin represent 1, \"i\", −1, and −\"i\", the 4th roots of unity.\n\n"}
{"id": "4741593", "url": "https://en.wikipedia.org/wiki?curid=4741593", "title": "Attentional bias", "text": "Attentional bias\n\nAttentional bias is the tendency for people's perception to be affected by their recurring thoughts at the time. Attentional biases may explain an individual's failure to consider alternative possibilities, as specific thoughts guide the train of thought in a certain manner. For example, smokers tend to possess a bias for cigarettes and other smoking-related cues around them, due to the positive thoughts they've already attributed between smoking and the cues they were exposed to while smoking. Attentional bias has also been associated with clinically relevant symptoms such as anxiety and depression.\n\nA commonly studied experiment to test for attentional bias is one in which there are two variables, a factor (A) and a result (B). Both can be either present (P) or not present (N). This results in four possible combinations:\n\n\nThe four combinations can be shown in table form as follows:\n\nA common question which follows the structure of the above experiment is: \"Does God answer prayers?\" Due to attentional bias, theists tend to say \"yes\". They focus on the present/present (A/B) cell, as their religious beliefs in a deity cause them to fixate on the occasions when they were given what they asked for, thus they use the justification: \"Many times I've asked God for something, and he's given it to me.\" Similarly, due to attentional bias, atheists equally tunnel on data from the present/absent (A/B', A'/B) cells: \"Has God ever given me something that I didn't ask for?\" or \"Have I asked God for something and didn't receive it?\" This experiment too supports Smedslund's general conclusion that subjects tend to ignore part of the table depending on their specific attentional biases.\n\nThe scenarios can be illustrated below in a similar table to above:\n\nWhen making decisions, attentional biases toward positive stimuli have been associated with numerous positive outcomes, such as increased social engagement, increased prosocial behaviour, decreased externalizing disorders, and decreased emotionally withdrawn behavior. In contrast, individuals with clinically relevant symptoms, such as anxiety disorder and chronic pain are shown to prioritize threat cues over reward cues. In one experiment, faces with varying valences were presented (neutral, threatening, and happy) with a forced-choice reaction time at two exposure durations, 500 and 1250msec. For individuals with high trait anxiety, there was strong evidence for an attentional bias favoring threatening facial expressions. Additionally, increased dysphoria correlated with the tendency to avoid happy faces. This tendency leads to a spiraling effect, as one will only see negative faces, which induces greater anxiety, which exacerbates the aforementioned tendency to avoid positive stimuli – a form of the vigilance-avoidance pattern.\n\nNotably, there is also a difference in attention biases between anxious and depressed individuals. Word pairs were shown to the subjects, with a dot probe following a word of each pair (dot probe paradigm). One-half of the word pairs were presented on the subliminal level, and the other half were presented on the supraliminal level, and then the response time was measured. As expected, the anxious and depressed groups showed an attentional bias towards negative words compared to the normal control group. On a supraliminal level, the depressed group showed greater vigilance for threat stimuli than the anxious group. However, for subliminal threat stimuli, the anxious group showed a greater vigilance, which implies an anxiety-related bias on the subconscious level.\n\nResearch from the past two decades has established that addictive behaviour is strongly correlated to the attentional bias for substance-related cues, in how the latter characterizes the former. An example of this is smoking and smoking-related cues.\n\nResearch (using the Stroop paradigm) tested the effect of mixing smoking related words (cigarette, puff, and smoke) with: negative connoting words (sick, pain and guilty), positive connoting words, (safe, glad, and hopeful) and neutral connoting words (tool, shovel, and hammer). Results showed a strong correlation between a slower reaction time and the degree of negative language employed when discussing smoking. The results indicate attentional bias, suggesting the influence negative language has had on the individual attitude towards smoking. When asked to think of the negative consequences of smoking, as the negative language evoked underlying negative feelings toward smoking, they displayed fewer cravings than the smoker subjects who were encouraged to smoke. The experiment illustrates the influence of attentional bias on environmental smoking cues and how these could contribute to a smokers' inability to quit. As stated earlier individuals' attentional biases are influenced by subliminal stimuli, so in the smoker's case, they are more subject to substance-related stimuli such as observing other smokers or noticing ads for cigarettes. The stimuli evoke expectancy of substance availability, which creates a further attentional bias for substance-related stimuli and induces craving for the substance.\n\nSimilar Stroop paradigm studies have concluded that attentional bias is not dependent on smoking itself, but rather the person who is the smoker displays attentional bias. A recent study required one group of smokers to refrain from smoking the night before and another less than an hour before. Abstinence from smoking created slower reaction time, but a smoke break between study sessions showed increased reaction time. Researchers say this shows that nicotine dependence intensifies attention, but does not directly depend on smoking itself due to lack of evidence. The longer reaction time suggests smokers craving a cigarette linger on smoking related words. Smokers and smokers attempting to quit displayed the same slower reaction time for smoking related words, which supports research that implies attentional bias is a behavioral mechanism versus a dependency mechanism, due to the fact that the smokers were slowed down by smoking related words and negative words, but not slowed down by positive and neutral words.\n\nDrug addiction is also an example of attentional bias in that certain memories or objects can prompt intense cravings to one’s drug of choice. It is easier for individuals who experience this to relapse and begin their drug use again, because the urges given off by that initial stimuli can prove to be too strong to curve. There are some ways that individuals could overcome attentional bias, and a solution is stimuli-related therapy. This type of therapy would give those struggling with addiction and relapse an opportunity to overcome the initial fear associated with a particular object. A study conducted by a group of researchers in the Netherlands found that by giving participants an opportunity to attend therapy sessions during their treatment for drug addiction, more participants remained drug free compared to those who relapsed. Therefore, the conclusion can be drawn that with exposure therapy, the number of patients who will leave a treatment facility and relapse decreases.The Stoop Test also showed in this study that between the control group and the treatment group the only major component of the test was time; researchers made the claim that those who received treatment reacted a lot faster to certain drug related stimuli versus those in the control group who did not. This means that when experiencing attentional bias, treated addicts seemed to brush off the memories a little easier compared to those who had not received proper treatment. In other words, certain steps need to be taken in treatment facilities across the country to ensure that drug addiction no longer rises, or continues to ruin people’s lives. Also, a therapy of this kind should be closely monitored and mandatory to ensure the smallest number of relapses occur after treatment.\n\nThere are two different forms of attentional bias that can be measured:\n\n\n\nThere are four main paradigms used to measure attentional bias:\n\n\n\n\n\nWhile the other options are valid methods, they all tap into different aspects of attention bias. Because of this, some methods are less used when looking into specific aspects of attentional bias. For example, in a posner cueing task, the cues were either a \"neutral\", \"angry\" or \"happy\", facial expression. There were both valid (targets appearing in the same location as the cue/face) and invalid trials (The target appearing in a different location to the cue/face). Surprisingly enough, in the invalid tests, individuals' response times increased to the same degree of attentional bias for both negative stimuli and positive stimuli, contrary to hundreds of other studies.\n\nOn a scientific level, attentional bias often seen in eye tracking movements is thought to be an underlying issue of addiction. Smokers linger on smoking cues compared with neutral cues. Researchers found higher activation in the insular cortex, the orbitofrontal cortex and the amygdala when presented with smoking cues. The orbitofrontal cortex is known to be coordinated with drug-seeking behavior and the insular cortex and amygdala are involved in the autonomic and emotional state of an individual.\n\nNeural activity is also known to decrease upon the beginning of smoking, focusing the smokers' attention on their upcoming cigarette. Therefore, when smoking cues are nearby it is harder for a smoker to concentrate on other tasks. This is seen in the activation of the dorsal anterior cingulate cortex, known for focusing attention on relevant stimuli.\n\nHowever beyond this, the mechanisms of attentional bias is an uncertain area, as there are many conflicting theories on how attentional biases operate. An initial theory was schema theory, in which it was believed schema was biased towards threats, thus threat-related material is always favored in cognitive thinking. Conversely, other individuals have argued that humans are prone to attentional biases at certain points of information processing, which is now a more common topic of controversy.\n\nPsychologist J. Mark G. Williams and colleagues have argued that anxious individuals tend to prioritize threat stimuli during early information processing, and direct their attention away from threats in more strategic stages of processing. This correlates with the vigilance-avoidance pattern, which is when one initially directs attention to threat, however then proceeds to avoid processing details and information in order to avoid an anxious state of mind. Conversely, others theorize that anxiety has little impact on initial detection of threats but has is more significant in modulating the maintenance of attention on the source of the threat. This can be explained by the alternative theory to the vigilance-avoidance pattern, which is that anxious individuals, once processing the threat, struggle to disengage attention from the threat stimuli due to reasons such as fear.\n\nRegardless of the opinions, there have been numerous studies which attempt to find the ultimate explanation, however, there have been results which support both theories, thus making the mechanisms of attention bias an uncertain topic.\n\nIn one study, stimulus exposure duration was tested against attentional bias for threat stimuli (for non-clinical anxiety). Individuals were given exposure durations of 100, 500, and 1500 millisecond intervals. However, there was shown to be no significant change is the bias towards threat stimuli. The experiment has yet to be tested for clinical anxiety.\n\nA study also explored the negative relationship between neurocognitive function and attentional bias. Individuals with a lower capacity in the attentional domain, particularly in digit symbol coding, exhibited more attentional bias toward threats.\n\nThe link between attentional biases and addictions illustrate how controlling attentional processes may be essential in assisting smokers who are trying to quit. However, this is not dealt with, as in the case of the United Kingdom (UK), the Stop Smoking Services (SSS) and National Health Service (NHS) both have yet to target attentional biases in their smoking cessation programs.\n\nIndividuals with clinically relevant symptoms, such as anxiety disorders and chronic pain are shown to initially focus on threatening information. However, there is still uncertainty regarding the causes of this relationship. Two studies explored the causes by using a modified dot-probe paradigm and experimentally inducing differential attentional responses to emotional stimuli and then noting the effect on the consequential emotional vulnerability. The results confirmed how inducing attentional bias can alter emotional vulnerability, thus introducing the possibility that cognitive-experimental procedures designed around these results have potential therapeutic value in the future.\n\n"}
{"id": "58751662", "url": "https://en.wikipedia.org/wiki?curid=58751662", "title": "Bonnie Bainbridge-Cohen", "text": "Bonnie Bainbridge-Cohen\n\nBonnie Bainbridge-Cohen (b. 1943) is a researcher, therapist and educator in the field of somatics. She is most well known for being the originator of Body-Mind Centering. She is considered one of the major contributors in the 20th and 21st century to the field of movement studies and has been influential in body oriented psychotherapy, dance therapy, contemporary dance, yoga and manual bodywork.\n\nAccording to her own biography Bonnie Bainbridge-Cohen grew up in Ringling Bros. and Barnum & Bailey Circus, her mother was an acrobat and her father a ticket seller. In 1959, aged 16, she participated in a high-school dance project with children with learning disabilities. This led her to study ocupational therapy at Ohio State University.\n\nHaving danced since childhood, she maintained a strong connection to dance at this time and took classes with Marian Chace, one of the pioneers of the field of dance therapy, and summer schools with Erick Hawkins, a prominent modern dancer.\n\nOnce she completed her studies, she began working in hospitals and started using principles from Hawkin’s dance technique, such as focusing on active lengthening of muscles, in rehabilitation work. This was a controversial choice with her supervisors but was the beginnings of her development of Body-Mind Centering.\n\nLater she studied neurodevelopmental therapy with Bertha and Dr. Karel Bobath, Laban movement analysis with Irmgard Bartenieff, Kestenberg movement profiling with Judith Kestenberg, craniosacral therapy with John Upledger and ideokinesis with Barbara Clark and Andre Bernard.\n\nWhen she completed her studies in neurodevelopmental therapy with the Bobaths, she moved to New York but did not find the hospital environment conducive to this way of working. She found that many of New York’s dancers were however very receptive and thus began adapting the work for adults without disabilities. Out of these classes grew, directly, what was later to become the School of Body-Mind Centering and the core material in the Body-Mind Centering curriculum was developed there.\n\nBody-Mind Centering, the approach to somatic movement education and therapy developed by Bainbridge-Cohen, combines elements of movement analysis, re-education. \n\nThe core areas of study in Body-Mind Centering include embodied anatomy, embodied developmental movement and somatic psychology.\n"}
{"id": "34195159", "url": "https://en.wikipedia.org/wiki?curid=34195159", "title": "Cajun Pawn Stars", "text": "Cajun Pawn Stars\n\nCajun Pawn Stars is an American reality television series on the History channel that debuted January 8, 2012, at 10 pm ET.\n\nThe show was the second spin-off of \"Pawn Stars\", but unlike fellow spin-offs \"American Restoration\" and \"Counting Cars\", it is entirely unrelated to the venue and staff of \"Pawn Stars\".\n\nFollowing its fourth and final season in 2012, the show went on hiatus, before effectively being canceled as the contract option date passed without renewal.\n\n\"Cajun Pawn Stars\" revolves around another family-owned pawn shop, the Silver Dollar Pawn & Jewelry Center in Alexandria, Louisiana, which is owned by Jimmie \"Big Daddy\" DeRamus, who runs the store along with his wife Peggy, his brother Johnnie, and daughter Tammie. The shop claims to have over 100,000 items within its 20,000 square foot showroom.\n\nThe show's format is similar to the original \"Pawn Stars\", as it features an array of collectible, antique and unusual items that people sell or pawn, complemented with \"pop-up\" facts related to the item. Also, as with the original series, the shop sometimes consults an expert to give an appraisal/opinion on the item being sold or pawned. In addition, at the second commercial break, a trivia question is asked in relation to the shop or item, as with \"Pawn Stars\".\n\nWhile the show is named \"\"Cajun\" Pawn Stars\", Alexandria, where the pawn shop is located, is the parish seat of Rapides Parish, Louisiana, which is not considered part of Acadiana, the hub of Cajun culture.\n\n"}
{"id": "43676277", "url": "https://en.wikipedia.org/wiki?curid=43676277", "title": "Cartesian monoidal category", "text": "Cartesian monoidal category\n\nIn mathematics, specifically in the field known as category theory, a monoidal category where the monoidal (\"tensor\") product is the categorical product is called a cartesian monoidal category. Any category with finite products (a \"finite product category\") can be thought of as a cartesian monoidal category. In any cartesian monoidal category, the terminal object is the tensor unit. Dually, a monoidal finite coproduct category with the monoidal structure given by the coproduct and unit the initial object is called a cocartesian monoidal category, and any finite coproduct category can be thought of as a cocartesian monoidal category.\n\nCartesian categories with a Hom functor that is an adjoint functor to the product are called Cartesian closed categories.\n\nCartesian monoidal categories have a number of special and important properties, such as the existence of diagonal maps Δ : \"x\" → \"x\" ⊗ \"x\" and augmentations \"e\" : \"x\" → \"I\" for any object \"x\". In applications to computer science we can think of Δ as ‘duplicating data’ and \"e\" as ‘deleting data’. These maps make any object into a comonoid. In fact, any object in a cartesian monoidal category becomes a comonoid in a unique way.\n\nCartesian monoidal categories: \nCocartesian monoidal categories: \n\nIn each of these categories of modules equipped with a cocartesian monoidal structure, finite products and coproducts coincide (in the sense that the product and coproduct of finitely many objects are isomorphic), or more formally that if \"f\" : \"X\" ∐ ... ∐ \"X\" → \"X\" × ... × \"X\" is the \"canonical\" map from the \"n\"-ary coproduct of objects \"X\" to their product, for a natural number \"n\", in the event that the map \"f\" is an isomorphism, we say that a biproduct for the objects \"X\" is an object formula_1 isomorphic to formula_2 and formula_3 together with maps \"i\" : \"X\" → \"X\" and \"p\" : \"X\" →  \"X\" such that the pair (\"X\", {\"i\"}) is a coproduct diagram for the objects \"X\" and the pair (\"X\", {\"p\"}) is a product diagram for the objects \"X\" , and where \"p\" ∘ \"i\" = id. If in addition the category in question has a zero object, so that for any objects \"A\" and \"B\" there is a unique map 0 : \"A\" → 0 → \"B\", it often follows that \"p\" ∘ \"i\" = : \"δ\", the Kronecker delta, where we interpret 0 and 1 as the 0 maps and identity maps of the objects \"X\" and \"X\", respectively. See pre-additive category for more.\n\n"}
{"id": "55872661", "url": "https://en.wikipedia.org/wiki?curid=55872661", "title": "Category of representations", "text": "Category of representations\n\nIn representation theory, the category of representations of some algebraic structure has the representations of as objects and equivariant maps as morphisms between them. One of the basic thrusts of representation theory is to understand the conditions under which this category is semisimple; i.e., whether an object decomposes into simple objects (see Maschke's theorem for the case of finite groups).\n\nThe Tannakian formalism gives conditions under which a group \"G\" may be recovered from the category of representations of it together with the forgetful functor to the category of vector spaces.\n\nThe Grothendieck ring of the category of finite-dimensional representations of a group \"G\" is called the representation ring of \"G\".\n\nDepending on the types of the representations one wants to consider, it is typical to use slightly different definitions.\n\nFor a finite group and a field , the category of representations of over has \n\nThe category is denoted by formula_1 or formula_2.\n\nFor a Lie group, one typically requires the representations to be smooth or admissible. For the case of a Lie algebra, see Lie algebra representation. See also: category O.\n\nThere is an isomorphism of categories between the category of representations of a group over a field (described above) and the category of modules over the group ring [], denoted []-Mod.\n\nEvery group can be viewed as a category with a single object, where morphisms in this category are the elements of and composition is given by the group operation. Given an arbitrary category ', a \"representation\" of in ' is a functor from to '. Such a functor selects an object of ' and a subgroup of the automorphism group of that object. For example, a -set is equivalent to a functor from to Set, the category of sets, and a linear representation is equivalent to a functor to Vect, the category of vector spaces over a field.\n\nIn this setting, the category of linear representations of over is the functor category → Vect, which has natural transformations as its morphisms.\n\nThe category of linear representations of a group has a monoidal structure given by the tensor product of representations, which is an important ingredient in Tannaka-Krein duality (see below).\n\nMaschke's theorem states that when the characteristic of doesn't divide the order of , the category of representations of over is semisimple.\n\nGiven a group with a subgroup , there are two fundamental functors between the categories of representations of and (over a fixed field): one is a forgetful functor called the restriction functor\nand the other, the induction functor\n\nWhen and are finite groups, they are adjoint to each other\na theorem called Frobenius reciprocity.\n\nThe basic question is whether the decomposition into irreducible representations (simple objects of the category) behaves under restriction or induction. The question may be attacked for instance by the Mackey theory.\n\nTannaka–Krein duality concerns the interaction of a compact topological group and its category of linear representations. Tannaka's theorem describes the converse passage from the category of finite dimensional representations of a group back to the group , allowing one to recover the group from its category of representations. Krein's theorem in effect completely characterizes all categories that can arise from a group in this fashion. These concepts can be applied to representations of several different structures, see the main article for details.\n\n"}
{"id": "25814293", "url": "https://en.wikipedia.org/wiki?curid=25814293", "title": "Climate governance", "text": "Climate governance\n\nIn political ecology and environmental policy, climate governance is the diplomacy, mechanisms and response measures \"aimed at steering social systems towards preventing, mitigating or adapting to the risks posed by climate change\". A definitive interpretation is complicated by the wide range of political and social science traditions (including comparative politics, political economy and multilevel governance) that are engaged in conceiving and analysing climate governance at different levels and across different arenas. In academia, climate governance has become the concern of geographers, anthropologists, economists and business studies scholars.\n\nIn the past two decades a paradox has arisen between rising awareness about the causes and consequences of climate change and an increasing concern that the issues that surround it represent an intractable problem.\nInitially, climate change was approached as a global issue, and climate governance sought to address it on the international stage. This took the form of Multilateral Environmental Agreements (MEAs), beginning with the United Nations Framework Convention on Climate Change (UNFCCC) in 1992. With the exception of the Kyoto Protocol, international agreements between nations have been largely ineffective in achieving legally binding emissions cuts and with the end of the Kyoto Protocol's first commitment period in 2012, starting from 2013 there is no legally binding Global climate regime. This inertia on the international political stage contributed to alternative political narratives that called for more flexible, cost effective and participatory approaches to addressing the multifarious problems of climate change. These narratives relate to the increasing diversity of methods that are being developed and deployed across the field of climate governance.\n\nThe development of climate governance can be traced firstly to climate diplomacy between inter-state actors and secondly to the development of transnational networks and non-state actors. The timeline above highlights key points throughout this process. The point of ‘creation’ is difficult to determine exactly, however a definitive point in its history is the 1992 United Nations Framework Convention on Climate Change (UNFCCC) in Rio. This has been termed “the first major milestone in the history of climate diplomacy”. The conference addressed nations from across the globe and sought to emulate the diplomatic success of the Montreal Protocol in phasing out ozone-depleting chemicals.\n\nAs climate governance has continued to develop on the international stage, a string of transnational public and public-private actor networks have sought to implement its aims within their own arena, for example the C40, the Global Cities Covenant on Climate (also known as the 'Mexico City Pact'), and the Cities for Climate Protection Programme (CCPP). The United Nations Conference on Environment and Development (UNFCED) in 1992 was a 'trigger' for this process. Existing regional and local networks adopted its emissions reduction targets and began to consider how they could be achieved at a local level. An example is ICLEI ‘Local Governments for Sustainability’ that adopted the convention's Framework Convention on Climate Change (UNFCCC) as part of its commitment to link local action to internationally agreed-upon goals. Under the umbrella of internationally agreed climate targets, innovative climate governance methods have also developed that seek to reduce emissions using market based mechanisms, for example the 'cap and trade' mechanism.\n\nThus, while the interstate process of treaty making continues to play a key part in mitigating anthropogenic climate change, it now exists as part of a wider tapestry of private and public climate governance initiatives that operate at multiple scales.\n\nThe North-South divide is a socio-economic and political division. Applied to climate governance, the divide separates 'developed' northern countries that have historically emitted disproportionately high emissions from 'undeveloped' southern countries that have emitted considerably less emissions. The divide has also been used to highlight differences in vulnerability to climate change (the global south is considered more vulnerable due to a higher incident of natural disasters, less developed infrastructure and less wealth). These divides have fed into all issues of international climate governance, bringing with them questions of social justice and equity that remain current today. A criticism of the divide is that it simplifies an increasingly complex landscape. In recent years, international trade, free capital flows and the development of some southern nations (for example China and India) have redefined global socio-economic and political relations.\n\nClimate governance has been identified as multi-scale, multi-actor and deeply embedded in our social and physical infrastructure:\n\n\nParticular scientific and technical practices shape and inform our understanding of climate change and in doing so define how environmental problems are defined as objects of governance. For example, recent advances in carbon cycle research, remote sensing and carbon accounting techniques have revealed that tropical deforestation accounts for 15% of global carbon dioxide emissions. As a result, it has become a viable concern of climate governance. Previous to its quantification, tropical deforestation had been expressly excluded from the Kyoto Protocol. However, the translation of scientific or policy research findings into governance through the political process remains difficult as science and politics have very different ways of dealing with the issue of uncertainty that is naturally a component of research\n\nCommunity engagement plays an important role in the implementation of climate governance policy. There are two main reasons for this. First, where climate governance necessitates change at a behavioural level, there is a need to educate the public in order to achieve this (for example reducing car travel). Where successful, this offers the possibility that communities can become self governing, for example choosing to drive less.\nSecond, effective community engagement ensures that climate governance policies are relevant to the communities in which they are intended to be applied. This necessitates a process of ‘bottom up learning’, as ideas are passed up from a local to national level. This approach has been identified as the normative framework of ‘learning organisations’ and popular within environmental organisations that seek to encourage grassroots development \n\nThe history of climate governance has seen increasing emphasis placed on market based solutions, or “flexibility mechanisms”. This is a development that complements, rather than replaces traditional ‘command and control’ regulation. The decision to favour market mechanisms has been identified as inevitable given the growth in popularity of neoliberalism over the past two decades. Thus, targets set at international climate governance conventions have been achieved through the application of markets (for example the EU-ETS), public-private partnerships (for example “type II partnerships”) and the self-regulation of industry (for example the Global Gas Flaring Reduction Partnership).\n\nSignificantly, the Kyoto Protocol offers participating countries three market based mechanisms as means to meeting their binding emissions reduction targets. These are 'emissions trading' (known as “the carbon market\"), 'the clean development mechanism' (CDM) and 'joint implementation' (JI). The three Kyoto market mechanisms have been identified as forms of carbon market governance, a market based form of climate governance. Carbon market governance allows carbon emissions in one place to be exchanged with emissions reductions in another. It relies on measuring, monitoring and verification techniques to commensurate carbon, allowing seemingly disparate activities to appear on the same balance sheet.\n\nThe largest working example of carbon market governance to date is the EU-ETS. It is a multinational emissions trading scheme. Advocates of this mechanism cite its focus on improving efficiency, reducing carbon where it is most cost efficient to do so. Its critics identify that it has so far allowed participating industries to profit from excess carbon credits while having little or no effect on their carbon emissions.\n\nThe view of climate governance stakeholders that climate action was a costly burden has somehow changed in recent years: According to the Global Commission on the Economy and Climate, up to 90% of the actions required to get onto a 2°C pathway would be compatible with the goals of boosting national development, equitable growth and broadly shared improvements in living standards. Three phenomena are behind this cost-benefit analysis: First, \"negative cost abatement\" means that curbing emissions reduces overall costs (e.g. energy savings). Second, economies of scale and learning-by-doing innovation potentially lead to falling costs over time. Third, so-called \"co-benefits\" such as health benefits through less air pollution or livelihood security through land restoration can be beneficial for individual countries. \n\nIn addition to the efforts of nation-states to coordinate internationally on matters of climate governance, nation-states, non-state actors and private actors are becoming increasingly involved in multiple parallel climate governance partnerships on a global scale. These actors include cities, regions, NGOs and corporations. Their increasingly prominent involvement has led scholars to reassess the nature of power in climate governance as well as the relationship between public and private authority \n\nTo distinguish between types of climate governance networks currently in existence, it is useful to separate components into sub-categories. Studies into climate governance have distinguished between modes of governance (self-governing, governing through enabling, governing by provision and governing by authority), types of actors and political scale of governance. For the purpose of this section they are separated according to the type of actors involved – ‘public climate governance partnerships’, ‘public-private climate governance’ partnerships and ‘private climate governance partnerships’. 'Modes of governance' and ‘scale’ (e.g. supranational, national, regional, and local) represent equally viable alternatives to this categorisation. While none of these approaches are definitive (each approach exhibits overlaps), defining partnerships according to participating actor is here considered to draw the clearer distinction.\n\n\n\n\nA relatively new approach to governing climate impacts upon social systems is to use the flexible technique of adaptive governance, introduced by Holling in 1978 as opposed to the more mitigation-focused approaches which have generally dominated efforts thus far. Adaptive governance “refers to the ways in which institutional arrangements evolve to satisfy the needs and desires of the community in a changing environment”.\nSeveral theorists believe that it is within a society’s capacity to adapt to the gradual climate changes we are experiencing currently, and those felt in the future. Therefore, utilizing adaptive governance is perhaps the ideal solution as its experimental approach allows newly created institutions to “experiment with different solutions and learn from them in order to adapt and transform\". The role of these institutions is to then formulate policies to strengthen the resilience between complex climate and social systems, and therefore the system’s ability to adapt and remain stable in the face of climate changes in the future.\n\nIn addition, institutions encourage communication between different levels of power (local, regional, national and international) to govern resources, whilst also engaging a broad set of stakeholders e.g. NGO’s and the public. Therefore, the approach takes a predominantly ‘bottom up’ strategy, focusing on community-based actions. In terms of climate change this provides an alternative to the ‘top down’ IPCC proceedings and world negotiations, which many perceive as having no effect in addressing climate issues.\n\nAdaptive governance has been successfully implemented in a number of local society’s around the world in building their ability to adapt to climate change associated impacts such as extreme weather and altering plant biodiversities. Success has mainly been attributed to the fact that through adaptive governance, the social impact is dealt with locally to achieve a more effective result whilst still allowing communication to flow between low to high levels of command. For example, Brunner & Lynch in 2010 studied how the Barrow community in Alaska successfully communicated with local and regional governments to develop adaptive strategies for minimizing extreme weather impacts.\n\nSeveral limitations have arisen when applying the adaptive governance strategy to climate governance. Firstly, when applied at local level, adaptive governance is evidently successful; however, Evans (2011) found problems when applying such techniques over a large scale. For example, the technique could have limited success when adapting to a national or international problem as the system may become too complex. A further weakness highlighted by Ostrom in 2007 is that many adaptive governance systems have been implemented to build resilience to gradual changes but anthropogenic climate change could cause rapid alterations and so challenge the robustness of the whole governance system. Finally, using this experimental approach for such a precarious and influential system as our climate has been considered too risky, especially as Earth is potentially nearing the 2 degree global warming tipping point.\n\nEven with these limitations, adaptive governance is evidently a successful strategy at local scale in addressing unique climate change impacts on social systems. Therefore, the idea of focusing on and monitoring localized problems to achieve a global goal may well be highly influential as the impacts of climate change become increasingly widespread and complex.\n\nIt is said with some imprecision by some popular observers that the core commitments of the Kyoto Protocol expire in 2012. More precisely, the first commitment period for Annex B Parties (commonly known as Annex 1 Parties) to the Kyoto Protocol run from 2008 to 2012 inclusive, with a carbon accounting truing up period that may run for some time after 2012. The other obligations of parties to the Kyoto Protocol are not time limited in the way that the First Commitment Period QELEROs of Annex B Parties are. While the more recent Copenhagen Accord endorses these commitments, it does not commit signatory countries to agree on a binding successor. Future global consensus will require the respective roles of developed and developing countries to be determined according to their relative responsibilities and capabilities. Furthermore, all participating countries will need to agree that resultant legal architecture is fair and therefore acceptable. A key limitation in achieving this is the refusal of the United States to commit to legally binding negotiations. The re-engagement of the United States in this field has been cited as a potential future \"trigger\" that could lead to multilateral legally binding emissions reductions in GHG emissions.\n\nMovement at a national level could also stimulate multilateral negotiations as some countries look set to press ahead with legally binding emissions cuts. On 17 May 2011, the UK Government introduced the Fourth Carbon Budget which aims to \"set an ambitious target in law to reduce greenhouse gas emissions . . . and build momentum toward a legally global climate change deal\".\n\nIn the absence of a multilateral emissions reduction agreement, the future direction of climate governance remains uncertain. Supranational and national legislation could legislate the continuation of market based emissions reduction mechanisms, for example the EU-ETS. The increased agency of non-state actors in the realm of global governance and the growth of public and public-private networks offer the potential for the global climate arena to develop at a sub-national level. Recent attempts to 'territorialise' the carbon cycle seek to frame climate change as a local rather than global problem by rearticulating the global carbon cycle as a combination of national 'sinks'.\n\nAn emerging research direction is focusing on the institutional accountabilities and capability for change involved in effective global climate governance, from a perspective of individual organisations involved, as well as systemic responsiveness to people most affected by climate change\n"}
{"id": "59863", "url": "https://en.wikipedia.org/wiki?curid=59863", "title": "Correspondence principle", "text": "Correspondence principle\n\nIn physics, the correspondence principle states that the behavior of systems described by the theory of quantum mechanics (or by the old quantum theory) reproduces classical physics in the limit of large quantum numbers. In other words, it says that for large orbits and for large energies, quantum calculations must agree with classical calculations.\n\nThe principle was formulated by Niels Bohr in 1920, though he had previously made use of it as early as 1913 in developing his model of the atom.\n\nThe term codifies the idea that a new theory should reproduce under some conditions the results of older well-established theories in those domains where the old theories work. This concept is somewhat different from the requirement of a formal limit under which the new theory reduces to the older, thanks to the existence of a deformation parameter. \n\nClassical quantities appear in quantum mechanics in the form of expected values of observables, and as such the Ehrenfest theorem (which predicts the time evolution of the expected values) lends support to the correspondence principle.\n\nThe rules of quantum mechanics are highly successful in describing microscopic objects, atoms and elementary particles. But \"macroscopic systems,\" like springs and capacitors, are accurately described by classical theories like classical mechanics and classical electrodynamics. If quantum mechanics were to be applicable to macroscopic objects, there must be some limit in which quantum mechanics reduces to classical mechanics. \"Bohr's correspondence principle demands that classical physics and quantum physics give the same answer when the systems become large\". A. Sommerfeld (1924) referred to the principle as \"Bohrs Zauberstab\" (Bohr's magic wand).\n\nThe conditions under which quantum and classical physics agree are referred to as the correspondence limit, or the classical limit. Bohr provided a rough prescription for the correspondence limit: it occurs \"when the quantum numbers describing the system are large\". A more elaborated analysis of quantum-classical correspondence (QCC) in wavepacket spreading leads to the distinction between robust \"restricted QCC\" and fragile \"detailed QCC\". \"Restricted QCC\" refers to the first two moments of the probability distribution and is true even when the wave packets diffract, while \"detailed QCC\" requires smooth potentials which vary over scales much larger than the wavelength, which is what Bohr considered.\n\nThe post-1925 new quantum theory came in two different formulations. In matrix mechanics, the correspondence principle was built in and was used to construct the theory. In the Schrödinger approach classical behavior is not clear because the waves spread out as they move. Once the Schrödinger equation was given a probabilistic interpretation, Ehrenfest showed that Newton's laws hold on average: the quantum statistical expectation value of the position and momentum obey Newton's laws.\n\nThe correspondence principle is one of the tools available to physicists for selecting quantum theories corresponding to reality. The principles of quantum mechanics are broad: states of a physical system form a complex vector space and physical observables are identified with Hermitian operators that act on this Hilbert space. The correspondence principle limits the choices to those that reproduce classical mechanics in the correspondence limit.\n\nBecause quantum mechanics only reproduces classical mechanics in a statistical interpretation, and because the statistical interpretation only gives the probabilities of different classical outcomes, Bohr has argued that quantum physics does not reduce to classical mechanics similarly as classical mechanics emerges as an approximation of special relativity at small velocities. He argued that classical physics exists independently of quantum theory and cannot be derived from it. His position is that it is inappropriate to understand the experiences of observers using purely quantum mechanical notions such as wavefunctions because the different states of experience of an observer are defined classically, and do not have a quantum mechanical analog. The relative state interpretation of quantum mechanics is an attempt to understand the experience of observers using only quantum mechanical notions. Niels Bohr was an early opponent of such interpretations.\n\nMany of these conceptual problems, however, resolve in the phase-space formulation of quantum mechanics, where the \"same variables with the same interpretation\" are utilized to describe both quantum and classical mechanics.\n\nThe term \"correspondence principle\" is used in a more general sense to mean the reduction of a new scientific theory to an earlier scientific theory in appropriate circumstances. This requires that the new theory explain all the phenomena under circumstances for which the preceding theory was known to be valid, the \"correspondence limit\".\n\nFor example, \n\nIn order for there to be a correspondence, the earlier theory has to have a domain of validity—it must work under \"some\" conditions. Not all theories have a domain of validity. For example, there is no limit where Newton's mechanics reduces to Aristotle's mechanics because Aristotle's mechanics, although academically dominant for 18 centuries, does not have any domain of validity.\n\nIf an electron in an atom is moving on an orbit with period , classically the electromagnetic radiation will repeat itself every orbital period. If the coupling to the electromagnetic field is weak, so that the orbit doesn't decay very much in one cycle, the radiation will be emitted in a pattern which repeats every period, so that the Fourier transform will have frequencies which are only multiples of . This is the classical radiation law: the frequencies emitted are integer multiples of .\n\nIn quantum mechanics, this emission must be in quanta of light, of frequencies consisting of integer multiples of , so that classical mechanics is an approximate description at large quantum numbers. This means that the energy level corresponding to a classical orbit of period must have nearby energy levels which differ in energy by , and they should be equally spaced near that level,\n\nBohr worried whether the energy spacing 1/ should be best calculated with the period of the energy state formula_2, or formula_3, or some average—in hindsight, this model is only the leading semiclassical approximation.\n\nBohr considered circular orbits. Classically, these orbits must decay to smaller circles when photons are emitted. The level spacing between circular orbits can be calculated with the correspondence formula. For a Hydrogen atom, the classical orbits have a period determined by Kepler's third law to scale as . The energy scales as , so the level spacing formula amounts to\nIt is possible to determine the energy levels by recursively stepping down orbit by orbit, but there is a shortcut.\n\nThe angular momentum of the circular orbit scales as . The energy in terms of the angular momentum is then\n\nAssuming, with Bohr, that quantized values of are equally spaced, the spacing between neighboring energies is\nThis is as desired for equally spaced angular momenta. If one kept track of the constants, the spacing would be , so the angular momentum should be an integer multiple of ,\n\nThis is how Bohr arrived at his model. Since only the level \"spacing\" is determined heuristically by the correspondence principle, one could always add a small fixed offset to the quantum number— could just as well have been . \n\nBohr used his physical intuition to decide which quantities were best to quantize. It is a testimony to his skill that he was able to get so much from what is only the leading order approximation. A less heuristic treatment accounts for needed offsets in the ground state L, cf. Wigner–Weyl transform.\n\nBohr's correspondence condition can be solved for the level energies in a general one-dimensional potential. Define a quantity which is a function only of the energy, and has the property that\n\nThis is the analog of the angular momentum in the case of the circular orbits. The orbits selected by the correspondence principle are the ones that obey for integer, since\n\nThis quantity is canonically conjugate to a variable which, by the Hamilton equations of motion changes with time as the gradient of energy with . Since this is equal to the inverse period at all times, the variable increases steadily from 0 to 1 over one period.\n\nThe angle variable comes back to itself after 1 unit of increase, so the geometry of phase space in coordinates is that of a half-cylinder, capped off at = 0, which is the motionless orbit at the lowest value of the energy. These coordinates are just as canonical as , but the orbits are now lines of constant instead of nested ovoids in space.\n\nThe area enclosed by an orbit is invariant under canonical transformations, so it is the same in space as in . But in the coordinates, this area is the area of a cylinder of unit circumference between 0 and , or just . So is equal to the area enclosed by the orbit in coordinates too,\n\nThe quantization rule is that the action variable is an integer multiple of .\n\nBohr's correspondence principle provided a way to find the semiclassical quantization rule for a one degree of freedom system. It was an argument for the old quantum condition mostly independent from the one developed by Wien and Einstein, which focused on adiabatic invariance. But both pointed to the same quantity, the action.\n\nBohr was reluctant to generalize the rule to systems with many degrees of freedom. This step was taken by Sommerfeld, who proposed the general quantization rule for an integrable system,\n\nEach action variable is a separate integer, a separate quantum number.\n\nThis condition reproduces the circular orbit condition for two dimensional motion: let be polar coordinates for a central potential. Then is already an angle variable, and the canonical momentum conjugate is , the angular momentum. So the quantum condition for reproduces Bohr's rule:\n\nThis allowed Sommerfeld to generalize Bohr's theory of circular orbits to elliptical orbits, showing that the energy levels are the same. He also found some general properties of quantum angular momentum which seemed paradoxical at the time. One of these results was that the z-component of the angular momentum, the classical inclination of an orbit relative to the z-axis, could only take on discrete values, a result which seemed to contradict rotational invariance. This was called \"space quantization\" for a while, but this term fell out of favor with the new quantum mechanics since no quantization of space is involved.\n\nIn modern quantum mechanics, the principle of superposition makes it clear that rotational invariance is not lost. It is possible to rotate objects with discrete orientations to produce superpositions of other discrete orientations, and this resolves the intuitive paradoxes of the Sommerfeld model.\n\nHere is a demonstration\nof how large quantum numbers can give rise to classical (continuous) behavior.\n\nConsider the one-dimensional quantum harmonic oscillator. Quantum mechanics tells us that the total (kinetic and potential) energy of the oscillator, , has a set of discrete values,\nwhere is the angular frequency of the oscillator.\n\nHowever, in a classical harmonic oscillator such as a lead ball attached to the end of a spring, we do not perceive any discreteness. Instead, the energy of such a macroscopic system appears to vary over a continuum of values. We can verify that our idea of macroscopic systems fall within the correspondence limit. The energy of the classical harmonic oscillator with amplitude , is\n\nThus, the quantum number has the value\n\nIf we apply typical \"human-scale\" values = 1kg, = 1 rad/s, and = 1 m, then ≈ 4.74×10. This is a very large number, so the system is indeed in the correspondence limit.\n\nIt is simple to see why we perceive a continuum of energy in this limit. With = 1 rad/s, the difference between each energy level is ≈ 1.05 × 10J, well below what we normally resolve for macroscopic systems. One then describes this system through an emergent classical limit.\n\nHere we show that the expression of kinetic energy from special relativity becomes arbitrarily close to the classical expression, for speeds that are much slower than the speed of light, .\n\nEinstein's mass-energy equation\nwhere the velocity, is the velocity of the body relative to the observer, formula_17 is the \"rest\" mass (the observed mass of the body at zero velocity relative to the observer), and is the speed of light.\n\nWhen the velocity vanishes, the energy expressed above is not zero, and represents the \"rest\" energy,\n\nWhen the body is in motion relative to the observer, the total energy exceeds the rest energy by an amount that is, by definition, the \"kinetic\" energy,\n\nUsing the approximation\nwe get, when speeds are much slower than that of light, or , \n\nwhich is the Newtonian expression for kinetic energy.\n"}
{"id": "43431118", "url": "https://en.wikipedia.org/wiki?curid=43431118", "title": "Dahara-vidya", "text": "Dahara-vidya\n\nDahara-vidya or 'the knowledge of Brahman within', is mentioned in the Chandogya Upanishad and the Taittiriya Upanishad. In this Upasana the sadhaka concentrates on Brahman (the Universal Self) in the cave of the heart. It is one of the thirty-two \"vidyas\" of the Upanishads taught in Vedanta, in which vidya Brahman is perceived as the imperceptible ether within the heart. This \"vidya\" occurs in the 8th Chapter of the Chandogya Upanishad. where it is taught that the abode of Brahman is the small lotus that is here in this city of Brahman, what is there in the small space within the lotus is to be searched out. This \"vidya\" explains the identity of the external and the internal, the objective and the subjective, the macrocosmic and the microcosmic, the universal and the individual, Brahman and the Atman.\n\nIn the \"Dahara-vidya\", Brahman is to be conceived as dwelling in the cavity of the heart, and yet as big as the whole universe. \"Dahara-vidya\" has for its object the realization of the Atman in the little space (\"dahara\" दहरा) the subtle inner sky within oneself in the heart. It is a classical meditative practice mentioned in the Vedas. In this \"vidya\" the desires are the auspicious qualities of Brahman which are the objects of desire; the man who knows Brahman obtains, together with Brahman, all qualities of Brahman.\n\n\"Dahara-vidya\" is described in six brief passages in the Chandogya Upanishad. Sankara explains that for persons who have realized the unity of the Self, there is absence of the idea of 'traveler', 'travel' and 'destination', and on the cessation of the causes for continuance of the traces of ignorance etc. they merge in their own self; Brahman who is devoid of direction, location, qualities, movement, and differences of results, appears to people of dull intellect as non-existing, \"Dahara-vidya\" is taught to make them come to the right path. Therefore, the sage of Chandogya Upanishad insists that he (Brahman) who resides in the small space existing within the small lotus-like dwelling that is within the city of Brahman has to be enquired into (with the help of a teacher and other valid means). The space referred to within the heart is as vast as the space outside, within it are included both heaven and earth; whatever one has and whatever one does not have, all that is included in that space as also all beings and all desires. For those who have not realized Brahman the results acquired through actions get exhausted in this world and those acquired through virtues in the next. For those who have realized the Self there is freedom of movement in all the worlds. Then, whatever province he becomes attracted to, whatever objects he desires, that appears by his very desire, and being associated with that he becomes glorified. The sage tells us –\n"}
{"id": "45134", "url": "https://en.wikipedia.org/wiki?curid=45134", "title": "Discourse", "text": "Discourse\n\nDiscourse (from Latin \"discursus\", \"running to and from\") denotes written and spoken communications:\n\n\nAs discourse, an \"enouncement\" (statement) is not a unit of semiotic signs, but an abstract construct that allows the semiotic signs to assign meaning, and so communicate specific, repeatable communications to, between, and among objects, subjects, and statements. Therefore, a discourse is composed of semiotic sequences (relations among signs that communicate meaning) between and among objects, subjects, and statements.\n\nThe term \"discursive formation\" () conceptually describes the regular communications (written and spoken) that produce such discourses, such as informal conversations. As a philosopher, Michel Foucault applied the discursive formation in the analyses of large bodies of knowledge, such as political economy and natural history.\n\nIn the first sense-usage (semantics and discourse analysis), the term \"discourse\" is studied in corpus linguistics, the study of language expressed in \"corpora\" (samples) of \"real world\" text. In the second sense (the codified language of a field of enquiry) and in the third sense (a statement, \"un énoncé\"), the analysis of a \"discourse\" examines and determines the connections among language and structure and agency.\n\nMoreover, because a discourse is a body of text meant to communicate specific data, information, and knowledge, there exist internal relations in the content of a given discourse; likewise, there exist external relations among discourses. As such, a discourse does not exist \"per se\" (in itself), but is related to other discourses, by way of inter-discursivity. Discourses are also perpetually differentiating toward each other in time. Therefore, in the course of intellectual enquiry, the discourse among researchers features the questions and answers of \"What is ...?\" and \"What is not. ...\", conducted according to the meanings (denotation and connotation) of the concepts (statements) used in the given field of enquiry, such as anthropology, ethnography, and sociology; cultural studies and literary theory; the philosophy of science and feminism.\n\nIn the humanities and in the social sciences, the term \"discourse\" describes a formal way of thinking that can be expressed through language; the discourse is a social boundary that defines what statements can be said about a topic.\n\nDiscourse can affect the person's perspective; it is impossible to avoid discourse for any subject. For example, two notably distinct discourses can be used about various guerrilla movements describing them either as \"freedom fighters\" or \"terrorists\". In other words, the chosen discourse provides the vocabulary, expressions and perhaps also the style needed to communicate.\n\nDiscourses are embedded in different rhetorical genres and metagenres that constrain and enable them. That is language talking about language, for instance the American Psychiatric Association's DSMIV manual tells which terms have to be used in talking about mental health, thereby mediating meanings and dictating practices of the professionals of psychology and psychiatry.\n\nDiscourse is closely linked to different theories of power and state, at least as long as defining discourses is seen to mean defining reality itself. This conception of discourse is largely derived from the work of French philosopher Michel Foucault.\n\nA discourse representation theory describes the formal semantics of a sentence using predicate logic.\n\nModern theorists were focused on achieving progress and believed in the existence of natural and social laws which could be used universally to develop knowledge and thus a better understanding of society. Modernist theorists were preoccupied with obtaining the truth and reality and sought to develop theories which contained certainty and predictability. Modernist theorists therefore viewed discourse as being relative to talking or way of talking and understood discourse to be functional. Discourse and language transformations are ascribed to progress or the need to develop new or more \"accurate\" words to describe new discoveries, understandings, or areas of interest. In modern times, language and discourse are dissociated from power and ideology and instead conceptualized as \"natural\" products of common sense usage or progress. Modernism further gave rise to the liberal discourses of rights, equality, freedom, and justice; however, this rhetoric masked substantive inequality and failed to account for differences, according to Regnier.\n\nStructuralist theorists, such as Ferdinand de Saussure and Jacques Lacan, argue that all human actions and social formations are related to language and can be understood as systems of related elements. This means that the \"…individual elements of a system only have significance when considered in relation to the structure as a whole, and that structures are to be understood as self-contained, self-regulated, and self-transforming entities.\" In other words, it is the structure itself that determines the significance, meaning and function of the individual elements of a system. Structuralism has made an important contribution to our understanding of language and social systems. Saussure's theory of language highlights the decisive role of meaning and signification in structuring human life more generally.\n\nFollowing the perceived limitations of the modern era, emerged postmodern theory. Postmodern theorists rejected modernist claims that there was one theoretical approach that explained all aspects of society. Rather, postmodernist theorists were interested in examining the variety of experience of individuals and groups and emphasized differences over similarities and common experiences.\n\nIn contrast to modern theory, postmodern theory is more fluid and allows for individual differences as it rejected the notion of social laws. Postmodern theorists shifted away from truth seeking and instead sought answers for how truths are produced and sustained. Postmodernists contended that truth and knowledge is plural, contextual, and historically produced through discourses. Postmodern researchers therefore embarked on analyzing discourses such as texts, language, policies and practices.\n\nFrench social theorist Michel Foucault developed a notion of discourse in his early work, especially the \"Archaeology of knowledge\" (1972). In \"Discursive Struggles Within Social Welfare: Restaging Teen Motherhood\", Iara Lessa summarizes Foucault's definition of discourse as \"systems of thoughts composed of ideas, attitudes, courses of action, beliefs and practices that systematically construct the subjects and the worlds of which they speak.\" Foucault traces the role of discourses in wider social processes of legitimating and power, emphasizing the construction of current truths, how they are maintained and what power relations they carry with them. Foucault later theorized that discourse is a medium through which power relations produce speaking subjects. Foucault (1977, 1980) argued that power and knowledge are inter-related and therefore every human relationship is a struggle and negotiation of power. Foucault further stated that power is always present and can both produce and constrain the truth. Discourse according to Foucault (1977, 1980, 2003) is related to power as it operates by rules of exclusion. Discourse therefore is controlled by objects, what can be spoken of; ritual, where and how one may speak; and the privileged, who may speak. Coining the phrases power-knowledge Foucault (1980) stated knowledge was both the creator of power and creation of power. An object becomes a \"node within a network.\" In his work, \"The Archaeology of Knowledge,\" Foucault uses the example of a book to illustrate a node within a network. A book is not made up of individual words on a page, each of which has meaning, but rather \"is caught up in a system of references to other books, other texts, other sentences.\" The meaning of that book is connected to a larger, overarching web of knowledge and ideas to which it relates.\n\nOne of the key discourses that Foucault identified as part of his critique of power-knowledge was that of neoliberalism, which he related very closely to his conceptualization of governmentality in his lectures on biopolitics. This trajectory of Foucault's thinking has been taken up widely within Human Geography.\n\n\n\n"}
{"id": "24680069", "url": "https://en.wikipedia.org/wiki?curid=24680069", "title": "El-Hibri Peace Education Prize", "text": "El-Hibri Peace Education Prize\n\nThe El-Hibri Peace Education Prize was established by Fuad El-Hibri in 2007 for the purpose of honoring an outstanding scholar, practitioner or policymaker annually in order to celebrate and encourage individuals who embody the principles of peace, justice, and inclusion. Today the prize is the longest-running program of the El-Hibri Foundation, which is a family foundation located in Washington, DC. It aims to empower and equip Muslim leaders and their allies to build thriving, inclusive communities. Its grantmaking and programs are intended to provide resources and skills, forge collaborative relationships, and increase inclusion of and within American Muslim communities.\n\n\"The El-Hibri Foundation awards an annual $30,000 Peace Education Prize to individuals who have dedicated their lives to building inclusive communities in the United States and building the capacity of others to create positive social change.\n\nThe prize is intended to celebrate and encourage individuals who embody the principles of peace, justice, and inclusion.\"\n\nIndividuals based in the United States whose primary work is focused on domestic audiences and aligned with the strategic focus areas of EHF are eligible. These individuals will have demonstrated:\n\n\nFinalists will be selected based on the following criteria:\n\n\"Working across difference\"\n\n\n\"Creating unique and broad-based institutional impact\"\n\n\n\n"}
{"id": "42126908", "url": "https://en.wikipedia.org/wiki?curid=42126908", "title": "Gregory Maass &amp; Nayoungim", "text": "Gregory Maass &amp; Nayoungim\n\nGregory Maass (born 29 April 1967 in Hagen, Germany) and Nayoungim (sometimes referred to as Kim Nayoung; ; born 13 March 1966 in Seoul, South Korea) are two artists who work together as a collaborative duo called Gregory Maass & Nayoungim. Gregory Maass & Nayoungim´s idiosyncratic work brings together philosophy, psychoanalysis, cybernetics, cybernetic management, economy, fringe science, science fiction, art and craft, music, comics, conspiracy theory, sub-culture, and food by focusing on such diverse means as adaptation, normality, perversion, and methodology. They are the founders of Kim Kim Gallery, which describes itself as \"a non-profit organization, locative art, an art dealership based on unconventional marketing, a curatorial approach, an exhibition design firm, and editor of rare art books, depending on the situation it adapts to; in short, it does not fit the format imposed by the term Gallery.\" One rarely appears in public without the other.\n\nGregory Maass was born in Hagen in North Rhine-Westphalia, northern Germany, his mother tongue being German. He worked as a paramedic before moving to Paris, France. He studied philosophy at the Paris-Sorbonne University and art at the École nationale supérieure des Beaux-Arts, at the Institut des Hautes Études en Arts Plastiques (IHEAP) Paris (1993–94) and at Jan Van Eyck Academie the Netherlands (1998-2000).\n\nNayoungim was born in Seoul in South Korea. She studied art at the Seoul National University and later at the École nationale supérieure des Beaux-Arts. The two first met on 12 September 1991 while studying sculpture at the ENSBA. The two claim they came together because they are both egomaniacs who form a symbiosis. They communicate with each other in French and English. They have claimed that they married in 2008.\n\nTheir work has addressed a wide variety of subject matters including scatology, survivalism, and economy. The two artists rarely appear in their own work.\n\nare often life-size photographic representations on canvas of toilet paper rolls arranged on a table top. Depending on the composition the images are called “Arsewipe rocket”, \"torche-cul\", or “Ass-ana”.\n\nThe pair is perhaps best known for their miniature work called \"Relationships Do Not Exist\". This group of sculptures is one of the largest series of work created by Gregory Maass & Nayoungim. Relationships Do Not Exist is among the more iconic, philosophically astute and visually humorous works that Gregory Maass & Nayoungim have created. The title derives from the famous Jacques Lacan quote “Sexual relationships do not exist”. \nThey proceeded by choosing samples out of a wide collection of figurines ranging from the 1950s until today. In an intricate process the bodies are dismembered and reassembled, painted and mounted on empty trophy pedestals. Gregory Maass & Nayoungim call this an adaptation method: \"First we cannibalize them and then they get frankensteined back together.\"\n\nis a public art work installed in Busan, a town where it hardly ever snows. It is a chromed steel snowman placed on a rooftop water tower of a local kindergarten.\n\nis a public art work, first installed in front of the Seoul Railway Station in 2008. It is made of rubber, toys, foam mattresses and steel frames, and sprayed over with expansion foam. The entire construction is painted with a collection of surplus paints. The face of the sculpture depicts the past, present, and future of the city of Seoul.\n\n\nGregory Maass´ first solo-show entitled \"Tears of Boredom\" (the original German title is \"Tränen vor Langeweile\"), was held in 1991 in Hagen, Germany. It consisted of a tautological representation of peanuts. Large scale peanut butter paintings representing peanuts, black and white photographs of peanuts, and an installation of peanuts positioned in tensegrity were on display.\n\nduo-show was about different kinds of possible success in art, be it fame and glory, money and power, or the desired result of an attempt. The title derives from Genesis P-Orridge´s first recording with Worm. \"In the summer of 1968, Worm recorded their first and only album, entitled Early Worm, in Megson's parents attic in Solihull. It was pressed onto vinyl in November at Deroy Sound Services in Manchester, but only one copy was ever produced. A second album, Catching the Bird, was recorded but never pressed.\"\n\n\"Tofu incorporates the meaning of mildness, nutritiousness, purity, shaped shapelessness, tasteful tastelessness, crème de la crème, exclusiveness, peacefulness and so on, which were the inspiration to build this show.\" It took place at the Department for Philosophy and Art in Assen, Netherlands.\n\nwas a show realized with the help of mentally ill patients in the 3bisF Contemporary Art Space in Aix-en-Provence, France, which is located inside the walls of a psychiatric ward. It included works such as \"This is punk\" and \"Hunter S. Thompson´s mirror shades\".\n\n\nGregory Maass claims to be influenced in his thinking by Robert Filliou´s \"Principle Of Equivalence\", which states that (Well done, Badly done, Not done) are three equivalent assumptions, and the writings of Philip K. Dick.\n\n\n"}
{"id": "1433747", "url": "https://en.wikipedia.org/wiki?curid=1433747", "title": "Harnack's principle", "text": "Harnack's principle\n\nIn complex analysis, Harnack's principle or Harnack's theorem is one of several closely related theorems about the convergence of sequences of harmonic functions, that follow from Harnack's inequality.\n\nIf the functions formula_1, formula_2, ... are harmonic in an open connected subset formula_3 of the complex plane C, and\nin every point of formula_3, then the limit\neither is infinite in every point of the domain formula_3 or it is finite in every point of the domain, in both cases uniformly in each compact subset of formula_3. In the latter case, the function\nis harmonic in the set formula_10.\n\n"}
{"id": "436287", "url": "https://en.wikipedia.org/wiki?curid=436287", "title": "Heaps' law", "text": "Heaps' law\n\nIn linguistics, Heaps' law (also called Herdan's law) is an empirical law which describes the number of distinct words in a document (or set of documents) as a function of the document length (so called type-token relation). It can be formulated as\n\nwhere \"V\" is the number of distinct words in an instance text of size \"n\". \"K\" and β are free parameters determined empirically. With English text corpora, typically \"K\" is between 10 and 100, and β is between 0.4 and 0.6.\n\nThe law is frequently attributed to Harold Stanley Heaps, but was originally discovered by . Under mild assumptions, the Herdan–Heaps law is asymptotically equivalent to Zipf's law concerning the frequencies of individual words within a text. This is a consequence of the fact that the type-token relation (in general) of a homogenous text can be derived from the distribution of its types.\n\nHeaps' law means that as more instance text is gathered, there will be diminishing returns in terms of discovery of the full vocabulary from which the distinct terms are drawn.\n\nHeaps' law also applies to situations in which the \"vocabulary\" is just some set of distinct types which are attributes of some collection of objects. For example, the objects could be people, and the types could be country of origin of the person. If persons are selected randomly (that is, we are not selecting based on country of origin), then Heaps' law says we will quickly have representatives from most countries (in proportion to their population) but it will become increasingly difficult to cover the entire set of countries by continuing this method of sampling.\n\n"}
{"id": "27232148", "url": "https://en.wikipedia.org/wiki?curid=27232148", "title": "Identity Performance", "text": "Identity Performance\n\nIdentity performance is a concept that holds that \"identity\" can be a project or a conscious effort or action taken to present oneself in social interactions. This is based on the definition of identity as an ongoing process of self-definition and the definitions of the self by others, which emerge out of interaction with others. The idea is that there are identities that are performed to achieve several objectives such as assimilation and acculturation, among others. It draws from the Erving Goffman's theatrical metaphor theory where, in social situations, the others perform the role of the audience, which an individual must perform to impress.\n\nIn everyday interactions, the body serves as a critical site of identity performance. In conveying who we are to other people, we use our bodies to project information about ourselves. This is done through movement, clothes, speech, and facial expressions. What we put forward is our best effort at what we want to say about who we are. Yet while we intend to convey one impression, our performance is not always interpreted as we might expect. Through learning to make sense of others’ responses to our behavior, we can assess how well we have conveyed what we intended. We can then alter our performance accordingly. This process of performance, interpretation, and adjustment is what Goffman calls impression management. Impression management is a part of a larger process where people seek to define a situation through their behavior. People seek to define social situations by using contextual cues from the environment around them. Social norms emerge from situational definitions, as people learn to read cues from the environment and the people present to understand what is appropriate behavior.\n\nLearning how to manage impressions is a critical social skill that is honed through experience. Over time, we learn how to make meaning out of a situation, others’ reactions, and what we are projecting of ourselves. As children, we learn that actions on our part prompt reactions by adults; as we grow older, we learn to interpret these reactions and adjust our behavior. Diverse social environments help people develop these skills because they force individuals to re-evaluate the signals they take for granted.\n\nThe process of learning to read social cues and react accordingly is core to being socialized into a society. While the process itself begins at home for young children, it is critical for young people to engage in broader social settings to develop these skills. Of course, how children are taught about situations and impression management varies greatly by culture, but these processes are regularly seen as part of coming of age. While no one is ever a true master of impression management, the teenage years are ripe with experiences to develop these skills.\n\nIn mediated environments, bodies are not immediately visible and the skills people need to interpret situations and manage impressions are different. As Jenny Sundén argues, people must learn to write themselves into being. Doing so makes visible how much we take the body for granted. While text, images, audio, and video all provide valuable means for developing a virtual presence, the act of articulation differs from how we convey meaningful information through our bodies. This process also makes explicit the self-reflexivity that Giddens argues is necessary for identity formation, but the choices individuals make in crafting a digital body highlight the self-monitoring that Foucault so sinisterly notes.\n\nIn some sense, people have more control online – they are able to carefully choose what information to put forward, thereby eliminating visceral reactions that might have seeped out in everyday communication. At the same time, these digital bodies are fundamentally coarser, making it far easier to misinterpret what someone is expressing. Furthermore, as Amy Bruckman shows, key information about a person’s body is often present online, even when that person is trying to act deceptively; for example, people are relatively good at detecting when someone is a man even when they profess to be a woman online. Yet because mediated environments present reveal different signals, the mechanisms of deception differ.\n\nThere are studies that reveal specific cases of identity performance. These include the investigation on the experiences of Latino students in the American public education system. It was found that within culturally coded classrooms, members of this ethnic group have to perform identity in the form of behavioral signal that they are as worthy of achievement as their white peers. This also underscored that the white identity serves as the standard and that the performances often emulated it so that they form part of the how individuals from different ethnic groups assimilate. The \"public performances\" enacted by black females such as the assumption of the role of the \"black vixen\" are also cases in point. Researchers cite that roles are performed to reenact, reimagine and even revise personal and collective history. \n\nMichelle Duffy. “Performing identity within a multicultural framework”, in \"Social and Cultural\nGeography\", special issue on 'music and place', VI(2005), no. 4, pp. 677-692.\n\nPhilip V. Bohlman and Marcello Sorce Keller (eds.), \"Musical Anthropology of the \nMediterranean: Interpretation, Performance, Identity\". Bologna: Edizioni Clueb – \nCooperativa Libraria Universitaria Editrice, 2009. \n\nLinda Barwick and Marcello Sorce Keller (eds.). \"Out of Place and Time: Italian and Australian Perspectives on Italian Music in Australia\". Lyrebird: Melbourne, 2012.\n\nMarcello Sorce Keller. “The Swiss-Germans in Melbourne. Some Considerations on Musical Traditions and Identity”, \"Schweizer Jahrbuch für Musikwissenschaft\", Neue Folge, XXV(2005), pp. 131-154.\n"}
{"id": "10769998", "url": "https://en.wikipedia.org/wiki?curid=10769998", "title": "Induced movement", "text": "Induced movement\n\nInduced movement or induced motion is an illusion of visual perception in which a stationary or a moving object appears to move or to move differently because of other moving objects nearby in the visual field. It is interpreted in terms of the change in the location of an object due to the movement in the space around it. The object affected by the illusion is called the \"target\", and the other moving objects are called the \"background\" or the \"context\" (Duncker, 1929).\n\nA stationary object appears to move in the opposite direction to the background. For example, the moon on a cloudy, windy night appears to be racing through the sky opposite to the direction of the clouds, though the moon is essentially stationary in the sky and only appears to be moving due to the movement of the clouds. For an illustration, see http://psychlab1.hanover.edu/Classes/Sensation/induced/\n\nA moving object appears to be moving faster when it is moving in the opposite direction to the background; it appears to be moving slower when it is moving in the same direction as the background.\n\nInduced motion has more continuous history than does apparent motion. Induced movement was reported by Ptolemy (ca. 90 – ca. 168 AD) (see Smith, 1996). It was researched extensively by Duncker (1929).\n\n\nDuncker, K. (1929). Über induzierte Bewegung (Ein Beitrag zur Theorie optisch wahrgenommener Bewegung). \"Psychologische Forschung, 12,\" 180-259.\n\nSmith, A. M. (1996). Ptolemy's theory of visual perception: An English translation of the Optics with introduction and commentary. \"Transactions of the American Philosophical Society, 86\"(2).\n\nHae-Won Shin; Mi J. Kim; Jong S. Kim; Myoung C. Lee; Sun J. Chung (2009). Levosulpiride-induced movement disorders . \"Movement Disorders\",24 (15), pg. 2249-2253 .\n"}
{"id": "45196", "url": "https://en.wikipedia.org/wiki?curid=45196", "title": "Injective function", "text": "Injective function\n\nIn mathematics, an injective function or injection or one-to-one function is a function that preserves distinctness: it never maps distinct elements of its domain to the same element of its codomain. In other words, every element of the function's codomain is the image of \"at most\" one element of its domain. The term \"one-to-one function\" must not be confused with \"one-to-one correspondence\" (a.k.a. bijective function), which uniquely maps all elements in both domain and codomain to each other (see figures).\n\nOccasionally, an injective function from \"X\" to \"Y\" is denoted , using an arrow with a barbed tail (). The set of injective functions from \"X\" to \"Y\" may be denoted \"Y\" using a notation derived from that used for falling factorial powers, since if \"X\" and \"Y\" are finite sets with respectively \"m\" and \"n\" elements, the number of injections from \"X\" to \"Y\" is \"n\" (see the twelvefold way).\n\nA function \"f\" that is not injective is sometimes called many-to-one. However, the injective terminology is also sometimes used to mean \"single-valued\", i.e., each argument is mapped to at most one value.\n\nA monomorphism is a generalization of an injective function in category theory.\n\nLet \"f\" be a function whose domain is a set \"X\". The function \"f\" is said to be injective provided that for all \"a\" and \"b\" in \"X\", whenever , then ; that is, implies .  Equivalently, if , then .\n\nSymbolically,\n\nwhich is logically equivalent to the contrapositive,\n\n\nMore generally, when \"X\" and \"Y\" are both the real line R, then an injective function is one whose graph is never intersected by any horizontal line more than once. This principle is referred to as the \"horizontal line test\".\n\nFunctions with left inverses are always injections. That is, given , if there is a function such that, for every ,\n\nthen \"f\" is injective. In this case, \"g\" is called a retraction of \"f\". Conversely, \"f\" is called a section of \"g\".\n\nConversely, every injection \"f\" with non-empty domain has a left inverse \"g\", which can be defined by fixing an element \"a\" in the domain of \"f\" so that \"g\"(\"x\") equals the unique preimage of \"x\" under \"f\" if it exists and \"g\"(\"x\") = \"a\" otherwise. \n\nThe left inverse \"g\" is not necessarily an inverse of \"f\" because the composition in the other order, , may differ from the identity on \"Y\". In other words, an injective function can be \"reversed\" by a left inverses, but is not necessarily invertible, which requires that the function is bijective.\n\nIn fact, to turn an injective function into a bijective (hence invertible) function, it suffices to replace its codomain \"Y\" by its actual range . That is, let such that for all \"x\" in \"X\"; then \"g\" is bijective. Indeed, \"f\" can be factored as , where is the inclusion function from \"J\" into \"Y\".\n\nMore generally, injective partial functions are called partial bijections.\n\n\n\nA proof that a function \"f\" is injective depends on how the function is presented and what properties the function holds.\nFor functions that are given by some formula there is a basic idea.\nWe use the contrapositive of the definition of injectivity, namely that if , then .\n\nHere is an example:\n\nProof: Let . Suppose . So ⇒ ⇒ . Therefore, it follows from the definition that \"f\" is injective.\n\nThere are multiple other methods of proving that a function is injective. For example, in calculus if \"f\" is a differentiable function defined on some interval, then it is sufficient to show that the derivative is always positive or always negative on that interval. In linear algebra, if \"f\" is a linear transformation it is sufficient to show that the kernel of \"f\" contains only the zero vector. If \"f\" is a function with finite domain it is sufficient to look through the list of images of each domain element and check that no image occurs twice on the list.\n\n\n\n"}
{"id": "555881", "url": "https://en.wikipedia.org/wiki?curid=555881", "title": "Innocence", "text": "Innocence\n\nInnocence is a lack of guilt, with respect to any kind of crime, or wrongdoing. In a legal context, innocence is to the lack of legal guilt of an individual, with respect to a crime. In other contexts, it is a lack of experience.\n\nInnocence can imply lesser experience in either a relative view to social peers, or by an absolute comparison to a more common normative scale. In contrast to \"ignorance\", it is generally viewed as a positive term, connoting an optimistic view of the world, in particular one where the lack of knowledge stems from a lack of wrongdoing, whereas greater knowledge comes from doing wrong. This connotation may be connected with a popular false etymology explaining \"innocent\" as meaning \"not knowing\" (Latin \"noscere\" (To know, learn)). The actual etymology is from general negation prefix \"in-\" and the Latin \"nocere\", \"to harm\".\n\nPeople who lack the mental capacity to understand the nature of their acts may be regarded as innocent regardless of their behavior. From this meaning comes the usage of \"innocent\" as a noun to refer to a child under the age of reason, or a person, of any age, who is severely mentally disabled. “Nonetheless, the word, innocence, is used to describe childhood innocence as a notion created and controlled by adults. As Jean-Jacques Rousseau describes 'childhood as a time of innocence' where children are 'not-knowing' and must reach the age of reason to become competent people in society. However, this is not the case anymore as technology advances, this has given children in the contemporary world a platform where they are referred to as 'digital natives', where they are seen more knowledgeable than adults Furthermore, because of digital media and internet, young people have become well-informed of the world around and have a better understanding.\n\nIn some cases, the term \"innocence\" has a pejorative meaning, where an assumed level of experience dictates common discourse or baseline qualifications for entry into another, different, social experience. Since experience is a prime factor in determining a person's point of view, innocence is often also used to imply naiveté or lack of personal experience.\n\nThe lamb is a commonly used symbol of innocence's nature. In Christianity, for example, Jesus is referred to as the \"Lamb of God\", thus emphasizing his sinless nature. Other symbols of innocence include children, virgins, acacia branches (especially in Freemasonry), non-sexual nudity, songbirds and the color white (biblical paintings and Hollywood films depict Jesus wearing a white tunic).\n\nA \"loss of innocence\" is a common theme in fiction, pop culture, and realism. It is often seen as an integral part of coming of age. It is usually thought of as an experience or period in a person's life that leads to a greater awareness of evil, pain and/or suffering in the world around them. Examples of this theme include songs like \"American Pie\", poetry like William Blake's collection Songs of Innocence and of Experience and novels like \"To Kill a Mockingbird\", \"The Catcher in the Rye\", \"A Farewell to Arms\", and \"Lord of the Flies\".\n\nBy contrast, the \"I Ching\" urges a recovery of innocence - the name given to Hexagram 25 - and \"encourages you to \"actively practice innocence\"\".\n\nInnocence could also be viewed as a Westernized view of childhood, and the \"loss\" of innocence is simply a social construction or viewed as the dominant ideology. Thinkers such as Jean-Jaques Rousseau used the romanticism discourse as a way to separate children from adults. Ideas surrounding childhood and childhood innocence stems from this discourse. It was during the 19th century when childhood became synonymous with \"innocence\", however not all children were considered to be innocent during that time, as it was highly dependent on the colour of one's skin. The term innocence being connected to \"white childhood\" was a way to racialize childhood and exclude the non-whites not only from \"innocence\" but from childhood as well.\n\nThe psychoanalytic tradition is broadly divided between those (like Fairbairn and Winnicott) who saw the child as initially innocent, but liable to lose its innocence under the impact of stress or psychological trauma; and those (like Freud and Klein) who see the child as \"developing\" innocence - maturing into it - as a result of surmounting the Oedipus complex and/or the depressive position.\n\nMore eclectically, Eric Berne saw the Child ego state, and its vocabulary, as reflecting three different possibilities: the cliches of conformity; the obscenities of revolt; and \"the sweet phrases of charming innocence\". In a rather different formulation, Christopher Bollas used the term 'Violent Innocence' to describe a fixed and obdurate refusal to acknowledge the existence of an alternative viewpoint - something akin to what he calls \"the fascist construction, the outcome is to empty the mind of all opposition\".\n\n\n"}
{"id": "24234345", "url": "https://en.wikipedia.org/wiki?curid=24234345", "title": "Jack Gladstone", "text": "Jack Gladstone\n\nJack Gladstone was a Guianese slave who led the Demerara Slave rebellion of 1823, one of the biggest slave revolts in the British colonies.\n\nHe was tried after the rebellion, and was deported.\n\nJack and his father, Quamina, an African-born enslaved carpenter, lived and worked on Success plantation in Demerara. He is surnamed Gladstone, as the enslaved adopted surnames of their masters by convention. Sir John Gladstone, who had never set foot on his plantation, had acquired half share in the plantation in 1812 through mortgage default; he acquired the remaining half four years later. Until 1828, the estate was entrusted to Frederick Cort, who was fired for being \"an idler and a deceiver\" who had mismanaged one estate after another.\n\nJack was a cooper on the plantation. As a slave who did not work under a driver, he enjoyed considerable freedom to roam about. He was a free spirit, and passionate man who despised limitations on his freedom; he was aware of the debate about slavery in Britain, and was made extremely listless by rumours of emancipation papers arriving from London. Jack was tall and debonair, and possessed \"European features\" — he stood at six feet two inches, was intelligent, and had a reputation as a \"wild fellow\". Jack had been baptised, was occasionally a \"teacher\", but was not a regular churchgoer because he was too restless to follow church rules. He had taken Susanna, a slave on \"Le Resouvenir\" who was on Rev. Smith's congregation, to his wife. However, in April 1812, Quamina had found out that she had become the mistress of John Hamilton, the manager at 'Le Resouvenir'. Rev. Smith reacted angrily, and she was expelled her from the flock by unanimous vote when she had refused to terminate the relationship. When Susanna left, Jack married a slave on Chateau Margo plantation, but would continue to have relations with several other women on the same plantation, to the disdain of both the owner of Margo and the manager at Success.\n\nDa Costa puts Jack's age at around 30 at the time of the rebellion. Following the arrival of news from Britain that measures aimed at improving the treatment of slaves in the colonies had been passed, Jack had heard a rumour that their masters had received instructions to set them free but were refusing to do so. He wrote a letter (signing his father's name) to the members of the chapel informing them of the \"new law\". Meanwhile, his father Quamina supported the idea of a peaceful strike, and made the fellow slaves promise not to use violence. Jack led tens of thousands of slaves to raise up against their masters. The very low number of white deaths is proof that the uprising was largely peaceful – Plantation owners, managers and their families were locked up and not harmed. After the slaves' defeat in a major battle at \"Bachelor's Adventure\", Jack fled into the woods. A \"handsome reward\" of one thousand guilder was offered for his capture. Jack and Quamina remained at large until Jack and his wife were captured by Capt. McTurk at \"Chateau Margo\". Leading up to it, McTurk had received information on 6 September from a slave about Jack's whereabouts; there was a three-hour standoff. Quamina evaded capture for several days longer. At its end, and the slaves' defeat, hundreds of slaves were executed as ringleaders, including Quamina. Jack Gladstone was sold and deported to Saint Lucia. His legacy was to help bring attention to the plight of sugar plantation slaves, accelerating the abolition of slavery.\n\n\n"}
{"id": "35454200", "url": "https://en.wikipedia.org/wiki?curid=35454200", "title": "Kanban board", "text": "Kanban board\n\nA Kanban board is one of the tools that can be used to implement Kanban to manage work at the personal or organizational level.\n\nKanban boards show how work moves from left to right, with each column representing a stage of the overall process, or to be more precise the system that is visualized by the board. The team pulls cards from one column to another to the right to show progress, and to coordinate their efforts with others.\n\nKanban boards can be used in knowledge work or for manufacturing process. \n\nAt its simplest, boards are usually divided into \"waiting\", \"work in progress\" and \"completed work\". Complex Kanban boards can be created that visualise the flow of work across a whole value stream map.\n\nKanban can be used to organize many areas of an organization and can be designed accordingly. The simplest kanban board consists of three columns: \"to-do\", \"in progress\" and \"done\", while some additional detail such as WiP limits are needed to fully support the Kanban Method. Business functions that use kanban boards include:\n\n\n\n"}
{"id": "47439118", "url": "https://en.wikipedia.org/wiki?curid=47439118", "title": "Kinetic diagram", "text": "Kinetic diagram\n\nIn dynamics a kinetic diagram is a pictorial device used in analyzing mechanics problems when there is determined to be a net force and/or moment acting on a body. They are related to and often used with free body diagrams. Similar to a free body diagram they depict a single body with forces and moments acting on it but in contrast they only include the net force and moment rather than all of the forces being considered.\n\nKinetic diagrams are not required to solve dynamics problems; their use in teaching dynamics is argued against by some in favor of other methods that they view as simpler. They appear in some dynamics texts but are absent in others.\n\n"}
{"id": "4663436", "url": "https://en.wikipedia.org/wiki?curid=4663436", "title": "Lavender scare", "text": "Lavender scare\n\nThe lavender scare refers to a witch hunt and the mass firings of homosexual people in the 1950s from the United States government. It contributed to and paralleled the anti-communist campaign known as McCarthyism and the Second Red Scare. Gay men and lesbians were said to be security risks and communist sympathizers, which led to the call to remove them from state employment.\n\nFormer U.S. Senator Alan K. Simpson has written: \"The so-called 'Red Scare' has been the main focus of most historians of that period of time. A lesser-known element ... and one that harmed far more people was the witch-hunt McCarthy and others conducted against homosexuals.\"\n\nThe term for this persecution was popularized by David K. Johnson's 2004 book which studied this anti-homosexual campaign, \"The Lavender Scare.\" The book drew its title from the term \"lavender lads\", used repeatedly by Senator Everett Dirksen as a synonym for homosexual males. In 1952, Dirksen said that a Republican victory in the November elections would mean the removal of \"the lavender lads\" from the State Department. The phrase was also used by \"Confidential\" magazine, a periodical known for gossiping about the sexuality of politicians and prominent Hollywood stars.\n\nIn 1950, the same year that Senator Joseph McCarthy claimed 205 communists were working in the State Department, Undersecretary of State John Peurifoy said that the State Department had allowed 91 homosexuals to resign. On April 19, 1950, the Republican National Chairman Guy George Gabrielson said that \"sexual perverts who have infiltrated our Government in recent years\" were \"perhaps as dangerous as the actual Communists\". The danger was not solely because they were gay though. The homosexuals were considered to be more susceptible to blackmail and thus were labeled as security risks. McCarthy hired Roy Cohnwho would later die of AIDS and was accused of being a closeted homosexualas chief counsel of his Congressional subcommittee. Together, McCarthy and Cohnwith the enthusiastic support of the head of the FBI, J. Edgar Hooverwere responsible for the firing of scores of gay men and women from government employment and strong-armed many opponents into silence using rumors of their homosexuality. In 1953, during the final months of the Truman administration, the State Department reported that it had fired 425 employees for allegations of homosexuality.\n\nMcCarthy often used accusations of homosexuality as a smear tactic in his anti-communist crusade, often combining the Second Red Scare with the Lavender Scare. On one occasion, he went so far as to announce to reporters, \"If you want to be against McCarthy, boys, you've got to be either a Communist or a cocksucker.\" At least one recent history has argued that, in linking communism and homosexuality and psychological imbalance, McCarthy was employing guilt-by-association if evidence for communist activity was lacking.\n\nIn 1953 President Dwight D. Eisenhower signed Executive Order 10450, which set security standards for federal employment and barred homosexuals from working in the federal government. The restrictions set in place were cause for hundreds of gay people to be forcibly outed and fired from the State Department. The executive order was also the cause for the firing of approximately 5,000 gay people from federal employment; this included private contractors and military personnel. Not only did the victims lose their jobs, but also they were forced out of the closet and thrust into the public eye as lesbian or gay. Executive Order 10450 stayed on paper and in effect until 1995 when President Bill Clinton rescinded the order and put in place the \"Don't ask, don't tell\" policy for admittance of gays into the military.\n\nBoth homosexuals and Communist Party members were seen as subversive elements in American society who all shared the same ideals of antitheism, rejection of bourgeois culture and middle-class morality, lack of conformity; they were scheming and manipulative and, most importantly, would put their own agendas above others in the eyes of the general population. McCarthy also associated homosexuality and communism as \"threats to the 'American way of life'.\" Homosexuality was directly linked to security concerns, and more government employees were dismissed because of their homosexual sexual orientation than because they were left-leaning or communist. George Chauncey noted that: \"The specter of the invisible homosexual, like that of the invisible communist, haunted Cold War America,\" and homosexuality (and by implication homosexuals themselves) were constantly referred to not only as a disease, but also as an invasion, like the perceived danger of communism and subversives.\n\nSenator Kenneth Wherry similarly attempted to invoke a connection between homosexuality and anti-nationalism. He said in an interview with Max Lerner that: \"You can't hardly separate homosexuals from subversives.\" Later in that same interview, he drew the line between patriotic Americans and gay men: \"But look Lerner, we're both Americans, aren't we? I say, let's get these fellows [closeted gay men in government positions] out of the government.\"\n\nWhile the Mattachine Society was founded by Harry Hay, a former member of the Communist Party USA, Hay resigned from the society when the membership condemned his politics as a threat to the organization he had founded.\n\nThe Subcommittee on Investigations was a subcommittee of the Committee on Expenditures in Executive Departments. This subcommittee led by Senator Clyde R. Hoey from 1949-1952 investigated \"the employment of homosexuals in the Federal workforce.\" A related report, known as the Hoey Report, stated that all of the government's intelligence agencies \"are in complete agreement that sex perverts in Government constitute security risks.\"\n\nWashington D.C. had a fairly large and active gay community before McCarthy launched his witch hunt campaign against homosexuals, but as time went on and the climate of the Cold War spread, so too did the negative views of homosexuals. Because social attitudes toward homosexuality were overwhelmingly negative and the psychiatric community regarded homosexuality as a mental disorder, gay men and lesbians were considered susceptible to blackmail, thus constituting a security risk. U.S. government officials assumed that communists would blackmail homosexual employees of the federal government to provide them classified information rather than risk exposure. The 1957 Crittenden Report of the United States Navy Board of Inquiry concluded that there was \"no sound basis for the belief that homosexuals posed a security risk\" and criticized the prior Hoey Report: \"No intelligence agency, as far as can be learned, adduced any factual data before that committee with which to support these opinions\" and said that \"the concept that homosexuals necessarily pose a security risk is unsupported by adequate factual data.\" The Crittenden Report remained secret until 1976. Navy officials claimed they had no record of studies of homosexuality, but attorneys learned of its existence and obtained it through a Freedom of Information Act request. As of September 1981, the Navy claimed it was still unable to fulfill a request for the Report's supporting documentation.\n\nAccording to John Loughery, author of a study of gay identity in the 20th century, \"few events indicate how psychologically wracked America was becoming in the 1950s ... than the presumed overlap of the Communist and the homosexual menace.\"\n\nThe research of Evelyn Hooker, presented in 1956, and the first conducted without a polluted sample (gay men who had been treated for mental illness) dispelled the illusory correlation between homosexuality and mental illness that prior research, conducted with polluted sampling, had established. Hooker presented a team of three expert evaluators with 60 unmarked psychological profiles from her year of research. She chose to leave the interpretation of her results to others, to avoid potential bias. The evaluators concluded that in terms of adjustment, there were no differences between the members of each group. Her demonstration that it is not an illness led the way to the eventual removal of homosexuality from the American Psychiatric Association's Diagnostic and Statistical Manual of Mental Disorders.\n\nOne of the first and most influential members of the gay rights movements, Frank Kameny, was thrust into unemployment because of his sexual orientation in 1957. He was working as an astronomer for the United States Army Map Service, but was fired as a result of the Lavender Scare and could never find another job in the United States federal government again. This led to Kameny devoting his life to the gay rights movement, which in some ways he began. In 1965, four years before the Stonewall Riots, Kameny picketed the White House on the grounds of gay rights.\n\nAccording to Lillian Faderman, the LGBT community formed a subculture of its own in this era, constituting \"not only a choice of sexual orientation, but of social orientation as well.\" The Mattachine Society and the Daughters of Bilitis, which formed the homophile movements of the U.S., were in many ways defined by McCarthyism and the lavender scare. They were underground organizations that maintained the anonymity of their members.\n\nThough the main vein of McCarthyism ended in the mid-1950s when the 1956 \"Cole v Young\" ruling severely weakened the ability to fire people from the federal government for discriminatory reasons, the movement that was born from it, the Lavender Scare, lived on. One such way was that Executive Order 10450, which was not rescinded until 1995, continued to bar gays from entering the military. Another form of the Lavender Scare that persisted was the Florida Legislative Investigation Committee, also referred to as the FLIC and the Johns Committee. The FLIC was founded in 1956 and was not disbanded until 1964. The purpose of the committee was to operate within Florida continuing the work of the Lavender Scare by investigating and firing public school teachers who were gay. During its active years the FLIC was responsible for more than 200 firings of alleged gay teachers. The FLIC was disbanded following the release of the Purple Pamphlet due to public outrage over its explicit and pornographic nature.\n\nIn January 2017, the State Department formally apologized.\n\n\"The Lavender Scare,\" directed by Josh Howard, is a documentary film that recounts the events of the Lavender Scare. David K. Johnson is part of the project as the movie is based on his book. To help with funding, Josh Howard created a Kickstarter that met its goal in donations. The film was completed in 2016 and began screenings in film festivals around the country.\n\n\n"}
{"id": "38646474", "url": "https://en.wikipedia.org/wiki?curid=38646474", "title": "List of peace activists", "text": "List of peace activists\n\nThis list of peace activists includes people who have proactively advocated diplomatic, philosophical, and non-military resolution of major territorial or ideological disputes through nonviolent means and methods. Peace activists usually work with others in the overall anti-war and peace movements to focus the world's attention on what they perceive to be the irrationality of violent conflicts, decisions, and actions. They thus initiate and facilitate wide public dialogues intended to nonviolently alter long-standing societal agreements directly relating to, and held in place by, the various violent, habitual, and historically fearful thought-processes residing at the core of these conflicts, with the intention of peacefully ending the conflicts themselves.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "1110742", "url": "https://en.wikipedia.org/wiki?curid=1110742", "title": "Multiplicative group", "text": "Multiplicative group\n\nIn mathematics and group theory, the term multiplicative group refers to one of the following concepts:\n\n\n\nThe group scheme of \"n\"-th roots of unity is by definition the kernel of the \"n\"-power map on the multiplicative group GL(1), considered as a group scheme. That is, for any integer \"n\" > 1 we can consider the morphism on the multiplicative group that takes \"n\"-th powers, and take an appropriate fiber product of schemes, with the morphism \"e\" that serves as the identity.\n\nThe resulting group scheme is written μ. It gives rise to a reduced scheme, when we take it over a field \"K\", if and only if the characteristic of \"K\" does not divide \"n\". This makes it a source of some key examples of non-reduced schemes (schemes with nilpotent elements in their structure sheaves); for example μ over a finite field with \"p\" elements for any prime number \"p\". \n\nThis phenomenon is not easily expressed in the classical language of algebraic geometry. It turns out to be of major importance, for example, in expressing the duality theory of abelian varieties in characteristic \"p\" (theory of Pierre Cartier). The Galois cohomology of this group scheme is a way of expressing Kummer theory.\n\n\n"}
{"id": "1082108", "url": "https://en.wikipedia.org/wiki?curid=1082108", "title": "Non-rigid designator", "text": "Non-rigid designator\n\nIn the philosophy of language and modal logic, a term is said to be a non-rigid designator (or flaccid designator) or connotative term if it does not extensionally designate (denote, refer to) the same object in all possible worlds. This is in contrast to a rigid designator, which does designate the same object in all possible worlds in which that object exists, and does not designate anything else in those worlds in which that object does \"not\" exist. The term was coined by Saul Kripke in his 1970 lecture series at Princeton University, later published as the book \"Naming and Necessity\".\n\nAs an example, consider the phrase \"The 43rd President of the United States of America\": while the 43rd President of the United States is \"actually\" George W. Bush, things might have been different. Bush might have lost the election, meaning that the 43rd President might have been Al Gore or Ralph Nader instead. (\"How remote\" these possible worlds are from the actual world is a discussion for physics and counterfactualism.) \"The 43rd President of the United States of America\" is thus a non-rigid designator, picking out George W. Bush in some possible worlds, Al Gore in others, and yet other people in other worlds.\n\nNon-rigid designators are defined by contrast with Kripke's notion of a rigid designator, which picks out the same thing uniquely in \"every\" possible world; while there are possible worlds in which the 43rd President of the United States is Al Gore instead of George W. Bush, there are \"no\" possible worlds where \"George W. Bush\" is anyone other than the man who, in fact, he is. (There \"are\" worlds where some person other than George W. Bush is \"named\" \"George W. Bush,\" but that's neither here nor there.) Kripke uses this apparent asymmetry to argue (in \"Naming and Necessity\") that no definite description can be the meaning of a proper name, because names must always be rigid designators, while definite descriptions can designate non-rigidly.\n\nSome philosophers, such as Gareth Evans, have expressed doubt as to whether non-rigid expressions ought to be called \"designators\" at all.\n"}
{"id": "48629", "url": "https://en.wikipedia.org/wiki?curid=48629", "title": "Normal space", "text": "Normal space\n\nIn topology and related branches of mathematics, a normal space is a topological space \"X\" that satisfies Axiom T: every two disjoint closed sets of \"X\" have disjoint open neighborhoods. A normal Hausdorff space is also called a T space. These conditions are examples of separation axioms and their further strengthenings define completely normal Hausdorff spaces, or T spaces, and perfectly normal Hausdorff spaces, or T spaces.\n\nA topological space \"X\" is a normal space if, given any disjoint closed sets \"E\" and \"F\", there are neighbourhoods \"U\" of \"E\" and \"V\" of \"F\" that are also disjoint. More intuitively, this condition says that \"E\" and \"F\" can be separated by neighbourhoods.\n\nA T space is a T space \"X\" that is normal; this is equivalent to \"X\" being normal and Hausdorff.\n\nA completely normal space or a is a topological space \"X\" such that every subspace of \"X\" with subspace topology is a normal space. It turns out that \"X\" is completely normal if and only if every two separated sets can be separated by neighbourhoods.\n\nA completely T space, or T space is a completely normal T space topological space \"X\", which implies that \"X\" is Hausdorff; equivalently, every subspace of \"X\" must be a T space.\n\nA perfectly normal space is a topological space \"X\" in which every two disjoint closed sets \"E\" and \"F\" can be precisely separated by a continuous function \"f\" from \"X\" to the real line R: the preimages of {0} and {1} under \"f\" are, respectively, \"E\" and \"F\". (In this definition, the real line can be replaced with the unit interval [0,1].)\n\nIt turns out that \"X\" is perfectly normal if and only if \"X\" is normal and every closed set is a \"G\" set. Equivalently, \"X\" is perfectly normal if and only if every closed set is a zero set. Every perfectly normal space is automatically completely normal.\n\nA Hausdorff perfectly normal space \"X\" is a T space, or perfectly T space.\n\nNote that the terms \"normal space\" and \"T\" and derived concepts occasionally have a different meaning. (Nonetheless, \"T\" always means the same as \"completely T\", whatever that may be.) The definitions given here are the ones usually used today. For more on this issue, see History of the separation axioms.\n\nTerms like \"normal regular space\" and \"normal Hausdorff space\" also turn up in the literature – they simply mean that the space both is normal and satisfies the other condition mentioned. In particular, a normal Hausdorff space is the same thing as a T space. Given the historical confusion of the meaning of the terms, verbal descriptions when applicable are helpful, that is, \"normal Hausdorff\" instead of \"T\", or \"completely normal Hausdorff\" instead of \"T\".\n\nFully normal spaces and fully T spaces are discussed elsewhere; they are related to paracompactness.\n\nA locally normal space is a topological space where every point has an open neighbourhood that is normal. Every normal space is locally normal, but the converse is not true. A classical example of a completely regular locally normal space that is not normal is the Nemytskii plane.\n\nMost spaces encountered in mathematical analysis are normal Hausdorff spaces, or at least normal regular spaces:\n\nAlso, all fully normal spaces are normal (even if not regular). Sierpinski space is an example of a normal space that is not regular.\n\nAn important example of a non-normal topology is given by the Zariski topology on an algebraic variety or on the spectrum of a ring, which is used in algebraic geometry.\n\nA non-normal space of some relevance to analysis is the topological vector space of all functions from the real line R to itself, with the topology of pointwise convergence.\nMore generally, a theorem of A. H. Stone states that the product of uncountably many non-compact metric spaces is never normal.\n\nEvery closed subset of a normal space is normal. The continuous and closed image of a normal space is normal.\n\nThe main significance of normal spaces lies in the fact that they admit \"enough\" continuous real-valued functions, as expressed by the following theorems valid for any normal space \"X\".\n\nUrysohn's lemma:\nIf \"A\" and \"B\" are two disjoint closed subsets of \"X\", then there exists a continuous function \"f\" from \"X\" to the real line R such that \"f\"(\"x\") = 0 for all \"x\" in \"A\" and \"f\"(\"x\") = 1 for all \"x\" in \"B\".\nIn fact, we can take the values of \"f\" to be entirely within the unit interval [0,1].\n\nMore generally, the Tietze extension theorem:\nIf \"A\" is a closed subset of \"X\" and \"f\" is a continuous function from \"A\" to R, then there exists a continuous function \"F\": \"X\" → R which extends \"f\" in the sense that \"F\"(\"x\") = \"f\"(\"x\") for all \"x\" in \"A\".\n\nIf U is a locally finite open cover of a normal space \"X\", then there is a partition of unity precisely subordinate to U.\n\nIn fact, any space that satisfies any one of these three conditions must be normal.\n\nA product of normal spaces is not necessarily normal. This fact was first proved by Robert Sorgenfrey. An example of this phenomenon is the Sorgenfrey plane. Also, a subset of a normal space need not be normal (i.e. not every normal Hausdorff space is a completely normal Hausdorff space), since every Tychonoff space is a subset of its Stone–Čech compactification (which is normal Hausdorff). A more explicit example is the Tychonoff plank. The only large class of product spaces of normal spaces known to be normal are the products of compact Hausdorff spaces, since both compactness (Tychonoff's theorem) and the axiom are preserved under arbitrary products.\n\nIf a normal space is R, then it is in fact completely regular.\nThus, anything from \"normal R\" to \"normal completely regular\" is the same as what we usually call \"normal regular\".\nTaking Kolmogorov quotients, we see that all normal T spaces are Tychonoff.\nThese are what we usually call \"normal Hausdorff\" spaces.\n\nA topological space is said to be pseudonormal if given two disjoint closed sets in it, one of which is countable, there are disjoint open sets containing them. Every normal space is pseudonormal, but not vice versa.\n\nCounterexamples to some variations on these statements can be found in the lists above.\nSpecifically, Sierpinski space is normal but not regular, while the space of functions from R to itself is Tychonoff but not normal.\n\n"}
{"id": "16568500", "url": "https://en.wikipedia.org/wiki?curid=16568500", "title": "Overall labor effectiveness", "text": "Overall labor effectiveness\n\nOverall labor effectiveness (OLE) is a key performance indicator (KPI) that measures the utilization, performance, and quality of the workforce and its impact on productivity.\n\nSimilar to overall equipment effectiveness (OEE), OLE measures availability, performance, and quality.\n\nOLE allows manufacturers to make operational decisions by giving them the ability to analyze the cumulative effect of these three workforce factors on productive output, while considering the impact of both direct and indirect labor.\nOLE supports Lean and Six Sigma methodologies and applies them to workforce processes, allowing manufacturers to make labor-related activities more efficient, repeatable and impactful.\n\nThere are many factors that influence workforce availability and therefore the potential output of equipment and the manufacturing plant. OLE can help manufacturers be sure that they have the person with the right skills available at the right time by enabling manufacturers to locate areas where providing and scheduling the right mix of employees can increase the number of productive hours. OLE also accounts for labor utilization. Understanding where downtime losses are coming from and the impact they have on production can reveal root causes—which can include machine downtime, material delays, or absenteeism—that delay a line startup.\n\nCalculation: Availability = Time operators are working productively / Time scheduled\nExample:\nTwo employees (workforce) are scheduled to work 8 hour (480 minutes) shifts.\nThe normal shift includes a scheduled 30 minute break.\nThe employees experience 60 minutes of unscheduled downtime.\nScheduled Time = 960 min − 60 min break = 900 Min\nAvailable Time = 900 min Scheduled − 120 min Unscheduled Downtime = 780 Min\nAvailability = 780 Avail Min / 900 Scheduled Min = 86.67%\n\nWhen employees cannot perform their work within standard times, performance can suffer. Effective training can increase performance by improving the skills that directly impact the quality of output. A skilled operator knows how to measure work, understands the impacts of variability, and knows to stop production for corrective actions when quality falls below specified limits. Accurately measuring this metric with OLE can pinpoint performance improvement opportunities down to the individual level.\n\nCalculation: Performance = Actual output of the operators / the expected output (or labor standard)\nExample:\nTwo employees (workforce) are scheduled to work an 8-hour (480 minute) shift with a 30-minute scheduled break.\nAvailable Time = 960 min − 60 min break − 120 min Unscheduled Downtime = 780 Min\n\nThe Standard Rate for the part being produced is 60 Units/Hour or 1 Minute/Unit\nThe Workforce produces 700 Total Units during the shift.\nTime to Produce Parts = 700 Units * 1 Minutes/Unit = 700 Minutes\nPerformance = 700 minutes / 780 minutes = 89.74 %\n\nA number of drivers contribute to quality, but the effort to improve quality can result in a lowering of labor performance. When making the correlation between the workforce and quality it is important to consider factors such as the training and skills of employees, whether they have access to the right tools to follow procedures, and their understanding of how their roles drive and impact quality. OLE can help manufacturers analyze shift productivity down to a single-shift level, and determine which individual workers are most productive, and then identify corrective actions to bring operations up to standards.\n\nCalculation: Quality = Saleable parts / Total parts produced\nExample:\nTwo employees (workforce) produce 670 Good Units during a shift.\n700 Units were started in order to produce the 670 Good Units.\nQuality = 670 Good Units / 700 Units Started = 95.71%\n\nEffective use of OLE uncovers the data that fuels root-cause analysis and points to corrective actions. Likewise, OLE exposes trends that can be used to diagnose more subtle problems. It also helps managers understand whether corrective actions did, in fact, solve problems and improve overall productivity.\n\nExample:\nCalculation: OLE = Availability x Performance x Quality\nExample:\nA workforce experiences...\nAvailability of 87%\nThe Work Center Performance is 89.74%.\nWork Center Quality is 96%.\nOLE = 86.67% Availability x 89.74% Performance x 95.71% Quality = 74,44%\n\nThe following table provides examples of the labor information tracked by overall labor effectiveness organized by its major categories. Using this labor information, manufacturers can make operational decisions to improve the cumulative effect of labor availability, performance, and quality.\n\n\n"}
{"id": "51220425", "url": "https://en.wikipedia.org/wiki?curid=51220425", "title": "P. Gopinathan Nair", "text": "P. Gopinathan Nair\n\nPadmanabha Pillai Gopinathan Nair is an Indian social worker, Gandhian, independence activist and the chairman of Mahatma Gandhi National Memorial Trust, popularly known as \"Gandhi Smarak Nidhi\", a trust managed by the Government of India. He participated in the Quit India movement of 1942 and worked alongside Vinoba Bhave to promote Bhoodan and Gramdan movements. He is the initiator of the \"camp movement\", a student program, as a part of the \"Construction Movement\" of Mahatma Gandhi. He is a recipient of the Jamnalal Bajaj Award, among other honors. The Government of India awarded him the fourth highest civilian honour of the Padma Shri, in 2016, for his contributions to society.\n\nGopinathan Nair was born on 7 July 1922 to M. Padmanabha Pillai and K. P. Janaki Amma in Neyyattinkara, a town in the southern part of Thiruvananthapuram district of the south Indian state of Kerala. After completing his school education at the Government High School, Neyyattinkara, he did his graduate studies in science at the University College, Thiruvananthapuram and it was during this period, he participated in the Quit India movement. In 1944, he founded \"Trivandrum Students Settlement\" gathering 35 students, inspired by the \"Construction movement\" of Mahatma Gandhi. In 1946, he became the Chief Tattwa Pracharak of the Kerala Gandhi Smarak Nidhi and conducted several courses for his colleagues as well as other students. The same year, he joined Shantiniketan for further studies in Chinese culture and Gandhian philosophy and returned to his home town after the completion of the course. For the next decade and a half, he organized several camps for training people and carried out constructive work such as roads and sanitation facilities and organized people for Bhoodan and Gramdan activities. When Vinoba Bhave visited Kerala as a part of his \"Padayatra\", Nair organized a meeting in Kalady. He also became associated with Shanti Sena and was involved in many of its activities. He was reported to have been active during the naxalite insurgency in Kilimanoor in 1970, the Hindu-Muslim communal riots in Thalassery, the East Bengali refugee crisis of 1971 and Kuttanad Peace Project of 1971–76. He also served as the chair of the \"Sarva Seva Sangh\" in 1989 and was the convenor of the Cow Protection Committee in Kerala when Bhave campaigned against slaughter of cows. In the aftermath of the Marad massacre of 2002, A. K. Antony, the then chief minister of Kerala requested Nair's assistance in mediating between the warring factions and he was reported to have been successful in his efforts.\n\nNair, who has written several articles on Gandhian thought, has been associated with Gandhi Smarak Nidhi in various positions, held the post of the secretary of the Kerala chapter during 1980–82 and is the incumbent national president of Gandhi Smarak Nidhi, besides heading the Kerala chapter since 1999. He is a life member and a member of the governing board of the \"Gandhi Peace Foundation\" and a former president of the All India Sarva Seva Sangham, Varanasi (6 years) and Sevagram, Wardha (11 years). He is the chairman and patron of the Noorul Islam Civil Service Academy and a member of \"Sree Uthradam Thirunal Institute Of Culture\", Thiruvananthapuram He is married to L. Saraswathi Amma, a retired State Women’s Welfare officer, and the couple lives in Neyyattinkara.\n\nNair received the Social Service Award of the Stallions International in 2003 and he was selected for the Jamnalal Bajaj Award in 2005, for his constructive social service. The University of Calicut honored him for his services to Gandhian studies in 2005 and the University of Kerala felicitated him on 24 April 2012, when he was elected as the national president of Gandhi Smarak Nidhi. The Government of India awarded him the civilian honor of the Padma Shri in 2016, though the original recommendation of the state government was for the higher award of the Padma Bhushan. The Department of Information and Public Relations of the Government of Kerala and the state chapter of Gandhi Smarak Nidhi jointly organized a photo exhibition at Gandhi Bhavan, Thiruvananthapuram, featuring various photographs from Nair's life, in connection with his 95th birthday celebrations. The exhibition, besides the photographs, also had several write-ups on him as exhibits. Noorul Islam Civil Service Academy of the NIMS Charity Trust, where he is the patron, was renamed as \"P. Gopinathan Nair Civil Service Training Academy\" in his honor in 2011, in connection with his 90th birthday celebrations. His life has been documented in a 30-minute documentary film, directed Rajan V, Pozhiyoor, the secretary of Thikkurissi Foundation and produced by the Media Research Institute, Thiruvananthapuram. His biography has also been published under the title, \"Gandhian Karmapadhangalil\" (Along the Gandhian Paths).\n\n\n"}
{"id": "300628", "url": "https://en.wikipedia.org/wiki?curid=300628", "title": "Persistent vegetative state", "text": "Persistent vegetative state\n\nA persistent vegetative state (PVS) is a disorder of consciousness in which patients with severe brain damage are in a state of partial arousal rather than true awareness. After four weeks in a vegetative state (VS), the patient is classified as in a persistent vegetative state. This diagnosis is classified as a \"permanent vegetative state\" some months (3 in the US and 6 in the UK) after a non-traumatic brain injury or one year after a traumatic injury. Nowadays, more doctors and neuroscientists prefer to call the state of consciousness an\"syndrome\", primarily because of ethical questions about whether a patient can be called \"vegetative\" or not.\n\nThere are several definitions that vary by technical versus layman's usage. There are different legal implications in different countries.\n\nA wakeful unconscious state that lasts longer than a few weeks is referred to as a persistent (or 'continuing') vegetative state.\n\nUnlike brain death, permanent vegetative state (PVS) is recognized by \"statute law\" as death in very few legal systems. In the US, courts have required petitions before termination of life support that demonstrate that any recovery of cognitive functions above a vegetative state is assessed as impossible by authoritative medical opinion. In England and Wales the legal precedent for withdrawal of clinically assisted nutrition and hydration in cases of patients in a PVS was set in 1993 in the case of Tony Bland, who sustained catastrophic anoxic brain injury in the 1989 Hillsborough disaster. An application to the Court of Protection is no longer required before nutrition and hydration can be withdrawn or withheld from PVS (or 'minimally conscious' - MCS) patients.\n\nThis legal grey area has led to vocal advocates that those in PVS should be allowed to die. Others are equally determined that, if recovery is at all possible, care should continue. The existence of a small number of diagnosed PVS cases that have eventually resulted in improvement makes defining recovery as \"impossible\" particularly difficult in a legal sense. This legal and ethical issue raises questions about autonomy, quality of life, appropriate use of resources, the wishes of family members, and professional responsibilities.\n\nThe vegetative state is a chronic or long-term condition. This condition differs from a coma: a coma is a state that lacks both awareness and wakefulness. Patients in a vegetative state may have awoken from a coma, but still have not regained awareness. In the vegetative state patients can open their eyelids occasionally and demonstrate sleep-wake cycles, but completely lack cognitive function. The vegetative state is also called a \"coma vigil\". The chances of regaining awareness diminish considerably as the time spent in the vegetative state increases.\n\nPersistent vegetative state is the standard usage (except in the UK) for a medical diagnosis, made after numerous neurological and other tests, that due to extensive and irreversible brain damage a patient is \"highly unlikely\" ever to achieve higher functions above a vegetative state. This diagnosis does not mean that a doctor has diagnosed improvement as impossible, but does open the possibility, in the US, for a judicial request to end life support. Informal guidelines hold that this diagnosis can be made after four weeks in a vegetative state. US caselaw has shown that successful petitions for termination have been made after a diagnosis of a persistent vegetative state, although in some cases, such as that of Terri Schiavo, such rulings have generated widespread controversy.\n\nIn the UK, the term 'persistent vegetative state' is discouraged in favor of two more precisely defined terms that have been strongly recommended by the Royal College of Physicians (RCP). These guidelines recommend using a continuous vegetative state for patients in a vegetative state for more than four weeks. A medical definition of a permanent vegetative state can be made if, after exhaustive testing and a customary 12 months of observation, a medical diagnosis that it is \"impossible\" by any informed medical expectations that the mental condition will ever improve. Hence, a \"continuous vegetative state\" in the UK may remain the diagnosis in cases that would be called \"persistent\" in the US or elsewhere.\n\nWhile the actual testing criteria for a diagnosis of \"permanent\" in the UK are quite similar to the criteria for a diagnosis of \"persistent\" in the US, the semantic difference imparts in the UK a \"legal\" presumption that is commonly used in court applications for ending life support. The UK diagnosis is generally only made after 12 months of observing a static vegetative state. A diagnosis of a persistent vegetative state in the US usually still requires a petitioner to prove in court that recovery is impossible by informed medical opinion, while in the UK the \"permanent\" diagnosis already gives the petitioner this presumption and may make the legal process less time-consuming.\n\nIn common usage, the \"permanent\" and \"persistent\" definitions are sometimes conflated and used interchangeably. However, the acronym \"PVS\" is intended to define a \"persistent vegetative state\", without necessarily the connotations of permanence, and is used as such throughout this article.\n\nBryan Jennett, who originally coined the term \"persistent vegetative state\", has now recommended using the UK division between continuous and permanent in his most recent book \"The Vegetative State\". This is one for purposes of precision, on the grounds that \"the 'persistent' component of this term ... may seem to suggest irreversibility\".\n\nThe Australian National Health and Medical Research Council has suggested \"post coma unresponsiveness\" as an alternative term for \"vegetative state\" in general.\n\nMost PVS patients are unresponsive to external stimuli and their conditions are associated with different levels of consciousness. Some level of consciousness means a person can still respond, in varying degrees, to stimulation. A person in a coma, however, cannot. In addition, PVS patients often open their eyes in response to feeding, which has to be done by others; they are capable of swallowing, whereas patients in a coma subsist with their eyes closed (Emmett, 1989).\n\nCerebral cortical function (e.g. communication, thinking, purposeful movement, etc) is lost while brainstem functions (e.g. breathing, maintaining circulation and hemodynamic stability, etc) are preserved.  Non-cognitive upper brainstem functions such as eye-opening, occasional vocalizations (e.g. crying, laughing), maintaining normal sleep patterns, and spontaneous non-purposeful movements often remain intact.   \n\nPVS patients' eyes might be in a relatively fixed position, or track moving objects, or move in a \"disconjugate\" (i.e., completely unsynchronized) manner. They may experience sleep-wake cycles, or be in a state of chronic wakefulness. They may exhibit some behaviors that can be construed as arising from partial consciousness, such as grinding their teeth, swallowing, smiling, shedding tears, grunting, moaning, or screaming without any apparent external stimulus.\n\nIndividuals in PVS are seldom on any life-sustaining equipment other than a feeding tube because the brainstem, the center of vegetative functions (such as heart rate and rhythm, respiration, and gastrointestinal activity) is relatively intact (Emmett, 1989).\n\nMany people emerge spontaneously from a vegetative state within a few weeks. The chances of recovery depend on the extent of injury to the brain and the patient's age – younger patients having a better chance of recovery than older patients. A 1994 report found that of those who were in a vegetative state a month after a trauma, 54% had regained consciousness by a year after the trauma, whereas 28% had died and 18% were still in the vegetative state. But for non-traumatic injuries such as strokes, only 14% had recovered consciousness at one year, 47% had died, and 39% were still vegetative. Patients who were vegetative six months after the initial event were much less likely to have recovered consciousness a year after the event than in the case of those who were simply reported vegetative at one month. A \"New Scientist\" article from 2000 gives a pair of graphs showing changes of patient status during the first 12 months after head injury and after incidents depriving the brain of oxygen. After a year, the chances that a PVS patient will regain consciousness are very low and most patients who do recover consciousness experience significant disability. The longer a patient is in a PVS, the more severe the resulting disabilities are likely to be. Rehabilitation can contribute to recovery, but many patients never progress to the point of being able to take care of themselves.\n\nThere are two dimensions of recovery from a persistent vegetative state: recovery of consciousness and recovery of function. Recovery of consciousness can be verified by reliable evidence of awareness of self and the environment, consistent voluntary behavioral responses to visual and auditory stimuli, and interaction with others. Recovery of function is characterized by communication, the ability to learn and to perform adaptive tasks, mobility, self-care, and participation in recreational or vocational activities. Recovery of consciousness may occur without functional recovery, but functional recovery cannot occur without recovery of consciousness (Ashwal, 1994).\n\nThere are three main causes of PVS (persistent vegetative state):\n\nMedical books (such as Lippincott, Williams, and Wilkins. (2007). In A Page: Pediatric Signs and Symptoms) describe several potential causes of PVS, which are as follows:\n\n\nIn addition, these authors claim that doctors sometimes use the mnemonic device AEIOU-TIPS to recall portions of the differential diagnosis: Alcohol ingestion and acidosis, Epilepsy and encephalopathy, Infection, Opiates, Uremia, Trauma, Insulin overdose or inflammatory disorders, Poisoning and psychogenic causes, and Shock.\n\nDespite converging agreement about the definition of persistent vegetative state, recent reports have raised concerns about the accuracy of diagnosis in some patients, and the extent to which, in a selection of cases, residual cognitive functions may remain undetected and patients are diagnosed as being in a persistent vegetative state. Objective assessment of residual cognitive function can be extremely difficult as motor responses may be minimal, inconsistent, and difficult to document in many patients, or may be undetectable in others because no cognitive output is possible (Owen et al., 2002). In recent years, a number of studies have demonstrated an important role for functional neuroimaging in the identification of residual cognitive function in persistent vegetative state; this technology is providing new insights into cerebral activity in patients with severe brain damage. Such studies, when successful, may be particularly useful where there is concern about the accuracy of the diagnosis and the possibility that residual cognitive function has remained undetected.\n\nResearchers have begun to use functional neuroimaging studies to study implicit cognitive processing in patients with a clinical diagnosis of persistent vegetative state. Activations in response to sensory stimuli with positron emission tomography (PET), functional magnetic resonance imaging (fMRI), and electrophysiological methods can provide information on the presence, degree, and location of any residual brain function. However, use of these techniques in people with severe brain damage is methodologically, clinically, and theoretically complex and needs careful quantitative analysis and interpretation.\n\nFor example, PET studies have shown the identification of residual cognitive function in persistent vegetative state. That is, an external stimulation, such as a painful stimulus, still activates \"primary\" sensory cortices in these patients but these areas are functionally disconnected from \"higher order\" associative areas needed for awareness. These results show that parts of the cortex are indeed still functioning in \"vegetative\" patients (Matsuda et al., 2003).\n\nIn addition, other PET studies have revealed preserved and consistent responses in predicted regions of auditory cortex in response to intelligible speech stimuli. Moreover, a preliminary fMRI examination revealed partially intact responses to semantically ambiguous stimuli, which are known to tap higher aspects of speech comprehension (Boly, 2004).\n\nFurthermore, several studies have used PET to assess the central processing of noxious somatosensory stimuli in patients in PVS. Noxious somatosensory stimulation activated midbrain, contralateral thalamus, and primary somatosensory cortex in each and every PVS patient, even in the absence of detectable cortical evoked potentials. In conclusion, somatosensory stimulation of PVS patients, at intensities that elicited pain in controls, resulted in increased neuronal activity in primary somatosensory cortex, even if resting brain metabolism was severely impaired. However, this activation of primary cortex seems to be isolated and dissociated from higher-order associative cortices (Laureys et al., 2002).\n\nAlso, there is evidence of partially functional cerebral regions in catastrophically injured brains. To study five patients in PVS with different behavioral features, researchers employed PET, MRI and magnetoencephalographic (MEG) responses to sensory stimulation. In three of the five patients, co-registered PET/MRI correlate areas of relatively preserved brain metabolism with isolated fragments of behavior. Two patients had suffered anoxic injuries and demonstrated marked decreases in overall cerebral metabolism to 30–40% of normal. Two other patients with non-anoxic, multifocal brain injuries demonstrated several isolated brain regions with higher metabolic rates, that ranged up to 50–80% of normal. Nevertheless, their global metabolic rates remained <50% of normal. MEG recordings from three PVS patients provide clear evidence for the absence, abnormality or reduction of evoked responses. Despite major abnormalities, however, these data also provide evidence for localized residual activity at the cortical level. Each patient partially preserved restricted sensory representations, as evidenced by slow evoked magnetic fields and gamma band activity. In two patients, these activations correlate with isolated behavioral patterns and metabolic activity. Remaining active regions identified in the three PVS patients with behavioral fragments appear to consist of segregated corticothalamic networks that retain connectivity and partial functional integrity. A single patient who suffered severe injury to the tegmental mesencephalon and paramedian thalamus showed widely preserved cortical metabolism, and a global average metabolic rate of 65% of normal. The relatively high preservation of cortical metabolism in this patient defines the first functional correlate of clinical– pathological reports associating permanent unconsciousness with structural damage to these regions. The specific patterns of preserved metabolic activity identified in these patients reflect novel evidence of the modular nature of individual functional networks that underlie conscious brain function. The variations in cerebral metabolism in chronic PVS patients indicate that some cerebral regions can retain partial function in catastrophically injured brains (Schiff et al., 2002).\n\nStatistical PVS misdiagnosis isn't uncommon. An example study with 40 patients in the United Kingdom reported 43% of their patients classified as PVS were believed so and another 33% had recovered whilst the study was underway. Some PVS cases may actually be a misdiagnosis of patients being in an undiagnosed minimally conscious state. Since the exact diagnostic criteria of the minimally conscious state were only formulated in 2002, there may be chronic patients diagnosed as PVS before the secondary notion of the minimally conscious state became known.\n\nWhether or not there is any conscious awareness with a patient's vegetative state is a prominent issue. Three completely different aspects of this should be distinguished. First, some patients can be conscious simply because they are misdiagnosed (see above). In fact, they are not in vegetative states. Second, sometimes a patient was correctly diagnosed but is then examined during the early stages of recovery. Third, perhaps some day the notion itself of vegetative states will change so to include elements of conscious awareness. Inability to disentangle these three example cases causes confusion. An example of such confusion is the response to a recent experiment using functional magnetic resonance imaging which revealed that a woman diagnosed with PVS was able to activate predictable portions of her brain in response to the tester's requests that she imagine herself playing tennis or moving from room to room in her house. The brain activity in response to these instructions was indistinguishable from those of healthy patients.\n\nIn 2010, Martin Monti and fellow researchers, working at the MRC Cognition and Brain Sciences Unit at the University of Cambridge, reported in an article in the \"New England Journal of Medicine\" that some patients in persistent vegetative states responded to verbal instructions by displaying different patterns of brain activity on fMRI scans. Five out of a total of 54 diagnosed patients were apparently able to respond when instructed to think about one of two different physical activities. One of these five was also able to \"answer\" yes or no questions, again by imagining one of these two activities. It is unclear, however, whether the fact that portions of the patients' brains light up on fMRI could help these patients assume their own medical decision making.\n\nIn November 2011, a publication in \"The Lancet\" presented bedside EEG apparatus and indicated that its signal could be used to detect awareness in three of 16 patients diagnosed in the vegetative state.\n\nCurrently no treatment for vegetative state exists that would satisfy the efficacy criteria of evidence-based medicine. Several methods have been proposed which can roughly be subdivided into four categories: pharmacological methods, surgery, physical therapy, and various stimulation techniques. Pharmacological therapy mainly uses activating substances such as tricyclic antidepressants or methylphenidate. Mixed results have been reported using dopaminergic drugs such as amantadine and bromocriptine and stimulants such as dextroamphetamine. Surgical methods such as deep brain stimulation are used less frequently due to the invasiveness of the procedures. Stimulation techniques include sensory stimulation, sensory regulation, music and musicokinetic therapy, social-tactile interaction, and cortical stimulation.\n\nThere is limited evidence that the hypnotic drug zolpidem has an effect. The results of the few scientific studies that have been published so far on the effectiveness of zolpidem have been contradictory.\n\nIn the United States, it is estimated that there may be between 15,000 and 40,000 patients who are in a persistent vegetative state, but due to poor nursing home records exact figures are hard to determine.\n\nThe syndrome was first described in 1940 by Ernst Kretschmer who called it \"apallic syndrome\". The term \"persistent vegetative state\" was coined in 1972 by Scottish spinal surgeon Bryan Jennett and American neurologist Fred Plum to describe a syndrome that seemed to have been made possible by medicine's increased capacities to keep patients' bodies alive.\n\nAn ongoing debate exists as to how much care, if any, patients in a persistent vegetative state should receive in health systems plagued by limited resources. In a case before the New Jersey Superior Court, \"Betancourt v. Trinitas Hospital\", a community hospital sought a ruling that dialysis and CPR for such a patient constitutes futile care. An American bioethicist, Jacob M. Appel, argued that any money spent treating PVS patients would be better spent on other patients with a higher likelihood of recovery.\nThe patient died naturally prior to a decision in the case, resulting in the court finding the issue moot.\n\nIn 2010, British and Belgian researchers reported in an article in the \"New England Journal of Medicine\" that some patients in persistent vegetative states actually had enough consciousness to \"answer\" yes or no questions on fMRI scans. However, it is unclear whether the fact that portions of the patients' brains light up on fMRI will help these patient assume their own medical decision making. Professor Geraint Rees, Director of the Institute of Cognitive Neuroscience at University College London, responded to the study by observing that, \"As a clinician, it would be important to satisfy oneself that the individual that you are communicating with is competent to make those decisions. At the moment it is premature to conclude that the individual able to answer 5 out of 6 yes/no questions is fully conscious like you or I.\" In contrast, Jacob M. Appel of the Mount Sinai Hospital told the \"Telegraph\" that this development could be a welcome step toward clarifying the wishes of such patients. Appel stated: \"I see no reason why, if we are truly convinced such patients are communicating, society should not honour their wishes. In fact, as a physician, I think a compelling case can be made that doctors have an ethical obligation to assist such patients by removing treatment. I suspect that, if such individuals are indeed trapped in their bodies, they may be living in great torment and will request to have their care terminated or even active euthanasia.\"\n\n\n\n\"This article contains text from the NINDS public domain pages on TBI. and .\"\n"}
{"id": "14746730", "url": "https://en.wikipedia.org/wiki?curid=14746730", "title": "Planet Earth: The Future", "text": "Planet Earth: The Future\n\nPlanet Earth: The Future is a 2006 BBC documentary series on the environment and conservation, produced by the BBC Natural History Unit as a companion to the multi-award winning nature documentary \"Planet Earth\". The programmes were originally broadcast on BBC Four immediately after the final three episodes of \"Planet Earth\" on BBC One. Each episode highlights the conservation issues surrounding some of the species and environments featured in \"Planet Earth\", using interviews with the film-makers and eminent figures from the fields of science, conservation, politics, and theology. The programmes are narrated by Simon Poland and the series producer was Fergus Beeley.\n\nWhen the first episodes of \"Planet Earth\" were broadcast in the UK, the producers were criticised by some green campaigners for glossing over the environmental problems faced by the planet. Executive producer Alastair Fothergill defended the approach, explaining that a heavy-handed environmental message would not work on primetime BBC One. However, the \"Planet Earth\" film crews witnessed first-hand scenes of environmental degradation and the increasing scarcity of wildlife in some of the shooting locations. This experience formed the basis of \"Planet Earth - The Future\", which was designed to engage viewers in a mature debate about environmental issues.\n\nThe following year, the BBC commissioned \"Saving Planet Earth\", the second overtly conservation-themed series to be shown on BBC One. The first BBC series to deal comprehensively with conservation was \"State of the Planet\" in 2000.\n\nThe following is an alphabetical list of the interviewees featured in the series, with their titles and professions as credited on screen:\n\n\n\n"}
{"id": "1236666", "url": "https://en.wikipedia.org/wiki?curid=1236666", "title": "Pointed space", "text": "Pointed space\n\nIn mathematics, a pointed space is a topological space with a distinguished point, the basepoint. The distinguished point is just simply one particular point, picked out from the space, and given a name, such as \"x\", that remains unchanged during subsequent discussion, and is kept track of during all operations.\n\nMaps of pointed spaces (based maps) are continuous maps preserving basepoints, i.e., a map \"f\" between a pointed space \"X\" with basepoint \"x\" and a pointed space \"Y\" with basepoint \"y\" is a based map if it is continuous with respect to the topologies of \"X\" and \"Y\" and if \"f\"(\"x\") = \"y\". This is usually denoted\nPointed spaces are important in algebraic topology, particularly in homotopy theory, where many constructions, such as the fundamental group, depend on a choice of basepoint.\n\nThe pointed set concept is less important; it is anyway the case of a pointed discrete space.\n\nPointed spaces are often taken as a special case of the relative topology, where the subset is a single point. Thus, much of homotopy theory is usually developed on pointed spaces, and then moved to relative topologies in algebraic topology.\n\nThe class of all pointed spaces forms a category Top with basepoint preserving continuous maps as morphisms. Another way to think about this category is as the comma category, ({•} ↓ Top) where {•} is any one point space and Top is the category of topological spaces. (This is also called a coslice category denoted {•}/Top.) Objects in this category are continuous maps {•} → \"X\". Such morphisms can be thought of as picking out a basepoint in \"X\". Morphisms in ({•} ↓ Top) are morphisms in Top for which the following diagram commutes:\n\nIt is easy to see that commutativity of the diagram is equivalent to the condition that \"f\" preserves basepoints.\n\nAs a pointed space, {•} is a zero object in Top, while it is only a terminal object in Top.\n\nThere is a forgetful functor Top → Top which \"forgets\" which point is the basepoint. This functor has a left adjoint which assigns to each topological space \"X\" the disjoint union of \"X\" and a one-point space {•} whose single element is taken to be the basepoint.\n\n\n\n"}
{"id": "399630", "url": "https://en.wikipedia.org/wiki?curid=399630", "title": "Posting style", "text": "Posting style\n\nWhen a message is replied to in e-mail, Internet forums, or Usenet, the original can often be included, or “quoted,” in a variety of different posting styles.\n\nThe main options are interleaved posting (also called inline replying, in which the different parts of the reply follow the relevant parts of the original post), bottom-posting (in which the reply follows the quote) or top-posting (in which the reply precedes the quoted original message). For each of those options, there is also the issue of whether trimming of the original text is allowed, required, or preferred.\n\nFor a long time the traditional style was to post the answer below as much of the quoted original as was necessary to understand the reply (bottom or inline). Many years later, when email became widespread in business communication, it became a widespread practice to reply above the entire original and leave it (supposedly untouched) below the reply.\n\nWhile each online community differs on which styles are appropriate or acceptable, within some communities the use of the “wrong” method risks being seen as a breach of netiquette, and can provoke vehement response from community regulars.\n\nIn an e-mail reply, it is sometimes appropriate to include a full or partial copy of the original message that is being replied to. As opposed to in-person conversations and Internet chats, email responses may be received long after the original message was sent, so the original sender may have forgotten, misplaced or deleted the original. Many email reading programs (mail user agents) encourage this behaviour by automatically including a copy of the original message in the reply editing window.\n\nQuoted text from previous messages is usually distinguished in some way from the new (reply) text. At a minimum, the two parts are given different indentation. In the example below, the first line is the original message, the second line is the reply:\n\nAlternatively, special delimiter lines may be used:\n\nFor extra clarity, blank lines may also be inserted between the two parts. When using an email medium that supports text markup (such as HTML or RTF), the previous text may be indicated by a distinctive font and/or color:\n\nA common convention in plain-text email is to prefix each line of the quoted text with a distinctive character or string. Today (and for many years previously), the greater-than sign (“codice_1”, the canonical prefix) is almost universally used; but other characters such as the ASCII vertical bar character (“codice_2”) have been used as well, sometimes with one or more spaces inserted before or after the quoted text marker.\n\nThere is no standard declaring one quote-prefix to be “right” and others to be “wrong”, but some standards depend on conventional quoting. The (unpublished) “son-of-1036” draft recommends “codice_1” as the quote-prefix; RFC 3676 depends on it and considers “codice_4” and “codice_5” to be semantically different. That is, “codice_4” has a quote-depth of two, while “codice_5” has a quote-depth of one, quoting a line starting with “>”. Most e-mail clients treat both alternatives equivalently, however.\n\nThe convention of quoting was common in Usenet newsgroups by 1990, and is supported by many popular email interfaces, either by default or as a user-settable option. In Microsoft Outlook, for instance, this option is labeled “prefix each line of the original.” Besides inserting markers automatically in quoted lines, some interfaces assume that a line starting with a “codice_1” character or similar is quoted text, and will automatically display it in a distinctive font or color:\n\nSometimes the insertion of a quoted line marker will cause one original line to be folded as two lines in the reply, and the continuation line may not have the proper marker. To avoid ambiguity in such cases, one may consider inserting blank lines after each block of quoted text:\n\nQuoted line markers are most commonly used in plain-text messages. In HTML messages, other devices may be used to indicate quoted text, such as HTML indentation elements like codice_9 or codice_10.\n\nA message often includes text from two or more messages exchanged in previous rounds of a long discussion. If an additional quotation marker is inserted at every round, without removing any existing markers, the number of markers at the beginning of each line will show the “level” of the reply, that is, how many rounds have occurred since that line was written. These accumulated markers are usually sufficient to distinguish the parts that came from each message. Some email interfaces recognize this convention and automatically render each level in a different color. For example:\n\nIf the discussion is between two parties only, then an even number of markers (including zero) identifies text written by the sender, while an odd number of markers identifies text by the recipient. (In the above example even numbers are Joe's text and odd number are Mary's.)\n\nIn HTML messages, codice_9 or codice_10 elements may be nested to achieve the same effect.\n\nQuoted material is often preceded by an \"attribution line\" that identifies its author. These lines are particularly helpful in discussions between multiple parties. For example:\n\nThis reply quotes two messages, one by Nancy (itself a reply to Peter) and one by Peter (itself a reply to Mary).\n\nMany mail agents will add these attribution lines automatically to the top of the quoted material. Note that a newly added attribution line should not get the quotation marker, since it is not part of the quoted text; so that the level indicator of the attribution line is always one less than the corresponding text. Doing otherwise may confuse the reader and also e-mail interfaces that choose the text color according to the number of leading markers.\n\nInstead of an attribution line, one may indicate the author by a comment in brackets, at the beginning of the quotation:\n\nAnother alternative, used in Fidonet and some mail user agents, is to place the initials of the author before the quoting marker. This may be used with or without attribution lines:\n\nWhen replying to long discussions, particularly in newsgroup discussions, quoted text from the original message is often trimmed so as to leave only the parts that are relevant to the reply — or only a reminder thereof. This practice is sometimes called “trim-posting” or “edited posting”, and is recommended by some manuals of posting etiquette.\n\nSometimes an indicator of deleted text is given, usually in the form of a square bracketed tag as: “[snipped],” “[trimmed],” or simply “[...]”. The text that is retained may be edited to some extent, e.g. by re-folding the lines. For example, if the original message was\n\nthe reply may be\n\nor even just\n\nDeleted text may also be replaced by a summary in brackets:\n\nAutomatically included text (such as signature blocks, free e-mail service ads, and corporate disclaimers) are more likely to be deleted, usually without ellipses, than manually written text. Some posters may delete any parts of the original message that they are not replying to. Some posters delete only parts dealing with issues that they see as “closed,” and leave any parts that, in their opinion, deserve further discussion or will be replied to in a later message.\n\nSome style guides recommend that, as a general rule, quoted material in replies should be trimmed or summarized as much as possible, keeping only the parts that are necessary to make the readers understand the replies. That of course depends on how much the readers can be assumed to know about the discussion. For personal e-mail, in particular, the subject line is often sufficient, and no quoting is necessary; unless one is replying to only some points of a long message.\n\nIn particular, when replying to a message that already included quoted text, one should consider whether that quoted material is still relevant. For example:\n\nThe quote from Mary's message is relevant to Peter's reply, but not to Joe's reply. The latter could have been trimmed to\n\nOn the other hand, in some situations, any trimming or editing of the original message may be inappropriate. For example, if the reply is being copied to a third person who did not see the original message, it may be advisable to quote it in full; otherwise the trimmed message may be misinterpreted by the new recipient, for lack of context.\n\nAlso, when replying to a customer or supplier, it may be advisable to quote the original message in its entirety, in case the other party somehow failed to keep a copy of it.\n\nIn the interleaved reply style (also called “inline reply,” “interlined reply,” “point-by-point rebuttal,” or, sometimes, “bottom posting”), the original message is broken into two or more sections, each followed by a specific reply or comment. A reply in inline style may also include some top-posted or bottom-posted comments that apply to the whole reply message, rather than to a specific point. For example:\n\nThe interleaved reply style can also be combined with top-posting: selected points are quoted and replied to, as above, and then a full copy of the original message is appended.\n\nInterleaving was the predominant reply style in the Usenet discussion lists, years before the existence of the WWW and the spread of e-mail and the Internet outside the academic community.\n\nInterleaving was also common originally in e-mail, because many internet users had been exposed to Usenet newsgroups and other Internet forums, where it is still used. The style became less common for email after the opening of the internet to commercial and non-academic personal use. One possible reason is the large number of casual e-mail users that entered the scene at that time. Another possible reason is the inadequate support provided by the reply function of some webmail readers, which either do not automatically insert a copy of the original message into the reply, or do so without any quoting prefix level indicators. Finally, most forums, wiki discussion pages, and blogs (such as Slashdot) essentially impose the bottom-post format, by displaying all recent messages in chronological order.. Interleaving continues to be used on technical mailing lists where clarity within complex threads is important..\n\nIn top-posting style, the original message is included verbatim, with the reply above it. It is sometimes referred to by the term TOFU, an acronym for “text over, fullquote under.” It has also been colloquially referred to as \"Jeopardy!\" reply style. The original message asks a question and the reply answers it, so the order in which these texts appear follows the format of that game show, where the answer (the clue) comes first and the response is a question.\n\nExample:\n\nTop-posting preserves an apparently unmodified transcript of a branch in the conversation. Often all replies line up in a single branch of a conversation. The top of the text shows the latest replies. This appears to be advantageous for business correspondence, where an e-mail thread can dupe others into believing it is an “official” record.\n\nBy contrast, excessive indentation of interleaved and bottom posting may turn difficult to interpret. If the participants have different stature such as manager vs. employee or consultant vs. client, one person's cutting apart another person's words without the full context may look impolite or cause misunderstanding.\n\nIn the earlier days of Usenet informal discussions where everyone was an equal encouraged bottom-posting. Until the mid-1990s, posts in a net.newcomers newsgroup insisted on interleaving replies. Usenet \"comp.lang\" hierarchy, especially comp.lang.c and comp.lang.c++ insisted on the same as of the 2010s. The \"alt\" hierarchy tolerated top-posting. Newer online participants, especially those with limited experience of Usenet, tend to be less sensitive to arguments about posting style.\n\nTop-posting can be problematic on mailing lists with ongoing discussions which eventually require someone to act on the top-posted material. For example, top-posting “Those changes look ok to me, go ahead and make them” can be very inconvenient for the person who needs to make the changes if he or she has to read through a long email trail to know which changes the top-poster is referring to. Inter-leaving the text directly below the text describing the changes is much more convenient in these cases.\n\nUsers of mobile devices, like smartphones, are encouraged to use top-posting because the devices may only download the beginning of a message for viewing. The rest of the message is only retrieved when needed, which takes additional download time. Putting the relevant content at the beginning of the message requires less bandwidth, less time, and less scrolling for the user.\n\nTop-posting is a natural consequence of the behavior of the “reply” function in many current e-mail readers, such as Microsoft Outlook, Gmail, and others. By default, these programs insert into the reply message a copy of the original message (without headers and often without any extra indentation or quotation markers), and position the editing cursor above it. Moreover, a bug present on most flavours of Microsoft Outlook caused the quotation markers to be lost when replying in plain text to a message that was originally sent in HTML/RTF. \nFor these and possibly other reasons, many users seem to accept top-posting as the “standard” reply style.\n\nPartially because of Microsoft's influence, top-posting is very common on mailing lists and in personal e-mail.\n\nTop-posting has always been the standard format for forwarding a message to a third party, in which case the comments at the top (if any) are a \"cover note\" for the recipient.\n\nIn the \"bottom-posting\" style, the reply is appended to a full or partial copy of the original message. The name bottom-posting is sometimes used for inline-style replies, and indeed the two formats are the same when only one point is being replied to.\n\nBottom-posting, like inline replies, encourages posters to trim the original message as much as possible, so that readers are not forced to scroll past irrelevant text, or text that they have already seen in the original message:\n\nThe choice between interleaved, top or bottom posting generally depends on the forum and on the nature of the message. Some forums (such as personal e-mail) are quite tolerant, in which case the proper style is dictated by taste and effectiveness. In any case one should consider whether the reply will be easily read by the intended recipient(s). Their e-mail interfaces may have different rules for handling quoted line markers and long lines, so a reply that looks readable in one's screen may be jumbled and incorrectly colored on theirs. Blank lines and judicious trimming of the original text may help avoid ambiguity.\n\nThe interleaved reply style can require more work in terms of labeling lines, but possibly less work in establishing the context of each reply line. It also keeps the quotes and their replies close to each other and in logical reading order, and encourages trimming of the quoted material to the bare minimum. This style makes it easier for readers to identify the points of the original message that are being replied to; in particular, whether the reply misunderstood or ignored some point of the original text. It also gives the sender freedom to arrange the quoted parts in any order, and to provide a single comment to quotations from two or more separate messages, even if these did not include each other.\n\nTop- and bottom-posting are sometimes compared to traditional written correspondence in that the response is a single continuous text, and the whole original is appended only to clarify which letter is being replied to. Customer service e-mail practices, in particular, often require that all points be addressed in a clear manner without quoting, while the original e-mail message may be included as an attachment. Including the whole original message may be necessary also when a new correspondent is included in an ongoing discussion. Especially in business correspondence, an entire message thread may need to be forwarded to a third party for handling or discussion. On the other hand, in environments where the entire discussion is accessible to new readers (such as newsgroups or online forums), full inclusion of previous messages is inappropriate; if quoting is necessary, the interleaved style is probably best.\n\nIf the original message is to be quoted in full, for any reason, bottom-posting is usually the most appropriate format — because it preserves the logical order of the replies and is consistent with the Western reading direction from top to bottom.\n\nIt is not uncommon during discussions concerning top-posting vs. bottom-posting to hear quotes from \"Netiquette Guidelines (RFC 1855)\". While many RFCs are vetted and approved though a committee process, some RFCs, such as RFC 1844, are just \"Informational\" and in reality, sometimes just personal opinions. (Additional information on \"Informational\" RFCs can be found in RFC 2026, under \"4.2.2 Informational\" and \"4.2.3 Procedures for Experimental and Informational RFCs\".) The nature of RFC 1855 should be considered while reading the following discussion.\n\nAccording to RFC 1855, a message can begin with an abbreviated summary; i.e. a post can begin with a paraphrasing instead of quoting selectively. Specifically, it says:\n\nInterleaved reply combined with top-posting combines the advantages of both styles. However this also results in some portions of the original message being quoted twice, which takes up extra space and may confuse the reader.\n\nIn forwarding it is sometimes preferred to include the entire original message (including all headers) as a MIME attachment, while in top-posted replies these are often trimmed or replaced by an attribution line. An untrimmed quoted message is a weaker form of transcript, as key pieces of meta information are destroyed. (This is why an ISP's Postmaster will typically insist on a \"forwarded\" copy of any problematic e-mail, rather than a quote.) These forwarded messages are displayed in the same way as top-posting in some mail clients.\nTop-posting is viewed as seriously destructive to mailing-list digests, where multiple levels of top-posting are difficult to skip. The worst case would be top-posting while including an entire digest as the original message.\n\nSome believe that \"top-posting\" is appropriate for interpersonal e-mail, but inline posting should always be applied to threaded discussions such as newsgroups.\n\nThis example is occasionally used in mailing lists to mock and discourage top-posting:\n\nBottom-posting preserves the logical order of the replies and is consistent with the Western reading direction from top to bottom.\n\nThe major argument against bottom-posting is that scrolling down through a post to find a reply is inconvenient, especially for short replies to long messages, and many inexperienced computer users may not know that they need to scroll down to find a reply to their query. When sending an untrimmed bottom-posted message, one might indicate inline replies with a notice at the top such as \"I have replied below.\" However, as many modern mail programs are capable of displaying different levels of quotation with different colors (as seen in the bottom-posting example on this page), this is not so much of an issue any more. Another method to indicate that there is more reply text still to come is to always end your text with a signature line. Then a reader who is familiar with your reply style will know to continue to read until your signature line appears. This method is particularly polite and useful when using the inline reply method, since it tells the reader that your response is complete at the point where your signature line appears.\n\nThis widespread policy in business communication made bottom and inline posting so unknown among most users that some of the most popular email programs no longer support the traditional posting style. For example, Microsoft Outlook, AOL, and Yahoo! make it difficult or impossible to indicate which part of a message is the quoted original or do not let users insert comments between parts of the original.\n\nYahoo! does not have the option \"Quote the text of the original message\" in Mail Classic, but this setting is retained after turning it on in All-New Mail and then switching back to Mail Classic. Inline replying is broken in Microsoft Outlook, which despite choosing the setting to prefix each line of the original with the \"greater-than\" character (>) produces a blue line that makes answers inserted between quotes of an HTML email look like part of the original. The workarounds are to use the setting \"read all standard mail in plain text\", or to use the \"Edit Message\" option on the original email and convert it to plain text before replying (then discard the edited version).\n\n"}
{"id": "882424", "url": "https://en.wikipedia.org/wiki?curid=882424", "title": "Practical reason", "text": "Practical reason\n\nIn philosophy, practical reason is the use of reason to decide how to act. It contrasts with theoretical reason, often called speculative reason, the use of reason to decide what to follow. For example, agents use practical reason to decide whether to build a telescope, but theoretical reason to decide which of two theories of light and optics is the best.\n\nPractical reason is understood by most philosophers as determining a plan of action. Thomistic ethics defines the first principle of practical reason as \"good is to be done and pursued, and evil is to be avoided.\" For Kant, practical reason has a law-abiding quality because the categorical imperative is understood to be binding one to one's duty rather than subjective preferences. Utilitarians tend to see reason as an instrument for the satisfactions of wants and needs.\n\nIn classical philosophical terms, it is very important to distinguish three domains of human activity: theoretical reason, which investigates the truth of contingent events as well as necessary truths; practical reason, which determines whether a prospective course of action is worth pursuing; and productive or technical reason, which attempts to find the best means for a given end. Aristotle viewed philosophical activity as the highest activity of the human being and gave pride of place to metaphysics or wisdom. Since Descartes, practical judgment and reasoning have been treated with less respect because of the demand for greater certainty and an infallible method to justify beliefs.\n\nIn cognitive research, practical reason is the process of ignoring unproductive possibilities in favor of productive possibilities. It is considered a form of cognitive bias, because it is illogical. An example would be calling all hospitals to look for your missing child, but not checking morgues, as finding his corpse would be 'counter-productive.'\n\nPractical reasoning is basically goal-directed reasoning from an agent's goal, and from some action selected as a means to carry out the goal, to the agent's reasoned decision to carry out the action. The agent can be a person or a technical device, such as a robot or a software device for multi-agent communications. It is a type of reasoning used all the time in everyday life and all kinds of technology where autonomous reasoning is required. Argumentation theorists have identified two kinds of practical reasoning: \"instrumental practical reasoning\" that does not explicitly take values into account, and \"value-based practical reasoning\". The following argumentation scheme for instrumental practical reasoning is given in . The pronoun \"I\" represents an autonomous agent.\n\nCritical questions\n\nIt can be seen from CQ5 that argumentation from consequences is closely related to the scheme for practical reasoning.\nIt has often been disputed in philosophy whether practical reasoning is purely instrumental or whether it needs to be based on values. Argument from values is combined with practical reasoning in the type of argumentation called value-based practical reasoning. The following argumentation scheme for value-based practical reasoning is given in .\n\nPractical reasoning is used in arguments, but also in explanations used to draw conclusions about an agent's goals, motives or intentions, based on reports of what the agent said or did.\n\nPractical reasoning is centrally important in artificial intelligence, and also vitally important in many other fields such as law, medicine and engineering. It has been known as a distinctive type of argumentation as far back as Aristotle.\n\n\n\n"}
{"id": "52671158", "url": "https://en.wikipedia.org/wiki?curid=52671158", "title": "Red Umbrella Project", "text": "Red Umbrella Project\n\nThe Red Umbrella Project is a New York based non-profit organization that advocates on behalf of sex workers and strives to empower them by giving them a voice.\n\nThe Red Umbrella Project was founded in 2010 by writer and activist Audacia Ray. As a former sex worker, Ray witnessed first-hand the discrimination against sex workers by police and society. Ray envisioned an organization where sex workers could come together to share their stories, advocate for change and help one another. She chose the name The Red Umbrella Project because in 2001 during the 49th Venice Biennale of Art in Venice, Italy, sex workers demonstrated against inhumane work conditions and human rights violation by holding up red umbrellas, making this a symbol of resistance to discrimination.\n\nIn 2009 Ray started hosting storytelling events for sex workers at the Happy Ending Lounge on New York's Lower East Side. The goals of these workshops and storytelling events were to shine light and empower sex workers, but it soon became apparent that these sex workers shared several common burdens. Many identified as trans or queer, there was an alarming rate of HIV/AIDS cases among them, they feared carrying condoms due to the criminalization of condoms, and most of all they were tossed aside and mistreated by most of society, when all they were doing is trying to make a living and find economic opportunity.\n\nIn 2014 New York City created a series of special courts for sex workers arrested on prostitution-related charges. The new courts, known as Human Trafficking Intervention Courts (HTIC), treated all sex workers as human trafficking victims, and through a variety of bullying tactics forced defendants to forgo their constitutional right of a trial by jury and agree to a plea bargain of a sex worker diversion program which consisted of a court mandated treatment program, followed by adjournment in contemplation of dismissal (ACD). The Red Umbrella Project argued that the city's intentions were good and that the new court does help people who are forced into sex work. However, the court still treats the sex workers like criminals and makes the assumption that all sex workers are victims of human trafficking and that no one does sex work out of free will, for their personal economic gain. There may also be assumed discrimination within the workforce due to the fact that many sex workers are of color, queer or trans. The counseling and assistance offered through the court mandated treatment program provides them with no way of economic opportunity other than sex work. The Red Umbrella Project wants to see the sex-worker diversion program restructured with an emphasis on economic empowerment through job training and economic opportunities.\n\nThe Red Umbrella Project along with the Nation Center for Transgender Equality (NCTE) and Best Practices Policy Project (BPPP) published a report that transgender people in the sex trade are twelve times more likely to be living with HIV/AIDS than transgender people who were never involved in the sex trade and twenty-five times more likely to be living with HIV/AIDS than the general population. The Red Umbrella Project points to the fear of condoms as being used as evidence of prostitution along with profiling of race and gender by police officers where: \"Women and trans people having condoms on them is criminalized, whereas a white cis male having condoms on him is looked at as safe-sex practice.\" \n\nThe Red Umbrella Project and other advocacy groups have been able to push for reform in heavily liberal cities such as New York City, San Francisco and Washington, D.C., but other more conservative cities such as Phoenix use condoms as evidence as part of their anti-prostitution campaign Project Rose.\n\nThe Red Umbrella Diaries started as a monthly story-telling event at the Happy Ending Lounge on New York's Lower East Side that sought to shed the stigma around sex work, make it less isolating and show that it can be both exploitative and empowering\" at the same time. The Red Umbrella Diaries was listed by \"The Village Voice\" as \"The Best Way to Meet Sex Workers (for Free)\", and was listed as \"Best of New York City's Sports and Recreation\" in 2010. \n\nThe monthly event eventually led to a documentary produced by Audacia Ray and multi-Emmy Award-Winning director David Kornfield and funded by the Red Umbrella Project. The documentary featured seven sex workers telling their stories about trading money for sex on the streets of New York City. The documentary premiered at the Portland Film Festival, in Portland, Oregon and at the IFC theater in New York City, and was a Doc NYC official selection.\n\nIn 2012 the Red Umbrella Project started offering memoir writing workshops in New York City which was made possible in part by a grant from Poets & Writers. The peer-facilitated workshops were open to all people with experience in the sex trade and allows sex workers a safe space to build writing skills, share their stories with others, and get feedback from their peers. Attendees of the workshop have the option of having their work published in the Red Umbrella Project's biannual literary journal \"Prose & Lore\", and to share their work on stage as part of their Page to Stage workshop. One participant was Nahshon Anderson, who for eight weeks in 2013 workshopped the first chapter of their nonfiction manuscript Shooting Range that won a 2014 Bronx Recognizes Its Own Award (BRIO), given by the Bronx Council on the Arts.\n\n"}
{"id": "2149410", "url": "https://en.wikipedia.org/wiki?curid=2149410", "title": "Right of reply", "text": "Right of reply\n\nThe right of reply generally means the right to defend oneself against public criticism in the same venue where it was published. In some countries, such as Brazil, it is a legal or even constitutional right. In other countries, it is not a legal right as such, but a right which certain media outlets and publications choose to grant to people who have been severely criticised by them, as a matter of editorial policy.\n\nThe Brazilian Constitution guarantees the right of reply (\"direito de resposta\").\n\nIn Europe, there have been proposals for a legally enforceable right of reply that applies to all media, including newspapers, magazines, and other print media, along with radio, television, and the internet. In 1974, the Committee of Ministers of the Council of Europe already voted a resolution granting a right of reply to all individuals. Article 1 of a 2004 Council of Europe recommendation defined a right of reply as: \"offering a possibility to react to any information in the media presenting inaccurate facts … which affect … personal rights\".\n\nIn the federal system of Germany, the individual federal states are responsible for education, cultural affairs, and also the press and electronic media. All press laws of the 16 federal states guarantee the right to a counter presentation of factual statements which are deemed to be wrong by the individuals and organisations concerned. This is based on article 11 the national press law of 1874, and is found in all 16 laws as §11 or §10 in slightly modified versions.\n\nAustria and Switzerland have similar laws on the book. In Austria this is in article 9 of the national media law, in Switzerland in article 28g of the civil code.\n\nIn France, the right to a corrective reply goes back to the and is renewed and extended to broadcast and digital media via various laws and decrees.\n\nThe Belgian law on the right to reply emerged in 1831 as article 13 of the 1831 decree on the press. This was replaced 130 years later by the law on the \"droit de réponse\" or «loi du 23 juin 1961». Originally referring only to the printed press, this law was amended in 1977 by the law of «4 mars 1977 relative au droit de réponse dans l’audiovisuel» i.e. audiovisual media, published in the \"Moniteur Belge\" of March 15, 1977. Since the federalisation of the Belgian state in 1980, the language communities are responsible for the media, and so the Flemish community has passed in 2005 a decrée dated March 4, 2005, which regulates the right to reply in articles 177 to 199, and the German language community has passed the decree of 27 June 2005, which simply refers to the law of 1961 as amended in 1977.\n\nThe United Nations recognises the \"International Right of Correction\" through the \"Convention on the International Right of Correction\", which entered into force on August 24, 1962.\n\nA Florida right of reply law (referring to print media) was overturned by \"Miami Herald Publishing Co. v. Tornillo\", 418 U.S. 241 (1974), while a FCC policy (referring to broadcast media) was affirmed in \"Red Lion Broadcasting Co. v. FCC\", 395 U.S. 367 (1969).\n\nA right of reply can also be part of the editorial policy of a news publication or an academic journal. The BBC's Editorial Guidelines state:\n\nWhen our output makes allegations of wrongdoing, iniquity or incompetence or lays out a strong and damaging critique of an individual or institution the presumption is that those criticised should be given a \"right of reply\", that is, given a fair opportunity to respond to the allegations.\n\nThe \"Australasian Journal of Philosophy\"<nowiki>'</nowiki>s editorial policy says:\n\n[A]uthors of the materials being commented on [in Discussion Notes] may be given a right of reply (subject to the usual refereeing), on the understanding that timely publication of the Note will take priority over the desirability of including both Note and Reply in the same issue of the Journal.\n\n\n"}
{"id": "13440964", "url": "https://en.wikipedia.org/wiki?curid=13440964", "title": "Sentient beings (Buddhism)", "text": "Sentient beings (Buddhism)\n\nIn Buddhism, sentient beings are beings with consciousness, sentience, or in some contexts life itself. Sentient beings are composed of the five aggregates, or skandhas: matter, sensation, perception, mental formations and consciousness. In the \"Samyutta Nikaya\", the Buddha is recorded as saying that \"just as the word 'chariot' exists on the basis of the aggregation of parts, even so the concept of 'being' exists when the five aggregates are available.\" While distinctions in usage and potential subdivisions or classes of sentient beings vary from one school, teacher, or thinker to another, it principally refers to beings in contrast with buddhahood. That is, sentient beings are characteristically \"not\" enlightened, and are thus confined to the death, rebirth, and dukkha (suffering) characteristic of saṃsāra.\n\nHowever, Mahayana Buddhism simultaneously teaches that sentient beings also contain Buddha-nature—the intrinsic potential to transcend the conditions of saṃsāra and attain enlightenment, thereby obtaining Buddhahood.\n\nIn Mahayana Buddhism, it is to sentient beings that the Bodhisattva vow of compassion is pledged. Furthermore, and particularly in Tibetan Buddhism and Japanese Buddhism, \"all\" beings (including plant life and even inanimate objects or entities considered \"spiritual\" or \"metaphysical\" by conventional Western thought) are or may be considered sentient beings.\n\nGetz (2004: p. 760) provides a generalist Western Buddhist encyclopedic definition:\n\n\"Sentient beings\" is a term used to designate the totality of living, conscious beings that constitute the object and audience of Buddhist teaching. Translating various Sanskrit terms (\"jantu, bahu jana, jagat, sattva\"), \"sentient beings\" conventionally refers to the mass of living things subject to illusion, suffering, and rebirth (Saṃsāra). Less frequently, \"sentient beings\" as a class broadly encompasses all beings possessing consciousness, including Buddhas and Bodhisattvas.\nEarly scriptures in the Pāli Canon and the conventions of the Tibetan \"Bhavacakra\" classify sentient beings into five categories—divinities, humans, animals, tormented spirits, and denizens of hell—although sometimes the classification adds another category of beings called asuras between divinities and humans.\n\n"}
{"id": "1813996", "url": "https://en.wikipedia.org/wiki?curid=1813996", "title": "Septenary (Theosophy)", "text": "Septenary (Theosophy)\n\nThe Septenary in Helena Blavatsky's teachings refers to the seven principles of man. In \"The Key to Theosophy\" she presents a synthesis of Eastern (Advaita Vedanta, Samkhya) and Western (Platonism, 19th century Occultism) ideas, according to which human nature consists of seven principles. These are:\n\n\nEach of these principles are embodied as such:\n\nDespite using Sanskrit terminology, many of these concepts are expressed differently from their Indian counterparts. The Atman or Self in monistic Vedanta for example is considered the Universal Self that is the same as, and not just a \"ray\" of, the Absolute or Brahman.\n\nThese seven principles can be grouped into a threefold division of \"Monad\" (transcendent Spirit, consisting of Atma and Buddhi), \"Ego\" (the higher immortal spiritual Personality, made up of the Higher Manas only) and \"Lower Quaternity\" (the mortal personality, the Lower Manas and the remaining principles). In this, the Lower Manas is a transitional principle, the soul so to speak, which can choose to join either with the Kama (Desire) principle to form the \"Kama-Manas\", which becomes an \"elementary\" or \"astral\" spirit after death (equivalent perhaps to the \"preta\" or hungry ghost of Buddhism), or link with the higher or Buddhi principle to form a higher spiritual consciousness, the \"Buddhi-Manas\".\n\nTheosophists believe that the most material of the vestures of the soul are interpenetrated by the particles of the more subtle vesture. The Sthula Sarira or gross physical body is mostly space at its atomic level, as all matter is known to be. The interstitial space is inhabited by the subtler particles of the Astral body or Linga sarira, and so on for the other more energy-like envelopes of the Soul. Because of the interpenetration of each sheath the so-called \"inner person\" is a fluid and unbroken continuity, although varying in density/flexibility and energy. Therefore, it is progressively more susceptible to its true spiritual nature as it is progressively less encumbered by material boundaries; the image of a suspension or colloid in chemistry is a similar perspective. Matter is postulated to be the physical counterpart of consciousness (ultimately our aspect being pure consciousness); the interpenetration of sheaths allows for consciousness to interpenetrate man's nature and is a Theosophical explanation of sensory experience.\n\nAs well as seven subtle bodies, there are also seven Cosmic planes of existence. However, in Blavatsky's teachings, the Planes and Principles don't match up (post-Blavatskian re-interpreters like C.W. Leadbeater reinterpreted the seven principles so they equate with the seven planes; this interpretation since became standard everywhere but original or orthodox Blavatskyian Theosophy).\n\nWhile undergoing some changes and modifications in the hands of later esotericists such as C.W. Leadbeater, Rudolf Steiner, and Alice Bailey, Blavatsky's description of the seven bodies or principles remained a central part of western esoteric and New Age thinking ever since.\n\n"}
{"id": "2148069", "url": "https://en.wikipedia.org/wiki?curid=2148069", "title": "Social peer-to-peer processes", "text": "Social peer-to-peer processes\n\nSocial peer-to-peer processes are interactions with a peer-to-peer dynamic. These peers can be humans or computers. Peer-to-peer (P2P) is a term that originated from the popular concept of the P2P distributed computer application architecture which partitions tasks or workloads between peers. This application structure was popularized by file sharing systems like Napster, the first of its kind in the late 1990s.\n\nThe concept has inspired new structures and philosophies in many areas of human interaction. P2P human dynamic affords a critical look at current authoritarian and centralized social structures. Peer-to-peer is also a political and social program for those who believe that in many cases, peer-to-peer modes are a preferable option.\n\nP2P is a specific form of relational dynamic, based on the assumed equipotency of its participants, organized through the free cooperation of equals in view of the performance of a common task, for the creation of a common good, with forms of decision making and autonomy that are widely distributed throughout the network.\n\nThere are several fundamental aspects of social P2P processes:\n\nPeer production does not produce commodities for exchange value, and does not use the price mechanism or corporate hierarchy to determine the allocation of resources. It must therefore be distinguished from both the capitalist market (though it can be linked and embedded in the broader market) and from production through state and corporate planning; as a mode of governance it differs from traditional linear hierarchies; and as a mode of property it differs from both traditional private property and state-based collective public property; it is rather the common property of its producers and users and the whole of humankind. Unlike private property, peer property is inclusive rather than exclusive — its nature is to share ownership as widely, rather than as narrowly, as possible.\n\nP2P processes are not structureless, but are characterized by dynamic and changing structures which adapt themselves to phase changes. Its rules are not derived from an external authority, as in hierarchical systems, but are generated from within. It does not deny ‘authority’, but only fixed forced hierarchy, and therefore accepts authority based on expertise, initiation of the project, etc. P2P may be the first true meritocracy. P2P eliminates most, if not all, barriers to entry. The threshold for participation is kept as low as possible. Equipotency means that there is no prior formal filtering for participation, but rather that it is the immediate practice of cooperation which determines the expertise and level of participation. Communication is not top-down and based on strictly defined reporting rules, but feedback is systemic, integrated in the protocol of the cooperative system. Techniques of 'participation capture' and other social accounting make automatic cooperation the default scheme of the project. Personal identity becomes partly generated by the contribution to the common project. P2P characterists have been studied by Howard Rheingold \"et al.\"'s Cooperation Project.\n\nP2P is a network, not a linear or 'pyramidal' hierarchy (though it may have elements of it); it is 'distributed', though it may have elements of centralization and 'decentralisation'; intelligence is not located at any center, but everywhere within the system. Assumed equipotency means that P2P systems start from the premise that ‘it doesn’t know where the needed resource will be located’, it assumes that ‘everybody’ can cooperate, and does not use formal rules in advance to determine its participating members. Participants are expected to self-select the module that corresponds best to their expertise. Equipotency, i.e. the capacity to cooperate, is verified in the process of cooperation itself. Validation of knowledge, acceptance of processes, are determined by the collective through the use of digital rules which are embedded in the project's basic protocol. Cooperation must be free, not forced, and not based on neutrality (i.e. the buying of cooperation in a monetary system). It exists to produce something. It enables the widest possible participation. These are a number of characteristics that we can use to describe P2P systems ‘in general’, and in particular as it emerges in the human lifeworld. Whereas participants in hierarchical systems are subject to the panoptism of the select few who control the vast majority, in P2P systems, participants have access to holoptism, the ability for any participant to see the whole.\n\nThe first requirement to facilitate the emergence of peer-to-peer processes is the existence of a technological infrastructure that enables distributed access to fixed capital. Individual computers that enable a universal machine capable of executing any logical task are a form of distributed fixed capital, available at low cost to many producers. The internet, as a point to point network, was specifically designed for participation by the edges (computer users) without the use of obligatory hubs. Although it is not fully in the hands of its participants, the internet is controlled through distributed governance, and outside the complete hegemony of particular private or state actors. The Internet's hierarchical elements, such as the stacked IP protocols and Domain Name System, do not deter participation. Viral communicators, or meshworks, are a logical extension of the internet. With this methodology, devices create their own networks through the use of excess capacity, bypassing the need for a pre-existing infrastructure. Wireless community networks, Open Spectrum advocacy, file-serving television, and alternative meshwork-based telecommunication infrastructures are exemplary of this trend.\n\nThe second requirement is alternative information and communication systems which allow for autonomous communication between cooperating agents. The web (in particular the Writeable Web and the Web 2.0 that is in the process of being established) allows for the universal autonomous production, dissemination, and 'consumption' of written material while the associated podcasting and webcasting developments create an 'alternative information and communication infrastructure' for audio and audiovisual creation. The existence of such an infrastructure enables autonomous content production that may be distributed without the intermediary of the classic publishing and broadcasting media (though new forms of mediation may arise).\n\nThe third requirement is the existence of a 'software' infrastructure for autonomous global cooperation. A growing number of collaborative tools, such as blogs and wikis, embedded in social networking software facilitate the creation of trust and social capital, making it possible to create global groups that can create use-value without the intermediary of manufacturing or distribution by for-profit enterprises.\n\nThe fourth requirement is a legal infrastructure that enables the creation of use-value and protects it from private appropriation. The General Public License (which prohibits the appropriation of software code), the related Open Source Initiative, and certain versions of the Creative Commons license fulfill this role. They enable the protection of common use-value and use viral characteristics to spread. GPL and related material can only be used in projects that in turn put their adapted source code in the public domain.\n\nThe fifth requirement is cultural. The diffusion of mass intellectuality, (i.e. the distribution of human intelligence) and associated changes in ways of feeling and being (ontology), ways of knowing (epistemology) and value constellations (axiology) have been instrumental in creating the type of cooperative individualism needed to sustain an ethos which can enable P2P projects.\n\nThere are two important aspects to the emergence of P2P in the economic sphere. On the one hand, as format for peer production processes, it is emerging as a 'third mode of production' based on the cooperation of autonomous agents. Indeed, if the first mode of production was laissez-faire based capitalism, and the second mode was the model of a centrally-planned economy, then the third mode is defined neither by the motor of profit, nor by central planning: to allocate resources and make decisions, it does not use market and pricing mechanisms, or managerial commands, but instead uses social relations. Peer production is a significant part of the mainstream economy, even if it is not much advertised as such in mainstream economic literature.\n\nDespite significant differences, P2P and the capitalist market are highly interconnected. P2P is dependent on the market and the market is dependent on P2P. Peer production produces use-value through mostly immaterial production, without directly providing an income for its producers. Participants cannot live from peer production, though they derive meaning and value from it.\n\nThe market and capitalism are also dependent on P2P. Capitalism has become a system relying on distributed networks, in particular on the P2P infrastructure in computing and communication. Productivity is highly reliant on cooperative teamwork, most often organized in ways that are derivative of peer production's governance. The support given by major IT companies to open-source development is a testimony to the use derived from even the new common property regimes. The general business model seems to be that businesses use the P2P infrastructure, and create a surplus value through services, which can be packaged for exchange value. For-profit enterprises mostly use partial implementations of P2P. Amazon built itself around user reviews, eBay lives on a platform of worldwide distributed auctions, and Google is constituted by user-generated content. Value creation today is no longer confined to the enterprise, but beholden to the mass intellectuality of knowledge workers, who through their lifelong learning/experiencing and systemic connectivity, constantly innovate within and without the enterprise. Yet more recently, in the last decade, peer-to-peer exchanges have become even more prevalent in the so-called \"sharing economy\", also termed an \"access economy\" or a \"peer exchange economy.\" For instance, businesses such as Uber, Lyft, and Airbnb are all based on peer-to-peer physical exchanges. This sharing economy is projected by some analysts to encompass $335 billion by 2025.\n\nPeer-to-peer systems contribute to more specific forms of distributed capitalism. The massive use of open source software in business, enthusiastically supported by venture capital and large IT companies such as IBM, is creating a distributed software platform that will drastically undercut the monopolistic rents enjoyed by companies such as Microsoft and Oracle, while Skype and VoIP will drastically redistribute the telecom infrastructure. In addition, it also points to a new business model that is 'beyond' products, focusing instead on services associated with the nominally free FS/OS software model. Industries are gradually transforming themselves to incorporate user-generated innovation, and a new intermediation may occur around user-generated media. Many knowledge workers are choosing non-corporate paths and becoming mini-entrepreneurs, relying on an increasingly sophisticated participatory infrastructure, a kind of digital corporate commons.\n\nSocial P2P systems are different from market economy: neither market pricing nor managerial command are required for P2P processes to make decisions regarding the allocation of resources. There are further differences:\n\n\nMarkets do not function well for common needs that do not involve direct payment (national defense, general policing, education and public health). In addition, they fail to take into account negative externalities (the environment, social costs, future generations).\n\nIn \"The Political Economy of Peer Production\" Bauwens regards P2P phenomena as an emerging alternative to capitalist society. P2P economy may be seen as extending or already existing outside the sphere of free/open source software production and other non-rival immaterial goods. Peer production effectively enables the free cooperation of producers, who have access to their own means of production, and the resulting use-value of the projects supersedes for-profit alternatives.\n\nHistorically, though forces of higher productivity may be temporarily embedded in the old productive system, they ultimately lead to deep upheavals and reconstitutions of the political economy. The emergence of capitalist modes within the feudal system is a case in point. This is particularly significant because leading sectors of the for-profit economy are deliberately slowing down productive growth (through patents and monopolization) and trying to outlaw P2P production and sharing practices.\n\nGovernments of countries are composed of a specialized and privileged body of individuals, who monopolize political decision-making. Their function is to enforce existing laws, legislate new ones, and arbitrate conflicts via their monopoly on violence. Legislation can be open to the general citizenry through open source governance, allowing policy development to benefit from the collected wisdom of the people as a whole.\n\nMichel Bauwens has stated, that society is not a peer group with an a priori consensus, but rather a decentralized structure of competing groups and representative democracy cannot be replaced entirely by peer governance.\n\nPeer projects which evolve beyond a certain scale and start facing issues of decisions about scarce resources, will probably adapt some representational mechanisms. Representative and bureaucratic decision-making can and will in some places be replaced by global governance networks which may be self-governed to a large extent, but in any case, it will and should incorporate more and more Multistakeholder Models (i.e. collaborative e-democracy), which strives to include all groups that could be affected. This group-based partnership model is different, but related in spirit, to the individual-based peer governance, because they share an ethos of participation.\n\nMany new movements are taking on P2P organizational formats, such as the alter-globalization movement and the \"Occupy\" movement (i.e. Occupy Wall Street). The movements see itself as a network of networks that combines players from a wide variety of fields and opinion, who, despite the fact that they do not see eye to eye in all things, manage to unite around a common platform of action around certain key events.\n\nThey are able to mobilize vast numbers of people from every continent, without having at their disposal any of the traditional news media, such as television, radio or newspapers. Rather, they rely almost exclusively on the P2P technologies described above. Thus, Internet media are used for communication and learning on a continuous basis, prior to the mobilizations, and also during the mobilizations.\n\nIndependent Internet media platforms such as Indymedia, as well as the skillful use of mobile phones, are used for real-time response management, undertaken by small groups that use buddy-list technologies, and sometimes open source programs that have been explicitly designed for political activism such as TextMob.\n\nMany reports have appeared, including those described in Howard Rheingold's Smart Mobs, about the political significance of SMS in organizing successful protests and ‘democratic revolutions’. The network model allows for a more fluid organization that does not fix any group in a permanent adversarial position. Various temporary coalitions are created on an ad hoc basis depending on the issues.\n\nThe following is a list of individuals who have made contributions to the peer-to-peer paradigm.\n\n\n\n\n\n\nMIT Press, 2004 (power as embedded in the digital protocols governing networked systems)\n\n"}
{"id": "2155215", "url": "https://en.wikipedia.org/wiki?curid=2155215", "title": "Son et lumière (show)", "text": "Son et lumière (show)\n\nSon et lumière (French, lit. \"sound and light\"), or a sound and light show, is a form of nighttime entertainment that is usually presented in an outdoor venue of historic significance. \n\nSpecial lighting effects are projected onto the façade of a building or ruin and synchronized with recorded or live narration and music to dramatize the history of the place. The invention of the concept is credited to Paul Robert-Houdin, who was the curator of the Château de Chambord in France, which hosted the world's first \"son et lumière\" in 1952. Another was established in the early 1960s at the site of the Great Pyramid of Giza in Egypt.\n\nThis nighttime medium naturally lends itself to ecclesiastical buildings, stately homes and ruins, and has rapidly become very popular in France where about 50 annual productions take place, principally in the Loire Valley, at the Palace of Versailles and at Les Invalides in Paris.\n\nThe format usually involves no active participation by actors but a recorded narrative of the history of the building concerned by one or a cast of voices. To this is added music or sound effects as appropriate, all of which is synchronised to lighting and/or projection effects which provide the visual dimension. Pyrotechnic effects are occasionally included for added spectacle.\n\nA relatively recent variation is that, rather than the music and narration coming through a concert-like sound system, they may use headsets, such as in Philadelphia, Pennsylvania's \"Lights of Liberty\". This allows an audience to move through a historic district as the show proceeds.\n\nIn France, \"son et lumière\" shows are performed in and around France's historical châteaux. \n\nIn neighboring Luxembourg, a \"son et lumière\" event took place in 2007 at the Chateau de Septfontaines. \n\nIn other countries, \"son et lumière\" has been mounted at the Forum in Rome and at the Parthenon in Athens. \n\nIn the United States, the first such presentation took place at Independence Hall in Philadelphia in 1962. Another presentation took place at George Washington's Mount Vernon in May 1976 as France's bicentennial gift to the United States. The opening performance was attended by French President Giscard d'Estaing and American President Gerald Ford.\n\nFurther afield, the first African production was at the Pyramids of Giza at Cairo, Egypt, in 1961, while the first in Asia was the Red Fort in Delhi, India in 1965 by the India Tourism Development Corporation. \n\nCanterbury Cathedral in England featured a \"son et lumière\" in 1965 and more recently in 2005, along with Rochester Cathedral and Castle as part of the European \"Cathedrales en Lumière\" project.\n\nIn Britain, where the majority of such productions have been staged at churches, cathedrals and abbeys, indoor presentations are frequently preferred, particularly as architectural gems might otherwise not be shown to best advantage. The first British production was at Greenwich Palace in south London in 1957. In England in particular, where \"son et lumière\" is as well received as it is in France, many of the nations's principal historic houses and church buildings have enjoyed such a production. Of particular interest have been the ones at Canterbury Cathedral (produced as part of the European \"Cathedrales en Lumière\" events), Rochester Castle, St Augustine's Abbey, St. George's Hall, Liverpool, Tewkesbury Abbey, St Paul's Cathedral, Hampton Court Palace, and at Chartwell, the country home of Winston Churchill. Part of the London 2012 Olympic bid involved the use of \"son et lumière\" inspired light projections of athletes upon various London buildings. \n\nIn India, popular shows are at Red Fort, Amer Fort, Akbari Quila, Ajmer, Jantar Mantar, Jaipur, Purana Qila, Delhi, and Golconda Fort. In Peru, a \"son et lumière\" show opened in Park of the Reserve, Lima in 2007, called \"Circuito Mágico del Agua\" (\"magic water circuit\") which has a Guinness record as the world's largest water source exposed in a public park. \n\nIn Canada, the National Capital Commission has sponsored a sound and light show on Parliament Hill in Ottawa every year since 1984, from early July to mid-September.\n\nIn Australia, \"Blood Under the Southern Cross\", shown at Sovereign Hill in Ballarat since 1992, depicts the events of the 1854 Eureka Rebellion.\n\nIn Israel, a son et lumière production is presented both at the Tower of David in the Citadel of the Old City of Jerusalem, and at the desert butte of Masada. \n\nComposers who have produced son et lumière shows include Jacqueline Nova and Halim El-Dabh. French electronic music composer Jean Michel Jarre has incorporated son et lumière productions into his live concerts, which often take place outdoors at historical sites, sometimes with more than one million spectators.\n\n"}
{"id": "1547308", "url": "https://en.wikipedia.org/wiki?curid=1547308", "title": "Subjunctive possibility", "text": "Subjunctive possibility\n\nSubjunctive possibility (also called alethic possibility) is the form of modality most frequently studied in modal logic. Subjunctive possibilities are the sorts of possibilities we consider when we conceive of counterfactual situations; subjunctive modalities are modalities that bear on whether a statement \"might have been\" or \"could be\" true—such as \"might\", \"could\", \"must\", \"possibly\", \"necessarily\", \"contingently\", \"essentially\", \"accidentally\", and so on. Subjunctive possibilities include logical possibility, metaphysical possibility, nomological possibility, and temporal possibility.\n\nSubjunctive possibility is contrasted with (among other things) epistemic possibility (which deals with how the world \"may\" be, \"for all we know\") and deontic possibility (which deals with how the world \"ought\" to be). \n\nThe contrast with epistemic possibility is especially important to draw, since in ordinary language the same phrases (\"it's possible,\" \"it can't be\", \"it must be\") are often used to express either sort of possibility. But they are not the same. We do not \"know\" whether Goldbach's conjecture is true or not (no-one has come up with a proof yet); so it is (epistemically) \"possible that\" it is true and it is (epistemically) \"possible that\" it is false. But if it \"is\", in fact, provably true (as it may be, for all we know), then it would have to be (subjunctively) \"necessarily\" true; what being provable \"means\" is that it would not be (logically) \"possible for\" it to be false. Similarly, it might not be at all (epistemically) \"possible that\" it is raining outside—we might \"know\" beyond a shadow of a doubt that it is not—but that would hardly mean that it is (subjunctively) \"impossible for\" it to rain outside. This point is also made by Norman Swartz and Raymond Bradley.\n\nThere is some overlap in language between subjunctive possibilities and deontic possibilities: for example, we sometimes use the statement \"You can/cannot do that\" to express (i) what it is or is not subjunctively possible for you to do, and we sometimes use it to express (ii) what it would or would not be right for you to do. The two are less likely to be confused in ordinary language than subjunctive and epistemic possibility as there are some important differences in the logic of subjunctive modalities and deontic modalities. In particular, subjunctive necessity entails truth: if people logically must such and such, then you can infer that they actually do it. But in this non-ideal world, a deontic ‘must’ does not carry the moral certitude that people morally must do such and such.\n\nThere are several different types of subjunctive modality, which can be classified as broader or more narrow than one another depending on how restrictive the rules for what counts as \"possible\" are. Some of the most commonly discussed are:\n\n\nSimilarly David Lewis could have taken a degree in Economics but not in, say, Aviation (because it was not taught at Harvard) or Cognitive Neuroscience (because the so-called 'conceptual space' for such a major did not exist). There is some debate whether this final type of possibility in fact constitutes a type of possibility distinct from Temporal, and is sometimes called Historical Possibility by thinkers like Ian Hacking.\n"}
{"id": "8028338", "url": "https://en.wikipedia.org/wiki?curid=8028338", "title": "Systematic evolution of ligands by exponential enrichment", "text": "Systematic evolution of ligands by exponential enrichment\n\nSystematic evolution of ligands by exponential enrichment (SELEX), also referred to as \"in vitro selection\" or \"in vitro evolution\", is a combinatorial chemistry technique in molecular biology for producing oligonucleotides of either single-stranded DNA or RNA that specifically bind to a target ligand or ligands, which are commonly referred to as aptamers. \nAlthough SELEX has emerged as the most commonly used name for the procedure, some researchers have referred to it as SAAB (selected and amplified binding site) and CASTing (cyclic amplification and selection of targets) SELEX was first introduced in 1990. In 2015 a special issue was published in the Journal of Molecular Evolution in the honor of quarter century of the SELEX discovery.\n\nThe process begins with the synthesis of a very large oligonucleotide library consisting of randomly generated sequences of fixed length flanked by constant 5' and 3' ends that serve as primers. For a randomly generated region of length \"n\", the number of possible sequences in the library is 4 (\"n\" positions with four possibilities (A,T,C,G) at each position). The sequences in the library are exposed to the target ligand - which may be a protein or a small organic compound - and those that do not bind the target are removed, usually by affinity chromatography or target capture on paramagnetic beads. The bound sequences are eluted and amplified by PCR to prepare for subsequent rounds of selection in which the stringency of the elution conditions can be increased to identify the tightest-binding sequences. A caution to consider in this method is that the selection of extremely high, sub-nanomolar binding affinity entities may not in fact improve specificity for the target molecule. Off-target binding to related molecules could have significant clinical effects.\n\nSELEX has been used to develop a number of aptamers that bind targets interesting for both clinical and research purposes. Also towards these ends, a number of nucleotides with chemically modified sugars and bases have been incorporated into SELEX reactions. These modified nucleotides allow for the selection of aptamers with novel binding properties and potentially improved stability.\n\nThe first step of SELEX involves the synthesis of fully or partially randomized oligonucleotide sequences of some length flanked by defined regions which allow PCR amplification of those randomized regions and, in the case of RNA SELEX, in vitro transcription of the randomized sequence. While Ellington and Szostak demonstrated that chemical synthesis is capable of generating ~10 unique sequences for oligonucleotide libraries in their 1990 paper on in vitro selection, they found that amplification of these synthesized oligonucleotides led to significant loss of pool diversity due to PCR bias and defects in synthesized fragments. The oligonucleotide pool is amplified and a sufficient amount of the initial library is added to the reaction so that there are numerous copies of each individual sequence to minimize the loss of potential binding sequences due to stochastic events. Before the library is introduced to target for incubation and selective retention, the sequence library must be converted to single stranded oligonucleotides to achieve structural conformations with target binding properties.\n\nImmediately prior to target introduction, the single stranded oligonucleotide library is often heated and cooled slowly to renature oligonucleotides into thermodynamically stable secondary and tertiary structures. Once prepared, the randomized library is incubated with immobilized target to allow oligonucleotide-target binding. There are several considerations for this target incubation step, including the target immobilization method and strategies for subsequent unbound oligonucleotide separation, incubation time and temperature, incubation buffer conditions, and target versus oligonucleotide concentrations. Examples of target immobilization methods include affinity chromatography columns, nitrocellulose binding assay filters, and paramagnetic beads. Recently, SELEX reactions have been developed where the target is whole cells, which are expanded near complete confluence and incubated with the oligonucleotide library on culture plates. Incubation buffer conditions are altered based on the intended target and desired function of the selected aptamer. For example, in the case of negatively charged small molecules and proteins, high salt buffers are used for charge screening to allow nucleotides to approach the target and increase the chance of a specific binding event. Alternatively, if the desired aptamer function is in vivo protein or whole cell binding for potential therapeutic or diagnostic application, incubation buffer conditions similar to in vivo plasma salt concentrations and homeostatic temperatures are more likely to generate aptamers that can bind in vivo. Another consideration in incubation buffer conditions is non-specific competitors. If there is a high likelihood of non-specific oligonucleotide retention in the reaction conditions, non specific competitors, which are small molecules or polymers other than the SELEX library that have similar physical properties to the library oligonucleotides, can be used to occupy these non-specific binding sites. Varying the relative concentration of target and oligonucleotides can also affect properties of the selected aptamers. If a good binding affinity for the selected aptamer is not a concern, then an excess of target can be used to increase the probability that at least some sequences will bind during incubation and be retained. However, this provides no selective pressure for high binding affinity, which requires the oligonucleotide library to be in excess so that there is competition between unique sequences for available specific binding sites.\n\nOnce the oligonucleotide library has been incubated with target for sufficient time, unbound oligonucleotides are washed away from immobilized target, often using the incubation buffer so that specifically bound oligonucleotides are retained. With unbound sequences washed away, the specifically bound sequences are then eluted by creating denaturing conditions that promote oligonucleotide unfolding or loss of binding conformation including flowing in deionized water, using denaturing solutions containing urea and EDTA, or by applying high heat and physical force. Upon elution of bound sequences, the retained oligonucleotides are reverse-transcribed to DNA in the case of RNA or modified base selections, or simply collected for amplification in the case of DNA SELEX. These DNA templates from eluted sequences are then amplified via PCR and converted to single stranded DNA, RNA, or modified base oligonucleotides, which are used as the initial input for the next round of selection.\n\nOne of the most critical steps in the SELEX procedure is obtaining single stranded DNA (ssDNA) after the PCR amplification step. This will serve as input for the next cycle so it is of vital importance that all the DNA is single stranded and as little as possible is lost. Because of the relative simplicity, one of the most used methods is using biotinylated reverse primers in the amplification step, after which the complementary strands can be bound to a resin followed by elution of the other strand with lye. Another method is asymmetric PCR, where the amplification step is performed with an excess of forward primer and very little reverse primer, which leads to the production of more of the desired strand. A drawback of this method is that the product should be purified from double stranded DNA (dsDNA) and other left-over material from the PCR reaction. Enzymatic degradation of the unwanted strand can be performed by tagging this strand using a phosphate-probed primer, as it is recognized by enzymes such as Lambda exonuclease. These enzymes then selectively degrade the phosphate tagged strand leaving the complementary strand intact. All of these methods recover approximately 50 to 70% of the DNA. For a detailed comparison refer to the article by Svobodová et al. where these, and other, methods are experimentally compared. In classical SELEX, the process of randomized single stranded library generation, target incubation, and binding sequence elution and amplification described above are repeated until the vast majority of the retained pool consists of target binding sequences, though there are modifications and additions to the procedure that are often used, which are discussed below.\n\nIn order to increase the specificity of aptamers selected by a given SELEX procedure, a negative selection, or counter selection, step can be added prior to or immediately following target incubation. To eliminate sequences with affinity for target immobilization matrix components from the pool, negative selection can be used where the library is incubated with target immobilization matrix components and unbound sequences are retained. Negative selection can also be used to eliminate sequences that bind target-like molecules or cells by incubating the oligonucleotide library with small molecule target analogs, undesired cell types, or non-target proteins and retaining the unbound sequences.\n\nTo track the progress of a SELEX reaction, the number of target bound molecules, which is equivalent to the number of oligonucleotides eluted, can be compared to the estimated total input of oligonucleotides following elution at each round. The number of eluted oligonucleotides can be estimated through elution concentration estimations via 260 nm wavelength absorbance or fluorescent labeling of oligonucleotides. As the SELEX reaction approaches completion, the fraction of the oligonucleotide library that binds target approaches 100%, such that the number of eluted molecules approaches the total oligonucleotide input estimate, but may converge at a lower number.\n\nSome SELEX reactions can generate probes that are dependent on primer binding regions for secondary structure formation. There are aptamer applications for which a short sequence, and thus primer truncation, is desirable. An advancement on the original method allows an RNA library to omit the constant primer regions, which can be difficult to remove after the selection process because they stabilize secondary structures that are unstable when formed by the random region alone.\n\nRecently, SELEX has expanded to include the use of chemically modified nucleotides. These chemically modified oligonucleotides offer many potential advantages for selected aptamers including greater stability and nuclease resistance, enhanced binding for select targets, expanded physical properties - like increased hydrophobicity, and more diverse structural conformations.\n\nThe genetic alphabet, and thus possible aptamers, is also expanded using unnatural base pairs the use of these unnatural base pairs was applied to SELEX and high affinity DNA aptamers were generated.\n\nThe technique has been used to evolve aptamers of extremely high binding affinity to a variety of target ligands, including small molecules such as ATP and adenosine and proteins such as prions and vascular endothelial growth factor (VEGF). Moreover, SELEX has been used to select high-affinity aptamers for complex targets such as tumor cells. Clinical uses of the technique are suggested by aptamers that bind tumor markers, GFP-related fluorophores, and a VEGF-binding aptamer trade-named Macugen has been approved by the FDA for treatment of macular degeneration. Additionally, SELEX has been utilized to obtain highly specific catalytic DNA or DNAzymes. Several metal-specific DNAzymes have been reported including the GR-5 DNAzyme (lead-specific), the CA1-3 DNAzymes (copper-specific), the 39E DNAzyme (uranyl-specific) and the NaA43 DNAzyme (sodium-specific).\n\nThese developed aptamers have seen diverse application in therapies for macular degeneration and various research applications including biosensors, fluorescent labeling of proteins and cells, and selective enzyme inhibition.\n\n\n"}
{"id": "24210982", "url": "https://en.wikipedia.org/wiki?curid=24210982", "title": "Systems Biology Graphical Notation", "text": "Systems Biology Graphical Notation\n\nThe Systems Biology Graphical Notation (SBGN) is a standard graphical representation intended to foster the efficient storage, exchange and reuse of information about signaling pathways, metabolic networks, and gene regulatory networks amongst communities of biochemists, biologists, and theoreticians. The system was created over several years by a community of biochemists, modelers and computer scientists.\n\nSBGN is made up of three orthogonal languages for representing different views of biological systems: \"Process Descriptions\", \"Entity Relationships\" and \"Activity Flows\". Each language defines a comprehensive set of symbols with precise semantics, together with detailed syntactic rules regarding the construction and interpretation of maps. Using these three notations, a life scientist can represent in an unambiguous way networks of interactions (for example biochemical interactions). These notations make use of an idea and symbols similar to that used by electrical and other engineers and known as the block diagram. The simplicity of SBGN syntax and semantics makes SBGN maps suitable for use at the high school level.\n\nSome software support for SBGN is already available, mostly for the Process Description language.\n\n The SBGN Process Description (PD) language shows the temporal courses of biochemical interactions in a network. It can be used to show all the molecular interactions taking place in a network of biochemical entities, with the same entity appearing multiple times in the same diagram.\n\n The SBGN Entity Relationship (ER) language allows to see all the relationships in which a given entity participates, regardless of the temporal aspects. Relationships can be seen as rules describing the influences of entities nodes on other relationships.\n\n The SBGN Activity Flow (AF) language depicts the flow of information between biochemical entities in a network. It omits information about the state transitions of entities and is particularly convenient for representing the effects of perturbations, whether genetic or environmental in nature.\n\nWork on defining a set of symbols to describe interactions and relationships of molecules was pioneered by Kurt Kohn at the National Cancer Institute with his Molecular Interaction Maps (MIM). The development of SBGN was initiated by Hiroaki Kitano, supported by a funding from the Japanese New Energy and Industrial Technology Development Organization. The meeting that initiated development of the Systems Biology Graphical Notation took place on February 11–12, 2006, at the National Institute of Advanced Industrial Science and Technology (AIST), in Tokyo, Japan.\n\nThe first specification of SBGN Process Description language – then called Process Diagrams – was released on August 23, 2008 (Level 1 Version 1). Corrections of the document were released on September 1, 2009 (Level 1 Version 1.1), October 3, 2010 (Level 1 Version 1.2) and February 14, 2011 (Level 1 Version 1.3).\n\nThe first specification of SBGN Entity relationship language was released on September 1, 2009 (Level 1 Version 1). Corrections of the document were released on October 6, 2010 (Level 1 Version 1.1) and April 14, 2011 (Level 1 Version 1.2).\n\nThe first specification of SBGN Activity Flow language was released on September 1, 2009.\n\n"}
{"id": "19522414", "url": "https://en.wikipedia.org/wiki?curid=19522414", "title": "Tagmar", "text": "Tagmar\n\nTagmar is a roleplaying game (RPG) launched in 1991 by GSA that claims to be the first such Brazilian offering on what was at the time a nascent market.\nThe game was a typical early 1990s RPG but featured a series of innovations, the main one being that it was a self-contained package with everything necessary to play provided in a single book: rules, setting, magic, creatures and a pre-prepared adventure for beginners. At the time, RPG books were imported to Brazil and it was necessary to have several to play a game.\nBased on the works of J. R. R. Tolkien, Tagmar faced accusations that it was based on Dungeons & Dragons (D&D), especially from \"Dragão Brasil\" magazine, at the time edited by Marcelo Cassaro, while others claimed that it was very different. Due to a variety of factors including price, availability and innovation, such as the unprecedented concept of \"Heroic Energy\", in a short time Tagmar became a success and gathered a large fan base.\nDuring the 1990s, the \"world\" of Tagmar was enlarged through the publication of complementary books such as the \"Creatures Book\" (\"Livro de Criaturas\") and \"The Empire\" (\"O Império\"). These books provided details on the appearance, skills and habitat of the creatures of Tagmar as well as information about new geographic regions.\n\nThis success continued until 1997 when the publisher GSA closed down leaving Tagmar to stagnate.\n\nLaunched in 1991, the same year that Devir launched GURPS in Brazil, the first Brazilian RPG is based on the stories of fantasy of JRR Tolkien, the game was accused of be a copy of Dungeons and Dragons, only to be released in 1993 by Grow until then, the system was known only to players who played with the original versions in English. In 1992, GSA published the second Brazilian RPG, O Desafio dos Bandeirantes (The Challenge of the Explorers), set in Colonial Brazil.\nFive supplements were published: O Arado de Ouro, O Livro de Criaturas, A Fronteira, the gamebook Estandarte Sangrento and O Império, however, the label closed in 1997.\nIn 2004, the authors of Tagmar decided to republish the game, released on an official website, \"Tagmar 2\" was made available through a Creative Commons Non-Commercial license.\n\nIn 2006, Tagmar no longer restricted to the system itself and the scene happened to be adapted to other systems, the first system chosen was the Daemon of Daemon Editora. In February 2007, it announced the project to adapt the D20 System, on the official site there are also adaptations for GURPS, Mutants & Masterminds and Dungeon World, 11 in 2011, has been published adventure O Casamento, an e-book to set in the backdrop of Tagmar for Old Dragon.\n\nCurrently, Tagmar 2 has an extensive list of published titles that can be downloaded for free from the official site. Among these are:\n\n\n"}
{"id": "54460130", "url": "https://en.wikipedia.org/wiki?curid=54460130", "title": "The Parliamentary Network on the World Bank &amp; International Monetary Fund", "text": "The Parliamentary Network on the World Bank &amp; International Monetary Fund\n\nThe Parliamentary Network on the World Bank & International Monetary Fund (French: \"Réseau parlementaire sur la Banque mondiale et le FMI\") is an independent inter-parliamentary organization aiming to increase transparency and accountability in international financial institutions., notably the World Bank Group and the International Monetary Fund. It consists of over a thousand legislators from 158 World Bank Group and IMF member countries.\n\nThe Parliamentary Network on the World Bank & IMF was founded in 2000 as an independent, non-governmental organization providing a platform for advocacy for Parliamentarians from IMF and World Bank member countries;. The Network has formed partnerships with numerous organizations, including: the World Bank, the IMF, the OECD, the Inter-Parliamentary Union, GOPAC, GLOBE, Transparency International, etc.\n\nThe Parliamentary Network is governed by the Board of Directors currently composed of 10 members elected every two years. The members of the Board represent the regions of MENA, Europe, Africa, Latin America, East Asia, and World Bank donor countries. Membership in the Network is open to all elected or nominated parliamentarians from World Bank and IMF member states who currently hold a mandate.\n\nThe International Secretariat of the Network is based in Paris, France.\n\nThe Parliamentary Network on the World Bank & IMF is principally focused on increasing transparency and accountability of the World Bank Group and the International Monetary Fund by:\n\n\nEvery year, the Parliamentary Network on the World Bank & IMF organizes, jointly with the World Bank Group and the International Monetary Fund, the Global Parliamentary Conference. The conference brings together legislators, the IMF and World Bank leadership.\n\nThe Parliamentary Network organizes visits for parliamentarians to on-the-ground development projects supported by the World Bank and the IMF. To this day, its members have participated in visits to Albania, Burkina Faso, Burundi, Cambodia, Democratic Republic of the Congo, Ethiopia, Ghana, Haiti, Indonesia, Kenya, Laos, Madagascar, Mongolia, Montenegro, Mozambique, Nicaragua, Nigeria, Peru, Rwanda, Serbia, Sri Lanka, Tanzania, Uganda, Vietnam and Yemen.\n\nNational and regional chapters are parliamentary discussion groups organized by a local initiative which aim to strengthen the position of parliamentarians among international financial institutions and other development stakeholders and facilitate regular interaction between local and regional legislators and staff in World Bank and IMF country offices, including consultations on Country Assistance Strategies, Public Expenditure Reviews, World Bank and IMF policies and programmes \n\nThe Parliamentary Network regularly participates in a number of special events including global summits, parliamentary assembly caucuses and economic briefing sessions.\n\n"}
{"id": "603325", "url": "https://en.wikipedia.org/wiki?curid=603325", "title": "Topic and comment", "text": "Topic and comment\n\nIn linguistics, the topic, or theme, of a sentence is what is being talked about, and the comment (rheme or focus) is what is being said about the topic. This opposition of the given/new information is called information structure. That the information structure of a clause is divided in this way is generally agreed on, but the boundary between topic/theme and comment/rheme/focus depends on grammatical theory. \n\nThe difference between \"topic\" and grammatical subject is that topic is used to describe the information structure, or pragmatic structure of a clause and how it coheres with other clauses, whereas the subject is a purely grammatical category. \"Topic\" and \"subject\" must also be distinguished from \"actor\" (or \"agent\"), the \"doer\". In English clauses with a verb in the passive voice, for instance, the topic is typically the subject, while the agent may be omitted or may follow the preposition \"by\". In some languages, word order and other syntactic phenomena are determined largely by the topic–comment (theme–rheme) structure. These languages are sometimes referred to as topic-prominent languages. Korean and Japanese are often given as examples of this.\n\nThe distinction was probably first suggested by Henri Weil in 1844. He established the\nconnection between information structure and word order. Georg von der Gabelentz distinguished psychological subject (roughly topic) and psychological object (roughly focus). In the Prague school, the dichotomy, termed topic–focus articulation, has been studied mainly by Vilém Mathesius, Jan Firbas, František Daneš, Petr Sgall and Eva Hajičová. They have been concerned mainly by its relation to intonation and word-order. Mathesius also pointed that the topic does not provide new information but connects the sentence to the context. The work of Michael Halliday in the 1960s is responsible for developing linguistic science through his systemic functional linguistics model for English.\n\nThe sentence- or clause-level \"topic\", or \"theme\", can be defined in a number of different ways. Among the most common are\n\nIn an ordinary English clause, the subject is normally the same as the topic/theme (example 1), even in the passive voice (where the subject is a patient, not an agent: example 2):\n\nThese clauses have different topics: the first is about \"the dog\", and the second about \"the little girl\".\n\nIn English it is also possible to use other sentence structures to show the topic of the sentence, as in the following:\n\nThe case of expletives is sometimes rather complex. Consider sentences with expletives (meaningless subjects), like:\n\n\nIn these examples the syntactic subject position (to the left of the verb) is manned by the meaningless expletive (\"it\" or \"there\"), whose sole purpose is satisfying the extended projection principle, and is nevertheless necessary. In these sentences the topic is never the subject, but is determined pragmatically. In all these cases, the whole sentence refers to the comment part.\n\nThe relation between topic/theme and comment/rheme/focus should not be confused with the topic-comment relation in Rhetorical structure theory Discourse Treebank (RST-DT corpus) where it is defined as \"a general statement or topic of discussion is introduced, after which a specific remark is made on the statement or topic\" (ex. \"[As far as the pound goes,] [some traders say a slide toward support at 1.5500 may be a favorable development for the dollar this week.]\") \n\nDifferent languages mark topics in different ways. Distinct intonation and word-order are the most common means. The tendency to place topicalized constituents sentence-initially (\"topic fronting\") is widespread. Topic fronting refers to placing the topic at the beginning\nof a clause regardless whether it is marked or not. Again, linguists disagree on many details. \n\nLanguages often show different kinds of grammar for sentences that introduce new topics and those that continue discussing previously established topics. \n\nWhen a sentence continues discussing a previously established topic, it is likely to use pronouns to refer to the topic. Such topics tend to be subjects. In many languages, pronouns referring to previously established topics will show pro-drop.\n\nThe topic/theme comes first in the clause, and is typically marked out by intonation as well.\n\n\nThe main application of the topic-comment structure is in the domain of speech technology, especially the design of embodied conversational agents (intonational focus assignment, relation between information structure and posture and gesture). There were some attempts to apply the theory of topic/comment for the information retrieval and the automatic summarization .\n\n\n\n"}
{"id": "7480157", "url": "https://en.wikipedia.org/wiki?curid=7480157", "title": "Trigger list", "text": "Trigger list\n\nTrigger list in its most general meaning refers to a list whose items are used to initiate (\"trigger\") certain actions.\n\nIn the United States, when a person applies for a mortgage loan, the lender makes a credit inquiry about the potential borrower from the national credit bureaus, Equifax, Experian and TransUnion. Unless the borrower is opted out, the credit bureaus put the applicants onto a \"trigger list\" of \"leads\" about persons who are interested in new loans. These lists are sold to numerous lenders all over the United States, and soon after the application the applicant starts receiving offers from all parts of the country. The trigger lists contain a significant amount of personal financial information. Among the buyers of trigger lists are \"lead generators\" which resell filtered information to borrowers, e.g., of people who live in a certain area and have a certain credit score.\n\nWhile the Federal Trade Commission considers the market of \"trigger lists\" to be a legal business, many people and organizations (such as the National Association of Mortgage Brokers) consider this a serious breach of privacy and lobby for putting this practice under regulatory controls.\n\nAs of now, American consumers may opt-out from \"trigger lists\" by calling 1-888-5-OPTOUT (1-888-567-8688). \n\nThe Zangger Committee and the Nuclear Suppliers Group maintain lists of items that may contribute to nuclear proliferation; The nuclear non-proliferation treaty forbids its members to export such items to non-treaty members. these items are said to trigger the countries' responsibilities under the NPT, hence the name.\n\n"}
{"id": "45064334", "url": "https://en.wikipedia.org/wiki?curid=45064334", "title": "Warnock's dilemma", "text": "Warnock's dilemma\n\nWarnock's dilemma, named for its originator Bryan Warnock, is the problem of interpreting a lack of response to a posting in a virtual community. The term originally referred to mailing list discussions, but has been applied to Usenet posts, blogs, Web forums, and online content in general. The dilemma arises because a lack of response does not necessarily imply that no one is interested in the topic, but could also mean for example that readers find the content to be exceptionally good (leaving nothing for commenters to add).\n\nOn many internet forums, only around 1 percent of users create new posts, while 9 percent reply and 90 percent are lurkers that don't contribute to the discussion. When no users reply, the original poster has no way of knowing what lurkers think of their contribution.\n\nWarnock's dilemma leads to online writers and publishers adopting more confrontational writing strategies in order to ensure that they will get a response. However, this can also lead publishers to avoid producing the kind of content that might fail to generate comments due to its high quality. This problem arises particularly with sites that focus on viral content, such as \"Buzzfeed\" and \"Huffington Post\".\n\nSince Warnock's original description of the dilemma in August 2000, the expression has become used in the Perl world.\n\n\n"}
{"id": "19571465", "url": "https://en.wikipedia.org/wiki?curid=19571465", "title": "Weakly symmetric space", "text": "Weakly symmetric space\n\nIn mathematics, a weakly symmetric space is a notion introduced by the Norwegian mathematician Atle Selberg in the 1950s as a generalisation of symmetric space, due to Élie Cartan. Geometrically the spaces are defined as complete Riemannian manifolds such that any two points can be exchanged by an isometry, the symmetric case being when the isometry is required to have period two. The classification of weakly symmetric spaces relies on that of periodic automorphisms of complex semisimple Lie algebras. They provide examples of Gelfand pairs, although the corresponding theory of spherical functions in harmonic analysis, known for symmetric spaces, has not yet been developed.\n\n"}
