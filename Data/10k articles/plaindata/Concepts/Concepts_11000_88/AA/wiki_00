{"id": "7372596", "url": "https://en.wikipedia.org/wiki?curid=7372596", "title": "1968 Olympics Black Power salute", "text": "1968 Olympics Black Power salute\n\nDuring their medal ceremony in the Olympic Stadium in Mexico City on October 16, 1968, African-American athletes Tommie Smith and John Carlos each raised a black-gloved fist during the playing of the US national anthem, \"The Star-Spangled Banner\". While on the podium, Smith and Carlos, who had won gold and bronze medals respectively in the 200-meter running event of the 1968 Summer Olympics, turned to face the US flag and then kept their hands raised until the anthem had finished. In addition, Smith, Carlos, and Australian silver medalist Peter Norman all wore human-rights badges on their jackets.\n\nIn his autobiography, \"Silent Gesture\", Smith stated that the gesture was not a \"Black Power\" salute but rather a \"human rights salute\". The demonstration is regarded as one of the most overtly political statements in the history of the modern Olympics.\n\nOn the morning of October 16, 1968, US athlete Tommie Smith won the 200 meter race with a world-record time of 19.83 seconds. Australia's Peter Norman finished second with a time of 20.06 seconds, and the US's John Carlos won third place with a time of 20.10 seconds. After the race was completed, the three went to the podium for their medals to be presented by David Cecil, 6th Marquess of Exeter. The two US athletes received their medals shoeless, but wearing black socks, to represent black poverty. Smith wore a black scarf around his neck to represent black pride, Carlos had his tracksuit top unzipped to show solidarity with all blue-collar workers in the US and wore a necklace of beads which he described \"were for those individuals that were lynched, or killed and that no-one said a prayer for, that were hung and tarred.\" It was for those thrown off the side of the boats in the Middle Passage.\" All three athletes wore Olympic Project for Human Rights (OPHR) badges after Norman, a critic of Australia's former White Australia Policy, expressed empathy with their ideals. Sociologist Harry Edwards, the founder of the OPHR, had urged black athletes to boycott the games; reportedly, the actions of Smith and Carlos on October 16, 1968 were inspired by Edwards's arguments.\n\nThe famous picture of the event was taken by photographer John Dominis.\n\nBoth US athletes intended to bring black gloves to the event, but Carlos forgot his, leaving them in the Olympic Village. It was Peter Norman who suggested Carlos wear Smith's left-handed glove. For this reason, Carlos raised his left hand as opposed to his right, differing from the traditional Black Power salute. When \"The Star-Spangled Banner\" played, Smith and Carlos delivered the salute with heads bowed, a gesture which became front-page news around the world. As they left the podium they were booed by the crowd. Smith later said, \"If I win, I am American, not a black American. But if I did something bad, then they would say I am a Negro. We are black and we are proud of being black. Black America will understand what we did tonight.\"\n\nTommie Smith stated in later years that \"We were concerned about the lack of black assistant coaches. About how Muhammad Ali got stripped of his title. About the lack of access to good housing and our kids not being able to attend the top colleges.\"\n\nInternational Olympic Committee (IOC) president Avery Brundage deemed it to be a domestic political statement unfit for the apolitical, international forum the Olympic Games were intended to be. In response to their actions, he ordered Smith and Carlos suspended from the US team and banned from the Olympic Village. When the US Olympic Committee refused, Brundage threatened to ban the entire US track team. This threat led to the expulsion of the two athletes from the Games.\n\nA spokesman for the IOC said Smith and Carlos's actions were \"a deliberate and violent breach of the fundamental principles of the Olympic spirit.\" Brundage, who was president of the United States Olympic Committee in 1936, had made no objections against Nazi salutes during the Berlin Olympics. He argued that the Nazi salute, being a national salute at the time, was acceptable in a competition of nations, while the athletes' salute was not of a nation and therefore unacceptable.\n\nBrundage had been accused of being one of the United States' most prominent Nazi sympathisers even after the outbreak of the Second World War, and his removal as president of the IOC had been one of the three stated objectives of the Olympic Project for Human Rights.\n\nIn 2013, the official IOC website stated that \"Over and above winning medals, the black American athletes made names for themselves by an act of racial protest.\"\n\nSmith and Carlos were largely ostracized by the US sporting establishment and they were subject to criticism. \"Time\" magazine on October 25, 1968, wrote: \"'Faster, Higher, Stronger' is the motto of the Olympic Games. 'Angrier, nastier, uglier' better describes the scene in Mexico City last week.\" Back home, both Smith and Carlos were subject to abuse and they and their families received death threats.\n\nSmith continued in athletics, playing in the NFL with the Cincinnati Bengals before becoming an assistant professor of physical education at Oberlin College. In 1995, he helped coach the US team at the World Indoor Championships at Barcelona. In 1999 he was awarded the California Black Sportsman of the Millennium Award. He is now a public speaker.\nCarlos' career followed a similar path. He tied the 100 yard dash world record the following year. Carlos also tried professional football, was a 15th round selection in the 1970 NFL Draft, but a knee injury curtailed his tryout with the Philadelphia Eagles. He then went on to the Canadian Football League where he played one season for the Montreal Alouettes. He fell upon hard times in the late 1970s. In 1977, his ex-wife committed suicide, leading him to a period of depression. In 1982, Carlos was employed by the Organizing Committee for the 1984 Summer Olympics in Los Angeles to promote the games and act as liaison with the city's black community. In 1985, he became a track and field coach at Palm Springs High School. As of 2012, Carlos works as a counselor at the school.\n\nSmith and Carlos received an Arthur Ashe Courage Award at the 2008 ESPY Awards honoring their action.\n\nNorman, who was sympathetic to his competitors' protest, was criticized by conservatives in the Australian media. Julius Patching, the Australian Chef de Mission, was amused and semi-jokingly told Norman off in private with the words, \"They're screaming out for your blood, so consider yourself severely reprimanded. Now, you got any tickets for the hockey today?\" He was not picked for the 1972 Summer Olympics, despite having qualified 13 times over. However Australian officials say he was not picked because he came third in the Australian trials, in part due to a knee injury which severely affected his performance; that he was only cautioned after the 1968 incident, and he had been profiled \"one of our finest Olympians\". Norman also represented Australia at the 1970 Commonwealth Games.\n\nWhen Norman died in 2006, Smith and Carlos were pallbearers at his funeral.\n\nIn 2012, Australia formally apologized to Norman, with one MP telling Parliament that Norman's gesture \"was a moment of heroism and humility that advanced international awareness for racial inequality.\"\n\nWayne Collett and Vincent Matthews were banned from the Olympics after they staged a similar protest at the 1972 games in Munich.\n\nThe 2008 Sydney Film Festival featured a documentary about the protest entitled \"Salute\". The film was written, directed and produced by Matt Norman, a nephew of Peter Norman.\n\nOn July 9, 2008, BBC Four broadcast a documentary, \"Black Power Salute\", by Geoff Small, about the protest. In an article, Small noted that the athletes of the British team attending the 2008 Olympics in Beijing had been asked to sign gagging clauses which would have restricted their right to make political statements but that they had refused.\n\nIn a 2011 speech to the University of Guelph, Akaash Maharaj, a member of the Canadian Olympic Committee and head of Canada's Olympic equestrian team, said, \"In that moment, Tommie Smith, Peter Norman, and John Carlos became the living embodiments of Olympic idealism. Ever since, they have been inspirations to generations of athletes like myself, who can only aspire to their example of putting principle before personal interest. It was their misfortune to be far greater human beings than the leaders of the IOC of the day.\"\n\nIn 2016, the National Museum of African American History and Culture in Washington, DC also features a statue to honor the athletes' tribute.\n\nIn 2005, San Jose State University honored former students Smith and Carlos with a 22-foot high statue of their protest titled \"Victory Salute\", created by artist Rigo 23. A student, Erik Grotz, initiated the project; \"One of my professors was talking about unsung heroes and he mentioned Tommie Smith and John Carlos. He said these men had done a courageous thing to advance civil rights, and, yet, they had never been honored by their own school.\" The statues are located in a central part of the campus at , next to Robert D. Clark Hall and Tower Hall.\n\nThose who come to view the statue are allowed to participate by standing on the monument. Peter Norman is not included in the monument so viewers can be in his place; there is a plaque in the empty spot inviting those to \"Take a Stand.\" Norman requested that his space was left empty so visitors could stand in his place and feel what he felt.\nThe bronze figures are shoeless but there are two shoes included at the base of the monument. The right shoe, a bronze, blue Puma, is next to Carlos; while the left shoe is placed behind Smith. The signature of the artist is on the back of Smith's shoe, and the year 2005 is on Carlos's shoe.\n\nThe faces of the statues are realistic and emotional. \"The statue is made of fiberglass stretched over steel supports with an exoskeleton of ceramic tiles.\" Rigo 23 used 3D scanning technology and computer-assisted virtual imaging to take full-body scans of the men. Their track pants and jackets are a mosaic of dark blue ceramic tiles while the stripes of the track suits are detailed in red and white.\n\nIn January 2007, History San Jose opened a new exhibit called \"Speed City: From Civil Rights to Black Power\", covering the San Jose State athletic program \"from which many student athletes became globally recognized figures as the Civil Rights and Black Power movements reshaped American society.\"\n\nIn Australia, an airbrush mural of the trio on podium was painted in 2000 in the inner-city suburb of Newtown in Sydney. Silvio Offria, who allowed the mural to be painted on his house in Leamington Lane by an artist known only as \"Donald,\" said that Norman, a short time before he died in 2006, came to see the mural. \"He came and had his photo taken; he was very happy,\" he said. The monochrome tribute, captioned \",\" was under threat of demolition in 2010 to make way for a rail tunnel but is now listed as an item of heritage significance.\n\nIn the historically African-American neighborhood of West Oakland, California there was a large mural depicting Smith and Carlos on the corner of 12th Street and Mandela Parkway.\n\nAbove the life-sized depictions read \"Born with insight, raised with a fist\" (Rage Against the Machine lyrics); previously it read \"It only takes a pair of gloves.\" In early February 2015, the mural was razed.\n\nThe private lot was once a gas station, and the mural was on the outside wall of an abandoned building or shed. The owner wanted to pay respect to the men and the moment but also wanted a mural to prevent tagging. The State was monitoring water contamination levels at this site; the testing became within normal levels \"so the state ordered the removal of the tanks, testing equipment, and demolition of the shed.\"\n\nThe song \"Mr. John Carlos\" by the Swedish group Nationalteatern on their 1974 album \"Livet är en fest\" is about the event and its aftermath.\n\nRage Against the Machine used a cropped photo of the salute on the cover art for the \"Testify\" single (2000). The image has both men wearing shoes.\n\nThe cover art for the single \"HiiiPoWeR\" (2011) by American rapper Kendrick Lamar features a cropped photo of the salute.\n\nThe song \"Hoarse\" (2013) by American rapper Earl Sweatshirt features the lines \"pinnacle of titillating crispate, fists clenched, emulating '68 Olympics\".\n\nThe music video for \"The Story of O.J.\" (2017) by American rapper Jay-Z features a depiction of the protest.\n\nThe song \"Shivers\" by Peter Perrett, best known as the frontman of The Only Ones, features the lines \"The torch of liberty, Tommie Smith's black glove\".\n\nThe music video for \"The Space Program\" (2017) by American Hip-Hop group A Tribe Called Quest features Pharrell Williams imitating the salute.\n\n\n\n"}
{"id": "2179718", "url": "https://en.wikipedia.org/wiki?curid=2179718", "title": "Acharya", "text": "Acharya\n\nIn Indian religions and society, an acharya (IAST: ) is a preceptor or instructor in religious matters; founder, or leader of a sect; or a highly learned person or a title affixed to the names of learned people. The designation has different meanings in Hinduism, Buddhism and secular contexts. It is also a Vishwabrahmin/brahmin surname found in Nepal and across India, including Odisha, Karnataka, West Bengal and Maharashtra.\n\nAcharya is sometimes used to address a teacher or a scholar in any discipline, e.g.: Bhaskaracharya, the mathematician.\n\nThe term \"acharya\" is most often said to include the root \"char\" or \"charya\" (conduct). Thus it literally connotes \"one who teaches by conduct (example)\", i.e. an exemplar.\n\nIn Hinduism, an \"acharya\" (आचार्य) is a formal title of a teacher or guru, who has attained a degree in Veda and Vedanga.\n\nProminent acharyas in the Hindu tradition are as given below :\n\n\n\nIn Buddhism, acharya is a senior teacher. Notable acharyas:\n\nIn Jainism, an \"acharya\" is the highest leader of a Jain order. \"Acharya\" is one of the Pañca-Parameṣṭhi (five supreme beings) and thus worthy of worship. They are the final authority in the monastic order and has the authority to ordain new monks and nuns. They are also authorized to consecrate new idols, although this authority is sometimes delegated to scholars designated by them.\n\nAn acharya, like any other Jain monk, is expected to wander except for the Chaturmas. Bhaṭṭārakas, who head institutions, are technically junior monks, and thus permitted to stay in the same place.\n\n\nIn Sanskrit institutions, acharya is a post-graduate degree.\n\n\n"}
{"id": "47768545", "url": "https://en.wikipedia.org/wiki?curid=47768545", "title": "Andrés Waissman", "text": "Andrés Waissman\n\nAndrés Waissman is a visual artist born in Buenos Aires, Argentina, in 1955. A relevant figure of Argentinian and Latin-American contemporary art, he is known for paintings such as \"Multitudes\", \"Black & White\", and his most recent work, \"Virutas\". He lives and works in Buenos Aires.\n\nWaissman was born in Buenos Aires on July 14, 1955. The third and last son of Carlos Luis Waissman and Regina Tchira, he had a close relationship with the art world since he was a child. Trained in independent workshops, he began exhibiting quite early in the mid 1970s, having his first solo shows at 'Lirolay Gallery' in 1973 and 1977, respectively. At the same time, he hosted AM and FM radio programs, interviewing critics, intellectuals and artists of various artistic expressions. In 1974 he worked in the studio of Augusto Torres in Barcelona, and in 1978 in Paris with Antonio Seguí. In 1984 he moved to San Francisco, where he worked at the Argentinian Consulate as the cultural attaché. It was while he was at the consulate that his career developed internationally, exhibiting in galleries and museums in Los Angeles, San Francisco, New York, and cities throughout Europe.\n\nIn 1992 he returned to Buenos Aires, where he began teaching. For three and a half years he and Marina Pellegrini co-hosted \"Styles\", a television program dedicated to rescuing cultural values, especially in the visual arts. In 1995 he opened \"Dock del Plata Espacio de Arte\", the first showroom in Puerto Madero. It became one of the most prestigious studios in the city until its closure in 1998. After the closure of the studio, Andrés Waissman began to work as a curator and communicator, advising many national public officers and agencies in projects and cultural management strategies.\n\nIn 2005 the book \"Waissman/a pilgrim artist\" was published. In November 2010 the documentary \"Waissman\", by Eduardo Montes Bradley, premiered on WPBT Channel 2 (PBS) in the United States, as well as being shown at the Museo de Arte Latinoamericano de Buenos Aires (MALBA).\n\nSince 2012 Waissman, along with Rodrigo Alonso, Carlos Herrera, Gabriel Valansi and Eduardo Stupía, has been one of the head teachers for \"Proyecto PAC: Prácticas Artísticas Contemporáneas\", an annual meeting with a program of art analysis, critique and production. He continues working on his art and developing new art related projects in his studio in Palermo, Buenos Aires, where he also leads a Studio Cri Program and workshops.\n\nHe has had several solo exhibitions and more than sixty collective exhibits in both Argentina and international cities. His work is part of private collections and museums in England, Belgium, Italy, Israel, the United States, Venezuela, Argentina, and Chile, among others. He has also participated in international fairs such as: the Pinta in London; the Lisbon Art Fair; the Miami International Art Fair; the Chicago Contemporary & Classic Art Fair; Ch.ACO in Santiago de Chile; the Miart Fiera Internazionale d'Arte Moderna e Contemporanea Milano; and the arteBA in Buenos Aires.\n"}
{"id": "2097128", "url": "https://en.wikipedia.org/wiki?curid=2097128", "title": "Anti-art", "text": "Anti-art\n\nAnti-art is a loosely used term applied to an array of concepts and attitudes that reject prior definitions of art and question art in general. Somewhat paradoxically, anti-art tends to conduct this questioning and rejection from the vantage point of art. The term is associated with the Dada movement and is generally accepted as attributable to Marcel Duchamp pre-World War I around 1914, when he began to use found objects as art. It was used to describe revolutionary forms of art. The term was used later by the Conceptual artists of the 1960s to describe the work of those who claimed to have retired altogether from the practice of art, from the production of works which could be sold.\n\nAn expression of anti-art may or may not take traditional form or meet the criteria for being defined as a work of art according to conventional standards. Indeed, works of anti-art may express an outright rejection of having conventionally defined criteria as a means of defining what art is, and what it is not. Anti-artworks may reject conventional artistic standards altogether, or focus criticism only on certain aspects of art, such as the art market and high art. Some anti-artworks may reject individualism in art, whereas some may reject \"universality\" as an accepted factor in art. Additionally, some forms of anti-art reject art entirely, or reject the idea that art is a separate realm or specialization. Anti-artworks may also reject art based upon a consideration of art as being oppressive of a segment of the population.\n\nAnti-art artworks may articulate a disagreement with the generally supposed notion of there being a separation between art and life. Indeed, anti-art artworks may voice a question as to whether \"art\" really exists or not. \"Anti-art\" has been referred to as a \"paradoxical neologism\", in that its obvious opposition to art has been observed concurring with staples of twentieth-century art or \"modern art\", in particular art movements that have self-consciously sought to transgress traditions or institutions. Anti-art itself is not a distinct art movement, however. This would tend to be indicated by the time it spans—longer than that usually spanned by art movements. Some art movements though, are labeled \"anti-art\". The Dada movement is generally considered the first anti-art movement; the term anti-art itself is said to have been coined by Dadaist Marcel Duchamp around 1914, and his readymades have been cited as early examples of anti-art objects. Theodor W. Adorno in \"Aesthetic Theory\" (1970) stated that \"...even the abolition of art is respectful of art because it takes the truth claim of art seriously\".\n\nAnti-art has become generally accepted by the artworld to be art, although some people still reject Duchamp's readymades as art, for instance the Stuckist group of artists, who are \"anti-anti-art\".\n\nAnti-art can take the form of art or not. It is posited that anti-art need not even take the form of art, in order to embody its function as anti-art. This point is disputed. Some of the forms of anti-art which are art strive to reveal the conventional limits of art by expanding its properties.\n\nSome instances of anti-art are suggestive of a reduction to what might seem to be fundamental elements or building blocks of art. Examples of this sort of phenomenon might include monochrome paintings, empty frames, silence as music, chance art. Anti-art is also often seen to make use of highly innovative materials and techniques, and well beyond—to include hitherto unheard of elements in visual art. These types of anti-art can be readymades, found object art, détournement, combine paintings, appropriation (art), happenings, performance art, and body art.\n\nAnti-art can involve the renouncement of making art entirely. This can be accomplished through an art strike and this can also be accomplished through revolutionary activism. An aim of anti-art can be to undermine or understate individual creativity. This may be accomplished through the utilization of readymades. Individual creativity can be further downplayed by the use of industrial processes in the making of art. \"Anti-artists\" may seek to undermine individual creativity by producing their artworks anonymously. They may refuse to show their artworks. They may refuse public recognition. Anti-artists may choose to work collectively, in order to place less emphasis on individual identity and individual creativity. This can be seen in the instance of happenings. This is sometimes the case with \"supertemporal\" artworks, which are by design impermanent. Anti-artists will sometimes destroy their works of art. Some artworks made by anti-artists are purposely created to be destroyed. This can be seen in auto-destructive art.\n\nAndré Malraux has developed a concept of anti-art quite different from that outlined above. For Malraux, anti-art began with the 'Salon' or 'Academic' art of the nineteenth century which rejected the basic ambition of art in favour of a semi-photographic illusionism (often prettified). Of Academic painting, Malraux writes, 'All true painters, all those for whom painting is a value, were nauseated by these pictures – \"Portrait of a Great Surgeon Operating\" and the like – because they saw in them not a form of painting, but the negation of painting'. For Malraux, anti-art is still very much with us, though in a different form. Its descendants are commercial cinema and television, and popular music and fiction. The 'Salon', Malraux writes, 'has been expelled from painting, but elsewhere it reigns supreme'.\n\nAnti-art is also a tendency in the theoretical understanding of art and fine art.\n\nThe philosopher Roger Taylor puts forward that art is a bourgeois ideology that has its origins with capitalism in \"Art, an Enemy of the People\". Holding a strong anti-essentialist position he states also that art has not always existed and is not universal but peculiar to Europe, a claim that is factually inaccurate as proven by many substantial archaeological findings on the Asian and African continents.\n\n\"\" by Larry Shiner is an art history book which fundamentally questions our understanding of art.\n\"The modern system of art is not an essence or a fate but something we have made. Art as we have generally understood it is a European invention barely two hundred years old.\" (Shiner 2003, p. 3)\nShiner presents (fine) art as a social construction that has not always existed throughout human history and could also disappear in its turn.\n\nJean-Jacques Rousseau rejected the separation between performer and spectator, life and theatre. Karl Marx posited that art was a consequence of the class system and therefore concluded that, in a communist society, there would only be people who engage in the making of art and no \"artists\".\n\nArguably the first movement that deliberately set itself in opposition to established art were the Incoherents in late 19th. century Paris. Founded by Jules Lévy in 1882, the Incoherents organized charitable art exhibitions intended to be satirical and humoristic, they presented \"...drawings by people who can't draw...\" and held masked balls with artistic themes, all in the greater tradition of Montmartre cabaret culture. While short lived – the last Incoherent show took place in 1896 – the movement was popular for its entertainment value. In their commitment to satire, irreverence and ridicule they produced a number of works that show remarkable formal similarities to creations of the avant-garde of the 20th century: ready-mades, monochromes, empty frames and silence as music.\n\nBeginning in Switzerland, during World War I, much of Dada, and some aspects of the art movements it inspired, such as Neo-Dada, Nouveau réalisme, and Fluxus, is considered anti-art. Dadaists rejected cultural and intellectual conformity in art and more broadly in society. For everything that art stood for, Dada was to represent the opposite.\n\nWhere art was concerned with traditional aesthetics, Dada ignored aesthetics completely. If art was to appeal to sensibilities, Dada was intended to offend. Through their rejection of traditional culture and aesthetics the Dadaists hoped to destroy traditional culture and aesthetics. Because they were more politicized, the Berlin dadas were the most radically anti-art within Dada. In 1919, in the Berlin group, the Dadaist revolutionary central council outlined the Dadaist ideals of radical communism.\n\nBeginning in 1913 Marcel Duchamp's readymades challenged individual creativity and redefined art as a nominal rather than an intrinsic object.\n\nTristan Tzara indicated: \"I am against systems; the most acceptable system is on principle to have none.\" In addition, Tzara, who once stated that \"logic is always false\", probably approved of Walter Serner's vision of a \"final dissolution\". A core concept in Tzara's thought was that \"as long as we do things the way we think we once did them we will be unable to achieve any kind of livable society.\"\n\nOriginating in Russia in 1919, constructivism rejected art in its entirety and as a specific activity creating a universal aesthetic in favour of practices directed towards social purposes, \"useful\" to everyday life, such as graphic design, advertising and photography. In 1921, exhibiting at the 5x5=25 exhibition, Alexander Rodchenko created monochromes and proclaimed the end of painting. For artists of the Russian Revolution, Rodchenko's radical action was full of utopian possibility. It marked the end of art along with the end of bourgeois norms and practices. It cleared the way for the beginning of a new Russian life, a new mode of production, a new culture.\n\nBeginning in the early 1920s, many Surrealist artists and writers regard their work as an expression of the philosophical movement first and foremost, with the works being an artifact. Surrealism as a political force developed unevenly around the world, in some places more emphasis being put on artistic practices, while in others political practises outweighed. In other places still, Surrealist praxis looked to overshadow both the arts and politics. Politically, Surrealism was ultra-leftist, communist, or anarchist. The split from Dada has been characterised as a split between anarchists and communists, with the Surrealists as communist. In 1925, the Bureau of Surrealist Research declared their affinity for revolutionary politics. By the 1930s many Surrealists had strongly identified themselves with communism. Breton and his comrades supported Leon Trotsky and his International Left Opposition for a while, though there was an openness to anarchism that manifested more fully after World War II.\n\nLeader André Breton was explicit in his assertion that Surrealism was above all a revolutionary movement. Breton believed the tenets of Surrealism could be applied in any circumstance of life, and is not merely restricted to the artistic realm. Breton's followers, along with the Communist Party, were working for the \"liberation of man.\" However, Breton's group refused to prioritize the proletarian struggle over radical creation such that their struggles with the Party made the late 1920s a turbulent time for both. Many individuals closely associated with Breton, notably Louis Aragon, left his group to work more closely with the Communists. In 1929, Breton asked Surrealists to assess their \"degree of moral competence\", and theoretical refinements included in the second \"manifeste du surréalisme\" excluded anyone reluctant to commit to collective action\n\nBy the end of World War II the surrealist group led by André Breton decided to explicitly embrace anarchism. In 1952 Breton wrote \"It was in the black mirror of anarchism that surrealism first recognised itself.\"\n\nFounded in the mid-1940s in France by Isidore Isou, the Letterists utilised material appropriated from other films, a technique which would subsequently be developed (under the title of 'détournement') in Situationist films. They would also often supplement the film with live performance, or, through the 'film-debate', directly involve the audience itself in the total experience. The most radical of the Letterist films, Wolman's \"The Anticoncept\" and Debord's \"Howls for Sade\" abandoned images altogether.\n\nIn 1956, recalling the infinitesimals of Gottfried Wilhelm Leibniz, quantities which could not actually exist except conceptually, the founder of Lettrism, Isidore Isou, developed the notion of a work of art which, by its very nature, could never be created in reality, but which could nevertheless provide aesthetic rewards by being contemplated intellectually. Related to this, and arising out of it, is excoördism, the current incarnation of the Isouian movement, defined as the art of the infinitely large and the infinitely small.\n\nIn 1960, Isidore Isou created supertemporal art: a device for inviting and enabling an audience to participate in the creation of a work of art. In its simplest form, this might involve nothing more than the inclusion of several blank pages in a book, for the reader to add his or her own contributions.\n\nIn Japan in the late 1950s, Group Kyushu was an edgy, experimental and rambunctious art group. They ripped and burned canvasses, stapled corrugated cardboard, nails, nuts, springs, metal drill shavings, and burlap to their works, assembled all kinds of unwieldy junk assemblages, and were best known for covering much of their work in tar. They also occasionally covered their work in urine and excrement. They tried to bring art closer to everyday life, by incorporating objects from daily life into their work, and also by exhibiting and performing their work outside on the street for everyone to see.\n\nOther similar anti-art groups included Neo-Dada (Neo-Dadaizumu Oganaizazu), Gutai (Gutai Bijutsu Kyokai), and Hi-Red-Center. Influenced in various ways by L'Art Informel, these groups and their members worked to foreground material in their work: rather than seeing the art work as representing some remote referent, the material itself and the artists' interaction with it became the main point. The freeing up of gesture was another legacy of L'Art Informel, and the members of Group Kyushu took to it with great verve, throwing, dripping, and breaking material, sometimes destroying the work in the process.\n\nBeginning in the 1950s in France, the Letterist International and after the Situationist International developed a dialectical viewpoint, seeing their task as \"superseding\" art, abolishing the notion of art as a separate, specialized activity and transforming it so it became part of the fabric of everyday life. From the Situationist's viewpoint, art is revolutionary or it is nothing. In this way, the Situationists saw their efforts as completing the work of both Dada and surrealism while abolishing both.\nThe situationists renounced the making of art entirely.\n\nThe members of the Situationist International liked to think they were probably the most radical, politicized, well organized, and theoretically productive anti-art movement, reaching their apex with the student protests and general strike of May 1968 in France, a view endorsed by others including the academic Martin Puchner.\n\nIn 1959 Giuseppe Pinot-Gallizio proposed Industrial Painting as an \"industrial-inflationist art\"\n\nSimilar to Dada, in the 1960s, Fluxus included a strong current of anti-commercialism and an anti-art sensibility, disparaging the conventional market-driven art world in favor of an artist-centered creative practice. Fluxus artists used their minimal performances to blur the distinction between life and art.\n\nIn 1962 Henry Flynt began to campaign for an anti-art position. Flynt wanted avant-garde art to become superseded by the terms of \"veramusement\" and \"brend\" – neologisms meaning approximately pure recreation.\n\nIn 1963 George Maciunas advocated revolution, \"living art, anti-art\" and \"non art reality to be grasped by all peoples\". Maciunas strived to uphold his stated aims of demonstrating the artist's 'non-professional status...his dispensability and inclusiveness' and that 'anything can be art and anyone can do it.'\n\nIn the 1960s, the Dada-influenced art group Black Mask declared that revolutionary art should be \"an integral part of life, as in primitive society, and not an appendage to wealth\". Black Mask disrupted cultural events in New York by giving made up flyers of art events to the homeless with the lure of free drinks. Later, the Motherfuckers were to grow out of a combination of Black Mask and another group called Angry Arts.\n\nThe BBC aired an interview with Duchamp conducted by Joan Bakewell in 1966 which expressed some of Duchamps more explicit Anti-Art ideas.\nDuchamp compared art with religion, whereby he stated that he wished to do away with art the same way many have done away with religion. Duchamp goes on to explain to the interviewer that \"the word art etymologically means to do\", that art means activity of any kind, and that it is our society that creates \"purely artificial\" distinctions of being an artist.\n\nDuring the 1970s, King Mob was responsible for various attacks on art galleries. According to the philosopher Roger Taylor the concept of art is not universal but is an invention of bourgeois ideology helping to promote this social order. He compares it to a cancer that colonises other forms of life so that it becomes difficult to distinguish one from the other.\n\nStewart Home called for an Art Strike between 1990 and 1993. Unlike earlier art-strike proposals such as that of Gustav Metzger in the 1970s, it was not intended as an opportunity for artists to seize control of the means of distributing their own work, but rather as an exercise in propaganda and psychic warfare aimed at smashing the entire art world rather than just the gallery system. As Black Mask had done in the 1960s, Stewart Home disrupted cultural events in London in the 1990s by giving made up flyers of literary events to the homeless with the lure of free drinks.\n\nThe K Foundation was an art foundation that published a series of Situationist-inspired press adverts and extravagant subversions in the art world. Most notoriously, when their plans to use banknotes as part of a work of art fell through, they burnt a million pounds in cash.\n\nPunk has developed anti-art positions. Some \"industrial music\" bands describe their work as a form of \"cultural terrorism\" or as a form of \"anti-art\". The term is also used to describe other intentionally provocative art forms, such as nonsense verse.\n\nParadoxically, most forms of anti-art have gradually been completely accepted by the art establishment as normal and conventional forms of art. Even the movements which rejected art with the most virulence are now collected by the most prestigious cultural institutions.\n\nDuchamp's readymades are still regarded as anti-art by the Stuckists, who also say that anti-art has become conformist, and describe themselves as anti-anti-art.\n\n\n\n"}
{"id": "576855", "url": "https://en.wikipedia.org/wiki?curid=576855", "title": "Binary decision diagram", "text": "Binary decision diagram\n\nIn computer science, a binary decision diagram (BDD) or branching program is a data structure that is used to represent a Boolean function. On a more abstract level, BDDs can be considered as a compressed representation of sets or relations. Unlike other compressed representations, operations are performed directly on the compressed representation, i.e. without decompression. Other data structures used to represent a Boolean function include negation normal form (NNF), and propositional directed acyclic graph (PDAG).\n\nA Boolean function can be represented as a rooted, directed, acyclic graph, which consists of several decision nodes and terminal nodes. There are two types of terminal nodes called 0-terminal and 1-terminal. Each decision node formula_1 is labeled by Boolean variable formula_2 and has two child nodes called low child and high child. The edge from node formula_2 to a low (or high) child represents an assignment of formula_2 to 0 (resp. 1).\nSuch a BDD is called 'ordered' if different variables appear in the same order on all paths from the root. A BDD is said to be 'reduced' if the following two rules have been applied to its graph:\n\nIn popular usage, the term BDD almost always refers to Reduced Ordered Binary Decision Diagram (ROBDD in the literature, used when the ordering and reduction aspects need to be emphasized). The advantage of an ROBDD is that it is canonical (unique) for a particular function and variable order. This property makes it useful in functional equivalence checking and other operations like functional technology mapping.\n\nA path from the root node to the 1-terminal represents a (possibly partial) variable assignment for which the represented Boolean function is true. As the path descends to a low (or high) child from a node, then that node's variable is assigned to 0 (resp. 1).\n\nThe left figure below shows a binary decision \"tree\" (the reduction rules are not applied), and a truth table, each representing the function f (x1, x2, x3). In the tree on the left, the value of the function can be determined for a given variable assignment by following a path down the graph to a terminal. In the figures below, dotted lines represent edges to a low child, while solid lines represent edges to a high child. Therefore, to find (x1=0, x2=1, x3=1), begin at x1, traverse down the dotted line to x2 (since x1 has an assignment to 0), then down two solid lines (since x2 and x3 each have an assignment to one). This leads to the terminal 1, which is the value of f (x1=0, x2=1, x3=1).\n\nThe binary decision \"tree\" of the left figure can be transformed into a binary decision \"diagram\" by maximally reducing it according to the two reduction rules. The resulting BDD is shown in the right figure.\n\nThe basic idea from which the data structure was created is the Shannon expansion. A switching function is split into two sub-functions (cofactors) by assigning one variable (cf. \"if-then-else normal form\"). If such a sub-function is considered as a sub-tree, it can be represented by a \"binary decision tree\". Binary decision diagrams (BDD) were introduced by Lee, and further studied and made known by Akers and Boute.\n\nThe full potential for efficient algorithms based on the data structure was investigated by Randal Bryant at Carnegie Mellon University: his key extensions were to use a fixed variable ordering (for canonical representation) and shared sub-graphs (for compression). Applying these two concepts results in an efficient data structure and algorithms for the representation of sets and relations. By extending the sharing to several BDDs, i.e. one sub-graph is used by several BDDs, the data structure \"Shared Reduced Ordered Binary Decision Diagram\" is defined. The notion of a BDD is now generally used to refer to that particular data structure.\n\nIn his video lecture \"Fun With Binary Decision Diagrams (BDDs)\", Donald Knuth calls BDDs \"one of the only really fundamental data structures that came out in the last twenty-five years\" and mentions that Bryant's 1986 paper was for some time one of the most-cited papers in computer science.\n\nAdnan Darwiche and his collaborators have shown that BDDs are one of several normal forms for Boolean functions, each induced by a different combination of requirements. Another important normal form identified by Darwiche is Decomposable Negation Normal Form or DNNF.\n\nBDDs are extensively used in CAD software to synthesize circuits (logic synthesis) and in formal verification. There are several lesser known applications of BDD, including fault tree analysis, Bayesian reasoning, product configuration, and private information retrieval.\nEvery arbitrary BDD (even if it is not reduced or ordered) can be directly implemented in hardware by replacing each node with a 2 to 1 multiplexer; each multiplexer can be directly implemented by a 4-LUT in a FPGA. It is not so simple to convert from an arbitrary network of logic gates to a BDD (unlike the and-inverter graph).\n\nThe size of the BDD is determined both by the function being represented and the chosen ordering of the variables. There exist Boolean functions formula_5 for which depending upon the ordering of the variables we would end up getting a graph whose number of nodes would be linear (in \"n\") at the best and exponential at the worst case (e.g., a ripple carry adder). Let us consider the Boolean function formula_6\nUsing the variable ordering formula_7, the BDD needs 2 nodes to represent the function. Using the ordering formula_8, the BDD consists of 2\"n\" + 2 nodes.\n\nIt is of crucial importance to care about variable ordering when applying this data structure in practice.\nThe problem of finding the best variable ordering is NP-hard. For any constant \"c\" > 1 it is even NP-hard to compute a variable ordering resulting in an OBDD with a size that is at most c times larger than an optimal one. However, there exist efficient heuristics to tackle the problem.\n\nThere are functions for which the graph size is always exponential — independent of variable ordering. This holds e.g. for the multiplication function. In fact, the function computing the middle bit of the product of two formula_9-bit numbers does not have an OBDD smaller than formula_10 vertices. (If the multiplication function had polynomial-size OBDDs, it would show that integer factorization is in P/poly, which is not known to be true.)\n\nResearchers have suggested refinements on the BDD data structure giving way to a number of related graphs, such as BMD (binary moment diagrams), ZDD (zero-suppressed decision diagram), FDD (free binary decision diagrams), PDD (parity decision diagrams), and MTBDDs (multiple terminal BDDs).\n\nMany logical operations on BDDs can be implemented by polynomial-time graph manipulation algorithms:\n\nHowever, repeating these operations several times, for example forming the conjunction or disjunction of a set of BDDs, may in the worst case result in an exponentially big BDD. This is because any of the preceding operations for two BDDs may result in a BDD with a size proportional to the product of the BDDs' sizes, and consequently for several BDDs the size may be exponential. Also, since constructing the BDD of a Boolean function solves the NP-complete Boolean satisfiability problem and the co-NP-complete tautology problem, constructing the BDD can take exponential time in the size of the Boolean formula even when the resulting BDD is small.\n\n\n\n\n"}
{"id": "56253151", "url": "https://en.wikipedia.org/wiki?curid=56253151", "title": "Carpenter's lar gibbon", "text": "Carpenter's lar gibbon\n\nCarpenter's lar gibbon, \"Hylobates lar carpenteri\", is an endangered subspecies of white-handed gibbon, also known as the lar gibbon. It is listed as an endangered species because it is believed to have undergone a decline of more than 50% in the prior three generations due to loss of forest habitat and loss of mature individuals to hunting. The subspecific name honors primatologist Clarence R. Carpenter.\n\nThe subspecies is distinguished by sharply distinct dark and light color forms, both having a ring of white hair around the face, with hands and feet white sometimes as far as the wrists and ankles, and the hair much longer than in other subspecies. The dark form is very dark chocolate brown, the tips of the hairs being blackish and their bases silvery-brown, whereas the light form is creamy-white, with the basal one-quarter to one-third of the hairs light gray. Its range is confined to northern and part of northeastern Thailand. In the southwest part of its range, its distribution abuts that of the pileated gibbon, \"Hylobates pileatus\".\n\n"}
{"id": "43284488", "url": "https://en.wikipedia.org/wiki?curid=43284488", "title": "Change (philosophy)", "text": "Change (philosophy)\n\nChange refers to a difference in a state of affairs at different points in time. Although it is a familiar experience, an analysis of change provides subtle problems which have occupied philosophers since the Presocratics. Heraclitus is the first philosopher known to have directly raised such issues, with aphorisms such as \"one cannot step into the same river twice\". The Eleatics were particularly concerned with change and raised a number of problems, including Zeno's paradoxes, which caused them to go as far as insisting that change was impossible, and that reality was one and unchanging. Later philosophers would reject this conclusion, instead developing systems such as atomism in attempts to circumvent the Eleatic problems. In the modern era, some of these problems would enter the domain of mathematics, with the development of calculus and analysis. These developments were regarded by some as solving problems of change, but others maintain that philosophical issues persist.\n\nThe Chinese philosophy of change was described in centuries of commentary on the \"I Ching\", the Book of Changes.\n\nHeraclitus is the first philosopher for whom there exists an extant written account of an enquiry into change. Writing in an aphoristic and esoteric style, Heraclitus remarked that, \"On those stepping into rivers staying the same other and other waters flow\". Or, more popularly: \"One cannot step into the same river twice.\" This is generally taken to refer to the seeming contradiction between our calling a river \"the same\", while knowing that the material constituents of a river, the \"waters\", have completely changed. (A later follower amended the final word in the saying from \"twice\" to \"once\".)\n\nIt is unclear what reaction Heraclitus intends to induce by this statement, and he provides no exposition. It is however but one of many examples of a more general theme which Heraclitus termed the \"unity of opposites\" - the fact that opposing predicates could be asserted of the same thing, another example being, \"the road up and the road down is one and the same\".\n\nChange was one of the chief concerns of the Eleatic school of thought founded by Parmenides. Parmenides considered non-existence to be absurd, and thus asserted that it was impossible for something to come into existence out of nothing, or for something to pass out of existence into nothing. By \"something\", he was referring not just to material, but to any general predicate; rejecting, for instance, changes of colour, as they involved the new colour arising from nothing and the old colour passing into nothing. He therefore rejected all change as impossible, and claimed that reality was an undifferentiated and unchanging whole.\n\nThese ideas were taken up by various followers of Parmenides, most notably Melissus and Zeno, who provided additional arguments, specifically for the impossibility of motion. Melissus claimed that reality was \"full\" (nonexistence being impossible), and that therefore nothing could move. Zeno gave a series of arguments which were particularly influential. Among the simplest was his observation that to move from A to B, one must first reach the halfway point between A and B; but then in order to do this, one must get halfway from A to this halfway point; and so on. Thus all motion involves an infinite number of steps, which Zeno held to be impossible. A similar argument involved a footrace between Achilles and a tortoise. The tortoise is given a headstart. Achilles quickly reaches the point where the tortoise stood, but by this time the tortoise has moved on a little, so Achilles must now reach this new point, and so on. A different argument involved the flight of an arrow. Zeno observed that if one considers a single moment of time, the arrow is not moving in that moment. He then claimed it was impossible that an arrow in motion could arise as the result of a sequence of motionless arrows.\n\nThe atomism of Democritus and Leucippus can be seen as a response to the Eleatic denial of change. The atomists conceded that something coming from or becoming nothing was impossible, but only with respect to material substance, not to general qualities. They hypothesised that every visible object was in fact a composite of unseen indivisible particles of different shapes and sizes. These particles were held to be eternal and unchanging, but by rearranging themselves, the composite objects which they formed could come into and go out of being. These composite objects and their properties were not taken as truly real; in the words of Democritus, \"by convention sweet, by convention bitter; by convention hot, by convention cold; by convention colour: but in reality atoms and void.\" Any perceived change in an object's properties was therefore illusory and not susceptible to the objections of Parmenides.\n\nAnaxagoras provided a similar response, but instead of atoms, he hypothesised a number of eternal, primal \"ingredients\" which were mixed together in a continuum. No material object was made of a pure ingredient; rather, it had its material character due to a preponderance of various ingredients over every other. In this way, Anaxagoras could assert that nowhere did any ingredient ever fully come into or go out of being.\n\n"}
{"id": "17257928", "url": "https://en.wikipedia.org/wiki?curid=17257928", "title": "Chastity (disambiguation)", "text": "Chastity (disambiguation)\n\nChastity is the sexual behavior of a man or woman acceptable to the ethical norms and guidelines of a certain culture, civilization or religion.\n\nChastity may also refer to:\n\nArts and entertainment:\n\nPeople:\n\nOther uses:\n\n"}
{"id": "7403", "url": "https://en.wikipedia.org/wiki?curid=7403", "title": "Chemotaxis", "text": "Chemotaxis\n\nChemotaxis (from \"chemo-\" + \"taxis\") is the movement of an organism in response to a chemical stimulus. Somatic cells, bacteria, and other single-cell or multicellular organisms direct their movements according to certain chemicals in their environment. This is important for bacteria to find food (e.g., glucose) by swimming toward the highest concentration of food molecules, or to flee from poisons (e.g., phenol). In multicellular organisms, chemotaxis is critical to early development (e.g., movement of sperm towards the egg during fertilization) and subsequent phases of development (e.g., migration of neurons or lymphocytes) as well as in normal function and health (e.g., migration of leukocytes during injury or infection). In addition, it has been recognized that mechanisms that allow chemotaxis in animals can be subverted during cancer metastasis.\n\n\"Positive\" chemotaxis occurs if the movement is toward a higher concentration of the chemical in question; \"negative\" chemotaxis if the movement is in the opposite direction. Chemically prompted kinesis (randomly directed or nondirectional) can be called chemokinesis.\n\nAlthough migration of cells was detected from the early days of the development of microscopy by Leeuwenhoek, a Caltech lecture regarding chemotaxis propounds that 'erudite description of chemotaxis was only first made by T. W. Engelmann (1881) and W. F. Pfeffer (1884) in bacteria, and H. S. Jennings (1906) in ciliates'. The Nobel Prize laureate I. Metchnikoff also contributed to the study of the field during 1882 to 1886, with investigations of the process as an initial step of phagocytosis. The significance of chemotaxis in biology and clinical pathology was widely accepted in the 1930s, and the most fundamental definitions underlying the phenomenon were drafted by this time. The most important aspects in quality control of chemotaxis assays were described by H. Harris in the 1950s. In the 1960s and 1970s, the revolution of modern cell biology and biochemistry provided a series of novel techniques that became available to investigate the migratory responder cells and subcellular fractions responsible for chemotactic activity. The availability of this technology led to the discovery of C5a, a major chemotactic factor involved in acute inflammation. The pioneering works of J. Adler represented a significant turning point in understanding the whole process of intracellular signal transduction of bacteria.\n\nSome bacteria, such as \"E. coli\", have several flagella per cell (4–10 typically). These can rotate in two ways:\nThe directions of rotation are given for an observer outside the cell looking down the flagella toward the cell.\n\nThe overall movement of a bacterium is the result of alternating tumble and swim phases. If one watches a bacterium swimming in a uniform environment, its movement will look like a random walk with relatively straight swims interrupted by random tumbles that reorient the bacterium. Bacteria such as \"E. coli\" are unable to choose the direction in which they swim, and are unable to swim in a straight line for more than a few seconds due to rotational diffusion; in other words, bacteria \"forget\" the direction in which they are going. By repeatedly evaluating their course, and adjusting if they are moving in the wrong direction, bacteria can direct their motion to find favorable locations with high concentrations of attractants (usually food) and avoid repellents (usually poisons).\n\nIn the presence of a chemical gradient bacteria will chemotax, or direct their overall motion based on the gradient. If the bacterium senses that it is moving in the correct direction (toward attractant/away from repellent), it will keep swimming in a straight line for a longer time before tumbling; however, if it is moving in the wrong direction, it will tumble sooner and try a new direction at random. In other words, bacteria like \"E. coli\" use temporal sensing to decide whether their situation is improving or not, and in this way, find the location with the highest concentration of attractant (usually the source) quite well. Even under very high concentrations, it can still distinguish very small differences in concentration, and fleeing from a repellent works with the same efficiency.\n\nThis biased random walk is a result of simply choosing between two methods of random movement; namely tumbling and straight swimming. In fact, chemotactic responses such as \"forgetting\" direction and \"choosing\" movements resemble the decision-making abilities of higher life-forms with brains that process sensory data.\n\nThe helical nature of the individual flagellar filament is critical for this movement to occur, and the protein that makes up the flagellar filament, flagellin, is quite similar among all flagellated bacteria. Vertebrates seem to have taken advantage of this fact by possessing an immune receptor (TLR5) designed to recognize this conserved protein.\n\nAs in many instances in biology, there are bacteria that do not follow this rule. Many bacteria, such as \"Vibrio\", are monoflagellated and have a single flagellum at one pole of the cell. Their method of chemotaxis is different. Others possess a single flagellum that is kept inside the cell wall. These bacteria move by spinning the whole cell, which is shaped like a corkscrew.\n\nChemical gradients are sensed through multiple transmembrane receptors, called methyl-accepting chemotaxis proteins (MCPs), which vary in the molecules that they detect. These receptors may bind attractants or repellents directly or indirectly through interaction with proteins of periplasmatic space. The signals from these receptors are transmitted across the plasma membrane into the cytosol, where \"Che proteins\" are activated. The Che proteins alter the tumbling frequency, and alter the receptors.\n\nThe proteins CheW and CheA bind to the receptor. The absence of receptor activation results in autophosphorylation in the histidine kinase, CheA, at a single highly conserved histidine residue. CheA, in turn, transfers phosphoryl groups to conserved aspartate residues in the response regulators CheB and CheY; CheA is a histidine kinase and it does not actively transfer the phosphoryl group, rather, the response regulator CheB takes the phosphoryl group from CheA. This mechanism of signal transduction is called a two-component system, and it is a common form of signal transduction in bacteria. CheY induces tumbling by interacting with the flagellar switch protein FliM, inducing a change from counter-clockwise to clockwise rotation of the flagellum. Change in the rotation state of a single flagellum can disrupt the entire flagella bundle and cause a tumble.\n\nCheB, when activated by CheA, acts as a methylesterase, removing methyl groups from glutamate residues on the cytosolic side of the receptor; it works antagonistically with CheR, a methyltransferase, which adds methyl residues to the same glutamate residues. If the level of an attractant remains high, the level of phosphorylation of CheA (and, therefore, CheY and CheB) will remain low, the cell will swim smoothly, and the level of methylation of the MCPs will increase (because CheB-P is not present to demethylate). The MCPs no longer respond to the attractant when they are fully methylated; therefore, even though the level of attractant might remain high, the level of CheA-P (and CheB-P) increases and the cell begins to tumble. The MCPs can be demethylated by CheB-P, and, when this happens, the receptors can once again respond to attractants. The situation is the opposite with regard to repellents: fully methylated MCPs respond best to repellents, while least-methylated MCPs respond worst to repellents. This regulation allows the bacterium to 'remember' chemical concentrations from the recent past, a few seconds, and compare them to those it is currently experiencing, thus 'know' whether it is traveling up or down a gradient. Although the methylation system accounts for the wide range of sensitivity that bacteria have to chemical gradients, other mechanisms are involved in increasing the absolute value of the sensitivity on a given background. Well-established examples are the ultra-sensitive response of the motor to the CheY-P signal, and the clustering of chemoreceptors.\n\nChemoattractants and chemorepellents are inorganic or organic substances possessing chemotaxis-inducer effect in motile cells. These chemotactic ligands create chemical concentration gradients that organisms, prokaryotic and eukaryotic, move toward or away from, respectively.\n\nEffects of chemoattractants are elicited via chemoreceptors such as methyl-accepting chemotaxis proteins (MCP). MCPs in E.coli include Tar, Tsr, Trg and Tap. Chemoattracttants to Trg include ribose and galactose with phenol as a chemorepellent. Tap and Tsr recognize dipeptides and serine as chemoattractants, respectively.\n\nChemoattractants or chemorepellents bind MCPs at its extracellular domain; an intracellular signaling domain relays the changes in concentration of these chemotactic ligands to downstream proteins like that of CheA which then relays this signal to flagellar motors via phosphorylated CheY (CheY-P). CheY-P can then control flagellar rotation influencing the direction of cell motility.\n\nFor \"E.coli\", \"S. meliloti\", and \"R. spheroids,\" the binding of chemoattractants to MCPs inhibit CheA and therefore CheY-P activity, resulting in smooth runs, but for \"B. substilis\", CheA activity increases. Methylation events in \"E.coli\" cause MCPs to have lower affinity to chemoattractants which causes increased activity of CheA and CheY-P resulting in tumbles. In this way cells are able to adapt to the immediate chemoattractant concentration and detect further changes to modulate cell motility.\n\nChemoattractants in eukaryotes are well characterized for immune cells. Formyl peptides, such as N-formylmethioninyl, attract leukocytes such as neutrophils and macrophages, causing movement toward infection sites. Non-acylated methioninyl peptides do not act as chemoattractants to neutrophils and macrophages. Leukocytes also move toward chemoattractants C5a, a complement component, and pathogen-specific ligands on bacteria.\n\nMechanisms concerning chemorepellents are less known than chemoattractants. Although chemorepellents work to confer an avoidance response in organisms, \"Tetrahymena thermophila\" adapt to a chemorepellent, Netrin-1 peptide, within 10 minutes of exposure; however, exposure to chemorepellents such as GTP, PACAP-38, and nociceptin show no such adaptations. GTP and ATP are chemorepellents in micro-molar concentrations to both \"Tetrahymena\" and \"Paramecium\". These organisms avoid these molecules by producing avoiding reactions to re-orient themselves away from the gradient.\n\nThe mechanism of chemotaxis that eukaryotic cells employ is quite different from that in bacteria; however, sensing of chemical gradients is still a crucial step in the process. Due to their small size, prokaryotes cannot directly detect a concentration gradient. Instead, prokaryotes sense their environments temporally, constantly swimming and redirecting themselves each time they sense a change in the gradient.\n\nEukaryotic cells are much larger than prokaryotes and have receptors embedded uniformly throughout the cell membrane. Eukaryotic chemotaxis involves detecting a concentration gradient spatially by comparing the asymmetric activation of these receptors at the different ends of the cell. Activation of these receptors results in migration towards chemoattractants, or away from chemorepellants.\n\nIt has also been shown that both prokaryotic and eukaryotic cells are capable of chemotactic memory. In prokaryotes, this mechanism involves the methylation of receptors called methyl-accepting chemotaxis proteins (MCPs). This results in their desensitization and allows prokaryotes to \"remember\" and adapt to a chemical gradient. In contrast, chemotactic memory in eukaryotes can be explained by the Local Excitation Global Inhibition (LEGI) model. LEGI involves the balance between a fast excitation and delayed inhibition which controls downstream signaling such as Ras activation and PIP3 production.\n\nLevels of receptors, intracellular signalling pathways and the effector mechanisms all represent diverse, eukaryotic-type components. In eukaryotic unicellular cells, amoeboid movement and cilium or the eukaryotic flagellum are the main effectors (e.g., Amoeba or Tetrahymena). Some eukaryotic cells of higher vertebrate origin, such as immune cells also move to where they need to be. Besides immune competent cells (granulocyte, monocyte, lymphocyte) a large group of cells—considered previously to be fixed into tissues—are also motile in special physiological (e.g., mast cell, fibroblast, endothelial cells) or pathological conditions (e.g., metastases). Chemotaxis has high significance in the early phases of embryogenesis as development of germ layers is guided by gradients of signal molecules.\n\nUnlike motility in bacterial chemotaxis, the mechanism by which eukaryotic cells physically move is unclear. There appear to be mechanisms by which an external chemotactic gradient is sensed and turned into an intracellular PIP3 gradient, which results in a gradient and the activation of a signaling pathway, culminating in the polymerisation of actin filaments. The growing distal end of actin filaments develops connections with the internal surface of the plasma membrane via different sets of peptides and results in the formation of anteriorpseudopods and posterior uropods.\nCilia of eukaryotic cells can also produce chemotaxis; in this case, it is mainly a Ca-dependent induction of the microtubular system of the basal body and the beat of the 9+2 microtubules within cilia. The orchestrated beating of hundreds of cilia is synchronized by a submembranous system built between basal bodies.\nThe details of the signaling pathways are still not totally clear.\n\nChemotaxis refers to the directional migration of cells in response to chemical gradients; several variations of chemical-induced migration exist as listed below. \n\nIn general, eukaryotic cells sense the presence of chemotactic stimuli through the use of 7-transmembrane (or serpentine) heterotrimeric G-protein-coupled receptors, a class representing a significant portion of the genome. Some members of this gene superfamily are used in eyesight (rhodopsins) as well as in olfaction (smelling). The main classes of chemotaxis receptors are triggered by:\nHowever, induction of a wide set of membrane receptors (e.g., cyclic nucleotides, amino acids, insulin, vasoactive peptides) also elicit migration of the cell.\n\nWhile some chemotaxis receptors are expressed in the surface membrane with long-term characteristics, as they are determined genetically, others have short-term dynamics, as they are assembled \"ad hoc\" in the presence of the ligand. The diverse features of the chemotaxis receptors and ligands allows for the possibility of selecting chemotactic responder cells with a simple chemotaxis assay. By chemotactic selection, we can determine whether a still-uncharacterized molecule acts via the long- or the short-term receptor pathway. The term \"chemotactic selection\" is also used to designate a technique that separates eukaryotic or prokaryotic cells according to their chemotactic responsiveness to selector ligands.\n\nThe number of molecules capable of eliciting chemotactic responses is relatively high, and we can distinguish primary and secondary chemotactic molecules. The main groups of the primary ligands are as follows:\n\nChemotactic responses elicited by the ligand-receptor interactions are, in general, distinguished upon the optimal effective concentration(s) of the ligand. Nevertheless, correlation of the amplitude elicited and ratio of the responder cells compared to the total number are also characteristic features of the chemotactic signaling. Investigations of ligand families (e.g., amino acids or oligo peptides) proved that there is a fitting of ranges (amplitudes; number of responder cells) and chemotactic activities: Chemoattractant moiety is accompanied by wide ranges, whereas chemorepellent character by narrow ranges.\n\nA changed migratory potential of cells has relatively high importance in the development of several clinical symptoms and syndromes.\nAltered chemotactic activity of extracellular (e.g., Escherichia coli) or intracellular (e.g., Listeria monocytogenes) pathogens itself represents a significant clinical target. Modification of endogenous chemotactic ability of these microorganisms by pharmaceutical agents can decrease or inhibit the ratio of infections or spreading of infectious diseases.\nApart from infections, there are some other diseases wherein impaired chemotaxis is the primary etiological factor, as in Chédiak–Higashi syndrome, where giant intracellular vesicles inhibit normal migration of cells.\n\nSeveral mathematical models of chemotaxis were developed depending on the type of\n\nAlthough interactions of the factors listed above make the behavior of the solutions of mathematical models of chemotaxis rather complex, it is possible to describe the basic phenomenon of chemotaxis-driven motion in a straightforward way.\nIndeed, let us denote with formula_1 the spatially non-uniform concentration of the chemo-attractant and with formula_2 its gradient. Then the chemotactic cellular flow (also called current) formula_3 that is generated by the chemotaxis is linked to the above gradient by the law: formula_4, where formula_5 is the spatial density of the cells and formula_6 is the so-called ’Chemotactic coefficient’. However, note that in many cases formula_6 is not constant: It is, instead, a decreasing function of the concentration of the chemo-attractant formula_8: formula_9.\n\nSpatial ecology of soil microorganisms is a function of their chemotactic sensitivities towards substrate and fellow organisms. The chemotactic behavior of the bacteria was proven to lead to non-trivial population patterns even in the absence of environmental heterogeneities. The presence of structural pore scale heterogeneities has an extra impact on the emerging bacterial patterns.\n\nA wide range of techniques is available to evaluate chemotactic activity of cells or the chemoattractant and chemorepellent character of ligands.\nThe basic requirements of the measurement are as follows:\n\nDespite the fact that an ideal chemotaxis assay is still not available, there are several protocols and pieces of equipment that offer good correspondence with the conditions described above. The most commonly used are summarised in the table below:\n\"Chemical robots\" that use artificial chemotaxis to navigate autonomously have been designed. Applications include targeted delivery of drugs in the body. More recently, enzyme molecules have also shown positive chemotactic behavior in a gradient of their substrates. Additionally, enzymes in cascades have also shown substrate-driven chemotactic aggregation.\n\nApart from active enzymes, non-reacting molecules also show chemotactic behavior. This has been demonstrated by using dye molecules that move directionally in gradients of polymer solution through favorable hydrophobic interactions. \n\n"}
{"id": "181592", "url": "https://en.wikipedia.org/wiki?curid=181592", "title": "Competition", "text": "Competition\n\nCompetition is, in general, a contest or rivalry between two or more entities, organisms, animals, individuals, economic groups or social groups, etc., for territory, a niche, for scarce resources, goods, for mates, for prestige, recognition, for awards, for group or social status, or for leadership and profit. It arises whenever at least two parties strive for a goal which cannot be shared, where one's gain is the other's loss (an example of which is a zero-sum game).\n\nCompetition occurs naturally between living organisms which co-exist in the same environment. For example, animals compete over water supplies, food, mates, and other biological resources. Humans usually compete for food and mates, though when these needs are met deep rivalries often arise over the pursuit of wealth, power, prestige, and fame.\n\nCompetition is often considered to be the opposite of cooperation, however in the real world, mixtures of cooperation and competition are the norm. Optimal strategies to achieve goals are studied in the branch of mathematics known as game theory.\n\nCompetition is also a major tenet of market economies and business. It is often associated with business competition as most companies are in competition with at least one other firm over the same group of customers. Also competition inside a company is usually stimulated with the larger purpose of meeting and reaching higher quality of services or improved products that the company may produce or develop.\n\nCompetition can have both beneficial and detrimental effects. Many evolutionary biologists view inter-species and intra-species competition as the driving force of adaptation, and ultimately of evolution. However, some biologists disagree, citing competition as a driving force only on a small scale, and citing the larger scale drivers of evolution to be abiotic factors (termed 'Room to Roam'). Richard Dawkins prefers to think of evolution in terms of competition between single genes, which have the welfare of the organism 'in mind' only insofar as that welfare furthers their own selfish drives for replication (termed the 'selfish gene').\n\nSome social Darwinists claim that competition also serves as a mechanism for determining the best-suited group; politically, economically and ecologically. Positively, competition may serve as a form of recreation or a challenge provided that it is non-hostile. On the negative side, competition can cause injury and loss to the organisms involved, and drain valuable resources and energy. In the human species competition can be expensive on many levels, not only in lives lost to war, physical injuries, and damaged psychological well beings, but also in the health effects from everyday civilian life caused by work stress, long work hours, abusive working relationships, and poor working conditions, that detract from the enjoyment of life, even as such competition results in financial gain for the owners.\n\nCompetition within, between, and among species is one of the most important forces in biology, especially in the field of ecology.\n\nCompetition between members of a species (\"intraspecific\") for resources such as food, water, territory, and sunlight may result in an increase in the frequency of a variant of the species best suited for survival and reproduction until its fixation within a population. However, competition among resources also has a strong tendency for diversification between members of the same species, resulting in coexistence of competitive and non-competitive strategies or cycles between low and high competitiveness. Third parties within a species often favour highly competitive strategies leading to species extinction when environmental conditions are harsh (evolutionary suicide).\n\nCompetition is also present between species (\"interspecific\"). When resources are limited, several species may depend on these resources. Thus, each of the species competes with the others to gain access to the resources. As a result, species less suited to compete for the resources may die out unless they adapt by character dislocation, for instance. According to evolutionary theory, this competition within and between species for resources plays a significant role in natural selection. At shorter time scales, competition is also one of the most important factors controlling diversity in ecological communities, but at larger scales expansion and contraction of ecological space is a much more larger factor than competition. This is illustrated by living plant communities where asymmetric competition and competitive dominance frequently occur. Multiple examples of symmetric and asymmetric competition also exist for animals.\n\nGame theory is \"the study of mathematical models of conflict and cooperation between intelligent rational decision-makers.\" Game theory is mainly used in economics, political science, and psychology, as well as logic, computer science, biology and poker. Originally, it mainly addressed zero-sum games, in which one person's gains result in losses for the other participants.\n\nGame theory is a major method used in mathematical economics and business for modeling competing behaviors of interacting agents. Applications include a wide array of economic phenomena and approaches, such as auctions, bargaining, mergers & acquisitions pricing, fair division, duopolies, oligopolies, social network formation, agent-based computational economics, general equilibrium, mechanism design, and voting systems; and across such broad areas as experimental economics, behavioral economics, information economics, industrial organization, and political economy.\n\nThis research usually focuses on particular sets of strategies known as \"solution concepts\" or \"equilibria\". A common assumption is that players act rationally. In non-cooperative games, the most famous of these is the Nash equilibrium. A set of strategies is a Nash equilibrium if each represents a best response to the other strategies. If all the players are playing the strategies in a Nash equilibrium, they have no unilateral incentive to deviate, since their strategy is the best they can do given what others are doing.\n\nMerriam-Webster defines competition in business as \"the effort of two or more parties acting independently to secure the business of a third party by offering the most favorable terms\". It was described by Adam Smith in \"The Wealth of Nations\" and later economists as allocating productive resources to their most highly valued uses and encouraging efficiency. Later microeconomic theory distinguished between perfect competition and imperfect competition, concluding that no system of resource allocation is more efficient than perfect competition. Competition, according to the theory, causes commercial firms to develop new products, services and technologies, which would give consumers greater selection and better products. The greater selection typically causes lower prices for the products, compared to what the price would be if there was no competition (monopoly) or little competition (oligopoly).\n\nHowever, competition may also lead to wasted (duplicated) effort and to increased costs (and prices) in some circumstances. For example, the intense competition for the small number of top jobs in music and movie acting leads many aspiring musicians and actors to make substantial investments in training which are not recouped, because only a fraction become successful. Critics have also argued that competition can be destabilizing, particularly competition between certain financial institutions.\n\nExperts have also questioned the constructiveness of competition in profitability. It has been argued that competition-oriented objectives are counterproductive to raising revenues and profitability because they limit the options of strategies for firms as well as their ability to offer innovative responses to changes in the market. In addition, the strong desire to defeat rival firms with competitive prices has the strong possibility of causing price wars.\n\nThree levels of economic competition have been classified:\n\n\nIn addition, companies also compete for financing on the capital markets (equity or debt) in order to generate the necessary cash for their operations. An investor typically will consider alternative investment opportunities given his risk profile and not only look at companies just competing on product (direct competitors). Enlarging the investment universe to include indirect competitors leads to a broader peer universe of comparable, indirectly competing companies.\n\nCompetition does not necessarily have to be between companies. For example, business writers sometimes refer to internal competition. This is competition within companies. The idea was first introduced by Alfred Sloan at General Motors in the 1920s. Sloan deliberately created areas of overlap between divisions of the company so that each division would be competing with the other divisions. For example, the Chevrolet division would compete with the Pontiac division for some market segments. The competing brands by the same company allowed parts to be designed by one division and shared by several divisions, for example parts designed by Chevrolet would also be used by Pontiac. Also, in 1931, Procter & Gamble initiated a deliberate system of internal brand-versus-brand rivalry. The company was organized around different brands, with each brand allocated resources, including a dedicated group of employees willing to champion the brand. Each brand manager was given responsibility for the success or failure of the brand, and compensated accordingly.\n\nFinally, most businesses also encourage competition between individual employees. An example of this is a contest between sales representatives. The sales representative with the highest sales (or the best improvement in sales) over a period of time would gain benefits from the employer. This is also known as intra-brand competition.\n\nShalev and Asbjornsen also found that success (i.e. the saving resulted) of reverse auctions correlated most closely with competition. The literature widely supported the importance of competition as the primary driver of reverse auctions success. Their findings appear to support that argument, as competition correlated strongly with the reverse auction success, as well as with the number of bidders.\n\nIt should also be noted that business and economic competition in most countries is often limited or restricted. Competition often is subject to legal restrictions. For example, competition may be legally prohibited, as in the case with a government monopoly or a government-granted monopoly. Tariffs, subsidies or other protectionist measures may also be instituted by government in order to prevent or reduce competition. Depending on the respective economic policy, pure competition is to a greater or lesser extent regulated by competition policy and competition law. Another component of these activities is the discovery process, with instances of higher government regulations typically leading to less competitive businesses being launched.\n\nCompetition between countries is quite subtle to detect, but is quite evident in the world economy. Countries compete to provide the best possible business environment for multinational corporations. Such competition is evident by the policies undertaken by these countries to educate the future workforce. For example, East Asian economies such as Singapore, Japan and South Korea tend to emphasize education by allocating a large portion of the budget to this sector, and by implementing programmes such as gifted education.\n\nCompetition law, known in the United States as antitrust law, has three main functions. First, it prohibits agreements aimed to restrict free trading between business entities and their customers. For example, a cartel of sports shops who together fix football jersey prices higher than normal is illegal. Second, competition law can ban the existence or abusive behaviour of a firm dominating the market. One case in point could be a software company who through its monopoly on computer platforms makes consumers use its media player. Third, to preserve competitive markets, the law supervises the mergers and acquisitions of very large corporations. Competition authorities could for instance require that a large packaging company give plastic bottle licenses to competitors before taking over a major PET producer. In this case (as in all three), competition law aims to protect the welfare of consumers by ensuring business must compete for its share of the market economy.\n\nIn recent decades, competition law has also been sold as good medicine to provide better public services, traditionally funded by tax payers and administered by democratically accountable governments. Hence competition law is closely connected with the law on deregulation of access to markets, providing state aids and subsidies, the privatisation of state-owned assets and the use of independent sector regulators, such as the United Kingdom telecommunications watchdog Ofcom. Behind the practice lies the theory, which over the last fifty years has been dominated by neo-classical economics. Markets are seen as the most efficient method of allocating resources, although sometimes they fail, and regulation becomes necessary to protect the ideal market model. Behind the theory lies the history, reaching back further than the Roman Empire. The business practices of market traders, guilds and governments have always been subject to scrutiny and sometimes severe sanctions. Since the twentieth century, competition law has become global. The two largest, most organised and influential systems of competition regulation are United States antitrust law and European Community competition law. The respective national authorities, the U.S. Department of Justice (DOJ) and the Federal Trade Commission (FTC) in the United States and the European Commission's Competition Directorate General (DGCOMP) have formed international support and enforcement networks. Competition law is growing in importance every day, which warrants for its careful study.\n\nCompetition is also found in trade. For nations, as well as firms it is important to understand trade dynamics in order to market their goods and services effectively in international markets. Balance of trade can be considered a crude, but widely used proxy for international competitiveness across levels: country, industry or even firm. Research data hints that exporting firms have a higher survival rate and achieve greater employment growth compared with non-exporters.\n\nUsing a simple concept to measure heights that firms can climb may help improve execution of strategies. International competitiveness can be measured on several criteria but few are as flexible and versatile to be applied across levels as Trade Competitiveness Index (TCI) \n\nCompetition is also found in politics. In democracies, an election is a competition for an elected office. In other words, two or more candidates strive and compete against one another to attain a position of power. The winner gains the seat of the elected office for a predefined period of time, towards the end of which another election is usually held to determine the next holder of the office.\n\nIn addition, there is inevitable competition inside a government. Because several offices are appointed, potential candidates compete against the others in order to gain the particular office. Departments may also compete for a limited amount of resources, such as for funding. Finally, where there are party systems, elected leaders of different parties will ultimately compete against the other parties for laws, funding and power.\n\nFinally, competition also exists between governments. Each country or nationality struggles for world dominance, power, or military strength. For example, the United States competed against the Soviet Union in the Cold War for world power, and the two also struggled over the different types of government (in these cases representative democracy and communism). The result of this type of competition often leads to worldwide tensions, and may sometimes erupt into warfare.\n\nWhile some sports and games (such as fishing or hiking) have been viewed as primarily recreational, most sports are considered competitive. The majority involve competition between two or more persons (sometimes using horses or cars). For example, in a game of basketball, two teams compete against one another to determine who can score the most points. When there is no set reward for the winning team, many players gain a sense of pride. In addition, extrinsic rewards may also be given. Athletes, besides competing against other humans, also compete against nature in sports such as whitewater kayaking or mountaineering, where the goal is to reach a destination, with only natural barriers impeding the process. A regularly scheduled (for instance annual) competition meant to determine the \"best\" competitor of that cycle is called a championship.\n\nCompetitive sports are governed by codified rules agreed upon by the participants. Violating these rules is considered to be unfair competition. Thus, sports provide artificial (not natural) competition; for example, competing for control of a ball, or defending territory on a playing field is not an innate biological factor in humans. Athletes in sports such as gymnastics and competitive diving compete against each other in order to come closest to a conceptual ideal of a perfect performance, which incorporates measurable criteria and standards which are translated into numerical ratings and scores by appointed judges.\n\nSports competition is generally broken down into three categories: individual sports, such as archery; dual sports, such as doubles tennis, and team sports competition, such as cricket or football. While most sports competitions are recreation, there exist several major and minor professional sports leagues throughout the world. The Olympic Games, held every four years, is usually regarded as the international pinnacle of sports competition.\n\nCompetition is a major factor in education. On a global scale, national education systems, intending to bring out the best in the next generation, encourage competitiveness among students through scholarships. Countries such as England and Singapore have special education programmes which cater for specialist students, prompting charges of academic elitism. Upon receipt of their academic results, students tend to compare their grades to see who is better. In severe cases, the pressure to perform in some countries is so high that it can result in stigmatization of intellectually deficient students, or even suicide as a consequence of failing the exams; Japan being a prime example (see Education in Japan). This has resulted in critical re-evaluation of examinations as a whole by educationalists . Critics of competition as a motivating factor in education systems, such as Alfie Kohn, assert that competition actually has a net negative influence on the achievement levels of students, and that it \"turns all of us into losers\" (Kohn 1986). Economist Richard Layard has commented on the harmful effects, stating \"people feel that they are under a great deal of pressure. They feel that their main objective in life is to do better than other people. That is certainly what young people are being taught in school every day. And it's not a good basis for a society.\"\n\nHowever, other studies such as the Torrance Tests of Creative Thinking show that the effect of competition on students depends on each individual's level of agency. Students with a high level of agency thrive on competition, are self-motivated, and are willing to risk failure. Compared to their counterparts who are low in agency, these students are more likely to be flexible, adaptable and creative as adults.\n\nLiterary competitions, such as contests sponsored by literary journals, publishing houses and theaters, have increasingly become a means for aspiring writers to gain recognition. Awards for fiction include those sponsored by the \"Missouri Review\", \"Boston Review\", \"Indiana Review\", \"North American Review\" and \"Southwest Review\". The Albee Award, sponsored by the Yale Drama Series, is among the most prestigious playwriting awards.\n\nIn Australia, New Zealand and the United Kingdom, competitions or lottos are the equivalent of what are commonly known as sweepstakes in the United States. The correct technical name for Australian consumer competitions is a trade promotion lottery or lottos.\n\nCompetition or trade promotion lottery entrants enter to win a prize or prizes, hence many entrants are all in competition, or competing for a limited number of prizes.\n\nA trade promotion lottery or competition is a free entry lottery run to promote goods or services supplied by a business. An example is where you purchase goods or services and then given the chance to enter into the lottery and possibly win a prize. A trade promotion lottery can be called a lotto, competition, contest, sweepstake, or giveaway.\n\nSuch competitions can be games of luck (randomly drawn) or skill (judged on an entry question or submission), or possibly a combination of both.\n\nPeople that enjoy entering competitions are known as compers. Many compers attend annual national conventions. In 2012 over 100 members of the online competitions community of lottos.com.au from around Australia met on the Gold Coast, Queensland to discuss competitions.\n\nCompetition has been studied in several fields, including psychology, sociology and anthropology. Social psychologists, for instance, study the nature of competition. They investigate the natural urge of competition and its circumstances. They also study group dynamics, to detect how competition emerges and what its effects are. Sociologists, meanwhile, study the effects of competition on society as a whole. In addition, anthropologists study the history and prehistory of competition in various cultures. They also investigate how competition manifested itself in various cultural settings in the past, and how competition has developed over time.\n\nMany philosophers and psychologists have identified a trait in most living organisms which can drive the particular organism to compete. This trait, called competitiveness, is viewed as an innate biological trait which coexists along with the urge for survival. Competitiveness, or the inclination to compete, though, has become synonymous with aggressiveness and ambition in the English language. More advanced civilizations integrate aggressiveness and competitiveness into their interactions, as a way to distribute resources and adapt. Many plants compete with neighboring ones for sunlight.\n\nHowever, Stephen Jay Gould and others have argued that as one ascends the evolutionary hierarchy, competitiveness (the survival instinct) becomes less innate, and more a learned behavior. The same could be said for co-operation: in humans, at least, both co-operation and competition are considered learned behaviors, because the human species learns to adapt to environmental pressures. Consequently, if survival requires competitive behaviors, the individual will compete, and if survival requires co-operative behaviors, the individual will co-operate. In the case of humans, therefore, aggressiveness may be an innate characteristic, but a person need not be competitive at the same time, for instance when scaling a cliff. On the other hand, humans seem also to have a nurturing instinct, to protect newborns and the weak. While that does not necessitate co-operative behavior, it does help.\n\nThe term also applies to econometrics. Here, it is a comparative measure of the ability and performance of a firm or sub-sector to sell and produce/supply goods and/or services in a given market. The two academic bodies of thought on the assessment of competitiveness are the Structure Conduct Performance Paradigm and the more contemporary New Empirical Industrial Organisation model. Predicting changes in the competitiveness of business sectors is becoming an integral and explicit step in public policymaking. Within capitalist economic systems, the drive of enterprises is to maintain and improve their own competitiveness.\n\nThe tendency toward extreme, unhealthy competition has been termed hypercompetitiveness. This concept originated in Karen Horney's theories on neurosis; specifically, the highly aggressive personality type which is characterized as \"moving against people\". In her view, some people have a need to compete and win at all costs as a means of maintaining their self-worth. These individuals are likely to turn any activity into a competition, and they will feel threatened if they find themselves losing. Researchers have found that men and women who score high on the trait of hypercompetitiveness are more narcissistic and less psychologically healthy than those who score low on the trait. Hypercompetitive individuals generally believe that \"winning isn't everything; it's the only thing\".\n\nMargaret Heffernan's study, \"A Bigger Prize\",\nexamines the perils and disadvantages of competition in (for example) biology, families, sport, education, commerce and the Soviet Union.\n\nKarl Marx insisted that \"the capitalist system fosters competition and egoism in all its members and thoroughly undermines all genuine forms of community\".\nIt promotes a \"climate of competitive egoism and individualism\", with competition for jobs and competition between employees; Marx said competition between workers exceeds that demonstrated by company owners. He also points out that competition separates individuals from one another and while concentration of workers and development of better communication alleviate this, they are not a decision.\n\nSigmund Freud explained competition as a primal dilemma in which all infants find themselves. The infant competes with other family members for the attention and affection of the parent of the opposite sex or the primary caregiving parent. During this time, a boy develops a deep fear that the father (the son's prime rival) will punish him for these feelings of desire for the mother, by castrating him. Girls develop penis envy towards all males. The girl’s envy is rooted in the biologic fact that, without a penis, she cannot sexually possess mother, as the infantile id demands, resultantly, the girl redirects her desire for sexual union upon father in competitive rivalry with her mother. This constellation of feelings is known as Oedipus Complex ( after the Greek Mythology figure who accidentally killed his father and married his mother). This is associated with the phallic stage of childhood development where intense primal emotions of competitive rivalry with (usually) the parent of the same sex are rampant and create a crisis that must be negotiated successfully for healthy psychological development to proceed. Unresolved Oedipus complex competitiveness issues can lead to lifelong neuroses manifesting in various ways related to an overdetermined relationship to competition.\n\nGandhi speaks of egoistic competition. For him, such qualities glorified and/or left unbridled, can lead to violence, conflict, discord and destructiveness. For Gandhi, competition comes from the ego, and therefore society must be based on mutual love, cooperation and sacrifice for the well-being of humanity. In the society desired by Gandhi, each individual will cooperate and serve for the welfare of others and people will share each other's joys, sorrows and achievements as a norm of a social life. For him, in a non-violent society, competition does not have a place and this should become realized with more people making the personal choice to have fewer tendencies toward egoism and selfishness.\n\n"}
{"id": "48315631", "url": "https://en.wikipedia.org/wiki?curid=48315631", "title": "Control (psychology)", "text": "Control (psychology)\n\n“Control has been one of the most widely explored topics in the social and psychological sciences” In psychology it can refer to one’s perception regarding her/his ability to achieve outcomes (Perceived Control), the ability to select one’s thoughts and actions (cognitive control), the ability to regulate one’s feelings or attitudes toward something (emotional control), one’s ability to act on prescribed behaviors (motivational control), the amount of control one seeks within a relationship (control desire), the ability to inhibit thoughts or actions in favor of others (inhibitory control), selecting one’s social environment for one’s benefit (social control), the attempt to regulate impulses or attentional processes (Ego control), and the ability to regulate how much effort one invests into a goal (effortful control).\n\nPerceived control in psychology is a “person’s belief that he or she is capable of obtaining desired outcomes, avoiding undesired outcomes, and achieving goals.” High perceived control is associated with better health, relationships, and adjustment. Strategies for restoring perceived control are called Compensatory control strategies.\n\nControl desire in the context of a sales relationship refers to the amount of control a customer wants within the relationship.\n\nCognitive control in psychology describes “the ability to control one’s thoughts and actions.” It is also known as \"controlled processing, executive attention, and supervisory attention\". Controlled behaviors are guided by maintenance, updating, and representing task goals, and inhibiting information irrelevant to the task goal.\n\nEmotional control is a term from the self-regulatory psychology literature and refers to “the ability to self-manage or regulate attitudes and feelings that directly affect participant receptiveness to, and implementation of, training activities.”\n\nMotivational control in psychology “refers to the self-regulatory mechanism by which individuals are able to act on prescribed behaviors to implement training activities.” For example, a student who studies for an hour each morning for two months before a test, whether or not the student likes studying.\n\nInhibitory control or “IC” in psychology it refers to a type of self-regulation defined as “the ability to inhibit prepotent thoughts or actions flexibly, often in favor of a subdominant action, typically in goal-directed behavior”. There are two types of IC: hot and cold. Hot IC involves activities or tasks related to emotion regulation, and cold IC involves abstract activities or tasks.\n\nSocial control is learning psychology “refers to an individual’s skills in engaging the social environment in ways that help to support and reinforce his or her learning activities.”\n\nEgo control in psychology refers to “the efforts of the individual to control ‘thoughts, emotions, impulses or appetites… task performances [and] attentional processes.’ ” Failure of ego control is seen as a central problem in individuals who suffer from substance abuse disorders.\n\nSituational control in psychology is part of leadership psychology that refers to “the degree to which the situation provides the leader “with potential influence over the group’s behavior”.\n\nEffortful control in psychology refers to a type of self regulation. It is a broader construct than inhibitory control, and encompasses working memory and attention shifting.\n"}
{"id": "38115", "url": "https://en.wikipedia.org/wiki?curid=38115", "title": "Crucifixion", "text": "Crucifixion\n\nCrucifixion is a method of capital punishment in which the victim is tied or nailed to a large wooden beam and left to hang for several days until eventual death from exhaustion and asphyxiation.\n\nThe crucifixion of Jesus is a central narrative in Christianity, and the cross (sometimes depicting Jesus nailed onto it) is the main religious symbol for many Christian churches.\n\nAncient Greek has two verbs for crucify: \"ana-stauro\" (ἀνασταυρόω), from \"stauros\", \"stake\", and \"apo-tumpanizo\" (ἀποτυμπανίζω) \"crucify on a plank\", together with \"anaskolopizo\" (ἀνασκολοπίζω \"impale\"). In earlier pre-Roman Greek texts \"anastauro\" usually means \"impale\".\n\nNew Testament Greek uses four verbs, three of them based upon \"stauros\" (σταυρός), usually translated \"cross\". The most common term is \"stauroo\" (σταυρόω), \"to crucify\", occurring 43 times; \"sustauroo\" (συσταυρόω), \"to crucify with\" or \"alongside\" occurs five times, while \"anastauroo\" (ἀνασταυρόω), \"to crucify again\" occurs only once at the Epistle to the Hebrews 6:6. \"prospegnumi\" (προσπήγνυμι), \"to fix or fasten to, impale, crucify\" occurs only once at the Acts of the Apostles 2:23.\n\nThe English term \"cross\" derives from the Latin word \"crux\". The Latin term \"crux\" classically referred to a tree or any construction of wood used to hang criminals as a form of execution. The term later came to refer specifically to a cross.\n\nThe English term \"crucifix\" derives from the Latin \"crucifixus\" or \"cruci fixus\", past participle passive of \"crucifigere\" or \"cruci figere\", meaning \"to crucify\" or \"to fasten to a cross\".\n\nCrucifixion was most often performed to dissuade its witnesses from perpetrating similar (usually particularly heinous) crimes. Victims were sometimes left on display after death as a warning to any other potential criminals. Crucifixion was usually intended to provide a death that was particularly slow, painful (hence the term \"excruciating\", literally \"out of crucifying\"), gruesome, humiliating, and public, using whatever means were most expedient for that goal. Crucifixion methods varied considerably with location and time period.\n\nThe Greek and Latin words corresponding to \"crucifixion\" applied to many different forms of painful execution, including being impaled on a stake, or affixed to a tree, upright pole (a crux simplex), or (most famous now) to a combination of an upright (in Latin, \"stipes\") and a crossbeam (in Latin, \"patibulum\"). Seneca the Younger wrote: \"I see crosses there, not just of one kind but made in many different ways: some have their victims with head down to the ground; some impale their private parts; others stretch out their arms on the gibbet\".\n\nIn some cases, the condemned was forced to carry the crossbeam to the place of execution. A whole cross would weigh well over 135 kg (300 lb), but the crossbeam would not be quite as burdensome, weighing around 45 kg (100 lb). The Roman historian Tacitus records that the city of Rome had a specific place for carrying out executions, situated outside the Esquiline Gate, and had a specific area reserved for the execution of slaves by crucifixion. Upright posts would presumably be fixed permanently in that place, and the crossbeam, with the condemned person perhaps already nailed to it, would then be attached to the post.\n\nThe person executed may have been attached to the cross by rope, though nails and other sharp materials are mentioned in a passage by the Judean historian Josephus, where he states that at the Siege of Jerusalem (70), \"the soldiers out of rage and hatred, \"nailed\" those they caught, one after one way, and another after another, to the crosses, by way of jest\". Objects used in the crucifixion of criminals, such as nails, were sought as amulets with perceived medicinal qualities.\n\nWhile a crucifixion was an execution, it was also a humiliation, by making the condemned as vulnerable as possible. Although artists have traditionally depicted the figure on a cross with a loin cloth or a covering of the genitals, the person being crucified was usually stripped naked. Writings by Seneca the Younger state some victims suffered a stick forced upwards through their groin. Despite its frequent use by the Romans, the horrors of crucifixion did not escape criticism by some eminent Roman orators. Cicero, for example, described crucifixion as \"a most cruel and disgusting punishment\", and suggested that \"the very mention of the cross should be far removed not only from a Roman citizen's body, but from his mind, his eyes, his ears\". Elsewhere he says, \"It is a crime to bind a Roman citizen; to scourge him is a wickedness; to put him to death is almost parricide. What shall I say of crucifying him? So guilty an action cannot by any possibility be adequately expressed by any name bad enough for it.\"\n\nFrequently, the legs of the person executed were broken or shattered with an iron club, an act called \"crurifragium\", which was also frequently applied without crucifixion to slaves. This act hastened the death of the person but was also meant to deter those who observed the crucifixion from committing offenses.\n\nThe gibbet on which crucifixion was carried out could be of many shapes. Josephus describes several tortures and positions of crucifixion during the Siege of Jerusalem as Titus crucified the rebels; and Seneca the Younger recounts: \"I see crosses there, not just of one kind but made in many different ways: some have their victims with head down to the ground; some impale their private parts; others stretch out their arms on the gibbet.\"\n\nAt times the gibbet was only one vertical stake, called in Latin \"crux simplex\". This was the simplest available construction for torturing and killing the condemned. Frequently, however, there was a cross-piece attached either at the top to give the shape of a T (\"crux commissa\") or just below the top, as in the form most familiar in Christian symbolism (\"crux immissa\"). The most ancient image of a Roman crucifixion depicts an individual on a T-shaped cross. It is a graffito found in a taberna (hostel for wayfarers) in Puteoli, dating to the time of Trajan or Hadrian (late 1st century to early 2nd century AD).\n\nSome 2nd-century writers took it for granted that a crucified person's arms would be stretched out, not connected to a single stake: Lucian speaks of Prometheus as crucified \"above the ravine with his hands outstretched\" and explains that the letter T (the Greek letter tau) was looked upon as an unlucky letter or sign (similar to the way the number thirteen is looked upon today as an unlucky number), saying that the letter got its \"evil significance\" because of the \"evil instrument\" which had that shape, an instrument on which tyrants crucified people. Jehovah's Witnesses argue that Jesus was crucified on a \"crux simplex\", and that the \"crux immissa\" was first used as a Christian symbol near the time of the supposed conversion of Emperor Constantine. Other forms were in the shape of the letters X and Y.\n\nThe New Testament writings about the crucifixion of Jesus do not speak specifically about the shape of that cross, but the early writings that do speak of its shape, from about the year AD 100 on, describe it as shaped like the letter T (the Greek letter tau) or as composed of an upright and a transverse beam, sometimes with a small projection in the upright.\n\nIn popular depictions of the crucifixion of Jesus (possibly because in translations of the wounds are described as being \"in his hands\"), Jesus is shown with nails in his hands. But in Greek the word \"χείρ\", usually translated as \"hand\", could refer to the entire portion of the arm below the elbow, and to denote the \"hand\" as distinct from the \"arm\" some other word could be added, as \"ἄκρην οὔτασε χεῖρα\" (he wounded the end of the χείρ, i.e., \"he wounded her in the hand\".\n\nA possibility that does not require tying is that the nails were inserted just above the wrist, between the two bones of the forearm (the radius and the ulna).\n\nAn experiment that was the subject of a documentary on the National Geographic Channel's \"Quest For Truth: The Crucifixion\", showed that nailed feet provided enough support for the body, and that the hands could have been merely tied. Nailing the feet to the side of the cross relieves strain on the wrists by placing most of the weight on the lower body.\n\nAnother possibility, suggested by Frederick Zugibe, is that the nails may have been driven in at an angle, entering in the palm in the crease that delineates the bulky region at the base of the thumb, and exiting in the wrist, passing through the carpal tunnel.\n\nA foot-rest (\"suppedaneum\") attached to the cross, perhaps for the purpose of taking the person's weight off the wrists, is sometimes included in representations of the crucifixion of Jesus, but is not discussed in ancient sources. Some scholars interpret the Alexamenos graffito, the earliest surviving depiction of the Crucifixion, as including such a foot-rest. Ancient sources also mention the \"sedile\", a small seat attached to the front of the cross, about halfway down, which could have served a similar purpose.\n\nIn 1968, archaeologists discovered at Giv'at ha-Mivtar in northeast Jerusalem the remains of one Jehohanan, who had been crucified in the 1st century. The remains included a heel bone with a nail driven through it from the side. The tip of the nail was bent, perhaps because of striking a knot in the upright beam, which prevented it being extracted from the foot. A first inaccurate account of the length of the nail led some to believe that it had been driven through both heels, suggesting that the man had been placed in a sort of sidesaddle position, but the true length of the nail, 11.5 cm (4.53 inches), suggests instead that in this case of crucifixion the heels were nailed to opposite sides of the upright. The skeleton from Giv'at ha-Mivtar is currently the only recovered example of ancient crucifixion in the archaeological record.\n\nThe length of time required to reach death could range from hours to days depending on method, the victim's health, and the environment. A literature review by Maslen and Mitchell identified scholarly support for several possible causes of death: cardiac rupture, heart failure, hypovolemic shock, acidosis, asphyxia, arrhythmia, and pulmonary embolism. Death could result from any combination of those factors or from other causes, including sepsis following infection due to the wounds caused by the nails or by the scourging that often preceded crucifixion, eventual dehydration, or animal predation.\n\nA theory attributed to Pierre Barbet holds that, when the whole body weight was supported by the stretched arms, the typical cause of death was asphyxiation. He wrote that the condemned would have severe difficulty inhaling, due to hyper-expansion of the chest muscles and lungs. The condemned would therefore have to draw himself up by the arms, leading to exhaustion, or have his feet supported by tying or by a wood block. When no longer able to lift himself, the condemned would die within a few minutes. Some scholars, including Frederick Zugibe, posit other causes of death. Zugibe suspended test subjects with their arms at 60° to 70° from the vertical. The test subjects had no difficulty breathing during experiments, but did suffer rapidly increasing pain, which is consistent with the Roman use of crucifixion to achieve a prolonged, agonizing death. However, Zugibe's positioning of the test subjects' feet is not supported by any archaeological or historical evidence.\n\nSince death does not follow immediately on crucifixion, survival after a short period of crucifixion is possible, as in the case of those who choose each year as a devotional practice to be non-lethally crucified.\n\nThere is an ancient record of one person who survived a crucifixion that was intended to be lethal, but that was interrupted. Josephus recounts: \"I saw many captives crucified, and remembered three of them as my former acquaintance. I was very sorry at this in my mind, and went with tears in my eyes to Titus, and told him of them; so he immediately commanded them to be taken down, and to have the greatest care taken of them, in order to their recovery; yet two of them died under the physician's hands, while the third recovered.\" Josephus gives no details of the method or duration of the crucifixion of his three friends before their reprieve.\n\nAlthough the ancient Jewish historian Josephus, as well as other sources, refers to the crucifixion of thousands of people by the Romans, there is only a single archaeological discovery of a crucified body dating back to the Roman Empire around the time of Jesus. This was discovered at Givat HaMivtar, Jerusalem in 1968. It is not necessarily surprising that there is only one such discovery, because a crucified body was usually left to decay on the cross and therefore would not be preserved. The only reason these archaeological remains were preserved was because family members gave this particular individual a customary burial.\n\nThe remains were found accidentally in an ossuary with the crucified man's name on it, 'Jehohanan, the son of Hagakol'. Nicu Haas, an anthropologist at the Hebrew University Medical School in Jerusalem, examined the ossuary and discovered that it contained a heel bone with a nail driven through its side, indicating that the man had been crucified. The position of the nail relative to the bone indicates that the feet had been nailed to the cross from their side, not from their front; various opinions have been proposed as to whether they were both nailed together to the front of the cross or one on the left side, one on the right side. The point of the nail had olive wood fragments on it indicating that he was crucified on a cross made of olive wood or on an olive tree.\n\nAdditionally, a piece of acacia wood was located between the bones and the head of the nail, presumably to keep the condemned from freeing his foot by sliding it over the nail. His legs were found broken, possibly to hasten his death. It is thought that because in Roman times iron was rare, the nails were removed from the dead body to conserve costs. According to Haas, this could help to explain why only one nail has been found, as the tip of the nail in question was bent in such a way that it could not be removed.\n\nHaas had also identified a scratch on the inner surface of the right radius bone of the forearm, close to the wrist. He deduced from the form of the scratch, as well as from the intact wrist bones, that a nail had been driven into the forearm at that position. However, many of Haas' findings have been challenged. For instance, it was subsequently determined that the scratches in the wrist area were non-traumatic – and, therefore, not evidence of crucifixion – while reexamination of the heel bone revealed that the two heels were not nailed together, but rather separately to either side of the upright post of the cross.\n\nCrucifixion (or impalement), in one form or another, was used by Persians, Carthaginians, and Macedonians.\n\nThe Greeks were generally opposed to performing crucifixions. However, in his \"Histories\", ix.120–122, the Greek writer Herodotus describes the execution of a Persian general at the hands of Athenians in about 479 BC: \"They nailed him to a plank and hung him up ... this Artayctes who suffered death by crucifixion.\" The \"Commentary on Herodotus\" by How and Wells remarks: \"They crucified him with hands and feet stretched out and nailed to cross-pieces; cf. vii.33. This barbarity, unusual on the part of Greeks, may be explained by the enormity of the outrage or by Athenian deference to local feeling.\"\n\nSome Christian theologians, beginning with Paul of Tarsus writing in Galatians , have interpreted an allusion to crucifixion in Deuteronomy . This reference is to being hanged from a tree, and may be associated with lynching or traditional hanging. However, Rabbinic law limited capital punishment to just 4 methods of execution: stoning, burning, strangulation, and decapitation, while the passage in Deuteronomy was interpreted as an obligation to hang the corpse on a tree as a form of deterrence. The fragmentary Aramaic Testament of Levi (DSS 4Q541) interprets in column 6: \"God ... (partially legible)-\"will set\" ... right errors. ... (partially legible)-\"He will judge\" ... revealed sins. Investigate and seek and know how Jonah wept. Thus, you shall not destroy the weak by wasting away or by ... (partially legible)-\"crucifixion\" ... Let not the nail touch him.\"\n\nThe Jewish king Alexander Jannaeus, king of Judea from 103 BC to 76 BC, crucified 800 rebels, said to be Pharisees, in the middle of Jerusalem.\n\nAlexander the Great is reputed to have crucified 2,000 survivors from his siege of the Phoenician city of Tyre, as well as the doctor who unsuccessfully treated Alexander's friend Hephaestion. Some historians have also conjectured that Alexander crucified Callisthenes, his official historian and biographer, for objecting to Alexander's adoption of the Persian ceremony of royal adoration.\n\nIn Carthage, crucifixion was an established mode of execution, which could even be imposed on generals for suffering a major defeat.\n\nThe oldest crucifixion may be a post-mortem one mentioned by Herodotus. Polycrates, the tyrant of Samos, was put to death in 522 B.C. by Persians, and his dead body was then crucified.\n\nThe hypothesis that the Ancient Roman custom of crucifixion may have developed out of a primitive custom of \"arbori suspendere\"—hanging on an \"arbor infelix\" (\"inauspicious tree\") dedicated to the gods of the nether world—is rejected by William A. Oldfather, who shows that this form of execution (the \"supplicium more maiorum\", punishment in accordance with the custom of our ancestors) consisted of suspending someone from a tree, not dedicated to any particular gods, and flogging him to death. Tertullian mentions a 1st-century AD case in which trees were used for crucifixion, but Seneca the Younger earlier used the phrase \"infelix lignum\" (unfortunate wood) for the transom (\"patibulum\") or the whole cross. Plautus and Plutarch are the two main sources for accounts of criminals carrying their own patibula to the upright \"stipes\".\n\nNotorious mass crucifixions followed the Third Servile War in 73–71 BC (the slave rebellion under Spartacus), other Roman civil wars in the 2nd and 1st centuries BC, and the destruction of Jerusalem in AD 70. Crassus crucified 6,000 of Spartacus' followers hunted down and captured after his defeat in battle. Josephus tells a story of the Romans crucifying people along the walls of Jerusalem. He also says that the Roman soldiers would amuse themselves by crucifying criminals in different positions.\n\nConstantine the Great, the first Christian emperor, abolished crucifixion in the Roman Empire in 337 out of veneration for Jesus Christ, its most famous victim.\n\nCrucifixion was intended to be a gruesome spectacle: the most painful and humiliating death imaginable. It was used to punish slaves, pirates, and enemies of the state. It was originally reserved for slaves (hence still called \"supplicium servile\" by Seneca), and later extended to citizens of the lower classes (\"humiliores\"). The victims of crucifixion were stripped naked and put on public display while they were slowly tortured to death so that they would serve as a spectacle and an example.\n\nAccording to Roman law, if a slave killed his or her master, all of the master's slaves would be crucified as punishment. Both men and women were crucified. Tacitus writes in his \"Annals\" that when Lucius Pedanius Secondus was murdered by a slave, some in the Senate tried to prevent the mass crucifixion of four hundred of his slaves because there were so many women and children, but in the end tradition prevailed and they were all executed. Although not conclusive evidence for female crucifixion by itself, the most ancient image of a Roman crucifixion may depict a crucified woman, whether real or imaginary. Crucifixion was such a gruesome and humiliating way to die that the subject was somewhat of a taboo in Roman culture, and few crucifixions were specifically documented. One of the only specific female crucifixions we have documented is that of Ida, a freedwoman (former slave) who was crucified by order of Tiberius.\n\nCrucifixion was typically carried out by specialized teams, consisting of a commanding centurion and his soldiers. First, the condemned would be stripped naked and scourged. This would cause the person to lose a large amount of blood, and approach a state of shock. The convict then usually had to carry the horizontal beam (\"patibulum\" in Latin) to the place of execution, but not necessarily the whole cross.\n\nDuring the death march, the prisoner, probably still nude after the scourging, would be led through the most crowded streets bearing a \"titulus\" — a sign board proclaiming the prisoner's name and crime. Upon arrival at the place of execution, selected to be especially public, the convict would be stripped of any remaining clothing, then nailed to the cross naked. If the crucifixion took place in an established place of execution, the vertical beam (\"stipes\") might be permanently embedded in the ground. In this case, the condemned person's wrists would first be nailed to the \"patibulum\", and then he or she would be hoisted off the ground with ropes to hang from the elevated \"patibulum\" while it was fastened to the \"stipes\". Next the feet or ankles would be nailed to the upright stake. The 'nails' were tapered iron spikes approximately long, with a square shaft across. The \"titulus\" would also be fastened to the cross to notify onlookers of the person's name and crime as they hung on the cross, further maximizing the public impact.\n\nThere may have been considerable variation in the position in which prisoners were nailed to their crosses and how their bodies were supported while they died. Seneca the Younger recounts: \"I see crosses there, not just of one kind but made in many different ways: some have their victims with head down to the ground; some impale their private parts; others stretch out their arms on the gibbet.\" One source claims that for Jews (apparently not for others), a man would be crucified with his back to the cross as is traditionally depicted, while a woman would be nailed facing her cross, probably with her back to onlookers, or at least with the \"stipes\" providing some semblance of modesty if viewed from the front. Such concessions were \"unique\" and not made outside a Jewish context. Several sources mention some sort of seat fastened to the \"stipes\" to help support the person's body, thereby prolonging the person's suffering and humiliation by preventing the asphyxiation caused by hanging without support. Justin Martyr calls the seat a \"cornu\", or \"horn,\" leading some scholars to believe it may have had a pointed shape designed to torment the crucified person. This would be consistent with Seneca's observation of victims with their private parts impaled.\n\nIn Roman-style crucifixion, the condemned could take up to a few days to die, but death was sometimes hastened by human action. \"The attending Roman guards could leave the site only after the victim had died, and were known to precipitate death by means of deliberate fracturing of the tibia and/or fibula, spear stab wounds into the heart, sharp blows to the front of the chest, or a smoking fire built at the foot of the cross to asphyxiate the victim.\" The Romans sometimes broke the prisoner's legs to hasten death and usually forbade burial. On the other hand, the person was often deliberately kept alive as long as possible to prolong their suffering and humiliation, so as to provide the maximum deterrent effect. Corpses of the crucified were typically left on the crosses to decompose and be eaten by animals.\n\nIslam spread in a region where many societies, including the Persian and Roman empires, had used crucifixion to punish traitors, rebels, robbers and criminal slaves. The Qur'an refers to crucifixion in six passages, of which the most significant for later legal developments is verse 5:33:\n\nThe corpus of hadith provides contradictory statements about the first use of crucifixion under Islamic rule, attributing it variously to Muhammad himself (for murder and robbery of a shepherd) or to the second caliph Umar (applied to two slaves who murdered their mistress). Classical Islamic jurisprudence applies the verse 5:33 chiefly to highway robbers, as a \"hadd\" (scripturally prescribed) punishment. The preference for crucifixion over the other punishments mentioned in the verse or for their combination (which Sadakat Kadri has called \"Islam's equivalent of the hanging, drawing and quartering that medieval Europeans inflicted on traitors\") is subject to \"complex and contested rules\" in classical jurisprudence. Most scholars required crucifixion for highway robbery combined with murder, while others allowed execution by other methods for this scenario. The main methods of crucifixion are:\n\n\nMost classical jurists limit the period of crucifixion to three days. Crucifixion involves affixing or impaling the body to a beam or a tree trunk. Various minority opinions also prescribed crucifixion as punishment for a number of other crimes. Cases of crucifixion under most of the legally prescribed categories have been recorded in the history of Islam, and prolonged exposure of crucified bodies was especially common for political and religious opponents.\n\nCrucifixion was introduced into Japan during the Sengoku period (1467–1573), after a 350-year period with no capital punishment. It is believed to have been suggested to the Japanese by the introduction of Christianity into the region, although similar types of punishment had been used as early as the Kamakura period. Known in Japanese as , crucifixion was used in Japan before and during the Tokugawa Shogunate. Several related crucifixion techniques were used. Petra Schmidt, in \"Capital Punishment in Japan\", writes:\nIn 1597 twenty-six Christian Martyrs were nailed to crosses at Nagasaki, Japan. Among those executed were Saints Paulo Miki, Philip of Jesus and Pedro Bautista, a Spanish Franciscan who had worked about ten years in the Philippines. The executions marked the beginning of a long history of persecution of Christianity in Japan, which continued until its decriminalization in 1871.\n\nCrucifixion was used as a punishment for prisoners of war during World War II. Ringer Edwards, an Australian prisoner of war, was crucified for killing cattle, along with two others. He survived 63 hours before being let down.\n\nIn Burma, crucifixion was a central element in several execution rituals. Felix Carey, a missionary in Burma from 1806 to 1812, wrote the following:\n\nDuring World War I, there were persistent rumors that German soldiers had crucified a Canadian soldier on a tree or barn door with bayonets or combat knives. The event was initially reported in 1915 by Private George Barrie of the 1st Canadian Division. Two investigations, one a post-war official investigation, and the other an independent investigation by the Canadian Broadcasting Corporation, concluded that there was no evidence to support the story. However, British documentary maker Iain Overton in 2001 published an article claiming that the story was true, identifying the soldier as Harry Band. Overton's article was the basis for a 2002 episode of the Channel 4 documentary show \"Secret History\".\n\nIt has been reported that crucifixion was used in several cases against the German civil population of East Prussia when it was occupied by Soviet forces at the end of the Second World War.\n\nCrucifixion is still used as a rare method of execution in some countries. The punishment of crucifixion (\"șalb\") imposed in Islamic law is variously interpreted as exposure of the body after execution, crucifixion followed by stabbing in the chest, or crucifixion for three days, survivors of which are allowed to live.\n\nSeveral people have been executed by crucifixion in Saudi Arabia in the 2000s, although on occasion they were first beheaded and then crucified. Most recently, in March 2013, a robber was set to be executed by being crucified for three days. However, the method was changed.\n\nAli Mohammed Baqir al-Nimr was arrested in 2012 when he was 17 years old for taking part in an anti-government protests in Saudi Arabia during the Arab Spring. In May 2014, Ali al-Nimr was sentenced to be publicly beheaded and crucified.\n\nTheoretically, crucifixion is still one of the Hadd punishments in Iran. If a crucified person were to survive three days of crucifixion, that person would be allowed to live. Execution by hanging is described as follows: \"In execution by hanging, the prisoner will be hung on a hanging truss which should look like a cross, while his (her) back is toward the cross, and (s)he faces the direction of Mecca [in Saudi Arabia], and his (her) legs are vertical and distant from the ground.\"\n\nSudan's penal code, based upon the government's interpretation of shari'a, includes execution followed by crucifixion as a penalty. When, in 2002, 88 people were sentenced to death for crimes relating to murder, armed robbery, and participating in ethnic clashes, Amnesty International wrote that they could be executed by either hanging or crucifixion.\n\nCrucifixion is a legal punishment in the United Arab Emirates.\n\nOn 5 February 2015 the United Nations Committee on the Rights of the Child (CRC) reported that the Islamic State of Iraq and the Levant (ISIL) had committed \"several cases of mass executions of boys, as well as reports of beheadings, crucifixions of children and burying children alive\".\n\nOn 30 April 2014 Islamic extremists carried out a total of seven public executions in Raqqa, northern Syria. The pictures, originally posted to Twitter by a student at Oxford University, were retweeted by a Twitter account owned by a known member of the Islamic State of Iraq and the Levant (ISIL) causing major media outlets to incorrectly attribute the crucifixions to the militant group. In most of these cases of \"crucifixion\" the victims are shot first then their bodies are displayed but there have also been reports of \"crucifixion\" preceding shootings or decapitations as well as a case where a man was said to have been \"crucified alive for eight hours\" with no indication of whether he died.\n\nThe human rights group Karen Women Organization documented a case of Tatmadaw forces crucifying several Karen villagers in 2000 in the Dooplaya District in Burma's Kayin State.\n\nOn 22 January 2014, an anti-government activist and member of AutoMaidan was kidnapped by unknown parties and tortured for a week. His captors kept him in the dark, beat him, cut off a piece of his ear, and nailed him to a cross. His captors ultimately left him in a forest outside Kiev after forcing him to confess to being an American spy and accepting money from the US Embassy in Ukraine to organize protests against then-President Viktor Yanukovych.\n\nIn 2015, a video surfaced depicting members of the Azov Battalion, an official regiment of the Ukrainian Armed Forces, allegedly crucifying a separatist rebel of Novorossiya and burning him alive. Therein they declare, \"all the separatists, traitors of Ukraine and militia fighters [sic] will be treated the same\". The Azov Battalion is associated with neo-Nazism and flaunts symbols associated with the SS such as the wolfsangel and black sun. They allegedly sent the video to the pro-Russian hacktivist organization CyberBerkut, which responded by threatening to take no Ukrainian Army soldiers or militia fighters as prisoners from then on. The authenticity of this video is unconfirmed.\n\nThe Catholic Church frowns upon self-crucifixion as a form of devotion: \"Penitential practices leading to self-crucifixion with nails are not to be encouraged.\" Nevertheless, the practice is not unknown.\n\nIn the Philippines, some Catholics are voluntarily, non-lethally crucified for a limited time on Good Friday to imitate the sufferings of Christ. Pre-sterilised nails are driven through the palm of the hand between the bones, while there is a footrest to which the feet are nailed. Rolando del Campo, a carpenter in Pampanga, vowed to be crucified every Good Friday for 15 years if God would carry his wife through a difficult childbirth, while in San Pedro Cutud, Ruben Enaje has been crucified 27 times. The Church in the Philippines has repeatedly voiced disapproval of crucifixions and self-flagellation, while the government has noted that it cannot deter devotees. The Department of Health insists that participants in the rites should have tetanus shots and that the nails used should be sterilized.\n\nIn other cases, a crucifixion is only simulated within a passion play, as in the ceremonial re-enactment that has been performed yearly in the town of Iztapalapa, on the outskirts of Mexico City, since 1833, and in the more famous Oberammergau Passion Play. Also, since at least the mid-19th century, a group of flagellants in New Mexico, called \"Hermanos de Luz\" (\"Brothers of Light\"), have annually conducted reenactments of Christ's crucifixion during Holy Week, in which a penitent is tied—but not nailed—to a cross.\n\n\n\n"}
{"id": "598669", "url": "https://en.wikipedia.org/wiki?curid=598669", "title": "Diagram", "text": "Diagram\n\nA diagram is a symbolic representation of information according to some visualization technique. Diagrams have been used since ancient times, but became more prevalent during the Enlightenment. Sometimes, the technique uses a three-dimensional visualization which is then projected onto a two-dimensional surface. The word \"graph\" is sometimes used as a synonym for diagram.\n\nThe term \"diagram\" in its commonly used sense can have a general or specific meaning: \n\nIn science the term is used in both ways. For example, Anderson (1997) stated more generally: \"diagrams are pictorial, yet abstract, representations of information, and maps, line graphs, bar charts, engineering blueprints, and architects' sketches are all examples of diagrams, whereas photographs and video are not\". On the other hand, Lowe (1993) defined diagrams as specifically \"abstract graphic portrayals of the subject matter they represent\".\n\nIn the specific sense diagrams and charts contrast with computer graphics, technical illustrations, infographics, maps, and technical drawings, by showing \"abstract rather than literal representations of information\". The essence of a diagram can be seen as:\nOr in Hall's (1996) words \"diagrams are simplified figures, caricatures in a way, intended to convey essential meaning\". These simplified figures are often based on a set of rules. The basic shape according to White (1984) can be characterized in terms of \"elegance, clarity, ease, pattern, simplicity, and validity\". Elegance is basically determined by whether or not the diagram is \"the simplest and most fitting solution to a problem\".\n\nThere are at least the following types of diagrams:\n\n\nSchematics and other types of diagrams, e.g.,\nMany of these types of diagrams are commonly generated using diagramming software such as Visio and Gliffy. Thousands of diagram techniques exist. Some more examples follow.\n\nDiagrams may also be classified according to use or purpose, for example, explanatory and/or how to diagrams.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGarcia, M (Ed) (2012) The Diagrams of Architecture. Wiley. Chichester.\n"}
{"id": "234393", "url": "https://en.wikipedia.org/wiki?curid=234393", "title": "Dignity", "text": "Dignity\n\nDignity is the right of a person to be valued and respected for their own sake, and to be treated ethically. It is of significance in morality, ethics, law and politics as an extension of the Enlightenment-era concepts of inherent, inalienable rights. The term may also be used to describe personal conduct, as in \"behaving with dignity\".\n\nThe English word \"dignity\", attested from the early 13th century, comes from Latin \"dignitas\" (worthiness)\nby way of French \"dignité\".\n\nEnglish-speakers often use the word \"dignity\" in proscriptive and cautionary ways: for example, in politics it can be used to critique the treatment of oppressed and vulnerable groups and peoples, but it has also been applied to cultures and sub-cultures, to religious beliefs and ideals, and even to animals used for food or research.\n\n\"Dignity\" also has descriptive meanings pertaining to the \"worth\" of human beings. In general, the term has various functions and meanings depending on how the term is used and on the context.\n\nIn ordinary modern usage, the word denotes \"respect\" and \"status\", and it is often used to suggest that someone is not receiving a proper degree of respect, or even that they are failing to treat themselves with proper self-respect. There is also a long history of special philosophical use of this term. However, it is rarely defined outright in political, legal, and scientific discussions. International proclamations have thus far left dignity undefined,\nand scientific commentators, such as those arguing against genetic research and algeny, cite dignity as a reason but are ambiguous about its application.\n\nHuman dignity can be violated in multiple ways. The main categories of violations are:\nViolations of human dignity in terms of humiliation refer to acts that humiliate or diminish the self-worth of a person or a group. Acts of humiliation are context dependent but we normally have an intuitive understanding where such a violation occurs. As Schachter noted, “it has been generally assumed that a violation of human dignity can be recognized even if the abstract term cannot be defined. ‘I know it when I see it even if I cannot tell you what it is’”. More generally, etymology of the word “humiliation” has a universal characteristic in the sense that in all languages the word involves “downward spatial orientation” in which “something or someone is pushed down and forcefully held there”. This approach is common in judicial decisions where judges refer to violations of human dignity as injuries to people's self-worth or their self-esteem.\nThis aspect refers to treating a person as an instrument or as means to achieve some other goal. This approach builds on Immanuel Kant's moral imperative stipulating that we should treat people as ends or goals in themselves, namely as having ultimate moral worth which should not be instrumentalized. \nViolations of human dignity as degradation refer to acts that degrade the value of human beings. These are acts that, even if done by consent, convey a message that diminishes the importance or value of all human beings. They consist of practices that human beings should not be subjected to, regardless of whether subjective humiliation is involved, such as selling oneself to slavery, or when a state authority deliberately puts prisoners in inhuman living conditions. \nThese are acts that strip a person or a group of their human characteristics. It may involve describing or treating them as animals or as a lower type of human beings. This has occurred in genocides such as the Holocaust and in Rwanda where the minority were compared to insects.\n\nSome of the practices that violate human dignity include torture, rape, social exclusion, labor exploitation, bonded labor, and slavery. \n\nBoth absolute and relative poverty are violations of human dignity, although they also have other significant dimensions, such as social injustice. Absolute poverty is associated with overt exploitation and connected to humiliation (for example, being forced to eat food from other people's garbage), but being dependent upon others to stay alive is a violation of dignity even in the absence of more direct violations. Relative poverty, on the other hand, is a violation because the cumulative experience of not being able to afford the same clothes, entertainment, social events, education, or other features of typical life in that society results in subtle humiliation; social rejection; marginalization; and consequently, a diminished self-respect.\n\nAnother example of violation of human dignity, especially for women in developing countries, is lack of sanitation. Having no access to toilets leaves currently about 1 billion people of the world with no choice other than to defecation in the open, which has been declared by the Deputy Secretary-General of the United Nations as an affront to personal dignity. Human dignity is also violated by the practice of employing people in India for \"manual scavenging\" of human excreta from unsanitary toiletsusually by people of a lower caste, and more often by women than men.\n\nA further example of violation of human dignity, affecting women mainly in developing countries, is female genital mutilation (FGM).\n\nThe movie \"The Magic Christian\" depicts a wealthy man (Peter Sellers) and his son (Ringo Starr) who test the limits of dignity by forcing people to perform self-degrading acts for money. The \"Simpsons\" episode \"Homer vs. Dignity\" has a similar plot.\n\nA philosopher of the Renaissance, Pico della Mirandola, granted dignity to ideas and to beings. In his \"Oration on the Dignity of Man\", he told hostile clerics about the dignity of the liberal arts and about the dignity and the glory of angels. His comments implied the dignity of philosophers. This oration is commonly seen as one of the central texts of the Renaissance, intimately tied with the growth of humanist philosophies.\n\nA philosopher of the Age of Enlightenment (18th century), Immanuel Kant held that there were things that should not be discussed in terms of value, and that these things could be said to have dignity. 'Value' is necessarily relative, because the value of something depends on a particular observer's judgment of that thing. Things that are \"not\" relativethat are \"ends in themselves\", in Kant's terminologyare by extension beyond all value, and a thing is an \"end in itself\" only if it has a moral dimension; if it represents a choice between right and wrong. In Kant's words: \"Morality, and humanity as capable of it, is that which alone has dignity.\" Specifically with respect to human dignity, which his writings brought from relative obscurity in Western philosophy into a focal point for philosophers, Kant held that \"free will\" is essential; human dignity is related to human agency, the ability of humans to choose their own actions.\n\nPhilosophers of the late 20th century who have written significant works on the subject of dignity include Mortimer Adler and Alan Gewirth. Gewirth's views on human dignity are typically compared and contrasted with Kant's, for like Kant he theorizes that human dignity arises from agency. But while sharing Kant's view that rights arise from dignity, Gewirth focused far more than Kant on the positive obligations that dignity imposed on humans, the moral requirement not only to avoid harming but to actively assist one another in achieving and maintaining a state of \"well being\".\n\nAmong other topics, including the dignity of labor, Adler extensively explored the question of human equality and equal right to dignity. According to Adler, the question of whether humans have equal right to dignity is intrinsically bound in the question of whether human beings are truly equal, which itself is bound in the question of whether human beings are a distinct class from all things, including animals, or vary from other things only by degree. Adler wrote that the only sense in which it is true that all human beings are equal is that they are equally distinct from animals. \"The dignity of man,\" he said, \"is the dignity of the human being as a person—a dignity that is not possessed by things.\" To Adler, failure to recognize the distinction challenged the right of humans to equal dignity and equal treatment.\n\nDan Egonsson, followed by Roger Wertheimer, argued that while it is conventional for people to equate dignity with 'being human' (Egonsson's 'Standard Attitude', Wertheimer's 'Standard Belief'), people generally also import something other than mere humanness to their idea of dignity. Egonsson suggested that an entity must be both human and \"alive\" to merit an ascription of dignity, while Wertheimer states \"it is not a definitional truth that human beings have human status.\"\n\nAccording to Arthur Schopenhauer, dignity is opinion of others about our worth and subjective definition of dignity is our fear from this opinion of others.\n\nMore recently, Philippe-André Rodriguez has argued that human dignity is best understood as an essentially contested concept. As he argues, \"it seems that it is this very nature of the concept that has allowed, on the one hand, human rights to receive such international acceptance as a theoretical enterprise and, on the other hand, has led the concept to be constantly challenged by different cultures worldwide.\"\n\nHuman dignity is a central consideration of Christian philosophy The Catechism of the Catholic Church insists the \"dignity of the human person is rooted in his or her creation in the image and likeness of God.\" \"All human beings,\" says the Church, \"in as much as they are created in the image of God, have the dignity of a person.\" The catechism says, \"The right to the exercise of freedom belongs to everyone because it is inseparable from his or her dignity as a human person.\" The Catholic Church's view of human dignity is like Kant's insofar as it springs from human agency and free will, with the further understanding that free will in turn springs from human creation in the image of God.\n\nHuman dignity, or \"kevod ha-beriyot\", is also a central consideration of Judaism. \"Talmud\" cautions against giving charity publicly rather than in private to avoid offending the dignity of the recipient. Medieval Jewish philosopher Maimonides in his codification of \"Halakha\" cautioned judges to preserve the self-respect of people who came before them: \"Let not human dignity be light in his eyes; for the respect due to man supersedes a negative rabbinical command\".\n\nAn Islamic view of dignity is crystallized in the Quran through the selected biographies of Noah, Abraham, Joseph, David, Moses, Mary, Jesus and others (differing from the narratives in the Bible, which the Quran claims were corrupted). Individuals such as these are presented as role-models of dignity because they did not abandon their self-respect by bowing to social pressures. When faced with the fear of disapproval, poverty, hunger, death etc. these individuals held firm in their sense of right and wrong, which was in-line with Divine ordinances. \"The right course is that on which one keeps his attitudes, ambitions and requirements subjected to the Divine Laws; and in this way leads a balanced and graceful life. Such a person has grasped the most trustworthy support which will never fail him\" (Quran 31:22) Such individuals are given the title of Muhsineen, who faced immense pressures but held firm in their positive actions. God awarded these individuals with authority and status in the land, and this reward is open to anyone who proves themselves worthy: \"We bestow such honour and position on all those who lead their lives according to Our Laws.\" (Quran 37:80) Those who fall into this category are also afforded Divine protection from their mistakes: \"Therefore We have saved you and your son from this. We have done so because We keep those who lead their lives according to Divine guidance safe from such mishaps.\" (37:104-105) The Quranic State that Muhammad began in Medinah sought to protect human dignity, since in a Quranic Welfare State individuals are free to work and live without the pressures faced by the threat of poverty, and thus can obey God's Laws as free individuals, contributing as part of a unified brotherhood working towards achieving humanity's full potential. Elaborations on dignity have been made by many scholars of Islam, such as Mohammad-Ali Taskhiri, head of the Islamic Culture and Communications Organization in Iran, in 1994. According to Taskhiri, dignity is a state to which all humans have equal \"potential\", but which can only be actualized by living a life pleasing to the eyes of God. This is in keeping with the 1990 Cairo Declaration on Human Rights in Islam, which states that \"True faith is the guarantee for enhancing such [basic human] dignity along the path to human perfection\".\n\nHuman dignity is considered as Buddhahood in Mahayana Buddhism in which it is rooted in the idea that we are able to choose the path of self-perfection as a human being.\n\nIn the 20th century, dignity became an issue for physicians and medical researchers. It has been invoked in questions of the bioethics of human genetic engineering, human cloning, and end-of-life care (particularly in such situations as the Terri Schiavo case, a controversial situation in which life support was withdrawn from a woman diagnosed in a persistent vegetative state).\n\nIn June 1964, the World Medical Association issued the \"Declaration of Helsinki\". The Declaration says at article 11, \"It is the duty of physicians who participate in medical research to protect the life, health, dignity, integrity, right to self-determination, privacy, and confidentiality of personal information of research subjects.\"\n\nThe Council of Europe invoked dignity in its effort to govern the progress of biology and medicine. On 4 April 1997, the Council, at Oviedo, approved the \"Convention for the Protection of Human Rights and Dignity of the Human Being with regard to the Application of Biology and Medicine\". The convention's preamble contains these statements, among others:\n\nThe Convention states, \"Parties to this Convention shall protect the dignity and identity of all human beings and guarantee everyone, without discrimination, respect for their integrity and other rights and fundamental freedoms with regard to the application of biology and medicine.\"\n\nIn 1998, the United Nations mentioned dignity in the \"UNESCO Declaration on the Human Genome and Human Rights\". At Article 2, the declaration states, \"Everyone has a right to respect for their dignity.\" At Article 24, the declaration warns that treating a person to remove a genetic defect \"could be contrary to human dignity.\" The \"Commentary\" that accompanies the declaration says that, as a consequence of the possibility of germ-line treatment, \"it is the very dignity of the human race which is at stake.\"\n\nIn 1996, the Government of Canada issued a report entitled \"New Reproductive and Genetic Technologies\". The report used \"the principles of respect for human life and dignity\" as its reason for recommending that various activities associated with genetic research and human reproduction be prohibited. The report said the prohibited activities were \"contrary to Canadian values of equality and respect for human life and dignity.\"\n\nThe Ministry of Health enacted the \"Danish Council Act 1988\", which established the Danish Council of Ethics. The Council advises the Ministry on matters of medicine and genetic research on humans. In 2001, the Council condemned \"reproductive cloning because it would violate human dignity, because it could have adverse consequences for the cloned person and because permitting research on reproductive cloning would reflect a disregard for the respect due to the moral status of embryos.\"\n\nIn 1984, France set up the National Consultative Committee for Ethics in the Life and Health Sciences (CCNE) to advise the government about the regulation of medical practices and research. In 1986, the CCNE said, \"Respect for human dignity must guide both the development of knowledge and the limits or\nrules to be observed by research.\" The CCNE said that research on human embryos must be subject to \"the rule of reason\" and must have regard for \"undefined dignity in its practical consequences.\" The CCNE insisted that, in research on human embryos, the ethical principles that should apply are \"respecting human dignity\" and respecting \"the dignity of science.\"\n\nThe National Council of Ethics of Portugal published its \"Opinion on the Ethical Implications of Cloning\" in 1997. The opinion states, \"the cloning of human beings, because of the problems it raises concerning the dignity of the human person, the equilibrium of the human species and life in society, is ethically unacceptable and must be prohibited.\"\n\nSweden's \"The Genetic Integrity Act\" (2006:351), \"The Biobanks in Medical Care Act\" (2002:297), \"Health and Medical Services (Professional Activities) Act\" (1998:531), and \"The Health and Medical Services Act\" (1982:763) all express concern for \"the integrity of the individual\" or \"human dignity.\"\n\nIn 2008, The President's Council on Bioethics tried to arrive at a consensus about what dignity meant but failed. Edmund D. Pellegrino, M.D., the Council's Chairman, says in the Letter of Transmittal to the President of The United States, \"… there is no universal agreement on the meaning of the term, human dignity.\"\n\nMcDougal, Lasswell, and Chen studied dignity as a basis for international law. They said that using dignity as the basis for laws was a \"natural law approach.\" The natural law approach, they said, depends upon \"exercises of faith.\" McDougal, Lasswell, and Chen observed:\nIn 2004, Canada enacted the \"Assisted Human Reproduction Act\". Section 2(b) of the Act states, \"the benefits of assisted human reproductive technologies and related research for individuals, for families and for society in general can be most effectively secured by taking appropriate measures for the protection and promotion of human health, safety, dignity and rights in the use of these technologies and in related research.\" The Act prescribes a fine not exceeding $500,000 or imprisonment for a term not exceeding ten years, or both, if someone undertakes a proscribed activity such as the creation of a chimera.\n\nArticle 1 of the Charter of Fundamental Rights of the European Union affirms the inviolability of human dignity.\n\nIn 1997, the National Consultative Committee for Ethics in the Life and Health Sciences, as well as other observers, noted that France's dignity-based laws on bio-medical research were paradoxical. The law prohibited the willful destruction of human embryos but directed that human embryos could be destroyed if they were more than five years old. The law prohibited research on human embryos created in France but permitted research on human embryos brought to France. The law prohibited researchers from creating embryos for research but allowed researchers to experiment with embryos that were superfluous after \"in vitro\" fertilization.\n\nHuman dignity is the fundamental principle of the German constitution. Article 1, paragraph 1 reads: \"\"Human dignity is inviolable. To respect and protect it is the duty of all state authority.\" \"Human dignity is thus mentioned even before the right to life. This has a significant impact on German law-making and jurisdiction in both serious and trivial items:\n\n\nThe need to respect human dignity has been written in the Iranian constitution law. Article 2 of the Iranian Constitution Law mentions six principles and infrastructures as basic to the governing system which in Article 1 is called the Islamic Republic of Iran. The sixth principle of this Article concerns human dignity and stipulates that “the Islamic Republic of Iran is a system founded on faith in ….6) Human dignity and high value and his/her freedom as well as his responsibility before God”[3]. Besides, in the prelude to the Constitution, human dignity is referred to concerning the mass media.\n\nThe Constitution of South Africa lists \"human dignity, the achievement of equality and the advancement of human rights and freedoms\" as one of the founding values of the South African state, and the Bill of Rights is described as affirming the \"democratic values of human dignity, equality and freedom\". Section 10 of the Constitution explicitly states that \"Everyone has inherent dignity and the right to have their dignity respected and protected.\" In jurisprudence, the right to dignity is often seen as underlying more specific rights, such as equality, security of the person or privacy, but it has been directly applied in a number of cases relating to criminal punishment, the law of defamation, and the right to marriage and family life.\n\nThe Swiss Federal Constitution provides in article 7 that \"Human dignity must be respected and protected.\" It also provides, in art. 120, that the state must \"take account of the dignity of living beings as well as the safety of human beings, animals and the environment\" when legislating on the use of reproductive and genetic material; consequently the Federal Ethics Commission on Non-Human Biotechnology (ECNH) issued, in 2008, a publication entitled \"The dignity of living beings with regard to plants\".\n\n\n"}
{"id": "2850124", "url": "https://en.wikipedia.org/wiki?curid=2850124", "title": "Fleming's left-hand rule for motors", "text": "Fleming's left-hand rule for motors\n\nFleming's left-hand rule for electric motors is one of a pair of visual mnemonics, the other being Fleming's right-hand rule (for generators). They were originated by John Ambrose Fleming, in the late 19th century, as a simple way of working out the direction of motion in an electric motor, or the direction of electric current in an electric generator.\n\nWhen current flows through a conducting wire, and an external magnetic field is applied across that flow, the conducting wire experiences a force perpendicular both to that field and to the direction of the current flow (i.e they are mutually perpendicular) . A left hand can be held, as shown in the illustration, so as to represent three mutually orthogonal axes on the thumb, fore finger and middle finger. Each finger is then assigned to a quantity (mechanical force, magnetic field and electric current). The right and left hand are used for generators and motors respectively.\n\n\n\n\nVan de Graaff's translation of Fleming's rules is the FBI rule, easily remembered because these are the initials of the Federal Bureau of Investigation.\n\n\nThis uses the conventional symbolic parameters of F (for Lorentz force), B (for magnetic flux density) and I (for electric current), and attributing them in that order (FBI) respectively to the thumb, first finger and second finger.\n\nOf course, if the mnemonic is taught (and remembered) with a different arrangement of the parameters to the fingers, it could end up as a mnemonic that also reverses the roles of the two hands (instead of the standard left hand for motors, right hand for generators). These variants are catalogued more fully on the FBI mnemonics page.\n\nThis approach to remembering which finger represents which quantity uses some actions. First of all you need to point your fingers like a pretend gun, with the index finger acting as the barrel of the gun and the thumb acting as the hammer. Then go through the following actions:\n\n\nFleming's left-hand rule is used for electric motors, while Fleming's right-hand rule is used for electric generators.\n\nDifferent hands need to be used for motors and generators because of the differences between cause and effect. \n\nIn an electric motor, the electric current and magnetic field exist (which are the causes), and they lead to the force that creates the motion (which is the effect), and so the left hand rule is used. In an electric generator, the motion and magnetic field exist (causes), and they lead to the creation of the electric current (effect), and so the right hand rule is used.\n\nTo illustrate why, consider that many types of electric motors can also be used as electric generators. A vehicle powered by such a motor can be accelerated up to high speed by connecting the motor to a fully charged battery. If the motor is then disconnected from the fully charged battery, and connected instead to a completely flat battery, the vehicle will decelerate. The motor will act as a generator and convert the vehicle's kinetic energy back to electrical energy, which is then stored in the battery. Since neither the direction of motion nor the direction of the magnetic field (inside the motor/generator) has changed, the direction of the electric current in the motor/generator has reversed. This follows from the second law of thermodynamics (the generator current must oppose the motor current, and the stronger current outweighs the other to allow the energy to flow from the more energetic source to the less energetic source).\n\nThe rule for motors can be recalled by remembering that \"motors drive on the left in Britain\". The rule for generators can be recalled by remembering that either the letters \"g\" and \"r\" is common to both \"right\" and \"generator\", or the phrase \"Jenny is always right\" (\"Genny\" being a common shortened version of Generator).\n\nWhen electrons, or any charged particles, flow in the same direction (for example, as an electric current in an electrical conductor, such as a metal wire) they generate a cylindrical magnetic field that wraps round the conductor (as discovered by Hans Christian Ørsted). \n\nThe direction of the induced magnetic field is sometimes remembered by \"Maxwell's corkscrew rule\". That is, if the conventional current is flowing away from the viewer, the magnetic field runs clockwise round the conductor, in the same direction that a corkscrew would have to turn in order to move away from the viewer. The direction of the induced magnetic field is also sometimes remembered by the right-hand grip rule, as depicted in the illustration, with the thumb showing the direction of the conventional current, and the fingers showing the direction of the magnetic field. The existence of this magnetic field can be confirmed by placing magnetic compasses at various points round the periphery of an electrical conductor that is carrying a relatively large electric current.\n\nIf an external magnetic field is applied horizontally, so that it crosses the flow of electrons (in the wire conductor, or in the electron beam), the two magnetic fields will interact. Michael Faraday introduced a visual analogy for this, in the form of imaginary magnetic lines of force: those in the conductor form concentric circles round the conductor; those in the externally applied magnetic field run in parallel lines. If those on one side of the conductor are running (from the north to south magnetic pole) in the opposite direction to those surrounding the conductor, they will be deflected so that they pass on the other side the conductor (because magnetic lines of force cannot cross or run contrary to each other). Consequently, there will be a large number of magnetic field lines in a small space on that side of the conductor, and a dearth of them on the original side of the conductor. Since the magnetic field lines of force are no longer straight lines, but curved to run around the electrical conductor, they are under tension (like stretched elastic bands), with energy bound up in the magnetic field. Since this energetic field is now mostly unopposed, its build-up or expulsion in one direction creates — in a manner analogous to Newton's Third Law of Motion — a force in the opposite direction. Since there is only one moveable object in this system (the electrical conductor) for this force to work upon, the net effect is a physical force working to expel the electrical conductor out of the externally applied magnetic field in the direction opposite to that which the magnetic flux is being redirected to — in this case (motors), if the conductor is carrying conventional current \"upwards\", and the external magnetic field is moving \"away from\" the viewer, the physical force will work to push the conductor to the left. This is the reason for torque in an electric motor. (The electric motor is then constructed so that the expulsion of the conductor out of the magnetic field causes it be placed inside the next magnetic field, and for this switching to be continued indefinitely.)\n\nFaraday's Law: the induced electromotive force in a conductor is directly proportional to the rate of change of the magnetic flux in the conductor.\n\n\n"}
{"id": "34824761", "url": "https://en.wikipedia.org/wiki?curid=34824761", "title": "Fraïssé's theorem", "text": "Fraïssé's theorem\n\nIn mathematics, Fraïssé's theorem, named after Roland Fraïssé, states that a class \"K\" of finite relational structures is the age of a countable homogeneous relational structure if and only if it satisfies the following four conditions:\n\n\nIf these conditions hold, then the countable homogeneous structure whose age is \"K\" is unique up to isomorphism.\n\nFraïssé proved the theorem in the 1950s. \n\nFor a proof and more details see Section 1.2 and Appendix A of this thesis. \n"}
{"id": "32926280", "url": "https://en.wikipedia.org/wiki?curid=32926280", "title": "Free Basket", "text": "Free Basket\n\nFree Basket is a public artwork by the Cuban artist group Los Carpinteros, located in the , in Indianapolis, Indiana, United States. The artwork is in the form of an international basketball court with twenty-four red or blue steel arches that travel throughout the court, mimicking the trajectory of two bouncing basketballs. Two of the arches terminate with their own regulation size basketball hoop, netting, and backboard.\n\n\"Free Basket\" is located outside the boundary of the 100 Acres park on city property. The parking loop surrounding the artwork is situated just south of the Lake and west of the museum. The artwork can be accessed by means of the IWC Canal Greenway (Central Canal Trail), W 38th Street, and the 100 Acres Park walkway. \"Free Basket\" is a site-specific work consisting of twenty-four red- or blue-painted steel tubular arches that mimic the trajectory of two bouncing basketballs. The arches travel throughout the court and are of varying heights and span widths. Two of the arches (one red and one blue) are capped at midpoint, each with their own basketball backboard fashioned with: backboard, metal rim, and nylon net. The steel arches have been mounted on a level, rectangular concrete surface that is size of an international basketball court, where they have been filled and secured with concrete cement. The concrete court has been surfaced with Rhino Guard colored plastic and has been painted to the standards of an international basketball court. The primary court color is yellow, the “goal lines” are painted white, and sections of black and green flank both sides of the court, and a black border surrounds entire court. There are also built-in lighting systems that have been sunk into the court to illuminate the sculpture.\n\nLos Carpinteros sought to portray the juxtaposition of the practical and the imaginary with \"Free Basket\", and drew on the history of sports in Indianapolis to merge art, sports, and culture.\n\nThis artwork was installed at the IMA in May 2010.\n\n\"Free Basket\" has been acquired by the Indianapolis Museum of Art.\n\nIn general, the artwork requires regular cleaning of both the steel and court components to discourage the buildup of damaging materials. Instrumental analysis involving the artwork's color and gloss levels has also been recorded.\n\n"}
{"id": "2308033", "url": "https://en.wikipedia.org/wiki?curid=2308033", "title": "Fundamental rights", "text": "Fundamental rights\n\nSome universally recognized rights that are seen as fundamental, i.e., contained in the United Nations Universal Declaration of Human Rights, the U.N. International Covenant on Civil and Political Rights, or the U.N. International Covenant on Economic, Social and Cultural Rights, include the following:\n\nThough many fundamental rights are also widely considered human rights, the classification of a right as \"fundamental\" invokes specific legal tests courts use to determine the constrained conditions under which the United States government and various state governments may limit these rights. In such legal contexts, courts determine whether rights are fundamental by examining the historical foundations of those rights and by determining whether their protection is part of a longstanding tradition. Individual states may guarantee other rights as fundamental. That is, States may add to fundamental rights but can never diminish or infringe upon fundamental rights by legislative processes. Any such attempt, if challenged, may involve a \"strict scrutiny\" review in court.\n\nIn Canada, the Charter of Rights and Freedoms outlines four Fundamental Freedoms. These are freedom of:\n\nEurope has no identical doctrine (It would be incompatible with the more restrained role of judicial review in European law.) However, EU law recognizes many of the same human rights and protects them through other means.\n\nSee also: Copenhagen criteria, and European Convention on Human Rights, which every member state of the EU has to comply with and for which the European Court of Human Rights has final appellate jurisdiction.\n\nThe Indian fundamental rights, contrasted with such rights contained in the US bill of rights, present several peculiarities.The fundamental rights in India are far more elaborate than in the United States. Thus, for example, the US bill of rights (first ten amendments) only names some rights. The Supreme Court, through the process of judicial review, decides the limitations on these rights.\nThere are seven main fundamental rights of India:\n\nNewly implemented 7th Fundamental right in India is\n\nIt was added in the constitution after the 86th amendment in the year 2002 under article 21A. It is the most recently implemented fundamental right. The RTE Act enabled this right in the year 2010.\n\nA recent addition was made to the list of fundamental rights in India in 2017.\n\nIn American Constitutional Law, \"fundamental rights\" have special significance under the U.S. Constitution. Those rights enumerated in the U.S. Constitution are recognized as \"fundamental\" by the U.S. Supreme Court. According to the Supreme Court, enumerated rights that are incorporated are so fundamental that any law restricting such a right must both serve a compelling state purpose and be narrowly tailored to that compelling purpose.\n\nThe original interpretation of the United States Bill of Rights was that only the Federal Government was bound by it. In 1835, the U.S. Supreme Court in \"Barron v Baltimore\" unanimously ruled that the Bill of Rights did not apply to the states. During post-Civil War Reconstruction, the 14th Amendment was adopted in 1868 to rectify this condition, and to specifically apply the whole of the Constitution to all U.S. states. In 1873, the Supreme Court essentially nullified the key language of the 14 Amendment that guaranteed all \"privileges and immunities\" to all U.S. persons, in a series of cases called the Slaughterhouse cases. This decision and others allowed post-emancipation racial discrimination to continue largely unabated.\n\nLater Supreme Court justices found a way around these limitations without overturning the Slaughterhouse precedent: they created a concept called Selective Incorporation. Under this legal theory, the court used the remaining 14 Amendment protections for equal protection and due process to \"incorporate\" individual elements of the Bill of Rights against the states. \"The test usually articulated for determining fundamentality under the Due Process Clause is that the putative right must be 'implicit in the concept of ordered liberty', or 'deeply rooted in this Nation's history and tradition.'\" Compare page 267 Lutz v. City of York, Pa., 899 F. 2d 255 - United States Court of Appeals, 3rd Circuit, 1990.\n\nThis set in motion a continuous process under which each individual right under the Bill of Rights was incorporated, one by one. That process has extended more than half a century, with the free speech clause of the First Amendment first incorporated in 1925 in Gitlow v New York. The most recent amendment completely incorporated as fundamental was the Second Amendment right to possess and bear arms for personal self-defense, in McDonald v Chicago, handed down in 2010.\n\nNot all clauses of all amendments have been incorporated. For example, states are not required to obey the Fifth Amendment's requirement of indictment by grand jury. Many states choose to use preliminary hearings instead of grand juries. It is possible that future cases may incorporate additional clauses of the Bill of Rights against the states.\n\nThe Bill of Rights lists specifically enumerated rights. The Supreme Court has extended fundamental rights by recognizing several fundamental rights not specifically enumerated in the Constitution, including but not limited to:\nAny restrictions a government statute or policy places on these rights are evaluated with strict scrutiny. If a right is denied to everyone, it is an issue of substantive due process. If a right is denied to some individuals but not others, it is also an issue of equal protection. However, any action that abridges a right deemed fundamental, when also violating equal protection, is still held to the more exacting standard of strict scrutiny, instead of the less demanding rational basis test.\n\nDuring the Lochner era, the right to freedom of contract was considered fundamental, and thus restrictions on that right were subject to strict scrutiny. Following the 1937 Supreme Court decision in \"West Coast Hotel Co. v. Parrish\", though, the right to contract became considerably less important in the context of substantive due process and restrictions on it were evaluated under the rational basis standard.\n\n"}
{"id": "39617264", "url": "https://en.wikipedia.org/wiki?curid=39617264", "title": "Holacracy", "text": "Holacracy\n\nHolacracy is a method of decentralized management and organizational governance, in which authority and decision-making are distributed throughout a holarchy of self-organizing teams rather than being vested in a management hierarchy. Holacracy has been adopted by for-profit and non-profit organizations in several countries.\n\nThe Holacracy system was developed at Ternary Software, an Exton, Pennsylvania company that was noted for experimenting with more democratic forms of organizational governance. Ternary founder Brian Robertson distilled the company's best practices into an organizational system that became known as Holacracy in 2007. Robertson later developed the \"Holacracy Constitution\", which lays out the core principles and practices of the system. In June 2015, he released the book \"Holacracy: The New Management System for a Rapidly Changing World,\" that details and explains his practices.\n\nThe term holacracy is derived from the term holarchy, coined by Arthur Koestler in his 1967 book \"The Ghost in the Machine\". A holarchy is composed of holons (Greek: ὅλον, holon neuter form of ὅλος, holos \"whole\") or units that are autonomous and self-reliant, but also dependent on the greater whole of which they are part. Thus a holarchy is a hierarchy of self-regulating holons that function both as autonomous wholes and as dependent parts.\n\nHolacracy is one of several systems of flat organization. It has been compared to sociocracy, a system of governance developed in the second half of the 20th century. Sociocracy had a significant early influence during the incubation of Holacracy, though Holacracy has increasingly differentiated away from it since then. Sociocracy particularly inspired the development of the circle structure and governance processes (described in more detail later) within Holacracy. Holacracy is designed for organizations and fundamentally differentiates the roles of the organization from the people working in it.\n\nIn its emphasis on iterative governance, adaptive processes, and self-organization, . Holacracy is highly compatible with stakeholder theory as its board structure allows for multiple stakeholders to be represented in the governance of an organization and for multiple organizations with shared interests to be linked at the governance level.\n\nThe building blocks of Holacracy's organizational structure are roles. Holacracy distinguishes between roles and the people who fill them, as one individual can hold multiple roles at any given time. A role is not a job description; its definition follows a clear format including a name, a purpose, optional \"domains\" to control, and accountabilities, which are ongoing activities to perform. Roles are defined by each circle —or team— via a collective governance process, and are updated regularly in order to adapt to the ever-evolving needs of the organization.\n\nHolacracy structures the various roles in an organization in a system of self-organizing (but not self-directed) circles. Circles are organized hierarchically, and each circle is assigned a clear purpose and accountabilities by its broader circle. However, each circle has the authority to self-organize internally to best achieve its goals. Circles conduct their own governance meetings, assign members to fill roles, and take responsibility for carrying out work within their domain of authority. Circles are connected by two roles known as \"lead link\" and \"rep link\", which sit in the meetings of both their circle and the broader circle to ensure alignment with the broader organization’s mission and strategy.\n\nEach circle uses a defined governance process to create and regularly update its own roles and policies. Holacracy specifies a structured process known as \"integrative decision making\" for proposing changes in governance and amending or objecting to proposals. This is not a consensus-based system, not even a consent-based system, but one that integrates relevant input from all parties and ensures that the proposed changes and objections to those changes are anchored in the roles' needs (and through them, the organization's needs), rather than people's preferences or ego.\n\nHolacracy specifies processes for aligning teams around operational needs, and requires that each member of a circle fulfill certain duties in order to work efficiently and effectively together. In contrast to the governance process, which is collective and integrative, each member filling a role has a lot of autonomy and authority to make decisions on how to best achieve his or her goals. Some have described the authority paradigm in Holacracy as completely opposite to the one of the traditional management hierarchy; instead of needing permission to act or innovate, Holacracy gives blanket authority to take any action needed to perform the work of the roles, unless it is restricted via policies in governance or it involves spending some assets of the organization (money, intellectual property, etc.) Holacracy is thus highly biased toward action and innovation: it defaults to autonomy and freedom, then uses internal processes to limit that autonomy when its use in a specific way turns out to be detrimental.\n\nHolacracy specifies a tactical meeting process that every circle goes through usually on a weekly basis. This process includes different phases to report on relevant data, share updates on projects, and open discussions where any circle member can add to the agenda. A particular feature of this last phase, known as \"triage\", is to focus discussions on the concrete next steps needed by the individual who added the agenda item to address his or her issue. The intention is to avoid large, unproductive discussions dominated by the louder voices.\n\nIn the U.S., for-profit and not-for-profit organizations have adopted and practiced Holacracy. Examples include Zappos, the David Allen Company, Precision Nutrition, and nonprofit Conscious Capitalism. Medium used Holacracy for several years before abandoning it in 2016.\n\nHolacracy is claimed to increase agility, efficiency, transparency, innovation and accountability within an organization. The approach encourages individual team members to take initiative and gives them a process in which their concerns or ideas can be addressed. The system of distributed authority reduces the burden on leaders to make every decision.\n\nAccording to Zappos's CEO Tony Hsieh, Holacracy makes individuals more responsible for their own thoughts and actions.\n\nSteve Denning warned against viewing Holacracy as a panacea, claiming that instead of removing hierarchy, decisions are funneled down from circle to circle in a clear hierarchy, with each subsequent circle knowing less about the big picture than the one above. He also claimed that the rules and procedures laid out in the founding documents of Holacracy such as Robertson's originating article are very detailed and focused on \"administrivia.\" Lastly, Denning added that the voice of the customer was missing from the Holacracy model, concluding that for agile and customer-focused companies such as Zappos, Holacracy is a way to add administrative rigor, but that Holacracy would not necessarily work well in an organization that did not already have agility and passion for the customer. HolacracyOne partner Olivier Compagne replied to those criticisms on the company's blog, claiming that Denning's criticisms misunderstand Holacracy, and explaining how the rules of Holacracy address or avoid those alleged pitfalls.\n\nIn moving away from Holacracy, \"Medium\" noted that \"for larger initiatives, which require coordination across functions, it can be time-consuming and divisive to gain alignment\" and that Medium believed that \"the act of codifying responsibilities in explicit detail hindered a proactive attitude and sense of communal ownership\". They also noted that the inaccurate media coverage of Holacracy created a challenge for recruitment.\n\nAt Zappos, about 14% of the company left voluntarily in 2015 in a deliberate attempt by Zappos to have only retain employees who believed in holacracy.\n\nOther criticisms include a \"one-size-fits-all\" approach, layers of bureaucracy and more psychological weight.\n\nThe name Holacracy is a registered trademark of HolacracyOne LLC. Selling products and services under the \"Holacracy\" name requires explicit approval from HolacracyOne. It is not a patent, and does not limit anyone from using the model—it only limits the use of the brand name for commercial purposes.\n\nThe model itself, as defined by the Holacracy Constitution, is released under a Creative Commons Attribution ShareAlike 4.0 license. It is a \"Free Cultural Work\" license that and can be considered \"open source\".\n\n\n"}
{"id": "505029", "url": "https://en.wikipedia.org/wiki?curid=505029", "title": "Hypermodernity", "text": "Hypermodernity\n\nHypermodernity (supermodernity) is a type, mode, or stage of society that reflects an inversion of modernity in which the function of an object has its reference point in the form of an object rather than function being the reference point for form. Hypermodernism stipulates a world in which the object has been replaced by the attributes of the object. The new attribute-driven world is driven by the rise of technology and aspires to a convergence between technology and biology and more importantly information and matter. Hypermodernism finds its validation in emphasis on the value of new technology to overcome natural limitations and emphasizes a dismissal of an object-driven past in favor of a flexible, attribute-driven heuristic. \n\nHypermodernity emphasizes a hyperbolic separation between past and present due to the fact that:\n\nHypermodernity inverts Modernity to allow the attributes of an object to provide even more individuality than modernism. Modernity trapped form within the bounds of limited function; hypermodernity posits that function is now evolving so rapidly, it must take its reference point from form itself. Both positive and negative societal changes occur due to hyper-individualism and increased personal choice. \n\nPostmodernity rejected the idea of the past as a reference point and curated objects from the past for the sole purpose of freeing form from function. In postmodernism, truth was ephemeral as the focus was to avoid non-falsifiable tenets. Postmodernity described a total collapse of Modernity and its faith in progress and improvement in empowering the individual.\n\nIf distinguished from hypermodernity, supermodernity is a step beyond the ontological emptiness of postmodernism and relies upon plausible heuristic truths. Whereas modernism focused upon the creation of great truths (or what Lyotard called \"master narratives\" or \"metanarratives\"), and postmodernity was intent upon their destruction (deconstruction); supermodernity operates extraneously of meta-truth. Instead, attributes are extracted from objects of the past based on their present relevance. Since attributes are both true and false, a truth value is not necessary including falsifiability. Supermodernity curates useful attributes from modern and postmodern objects in order to escape nihilistic postmodern tautology. The touchscreen phone is an excellent example of supermodernism in action. Related authors are Terry Eagleton \"After Theory\", and Marc Augé \"Non-Places: Introduction to an Anthropology of Supermodernity\".\n\n\n\n"}
{"id": "34953080", "url": "https://en.wikipedia.org/wiki?curid=34953080", "title": "Illusion of validity", "text": "Illusion of validity\n\nIllusion of validity is a cognitive bias in which a person overestimates his or her ability to interpret and predict accurately the outcome when analyzing a set of data, in particular when the data analyzed show a very consistent pattern—that is, when the data \"tell\" a coherent story.\n\nThis effect persists even when the person is aware of all the factors that limit the accuracy of his or her predictions, that is when the data and/or methods used to judge them lead to highly fallible predictions.\n\nDaniel Kahneman, Paul Slovic, and Amos Tversky explain the illusion as follows: \"people often predict by selecting the output...that is most representative of the input...The confidence they have in their prediction depends primarily on the degree of representativeness...with little or no regard for the factors that limit predictive accuracy. Thus, people express great confidence in the prediction that a person is a librarian when given a description of his personality which matches the stereotype of librarians, even if the description is scanty, unreliable, or outdated. The unwarranted confidence which is produced by a good fit between the predicted outcome and the input information may be called the illusion of validity.\"\n\nIn one study, for example, subjects reported higher confidence in a prediction of the final grade point average of a student after seeing a first-year record of consistent \"B\"&apos;s than a first-year record of an even number of \"A\"&apos;s and \"C\"&apos;s. Consistent patterns may be observed when input variables are highly redundant or correlated, which may increase subjective confidence. However, a number of highly correlated inputs should not increase confidence much more than only one of the inputs; instead higher confidence should be merited when a number of highly \"independent\" inputs show a consistent pattern.\n\nThis bias was first described by Amos Tversky and Daniel Kahneman in their 1973 paper \"On the Psychology of Prediction\".\n\nIn a 2011 article, Kahneman recounted the story of his discovery of the illusion of validity. After completing an undergraduate psychology degree and spending a year as an infantry officer in the Israeli Army, he was assigned to the army's Psychology Branch, where he helped evaluate candidates for officer training using a test called the Leaderless Group Challenge. Candidates were taken to an obstacle field and assigned a group task so that Kahneman and his fellow evaluators could discern their individual leadership qualities or lack thereof.\n\nBut although Kahneman and his colleagues emerged from the exercise with very clear judgments as to who was and wasn't a potential leader, their forecasts proved \"largely useless\" in the long term. Comparing their original evaluations of candidates with the judgments of their officer-training school commanders months later, Kahneman and his colleagues found that their own \"ability to predict performance at the school was negligible. Our forecasts were better than blind guesses, but not by much.\"\n\nYet when asked to again to assess yet another group of candidates, their judgments were as clear as before. \"The dismal truth about the quality of our predictions,\" recalled Kahneman, \"had no effect whatsoever on how we evaluated new candidates and very little effect on the confidence we had in our judgments and predictions.\" Kahneman found this striking: \"The statistical evidence of our failure should have shaken our confidence in our judgments of particular candidates, but it did not. It should also have caused us to moderate our predictions, but it did not.\" Kahneman named this cognitive fallacy \"the illusion of validity\".\n\nDecades later, Kahneman reflected that at least part of the reason for his and his colleagues' failure in assessing the officer candidates was that they had been confronted with a difficult question but had instead, without realizing it, answered an easier one instead. \"We were required to predict a soldier's performance in officer training and in combat, but we did so by evaluating his behavior over one hour in an artificial situation. This was a perfect instance of a general rule that I call WYSIATI, 'What you see is all there is.' We had made up a story from the little we knew but had no way to allow for what we did not know about the individual’s future, which was almost everything that would actually matter.\"\n\nComparing the results of 25 wealth advisers over an eight-year period, Kahneman found that none of them stood out consistently as better or worse than the others. \"The results,\" as he put it, \"resembled what you would expect from a dice-rolling contest, not a game of skill.\" Yet at the firm for which all these advisers worked, no one seemed to be aware of this: \"The advisers themselves felt they were competent professionals performing a task that was difficult but not impossible, and their superiors agreed.\" Kahneman informed the firm's directors that they were \"rewarding luck as if it were skill.\" The directors believed this, yet \"life in the firm went on just as before.\" The directors clung to the \"illusion of skill,\" as did the advisers themselves.\n\nThe scientist Freeman Dyson has recalled his experience as a British Army statistician during World War II, performing an analysis of the operations of the Bomber Command. At the time, an officer argue that because of the heavy gun turrets they carried, the bombers were too slow and could not fly high enough to avoid being shot down. He suggested they remove the turrets and gunners. But the commander in chief rejected the suggestion – because, said Dyson, \"he was blinded by the illusion of validity.\" He was not alone: everyone in the command \"saw every bomber crew as a tightly knit team of seven, with the gunners playing an essential role defending their comrades against fighter attack.\" Part of this illusion \"was the belief that the team learned by experience. As they became more skillful and more closely bonded, their chances of survival would improve.\" Yet statistics, Dyson found, proved that all this was an illusion: deaths occurred randomly, having nothing to do with experience. Members of the bomber command, he realized, were dying unnecessarily because everyone was taken in by an illusion.\n\nIn 2014, an article in \"Rolling Stone\" presented as fact an accusation of rape at the University of Virginia that proved to be false. Rolling Stone's writers and editors, the university president and other administrators, and many U.Va. students were quick to believe the false charges. Harlan Loeb later explained this as an example of the illusion of validity in action.\n\nIn 2012, a sportswriter who described Kahneman as his \"favorite scientist\" wrote: \"The illusion of validity is why I get deeply suspicious whenever a fan, sportswriter, coach, or GM says anything to the effect of 'the numbers don’t tell the whole story.' This is, in fact, true, but what the person saying this usually means is 'I don't care what the numbers say because I am convinced that what I have seen is correct.' Which is, thanks to this illusion, almost never true. If I make an argument that the data says a player isn't good, and someone points out 'Yes, but if you watch the games you will notice that this year they are only shooting threes from the slot, and rarely from the corner, where he used to excel,' then that person is pointing out a hole in the data that's worth investigating. If the argument is along the lines of 'anyone who's watching him can clearly see he's much better than that,' then I'm certain the illusion of validity is doing its dirty work.\"\n\nIn a 1981 paper, J.B. Bushyhead and J.J. Christensen-Szalanski studied data from an outpatient clinic showing that doctors there ordered chest radiographs only on patients who manifested clinical attributes linked to some pneumonia cases, rather than on patients manifesting clinical attributes associated with all pneumonia cases. They attributed this behavior to the illusion of validity.\n\nOther cases where this phenomenon appears include job interviews, wine tasting, stock markets, political strategy.\n\nThe illusion of validity may be caused in part by confirmation bias and/or the representativeness heuristic, and could in turn cause the overconfidence effect.\n\nAmong the factors contributing to the illusion of validity, according to Meinolf Dierkes, Ariane Berthoin Antal, John Child, and Ikujiro Nonaka, are \"a person's tendency to register the frequency of events more than their probability\"; \"the impossibility of gathering information about alternative assumptions if action is based on a hypothesis\"; a \"disregard of base-rate information\"; and \"the self-fulfilling prophecy,\" or \"a behavior manifested in individuals or groups because it was expected.\"\n\nIf one wishes to try to avoid being traduced by the illusion of validity, according to Kahneman, one should ask two questions: \"Is the environment in which the judgment is made sufficiently regular to enable predictions from the available evidence? The answer is yes for diagnosticians, no for stock pickers. Do the professionals have an adequate opportunity to learn the cues and the regularities? The answer here depends on the professionals' experience and on the quality and speed with which they discover their mistakes.\" While many professionals \"easily pass both tests,\" meaning that their \"off-the-cuff judgments\" are of value, in general judgments by \"assertive and confident people\" should be taken with a grain of salt \"unless you have independent reason to believe that they know what they are talking about.\" This can be difficult, however, because \"overconfident professionals...act as experts and look like experts,\" and it can be a \"struggle to remind yourself that they may be in the grip of an illusion.\"\n\nIn his article on the false rape case at the University of Virginia, Harlan Loeb outlined an approach to avoiding the illusion of validity in cases which, like that one, involve “a highly emotional and personal issue that has national resonance, high-profile media coverage and an organization already on the defensive with recent issues.” He advised, first: \"Always challenge (appropriately, of course) facts and assumptions that many rely on to inform their thinking and decision-making about risk and crisis management.\" Second: \"In situations with palpable unknowns, where the illusion of validity in decision-making is a material threat, push hard to do research, polling and active listening to help identify the levers and pulleys that shape the operating and environmental realities of the present risk.\" Third: \"Determine existing organizational challenges that will prevent leadership from making decisions consistently, effectively, and quickly in the face of uncertainty.\" Fourth: \"Be aware of how current actions could dictate future strategy.\" Fifth: \"Be ready to take on current risk to manage future risk.\"\n\nPhil Thornton has offered the following advice for avoiding the illusion of validity in the financial sector. First, \"remember that just because previous generations were successful following certain approaches, replicating their actions may not necessarily be a good idea.\" Second, \"remember that the consequences of decisions being wrong can be more important than the probability of them being correct.\"\n\n\n"}
{"id": "342899", "url": "https://en.wikipedia.org/wiki?curid=342899", "title": "Image (category theory)", "text": "Image (category theory)\n\nIn category theory, a branch of mathematics, the image of a morphism is a generalization of the image of a function.\n\nGiven a category formula_1 and a morphism formula_2 in formula_3, the image\n\nof formula_4 is a monomorphism formula_5 satisfying the following universal property:\n\nRemarks:\n\nThe image of formula_4 is often denoted by formula_20 or formula_21.\n\nProposition: If formula_1 has all equalizers then the formula_14 in the factorization formula_24 of \"(1)\" is an epimorphism.\n= v\\, q</math>.\n\nThis means that formula_25 and thus that formula_26 equalizes formula_27, whence formula_28.\n\nIn a category formula_1 with all finite limits and colimits, the image is defined as the equalizer formula_30 of the so-called cokernel pair formula_31\n\nRemarks: \n\nIn the category of sets the image of a morphism formula_36 is the inclusion from the ordinary image formula_37 to formula_38. In many concrete categories such as groups, abelian groups and (left- or right) modules, the image of a morphism is the image of the correspondent morphism in the category of sets.\n\nIn any normal category with a zero object and kernels and cokernels for every morphism, the image of a morphism formula_39 can be expressed as follows:\nIn an abelian category (which is in particular binormal), if \"f\" is a monomorphism then \"f\" = ker coker \"f\", and so \"f\" = im \"f\".\n\n"}
{"id": "649793", "url": "https://en.wikipedia.org/wiki?curid=649793", "title": "Iraq prison abuse scandals", "text": "Iraq prison abuse scandals\n\nAbout six months after the invasion of Iraq rumors of Iraq prison abuse scandals started to emerge.\n\nThe best known abuse incidents occurred at the large Abu Ghraib prison. Graphic pictures of some of those abuse incidents were made public. Less well-known abuse incidents have been documented at American prisons throughout Iraq.\n\nAccording to the \"Washington Post\", the coalition forces regularly use \"torture-like\" methods during the interrogation of suspects. Such methods were reportedly applied to people to find the hiding place of Saddam Hussein in Operation Red Dawn. British troops have also on occasion been accused of abusing Iraqi detainees. Such treatment violates article 17 of the Third Geneva Convention and the USA and Britain's official policies on combat and occupation. Despite numerous complaints by Amnesty International and Human Rights Watch, it took a year before the first US soldier was court-martialed for their actions concerning abuse of Iraqis.\n\nEight marine reservists were investigated for abuse and the death of a prisoner, outside Nasiriyah.\n\nA photograph leaked after the initial set shows Spc. Sabrina Harman smiling and giving a thumbs up next to the body of Manadel al-Jamadi. Jamadi was reportedly beaten to death during interrogations in the prison's showers.\nDeath certificates repeatedly stated that prisoners had died \"while sleeping\", and of \"natural reasons\". Iraqi doctors are not allowed to investigate the deaths of prisoners, even if death certificates are allegedly forged. No investigations against US military doctors who are alleged to have forged death certificates have been reported.\n\nA US veteran sergeant reports witnessing torture of journalists and writers all over Iraq. Kurdistan region was not an exception. Writers without Borders embarrassed the Iraqi government quite frequently in reports covering minority, women and marginalised Iraqis from all over the country but with much focus on Baghdad, Karkuk, Salahedin and Mosul.\n\nHonorably discharged US veteran, Sergeant Frank \"Greg\" Ford reports that he witnessed war crimes in Samarra, Iraq. According to Ford, several members of his own unit, the 205th Military Intelligence Brigade participated in the torture of Iraqi detainees as young as 14.\n\nAther Karen al-Mowafakia died in Basra, while in British custody. Details about the investigation are not known.\n\nGary Bartlam, a British soldier of the 7th Armoured Brigade, was arrested after submitting film to a photo developers shop in Tamworth, England while on leave. The photographs depict a gagged Iraqi POW suspended hanging by rope from a fork lift, and other pictures seem to show prisoners being forced to perform sexual acts. Bartlam and two other soldiers were convicted at court martial of abuse - a fourth soldier was cleared.\n\nBritish Lieutenant Colonel Tim Collins was alleged by US Army Major Re Biastre to have been responsible for mistreatment of Iraqi civilians and prisoners of war. Lieutenant Colonel Collins was later cleared of any wrongdoing by an MOD investigation.\n\nIn separate incidents, the Royal Military Police declared that Radhi Natna died of a heart attack while in British custody, yet his family reports that he had no heart trouble; and the Black Watch regiment arrested the 17-year-old Ahmad Jabber Kareem Ali in Basra, who then drowned after being ordered to swim across a river despite not being able to swim, according to his friend Ayad Salim Hanoon.\n\nArmy Reservists abused Prisoners at Camp Bucca, and were later court-martialed.\n\nBrigadier General Ennis Whitehead III reported that Master Sergeant Lisa Marie Girman, a state trooper, \"repeatedly kick[ed a prisoner] in the groin, abdomen and head, and encouraging her subordinate soldiers to do the same,\"\n\nLieutenant Colonel Vic Harris reported that Staff Sergeant Scott A. McKenzie who worked at a Pennsylvania Department of Corrections boot-camp-style prison, and Specialist Timothy F. Canjar: held prisoners' legs, encouraged others to then kick them in the groin, stepped on their previously injured arms, and made false sworn statements to the Army Criminal Investigation Division.\n\nThey received \"general under honorable conditions\" discharges, were ordered to forfeit two months' salary, and returned to the United States.\n\nSergeant Shawna Edmondson, also involved in the case, received an \"other-than-honorable\" discharge, after she requested it instead of being court-martialed.\n\nHossam Shaltout said the abuse at Camp Bucca was similar to that at Abu Ghraib prisoner abuse, and that his torture included scorpions placed on his body.\n\nSaid Shabram died in custody, but no information of the investigation were made public.\n\nAmerican forces detained the family of an unidentified lieutenant general to induce him to turn himself in.\n\nThe abuses at Abu Ghraib prison were reportedly committed by MPs. There are allegations that private contractors contributed to them as well and that intelligence agencies such as the CIA ordered them to do so in order to break prisoners for interrogations. It is said to be a usual practice in other US prisons as well, such as in Afghanistan and Guantanamo Bay.\n\nThe International Committee of the Red Cross submitted a detailed report to the U.S. Army in October 2003 about abuses in prisons, and the president of the Red Cross stated he had informed high-ranking members of the Bush administration about the abuses during a meeting in the White House in January 2004. A soldier came forward that month with photos of abuse that he found disturbing, some showed the stacking of prisoners into a human pyramid, with one prisoner's skin visibly bearing a slur written in English. Another showed a prisoner being forced to stand on a box with wires attached to his head and hands, who had reportedly been told that if he fell off the box, he would be electrocuted. Photos released to the public later included a person being attacked by a guard dog, which the soldier involved described as being useful for intimidation of prisoners. It was also reported that an Iraqi hired as a translator raped a juvenile male prisoner while a female soldier took pictures. No charges have been brought against the contractor because he does not fall under military jurisdiction; it is questionable whether any charges will or even can be brought against him.\n\nDonald Rumsfeld had said that army and government had only been informed in January and not in detail. On January 16, 2004, a press release was issued by the United States Central Command (CENTCOM) stating that an investigation had been initiated in response to allegations of detainee abuse at an unspecified detention facility (now known to be Abu Ghraib prison).\n\nIn March 2004, 6 soldiers in Abu Ghraib were charged with dereliction of duty, cruelty and maltreatment, and sexual abuse. 17 others were suspended from duty, including the seven U.S. officers who ran the prison. Also recommended for discipline was Brig. Gen Janis Karpinski, the commander of the 800th brigade. The Red Cross, which had access to these prisons, has stated that the instances of torture were not aberrations but were systemic. Some officers have attempted to defend themselves by saying that they were only doing their duty.\n\nIn response to ongoing complaints, the US military initiated a program to reform the internment and treatment systems. The reforms are expected to increase safeguards for prisoners' rights, to ensure each prisoner receives a copy of their internment order, and has their charges explained to them within 72 hours. They additionally plan to publicly post information about detainees so that family members can know what happened to their loved ones. Reforms were made in March 2004.\n\nTheft of prisoner's possessions by soldiers, dirty, cramped quarters and bad food, prisoners forced into uncomfortable positions for prolonged periods of time, extreme exposure to the elements, and excessive jailings of people based on the paid testimony of individual informants were reported. 55-year-old cafe owner Mahmoud Khodair, who was arrested and held for six months before being released in early march without ever knowing what he was charged with, stated, \"It was just like hell\", and \"Nothing has changed since Saddam. Before, the Mukhabarat [secret police] would take us away, and at least they wouldn't blow down the door. Now, some informant fingers you and gets $100 even if you're innocent.\"\n\nDuring April 2004 the media started to report on the abuse. The journalist Seymour Hersh (who was awarded the Pulitzer Prize for his disclosure of the Vietnam War tragedy at the hamlet of My Lai) published a series of articles in \"The New Yorker\" with photo coverage of U.S. soldiers abusing prisoners in the Abu Ghraib prison on 2004-04-30.\n\nIn an interview with Dan Rather, the deputy director of operations for the US-led coalition, Brig. Gen. Mark Kimmitt, stated \"We're appalled. These are our fellow soldiers. These are the people we work with every day. They represent us. They wear the same uniform as us, and they let their fellow soldiers down. If we can't hold ourselves up as an example of how to treat people with dignity and respect, we can't ask that other nations do that to our soldiers.\"\n\nOn May 1, 2004, photos of prisoners at Abu Ghraib prison in Iraq being abused and humiliated by United States soldiers provoke an international outrage.\n\nFurthering the charges, excerpts from the Abu Ghraib Taguba report were published on May 3, 2004. The report documented: the sodomizing of a prisoner with a chemical light, pouring phosphoric liquid on detainees, rape of a female prisoner, forced masturbation, \"ghost detainees\" moved around to avoid the Red Cross, and many other abuses.\n\nThe release of the photographs and reports had led to renewed calls for investigations into the abuses reported in other US military prisons, such as Camp X-Ray and Camp Delta.\n\nOn May 14, 2004, reporters for the Guardian documented a coercive technique which soldiers called \"bitch in a box\". The prisoner was shoved into the trunk of a car on a hot day, and driven around until the prisoner was near ready to pass out. Another technique documented was \"waterboarding\", which involves water being poured over a cloth covering the face and breathing passages of an immobilized captive, causing the individual to experience the sensation of drowning. They also interviewed many soldiers not involved in the current scandal, who claimed that they were taught to use sleep deprivation, to stage mock executions, and to use other procedures. One platoon leader who objected to these practices was reportedly told that his stand could end his military career.\n\nUSA Defence Secretary Donald Rumsfeld told an armed services committee of the Senate on 2004-05-07 that \"There are a lot more photographs and videos that exist [...] I looked at them last night and they're hard to believe [...] The pictures I've seen depict conduct, behaviour that is so brutal and so cruel and so inhumane that anyone engaged in it or involved in it would have to be brought to justice.\" He also said that the abused detainees may be offered compensation.\n\nIn a scene described as \"surreal\" by AFP, it was found in mid May, 2004 that US troops were handing out cash to freed prisoners along with a note stating \"You have not been mistreated.\". A reporter visiting the prison Camp War Horse described the tour:\n\nIt was claimed that eleven Iraqis had been severely beaten by members of the SAS in Majar al-Kabir; they were released and paid compensation for their injuries.\n\nSadiq Zoman, 57, is delivered in a vegetative state, to a hospital in Tikrit. His body bearing telltale signs of torture: burn marks on his skin, bludgeon marks on the back of his head, a badly broken thumb, electrical burns on the soles of his feet. Additionally, family members say they found whipmarks across his back and more electrical burns on his genitalia. He had entered US custody healthy barely 1 month earlier.\n\nHassan Abbad Said died in custody, but no information of the investigation were made public.\n\nCorporal Donald Payne of the Queen's Lancashire Regiment now the 1st Battalion, Duke of Lancaster's Regiment (King's, Lancashire and Border), became Britain's first convicted war criminal after pleading guilty to abusing Iraqi detainees, which resulted in the death of one detainee Baha Mousa.\n\nAn al Jazeera cameraman, Salah Hassan, reported various abuses in the infamous Abu Ghraib prison complex, such as being forced to strip naked, standing up for 11 hours and being kicked when he collapsed, being forced to wear a vomit-covered jumpsuit, and many other abuses. He later also witnessed a 12- or 13-year-old girl who was stripped naked and beaten. Her brother was held in another cell and heard her screams.\n\nJanuary 3: Marwan Hassoun and his cousin Zaydun Al-Samarrai are taken from their broken-down truck at about curfew time and forced to jump from the Tharthar dam into the Tigris River; the latter drowns. First Lt. Jack M. Saville and Sgt. 1st Class Tracy E. Perkins were charged on 2004 June 7 with manslaughter, assault, conspiracy, making false statements, and obstruction of justice. Sgt. Reggie Martinez was charged three weeks later with manslaughter and for making false statements, and Spec. Terry Bowman with assault and making false statements. Martinez' and Bowman's charges were dropped; Perkins got six months in jail. Saville was jailed (45 days) and fined $12,000 for assault but he remained on active duty until his military obligation was fulfilled.\n\nAlleged photographs of prisoner abuses by UK troops were published by the \"Daily Mirror\" within 48 hours of the breaking of the story of abuses by US troops in the Abu Ghraib prison in Iraq.\n\nGeneral Sir Mike Jackson, Chief of the General Staff, said \"if proven, the perpetrators are not fit to wear the Queen's uniform and they have besmirched the Army's good name and conduct\".\n\nThe authenticity of the photographs was called into question a day later. In particular, a number of specifics in the images, such as the type of rifles the soldiers in the pictures are carrying and the type of truck pictured did not match the equipment used by UK troops in Iraq. The \"Mirror\" responded to these criticisms of the photographs on May 3, 2004.\n\nOn May 14, 2004, the \"Daily Mirror\" reported that the pictures it had published, allegedly showing UK troops abusing an Iraqi prisoner, were fake and that \"the Daily Mirror has been the subject of a calculated and malicious hoax.\" The \"Daily Mirror\" editor, Piers Morgan, was sacked due to the controversy.\n\nOn May 11, 2004, The Boston Globe covered a press conference by Boston City Councilor Chuck Turner and local civil rights activist Sadiki Kambon during which they distributed photographs they alleged showed American soldiers raping Iraqi woman. In its early editions on May 12, photographs from the event clearly showed some of the pictures presented, the Globe later apologized for the error. Other news agencies quickly responded to the story by linking the photographs to American and Hungarian pornography sites. One week prior to the press conference, WorldNetDaily had published a story detailing the origin of these pictures and how they were being used as propaganda. However, several other sources have stated that Iraqi females, including teenage girls, were sexually assaulted while being detained at Abu Ghraib and other US military detention facilities across Iraq. American journalist Tara McKelvey, writing for the magazine The American Prospect, interviewed an Iraqi sheik in the fall of 2004 about this issue and he told her that \"he had seen a young girl, 15 years old, with internal bleeding. She had been raped over and over again by the soldiers, and she could no longer talk. He is a deeply religious man. But that night, he shouted at Allah. ‘How is it possible that you are there and these things are happening?!' he said.”\n\nAmnesty International claimed that British soldiers had killed innocent civilians who were no threat, had kicked a prisoner to death and that the British military did not investigate the abuses appropriately.\n\nDeath in U.S. custody of chemistry professor Mohammed Munim al-Izmerly. An autopsy concluded death was caused by a sudden hit to the back of his head and that the cause of death was blunt trauma.\n\nThe Pentagon confirms a report in the New York Times that CIA chief George Tenet was allowed by U.S. Secretary of Defense Donald Rumsfeld to have an Iraqi prisoner secretly detained at Camp Cropper in November, preventing the International Committee of the Red Cross from monitoring their treatment, a possible violation of the Geneva Conventions.\n\nJune 29: Oregon national guardsmen intervene in the beating of bound prisoners on the grounds of the Iraqi Interior Ministry; are told to back off and let the newly \"sovereign\" Iraqis run their own affairs.\n\nThe International Red Cross reports that more than 100 children were kept in six different prisons of the coalition. Witnesses say US forces also abused children and youths. Soldier Samuel Provance from Abu Ghraib reported the harassment of a 15- to 16-year-old girl in her cell as well as a 16-year-old boy who was driven through the cold after he had been showered and who was then covered with mud. Allegations have been made that children have been subjected to torture and rape. This has been used to make detained parents talk in cases where other interrogation methods have failed. Seymour Hersh told a San Francisco audience: \"what happened is that those women who were arrested with young boys, children, in cases that have been [video] recorded, the boys were sodomized, with the cameras rolling... the worst above all of them is the soundtrack of the boys shrieking.\" An unpublished UNICEF report is said to include statements about children that were arrested in Basra and Kerbela and routinely detained in Umm Kasr. The children are said to be without contact to their families and cannot expect a trial.\n\nDeath penalty \"reluctantly\" reinstated in Iraq \"until stability [is] restored.\"\n\nReports of mock executions by the US Marines in Iraq have surfaced in December 2004, as the ACLU published internal documents of the Naval Criminal Investigative Service (NCIS) obtained through the Freedom of Information Act. The documents were written seven weeks after the publication of the photographs which triggered the Abu Ghraib prisoner abuse scandal.\n\nSeveral torture cases were also reported, notably torture by electricity, beatings, and sprayings of prisoners with fire extinguishers.\n\nOn 21 December, the ACLU released further documents documenting tortures. Notably, in a case of shooting of suspects without warning, Army commanders are reported to have interfered with the investigation. Procedures of autopsy of detainees who died in unclear circumstances have been canceled by battalion and group commands. Other cases include \n\nOn 24 January 2005, the ACLU accused the Pentagon of deliberately closing investigations over Human Rights violations and torture cases before they were over.\n\nHuman Rights Watch accused Iraqi security forces of using torture and improper treatments on prisoners. Arbitrary arrests and long periods of isolation are now common. Human Right Watch interviewed 90 prisoners, among which 72 said they had been tortured during interrogation. Sarah Leah Whitson, HRW director, said that the Iraqi provisional government was not holding to its promise to stand by Human Rights: \n\"A new Iraqi government requires more than a change of leadership - it requires a change of attitude about basic human dignity\" . \n\n\"During the first three days there was continuous torture. I was beaten with an aluminum rod and with cables. ? Then I was told to sign a statement with my hands tied behind my back, so I didn't even see the paper and I don't know what I signed.\" \n\nAmong bad treatments were such elements as beatings with cables, electric shocks, including on genitals, being tied and blindfolded for days, cells so crowded that it is only possible to stand, arbitrary detention, refusal of trials, access to lawyers or contacts with families. These treatments were inflicted to insurgents and criminals alike.\n\nA Pentagon order is mentioned in a military report filed on May 16, 2005 ordering U.S. personnel to turn a blind eye to Iraqi torture by refraining from investigating instances of apparent detainee abuse by Iraqi personnel, unless the investigation is first approved by U.S. headquarters: \"Provided the initial report confirms US forces were not involved in the detainee abuse, no further investigation will be conducted unless directed by HHQ.\" Such approval was rarely granted.\n\nIn a report published by Human Rights Watch in September 2005, U.S. Troops are accused to routinely torture prisoners in Iraq. Two sergeants and a captain describe e.g. the breaking of a detainee’s leg, and applying chemical substances to detainees’ skin and eyes. Capt. Ian Fishback of the 82nd Airborne who made persistent efforts over 17 months to raise concerns about detainee abuse with his chain of command was consistently told to ignore abuses and to “consider your career.” When he made an appointment with Senate staff members of Senators John McCain and John Warner, he says his commanding officer denied him a pass to leave his base.\n\n-173 detainees found in an Iraqi government bunker in Baghdad were found starved, beaten and tortured.\n\n-Colin Powell's former Chief of Staff, Colonel Lawrence Wilkerson, stated in an interview with Amy Goodman on November 22 that:\n\nThe Haditha killings occurred on November 19 in the town of Haditha, Iraq. A convoy of United States Marines was attacked with an improvised explosive device which killed Lance Corporal Miguel Terrazas. Up to twenty-four Iraqis were subsequently killed; it is alleged that they were non-combatant local residents who were massacred by Marines in the aftermath of the insurgent attack.\n\nJohn Pace, human rights chief for the United Nations Assistance Mission in Iraq (UNAMI), told Reuters that there were an estimated 14,000 people being held in prison in Iraq contrary to UN Resolution 1546, according to which the US government claims legal permission to occupy Iraq. In a December 5, 2005, interview, Pace said,\n\nAccording to the Iraqi Defense Ministry, Private First Class Thomas Tucker and Private First Class Kristian Menchaca were reportedly \"killed in a barbaric way,\" \"slaughtered,\" and tortured to death, and their bodies were so mutilated that DNA tests are being performed to help identify their remains. The alleged group has said it was a revenge for the rape and murder of an Iraqi girl who was dishonoured by soldiers of the same brigade.\n\nVideo of the killing of four Russian diplomats kidnapped in Iraq appear on the Internet. A group called the Mujahideen Shura Council released the hostage video.\n\nIn 2009, an additional 21 color photographs surfaced, showing prisoners in Afghanistan and Iraq being abused by their U.S. captors.\nThe American Civil Liberties Union (ACLU) said, \"[T]he government had long argued that the abuse at Abu Ghraib was isolated and was an aberration. The new photos would show that the abuse was more widespread.\" President Barack Obama initially indicated he would not fight the release of the photographs, but \"reversed course in May and authorized an appeal to the high court.\" \"The Obama administration believe[d] giving the imminent grant of authority over the release of such pictures to the defense secretary would short-circuit a lawsuit filed by the American Civil Liberties Union under the Freedom of Information Act.\" On Oct 10, 2009 the US \"Congress [was] set to allow the Pentagon to keep new pictures ... from the public\"\n\nOn February 3, 2010, David A. Larson, an elected official in California who has a relationship with government contract personnel, made disclosures to the U.S. Department of Defense (DOD), Office of the Inspector General (OIG) alleging that under the Bush Administration, prisoners detained at Abu Ghraib, Guantanamo Bay, and undisclosed \"black sites\" were being used as involuntary research subjects for human biomedical experimentation, behavior modification research, and drug-testosterone delivery in a manner similar to past CIA Project MKULTRA activities investigated in 1977 by Senators Kennedy and Inuoye. The allegation supports information contained in an International Red Cross report relative to the expanded role of CIA medical personnel in torture and interrogation.\n\nIn 2010, the last of the prisons were turned over to the Iraqi government to run. An Associated Press article said \n\nIn September 2010 Amnesty International warned in a report titled \"New Order, Same Abuses; Unlawful Detentions and Torture in Iraq\" that up to 30,000 prisoners, including many veterans of the US detention system, remain detained without rights in Iraq and are frequently tortured or abused. Furthermore, it describes a detention system that has not evolved since Saddam Hussein's regime, in which human rights abuses were endemic with arbitrary arrests and secret detention common and a lack of accountability throughout the security forces. Amnesty's Middle East and North Africa director, Malcolm Smart went on to say that \"Iraq's security forces have been responsible for systematically violating detainees' rights and they have been permitted. US authorities, whose own record on detainees' rights has been so poor, have now handed over thousands of people detained by US forces to face this catalogue of illegality, violence and abuse, abdicating any responsibility for their human rights.\"\n\nOn October 22, 2010 nearly 400,000 secret United States army field reports and war logs, detailing torture, summary executions and war crimes, were passed on to the British paper, the Guardian and several other international media organisations through the whistleblowing website WikiLeaks. Among others, the logs detail how US authorities failed to investigate hundreds of reports of abuse, torture, rape and even murder by Iraqi police and soldiers, whose conduct appears to be systematic and normally unpunished and that US troops abused prisoners for years even after the Abu Ghraib scandal. Both the UK and the US have condemned the unauthorised release of classified material, but did not question its accuracy.\n\nSeveral sets of investigations, both congressional via the Senate Armed Services Committee, military via courts-martial, and criminal for non-military contractors, were launched in response to the scandal.\n\nSeymour Hersh, who exposed the Abu Ghraib scandal, and reports in Newsweek, has taken the case even further. In 2003, Donald Rumsfeld instituted a policy that \"encouraged physical coercion and sexual humiliation of Iraqi prisoners in an effort to generate more intelligence about the growing insurgency in Iraq.\". This policy stemmed from an earlier policy taken toward al-Qaeda prisoners. A memo to the Bush White House from counsel Alberto Gonzales claimed that the new sort of war renders the Geneva Conventions' limitations on interrogating enemy prisoners \"obsolete\". The program was approved by the CIA, NSA, and the National Security Council. President George W. Bush was informed of it. The Under Secretary of Defense for Intelligence Steven Cambone administered the operation. His deputy, William Boykin, instructed the head of operations at Camp X-ray Maj. Gen. Geoffrey Miller to do the same at Abu Ghraib. Miller told Brig. Gen. Janis Karpinski that the prison would now be dedicated to gathering intelligence. Douglas Feith and William Haynes were also involved in the operation.\n\nOn May 18, 2004, a military intelligence analyst named Samuel Provance came out to the press, stating \"There's definitely a cover-up\". Provance, who ran a computer network used by military intelligence in the prison and who had been ordered not to speak to the press, told ABC News \"Anything [the MPs] were to do legally or otherwise, they were to take those commands from the interrogators,\" and that the sexual humiliation began as a technique ordered by the investigators. He described several of the goings-on in the prison that he witnessed, such as the punching people in the neck hard enough to knock them unconscious after assuring them they weren't going to be hit, in order to catch them off guard. He also stated that Maj. Gen. George Fay, the Army's deputy chief of staff for intelligence, has shown little interest in investigating the interrogators and has gone only after the MPs, and that there is a culture of silence right now among those involved, who fear that if they say anything, the investigations will turn to them.\n\nOn May 19, 2004, a court martial hearing was held for Cpl. Charles A. Graner Jr., who has been accused of being the ringleader of the group employing torture at Abu Ghraib. In an unexpected move, all three key witnesses - Lt. Col. Steven L. Jordan, Capt. Donald J. Reese, and contractor Adel L. Nakhla - refused to testify. This is an almost unheard of action. Under court martial proceedings, one cannot refuse to testify unless they have a belief that they will be exposed to criminal charges for doing so. Consequently, it is likely that the investigative proceedings will be forced to move higher up the chain of command.\n\n\n"}
{"id": "56833284", "url": "https://en.wikipedia.org/wiki?curid=56833284", "title": "Jesus and the Disinherited", "text": "Jesus and the Disinherited\n\nJesus and the Disinherited is a 1949 book by African-American minister, theologian, and civil rights leader Howard Thurman.\n\nIn the book, Thurman interprets the teachings of Jesus through the experience of the oppressed and discusses nonviolent responses to oppression. The book developed out of a series of lectures that Thurman presented at Samuel Huston College in Austin, Texas during April 1948.\"\n\nIn his biography of Martin Luther King Jr., Lerone Bennett Jr. notes that King studied Thurman's \"Jesus and the Disinherited\" during the Montgomery bus boycott.\n"}
{"id": "324559", "url": "https://en.wikipedia.org/wiki?curid=324559", "title": "Kanun (Albania)", "text": "Kanun (Albania)\n\nThe Kanun is a set of traditional Albanian laws. The Kanun was primarily oral and only in the 20th century was it published in writing. The Kanun of Lekë Dukagjini () was codified in the 15th century. Six later variations eventually evolved:\n\nThe Kanun of Skanderbeg is the closest in similarity with the Kanun of Lekë Dukagjini, and the latter is usually the most known and is also regarded as a synonym of the word \"kanun\". The Kanun of Lekë Dukagjini was developed by Lekë Dukagjini, who codified the existing customary laws. It has been used mostly in northern and central Albania and surrounding areas formerly in Yugoslavia where there is a large ethnic Albanian population; Montenegro, Kosovo and Macedonia. It was first codified in the 15th century but the use of it has been outspread much earlier in time. It was used under that form until the 20th century, and revived recently after the fall of the communist regime in the early 1990s.\n\nThe term \"kanun\" comes from the Greek \"\" (\"canon\"), meaning amongst others \"pole\" or \"rule\" and was transported from Greek to Arabic and then into early Turkish. Kanun was also known by the word of \"Doke\".\n\nThe practice of the oral laws that Lekë Dukagjini codified in the Kanun was suggested by Edith Durham as dating back to the Bronze Age. Some authors have conjectured that the Kanun may derive from ancient Illyrian tribal laws. Other authors have suggested that the Kanun has retained elements from Indo-European prehistoric eras.\n\nHowever several stratifications can be easily observed in the code, beginning with pre-Indo-European, Indo-European, Ancient Greek, Roman, general Balkan and Osmanli.\n\nAccording to Serbian authors T. O. Oraovac and S. S. Djuric, it is largely based on Dušan's Code, the constitution of the Serbian Empire (enacted 1349), which at the time held the whole of Albania. Noel Malcolm speculates that an article in Dušan's Code was an early attempt to clamp down on the self-administered customary law of the mountains, as later codified in the Kanun of Lek Dukagjin, and if so, this would be the earliest evidence that such customary laws were in effect. Despite the similarities the majority of scientists agree that the Code of Leke Dukagjini is not the same as Dusans Code and that such conclusions are \"far-fetched\". When the Turkish invaders conquered the medieval Serbian state many customary laws of social life amongst the Balkan peoples were brought back to use, this included the Albanians. \nThe town of Shkodra had for example, before Dušan's Code, its own customary laws and rules.\n\nThe Law of Lek Dukagjini (kanun) was named after a medieval prince Lekë Dukagjini of the fifteenth century who ruled in northern Albania and codified the customary laws of the highlands. The code was written down only in the 19th century by Shtjefën Gjeçovi and partially published in the \"Hylli i Drites\" periodical in 1913. The full version appeared only in 1933 after Gjeçovi's death in 1926. In 1989 a dual English-Albanian version was published. and then replicated in a 1992 version.\n\nAlthough the laws are attributed to Lekë Dukagjini, the laws evolved over time as a way to bring law and rule to these lands. The Kanun is divided into 12 sections, and Gjeçovi's version has 1,262 articles which regulate all aspects of the mountainous life: economic organisation of the household, hospitality, brotherhood, clan, boundaries, work, marriage, land, and so on. The \"Besa\" (personal honour, compare with Lat. \"fides\") and nderi (family honour, Lat. \"honor\") are of prime importance throughout the code as the cornerstone of personal and social conduct. The Kanun applies to both Christian and Muslim Albanians.\n\nSome of the most controversial rules of the Kanun (in particular book 10 section 3) specify how murder is supposed to be handled, which often in the past and sometimes still now led to blood feuds that last until all the men of the two involved families are killed. In situations of murder tribal law stipulates the principle of \"koka për kokë\" (head for a head) where the relatives of the victim are obliged to seek \"gjakmarje\" (blood vengeance). Women are only seen as producers of offspring and are referred to in a discriminatory manner and so are not considered worthy targets. The Albanian name for blood feud is \"Gjakmarrja\". In some parts of the country, the Kanun resembles the Italian vendetta. These rules have resurfaced during the 1990s in Northern Albania, since people had no faith in the powerless local government and police. There are organizations that try to mediate between feuding families and try to get them to \"pardon the blood\" (), but often the only resort is for men of age to stay in their homes, which are considered a safe refuge by the Kanuni, or flee the country. Tribal also held that thieves would need to pay fines to the relative amount that was stolen.\n\nAlbanian tribes from the Dibra region (known as the \"Tigers of Dibra\") governed themselves according to the Law of Skanderbeg, named after a fifteenth century warrior who fought the Ottomans.\n\nFormer communist leader of Albania Enver Hoxha effectively stopped the practice of Kanun with hard repression and a very strong state police. However, after the fall of communism, some communities have tried to rediscover the old traditions, but some of their parts have been lost, leading to fears of misinterpretation.\n\nNotably, the current Albanian Penal Code does not contain any provisions from the Kanun that deal with blood feuds, and no acknowledgment of this code is made in the contemporary Albanian legal system. In 2014 about 3,000 Albanian families were estimated to be involved in blood feuds and this since the fall of Communism has led to the deaths of 10,000 people.\n\nThe Kanun is based on four pillars:\n\nThe \"Kanun of Lekë Dukagjini\" is composed of 12 books and 1,262 articles. The books and their subdivisions are the following:\n\nAlbanian writer Ismail Kadare evokes the Kanun several times in his books and has it as the main theme in his novel Broken April. He also evoques the kanun in his novel (), where Kadare literally describes the Monastir massacre of 1830 as the struggle between two empires: the Albanian Kanun with its code of \"besa\" and the Ottoman Empire itself. According to Kadare in his literary critique book (), where \"loser\" refers to the great number of tragedies that were lost from Aeschylus, there are evident similarities between the \"kanun\" and the vendetta customs in all the Mediterranean countries.\n\nBarbara Nadel's \"Deep Waters\" refers to Kanun and Gjakmarrja.\n\nJoshua Marston's 2011 film The Forgiveness of Blood, a drama set in modern-day Albania, deals with the Kanun. The film relates a blood feud between two families in Northern Albania, focusing primarily on how the feud affects the children of one family.\n\nThe Kanun is referred to in season 6, episode 9 of (\"\") as the explanation for the sudden retreat of a group of Albanian assassins.\n\nThe Kanun plays a major role in the Belgian movie Dossier K.\n\nElvira Dones's \"Sworn Virgin\" refers to Kanun and women's practice of swearing celibacy in return to being accepted as men by all local villagers.\n\nBelgian TV maker Tom Waes visited Albania during one of the shows in his series Reizen Waes. He was served spit roasted goat and was offered the head of the goat. According to Kanun rules, this is how they honor a guest during dinner.\n\nThe Kanun is referred to in \"The Closer\" Season 6 | Episode 14 \"The investigation into the Albanian blood feud\" \n\n\n"}
{"id": "3267286", "url": "https://en.wikipedia.org/wiki?curid=3267286", "title": "Lahontan cutthroat trout", "text": "Lahontan cutthroat trout\n\nLahontan cutthroat trout (\"Oncorhynchus clarkii henshawi\") is the largest subspecies of cutthroat trout, and the state fish of Nevada. It is one of three subspecies of cutthroat trout that are listed as federally threatened.\n\nThe Lahontan cutthroat is native to the drainages of the Truckee River, Humboldt River, Carson River, Walker River, Quinn River and several smaller rivers in the Great Basin of North America. These were tributaries of ancient Lake Lahontan during the ice ages until the lake shrank to remnants such as Pyramid Lake and Walker Lake about 7,000 years ago, although Lake Tahoe—from which the Truckee flows to Pyramid Lake—is still a large mountain lake.\n\nLahontan cutthroats evolved into a large (up to 1 m or 39 in) and moderately long-lived predator of chub, suckers, and other fish as long as 30 or . The trout was able to remain a predator in the larger remnant lakes where prey fish continued to flourish, but upstream populations were forced to adapt to eating smaller fish and insects. Some experts consider \"O. c. henshawi\" in the upper Humboldt River and tributaries to be a separate subspecies, \"O. clarkii humboldtensis\" or the Humboldt cutthroat trout, adapted to living in small streams rather than large lakes.\n\nThe record size cutthroat trout of any subspecies was a Lahontan caught in Pyramid Lake weighing , although anecdotal and photographic evidence exists of even larger fish from this lake.\n\nThe Lahontan cutthroats of Pyramid and Walker Lakes were of considerable importance to the Paiute tribe. These trout, as well as cui-ui, a sucker found only in Pyramid Lake, were dietary mainstays and were used by other tribes in the area.\n\nWhen John C. Frémont and Kit Carson ascended the Truckee River on January 16, 1844, they called it the 'Salmon Trout River', after the huge Lahontan cutthroat trout that ran up the river from Pyramid Lake to spawn.\n\nAmerican settlement in the Great Basin nearly extirpated these remarkable fish. During the 19th and early 20th centuries, Lahontan cutthroats were caught in tremendous numbers and shipped to towns and mining camps throughout the West; estimates have ranged as high as annually between 1860 and 1920. A dam in Mason Valley blocked spawning runs from Walker Lake. By 1905, Derby Dam on the Truckee River below Reno interfered with Pyramid Lake's spawning runs. A poorly designed fish ladder washed away in 1907, then badly timed water diversions to farms in the Fallon, Nevada, area stranded spawning fish and desiccated eggs below the dam. By 1943, Pyramid Lake's population was extinct. Lake Tahoe's population was extinct by 1930 from competition and inbreeding with introduced rainbow trout (creating cutbows), predation by introduced lake trout, and diseases introduced along with these exotic species.\n\nUpstream populations have been isolated and decimated by poorly managed grazing and excessive water withdrawals for irrigation, as well as by hybridization, competition, and predation by non-native salmonids. This is important, as although Lahontan cutthroat trout can inhabit either lakes or streams, they are obligatory stream spawners.\n\nPyramid Lake, the second-largest natural lake in the western U.S. prior to construction of the Derby Dam, which diverted water from the lake, has been the focus of several water quality investigations, the most detailed starting in the mid-1980s. Under direction of the U.S. Environmental Protection Agency a comprehensive dynamic hydrology transport model, the Dynamic Stream Simulation and Assessment Model (DSSAM), was applied to analyze impacts of a variety of land use and wastewater management decisions throughout the Truckee River Basin. These analyses allowed more competent decisions to be made regarding the watersheds, as well as management of treated effluent discharged to the Truckee River.\n\nLahontan cutthroat trout currently occupy a small fraction of their historic range. The primary obstacle to their recovery is non-native salmonid predation by brook trout (\"Salvelinus fontinalis\") on fluvial cutthroat and lake trout (\"Salvelinus namaycush\") on lacustrine cutthroat. Also, hybridization of cutthroat with non-native rainbow trout (\"Oncorhynchus mykiss\") continues to threaten recovery of the pure Lahontan cutthroat. Only Independence Lake has continuously harbored its historic native Lahontan cutthroat population, although precariously low spawner numbers there have recently increased along with five years of brook trout removal.\n\nPyramid and Walker Lakes have been restocked with fish captured in Summit Lake (Nevada) and Lake Heenan, and those populations are maintained by fish hatcheries. Unfortunately, the Summit Lake strain does not live as long or grow as large as the original strain of fish. However, in the 1970s, fish believed to have been stocked almost a century ago from the Pyramid Lake strain were discovered in a small stream along the Pilot Peak area of western Utah border, and are a genetic match to the original strain. This Pilot Peak strain is now integral to the reintroduction and planting programs maintained by the U.S. Fish and Wildlife Service.\n\nPreservation of highly complementary habitats is crucial for survival of the different age classes of cutthroat trout, with clean gravels needed for spawning, slow-moving side channel habitats used by juvenile fish, and deeper pool habitats such as beaver ponds for larger adult fish.\n\nThey were classified as an endangered species between 1970 and 1975, then the classification was relaxed to threatened species in 1975, and reaffirmed as threatened in 2008.\n\nAlthough Lahontan cutthroat trout stand little chance of surviving for long in Lake Tahoe, the Nevada Department of Wildlife (NDOW) planted them instead of rainbow trout on the lake's Nevada shore in summer 2011. The goal is to enable anglers to catch Lake Tahoe's native trout for the first time since 1939. The California state record was caught in Lake Tahoe in 1911 by William Pomin, weighing in at an impressive , .\n\nBecause it tolerates water too alkaline for other trout, Lahontan cutthroats are stocked in alkaline lakes outside its native range, including Lake Lenore (alternately Lenore Lake), Grimes Lake and Omak Lake in central Washington and Mann Lake in Oregon's Alvord Desert east of Steens Mountain.\n\n"}
{"id": "732763", "url": "https://en.wikipedia.org/wiki?curid=732763", "title": "Lump of labour fallacy", "text": "Lump of labour fallacy\n\nIn economics, the lump of labour fallacy is the idea that there is a fixed amount of work—a lump of labour—to be done within an economy which can be distributed to create more or fewer jobs. It was considered a fallacy in 1891 by economist David Frederick Schloss, who held that the amount of work is not fixed.\n\nThe term originated to rebut the idea that reducing the number of hours employees are allowed to labour during the working day would lead to a reduction in unemployment. The term is also commonly used to describe the belief that increasing labour productivity, immigration, or automation causes an increase in unemployment. Whereas some argue immigrants displace a country's workers, others believe this to be a fallacy by arguing that the number of jobs in the economy is not fixed and that immigration increases the size of the economy, thus creating more jobs.\n\nThe lump of labor fallacy is also known as the lump of jobs fallacy, fallacy of labour scarcity, fixed pie fallacy or the zero-sum fallacy – due to its ties to zero-sum games. Some economics studies have noted criticism and complexities with the fallacy claim.\n\nThe lump of labour fallacy has been applied to concerns around immigration and labour. Given a fixed availability of employment, the lump of labour position argues that allowing immigration of working-age people reduces the availability of work for native-born workers (\"they are taking our jobs\").\n\nHowever, skilled immigrating workers can bring capabilities that are not available in the native workforce, for example in academic research or information technology. Additionally, immigrating workforces also create new jobs by expanding demand, thus creating more jobs, either directly by setting up businesses (therefore requiring local services or workers), or indirectly by raising consumption. As an example, a greater population that eats more groceries will increase demand from shops, which will therefore require additional shop staff.\n\nAdvocates of restricting working hours regulation may assume that there is a fixed amount of work to be done within the economy. By reducing the amount that those who are already employed are allowed to work, the remaining amount will then accrue to the unemployed. This policy was adopted by the governments of Herbert Hoover in the United States and Lionel Jospin in France, in the 35-hour working week (though in France various exemptions to the law were granted by later centre-right governments).\n\nMany economists contend that such proposals are likely to be ineffective, alleging that there are usually substantial administrative costs associated with employing more workers. These can include additional costs in recruitment, training, and management that would increase average cost per unit of output. This overall would lead to a reduced production per worker, and may even result in higher unemployment.\n\nEarly retirement has been used to induce workers to accept termination of employment before retirement age following the employer's diminished labour needs. Government support for the practice has come from the belief that this should lead to a reduction in unemployment. The unsustainability of this practice has now been recognised, and the trend in Europe is now towards postponement of the retirement age.\n\nIn an editorial in \"The Economist\" a thought experiment is proposed in which old people leave the workforce in favour of young people, on whom they become dependent for their living through state benefits. It is then argued that since growth depends on having either more workers or greater productivity, the society cannot really become more prosperous by paying an increasing number of its citizens unproductively. The article also points out that even early retirees with private pension funds become a burden on society as they also depend on equity and bond income generated by workers.\n\n\n"}
{"id": "1274313", "url": "https://en.wikipedia.org/wiki?curid=1274313", "title": "Lunar orbit rendezvous", "text": "Lunar orbit rendezvous\n\nLunar orbit rendezvous (LOR) is a key concept for efficiently landing humans on the Moon and returning them to Earth. It was utilized for the Project Apollo missions in the 1960s and 1970s. In a LOR mission, a main spacecraft and a smaller lunar lander travel to lunar orbit. The lunar lander then independently descends to the surface of the Moon, while the main spacecraft remains in lunar orbit. After completion of the mission there, the lander returns to lunar orbit to rendezvous and re-dock with the main spacecraft, then is discarded after transfer of crew and payload. Only the main spacecraft returns to Earth.\nLunar orbit rendezvous was first known to be proposed in 1919 by Soviet engineer Yuri Kondratyuk, as the most economical way of sending a human on a round-trip journey to the Moon.\nThe most famous example involved Apollo CSM and Apollo LM, where they were both sent to a Translunar flight in a single rocket stack. However, variants where the landers and main spacecraft travel separately, such as the lunar landing plan proposed for Shuttle-Derived Heavy Lift Launch Vehicle and Golden Spike, are also considered as Lunar Orbit rendezvous.\n\nThe main advantage of LOR is the spacecraft payload saving, due to the fact that the propellant necessary to return from lunar orbit back to Earth need not be carried as dead weight down to the Moon and back into lunar orbit. This has a multiplicative effect, because each pound of \"dead weight\" propellant used later has to be propelled by more propellant sooner, and also because increased propellant requires increased tankage weight. The resultant weight increase would also require more thrust for lunar landing, which means larger and heavier engines.\n\nAnother advantage is that the lunar lander can be designed for just that purpose, rather than requiring the main spacecraft to also be made suitable for a lunar landing. Finally, the second set of life support systems that the lunar lander requires can serve as a backup for the systems in the main spacecraft.\n\nLunar-orbit rendezvous was considered risky as of 1962, because space rendezvous had not been achieved, even in Earth orbit. If the LEM could not reach the CSM, two astronauts would be stranded with no way to get back to Earth or survive re-entry into the atmosphere. The fear proved to be unfounded, as rendezvous was successfully demonstrated in 1965 and 1966 on six Project Gemini missions with the aid of radar and on-board computers. It was also successfully done each of the eight times it was tried on Apollo missions.\n\nWhen the Apollo Moon landing program was started in 1961, it was assumed that the three-man Command and Service Module combination (CSM) would be used for takeoff from the lunar surface, and return to Earth. It would therefore have to be landed on the Moon by a larger rocket stage with landing gear legs, resulting in a very large spacecraft (in excess of ) to be sent to the Moon.\n\nIf this were done by direct ascent (on a single launch vehicle), the rocket required would have to be extremely large, in the Nova class. The alternative to this would have been Earth orbit rendezvous, in which two or more rockets in the Saturn class would launch parts of the complete spacecraft, which would rendezvous in Earth orbit before departing for the Moon. This would possibly include a separately launched Earth departure stage, or require on-orbit refueling of the empty departure stage.\n\nTom Dolan proposed the alternative of lunar orbit rendezvous, which had been studied and promoted by Jim Chamberlin and Owen Maynard at the Space Task Group in 1960 early Apollo feasibility studies. This mode allowed a single Saturn V to launch the CSM to the Moon with a smaller Lunar Excursion Module (LEM). When the combined spacecraft reaches lunar orbit, one of the three astronauts remains with the CSM, while the other two enter the LEM, undock and descend to the surface of the Moon. They then use the ascent stage of the LEM to rejoin the CSM in lunar orbit, then discard the LEM and use the CSM for the return to Earth. This method was brought to the attention of NASA Associate Administrator Robert Seamans by Langley Research Center engineer John C. Houbolt, who led a team to develop it.\n\nBesides requiring less payload, the ability to use a lunar lander designed just for that purpose was another advantage of the LOR approach. The LEM's design gave the astronauts a clear view of their landing site through observation windows approximately above the surface, as opposed to being on their backs in a Command Module lander, at least above the surface, able to see it only through a television screen.\n\nDeveloping the LEM as a second manned vehicle provided the further advantage of redundant critical systems (electrical power, life support, and propulsion), which enabled it to be used as a \"lifeboat\" to keep the astronauts alive and get them home safely in the event of a critical CSM system failure. This was envisioned as a contingency, but not made a part of the LEM specifications. As it turned out, this capability proved invaluable in 1970, when just such a critical failure occurred on the Apollo 13 mission when an oxygen tank failure disabled the Service Module.\n\nDr. John Houbolt would not let the advantages of LOR be ignored. As a member of Lunar Mission Steering Group, Houbolt had been studying various technical aspects of space rendezvous since 1959 and was convinced, like several others at Langley Research Center, that LOR was not only the most feasible way to make it to the Moon before the decade was out, it was the only way. He had reported his findings to NASA on various occasions but felt strongly that the internal task forces (to which he made presentations) were following arbitrarily established \"ground rules.\" According to Houbolt, these ground rules were constraining NASA's thinking about the lunar mission—and causing LOR to be ruled out before it was fairly considered.\n\nIn November 1961, Houbolt took the bold step of skipping proper channels and writing a private letter, nine pages long, directly to Robert C. Seamans, the associate administrator. \"Somewhat as a voice in the wilderness,\" Houbolt protested LOR's exclusion. \"Do we want to go to the Moon or not?\" the Langley engineer asked. \"Why is Nova, with its ponderous size simply just accepted, and why is a much less grandiose scheme involving rendezvous ostracized or put on the defensive? I fully realize that contacting you in this manner is somewhat unorthodox,\" Houbolt admitted, \"but the issues at stake are crucial enough to us all that an unusual course is warranted.\"\n\nIt took two weeks for Seamans to reply to Houbolt's extraordinary letter. The associate administrator agreed that \"it would be extremely harmful to our organization and to the country if our qualified staff were unduly limited by restrictive guidelines.\" He assured Houbolt that NASA would in the future be paying more attention to LOR than it had up to this time.\n\nIn the following months, NASA did just that, and to the surprise of many both inside and outside the agency, the dark horse candidate, LOR, quickly became the front runner. Several factors decided the issue in its favor. First, there was growing disenchantment with the idea of direct ascent due to the time and money it was going to take to develop a diameter Nova rocket, compared to the diameter Saturn V. Second, there was increasing technical apprehension over how the relatively large spacecraft demanded even by Earth-orbit rendezvous would be able to maneuver to a soft landing on the Moon. As one NASA engineer who changed his mind explained: The business of eyeballing that thing down to the Moon really didn't have a satisfactory answer. The best thing about LOR was that it allowed us to build a separate vehicle for landing.\n\nThe first major group to break camp in favor of LOR was Robert Gilruth's Space Task Group, which was still located at Langley but was soon to move to Houston. The second to come over was the Von Braun team at the Marshall Space Flight Center in Huntsville, Alabama. Then these two powerful groups of converts, along with the original true believers at Langley, persuaded key officials at NASA Headquarters, notably Administrator James Webb, who had been holding out for direct ascent, that LOR was the only way to land on the Moon by 1969. With the key players inside NASA lined up behind the concept, Webb approved LOR in July 1962. The decision was officially announced at a press conference on July 11, 1962. President Kennedy's science adviser, Jerome Wiesner, remained firmly opposed to LOR.\n\n\n"}
{"id": "44012079", "url": "https://en.wikipedia.org/wiki?curid=44012079", "title": "Meter water equivalent", "text": "Meter water equivalent\n\nIn physics, the meter water equivalent (often \"m.w.e.\" or \"mwe\") is a standard measure of cosmic ray attenuation in underground laboratories. A laboratory at a depth of 1000 m.w.e is shielded from cosmic rays equivalent to a lab 1000 m below the surface of a body of water. Because laboratories at the same depth (in meters) can have greatly varied levels of cosmic ray penetration, the m.w.e. provides a convenient and consistent way of comparing cosmic ray levels in different underground locations.\n\nCosmic ray attenuation is dependent on the density of the material of the overburden, so the m.w.e. is defined as the product of depth and density (also known as an interaction depth). Because the density of water is 1 g/cm, 1 m of water gives an interaction depth of 1 hectogram per square centimeter (hg/cm). Some publications use hg/cm instead of m.w.e., although the two units are equivalent.\n\nFor example, the Waste Isolation Pilot Plant, located 660 m ideep in a salt formation, achieves 1585 m.w.e. shielding. Soudan Mine, at 713 m depth is only 8% deeper, but because it is in iron-rich rock it achieves 2100 m.w.e. shielding, 32% more.\n\nAnother factor that must be accounted for is the \"shape\" of the overburden. While some laboratories are located beneath a flat ground surface, many are located in tunnels in mountains. Thus, the distance to the surface in directions other than straight up is less than it would be assuming a flat surface.\n\nIn addition to m.w.e., underground laboratory depth can also be measured in meters of standard rock. Standard rock is defined to have mass number A = 22, atomic number Z = 11, and density 2.65 g/cm. Because most laboratories are under earth and not underwater, the depth in standard rock is often closer to the actual underground depth of the laboratory.\n\nUnderground laboratories exist at depths ranging from just below ground level to approximately 6000 m.w.e. at SNOLAB and 6700 m.w.e. at the Jinping Underground Laboratory in China.\n"}
{"id": "21172177", "url": "https://en.wikipedia.org/wiki?curid=21172177", "title": "Military taxonomy", "text": "Military taxonomy\n\nMilitary taxonomy encompasses the domains of weapons, equipment, organizations, strategies, and tactics. The use of taxonomies in the military extends beyond its value as an indexing tool or record-keeping template.\n\nMilitary theorist Carl von Clausewitz stressed the significance of grasping the fundamentals of any situation in the \"blink of an eye\" (\"coup d'œil\"). In a military context, the astute tactician can immediately grasp a range of implications and can begin to anticipate plausible and appropriate courses of action. Clauzewitz' conceptual \"blink\" represents a tentative ontology which organizes a set of concepts within a domain.\n\nA conventional military taxonomy might be an hierarchical set of classifications for a given set of objects; and the progress of reasoning is developed from the general to the more specific. In such taxonomic schema, a conflative term is always a polyseme.\n\nIn contrast, a less conventional approach might employ an open-ended contextual military taxonomy—a taxonomy holding only with respect to a specific context; and the progress of reasoning is developed form the specific to the more general.\n\nA taxonomy of terms to describe various types of military operations is fundamentally affected by the way all elements are defined and addressed—not unlike framing.\n\nIn terms of a specific military operation, a taxonomic approach based on differentiation and categorization of the entities participating would produce results which were quite different from an approach based on functional objective of an operation (such as peacekeeping, disaster relief, or counter-terrorism). An incidental advantage which flows from give-and-take in refining taxonomic terms more accurately and efficiently becomes more than a worthwhile objective in terms of anticipated outcomes or results. In today's nontraditional operations, the discussion about fundamentals also generates greater precision in how the defense and security community understands and discusses integrated operations.\n\nMilitary taxonomy in Japan is circumscribed by Japan's pacifist post-war constitution. For example, this affects classification of the \"Hyūga\" class helicopter carriers, which are ships of the Japan Maritime Self-Defense Force (JMSDF).\n\nThis type of helicopter carrier was formally identified as a helicopter destroyer (DDH) to comply with explicit constitutional limitations written in Article 9 of the Japanese Constitution.\n\nThe two ships of this class, the JS \"Hyūga\" and the JS \"Ise\" resemble a light aircraft carrier or amphibious assault ship such as the Italian Navy's 13,850-ton \"Giuseppe Garibaldi\", the Spanish Navy's 17,000-ton \"Principe de Asturias\" or the Royal Navy's 21,000-ton \"Invincible\"-class carriers. According to a PBS documentary, JS \"Hyūga\" is the \"first Japanese aircraft carrier built since WWII;\" but this label is controversial. A taxonomic label of \"aircraft carrier\" is legally proscribed.\n\nEach ship in this class has attracted media and Diet attention because of its resemblance to an aircraft carrier. Until the 1970s, US Navy taxonomy categorized large-scale flattops as \"attack aircraft carriers\" and small flattops as \"antisubmarine aircraft carriers.\" In Japan, the constitutional prohibition against having \"attack\" aircraft carries has been construed to encompass small aircraft carriers but not helicopter carriers.\n\nA uniquely Japanese taxonomic template is applied to these ships and to their missions, which are limited to \"military operations other than war\" (MOOTW).\n\nA number of military strategies can be parsed using a taxonomy model. The comparative theoretical framework might posit a range of criteria, e.g., the character of envisaged political goals, the type of military strategy preferred, and the scope of forces engaged; and this template suggests discrete modes of force. The taxonomy-model analysis suggests a useful depiction of the spectrum of the use of military force in a political context.\n\nIn the 21st century, the ambit of a subset taxonomy of terrorism would include terms related to terrorists, terrorist groups, terrorist attacks, weapons, venues, and characteristics of terrorists and terrorist groups.\n\nTaxonomies offer useful, but incomplete means of structuring information.\n\nTaxonomies are a necessary but not sufficient condition for adequate evaluation of a given data set. While the taxonomic categorizations and sub-categorizations do enhance understanding, it may be significant that the lack of detail in describing objects or elements creates room for ambiguity.\n\n\n"}
{"id": "14611039", "url": "https://en.wikipedia.org/wiki?curid=14611039", "title": "Motivated tactician", "text": "Motivated tactician\n\nIn social psychology, a motivated tactician is someone who shifts between quick-and-dirty cognitively economical tactics and more thoughtful, thorough strategies when processing information, depending on the type and degree of motivation. Such behavior is a type of motivated reasoning. The idea has been used to explain why people use stereotyping, biases and categorization in some situations, and more analytical thinking in others.\n\nAfter much research on categorization, and other cognitive shortcuts, psychologists began to describe human beings as cognitive misers; which explains that a need to conserve mental resources causes people to use shortcuts to thinking about stimuli, instead of motivations and urges influencing the way humans think about their world. Stereotypes and heuristics were used as evidence of the economic nature of human thinking. In recent years, the work of , , and others has led to the recognition of the importance of motivational thinking. This is due to contemporary research studying the importance of motivation in cognitive processes, instead of concentrating on cognition versus motivation. Current research does not deny that people will be cognitively miserly in certain situations, but it takes into account that thorough analytic thought does occur in other situations. \n\nUsing this perspective, researchers have begun to describe human beings as \"motivated tacticians\" who are tactical about how much cognitive resources will be used depending on the individual's intent and level of motivation. Based on the complex nature of the world and the occasional need for quick thinking, it would be detrimental for a person to be methodical about everything, while other situations require more focus and attention. Considering human beings as motivated tacticians has become popular because it takes both situations into account. This concept also takes into account, and continues to study, what motivates people to use more or less mental resources when processing information about the world. Research has found that intended outcome, relevancy to the individual, culture, and affect can all influence the way a person processes information.\n\nThe most prominent explanation of motivational thinking is that the person's desired outcome motivates him to use more or less cognitive resources while processing a situation or thing. Researchers have divided preferred outcomes into two broad categories: directional and non-directional outcomes. The preferred outcome provides the motivation for the level of processing involved.\n\nIndividuals motivated by directional outcomes have the intention of accomplishing a specific goal. These goals can range from appearing smart, courageous or likeable to affirming positive thoughts and feelings about something or someone to whom they are close or find likable. If someone is motivated by non-directional outcomes, he or she wishes to make the most logical and clear decision. Whether a person is motivated by directional or non-directional outcomes depends on the situation and the person's goals. Confirmation bias is an example of thought-processing motivated by directional outcomes. The goal is to affirm previously held beliefs, so one will use less thorough thinking in order to reach that goal. A person motivated to get the best education, who researches information on colleges and visit schools is motivated by a non-directional outcome. Evidence for outcome-influenced motivation is illustrated by research on self-serving bias. According to ,\n\n\"Independent of expectancies from prior success or failure, the more personally important a success is in any given situation, the stronger is the tendency to claim responsibility for this success but to deny responsibility for failure.\"\nThough outcome-based motivation is the most prominent approach to motivated thinking, there is evidence that a person can be motivated by his or her preferred strategy of processing information. However, rather than being an alternative, this idea is actually a compliment to the outcome-based approach. Proponents of this approach feel that a person prefers a specific method of information-processing because it usually yields the results he or she wishes to receive. This relates back to the intended outcome being the primary motivation. \"Strategy of information processing\" means whether a person makes a decision using bias, categories, or analytical thinking. Regardless of whether the method is best suited for the situation or more thorough is less important to the person than its likelihood of yielding the intended result. People feel that their preferred strategy just \"feels right\". What makes the heuristic or method feel \"right\" is that the strategy accomplishes the desired goal (i.e. affirming positive beliefs of self-efficacy).\n\nThere has been limited research on motivated tactical thinking outside of Western countries. One theory experts have mentioned is that a person's culture could play a large role in a person's motivations. Nations like the United States are considered to be individualistic, while many Asian nations are considered to be collectivistic. An individualist emphasizes importance on the self and is motivated by individual reward and affirmation, while a collectivist sees the world as being more group- or culture-based. The difference in the two ways of thinking could affect motivation in information processing. For example, instead of being motivated by self-affirmation, a collectivist would be motivated by more group-affirming goals.\n\nAnother theory is that emotions can affect the way a person processes information . has stated that current mood can determine the information processing as well as thoroughness of thought. He also mentioned that achieving a desired emotion can influence the level to which information is processed.\n\n\n"}
{"id": "23691133", "url": "https://en.wikipedia.org/wiki?curid=23691133", "title": "Mr. Payback: An Interactive Movie", "text": "Mr. Payback: An Interactive Movie\n\nMr. Payback: An Interactive Movie is a 1995 American science-fiction/adventure short film written by Bob Gale and co-directed by Gale and Charles Croughwell. Designed as an interactive movie, it comprises slightly over two hours of footage, approximately 20 minutes of which is seen in each viewing. It requires the audience to vote for various directions the story will take, using a joystick attached to the armrests of their seats. The film stars an android (Billy Warlock) who, in a number of possible storylines, takes action by humiliating or attacking people who deserve it. Gale and Christopher Lloyd, who had previously worked on the \"Back to the Future\" trilogy, worked on this film as well, and the music was scored by Michael Tavera, who had composed the music for the animated \"Back to the Future\" series.\n\nThe movie billed itself as \"the world's first interactive movie,\" but it was predated by 1992's \"I'm Your Man\".\n\n\n\"Mr. Payback\" received negative reviews from critics. Roger Ebert of the \"Chicago Sun Times\" gave the film a half-star out of a possible four, and called it \"the kind of film where horrified parents might encourage the kids to shout at the screen, hoping the noise might drown out the flood of garbage.\" Ty Burr of \"Entertainment Weekly\" tagged the film with an \"F\" grade.\n\n"}
{"id": "236895", "url": "https://en.wikipedia.org/wiki?curid=236895", "title": "Negative capability", "text": "Negative capability\n\nNegative capability was a phrase first used by Romantic poet John Keats in 1817 to characterise the capacity of the greatest writers (particularly Shakespeare) to pursue a vision of artistic beauty even when it leads them into intellectual confusion and uncertainty, as opposed to a preference for philosophical certainty over artistic beauty. The term has been used by poets and philosophers to describe the ability of the individual to perceive, think, and operate beyond any presupposition of a predetermined capacity of the human being.\n\nKeats used the phrase only briefly in a private letter, and it became known only after his correspondence was collected and published. In a letter to his brothers, George and Thomas, on 22 December 1817, Keats described a conversation he had been engaged in a few days previously: \nI had not a dispute but a disquisition with Dilke, upon various subjects; several things dove-tailed in my mind, and at once it struck me what quality went to form a Man of Achievement, especially in Literature, and which Shakespeare possessed so enormously—I mean Negative Capability, that is, when a man is capable of being in uncertainties, mysteries, doubts, without any irritable reaching after fact and reason—Coleridge, for instance, would let go by a fine isolated verisimilitude caught from the Penetralium of mystery, from being incapable of remaining content with half-knowledge. This pursued through volumes would perhaps take us no further than this, that with a great poet the sense of Beauty overcomes every other consideration, or rather obliterates all consideration.\nSamuel Taylor Coleridge was, by 1817, a frequent target of criticism by the younger poets of Keats's generation, often ridiculed for his infatuation with German idealistic philosophy. Against Coleridge's obsession with philosophical truth, Keats sets up the model of Shakespeare, whose poetry articulated various points of view and never advocated a particular vision of truth.\n\nKeats's ideas here, as was usually the case in his letters, were expressed tersely with no effort to fully expound what he meant, but passages from other letters enlarge on the same theme. In a letter to J.H. Reynolds in February, 1818, he wrote: \nWe hate poetry that has a palpable design upon us—and if we do not agree, seems to put its hand in its breeches pocket. Poetry should be great & unobtrusive, a thing which enters into one's soul, and does not startle it or amaze it with itself but with its subject.\nIn another letter to Reynolds the following May, he contrived the metaphor of 'the chamber of maiden thought' and the notion of the 'burden of mystery', which together express much the same idea as that of negative capability:\nI compare human life to a large Mansion of Many Apartments, two of which I can only describe, the doors of the rest being as yet shut upon me—The first we step into we call the infant or thoughtless Chamber, in which we remain as long as we do not think—We remain there a long while, and notwithstanding the doors of the second Chamber remain wide open, showing a bright appearance, we care not to hasten to it; but are at length imperceptibly impelled by the awakening of the thinking principle—within us—we no sooner get into the second Chamber, which I shall call the Chamber of Maiden-Thought, than we become intoxicated with the light and the atmosphere, we see nothing but pleasant wonders, and think of delaying there for ever in delight: However among the effects this breathing is father of is that tremendous one of sharpening one's vision into the heart and nature of Man—of convincing ones nerves that the World is full of Misery and Heartbreak, Pain, Sickness, and oppression—whereby This Chamber of Maiden Thought becomes gradually darken'd and at the same time on all sides of it many doors are set open—but all dark—all leading to dark passages—We see not the balance of good and evil. We are in a Mist—We are now in that state—We feel the 'burden of the Mystery,' To this point was Wordsworth come, as far as I can conceive when he wrote 'Tintern Abbey' and it seems to me that his Genius is explorative of those dark Passages. Now if we live, and go on thinking, we too shall explore them. he is a Genius and superior to us, in so far as he can, more than we, make discoveries, and shed a light in them—Here I must think Wordsworth is deeper than Milton[.]\nKeats understood Coleridge as searching for a single, higher-order truth or solution to the mysteries of the natural world. He went on to find the same fault in Dilke and Wordsworth. All these poets, he claimed, lacked objectivity and universality in their view of the human condition and the natural world. In each case, Keats found a mind which was a narrow private path, not a \"thoroughfare for all thoughts\". Lacking for Keats were the central and indispensable qualities requisite for flexibility and openness to the world, or what he referred to as negative capability.\n\nThis concept of Negative Capability is precisely a rejection of set philosophies and preconceived systems of nature. He demanded that the poet be receptive rather than searching for fact or reason, and to not seek absolute knowledge of every truth, mystery, or doubt.\n\nIt is not known why Keats settled on the phrase 'negative capability', but some scholars have hypothesized that Keats was influenced in his studies of medicine and chemistry, and that it refers to the negative pole of an electric current which is passive and receptive. In the same way that the negative pole receives the current from the positive pole, the poet receives impulses from a world that is full of mystery and doubt, which cannot be explained but which the poet can translate into art.\n\nRoberto Unger appropriated Keats' term in order to explain resistance to rigid social divisions and hierarchies. For Unger, \"negative capability\" is the \"denial of whatever in our contexts delivers us over to a fixed scheme of division and hierarchy and to an enforced choice between routine and rebellion.\" It is thus through \"negative capability\" that we can further empower ourselves against social and institutional constraints, and loosen the bonds that entrap us in a certain social station.\n\nAn example of negative capability can be seen at work in industrial innovation. In order to create an innovator's advantage and develop new forms of economic enterprise, the modern industrialist could not just become more efficient with surplus extraction based on pre-existing work roles, but rather needed to invent new styles of flexible labor, expertise, and capital management. The industrialist needed to bring people together in new and innovative ways and redefine work roles and workplace organization. The modern factory had to at once stabilize its productive environment by inventing new restraints upon labor, such as length of the work day and division of tasks, but at the same time could not be too severe or risk being at a disadvantage to competitors, e.g. not being able to shift production tasks or capacity. Those industrialists and managers who were able to break old forms of organizational arrangements exercised negative capability.\n\nThis thesis of \"negative capability\" is a key component in Unger's theory of false necessity and formative context. The theory of false necessity claims that our social worlds are the artifact of our own human endeavors. There is no pre-set institutional arrangement that our societies adhere to, and there is no necessary historical mold of development that they will follow. Rather we are free to choose and develop the forms and the paths that our societies will take through a process of conflicts and resolutions. However, there are groups of institutional arrangements that work together to bring out certain institutional forms, liberal democracy, for example. These forms are the basis of a social structure, and which Unger calls formative contexts. In order to explain how we move from one formative context to another without the conventional social theory constraints of historical necessity (e.g. feudalism to capitalism), and to do so while remaining true to the key insight of individual human empowerment and anti-necessitarian social thought, Unger recognized that there are an infinite number of ways of resisting social and institutional constraints, which can lead to an infinite number of outcomes. This variety of forms of resistance and empowerment (i.e. negative capability) make change possible.\n\nThis thesis of \"negative capability\" addresses the problem of agency in relation to structure. It recognizes the constraints of structure and its molding influence upon the individual, but at the same time finds the individual able to resist, deny, and transcend their context. Unlike other theories of structure and agency, \"negative capability\" does not reduce the individual to a simple actor possessing only the dual capacity of compliance or rebellion, but rather sees him as able to partake in a variety of activities of self empowerment.\n\nThe twentieth-century British psychoanalyst Wilfred Bion elaborated on Keats's term to illustrate an attitude of openness of mind which he considered of central importance, not only in the psychoanalytic session, but in life itself. For Bion, negative capability was the ability to tolerate the pain and confusion of not knowing, rather than imposing ready-made or omnipotent certainties upon an ambiguous situation or emotional challenge. His idea has been taken up more widely in the British Independent School, as well as elsewhere in psychoanalysis and psychotherapy.\n\nThe notion of negative capability has been associated with the Zen philosophy. Keats' man of negative capability had qualities that enabled him to \"lose his self-identity, his 'imaginative identification' with and submission to things, and his power to achieve a unity with life\". The Zen concept of satori is the outcome of passivity and receptivity, culminating in \"sudden insight into the character of the real\". Satori is reached without deliberate striving. The antecedent stages to satori: quest, search, ripening and explosion. The \"quest\" stage is accompanied by a strong feeling of uneasiness, resembling the capacity to practice negative capability while the mind is in a state of \"uncertainties, mysteries and doubts\". In the explosive stage (akin to Keats' 'chief intensity'), a man of negative capability effects a \"fellowship with essence\".\n\nStanley Fish has expressed strong reservations about the attempt to apply the concept of negative capability to social contexts. He has written in critique of Unger's early work as being unable to chart a route for the idea to pass into reality, which leaves history closed and the individual holding onto the concept while kicking against air. Fish finds the capability Unger invokes in his early works unimaginable and unmanufacturable that can only be expressed outright in blatant speech, or obliquely in concept. More generally, Fish finds the idea of radical culture as an oppositional ideal in which context is continuously refined or rejected impracticable at best, and impossible at worst. Unger has addressed these criticisms by developing a full theory of historical process in which negative capability is employed.\n\n"}
{"id": "15850906", "url": "https://en.wikipedia.org/wiki?curid=15850906", "title": "Nosism", "text": "Nosism\n\nNosism, from the Latin \"nos\", \"we\", is the practice of using the pronoun \"we\" to refer to oneself when expressing a personal opinion.\n\nDepending on the person using the nosism different uses can be distinguished:\n\nThe royal \"we\" (\"pluralis majestatis\") refers to a single person holding a high office, such as a monarch, bishop, or pope.\n\nThe editorial \"we\" is a similar phenomenon, in which an editorial columnist in a newspaper or a similar commentator in another medium refers to themselves as \"we\" when giving their opinion. Here, the writer casts themselves in the role of a spokesperson: either for the media institution that employs them, or more generally on behalf of the party or body of citizens who agree with the commentary.\n\nSimilar to the editorial \"we\", \"pluralis modestiae\" is the practice common in mathematical and scientific literature of referring to a generic third person by \"we\" (instead of the more common \"one\" or the informal \"you\"):\n\n\"We\" in this sense often refers to \"the reader and the author,\" since the author often assumes that the reader knows and agrees with certain principles or previous theorems for the sake of brevity (or, if not, the reader is prompted to look them up).\n\nThis practice is discouraged in the social sciences because it fails to distinguish between sole authorship and co-authorship.\n\n"}
{"id": "3214515", "url": "https://en.wikipedia.org/wiki?curid=3214515", "title": "Padded V-hull", "text": "Padded V-hull\n\nA padded v-hull is a type of high performance watercraft.\n\nThey can come in many different configurations from that of a pure race boat to that of a recreational craft. A padded v-hull is very similar in basic shape to the popular v-hull which simply forms a vee when looking at the back of the watercraft. The difference in design with the padded v-hull is that where the point of the vee would be on the bottom of a plain v-hull there is a flat area ranging from six to ten inches wide. When looking at a padded v-hull from underneath, the front of the hull shows a vee which slowly starts to taper and blend back to the flat pad area. This back portion of the hull is the pad and it will protrude from the vee surface one-half to one-full inch. The pad more efficiently provides hydrodynamic lift due to very low deadrise planing surface, compared to the vee hull lifting surfaces. This highly efficient lift helps to unwet the less efficient vee sections hull which reduces drag tremendously. It uses hydrodynamic pressure to ride higher in the water. As the boats speed increases, water pressure builds on the flat surface of the pad causing the boat to ride higher in the water and ultimately the boat will be riding on just the pad area. At low speeds these hulls ride and handle just the same as a regular v-hull of the same size and weight. Once speeds increase the padded hull will out accelerate and have a higher top speed than a plain v-hull since the padded hull has less drag once speeds increase.\n\nDriving a padded v-hull takes practice and patience. At speed the hull is riding on a small area roughly the size of a paper towel. It is a balancing act to keep the hull on the pad and it requires small steering inputs from the driver to keep the hull flying level. Padded v-hulls will want to chine-walk if no steering corrections are used. Chine-walk is when the boat rocks side to side on the rear portion of the hull. As speeds increase, chine walk becomes more of a factor and can become violent and dangerous if the driver does not know how to compensate for it.\n\n"}
{"id": "312252", "url": "https://en.wikipedia.org/wiki?curid=312252", "title": "Partition function (statistical mechanics)", "text": "Partition function (statistical mechanics)\n\nIn physics, a partition function describes the statistical properties of a system in thermodynamic equilibrium. Partition functions are functions of the thermodynamic state variables, such as the temperature and volume. Most of the aggregate thermodynamic variables of the system, such as the total energy, free energy, entropy, and pressure, can be expressed in terms of the partition function or its derivatives. The partition function is dimensionless, it is a pure number.\n\nEach partition function is constructed to represent a particular statistical ensemble (which, in turn, corresponds to a particular free energy). The most common statistical ensembles have named partition functions. The canonical partition function applies to a canonical ensemble, in which the system is allowed to exchange heat with the environment at fixed temperature, volume, and number of particles. The grand canonical partition function applies to a grand canonical ensemble, in which the system can exchange both heat and particles with the environment, at fixed temperature, volume, and chemical potential. Other types of partition functions can be defined for different circumstances; see partition function (mathematics) for generalizations. The partition function has many physical meanings, as discussed in Meaning and significance.\n\nInitially, let us assume that a thermodynamically large system is in thermal contact with the environment, with a temperature \"T\", and both the volume of the system and the number of constituent particles are fixed. A collection of this kind of systems comprises an ensemble called a canonical ensemble. The appropriate mathematical expression for the canonical partition function depends on the degrees of freedom of the system, whether the context is classical mechanics or quantum mechanics, and whether the spectrum of states is discrete or continuous.\n\n\nFor a canonical ensemble that is classical and discrete, the canonical partition function is defined as\nwhere\n\nThe exponential factor exp(−\"βE\") is known as the Boltzmann factor.\n\n\nIn classical mechanics, the position and momentum variables of a particle can vary continuously, so the set of microstates is actually uncountable. In \"classical\" statistical mechanics, it is rather inaccurate to express the partition function as a sum of discrete terms. In this case we must describe the partition function using an integral rather than a sum. For a canonical ensemble that is classical and continuous, the canonical partition function is defined as\nwhere\n\nTo make it into a dimensionless quantity, we must divide it by \"h\", which is some quantity with units of action (usually taken to be Planck's constant).\n\n\nFor a gas of \"N\" identical classical particles, the partition function is\n\nwhere\n\nThe reason for the factorial factor \"N\"! is discussed below. The extra constant factor introduced in the denominator was introduced because, unlike the discrete form, the continuous form shown above is not dimensionless. As stated in the previous section, to make it into a dimensionless quantity, we must divide it by \"h\" (where \"h\" is usually taken to be Planck's constant).\n\n\nFor a canonical ensemble that is quantum mechanical and discrete, the canonical partition function is defined as the trace of the Boltzmann factor:\nwhere\nThe dimension of formula_19 is the number of energy eigenstates of the system.\n\n\nFor a canonical ensemble that is quantum mechanical and continuous, the canonical partition function is defined as\nwhere\n\nIn systems with multiple quantum states \"s\" sharing the same energy \"E\", it is said that the energy levels of the system are degenerate. In the case of degenerate energy levels, we can write the partition function in terms of the contribution from energy levels (indexed by \"j\") as follows:\n\nwhere \"g\" is the degeneracy factor, or number of quantum states \"s\" that have the same energy level defined by \"E\" = \"E\".\n\nThe above treatment applies to \"quantum\" statistical mechanics, where a physical system inside a finite-sized box will typically have a discrete set of energy eigenstates, which we can use as the states \"s\" above. In quantum mechanics, the partition function can be more formally written as a trace over the state space (which is independent of the choice of basis):\n\nwhere \"Ĥ\" is the quantum Hamiltonian operator. The exponential of an operator can be defined using the exponential power series.\n\nThe classical form of \"Z\" is recovered when the trace is expressed in terms of coherent states\nand when quantum-mechanical uncertainties in the position and momentum of a particle \nare regarded as negligible. Formally, using bra–ket notation, one inserts under the trace for each degree of freedom the identity:\nwhere |\"x\", \"p\" is a normalised Gaussian wavepacket centered at\nposition \"x\" and momentum \"p\". Thus\nA coherent state is an approximate eigenstate of both operators formula_31 and formula_32, hence also of the Hamiltonian \"Ĥ\", with errors of the size of the uncertainties. If Δ\"x\" and Δ\"p\" can be regarded as zero, the action of \"Ĥ\" reduces to multiplication by the classical Hamiltonian, and \"Z\" reduces to the classical configuration integral.\n\nFor simplicity, we will use the discrete form of the partition function in this section. Our results will apply equally well to the continuous form.\n\nConsider a system \"S\" embedded into a heat bath \"B\". Let the total energy of both systems be \"E\". Let \"p\" denote the probability that the microstate that system \"S\" is in has energy \"E\". According to the fundamental postulate of statistical mechanics (which states that all attainable microstates of a system are equally probable), the probability \"p\" will be proportional to the number of microstates of the total closed system (\"S\", \"B\") in which \"S\" is in microstate \"i\" with energy \"E\". Equivalently, \"p\" will be proportional to the number of microstates of the heat bath \"B\" with energy \"E\" − \"E\":\n\nAssuming that the heat bath's internal energy is much larger than the energy of \"S\" (\"E\" ≫ \"E\"), we can Taylor-expand formula_34 to first order in \"E\" and use the thermodynamic relation formula_35, where here formula_36, formula_37 are the entropy and temperature of the bath respectively:\n\nThus\n\nSince the total probability to find the system in \"some\" microstate (the sum of all \"p\") must be equal to 1, we can define the partition function as the normalization constant:\n\nIn order to demonstrate the usefulness of the partition function, let us calculate the thermodynamic value of the total energy. This is simply the expected value, or ensemble average for the energy, which is the sum of the microstate energies weighted by their probabilities:\n\nor, equivalently,\n\nIncidentally, one should note that if the microstate energies depend on a parameter λ in the manner\n\nthen the expected value of \"A\" is\n\nThis provides us with a method for calculating the expected values of many microscopic quantities. We add the quantity artificially to the microstate energies (or, in the language of quantum mechanics, to the Hamiltonian), calculate the new partition function and expected value, and then set \"λ\" to zero in the final expression. This is analogous to the source field method used in the path integral formulation of quantum field theory. \n\nIn this section, we will state the relationships between the partition function and the various thermodynamic parameters of the system. These results can be derived using the method of the previous section and the various thermodynamic relations.\n\nAs we have already seen, the thermodynamic energy is\n\nThe variance in the energy (or \"energy fluctuation\") is\n\nThe heat capacity is\n\nThe entropy is\n\nwhere \"A\" is the Helmholtz free energy defined as \"A\" = \"U\" − \"TS\", where \"U\" = \"E\" is the total energy and \"S\" is the entropy, so that\n\nSuppose a system is subdivided into \"N\" sub-systems with negligible interaction energy, that is, we can assume the particles are essentially non-interacting. If the partition functions of the sub-systems are \"ζ\", \"ζ\", ..., \"ζ\", then the partition function of the entire system is the \"product\" of the individual partition functions:\n\nIf the sub-systems have the same physical properties, then their partition functions are equal, ζ = ζ = ... = ζ, in which case\n\nHowever, there is a well-known exception to this rule. If the sub-systems are actually identical particles, in the quantum mechanical sense that they are impossible to distinguish even in principle, the total partition function must be divided by a \"N\"! (\"N\" factorial):\n\nThis is to ensure that we do not \"over-count\" the number of microstates. While this may seem like a strange requirement, it is actually necessary to preserve the existence of a thermodynamic limit for such systems. This is known as the Gibbs paradox.\n\nIt may not be obvious why the partition function, as we have defined it above, is an important quantity. First, let us consider what goes into it. The partition function is a function of the temperature \"T\" and the microstate energies \"E\", \"E\", \"E\", etc. The microstate energies are determined by other thermodynamic variables, such as the number of particles and the volume, as well as microscopic quantities like the mass of the constituent particles. This dependence on microscopic variables is the central point of statistical mechanics. With a model of the microscopic constituents of a system, one can calculate the microstate energies, and thus the partition function, which will then allow us to calculate all the other thermodynamic properties of the system.\n\nThe partition function can be related to thermodynamic properties because it has a very important statistical meaning. The probability \"P\" that the system occupies microstate \"s\" is\n\nThus, as shown above, the partition function plays the role of a normalizing constant (note that it does \"not\" depend on \"s\"), ensuring that the probabilities sum up to one:\n\nThis is the reason for calling \"Z\" the \"partition function\": it encodes how the probabilities are partitioned among the different microstates, based on their individual energies. The letter \"Z\" stands for the German word \"Zustandssumme\", \"sum over states\". The usefulness of the partition function stems from the fact that it can be used to relate macroscopic thermodynamic quantities to the microscopic details of a system through the derivatives of its partition function. Finding the partition function is also equivalent to performing a laplace transform of the density of states function from the energy domain to the β domain, and the inverse laplace transform of the partition function reclaims the state density function of energies.\n\nWe can define a grand canonical partition function for a grand canonical ensemble, which describes the statistics of a constant-volume system that can exchange both heat and particles with a reservoir.\nThe reservoir has a constant temperature \"T\", and a chemical potential \"μ\".\n\nThe grand canonical partition function, denoted by formula_55, is the following sum over microstates\nHere, each microstate is labelled by formula_57, and has total particle number formula_58 and total energy formula_59.\nThis partition function is closely related to the Grand potential, formula_60, by the relation\nThis can be contrasted to the canonical partition function above, which is related instead to the Helmholtz free energy.\n\nIt is important to note that the number of microstates in the grand canonical ensemble may be much larger than in the canonical ensemble,\nsince here we consider not only variations in energy but also in particle number.\nAgain, the utility of the grand canonical partition function is that it is related to the probability that the system is in state formula_57:\n\nAn important application of the grand canonical ensemble is in deriving exactly the statistics of a non-interacting many-body quantum gas (Fermi–Dirac statistics for fermions, Bose–Einstein statistics for bosons), however it is much more generally applicable than that.\nThe grand canonical ensemble may also be used to describe classical systems, or even interacting quantum gases.\n\nThe grand partition function is sometimes written (equivalently) in terms of alternate variables as\nwhere formula_65 is known as the absolute activity (or fugacity) and formula_66 is the canonical partition function.\n\n\n"}
{"id": "14500263", "url": "https://en.wikipedia.org/wiki?curid=14500263", "title": "Physiographic regions of the world", "text": "Physiographic regions of the world\n\nThe physiographic regions of the world are a means of defining the Earth's landforms into distinct regions, based upon the classic three-tiered approach by Nevin Fenneman in 1916, that further defines landforms into: 1. physiographic divisions; 2. physiographic provinces; and 3. physiographic sections. This foundational model, which Fenneman used to classify the United States, was the basis for similar classifications of other continents later, and is still considered basically valid.\n\nDuring the early 1900s, the study of regional-scale geomorphology was termed \"physiography\". Unfortunately, physiography later was considered to be a contraction of \"physical\" and \"geography\", and therefore synonymous with physical geography, and the concept became embroiled in controversy surrounding the appropriate concerns of that discipline. Some geomorphologists held to a geological basis for physiography and emphasized a concept of physiographic regions while a conflicting trend among geographers was to equate physiography with \"pure morphology,\" separated from its geological heritage. In the period following World War II, the emergence of process, climatic, and quantitative studies led to a preference by many Earth scientists for the term \"geomorphology\" in order to suggest an analytical approach to landscapes rather than a descriptive one. In current usage, physiography still lends itself to confusion as to which meaning is meant, the more specialized \"geomorphological\" definition or the more encompassing \"physical geography\" definition. For the remainder of this article, emphasis will remain on the more \"geomorphological\" usage, which is based upon geological landforms, not on climate, vegetation, or other non-geological criteria.\n\nFor the purposes of physiographic mapping, landforms are classified according to both their geologic structures and histories. Distinctions based on geologic age also correspond to physiographic distinctions where the forms are so recent as to be in their first erosion cycle, as is generally the case with sheets of glacial drift. Generally, forms which result from similar histories are characterized by certain similar features, and differences in history result in corresponding differences of form, usually resulting in distinctive features which are obvious to the casual observer, but this is not always the case. A maturely dissected plateau may grade without a break from rugged mountains on the one hand to mildly rolling farm lands on the other. So also, forms which are not classified together may be superficially similar; for example, a young coastal plain and a peneplain. In a large number of cases, the boundary lines are also geologic lines, due to differences in the nature or structure of the underlying rocks.\n\nThe history of \"physiography\" itself is at best a complicated effort. Much of the complications arise from how the term has evolved over time, both as its own 'science' and as a synonym for other branches of science. In 1848, Mary Somerville published her book \"Physical Geography\" which gave detailed descriptions of the topography of each continent, along with the distribution of plant, animals and humans. This work gave impetus to further works along the field. In Germany, Oscar Peschel in 1870, proposed that geographers should study the morphology of the Earth's surface, having an interest in the study of landforms for the development of human beings. As the chair of geography (and a geologist by training) in Bonn, Germany, Ferdinand von Richthofen made the study of landforms the main research field for himself and his students. Elsewhere, Thomas Henry Huxley's \"Physiography\" was published in 1877 in Britain. Shortly after, the field of \"physical geography\" itself was renamed as \"physiography\". Afterwards, physiography became a very popular school subject in Britain, accounting for roughly 10% of all examination papers in both English and Welsh schools, and physiography was now regarded as an integral, if not the most important aspect of geography.\n\nIn conjunction with these 'advances' in physiography, physically and visually mapping these descriptive areas was underway as well. The early photographers and balloonists, Nadar and Triboulet, experimented with aerial photography and the view it provided of the landscape. In 1899, Albert Heim published his photographs and observations made during a balloon flight over the Alps; he is probably the first person to use aerial photography in geomorphological or physiographical research. The block diagrams of Fenneman, Raisz, Lobeck and many others were based in part upon both aerial photography and topographic maps, giving an oblique \"birds-eye\" view.\n\nBy 1901, there were clear differences in the definition of the term physiography. \"In England, physiography is regarded as the introduction to physical science in general. It is made to include the elements of physics, chemistry, astronomy, physical geography, and geology, and sometimes even certain phases of botany and zoology. In America, the term has a somewhat different meaning. It is sometimes used as a synonym for physical geography, and is sometimes defined as the science which describes and explains the physical features of the earth's surface\".\n\nBy 1911, the definition of physiography in \"Encyclopædia Britannica\" had evolved to be \"In popular usage the words 'physical geography' have come to mean geography viewed from a particular standpoint rather than any special department of the subject. The popular meaning is better conveyed by the word physiography, a term which appears to have been introduced by Linnaeus, and was reinvented as a substitute for the cosmography of the Middle Ages by Professor Huxley. Although the term has since been limited by some writers to one particular part of the subject, it seems best to maintain the original and literal meaning. In the stricter sense, physical geography is that part of geography which involves the processes of contemporary change in the crust and the circulation of the fluid envelopes. It thus draws upon physics for the explanation of the phenomena with the space-relations of which it is specially concerned. Physical geography naturally falls into three divisions, dealing respectively with the surface of the lithosphere – geomorphology; the hydrosphere – oceanography; and the atmosphere – climatology. All these rest upon the facts of mathematical geography, and the three are so closely inter-related that they cannot be rigidly separated in any discussion\".\n\nThe 1919 edition of \"The Encyclopedia Americana: A Library of Universal Knowledge\" further adjusted the definition to be \"Physiography (geomorphology), now generally recognized as a science distinct from geology, deals with the origins and development of land forms, traces out the topographic expression of structure, and embodies a logical history of oceanic basins, and continental elevations; of mountains, plateaus and plains; of hills and valleys. Physical geography is used loosely as a synonym, but the term is more properly applied to the borderland between geography and physiography; dealing, as it does, largely with the human element as influenced by its physiographic surroundings\".\n\nEven in the 21st century, some confusion remains as to exactly what \"physiography\" is. One source states \"Geomorphology includes quaternary geology, physiography and most of physical geography\", treating physiography as a separate field, but subservient to geomorphology. Another source states \"Geomorphology (or physiography) refers to the study of the surface features of the earth. It involves looking at the distribution of land, water, soil and rock material that forms the land surface. Land is closely linked to the geomorphology of a particular landscape\", regarding physiography as synonymous with geomorphology. Yet another source states \"Physiography may be viewed from two distinct angles, the one dynamic, the other passive\". The same source continues by stating \"In a large fashion geodynamics is intimately associated with certain branches of geology, as sedimentation, while geomorphology connects physiography with geography. The dynamic interlude representing the active phase of physiography weaves the basic threads of geologic history.\" The U.S. Geological Survey defines physiography as a study of \"Features and attributes of earth's land surface\", while geomorphology is defined separately as \"Branch of geology dealing with surface land features and the processes that create and change them\".\n\nPartly due to this confusion over what \"physiography\" actually means, some scientists have refrained from using the term physiography (and instead use the similar term geomorphology) because the definitions vary from the American Geological Institute's \"the study and classification of the surface features of Earth on the basis of similarities in geologic structure and the history of geologic changes\" to descriptions that also include vegetation and/or land use.\n\n"}
{"id": "12303440", "url": "https://en.wikipedia.org/wiki?curid=12303440", "title": "Reduction in rank", "text": "Reduction in rank\n\nReduction in rank may refer to three separate concepts:\n\nReduction in rank (Latin \"gradus deiectio\" meaning position degradation) was a Roman military punishment.\n\nIn the United States, courts-martial may adjudge reduction to any enlisted member to the lowest or any intermediate pay grade. However, a summary court-martial may not sentence a person to reduction by more than one grade.\n\nArticle 15 of the Uniform Code of Military Justice (UCMJ) authorizes commanding officers to \"in addition to or in lieu of admonition or reprimand\" impose \"reduction to the next inferior pay grade, if the grade from which demoted is within the promotion authority of the officer imposing the reduction or any officer subordinate to the one who imposes the reduction.\" Additionally, an officer of the grade of major, lieutenant commander, or above is authorized to impose \"reduction to the lowest or any intermediate pay grade, if the grade from which demoted is within the promotion authority of the officer imposing the reduction or any officer subordinate to the one who imposes the reduction, but an enlisted member in a pay grade above E-4 may not be reduced more than two pay grades.\"\n\nAdditionally, article 58a of the UCMJ provides that, unless otherwise provided in regulation, an enlisted member above the pay grade of E-1 sentenced by a court-martial to confinement, a dishonorable or bad-conduct discharge, or hard labor without confinement, shall be automatically reduced to the pay grade of E-1.\n\nIn other countries, there is such a punishment, which is sometimes much more severe than that in the US. It usually is assigned for serious crimes in peacetime and wartime.\n\nIn the Russian Empire and in the USSR, most often it was a demotion in rank to private. \nIn the Russian Empire to this punishment was added also other penalties such as beatings with whips, which were all the staff. Personnel lined up in formation, then each dealt one blow sentenced. Most often, this has led to the death of the convict from his injuries.\n\nLieutenant-General Marquis Philip Osipovich Paulucci, being quartermaster General of the Caucasus army, on 3 November 1810, wrote in his diary: \"the Tiflis infantry regiment non-commissioned officer Ermolaev, the former in the recruit depot when you split the party on the shelves, took the recruit 5 rubles brazenly. For any impermissible and intolerable service act, reducted thereof in the ordinary non-commissioned officer, require him to drive the rods through 500 people one time, and taken money from him to take away and give to a recruit. Flogging this very same to do tomorrow in 8 hours. This case put the body on view at the end of the Lord to the heads of regiments are strictly watched so that the lower ranks no one had injustices...\"\n\nDemoted in rank, with the exception only of occasions a great military feat, can get officer rank except by Highest permission about not reading an incurred penalty obstacle to the awards; to enter with the idea of this is permitted no sooner than after three years after a demotion (article 43). On the basis of article 60, 556, 634, and 727 kN. SV VII. military. post. demoted cannot be produced in the non-commissioned officers, not assigned to any trip, you don't leave and transferred to the reserve only with a special permission.\n\nIn the USSR, demotion in rank to private begin to see use as a punishment immediately after the creation of the red army. As a rule, it punished those who made unforgivable mistakes during combat, especially those who led to serious losses or tactical defeat. In addition, it also punished those who committed serious crimes while serving. In the second case, a demotion in rank was usually not the only punishment administered, and often accompanied an imprisonment or execution.\nDuring the second world war, those demoted in rank were not imprisoned away from the front lines but instead made to serve in the penal divisions.\nAfter the second world war, the punishment no longer meant execution or service in a penal unit, but did mean dismissal from service and forfeiture of all military awards. Most often it was imposed for serious crimes which entail criminal liability. In modern Russia this post-WW2 version of the punishment is still used.\n\nOn December 22, 2015, Konstantin Grishin (better known as Semen Semenchenko) was demoted in rank while serving as the commander of the voluntary Donbass battalion. While all of the other punishments he received. The reason for the demotion in rank was the fact that he does not have the appropriate training and education to carry the title of Lieutenant.\n\nFor example, during the Third Reich, the SS officer Helmut Knochen was demoted in rank because, during the coup attempt of 20 July 1944, he did not adequately resist the conspirators, and got himself arrested.\n\n"}
{"id": "11224741", "url": "https://en.wikipedia.org/wiki?curid=11224741", "title": "Right to equal protection", "text": "Right to equal protection\n\nThe Right to Equal Protection is a concept that was introduced into the Constitution of the United States during the American Civil War. It is intended to protect the rights provided by the United States Constitution for all individuals regardless of race, ethnicity, gender, etc. It is fundamentally based on the Fourteenth Amendment of the Constitution, intended to secure rights for former slaves. The Constitution is claimed to uphold racial and gender equality, but until the 1950s, enforcing slavery, segregation, and gender inequality were major aspects of the history of the American federal government.\n\nIn 1896, the United States Supreme Court determined that the \"separate but equal\" doctrine was constitutional in the case \"Plessy v. Ferguson.\" Although the Fourteenth Amendment abolished slavery, and intended to end racial segregation, the Southern States initiated Jim Crow Laws, which segregated people of color in public schools, public transportation, restaurants, etc. The ruling in Plessy v. Ferguson meant that as long as facilities for both colored and white individuals were equal, it was constitutional. In 1954, the ruling of Plessy v. Ferguson was overturned in the Supreme Court case \"Brown v. Board of Education. \"The Supreme Court determined that the establishment of separate schools for whites and blacks inherently unequal, and as a result unconstitutional. This ruling put an end to segregation on the basis of equal rights of protection.\n\nThese court cases however had no bearing on women's suffrage or equality. The Nineteenth Amendment of the United States Constitution legislates that neither the individual states of the United States nor its federal government may deny a citizen the right to vote because of the citizen's sex.\n\nIn recent years equal protection of citizens within the workplace has become a major issue. As a result of various amendments, citizens can not be discriminated against in work places based on terms of gender, ethnicity, race, height, or other similar differences. For example, a potential employee who is unusually short and weak can not be denied a job in a police force based upon his size.\n\nAn Equal Rights Amendment (ERA), which would grant equal rights to women, has been a proposed amendment to the United States Constitution since 1972. Having failed to meet the deadline requirements for passage incorporated into the original proposed amendment, efforts to reintroduce and ratify similar amendments have come before Congress every year since 1982.\n\nThe very existence of equal rights, however, is controversial because it sets boundaries and makes clear the differences among citizens. In order to declare something as equal, there must exist a comparison to something that is unequal. In doing this, people are forced to compare equality in terms of education, wage, and many other controversial considerations.\n"}
{"id": "29174", "url": "https://en.wikipedia.org/wiki?curid=29174", "title": "Social class", "text": "Social class\n\nA social class is a set of subjectively defined concepts in the social sciences and political theory centered on models of social stratification in which people are grouped into a set of hierarchical social categories, the most common being the upper, middle and lower classes.\n\n\"Class\" is a subject of analysis for sociologists, political scientists, anthropologists and social historians. However, there is not a consensus on a definition of \"class\" and the term has a wide range of sometimes conflicting meanings. In common parlance, the term \"social class\" is usually synonymous with \"socio-economic class\", defined as \"people having the same social, economic, cultural, political or educational status\", e.g., \"the working class\"; \"an emerging professional class\". However, academics distinguish social class and socioeconomic status, with the former referring to one's relatively stable sociocultural background and the latter referring to one's current social and economic situation and consequently being more changeable over time.\n\nThe precise measurements of what determines social class in society has varied over time. Karl Marx thought \"class\" was defined by one's relationship to the means of production (their relations of production). His simple understanding of classes in modern capitalist society are the proletariat, those who work but do not own the means of production; and the bourgeoisie, those who invest and live off of the surplus generated by the proletariat's operation of the means of production. This contrasts with the view of the sociologist Max Weber, who argued \"class\" is determined by economic position, in contrast to \"social status\" or \"Stand\" which is determined by social prestige rather than simply just relations of production. The term \"class\" is etymologically derived from the Latin \"classis\", which was used by census takers to categorize citizens by wealth in order to determine military service obligations.\n\nIn the late 18th century, the term \"class\" began to replace classifications such as estates, rank and orders as the primary means of organizing society into hierarchical divisions. This corresponded to a general decrease in significance ascribed to hereditary characteristics and increase in the significance of wealth and income as indicators of position in the social hierarchy.\n\nHistorically, social class and behavior were sometimes laid down in law. For example, permitted mode of dress in sometimes and places was strictly regulated, with sumptuous dressing only for the high ranks of society and aristocracy, whereas sumptuary laws stipulated the dress and jewelry appropriate for a person's social rank and station.\n\nDefinitions of social classes reflect a number of sociological perspectives, informed by anthropology, economics, psychology and sociology. The major perspectives historically have been Marxism and structural functionalism. The common stratum model of class divides society into a simple hierarchy of working class, middle class and upper class. Within academia, two broad schools of definitions emerge: those aligned with 20th-century sociological stratum models of class society and those aligned with the 19th-century historical materialist economic models of the Marxists and anarchists.\n\nAnother distinction can be drawn between analytical concepts of social class, such as the Marxist and Weberian traditions, as well as the more empirical traditions such as socio-economic status approach, which notes the correlation of income, education and wealth with social outcomes without necessarily implying a particular theory of social structure.\n\nFor Marx, class is a combination of objective and subjective factors. Objectively, a class shares a common relationship to the means of production. Subjectively, the members will necessarily have some perception (\"class consciousness\") of their similarity and common interest. Class consciousness is not simply an awareness of one's own class interest but is also a set of shared views regarding how society should be organized legally, culturally, socially and politically. These class relations are reproduced through time.\n\nIn Marxist theory, the class structure of the capitalist mode of production is characterized by the conflict between two main classes: the bourgeoisie, the capitalists who own the means of production and the much larger proletariat (or \"working class\") who must sell their own labour power (wage labour). This is the fundamental economic structure of work and property, a state of inequality that is normalized and reproduced through cultural ideology.\n\nMarxists explain the history of \"civilized\" societies in terms of a war of classes between those who control production and those who produce the goods or services in society. In the Marxist view of capitalism, this is a conflict between capitalists (bourgeoisie) and wage-workers (the proletariat). For Marxists, class antagonism is rooted in the situation that control over social production necessarily entails control over the class which produces goods—in capitalism this is the exploitation of workers by the bourgeoisie.\n\nFurthermore, \"in countries where modern civilisation has become fully developed, a new class of petty bourgeois has been formed\". \"An industrial army of workmen, under the command of a capitalist, requires, like a real army, officers (managers) and sergeants (foremen, over-lookers) who, while the work is being done, command in the name of the capitalist\".\n\nMarx makes the argument that, as the bourgeoisie reach a point of wealth accumulation, they hold enough power as the dominant class to shape political institutions and society according to their own interests. Marx then goes on to claim that the non-elite class, owing to their large numbers, have the power to overthrow the elite and create an equal society.\n\nIn \"The Communist Manifesto\", Marx himself argued that it was the goal of the proletariat itself to displace the capitalist system with socialism, changing the social relationships underpinning the class system and then developing into a future communist society in which: \"the free development of each is the condition for the free development of all\". This would mark the beginning of a classless society in which human needs rather than profit would be motive for production. In a society with democratic control and production for use, there would be no class, no state and no need for financial and banking institutions and money.\n\nMax Weber formulated a three-component theory of stratification that saw social class as emerging from an interplay between \"class\", \"status\" and \"power\". Weber believed that class position was determined by a person's relationship to the means of production, while status or \"Stand\" emerged from estimations of honor or prestige.\n\nWeber derived many of his key concepts on social stratification by examining the social structure of many countries. He noted that contrary to Marx's theories, stratification was based on more than simply ownership of capital. Weber pointed out that some members of the aristocracy lack economic wealth yet might nevertheless have political power. Likewise in Europe, many wealthy Jewish families lacked prestige and honor because they were considered members of a \"pariah group\".\n\n\nOn April 2, 2013, the results of a survey conducted by BBC Lab UK developed in collaboration with academic experts and slated to be published in the journal \"Sociology\" were published online. The results released were based on a survey of 160,000 residents of the United Kingdom most of whom lived in England and described themselves as \"white\". Class was defined and measured according to the amount and kind of economic, cultural and social resources reported. Economic capital was defined as income and assets; cultural capital as amount and type of cultural interests and activities; and social capital as the quantity and social status of their friends, family and personal and business contacts. This theoretical framework was developed by Pierre Bourdieu who first published his theory of social distinction in 1979.\n\nToday, concepts of social class often assume three general categories: a very wealthy and powerful upper class that owns and controls the means of production; a middle class of professional workers, small business owners and low-level managers; and a lower class, who rely on low-paying wage jobs for their livelihood and often experience poverty.\n\nThe upper class is the social class composed of those who are rich, well-born, powerful, or a combination of those. They usually wield the greatest political power. In some countries, wealth alone is sufficient to allow entry into the upper class. In others, only people who are born or marry into certain aristocratic bloodlines are considered members of the upper class and those who gain great wealth through commercial activity are looked down upon by the aristocracy as \"nouveau riche\". In the United Kingdom, for example, the upper classes are the aristocracy and royalty, with wealth playing a less important role in class status. Many aristocratic peerages or titles have seats attached to them, with the holder of the title (e.g. Earl of Bristol) and his family being the custodians of the house, but not the owners. Many of these require high expenditures, so wealth is typically needed. Many aristocratic peerages and their homes are parts of estates, owned and run by the title holder with moneys generated by the land, rents or other sources of wealth. However, in the United States where there is no aristocracy or royalty, the upper class status belongs to the extremely wealthy, the so-called \"super-rich\", though there is some tendency even in the United States for those with old family wealth to look down on those who have earned their money in business, the struggle between New Money and Old Money.\n\nThe upper class is generally contained within the richest one or two percent of the population. Members of the upper class are often born into it and are distinguished by immense wealth which is passed from generation to generation in the form of estates.\n\nThe middle class is the most contested of the three categories, the broad group of people in contemporary society who fall socio-economically between the lower and upper classes. One example of the contest of this term is that in the United States \"middle class\" is applied very broadly and includes people who would elsewhere be considered working class. Middle-class workers are sometimes called \"white-collar workers\".\n\nTheorists such as Ralf Dahrendorf have noted the tendency toward an enlarged middle class in modern Western societies, particularly in relation to the necessity of an educated work force in technological economies. Perspectives concerning globalization and neocolonialism, such as dependency theory, suggest this is due to the shift of low-level labour to developing nations and the Third World.\n\nLower class (occasionally described as working class) are those employed in low-paying wage jobs with very little economic security. The term \"lower class\" also refers to persons with low income.\n\nThe working class is sometimes separated into those who are employed but lacking financial security (the \"working poor\") and an underclass—those who are long-term unemployed and/or homeless, especially those receiving welfare from the state. The latter is analogous to the Marxist term \"lumpenproletariat\". Members of the working class are sometimes called blue-collar workers.\n\nA person's socioeconomic class has wide-ranging effects. It can impact the schools they are able to attend, their health, the jobs open to them, who they may marry and their treatment by police and the courts.\n\nAngus Deaton and Anne Case have analyzed the mortality rates related to the group of white, middle-aged Americans between the ages of 45 and 54 and its relation to class. There has been a growing number of suicides and deaths by substance abuse in this particular group of middle-class Americans. This group also has been recorded to have an increase in reports of chronic pain and poor general health. Deaton and Case came to the conclusion from these observation that because of the constant stress that these white, middle aged Americans feel fighting poverty and wavering between the lower and working class, these strains have taken a toll on these people and affected their whole bodies.\n\nSocial classifications can also determine the sporting activities that such classes take part in. It is suggested that those of an upper social class are more likely to take part in sporting activities, whereas those of a lower social background are less likely to participate in sport. However, upper-class people tend to not take part in certain sports that have been commonly known to be linked with the lower class.\n\nA person's social class has a significant impact on their educational opportunities. Not only are upper-class parents able to send their children to exclusive schools that are perceived to be better, but in many places state-supported schools for children of the upper class are of a much higher quality than those the state provides for children of the lower classes. This lack of good schools is one factor that perpetuates the class divide across generations.\n\nIn 1977, British cultural theorist Paul Willis published a study titled \"Learning to Labour\" in which he investigated the connection between social class and education. In his study, he found that a group of working-class schoolchildren had developed an antipathy towards the acquisition of knowledge as being outside their class and therefore undesirable, perpetuating their presence in the working class.\n\nA person's social class has a significant impact on their physical health, their ability to receive adequate medical care and nutrition and their life expectancy.\n\nLower-class people experience a wide array of health problems as a result of their economic status. They are unable to use health care as often and when they do it is of lower quality, even though they generally tend to experience a much higher rate of health issues. Lower-class families have higher rates of infant mortality, cancer, cardiovascular disease and disabling physical injuries. Additionally, poor people tend to work in much more hazardous conditions, yet generally have much less (if any) health insurance provided for them, as compared to middle- and upper-class workers.\n\nThe conditions at a person's job vary greatly depending on class. Those in the upper-middle class and middle class enjoy greater freedoms in their occupations. They are usually more respected, enjoy more diversity and are able to exhibit some authority. Those in lower classes tend to feel more alienated and have lower work satisfaction overall. The physical conditions of the workplace differ greatly between classes. While middle-class workers may \"suffer alienating conditions\" or \"lack of job satisfaction\", blue-collar workers are more apt to suffer alienating, often routine, work with obvious physical health hazards, injury and even death.\n\nA recent United Kingdom government study has suggested that a \"glass floor\" exists in British society which prevents those who are less able, but who come from wealthier backgrounds, from slipping down the social ladder. This is due to the fact that those from wealthier backgrounds have more opportunities available to them. In fact, the article shows that less able, better-off kids are 35% more likely to become high earners than bright poor kids.\n\nClass conflict, frequently referred to as \"class warfare\" or \"class struggle\", is the tension or antagonism which exists in society due to competing socioeconomic interests and desires between people of different classes.\n\nFor Marx, the history of class society was a history of class conflict. He pointed to the successful rise of the bourgeoisie and the necessity of revolutionary violence—a heightened form of class conflict—in securing the bourgeoisie rights that supported the capitalist economy.\n\nMarx believed that the exploitation and poverty inherent in capitalism were a pre-existing form of class conflict. Marx believed that wage labourers would need to revolt to bring about a more equitable distribution of wealth and political power.\n\n\"Classless society\" refers to a society in which no one is born into a social class. Distinctions of wealth, income, education, culture or social network might arise and would only be determined by individual experience and achievement in such a society.\n\nSince these distinctions are difficult to avoid, advocates of a classless society (such as anarchists and communists) propose various means to achieve and maintain it and attach varying degrees of importance to it as an end in their overall programs/philosophy.\n\nRace and other large-scale groupings can also influence class standing. The association of particular ethnic groups with class statuses is common in many societies. As a result of conquest or internal ethnic differentiation, a ruling class is often ethnically homogenous and particular races or ethnic groups in some societies are legally or customarily restricted to occupying particular class positions. Which ethnicities are considered as belonging to high or low classes varies from society to society.\n\nIn modern societies, strict legal links between ethnicity and class have been drawn, such as in apartheid, the caste system in Africa, the position of the Burakumin in Japanese society and the casta system in Latin America.\n\n"}
{"id": "2744606", "url": "https://en.wikipedia.org/wiki?curid=2744606", "title": "Social criticism", "text": "Social criticism\n\nThe term social criticism often refers to a mode of criticism that locates the reasons for malicious conditions in a society considered to be in a flawed social structure. It may also refer to people adhering to a social critic's aims at practical solutions by way of specific measures either for consensual reform or powerful revolution.\n\nReligious persecution was common in Europe and was the reason for many physical and mental exoduses within the continent. Through such experiences, one of the first documents of social criticism was born: the \"Testament\" of Jean Meslier.\n\nRepression experienced by a minority often leads to protest. Without sufficient resolution of the dispute, a social criticism can be formulated, often covered by political groups (political monopoly). For protesting people \"within\" a social movement, it is often frustrating to experience failure of the movement and its own agenda.\n\nThe positivism dispute between critical rationalism, e.g. between Karl Popper and the Frankfurt School, is the academic form of the same discrepancy. This dispute deals with the question of whether research in the social sciences should be \"neutral\" or consciously adopt a partisan view.\n\nAcademic works of social criticism can belong to social philosophy, political economy, sociology, social psychology, psychoanalysis but also cultural studies and other disciplines or reject academic forms of discourse.\n\nSocial criticism can also be expressed in a fictional form, e.g. in a revolutionary novel like \"The Iron Heel\" by Jack London or in dystopian novels like Aldous Huxley's \"Brave New World\" (1932) or George Orwell's \"Nineteen Eighty-Four\" (1949) or Ray Bradbury's \"Fahrenheit 451\" (1953), or Rafael Grugman's \"Nontraditional Love\" (2008), children's books or films.\n\nFictional literature can have a significant social impact. For example, the 1852 novel \"Uncle Tom's Cabin\", by Harriet Beecher Stowe furthered the anti-slavery movement in the United States, and the 1885 novel \"Ramona\", by Helen Hunt Jackson, brought about changes in laws regarding Native Americans. Similarly, Upton Sinclair's 1906 novel \"The Jungle\" helped create new laws related to public health and food handling, and Arthur Morrison's 1896 novel \"A Child of the Jago\" caused England to change its housing laws. George Orwell and Charles Dickens wrote \"Animal Farm\" and \"A Tale of Two Cities\", respectively, to express their disillusionment with society and human nature. \"Animal Farm\", written in 1944, is a book that tells the animal fable of a farm in which the farm animals revolt against their human masters. It is an example of social criticism in literature in which Orwell satirized the events in Russia after the Bolshevik Revolution. He anthropomorphises the animals, and alludes each one to a counterpart in Russian history. \"A Tale of Two Cities\" also typifies this kind of literature. Besides the central theme of love, is another prevalent theme, that of a revolution gone bad. He shows us that, unfortunately, human nature causes us to be vengeful and, for some of us, overly ambitious. Both these books are similar in that both describe how, even with the best of intentions, our ambitions get the best of us. Both authors also demonstrate that violence and the Machiavellian attitude of \"the ends justifying the means\" are deplorable. They also express their authors' disenchantment with the state of evolution of human nature.\n\nAccording to Frederick Douglass, \"Where justice is denied, where poverty is enforced, where ignorance prevails, and where any one class is made to feel that society is an organized conspiracy to oppress, rob and degrade them, neither persons nor property will be safe.\"\n\nThe authors imply, that even if we begin with honourable intentions, there will be some who will let their basic instincts take control. \"Animal Farm\" portrays this nature through parodying events in real history. Given the right conditions, these events could happen anywhere. Take for example, a leader becoming overly ambitious, to the point of harming his people for more power.\n\nIn \"A Tale of Two Cities\", Dickens examines the inner soul, and shares with us how people are driven to the valley of human emotions, where desperation and anger reign, and what could happen afterwards if we let these emotions build up inside. Every human being is capable of becoming a ruthless, opportunistic being like Napoleon or Madame Defarge, if placed in the right place, at the right time.\n\nSocial criticism is certainly present in opera (The Cradle Will Rock, Trouble in Tahiti) and other types of classical music, such as the Symphony No.13, called \"Babi Yar\", of Dmitri Shostakovich. Other musical expressions of social criticism are frequent in punk and rap music, examples being \"Pretty Vacant\" by Sex Pistols and \"Brenda's Got a Baby\" by 2Pac. Heavy metal bands such as Black Sabbath, Metallica and Megadeth also use social criticism extensively, particularly in their earlier works.\n"}
{"id": "14589447", "url": "https://en.wikipedia.org/wiki?curid=14589447", "title": "Soku hi", "text": "Soku hi\n\nSoku-hi () means \"is and is not\". The term is primarily used by the representatives of the Kyoto School of Eastern philosophy.\n\nThe logic of soku-hi or \"is and is not\" represents a balanced logic of symbolization reflecting sensitivity to the mutual determination of universality and particularity in nature, and a corresponding emphasis on nonattachment to linguistic predicates and subjects as representations of the real.\n\n\n"}
{"id": "2528728", "url": "https://en.wikipedia.org/wiki?curid=2528728", "title": "Species complex", "text": "Species complex\n\nIn biology, a species complex is a group of closely related species that are very similar in appearance to the point that the boundaries between them are often unclear. Terms sometimes used synonymously but with more precise meanings are: cryptic species for two or more species hidden under one species name, sibling species for two cryptic species that are each other's closest relative, and species flock for a group of closely related species living in the same habitat. As informal taxonomic ranks, species group, species aggregate, and superspecies are also in use.\n\nTwo or more taxa once considered conspecific (of the same species) may later be subdivided into infraspecific taxa (taxa within a species, such as bacterial strains or plant varieties), but this is not a species complex.\n\nA species complex is in most cases a monophyletic group with a common ancestor, although there are exceptions. It may represent an early stage after speciation, but may also have been separated for a long time period without evolving morphological differences. Hybrid speciation can be a component in the evolution of a species complex.\n\nSpecies complexes exist in all groups of organisms. They are identified by the rigorous study of differences between individual species, making use of minute morphological details, tests of reproductive isolation, or DNA-based methods such as molecular phylogenetics or DNA barcoding. The existence of extremely similar species may cause local and global species diversity to be underestimated. Recognizing similar but distinct species is important for disease and pest control, and in conservation biology, although drawing dividing lines between species can be inherently difficult.\n\nA species complex is typically considered as a group of close, but distinct species. Obviously, the concept is closely tied to the definition of a species. Modern biology understands a species as \"separately evolving metapopulation lineage\" but acknowledges that the criteria to delimit species may depend on the group studied. Thus, many species defined traditionally, based only on morphological similarity, have been found to comprise several distinct species when other criteria, such as genetic differentiation or reproductive isolation were applied.\n\nA more restricted use applies the term to close species between which hybridisation occurred or is occurring, leading to intermediate forms and blurred species boundaries.  The informal classification, superspecies, can be exemplified by the grizzled skipper butterfly, a superspecies that is further divided into three subspecies.\n\nSome authors apply the term also to a species with intraspecific variability, which might be a sign of ongoing or incipient speciation. Examples are ring species or species with subspecies, where it is often unclear if these should be considered separate species.\n\nSeveral terms are used synonymously for a species complex, but some of them may also have slightly different, or more narrow meanings. In the nomenclature codes of zoology and bacteriology, no taxonomic ranks are defined at the level between subgenera and species, while the botanical code defines four ranks below genera (section, subsections, series and subseries). Different informal taxonomic solutions have been used to indicate a species complex.\n\nDistinguishing close species within a complex requires the study of often very small differences. Morphological differences may be minute and only visible using adapted methods, such as microscopy. However, distinct species may sometimes have no morphological differences. In these cases, other characters, e.g. in the species' life history, behavior, physiology, or karyology can be explored. As an example, territorial songs are indicative of species in the treecreepers, a bird genus with little morphological differences. Mating tests are common in some groups such as fungi to confirm the reproductive isolation of two species.\n\nAnalysis of DNA sequences is becoming increasingly standard for species recognition and may in many cases be the only useful method. Different methods are used to analyse such genetic data, for example molecular phylogenetics or DNA barcoding. Such methods have greatly contributed to the discovery of cryptic species, including such emblematic species as the fly agaric or the African elephants.\n\nSpecies forming a complex have typically diverged very recently from each other, allowing in some cases to retrace the process of speciation. Species with differentiated populations such as ring species are sometimes seen as an example of early, ongoing speciation, i.e. a species complex in formation. Nevertheless, similar but distinct species have sometimes been isolated for a long time without evolving differences, a phenomenon called \"morphological stasis\". As an examples, the Amazonian frog \"Pristimantis ockendeni\" is actually at least three different species that diverged over 5 million years ago.\n\nStabilizing selection has been invoked as a force maintaining similarity in species complexes, especially when adaptation to special environments, such as a host in the case of symbionts, or extreme environments, constrains possible directions of evolution: In such cases, strongly divergent selection is not to be expected. Also, asexual reproduction, such as through apomixis in plants, may separate lineages without producing a great degree of morphological differentiation.\n\nA species complex is usually a group that has one common ancestor (a monophyletic group), although closer examination can sometimes disprove this. As an example, the yellow-spotted \"fire salamanders\" in the genus \"Salamandra\", formerly all classified as one species \"S. salamandra\", are not monophyletic: the Corsican fire salamander's closest relative was shown to be the entirely black Alpine salamander. In such cases, similarity has arisen from convergent evolution.\n\nHybrid speciation can lead to unclear species boundaries through a process of reticulate evolution, where species have two parent species as their most recent common ancestors. In such cases, the hybrid species may have intermediate characters, as demonstrated e.g. in \"Heliconius\" butterflies. Hybrid speciation has been observed in various species complexes, such as insects, fungi, and plants. In plants, hybridization often takes place through polyploidization, and hybrid plant species are called nothospecies.\n\nIn regards to whether or not members of a species group share a range, sources differ. A source from Iowa State University Department of Agronomy says that members of a species group usually have partially overlapping ranges but do not interbreed with each other. \"A Dictionary of Zoology\" (Oxford University Press 1999) describes a species group as complex of related species that exist allopatrically and explains that this \"grouping can often be supported by experimental crosses in which only certain pairs of species will produce hybrids.\" The examples given below may support both uses of the term \"species group.\"\n\nOften such complexes only become evident when a new species is introduced into the system, breaking down existing species barriers. An example is the introduction of the Spanish slug in Northern Europe, where interbreeding with the local black slug and red slug, traditionally considered clearly separate species that did not interbreed, shows they may be actually just subspecies of the same species.\n\nWhere closely related species coexist in sympatry, it is often a particular challenge to understand how these similar species persist without outcompeting each other. Niche partitioning is one mechanism invoked to explain this. Studies in some species complexes indeed suggest that species divergence went in par with ecological differentiation, with species now preferring different microhabitats.\nSimilar methods also found that the Amazonian frog \"Eleutherodactylus ockendeni\" is actually at least 3 different species that diverged over 5 million years ago.\nA \"species flock\" may arise when a species penetrates a new geographical area and diversifies to occupy a variety of ecological niches; this process is known as adaptive radiation. The first species flock to be recognized as such was the 13 species of Darwin's finches on the Galápagos Islands described by Charles Darwin.\n\nIt has been suggested that cryptic species complexes are very common in the marine environment. Although this suggestion came before the detailed analysis of many systems using DNA sequence data, it has been proven correct. The increased use of DNA sequence in the investigation of organismal diversity (also called Phylogeography and DNA barcoding) has led to the discovery of a great many cryptic species complexes in all habitats. In the marine bryozoan \"Celleporella hyalina\", detailed morphological analyses and mating compatibility tests between the isolates identified by DNA sequence analysis were used to confirm that these groups consisted of more than 10 ecologically distinct species that had been diverging for many million years.\n\nEvidence from the identification of cryptic species has led some to conclude that current estimates of global species richness are too low.\n\nPests, species causing diseases, and their vectors, have direct importance for humans. When they are found to be cryptic species complexes, the ecology and virulence of each of these species needs to be reevaluated to devise appropriate control strategies. Examples are cryptic species in the malaria vector genus of mosquito, \"Anopheles\", or the fungi causing cryptococcosis.\n\nWhen a species is found to comprise in fact several phylogenetically distinct species, each of these typically have smaller distribution ranges and population sizes than reckoned before. These different species can also differ in their ecology, e.g. having different breeding strategies or habitat requirements, which has to be taken into account for appropriate management. For example, giraffe populations and subspecies differ genetically to such an extent that they may be considered species; while the giraffe as a whole is not considered threatened, considering each cryptic species separately would mean a much higher level of threat.\n\n"}
{"id": "76293", "url": "https://en.wikipedia.org/wiki?curid=76293", "title": "Temperance movement", "text": "Temperance movement\n\nThe temperance movement is a social movement against the consumption of alcoholic beverages. Participants in the movement typically criticize alcohol intoxication or promote complete abstinence (teetotalism), with leaders emphasizing alcohol's negative effects on health, personality, and family life. Typically the movement promotes alcohol education, as well as demands new laws against the selling of alcohols, or those regulating the availability of alcohol, or those completely prohibiting it. During the 19th and early 20th centuries, the Temperance Movement became prominent in many countries, particularly English-speaking and Scandinavian ones, and it led to Prohibition in the United States from 1920 to 1933.\n\nIn the late-seventeenth century, alcohol was a vital part of colonial life as a beverage, medicine, and commodity for men, women, and children. Drinking was widely accepted and completely integrated in society; however, drunkenness was not. Despite that, drunkenness was common and not often seen as a social problem. The attitudes towards alcohol began to change in the late eighteenth century. One of the reasons for the shifting attitudes was the necessity for sober laborers to operate heavy machinery that had been developed as a result of the Industrial Revolution. Anthony Benezet suggested abstinence from alcohol in 1775. As early as the 1790s, physician Benjamin Rush researched the danger that drinking alcohol could lead to disease that leads to a lack of self-control and he cited abstinence as the only treatment option. Rush saw benefits in fermented drinks, but condemned the use of distilled spirits. As well as addiction, Rush noticed the correlation that drunkenness had with disease, death, suicide and crime. After the American Revolution, Rush called upon ministers of various churches to act in preaching the messages of temperance. However, abstinence messages were largely ignored by Americans until the 1820s.\n\nIn the eighteenth century, there was a \"Gin Craze\" in the Kingdom of Great Britain. The bourgeoisie became increasingly critical of the widespread drunkenness among the lower classes. Motivated by the bourgeoisie's desire for order, and amplified by the population growth in the cities, the drinking of gin became the subject of critical national debate.\n\nIn the early nineteenth-century United States, alcohol was still regarded as a necessary part of the American diet for both practical and social reasons. On the one hand, water supplies were often polluted, milk was not always available, and coffee and tea was expensive. On the other hand, social construct of the time made it impolite for people (particularly men) to refuse alcohol. Drunkenness was not a problem, because people would only drink small amounts of alcohol throughout the day, but at the turn of the nineteenth-century, overindulgence and subsequent intoxication became an issue that led to the disintegration of the family. Early temperance societies often associated with churches were located in upstate New York and New England, but only lasted a few years. These early temperance societies called for moderate drinking, but had little influence outside of their geographical areas.\n\nIn 1743, John Wesley, the founder of the Methodist Churches, proclaimed \"that buying, selling, and drinking of liquor, unless absolutely necessary, were evils to be avoided\".\n\nIn 1810, Calvinist ministers met with a seminary in Massachusetts to write articles about abstinence from alcohol to use in preaching to their congregations. The Massachusetts Society for the Suppression of Intemperance (MSSI) was formed in 1813. The organization only accepted men of high social standing and encouraged moderation in alcohol consumption. Its peak of influence was in 1818, but the MSSI ended in 1820 and made no significant mark on the future of the temperance movement. Other small temperance societies appear in the 1810s, but had little impact outside their immediate regions and they disbanded soon after. Their methods had little effect in implementing temperance, and drinking actually increased until after 1830; however, their methods of public pledges and meetings, as well as handing out of pamphlets, were implemented by more lasting temperance societies such as the American Temperance Society.\n\nThe temperance movement began at a national level in the 1820s, having been popularized by evangelical temperance reformers and among the middle classes. There was a concentration on advice against hard spirits rather than on abstinence from all alcohol and on moral reform rather than legal measures against alcohol. An early temperance movement began during the American Revolution in Connecticut, Virginia and New York state, with farmers forming associations to ban whiskey distilling. The movement spread to eight states, advocating temperance rather than abstinence and taking positions on religious issues such as observance of the Sabbath.\n\nAfter the American Revolution there was a new emphasis on good citizenship for the new republic. With the Evangelical Protestant religious revival of the 1820s and '30s, called the Second Great Awakening, social movements began aiming for a perfect society. This included abolitionism and temperance. The Awakening brought with it an optimism about moral reform, achieved through volunteer organizations. Although the temperance movement was nonsectarian in principle, the movement consisted mostly of church-goers.\n\nThe temperance movement promoted temperance and emphasized the moral, economical and medical effects of overindulgence. Connecticut born minister Lyman Beecher published a book in 1826 called \"Six Sermons on...Intemperance\". Beecher described inebriation as a \"national sin\" as well as suggesting legislation to prohibit the sales of alcohol. He believed that it was only possible for drinkers to reform in the early stages of addiction, because anyone in advanced stages of addiction, according to Beecher, had damaged their morality and could not be saved. Early temperance reformers often viewed drunkards as warnings rather than as victims of a disease, leaving the state to take care of them and their conduct. In the same year, the American Temperance Society (ATS) was formed in Boston, Massachusetts, within 12 years claiming more than 8,000 local groups and over 1,250,000 members.Presbyterian preacher Charles Grandison Finney, taught abstinence from ardent spirits. In the Rochester, New York revival of 1831, individuals were required to sign a temperance pledge in order to receive salvation. Finney believed and taught that the body represented the \"temple of God\" and anything that would harm the \"temple\" including alcohol, must be avoided. By 1833, several thousand groups similar to the ATS were formed in most states. In some of the large communities, temperance almanacs were released which gave information about planting and harvesting as well as current information about the temperance issues.\n\nTemperance societies were being organized in England about the same time, many inspired by a Belfast professor of theology, and Presbyterian Church of Ireland Minister John Edgar, who poured his stock of whiskey out of his window in 1829. He mainly concentrated his fire on the elimination of spirits rather than wine and beer. On August 14, 1829 he wrote a letter in the \"Belfast Telegraph\" publicizing his views on temperance. He also formed the Ulster Temperance Movement with other Presbyterian clergy, initially enduring ridicule from members of his community.\n\nThe 1830s saw a tremendous growth in temperance groups, not just in England and the United States, but also in British colonies, especially New Zealand and Australia.\n\nOut of the religious revival and reform appeared Mormonism and Seventh-day Adventism, new Christian denominations that established criteria for healthy living as a part of their religious teachings, namely temperance.\n\nThe Word of Wisdom is a health code followed by the members of the Church of Jesus Christ of Latter-day Saints and other Latter Day Saint denominations which advises how to maintain good health: what one should do and what one should abstain from. One of the most prominent items in the Word of Wisdom is the complete abstinence from alcohol. When the Word of Wisdom was written, the Latter Day Saints were residing in Kirtland, Ohio and the Kirtland Temperance Society was organized on October 6, 1830 with 239 members. According to some scholars, the Word of Wisdom was influenced by the temperance movement. In June 1830, the \"Millenial Harbinger\" quoted from a book \"The Simplicity of Health\" which strongly condemned the use of alcohol, tobacco, and the untempered consumption of meat, similar to the provisions in the Word of Wisdom revealed three years later. This gave publicity to the movement and Temperance Societies began to form. On February 1, 1833, a few weeks before the Word of Wisdom came forth, all distilleries in the Kirtland area were shut down. During the early history of the Word of Wisdom, temperance and other items in the health code were seen more as wise recommendations than commandments. \n\nAlthough he advocated for temperance, Joseph Smith did not preach complete abstinence from alcohol. According to Paul H. Peterson and Ronald W. Walker, Joseph Smith did not enforce abstinence from alcohol because he believed it would threaten individual choice and agency as well as that forcing the Latter Day Saints to comply would cause separation in the Church. In Harry M. Beardsley's book \"Joseph Smith and his Mormon Empire\", Beardsley argues that some Mormon historians attempted to portray Joseph Smith as a teetotaler, but according to the testimonies of his contemporaries, Joseph Smith often drank alcohol in his own home or the homes of his friends in Kirtland. In Nauvoo, Illinois Smith was far less discreet with his drinking habits. However, at the end of the nineteenth century, second president of the Church of Jesus Christ of Latter-day Saints Brigham Young said that the Saints could no longer justify disobeying the Word of Wisdom because of the way that it was originally presented. In 1921, Heber J. Grant, then president of the LDS church, officially called on the Latter-day Saints to strictly adhere to the Word of Wisdom, including complete abstinence from alcohol.\n\nFounder of the Millerites, William Miller claimed that the Second Coming of Jesus Christ would be in 1843 and that anyone who drank alcohol would be unprepared for the Second Coming. After the Great Disappointment in 1843, the Seventh-day Adventist denomination was formed by Ellen G. White and her husband, a preacher, James Springer White who did not use alcohol or tobacco. Ellen preached healthful living to her followers, without specifying abstinence from alcohol, as most of her followers were temperance followers, and that would have been implied.\n\nAs a response to rising social problems in urbanized areas, a stricter form of temperance emerged called teetotalism, which promoted the complete abstinence from alcoholic beverages, this time including wine and beer, not just ardent spirits. The name \"teetotaler\" came from the capital \"T\"s that were written next to the names of people who pledged complete abstinence from alcohol. People were instructed to only drink pure water and the teetotalists were known as the \"pure-water army\". In the US, the American Temperance Union advocated the total abstinence of distilled and fermented liquors. By 1835, they had gained 1.5 million members. This created conflict between the teetotalists and the more moderate members of the ATS. Even though there were temperance societies in the South, as the movement became more closely tied with the abolitionist movement, people in the South created their own teetotal societies. Considering drinking was an important part of their cultures, German and Irish immigrants resisted the movement. In the UK, teetotalism originated in Preston, in 1833. The Catholic temperance movement started in 1838 when the Irish priest Theobald Mathew established the Teetotal Abstinence Society in 1838. In 1838, the mass working class movement for universal suffrage for men, Chartism, included a current called \"temperance chartism\". Faced with the refusal of the Parliament of the time to give the right to vote to working people, the temperance chartists saw the campaign against alcohol as a way of proving to the elites that working-class people were responsible enough to be granted the vote. In short, the 1830s was mostly characterized by moral persuasion of workers.\n\nIn 1840, a group of artisans in Baltimore, Maryland created their own temperance society that could appeal to hard-drinking men like themselves. Calling themselves the Washingtonians, they pledged complete abstinence, attempting to persuade others through their own experience with alcohol rather than relying on preaching and religious lectures. They argued that sympathy was an overlooked method for helping people with alcohol addictions, citing coercion as an ineffective method. For that reason, they did not support prohibitive legislation of alcohol. They were suspicious of the divisiveness of denominational religion and did not use religion in their discussions, emphasizing personal abstinence. They never set up national organizations, believing that concentration of power and distance from citizens causes corruption. Meetings were public and they encouraged equal participation, appealing to both men and women and northerners and southerners. Unlike early temperance reformers, the Washingtonians did not believe that intemperance destroyed a drinker's morality. They worked on the platform that abstinence communities could be created through sympathizing with drunkards rather than ostracizing them through the belief that they are sinners or diseased. \n\nOn February 22, 1842 in Springfield, Illinois, while a member of the Illinois Legislature, Abraham Lincoln gave an address to the Springfield Washington Temperance Society on the 110th anniversary of the birth of George Washington. In the speech, Lincoln criticized early methods of the temperance movement as overly forceful and advocated reason as the solution to the problem of intemperance, praising the current temperance movement methods of the Washingtonian movement.\n\nBy 1845, the Washingtonian movement was no longer as prominent for three reasons. Firstly, the evangelist reformers attacked them for refusing to admit alcoholism was a sin. Secondly, the movement was criticized as unsuccessful due to the number of men who would go back to drinking. Finally, the movement was internally divided by differing views on prohibition legislation. Temperance fraternal societies such as the Sons of Temperance and the Good Samaritans took the place of the Washingtonian movement with largely similar views relating to helping alcoholics by way of sympathy and philanthropy. They, however, differed from the Washingtonians through their closed rather than public meetings, fines, and membership qualifications, believing their methods would be more effective in curbing men's alcohol addictions. After the 1850s, the temperance movement was characterized more by prevention by means of prohibitions laws, than remedial efforts to facilitate the recovery of alcoholics.\n\nBy the mid-1850s, the United States was divided from differing views of slavery and prohibition laws and economic depression. This influenced the Third Great Awakening in the United States. The prayer meeting largely characterized this religious revival. Prayer meetings were devotional meetings run by laypeople rather than clergy and consisted of prayed and testimony by attendees. The meetings were held frequently and pledges of temperance were confessed. Prayer meetings and pledges characterized the post-Civil war \"gospel\" temperance movement. This movement was similar to early temperance movements in that drunkenness was seen as a sin; however, public testimony was used to convert others and convince them to sign the pledge. New and revitalized organizations emerged including the Young Men's Christian Association (YMCA) and the early Woman's Christian Temperance Union (WCTU). The movement relied on the reformed individuals using local evangelical resources to create institutions to reform drunk men. Reformed men in Massachusetts and Maine formed \"ribbon\" clubs to support men who were interested in stopping drinking. Ribbon reformers traveled throughout the Midwest forming clubs and sharing their experiences with others. Gospel rescue missions or inebriate homes were created that allowed homeless drunkards a safe place to reform and learn to practice total abstinence while receiving food and shelter. These movements emphasized sympathy over coercion, yet unlike the Washingtonian movements, emphasized helplessness as well with relief from their addictions as a result from seeking the grace of God.\n\nAs an expression of moralism, the membership of the temperance movement overlapped with that of the abolitionist movement and women's suffrage movement.\n\nDuring the Victorian period, the temperance movement became more political, advocating the legal prohibition of all alcohol, rather than only calling for moderation. Proponents of temperance, teetotalism and prohibition came to be known as the \"drys\".\n\nThere was still a focus on the working class, but also their children. The Band of Hope was founded in 1847 in Leeds, UK, by the Reverend Jabez Tunnicliff. It aimed to save working class children from the drinking parents by teaching them the importance and principles of sobriety and teetotalism. In 1855, a national organisation was formed amidst an explosion of Band of Hope work. Meetings were held in churches throughout the UK and included Christian teaching. The group campaigned politically for the curtailment of the influence of pubs and brewers. The organization became quite radical, organizing rallies, demonstrations and marches to influence as many people as possible to sign the pledge of allegiance to the society and to resolve to abstain \"from all liquors of an intoxicating quality, whether ale, porter, wine or spirits, except as medicine.\"\n\nIn this period there was local success at restricting or banning the sale of alcohol in many parts of the United States. In 1838, Massachusetts banned certain sales of spirits. The law was repealed two years later, but it set a precedent. In 1845, Michigan allowed its municipalities to decide whether they were going to prohibit. In 1846, a law was passed in Maine which was a full-fledged prohibition, and this was followed by bans in several other states in the next two decades.\n\nThe movement became more effective, with alcohol consumption in the US being decreased by half between 1830 and 1840. During this time, prohibition laws came into effect in twelve US states, such as Maine. Maine Law was passed in 1851 by the efforts of Neal Dow. Organized opposition caused five of these states to eliminate or weaken the laws.\n\nThe Temperance movement was a significant mass movement at this time and encouraged a general abstinence from the consumption of alcohol. A general movement to build alternatives to replace the functions of public bars existed, so the Independent Order of Rechabites was formed in England, with a branch later opening in America as a friendly society that did not hold meetings in public bars. There was also a movement to introduce temperance fountains across the United States—to provide people with reliably safe drinking water rather than saloon alcohol.\n\nThe National Prohibition Party led by John Russell gradually became more popular, gaining more votes, as they felt that the existing Democrat and Republican parties did not do enough for the temperance cause. The party was associated with the Independent Order of Good Templars, which entertained a universalist orientation, being more open to blacks and repentant alcoholics than most other organizations.\n\nReflecting the teaching on alcohol of their founder John Wesley, Methodist Churches were aligned with the temperance movement. Methodists believed that despite the supposed economic benefits of liquor traffic because of job creation and taxes, the harm that it causes society through its contribution to murder, gambling, prostitution, crime, and political corruption outweiged the economic benefits. In Great Britain, both Wesleyan Methodists and Primitive Methodists championed the cause of temperance; the Methodist Board of Temperance, Prohibition, and Public Morals was later established in the United States to further the movement. In 1864, the Salvation Army, another denomination in the Wesleyan-Arminian tradition, was founded in London with a heavy emphasis on both abstinence from alcohol and ministering to the working class, which led publicans to fund a Skeleton Army to disrupt their meetings. The Salvation Army quickly spread internationally, maintaining an emphasis on abstinence. Many of the most important prohibitionist groups, such as the avowedly prohibitionist United Kingdom Alliance (1853) and the US-based (but international) Woman's Christian Temperance Union (WCTU; 1873), began in the latter half of the nineteenth century, the latter of which was the one of the largest women societies in the world at the time. But the largest and most radical international temperance organization was the Good Templars. In 1862, the \"Soldiers Total Abstinence Association\" was founded in British India by Joseph Gelson Gregson, a Baptist missionary. In 1898, the Pioneer Total Abstinence Association was formed by James Cullen, an Irish Catholic, which spread to other English-speaking Catholic communities.\n\nIn 1870, physicians created the American Association of the Cure of Inebrity (AACI) to treat alcohol addiction. The two goals of the organization were to convince the skeptical medical community of the existence and seriousness of the disease of alcoholism and to prove the efficacy of asylum treatments of alcoholics. They argued for more genetic causes of alcohol addictions. Treatment often included restraint of the patient while they reformed both physically and morally.\n\nThe Anti-Saloon League was an organization that began in 1893 in Ohio. Reacting to urban growth, it was driven by evangelical Protestantism. Furthermore, the League was strongly supported by the WCTU: in some US states alcoholism had become epidemic and domestic violence rates were high. At the time, Americans drank about three times much as they did in the 2010s. The League campaigned for suffrage and temperance simultaneously, with leader Susan B. Anthony stating that \"The only hope of the Anti-Saloon League's success lies in putting the ballot into the hands of women\", i.e. it was expected that the first act that women were to take upon themselves after having obtained the right to vote, was to vote for an alcohol ban.\n\nActions of the temperance movement were organizing sobriety lectures and setting up reform clubs for men and children. Some proponents also opened special temperance hotels and lunch wagons, and lobbied for banning liquor during prominent events. The Scientific Temperance Instruction Movement published textbooks, promoted alcohol education and held many lectures. Political action included lobbying local legislators and creating petition campaigns.\n\nThis new trend of temperance movement would be the last but also prove the most effective. Scholars have estimated that by 1900, one in ten Americans had signed a pledge to abstain from drinking, as the temperance movement became the most well-organized lobby group of the time. International conferences were held, in which temperance advocacy methods and policies were discussed. By the turn of the century, temperance societies became commonplace in the US.\n\nDuring this time, there was also a growth in non-religious temperance groups linked to left-wing movements, such as the Scottish Prohibition Party. Founded in 1901, it went on to defeat Winston Churchill in Dundee in the 1922 general election.\n\nA favorite goal of the British Temperance movement was sharply to reduce heavy drinking by closing as many pubs as possible. Advocates were Protestant nonconformists who played a major role in the Liberal Party. The Liberal Party adopted temperance platforms focused on local option. In 1908, Prime Minister H.H. Asquith—although a heavy drinker himself—took the lead by proposing to close about a third of the 100,000 pubs in England and Wales, with the owners compensated through a new tax on surviving pubs. The brewers controlled the pubs and organized a stiff resistance, supported by the Conservatives, who repeatedly defeated the proposal in the House of Lords. However, the People's Tax of 1910 included a stiff tax on pubs.\n\nThe movement gained further traction during the First World War, with President Wilson issuing sharp restrictions on the sale of alcohol in many combatant countries. This was done to preserve grain for food production. During this time, prohibitionists used anti-German sentiment related to the war to rally against alcohol sales, since many brewers were of German-American descent.\n\nAccording to alcohol researcher Johan Edman, the first country to issue an alcohol prohibition was Russia, as part of war mobilization policies. This followed after Russia had made significant losses in the war against the sober Japanese in 1905. In the UK, the Liberal government passed the Defence of the Realm Act 1914 when pub hours were licensed, beer was watered down and was subject to a penny a pint extra tax, and in 1916 a State Management Scheme meant that breweries and pubs in certain areas of Britain were nationalized, especially in places where armaments were made. \n\nIn 1913, the ASL began its efforts for national prohibition. Wayne Wheeler, a member of the Anti-Saloon League was integral in the prohibition movement in the United States. He used hard political persuasion called \"Wheelerism\" in the 1920s of legislative bodies. Rather than ask directly for a vote, which Wheeler viewed as weak, Wheeler would cover the desks of legislators in telegrams. He was also accomplished in rallying supporters; the Cincinnati \"Enquirer\" called Wheeler \"the strongest political force of his day\". His efforts specifically influenced the passing of the eighteenth-amendment. And in 1920, the Eighteenth Amendment was successfully passed in the United States, introducing prohibition of the manufacture, sale and distribution of alcoholic beverages. The amendment, also called \"the noble experiment\", was preceded by the National Prohibition Act, which stipulated how the federal government should enforce the amendment.\n\nNational prohibition was proposed several times in New Zealand as well, and nearly successful. On a similar note, Australian states and New Zealand introduced\nrestrictive early closing times for bars during and immediately after the First World War. In Canada, in 1916 the Ontario Temperance Act was passed, prohibiting the sales of alcoholic beverages with more than 2.5% alcohol. In the 1920s imports of alcohol were cut off by provincial referendums.\n\nNorway introduced partial prohibition in 1917, which became full prohibition through a referendum in 1919, although this was overturned in 1926. Similarly, Finland introduced prohibition in 1919, but repealed it in 1932 after an upsurge in violent crime associated with criminal opportunism and the illegal liquor trade. Iceland introduced prohibition in 1915, but liberalized consumption of spirits in 1933, although beer was still illegal until 1989. In the 1910s, half of the countries in the world had introduced some form of alcohol control in their laws or policies.\n\nThe temperance movement started to wane in the 1930s, with prohibition being criticised as creating unhealthy drinking habits, encouraging criminals and discouraging economic activity. Prohibition would not last long: the legislative tide largely moved away from prohibition when the Twenty-first Amendment to the Constitution was ratified on December 5, 1933, repealing nationwide prohibition. The gradual relaxation of licensing laws went on throughout the 20th century, with Mississippi being the last state to end prohibition in 1966. In Australia, early hotel closing times were reverted in the 1950s and 1960s.\n\nInitially, prohibition had some positive effects in some states, with Ford reporting that absenteeism in his companies had decreased by half. Alcohol consumption decreased dramatically. Also, statistical analysis has shown that the temperance movement during this time had a positive, though moderate, effect on later adult educational outcomes through providing a healthy pre-natal environment. However, prohibition had negative effects on the American economy, with thousands of jobs being lost, the catering and entertainment industries losing huge profits. The US and other countries with prohibition saw their tax revenues decrease dramatically, with some estimating this at a loss of 11 billion dollars for the US. Furthermore, enforcement of the alcohol ban was an expensive undertaking for the government. Because the Eighteenth Amendment did not prohibit consumption, but only manufacture, distribution and sale, illegal consumption became commonplace. Illegal production of alcohol rose, and a thousand people per year died of alcohol that was illegally produced with little quality control. Bootlegging was a profitable activity for the mafia, and crime increased rather than decreased as expected and advocated by proponents.\n\nThe temperance movement itself was in decline as well: fundamentalist and nativist groups had become dominant in the movement, which led moderate members to leave the movement.\n\nDuring this time, in former colonies (such as Gujarat in India, Sri Lanka and Egypt), the temperance movement was associated with anti-colonialism or religious revival.\n\nThe temperance movement still exists in many parts of the world, although it is generally less politically influential than it was in the early 20th century. Its efforts today include disseminating research regarding alcohol and health, in addition to its effects on society and the family unit.\n\nProminent temperance organizations active today include the World Woman's Christian Temperance Union, International Blue Cross, White Ribbon Association, and International Organisation of Good Templars.\n\nThe Allegheny Wesleyan Methodist Connection and Salvation Army, for example, are Christian Churches that continue to require that their members refrain from drinking alcohol as well as smoking, taking illegal drugs, and gambling.\n\nIn youth culture in the 1990s, temperance was an important part of the straight edge scene, which also stressed abstinence from other drugs. \n\nFitzpatrick's Herbal Health in Lancashire, England, is thought to be the last original Temperance Bar.\n\nTemperance proponents saw the alcohol problem as the most crucial problem of Western civilization. Alcoholism was seen to cause poverty, and all types of social problems: alcohol was the enemy of everything good that modernity and science had to offer. They believed that abstinence would help decrease crime, make families stronger, and improve society as a whole. Although the temperance movement was non-denominational in principle, the movement consisted mostly of church-goers. Temperance advocates tended to use scientific arguments to back up their views, although at the core the temperance philosophy was moral-religious in nature. The alcohol problem was connected with a sense of purpose and modernity of the western nation, and was largely international in nature, in keeping with the international optimism typical for the period preceding the First World War.\n\nHistorical analysis of conference documents helps create an image of what the temperance movement stood for. The movement believed that alcohol abuse was a threat to scientific progress, as it was believed citizens had to be strong and sober to be ready for the modern age. Progressive themes and causes such as abolition, natural self-determination, worker's rights, and the importance of women in rearing children to be good citizens were key themes of this citizenship ideology. The movement put itself at service of the state, but was also critical of it. In that sense, it was a radical movement with liberal and socialist aspects, although in some parts of the world, notably the US, allied with conservatism. Alcohol was often associated with oppression: not only oppression in the West, but also in colonies. Temperance advocates saw alcohol as a product that \"... enables a few to become rich while it impoverishes the very many\". Temperance advocates worked closely with the labor movement, as well as the women suffrage movement, partly because there was mutual support and benefit, and the causes were seen as connected.\n\nTemperance proponents used a variety of means to prevent and treat alcohol abuse and restrict its consumption. At the end of the nineteenth century, medically-oriented treatment of alcohol abuse became more common. In a trend that was preceded by Rush's writings, alcoholism came to be seen as an illness which could be medically treated. Scientists who were temperance proponents attempted to find the underlying causes of alcohol abuse. At the same time, criticism rose toward use of alcohol in medical care. The notion of alcohol abuse as a disease would only become widely accepted much later, however, until after the Second World War.\n\nNevertheless, restriction of consumption was most emphasized in the movement, though ideas on how to accomplish this were varied and conflicting. Apart from the prohibition by law, there were also ideas to establish state monopoly on all alcohol sales, or through law reform remove profit from the alcohol industry.\n\nDuring the 1900s decade, the ideal of strong citizens was further developed into the hygienism ideology. Through the influence of scientific theories on heredity, temperance proponents came to believe that alcohol problems were not just a personal concern, but would cause later generations of people to \"degenerate\" as well. Public hygiene and improving the population through personal lifestyle were therefore promoted. A variety of temperance halls and coffee palaces were established as replacements for bars. Numerous periodicals devoted to temperance were published and temperance theatre, which had started in the 1820s, became an important part of the American cultural landscape at this time. The temperance movement generated its own popular culture. Popular songwriters such as Susan McFarland Parkhurst, George Frederick Root, Henry Clay Work and Stephen C. Foster composed a number of these songs. At temperance inns puppet plays, minstrel acts, parades and other shows were held.\n\nMuch of the temperance movement was based on organized religion, which saw women as responsible for edifying their children to be abstaining citizens. Nevertheless, temperance was tied in with both religious renewal and progressive politics, particularly female suffrage Furthermore, temperance activists were able to promote suffrage more effectively than suffrage activists themselves, because of their wide-ranging experience as activists, and because they argued for a concrete aim of safety at home, rather than an abstract aim of justice as the suffragists did.\n\nBy 1831, there were over 24 women's organizations dedicated to the temperance movement. Women were specifically drawn to the temperance movement, because it represented a fight to end a practice that greatly affected women's quality of life. Temperance was seen as a feminine, religious and moral duty, and when achieved, it was seen as a way to gain familial and domestic security as well as salvation in a religious sense. Indeed, scholar Ruth Bordin stated that the temperance movement was \"the foremost example of American feminism.\" Prominent women such as Amelia Bloomer, Elizabeth Cady Stanton, and Susan B. Anthony were active in temperance and abolitionist movements in the 1840s.\n\nA myriad of factors contributed to women's interest in the temperance movement. One of the initial contributions was the frequency in which women were victims of alcohol abuse. In a Chicago meeting of the National American Woman Suffrage Association, Susan B. Anthony stated that women suffer the most from drunkenness. The inability for women to control wages, vote, or own property added to a woman's vulnerability. Another contribution was related to the role of women in the home in the nineteenth century which was largely to preside over the spiritual and physical needs of the home and the family. Because of this, women believed it was their duty to protect their families from the danger of alcohol and to convert their family members to the ideas of abstinence. This new found calling to temperance, however, did not change the widely held viewpoint at the time that women were only responsible for matters regarding their homes. Consequently, women had what Ruth Bordin referred to as the \"maternal struggle\" which was the internal contradiction women felt with the new power to make change they had discovered, but in still believing in their nurturing and domestic roles and they did not yet understand how to use their power. June Sochen called women who joined movements such as women's temperance organizations \"pragmatic feminists\", because they took action to solve their grievances, but were not interested in altering traditional sex roles. The missionary organizations of many Protestant denominations gave women avenue to work from; there were already all-female missionary societies that were easily changed into women's temperance organizations.\n\nIn the 1870s and 1880s, the number of women in the middle and upper classes was large enough to support women participation in the temperance movement. Higher class women did not need to work and could rely on their husbands to support their families and consequently had more leisure time to engage in organizations and associations related to the temperance movement. The influx of Irish immigrants filled in the servant jobs left by freed African-Americans after the American Civil War, leaving upper and middle class women with even more time to participate in the community with domestic jobs being taken care of. Moreover, the birth rate had fallen, leaving women with an average of four children in 1880 as compared to seven children at the beginning of the nineteenth-century. The gathering of people in urban areas and the extra leisure time for women contributed to the mass female temperance movement. \n\nThe Woman's Christian Temperance Union (WCTU) grew out of a spontaneous crusade against saloons and liquor stores that began Ohio and spread throughout the Midwestern United States during the winter of 1873-1874. The crusade consisted of over 32,000 women storming into saloons and liquor stores to disrupt business and stop the sales of alcohol. The WCTU was officially organized in late November 1874 in Cleveland, Ohio. Frances Willard, the organization's second president, helped grow the organization into the largest women's religious organization in the 19th century. Willard was interested in suffrage and women's rights as well as temperance, believing that temperance could improve the quality of life on a family and a community level. The WCTU trained women in skills such as public speaking, leadership, and political thinking, using temperance as a springboard to achieve a higher quality of life for women on many levels. In 1881, the WCTU began to lobby for the mandation of instruction of temperance in public schools. In 1901, schools were required to instruct students on temperance ideas, but were accused of perpetuating misinformation, fear mongering, and racist stereotypes. Carrie Nation was one of the most extremist temperance movement workers and was arrested 30 times for the destruction of property at bars, saloons, and even pharmacies, believing that even alcohol used for medicine was unjustified. At the approach of the 20th century, the temperance movement became more interested in legislative reform as the pressure from the Anti-Saloon League increased. Women, having not yet achieved suffrage became less central to the movement in the early 1900s.\n\nProhibition agendas also became popular among factory owners, who strove for more efficiency during a period of increased industrialization. For this reason, industrial leaders such as Henry Ford and S.S. Kresge supported Prohibition. The cause of the sober factory worker was related to the cause of women temperance leaders: concerned mothers protested against the enslavement of factory workers, as well as the temptation saloons offered to these workers. Efficiency was also an important argument for the government, because they wanted their soldiers to be sober.\n\nAt the end of the nineteenth century, temperance movement opponents started to criticize the slave trade in Africa. This came during the last period of rapid colonial expansion. Slavery and alcohol trade in colonies were seen as two closely related problems, described as \"the twin oppressors of the people\". Again, this subject tied in with the ideas of civilization and effectiveness: temperance advocates raised the issue that the \"natives\" could not be properly \"civilized\" and put to work, if they were provided with the vice of alcohol.\n\n\n\n"}
{"id": "3959029", "url": "https://en.wikipedia.org/wiki?curid=3959029", "title": "The Lexicon of Comicana", "text": "The Lexicon of Comicana\n\nThe Lexicon of Comicana is a 1980 book by the American cartoonist Mort Walker. It was intended as a tongue-in-cheek look at the devices used by cartoonists. In it, Walker invented an international set of symbols called \"symbolia\" after researching cartoons around the world. In 1964, Walker had written an article called \"Let's Get Down to Grawlixes\", a satirical piece for the National Cartoonists Society. He used terms such as \"grawlixes\" for his own amusement, but they soon began to catch on and acquired an unexpected validity. The \"Lexicon\" was written in response to this.\n\nThe names he invented for them sometimes appear in dictionaries, and serve as convenient terminology occasionally used by cartoonists and critics. A 2001 gallery showing of comic- and street-influenced art in San Francisco, for example, was called \"Plewds! Squeans! and Spurls!\"\n\nAdditional symbolia terms include whiteope, sphericasia, that-a-tron, spurls, oculama, crottles, maledicta balloons, farkles, doozex, staggeration, boozex, digitrons, nittles, waftaroms, and jarns.\n\n\n"}
{"id": "56291903", "url": "https://en.wikipedia.org/wiki?curid=56291903", "title": "The Pawnee capture of the Cheyenne Sacred Arrows", "text": "The Pawnee capture of the Cheyenne Sacred Arrows\n\nThe Pawnee capture of the Cheyenne Sacred Arrows occurred around 1830 in central Nebraska, when the Cheyenne attacked a group from the Skidi Pawnee tribe, who were hunting bison. The Cheyenne had with them their sacred bundle of four arrows, called the Mahuts. During the battle, this sacred, ceremonial object was taken by the Pawnee. The Cheyenne initially made replica arrows but also tried to get the originals back. They recovered one from the Pawnee directly, either given to them or taken by them, and a second was captured by the Lakota and returned to the Cheyenne in exchange for horses. The two corresponding replicas were ceremonially returned to the Black Hills, where the arrows were traditionally believed to have originated. Eventually the bundles were re-established and the societies and their ceremonies continue into the present day. \n\nLikely, the Pawnee lived in villages of earth lodges in the present-day state of Nebraska and northern Kansas already in the 16th century. At the time of the battle with the Cheyenne, the Skidi Pawnee populated the banks of Loup River in the central part of Nebraska. The Chawi, the Kitkahahki and the Pitahawirata made up the South Bands as they lived south of the Platte River. Just some years later, they would move north and gather in the same area as the Skidi Pawnee. The Pawnee raised corn and other crops near their villages. However, they went on long communal bison hunts in both summer and winter. While out on the plains, they lived in skin tents and tipis.\n\nThe final groups of Cheyenne Indians seem to have crossed the Missouri River from eastern North Dakota in the last quarter of the 18th century. For a while, they lived south of the Cannonball River near already-established Cheyenne villages or camps. In the first decade of the 19th century, they mainly camped north of the North Platte. Around 1825, some bands headed south lured by reports about large herds of wild horses between the Platte River and the Arkansas River. This brought them close to the hunting grounds used by the Pawnee.\n\nThe Pawnee and the Cheyenne had long been enemies, and had fought each other since the Cheyenne first moved into the area. They captured horses and confronted each other on the plains, but neither side achieved any definite lasting advantage over the other.\n\nAccording to his traditional biography, the Cheyenne ancestral hero Sweet Medicine received the Sacred Arrows as a gift from supernatural beings, after being taken into a sacred cave at Bear Butte in the Black Hills. The two Buffalo Arrows in the bundle were painted red and provided for good hunting. The two Man Arrows were painted black painted and were instead for war′. When the four arrows were tied near the top of a lance in two separate pairs and carried against an enemy after the performance of the proper ceremony, they promised victory, and had already been present in the total destruction of a big Crow camp at Tongue River in 1820.\n\nThe renewal of the arrows form one of the most sacred of the Cheyenne ceremonies, and traditionally take place during the same time every summer, as well as in response to unfortunate events, such as a homicide or other tragedy.\n\nA year before this historic battle, a party of Cheyenne warriors intended to raid the Pawnee near the lower Platte. The party was discovered and all killed, just as the Cheyenne had done ten years before after the killing of thirty Cheyenne Bowstring warriors by the Crow. The tribe vowed to avenge the war group by moving the against those to blame for the killings.\n\nIn the summer of 1830, the entire Cheyenne tribe started down the Platte. A number of allied Lakota and Arapaho joined. The special custodian or keeper of the Sacred Arrows, White Thunder, and his wife led them. The scouts sent out to locate the enemy found no traces of the Pawnee. By chance, the group came across four messengers from a party of scouts, who had been killed by the Pawnee. The scouts finally located a large camp of Pawnees at the head of the South Loup. (According to the Pawnee, they had camp somewhere on Platte River).\n\nAfter marching for another day and night march, the body of people reached a place near the Pawnee camp in the early morning. The warriors prepared for battle. The women and children grouped in a circle where they had a view of the flat area soon to become a battlefield. The Pawnee camp seems to have been hidden on the other side of a ridge.\n\nThe Cheyenne warriors and their allies placed themselves in two separate wings. The Sacred Arrows were in front of one wing, and the other wing would follow a man wearing the sacred Buffalo Hat. \"These two great medicines protected all who were behind them ... and rendered the enemy in front helpless\".\n\nMeanwhile, the first bison hunters left the Pawnee camp and almost stumbled on the lined of the army. The battle was on, and White Thunder was unable to restrain the Cheyenne. Without having performed the required ceremony, he handed over the arrow bundle to a selected medicine man named Bull. Bull in turn hastily tied the whole bundle to the middle of his lance. Then he mounted his horse and tried to catch up with the rest of the warriors.\n\n\"The battle was hard fought\". An old Pawnee, apparently a Pitahawirata from the South Bands, was sick and tired of living. He had told his relatives to carry him to the very front line of the battle. He was sitting on the ground with a bow and some arrows. Bull wanted to count coup on this enemy, although the rest of the Cheyenne tried to talk him from it. The old Pawnee avoided the thrust with the lance and seized it. He dragged it from Bull, who slowly rode back to his own line. \"This spear must be a wonderful spear ...\", shouted the Pawnee, when he saw the medicine bundle in a wrapping of hide tied to it. The Pawnee rushed forward. Chief Big Eagle came first and secured the lance before the Cheyenne could recapture it.\n\nDuring the fight, Chief Big Eagle wore the Wonderful Leggings of Pahukatawa. The leggings were a part of a tribal war bundle, and they seemed to make Big Eagle fearless. \"Through the power of these leggings the Skiri [Skidi] captured the wonderful Cheyenne arrows\". Further, Big Eagle was dressed in a red shirt and wore a government medal on his breast. Throughout the battle, he rode on a small spotted horse. Therefore, the Cheyenne remembered him as Spotted Horse or Big Spotted Horse. \n\nAccording to the Cheyenne, they killed the old Pawnee on the battlefield. The Pawnee say, he first died the next summer during a Cheyenne attack on an almost empty Pawnee village.\n\nWith the Sacred Arrows gone and morale low, the Cheyenne failed to withstand a renewed charge by the Pawnee and retreated. \"How many were killed on either side was not known\". Later, the Cheyenne retreated up the Platte, mourning the loss of the arrows, which George Bent described as \"... the greatest disaster the Cheyennes ever suffered.\"\n\nPawnee Chief Big Eagle concluded they had captured something of extraordinary importance when he examined the arrows. He was keeper of the Morning Star bundle of the Skidi Pawnee and placed three of the arrows in that bundle. \n\nSome time after the battle, the best Cheyenne arrow makers made four surrogate Sacred Arrows. However, they also tried in various ways to retrieve the originals. Once, they invited Big Eagle and the Pawnees to their camp. In return for the four arrows they promised the guests many horses. Big Eagle expected treachery and brought just one arrow wrapped in a bundle. As feared, a Cheyenne rode away with the arrow in an unguarded moment. Another source recounts that three Cheyenne, White Thunder, Old Bark, and Doll Man traveled to a Skidi village in 1835 where they were received in Big Eagle's lodge and given one Buffalo Arrow. Despite gifts of more than a hundred horses, no more arrows were returned. \nIn either the winter of 1843 to 1844 according to a contemporary source, or in 1837 according to more modern sources, the Lakota attacked a village of Pawnee and retrieved a single medicine arrow. They recognized the Man Arrow and returned it to the Cheyenne in exchange for one hundred horses. \n\nTwo of the remade Sacred Arrows were now in excess. A ceremony was held, and the Cheyenne left two of the new arrows in a bundle in a crevice of the Black Hills, near the place where Sweet Medicine had received the original arrows. There they remained for a long while, and were occasional visited by Cheyenne travelers, before eventually disappearing.\n\nEfforts to restore the additional two original arrows were again made in the 1890s and 1930s to no avail. The return of the remaining arrows remained a source of bitterness for generations.\n\n"}
{"id": "46212073", "url": "https://en.wikipedia.org/wiki?curid=46212073", "title": "VinylPlus", "text": "VinylPlus\n\nVinylPlus was founded by the European Council of Vinyl Manufacturers (ECVM), the European Stabiliser Producers Association (ESPA), European Plasticisers and the European Plastics Converters (EuPC) in 2011 when the PVC industry renewed a previous initiative called Vinyl 2010. VinylPlus is a ten-year, industry-wide voluntary commitment to develop more ecologically responsible ways to produce, use and recycle PVC. The programme aligns with the principles and targets of the UN’s Sustainable Development Goals (SDGs) and the circular economy.\n\nVinylPlus includes all European PVC industry sectors: resin and additives producers, as well as plastics converters and recyclers. It covers the EU-28 plus Norway and Switzerland.\n\nVinylPlus is included in the Rio+20 Registry of Commitments, and is a member of the Green Industry Platform, the global partnership led by the United Nations Industrial Development Organization (UNIDO) and the United Nations Environment Platform Programme (UNEP). VinylPlus is also registered as a partner on the UN Partnerships for SDGs platform where it is recognised as fulfilling the SMART criteria. \n\nVinylPlus succeeded Vinyl 2010, which was the European PVC industry’s first voluntary commitment. Vinyl 2010 was set up in 2000 around the principles of Responsible Care adopted by the European chemicals industry in the 1980s . Its programme aimed to shift the PVC industry to a more sustainable model by improving recycling and substituting hazardous additives.\n\nAt the same time, the European Union also started addressing environmental concerns about plastics, notably developing the Waste Framework Directive (EU Directive 2008/98/EC), which laid down key EU recycling rules.\n\nVinyl 2010 also set up a monitoring committee, which was kept upon the creation of VinylPlus. The committee was designed as an independent verification of the programme’s activities, and includes representatives from the European Commission, the European Parliament, trade unions, consumer associations, academia and members of the European \n\nVinylPlus publishes an annual Progress Report summarising progress and data. Progress is measured against each of the five sustainability challenges identified for PVC. All information included in the report is presented to the Monitoring Committee and independently audited by third parties.\n\nThe VinylPlus Product Label was launched in 2018 as an identification tool.\n\nOne aspect of the programme is to Improve recycling figures.\n\nVinylPlus organises an annual forum: The VinylPlus Sustainability Forum. The first one took place in Istanbul in 2013. The event aims to encourage dialogue on sustainability by assembling representatives from the PVC industry, policy makers, consumer groups, retailers, architects, designers, recyclers and NGOs. The themes from past forums have been:\n\n\nVinylPlus’s management Board represents all European PVC industry sectors: resin and additives producers, as well as plastics converters. The Monitoring Committee offers guidance and advice, while ensuring an independent evaluation of the initiatives undertaken in the Voluntary Commitment. The Monitoring Committee currently includes representatives from the European Commission, the European Parliament, trade unions, consumer associations and academia, as well as representatives from the European PVC industry. The Monitoring Committee’s stated goal is to ensure VinylPlus’s transparency, participation and accountability. \n\nThe Recovinyl programme was set up in 2003 as part of Vinyl 2010’s commitment. Its original mission was to advance waste collection and recycling schemes. When the Vinyl 2010 programme ended, it was given a dual role under the new VinylPlus initiative. While Recovinyl still encourages PVC recycling, it also aims to optimise resource efficiency by acting as an intermediary between recyclers and converters.\n\nThe Vinyl Foundation is the non-profit organisation that manages the funds from the European PVC product manufacturers, compounders and raw material traders that support VinylPlus.\n"}
{"id": "33075140", "url": "https://en.wikipedia.org/wiki?curid=33075140", "title": "Williamson's model of managerial discretion", "text": "Williamson's model of managerial discretion\n\nOliver E. Williamson hypothesised (1964) that profit maximization would not be the objective of the managers of a joint stock organisation.\nThis theory, like other managerial theories of the firm, assumes that utility maximisation is a manager’s sole objective.\nHowever it is only in a corporate form of business organisation that a self-interest seeking manager maximise his/her own utility, since there exists a separation of ownership and control.\nThe managers can use their ‘discretion’ to frame and execute policies which would maximise their own utilities rather than maximising the shareholders’ utilities. This is essentially the principal–agent problem. This could however threaten their job security, if a minimum level of profit is not attained by the firm to distribute among the shareholders.\n\nThe basic assumptions of the model are:\n\nThe managerial utility function includes variables such as salary, job security, power, status, dominance, prestige and professional excellence of managers. Of these, salary is the only quantitative variable and thus measurable. The other variables are non-pecuniary, which are non-quantifiable.\nThe variables expenditure on staff salary, management slack, discretionary investments can be assigned nominal values. Thus these will be used as proxy variables to measure the real or unquantifiable concepts like job security, power, status, dominance, prestige and professional excellence of managers, appearing in the managerial utility function.\n\nUtility function or \"expense preference\" of a manager can be given by:\n\nwhere \"U\" denotes the Utility function, \"S\" denotes the “monetary expenditure on the staff”, \"M\" stands for \"Management Slack\" and \"I\" stands for amount of \"Discretionary Investment\".\n\n\"Monetary expenditure on staff\" include not only the manager's salary and other forms of monetary compensation received by him from the business firm but also the number of staff under the control of the manager as there is a close positive relationship between the number of staff and the manager's salary.\n\n\"Management slack\" consists of those non-essential management perquisites such as entertainment expenses, lavishly furnished offices, luxurious cars, large expense accounts, etc. which are above minimum to retain the managers in the firm. These perks, even if not provided would not make the manager quit his job, but these are incentives which enhance their prestige and status in the organisation in turn contributing to efficiency of the firm's operations.\nThe Management Slack is also a part of the cost of production of the firm.\n\n\"Discretionary investment\" refers to the amount of resources left at a manager's disposal, to be able to spend at his own discretion. For example, spending on latest equipment, furniture, decoration material, etc. It satisfies their ego and gives them a sense of pride. These give a boost to the manager's esteem and status in the organisation. Such investments are over and above the amount required for the survival of the firm (such as periodic replacement of the capital equipment).\n\nThe various concepts of profit used in the model needs to be understood clearly before moving to the main model. Williamson has put forth four main concepts of profits in his model:\n\nwhere \"R\" is the total revenue, \"C\" is the cost of production and \"S\" is the staff expenditure.\n\nwhere Π is the actual profit and \"M\" is the management slack.\n\nIt is the amount of profit after tax which should be paid to the shareholders of the firm, in the form of dividends, to keep them satisfied. If the minimum level of profit cannot be given out to the shareholders, they might resort of bulk sale of their shares which will transfer the ownership to other hands leaving the company in the risk of a complete take over. Since the shareholders have the voting rights, they might also vote for the change of the top level of management. Thus the job security of the manager is also threatened.\nIdeally the reported profits must be either equal to or greater than the minimum profits plus the taxes, as it is only after paying out the minimum profit that the additional profit can be used to increase the managerial utility further.\n\nwhere Π is the reported profit, Π is the minimum profit and \"T\" is the tax.\n\nIt is basically the entire amount of profit left after minimum profits and tax which is used to increase the manager’s utility, that is, to pay out managerial emoluments as well as allow them to make discretionary investments.\n\nwhere Π is the discretionary profit, Π is the actual profit, Π is the minimum profit and \"T\" is the tax amount.\n\nHowever, what appears in the managerial utility function is discretionary investments (\"I\") and not discretionary profits. Thus it is very important to distinguish between the two as further in the model we would have to maximize the managerial utility function given the profit constraint.\n\nwhere Π is the reported profit, Π is the minimum profit and \"T\" is the tax amount.\n\nThus it can be seen that the difference in the Discretionary Profit and the Discretionary investment arises because of the amount of managerial slack. This can be represented by the given equation\n\nwhere Π is the discretionary profit, \"I\" is the Discretionary investment and \"M\" is the management slack.\n\nFor simple representation of the model the managerial slack is considered to be zero. Thus there is no difference between the actual profit and reported profit, which implies that the discretionary profit is equal to the discretionary investment. I.e.\n\nwhere Π is the reported profit, Π is the actual profit, Π is the discretionary profit and \"I\" is the discretionary investment.\n\nSuch that the utility function of the manager becomes\n\nwhere S is the staff expenditure and I is the discretionary investment.\n\nThere is a trade off between these two variables. Increase in either will give the manager a higher level of satisfaction. At any point of time the amount of both these variables combined is the same, therefore an increase in one would automatically require a decrease in the other. The manager therefore has to make a choice of the correct combination of these two variables to attain a certain level of desired utility.\n\nSubstituting\n\nThe relationship between the two variables in the manager’s utility function is determined by the profit function. Profit of a firm is dependent on the demand and cost conditions. Given the cost conditions the demand is dependent of the price, staff expenditures and the market condition.\n\nPrice and market condition is assumed to be given exogenously at equilibrium. Thus the profit of the firm becomes dependent on the staff expenditure which can be written as\n\nDiscretionary profit can be rewritten as\n\nIn the model, the managers would try to maximise their utility given the profit constraint\n\nFig 1. shows the various levels of utility (\"U\", \"U\", \"U\") derived by the manager by combining different amounts of discretionary profits and staff expenditure. Higher the indifference curve, higher is the level of utility derived by the manager. Hence the manager would try to be on the highest level of indifference curve possible given the constraints. Staff expenditure is plotted on the \"x\"-axis and discretionary profits on the \"y\"-axis.\n\nThe discretionary profit in this simplified model is equal to the discretionary investment. The indifference curves are downward sloping and convex to the origin. This shows diminishing marginal rate of substitution of staff expenditure for discretionary profits. The curves are asymptotic in nature which implies that at any point of time and under any given circumstance the manager will choose positive amounts of both discretionary profits and staff expenditure.\n\nAssuming that the firm is producing an optimum level of output and the market environment is given, the discretionary profits curve is generated, shown in Fig 2. It gives the relationship between staff expenditure and discretionary profits.\n\nIt can be seen from the figure that profit will be positive in the region between the points B and C. Initially with increase in profits, the staff expenditure the discretionary profits also increase, but this is only till the point Π, that is, till S level of staff expenditure. Beyond this if staff expenditure is increased due to increase in output, then a fall in the discretionary profits is noticed. Staff expenditure of less than B and more than C is not feasible as it wouldn't satisfy the minimum profit constraint and would in turn threaten the job security of managers.\n\nTo find the equilibrium in the model, Fig 1. is superimposed on Fig 2. The equilibrium point is the point where the discretionary profit curve is tangent to the highest possible indifference curve of the manager, which is point E in Fig 3. Staying at the highest profit point would require the manager to be at a lower indifference curve \"U\". In this case the highest attainable level of utility is \"U\". At equilibrium, the level of profits would be lower but staff expenditure S* is higher than the staff expenditure made at the maximum profit point. As indifference curve is downward sloping, the equilibrium point would always be on the right of the maximum profit point. Thus the model shows the higher preference of managers for staff expenditure as compared to the discretionary investments.\n\n\n\n"}
