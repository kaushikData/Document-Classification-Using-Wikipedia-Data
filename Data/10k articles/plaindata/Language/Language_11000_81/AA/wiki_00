{"id": "4184791", "url": "https://en.wikipedia.org/wiki?curid=4184791", "title": "10-foot user interface", "text": "10-foot user interface\n\nIn computing, 10-foot user interface (\"10-foot UI\") is a graphical user interface designed for televisions. Compared to desktop computer and smartphone user interfaces, it uses text and other interface elements which are much larger in order to accommodate a typical television viewing distance of 10 feet (3 meters). Additionally, the limitations of a television's remote control necessitate extra user experience considerations to minimize user effort.\n\nThe term \"10-foot\" is used to differentiate this user interface style from those used on desktop computers, which typically assume the user's eyes are only about two feet (60 cm) from the display. This difference in distance from the display has a huge impact on the interface design, requiring the use of extra large fonts on a television and allowing relatively few items to be shown on a television at once.\n\nA 10 foot UI is almost always designed to be operated by a simple hand-held remote control. Rather than the mouse or touchscreen which are commonly used with other types of user interfaces, the remote's directional pad is the primary means of navigation. This means that a 10-foot UI needs to arrange items on screen in a way that clearly shows which item would be next in each of the four directions of the directional pad - usually a grid layout. Also, without a mouse cursor, the currently-selected item must be highlighted in some way.\n\nTen-foot interfaces may resemble other post-WIMP systems graphically, due to a similar paucity of pixels, but do not assume the use of a touch screen.\n\nThe goal of 10 foot user interface design is normally to make the user's interaction as simple and efficient as possible, trying to achieve a more laid-back and relaxed user experience with as few button presses as possible while still having an intuitive layout, in terms of accomplishing user goals—what is often called user-centered design. Good user interface design facilitates finishing the task at hand without drawing unnecessary attention to itself. Graphic design may be utilized to support its usability; however, the design process must balance technical functionality and visual elements (e.g., mental model) to create a system that is not only operational but also usable and adaptable to changing user needs.\n\n"}
{"id": "42688769", "url": "https://en.wikipedia.org/wiki?curid=42688769", "title": "A. Santha Kumar", "text": "A. Santha Kumar\n\nA. Santha Kumar is a Malayalam language playwright from Kerala state, South India. He won the Kerala Sahitya Akademi Award for Drama in 2010 for the work \"Maram Peyyunnu\".\n\n\nHe has numerous accolades to his credit including the Kerala Sahitya Akademi Award for Drama for “Marram Peyyunnu” (2010),\nAbu Dhabi Shakti Award, Kerala Sangeetha Nataka Akademi Award for the drama “Perum Kollan (1999),\nNilambur Balan Puraskaram (2002) for his contribution in theatre field, The Thopile Basi Award (2004) for the drama “Chirutha Chilathoke Maranupoyee”, \nP M Taj Award (2009) for drama “Oru Desham Nuna Parayunu”, \nAtlas Kairali Award, Irigale Narayani Award.\n"}
{"id": "637993", "url": "https://en.wikipedia.org/wiki?curid=637993", "title": "Arawak language", "text": "Arawak language\n\nArawak (Arowak/Aruák), also known as Lokono (Lokono Dian, literally 'people's talk' by its speakers), is an Arawakan language spoken by the Lokono (Arawak) people of South America in eastern Venezuela, Guyana, Suriname, and French Guiana. It is the eponymous language of the Arawakan language family.\n\nLokono has an active–stative syntax.\n\nLokono is a critically endangered language. The Lokono language is most commonly spoken in South America. Some specific countries where this language is spoken include Guyana, Suriname, French Guiana, and Venezuela. The percentage of living fluent speakers with active knowledge of the language is estimated to be 5% of the ethnic population. There are small communities of semi-speakers who have varying degrees of comprehension and fluency in Lokono that keep the language alive.. It is estimated that there are around 2,500 remaining speakers (including fluent and semi-fluent speakers). The decline in the use of Lokono as a language of communication is due to its lack of transmission from older speakers to the next generation. The language is not being passed to young children, as they are taught to speak the official languages of their countries. The oldest generation of speakers are around the age of 70 years of age of older.\n\nThe Lokono language is part of the larger Arawakan language family spoken by indigenous people in South and Central America along with the Caribbean. It spans four countries of Central America — Belize, Honduras, Guatemala, Nicaragua — and eight of South America — Bolivia, Guyana, French Guiana, Surinam, Venezuela, Colombia, Peru, Brazil (and also formerly Argentina and Paraguay). With about 40 extant languages, it is the largest language family in Latin America.\n\n\"Arawak\" is a tribal name in reference to the main crop food, the cassava root. It is commonly known as \"Manioc.\" The cassava root is a popular staple to millions in South America, Asia and Africa. It is a woody shrub grown in tropical or subtropical regions. The speakers of the Arawak language also identify themselves as, \"Lokono\", which translates to \"the people\" . The Arawak language within itself is known as, \"Lokono Dian\", \"the people's speech\".\n\nAlternative names of the same language include Arawák, Arahuaco, Aruak, Arowak, Arawac, Araguaco, Aruaqui, Arwuak, Arrowukas, Arahuacos, Locono, and Luccumi.\n\nLokono is an Arawakan language most commonly found to be spoken in eastern Venezuela, Guyana, Suriname and French Guiana. It was also formerly spoken on Caribbean islands such as Barbados and other neighboring countries. There are approximately 2,500 native speakers today. The following are regions where Arawak has been found spoken by native speakers.\n\nWilliam Pet observes an additional /p/ in loanwords.\nPet notes that phonetic realization of /o/ varies between [o] and [u].\n\nThe personal pronouns are shown below. The forms on the left are free forms, which can stand alone. The forms on the right are bound forms (prefixes), which must be attached to the front of a verb, a noun, or a postposition.\nAll verbs are sectioned into transitive, active transitive and stative intransitive.\n\n\"A= Sa=cross referencing prefix\"\n\n\"O=So= cross referencing suffix\"\n\nIn the Arawak language there are two distinct genders of masculine and feminine. They are used in cross referencing affixes, in demonstratives, in nominalization and in personal pronouns. Typical pronominal genders for example are feminine and non-feminine. The markers go back to Arawak third person singular cross referencing : feminine \"-(r)u,\" masculine \"-(r)i\"\n\nArawak Languages do distinguish singular and plural, however plural is optional unless the referent is a person. Markers used are \"*-na/-ni\" (animate/human plural) and \"*-pe\" (inanimate/animate non-human plural)\n\nArawak nouns are fragmented into inalienably and alienably possessed. Inalienably crossed nouns include things such as body parts, terms for kinship and common nouns like food selections. Deverbal nominalization belong to that grouping. Both forms of possession are marked with prefixes (A/Sa) . Inalienably possessed nouns have what is known as an \"unpossessed\" form (also known as 'absolute') marked with the suffix \"*-tfi or *-hV.\" Alienably possessed nouns take one of the suffixes \"*-ne/ni, *-te, *-re, *i/e, or *-na.\" All suffixes used as nominalizers.\n\nArawak languages have a negative prefix \"ma-\" and attributive-relative prefix \"ka-.\" An example of the use is \"ka-witi-w\" (a woman with good eyes) and \"ma-witti-w (a woman with bad eyes aka. blind) .\"\n\nThe Arawak language system has an alphabetical system similar to the Roman Alphabet with some minor changes and new additions to letters. The letters in brackets under each alphabetical letter is the IPA symbol for each letter.\n"}
{"id": "42212026", "url": "https://en.wikipedia.org/wiki?curid=42212026", "title": "Banarsidas Chaturvedi", "text": "Banarsidas Chaturvedi\n\nBanarsidas Chaturvedi (24 December 1892 - 2 May 1985) was a noted Hindi-language writer, journalist and recipient of Padma Bhushan awarded by Government of India in 1973. He was born on 24 December 1892 in Firozabad in Uttar Pradesh and died on 2 May 1985.\nHe served as a nominated member of Rajya Sabha for twelve years.\n\nBanarsidas became interested in the plight of indentured labourers (Girmitiya) of Indian origin in Fiji where he spent several years. He wrote extensively about the predicament of Indians in Fiji. With the intervention of Reverend C. F. Andrews, the system of indentured labour in Fiji was formally ended in 1920.\n\nA book in English titled 'Charles Freer Andrews, a Narrative' written by Banarsidas with Marjorie Sykes as co-author and foreword written by Mahatma Gandhi was published in 1949.\n"}
{"id": "9799957", "url": "https://en.wikipedia.org/wiki?curid=9799957", "title": "Baseline (medicine)", "text": "Baseline (medicine)\n\nA baseline in medicine is information found at the beginning of a study or other initial known value which is used for comparison with later data. The concept of a baseline is essential to the daily practice of medicine in order to establish a relative rather than absolute meaning to data. The meaning of baseline in medicine is very similar to that of the running baseline (baseball) being the direct path that a baserunner is taking to the base he is in route to. If the baserunner is outside the 3 foot margin around his running baseline, then he is considered out. Whereas if a patient with kidney failure (whose creatinine is usually 3.0 mg/dL) suddenly has a creatinine of 5.0 mg/dL, then his creatinine is out of his normal. For that person with kidney failure, absolute normal no longer applies because he will never again be able to obtain an absolutely normal creatinine level (0.5-1.2 mg/dL) with kidneys that no longer function properly.\n\n\n"}
{"id": "234802", "url": "https://en.wikipedia.org/wiki?curid=234802", "title": "Blackboard", "text": "Blackboard\n\nA blackboard (also known as a chalkboard) is a reusable writing surface on which text or drawings are made with sticks of calcium sulfate or calcium carbonate, known, when used for this purpose, as chalk. Blackboards were originally made of smooth, thin sheets of black or dark grey slate stone.\n\nA blackboard can simply be a board painted with matte dark paint (usually black, occasionally dark green). Matte black plastic sign material (known as ‘closed-cell PVC foamboard’) is also used to create custom chalkboard art.\nA more modern variation consists of a coiled sheet of plastic drawn across two parallel rollers, which can be scrolled to create additional writing space while saving what has been written. The highest grade blackboards are made of a rougher version porcelain enamelled steel (black, green, blue or sometimes other colours). Porcelain is very hard wearing and blackboards made of porcelain usually last 10–20 years in intensive use.\n\nManufacturing of slate blackboards began by the 1840s. Green chalkboards, generally made of porcelain enamel on a steel base, first appeared in the 1960s.\n\nLecture theatres may contain a number of blackboards in a grid arrangement. The lecturer then moves boards into reach for writing and then moves them out of reach, allowing a large amount of material to be shown simultaneously.\n\nThe chalk marks can be easily wiped off with a damp cloth, a sponge or a special blackboard eraser usually consisting of a block of wood covered by a felt pad. However, chalk marks made on some types of wet blackboard can be difficult to remove. Blackboard manufacturers often advise that a new or newly resurfaced blackboard be completely covered using the side of a stick of chalk and then that chalk brushed off as normal to prepare it for use.\n\nSticks of processed ‘chalk’ are produced especially for use with blackboards in white and also in various colours. White chalk sticks are made mainly from calcium carbonate derived from mineral chalk rock or limestone, while colored or pastel chalks are made from calcium sulfate in its dihydrate form, CaSO·2HO, derived from gypsum. Chalk sticks containing calcium carbonate typically contain 40–60% of CaCO (calcite).\n\nAs compared to whiteboards, blackboards still have a variety of advantages:\n\n\nOn the other hand, chalk produces dust, the amount depending on the quality of chalk used. Some people find this uncomfortable or may be allergic to it, and according to the American Academy of Allergy, Asthma and Immunology (AAAAI), there are links between chalk dust and allergy and asthma problems. The dust also precludes the use of chalk in areas shared with dust-sensitive equipment such as computers. The writing on blackboards is difficult to read in the dark. Chalk sticks shrink through use, and are notorious for breaking in half unless inserted in a writing utensil designed for chalk.\n\nThe scratching of fingernails on a blackboard, as well as other pointed, especially metal objects against blackboards, produces a sound that is well known for being extremely irritating to most people. According to a study run by Michael Oehler, a professor at the University of Media and Communication in Cologne, Germany, humans are \"predisposed to detest\" the sound of nails on a blackboard. The findings of the study were presented at the Acoustical Society of America conference and support earlier findings from a 1986 study by Vanderbilt psychologist Randolph Blake and two colleagues found that the sound of nails on a chalkboard annoyed people even when the high-pitch frequencies were removed. The study earned Blake a 2006 Ig Nobel Prize.\n\nThe writing slate was in use in Indian schools in the 11th century as mentioned in Alberuni’s \"Indica\" (\"Tarikh Al-Hind\"), written in the early 11th century:\n\nThey use black tablets for the children in the schools, and write upon them along the long side, not the broadside, writing with a white material from the left to the right.\n\nThe first classroom uses of large blackboards are difficult to date, but they were used for music education and composition in Europe as far back as the sixteenth century.\nThe term ‘blackboard’ is attested in English from the mid-eighteenth century; the \"Oxford English Dictionary\" provides a citation from 1739, to write “with Chalk on a black-Board”.\nThe first attested use of chalk on blackboard in the United States dates to September 21, 1801, in a lecture course in mathematics given by George Baron. James Pillans has been credited with the invention of coloured chalk (1814): he had a recipe with ground chalk, dyes and porridge.\n\nThe use of blackboard did change methods of education and testing, as found in the Conic Sections Rebellion of 1830 in Yale.\n\n\n"}
{"id": "464811", "url": "https://en.wikipedia.org/wiki?curid=464811", "title": "Contraindication", "text": "Contraindication\n\nIn medicine, a contraindication is a condition or factor that serves as a reason to withhold a certain medical treatment due to the harm that it would cause the patient. Contraindication is the opposite of indication, which is a reason to use a certain treatment.\n\nAbsolute contraindications are contraindications for which there are no reasonable circumstances for undertaking a course of action. For example, children and teenagers with viral infections should not be given aspirin because of the risk of Reye's syndrome, and a person with an anaphylactic food allergy should never eat the food to which they are allergic. Similarly, a person with hemochromatosis should not be administered iron preparations.\n\nRelative contraindications are contraindications for circumstances in which the patient is at higher risk of complications from treatment, but these risks may be outweighed by other considerations or mitigated by other measures. For example, a pregnant woman should normally avoid getting X-rays, but the risk may be outweighed by the benefit of diagnosing (and then treating) a serious condition such as tuberculosis. Relative contraindications may also be referred to as \"cautions\", such as in the British National Formulary.\n\n"}
{"id": "19820494", "url": "https://en.wikipedia.org/wiki?curid=19820494", "title": "Cross merchandising", "text": "Cross merchandising\n\nCross merchandising is the retail practice of marketing or displaying products from different categories together, in order to generate additional revenue for the store, sometimes also known as add-on sales, incremental purchase or secondary product placement. Its main objective is to link different products that complement each other or can logically be used in association. This strategy also aims to improve overall customer experience by allowing them to pick up related goods at the same place instead of having to spend time searching for them.\n\nCross merchandising generally exists in several forms:\n\nDisplays involve exhibiting a series of related products which together offers a complete package or solution to the customer's needs. This technique explicitly demonstrates the way multiple different products displayed complement and interact with each other.\n\nCommon examples include a clothing store featuring outfits and accessories ensemble on a mannequin, or a department store presenting a full set of furniture and electronics in a showcase window.\n\nSecondary placements or merchandising are carried out by showing products of different categories to the same shelf, pegs or aisle. This enables customers to link the related products at the time of purchase, saving their time of travelling down another aisle or luring them into buying additional items that they would not have done otherwise.\n\nThis strategy is most typically realised in supermarkets where Italian bread can be found directly in front of the butter and margarine aisle.\n\nLink suggestions or redirections describe the attempt of e-commerce platform to encourage additional purchases by displaying a link to complementary goods on the page of a specific product. The advantages of this online product placement approach are the absence of physical constraints and the ability to tailor product suggestions according to individual consumption history.\n\nThe use of the section titled \"Customers who bought this item also bought...\" on the online shopping website Amazon.com is an illustration of link suggestions and how they can constantly adjust with transaction patterns.\n\nAn effective cross merchandising programme creates a linkage between the products involves to appeal to customers, and the source of that correlation differs depending on the products themselves. The products being displayed often change over time. Stores regularly adjust merchandise according to season, sales target, consumption pattern and many other factors to maximize impact.\n\nA common type of product used in cross merchandising is complementary goods, which are products that are consumed in conjunction with one another. Electronics and batteries as well as printers and ink cartridges are examples of products that exhibit complementary properties for customers to connect.\n\nPairing products that offsets the unwanted effects of another is also a conventional strategy often found in cross merchandising. Examples include placing chewing gums next to cigarettes and putting toothpaste beside chocolates and sweets.\n\nThe technique of cross merchandising is not exclusively introduced by supermarkets and department stores. Examples can be found in a wide range of markets, as brands explore new markets and boost sales by cross merchandising their products with each other's.\n\nMarkets that frequently adopt cross merchandising include: \n"}
{"id": "16882590", "url": "https://en.wikipedia.org/wiki?curid=16882590", "title": "Domingos Caldas Barbosa", "text": "Domingos Caldas Barbosa\n\nDomingos Caldas Barbosa (1739? — November 9, 1800) was a Colonial Brazilian Neoclassic poet and musician, famous for creating the \"modinha\". He wrote under the pen name Lereno.\n\nBarbosa is the patron of the 3rd chair of the Academia Brasileira de Música (Brazilian Academy of Music).\n\nBarbosa's date of birth is unknown. It is most accepted to be in 1739, in Rio de Janeiro, to a Portuguese man and a liberated Angolan slave woman. Trained at the Jesuit college in Rio de Janeiro, he developed a power of literary improvisation which he indulged at the expense of the Portuguese whites and thereby stirred them up against him. His enemies had him forcibly enrolled in a body of troops setting forth for the Colonia del Sacramento, where he remained until 1762. Returning to Rio Janeiro he soon embarked for Portugal, and there obtained the patronage of two nobles of the Vasconcellos family, the Conde de Pombeiro and the Marquez de Castello Melhor. Taking minor orders he received a religious benefice, being attached as chaplain to the Casa da Supplicaçáo.\n\nAlthough he was a mulatto, he obtained entrance into high society in the Portuguese capital: he could improvise \"cantigas\" and play his own accompaniment on the viol. Hence the condescending nickname \"cantor de viola\" which was given to him. Well aware that his social status was uncertain, he retained his self-possession even in the face of the insulting attitude of the poet Bocage and others.\n\nWith most of the Portuguese poets of the time he had good relations, consorting with them in one or another literary academy. His \"cantigas\" acquired great popularity. He was a minor poet with facility, able to express himself simply, and to avoid bombast and sensuality. His poetical definition of the characteristically Portuguese quality of \"saudades\" remains famous.\n\nBarbosa's poems were published posthumously, in 1825, under the name \"Viola de Lereno\" (\"Lereno's Viol\").\n\n"}
{"id": "5131815", "url": "https://en.wikipedia.org/wiki?curid=5131815", "title": "Eggon language", "text": "Eggon language\n\nEggon (also Egon, Ero, Mo Egon, Hill Mada or Mada Eggon) is a Plateau language spoken in central Nigeria. It is a major language in Nasarawa State.\n\nThe exact classification of the Eggon language has been in dispute and it can be said that this issue remains unresolved. Eggon was first classified by Greenberg (1963) as a Plateau language in his group 5, together with Nungu and Yeskwa. In the revision prepared by Carl Hoffman published in Hansford et al. (1976) a Benue group was set up that combined Greenberg's Plateau 5 and 7 with Jukunoid. The new subgrouping classified Eggon together with Nungu, Ake and Jidda-Abu. This concept of a Benue grouping came from the lexicostatistical studies of Shimizu (1975) who argued against the unity of Greenberg's Plateau and proposed the Benue group. However, in 1983, Gerhardt published a convincing rebuttal of Shimizu's arguments. The latest version of classification of Plateau languages in Gerhardt (1989) adds Yashi to the Eggon subgroup but removes the links with 'Benue' i.e. Tarok and the Jukunoid languages. Blench (2008) classifies Eggon and Ake as the Eggonic group of the Southern branch of Plateau.\n\nThe main towns of the Eggon people are Nassarawa-Eggon, Kagbu, Washo and Wana. They stretch as far south as Lafia and west of Akwanga as far as the railway line. They are bordered on the north by the Mada and to the south by the Migili and the Idoma.\n\nIn much of the colonial literature, the Eggon were known as the \"Hill Mada\" in contrast to the \"Plains Mada\", the people known as Mada today. The Eggon lived in the Mada hills south of Akwanga in the pre-colonial period, but there is no connection between the groups that would justify these terms, and they have now been discarded.\n\nThe exact number of speakers is unknown, but it is unlikely to be less than the estimate of 200,000 given by Sibomana (1985). Ames (1934) gave a figure of 41,276 for the 1920s, but this is likely to have been substantially underestimated. Welmers (1971) estimated 52,000 although this may have been only a projection from Ames.\n\nVery little has been written about Eggon society and Temple (1922) and Ames (1934) are the only sources that contain any descriptions of Eggon social organisation.\n\nEggon is conventionally divided into twenty-five mutually comprehensible dialects, some of which are; Eggon Wangibi, Ikka, Wana, Washo, Wakama, Ogne, Angbashu, Alushi, Alogani, Eva, Nabe, Lizzi, Ezzen, Arikpa, etc. The only author to discuss dialects is Sibomana (1985) whose discussion focuses on Kagbu, which he states is the main dialect. He also cites data from the Nassarawa-Eggon dialect. The Benue–Congo Comparative Wordlist (1969, 1972) also gives data from two dialects.\n\nA twenty-sixth variety is Madan-tara, spoken by a group of Eggon east of Nassarawa-Eggon. It is said to be impossible to understand without special learning and is sufficiently different from other lects to be effectively a new language. Its precise relationship to the other varieties of Eggon is unknown.\n\nEggon has no literary standard language. The earliest written material in Eggon appears to be scripture portions from 1937, probably prepared by I.D. Hepburn. The dialect chosen for bible translation is based on the Wana dialect, although it is supplemented by forms from other dialects and so is a sort of synthetic Eggon not based on the speech of a particular group. A hymnbook and 2 readers were prepared, and the translation of the New Testament was completed in 1974. The orthography of the New Testament is somewhat different from the earlier publications. There are however, literature works written in eggon language which provides confidence for one to surely say there is improvement in the written language of eggon. There are also summer lessons to teach and train eggon sons and daughters their language and culture.\n\nEggon is apparently in use in churches only in remoter regions and it has been displaced by Hausa in all establishments along the main road. However, there is apparently a move to revive the use of Eggon. Some evidence of this is the recent publication of new material in Eggon, a book of history and customs and a women's magazine which is intended to make a regular appearance.\n\nThe following are the main things that have been written about Eggon. Some have not been published and are only available in mimeo.\n\n\n\n"}
{"id": "2339522", "url": "https://en.wikipedia.org/wiki?curid=2339522", "title": "Eliezer Dob Liebermann", "text": "Eliezer Dob Liebermann\n\nEliezer Dob Liebermann (12 April 1820 - 15 April 1895) was a Russian Hebrew-language writer of Jewish origin. \n\nHe was born in Pilvischok in the region of Suwałki. His father was a shohet, a kosher butcher, and gave him a normal Jewish education. At the age of twelve he was sent to his uncle R. Elijah Schick (\"Reb Elinke Lider\"), then the rabbi of Amstibove, who instructed him in Talmud and rabbinical literature. In 1838 he went to Vilna and joined the Maskilim. In about 1844 he settled as a teacher in Białystok. In 1867 he left to Suwałki, remained there about twenty years, and then returned to Białystok.\n\nLiebermann was the author of \"Megillat Sefer\", a collection of short stories, essays, fables, and letters, and of \"Zedek u-Mishpat\", a Hebrew adaptation of S. D. Luzzatto's \"Lezioni di Teologia Morale Israelitica\". He wrote also \"Ge Hizzayon\", and a number of articles which he published in various Hebrew periodicals.\n\n"}
{"id": "10853", "url": "https://en.wikipedia.org/wiki?curid=10853", "title": "Fictional language", "text": "Fictional language\n\nFictional languages are constructed languages created as part of a fictional setting, for example in books, movies, television shows, and video games. Fictional languages are intended to be the languages of a fictional world and are often designed with the intent of giving more depth and an appearance of plausibility to the fictional worlds with which they are associated, and to have their characters communicate in a fashion which is both alien and dislocated.\n\nSome of these languages, e.g., in worlds of fantasy fiction, alternate universes, Earth's future, or alternate history, are presented as distorted versions or dialects of modern English or other natural language, while others are independently designed conlangs.\n\nWhile most fictional languages are just gibberish, a few are fully functioning and comprehensive languages that can be learned.\n\nFictional languages are separated from artistic languages by both purpose and relative completion: a fictional language often has the least amount of grammar and vocabulary possible, and rarely extends beyond the absolutely necessary. At the same time, some others have developed languages in detail for their own sake, such as J. R. R. Tolkien's Quenya and Sindarin (two Elvish languages), \"Star Trek\"'s Klingon language and \"Avatar\"'s Na'vi language which exist as functioning, usable languages. Here \"fictional\" can be a misnomer.\n\nBy analogy with the word \"conlang,\" the term \"conworld\" is used to describe these fictional worlds, inhabited by fictional constructed cultures. The conworld influences vocabulary (what words the language will have for flora and fauna, articles of clothing, objects of technology, religious concepts, names of places and tribes, etc.), as well as influencing other factors such as pronouns, or how their cultures view the break-off points between colors or the gender and age of family members.\n\nProfessional fictional languages are those languages created for use in books, movies, television shows, video games, comics, toys, and musical albums (prominent examples of works featuring fictional languages include the Middle-Earth and \"Star Trek\" universes and the game \"Myst\").\n\nA notable subgenre of fictional languages are alien languages, the ones that are used or might be used by putative extraterrestrial life forms. Alien languages are subject of both science fiction and scientific research.\n\nPerhaps the most fully developed fictional alien language is the Klingon language of the \"Star Trek\" universe - a fully developed constructed language.\n\nThe problem of alien language has confronted generations of science fiction writers; some have created fictional languages for their characters to use, while others have circumvented the problem through translation devices or other fantastic technology.\n\nAlthough this field remains largely confined to science fiction, the possibility of intelligent extraterrestrial life makes the question of alien language a credible topic for scientific and philosophical speculation.\n\nWhile in many cases an alien language is but an element of a fictional reality, in a number of science fiction works the core of the plot involves linguistic and psychological problems of communication between various alien species.\n\nInternet-based fictional languages are hosted along with their \"conworlds\" on the internet, and based at these sites, becoming known to the world through the visitors to these sites; Verdurian, the language of Mark Rosenfelder's Verduria on the planet of Almea, is a flagship Internet-based fictional language. Many other fictional languages and their associated conworlds are created privately by their inventor, known only to the inventor and perhaps a few friends. In this context the term \"professional\" (used for the first category) as opposed to \"amateur\" (used for the second and third) refers only to the professionalism of the used medium, and not to the professionalism of the language itself or its creator. In fact, most professional languages are the work of non-linguists, while many amateur languages were in fact created by linguists, and in general the latter are better developed.\n\n\n\n"}
{"id": "1097569", "url": "https://en.wikipedia.org/wiki?curid=1097569", "title": "Género chico", "text": "Género chico\n\nGénero chico (literally, \"little genre\") is a Spanish genre of short, light plays with music. It is a major branch of \"zarzuela\", Spain's form of popular music theatre with dialogue, and differs from \"zarzuela grande\" and most other operatic forms both in its brevity and by being aimed at audiences of a wide social spectrum.\n\n\"Zarzuela\" was developed during the reign of Philip IV (1605–1665, reigned from 1621), who during the 1640s began to commission musico-theatrical entertainments on mythological themes mixed with popular peasant song and dance, from the writer Calderón de la Barca working with composers such as Juan de Hidalgo. These were performed at the Royal hunting lodge, the \"Palacio de la Zarzuela\". During the next two hundred years, \"zarzuela\", as these mixed entertainments swiftly became known, became the native-language alternative to the Italian operatic form nurtured by successive monarchs.\n\nIn the 19th century, the country's tense political circumstances affected \"zarzuela\". Isabella II fell from power during the liberal revolution of 1868, and the country found itself submerged in a crisis at all levels: economic, political, and ideological (with various strands of socialism coming to prominence). Instability increased with the 1870 assassination of Juan Prim, President of the regency council and Marshal of Spain. For economic and other reasons, there was a sharp drop in theatre box-office sales, as most people could not afford the average fourteen \"reales\" for non-necessities. Such high prices, plus the national uncertainty, brought most Madrid theatres into crisis, and many - including the \"Teatro de la Zarzuela\" itself - came close to ruin.\n\nAgainst this trend, Juan José Luján, Antonio Riquelme and José Vallés, three actors, had the idea of splitting the afternoon at the theatre into four parts of one hour each, creating the so-called \"sesiones por horas\", or \"performances by the hour\", which cost barely a \"real\", and were given in down-market theatres. This kept the seats filled, since people came more often, due to low prices. Managers accepted the idea, needing customers.\n\nThey wanted to repeat the success of \"teatro cómico\", an earlier phenomenon that copied Offenbach's comic model, and was brought by the theatre manager Arderíus to the Madrid Variety Theatre (with his own \"El Joven Telémaco\" — \"Young Telemachus\" — as the main draw). The comedic model for these featured zany, unpredictable plots based on myths, tending towards caricature and mockery of various topics such as royalty, the Army, and politics. They do so with pleasant, catchy music with a certain popular, erotic tone. Comic operas of this sort were nevertheless quickly eclipsed by the expansion of the \"género chico\" and became less popular after the mid-1870s.\n\nBecause of the need for short operetta-like works that could fit into one hour, the first performances were of old plays that were already popular, such as \"El Maestro de baile\" (\"The Dancing Master\", by Luis Misón, and predating the \"género chico\" by many years), or plays like \"Una vieja\" (\"An Old Woman\", Joaquín Romualdo Gaztambide) and \"El grumete\" (\"The Cabin Boy\", Juan Pascual Antonio Arrieta). These plays had originally been considered secondary and were programmed as such, beside larger, more important \"zarzuelas\", but with a change of taste and the tendency towards nationalism and German opera, the Italian taste copied by the \"zarzuelas\" would fall out of fashion, whilst the character of these little plays shone for itself. With time, new short plays were written for this short format and jolly style, notably influenced by the comic genre (with suggestive titles such as \"La hoja de parra\" (\"The Fig Leaf\") or \"Dice el sexto mandamiento\" (\"According to the Sixth Commandment\").\n\nIt is easy to see that the goal of \"género chico\" is purely to entertain the audience. Unlike the serious, dramatic themes and complicated plots in \"zarzuela mayor\", this genre presented simplified farces about everyday topics such as daily life in Madrid. This is why it was so successful with the public: apart from the low price, people could easily follow the plot and identify with the characters.\n\nThe decade of the 1870s saw the genre consolidate itself, with numerous authors publishing, for example Miguel Nieto and his \"El Gorro Frigio\" (\"The Phrygian Cap\"), and Fernández Caballero's \"Château Margaux\". The genre was now centred on a model similar to that of contemporary realist literature, mainly with the musical form of lyrical one-act farces.\n\nThe definitive accolade that the \"género chico\" would receive was with Chueca and Valverde's \"La Gran Vía\", in the summer of 1886. The play, named after a major street that was then under construction through the heart of Madrid, was so successful that it went from the summer theatres to the Apolo, and was repeated several times. It incorporated a series of lively, unrelated one-act farces on current affairs. Federico Chueca was one of the most prolific and important \"chico\" composer-librettists, often collaborating with Joaquín Valverde Durán. His work includes \"El año pasado por agua\" (\"Last Year Under Water\"), \"Agua, azucarillos y aguardiente\" (\"Water, Sweets, and Spirits\"), perhaps the most popular nowadays, \"La alegría de la huerta\" (\"The happiness of the orchard\"), \"El arca de Noé\" (\"Noah's Ark\"), \"Los descamisados\" (\"The Shirtless Ones\") and more.\n\nAnother common model for these works was comparison of two places: \"De Madrid a París\" (Chueca y Velarde, \"From Madrid to Paris\") or \"De Getafe al paraíso\" (\"From Getafe to Paradise\", a two-act \"zarzuela\" by Barbieri, Getafe is a town close to Madrid), \"Cádiz\" (Valverde). Other important playwrights were Giménez, Joaquín \"Quinito\" Valverde Sanjuán (Joaquín Valverde Durán's son), Tomás Lopez Torregrosa (\"San Antón\" and \"El santo de la Isidra\" [\"Isidra's Saint\", Isidra being one of the characters]) Fernández Caballero (\"El dúo de la africana\" [The Duet from \"L'Africaine\", a reference to the opera by Meyerbeer], \"El cabo primero\" [\"The Headman\", that is, the person in command], \"La viejecita\" [\"The Little Old Lady\"], and \"Gigantes y cabezudos\" [\"Giants and \"cabezudos\"\"]; named after popular Spanish parade disguises), Jerónimo Jiménez (\"El baile de Luis Alonso\" [\"The Dance of Luis Alonso\"] and its sequel \"La boda de Luis Alonso\" [\"The Marriage of Luis Alonso\"]). \n\nOne very important \"auteur\" was Ruperto Chapí, who spent his life oscillating between attempts to create a proper Spanish opera, and his modest \"género chico\" plays, which included \"Música Clásica\" (\"Classical Music\"), \"La revoltosa\" (\"The Rebel Girl\"), \"¡Las doce y media y sereno!\" (\"Half Past Midnight and all is quiet\"), y \"El tambor de granaderos\" (\"The Grenadiers' Drum\"). \n\nFinally, one of the best-known examples of \"género chico\" was \"La verbena de la Paloma\" (\"The Fair of the Dove\", set at a \"verbena\" on the night of the Virgin of the Paloma, August 14) ;, by composer Tomás Bretón. This popular piece came about following several years of experiments by its creator.\n\nThe \"género chico\" was to decline in importance with the turn of the 19th century.\n\nThe idea of performances by the hour began in cheap theatres, the \"Teatro del Recreo\" being the first. Whilst the critics were harsh with the genre, it was a great success with the public and was adopted by a few more theatres, to the point where it took over the Variedades theater, which the decline of comic opera had left free, and which was already a venue of some note. But the most important venue associated with the \"género chico\" is the Teatro Apolo, opened in 1873, which, following the crisis in \"zarzuela grande\", began to put on \"género chico\", to overwhelming popular success.\n\nThe Apolo was considered the real bastion of the genre, and very famous because of the popularity of its fourth session, \"la cuarta de Apolo\", which was a night-time performance and was always full of dodgy characters, rogues and tricksters no different from the villains represented on stage.\nOutside of the theatres, the \"género chico\" was also performed in small cafés, and during the summer cheap stages were set up for plays. Indeed, the arguably most important play in the genre, \"La Gran Vía\", was performed in this way.\n\nThe main model for \"género chico\" is the \"sainete lírico\" or one-act lyrical farce, thanks to the successful \"La canción de la Lola\" (\"Lola's Song\") by Chueca and Valverde, in 1880. Although other genres are also utilised, the most important plays follow this model. The \"sainete\", established in its definitive form by Ramón de la Cruz, is the direct heir of the comic interludes or brief farces that were previously so popular. These are essentially short, independent pieces, with music and often dance. The \"género chico\" evolved from this form towards a relatively faithful portrait of everyday Madrid life, in keeping with the abovementioned Realism. However, unlike Realism, which lingers on the darker and murkier aspects of reality, such as poor, marginal sections of society and the violence running through them, the \"género chico\", whilst dealing with low-class neighbourhoods and uneducated people, concentrated on the jollier, picturesque aspects of Madrid, such as the dialect of the characters, and their most jovial facets.\n\nMoreover, as a unique characteristic of the genre, the constant presence of open-air parties, often at night, which appear at the beginning of the plays in order to situate them and at the end as \"dénouement\".\n\nThe plot is very simple, and sometimes barely holds up the play, which then relies on the scenes it creates. In the majority of cases, it consists of a simple love story with the same basic structure: a couple is in love but some outside difficulty prevents them from consummating their love (always, by marrying each other in a happy ending); this difficulty is overcome and the story ends with a public \"dénouement\", a happy ending and an implicit or explicit moral (as well as asking the audience's favour at the very end). Beside this structure, stereotyped characters from the Madrid scene are brought in (Madrid is typically the locale for these plays): the cheeky chappy, the colourful anarchist who avoids making provocative comments, the idler, the scrounger, the flirt, the sententious old geezer. There usually aren't any educated characters; instead, popular folk wisdom is represented.\n\nThe \"género chico\" was always fiercely current: the actors make references (often in the songs, into which extra verses are added) to the outside world, with this \"news\" aspect of the play being even more important than the actual plot. There are mentions of politicians, external events and so forth, all as a way of connecting with an audience of humble culture. To this effect, the unity of what is going on in the play is broken, and the spectator is drawn in with the actors, without actually getting on stage.\n\nThe text is usually in prose, although some of the first plays alternate between parts in prose and in verse. Moreover, the language used is deliberately vulgar, with fashionable expressions and badly-pronounced foreign words and references. Jokes and other semantic aspects were not originally part of the \"sainete\", but were subsequently incorporated by \"quinteros\". The music was then justified by the text: people dancing in the street and suchlike. There is also theatre within theatre, as well as orchestra in the text. All these features aim fundamentally to create contact with the audience.\n\nThere is disagreement regarding the relevance of the music itself. While some writers consider it always subordinate to the text in terms of importance, others such as Ramón Barce have theorised that the music comes first in the composition of the work; incoherent texts, called \"monstruos\" (\"monsters\"), merely gave the librettist a rhythm to which he must fit his words; these words were then often inexpertly fiddled with by the composer). In any case, the music does not usually correspond closely to the action, but rather is something in the background, sometimes coming in unexpectedly.\n\nThe musical part varies greatly in length, the plays with most music being \"Agua, azucarillos y aguardiente\" and \"La verbena de la paloma\". Normally, the plays are preceded by a musical prelude, and occasionally have little intervals or music for dancing, and finish with a short finale in which the music from some previous scene is repeated. There are usually passages read over background music, in \"Singspiel\" style.\n\nThe music is familiar to the ear, popular and traditional, with popular or fashionable melodies of the time being taken and their lyrics changed. The aim is to have the ditty stick in the audience's mind after they leave the theatre. Furthermore, pronounced, popular rhythms are sought in the dance halls, generally imported but \"nationalised\", such as the \"chotis\" (from the German \"Schottisch\", its ultimate origin being in Scotland), and many others, such as boleros, fandangos, or habaneras from Latin America, jotas, seguidillas, soleás, pasacalles, and waltzes, polkas, or mazurcas from Poland.\n\n\nVincent J. Cincotta, Zarzuela: The Spanish Lyric Theatre - A Complete Reference (4th ed. revised), 2011. Wollongong, Australia: University of Wollongong Press, pp. 766, \n"}
{"id": "47904078", "url": "https://en.wikipedia.org/wiki?curid=47904078", "title": "Hariprasad Vyas", "text": "Hariprasad Vyas\n\nHariprasad Maniray Vyas was a Gujarati humorist and author of Children's literature.\n\nHariprasad Vyas was born on 25 May 1904 in Bodka village near Vadodara, Gujarat. He passed matriculation in 1921 in Vadodara. He served as Manager in the office of Zenith Life and General Insurance from 1925 to his retirement. He died on 13 July 1980 in San Jose, California, US.\n\nHariprasad Vyas created several popular fictional characters for children's literature in Gujarati language including Bakor Patel, Shakri Patlani, Vaghjibhai Vakil, Untadiya Doctor, Hathishankar Dhamdhamiya, Bhotvashankar. He wrote humorous stories of Bakor Patel in children's biweekly \"Gandiv\" published by Gandiv Sahitya Madir, Surat from 1936 to 1955. These stories are later published as story collections. His works include Bakor Patel (30 works), Bhejabaj Bhagabhai (6 works), Hathishankar Dhamdhamiya (6 books), Bhotvashankarna Parakramo, Sundar Sundar (6 works), Balvinod, Hasyavinod, Anandvinod. He also published ten collections of children's plays under \"Chalo Bhajavie\" series. He also wrote several humorous essays collected under various titles; \"Hasyazarna\", \"Hasyakillol\", \"Hasyavasant\", \"Kathahasya\", \"Patnini Shodhama\", \"Andhale Behru\", \"Pothimana Ringana\".\n"}
{"id": "14894492", "url": "https://en.wikipedia.org/wiki?curid=14894492", "title": "Harold Innis's communications theories", "text": "Harold Innis's communications theories\n\nHarold Adams Innis (November 5, 1894 – November 8, 1952) was a professor of political economy at the University of Toronto and the author of seminal works on Canadian economic history and on media and communication theory. He helped develop the staples thesis, which holds that Canada's culture, political history and economy have been decisively influenced by the exploitation and export of a series of staples such as fur, fish, wood, wheat, mined metals and fossil fuels. Innis's communications writings explore the role of media in shaping the culture and development of civilizations. He argued, for example, that a balance between oral and written forms of communication contributed to the flourishing of Greek civilization in the 5th century BC. But he warned that Western civilization is now imperiled by powerful, advertising-driven media obsessed by \"present-mindedness\" and the \"continuous, systematic, ruthless destruction of elements of permanence essential to cultural activity.\"\n\nOne of Harold Innis's primary contributions to the field of communications was to apply the dimensions of time and space to various media. He divided media into time-biased and space-biased types. Time-biased media include clay or stone tablets, hand-copied manuscripts on parchment or vellum and oral sources such as Homer's epic poems. These are intended to carry stories and messages that last for many generations, but tend to reach limited audiences. Space-biased media are more ephemeral. They include modern media such as radio, television, and mass circulation newspapers that convey information to many people over long distances, but have short exposure times. While time-biased media favour stability, community, tradition and religion, space-biased media facilitate rapid change, materialism, secularism and empire. Innis elaborated on his distinctions between time-biased and space-biased media in \"Empire and Communications\":\n\nThe concepts of time and space reflect the significance of media to civilization. Media that emphasize time are those durable in character such as parchment, clay and stone. The heavy materials are suited to the development of architecture and sculpture. Media that emphasize space are apt to be less durable and light in character such as papyrus and paper. The latter are suited to wide areas in administration and trade. The conquest of Egypt by Rome gave access to supplies of papyrus, which became the basis of a large administrative empire. Materials that emphasize time favour decentralization and hierarchical types of institutions, while those that emphasize space favour centralization and systems of government less hierarchical in character.\n\nSocieties that depend solely on time-biased media are oral and tribal. Although leadership tends to be hierarchical, time-bound societies may also operate by consensus. Since, in their purest form, time-bound cultures do not rely on written records, they must preserve their traditions in story, song and myth handed down unchanged from one generation to the next. For them memory is of crucial importance; they revere the wisdom of elders and favour concrete over abstract forms of thought. On the other hand, societies that depend on space-biased media such as printed newspapers and books tend to favour abstract thought and control over space. They have little regard for tradition and when compared with oral societies, their ways of thinking are apt to be more rational, linear and impersonal.\n\nThe encounter of European traders from the imperial centres of France and Britain with the aboriginal tribes of North America that Innis chronicled in \"The Fur Trade in Canada\" is a poignant example of what can happen when two different civilizations meet --- one traditional and oriented to preserving its tribal culture in time and the other bent on spreading its influence over long distances. European guns used in war and conquest, for example, enabled the indigenous peoples to hunt more efficiently, but led to the rapid destruction of their food supply and of the beaver they depended on to obtain European goods. Conflicts over hunting territories led to warfare, made more deadly by European bullets. And all this, Innis argued, disturbed the balance that \"...had grown up previous to the coming of the European.\"\n\nHarold Innis examined the rise and fall of ancient empires as a way of tracing the effects of communications media. He looked at media that led to the growth of an empire; those that sustained it during its periods of success, and then, the communications changes that hastened an empire's collapse. He tried to show that media 'biases' toward time or space affected the complex interrelationships needed to sustain an empire. These interrelationships included the partnership between the knowledge (and ideas) necessary to create and maintain the empire, and the power (or force) required to expand and defend it. Innis wrote that the interplay between knowledge and power was always a crucial factor in understanding empire: \"The sword and pen worked together. Power was increased by concentration in a few hands, specialization of function was enforced, and scribes with leisure to keep and study records contributed to the advancement of knowledge and thought. The written record, signed, sealed and swiftly transmitted was essential to military power and the extension of government.\"\n\nInnis warned however, that such generalizations tended to obscure the differences between empires. So, he embarked on specific studies of the civilizations of ancient Egypt, Babylonia and Mesopotamia; as well as of the effects of the oral tradition on Greek civilization and the written tradition on the Roman Empire. His reflections appear in separate chapters in his book \"Empire and Communications\" along with additional chapters on the combined effects of parchment and paper in the Middle Ages, and paper and the printing press in the development of modern societies.\nBiographer John Watson warns against the tendency to apply Innis's concept of media 'bias' in a mechanical or deterministic way. He writes that Innis \"emphasizes, in dealing with \"concrete historical cases\", the necessity of a balance of \"various media\" whose predispositions [or biases] complement each other to make for a successful imperial project.\" Watson points out that for Innis, balance was crucial in sustaining an empire. Innis examined each empire to discover how time-binding and space-binding media contributed to the necessary balance between power and knowledge and among ruling groups – religious, political and military. As Innis himself wrote:\n\nConcentration on a medium of communication implies a bias in the cultural development of the civilization concerned either towards an emphasis on space and political organization or towards an emphasis on time and religious organization. Introduction of a second medium tends to check the bias of the first and to create conditions suited to the growth of empire. The Byzantine empire emerged from a fusion of a bias incidental to papyrus in relation to political organization and of parchment in relation to ecclesiastical organization.\nInnis argued that a balance between the spoken word and writing contributed to the flourishing of ancient Greece in the time of Plato. Plato conveyed his ideas by recording the conversations of Socrates. His philosophy thus preserved \"the power of the spoken word on the written page.\" Plato's method of using poetic dialogues cast in prose enabled him to arrive at new philosophical positions. This balance between the time-biased medium of speech and the space-biased medium of writing was eventually upset, Innis argued, as the oral tradition gave way to the dominance of writing. The torch of empire then passed from Greece to Rome.\n\nIn his 1947 presidential address to the Royal Society of Canada, Innis remarked: \"I have attempted to suggest that Western civilization has been profoundly influenced by communication and that marked changes in communications have had important implications.\" He went on to mention the evolution of communications media from the cuneiform script inscribed on clay tablets in ancient Mesopotamia to the advent of radio in the 20th century. \"In each period I have attempted to trace the implications of the media of communication for the character of knowledge and to suggest that a monopoly or oligopoly of knowledge is built up to the point that equilibrium is disturbed.\" Innis argued, for example, that a \"complex system of writing\" such as cuneiform script resulted in the growth of a \"special class\" of scribes. The long training required to master such writing ensured that relatively few people would belong to this privileged and aristocratic class. As Paul Heyer explains:\nIn the beginning, which for Innis means Mesopotamia, there was clay, the reed stylus used to write on it, and the wedge-shaped cuneiform script. Thus did civilization arise, along with an elite group of scribe priests who eventually codified laws. Egypt followed suit, using papyrus, the brush, and hieroglyphic writing.\n\nIn \"Empire and Communications\", Innis wrote that the ebb and flow of Egypt's ancient empire partly reflected weaknesses or limitations imposed by \"the inflexibility of religious institutions supported by a monopoly over a complex system of writing\":\n\nWriting was a difficult and specialized art requiring long apprenticeship, and reading implied a long period of instruction. The god of writing was closely related to the leading deities and reflected the power of the scribe over religion. The scribe had the full qualifications of a special profession and was included in the upper classes of kings, priests, nobles and generals, in contrast with peasants, fishermen, artisans and labourers. Complexity favoured increasing control under a monopoly of priests and the confinement of knowledge to special classes.\nInnis argued that this priestly or scribal monopoly disturbed the necessary balance between the religious bias toward time and continuity, and the political bias toward space and power. \"A successful empire,\" he wrote, \"required adequate appreciation of the problems of space, which were in part military and political, and of problems of time, which were in part dynastic and biological and in part religious.\" He ended his essay on ancient Egypt by pointing to the imbalance that arose because the priestly monopoly over writing and knowledge supported an emphasis on time and religion, but neglected the political problems inherent in ruling over an empire extended in space.\n\nAccording to Harold Innis, monopolies of knowledge eventually face challenges to their power, especially with the arrival of new media. He pointed for example, to the monasteries that spread throughout Europe after the fall of the Roman Empire. Their monopoly of knowledge depended on their control over the production of the time-binding medium of parchment useful for preserving hand-copied manuscripts written in Latin. Power was vested therefore, in a scribal and literate, religious elite. The largely illiterate laity depended on priests to interpret the scriptures and on image-driven media such as paintings and statues that depicted the central figures in Biblical stories.\n\nBut the space-binding medium of paper imported from China, Innis wrote, facilitated challenges from Islam and later from a rising commercial class. \"Paper supported the growth of trade and cities and of education beyond the control of the monasteries, and in turn of the Church and the cathedrals.\" Paper also supported the rise of vernacular languages reducing Latin's cultural sway.\n\nInnis wrote that the Catholic Church fought to preserve its time-oriented monopoly of knowledge with the Inquisition, but eventually paper achieved even greater power with the invention of the printing press around the middle of the 15th century. Now, the balance shifted decisively in favour of space over time. The Protestant Reformation followed, along with European exploration and empire, the rise of science and the evolution of the nation-state. Characteristically, Innis summarizes the far-reaching implications of the new medium of paper in a single paragraph that starts with the Middle Ages and ends with the modern United States:\n\nThe dominance of parchment in the West gave a bias toward ecclesiastical organization, which led to the introduction of paper, with its bias toward political organization. With printing, paper facilitated an effective development of the vernaculars and gave expression to their vitality in the growth of nationalism. The adaptability of the alphabet to large-scale machine industry became the basis of literacy, advertising and trade. The book as a specialized product of printing and, in turn, the newspaper strengthened the position of language as a basis of nationalism. In the United States, the dominance of the newspaper led to large-scale development of monopolies of communication in terms of space and implied a neglect of problems of time.\n\nHarold Innis's analysis of the effects of communications on the rise and fall of empires led him, in the end, to warn grimly that Western civilization was now facing its own profound crisis. The development of \"mechanized\" communications media such as mass-circulation newspapers had shifted the balance decisively in favour of space and power, over time, continuity and knowledge. Industrial societies cut time into precise fragments suitable to engineers and accountants and Western civilization suffered from an \"obsession with present-mindedness\" that eliminated concerns about past or future. Communications media that transmit information quickly over long distances had upset the balance required for cultural survival. \"The overwhelming pressure of mechanization evident in the newspaper and the magazine,\" Innis wrote, \"has led to the creation of vast monopolies of communication. Their entrenched positions involve a continuous, systematic, ruthless destruction of elements of permanence essential to cultural activity. The emphasis on change is the only permanent characteristic.\"\n\nThe crisis facing the West was worsened, Innis argued, because communications monopolies that ran the media were largely immune from outside challenge. They literally spoke the language of the masses, effectively penetrating popular consciousness and shaping public opinion. American media, with their dependence on advertising and therefore mass appeal, were extremely effective at mobilizing large audiences. Not only were Americans exhorted to buy the newest \"improved\" products, they were also exposed to a barrage of propaganda from political elites. Theodore Roosevelt mastered the newspaper as a communications device, just as his fifth cousin, Franklin D. Roosevelt mastered radio. The news media were also influenced by a large public relations industry that shaped public opinion on behalf of powerful interests.\n\nInnis believed that the overwhelming spatial bias of modern media was heightened in the United States by the development of powerful military technologies, including atomic weapons. The advent of the Cold War led to such an emphasis on military preparedness that the U.S. was placed on a permanent war footing, its economy increasingly dependent on the manufacture of weapons. As Canadian scholar Arthur Kroker writes, \"Innis's political lesson was clear: the United States was now a fully 'space-oriented' society, with no inner coordinating principle and with no organic conception of 'lived tradition,' time, succession or duration which might act as an inner check against the politics of imperialism.\" \n\nBiographer John Watson writes that \"the United States represents to Innis something akin to cultural apocalypse.\" In an essay entitled, \"Technology and Public Opinion in U.S.A,\" Innis concluded that the United States depended on a foreign policy shaped by military power. \"Dependence on organized power and a traditional antipathy to coloured peoples weakens political sensitivity, and lack of experience with problems of continuity and empire threatens the Western world with uncertainty and war.\" Innis was among the first to suggest that the U.S. had lost the balance between power and knowledge essential to its long-term survival. \n\nWestern civilization could only be saved, Innis argued, by recovering the balance between space and time. For him, that meant reinvigorating the oral tradition within universities while freeing institutions of higher learning from political and commercial pressures. In his essay, \"A Plea for Time\", he suggested that genuine dialogue within universities could produce the critical thinking necessary to restore the balance between power and knowledge. Then, universities could muster the courage to attack the monopolies that always imperil civilization.\n\nInfluenced by Innis's communications theories, historian Marshall Poe proposed a theory on the genesis of new media. He proposed that new media are \"pulled\" into existence by organized interests after inventors have already developed the technology, or prototypes of the technology, necessary to support the media. Poe's theory also predicts the effects the media will have on society by considering eight attributes of a medium: accessibility, privacy, fidelity, volume, velocity, range, persistence, and searchability.\n\nMarshall McLuhan, Canadian philosopher, public intellectual and former colleague of Innis at the University of Toronto, also acknowledged Innis's impact on McLuhan's own works, including \"The Gutenberg Galaxy\", and \"Understanding Media\".\n\n"}
{"id": "35719425", "url": "https://en.wikipedia.org/wiki?curid=35719425", "title": "Herman Grimm", "text": "Herman Grimm\n\nHerman Grimm (6 January 1828, in Kassel – 16 June 1901, in Berlin) was a German academic and writer.\n\nGrimm's father was Wilhelm Grimm (1786-1859), and his uncle Jakob Grimm (1785-1863), the philologist compilers of indigenous folk tales (\"Brothers Grimm\"). His other uncle was the painter engraver Ludwig Emil Grimm (1790-1863). Herman Grimm is believed to have had only one (known) child at a young age, Martin Grimm. From 1841 Herman attended the Friedrich Wilhelm Gymnasium in Berlin. He belonged to a clique associated with Bettina von Arnim (1785-1859), wife of the late poet Achim von Arnim (1781-1831), and started publishing drama and novels. He began legal and philological studies at the universities of Berlin and Bonn. \n\nIn 1857 he visited Rome where the artistic circle of Peter von Cornelius brought his interests to art. In 1859, he married Gisela von Arnim (1827-1889), the Arnim's daughter, and published his treatise, \"Die Akademie der Künste und das Verhältniß der Künstler zum Staate\". His short-lived periodical, \"über Künstler und Kunstwerke\" (1864-1867), published many important essays. It also contained some of the first photographic illustrations of art in a magazine. The first volume of his biography of Michelangelo, \"Das Leben Michelangelos\", began appearing in 1868. He wrote his dissertation in 1868 from Leipzig and his habilitation (1870) in Berlin. In 1871 he weighed in on the famous Hans Holbein \"Meyer Madonna\" debate concluding against the sound reasoning of the \"Holbein convention\" of eminent scholars, that the Dresden version was the autograph one. \n\nHe accepted the chair in the newly created discipline of history of art (\"Lehrstuhl für Kunstgeschichte\") in Berlin in 1872 and remained there the rest of his life. Grimm published the first (though incomplete) edition of his popular \"Das Leben Raphaels\" in 1872. Grimm's art history writing is characteristic of the period consolidation of standards following unification of Germany, known as the Gründerzeit. When Friedrich Waagen, for example, criticized in the early issues of the \"Zeitschrift für bildende Kunst\", Goethe's aesthetic taste of some fifty years before, Grimm, the spokesman for the Gründerzeit, took it personally, refuting Waagen effectively point by point. Grimm's \"Beiträge zur deutschen Culturgeschichte\", essays about important cultural personalities, appeared in 1897. Throughout his life his books were popular and his biographies went through numerous editions. At his death he was succeeded by Heinrich Wölfflin. His more famous students included Alfred Lichtwark; Julius Meier-Graefe studied under him but received not a degree.\n\nGrimm's reputation is that of the arch-Romantic, Gründerzeit art historian. He viewed himself as the intellectual successor of Goethe. His approach to art history was through the \"Great Masters\", and arranging significance of art through a biographical account of art history. His tastes both typified and led German and continental bourgeois taste. Homer, Dante and Shakespeare were the great writers of their age; in art, only Raphael and Michelangelo could compare. The nineteenth century's adoration of Raphael is in large part Grimm's doing. Wölfflin wrote that Grimm showed indifference to all but the very great. This approach to art history is shared by other historians of his age, including Carl Justi, but was personally savaged in the lectures of Anton Springer. Grimm was one of the first to carefully study reception theory, though he is little acclaimed for it. In the 3rd edition of his life of Raphael (1896) he added a section on \"Rezeptionsgeschichte\". Perhaps because formal analysis and the sanctity of viewing the original work of art mattered so little to him, he was among the first to use lantern slides (reproductive images) in his lectures. Grimm's writings were gradually supplanted by better scholarship in the twentieth century. His emotional approach to art-historical debate, as evidence in the Holbein Madonna incident, proved his allegiances were usually closer to nationalism than art history. In Germany, his concept of the [German] hero as a mover of history was embraced by the Nazis, who saw to it that new and repackaged versions of his writings, such as \"Vom Geist der Deutschen\" (1943), appeared up until the war's end.\nSchuchhardt, Wolfgang, ed. Vom Geist der Deutschen, Gedanken von Herman Grimm: ein Brevier. Berlin: F. A. Herbig, 1943; Dilly, Heinrich. Kunstgeschichte als Institution: Studien zur Geschichte einer Diziplin. Frankfurt am Main: Suhrkamp, 1979, p. 41 mentioned; Wölfflin, Heinrich. Heinrich Wölfflin, 1864-1945: Autobiographie, Tagebücher und Briefe. Joseph Ganter, ed. 2nd ed. Basel: Schwabe & Co., 1984, p. 492; Bazin, Germain. Histoire de l'histoire de l'art: de Vasari à nos jours. Paris: Albin Michel, 1986, pp. 158, 530-531; Kultermann, Udo. The History of Art History. New York: Abaris, 1993, pp. 126–27, 147; Metzler Kunsthistoriker Lexikon: zweihundert Porträts deutschsprachiger Autoren aus vier Jahrhunderten. Stuttgart: Metzler, 1999, pp. 130–133; Schlink, Wilhelm. \"Herman Grimm (1828-1901): Epigone und Vorläufer.\" in Osinski, Jutta and Saure, Felix, eds. Aspekte der Romantik: zur Verleihung des „Brüder Grimm-Preises“ der Philipps-Universität Marburg im Dezember 1999. Kassel: Brüder-Grimm-Gesellschaft, 2001 pp. 73–93.\nDie Cartons von Peter von Cornelius in den Sälen der Königl. Akademie der Künste zu Berlin. Berlin: Hertz, 1859; Leben Michelangelo's. 2 vols. Hanover: Carl Rümpler, 1860-1863 [and Berlin: Gustav Schade], English, Life of Michael Angelo. Boston: Little, Brown, 1865; \"Ist die moderne Kunstgeschichte eine auf solider Grundlage ruhende Wissenschaft?-- Gründe warum nicht.-- Notwendigkeit einer änderung.\" in, über Künstler und Kunstwerke 1 (1864): 4-8; Die Venus von Milo. Rafael und Michel Angelo: Zwei Essays von Herman Grimm. Boston: De Vries, Ibarra & Co., 1864, partially translated into English, The Venus de Milo. Boston: J. J. Hawes, 1868, collected and republished as, Zehn ausgewählte Essays zur Einführung in das Studium der Neuern Kunst. Berlin: Dümmler, 1871; Über Künstler und Kunstwerke. 2 vols. Berlin: F. Dümmler's Verlagsbuchhandlung, 1865-1867; Albrecht Dürer. Berlin: C. G. Lüderitz, 1866; [Meyer Madonna opinion] \"Die Holbein'sche Madonna.\" Preussische Jahrbücher 28 (1871): 418-31; Das Leben Raphaels von Urbino: italienischer Text von Vasari übersetzt und Commentar. Berlin: F. Dümmler, 1872, [first complete edition, 2nd, 1886, 3rd ed., 1896 contains the chapter on Rezeptionsgeschichte of Raphael], English, The Life of Raphael. Boston: Cupples and Hurd, 1888; The Destruction of Rome: a Letter. Boston: Cupples, Upham, 1886; Beiträge zur deutschen Culturgeschichte. Berlin: W. Herts, 1897; Fragmente. Berlin: W. Spemann, 1900\n"}
{"id": "20625310", "url": "https://en.wikipedia.org/wiki?curid=20625310", "title": "Hozo language", "text": "Hozo language\n\nHozo is an Afroasiatic language spoken mostly in the Kondala woreda of Mirab Welega Zone (Western Oromia) by peoples generically known as \"Mao\". There are smaller groups of Hozo speakers in Mana Sibu woreda. The term Hozo is usually understood by the Mao to refer to a clan. Hozo speakers prefer to call themselves Amo. Hozo and Seze are sometimes called Begi Mao. Hozo is spoken by roughly 3,000 people in Ethiopia. Hozo is also a clan in the Begi area. The Hozo language is also known as Begi-Mao and Mao of Begi. Its classification is Afro-Asiatic, Omotic, and Mao. The word Mao is Omotic and means ‘man; people’, occurring as [ma:ɪ] in Seze and as [mɔ:] in Hozo. Mao is frequently used as an ethnic term. There is a kind of Mao identity across language differences in Ethiopia. While it is generally accepted today that Omotic is one of the primary branches of the Afro-Asiatic family, the position of the four languages Hozo, Seze, Ganza and Northern Mao is still being discussed. The Mao languages are the least documented within Omotic, and Omotic itself is the least documented of the Afroasiatic groups.\n\nThe Omotic Mao languages Seze and Hozo form a compact area in Oromia Regional State surrounded by Oromo speakers on three sides. There seems to be some disagreement amongst the scientists as well as amongst the speakers in how far Seze and Hozo can be classified as two different languages or as dialects of the same language. It has been argued that Seze and Hozo are not two different languages; just two different dialects from village to village. The area where Hozo is predominately spoken appears to be scattered, and there are only a few villages where Hozo is reported as the only Omotic Mao language. Hozo people prefer less permanent forms of settlements for their families and herds. Omotic languages include Anfillo, Ari, Bambassi, Kara, Kefa, Gana, Dime, Nayi, Sheko, Hozo, Yemsa, and Welaytta.\n\nHozo is an Omotic language. Omotic languages are an Ethiopian linguistic group consisting of more than twenty-five distinct languages. Omotic languages developed in the southwestern region near the river Omo, which gave the group its name. Distinct ethnic groups in Ethiopia speak individual languages classified as Omotic.\n\nLargely verbal, the Omotic languages are rarely written down. When they are written, either the Ge’ez (Ethiopic) or Latin alphabet is used, but no standard transliteration from the Ethiopic to the Latin exists. Ge’ez is the ancient language of Ethiopia, which was first introduced as an official written language during the first Aksumite Kingdom between the first and seventh centuries BCE. The earliest known inscriptions of Ge’ez date to the fifth century BCE. Written in horizontal lines from left to right, it was created based on the Sabean/Minean alphabet and is still used by the Ethiopian Orthodox Church in the twenty-first century.\n\nEthiopian languages are classified into four major groups: Semitic, Cushitic, Omotic, and Nilo-Saharan. The Omotic languages are largely verbal and have several defining characteristics: the majority of vocabulary is monosyllabic, and the languages have ten vowel-sounds: five short and five long. Scholars estimate that there are between twenty-five and forty Omotic languages, but the group has not been extensively studied.\n\nAn ongoing debate among linguists exists regarding the inclusion of Omotic languages in the Afro-Asiatic phylum. Experts cannot agree as to whether the system should be labeled as Afro-Asiatic, Nilo-Saharan, or something unique. Until the 1960s, Omotic languages were considered as a west-Cushitic subgrouping.\n\nAfter World War II, efforts began to document Ethiopia’s history; however, much more attention was paid to the northern region, which had many Christian communities, a connection to the Ark of the Covenant, and the rock-hewn churches. Little attention was paid to the southern and southwestern Omo valley. Then a socialist coup in 1974 halted most research and expeditions, leaving vast gaps of knowledge about Omotic speakers and their history. Omotic languages are not well studied.\n\n"}
{"id": "991810", "url": "https://en.wikipedia.org/wiki?curid=991810", "title": "ISO 15924", "text": "ISO 15924\n\nISO 15924, Codes for the representation of names of scripts, defines two sets of codes for a number of writing systems (scripts). Each script is given both a four-letter code and a numeric one.\nScript is defined as \"set of graphic characters used for the written form of one or more languages\". \n\nWhere possible the codes are derived from ISO 639-2 where the name of a script and the name of a language using the script are identical (example: Gujarātī ISO 639 guj, ISO 15924 Gujr). Preference is given to the 639-2 Bibliographical codes, which is different from the otherwise often preferred use of the Terminological codes.\n\n4-letter ISO 15924 codes are incorporated into the Language Subtag Registry for IETF language tags and so can be used in file formats that make use of such language tags. For example, they can be used in HTML and XML to help Web browsers determine which typeface to use for foreign text. This way one could differentiate, for example, between Serbian written in the Cyrillic (codice_1) or Latin (codice_2) script, or mark romanized text as such.\n\nISO has appointed the Unicode Consortium as the Registration Authority (RA) for the standard. In 2004, the RA appointed Michael Everson to act as Registrar. The Registrar works with a Joint Advisory Committee (JAC) in developing and implementing the standard. The JAC contains six members: the Registrar, one member from the Library of Congress, one from Standards Norway, one from the French Encyclopaedia Universalis, an officer of Unicode, and a member of Unicode. These individuals represent the interests of the ISO 15924 RA, the ISO 639-2 RA, ISO Technical Committee 37, ISO Technical Committee 46, and the ISO Coded Character Set Sub-Committee, ISO/IEC JTC1/SC2.\n\n\n\nTwo four letter codes are reserved at the request of the Common Locale Data Repository Project (CLDR):\n\nThis list of codes is from the ISO 15924 standard.\n\nThe following standards are referred to as indispensable by ISO 15924.\n\nFor definition of font and glyph the standard refers to\n\nAround 146 scripts are defined in Unicode. Through a linkpin called \"Property Value Alias\", Unicode has made a 1:1 connection between a script defined, and its ISO 15924 standard. See Script (Unicode).\n\n"}
{"id": "17576792", "url": "https://en.wikipedia.org/wiki?curid=17576792", "title": "Ignatius Noah of Lebanon", "text": "Ignatius Noah of Lebanon\n\nIgnatius Noah of Lebanon, also known as Nuh the Lebanese, was the Patriarch of Antioch, and head of the Syriac Orthodox Church from 1493 until his death in 1509.\n\nNoah was born in 1451 in the village of Baqufa, near Tripoli, into a Maronite family originally from Damascus. At an early age, Noah and his brother converted to miaphysitism, the doctrine of the Syriac Orthodox Church, as a result of missionary work led by Mor Dioscurus, the metropolitan bishop of Syria. Noah undertook a pilgrimage to Jerusalem and was subsequently ordained as a priest by Dioskoros Isa ibn Daw, metropolitan bishop of Jerusalem, at the Monastery of Saint Moses the Abyssinian. Whilst at the monastery, Noah studied the Syriac language and religious sciences under Thomas of Homs. He was later sent by Dioskoros Isa ibn Daw to preach amongst the Maronites in the Lebanese mountains.\n\nIn 1480, Noah was ordained metropolitan of Homs by Ignatius John XIV, Patriarch of Antioch, upon which he took the name Cyril. Noah continued his work amongst the Maronite communities of Lebanon and converted many priests and their congregations. He was later ordained the Maphrian of the East by Ignatius John XIV in 1489, thereafter assuming the name Basilius, and held this office until his election and consecration as Patriarch of Antioch, the head of the Syriac Orthodox Church, in 1493. Noah adopted the name Ignatius, after St. Ignatius of Antioch, thus following the tradition established by Ignatius Behnam Hadliyo, Patriarch of Antioch.\n\nAs patriarch, a dispute emerged between Noah and Ignatius Mas'ud of Zaz, Patriarch of Tur Abdin, over the consecration of a certain Abraham as the metropolitan bishop of Ma'dan. Both Mas'ud and Noah had consecrated their candidates as metropolitan bishop of Ma'dan despite the location of Ma'dan, which was outside of the jurisdiction of the patriarchate of Tur Abdin. Pope John XIII of Alexandria, the head of the Coptic Orthodox Church, joined Noah in condemning Mas'ud, however, advised conciliation and unity in a letter to Noah. During his tenure as patriarch, Noah ordained thirteen bishops before his death at Hama on 28 July 1509.\n\nNoah is known to have also been a writer and poet and several surviving works are attributed to him. He produced a 92-page anthology containing a number of odes and a eulogy to Thomas of Homs, his former tutor. The patriarch is known to have written a very brief history of the church as well as theological works in Arabic and Syriac.\n\n"}
{"id": "31217937", "url": "https://en.wikipedia.org/wiki?curid=31217937", "title": "Isanzu language", "text": "Isanzu language\n\nIsanzu is a Bantu language of spoken by the Isanzu people south of Lake Eyasi in Tanzania.\n\nThe position of Isanzu within the Bantu family is uncertain. It is rather distinct in certain features from other Bantu languages of the area, such as Nyaturu, but is quite close in others. One easily recognizable feature is /h/ in words where neighboring languages have /s/ or /tʃ/, as in the name Isanzu ~ \"Ihanzu\", a feature it shares with Iramba, and a reason it is commonly classified with Iramba.\n"}
{"id": "43368740", "url": "https://en.wikipedia.org/wiki?curid=43368740", "title": "Jan van Steenbergen", "text": "Jan van Steenbergen\n\nJohannes Hendrik \"Jan\" van Steenbergen (born June 3, 1970) is a Dutch linguist, journalist, translator and interpreter. He is known for being the author of several constructed languages, notably Interslavic and Wenedyk.\n\nHe was born in Hoorn, where he spent most of his childhood. In 1988 he became a student at the Amsterdam University, where he graduated in East European Studies with major topics in Slavistics and musicology. He continued his studies in Poland at Warsaw University and worked at the Warsaw Autumn festival for contemporary music. In 1997, he became a Polish translator and interpreter in the Netherlands.\n\nIn 1996, he started working on an artificial North Slavic language, \"Vuozgašchai\" (Vozgian), and in 2002 he created another language, Wenedyk, a reconstruction of what Polish might have looked like if it had been influenced by Vulgar Latin. In 2006, he was one of the initiators of the Pan-Slavic language Slovianski (later renamed Interslavic), as well as the coordinator of a project for the creation of an electronic Interslavic dictionary. In November 2013, he was awarded the Josef Dobrovský medal for his 'contributions to Slavic culture and science'. In 2018 he also received the medal \"The Living Word\" of the Khovansky Foundation.\n\nVan Steenbergen lives in IJmuiden. He is married and has three children.\n\n"}
{"id": "4751006", "url": "https://en.wikipedia.org/wiki?curid=4751006", "title": "Jean-Joseph de Mondonville", "text": "Jean-Joseph de Mondonville\n\nJean-Joseph de Mondonville (25 December 1711 (baptised) – 8 October 1772), also known as Jean-Joseph Cassanéa de Mondonville, was a French violinist and composer. He was a younger contemporary of Jean-Philippe Rameau and enjoyed great success in his day. Pierre-Louis Daquin (son of the composer Louis-Claude Daquin) claimed: \"If I couldn't be Rameau, there's no one I would rather be than Mondonville\".\n\nMondonville was born in Narbonne in Occitania (South France) to an aristocratic family which had fallen on hard times. In 1733 he moved to Paris where he gained the patronage of the king's mistress Madame de Pompadour and won several musical posts, including violinist for the Concert Spirituel.\n\nHis first opus was a volume of violin sonatas, published in 1733. He became a violinist of the Chapelle royale and chamber and performed in some 100 concerts; some of his \"grands motets\" were also performed that year receiving considerable acclaim. He was appointed \"sous-maître\" in 1740 and then, in 1744, intendant of the Royal Chapel. He produced operas and grands motets for the Opéra and Concert Spirituel respectively, and was associated with the Théatre des Petits-Cabinets, all the while maintaining his career as a violinist throughout the 1740s. In 1755, he became director of the Concert Spirituel on the death of Pancrace Royer. Mondonville died in Belleville near Paris at the age of sixty.\n\nBetween 1734 and 1755 Mondonville composed 17 \"grands motets\", of which only nine have survived. The motet \"Venite exultemus domino\", published in 1740, won him the post of \"Maître de musique de la Chapelle\" (Master of Music of the Chapel). Thanks to his mastery of both orchestral and vocal music, Mondonville brought to the grand motet—the dominant genre of music in the repertory of the \"Chapelle royale\" (Royal Chapel) before the French Revolution—an intensity of colour and a dramatic quality hitherto unknown. In 1758, Mondonville introduced oratorios as a new genre at the Concert Spirituel.\n\nAlthough Mondonville's first stage work, \"Isbé\", was a failure, he enjoyed great success with the lighter forms of French Baroque opera: the \"opéra-ballet\" and the \"pastorale héroïque\". His most popular works were \"Le carnaval de Parnasse\", \"Titon et l'Aurore\" and \"Daphnis et Alcimadure\" (for which Mondonville wrote his own libretto in Languedocien - his native Occitan dialect). \"Titon et l'Aurore\" played an important role in the Querelle des Bouffons, the controversy between partisans of French and Italian opera which raged in Paris in the early 1750s. Members of the \"French party\" ensured that \"Titon\"'s premiere was a resounding success (their opponents even alleged they had guaranteed this result by packing the Académie Royale de Musique, where the staging took place, with royal soldiers). Mondonville's one foray into serious French opera - the genre known as \"tragédie en musique\" - was a failure however. He took the unusual step of re-using a libretto, \"Thésée\", which had originally been set in 1675 by the \"father of French opera\", Jean-Baptiste Lully. Mondonville's bold move to substitute Lully's much-loved music with his own did not pay off. The premiere at the court in 1765 had a mixed reception and a public performance two years later ended with the audience demanding it be replaced by the original. Yet Mondonville was merely ahead of his time; in the 1770s, it became fashionable to reset Lully's tragedies with new music, the most famous example being \"Armide\" by Gluck.\n\n\n\nMondonville's nine surviving \"grands motets\" are:\n\n\nMondonville's three oratorios (none survive) were:\n\n\n\n"}
{"id": "3179416", "url": "https://en.wikipedia.org/wiki?curid=3179416", "title": "Joint issue", "text": "Joint issue\n\nA joint issue is the release of stamps or postal stationery by two or more countries to commemorate the same topic, event or person. Joint issues typically have the same first day of issue and their design is often similar or identical, except for the identification of country and value.\n\n\n\nThe Australian Post Office has collaborated several times with the postal administration of another country to release a joint issue.\n\nThe Austria Post Office has collaborated several times with the postal administration of other countries to release joint issues.\n\nThe Belgium Post Office has collaborated several times with the postal administration of other countries to release joint issues.\n\nBulgarian Posts of the Republic of Bulgaria have released the following joint issues:\n\nCanada Post has released the following joint issues. The United States Postal Service has been Canada Post's most prolific philatelic partner.\n\nThe Cyprus Postal Services of the Republic of Cyprus has released the following joint issues.\n\nČeská pošta of the Czech Republic has released the following joint issues.\nPost Danmark has collaborated a number of times with other postal administration to release joint issues.\n\nThe Estonian Post Office has collaborated a number of times with other postal administration to release joint issues.\n\nPosti has collaborated a number of times with other postal administration to release joint issues.\n\nThe French Post Office has collaborated with the postal administration of other countries to release several joint issues.\n\nDeutsche Post, and its predecessor Deutsche Bundespost prior to German reunification in 1990, collaborates with the postal administrations of other countries to release joint issues on a regular basis.\n\nHellenic Post (ELTA) begun releasing joint issues with other countries in 1999.\n\nPost Greenland has collaborated a number of times with other postal administration to release joint issues.\n\nMagyar Posta has collaborated a number of times with other postal administration to release joint issues.\n\nÍslandspóstur has collaborated a number of times with other postal administration to release joint issues.\n\nIndia Post has collaborated a number of times with the postal administration of other countries to release a joint issue.\nIran Post has collaborated a number of times with the postal administration of other countries to release a joint issue.\n\nThe Irish Post Office has collaborated several times with the postal administration of another country to release a joint issue.\n\nIsrael Post has collaborated a number of times with other postal administration to release a joint issue.\n2001 Georgia Shota Rustaveli, Georgian national poet 3Sep2001\n\n2010 Austria Simon Wiesenthal, Nazi hunter 14Jun2010\n\n2010 Vatican City Pope's visit to Israel 15Nov2010\n\n2013 Australia Battle of Beersheba in WW I 16May2013\n\n2013 Greenland Endangered species 11Jun2013\n\n2013 Uruguay Jose Gurvich, \"The Annunciation of Sarah\" 29Oct2013\n\n2014 Thailand 60 Years of Friendship Mangosteen & pomegranate 6May2014\n\n2014 Ecuador Orchids (Stamp never issued by Ecuador) 14Dec2014\n\n2015 Philippines Philippine rescue of Jews in Holocaust 27Jan2015\n\n2015 Germany 50 Years Diplomatic Relations 5Jul2015\n\n2015 Vatican City Church of the Holy Sepulchre, Jerusalem 2Sep2015\n\n2016 Greece 25 Years Diplomatic Relations 9Feb2016\n\n2016 Spain 30 years of diplomatic relations Bridge of Strings, Jerusalem 19Apr2016\n\n2016 Bulgaria Bird Migration 13Sep2016\n\n2017 Portugal Dolphin research 4Apr2017\n\n2017 Croatia 20 years of diplomatic relations Flowers 4Sep2017\n\n2017 Russia Gorny Convent, Ein Karem, Israel 14Nov2017\n\nJapan Post has collaborated a number of times with the postal administration of other countries to release a joint issue.\n\nLatvijas Pasts has collaborated a number of times with other postal administration to release a joint issue.\n\nLithuania Post has collaborated a number of times with other postal administration to release a joint issue.\n\nMaltaPost has collaborated a number of times with other postal administration to release a joint issue.\n\nCorreos de México, the national postal service of Mexico, has collaborated a number of times with the postal administration of other countries to release a joint issue.\n\nMongol Post, the national postal service of Mongolia, has collaborated with some postal administration of other countries to release a joint issue.\n\nPosten Norge has collaborated a number of times with other postal administration to release joint issues.\n\nPakistan Post has collaborated with other countries to release several joint issues.\n\nSerpost, the national postal service of Peru, has collaborated with some postal administration of other countries to release a joint issue.\n\nPhilippine Postal Corporation, the national postal service of the Philippines, has collaborated with some postal administration of other countries to release a joint issue.\n\nRussian Post has collaborated a number of times with other postal administration to release a joint issue.\n\nPošta Slovenije has collaborated a number of times with other postal administration to release a joint issue.\n\nSouth African Post Office has collaborated with some postal administration of other countries to release a joint issue.\n\nKorea Post has collaborated a number of times with the postal administration of other countries to release a joint issue, mainly commemorating diplomatic relations.\n\nPosten AB has collaborated a number of times with other postal administration to release a joint issue.\n\nThe United States Postal Service collaborates with the postal administration of another country to release a joint issue on a sporadic basis. With seven joint issues, Sweden is the most prolific philatelic partner of the United States.\n\n"}
{"id": "1436254", "url": "https://en.wikipedia.org/wiki?curid=1436254", "title": "Linguistic Data Consortium", "text": "Linguistic Data Consortium\n\nThe Linguistic Data Consortium is an open consortium of universities, companies and government research laboratories. It creates, collects and distributes speech and text databases, lexicons, and other resources for linguistics research and development purposes. The University of Pennsylvania is the LDC's host institution. The LDC was founded in 1992 with a grant from the Advanced Research Projects Agency (DARPA), and is partly supported by grant IRI-9528587 from the Information and Intelligent Systems division of the National Science Foundation. The director of LDC is Mark Liberman and the Executive Director is Christopher Cieri.\n\n\n"}
{"id": "37192174", "url": "https://en.wikipedia.org/wiki?curid=37192174", "title": "Luimbi language", "text": "Luimbi language\n\nLuimbi (Lwimbi) is a minor Bantu language of Angola. \n"}
{"id": "38541891", "url": "https://en.wikipedia.org/wiki?curid=38541891", "title": "Malango language", "text": "Malango language\n\nMalango is a Southeast Solomonic language of Guadalcanal.\n\n"}
{"id": "1207755", "url": "https://en.wikipedia.org/wiki?curid=1207755", "title": "Monogastric", "text": "Monogastric\n\nA monogastric organism has a simple single-chambered stomach, compared with a ruminant organism, like a cow, goat, or sheep, which has a four-chambered complex stomach. Examples of monogastric animals include omnivores such as humans, rats, dogs and pigs, carnivores such as cats, and herbivores such as horses and rabbits. Herbivores with monogastric digestion can digest cellulose in their diets by way of symbiotic gut bacteria. However, their ability to extract energy from cellulose digestion is less efficient than in ruminants. \n\nHerbivores digest cellulose by microbial fermentation. Monogastric herbivores which can digest cellulose nearly as well as ruminants are called hindgut fermenters, while ruminants are called foregut fermenters. These are subdivided into two groups based on the relative size of various digestive organs in relationship to the rest of the system: colonic fermenters tend to be larger species such as horses and rhinos, and cecal fermenters are smaller animals such as rabbits and rodents. Great apes (other than humans) derive significant amounts of phytanic acid from the hindgut fermentation of plant materials.\n\nMonogastrics cannot digest the fiber molecule cellulose as efficiently as ruminants, though the ability to digest cellulose varies amongst species.\n\nA monogastric digestive system works as soon as the food enters the mouth. Saliva moistens the food and begins the digestive process. (Note that horses have no (or negligible amounts of) amylase in their saliva). After being swallowed, the food passes from the esophagus into the stomach, where stomach acid and enzymes help to break down the food. Bile salts are stored in the gall bladder (note that horses do not have a gall bladder and bile is directly secreted into the small intestine) and secreted once the contents of the stomach have reached the small intestines where most fats are broken down. The pancreas secretes enzymes and alkali to neutralize the stomach acid.\n"}
{"id": "10950359", "url": "https://en.wikipedia.org/wiki?curid=10950359", "title": "Moorsom System", "text": "Moorsom System\n\nThe Moorsom System is a method created in Great Britain of calculating the tonnage or cargo capacity of sailing ships as a basis for assessing harbour and other vessel fees. It was put into use starting in 1849 and became British law in 1854.\n\nPrevious methods of calculating tonnage, as Builder's Old Measurement, were not being consistently applied and, because they were designed for sailing ships, could not be applied appropriately or fairly for steamships. Substantial portions of a steamship were required for boilers, machinery and coal, thus limiting the proportion of the ship's space available for cargo.\n\nIn 1849, Great Britain appointed a Commission with Admiral George Moorsom as secretary to resolve these problems. The Commission determined that fees should be proportional to the earning capacity of the ship, whether for cargo or passengers. \n\nThe result was called The Moorsom System, which set forth the rules for the measurement of the internal volume of entire ship.\n\nThe Commission sought to avoid a significant change in the fees charged to an existing vessel when the new system was implemented.\n\nGeorge Moorsom ordered the entire fleet of British merchant ships to be measured according to the new System and then divided the total gross tonnage by the total registered tonnage.\n\nThe result was per gross ton, which was rounded to per ton.\n\nWhile the rules for measuring ships changed over the years, the standard of per ton remained in effect until a new system was established by The International Convention on the Tonnage Measurement of Ships, effective for new ships in July 1982.\n"}
{"id": "43025777", "url": "https://en.wikipedia.org/wiki?curid=43025777", "title": "Narayan Athawale", "text": "Narayan Athawale\n\nNarayan Athawale (1932–2011) was a leader of Shiv Sena and a member of Lok Sabha elected from Mumbai North Central. He was a writer and trade unionist. He was also the president of Mumbai Marathi Patrakar Sangh in 1972.\n"}
{"id": "33151978", "url": "https://en.wikipedia.org/wiki?curid=33151978", "title": "Ndut language", "text": "Ndut language\n\nNdut (\"Ndoute\") is a Cangin language of Senegal. \"Ethnologue\" reports that it is 84% cognate (and 55% intelligible) with Palor, essentially a divergent dialect, and 68% cognate with the other Cangin languages.\n"}
{"id": "35052736", "url": "https://en.wikipedia.org/wiki?curid=35052736", "title": "Nsei language", "text": "Nsei language\n\nKenswei Nsei (Kensense), also Nsei or Mesing (Bamessing), is a Grassfields Bantu language of Cameroon.\n"}
{"id": "354374", "url": "https://en.wikipedia.org/wiki?curid=354374", "title": "Parallel text", "text": "Parallel text\n\nA parallel text is a text placed alongside its translation or translations. Parallel text alignment is the identification of the corresponding sentences in both halves of the parallel text. The Loeb Classical Library and the Clay Sanskrit Library are two examples of dual-language series of texts. Reference Bibles may contain the original languages and a translation, or several translations by themselves, for ease of comparison and study; Origen's Hexapla (Greek for \"sixfold\") placed six versions of the Old Testament side by side. The most famous example is the Rosetta Stone.\n\nLarge collections of parallel texts are called parallel corpora (see text corpus). Alignments of parallel corpora at sentence level are prerequisite for many areas of linguistic research. \nDuring translation, sentences can be split, merged, deleted, inserted or reordered by the translator. This makes alignment a non-trivial task.\n\nFour main corpora types can be distinguished.\n\nA \"noisy parallel corpus\" contains bilingual sentences that are not perfectly aligned or have poor quality translations. Nevertheless, most of its contents are bilingual translations of a specific document.\n\nA \"comparable corpus\" is built from non-sentence-aligned and untranslated bilingual documents, but the documents are topic-aligned.\n\nA \"quasi-comparable corpus\" includes very heterogeneous and non-parallel bilingual documents that may or may not be topic-aligned.\n\nThe rarest parallel corpora are corpora that contain translations of the same document into two or more languages, aligned at the sentence level at least.\n\nLarge corpora used as training sets for machine translation algorithms are usually extracted from large bodies of similar sources, such as databases of news articles written in the first and second languages describing similar events.\n\nHowever, extracted fragments may be noisy, with extra elements inserted in each corpus. Extraction techniques can differentiate between bilingual elements represented in both corpora and monolingual elements represented in only one corpus in order to extract cleaner parallel fragments of bilingual elements. Comparable corpora are used to directly obtain knowledge for translation purposes. High-quality parallel data is difficult to obtain, however, especially for under-resourced languages.\n\nIn the field of translation studies a bitext is a merged document composed of both source- and target-language versions of a given text.\n\nBitexts are generated by a piece of software called an \"alignment tool\", or a \"bitext tool\", which automatically aligns the original and translated versions of the same text. The tool generally matches these two texts sentence by sentence. A collection of bitexts is called a \"bitext database\" or a \"bilingual corpus\", and can be consulted with a search tool.\n\nThe concept of the \"bitext\" shows certain similarities with that of the translation memory. Generally, the most salient difference between a bitext and a translation memory is that a translation memory is a database in which its segments (matched sentences) are stored in a way that is totally unrelated to their original context; the original sentence order is lost. A bitext retains the original sentence order. However, some implementations of translation memory, such as Translation Memory eXchange (TMX), a standard XML format for exchanging translation memories between computer-assisted translation (CAT) programs, allow preserving the original order of sentences.\n\nBitexts are designed to be consulted by a human translator, not by a machine. As such, small alignment errors or minor discrepancies that would cause a translation memory to fail are of no importance.\n\nIn his original 1988 article, Harris also posited that bitext represents how translators hold their source and target texts together in their mental working memories\nas they progress. However, this hypothesis has not been followed up.\n\n\n\n\n"}
{"id": "36399843", "url": "https://en.wikipedia.org/wiki?curid=36399843", "title": "Pomoz Bog", "text": "Pomoz Bog\n\nPomoz Bog () or Pomaže Bog (Помаже Бог) is a traditional Serbian greeting used by Serbs. It literally means \"God helps\" but is considered the equivalent to \"hello\" or \"good day\" in English.\n\n"}
{"id": "3887450", "url": "https://en.wikipedia.org/wiki?curid=3887450", "title": "Postage stamp demonetization", "text": "Postage stamp demonetization\n\nThe demonetization of postage and revenue stamps is the process by which the stamps are rendered no longer valid. In general, stamp demonetization is a rare event, since any unused stamp is effectively equivalent to its face value, and there is no financial disadvantage if postal customers use old stamps on their mail. Demonetization chiefly occurs in connection with major upheavals in the postal system, such as a transfer from one country to another, or currency changes, such as decimalisation, or a change of government. The process of exchanging millions or billions of stamps in the public's hands, plus that of exchanging post office stock, is usually complicated and difficult, and offers much interest for students of postal history.\n\nThere are typically two parts to the process; first, the exchange of unused stamps for new ones of equivalent value. This normally occurs at post offices, with patrons bringing in their old stamps. The second part is the handling of mail with stamps already on it. Uncancelled letters, such as those dropped in mailbox, will get a grace period, ending at roughly the same time as the exchange of old stamps. Cancelled letters already in the mailstream may be accepted for a longer period, since remote post offices may not yet have exchanged their stamps, and sometimes there may be delays within the postal system itself.\n\nIn the Eurozone, some countries have demonetized stamps denominated in the old currency while others have not. The countries where pre-euro stamps are still valid include Belgium, France, Italy and San Marino.\n\nAustrian stamps denominated in schillings were demonetized on 1 July 2002.\n\nFinnish stamps denominated in marks were demonetized at the end of 2011.\n\nGerman stamps denominated in Deutsche Marks were demonetized on 1 July 2002. All stamps issued since 9 November 2000 are valid for postage.\n\nIrish stamps denominated in pounds were demonetized on 31 December 2002. Stamps issued since 2 August 2000 are valid for postage.\n\nIn Malta, all stamps denominated in Maltese pounds were demonetized in 2008. All stamps issued since 29 December 2006 are valid for postage. Mail franked with older stamps is marked STAMP NOT VALID and postage due is charged.\n\nStamps of the Netherlands denominated in guilders were demonetized on 1 November 2013. It is not possible to exchange guilder stamps for ones denominated in euros.\n\nPortuguese stamps denominated in escudos were demonetized in 2002. All stamps issued since 15 March 1999 are valid for postage.\n\nSpanish stamps denominated in pesetas were demonetized in 2002. All stamps issued since 8 January 2001 are valid for postage.\n\nStamps of the Vatican City denominated in lire are no longer valid for postage.\n\nThe six self-governing Australian colonies that formed the Commonwealth of Australia on 1 January 1901 operated their own postal service and issued their own stamps. Under section 51(v) of the Commonwealth of Australia Constitution 1900, “postal, telegraphic, telephonic, and other like services” became a Commonwealth responsibility.\n\nThe Commonwealth's Postmaster-General's Department became effective on 1 March 1901 (this agency would be disaggregated on 1 July 1975 in part into the Australian Postal Commission trading as Australia Post). All then-current colony stamps which continued on sale became de facto Commonwealth stamps. Some of these stamps continued to be used for some time following the introduction in 1913 of the Commonwealth's uniform postage stamp series. These stamps continued to be valid for postage until 14 February 1966 when the introduction of decimal currency made all stamps bearing the earlier currency invalid for use.\n\nIn Hong Kong postage stamps have been demonetized only once, which happened because of the 1997 handover. The postage stamps from before 1997 bear the portrait of the King/Queen of the United Kingdom (who at the time of handover was Queen Elizabeth II). Although there was already a series of politically neutral stamps issued (which did not bear the portrait of Queen Elizabeth II nor the words \"Hong Kong, China\", which appear on today's Hong Kong stamps) during the period of handover, Hongkong Post decided to let the old stamps bearing the portrait of Queen Elizabeth II be used for a few more years after the handover since there were some old stamps in the hands of Hong Kong people. Hong Kong people can also exchange those old stamps for new ones if they desire. After the transition period, those old stamps bearing the portrait of the King/Queen of the United Kingdom were declared invalid and hence demonetized. The politically neutral stamps were not demonetized however. All stamps issued now bear the word \"Hong Kong, China\", as required by Basic Law. As a side note, the Hong Kong dollar coins/notes that bear the portrait of the King/Queen of the United Kingdom were never demonetized, however they will not be recirculated when the banks receive them, primarily because of their old age rather than sovereignty issue.\n\nThe country of Poland has a very recent example of demonetization involving the stamp issues of 1990 to 1994. During this period of time, the face values of stamps due to hyperinflation gradually changed the face values to thousands of złoty. Commemorative stamp issues from 1995 to 1997 are also demonetized now as are certain selected issues as announced by the Polish Post Office.\n\nWhen a newer stamp issue is demonetized a date is announced; however, if a postal patron in a small town has not been notified of the demonetization or a postal patron does not visit their local Post Office often, then Polish Post Office will accept their obsolete stamps for letter franking well after the demonetization date.\n\nIn the United Kingdom, earlier issues have been demonetized on several occasions. The first when stamps issued during the reigns of Queen Victoria and King Edward VII (issued 1840 to 1911) were declared no longer valid for postage. The second, early in 1970, when the stamps issued during the reigns of King George V, King Edward VIII and King George VI (issued 1911 to 1952) ceased to be valid and the third some months after the introduction in 1971 of decimal currency, when all stamps with pre-decimalization values were demonetized. Queen Elizabeth II £1 value stamps issued prior to 1971 are identifiable by design but remain valid for postage.\n\nUnited States postage stamps have been demonetized only twice. The first time was in 1851, when the 5-cent and 10-cent stamps of the 1847 issue were declared invalid as of July 1 by the Act of March 3, 1851 reducing the normal letter rate from five to three cents. A few dozen covers are known that carry 1847 stamps after the demonetization date; as stamp usage was then still optional (it would not be made mandatory until 1855), the demonetization seems to have had relatively little impact.\n\nThe second, more serious, demonetization was prompted by the outbreak of the American Civil War in 1861. Southern post offices held substantial U.S. assets in the form of their stamp stocks, and the Confederates could theoretically have brought in some income by selling those stamps to private individuals in the North. Although in April 1861 John H. Reagan, postmaster of the CSA, ordered the offices in his charge to return their stamps to Washington D.C., few seem to have done so, and by June 1861 U.S. postmaster-general Montgomery Blair ordered the severance of postal ties and the production of new stamps. In August the stamps of the U.S. 1861 issue began to be distributed throughout the Union, along with orders that postmasters should offer to exchange old stamps for new for a period of six days after giving \"public notice through the newspapers and otherwise\". After the six-day period was over, that post office was not to recognize the old stamps as paying postage. In addition, postmasters were to accept letters with old stamps from other post offices until set dates, ranging from September 10 in the East, to November 1 from letters arriving from the Far West. (Later the periods were extended for an additional two months.) The process stretched over some months; the large cities in the East were exchanging stamps in the third week of August, while some small remote offices did not start until November.\nGeneral confusion, combined with exhaustion of the new stamps at some post offices, led to some instances of the old stamps still being accepted on letters after demonetization, although surviving covers are rare.\n\nThe U.S. stamps of 1861, and all issued since then, continue to be valid on mail.\n"}
{"id": "53480676", "url": "https://en.wikipedia.org/wiki?curid=53480676", "title": "Probabilistic Action Cores", "text": "Probabilistic Action Cores\n\nPRAC (Probabilistic Action Cores) is an interpreter for natural-language instructions for robotic applications developed at the Institute for Artificial Intelligence at the University of Bremen, Germany, and is supported in parts by the European Commission and the German Research Foundation (DFG).\n\nThe ultimate goal of the PRAC system is to make knowledge about everyday activities from websites like wikiHow available for service robots, such that they can autonomously acquire new high-level skills by browsing the Web. PRAC addresses the problem that natural language is inherently vague and unspecific. To this end, PRAC maintains probabilistic first-order knowledge bases over semantic networks represented in Markov logic networks. As opposed to other semantic learning initiatives like NELL or IBM's Watson, PRAC does not aim at answering questions in natural language, but to disambiguate and infer information pieces that are missing in natural-language instructions, such that they can be executed by a robot. \"This problem formulation is substantially different to the problem of text understanding for question answering or machine translation. In those reasoning tasks, the vagueness and ambiguity of natural-language expressions can often be kept and translated into other languages. In contrast, robotic agents have to infer missing information pieces and disambiguate the meaning of the instruction in order to perform the instruction successfully.\" In addition to probabilistic relational models, PRAC uses the principles of analogical reasoning and instance-based learning to infer completions of roles in semantic networks.\n\nPRAC has been successfully applied to teach robots to conduct chemical experiments and to make pancakes and pizza from wikiHow articles.\n\n"}
{"id": "3415272", "url": "https://en.wikipedia.org/wiki?curid=3415272", "title": "Proto-Afroasiatic language", "text": "Proto-Afroasiatic language\n\nThe Proto–Afroasiatic language is the reconstructed proto-language from which all modern Afroasiatic languages are descended. Though estimations vary widely, it is believed by scholars to have been spoken as a single language around 12,000 to 18,000 years ago. As Afroasiatic is the oldest established language family in the world, the reconstruction of Proto-Afroasiatic is problematic and remains largely lacking. Moreover, there is no consensus as to where the Afroasiatic Urheimat, the homeland of Proto-Afroasiatic speakers, was located.\n\nReconstructed words for fauna and flora and evidence of linguistic contact with language families known to have been spoken in Eurasia suggest that its home was in the Middle East, probably the Levant. Some geneticists and archaeologists have argued for a back migration of proto-Afroasiatic speakers from Western Asia to Africa as early as the 10th millennium BC. They suggest the Natufian culture might have spoken a proto-Afroasian language just prior to its disintegration into sub-languages. The hypothesis is supported by the Afroasiatic terms for early livestock and crops in both Anatolia and Iran. Evidence of Cushitic being formerly spoken in the south of Arabia also speaks for a Middle Eastern origin, but some proposals also claim Northern Africa or the Horn of Africa.\nThe following table shows consonant correspondences in Afroasiatic languages, as given in Dolgopolsky (1999), along with some reconstructed consonants for Proto-Afroasiatic.\n\n\nNOTE:\n\n reconstructs the following pronouns, most of which are supported by at least five of the six branches:\n\n reconstructs the following cardinal numbers (Ehret does not include Berber in his reconstruction):\n\nThe first root for \"two\" has been compared to Berber (Tamazight) \"sin\". There are other proposed cognate sets:\n\n\n\n\n\n"}
{"id": "11068520", "url": "https://en.wikipedia.org/wiki?curid=11068520", "title": "Proto-Oceanic language", "text": "Proto-Oceanic language\n\nProto-Oceanic (abbr. \"POc\") is a proto-language that language comparatists since Otto Dempwolff have proposed as the probable common ancestor to the group of Oceanic languages. Proto-Oceanic is itself an Austronesian language and so therefore a descendant of the Proto-Austronesian language (PAN), the common ancestor of the Austronesian languages.\n\nProto-Oceanic was probably spoken about 4200 years ago, in the Bismarck Archipelago, east of Papua New Guinea. Archaeologists and linguists currently agree that its community more or less coincides with the Lapita culture.\n\nThe methodology of comparative linguistics, together with the relative homogeneity of Oceanic languages, make it possible to reconstruct with reasonable certainty the principal linguistic properties of their common ancestor, Proto-Oceanic. Like all scientific hypotheses, these reconstructions must be understood as obviously reflecting the state of science at a particular moment in time; the detail of these reconstructions is still the object of much discussion among Oceanicist scholars.\n\nThe phonology of POc can be reconstructed with reasonable certainty.\nProto-Oceanic had five vowels: *i, *e, *a, *o, *u, with no length contrast. \n\nTwenty-three consonants are reconstructed. When the conventional transcription of a protophoneme differs from its value in the IPA, the latter is indicated:\n\nMany Oceanic languages of New Guinea, Vanuatu, the Solomon Islands, and Micronesia are SVO, or verb-medial, languages. SOV, or verb-final, word order is considered to be typologically unusual for Austronesian languages, and is only found in some Oceanic languages of New Guinea and to a more limited extent, the Solomon Islands. This is because SOV word order is very common in some non-Austronesian Papuan languages in contact with Oceanic languages. In turn, most Polynesian languages, and several languages of New Caledonia, have the VSO word order. Whether Proto-Oceanic had SVO or VSO is still debatable.\n\n\n"}
{"id": "607301", "url": "https://en.wikipedia.org/wiki?curid=607301", "title": "Pseudo-Philo", "text": "Pseudo-Philo\n\nPseudo-Philo is the name commonly used for the unknown, anonymous author of Biblical Antiquities. This text is also commonly known today under the Latin title Liber Antiquitatum Biblicarum (Book of Biblical Antiquities), a title that is not found, per se, on the Latin manuscripts of Pseudo-Philo's Biblical Antiquities. Pseudo-Philo’s Biblical Antiquities \"is\" preserved today in 18 complete and 3 fragmentary Latin manuscripts that date between the eleventh and fifteenth centuries CE. In addition, portions of Pseudo-Philo's Biblical Antiquities parallel material also found in the \"Chronicles of Jerahmeel\", a 14 century Hebrew composition. The Latin text of Pseudo-Philo’s Biblical Antiquities circulated in some Latin collections of writings by Philo of Alexandria. Scholars have long recognized the pseudonymous character of the text now known as Pseudo-Philo’s Biblical Antiquities. Primary in this regard is a vastly differing approach to and use of the Jewish Scriptures than that of Philo of Alexandria. For the sake of convenience and due to the lack of a better option, scholars continue to follow the lead of Philo scholar Leopold Cohn in calling the author “Pseudo-Philo.” \n\nMost scholars contend that Pseudo-Philo’s Biblical Antiquities was written sometime between the mid-first century CE and the mid-second century CE. Some scholars propose that Pseudo-Philo's Biblical Antiquities was written shortly preceding the destruction of Jerusalem and its temple in 70 CE while other scholars suggest that Pseudo-Philo's Biblical Antiquites was written post-70 CE, possibly as late as shortly following the Bar Kokhba revolt (132-136 CE). A very small minority of scholars suggest dates outside these bounds. Examples include Abram Spiro who suggests that it was composed in the second century BCE, J. R. Porter who dates Pseudo-Philo to 25 CE, and Alexander Zeron who posits that it was composed sometime in the third or fourth centuries CE. Among the evidence cited by scholars in support of a pre-70 CE date of composition is the depiction of the temple in Jerusalem as still standing and in use for sacrifices (e.g. LAB 22:8). Further, Daniel J. Harrington writes: 'A date prior to AD 70 (and perhaps around the time of Jesus) is suggested by the kind of Old Testament text used in the book, the free attitude towards the text, the interest in the sacrifices and other things pertaining to cult, and the silence about the destruction of the temple'. Howard Jacobson, for example, treats this view dismissively, stating that \"Simply put, there are no particularly cogent arguments in support of a pre-70 date.\" Among the evidence cited in support of a post-70 CE date of composition are thematic parallels with 2 Baruch and 4 Ezra, Jewish texts composed post-70 CE and references to the destruction of the temple (e.g. LAB 19:7).\n\nThe scholarly consensus is that Pseudo-Philo’s Biblical Antiquities was not composed in Latin but, rather that it was composed in Hebrew and translated into Greek before being translated into Latin by the fourth century CE. The primary evidence for this are the many difficult readings in Pseudo-Philo's Biblical Antiquities that are best explained by the existence of Hebrew and Greek antecedents. \n\nPseudo-Philo's Biblical Antiquities is a selective rewriting of Jewish scriptural texts and traditions. Following a basic narrative outline derived from the Jewish Scriptures, the work opens with the creation of the world (LAB 1) and concludes with the death of King Saul (LAB 65). As Leopold Cohn observes, Pseudo-Philo’s Biblical Antiquities “passes rapidly over” or “omits” certain aspects of the scriptural narrative while elaborating other on others, even supplying “many quite novel additions” not paralleled in the Jewish Scriptures. Many of its additions have parallels in other Jewish traditions.\n\nSome scholars have reasoned that the fact that it ends with the death of Saul implies that there were further parts of the work which are now missing while others believe that it is complete. \n\nIt is probably the earliest reference for many later legendary accretions to the Biblical texts, such as the casting of Abraham into the fire, Dinah's marriage to Job, and Moses born circumcised. It also contains several other embellishments which deviate quite substantially from the norm, such as Abraham leading a rebellion against the builders of the Tower of Babel (the reason for him being cast into the fire).\n\nIt includes a lament about the symbolic human sacrifice of Jephthah's daughter, with the daughter being the singer. Commentators have noted that the characterisation of the daughter is (like other female characterisations in Pseudo-Philo) much stronger and more positive than that of her biblical counterpart. She has a name (Seila), and her role is as wise and willing, rather than passive and reluctant, participant. One commentator has observed that 'the author has done his utmost to put this woman on the same level as the patriarchs, in this case especially Isaac'.\n\n\n\n"}
{"id": "3193758", "url": "https://en.wikipedia.org/wiki?curid=3193758", "title": "Pumping lemma for context-free languages", "text": "Pumping lemma for context-free languages\n\nIn computer science, in particular in formal language theory, the pumping lemma for context-free languages, also known as the Bar-Hillel lemma, is a lemma that gives a property shared by all context-free languages and generalizes the pumping lemma for regular languages. As the pumping lemma does not suffice to guarantee that a language is context-free there are more stringent necessary conditions, such as Ogden's lemma.\n\nIf a language formula_1 is context-free, then there exists some integer formula_2 (called a \"pumping length\") such that every string formula_3 in formula_1 that has a length of formula_5 or more symbols (i.e. with formula_6) can be written as\n\nwith substrings formula_8 and formula_9, such that\n\nBelow is a formal expression of the Pumping Lemma.\n\nformula_14\n\nThe pumping lemma for context-free languages (called just \"the pumping lemma\" for the rest of this article) describes a property that all context-free languages are guaranteed to have.\n\nThe property is a property of all strings in the language that are of length at least formula_5, where formula_5 is a constant—called the \"pumping length\"—that varies between context-free languages.\n\nSay formula_3 is a string of length at least formula_5 that is in the language.\n\nThe pumping lemma states that formula_3 can be split into five substrings, formula_7, where formula_21 is non-empty and the length of formula_22 is at most formula_5, such that repeating formula_24 and formula_25 the same number of times (formula_26) in formula_3 produces a string that is still in the language. It is often useful to repeat zero times, which removes formula_24 and formula_25 from the string. This process of \"pumping up\" additional copies of formula_24 and formula_25 is what gives the pumping lemma its name.\n\nFinite languages (which are regular and hence context-free) obey the pumping lemma trivially by having formula_5 equal to the maximum string length in formula_1 plus one. As there are no strings of this length the pumping lemma is not violated.\n\nThe pumping lemma is often used to prove that a given language formula_1 is non-context-free, by showing that arbitrarily long strings formula_3 are in formula_1 that cannot be \"pumped\" without producing strings outside formula_1.\n\nFor example, the language formula_38 can be shown to be non-context-free by using the pumping lemma in a proof by contradiction. First, assume that formula_1 is context free. By the pumping lemma, there exists an integer formula_5 which is the pumping length of language formula_1. Consider the string formula_42 in formula_1. The pumping lemma tells us that formula_3 can be written in the form formula_7, where formula_8, and formula_9 are substrings, such that formula_10, formula_11, and formula_50 for every integer formula_51. By the choice of formula_3 and the fact that formula_10, it is easily seen that the substring formula_22 can contain no more than two distinct symbols. That is, we have one of five possibilities for formula_22:\n\n\nFor each case, it is easily verified that formula_70 does not contain equal numbers of each letter for any formula_71. Thus, formula_72 does not have the form formula_73. This contradicts the definition of formula_1. Therefore, our initial assumption that formula_1 is context free must be false.\n\nWhile the pumping lemma is often a useful tool to prove that a given language is not context-free, it does not give a complete characterization of the context-free languages. If a language does not satisfy the condition given by the pumping lemma,\nwe have established that it is not context-free.\n\nOn the other hand, there are languages that are not context-free, but still satisfy the condition given by the pumping lemma, for example\nformula_76\n∪ { \"a\"\"b\"\"c\"\"d\" | \"i\", \"j\" ∈ ℕ, \"i\"≥1 }: for \"s\"=\"b\"\"c\"\"d\" with e.g. \"j\"≥1 choose \"vwx\" to consist only of \"b\"’s, for \"s\"=\"a\"\"b\"\"c\"\"d\" choose \"vwx\" to consist only of \"a\"’s; in both cases all pumped strings are still in \"L\".\n\nA precursor of the pumping lemma was used in 1960 by Scheinberg to prove that formula_77 is not context-free.\n\n"}
{"id": "4044867", "url": "https://en.wikipedia.org/wiki?curid=4044867", "title": "Recursion (computer science)", "text": "Recursion (computer science)\n\nRecursion in computer science is a method of solving a problem where the solution depends on solutions to smaller instances of the same problem (as opposed to iteration). The approach can be applied to many types of problems, and recursion is one of the central ideas of computer science.\n\nMost computer programming languages support recursion by allowing a function to call itself from within its own code. Some functional programming languages do not define any looping constructs but rely solely on recursion to repeatedly call code. Computability theory proves that these recursive-only languages are Turing complete; they are as computationally powerful as Turing complete imperative languages, meaning they can solve the same kinds of problems as imperative languages even without iterative control structures such as and .\nA common computer programming tactic is to divide a problem into sub-problems of the same type as the original, solve those sub-problems, and combine the results. This is often referred to as the divide-and-conquer method; when combined with a lookup table that stores the results of solving sub-problems (to avoid solving them repeatedly and incurring extra computation time), it can be referred to as dynamic programming or memoization.\n\nA recursive function definition has one or more \"base cases\", meaning input(s) for which the function produces a result trivially (without recurring), and one or more \"recursive cases\", meaning input(s) for which the program recurs (calls itself). For example, the factorial function can be defined recursively by the equations and, for all , . Neither equation by itself constitutes a complete definition; the first is the base case, and the second is the recursive case. Because the base case breaks the chain of recursion, it is sometimes also called the \"terminating case\".\n\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a properly designed recursive function, with each recursive call, the input problem must be simplified in such a way that eventually the base case must be reached. (Functions that are not intended to terminate under normal circumstances—for example, some system and server processes—are an exception to this.) Neglecting to write a base case, or testing for it incorrectly, can cause an infinite loop.\n\nFor some functions (such as one that computes the series for ) there is not an obvious base case implied by the input data; for these one may add a parameter (such as the number of terms to be added, in our series example) to provide a 'stopping criterion' that establishes the base case. Such an example is more naturally treated by co-recursion, where successive terms in the output are the partial sums; this can be converted to a recursion by using the indexing parameter to say \"compute the \"n\"th term (\"n\"th partial sum)\".\n\nMany computer programs must process or generate an arbitrarily large quantity of data. Recursion is one technique for representing data whose exact size the programmer does not know: the programmer can specify this data with a self-referential definition. There are two types of self-referential definitions: inductive and coinductive definitions.\n\nAn inductively defined recursive data definition is one that specifies how to construct instances of the data. For example, linked lists can be defined inductively (here, using Haskell syntax):\n\nThe code above specifies a list of strings to be either empty, or a structure that contains a string and a list of strings. The self-reference in the definition permits the construction of lists of any (finite) number of strings.\n\nAnother example of inductive definition is the natural numbers (or positive integers):\n\nSimilarly recursive definitions are often used to model the structure of expressions and statements in programming languages. Language designers often express grammars in a syntax such as Backus–Naur form; here is such a grammar, for a simple language of arithmetic expressions with multiplication and addition:\n\nThis says that an expression is either a number, a product of two expressions, or a sum of two expressions. By recursively referring to expressions in the second and third lines, the grammar permits arbitrarily complex arithmetic expressions such as codice_2, with more than one product or sum operation in a single expression.\n\nA coinductive data definition is one that specifies the operations that may be performed on a piece of data; typically, self-referential coinductive definitions are used for data structures of infinite size.\n\nA coinductive definition of infinite streams of strings, given informally, might look like this:\n\nThis is very similar to an inductive definition of lists of strings; the difference is that this definition specifies how to access the contents of the data structure—namely, via the accessor functions codice_3 and codice_4—and what those contents may be, whereas the inductive definition specifies how to create the structure and what it may be created from.\n\nCorecursion is related to coinduction, and can be used to compute particular instances of (possibly) infinite objects. As a programming technique, it is used most often in the context of lazy programming languages, and can be preferable to recursion when the desired size or precision of a program's output is unknown. In such cases the program requires both a definition for an infinitely large (or infinitely precise) result, and a mechanism for taking a finite portion of that result. The problem of computing the first n prime numbers is one that can be solved with a corecursive program (e.g. here).\n\nRecursion that only contains a single self-reference is known as ', while recursion that contains multiple self-references is known as '. Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search.\n\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced by an iterative computation, running in linear time and requiring constant space. Multiple recursion, by contrast, may require exponential time and space, and is more fundamentally recursive, not being able to be replaced by iteration without an explicit stack.\n\nMultiple recursion can sometimes be converted to single recursion (and, if desired, thence to iteration). For example, while computing the Fibonacci sequence naively is multiple iteration, as each value requires two previous values, it can be computed by single recursion by passing two successive values as parameters. This is more naturally framed as corecursion, building up from the initial values, tracking at each step two successive values – see corecursion: examples. A more sophisticated example is using a threaded binary tree, which allows iterative tree traversal, rather than multiple recursion.\n\nMost basic examples of recursion, and most of the examples presented here, demonstrate \"direct\" recursion, in which a function calls itself. \"Indirect\" recursion occurs when a function is called not by itself but by another function that it called (either directly or indirectly). For example, if \"f\" calls \"f,\" that is direct recursion, but if \"f\" calls \"g\" which calls \"f,\" then that is indirect recursion of \"f.\" Chains of three or more functions are possible; for example, function 1 calls function 2, function 2 calls function 3, and function 3 calls function 1 again.\n\nIndirect recursion is also called mutual recursion, which is a more symmetric term, though this is simply a difference of emphasis, not a different notion. That is, if \"f\" calls \"g\" and then \"g\" calls \"f,\" which in turn calls \"g\" again, from the point of view of \"f\" alone, \"f\" is indirectly recursing, while from the point of view of \"g\" alone, it is indirectly recursing, while from the point of view of both, \"f\" and \"g\" are mutually recursing on each other. Similarly a set of three or more functions that call each other can be called a set of mutually recursive functions.\n\nRecursion is usually done by explicitly calling a function by name. However, recursion can also be done via implicitly calling a function based on the current context, which is particularly useful for anonymous functions, and is known as anonymous recursion.\n\nSome authors classify recursion as either \"structural\" or \"generative\". The distinction is related to where a recursive procedure gets the data that it works on, and how it processes that data:\n\nThus, the defining characteristic of a structurally recursive function is that the argument to each recursive call is the content of a field of the original input. Structural recursion includes nearly all tree traversals, including XML processing, binary tree creation and search, etc. By considering the algebraic structure of the natural numbers (that is, a natural number is either zero or the successor of a natural number), functions such as factorial may also be regarded as structural recursion.\n\nThis distinction is important in proving termination of a function. \n\nA classic example of a recursive procedure is the function used to calculate the factorial of a natural number:\n\nThe function can also be written as a recurrence relation:\nThis evaluation of the recurrence relation demonstrates the computation that would be performed in evaluating the pseudocode above:\nThis factorial function can also be described without using recursion by making use of the typical looping constructs found in imperative programming languages:\n\nThe imperative code above is equivalent to this mathematical definition using an accumulator variable \":\n\nThe definition above translates straightforwardly to functional programming languages such as Scheme; this is an example of iteration implemented recursively.\n\nThe Euclidean algorithm, which computes the greatest common divisor of two integers, can be written recursively.\nFunction definition\":\n\nRecurrence relation for greatest common divisor, where formula_6 expresses the remainder of formula_7:\n\nThe recursive program above is tail-recursive; it is equivalent to an iterative algorithm, and the computation shown above shows the steps of evaluation that would be performed by a language that eliminates tail calls. Below is a version of the same algorithm using explicit iteration, suitable for a language that does not eliminate tail calls. By maintaining its state entirely in the variables \"x\" and \"y\" and using a looping construct, the program avoids making recursive calls and growing the call stack.\n\nThe iterative algorithm requires a temporary variable, and even given knowledge of the Euclidean algorithm it is more difficult to understand the process by simple inspection, although the two algorithms are very similar in their steps.\n\nThe Towers of Hanoi is a mathematical puzzle whose solution illustrates recursion. There are three pegs which can hold stacks of disks of different diameters. A larger disk may never be stacked on top of a smaller. Starting with \"n\" disks on one peg, they must be moved to another peg one at a time. What is the smallest number of steps to move the stack?\n\n\"Function definition\":\n\n\"Recurrence relation for hanoi\":\n\nExample implementations:\n\nAlthough not all recursive functions have an explicit solution, the Tower of Hanoi sequence can be reduced to an explicit formula.\nThe binary search algorithm is a method of searching a sorted array for a single element by cutting the array in half with each recursive pass. The trick is to pick a midpoint near the center of the array, compare the data at that point with the data being searched and then responding to one of three possible conditions: the data is found at the midpoint, the data at the midpoint is greater than the data being searched for, or the data at the midpoint is less than the data being searched for.\n\nRecursion is used in this algorithm because with each pass a new array is created by cutting the old one in half. The binary search procedure is then called recursively, this time on the new (and smaller) array. Typically the array's size is adjusted by manipulating a beginning and ending index. The algorithm exhibits a logarithmic order of growth because it essentially divides the problem domain in half with each pass.\n\nExample implementation of binary search in C:\n\nAn important application of recursion in computer science is in defining dynamic data structures such as lists and trees. Recursive data structures can dynamically grow to a theoretically infinite size in response to runtime requirements; in contrast, the size of a static array must be set at compile time.\n\"Recursive algorithms are particularly appropriate when the underlying problem or the data to be treated are defined in recursive terms.\"\nThe examples in this section illustrate what is known as \"structural recursion\". This term refers to the fact that the recursive procedures are acting on data that is defined recursively.\nAs long as a programmer derives the template from a data definition, functions employ structural recursion. That is, the recursions in a function's body consume some immediate piece of a given compound value.\nBelow is a C definition of a linked list node structure. Notice especially how the node is defined in terms of itself. The \"next\" element of \"struct node\" is a pointer to another \"struct node\", effectively creating a list type.\n\nBecause the \"struct node\" data structure is defined recursively, procedures that operate on it can be implemented naturally as recursive procedures. The \"list_print\" procedure defined below walks down the list until the list is empty (i.e., the list pointer has a value of NULL). For each node it prints the data element (an integer). In the C implementation, the list remains unchanged by the \"list_print\" procedure.\n\nBelow is a simple definition for a binary tree node. Like the node for linked lists, it is defined in terms of itself, recursively. There are two self-referential pointers: left (pointing to the left sub-tree) and right (pointing to the right sub-tree).\nOperations on the tree can be implemented using recursion. Note that because there are two self-referencing pointers (left and right), tree operations may require two recursive calls:\nAt most two recursive calls will be made for any given call to \"tree_contains\" as defined above.\n\nThe above example illustrates an in-order traversal of the binary tree. A Binary search tree is a special case of the binary tree where the data elements of each node are in order.\n\nSince the number of files in a filesystem may vary, recursion is the only practical way to traverse and thus enumerate its contents. Traversing a filesystem is very similar to that of tree traversal, therefore the concepts behind tree traversal are applicable to traversing a filesystem. More specifically, the code below would be an example of a preorder traversal of a filesystem.\n\nThis code blends the lines, at least somewhat, between recursion and iteration. It is, essentially, a recursive implementation, which is the best way to traverse a filesystem. It is also an example of direct and indirect recursion. The method \"rtraverse\" is purely a direct example; the method \"traverse\" is the indirect, which calls \"rtraverse\". This example needs no \"base case\" scenario due to the fact that there will always be some fixed number of files or directories in a given filesystem.\n\nIn actual implementation, rather than a pure recursive function (single check for base case, otherwise recursive step), a number of modifications may be made, for purposes of clarity or efficiency. These include:\n\n\nOn the basis of elegance, wrapper functions are generally approved, while short-circuiting the base case is frowned upon, particularly in academia. Hybrid algorithms are often used for efficiency, to reduce the overhead of recursion in small cases, and arm's-length recursion is a special case of this.\n\nA wrapper function is a function that is directly called but does not recurse itself, instead calling a separate auxiliary function which actually does the recursion.\n\nWrapper functions can be used to validate parameters (so the recursive function can skip these), perform initialization (allocate memory, initialize variables), particularly for auxiliary variables such as \"level of recursion\" or partial computations for memoization, and handle exceptions and errors. In languages that support nested functions, the auxiliary function can be nested inside the wrapper function and use a shared scope. In the absence of nested functions, auxiliary functions are instead a separate function, if possible private (as they are not called directly), and information is shared with the wrapper function by using pass-by-reference.\n\nShort-circuiting the base case, also known as arm's-length recursion, consists of checking the base case \"before\" making a recursive call – i.e., checking if the next call will be the base case, instead of calling and then checking for the base case. Short-circuiting is particularly done for efficiency reasons, to avoid the overhead of a function call that immediately returns. Note that since the base case has already been checked for (immediately before the recursive step), it does not need to be checked for separately, but one does need to use a wrapper function for the case when the overall recursion starts with the base case itself. For example, in the factorial function, properly the base case is 0! = 1, while immediately returning 1 for 1! is a short-circuit, and may miss 0; this can be mitigated by a wrapper function.\n\nShort-circuiting is primarily a concern when many base cases are encountered, such as Null pointers in a tree, which can be linear in the number of function calls, hence significant savings for algorithms; this is illustrated below for a depth-first search. Short-circuiting on a tree corresponds to considering a leaf (non-empty node with no children) as the base case, rather than considering an empty node as the base case. If there is only a single base case, such as in computing the factorial, short-circuiting provides only savings.\n\nConceptually, short-circuiting can be considered to either have the same base case and recursive step, only checking the base case before the recursion, or it can be considered to have a different base case (one step removed from standard base case) and a more complex recursive step, namely \"check valid then recurse\", as in considering leaf nodes rather than Null nodes as base cases in a tree. Because short-circuiting has a more complicated flow, compared with the clear separation of base case and recursive step in standard recursion, it is often considered poor style, particularly in academia.\n\nA basic example of short-circuiting is given in depth-first search (DFS) of a binary tree; see binary trees section for standard recursive discussion.\n\nThe standard recursive algorithm for a DFS is:\n\nIn short-circuiting, this is instead:\n\nIn terms of the standard steps, this moves the base case check \"before\" the recursive step. Alternatively, these can be considered a different form of base case and recursive step, respectively. Note that this requires a wrapper function to handle the case when the tree itself is empty (root node is Null).\n\nIn the case of a perfect binary tree of height \"h,\" there are 2−1 nodes and 2 Null pointers as children (2 for each of the 2 leaves), so short-circuiting cuts the number of function calls in half in the worst case.\n\nIn C, the standard recursive algorithm may be implemented as:\nThe short-circuited algorithm may be implemented as:\n\nNote the use of short-circuit evaluation of the Boolean && (AND) operators, so that the recursive call is only made if the node is valid (non-Null). Note that while the first term in the AND is a pointer to a node, the second term is a bool, so the overall expression evaluates to a bool. This is a common idiom in recursive short-circuiting. This is in addition to the short-circuit evaluation of the Boolean || (OR) operator, to only check the right child if the left child fails. In fact, the entire control flow of these functions can be replaced with a single Boolean expression in a return statement, but legibility suffers at no benefit to efficiency.\n\nRecursive algorithms are often inefficient for small data, due to the overhead of repeated function calls and returns. For this reason efficient implementations of recursive algorithms often start with the recursive algorithm, but then switch to a different algorithm when the input becomes small. An important example is merge sort, which is often implemented by switching to the non-recursive insertion sort when the data is sufficiently small, as in the tiled merge sort. Hybrid recursive algorithms can often be further refined, as in Timsort, derived from a hybrid merge sort/insertion sort.\n\nRecursion and iteration are equally expressive: recursion can be replaced by iteration with an explicit call stack, while iteration can be replaced with tail recursion. Which approach is preferable depends on the problem under consideration and the language used. In imperative programming, iteration is preferred, particularly for simple recursion, as it avoids the overhead of function calls and call stack management, but recursion is generally used for multiple recursion. By contrast, in functional languages recursion is preferred, with tail recursion optimization leading to little overhead. Implementing an algorithm using iteration may not be easily achievable.\n\nCompare the templates to compute x defined by x = f(n, x) from x:\nFor imperative language the overhead is to define the function, for functional language the overhead is to define the accumulator variable x.\n\nFor example, a factorial function may be implemented iteratively in C by assigning to an loop index variable and accumulator variable, rather than by passing arguments and returning values by recursion:\n\nMost programming languages in use today allow the direct specification of recursive functions and procedures. When such a function is called, the program's runtime environment keeps track of the various instances of the function (often using a call stack, although other methods may be used). Every recursive function can be transformed into an iterative function by replacing recursive calls with iterative control constructs and simulating the call stack with a stack explicitly managed by the program.\n\nConversely, all iterative functions and procedures that can be evaluated by a computer (see Turing completeness) can be expressed in terms of recursive functions; iterative control constructs such as while loops and do loops are routinely rewritten in recursive form in functional languages. However, in practice this rewriting depends on tail call elimination, which is not a feature of all languages. C, Java, and Python are notable mainstream languages in which all function calls, including tail calls, may cause stack allocation that would not occur with the use of looping constructs; in these languages, a working iterative program rewritten in recursive form may overflow the call stack, although tail call elimination may be a feature that is not covered by a language's specification, and different implementations of the same language may differ in tail call elimination capabilities.\n\nIn languages (such as C and Java) that favor iterative looping constructs, there is usually significant time and space cost associated with recursive programs, due to the overhead required to manage the stack and the relative slowness of function calls; in functional languages, a function call (particularly a tail call) is typically a very fast operation, and the difference is usually less noticeable.\n\nAs a concrete example, the difference in performance between recursive and iterative implementations of the \"factorial\" example above depends highly on the compiler used. In languages where looping constructs are preferred, the iterative version may be as much as several orders of magnitude faster than the recursive one. In functional languages, the overall time difference of the two implementations may be negligible; in fact, the cost of multiplying the larger numbers first rather than the smaller numbers (which the iterative version given here happens to do) may overwhelm any time saved by choosing iteration.\n\nIn some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms. Consequently, these languages sometimes place a limit on the depth of recursion to avoid stack overflows; Python is one such language. Note the caveat below regarding the special case of tail recursion.\n\nBecause recursive algorithms can be subject to stack overflows, they may be vulnerable to pathological or malicious input. Some malware specifically targets a program's call stack and takes advantage of the stack's inherently recursive nature. Even in the absence of malware, a stack overflow caused by unbounded recursion can be fatal to the program, and exception handling logic may not prevent the corresponding process from being terminated.\n\nMultiply recursive problems are inherently recursive, because of prior state they need to track. One example is tree traversal as in depth-first search; though both recursive and iterative methods are used, they contrast with list traversal and linear search in a list, which is a singly recursive and thus naturally iterative method. Other examples include divide-and-conquer algorithms such as Quicksort, and functions such as the Ackermann function. All of these algorithms can be implemented iteratively with the help of an explicit stack, but the programmer effort involved in managing the stack, and the complexity of the resulting program, arguably outweigh any advantages of the iterative solution.\n\nRecursive algorithms can be replaced with non-recursive counterparts.. One method for replacing recursive algorithms is to simulate them using heap memory in place of stack memory. An alternative is to develop a replacement algorithm entirely based on non-recursive methods, which can be challenging. For example, recursive algorithms for matching wildcards, such as Rich Salz' wildmat algorithm, were once typical. Non-recursive algorithms for the same purpose, such as the Krauss matching wildcards algorithm, have been developed to avoid the drawbacks of recursion and have improved only gradually based on techniques such as collecting tests and profiling performance.\n\nTail-recursive functions are functions in which all recursive calls are tail calls and hence do not build up any deferred operations. For example, the gcd function (shown again below) is tail-recursive. In contrast, the factorial function (also below) is not tail-recursive; because its recursive call is not in tail position, it builds up deferred multiplication operations that must be performed after the final recursive call completes. With a compiler or interpreter that treats tail-recursive calls as jumps rather than function calls, a tail-recursive function such as gcd will execute using constant space. Thus the program is essentially iterative, equivalent to using imperative language control structures like the \"for\" and \"while\" loops.\n\nThe significance of tail recursion is that when making a tail-recursive call (or any tail call), the caller's return position need not be saved on the call stack; when the recursive call returns, it will branch directly on the previously saved return position. Therefore, in languages that recognize this property of tail calls, tail recursion saves both space and time.\n\nIn the simple case of a function calling itself only once, instructions placed before the recursive call are executed once per recursion before any of the instructions placed after the recursive call. The latter are executed repeatedly after the maximum recursion has been reached. Consider this example:\n\nThe time efficiency of recursive algorithms can be expressed in a recurrence relation of Big O notation. They can (usually) then be simplified into a single Big-O term.\n\nIf the time-complexity of the function is in the form\n\nformula_14\n\nThen the Big O of the time-complexity is thus:\n\n\nwhere represents the number of recursive calls at each level of recursion, represents by what factor smaller the input is for the next level of recursion (i.e. the number of pieces you divide the problem into), and represents the work the function does independent of any recursion (e.g. partitioning, recombining) at each level of recursion.\n\n\n\n\n\n"}
{"id": "29152171", "url": "https://en.wikipedia.org/wiki?curid=29152171", "title": "Remote radio head", "text": "Remote radio head\n\nA remote radio head (RRH), also called a remote radio unit (RRU) in wireless networks, is a remote radio transceiver that connects to an operator radio control panel via electrical or wireless interface. When used to describe aircraft radio cockpit radio systems, the control panel is often called the radio head.\n\nIn wireless system technologies such as GSM, CDMA, UMTS, LTE the radio equipment is remote to the BTS/NodeB/eNodeB. The equipment is used to extend the coverage of a BTS/NodeB/eNodeB in challenging environments such as rural areas or tunnels. They are generally connected to the BTS/NodeB/eNodeB via a fiber optic cable using Common Public Radio Interface protocols.\nRRHs have become one of the most important subsystems of today's new distributed base stations. The RRH contains the base station's RF circuitry plus analog-to-digital/digital-to-analog converters and up/down converters. RRHs also have operation and management processing capabilities and a standardized optical interface to connect to the rest of the base station. This will be increasingly true as LTE and WiMAX are deployed. Remote radio heads make MIMO operation easier; they increase a base station's efficiency and facilitate easier physical location for gap coverage problems. RRHs will use the latest RF component technology including Gallium nitride (GaN) RF power devices and envelope tracking technology within the RRH RF power amplifier (RFPA).\n\nFourth-generation (4G) and beyond infrastructure deployments will include the implementation of Fiber to the Antenna (FTTA) architecture. FTTA architecture has enabled lower power requirements, distributed antenna sites, and a reduced base station footprint than conventional tower sites. The use of FTTA will promote the separation of power and signal components from the base station and their relocation to the top of the tower mast in a Remote Radio Head (RRH).\n\nAccording to the Telcordia industry standard that establishes generic requirements for Fiber to the Antenna (FTTA) protection GR-3177, the RRH shifts the entire high-frequency and power electronic segments from the base station to a location adjacent to the antenna. The RRH will be served by optical fiber and DC power for the optical-to-electronic conversion at the RRH.\n\nRRHs located on cell towers will require Surge Protective Devices (SPDs) to protect the system from lightning strikes and induced power surges. There is also a change in electrical overstress exposure due to the relocation of the equipment from the base station to the top of the mast.\n\nRRHs can be installed in a low-profile arrangement along a rooftop, or can involve a much higher tower arrangement. When installed at the highest point on a structure (whether a building or a dedicated cell tower), they will be more vulnerable to receiving a direct lightning strike and higher induced lightning levels, compared with those installed in a lower profile manner below the upper edges of the building.\n\nAs noted in GR-3177, while surges can be induced into the RRH wiring for lightning striking the nearby rooftop or even the base station closure, the worst case will occur when a direct strike occurs to the antenna or its supporting structure. Designing the electrical protection to handle this situation will provide protection for less damaging scenarios...\nit can also be use in optical fiber communication but different type.\n\n\n"}
{"id": "44510914", "url": "https://en.wikipedia.org/wiki?curid=44510914", "title": "Seymur Baycan", "text": "Seymur Baycan\n\nSeymur Baycan () – an Azerbaijani writer, publicist, columnist.\n\nSeymur Baycan was born in 1976, in Fizuli, Azerbaijan. He graduated from the military school named after Jamshid Nakhchivanski. He went on to study at Qafqaz University, Department of Public Administration. He left his education and started his literary career. His short stories have been published in Russian, Georgian, Armenian, Ukrainian and Kazakh languages. He created the \"novel-skeleton\" in world literature. His best-known works include \"18.6 cm\", \"Meat and meat products\" and \"Gugark\". In different years he published essays and columns in newspapers \"Milli yol\", \"Reyting\", \"Daily Azerbaijan\", etc. He participated in several regional projects and delivered lectures on cultural topics. Seymur Baycan was awarded with \"Media Key\" for his essay \"The Sunday in Paradise\". He won the writing competition organized by \"Elmar Huseynov Foundation\".\n\n\nRussian\n\nAzerbaijani\n\n"}
{"id": "7991870", "url": "https://en.wikipedia.org/wiki?curid=7991870", "title": "Sight word", "text": "Sight word\n\nSight words, often also called high frequency sight words, are commonly used words that young children are encouraged to memorize as a whole by sight, so that they can automatically recognize these words in print within three seconds without having to use any strategies to decode. Sight words don’t follow the standards rules of phonics or the six syllable types. The term sight words is often confused with sight vocabulary, which is defined as each person's own vocabulary that the person recognizes from memory without the need to decode for understanding. Sight words were introduced after Whole language (a similar method) fell out of favor with the education establishment.\n\nSight words account for a large percentage (up to 75%) of the words used in beginning children's print materials. The advantage for children being able to recognize sight words automatically is that a beginning reader will be able to identify the majority of words in a beginning text before they even attempt to read it; therefore, allowing the child to concentrate on meaning and comprehension as they read without having to stop and decode every single word. Advocates of whole-word instruction believe that being able to recognize a large number of sight words gives students a better start to learning to read.\n\nRecognizing sight words automatically is said to be advantageous for beginning readers because many of these words have unusual spelling patterns, cannot be sounded out using basic phonics knowledge and cannot be represented using pictures. For example, the word \"was\" does not follow a usual spelling pattern, as the middle letter \"a\" makes an sound and the final letter \"s\" makes a sound, nor can the word be associated with a picture clue since it denotes an abstract state (existence). Another example, is the word “said”,it breaks the phonetic rule of ai normally makes the long a sound, ay. In this word it makes the short e sound of eh. The word \"said\" is pronounced as /s/ /e/ /d/. The word “has” also breaks the phonetic rule of s normally making the sss sound, in this word the s makes the z sound, /z/.\" The word is then pronounced /h/ /a/ /z/.\n\nA number of sight word lists have been compiled and published; among the most popular are the Dolch sight words and the magic 100 words. These lists have similar attributes, as they all aim to divide words into levels which are prioritized and introduced to children according to frequency of appearance in beginning readers' texts. Although many of the lists have overlapping content, the order of frequency of sight words varies and can be argued depending on contexts such as geographical location, empirical data, samples used, and year of publication.\n\nSome research shows that the use of sight words does not relate to phonological awareness. The dual route theory states that the use of sight words as a reading strategy involves out-of-context memorization rather than the development of phonological skills. Instead, it is suggested that children first learn to identify individual letter-sound correspondences before blending and segmenting letter combinations. \n\nExponents of synthetic phonics argue that children must first learn the alphabet, then the sounds represented by the letters, then the blends of those sounds, and that children should never memorize words as visual designs.\n\n"}
{"id": "32005030", "url": "https://en.wikipedia.org/wiki?curid=32005030", "title": "Sua language", "text": "Sua language\n\nSua, also known as Mansoanka or Kunante, is a divergent Niger–Congo language of Guinea-Bissau.\n\n"}
{"id": "48502235", "url": "https://en.wikipedia.org/wiki?curid=48502235", "title": "Summa Grammatica (John of Dacia)", "text": "Summa Grammatica (John of Dacia)\n\nThe (Latin for \"Overview of Grammar\"; ) or Speculative Grammar (\"\") was a work by the medieval Modist philosopher John of Dacia.\n\nJohn calls grammar the \"idiom of philosophers\" and analyzes the modes using Aristotle's \"Metaphysics\".\n\n"}
{"id": "30828753", "url": "https://en.wikipedia.org/wiki?curid=30828753", "title": "The Book of the Reason and the Ignorance", "text": "The Book of the Reason and the Ignorance\n\nThe Book of the Reason and the Ignorance is the first part of the Shias oldest Oral tradition named as 'Osul'i Kafi' or the Principles Sufficient. \n\nIn this book, Kuleini describes the importance of the reason in Shiite belief by traditions narrated by Shiite Imams.\n"}
{"id": "41820386", "url": "https://en.wikipedia.org/wiki?curid=41820386", "title": "Timeline of machine translation", "text": "Timeline of machine translation\n\nThis is a timeline of machine translation. For a more detailed qualitative account, see the history of machine translation page.\n\n"}
{"id": "3292195", "url": "https://en.wikipedia.org/wiki?curid=3292195", "title": "Verificationism", "text": "Verificationism\n\nVerificationism, also known as the verification idea or the verifiability criterion of meaning, is the philosophical doctrine that only statements that are empirically verifiable (i.e. verifiable through the senses) are cognitively meaningful, or else they are truths of logic (tautologies).\n\nVerificationism thus rejects as cognitively \"meaningless\" statements specific to entire fields such as metaphysics, spirituality, theology, ethics and aesthetics. Such statements may be meaningful in influencing emotions or behavior, but not in terms of truth value, information or factual content. Verificationism was a central thesis of logical positivism, a movement in analytic philosophy that emerged in the 1920s by the efforts of a group of philosophers who sought to unify philosophy and science under a common naturalistic theory of knowledge.\n\nAlthough verificationist principles of a general sort—grounding scientific theory in some verifiable experience—are found retrospectively even with the American pragmatist C.S. Peirce and with the French conventionalist Pierre Duhem who fostered instrumentalism, the vigorous program termed \"verificationism\" was launched by the logical positivists who, emerging from Berlin Circle and Vienna Circle in the 1920s, sought epistemology whereby philosophical discourse would be, in their perception, as authoritative and meaningful as empirical science.\n\nLogical positivists garnered the verifiability criterion of cognitive meaningfulness from young Ludwig Wittgenstein's philosophy of language posed in his 1921 book \"Tractatus\", and, led by Bertrand Russell, sought to reformulate the analytic–synthetic distinction in a way that would reduce mathematics and logic to semantical conventions. This would be pivotal to verificationism, in that logic and mathematics would otherwise be classified as synthetic a priori knowledge and defined as \"meaningless\" under verificationism.\n\nSeeking grounding in such empiricism as of David Hume, Auguste Comte, and Ernst Mach—along with the positivism of the latter two—they borrowed some perspectives from Immanuel Kant, and found the exemplar of science to be Albert Einstein's general theory of relativity.\n\nLogical positivists within the Vienna Circle quickly recognized that the verifiability criterion was too stringent. Notably, all universal generalizations are empirically unverifiable, such that, under verificationism, vast domains of science and reason, such as scientific hypothesis, would be rendered meaningless.\n\nRudolf Carnap, Otto Neurath, Hans Hahn and Philipp Frank led a faction seeking to make the verifiability criterion more inclusive, beginning a movement they referred to as the \"liberalization of empiricism\". Moritz Schlick and Friedrich Waismann led a \"conservative wing\" that maintained a strict verificationism. Whereas Schlick sought to reduce universal generalizations to frameworks of 'rules' from which verifiable statements can be derived, Hahn argued that the verifiability criterion should accede to less-than-conclusive verifiability. Among other ideas espoused by the liberalization movement were physicalism, over Mach's phenomenalism, coherentism over foundationalism, as well as pragmatism and fallibilism.\n\nIn 1936, Carnap sought a switch from verification to \"confirmation\". Carnap's confirmability criterion (confirmationism) would not require conclusive verification (thus accommodating for universal generalizations) but allow for partial testability to establish \"degrees of confirmation\" on a probabilistic basis. Carnap never succeeded in formalizing his thesis despite employing abundant logical and mathematical tools for this purpose. In all of Carnap's formulations, a universal law's degree of confirmation is zero.\n\nThat same year saw the publication of A. J. Ayer's work, \"Language, Truth and Logic\", in which he proposed two types of verification: \"strong\" and \"weak\". This system espoused conclusive verification, yet accommodated for probabilistic inclusion where verifiability is inconclusive. Ayer also distinguished between practical and theoretical verifiability. Under the latter, propositions that cannot be verified in practice would still be meaningful if they can be verified in principle.\n\nKarl Popper's \"The Logic of Scientific Discovery\" proposed falsificationism as a criterion under which scientific hypothesis would be tenable. Falsificationism would allow hypotheses expressed as universal generalizations, such as \"all swans are white\", to be provisionally true until falsified by evidence, in contrast to verificationism under which they would be disqualified immediately as meaningless.\n\nThough widely recognized as a revision of verificationism, Popper intended falsificationism as a methodological standard specific to the sciences rather than as a theory of meaning. Popper regarded scientific hypotheses to be unverifiable, as well as not \"confirmable\" under Carnap's thesis. He also found unscientific, metaphysical, ethical, and aesthetic statements often rich in meaning and important in the origination of scientific theories.\n\nThe 1951 article \"Two Dogmas of Empiricism\", by Willard Van Orman Quine, attacked the analytic/synthetic division and apparently rendered the verificationist program untenable. Carl Hempel, one of verificationism's greatest internal critics, had recently concluded the same as to the verifiability criterion. In 1958, Norwood Hanson explained that even direct observations must be collected, sorted, and reported with guidance and constraint by theory, which sets a horizon of expectation and interpretation, how observational reports, never neutral, are laden with theory.\n\nThe principle was also recognized as being self-refuting: it cannot itself be empirically verified, and it is not a logical tautology, so must be meaningless under its own terms.\n\nThomas Kuhn's landmark book of 1962, \"The Structure of Scientific Revolutions\"—which identified \"paradigms of science\" overturned by revolutionary science within fundamental physics—critically destabilized confidence in scientific foundationalism, commonly if erroneously attributed to verificationism. Popper, who had long claimed to have killed verificationism but recognized that some would confuse his falsificationism for more of it, was knighted in 1965. In 1967, John Passmore, a leading historian of 20th-century philosophy, wrote, \"Logical positivism is dead, or as dead as a philosophical movement ever becomes\"—a general view among philosophers. Logical positivism's fall heralded postpositivism, where Popper's view of human knowledge as hypothetical, continually growing, and open to change ascended, and verificationism became mostly maligned.\n\nKarl Popper has been the only philosopher of science often praised by scientists, whereas verificationists have been likened to economists of the 19th century who took circuitous, protracted measures to refuse falsification, that is, refutation, of their preconceived principles. Still, logical positivists practiced Popper's principles—conjecturing and refuting—until they ran their course, catapulting Popper, initially a contentious misfit, to carry the richest philosophy out of interwar Vienna. And his falsificationism, as did verificationism, poses a criterion, \"falsifiability\", to ensure that empiricism anchors scientific theory.\n\nIn a 1979 interview, A J Ayer, who had introduced logical positivism to the English-speaking world in the 1930s, was asked what he saw as its main defects, and answered that \"nearly all of it was false\". Still, he soon admitted still holding \"the same general approach\". The \"general approach\" of empiricism and reductionism—whereby mental phenomena resolve to the material or physical, and philosophical questions largely resolve to ones of language and meaning—has run through Western philosophy since the 17th century and lived beyond logical positivism's fall.\n\nIn 1977, Ayer had noted, \"The verification principle is seldom mentioned and when it is mentioned it is usually scorned; it continues, however, to be put to work. The attitude of many philosophers reminds me of the relationship between Pip and Magwitch in Dickens's \"Great Expectations\". They have lived on the money, but are ashamed to acknowledge its source\". In the late 20th and early 21st centuries, the general concept of verification criteria—in forms that differed from those of the logical positivists—was defended by Bas van Fraassen, Michael Dummett, Crispin Wright, Christopher Peacocke, David Wiggins, Richard Rorty, and others.\n\n"}
{"id": "33131", "url": "https://en.wikipedia.org/wiki?curid=33131", "title": "Wireless telegraphy", "text": "Wireless telegraphy\n\nWireless telegraphy means transmission of telegraph signals by radio waves; a more modern term for this is radiotelegraphy. Due to its simplicity, radiotelegraphy was the first means of radio communication; the first practical radio transmitters and receivers invented in 1894-5 by Guglielmo Marconi used radiotelegraphy. It continued to be the only type of radio transmission during the first three decades of radio, called the \"wireless telegraphy era\" up until World War I, when the development of amplitude modulation (AM) radiotelephony allowed sound (audio) to be transmitted by radio. In radiotelegraphy, information is transmitted by pulses of radio waves of two different lengths called \"dots\" and \"dashes\", which spell out text messages, usually in Morse code. In a manual system, the sending operator taps on a switch called a telegraph key which turns the transmitter on and off, producing the pulses of radio waves. At the receiver the pulses are audible in the receiver's speaker as beeps, which are translated back to text by an operator who knows Morse code. \n\nBefore about 1910 when radio became dominant, the term \"wireless telegraphy\" was also used for various other experimental technologies for transmitting telegraph signals without wires, such as electromagnetic induction, and ground conduction telegraph systems.\n\nRadiotelegraphy was used for long distance person-to-person commercial, diplomatic, and military text communication throughout the first half of the 20th century. It became a strategically important capability during the two world wars, since a nation without long distance radiotelegraph stations could be isolated from the rest of the world by an enemy cutting its submarine telegraph cables. Beginning about 1908, powerful transoceanic radiotelegraphy stations transmitted commercial telegram traffic between countries at rates up to 200 words per minute. Radiotelegraphy was transmitted by several different modulation methods during its history. The primitive spark gap transmitters used until 1920 transmitted damped waves, which had very large bandwidth and tended to interfere with other transmissions. This type of emission was banned by 1930. The vacuum tube (valve) transmitters which came into use after 1920 transmitted code by pulses of unmodulated sinusoidal carrier wave called continuous waves (CW), which is still used today. To make CW transmissions audible, the receiver requires a circuit called a beat frequency oscillator (BFO). A third type of modulation, frequency shift keying (FSK) was used mainly by radioteletypes. Morse code radiotelegraphy was gradually replaced by radioteletype networks (RTTY) in most high volume applications by World War 2. Today it is nearly obsolete, the only remaining users are the radio amateur community and some limited training by the military for emergency use.\n\nWireless telegraphy or radiotelegraphy, commonly called CW (continuous wave) transmission, is a radio communication method in which the sending operator taps on a switch called a telegraph key, which turns the radio transmitter on and off, producing pulses of unmodulated carrier wave of different lengths called \"dots\" and \"dashes\", which encode characters of text, usually in Morse code. At the receiving location the code is audible in the radio receiver's earphone or speaker as a sequence of buzzes or beeps, which is translated back to text by an operator who knows Morse code. \n\nAlthough this type of communication has been mostly replaced since its introduction over 100 years ago by other means of communication it is still used by amateur radio operators as well as some military services. A CW coastal station, KSM, still exists in California, run primarily as a museum by volunteers, and occasional contacts with ships are made. Radio beacons, particularly in the aviation service, but also as \"placeholders\" for commercial ship-to-shore systems, also transmit Morse but at very slow speeds. The US Federal Communications Commission issues a lifetime commercial Radiotelegraph Operator License. This requires passing a simple written test on regulations, a more complex written exam on technology, and demonstrating Morse reception at 20 words per minute plain language and 16 wpm code groups. (Credit is given for amateur extra class licenses earned under the old 20 wpm requirement.) Wireless telegraphy is still used widely today by amateur radio hobbyists where it is commonly referred to as radio telegraphy, continuous wave, or just CW. However, its knowledge is not required to obtain any class of amateur license.\n\nContinuous wave (CW) radiotelegraphy is regulated by the International Telecommunication Union (ITU) as emission type A1A.\n\nEfforts to find a way to transmit telegraph signals without wires grew out of the success of electric telegraph networks, the first instant telecommunication systems. Developed beginning in the 1830s, a telegraph line was a person-to-person text message system consisting of multiple telegraph offices linked by an overhead wire supported on telegraph poles. To send a message, an operator at one office would tap on a switch called a telegraph key, creating pulses of electric current which spelled out a message in Morse code. When the key was pressed, it would connect a battery to the telegraph line, sending current down the wire. At the receiving office the current pulses would operate a telegraph sounder, a device which would make a \"click\" sound when it received each pulse of current. The operator at the receiving station who knew Morse code would translate the clicking sounds to text and write down the message. The ground was used as the return path for current in the telegraph circuit, to avoid having to use a second overhead wire.\n\nBy the 1860s, telegraph was the standard way to send most urgent commercial, diplomatic and military messages, and industrial nations had built continentwide telegraph networks, with submarine telegraph cables allowing telegraph messages to bridge oceans. However installing and maintaining a telegraph line linking distant stations was very expensive, and wires could not reach some locations such as ships at sea. Inventors realized if a way could be found to send electrical impulses of Morse code between separate points without a connecting wire, it could revolutionize communications. \n\nThe successful solution to this problem was the discovery of radio waves in 1887, and the development of practical radiotelegraphy transmitters and receivers by about 1899, described in the next section. However this was preceded by a 50 year history of ingenious but ultimately unsuccessful experiments by inventors to achieve wireless telegraphy by other means. \n\nA number of wireless electrical signaling schemes based on the (sometimes erroneous) idea that electric currents could be conducted long range through water, ground, and air were investigated for telegraphy before practical radio systems became available.\n\nThe original telegraph lines used two wires between the two stations to form a complete electrical circuit or \"loop\". In 1837, however, Carl August von Steinheil of Munich, Germany, found that by connecting one leg of the apparatus at each station to metal plates buried in the ground, he could eliminate one wire and use a single wire for telegraphic communication. This led to speculation that it might be possible to eliminate both wires and therefore transmit telegraph signals through the ground without any wires connecting the stations. Other attempts were made to send the electric current through bodies of water, in order to span rivers, for example. Prominent experimenters along these lines included Samuel F. B. Morse in the United States and James Bowman Lindsay in Great Britain, who in August 1854, was able to demonstrate transmission across a mill dam at a distance of .\n\nUS inventors William Henry Ward (1871) and Mahlon Loomis (1872) developed an electrical conduction systems based on the erroneous belief that there was an electrified atmospheric stratum accessible at low altitude. They thought atmosphere current, connected with a return path using \"Earth currents\" would allow for wireless telegraphy as well as supply power for the telegraph, doing away with artificial batteries. A more practical demonstration of wireless transmission via conduction came in Amos Dolbear's 1879 magneto electric telephone that used ground conduction to transmit over a distance of a quarter of a mile.\n\nIn the 1890s inventor Nikola Tesla worked on an air and ground conduction wireless electric power transmission system, similar to Loomis', which he planned to include wireless telegraphy. Tesla's experiments had led him to incorrectly conclude that he could use the entire globe of the Earth to conduct electrical energy and his 1901 large scale application of his ideas, a high-voltage wireless power station, now called Wardenclyffe Tower, lost funding and was abandoned after a few years. \n\nTelegraphic communication using earth conductivity was eventually found to be limited to impractically short distances, as was communication conducted through water, or between trenches during World War I.\n\nBoth electrostatic and electromagnetic induction were used to develop wireless telegraph systems that saw limited commercial application. In the United States, Thomas Edison, in the mid-1880s, patented an electromagnetic induction system he called \"grasshopper telegraphy\", which allowed telegraphic signals to jump the short distance between a running train and telegraph wires running parallel to the tracks. This system was successful technically but not economically, as there turned out to be little interest by train travelers in the use of an on-board telegraph service. During the Great Blizzard of 1888, this system was used to send and receive wireless messages from trains buried in snowdrifts. The disabled trains were able to maintain communications via their Edison induction wireless telegraph systems, perhaps the first successful use of wireless telegraphy to send distress calls. Edison would also help to patent a ship-to-shore communication system based on electrostatic induction.\n\nThe most successful creator of an electromagnetic induction telegraph system was William Preece in the United Kingdom. Beginning with tests across the Bristol Channel in 1892, Preece was able to telegraph across gaps of about . However, his induction system required extensive lengths of antenna wires, many kilometers long, at both the sending and receiving ends. The length of those sending and receiving wires needed to be about the same length as the width of the water or land to be spanned. For example, for Preece's station to span the English Channel from Dover, England, to the coast of France would require sending and receiving wires of about along the two coasts. These facts made the system impractical on ships, boats, and ordinary islands, which are much smaller than Great Britain or Greenland. In addition, the relatively short distances that a practical Preece system could span meant that it had few advantages over underwater telegraph cables.\n\nOver several years starting in 1894, the Italian inventor Guglielmo Marconi worked on adapting the newly discovered phenomenon of radio waves to communication, turning what was essentially a laboratory experiment up to that point into a useful communication system, building the first radiotelegraphy system using them. After Marconi sent wireless telegraphic signals across the Atlantic Ocean in 1901, the system began being used for regular communication including ship-to-shore and ship-to-ship comuntication \n\nWith this development wireless telegraphy came to mean \"radiotelegraphy\", Morse code transmitted by radio waves. The first radio transmitters, primitive spark gap transmitters used until World War I, could not transmit voice (audio signals). Instead, the operator would tap out the text message on a telegraph key, which turned the transmitter on and off, producing short (\"dot\") and long (\"dash\") pulses of radio waves, groups of which comprised the letters and other symbols of the Morse code. At the receiver, the signals could be heard as musical \"beeps\" in the earphones by the receiving operator, who would translate the code back into text. By 1910, communication by what had been called \"Hertzian waves\" was being universally referred to as \"radio\", and the term wireless telegraphy has been largely replaced by the more modern term \"radiotelegraphy\".\n\nThe primitive spark transmitters used until 1920 transmitted by a modulation method called damped waves. As long as the telegraph key was pressed, the transmitter would produce a string of transient pulses of radio waves which repeated at an audio rate, usually between 50 and several thousand hertz. In a receiver's earphone this sounded like a musical tone, rasp or buzz. Thus the Morse code \"dots\" and \"dashes\" sounded like beeps. Damped waves had a large frequency bandwidth meaning that the radio signal was not a single frequency but occupied a wide band of frequencies. Damped wave transmitters had a limited range, and interfered with the transmissions of other transmitters on adjacent frequencies. \n\nAfter 1905 new types of radiotelegraph transmitters were invented which transmitted code using a new modulation method: continuous waves (CW) (designated by the International Telecommunication Union as emission type A1A). As long as the telegraph key was pressed, the transmitter produced a continuous sinusoidal wave of a constant amplitude. Since all the radio wave's energy was concentrated at a single frequency, CW transmitters could transmit further with a given power, and also caused virtually no interference to transmissions on adjacent frequencies. The first transmitters able to produce continuous waves were the arc converter (Poulsen arc) transmitter, invented by Danish engineer Valdemar Poulsen in 1903, and the Alexanderson alternator, invented 1906-1912 by Reginald Fessenden and Ernst Alexanderson. These slowly replaced the spark transmitters in high power radiotelegraphy stations. \n\nHowever the radio receivers used for damped waves could not receive continuous waves. Because the CW signal produced while the key was pressed was just an unmodulated carrier wave, it made no sound in a receiver's earphones. In order to receive a CW signal, some way had to be found to make the Morse code carrier wave pulses audible in a receiver. \n\nThis problem was solved by Reginald Fessenden in 1901. In his \"heterodyne\" receiver, the incoming radiotelegraph signal is mixed in the receiver's detector crystal or vacuum tube with a constant sine wave generated by an electronic oscillator in the receiver called a beat frequency oscillator (BFO). The frequency of the oscillator formula_1 is offset from the radio transmitter's frequency formula_2. In the detector the two frequencies subtract, and a beat frequency (heterodyne) at the difference between the two frequencies is produced: formula_3. If the BFO frequency is near enough to the radio station's frequency, the beat frequency is in the audio frequency range and can be heard in the receiver's earphones. During the \"dots\" and \"dashes\" of the signal, the beat tone is produced, while between them there is no carrier so no tone is produced. Thus the Morse code is audible as musical \"beeps\" in the earphones. \n\nThe BFO was rare until the invention in 1913 of the first practical electronic oscillator, the vacuum tube feedback oscillator by Edwin Armstrong. After this time BFOs were a standard part of radiotelegraphy receivers. Each time the radio was tuned to a different station frequency, the BFO frequency had to be changed also, so the BFO oscillator had to be tunable. In later superheterodyne receivers from the 1930s on, the BFO signal was mixed with the constant intermediate frequency (IF) produced by the superheterodyne's detector. Therefore the BFO could be a fixed frequency. \n\nContinuous wave vacuum tube transmitters replaced the other types of transmitter with the availability of power tubes after World War 1 because they were cheap. CW became the standard method of transmitting radiotelegraphy by the 20s, damped wave spark transmitters were banned by 1930 and CW continues to be used today. Even today most communications receivers produced for use in shortwave communication stations have BFOs.\n\nThe International Radiotelegraph Union was unofficially established at first International Radiotelegraph Convention in 1906, and was merged into the International Telecommunication Union in 1932. When the United States entered World War I, private radiotelegraphy stations were prohibited, which put an end to several pioneers' work in this field. By the 1920s, there was a worldwide network of commercial and government radiotelegraphic stations, plus extensive use of radiotelegraphy by ships for both commercial purposes and passenger messages. The transmission of sound (radiotelephony) began to displace radiotelegraphy by the 1920s for many applications, making possible radio broadcasting. Wireless telegraphy continued to be used for private person-to-person business, governmental, and military communication, such as telegrams and diplomatic communications, and evolved into radioteletype networks. The ultimate implementation of wireless telegraphy was telex, using radio signals, which was developed in the 1930s and was for many years the only reliable form of communication between many distant countries. The most advanced standard, CCITT R.44, automated both routing and encoding of messages by short wave transmissions. \n\nToday, due to more modern text transmission methods, Morse code radiotelegraphy for commercial use has become obsolete. On shipboard the computer and satellite linked GMDSS system has largely replaced Morse as a means of communication.\n\n\n\nListed by date [\"latest to earliest\"]\n\n"}
{"id": "18952287", "url": "https://en.wikipedia.org/wiki?curid=18952287", "title": "Woody plant", "text": "Woody plant\n\nA woody plant is a plant that produces wood as its structural tissue. Woody plants are usually either trees, shrubs, or lianas. These are usually perennial plants whose stems and larger roots are reinforced with wood produced from secondary xylem. The main stem, larger branches, and roots of these plants are usually covered by a layer of bark. Wood is a structural cellular adaptation that allows woody plants to grow from above ground stems year after year, thus making some woody plants the largest and tallest terrestrial plants.\n\nWood is primarily composed of xylem cells with cell walls made of cellulose and lignin. Xylem is a vascular tissue which moves water and nutrients from the roots to the leaves. Most woody plants form new layers of woody tissue each year, and so increase their stem diameter from year to year, with new wood deposited on the inner side of a vascular cambium layer located immediately beneath the bark. However, in some monocotyledons such as palms and dracaenas, the wood is formed in bundles scattered through the interior of the trunk.\n\nWoody herbs are herbaceous plants that develop hard woody stems. They include such plants as \"Uraria picta\" and certain species in family Polygonaceae. These herbs are not truly woody but have hard densely packed stem tissue. Other herbaceous plants have woody stems called a caudex, which is a thickened stem base often found in plants that grow in alpine or dry environments.\n\nUnder specific conditions, woody plants may decay or may in time become petrified wood.\n\nThe symbol for a woody plant, based on \"Species Plantarum\" by Linnaeus is , which is also the astronomical symbol for the planet Saturn.\n\n"}
