{"id": "3305260", "url": "https://en.wikipedia.org/wiki?curid=3305260", "title": "Albanian Wikipedia", "text": "Albanian Wikipedia\n\nThe Albanian Wikipedia () is the Albanian language edition of Wikipedia started on October 12, 2003. As of 03, 2018 the Wikipedia has articles and is the 73rd largest Wikipedia.\n\n\n"}
{"id": "7973428", "url": "https://en.wikipedia.org/wiki?curid=7973428", "title": "Anfinsen's dogma", "text": "Anfinsen's dogma\n\nAnfinsen's dogma (also known as the thermodynamic hypothesis) is a postulate in molecular biology that states that, at least for a small globular protein in its standard physiological environment, the native structure is determined only by the protein's amino acid sequence. The dogma was championed by the Nobel Prize Laureate Christian B. Anfinsen from his research on the folding of ribonuclease A. The postulate amounts to saying that, at the environmental conditions (temperature, solvent concentration and composition, etc.) at which folding occurs, the native structure is a unique, stable and kinetically accessible minimum of the free energy.\nThe three conditions:\n\nHow the protein reaches this structure is the subject of the field of protein folding, which has a related concept called Levinthal's paradox. The Levinthal paradox states that the number of possible conformations available to a given protein is astronomically large, such that even a small protein of 100 residues would require more time than the universe has existed (10 seconds) to explore all possible conformations and choose the appropriate one, it would also arguably make computational prediction of protein structures under the same basis unfeasible if not impossible.\n\nAlso, some proteins need the assistance of another protein called a chaperone protein to fold properly. It has been suggested that this disproves Anfinsen's dogma. However, the chaperones do not appear to affect the final state of the protein; they seem to work primarily by preventing aggregation of several protein molecules prior to the final folded state of the protein.\n\nPrions are an exception to Anfinsen's dogma. Prions are stable conformations of proteins which differ from the native folding state. In Bovine spongiform encephalopathy (Mad Cow Disease), native proteins re-fold into a different stable conformation, which causes fatal amyloid buildup. Other amyloid diseases, including Alzheimer's disease and Parkinson's disease, are also exceptions to Anfinsen's dogma.\n\n"}
{"id": "2555865", "url": "https://en.wikipedia.org/wiki?curid=2555865", "title": "Aura (symptom)", "text": "Aura (symptom)\n\nAn aura is a perceptual disturbance experienced by some with migraines or seizures. The aura stage precedes a seizure in epilepsy but can happen at any stage of a migraine. It often manifests as the perception of a strange light, an unpleasant smell, or confusing thoughts or experiences. Some people experience aura without a subsequent migraine or seizure (see silent migraine). Auras vary by individual experience; some people experience smells, lights, or hallucinations. Less known symptoms of the eye include disturbances, where the eyes roll in the back of the head caused by photosensitivity. A sufferer of this type of aura may experience tearfulness of the eyes and uncontrollable sensations of light followed by reduced symptoms after approximately 20 minutes; it is the rarest type of aura.\n\nWhen occurring, auras allow people who have epilepsy time to prevent injury to themselves and/or others. The time between the appearance of the aura and the migraine lasts from a few seconds up to an hour. The aura can stay with a migraine sufferer for the duration of the migraine; depending on the type of aura, it can leave the person disoriented and confused. It is common for migraine sufferers to experience more than one type of aura during the migraine. Most people who have auras have the same type of aura every time.\n\nAuras can also be confused with sudden onset of panic, panic attacks or anxiety attacks creating difficulties in diagnosis. The differential diagnosis of patients who experience symptoms of paresthesias, derealization, dizziness, chest pain, tremors, and palpitations can be quite challenging.\n\nAn epileptic aura is the consequence of the activation of functional cortex by abnormal, unilateral, and brief neuronal discharge. In addition to being a warning sign to an upcoming seizure, the nature of an aura can give insight into the localization and lateralization of the seizure or migraine.\n\nNot everyone experiences an aura with a seizure, but the most common auras include motor, somatosensory, visual, and auditory symptoms. The activation in the brain during an aura can spread through multiple regions continuously or discontinuously, on the same side or to both sides.\n\nAuras are particularly common in focal seizures. If the motor cortex is involved in the overstimulation of neurons, motor auras can result. Likewise, somatosensory auras (such as tingling, numbness, and pain) can result if in the somatosensory cortex. When the primary somatosensory cortex is activated, more discrete parts on the opposite side of the body and the secondary somatosensory areas result in symptoms ipsilateral to the seizure focus.\n\nVisual auras can be simple or complex. Simple visual symptoms can include static, flashing, or moving lights/shapes/colors caused mostly by abnormal activity in the primary visual cortex. Complex visual auras can include people, scenes, and objects which results from stimulation of the temporo-occipital junction and is lateralized to one hemifield. Auditory auras can also be simple (ringing, buzzing) or complex (voices, music). Simple symptoms can occur from activation in the primary auditory cortex and complex symptoms from the temporo-occipital cortex at the location of the auditory association areas.\n\nAn aura sensation can include some or a combination of the following:\n\n\n\n\n\n"}
{"id": "32828909", "url": "https://en.wikipedia.org/wiki?curid=32828909", "title": "B. D. Ganapathy", "text": "B. D. Ganapathy\n\nB. D. Ganapathy (Bācamāḍa Ḍevaiah Gaṇapati) was a noted writer, scholar and journalist writing in English, Kannada and Kodava Takk, covering religion, anthropology and philosophy. He is particularly noted for his coverage of the Kodagu (Coorg) region and the Kodava ethno-linguistic group, his own birthplace and community.\n\nGanapathy was born in Besagoor village in Coorg in 1920. He was a journalist for a newspaper in Karnataka state, and author of several books on Kodavas and other subjects in Kodava Takk, Kannada and English languages.\n\nDuring the Indian Independence Movement, he was the sub-editor of the \"Kodagu\", a pro-Independence weekly Kannada newspaper founded by his father-in-law, editor and freedom fighter Pandyanda I. Belliappa, who was known as Kodagu's Gandhi. In 1942 the British India authorities restricted the publication of the \"Kodagu\" weekly and had B. D. Ganapathy imprisoned along with his father-in-law.\n\nAmong Ganapathy's most noted works is his 1967 \"Kodavas (Coorgs), their customs and culture\" published by the Kodagu Ltd., also called the Coorg company, which owned the \"Kodagu\" weekly. Other works include: \"The Eternal Quest\" (1970), \"Naṅga Koḍava\" (1973 in Kodava takk), \"Kodavas\" (1980) and \"Kanni Kāvēri\" (1990 in Kodava Takk). Among his works two books are in the Kodava Language: \"Nanga Kodava\" and \"Kuttambolicha\". His Kannada book on Kodava culture \"Kodagu mattu Kodavaru\" has won him the State Academy Award. He wrote 11 works in 16 publications and in three languages. \n\nRecently, efforts are being made to foster Kodava literature and for the same purpose the Kodava Thak Parishat was established in 1978. The first conference was presided over by B. D. Ganapathi. A book has been written about him in 2002.\n\n\n"}
{"id": "58427", "url": "https://en.wikipedia.org/wiki?curid=58427", "title": "Back-bond", "text": "Back-bond\n\nBack-bond, or back-letter, in Scots law, is a deed qualifying the terms of another deed, or declaratory of the purposes for which another deed has been granted. Thus an ex facie absolute disposition, qualified by a back-bond expressing the limited nature of the right actually held by the person to whom the disposition is made, would constitute what in England is termed a deed of trust.\n"}
{"id": "3245932", "url": "https://en.wikipedia.org/wiki?curid=3245932", "title": "Bento Teixeira", "text": "Bento Teixeira\n\nBento Teixeira (1561? – 1618?) was a Portuguese poet. He is considered to be the introducer of Baroque in the Portuguese colony of Brazil and the first Brazilian poet — however, this last affirmation is contested by many historians.\n\nDetails about Teixeira's life are very sparse. His birthplace is most commonly accepted to be Porto, Portugal, to Manuel Álvares de Barros and Lianor Rodrigues. Teixeira moved to the colony of Brazil in 1567(?), first living in Bahia, but he had to flee to Pernambuco when he was accused of being a Jew.\n\nIn Pernambuco, Bento Teixeira became a teacher of Arithmetics, Grammar and Latin. Returning to Bahia, he married Filipa Raposa in the city of Ilhéus, in 1584(?).\n\nAllegedly, Teixeira murdered his wife under suspects of adultery, what made him flee to Pernambuco once more. Refugiated at the Monastery of São Bento, he wrote his masterpiece \"Prosopopeia\".\n\nAnother version tells that Teixeira's wife accused him of being Jewish. After being interrogated and absolved in 1589, he was intimated by the caller of the Portuguese Inquisition, and Teixeira then confessed that he was a follower of the Judaism. Enraged by his wife's delation, he murdered her and fled to the aforementioned monastery. However, he was found, arrested and sent to Lisbon in 1595(?), staying there until his death.\n\nMany works were attributed to Teixeira, such as:\n\n\nThe only one whose authorship is confirmed was the epic poem \"Prosopopeia\", written in 1601. The poem, inspired by Luís de Camões' \"Os Lusíadas\", tells about the life and works of the then-governor of Pernambuco Jorge de Albuquerque Coelho and his brother Duarte.\n\n"}
{"id": "31849035", "url": "https://en.wikipedia.org/wiki?curid=31849035", "title": "Bible translations into Serbian", "text": "Bible translations into Serbian\n\nThere are many translations of the Bible into Serbian and Serbo-Croatian language.\n\nThe first translation in Serbian is the famous Miroslav Gospel from 1186. It is currently in the National Museum of Serbia in Belgrade and is valued as the national treasure.\n\nThe first printed Bible was of Atanasije Stojković (published by the Russian Bible Society at Saint Petersburg, 1824) but was not written in the vernacular Serbian, but was a mixture of Church Slavonic and Serbian. Stojković later translated the New Testament to Serbian in 1830. A more popular translation of the New Testament by Vuk Karadžić was published in Vienna in 1847, and was combined with the translation of the Old Testament of 1867 by Đuro Daničić in Belgrade, printed together in 1868.\n\nOther subsequent translations are the following:\n\n\n"}
{"id": "35328411", "url": "https://en.wikipedia.org/wiki?curid=35328411", "title": "Bible translations into the languages of Africa", "text": "Bible translations into the languages of Africa\n\nThe Bible, or portions of it, have been translated into over 1,000 languages of Africa. Many of these are indexed by the Forum of Bible Agencies, Find.Bible site and available online in text and audio form, as print on demand versions, or through churches and book sellers. This effort continues. Not all are (yet) listed below.\n\nPart of the Bible in Bemba language was first published in 1904, followed by the New Testament in 1916, and the entire Bible in 1956. Currently a revision is in progress. Paul Mushindo and the Scottish missionary Robert McMinn worked together on Bible translation into the Bemba language for over twenty years.\n\nThe Chichewa, in Zambia still called the more neutral Chinyanja, Bible was translated by William Percival Johnson in 1912. This older version is bound as Buku Lopatulika. The Bible Society of Malawi records that the Buku Lopatulika translation was first published in 1922, revised in 1936 and 1966. A Jubilee edition was produced to commemorate Malawi's 50 years of independence. The new Buku Loyera version is a contemporary Chichewa dynamic equivalent translation first published in 1998.\n\nDinis Sengulane, an Anglican of the Mozambican Diocese of Lebombo, translated into Tshopi.\n\n\"Malangano Ga Sambano\" is the New Testament in the Ciyawo language (Chiyao, Chiyawo). It is published by the Bible Society of Malawi (2011)\n\nBritish Anglican Thomas John Dennis translated the Bible into a \"standard\" \"Union Igbo\" by 1913. This version was very influential but criticised by artists, among them Chinua Achebe, as stultifying the Igbo language. The Igbo Living Bible was published in 1988.\n\nJohann Heinrich Schmelen translated into the Khoekhoe language (formerly \"Hottentot\") of the Nama people of Namibia.\n\nJohann Ludwig Krapf, a German, translated parts of the New Testament into Kamba language.\n\n\nThe Bible was translated into the Malagasy language by David Jones (missionary) and David Griffiths, with the New Testament appearing in 1830.\n\nJohann Ludwig Krapf translated into Mijikenda languages.\n\nOromo is a language of Ethiopia and Kenya. The New Testament was published in 1893, the complete Bible in 1899, the work of Aster Ganno and Onesimos Nesib. A new translation of the entire Bible was published by the Ethiopian Bible Society in 1992.\n\nMartti Rautanen - Finnish Missionary Society, into Oshindonga dialect of the Ovambo language of Namibia.\n\nGottlieb Viehe - German, into Otjiherero language of Namibia.\n\nRobert Moffat - Congregationalist, translated into Setswana language.\n\nSamuel Rolland (1801–1873), first missionary of the Paris Missionary Society, translated some parts of the New Testament and several hymns into Sotho language in the 1840s. Today there are Northern Sotho and Southern Sotho versions.\n\nThe first translation of parts of the Bible into Swahili was accomplished by 1868, with a complete New Testament translation following in 1879 and a translation of the whole Bible in 1890. Since that time, there have been several translations into different dialects of Swahili as spoken in different regions of East Africa; these include the \"Union Translation\" published by the Bible Society of Tanzania in 1950 and the \"Swahili Common Language\" version.\nHenry Hare Dugmore, a Methodist, translated into Xhosa language. Tiyo Soga (1829–1871) was ordained the first African Presbyterian minister in 1856 and also translated.\n\"Ndandililo ni Kutyoka\" is a translation of the books of Genesis and Exodus from the Old Testament into the Yao language published by The Bible Society of Malawi, Blantyre, Malawi 2004.\n\nSamuel Ajayi Crowther translated the Bible into Yoruba language and concluded it in the mid-1880s known as \"Bibeli Mimo\". The complete Yoruba Bible was first published in 1884.\nIn 1837, the first portions of the Bible in the Zulu language were published; in the \"First Book for Readers,\" portions of Genesis and two Psalms were published. The first book of the Bible to be translated into the Zulu language was Matthew's Gospel, published in 1848 by the American Board of Commissioners for Foreign Missions (ABCFM). This was translated by George Champion (missionary) and revised by Newton Adams. The completed New Testament was published in 1865, translated by several missionaries of the ABCFM. The complete Bible, also translated by many members of the ABCFM, corrected by Andrew Abraham, and finally edited by S. C. Pixley, was published in 1883. It was revised in 1959 and published in London by the British and Foreign Bible Society. A Modern Zulu New Testament and the Psalms was completed in 1986 and published in Cape Town by the Bible Society of South Africa. This was translated by Dean Nils Joëlson, and project co-ordinated by Mr. D. T. Maseko and Mr. K. Magubane. John William Colenso and Hans Paludan Smith Schreuder are also said to have worked on the Zulu Bible translation.\n"}
{"id": "23018087", "url": "https://en.wikipedia.org/wiki?curid=23018087", "title": "Birhor language", "text": "Birhor language\n\nThe Birhor language is a highly endangered Munda language spoken by the Birhor people in Chhattisgarh, Odisha, West Bengal, and Maharashtra states in India.\n\nAccording to Vidyarthi (1960:519), the Birhor are found mostly in Chota Nagpur and Santhal Paragana, with the Uthlu Birhors living near Bishunpur, Gumla district, Jharkhand (along the western border with Chhattisgarh).\n\nMost Birhor know Santali and Hindi, and a small minority know Ho. However, children still learn the language, and Birhor families use the language all the time at home. In addition, most Birhor want to be educated in their own language, and the language is used in most community affairs.\n\n\n"}
{"id": "46682115", "url": "https://en.wikipedia.org/wiki?curid=46682115", "title": "BulPosCor", "text": "BulPosCor\n\nThe Bulgarian Part of Speech-annotated Corpus (BulPosCor) (in Bulgarian: Български Пос анотиран корпус (БулПосКор)) is a morphologically annotated general monolingual corpus of written language where each item in a text is assigned a grammatical tag. BulPosCor is created by the Department of Computational Linguistics at the Institute for Bulgarian Language of the Bulgarian Academy of Sciences and consists of 174 697 lexical items.\nBulPosCor has been compiled from the Structured \"Brown\" Corpus of Bulgarian by sampling 300+ word-excerpts (expanded to sentence boundary) from the original BCB files in such a way as to preserve the BCB overall structure. The annotation process consists of a primary stage of automatically assigning tags from the Bulgarian Grammar Dictionary and a stage of manual resolving of morphological ambiguities.The disambiguated corpus consists of 174,697 lexical units.\n\nBulPOSCor Search Interface\n\nKoeva, Sv. Gramatichen Rechnik na Balgarskiya ezik.Opisanie na koncepciyata za organizaciyata na lingvistichnite danni. (Grammatical Dictionary of Bulgarian.), в: Български език, 6, 1998, с. 49-58.\nKoeva, Sv., Sv. Leseva, I. Stoyanova, E. Tarpomanova, M. Todorova. Bulgarian Tagged Corpora, Proceedings of the Fifth International Conference Formal Approaches to South Slavic and Balkan Languages, 18–20 October 2006, Sofia, Bulgaria, pp. 78–86.\nTodorova, Maria, Rositsa Dekova. Balgarski POS anotiran korpus – osobenosti na gramatichnata anotaciya. (Bulgarian POS annoted corpus – specifics of the grammatical annotation) в: Езикови ресурси и технологии за български език. Състав. и научн. ред. Св. Коева, Д. Благоева, Т. Тинчев. София: Академично издателство „Марин Дринов“, 2014.\n\n\n"}
{"id": "33183627", "url": "https://en.wikipedia.org/wiki?curid=33183627", "title": "Cerma language", "text": "Cerma language\n\nCerma (Kirma) is a Gur language of Burkina Faso. It is spoken by the Gouin people (sometimes called \"Ciramba ( ← Cerma-ba)\" or \"Gouin (Gwe, Gwen)\").\n"}
{"id": "61762", "url": "https://en.wikipedia.org/wiki?curid=61762", "title": "Class (biology)", "text": "Class (biology)\n\nIn biological classification, class () is a taxonomic rank, as well as a taxonomic unit, a taxon, in that rank. Other well-known ranks in descending order of size are life, domain, kingdom, phylum, order, family, genus, and species, with class fitting between phylum and order. As for the other well-known ranks, there is the option of an immediately lower rank, indicated by the prefix \"sub-\": subclass (Latin: \"subclassis\"). For example, dogs are in the class Mammalia.\n\nThe composition of each class is determined by a taxonomist. Often there is no exact agreement, with different taxonomists taking different positions. There are no hard rules that a taxonomist needs to follow in describing a class, but for well-known animals there is likely to be consensus. \n\nIn botany, classes are now rarely discussed. Since the first publication of the APG system in 1998, which proposed a taxonomy of the flowering plants up to the level of orders, many sources have preferred to treat ranks higher than orders as informal clades. Where formal ranks have been assigned, the ranks have been reduced to a very much lower level, e.g. class Equisitopsida for the land plants, with the major divisions within the class assigned to subclasses and superorders.\n\nFor some clades, a number of alternative classifications are used.\n\nThe class as a distinct rank of biological classification having its own distinctive name (and not just called a \"top-level genus\" \"(genus summum)\") was first introduced by the French botanist Joseph Pitton de Tournefort in his classification of plants that appeared in his \"Eléments de botanique\", 1694.\n\nIn the first edition of his \"Systema Naturae\" (1735). Carl Linnaeus divided all three of his kingdoms of Nature (minerals, plants, and animals) into classes. Only in the animal kingdom are Linnaeus's classes similar to the classes used today; his classes and orders of plants were never intended to represent natural groups, but rather to provide a convenient \"artificial key\" according to his \"Systema Sexuale\", largely based on the arrangement of flowers.\n\nThe class was considered the highest level of the taxonomic hierarchy until George Cuvier's \"embranchements\", first called Phyla by Ernst Haeckel, were introduced in the early nineteenth century.\n\n"}
{"id": "39582405", "url": "https://en.wikipedia.org/wiki?curid=39582405", "title": "Darbar (title)", "text": "Darbar (title)\n\nDarbar (Persian: دربار, Urdu: دربار, Pashto: دربار, Hindi: दरबार, Bengali: দরবার, Nepali: दरबार) is a South Asian word mainly derived from Persian language and also equally common in all South Asian languages. It was the term used for the court or levee of the prince; an audience chamber or a place where Muslim Kings and other rulers had their formal and informal meetings, i.e. in European context, equivalent to a king's court.\n\nDarbar is a Persian-derived term (from Persian: دربار - darbār) meaning the court or place of discussion of king, Prince, ruler or noble court. It was later used in Pakistan, India and Nepal for a ruler's court or feudal levee as the latter came to be ruled and later administered by foreigners. A darbar may be either a feudal state council for administering the affairs of a princely state, or a Muslim shrine like data darbar in Lahore.\n"}
{"id": "42341374", "url": "https://en.wikipedia.org/wiki?curid=42341374", "title": "Demushbo language", "text": "Demushbo language\n\nDemushbo (Dëmushbo), or ambiguously \"Remo\", is an extinct Panoan language of the Brazilian Amazon basin, near the Peruvian border.\n"}
{"id": "34708696", "url": "https://en.wikipedia.org/wiki?curid=34708696", "title": "Determinantal conjecture", "text": "Determinantal conjecture\n\nIn mathematics, the determinantal conjecture of and asks whether the determinant of a sum \"A\" + \"B\" of two \"n\" by \"n\" normal complex matrices \"A\" and \"B\" lies in the convex hull of the \"n\"! points Π (\"λ(A)\" + \"λ(B)\"), where the numbers \"λ(A)\" and \"λ(B)\" are the eigenvalues of \"A\" and \"B\", and \"σ\" is an element of the symmetric group \"S\".\n\n"}
{"id": "19985174", "url": "https://en.wikipedia.org/wiki?curid=19985174", "title": "Dutch language", "text": "Dutch language\n\nDutch is a West Germanic language spoken by around 23 million people as a first language and 5 million people as a second language, constituting the majority of people in the Netherlands (where it is the sole official language) and Belgium (as one of three official languages). It is the third most widely spoken Germanic language, after its close relatives English and German.\n\nOutside the Low Countries, it is the native language of the majority of the population of Suriname where it also holds an official status, as it does in Aruba, Curaçao and Sint Maarten, which are constituent countries of the Kingdom of the Netherlands located in the Caribbean. Historical linguistic minorities on the verge of extinction remain in parts of France and Germany, and in Indonesia, while up to half a million native speakers may reside in the United States, Canada and Australia combined. The Cape Dutch dialects of Southern Africa have evolved into Afrikaans, a mutually intelligible daughter language which is spoken to some degree by at least 16 million people, mainly in South Africa and Namibia.\n\nDutch is one of the closest relatives of both German and English and is colloquially said to be \"roughly in between\" them. Dutch, like English, has not undergone the High German consonant shift, does not use Germanic umlaut as a grammatical marker, has largely abandoned the use of the subjunctive, and has levelled much of its morphology, including most of its case system. Features shared with German include the survival of two to three grammatical genders—albeit with few grammatical consequences—as well as the use of modal particles, final-obstruent devoicing, and a similar word order. Dutch vocabulary is mostly Germanic and incorporates slightly more Romance loans than German but far fewer than English. As with German, the vocabulary of Dutch also has strong similarities with the continental Scandinavian languages, but is not mutually intelligible in text or speech with any of the three.\n\nIn both Belgium and the Netherlands, the native official name for Dutch is \"Nederlands\". Sometimes \"Vlaams\" (\"Flemish\") is used as well to describe Standard Dutch in Flanders. Over time, the Dutch language has been known under a variety of names. In Middle Dutch \"Dietsc\", \"Duutsc\", or \"Duitsc\" was used. It derived from the Old Germanic word \"theudisk\", which literally means \"popular\" or \"belonging to the populace\". In Western Europe this term was used for the language of the local Germanic populace as opposed to Latin, the non-native language of writing and the Catholic Church. In the first text in which it is found, dating from 784, \"theodisce\" refers to Anglo-Saxon, the West Germanic dialects of Britain.\n\nOwing to commercial and colonial rivalry in the 16th and 17th centuries between England and the Low Countries, a cognate of \"theodisk\" (most likely Middle Dutch \"Duutsc\") was borrowed into English and developed into the exonym \"Dutch\", which came to refer exclusively to the people of the Netherlands. (A usage of the English term \"Dutch\" that includes German survives in the United States in the name Pennsylvania Dutch for a local German dialect and its speakers, commonly believed to be a corruption of their endonym \"Deitsch\".) In the Low Countries on the contrary, \"Dietsch\" or \"Duytsch\" as endonym for Dutch went out of common use and was gradually replaced by the Dutch endonym \"Nederlands\". This designation started at the Burgundian court in the 15th century, although the use of \"neder\", \"laag\", \"bas\", and \"inferior\" (\"nether\" or \"low\") to refer to the area known as the Low Counties goes back further in time. The Romans referred to the region as \"Germania Inferior\" (\"Lower\" Germania). It is a reference to the Low Countries' downriver location at the Rhine–Meuse–Scheldt delta near the North Sea.\n\nFrom 1551 the designation \"Nederlands\" received strong competition from the name \"Nederduits\" (\"Low Dutch;\" \"Dutch\" is used here in its archaic sense that covers all continental West Germanic languages). It is a calque of the before mentioned Roman province \"Germania Inferior\" and an attempt by early Dutch grammarians to give their language more prestige by linking it to Roman times. Likewise, \"Hoogduits\" (\"High Dutch\") came into use as a Dutch exonym for the German language, spoken in neighboring German states. However, 19th century Germany saw the rise of the categorisation of dialects, and German dialectologists termed the German dialects spoken in the mountainous south of Germany as \"Hochdeutsch\" (\"High German\"). Subsequently, German dialects spoken in the north were designated as \"Niederdeutsch\" (\"Low German\"). The names for these dialects were calqued in the Dutch language area as the exonyms \"Nederduits\" and \"Hoogduits\". As a result, \"Nederduits\" no longer served as a synonym for the Dutch language, and \"Nederlands\" prevailed as sole Dutch endonym. It also meant that \"Hoog\" (\"High\") had to be dropped in one of the two meanings of \"Hoogduits\", leading to the narrowing down of \"Duits\" as Dutch exonym for the German language, and \"Hoogduits\" as reference for southern German dialects.\n\nOld Dutch branched off more or less around the same time as Old English (Anglo-Saxon), Old High German, Old Frisian and Old Saxon did. The early form of Dutch was a set of Franconian dialects spoken by the Salian Franks in the fifth century, and thus, it has developed through Middle Dutch to Modern Dutch over the course of 15 centuries. During that period, it forced Old Frisian back from the western coast to the north of the Low Countries, and influenced or even replaced Old Saxon spoken in the east (contiguous with the Low German area). On the other hand, Dutch has been replaced in adjacent lands in present-day France and Germany. The division into Old, Middle and Modern Dutch is mostly conventional, since the transition between them was very gradual. One of the few moments when linguists can detect something of a revolution is when the Dutch standard language emerged and quickly established itself. The development of the Dutch language is illustrated by the following sentence in Old, Middle and Modern Dutch:\n\nAmong the Indo-European languages, Dutch is grouped within the Germanic languages, meaning it shares a common ancestor with languages such as English, German, and the Scandinavian languages. All Germanic languages are subject to the Grimm's law and Verner's law sound shifts, which originated in the Proto-Germanic language and define the basic features differentiating them from other Indo-European languages. This is assumed to have taken place in approximately the mid-first millennium BCE in the pre-Roman Northern European Iron Age.\n\nThe Germanic languages are traditionally divided into three groups: East (now extinct), West, and North Germanic. They remained mutually intelligible throughout the Migration Period. Dutch is part of the West Germanic group, which also includes English, Scots, Frisian, Low German (Old Saxon) and High German. It is characterized by a number of phonological and morphological innovations not found in North or East Germanic. The West Germanic varieties of the time are generally split into three dialect groups: Ingvaeonic (North Sea Germanic), Istvaeonic (Weser-Rhine Germanic) and Irminonic (Elbe Germanic). It appears that the Frankish tribes fit primarily into the Istvaeonic dialect group with certain Ingvaeonic influences towards the northwest, which are still seen in modern Dutch.\n\nThe Frankish language itself is poorly attested. A notable exception is the Bergakker inscription, found near the Dutch city of Tiel, which may represent a primary record of 5th-century Frankish. Although some place names recorded in Roman texts such as ' (modern Dutch: ', English: \"mudflat\"), could arguably be considered as the oldest single \"Dutch\" words, the Bergakker inscription yields the oldest evidence of Dutch morphology. However, there is no consensus on the interpretation of the rest of the text.\n\nThe Franks emerged in the southern Netherlands (Salian Franks) and central Germany (Ripuarian Franks), and later descended into Gaul. The name of their kingdom survives in that of France. Although they ruled the Gallo-Romans for nearly 300 years, their language, Frankish, became extinct in most of France and was replaced by later forms of the language throughout Luxembourg and Germany in around the 7th century. It was replaced in France by Old French (a Romance language with a considerable Old Frankish influence). \n\nHowever, the Old Franconian language did not die out at large, as it continued to be spoken in the Low Countries, and subsequently evolved into what is now called Old Low Franconian or Old Dutch in the Low Countries. In fact, Old Frankish could be reconstructed from Old Dutch and Frankish loanwords in Old French.\n\nOld Low Franconian or Old Dutch is regarded as the prime ancestor of a separate Dutch language. The \"Low\" in Old Low Franconian refers to the Low Countries, where Frankish was only minimally influenced by the High German consonant shift and the Ingvaeonic nasal spirant law. The High German consonant shift, moving over Western Europe from south to west, caused a differentiation with the Central and High Franconian in Germany. The latter would as a consequence evolve (along with Alemannic, Bavarian and Lombardic) into Old High German. At more or less the same time the Ingvaeonic nasal spirant law, moving over Western Europe from west to east, led to the development of Old English (or Anglo-Saxon), Old Frisian and Old Saxon. Hardly influenced by either development, Old Dutch remained close to the original language of the Franks, the people that would rule Europe for centuries. The language did however experience developments of its own, such as very early final-obstruent devoicing. In fact, the find at Bergakker indicates that the language may already have experienced this shift during the Old Frankish period.\n\nAttestations of Old Dutch sentences are extremely rare. The language is mostly recorded on fragmentary relics, and words have been reconstructed from Middle Dutch and loan words from Old Dutch in other languages. The oldest recorded is found in the Salic law. In this Frankish document written around 510 the oldest Dutch sentence has been identified: \"Maltho thi afrio lito\" (\"I say to you, I free you, serf\") used to free a serf. Another old fragment of Dutch is \"Visc flot aftar themo uuatare\" (\"A fish was swimming in the water\"). The oldest conserved larger Dutch text is the Utrecht baptismal vow (776–800) starting with \"Forsachistu diobolae ... ec forsacho diabolae\" (\"Do you forsake the devil? ... I forsake the devil\"). If only for its poetic content, the most famous Old Dutch sentence is probably \"Hebban olla vogala nestas hagunnan, hinase hic enda tu, wat unbidan we nu\" (\"All birds have started making nests, except me and you, what are we waiting for\"), is dated to around the year 1100, written by a Flemish monk in a convent in Rochester, England. Since the sentence speaks to the imagination, it is often erroneously stated as the oldest Dutch sentence.\n\nOld Dutch naturally evolved into Middle Dutch. The year 1150 is often cited as the time of the discontinuity, but it actually marks a time of profuse Dutch writing and during this period a rich Medieval Dutch literature developed. There was at that time no overarching standard language; Middle Dutch is rather a collective name for a number of closely related mutually intelligible dialects whose ancestor was Old Dutch. Where Old Dutch fragments are very hard to read for untrained Modern Dutch speakers, the various literary works of Middle Dutch are somewhat more accessible. The most notable difference between Old and Middle Dutch is in a feature of speech known as vowel reduction. Round vowels in word-final syllables are rather frequent in Old Dutch; in Middle Dutch, such vowels are leveled to a schwa.\n\nThe Middle Dutch dialect areas were affected by political boundaries. The sphere of political influence of a certain ruler often also created a sphere of linguistic influence, with the language within the area becoming more homogenous. Following the contemporary political divisions they are in order of importance:\n\nA process of standardisation started in the Middle Ages, especially under the influence of the Burgundian Ducal Court in Dijon (Brussels after 1477). The dialects of Flanders and Brabant were the most influential around this time. The process of standardisation became much stronger at the start of the 16th century, mainly based on the urban dialect of Antwerp. The 1585 fall of Antwerp to the Spanish army led to a flight to the northern Netherlands, where the Dutch Republic declared its independence from Spain. This influenced the urban dialects of the province of County of Holland. In 1637, a further important step was made towards a unified language, when the Statenvertaling, the first major Bible translation into Dutch, was created that people from all over the new republic could understand. It used elements from various, even Dutch Low Saxon, dialects but was predominantly based on the urban dialects of Holland of post 16th century.\n\nIn the Southern Netherlands (now Belgium and Luxembourg), developments were different. Under subsequent Spanish, Austrian and French rule, the standardisation of Dutch language came to a standstill. The state, law, and increasingly education used French, yet more than half the Belgian population were speaking a variety of Dutch. In the course of the nineteenth century the Flemish Movement stood up for the rights of Dutch speakers, mostly which were referred to as \"Flemish\". However, the dialect variation was a serious disadvantage in the face of the standardised francophonie. Since standardisation is a lengthy process, Dutch-speaking Belgium associated itself with the standard language that had already developed in the Netherlands over the centuries. Therefore, the situation in Belgium is essentially no different from that in the Netherlands, although there are recognisable differences in pronunciation, comparable to the pronunciation differences between standard British and standard American English. In 1980 the Netherlands and Belgium concluded the Language Union Treaty. This treaty lays down the principle that the two countries must gear their language policy to each other, among other things, for a common system of spelling.\n\n\nDutch belongs to its own West Germanic sub-group, the Low Franconian languages, paired with its sister language Limburgish or East Low Franconian. Its closest relative is the mutually intelligible daughter language, Afrikaans. Other West Germanic languages related to Dutch are German, English and the Frisian languages and the un-standardised languages Low German and Yiddish.\n\nDutch stands out in combining some Ingvaeonic characteristics (occurring consistently in English and Frisian and reduced in intensity from west to east over the continental West Germanic plane) with dominant Istvaeonic characteristics, of which some of them are also incorporated in German. Unlike German, Dutch (apart from Limburgish) has not been influenced at all by the south to north movement of the High German consonant shift and had some changes of its own. The cumulation of these changes resulted over time in separate, but related standard languages with various degrees of similarities and differences between them. For a comparison between the West Germanic languages, see the sections Morphology, Grammar and Vocabulary.\n\nDutch dialects are primarily the dialects that are both related with the Dutch language and are spoken in the same language area as the Dutch standard language. Although heavily under the influence of the standard language, some of them remain remarkably diverse and are found in the Netherlands and northern Belgium. The areas in which they are spoken often correspond with former mediaeval counties and duchies. The Netherlands (but not Belgium) distinguishes between a dialect and a \"streektaal\" (\"regional language\"). Those words are actually more political than linguistic because a regional language unites a large group of very different varieties. Such is the case with the Gronings dialect, which is considered a variety of the Dutch Low Saxon regional language, but it is really very distinct from other Low Saxon varieties because of a Frisian substrate. Also, some Dutch dialects are more remote from the Dutch standard language than some varieties of a regional language are. Such is the case with West Flemish, which is considered a Dutch dialect but is far more remote from the standard language than most Dutch Low Saxon varieties are. Within the Netherlands, a further distinction is made between a regional language and a separate language, which is the case with the (standardised) West Frisian language. It is spoken alongside Dutch in the province of Friesland.\n\nDutch dialects and regional languages are not spoken as often as they used to be, especially in the Netherlands. Recent research by Geert Driessen shows that the use of dialects and regional languages among both Dutch adults and youth is in heavy decline. In 1995, 27 percent of the Dutch adult population spoke a dialect or regional language on a regular basis, but in 2011, that was no more than 11 percent. In 1995, 12 percent of children of primary school age spoke a dialect or regional language, but in 2011, that had declined to 4 percent. Of the officially recognized regional languages Limburgish is spoken the most (in 2011 among adults 54%, among children 31%) and Dutch Low Saxon the least (adults 15%, children 1%). The decline of the West Frisian language in Friesland occupies a middle position (adults 44%, children 22%). Dialects are most often spoken in rural areas, but many cities have a distinct city dialect. For example, the city of Ghent has very distinct \"g\", \"e\" and \"r\" sounds that greatly differ from its surrounding villages. The Brussels dialect combines Brabantian with words adopted from Walloon and French.\n\nSome dialects had, until recently, extensions across the borders of other standard language areas. In most cases, the heavy influence of the standard language has broken the dialect continuum. Examples are the Gronings dialect spoken in Groningen as well as the closely related varieties in adjacent East Frisia (Germany). South Guelderish (\"Zuid-Gelders\") is a dialect spoken in Gelderland (Netherlands) and the closely related varieties in adjacent parts of North Rhine-Westphalia (Germany). Limburgish (\"Limburgs\") is spoken in Limburg (Belgium) as well as in Limburg (Netherlands) and extends across the German border. West Flemish (\"Westvlaams\") is spoken in West Flanders, the western part of Zeelandic Flanders and also in French Flanders, where it virtually became extinct to make way for French.\n\nThe West Flemish group of dialects, spoken in West Flanders and Zeeland, is so distinct that it might be considered as a separate language variant, although the strong significance of language in Belgian politics would prevent the government from classifying them as such. An oddity of the dialect is that, the voiced velar fricative (written as \"g\" in Dutch) shifts to a voiced glottal fricative (written as \"h\" in Dutch), while the letter \"h\" becomes mute (just like in French). As a result, when West Flemings try to talk Standard Dutch, they're often unable to pronounce the g-sound, and pronounce it similar to the h-sound. This leaves, for example, no difference between \"held\" (hero) and \"geld\" (money). Or in some cases, they are aware of the problem, and hyper-correct the \"h\" into a voiced velar fricative or g-sound, again leaving no difference. The West Flemish variety historically spoken in adjacent parts in France is sometimes called French Flemish and is listed as a French minority language, however only a very small and aging minority of the French-Flemish population still speaks and understands West Flemish.\n\nHollandic is spoken in Holland and Utrecht, though the original forms of this dialect (which were heavily influenced by a West Frisian substratum and, from the 16th century on, by Brabantian dialects) are now relatively rare. The urban dialects of the Randstad, which are Hollandic dialects, do not diverge from standard Dutch very much, but there is a clear difference between the city dialects of Rotterdam, The Hague, Amsterdam and Utrecht. In some rural Hollandic areas more authentic Hollandic dialects are still being used, especially north of Amsterdam. Another group of dialects based on Hollandic is that spoken in the cities and larger towns of Friesland, where it partially displaced West Frisian in the 16th century and is known as Stadsfries (\"Urban Frisian\").\n\nBrabantian is named after the historical Duchy of Brabant, which corresponded mainly to the provinces of North Brabant and southern Gelderland, the Belgian provinces of Antwerp and Flemish Brabant, as well as Brussels (where its native speakers have become a minority) and the province of Walloon Brabant. Brabantian expands into small parts in the west of Limburg while its strong influence on the East Flemish of East Flanders and eastern Zeelandic Flanders weakens towards the west. In a small area in the northwest of North Brabant (Willemstad), Hollandic is spoken. Conventionally, the South Guelderish dialects are distinguished from Brabantian, but there are no objective criteria apart from geography to do so. Over 5 million people live in an area with some form of Brabantian being the predominant colloquial language out of the area's 22 million Dutch-speakers.\n\nLimburgish, spoken in both Belgian Limburg and Netherlands Limburg and in adjacent parts in Germany, is considered as a dialect in Belgium, while having obtained the status of official regional language in the Netherlands.\n\nThe Dutch Low Saxon dialect area, comprising the provinces of Groningen, Drenthe and Overijssel, and parts of the province of Gelderland as well. The IJssel roughly forms the linguistic watershed here. This group, which is not Low Franconian but instead Low Saxon and close to neighbouring Low German, has been elevated by the Netherlands (and by Germany) to the legal status of \"streektaal\" (regional language) according to the European Charter for Regional or Minority Languages. It is regarded as Dutch for a number of reasons. From the 14th to 15th century onward, its urban centers (Deventer, Zwolle, Kampen, Zutphen and Doesburg) have been increasingly influenced by the western written Dutch and became a linguistically mixed area. From the 17th century onward, it was gradually integrated into the Dutch language area. Dutch Low Saxon used to be at one end of the Low German dialect continuum. However, the national border has given way to dialect boundaries coinciding with a political border, because the traditional dialects are strongly influenced by the national standard varieties. Cross-the-border dialects now separated by a plain gap also include South Guelderish and Limburgish on the Dutch side of the border and Meuse-Rhenish on the German side of the border.\n\nLimburgish has the status of official regional language (or \"streektaal\") in the Netherlands and Germany, but not in Belgium. It receives protection by chapter 2 of the European Charter for Regional or Minority Languages. Limburgish has been influenced by the Ripuarian varieties like the Colognian dialect, and has had a somewhat different development since the late Middle Ages.\n\nAfrikaans, although to a significant degree mutually intelligible with Dutch, is not a dialect but a separate standardised language. It is spoken in South Africa and Namibia. As a daughter language of Dutch, Afrikaans evolved mainly from 17th century Dutch dialects, but was influenced by various other languages in South Africa.\n\nWest Frisian (\"Westerlauwers Fries\"), along with Saterland Frisian and North Frisian, evolved from the same branch of the West Germanic languages as Old English (i.e. Anglo-Frisian) and are therefore genetically more closely related to English and Scots than to Dutch. The different influences on the respective languages, however, particularly that of Norman French on English and Dutch on West Frisian, have rendered English quite distinct from West Frisian, and West Frisian less distinct from Dutch than from English. Although under heavy influence of the Dutch standard language, it is not mutually intelligible with Dutch and considered a sister language of Dutch, like English and German.\n\nDutch is an official language of the Netherlands proper, Belgium, Suriname, the Dutch Caribbean municipal (St. Eustatius Saba & Bonaire), Aruba, Curaçao and Sint Maarten. Dutch is also an official language of several international organisations, such as the European Union, Union of South American Nations and the Caribbean Community. At an academic level, Dutch is taught in about 175 universities in 40 countries. About 15,000 students worldwide study Dutch at university.\n\nIn Europe, Dutch is the majority language in the Netherlands (96%) and Belgium (59%) as well as a minority language in Germany and northern France's French Flanders, where it is in the ultimate stage of language death. Though Belgium as a whole is multilingual, the two regions into which the country is divided (Flanders, francophone Wallonia, bilingual Brussels and small \"facility\" zones) are largely monolingual. The Netherlands and Belgium produce the vast majority of music, films, books and other media written or spoken in Dutch. Dutch is a monocentric language, with all speakers using the same standard form (authorized by the Dutch Language Union) based on a Dutch orthography employing the Latin alphabet when writing. In stark contrast to its written uniformity, Dutch lacks a prestige dialect and has a large dialectal continuum consisting of 28 main dialects, which can themselves be further divided into at least 600 distinguishable varieties.\n\nOutside the Netherlands and Belgium, the dialect around the German town of Kleve (South Guelderish) both historically and genetically belongs to the Dutch language. In North-Western France, the area around Calais was historically Dutch-speaking (West Flemish), of which an estimated 20,000 are daily speakers. The cities of Dunkirk, Gravelines and Bourbourg only became predominantly French-speaking by the end of the 19th century. In the countryside, until World War I, many elementary schools continued to teach in Dutch, and the Catholic Church continued to preach and teach the catechism in Dutch in many parishes.\n\nDuring the second half of the 19th century, Dutch was banned from all levels of education by both Prussia and France and lost most of its functions as a cultural language. In both Germany and France, the Dutch standard language is largely absent, and speakers of these Dutch dialects will use German or French in everyday speech. Dutch is not afforded legal status in France or Germany, either by the central or regional public authorities, and knowledge of the language is declining among younger generations.\n\nAs a foreign language, Dutch is mainly taught in primary and secondary schools in areas adjacent to the Netherlands and Flanders. In French-speaking Belgium, over 300,000 pupils are enrolled in Dutch courses, followed by over 23,000 in the German states of Lower Saxony and North Rhine-Westphalia, and about 7,000 in the French region of Nord-Pas-de-Calais (of which 4,550 are in primary school). At an academic level, the largest number of faculties of \"neerlandistiek\" can be found in Germany (30 universities), followed by France (20 universities) and the United Kingdom (5 universities).\n\nDespite the Dutch presence in Indonesia for almost 350 years, as the Asian bulk of the Dutch East Indies, the Dutch language has no official status there and the small minority that can speak the language fluently are either educated members of the oldest generation, or employed in the legal profession, as certain law codes are still only available in Dutch. Dutch is taught in various educational centres in Indonesia, the most important of which is the Erasmus Language Centre (ETC) in Jakarta. Each year, some 1,500 to 2,000 students take Dutch courses there. In total, several thousand Indonesians study Dutch as a foreign language. Owing to centuries of Dutch rule in Indonesia, many old documents are written in Dutch. Many universities therefore include Dutch as a source language, mainly for law and history students. In Indonesia this involves about 35,000 students.\n\nUnlike other European nations, the Dutch chose not to follow a policy of language expansion amongst the indigenous peoples of their colonies. In the last quarter of the 19th century, however, a local elite gained proficiency in Dutch so as to meet the needs of expanding bureaucracy and business. Nevertheless, the Dutch government remained reluctant to teach Dutch on a large scale for fear of destabilising the colony. Dutch, the language of power, was supposed to remain in the hands of the leading elite.\n\nAfter independence, Dutch was dropped as an official language and replaced by Malay. Yet the Indonesian language inherited many words from Dutch: words for everyday life as well as scientific and technological terms. One scholar argues that 20% of Indonesian words can be traced back to Dutch words, many of which are transliterated to reflect phonetic pronunciation e.g. \"\" \"office\" in Indonesian is \"kantor\", while \"bus\" \"bus\" becomes \"bis\". In addition, many Indonesian words are calques of Dutch; for example, \"rumah sakit\" \"hospital\" is calqued on the Dutch \"ziekenhuis\" (literally \"sickhouse\"), \"kebun binatang\" \"zoo\" on \"dierentuin\" (literally \"animal garden\"), \"undang-undang dasar\" \"constitution\" from \"grondwet\" (literally \"ground law\"). These account for some of the differences in vocabulary between Indonesian and Malay.\n\nAfter the declaration of independence of Indonesia, Western New Guinea, the \"wild east\" of the Dutch East Indies, remained a Dutch colony until 1962, known as Netherlands New Guinea. Despite prolonged Dutch presence, the Dutch language is not spoken by many Papuans, the colony having been ceded to Indonesia in 1963.\n\nDutch-speaking immigrant communities can also be found in Australia and New Zealand. The 2011 Australian census showed 37,248 people speaking Dutch at home. At the 2006 New Zealand census, 26,982 people, or 0.70 percent of the total population, reported to speak Dutch to sufficient fluency that they could hold an everyday conversation.\n\nIn contrast to the colonies in the East Indies, from the second half of the 19th century onwards, the Netherlands envisaged expansion of Dutch in its colonies in the West Indies. Until 1863, when slavery was abolished in the West Indies, slaves were forbidden to speak Dutch, with the effect that local creoles such as Papiamento and Sranan Tongo which were based not on Dutch but rather other European languages, became common in the Dutch West Indies. However, as most of the people in the Colony of Surinam (now Suriname) worked on Dutch plantations, this reinforced the use of Dutch as a means for direct communication.\n\nIn Suriname today, Dutch is the sole official language, and over 60 percent of the population speaks it as a mother tongue. Dutch is the obligatory medium of instruction in schools in Suriname, even for non-native speakers. A further twenty-four percent of the population speaks Dutch as a second language. Suriname gained its independence from the Netherlands in 1975 and has been an associate member of the Dutch Language Union since 2004. The lingua franca of Suriname, however, is Sranan Tongo, spoken natively by about a fifth of the population.\n\nIn Aruba, Bonaire, Curaçao and Sint Maarten, all parts of the Kingdom of the Netherlands, Dutch is the official language but spoken as a first language by only 7% to 8% of the population, although most native-born people on the islands can speak the language since the education system is in Dutch at some or all levels.\n\nIn the United States, a now extinct dialect of Dutch, Jersey Dutch, spoken by descendants of 17th-century Dutch settlers in Bergen and Passaic counties, was still spoken as late as 1921. Other Dutch-based creole languages once spoken in the Americas include Mohawk Dutch (in Albany, New York), Berbice (in Guyana), Skepi (in Essequibo, Guyana) and Negerhollands (in the United States Virgin Islands). Pennsylvania Dutch is not a member of the set of Dutch dialects and is less misleadingly called Pennsylvania German.\n\nMartin Van Buren, the eighth President of the United States, spoke Dutch as his first language and is the only U.S. President to have spoken a language other than English as his first language. Dutch prevailed for many generations as the dominant language in parts of New York along the Hudson River. Another famous American born in this region who spoke Dutch as a first language was Sojourner Truth.\n\nAccording to the 2000 United States census, 150,396 people spoke Dutch at home, while according to the 2006 Canadian census, this number reaches 160,000 Dutch speakers. At an academic level, 20 universities offer Dutch studies in the United States. In Canada, Dutch is the fourth most spoken language by farmers, after English, French and German, and the fifth most spoken non-official language overall (by 0.6% of Canadians).\n\nThe largest legacy of the Dutch language lies in South Africa, which attracted large numbers of Dutch, Flemish and other northwest European farmer (in Dutch, \"boer\") settlers, all of whom were quickly assimilated. The long isolation from the rest of the Dutch-speaking world made the Dutch as spoken in Southern Africa evolve into what is now Afrikaans. In 1876, the first Afrikaans newspaper called \"Die Afrikaanse Patriot\" was published in the Cape Colony.\n\nEuropean Dutch remained the literary language until the start of the 1920s, when under pressure of Afrikaner nationalism the local \"African\" Dutch was preferred over the written, European-based standard. In 1925, section 137 of the 1909 constitution of the Union of South Africa was amended by Act 8 of 1925, stating \"the word \"Dutch\" in article 137 ... is hereby declared to include Afrikaans\". The constitution of 1983 only listed English and Afrikaans as official languages. It is estimated that between 90% to 95% of Afrikaans vocabulary is ultimately of Dutch origin.\n\nBoth languages are still largely mutually intelligible, although this relation can in some fields (such as lexicon, spelling and grammar) be asymmetric, as it is easier for Dutch speakers to understand written Afrikaans than it is for Afrikaans speakers to understand written Dutch. Afrikaans is grammatically far less complex than Dutch, and vocabulary items are generally altered in a clearly patterned manner, e.g. \"vogel\" becomes \"voël\" (\"bird\") and \"regen\" becomes \"reën\" (\"rain\"). In South Africa, the number of students following Dutch at university is difficult to estimate, since the academic study of Afrikaans inevitably includes the study of Dutch. Elsewhere in the world, the number of people learning Dutch is relatively small.\nIt is the third language of South Africa in terms of native speakers (~13.5%), of whom 53 percent are Coloureds and 42.4 percent Whites. In 1996, 40 percent of South Africans reported to know Afrikaans at least at a very basic level of communication. It is the lingua franca in Namibia, where it is spoken natively in 11 percent of households. In total, Afrikaans is the first language in South Africa alone of about 7.1 million people and is estimated to be a second language for at least 10 million people worldwide, compared to over 23 million and 5 million respectively, for Dutch.\n\nDutch colonial presence elsewhere in Africa, notably Dutch Gold Coast, was too ephemeral not to be wiped out by prevailing colonizing European successors.\nBelgian colonial presence in Congo and Rwanda-Urundi (Burundi and Rwanda, held under League of Nations mandate and later UN trust) left little (Flemish) Dutch legacy, as French was the main colonial language.\n\nFor further details on different realisations of phonemes, dialectal differences and example words, see the full article at Dutch phonology.\n\nUnlike other Germanic languages, Dutch doesn't have phonological aspiration of consonants. Like most Germanic languages, the Dutch consonant system did not undergo the High German consonant shift and has a syllable structure that allows fairly complex consonant clusters. Dutch also retains full use of the velar fricatives that were present in Proto-Germanic, but lost or modified in many other Germanic languages. Dutch has final-obstruent devoicing: at the end of a word, voicing distinction is neutralised and all obstruents are pronounced voiceless. For example, Dutch ' (̇‘good’) is but the related form ' is . Dutch shares this final-obstruent devoicing with German (the Dutch noun \"goud\" is pronounced [ɣɑut], the adjective \"gouden\" is pronounced [ɣɑudə(n)], like the German noun \"Gold\", pronounced [ɡɔlt], adjective \"golden\", pronounced [ɡɔldn] vs English \"gold\" and \"golden\", both pronounced with [d].)\n\nVoicing of pre-vocalic initial voiceless alveolar fricatives occurs, although less in Dutch than in German (Dutch ', German ' with versus English \"seven\" and Low German ' with [s]), and also the shift → . Dutch shares only with Low German the development of → (Dutch ', ' and Low German ', ' versus German ', ' and English \"foxes\", \"oxen\"), and also the development of → though it is far more common in Dutch (Dutch ' and Low German ' versus German ' and English \"soft\", but Dutch ' versus German ' and English \"craft\").\n\nNotes:\n\nLike English, Dutch did not develop i-mutation as a morphological marker and shares with most Germanic languages the lengthening of short vowels in stressed open syllables, which has led to contrastive vowel length that is used as a morphological marker. Dutch has an extensive vowel inventory. Vowels can be grouped as back rounded, front unrounded and front rounded. They are also traditionally distinguished by length or tenseness.\n\nVowel length is not always considered a distinctive feature in Dutch phonology, because it normally co-occurs with changes in vowel quality. One feature or the other may be considered redundant, and some phonemic analyses prefer to treat it as an opposition of tenseness. However, even if not considered part of the phonemic opposition, the long/tense vowels are still realised as \"phonetically\" longer than their short counterparts. The changes in vowel quality are also not always the same in all dialects, and in some there may be little difference at all, with length remaining the primary distinguishing feature. And while it is true that older words always pair vowel length with a change in vowel quality, new loanwords have reintroduced phonemic oppositions of length. Compare \"zonne(n)\" (\"suns\") versus \"zone\" (\"zone\") versus \"zonen\" (\"sons\"), or \"kroes\" (\"mug\") versus \"cruise\" (\"cruise\").\n\nNotes:\n\nUnique to the development of Dutch is the collapse of older \"ol\"/\"ul\"/\"al\" + dental into \"ol\" + dental, followed by vocalisation of pre-consonantal /l/ and after a short vowel, creating the diphthong e.g., Dutch \"goud\", \"zout\" and \"bout\" corresponds with Low German \"Gold\", \"Solt\", \"Bolt\"; German \"Gold\", \"Salz\", \"Balt\" and English \"gold\", \"salt\", \"bolt\". This is the most common diphthong along with . All three are commonly the only ones considered unique phonemes in Dutch. The tendency for native English speakers is to pronounce Dutch names with (written as \"ij\" or \"ei\") as , (like the English vowel y) which does not normally lead to confusion among native listeners, since in a number of dialects (e.g. in Amsterdam) the same pronunciation is heard.\n\nIn contrast, and are rare in Dutch, and occur only in some words. The \"long/tense\" diphthongs, while they are indeed realised as proper diphthongs, are generally analysed phonemically as a long/tense vowel followed by a glide or . All diphthongs end in a close vowel (). They are grouped here by their first element.\nThe syllable structure of Dutch is (C)(C)(C)V(C)(C)(C)(C). Many words, as in English, begin with three consonants; for example, straat \"(street)\". There are words that end in four consonants, e.g., \"herfst\" 'autumn', \"ergst\" 'worst', \"interessantst\" 'most interesting', \"sterkst\" 'strongest', the last three of which are superlative adjectives.\n\nThe highest number of consonants in a single cluster is found in the word \"slechtstschrijvend\" 'writing worst' with 7 consonant phonemes. Similar is \"angstschreeuw\" \"scream in fear\", with six in a row.\n\nA notable change in pronunciation has been occurring in younger generations in the provinces of Utrecht, North and South Holland, which has been dubbed \"Polder Dutch\" by Jan Stroop. These speakers pronounce , , and , which used to be pronounced as , , and , increasingly lowered, as , , and respectively. Instead, , , and are pronounced as diphthongs now, as , , and respectively, which makes this change an instance of a chain shift.\n\nThis change is interesting from a sociolinguistic point of view because it has apparently happened relatively recently, in the 1970s, and was pioneered by older well-educated women from the upper middle classes. The lowering of the diphthongs has long been current in many Dutch dialects, and is comparable to the English Great Vowel Shift, and the diphthongisation of long high vowels in Modern High German, which centuries earlier reached the state now found in Polder Dutch. Stroop theorizes that the lowering of open-mid to open diphthongs is a phonetically \"natural\" and inevitable development and that Dutch, after having diphthongised the long high vowels like German and English, \"should\" have lowered the diphthongs like German and English as well.\n\nInstead, he argues, this development has been artificially frozen in an \"intermediate\" state by the standardisation of Dutch pronunciation in the 16th century, where lowered diphthongs found in rural dialects were perceived as ugly by the educated classes and accordingly declared substandard. Now, however, in his opinion, the newly affluent and independent women can afford to let that natural development take place in their speech. Stroop compares the role of Polder Dutch with the urban variety of British English pronunciation called Estuary English.\n\nAmong Belgian and Surinamese Dutch speakers and speakers from other regions in the Netherlands, this vowel shift is not taking place.\n\nDutch is grammatically similar to German, such as in syntax and verb morphology (for a comparison of verb morphology in English, Dutch and German, see Germanic weak verb and Germanic strong verb). Grammatical cases have largely fallen out of use and are now mostly limited to pronouns and a large number of set phrases. Inflected forms of the articles are also often found in surnames and toponyms.\n\nStandard Dutch uses three genders to differentiate between natural gender and three when discerning grammatical gender. But for most non-Belgian speakers, the masculine and feminine genders have merged to form the common gender (de), while the neuter (het) remains distinct as before. This gender system is similar to those of most Continental Scandinavian languages. As in English, but to a lesser degree, the inflectional grammar of the language (e.g., adjective and noun endings) has simplified over time.\n\nWhen grouped according to their conjugational class, Dutch has four main verb types: weak verbs, strong verbs, irregular verbs and mixed verbs.\n\nWeak verbs are the most numerous verbs, constituting about 60% of all verbs. In weak verbs, the past tense and past participle are formed with a dental suffix:\n\nStrong verbs are the second most numerous verb group. This group is characterised by a vowel alternation of the stem in the past tense and perfect participle. Dutch distinguishes between 7 classes of strong verbs with some internal variants. Dutch is known for its large group of 'half strong verbs' these have either a weak past tense and a strong participle or a strong past tense and a weak participle. Finally there are also strong verbs that don't neatly fit in any of the seven classes. The following table shows the vowel alternations in more detail. It also shows the number of roots (bare verbs) that belong to each class, variants with a prefix are excluded.\n\nIn Dutch the irregular verbs are the least numerous, but most used verb forms.\n\nAs in English, the case system of Dutch and the subjunctive have largely fallen out of use, and the system has generalised the dative over the accusative case for certain pronouns (NL: \"me\", \"je\"; EN: \"me\", \"you\"; LI: \"mi\", \"di\" vs. DE: \"mich/mir\", \"dich/dir\"). While standard Dutch has three grammatical genders, this has few grammatical consequences and the masculine and feminine gender are often merged into a common gender in the Netherlands but not in Belgium (EN: none; NL/LI: common and neuter; in Belgium masculine, feminine and neuter is in use).\n\nModern Dutch has mostly lost its case system. However, certain idioms and expressions continue to include now archaic case declensions. The article has just two forms, \"de\" and \"het\", more complex than English, which has only \"the\". The use of the older inflected form \"den\" in the dative or accusative as well as use of 'der' in the dative are restricted to numerous set phrases, surnames and toponyms.\n\nIn modern Dutch, the genitive articles 'des' and 'der' are commonly used in idioms. Other usage is typically considered archaic, poetic or stylistic. In most circumstances, the preposition 'van' is instead used, followed by the normal definitive article 'de' or 'het'. For the idiomatic use of the articles in the genitive, see for example:\n\nIn contemporary usage, the genitive case still occurs a little more often with plurals than with singulars, as the plural article is 'der' for all genders and no special noun inflection must be taken account of. 'Der' is commonly used in order to avoid reduplication of 'van', e.g. \"het merendeel der gedichten van de auteur\" instead of \"het merendeel van de gedichten van de auteur\" (\"the bulk of the author's poems\").\n\nThere is also a genitive form for the pronoun \"die/dat\" (\"that [one], those [ones]\"), namely \"diens\" for masculine and neuter singulars (occurrences of \"dier\" for feminine singular and all plurals are extremely rare). Although usually avoided in common speech, this form can be used instead of possessive pronouns to avoid confusion. Compare:\n\n\nAnalogically, the relative and interrogative pronoun \"wie\" (\"who\") has the genitive forms \"wiens\" and \"wier\" (corresponding to English \"whose\", but less frequent in use).\n\nDutch also has a range of fixed expressions that make use of the genitive articles, which can be abbreviated using apostrophes. Common examples include \"'s ochtends\" (with 's as abbreviation of des; \"in the morning\") and \"desnoods\" (lit: \"of the need\", translated: \"if necessary\").\n\nThe Dutch written grammar has simplified over the past 100 years: cases are now mainly used for the pronouns, such as \"ik\" (I), \"mij, me\" (me), \"mijn\" (my), \"wie\" (who), \"wiens\" (whose: masculine or neuter singular), \"wier\" (whose: feminine singular; masculine, feminine or neuter plural). Nouns and adjectives are not case inflected (except for the genitive of proper nouns (names): -s, -'s or -'). In the spoken language cases and case inflections had already gradually disappeared from a much earlier date on (probably the 15th century) as in many continental West Germanic dialects.\n\nInflection of adjectives is more complicated. The adjective receives no ending with indefinite neuter nouns in singular (as with \"een\" 'a/an'), and -e in all other cases. (This was also the case in Middle English, as in \"a goode man\".) Note that \"fiets\" belongs to the masculine/feminine category, and that \"water\" and \"huis\" are neuter.\n\nAn adjective has no e if it is in the predicative: \"De soep is koud\".\n\nMore complex inflection is still found in certain lexicalized expressions like \"de heer des huizes (literally, the man of the house), etc. These are usually remnants of cases (in this instance, the genitive case which is still used in German, cf. \"Der Herr des Hauses\") and other inflections no longer in general use today. In such lexicalized expressions remnants of strong and weak nouns can be found too, e.g. \"in het jaar des Heren (Anno Domini), where \"-en\" is actually the genitive ending of the weak noun. Also in this case, German retains this feature.\n\nDutch shares much of its word order with German. Dutch exhibits subject–object–verb word order, but in main clauses the conjugated verb is moved into the second position in what is known as verb second or V2 word order. This makes Dutch word order almost identical to that of German, but often different from English, which has subject–verb–object word order and has since lost the V2 word order that existed in Old English.\n\nAn example sentence used in some Dutch language courses and textbooks is \"\"Ik kan mijn pen niet vinden omdat het veel te donker is\", which translates into English word for word as \"I can my pen not find because it far too dark is\", but in standard English word order would be written \"I cannot find my pen because it is far too dark\". If the sentence is split into a main and subclause and the verbs highlighted, the logic behind the word order can be seen.\n\nMain clause: \"Ik kan mijn pen niet vinden \"\"\n\nVerbs are placed in the final position, but the conjugated verb, in this case \"kan\" (can), is made the second element of the clause.\n\nSubclause: \"\"omdat het veel te donker is \"\n\nThe verb or verbs always go in the final position.\n\nIn an interrogative main clause the usual word order is: conjugated verb followed by subject; other verbs in final position:\nIn the Dutch equivalent of a wh-question the word order is: interrogative pronoun (or expression) + conjugated verb + subject; other verbs in final position:\nIn a tag question the word order is the same as in a declarative clause:\nA subordinate clause does not change its word order:\n\nIn Dutch, the diminutive is used extensively. It is the nuances of meaning expressed by the diminutive which make it peculiarly unique Dutch but also difficult to master for non-native speakers. It is a very productive and formed by adding one of the suffixes to the noun in question, depending on the latter's phonological ending:\n\nThe diminutive suffixes -ke (from which - has derived by palatalization), -eke, -ske, - (only for words ending -ch, -k, -p, or -s), -kie (instead of -kje), and -pie (instead of -pje) are used in southern dialects, and the forms ending on - as well in northern urban dialects. Some of these form part of expressions that became standard language, like \"een makkie\", from gemak = \"ease\"). The noun joch (\"young boy\") has, exceptionally, only the diminutive form jochie, also in standard Dutch. The form -ke is also found in many women's given names: Janneke, Marieke, Marijke, Mieke, Meike etc.\n\nIn Dutch, the diminutive is not merely restricted to nouns, but can be applied to numerals (\"met z'n tweetjes\", \"the two of us\"), pronouns (\"onderonsje\", \"tête-à-tête\"), verbal particles (\"moetje\", \"shotgun marriage\"), and even prepositions (\"toetje\", \"dessert\"). Most notable however, are the diminutive forms of adjectives and adverbs. The former take a diminutive ending and thus function as nouns, the latter remain adverbs and always have the diminutive with the -s appended, e.g. adjective: groen (\"green\") → noun: groen (\"rookie\"); adverb: even (\"just\") → adverb: eventjes (\"just a minute\").\n\nSome nouns have two different diminutives, each with a different meaning: bloem (\"flower\") → bloempje (lit. \"small flower\"), but bloemetje (lit. also \"small flower\", meaning \"bouquet\"). A few nouns exist solely in a diminutive form, e.g. zeepaardje (\"seahorse\"), while many, e.g. meisje (\"girl\"), originally a diminutive of meid (\"maid\"), have acquired a meaning . A diminutive can sometimes be added to an uncountable noun to refer to a single portion: ijs (\"ice\", \"ice cream\") → ijsje (\"ice cream treat\", \"cone of ice cream\"), bier (\"beer\") → biertje. Some diminutive forms only exist in the plural, e.g. kleertjes (\"clothing\").\n\nWhen used to refer to time, the Dutch diminutive form can indicate whether the person in question found it pleasant or not: \"een uurtje kletsen\" (\"chatting for a \"little\" hour.\") The diminutive can, however, also be used pejoratively: \"Hij was weer eens het \"mannetje\"\". (\"He acted as if he was the \"little\" man.\")\n\nThere are two series of personal pronouns, subject and objects pronouns. The forms on the right-hand sides within each column are the unemphatic forms; those not normally written are given in brackets. Only \"ons\" and \"u\" do not have an unemphatic form. The distinction between emphatic and unemphatic pronouns is very important in Dutch. Emphatic pronouns in English use the reflexive pronoun form, but are used to emphasize the subject, not to indicate a direct or indirect object. For example, \"I gave (to) myself the money\" is reflexive but \"I myself gave the money (to someone else) \" is emphatic. \n\nLike in English, Dutch has generalised the dative over the accusative case for all pronouns, e.g. Du me, je, Eng me, you, vs. Germ mich/mir dich/dir. There is one exception: the standard language prescribes that in the third person plural, \"hen\" is to be used for the direct object, and \"hun\" for the indirect object. This distinction was artificially introduced in the 17th century by grammarians, and is largely ignored in spoken language and not well understood by Dutch speakers. Consequently, the third person plural forms \"hun\" and \"hen\" are interchangeable in normal usage, with \"hun\" being more common. The shared unstressed form \"ze\" is also often used as both direct and indirect objects and is a useful avoidance strategy when people are unsure which form to use.\n\nDutch shares also with English the presence of h- pronouns, e.g. Du \"hij\", \"hem\", \"haar\", \"hun\" and Eng \"he\", \"him\", \"her\" vs. Germ \"er\", \"ihn\", \"ihr\", \"ihnen\".\n\nLike most Germanic languages, Dutch forms noun compounds, where the first noun modifies the category given by the second (\"hondenhok\" = doghouse). Unlike English, where newer compounds or combinations of longer nouns are often written in open form with separating spaces, Dutch (like the other Germanic languages) either uses the closed form without spaces (\"boomhut\" = tree house) or inserts a hyphen (\"VVD-coryfee\" = outstanding member of the VVD, a political party). Like German, Dutch allows arbitrarily long compounds, but the longer they get, the less frequent they tend to be.\n\nThe longest serious entry in the Van Dale dictionary is (ceasefire negotiation). Leafing through the articles of association (Statuten) one may come across a 30-letter (authorisation of representation). An even longer word cropping up in official documents is \"ziektekostenverzekeringsmaatschappij\" (health insurance company) though the shorter \"ziektekostenverzekeraar\" (health insurer) is more common.\n\nNotwithstanding official spelling rules, some Dutch-speaking people, like some Scandinavians and German speakers, nowadays tend to write the parts of a compound separately, a practice sometimes dubbed \"de Engelse ziekte\" (the English disease).\n\nDutch vocabulary is predominantly Germanic in origin, with loanwords accounting for 20%. The main foreign influence on Dutch vocabulary since the 12th century and culminating in the French period has been French and (northern) Oïl languages, accounting for an estimated 6.8% of all words, or more than a third of all loanwords. Latin, which was spoken in the southern Low Countries for centuries, and subsequently played a major role as the language of science and religion, follows with 6.1%. High German and Low German were influential until the mid-19th century and account for 2.7%, but these are mostly unrecognizable since many have been \"Dutchified\", e.g. German ' → Dutch '. From English Dutch has borrowed words since the middle of the 19th century, as a consequence of the increasing power and influence of Britain and the United States. The share of English loanwords is about 1.5%, but this number is still on the increase. Conversely, Dutch contributed many loanwords to English, accounting for 1.3% of its lexicon.\n\nThe main Dutch dictionary is the Van Dale groot woordenboek der Nederlandse taal, which contains some 268,826 headwords. In the field of linguistics, the 45,000-page \"Woordenboek der Nederlandsche Taal\" is also widely used. This scholarly endeavor took 147 years to complete and contains all recorded Dutch words from the Early Middle Ages onward.\n\nThe official spelling is set by the \"Wet schrijfwijze Nederlandsche taal\" (Law on the writing of the Dutch language; Belgium 1946, Netherlands 1947; based on a 1944 spelling revision; both amended in the 1990s after a 1995 spelling revision). The \"Woordenlijst Nederlandse taal\", more commonly known as \"het groene boekje\" (i.e. \"the green booklet\", because of its color), is usually accepted as an informal explanation of the law.\n\nDutch is written using the Latin script. Dutch uses one additional character beyond the standard alphabet, the digraph IJ. It has a relatively high proportion of doubled letters, both vowels and consonants, due to the formation of compound words and also to the spelling devices for distinguishing the many vowel sounds in the Dutch language. An example of five consecutive doubled letters is the word \"voorraaddoos\" (food storage container). The diaeresis (Dutch: \"trema\") is used to mark vowels that are pronounced separately when involving a pre- or suffix, and a hyphen is used when the problem occurs in compound words. For example; \"\"be\"ïnvloed\" (influenced), but \"zee-eend\" (sea duck). Generally, other diacritical marks occur only in loanwords. However, the acute accent can also be used for emphasis or to differentiate between two forms, and its most common use is to differentiate between the indefinite article 'een' (a, an) and the numeral 'één' (one).\n\n\n\n"}
{"id": "89333", "url": "https://en.wikipedia.org/wiki?curid=89333", "title": "Elsa Beskow", "text": "Elsa Beskow\n\nElsa Beskow (\"née\" Maartman) (11February 187430June 1953) was a Swedish author and illustrator of children's books. Among her better known books are \"Tale of the Little Little Old Woman\" and \"Aunt Green, Aunt Brown and Aunt Lavender\".\n\nBorn in Stockholm her parents were businessman Bernt Maartman (1841–1889), whose family came from Bergen, Norway, and Augusta Fahlstedt (1850–1915). Beskow studied Art Education at Konstfack, University College of Arts, Crafts and Design, then called \"Tekniska skolan\", or the Technical school, in Stockholm.\n\nShe married former minister and social worker, doctor of theology Natanael Beskow in 1897. Elsa Beskow met her future husband at Djursholms samskola while serving as a teacher where he served as head master. From 1900 they lived in Villa Ekeliden in Djursholm which had initially been built for the author Viktor Rydberg. They had six sons, including the artist Bo Beskow (1906–1989) and geologist Gunnar Beskow (1901–1991).\n\nIn 1894 Beskow started to contribute to the children's magazine \"Jultomten\". Overall, she would publish some forty books with her own text and images. Beskow frequently combined reality with elements from the fairy tale world. Children meet elves or goblins, and farm animals talk with people. Central themes were the relationships between children and adults and children's independent initiative.\n\nBeskow became one of the most well known of all Swedish children's book artists. Many of her books became classics and are continually reprinted. Beskow also illustrated ABC books and songbooks for Swedish schools. Her book pages are often framed by decorative framework of the Art Nouveau style.\n\n<poem>\nSof du lilla vide ung,\nän så är det vinter.\nÄn så sofva björk och ljung\nros och hyacinter.\nÄn så är det långt till vår,\ninnan rönn i blomning står.\nSof du lilla vide,\nän så är det vinter.\n</poem>\nThe Elsa Beskow Award was created in 1958 to recognize the year's best Swedish picture book illustrator.\n\n\n\n\n"}
{"id": "53445822", "url": "https://en.wikipedia.org/wiki?curid=53445822", "title": "English surnames of Norman origin", "text": "English surnames of Norman origin\n\nSome family names contain clues as to their origin, like English surnames of Norman Origin. William, Duke of Normandy, successfully invaded England in 1066, and this invasion left a lasting legacy in the English language, in general, and in surnames, in particular. \n\nAccording to Christopher Daniell, in \"From Norman Conquest to Magna Carta\", 1140 marked what might be the first recorded use of a modern surname, inherited by multiple generations. The sons of a Norman named Robert used a modern inheritable surname, \"FitzGerald\", in honour of an earlier relative, named \"Gerald\".\n\nAccording to Joslin Fiennes's \"Origins of English surnames\" modern surnames were not used until the fourteenth century:\nBeginning in the late 1500s and peaking in the wake of the Edict of Fontainebleau (1685), French Protestant refugees from France, the Huguenots, brought surnames like Dubarry, Duhamel and Dupuy, from Normandy, into the English namespace, when the historical record shows these names had not been present prior to the fifteenth century.\n\n"}
{"id": "3086101", "url": "https://en.wikipedia.org/wiki?curid=3086101", "title": "Erdős–Burr conjecture", "text": "Erdős–Burr conjecture\n\nIn mathematics, the Erdős–Burr conjecture was a problem concerning the Ramsey number of sparse graphs. The conjecture is named after Paul Erdős and Stefan Burr, and is one of many conjectures named after Erdős; it states that the Ramsey number of graphs in any sparse family of graphs should grow linearly in the number of vertices of the graph.\n\nThe conjecture was proven by Choongbum Lee (thus it is now a theorem).\n\nIf \"G\" is an undirected graph, then the degeneracy of \"G\" is the minimum number \"p\" such that every subgraph of \"G\" contains a vertex of degree \"p\" or smaller. A graph with degeneracy \"p\" is called \"p\"-degenerate. Equivalently, a \"p\"-degenerate graph is a graph that can be reduced to the empty graph by repeatedly removing a vertex of degree \"p\" or smaller.\n\nIt follows from Ramsey's theorem that for any graph \"G\" there exists a least integer \nformula_1, the \"Ramsey number\" of \"G\", such that any complete graph on at least formula_1 vertices whose edges are coloured red or blue contains a monochromatic copy of \"G\". For instance, the Ramsey number of a triangle is 6: no matter how the edges of a complete graph on six vertices are colored red or blue, there is always either a red triangle or a blue triangle.\n\nIn 1973, Stefan Burr and Paul Erdős made the following conjecture:\n\nThat is, if an \"n\"-vertex graph \"G\" is \"p\"-degenerate, then a monochromatic copy of \"G\" should exist in every two-edge-colored complete graph on \"c n\" vertices.\n\nBefore the full conjecture was proved, it was first settled in some special cases. It was proven for bounded-degree graphs by ; their proof led to a very high value of \"c\", and improvements to this constant were made by and . More generally, the conjecture is known to be true for \"p\"-arrangeable graphs, which includes graphs with bounded maximum degree, planar graphs and graphs that do not contain a subdivision of \"K\". It is also known for subdivided graphs, graphs in which no two adjacent vertices have degree greater than two.\n\nFor arbitrary graphs, the Ramsey number is known to be bounded by a function that grows only slightly superlinearly. Specifically, showed that there exists a constant \"c\" such that, for any \"p\"-degenerate \"n\"-vertex graph \"G\",\n\n"}
{"id": "324772", "url": "https://en.wikipedia.org/wiki?curid=324772", "title": "Eurotra", "text": "Eurotra\n\nEurotra was an ambitious machine translation project established and funded by the European Commission from 1978 until 1992.\n\nEmboldened by modest success with an older, commercially developed machine translation system SYSTRAN, a large network of European computational linguists embarked upon the Eurotra project with the hope of creating a state-of-the-art MT system for the then seven, later nine, official languages of the European Community.\n\nHowever, as time passed, expectations became tempered; \"Fully Automatic High Quality Translation\" was not a reasonably attainable goal. The true character of Eurotra was eventually acknowledged to be in fact pre-competitive research rather than prototype development.\n\nThe project was motivated by one of the founding principles of the EU: that all citizens had the right to read any and all proceedings of the Commission in their own language. As more countries joined, this produced a combinatorial explosion in the number of language pairs involved, and the need to translate every paper, speech and even set of meeting minutes produced by the EU into the other eight languages meant that translation rapidly became the overwhelming component in the administrative budget. To solve this problem Eurotra was devised.\n\nThe project was unusual in that rather than consisting of a single research team, it had member groups distributed around the member countries, organised along language rather than national lines (for example, groups in Leuven and Utrecht worked closely together), and the secretariat was based at the European Commission in Luxembourg. While this contributed significantly to the culture of the project, it also demonstrated graphically Brooks' assertion in The Mythical Man-Month that adding personnel to a project results in it taking longer to complete; the more the number of groups involved, the more time is spent on administration and communication rather than actual research per se.\n\nThe actual design of the project was unusual as MT projects go. Older systems, such as SYSTRAN, were heavily dictionary-based, with minor support for rearranging word order. More recent systems have often worked on a probabilistic approach, based on parallel corpora. Eurotra addressed the constituent structure of the text to be translated, going through first a syntactic parse followed by a second parse to produce a dependency structure followed by a final parse with a third grammar to produce what was referred to internally as Intermediate Representation (IR). Since all three modules were implemented as Prolog programs, it would then in principle be possible to put this structure backwards through the corresponding modules for another language to produce a translated text in any of the other languages. However, in practice this was not in fact how language pairs were implemented.\n\nThe first \"live\" translation occupied a 4Mb Microvax running Ultrix and C-Prolog for a complete weekend some time in early 1987. The sentence, translated from English into Danish, was \"Japan makes computers\". The main problem faced by the system was the generation of so-called \"Parse Forests\" - often a large number of different grammar rules could be applied to any particular phrase, producing hundreds, even thousands of (often identical) parse trees. This used up huge quantities of computer store, slowing the whole process down unnecessarily. \n\nWhile Eurotra never delivered a \"working\" MT system, the project made a far-reaching long-term impact on the nascent language industries in European member states, in particular among the southern countries of Greece, Italy, Spain, and Portugal. There is at least one commercial MT system (developed by an academic/commercial consortium in Denmark) derived from Eurotra technology.\n\n\n"}
{"id": "58090820", "url": "https://en.wikipedia.org/wiki?curid=58090820", "title": "Facebook, Apple, Amazon, Netflix and Google", "text": "Facebook, Apple, Amazon, Netflix and Google\n\nFacebook, Apple, Amazon, Netflix and Google (FAANG), a further extension of FANG (which originally did not include Apple), is both an acronym and a buzzword to entice investors, as popularised by Jim Cramer from CNBC's Mad Money and other talking heads for grouping together currently high performance technology companies currently listed on NASDAQ. While it usually refers to the five (or four) of these technology companies specifically, the term is now generally used to refer to the technology and consumer discretionary sectors consisting of highly-traded growth stocks of American technology and tech-enabled companies in recent years. Such a perspective of the market demonstrates a huge impact with commensurate profit or loss. Opinions have been divided over whether this phenomenon is indicative of a tech bubble or long-term sustained growth of these technology companies.\n\nIn 2017, Intercontinental Exchange has initiated an index with this focus through the NYSE and extended FANG with Twitter, Nvidia and Tesla and with BAT stocks, the Chinese counterparts: Baidu, Alibaba and Tencent. Investment analysts have often compared FAANG against or together with BAT stocks due to the latter's similar level of growth in the Chinese stock market.\n\nThere are also actively managed ETFs, which attempt to take advantage of the phenomenon of these index-based funds, since indices don’t have the power to make adjustments on any given day. However, investors should be wary as an ETF may not be currently holding all of the implied tech company stocks. For example, the ETF known by ticker FNG, sold out of Facebook during the Cambridge Analytica scandal, but also dumped Apple holdings ahead of its earnings boost.\n\n\n"}
{"id": "10160", "url": "https://en.wikipedia.org/wiki?curid=10160", "title": "Final Solution", "text": "Final Solution\n\nThe Final Solution () or the Final Solution to the Jewish Question (, ) was a Nazi plan for the genocide or extermination of the Jews during World War II. The \"Final Solution of the Jewish Question\" was the official code name for the murder of all Jews within reach, which was not restricted to the European continent. This policy of deliberate and systematic genocide starting across German-occupied Europe was formulated in procedural and geo-political terms by Nazi leadership in January 1942 at the Wannsee Conference held near Berlin, and culminated in the Holocaust, which saw the killing of 90% of Polish Jews, and two thirds of the Jewish population of Europe.\n\nThe nature and timing of the decisions that led to the Final Solution is an intensely researched and debated aspect of the Holocaust. The program evolved during the first 25 months of war leading to the attempt at \"murdering every last Jew in the German grasp\". Most historians agree, wrote Christopher Browning, that the Final Solution cannot be attributed to a single decision made at one particular point in time. \"It is generally accepted the decision-making process was prolonged and incremental.\" In 1940, following the Fall of France, Adolf Eichmann devised the Madagascar Plan to move Europe's Jewish population to the French colony, but the plan was abandoned for logistical reasons, mainly a naval blockade. There were also preliminary plans to deport Jews to Palestine and Siberia. In 1941, wrote Raul Hilberg, in the first phase of the mass murder of Jews, the mobile killing units began to pursue their victims across occupied eastern territories; in the second phase, stretching across all of German-occupied Europe, the Jewish victims were sent on death trains to centralized extermination camps built for the purpose of systematic implementation of the Final Solution.\n\nThe term \"Final Solution\" was a euphemism used by the Nazis to refer to their plan for the annihilation of the Jewish people. Historians have shown that the usual tendency of the German leadership was to be extremely guarded when discussing the Final Solution. Euphemisms were, in Mark Roseman's words, \"their normal mode of communicating about murder\".\n\nFrom gaining power in January 1933 until the outbreak of war in September 1939, the Nazi persecution of the Jews in Germany was focused on intimidation, expropriating their money and property, and encouraging them to emigrate. According to the Nazi Party policy statement, the Jews, and Roma (although numerically fewer), were the only \"alien people in Europe\". In 1936 the Bureau of Romani Affairs in Munich was taken over by the Interpol and renamed as the Center for Combating the Gypsy Menace. Introduced at the end of 1937, the \"final solution of the Gypsy Question\" entailed round-ups, expulsions, and incarceration of Romani in concentration camps built at Dachau, Buchenwald, Flossenbürg, Mauthausen, Natzweiler, Ravensbruck, Taucha, and Westerbork until this point in time. After the Anschluss with Austria in 1938, special offices were established in Vienna and Berlin to \"facilitate\" Jewish emigration, without covert plans for their forthcoming annihilation.\n\nThe outbreak of war and the invasion of Poland brought a population of 3.5 million Polish Jews under the control of the Nazi and Soviet security forces, and marked the start of a far more savage persecution, including mass killings. In the German-occupied zone of Poland, Jews were forced into hundreds of makeshift ghettos pending other arrangements. Two years later, with the launch of Operation Barbarossa against the USSR, in late June 1941, the German top echelon began to pursue Hitler's new anti-Semitic plan to eradicate, rather than expel, Jews. Hitler's earlier ideas about forcible removal of Jews from the German-controlled territories in order to achieve \"Lebensraum\" were abandoned after the failure of the air campaign against Britain, initiating a naval blockade of Germany.<ref name=\"CRB/Path\"></ref> \"Reichsführer-SS\" Heinrich Himmler became the chief architect of a new plan, which came to be called \"the Final Solution to the Jewish Question\". On 31 July 1941, \"Reichsmarschall\" Hermann Göring wrote to Reinhard Heydrich (Himmler's deputy and chief of the RSHA), instructing Heydrich to submit concrete proposals for the implementation of the projected new goal.\n\nBroadly speaking, the extermination of Jews was carried out in two major operations. With the onset of Operation Barbarossa launched from occupied Poland in June 1941, mobile killing units of the SS and Orpo were dispatched to Soviet controlled territories of eastern Poland and further into the Soviet republics for the express purpose of killing all Jews, both Polish and Soviet. During the massive chase after the fleeing Red Army, Himmler himself visited Białystok in the beginning of July 1941, and requested that, \"as a matter of principle, any Jew\" behind the German-Soviet frontier \"was to be regarded as a partisan\". His new orders gave the SS and police leaders full authority for the mass murder behind the front-lines. By August 1941, all Jewish men, women, and children were shot. In the second phase of annihilation, the Jewish inhabitants of central, western, and south-eastern Europe were transported by Holocaust trains to camps with newly-built gassing facilities. Raul Hilberg wrote: \"In essence, the killers of the occupied USSR moved to the victims, whereas outside this arena, the victims were brought to the killers. The two operations constitute an evolution not only chronologically, but also in complexity.\" Massacres of about one million Jews occurred before plans for the Final Solution were fully implemented in 1942, but it was only with the decision to annihilate the entire Jewish population that extermination camps such as Auschwitz II Birkenau and Treblinka were fitted with permanent gas chambers to kill large numbers of Jews in a relatively short period of time.\n\nThe plans to exterminate all the Jews of Europe was formalized at the SS's guesthouse on the Wannsee near Berlin on 20 January 1942. The conference was chaired by Heydrich and attended by 15 senior officials of the Nazi Party and the German government. Most of those attending were representatives of the Interior Ministry, the Foreign Ministry, and the Justice Ministry, including Ministers for the Eastern Territories. At the conference, Heydrich indicated that approximately 11,000,000 Jews in Europe would fall under the provisions of the \"Final Solution\". This figure included not only Jews residing in Axis-controlled Europe, but also the Jewish populations of the United Kingdom, and of neutral nations (Switzerland, Ireland, Sweden, Spain, Portugal, and European Turkey). Eichmann's biographer David Cesarani wrote that Heydrich's main purpose in convening the conference was to assert his authority over the various agencies dealing with Jewish issues. \"The simplest, most decisive way that Heydrich could ensure the smooth flow of deportations\" to death camps, according to Cesarani, \"was by asserting his total control over the fate of the Jews in the Reich and the east\" under the single authority of the RSHA. A copy of the minutes of this meeting was found by the Allies in March 1947; it was too late to serve as evidence during the first Nuremberg Trial, but was used by prosecutor General Telford Taylor in the subsequent Nuremberg Trials.\n\nAfter the end of World War II, surviving archival documents provided a clear record of the Final Solution policies and actions of Nazi Germany. They included the Wannsee Conference Protocol, which documented the co-operation of various German state agencies in the SS-led Holocaust, as well as some 3,000 tons of original German records captured by Allied armies, including the Einsatzgruppen reports, which documented the progress of the mobile killing units assigned, among other tasks, to kill Jewish civilians during the attack on the Soviet Union in 1941. The evidential proof which documented the mechanism of the Holocaust were submitted at Nuremberg.\n\nThe Nazi invasion of the Soviet Union codenamed Operation Barbarossa, which commenced on 22 June 1941, set in motion a \"war of destruction\" which quickly opened the door to systematic mass murder of European Jews. For Hitler, Bolshevism was merely \"the most recent and most nefarious manifestation of the eternal Jewish threat\". On 3 March 1941, Wehrmacht Joint Operations Staff Chief Alfred Jodl repeated Hitler's declaration that the \"Jewish-Bolshevik intelligentsia would have to be eliminated\" and that the forthcoming war would be a confrontation between two completely opposing cultures. In May 1941, Gestapo leader Heinrich Müller wrote a preamble to the new law limiting the jurisdiction of military courts in prosecuting troops for criminal actions because: \"This time, the troops will encounter an especially dangerous element from the civilian population, and therefore, have the right and obligation to secure themselves.\"\n\nHimmler assembled a force of about 3,000 men from Security Police, Gestapo, Kripo, SD, and the Waffen-SS, as the so-called \"special commandos of the security forces\" known as the \"Einsatzgruppen\", to eliminate both communists and Jews in occupied territories. These forces were supported by 21 battalions of Orpo Reserve Police under Kurt Daluege, adding up to 11,000 men. The explicit orders given to the Order Police varied between locations, but for Police Battalion 309 participating in the first mass murder of 5,500 Polish Jews in the Soviet-controlled Białystok (a Polish provincial capital), Major Weiss explained to his officers that Barbarossa is a war of annihilation against Bolshevism, and that his battalions would proceed ruthlessly against all Jews, regardless of age or sex.\n\nAfter crossing the Soviet demarcation line in 1941, what had been regarded as exceptional in the Greater Germanic Reich became a normal way of operating in the east. The crucial taboo against the killing of women and children was breached not only in Białystok, but also in Gargždai in late June. By July, significant numbers of women and children were being killed behind all front-lines not only by the Germans, but also by the local Ukrainian and Lithuanian auxiliary forces. On 29 July 1941, at a meeting of SS officers in Vileyka (Polish Wilejka, now Belarus), the \"Einsatzgruppen\" had been given a dressing-down for their low execution figures. Heydrich himself issued an order to include the Jewish women and children in all subsequent shooting operations. Accordingly, by the end of July the entire Jewish population of Vileyka, men, women and children were murdered. Around 12 August, no less than two-thirds of the Jews shot in Surazh were women and children of all ages. In late August 1941 the \"Einsatzgruppen\" murdered 23,600 Jews in the Kamianets-Podilskyi massacre. A month later, the largest mass shooting of Soviet Jews took place on 29–30 September in the ravine of Babi Yar, near Kiev, where more than 33,000 Jewish people of all ages were systematically machine-gunned. In mid-October 1941, HSSPF South, under the command of Friedrich Jeckeln, had reported the indiscriminate killing of more than 100,000 people.\n\nBy the end of December 1941, before the Wannsee Conference, over 439,800 Jewish people had been murdered, and the Final Solution policy in the east became common knowledge within the SS. Entire regions were reported \"free of Jews\" by the \"Einsatzgruppen\". Addressing his district governors in the General Government on 16 December 1941, Governor-General Hans Frank said: \"But what will happen to the Jews? Do you believe they will be lodged in settlements in Ostland? In Berlin, we were told: why all this trouble; we cannot use them in the Ostland or the Reichskommissariat either; liquidate them yourselves!\" Two days later, Himmler recorded the outcome of his discussion with Hitler. The result was: \"als Partisanen auszurotten\" (\"exterminate them as partisans\"). Israeli historian Yehuda Bauer wrote that the remark is probably as close as historians will ever get to a definitive order from Hitler for the genocide carried out during the Holocaust. Within two years, the total number of shooting victims in the east had risen to between 618,000 and 800,000 Jews.\n\nSeveral scholars have suggested that the Final Solution began in the newly formed district of \"Bezirk Bialystok\". The German army took over Białystok within days. On Friday, 27 June 1941, the Reserve Police Battalion 309 arrived in the city and set the Great Synagogue on fire with hundreds of Jewish men locked inside. The burning of the synagogue was followed by a frenzy of killings both inside the homes around the Jewish neighbourhood of Chanajki, and in the city park, lasting until night time. The next day, some 30 wagons of dead bodies were taken to mass graves. As noted by Browning, the killings were led by a commander \"who correctly intuited and anticipated the wishes of his Führer\" without direct orders. For reasons unknown, the number of victims in the official report by Major Weis was cut in half. The next mass shooting of Polish Jews within the newly formed \"Reichskommissariat Ostland\" took place in two days of 5–7 August in occupied Pińsk, where over 12,000 Jews died at the hands of Waffen SS, not the \"Einsatzgruppen\". An additional 17,000 Jews perished there in a ghetto uprising crushed a year later with the aid of Belarusian Auxiliary Police.\n\nAn Israeli historian Dina Porat claimed that the Final Solution, i.e.: \"the systematic overall physical extermination of Jewish communities one after the other – began in Lithuania\" during the massive German chase after the Red Army across the Baltic states in \"Reichskommissariat Ostland\". The subject of the Holocaust in Lithuania has been analysed by Konrad Kweit from USHMM who wrote: \"Lithuanian Jews were among the first victims of the Holocaust [beyond the eastern borders of occupied Poland]. The Germans carried out the mass executions [...] signaling the beginning of the 'Final Solution'.\" About 80,000 Jews were killed in Lithuania by October (including in formerly Polish Wilno) and about 175,000 by the end of 1941 according to official reports.\n\nWithin one week from the start of Operation Barbarossa, Heydrich issued an order to his \"Einsatzkommandos\" for the on-the-spot execution of all Bolsheviks, interpreted by the SS to mean all Jews. One of the first indiscriminate massacres of men, women, and children in \"Reichskommissariat Ukraine\" took the lives of over 4,000 Polish Jews in occupied Łuck on 2–4 July 1941, murdered by \"Einsatzkommando\" 4a assisted by the Ukrainian People's Militia. Formed officially on 20 August 1941, the \"Reichskommissariat Ukraine\" – stretching from prewar east-central Poland to Crimea – had become operational theatre of the \"Einsatzgruppe\" C. Within the Soviet Union proper, between 9 July 1941 and 19 September 1941 the city of Zhytomyr was made \"Judenfrei\" in three murder operations conducted by German and Ukrainian police in which 10,000 Jews perished. In the Kamianets-Podilskyi massacre of 26–28 August 1941 some 23,600 Jews were shot in front of open pits (including 14,000–18,000 people expelled from Hungary). After an incident in Bila Tserkva in which 90 small children left behind had to be shot separately, Blobel requested that Jewish mothers hold them in their arms during mass shootings. Long before the conference at Wannsee, 28,000 Jews were shot by SS and Ukrainian military in Vinnytsia on 22 September 1941, followed by the 29 September massacre of 33,771 Jews at Babi Yar. In Dnipropetrovsk, on 13 October 1941 some 10,000–15,000 Jews were shot. In Chernihiv, 10,000 Jews were put to death and only 260 Jews were spared. In mid-October, during the Krivoy-Rog massacre of 4,000–5,000 Soviet Jews the entire Ukrainian auxiliary police force actively participated. In the first days of January 1942 in Kharkiv, 12,000 Jews were murdered, but smaller massacres continued in this period on daily basis in countless other locations. In August 1942 in the presence of only a few German SS men over 5,000 Jews were massacred in Polish Zofjówka by the Ukrainian Auxiliary Police leading to the town's complete sweep from existence.\n\nHistorians find it difficult to determine precisely when the first concerted effort at annihilation of all Jews began in the last weeks of June 1941 during Operation Barbarossa. Dr. Samuel Drix (\"Witness to Annihilation\"), Jochaim Schoenfeld (\"Holocaust Memoirs\"), and several survivors of the Janowska concentration camp, who were interviewed in the film \"Janovska Camp at Lvov\", among other witnesses, have argued that the Final Solution began in Lwów (Lemberg) in \"Distrikt Galizien\" of the General Government during the German advance across Soviet-occupied Poland. Statements and memoirs of survivors emphasize that, when Ukrainian nationalists and \"ad hoc\" Ukrainian People's Militia (soon reorganized as the Ukrainian Auxiliary Police) began to murder women and children, rather than only male Jews, the \"Final Solution\" had begun. Witnesses have said that such murders happened both prior to and during the pogroms reportedly triggered by the NKVD prisoner massacre. The question of whether there was some coordination between the Lithuanian and Ukrainian militias remains open (i.e. collaborating for a joint assault in Kovno, Wilno, and Lwów).\n\nThe killings continued uninterrupted. On 12 October 1941, in Stanisławów, some 10,000–12,000 Jewish men, women, and children were shot at the Jewish cemetery by the German uniformed SS-men and Ukrainian Auxiliary Police during the so-called \"Bloody Sunday\" \"\". The shooters began firing at 12 noon and continued without stopping by taking turns. There were picnic tables set up on the side with bottles of vodka and sandwiches for those who needed to rest from the deafening noise of gunfire. It was the single largest massacre of Polish Jews in \"Generalgouvernement\" prior to mass gassings of \"Aktion Reinhard\", which commenced at Bełżec in March 1942. Notably, the extermination operations in Chełmno had begun on 8 December 1941, one-and-a-half month before Wannsee, but Chełmno – located in \"Reichsgau Wartheland\" – was not a part of Reinhard, and neither was Auschwitz-Birkenau functioning as an extermination center until November 1944 in Polish lands annexed by Hitler and added to Germany proper.\n\nThe conference at Wannsee gave impetus to the so-called \"second sweep\" of the Holocaust by the bullet in the east. Between April and July 1942 in Volhynia, 30,000 Jews were murdered in death pits with the help of dozens of newly formed Ukrainian \"Schutzmannschaft\". Owing to good relations with the Ukrainian \"Hilfsverwaltung\", these auxiliary battalions were deployed by the SS also in Russia Center, Russia South, and in Byelorussia; each with about 500 soldiers divided into three companies. They participated in the extermination of 150,000 Volhynian Jews alone, or 98 percent of the Jewish inhabitants of the entire region. In July 1942 the Completion of the Final Solution in the General Government territory which included \"Distrikt Galizien\", was ordered personally by Himmler. He set the initial deadline for 31 December 1942.\n\nWhen in 1941 the Wehrmacht forces attacked the Soviet positions in eastern Poland during the initially successful Operation Barbarossa, the area of the General Government was enlarged by the inclusion of regions that had been occupied by the Red Army since 1939. The killings of Jews from the Łódź Ghetto in the \"Warthegau\" district began in early December 1941 with the use of gas vans [approved by Heydrich] at the Kulmhof extermination camp. The deceptive guise of \"Resettlement in the East\" organised by SS Commissioners, was also tried and tested at Chełmno. By the time the European-wide Final Solution was formulated two months later, Heydrich's RSHA had already confirmed the effectiveness of industrial killing by exhaust fumes, and the strength of deception.\n\nConstruction work on the first killing centre at Bełżec in occupied Poland began in October 1941, three months before the Wannsee Conference. The new facility was operational by March the following year.<ref name=\"M/MPwB\"></ref> By mid-1942, two more death camps had been built on Polish lands: Sobibór operational by May 1942, and Treblinka operational in July. From July 1942, the mass murder of Polish and foreign Jews took place at Treblinka as part of Operation Reinhard, the deadliest phase of the Final Solution. More Jews were killed at Treblinka than at any other Nazi extermination camp apart from Auschwitz. By the time the mass killings of Operation Reinhard ended in 1943, roughly two million Jews in German-occupied Poland had been murdered. The total number of people killed in 1942 in Lublin/Majdanek, Bełżec, Sobibór, and Treblinka was 1,274,166 by Germany's own estimation, not counting Auschwitz II Birkenau nor \"Kulmhof\". Their bodies were buried in mass graves initially. Both Treblinka and Bełżec were equipped with powerful crawler excavators from Polish construction sites in the vicinity, capable of most digging tasks without disrupting surfaces. Although other methods of extermination, such as the cyanic poison Zyklon B, were already being used at other Nazi killing centres such as Auschwitz, the \"Aktion Reinhard\" camps used lethal exhaust gases from captured tank engines.\n\nThe \"Holocaust by bullets\" (as opposed to the \"Holocaust by gas\") went on in the territory of occupied Poland in conjunction with the ghetto uprisings, irrespective of death camps' quota. In two weeks of July 1942, the Słonim Ghetto revolt, crushed with the help of Latvian, Lithuanian, and Ukrainian \"Schutzmannschaft\", cost the lives of 8,000–13,000 Jews. The second largest mass shooting (to that particular date) took place in late October 1942 when the insurgency was suppressed in the Pińsk Ghetto; over 26,000 men, women and children were shot with the aid of Belarusian Auxiliary Police before the ghetto's closure. During the suppression of the Warsaw Ghetto Uprising (the largest single revolt by Jews during World War II), 13,000 Jews were killed in action before May 1943. Numerous other uprisings were quelled without impacting the pre-planned Nazi deportations actions.\n\nAbout two-thirds of the overall number of victims of the Final Solution were killed before February 1943, which included the main phase of the extermination programme in the West launched by Eichmann on 11 June 1942 from Berlin. The Holocaust trains run by the \"Deutsche Reichsbahn\" and several other national railway systems delivered condemned Jewish captives from as far as Belgium, Bulgaria, France, Greece, Hungary, Italy, Moravia, Netherlands, Romania, Slovakia, and even Scandinavia. The cremation of exhumed corpses to destroy any evidence left behind began in early spring and continued throughout summer. The nearly completed clandestine programme of murdering all deportees was explicitly addressed by Heinrich Himmler in his Posen speeches made to the leadership of the Nazi Party on 4 October and during the Posen Conference of 6 October 1943 in occupied Poland. Himmler explained why the Nazi leadership found it necessary to kill Jewish women and children along with the Jewish men. The assembled functionaries were told that the Nazi state policy was \"the extermination of the Jewish people\" as such.\n\nOn 19 October 1943, five days after the prisoner revolt in Sobibór, Operation Reinhard was terminated by Odilo Globocnik on behalf of Himmler. The camps responsible for the killing of nearly 2,700,000 Jews were soon closed. Bełżec, Sobibór, and Treblinka were dismantled and ploughed over before spring. The operation was followed by the single largest German massacre of Jews in the entire war carried out on 3 November 1943; with approximately 43,000 prisoners shot one-by-one simultaneously in three nearby locations by the Reserve Police Battalion 101 hand-in-hand with the Trawniki men from Ukraine. Auschwitz alone had enough capacity to fulfill the Nazis' remaining extermination needs.\n\nUnlike Belzec, Sobibor, Treblinka, and Lublin-Majdanek, which were built in the occupied General Government territory inhabited by the largest concentrations of Jews, the killing centre at Auschwitz subcamp of Birkenau operated in Polish areas annexed by Nazi Germany directly. The new gas chambers at Bunker I were finished around March 1942 when the Final Solution was officially launched at Belzec. Until mid-June 20,000 Silesian Jews were killed there using Zyklon B. In July 1942, Bunker II became operational. In August, another 10,000-13,000 Polish Jews from Silesia perished, along with 16,000 French Jews declared 'stateless', and 7,700 Jews from Slovakia.\n\nThe infamous 'Gate of Death' at Auschwitz II for the incoming freight trains was built of brick and cement mortar in 1943, and the three-track rail spur was added. Until mid-August, 45,000 Thessaloniki Jews were murdered in a mere six months, including over 30,000 Jews from Sosnowiec (Sosnowitz) and Bendzin Ghettos. The spring of 1944 marked the beginning of the last phase of the Final Solution at Birkenau. The new big ramps and sidings were constructed, and two freight elevators were installed inside Crematoria II and III for moving the bodies faster. The size of the \"Sonderkommando\" was nearly quadrupled in preparation for the Special Operation Hungary (\"Sonderaktion Ungarn\"). In May 1944, Auschwitz-Birkenau became the site of one of the two largest mass murder operations in modern history, after the \"Großaktion Warschau\" deportations of the Warsaw Ghetto inmates to Treblinka in 1942. It is estimated that until July 1944 approximately 320,000 Hungarian Jews were gassed at Birkenau in less than eight weeks. The entire operation was photographed by the SS. In total, between April and November 1944, Auschwitz II received over 585,000 Jews from over a dozen regions as far as Greece, Italy, and France, including 426,000 Jews from Hungary, 67,000 from Łódź, 25,000 from Theresienstadt, and the last 23,000 Jews from the General Government. Auschwitz was liberated by the Red Army on 27 January 1945, when the gassing had already stopped.\n\nHistorians disagree as to when and how the Nazi leadership decided that the European Jews should be exterminated. The controversy is commonly described as the functionalism versus intentionalism debate which began in the 1960s, and subsided thirty years later. In the 1990s, the attention of mainstream historians moved away from the question of top executive orders triggering the Holocaust, and focused on factors which were overlooked earlier, such as personal initiative and ingenuity of countless functionaries in charge of the killing fields. No written evidence of Hitler ordering the Final Solution has ever been found to serve as a \"smoking gun\", and therefore, this one particular question remains unanswered.\n\nHitler made numerous predictions regarding the Holocaust of the Jews of Europe prior to the beginning of World War II. During a speech given on 30 January 1939, on the sixth anniversary of his accession to power, Hitler said:\n\nRaul Hilberg, in his book \"The Destruction of the European Jews\", was the first historian to systematically document and analyse the Nazi project to kill every Jew in Europe. The book was initially published in 1961, and issued in an enlarged version in 1985.\n\nHilberg's analysis of the steps that led to the destruction of European Jews revealed that it was \"an administrative process carried out by bureaucrats in a network of offices spanning a continent\". Hilberg divides this bureaucracy into four components or hierarchies: the Nazi Party, the civil service, industry, and the Wehrmacht armed forces – but their cooperation is viewed as \"so complete that we may truly speak of their fusion into a machinery of destruction\". For Hilberg, the key stages in the destruction process were: definition and registration of the Jews; expropriation of property; concentration into ghettoes and camps; and, finally, annihilation. Hilberg gives an estimate of 5.1 million as the total number of Jews killed. He breaks this figure down into three categories: Ghettoization and general privation: over 800,000; open-air shootings: over 1,300,000; extermination camps: up to 3,000,000.\n\nWith respect to the \"functionalism versus intentionalism\" debate about a master plan for the Final Solution, or the lack thereof, Hilberg posits what has been described as \"a kind of structural determinism\". Hilberg argues that \"a destruction process has an inherent pattern\" and the \"sequence of steps in a destruction process is thus determined\". If a bureaucracy is motivated \"to inflict maximum damage upon a group of people\", it is \"inevitable that a bureaucracy—no matter how decentralized its apparatus or how unplanned its activities—should push its victims through these stages\", culminating in their annihilation.\n\nIn his monograph, \"The Origins Of The Final Solution: The Evolution of Nazi Jewish Policy, September 1939 – March 1942\", Christopher Browning argues that Nazi policy toward the Jews was radicalized twice: in September 1939, when the invasion of Poland implied policies of mass expulsion and massive loss of Jewish lives; and in spring 1941, when preparation for Operation Barbarossa involved the planning of mass execution, mass expulsion, and starvation – to dwarf what had happened in Jewish Poland.\n\nBrowning believes that the \"Final Solution as it is now understood—the systematic attempt to murder every last Jew within the German grasp\" took shape during a five-week period, from 18 September to 25 October 1941. During this time: the sites of the first extermination camps were selected, different methods of killing were tested, Jewish emigration from the Third Reich was forbidden, and 11 transports departed for Łódź as a temporary holding station. During this period, Browning writes, \"The vision of the Final Solution had crystallised in the minds of the Nazi leadership, and was being turned into reality.\" This period was the peak of Nazi victories against the Soviet Army on the Eastern Front, and, according to Browning, the stunning series of German victories led to both an expectation that the war would soon be won, and the planning of the final destruction of the \"Jewish-Bolshevik enemy\".\n\nBrowning describes the creation of the extermination camps, which were responsible for the largest number of deaths in the Final Solution, as bringing together three separate developments within the Third Reich: the concentration camps which had been established in Germany since 1933; an expansion of the gassing technology of the Nazi euthanasia programme to provide killing mechanism of greater efficiency and psychological detachment; and the creation of \"factories of death\" to be fed endless streams of victims by mass uprooting and deportation that utilized the experience and personnel from earlier population resettlement programmes—especially the HSSPF and Adolf Eichmann's RSHA for \"Jewish affairs and evacuations\".\n\nPeter Longerich argues that the search for a finite date on which the Nazis embarked upon the extermination of the Jews is futile, in his book \"Holocaust: The Nazi Persecution and Murder of the Jews\" (2011). Longerich writes: \"We should abandon the notion that it is historically meaningful to try to filter the wealth of available historical material and pick out a single decision\" that led to the Holocaust.\n\nTimothy Snyder writes that Longerich \"grants the significance of Greiser's murder of Jews by gas at Chełmno in December 1941\", but also detects a significant moment of escalation in spring 1942, which includes \"the construction of the large death factory at Treblinka for the destruction of the Warsaw Jews, and the addition of a gas chamber to the concentration camp at Auschwitz for the murder of the Jews of Silesia\". Longerich suggests that it \"was only in the summer of 1942, that mass killing was finally understood as the realization of the Final Solution, rather than as an extensively violent preliminary to some later program of slave labor and deportation to the lands of a conquered USSR\". For Longerich, to see mass killing as the Final Solution was an acknowledgement by the Nazi leadership that there would not be a German military victory over the USSR in the near future.\n\nDavid Cesarani emphasises the improvised, haphazard nature of Nazi policies in response to changing war time conditions in his overview, \"Final Solution: The Fate Of The European Jews 1933-49\" (2016). \"Cesarani provides telling examples\", wrote Mark Roseman, \"of a lack of coherence and planning for the future in Jewish policy, even when we would most expect it. The classic instance is the invasion of Poland in 1939, when not even the most elementary consideration had been given to what should happen to Poland's Jews either in the shorter or longer term. Given that Poland was home to the largest Jewish population in the world, and that, in a couple of years, it would house the extermination camps, this is remarkable.\"\n\nWhereas Christopher Browning places the Nazi plan to exterminate the Jews in the context of the Wehrmacht victories on the Eastern front, Cesarani argues that the German subsequent realisation that there would be no swift victory over the Soviet Union \"scuppered the last territorial 'solution' still on the table: expulsion to Siberia\". Germany's declaration of war on the United States on December 11, 1941, \"meant that holding European Jews hostage to deter the US from entering the conflict was now pointless. As Joseph Goebbels put it when he summarised a secret speech Hitler made on 12 December 1941: 'The world war is here, the destruction of the Jews must be the inevitable consequence'.\" Cesarani concludes, the Holocaust \"was rooted in anti-Semitism, but it was shaped by war\". The fact that the Nazis were, ultimately, so successful in killing between five and six million Jews was not due to the efficiency of the Third Reich or the clarity of their policies. \"Rather, the catastrophic rate of killing was due to German persistence … and the duration of the murderous campaigns. This last factor was largely a consequence of allied military failure.\"\nThe entry of the U.S. into the War is also crucial to the time-frame proposed by Christian Gerlach, who argued in his 1997 thesis, that the Final Solution decision was announced on 12 December 1941, when Hitler addressed a meeting of the Nazi Party (the \"Reichsleiter\") and of regional party leaders (the \"Gauleiter\"). The day after Hitler's speech, on 13 December 1941 Joseph Goebbels wrote in his diary:\n\nCesarani notes that by 1943, as the military position of the German forces deteriorated, the Nazi leadership became more openly explicit about the Final Solution. In March, Goebbels confided to his diary: \"On the Jewish question especially, we are in it so deeply that there is no getting out any longer. And that is a good thing. Experience teaches that a movement and a people who have burned their bridges fight with much greater determination and fewer constraints than those that have a chance of retreat.\"\n\nWhen Himmler addressed senior SS personnel and leading members of the regime in the Posen speeches on October 4, 1943, he used \"the fate of the Jews as a sort of blood bond to tie the civil and military leadership to the Nazi cause\".\n\nIn May 1944, Himmler told senior army officers that, \"The Jewish question has been solved in Germany and in the countries occupied by Germany. It has been solved uncompromisingly, as was appropriate in view of the struggle in which we were engaged for the life of our nation.\" Himmler explained that it was important that even women and children had to die, so that no \"hate-filled avengers\" would be able to confront our children and grandchildren.\n\n\n\n"}
{"id": "1848867", "url": "https://en.wikipedia.org/wiki?curid=1848867", "title": "Functional load", "text": "Functional load\n\nIn linguistics and especially phonology, functional load, or phonemic load, refers to the importance of certain features in making distinctions in a language. In other words, a high functional load will make it hard to guess the identity of a phoneme that is not perceived in a word because of noise or omission.\n\nThe term \"functional load\" goes back to the days of the Prague School; references to it can be found in the work of Vilem Mathesius in 1929. Its most vocal advocate was André Martinet, a historical linguist who claimed it was a factor in the likelihood of a phonological merger.\n\nThe first suggested measurement for functional load was the number of minimal pairs, but this does not take into account word frequency and is difficult to generalize beyond binary phonemic oppositions. Charles Hockett proposed an information theoretic definition in 1955\n, which has since been generalized. Now, given a large text corpus, one can compute the functional load of any phonological contrast including distinctive features, suprasegmentals, and distinctions between groups of phonemes. For instance, the functional load of tones in Standard Chinese is as high as that of vowels i.e. the information lost when all tones sound alike is as much as that lost when all vowels sound alike. \nMartinet predicted that perceptually similar pairs of phonemes with low functional load would merge. This has not been proved empirically; indeed, all empirical tests have come out against it e.g. merged with in Cantonese in word-initial position in the late 20th century despite the fact that of all consonants in binary opposition to , only the opposition had a higher functional load than the opposition.\n\nEnglish vowels, for example, have a very high functional load. There are innumerable sets of words distinguished just by their vowels, such as \"pin, pen, pan, pun, pain, pine\". Voicing is similar, as can be seen in \"pat - bad, sue - zoo\". Speakers who do not control these differences make it very difficult for others to understand them. \n\nHowever, although voicing is generally important in English, the voicing difference between the two fricatives written ⟨th⟩, , has a very low functional load: it is difficult to find meaningful distinctions dependent solely on this difference. One of the few examples is \"thigh\" vs. \"thy\" although the two can be distinguished from context alone. Similar is the difference of (written ⟨j⟩, ⟨ge⟩, etc.) versus (resulting from , or the ⟨j⟩, ⟨ge⟩, etc. in some recent French loanwords), as in \"virgin\" vs. \"version\". The difference between the two ⟨ng⟩ sounds, , found in \"singer\" and \"finger\", is so unimportant that it makes no practical difference if one mixes them up, and some dialects pronounce the sounds the same in both words. The functional load is nearly zero—not surprising since the phoneme originated as a coalescence of when word-final.\n\nAn ongoing example would be the merger of the AIR and EAR vowels in New Zealand English. The phonetic similarity between words like \"here\" and \"hare\" does not seem to hamper oral communication in any major way as long as the context is provided. Therefore, those vowels have low functional load in New Zealand English despite their high frequency of occurrences in that dialect.\n\nAnother example is the functional load of tone in Mandarin Chinese, which is nearly as high as that of their vowels. This means that the loss of information when all tones sound alike in Mandarin is approximately equal to that when all vowels sound alike in the language. By contrast, in many Bantu languages, the tones have a low functional load, and in Swahili tones disappeared altogether.\n"}
{"id": "25221078", "url": "https://en.wikipedia.org/wiki?curid=25221078", "title": "GoldenDict", "text": "GoldenDict\n\nGoldenDict is an open-source dictionary program that gives translations of words and phrases for different languages. It allows the use of several popular dictionary file formats simultaneously and without conversion.\n\nThe project aims to create a feature-rich dictionary search program.\n\n\nCompared to other similar software GoldenDict:\n\n\n"}
{"id": "2280897", "url": "https://en.wikipedia.org/wiki?curid=2280897", "title": "Good ol' boy", "text": "Good ol' boy\n\nGood ol' boy or good old boy is an American English slang term that can have both positive and negative meanings, depending on context and use. The term is commonplace in the Southern United States.\n\nThe term can be used for well socialized men who live in rural and generally Southern areas. If a man is humble and well thought of, he can be referred to as a good old boy, regardless of his age.\n\nIt is also commonly applied to white men from a family with multi-generational wealth or prestige established by a legacy of plantation and slave ownership, or to men who behave like a Southern gentleman.\n\nPejoratively, the phrase can often suggest a man with an anti-intellectual or racist bias or some other intolerant viewpoint.\n\nThe phrase also can refer negatively to someone who engages in cronyism among men who have known each other for a long period of time. Collectively, these people are referred to as a good ol' boy network, or an old boys' club.\n\n"}
{"id": "35725211", "url": "https://en.wikipedia.org/wiki?curid=35725211", "title": "Guya language", "text": "Guya language\n\nGuya (Guiarak) is one of the Finisterre languages of Papua New Guinea.\n"}
{"id": "15929586", "url": "https://en.wikipedia.org/wiki?curid=15929586", "title": "Henry Spelman of Jamestown", "text": "Henry Spelman of Jamestown\n\nHenry Spelman (1595–1623) was an English adventurer, soldier, and author, the son of Erasmus Spelman and nephew to Sir Henry Spelman of Congham (1562–1641). The younger Henry Spelman was born in 1595, and left his home in Norfolk, England at age 14 to sail to Virginia Colony aboard the ship \"Unity\", as a part of the Third Supply to the Jamestown Colony in 1609. He is remembered for writing the \"Relation of Virginia\", documenting the first permanent English settlement in North America at Jamestown, Virginia, and particularly the lifestyles of the Native Americans of the Powhatan Confederacy led by Chief Powhatan.\n\nDespite being a son of the high sheriff of his county, Spelman, owing to the traditional English practice of primogeniture, was left to indenture himself as a laborer to pay his passage to the New World. The Third Supply flotilla of 9 ships set sail from Plymouth, England on 2 June 1609. In July 1609, the ships ran into a massive 3 day storm and the fleet was broken up, with the flagship Sea Venture wrecking upon the islands of Bermuda. After the storm passed, the remaining ships reassembled off of Cape Henry and sailed up the coast, arriving at Jamestown 4 or 5 days later in October 1609.\n\nOnly two weeks after his arrival at the Jamestown Settlement, Henry went with Captain John Smith on an expedition up the James River to the Indian town called Powhatan. (located in the East End portion of the modern-day city of Richmond, Virginia.) Smith knew that Jamestown would be unable to support the arrival of several hundred new colonists through the coming winter, and he traded young Henry's bonded servitude in exchange for the village, which was ruled by \"weroance\" Parahunt, son of Wahunsunacock (also known as Chief Powhatan.) The agreement was also for the boy to apprentice the native Powhatan language, and thus become an interpreter and serve as a messenger between the two cultures. Young Henry Spelman was not the first boy to be traded to the Powhatans; Thomas Savage had previously been given to Powhatan by Captain Christopher Newport in 1608, and Henry named in his writings of \"Dutchman Samuel\" (actually \"Samuel Collier\" who was John Smith's page) as another European child that lived with the Natives.\n\nParahunt treated Henry well, but relations soured between the English and the Powhatan, eventually leading to warfare. Henry wanted to return to the English and soon made his way back to Jamestown. His stay was brief however due to the shortage of food at the fort as they started into what has been named the starving time; and he knew the Indians had food in their village. Henry took a hatchet and some copper with him and gave it to Powhatan. Powhatan was pleased and treated Henry kindly for a while.\n\nHenry spent a total of about a year and a half with the Powhatan Indians, learning the Algonquian language and their way of life. He acted as a messenger and interpreter between the Powhatan people and the English, arranging for the two groups to trade with one another. He also witnessed hostilities between them which made him feel uneasy. He had been living at Yawtanoone (Youghtanund) for six months when a local chief of the Patawomeck, a tribe living on the south side of the Potomac River, came to visit Powhatan. Without telling Chief Powhatan, Henry, Thomas and Dutchman Samuel left when the visiting Chief left. Powhatan's men captured and killed Samuel. In his book \"Generall Historie of Virginia, …\", Capt. John Smith wrote that \" \"Pokahontas the Kings daughter saved a boy called Henry Spilman that lived many yeeres after, by her meanes, amongst the Patawomekes.\" \" There he stayed at Paspatanzie, moved freely and was treated as a special guest.\n\nIn September 1610, Captain Samuel Argall was on a trading mission and found Henry living with the Patawomeck, and he was bought back for \"sum copper.\" With his knowledge of the native language and culture, Henry continued to help the English trade copper for valuable supplies such as corn. He also helped the Colonists form an alliance with these northern Native Americans that would be important for the future of Jamestown. In 1613, Henry was the interpreter when Chief Japazaws helped Argall abduct Pocahontas, which eventually led to her marriage to John Rolfe and a temporary peace with Powhatan. Henry continued to work as an interpreter for the English, mixing with both English and Powhatan leaders.\n\nHenry went back to England in 1613, and made several other trips, but returned to Virginia each time to continue to serve as an interpreter, and eventually rising to the rank of Captain. During this time he married an Patawomeck Indian woman who is believed to have been given the English name \"Martha Fox.\" (\"According to traditions passed on to Henry Spellman's descendents, - his native wife was a sister of Pocahontas, and daughter of Powhatan\".) In 1619, a rival interpreter accused Henry of speaking badly about the now Governor Samuel Argall to Opchanacanough, who was the new chief of the Powhatan people. If he was found guilty of treason, Henry could have been executed, but he was instead found guilty of a lesser crime, and on 4 August 1619, he lost his rank of Captain and was sentenced to serve the Governor for seven years as an interpreter. Records state: \" \"this sentence being read to Spelman he, as one that had in him more of the Savage than of the Christian, muttered certain words to himself neither showing any remorse for his offences, nor yet any thankfulness to the Assembly for their so favorable censure.\" \" \n\nIn 1622 Opchanacanough tried to drive the English out of Virginia by attacking the settlers, killing about 330 men, women and children. Henry survived the attacks and was called upon to renew the English alliance with the Patawomeck tribe, who were at that point detached from Powhatan's Confederacy. In the spring of 1623, Henry volunteered to take a group of 19 men north to the Potomac River, away from the fighting near Jamestown, to barter for corn or other food. On 23 March 1623 the party was attacked by 60 canoes full of Anacostan Indians from their settlement of Nacochtank along the Anacostia River. Henry Spelman and all others in his party were killed or captured in the botched trading expedition (apart from Captain Henry Fleet, who spent 5 years in captivity with them and also learned their language). After providing much good service as an interpreter, Henry Spelman died as he had lived – amongst the Native Indians at 28 years old. Some sources say Spelman was captured and beheaded by the Anacostans. This attack was in reprisal for a 1622 attack by Fleet and the Patawomecks in which 18 Anacostans had been killed.\n\nHe was survived by his Patawomeck spouse \"Martha Fox,\" a child named Clement Spelman, his uncle Sir Henry Spelman, his brothers Thomas Spelman of Kecoughtan, Virginia and Francis Spelman of Truro, Cornwall, England.\n\nHenry Spelman's handwritten manuscript, \"a Relation of Virginia\" was later printed privately in 1872 by the Chiswick Press of London.\n\n\n"}
{"id": "1596564", "url": "https://en.wikipedia.org/wiki?curid=1596564", "title": "Jacob ben Isaac Ashkenazi", "text": "Jacob ben Isaac Ashkenazi\n\nRabbi Jacob ben Isaac Ashkenazi (1550–1625), of Janów (near Lublin, Poland), was the author of the \"Tseno Ureno\", sometimes called the \"Women's Bible\", a Yiddish-language prose work written around the 1590s whose structure parallels the weekly portions of the Pentateuch and Haftorahs used in Shabbat services.\n\nHe also authored a supplement, the \"Melitz Yosher\" () and \"Seyfer Ha Magid\" (). \"Ha Magid\", which literally means \"the book that tells\" or \"the messenger book\" in the biblical sense, as in \"the messenger came to David saying\" in , is a similar compilation on the Prophets and Hagiographa.\n\n"}
{"id": "39527448", "url": "https://en.wikipedia.org/wiki?curid=39527448", "title": "Jakov of Serres", "text": "Jakov of Serres\n\nJakov of Serres (; 1300–1365) was a medieval Serbian writer, scholar, translator, and hierarch of the Serbian Orthodox Church, one of the most important men of letters working in the 14th century.\n\nEvidence about his life is scarce but his literary legacy suggests an excellent knowledge of Greek and Slavic languages. In 1343, King and eventually Emperor, Stefan Dušan began to build the Monastery of the Holy Archangels near Prizren; and he appointed Jakov, a learned and highly esteemed monk, its first \"hegumen\" (abbot). Both Stefan Dušan and his wife Jelena were in awe of Jakov's wide knowledge and they often sought his company and counsel. In 1345, Stefan Dušan captured the city of Serres from the Byzantine Empire; and Jakov was appointed Metropolitan of Serres and its surrounding territories. The population of Serres was mixed Slavic, Albanian and Greek and Jakov was fluent in all three languages and their dialects. In fact, Jakov wrote some literature hymns in Greek, and is numbered among the Greek authors as well as Serbian. Jakov was a disciple of Gregory of Sinai and a friend of Romylos of Ravanica.\n\nAfter the sudden death of Stefan Dušan in 1355, Jelena, Dušan's wife, became a nun, took the name Jelisaveta, and moved from Skoplje, the capital of Serbia, to Serres. From there, she administered her estates; and Jakov was at her side as wise counsel. Jakov wrote the \"Triodion\" which he sent as his bequest to the Monastery of the Theotokos in Sinai in 1359 or 1360. At present, the Triodion (a two-part Triodion, one for Lent and the other for the period between Easter and Pentecost) is kept in Monastery of St. Catherine in Sinai. Copies are also kept at Hilandar Monastery, Mount Athos, Greece, and in libraries in the United Kingdom, Europe and North America.\n\nHe is illustrated in the Serbian manuscript of Kalist's \"Tetraevangelion\" (The Four Gospels) dating to 1354, held at the British Museum.\n\n"}
{"id": "31680397", "url": "https://en.wikipedia.org/wiki?curid=31680397", "title": "Kapinawá", "text": "Kapinawá\n\nThe Kapinawâ are an indigenous people of Pernambuco in eastern Brazil. \n\nThe Kapinawa are monolingual in Portuguese. Their original language is unattested and cannot be shown to have been distinct from neighboring languages.\n\n"}
{"id": "2560842", "url": "https://en.wikipedia.org/wiki?curid=2560842", "title": "Knee wall", "text": "Knee wall\n\nA knee wall is a short wall, typically under three feet (one metre) in height, used to support the rafters in timber roof construction. In his book \"A Visual Dictionary of Architecture\", Francis D. K. Ching defines a knee wall as \"a short wall supporting rafters at some intermediate position along their length.\" The knee wall provides support to rafters which therefore need not be large enough to span from the ridge to the eaves. Typically the knee wall is covered with plaster or gypsum board, enclosing the useful part of the attic space (not necessarily high enough for a person to stand up), while the remaining small space under the eaves is only useful for storage.\n\nThe term is derived from the association with the vertical location of the human knee. Knee walls are common in old houses in which the ceiling on the top floor is an attic, i.e. the ceiling is the underside of the roof and slopes down on one or more sides.\n\n"}
{"id": "2894103", "url": "https://en.wikipedia.org/wiki?curid=2894103", "title": "Languages used on the Internet", "text": "Languages used on the Internet\n\nAbout half of the homepages of the most visited sites on the Internet are in English, with varying amounts of information available in many other languages. Other top languages, according to W3Techs, are Russian, German, Japanese, Spanish, French, Chinese, Portuguese, and Italian.\n\nOf the more than 7,000 existing languages, only a few hundred are recognized as being in use for content pages on the Internet.\n\nThere is debate over the most-used languages on the Internet. A 2009 UNESCO report monitoring the languages of websites for 12 years, from 1996 to 2008, found a steady year-on-year decline in the percentage of webpages in English, from 75 percent in 1998 to 45 percent in 2005. The authors found that English remained at 45 percent of content for 2005 to the end of the study but believe this was due to the bias of search engines indexing more English-language content rather than a true stabilization of the percentage of content in English online.\n\nOngoing monitoring by W3Techs showed that in March 2015, just over 55 percent of the most visited websites had English-language homepages.\nOther top languages that are used at least in 2 percent of the one million most visited websites according to W3Techs are Russian, German, Japanese, Spanish, French, Chinese, and Portuguese.\n\nThe figures from the W3Techs study are based on the one million most visited websites (i.e., approximately 0.27 percent of all websites according to December 2011 figures) as ranked by Alexa.com, and language is identified using only the home page of the sites in most cases (i.e., all of Wikipedia is based on the language detection of http://www.wikipedia.org). As a consequence, the figures show a significantly higher percentage for many languages (especially for English) as compared to the figures for all websites. The figures for all websites are unknown, but some sources estimate below 50 percent for English; see for instance, Towards a multilingual cyberspace and the 2009 UNESCO report.\n\nThe number of non-English pages is rapidly expanding. The use of English online increased by around 281 percent from 2001 to 2011, a lower rate of growth than that of Spanish (743 percent), Chinese (1,277 percent), Russian (1,826 percent) or Arabic (2,501 percent) over the same period.\n\nAccording to a 2000 study, the international auxiliary language Esperanto ranked 40 out of all languages in search engine queries, also ranking 27 out of all languages that rely on the Latin script.\n\nW3Techs estimated percentages of the top 10 million websites using various content languages as of 7 September 2018:\n\nAll other languages are used in less than 0.1% of websites. Even including all languages, percentages may not sum to 100% because some websites contain multiple content languages.\n\nInternetWorldStats estimates of the number of Internet users by language as of April 20, 2018:\n\n\n"}
{"id": "579177", "url": "https://en.wikipedia.org/wiki?curid=579177", "title": "Late harvest wine", "text": "Late harvest wine\n\nLate harvest wine is wine made from grapes left on the vine longer than usual. \"Late harvest\" is usually an indication of a sweet dessert wine, such as late harvest Riesling. Late harvest grapes are often more similar to raisins, but have been naturally dehydrated while on the vine.\n\nBotrytis cinerea, or \"noble rot\", is a mold that causes grapes to lose nearly all of their water content. Wines made from botrytis-affected grapes are generally very sweet.\n\nBotrytis cinerea is a fungus that affects many wine grapes and causes them to shrivel into moldy raisins. The fungus responds to the humidity and warmth in the climate and attacks the grapes. As the mold penetrates the skin its spores begin to germinate, causing the water inside to evaporate and the grape to dehydrate. With the absence of water, the sugar becomes more concentrated and the botrytis begins to alter the acidity within the grape. Typically botrytis infection begins to take place in late September and can last till late October. In some years desiccation may occur leaving tiny amount of sweet liquor like juice within the grape.\n\nThe infection rate of botrytis is sporadic with vines and bunches achieving full rottenness at different times. This requires harvest workers to go through the vineyards several times between October and November to hand-pick the full rotted grapes. In some occasions, the usable grapes from a single vine may only produce enough juice for a single glass.\n\nSauternes, such as Château d'Yquem, are produced in the Sauternes region (including Barsac) south of Bordeaux. They are made from botrytis infected Semillon and Sauvignon blanc grapes. Semillon is preferred due to the grape's thin skin and susceptibility to the botrytis which gives the grape a high sugar content. These wines are noted for the balance that complements the honeyed sweetness.\n\nDuring fermentation, the juice is transferred into oak wine barrels where the high sugar concentration of must prolongs the fermentation time which can last up to a year. When the alcohol level kills off all present yeast, the fermentation stops leaving the residual sugar at levels between 8 and 12% and alcohol levels around 14%.\n\nAfter fermentation, the wine is placed in an aging barrel for two to three years before it is bottled where it will continue aging. A Sauterne from a reputable estate can bottle age for over 30 years though they normally hit their peak 10 years after the vintage date.\n\nTokaji wines are produced in the Tokaj regions of Hungary and Slovakia. Wine has been made in these regions since as early as 1650, before the botrytized wines of Sauternes and the Rheingau were produced. The Furmint, Yellow Muscat, and Hárslevelű/Lipovina grapes are the primary grapes used in this wine. In a manner similar to Sherry, the wine is aged in partially filled barrels with a film of yeast on top and stored underground in wine caverns.\n\nIn Germany, wines are classified according to the ripeness of the grape at time of harvest. Within the Qualitätswein mit Prädikat classification, there are four levels of late harvest wines, roughly ranging from dry to very sweet: Spätlese (\"late harvest\"), Auslese (\"selected harvest\"), Beerenauslese (\"selected berries harvest\") and Trockenbeerenauslese (\"selected dried-berries harvest\") with the last two levels being botrytized.\n\nIce wines are popular in the cold northernly wine regions of Germany and Canada where the grapes can freeze on the vine. As the grapes are pressed, the frozen water crystals are eliminated leaving the highly concentrated sugar behind.\n\nRaisin wines are sometimes made from grapes that have been left on the vine in the sun to concentrate their sugar.\n"}
{"id": "2624472", "url": "https://en.wikipedia.org/wiki?curid=2624472", "title": "Left May languages", "text": "Left May languages\n\nThe Left May or Arai languages are a small language family of half a dozen closely related but not mutually intelligible languages in the centre of New Guinea, along the left bank of the May River. There are only about 2,000 speakers in all.\n\nThe languages are:\n\nMalcolm Ross (2005) linked the Left May languages to Laycock's Kwomtari–Baibai languages in a Left May – Kwomtari family, based on similarities in the pronouns of Rocky Peak. However, he had not corrected for Laycock's errors in classification, and it is not clear if the links are with the Kwomtari or Fas languages.\n\nTimothy Usher links the Left May languages to their neighbors, the Amto–Musan languages and the Pyu language in as Arai–Samaia stock.\n\n\n"}
{"id": "3150161", "url": "https://en.wikipedia.org/wiki?curid=3150161", "title": "Madiya language", "text": "Madiya language\n\nMadiya or Maria is a Dravidian language spoken in India. It may be regarded as a dialect of Gondi, but is suspected to be mutually unintelligible with most other Gondi varieties.\n\nPhonology of Abhuj Maria:\n\nHill Maria has 3 additional consonants: a glottal stop (ʔ), a retroflex nasal (ɳ), and an uvular trill (ʀ).\n"}
{"id": "997665", "url": "https://en.wikipedia.org/wiki?curid=997665", "title": "Makalero dialect", "text": "Makalero dialect\n\nMakalero or Maklere is a dialect of Makasae spoken by 6,000 people in East Timor.\n\nAll the information in this section is from Huber's grammar.\n\nMakalero has 11 native consonant phonemes.\n\nMakalero has five vowel phonemes. Most long vowels occur in predictable contexts; thus Huber argues long vowels are marginal phonemes at best.\n\nSyllables are commonly CV; some are CVC. Epenthetic vowels are often inserted between series of two consonants, and echo vowels are often added to the end of phonological phrases.\n\n"}
{"id": "4113685", "url": "https://en.wikipedia.org/wiki?curid=4113685", "title": "Murder book", "text": "Murder book\n\nIn law enforcement parlance, the term murder book refers to the case file of a murder investigation. Typically, murder books include crime scene photographs and sketches, autopsy and forensic reports, transcripts of investigators' notes and witness interviews. The murder book encapsulates the complete paper trail of a murder investigation, from the time the murder is first reported through the arrest of a suspect.\n\nLaw enforcement agencies typically guard murder books carefully, and it is unusual for civilians to be given unfettered access to these kinds of records, especially for unsolved cases.\n\n\nAmerican crime novelist Michael Connelly makes regular references to the meticulous murder books kept by LAPD detective Harry Bosch, particularly in \"The Black Echo\", \"The Concrete Blonde\", \"The Last Coyote\", \"Trunk Music\", \"The Closers\", and \"The Drop\".\n\n"}
{"id": "5577531", "url": "https://en.wikipedia.org/wiki?curid=5577531", "title": "Northeastern Neo-Aramaic", "text": "Northeastern Neo-Aramaic\n\nNortheastern Neo-Aramaic (often abbreviated NENA) is a term used by Semiticists to refer to a large variety of Modern Aramaic languages that were once spoken in a large region stretching from the plain of Urmia, in northwestern Iran, to the plain of Mosul, in northern Iraq, as well as bordering regions in south east Turkey and north east Syria.\n\nAs of the 1990s, the NENA group had an estimated number of fluent speakers among the Assyrians just below 500,000, spread throughout the Middle East and the Assyrian diaspora. More than 90% of these speak either the Assyrian Neo-Aramaic or the Chaldean Neo-Aramaic variety, two varieties of Christian Neo-Aramaic or \"Sureth\" which, contrary to what their names suggest, are not divided among denominational Chaldean Catholic Church/Assyrian Church of the East lines, and indeed some speakers of both dialects may be followers of the Syriac Orthodox Church or Protestants. There are a number of other NENA varieties, but all of them are endangered or near-extinct, and in addition, some Assyrian communities speak Central Neo-Aramaic dialects such as Turoyo.\n\nThe NENA languages contain a large number of loanwords and some grammatical features from the extinct East Semitic Akkadian language of Mesopotamia (the original language of the Assyrians) and also in more modern times from their surrounding languages: Kurdish, Arabic, Persian, Azerbaijani and Turkish language. These languages are spoken by both Jews and Christian Assyrians from the area. Each variety of NENA is clearly Jewish or Assyrian.\n\nHowever, not all varieties of one or other religious groups are intelligible with all others of the group. Likewise, in some places Jews and Assyrian Christians from the same locale speak mutually unintelligible varieties of Aramaic, where in other places their language is quite similar. The differences can be explained by the fact that NENA communities gradually became isolated into small groups spread over a wide area, and some had to be highly mobile due to various ethnic and religious persecutions.\n\nThe influence of classical Aramaic varieties — Syriac on Christian varieties and Targumic on Jewish communities — gives a dual heritage that further distinguishes language by faith. Many of the Jewish speakers of NENA varieties, the Kurdish Jews, now live in Israel, where Neo-Aramaic is endangered by the dominance of Modern Hebrew. Many Christian NENA speakers, who usually are Assyrian, are in diaspora in North America, Europe, Australia, the Caucasus and elsewhere, although indigenous communities remain in northern Iraq, south east Turkey, north east Syria and north west Iran, an area roughly comprising what had been ancient Assyria.\n\nBlench (2006) considers Eastern Neo-Aramaic, including Neo-Mandaic, to be a single language, contrasting with Central (Turoyo) and Western Neo-Aramaic. SIL Ethnologue assigns ISO codes to twelve NENA varieties, two of them extinct:\n\n"}
{"id": "26656098", "url": "https://en.wikipedia.org/wiki?curid=26656098", "title": "PSTN network topology", "text": "PSTN network topology\n\nA PSTN network topology is the switching network topology of a telephone network connected to the public switched telephone network (PSTN).\n\nIn the United States and Canada, the Bell System network topology was the switching system hierarchy implemented and operated from the late 1940s to the 1980s for the purpose of integrating the diverse array of local telephone companies and telephone numbering plans to achieve nationwide Direct Distance Dialing (DDD) by telephone subscribers. It was the precursor of the world-wide interconnected public switched telephone network (PSTN).\n\nThe ideas originated in the Bell System in the United States, but were soon adopted by other countries where telephone operators were facing similar issues, even when service smaller geographic areas. The system in the United Kingdom implemented by the General Post Office resulted in fewer switching levels than the Bell System.\n\nIn the late 1940s the Bell System devised plans to consolidate the various incompatible local telephone numbering plans of its constituent service areas into a unified network, that later became known as the North American Numbering Plan (NANP). This was a prerequisite to achieve Direct Distance Dialing (DDD) by customers, first implemented in Englewood, New Jersey in 1951. In addition to devising a unified numbering plan, AT&T reorganized the nationwide system that was spearheaded by AT&T Long Lines of local telephone exchanges and central offices into a hierarchical network containing five levels, called \"classes\", of switching systems.\n\nAs long distance calling was originally established, it could take up to seven minutes to complete a connection to another major city, and small points would need to have \"call back\" appointments made with long lead times for circuits to be reserved.\n\nThe newly devised hierarchy was maintained into the early 1980s, when technological advances and business models rendered it increasingly obsolete, but the hierarchical features live on in terms, such as Class 4 and Class 5 telephone switch, referring to tandem and end-office switches, respectively. The PSTN in the United States was essentially restructured with the 1984 divestiture of AT&T. The old Long Lines network remained with AT&T, but its internal routing became non-hierarchical with the introduction of advanced computer-controlled switching. Each major long distance carrier can have its own internal routing policies, though they generally start with the same principles and even components.\n\nWith Bell System divestiture, the network in the US was divided into local access and transport areas (LATAs). Calls within LATAs were carried by Local Exchange Carriers (LECs), while calls between them were carried by interexchange carriers (IXCs). LATAs generally have one or more tandem switches which interconnect end office switches.\n\nWhile the following discussion refers to AT&T and (principally) to the United States, it is important to remember that until 1975, AT&T controlled Bell Canada and thus influenced corporate decisions north of the border. Bell Canada provided local operations in most of Ontario and Quebec, and both in its capacity as the largest telecommunications carrier in Canada and because of its historic operations in the Atlantic and Prairie provinces, dominated decisions over long distance practices. Canadian authorities agreed that integration of Canadian long distance services into a trans-national network was valuable to both countries, so that U.S. and Canadian services were integrated for networking capabilities at an early stage into what eventually became the foundation for the North American Numbering Plan area.\n\nBy the mid-1920s, a revised manual system where \"local\" toll operators connected tandem routes (a process formally called Combined Line and Recording) as needed to complete telephone calls, reduced the process to an average of two minutes, but still meant that some complex routing might interconnect as many as sixteen points. As long distance services grew in the Contiguous Continental US (48 states) and Canada, the amount of overhead equipment and people required to determine and establish Rates and Routes became excessive. As technology improved, network design included consideration of more automated and defined procedures. Thus, beginning with a switch installed in Philadelphia PA in 1943, AT&T began to automate the system, and establish a new switch hierarchy, which lasted until the breakup of AT&T in the 1980s.\n\nThe underlying principle of the five-level hierarchy was to provide economies of scale by establishing direct connections between centralized call \"collection points\" (essentially the Class 4 offices) where economically feasible, and to provide additional concentration points (Class 1 through 3) to handle overflow traffic that could not be handled directly, or to handle traffic to locations which were less likely to be dialed from a given point - usually longer distances and/or smaller locations in other parts of the North American dialing plan. The North American plan differed from those of other continents in the existence of three concentration levels of hierarchy for domestic (here defined as including all those points \"within\" the dialing plan) calls, a need not required where the larger geographic area was broken into several national plan jurisdictions. However, it is important to note that this was not a strict hierarchy of absolute levels. If enough call traffic existed between geographic areas, for example, a Class 4 office could have direct trunk connections not only to a Class 3 office, but to a Class 2 or Class 1 office, and vice versa. For example, the Class 2 switch in Toronto (TOROON0101T2) had connections not only to the Class 1 switch in Montréal (MTRLPQ0201T1), but to the Class 1 switch in White Plains (WHPLNY0201T1), one of the Class 2 switches in New York City (NYCMNYAA02T2) and a Class 3 switch in Buffalo (BFLONYFR04T3). Network engineers re-worked the system as necessary to balance off call completion percentages with budgetary limitations. In fact, minor changes were made almost every month.\n\nInitially excluded from the development of the North American network were locations that eventually would become part of the North American Numbering Plan Area - Alaska, Hawaii, some other United States possessions, various outlying Northern and rural portions of Canada, and much of the Caribbean. These areas were handled as International Calls until more advanced computer hardware and software allowed them to be included in the automated, integrated systems in later decades. After the spread of stored program control switching, many services of Class 1 through 3 could be delegated to newer switches in the class 4 and 5 offices, and that portion of the network became obsolete, although it was partially replaced by the establishment of multiple long distance carrier networks, connected to the local networks through their points of presence.\n\nThe class 1 office was the Regional Center (RC). Regional centers served three purposes in the North American toll network (a) their connections were the \"last resort\" for final setup of calls when routes between centers lower in the hierarchy were not available (b) they were initially staffed by engineers who had the authority to block portions of the network within the region in case of emergencies or network congestion - although these functions were transferred after 1962 to the Network Control/Operations Center and the distributed Network Management Centers (see below) (c) they provided collection points (until the development of more advanced computer hardware and software for toll operators) for circuits that would be passed along to one of the international overseas gateways (which operated as special centers outside the formal North American hierarchy). The regional centers updated each other on the status of every circuit in the network. These centers would then reroute traffic around the trouble spots and keep each informed at all times. There were twelve Regional Centers in North America, ten in the United States, nine of which were operated by AT&T (White Plains, NY, Wayne, PA, Pittsburgh, PA, Norway, IL [a rural crossroads west of Chicago at the intersection of US highway 52 and IL highway 71 - an underground office built with hardened construction to withstand nuclear attack], Conyers, GA in Rockdale County, St Louis, MO, Dallas, TX, Denver, CO, and Sacramento, CA), one by GTE (San Bernardino, CA). Two centres in Canada were operated on behalf of the Trans-Canada Telephone System, one by Bell Canada (Montréal, PQ), and one by Saskatchewan Telephone, (Regina, SK).\n\nFor control and oversight of the entire network hierarchy, AT&T established a Network Control Center in New York City in 1962, renamed the Network Operations Center and relocated to Bedminster, NJ in 1977. Engineering supervision was also centralized in eight regional Network Management Centers. The realignment and dispersion of functions were done, in part, to ensure maximum network integrity in the event of a national emergency, a major concern in that era. The basic structure of this unit, although significantly altered since the AT&T divestiture in the 1980s, still exists as the Global Operations Center, with domestic regional centers in Colorado and Georgia.\n\nThe class 2 office was the Sectional Center (SC). The sectional center typically connected major toll centers within one or two states or provinces, or a significant portion of a large state or province, to provide interstate or interprovincial connections for long-distance calls. At various times, there were between 50 and 75 active class two offices in the network.\n\nThe class 3 office was the Primary Center (PC). Calls being made beyond the limits of a small geographical area where circuits are not connected directly between class 4 toll offices would be passed from the toll center to the primary center. These locations use high usage trunks to complete connection between toll centers. The primary center never served dial tone to the user. The number of primary centers in the network fluctuated from time to time, ranging between 150 and 230.\n\nThe class 4 office is the Toll Center (TC), Toll Point (TP), or Intermediate Point (IP). A call going between two end offices not directly connected, or whose direct trunks are busy, is routed through the toll center. The toll center is also used to connect to the long-distance network for calls where added costs are incurred, such as operator handled services. This toll center may also be called the tandem office because calls have to pass through this location to get to another part of the network. Toll centers might have been operated either as interstate facilities, under the operation of AT&T Long Lines (GTE in a few cases), or by local telephone companies, handling long distance traffic to points within a particular operating company territory. Class 4 offices continue to exist, although with considerable changes, as they handle local exchange company interconnections, locally charged or long distance rated, or provide facilities for connection to long distance company points of presence.\n\nThe class 5 office is the local exchange or end office. It delivers dial tone to the customer. The end office, also called a branch exchange, is the closest connection to the end customer. Over 19,000 end offices in the United States alone provide basic dial tone services.\n\nIn modern times only the terms Class 4 and Class 5 are much used, as any tandem office is referred to as a Class 4. This change was prompted in great part by changes in the power of switches and the relative cost of transmission, both of which tended to flatten the switch hierarchy. The breakup of the Bell System, and the need for each of the surviving regional operating companies to handle long distance interconnections, also promoted the inclusion of inter-regional and international processing through larger Class 4 offices.\n\nThe special requirements of placing calls to locations outside main Canadian/United States points meant that these calls were handled by special operators in locations where connections could be monitored to other countries. The technology to automate these connections through \"regular\" operator traffic positions began to develop in the 1960s (see Bell Laboratories Record 42:7, July–August 1964). As the decade of the 1970s progressed, North American customers who were served by electronic offices began to be able to directly dial to an increasing number of international points, a service known as IDDD (International Direct Distance Dialing), (service between ESS offices in New York and London began on March 1, 1970). However, since points could not be connected until equipment in both countries was converted to electronic switching, implementation to many locations took some time, and while the majority of calls began to be connected via automated systems by the 1990s - after the termination of the five-level hierarchy - the majority of countries were still connected via manual intervention until the beginning of the 21st century.\n\nPlease note that the currently attached diagram of switch hierarchy is incorrect, as it identifies Class 1 points with International switching. International connections were located in places generally close to cable, later satellite, termination locations, and were not directly related to Class 1 switches. Major international connection points were located in Oakland, California; Miami, Florida; and New York, New York, with a number of secondary international operator toll points. Only after the rapid expansion of ESS terminal offices did operator handling of international calls begin to be off-loaded into the domestic network structure, as international calling services began to be customer dialable, ca. the mid-1980s. This in part paralleled the demise of the five-level hierarchy, so identification of international switches and class one offices is incorrect.\n\nThe forerunner of British Telecom, the General Post Office, also organized its intercity trunk network along similar hierarchical lines to that of North America. However, because of the significantly smaller geographic area involved, fewer levels of connection were required, and no formal numbering of class offices was made.\n\nThere were a few special exceptions to the following description, notably those involving Northern Ireland, some of the Channel Dependencies, and the few locations in England which were served by non-GPO companies, such as Hull (KCOM Group) and Portsmouth. \n\nIn the early days of manual exchanges, outlying areas (eventually called dependent exchanges) were connected through progressively larger locations (eventually called group switching centres) into one of the main cities - Birmingham, Edinburgh, Glasgow, Liverpool, London, and Manchester. As automation began to be established in the network, this was refined into a system of approximately fifty tandem locations for Group Switching Centres, with an additional layer of perhaps a dozen Wide Area Tandems to provide for busy periods, emergency routing, etc. There were also some additional Local Tandems to handle traffic in the London Metropolitan Area without involving the GSCs, although this was a later development, as it required common control signalling for identification.\n\nThe dialing codes used by trunk operators to connect calls were originally assigned and established to ensure speed with pulse dialing equipment. With the advent of subscriber dialed calls, numbering patterns were reassigned to provide for mnemonic methods of improving customer performance. Subscriber trunk dialling (STD) codes all began with 0. The largest cities, which had seven digit local numbers, were allocated special codes - London, 01; Birmingham, 021; etc. Smaller towns were typically allocated a code based on the first letters of their name, translated into digits on the telephone dial. For example, OXford translated into 09 on the British phone dial, so the original STD code for Oxford was 0096. However, because of subscriber dialing errors, there was an early decision to eliminate codes that began with \"00\" and Oxford soon became 0865, the sequence \"86\" designating the first two letter of \"university\".\n\nSome of the smallest towns connected to the trunk network only through nearby switches. In those cases, STD codes were composed of combination of the code for the nearby switch, plus some additional digits that were unused in that nearby switch, but which served two purposes (1) to identify the end location, and allow the nearby switch to complete the call (2) to \"pad out\" the overall length of the dialing string, since a small town might only have a three-digit telephone number, and allow the network to move to a more-standard number length.\n\nAs step offices became rarer, Subscriber Trunk Dialing Codes no longer followed the original rules, and were significantly revised in the mid-1990s, with further changes as wider use of mobile phones and non-BT competition came into the UK market. There are now some 70000 local exchange codes in use in the UK. The largest trunk carrier, British Telecom, connects the local network through some 60 transit (tandem) switches.\n\nThe early history of the telecommunications switching network in France is, unusually for this country, one of decentralized development. Early telephone exchanges were installed by local communities, often by private companies, and only later taken over by the French government. As a result, by 1930, France was served by almost 25,000 local exchanges, but almost half of these had fewer than five subscribers. Additionally, telephones were not considered important for residential customers (nor for small businesses), so France had a low penetration rate of telephone subscribers.\n\nUnder these conditions, early network development revolved around two major distinctions, \"Paris\" and \"not Paris.\" Within metropolitan Paris, automated step switches appeared, with a level of tandem switching, before World War II. In the rest of the country, automation was confined to major cities, with a high level of manual intervention.\n\nThe French telephone system was heavily damaged in World War II, so that by the end of the War only about 140 automatic exchanges (mostly in Paris and its \"banlieues\") and 228 manual exchanges were fully operational. Repair of much of the network had been deferred during the war due to lack of parts, as well as co-opting of technical personnel for German military needs.\n\nRecovery was rapid after the war, and the extensive damage in some ways helped the modernization of the system as new technology was introduced. The DGT (Direction Générale des Télécommunications) introduced automated operator dialing of long distance connections, generally using the INSEE codes as \"area codes\" for the various departments - with special handling for Paris. These codes subsequently became public as customer dialing of long distance calls began to be introduced in the late 1960s and early 1970s.\n\nThe network had a minimal hierarchy, with most connections routed into a central tandem in each department, and from there to Paris. As greater installation of private telephones, for both small business and private residences, increased in the 1970s, direct connections among the tandems in adjacent regions were installed, and a three-level tier of switches, local, tandem, and regional interconnection was implemented, with final routing through Paris. Also, during the 1970s and 1980s, the smaller rural switches were replaced and combined with nearby automated offices, and a closed numbering scheme was adopted for dialing consistency.\n\nIn common with most countries, the development of technology allowed for different networking, and the maintenance of a formal hierarchy disappeared into a distributed network. By the mid-1990s, a revised structure had appeared, reflected by the replacement of the old departmental area codes by the assignment of regional codes and a major renumbering scheme for strategic planning, privatization, and deregulation under the auspices of ART, the (Regulatory Authority for Telecommunications - since 2005, ARCEP, as responsibility for postal services was added). After 1996, the country prepared for complete deregulation of the telephone network.\n\nThus, the local exchanges () are connected somewhat differently by various carriers. However, the largest of these, based upon the (partially) privatised former government network, is a two-level long distance hierarchy, based on 80 CTS (centre de transit secondaire) and 8 CTP (centre de transit primaire) locations. In addition, there are 12 CTI (centre de transit internationaux) for connections to areas which are not integrated into the French telephone network [note that some overseas locations are considered \"domestic\" for telecommunications purposes].\n"}
{"id": "26519807", "url": "https://en.wikipedia.org/wiki?curid=26519807", "title": "Paraguayan Spanish", "text": "Paraguayan Spanish\n\nParaguayan Spanish () is a version of the Spanish language spoken in Paraguay. In addition, it influences the speech of the Argentine provinces of Misiones, Corrientes, Formosa, and, to a lesser extent, Chaco. \n\nThe Guarani language is co-official with Spanish in Paraguay, and most Paraguayans speak both languages. Guaraní is the home language of more than half the population of Paraguay, with higher proportions of its use in rural areas, and those who speak Spanish at home slightly in the majority in the cities.\n\nThe Swedish linguist Bertil Malmberg visited Paraguay in 1946 and observed several features of Spanish pronunciation that he attributed to Guaraní influence. The Guaraní origin of many of these features, however, has been questioned by other researchers, who document them in dialects not in contact with Guaraní.\n\nThe unique features of Paraguayan Spanish developed in part due to Paraguay's early isolation; for example, José Gaspar Rodríguez de Francia, the country's president until 1840, sealed Paraguay's borders. Other experiences with geographic, political, and economic isolation relative to its neighbours allowed Spanish spoken in Paraguay to develop its own unique characteristics, even apart from the wide-ranging influence of Guarani.\n\nParaguayan Spanish shares many similarities with Rioplatense Spanish (that is, the variety spoken in Argentina) such as the use of the voseo and various words and phrases.\n\n\n"}
{"id": "22877925", "url": "https://en.wikipedia.org/wiki?curid=22877925", "title": "Phrop", "text": "Phrop\n\nA phrop is an attempted neologism used to indicate a polite statement used in social contexts where the true meaning is the opposite of what is expressed. An example is the parting comment \"We must have lunch sometime\", meaning \"We don't particularly want to meet again\". The term was coined by mountaineer Sir Arnold Lunn. It has not entered common use.\n\n\n"}
{"id": "2836384", "url": "https://en.wikipedia.org/wiki?curid=2836384", "title": "Providence Island Sign Language", "text": "Providence Island Sign Language\n\nProvidence Island Sign Language (also known as Provisle or \"Providencia Sign Language\") is a village sign language of the small island community of Providence Island in the Western Caribbean, off the coast of Nicaragua but belonging to Colombia. The island is about and the total population is about 5000, of which an unusual proportion are deaf (5 in 1,000).\n\nIt is believed that the sign language emerged in the late 19th or early 20th century. Brief sociological studies have suggested that deaf people on the island are regarded as inferior in mental ability; hearing people do not discuss complex ideas with them, and they hold a marginalized social position. Perhaps consequently, PISL is rather simplistic in comparison to other sign languages. Another possibility for the state of the language is that few deaf people communicate directly, meaning that almost all signing is mediated by the hearing population.\n\n\n"}
{"id": "56271956", "url": "https://en.wikipedia.org/wiki?curid=56271956", "title": "Serengeti-Dorobo language", "text": "Serengeti-Dorobo language\n\nSerengeti-Dorobo (a nonce name) is an obscure \"Dorobo\" language, a few words of which were recorded in the late 19th century by Oscar Baumann. From the little data available, the language is not obviously related to any other. It is not the only \"Dorobo\" language formerly spoken in the Serengeti.\n\nA couple paragraphs are recorded, but without word-by-word translation. Numerals are as follows.\n\n"}
{"id": "16052460", "url": "https://en.wikipedia.org/wiki?curid=16052460", "title": "Social information processing (theory)", "text": "Social information processing (theory)\n\nSocial information processing theory, also known as SIP, is an interpersonal communication theory and media studies theory developed in 1992 by Joseph Walther. Social information processing theory explains online interpersonal communication without nonverbal cues and how people develop and manage relationships in a computer-mediated environment. While the term has traditionally referred to those communications that occur via computer-mediated formats (e.g., instant messages, e-mails, chat rooms), it has also been applied to other forms of text-based interaction such as text messaging. In computer-mediated environments, interpersonal relationship development may require more time to develop than traditional face-to-face (FtF) relationships. Social information processing theory argues that online interpersonal relationships may demonstrate the same relational dimensions and qualities as FtF relationships. These online relationships may help facilitate interactions that would not have occurred face-to-face due to factors such as geography and intergroup anxiety.\n\nBeginning in the 1990s, after the advent of the Internet and the World Wide Web, interest grew in studying how the Internet impacted the ways people communicate with each other. Joseph Walther, a communication and media theorist, said that computer-mediated communication (CMC) users can adapt to this restricted medium and use it effectively to develop close relationships. Walther understood that to describe the new nature of online communication required a new theory. Social information processing theory focuses on the social processes that occur when two or more people are engaged in communication, similar to theories such as social presence theory, social penetration theory, and uncertainty reduction theory. What makes SIP different from these theories is its distinct focus on communication mediated solely by information and communications technologies. While other media theories exist, such as media richness theory and uses and gratifications theory, SIP specifically focuses on \"relationships\" entirely mediated online.\n\nUnlike some theories that are rooted in other theoretical perspectives from various fields of study, SIP was conceptualized, in part, by addressing the shortcomings of other theories that addressed communication mediums. These theories are termed cues filtered-out theories. Cues filtered-out theories refer to theories that address the lack of nonverbal cues as being detrimental to online relationship development. Walther's research critiqued past methodological and conceptual problems with theoretical thinking. He subsequently worked toward establishing an interpersonal communication theory that more accurately reflected the intersection among communication, online environments, the self and relationships. Two of those theoretical perspective that influenced Walther's theory are social presence theory and media richness theory. Walther believes that both SPS and MRT suffer from a limited understanding of relational life online. He argues that if interactants communicate enough times and with sufficient breadth and depth, nonverbal communication does not remain paramount in relationship development.\n\nOne of the most important aspects of online interaction is the presentation of Self. Tory Higgins (1987) described three main forms of self: actual self, ideal self, and ought self. \"Actual self\" is the set of qualities and characteristics that person actually possesses, the \"ideal self\" contains the attributes that a person hopes to someday achieve, and the \"ought self\" contains the attributes that a person believes he/she should possess.\n\nCarl Rogers (1951) posited that there was another form of self, one that is not concerned with the future like the ideal and ought self. He called it the true self: a present form of self that exists psychologically and is not always fully expressed within social settings like the actual self.\n\nBargh, McKenna, and Fitzsimons (2002) conducted an experiment to test how the actual self and true self are expressed by people in face-to-face and computer-mediated interactions, and found that the actual self was more accessible following an initial face-to-face interaction, while the true self was more accessible following an initial interaction online. From the results of their study, the researchers concluded that people tend to like each other better when they meet online instead of meeting face-to-face.\n\nSocial information processing researchers like Joseph Walther are intrigued by how identities are managed online and how relationships are able to move from one of superficiality to one of intimacy. Three assumptions related to the SIP theory are listed below:\nThe first assumption rests on the premise that computer-mediated communication is a unique opportunity to build interpersonal relationships with others. The CMC systems are vast and almost always text based. It has been identified as \"an organic setting\" and it can be both synchronous and asynchronous. CMC is clearly different than face-to-face communication, but it offers an unparalleled opportunity to meet someone whom you would never meet FtF. Moreover, relationships established via CMC systems also prompt emotions and feelings we find in all relationships. Finally, since CMC systems are available around the globe, the uniqueness of being able to cultivate online relationships with someone who is very far away cannot be ignored.\nThe second assumption alludes that impression management is essential in online relationships and participants undertake efforts to ensure particular impressions. Researchers have found that social networking sites (SNS) like Facebook are filled with people who wish to provide a number of different self-presentations to others. Thus, how others present and manage themselves online remains important on various SNS and on numerous CMC system platforms.\nThe third assumption of SIP states that different rates of information exchange and information accrual affect relationship development. Social information processing theory is suggesting that although the messages are verbal, communicators \"adapt\" to the restrictions of online medium, look for cues in the messages from others, and modify their language to the extent that the words compensate for the lack of nonverbal cues.This third assumption reflects Walther's contention that given sufficient time and accrual of messages, online relationships have the same capacity to become intimate as those that are established face to face. In addition, online comments are usually delivered rather quickly and efficiently. Further, these messages \"build up\" over time and provide online participants sufficient information from which to begin and develop interpersonal relationships.\n\nSocial information processing theory describes computer-mediated communication as a process including three phases: impersonal, to interpersonal, and finally to hyperpersonal.\n\nIn the \"impersonal phase\", due to the lack of nonverbal cues, CMC is believed to be more task-oriented than traditional face-to-face communication. Since the content is not influenced by social and emotional influence, it can avoid overly personal interpersonal interaction, promote rationality by providing essential discipline, facilitate the efficiency of group work through getting rid of peer pressure and hierarchy, and ultimately, create a more \"democratic\" atmosphere within organizations.\n\nIn the \"interpersonal phase\", the nonverbal cues are lean and as the communication time increases, the exchange of social information increases accordingly. The anticipation of future communication may make communicators to look for more information about the other. This mechanism leads to similar immediacy, similarity, composure, and receptivity as in FtF communication.\n\nIn the \"hyperpersonal phase\", The sender uses the process of selective self-presentation. People who meet online have a better opportunity to make a favorable impression on the other. This is because the communicators can decide which information they would like to share about themselves by controlling their self-presentations online, giving them the power to disclose only their good traits. SIP has, at its core, impression management. Communication Scholars define impression management as either a strategic or unconscious effort to influence another's perception. Much of the earlier research on impression management focused on FtF communication and the nuances with meeting someone. A person's self-image was viewed as important in relational development. Later applications of impression management were undertaken once online communication began.\n\nSelective-Presentation is not as likely to occur in FtF communication due to the ability to observe all the obvious traits in person. The receivers may idealize the senders based on making attributions from available paralingual cues found in the message. This process is enhanced with asynchronous exchanges, letting both sender and receiver have ample time to consider the messages sent and received. In the absence of FtF contextual cues, the likelihood of over-attributing given information of the sender is increased, often creating an idealized image of the message sender. This is also known as social-identity-deindividuation (or SIDE). For example, over-attribution is also found in online dating. While reading a perspective date's profile, the reader is likely to see themselves as similar to one another and therefore become more interested than they originally would have been. Finally, the feedback process addresses the reciprocal influence of the senders and the receivers. They develop impressions and intimacy as a result of their interaction.\n\nThe hyperpersonal perspective is more than saying that an online relationship is intimate. Walther, in a number of different scholarly venues, articulated its complexity and some other scholars elucidate the four components he studied: senders; receivers; channel; and feedback. These four also constitute many of the models of communication.\nAccording to Walther, senders have the ability to present themselves in highly strategic and highly positive ways. This self-presentation is controlled and it serves as a foundation for how CMC users get to know one another. The fundamental underpinning of this component of the hyperpersonal perspective is affinity seeking. That is, senders provide information online that prompts affinity in others.\nAt the core of this component in the hyperpersonal perspective is attribution. Attributions are those evaluations and judgements we make based on the actions or behaviors of others. The receiver tends to attribute and, according to the theory, the receiver may \"overattribute\", which means that a receiver is likely to think that a sender has more similarities than differences. Further, a receiver may experience an overreliance on the minimal cues available online and forget that the relationship he or she has with a sender is based on words.\nThe asynchronous nature of CMC allows online participants to think about texts or emails before sending them. Further, prior to sending messages, you can rewrite them for clarity, sense, and relevancy. Online asynchronous experiences allow for \"optimal and desirable\" communication, ensuring that the messages are of high quality. Walther contends that the more relational the affection or more desirable the other communicator is, the more editing in message composition.\nWalther interprets feedback as behavioral confirmation, which is a \"reciprocal influence that partners exert\". In communication theory, we refer to this as self-fulfilling prophecy. This prophecy essentially is a tendency for an individual's expectation of a target person to evoke a response from that person which, in turn, reaffirms the original prediction. Walther's hyperpersonal perspective acknowledges a feedback system this way: \"When a receiver gets a selectively self-presented message and idealizes its source, that individual may respond in a way that reciprocates and reinforces the partially modified personae, reproducing, enhancing, and potentially exaggerating them\". Because cues in an online environment are limited, the feedback that does occur is often exaggerated or magnified.\n\nThe four components—sender, receiver, channel, and feedback—suggest that the hyperpersonal perspective is a process which is ongoing and dynamic. Walther concludes that SIP is a \"process\" theory because both information and interpersonal meaning is accumulated over time, providing online partners an opportunity to establish a relationship.\n\nTwo researches were carried out by Walther and his colleagues from 1992 to 1994, focusing on the channel management of the computer-mediated communication. Summary of the two experiments are as followed.\n\nAround the time in 1992 when Walther produced and published the Social Information Processing theory, he and his colleagues conducted an experiment, examining the effects of time and communication channel—asynchronous computer conferencing versus face-to-face meetings—on relational communication in groups. Prior research on the relational aspects of computer-mediated communication has suggested strong depersonalizing effects of the medium due to the absence of nonverbal cues. Past research is criticized for failing to incorporate temporal and developmental perspectives on information processing and relational development. In this study, data were collected from 96 subjects assigned to computer conferencing or face-to-face zero-history groups of 3, who completed three tasks over several weeks' time. Results showed that computer-mediated groups increased in several relational dimensions to more positive levels and that these subsequent levels approximated those of face-to-face groups. Boundaries on the predominant theories of computer-mediated communication are recommended, and principles from uncertainty reduction and social penetration are discussed.\n\nLater, Walther and his colleagues did follow-up research. Previous research on the interpersonal tone of computer-mediated communication shows different effects using longitudinal computer-mediated groups than are found in research using one-shot groups, even before the developmental aspects associated with time can accrue. One factor distinguishing these approaches is the anticipation of future interaction experienced by longitudinal groups. This research reports an experiment assessing the relative effects of anticipated future interaction and different communication media (computer-mediated versus face-to-face communication) on the communication of relational intimacy and composure. Asynchronous and synchronous computer conferencing and face-to-face groups were examined. Results show that the assignment of long-term versus short-term partnerships has a larger impact on anticipated future interaction reported by computer-mediated, rather than face-to-face, partners. Evidence also shows that anticipation is a more potent predictor of several relational communication dimensions than is communication condition. Implications for theory and practice are identified.\n\nSeveral theorists have explored the differences in intimacy developed through CMC versus face-to-face communication. Walther is convinced that the length of time that CMC users have to send their messages is the key factor that determines whether their messages can achieve the same level of intimacy that others develop face-to-face. Over an extended period the issue is not the amount of social information that can be conveyed online; rather, it is the rate at which the information builds up. Any message spoken in person will take at least four times longer to communicate through CMC. When comparing 10 minutes of face-to-face conversation with 40 minutes of CMC, there was no difference in partner affinity between the two modes. Anticipated future interaction is a way of extending physiological time, which gives the likelihood of future interaction and motivates CMC users to develop a relationship. Relational messages provide interactants with information about the nature of the relationship, the interactants' status in the relationship, and the social context within which the interaction occurs.\n\nThe \"shadow of the future\" motivates people to encounter others on a more personal level. A chronemic cue is a type of nonverbal cue not filtered out of CMC and indicates how one perceives, uses, or responds to issues of time. Unlike tone of voice, interpersonal distance, or gestures, times is the one nonverbal cue that cannot be filtered out of CMC. For example, a person can send a text message at a certain time of the day and when a response is received he or she can gauge how much time elapsed between messages. Social information processing theory says that a prompt reply signals deference and liking in a new relationship or business context. A delayed response may indicate receptivity and more liking in an intimate relationship; partners who are comfortable with each other do not need to reply as quickly.\n\nMeanwhile, Walther, with his colleagues, conducted another investigation which examined how computer-mediated communication (CMC) partners exchange personal information in initial interactions, focusing on the effects of communication channels on self-disclosure, question-asking, and uncertainty reduction. Unacquainted individuals (N = 158) met either face-to-face or via CMC. Computer-mediated interactants exhibited a greater proportion of more direct and intimate uncertainty reduction behaviors than unmediated participants did, and demonstrated significantly greater gains in attributional confidence over the course of the conversations. The use of direct strategies by mediated interactants resulted in judgments of greater conversational effectiveness by partners.\n\nOthers, such as Dr. Kevin B. Wright, examined the difference in developing and maintaining relationships both exclusively and primarily online. Specifically, Wright has found the effectiveness of \"openness and positivity\" in online communication versus avoidance in offline relationships.\n\nWalther and Parks noticed that people often meet offline after having first met online. Sometimes these experiences are positive, and other times negative. They are dissatisfied with existing theories' ability to explain these phenomena. To fill in the theoretical gap, Walther and Parks adopt the original concept of warranting presented by Stone, describing connections between one's self and self-presentation as a continuum rather than a binary, moderated by anonymity. They suggested that the potential for anonymity resulted in the potential for a discrepancy along this continuum. The greater this potential discrepancy, the more compelling it is for observers to be skeptical of information provided by the individual about the self. Warrants, as described by Walther and Parks, are perceived reliable cues that observers use to gauge how one's true identity matches that which is presented online.\n\nAccording to Walther, \"Warranting pertains to the perceived legitimacy and validity of information about another person that one may receive or observe online.\" Over the years, individuals have come to learn a lot about each other through online discussion groups or online role-playing games. Many have also started to gain an understanding of another person through \"personal homepages and other forms of online interaction and self-presentation, including online dating sites.\" However, with the introduction of many online social media sites such as Facebook, Twitter, and LinkedIn, there are many opportunities for people to interact using CMC. As such, there are many factors – photographs, videos, and the ability to build your own profile – that set social media apart from the text-only CMC that Walther originally studied. For example, if a person describes him or herself as a quiet, reserved person but friends add pictures of him or her out at a bar with a large group of people. These two ideas contradict each other. How the person processes this contradiction is the main idea of Walther's warranting theory.\n\n\"If the information we're reading has warranting value, then it gives us reason to believe it is true.\" This value is defined as the extent to which the cue is perceived to be unaltered by the target. Warrants that are very difficult to manipulate by the user are considered high in warranting value. They are more likely to be accepted as truth. An example of this is information added to your profile by others because the owner cannot easily change it (Others-generated warrants). Partial warranting is another example. It is information that, though provided by the user, contains easily verifiable facts. The numerical information, such as height, weight, age, or address constitutes as partial warranting, as these figures are easily checked and provide little room for gray area. Low warrant information is easily manipulated and therefore less believable. It is much more questionable in terms of accuracy (Walther & Parks, 2002). An example of this is information self-reported on personal profile pages. These can range from interests and hobbies, to other personal details (also known as constraining information, which is not easily verified but restricts identity).\n\nWalther, Van Der Heide, Kim, Westerman, and Tong (2008), wanted to explore if the attractiveness of friends, as well as what these friends said on an individual's profile, had an effect on social attraction. They investigated the topic by assigning random participants to view fake Facebook pages.\n\nThis experiment had two phases. In the first phase, researchers displayed two comments from friends of a profile with neutral content. The small profile pictures of commenting friends were either attractive or unattractive, and the comments suggested either socially desirable or socially undesirable behaviors. It was found that social attractiveness was positively correlated with the physical attractiveness of commenting friends (Walther et al., 2008). This indicates that the simple observable presence of others in one's social network may be enough to make social judgments. In the second phase, researchers tested the effects of self-generated information against information generated by others. Walther et al. (2009) compared subjects reactions to fake Facebook profiles and their judgments of extroversion and introversion. Profiles contained either self-generated information suggesting the profile owner was introverted or extroverted, and others-generated statements suggesting the owner was introverted or extroverted. Information suggesting introversion was considered negative while information suggestion extroversion was considered to be positive. Walther et al. (2009) found that while others-generated statements do indeed have an effect on observer judgments, the effect did not override self-generated information or negativity effects.\n\nHis experiments confirmed that people value high warrant information. It found that credibility levels and attractiveness were swayed by comments made on the profile by people other than its owner. It also confirmed his beliefs by comparing high and low warrant information and finding that friends' remarks were valued higher than the owner's claims in regards to physical attractiveness and outgoingness. These studies have found that, unlike email, communication comes from both the owner and other users of social media and viewers do not give these two opinions equal value.\n\nSynchronous communication refers to interactions that occur in real-time, where participants in a conversation are actively communicating while online at the same time. Examples of online synchronous communication would be text messages and other instant messaging platforms, as well as internet telephony, such as FaceTime and Skype. Asynchronous communication, on the other hand, occurs when conversation participants are not online at the same time, and messages are left for the other to receive. Examples of online asynchronous communication include voicemails, emails, blogs, and social media sites.\n\nA 2011 study in Finland suggested that it is synchronicity, not online social use in general, that separates generations in the Digital Age. The study collected data from a survey of over 600 people, ranging from age 15–65, and categorized its participants by 3 distinct generations: Digital Immigrants, or DI (born before 1989); the First Digital Generation, and 1DG (born between 1980–1989, who were exposed to early digital technologies at a relatively young age), and the Second Digital Generation, or 2DG (born after 1990, who mostly grew up with digital technologies). A survey revealed multiple differences in online communication methods between 1DG and 2DG. First, 75% of 1DG reported using online blogs (an asynchronous method), while 59% of 2DG reported using it. Also, 48% of 1DG reported using instant messaging (a synchronous method), while 77% of 2DG reported using it. Of the other 3 online methods tested (internet calls, social networking sites, and discussion forums), 2DG had the highest usage rate of the three generations. DI had significantly lower results for each method except internet calls, which was within 12% across all 3 generations. This data reveals that everyone is using the internet for social purposes, but that younger generations of the Digital Age prefer synchronous communication methods, while older generations tend to use asynchronous communication more often.\n\nBurgoon, Chen, and Twitchell (2010) also conducted an experiment to test how synchronicity affects online interactions. They had their participants conduct team-oriented tasks, and used different methods of communication to observe how people perceived their fellow team members. They proposed that synchronicity affects interactivity, and the results of the experiment supported their hypothesis. They observed that synchronous forms of communications allow for increased mental and behavioral engagement between parties, allowing participants to feel a stronger sense of connection, presence, identification, and social awareness in the conversation.\n\nSocial information processing theory has been used to study online relationships in a variety of contexts. Since the late 1990s, the Internet has increased the amount of totally-mediated interactions making the possibility of developing and sustaining an entire relationships online more possible.\n\nSome early studies looked at e-mail discussion groups while more contemporary research has found a great deal attention placed on social media networks such as Facebook and online dating sites. These situations are significant to observing SIP and the hyperpersonal perspective in action.\n\nIn relation to romantic relationships, several studies and subsequent theories have stemmed from SIP, combining it with theories such as Social Penetration Theory (SPT) or Relational Dialectics to further examine how modern day relationships are formed and sustained. Scholars Nicole Ellison, Rebecca Heino, and Jennifer Gibbs conducted such a study and formed their own theory in their article Managing Impressions Online: Self-Presentation Processes in the Online Dating Environment which utilized both SIP and SPT to examine the development of modern relationships from online acquaintances to intimate partners.\n\nScholars James Farrer and Jeff Gavin from Sophia University in Japan examined the online dating process and dating relationship development to test the SIP theory. This study examines the experiences of past and present members of a popular Japanese online dating site in order to explore the extent to which Western-based theories of computer-mediated communication and the development of online relationships are relevant to the Japanese online dating experience. Specifically, their study examines whether social information processing theory is applicable to Japanese online dating interactions, and how and to what extent Japanese daters overcome the limitations of CMC through the use of contextual and other cues. Thirty-six current members and 27 former members of Match.com Japan completed an online survey. Using issue-based procedures for grounded theory analysis, they found strong support for SIP. Japanese online daters adapt their efforts to present and acquire social information using the cues that the online dating platform provides, although many of these cues are specific to Japanese social context.\n\nIn 2011, scholar Daria Heinemann analyzed the effects of SIP in the 1998 movie \"You've Got Mail\", and developed an activity to foster the teaching of SIP to students.\n\nIn business contexts, social information processing has been used to study virtual teams as well as the ways viral marketers influence the adoption of products and services through the Internet.\n\nMani R. Subramani and Balaji Rajagopalan pay special attention to the SIP applied to real-world online marketing and promotion activities. The background which stimulate their academic interests is that online social networks are increasingly being recognized as an important source of information influencing the adoption and use of products and services. While the potential of viral marketing to efficiently reach out to a broad set of potential users is attracting considerable attention, the value of this approach is also being questioned. Social information-processing theory provides a useful lens to examine the interpersonal influence processes that are the hallmark of viral marketing since it views the social network as an important source of information and cues for behavior and action for individuals. Prior studies examining the diffusion of innovations and the transmission of ideas in social networks have viewed the interpersonal influence as occurring largely from face-to-face interactions. However, interpersonal influence in viral marketing occurs in computer-mediated settings and is significantly different from that occurring in conventional contexts in several ways.\n\nThere needs to be a greater understanding of the contexts in which this strategy works and the characteristics of products and services for which it is most effective. What is missing is an analysis of viral marketing that highlights systematic patterns in the nature of knowledge-sharing and persuasion by influencers and responses by recipients in online social networks. To this end, they propose an organizing framework for viral marketing that draws on prior theory and highlights different behavioral mechanisms underlying knowledge-sharing, influence, and compliance in online social networks.\n\nSIP has also been used to study learning in entirely online classes examining the ways that students develop relationships with the instructor and with each other. Dip Nandi, Margaret Hamilton, and James Harland from RMIT University did research on asynchronous discussion forums in fully online courses. Their study focuses on the online discussion process between the students and the instructors, as both senders and receivers, through the CMC channel with the asynchronous nature.\n\nFully online courses are becoming progressively more popular because of their \"anytime anywhere\" learning flexibility. One of the ways students interact with each other and with the instructors within fully online learning environments is via asynchronous discussion forums. However, student engagement in online discussion forums does not always take place automatically and there is a lack of clarity about the ideal role of the instructors in them. In their research, Dip Nandi and his colleges report on their research on the quality of discussion in fully online courses through analysis of discussion forum communication. They have conducted the research on two large fully online subjects for computing students over two consecutive semesters and used a grounded theoretic approach for data analysis. The results reveal what students and instructors consider as quality interaction in fully online courses. The researchers also propose two frameworks based on our findings that can be used to ensure effective online interaction.\n\nSocial information processing theory has also been used to examine the development of aggressive behavior in children in recent years. Theories of aggressive behavior and ethological observations in animals and children suggest the existence of distinct forms of reactive (hostile) and proactive (instrumental) aggression. Toward the validation of this distinction, groups of reactive aggressive, proactive aggressive, and nonaggressive children were identified. Social information-processing patterns were assessed in these groups by presenting hypothetical vignettes to subjects.\n\nKenneth A. Dodge and Nicki R. Crick from Vanderbilt University did research on the social information bases of aggressive behavior in children. In their study, the ways that basic theories and findings in cognitive and social psychology (including attribution, decision-making, and information-processing theories) have been applied to the study of aggressive behavior problems in children are described. Following an overview of each of these theories, a social information-processing model of children's aggressive behavior is outlined. According to this model, a child's behavioral response to a problematic social stimulus is a function of five: steps of processing: encoding of social cues, interpretation of social cues, response search, response evaluation, and enactment. Skillful processing at each step is hypothesized to lead to competent performance within a situation, whereas biased or deficient processing is hypothesized to lead to deviant social behavior Empirical studies are described in which children's patterns of processing have been found to predict individual differences in their aggressive behavior The implications of this body of work for empirically based interventions aimed at reducing children's aggressive behavior are discussed.\n\nWhile the theory revolves around the basis of interpersonal interaction from a socio-psychological perspective, communication scholars and academics use a positivistic (or empirical) approach to knowing in their study of SIP theory, meaning they rely heavily on numbers and data sets when striving to reach conclusions.\n\nDespite the fact that social information processing theory offers a more optimistic perspective through which to perceive of and analyze online interactions, the theory is not without its criticisms. Even though Walther proposed that users of computer-mediated communication (CMC) have the same interpersonal needs met as those communicating face-to-face (FtF), he proposed that the lack of visual cues inherent in CMC are disadvantages to be overcome over time. Thus, more time is needed for interactants to get to know one another, although he maintains that the same intimacy can be reached, just over a longer amount of time. In their research on social cues and impression formation in CMC, Martin Tanis and Tom Postmes found that when initial impressions in CMC are negative, it is questionable and not guaranteed that people will pursue future interaction which negates the idea that more personal and positive relationships will develop over time in CMC relationships.\n\nMany of Walther's initial hypotheses relied on the assumption that positive social behaviors would be greater in face-to-face interactions than those in CMC. In a 1995 study, Walther used this hypothesis but added that any initial differences in socialness between the two media would disappear in time. Walther was surprised to find that his results turned out to be contrary to this prediction. The results showed that, regardless of time-scale, CMC groups were rated higher in most measures of relational communication than those participating in the FtF condition.\n\nRobert Tokunaga has presented a cultural value flaw in the SIP theory. An additional support for this claim is that there is research on intercultural communication that suggests the amount of exchange of self-disclosures in CMC is shaped by cultural values. Also, Tokunaga's study found that individualistic cultural values were able to fit inside the SIP theory while collectivist cultural values did not.\n\nSome originally argued that the scope of SIP Theory was too broad, since the realm of CMC is so expansive. However, the theory has evolved and been refined over years of research, and has developed more specificity within the discussions of online relationships, such as the topics of warranting and hyperpersonal perspectives.\n\nAnother area of SIP that has received some criticism relates to its testability. Walther has been a self-reflective critic of his own theory. First, Walther acknowledges that SIP has not fully acknowledged nor clarified the role of the issue of time in CMC relationships. Second, in discussing the hyperpersonal perspective, Walther admits that not all of the theoretical components of his hyperpersonal approach have been researched sufficiently. Third, in examining the warranting hypothesis, Walther, Brandon Van Der Heide, Lauren Hamel, & Hillary Shulman accept the fact that high warranting value may exist on those matters that have strong social desirability. For example, physical attractiveness is a highly desirable trait in the United States, making it socially desirable. So, as Walther accepts, online communicators would seek corroboration for those qualities that society deems important or desirable. Whether or not other less socially desirable qualities are prone to warranting overtures is not fully explained.\n\nTo summarize, social information processing theory arrived in the communication discipline at the time that the rest of the research world was starting to examine the Internet for its possible influence on interpersonal communication and human relationships. Thus, Joseph Walther is somewhat of a scholarly prophet, forecasting the importance of looking at online relationships in the early 1990s. Although a few criticisms emerge in SIP, people cannot ignore the fact that Walther's theory remains a pivotal framework to consider as we envision future relationship development in an uncertain technological time.\n\nThe label 'social media' has been attached to a quickly growing number of Web sites whose content is primarily user-driven. These communities are large-scale examples of SIP. Navigating the 'social' world of information online is largely a product of interpersonal connections online, and has prompted the creation of aggregating, or collaborative sources, to help assist collective groups of people sort through information. Learning about others through the concept of \"seamless sharing\" opens another word for SIP. Some computer tools that facilitate this process are:\nThe process of learning from and connecting with others has not changed, but is instead manifested on the Internet. There are many different opinions regarding the value of social media interactions. These resources allow for people to connect and develop relationships using methods alternative to the traditional FtF-exclusive past, thus, making CMC more prevalent amongst social media users.\n\n\n\n"}
{"id": "1479375", "url": "https://en.wikipedia.org/wiki?curid=1479375", "title": "Suppire–Mamara languages", "text": "Suppire–Mamara languages\n\nThe Suppire–Mamara languages form the northern branch of the Senufo language family and are mainly spoken in Mali. They comprise five different languages, totalling approximately 750,000 speakers (Olson 1996). The Northern Senufo languages are separated from the Central Senufo languages by a small band of Mande speaking people (the Duun). To the east and west, they are also bordered mainly by Mande languages like Bambara and Dioula, and they have been influenced considerably by those languages in both vocabulary and grammar (Carlson 1994).\n\nThe Suppire–Mamara languages are: \n\n\n"}
{"id": "37367980", "url": "https://en.wikipedia.org/wiki?curid=37367980", "title": "Tartan Curtain", "text": "Tartan Curtain\n\nThe Tartan Curtain is a term of reference to the change in status of the Scottish border with England in the event that Scotland becomes an independent sovereign state, as supported by the Scottish National Party.\n\nThe term Tartan Curtain has the negative connotations of the Iron Curtain which divided Europe during the Cold War.\n\nThe constitutional consequences of a newly independent Scotland joining the EU remain unclear, but if Scotland has to join the EU as a new member state it will not necessarily inherit the vetoes enjoyed by the rest of the United Kingdom.\nPart of the issue relates to the Schengen treaty, which allows free movement between European Union member states. The United Kingdom exercises an opt out from this treaty in order to maintain complete control over its own border.\n\nThe House of Commons Foreign Affairs Committee report entitled \"The foreign policy implications of and for a separate Scotland\" contains the following quote as Written evidence from the Foreign and Commonwealth Office:\n\"The impact of an independent Scotland joining Schengen, were it to wish or be obliged to do so, would be significant, creating a UK land border with the Schengen area for the first time (the Republic of Ireland is not a member of Schengen).\"\n\nThe term has been used in parliament, the press and in public discussions associated with Scottish Independence.\n\nThe term itself could relate to an Independent Scotland's physical border with the rest of the UK as well as differences in the currency and membership of international organisations such as NATO.\n"}
{"id": "33486015", "url": "https://en.wikipedia.org/wiki?curid=33486015", "title": "Theodor Larsson", "text": "Theodor Larsson\n\nTheodor Larsson (1880–1937) was a Swedish songwriter and comedian.\n\nLarsson was born June 8, 1880 in Gylle parish near the town of Trelleborg in Skåne. He died June 30, 1937 in Mjölby. A Swedish \"bondkomiker\" (rustic comic) and lyricist, his professional name was Skånska Lasse (Skåning Lasse). He worked as a cabinetmaker in Malmö, then for a short time in Stockholm before moving to Östergötland, where he found employment at a furniture factory in Mjölby. It was during his time there that Larsson embarked on his course as an entertainer. He often performed in a long coat with a flowery vest while playing the accordion. Married twice, he was the father of eleven children, several of whom also became entertainers.\n\nA prolific songwriter, Larsson developed a talent for writing lyrics about topical events. He even found humor in technological advances as his protagonists grappled with electricity, radio and motorized transport. The song \"Motorcykeln\" (The Motorcycle) became a hit for the singer Ernst Rolf and was also recorded in America by Olle i Skratthult and Ragnar Hasselgren. Another of his compositions, \"Josefin mä symaskin\" (Josephine with the sewing machine), crossed the Atlantic in a version by Bert Leman.\n\nSkånska Lasse made many recordings himself. \"Sven Svenssons Sven\" — later recorded by the Swedish-American singers Olle i Skratthult and Charles G. Widdén — brought up the subject of temperance while \"De rysliga bolshevikerna\" (The terrible bolsheviks) was a sly piece of political satire. The latter song was recorded in 2009 by the Swedish actor Sven Wollter.\n\nThere is one song above all others for which Lasse is remembered, \"Bonnjazz\" (Country dance), which he recorded in 1924. The song, one of the best-known works in Swedish popular music, has gone by many names, including \"Jazz på landet\" (Dance in the country) and \"Johan på snippen\" (Johan on the snippet of land). In America it was recorded by Lydia Hedberg in 1925 and Olle i Skratthult in 1927.\n\nThe song commonly known as \"Johan på snippen\" was first published in 1922. It had music by Gaston René Wahlberg and words by Skånska Lasse (Theodor Larsson). The two men never met. \nWahlberg, who was an engineer by profession, lived in Örebro in the province of Närke. When the iron industry flourished in the mining region of Bergslagen, people would come to Örebro to do business at \"Hindersmässan\" (The St. Henry’s Fair), an annual event which has continued until the present day. Wahlberg used to amuse himself on the piano, and one time after a visit to the local fair he set down some musical impressions. The result was a schottische he called \"Hindersmässan\". \nErnst Rolf purchased the melody from Wahlberg and passed it on to Larsson, who then set about writing suitable lyrics. \"Hindersmässan\" was the only melody that Wahlberg ever published, and over the years there has been some confusion about his name. Some have thought the composer to be Gideon Wahlberg, a Swedish songwriter best known for the waltz \"Svinnsta skär\". It was Walter Larsson, the lyricist’s son, who finally tracked down G. R. Wahlberg and saw to it that he received royalty payments for the composition.\n\nNear Skånska Lasse’s home was a cottage on a small plot of land. He based \"Johan på snippen\" partly on the neighbor who lived there but also drew upon his knowledge of local customs and folk festivals, having written many such verses before.\n\nWahlberg’s famous tune has inspired countless parodies, the most notable being \"Johan på snippens Ford\" (Johan på snippen’s Ford) with lyrics by Skånska Lasse and \"Johan på snibbens dammsugsmaskin\" (Johan på snibben’s vacuum cleaner) with lyrics by Erik Eriksson. Both songs were recorded by Eric P:son Friberg in the late 1920s.\n\n\nPhotos\nArticles\nSwedish music and film\nSwedish discography\nSelected recordings (Sweden)\nAmerican discography\nSelected recordings (America)\nSongbook\nSkånska Lasse lyrics \nSkånska Lasse recordings \nVideos\nStreaming audio \n"}
{"id": "44902", "url": "https://en.wikipedia.org/wiki?curid=44902", "title": "Vowel harmony", "text": "Vowel harmony\n\nVowel harmony is a type of long-distance assimilatory phonological process involving vowels that occurs in some languages. A vowel or vowels in a word must be members of the same subclass (thus \"in harmony\"). In languages with vowel harmony, there are constraints on which vowels may be found near each other. Suffixes and prefixes will usually follow vowel harmony rules. Many agglutinative languages have vowel harmony.\n\nThe term \"vowel harmony\" is used in two different senses.\n\nIn the first sense, it refers to any type of long distance assimilatory process of vowels, either \"progressive\" or \"regressive\". When used in this sense, the term \"vowel harmony\" is synonymous with the term \"metaphony\".\n\nIn the second sense, \"vowel harmony\" refers only to \"progressive\" vowel harmony (beginning-to-end). For \"regressive\" harmony, the term \"umlaut\" is used. In this sense, \"metaphony\" is the general term while \"vowel harmony\" and \"umlaut\" are both sub-types of metaphony. The term \"umlaut\" is also used in a different sense to refer to a type of vowel gradation. This article will use \"vowel harmony\" for both progressive and regressive harmony.\n\nHarmony processes are \"long-distance\" in the sense that the assimilation involves sounds that are separated by intervening segments (usually consonant segments). In other words, \"harmony\" refers to the assimilation of sounds that are \"not\" adjacent to each other. For example, a vowel at the beginning of a word can trigger assimilation in a vowel at the end of a word. The assimilation occurs across the entire word in many languages. This is represented schematically in the following diagram:\n\nIn the diagram above, the V (type-a vowel) causes the following V (type-b vowel) to assimilate and become the same type of vowel (and thus they become, metaphorically, \"in harmony\").\n\nThe vowel that causes the vowel assimilation is frequently termed the \"trigger\" while the vowels that assimilate (or \"harmonize\") are termed \"targets\". When the vowel triggers lie within the root or stem of a word and the affixes contain the targets, this is called \"stem-controlled\" vowel harmony (the opposite situation is called \"dominant\"). This is fairly common among languages with vowel harmony and may be seen in the Hungarian dative suffix:\n\nThe dative suffix has two different forms . The form appears after the root with back vowels ( and are back vowels). The form appears after the root with front vowels ( and are front vowels).\n\nVowel harmony often involves dimensions such as\n\n\nIn many languages, vowels can be said to belong to particular sets or classes, such as back vowels or rounded vowels. Some languages have more than one system of harmony. For instance, Altaic languages are proposed to have a rounding harmony superimposed over a backness harmony.\n\nEven among languages with vowel harmony, not all vowels need to participate in the vowel conversions; these vowels are termed \"neutral\". Neutral vowels may be \"opaque\" and block harmonic processes or they may be \"transparent\" and not affect them. Intervening consonants are also often transparent.\n\nFinally, languages that do have vowel harmony often allow for lexical \"disharmony\", or words with mixed sets of vowels even when an opaque neutral vowel is not involved. point to two such situations: polysyllabic trigger morphemes may contain non-neutral vowels from opposite harmonic sets and certain target morphemes simply fail to harmonize. Many loanwords exhibit disharmony. For example, Turkish , ('time' [from Arabic ]); * would have been expected.\n\nThere are three classes of vowels in Korean: positive, negative, and neutral. These categories loosely follow the front (positive) and mid (negative) vowels. Traditionally, Korean had strong vowel harmony; however, this rule is no longer observed strictly in modern Korean. In modern Korean, it is only applied in certain cases such as onomatopoeia, adjectives, adverbs, conjugation, and interjections. The vowel () is considered a partially neutral and a partially negative vowel. There are other traces of vowel harmony in modern Korean: many native Korean words tend to follow vowel harmony such as (, 'person'), and (, 'kitchen').\n\nMongolian exhibits both a pharyngeal harmony and a rounding harmony. In particular, the pharyngeal harmony involves the vowels: (pharyngeal) and (non-pharyngeal). Rounding harmony only affects the open vowels, .\nTurkic languages inherit their systems of vowel harmony from Proto-Turkic, which already had a fully developed system.\n\nAzerbaijani's system of vowel harmony has both front/back and rounded/unrounded vowels.\n\nTatar has no neutral vowels. The vowel é is found only in loanwords. Other vowels also could be found in loanwords, but they are seen as Back vowels. Tatar language also has a rounding harmony, but it is not represented in writing. O and ö could be written only in the first syllable, but vowels they mark could be pronounced in the place where ı and e are written.\nKazakh's system of vowel harmony is primarily a front/back system, but there is also a system of rounding harmony that is not represented by the orthography, which strongly resembles the system in Kyrgyz.\n\nKyrgyz's system of vowel harmony is primarily a front/back system, but there is also a system of rounding harmony, which strongly resembles that of Kazakh.\n\nTurkish has a 2-dimensional vowel harmony system, where vowels are characterised by two features: [±front] and [±rounded]. There are two sets of vocal harmony systems: a simple one and a complex one. The simple one is concerned with the low vowels e, a and has only the [±front] feature (\"e\" front vs \"a\" back). The complex one is concerned with the high vowels i, ü, ı, u and has both [±front] and [±rounded] features (\"i\" front unrounded vs \"ü\" front rounded and \"ı\" back unrounded vs \"u\" back rounded). The close-mid vowels \"ö, o\" are not involved in vowel harmony processes.\n\nTurkish has two classes of vowels\"front\" and \"back\". Vowel harmony states that words may not contain both front and back vowels. Therefore, most grammatical suffixes come in front and back forms, e.g. \"Türkiye'de \"in Turkey\" but \"Almanya'da \"in Germany\".\n\nIn addition, there is a secondary rule that \"i\" and \"ı\" in suffixes tend to become \"ü\" and \"u\" respectively after rounded vowels, so certain suffixes have additional forms. This gives constructions such as \"Türkiye'dir \"it is Turkey\", \"kapıdır \"it is the door\", but \"gündür \"it is day\", \"paltodur \"it is the coat\".\n\nNot all suffixes obey vowel harmony perfectly.\n\nIn the suffix \"-(i)yor\", the \"o\" is invariant, while the \"i\" changes according to the preceding vowel; for example \"sönüyor\" – \"he/she/it fades\". Likewise, in the suffix \"-(y)ken\", the \"e\" is invariant: \"Roma'dayken\" – \"When in Rome\"; and so is the \"i\" in the suffix \"-(y)ebil\": \"inanılabilir\" – \"credible\". The suffix \"-ki\" exhibits partial harmony, never taking a back vowel but allowing only the front-voweled variant \"-kü\": \"dünkü – \"belonging to yesterday\"; \"yarınki – \"belonging to tomorrow\".\n\nThe suffix \"-(y)le\" follows vowel harmony. However, in the phonology, it fronts a preceding back vowel \"ı\", thus creating a violation of the harmony. So the word \"dolayısıyla\" (\"therefore\"), formed from \"dolayısı\" with the variant suffix \"-yla\", which has a back vowel \"a\" according to vowel harmony, is actually pronounced as if the word is written *\"dolayısiyla\".\n\nMost Turkish words do not only have vowel harmony for suffixes, but also internally. However, there are many exceptions.\n\nCompound words are considered separate words with respect to vowel harmony: vowels do not have to harmonize between members of the compound (thus forms like |\"gün\" \"this|day\" = \"today\" are permissible). Vowel harmony does not apply for loanwords, as in \"otobüs\" – from French \"autobus\". There are also a few native modern Turkish words that do not follow the rule (such as \"anne\" \"mother\" or \"kardeş\" \"sibling\" which used to obey vowel harmony in their older forms, \"ana\" and \"karındaş\", respectively). However, in such words, suffixes nevertheless harmonize with the final vowel; thus \"annesi – \"his/her mother\", and \"voleybolcu – \"volleyball player\".\n\nIn some loanwords the final vowel is an \"a\", \"o\" or \"u\" and thus looks like a back vowel, but is phonetically actually a front vowel, and governs vowel harmony accordingly. An example is the word \"saat\", meaning \"hour\" or \"clock\", a loanword from Arabic. Its plural is \"saatler\". This is not truly an exception to vowel harmony itself; rather, it is an exception to the rule that \"a\" denotes a front vowel.\n\nDisharmony tends to disappear through analogy, especially within loanwords; e.g. \"Hüsnü\" (a man's name) < earlier \"Hüsni\", from Arabic \"husnî\"; \"Müslüman\" \"Moslem, Muslim (adj. and n.)\" < Ottoman Turkish \"müslimân\", from Persian \"mosalmân\").\n\nMany, though not all, Uralic languages show vowel harmony between front and back vowels. Vowel harmony is often hypothesized to have existed in Proto-Uralic, though its original scope remains a matter of discussion.\n\nVowel harmony is found in Nganasan and is reconstructed also for Proto-Samoyedic.\n\nHungarian, like its distant relative Finnish, has the same system of \"front\", \"back\", and \"intermediate\" (neutral) vowels but is more complex than the one in Finnish, and some vowel harmony processes. The basic rule is that words including at least one back vowel get back vowel suffixes (\"karba – in(to) the arm), while words excluding back vowels get front vowel suffixes (\"kézbe – in(to) the hand). One vowel words including only the neutral vowels \"i\", \"í\" or \"é\" are unpredictable (not in case of \"e\" which surely gets front vowel suffix).\n\nOne essential difference in classification between Hungarian and Finnish is that standard Hungarian (along with 3 out of 10 local dialects) does not observe the difference between Finnish 'ä' and 'e' the Hungarian front vowel 'e' is closely pronounced as the Finnish front vowel 'ä' . 7 out of the 10 local dialects have the vowel ë which has never been part of the Hungarian alphabet, and thus is not used in practice.\n\n\"Unrounded front vowels\" (or \"Intermediate\" or \"neutral\" vowels) can occur together with either \"back vowels\" (e.g. \"répa carrot, \"kocsi car) or \"rounded front vowels\" (e.g. \"tető\", \"tündér\"), but \"rounded front vowels\" and \"back vowels\" can occur together only in words of foreign origins (e.g. \"sofőr\" = chauffeur, French word for driver). The basic rule is that words including at least one back vowel take back vowel suffixes (e.g. \"répá|ban\" in a carrot, \"kocsi|ban\" in a car), while words excluding back vowels usually take front vowel suffixes (except for words including only the vowels \"i\" or \"í\", for which there is no general rule, e.g. \"liszt|et\", \"hid|at\").\n\nSome other rules and guidelines to consider:\nGrammatical suffixes in Hungarian can have one, two, three, or four forms:\nAn example on basic numerals:\n\nVowel harmony occurred in Southern Mansi.\n\nIn the Khanty language, vowel harmony occurs in the Eastern dialects, and affects both inflectional and derivational suffixes. The Vakh-Vasyugan dialect has a particularly extensive system of vowel harmony, with seven different front-back pairs:\n\nThe vowels , (front) and (back) can only occur in the first syllable of a word, and do not actively participate in vowel harmony, but they do trigger it.\n\nVowel harmony is lost in the Northern and Southern dialects, as well as in the Surgut dialect of Eastern Khanty.\n\nMost varieties of the Mari language have vowel harmony.\n\nThe Erzya language has a limited system of vowel harmony, involving only two vowel phonemes: (front) versus (back).\n\nMoksha, the closest relative of Erzya, has no phonemic vowel harmony, though has front and back allophones in a distribution similar to the vowel harmony in Erzya.\n\nVowel harmony is found in most of the Finnic languages. It has been lost in Livonian and in Standard Estonian, where the front vowels \"ü\" \"ä\" \"ö\" occur only in the first (stressed) syllable. Võro, a dialect of South Estonian, however retains vowel harmony.\n\nIn the Finnish language, there are three classes of vowels\"front\", \"back\", and \"neutral\", where each front vowel has a back vowel pairing. Grammatical endings such as case and derivational endingsbut not encliticshave only archiphonemic vowels U, O, A, which are realized as either back or front inside a single word. From vowel harmony it follows that the initial syllable of each single (non-compound) word controls the frontness or backness of the entire word. Non-initially, the neutral vowels are transparent to and unaffected by vowel harmony. In the initial syllable:\n\nFor example:\n\nSome dialects that have a sound change opening diphthong codas also permit archiphonemic vowels in the initial syllable. For example, standard 'ie' is reflected as 'ia' or 'iä', controlled by noninitial syllables, in the Tampere dialect, e.g. \"tiä\" ← \"tie\" but \"miakka\" ← \"miekka\".\n\n... as evidenced by \"tuotteessa\" (not *\"tuotteessä\"). Even if phonologically front vowels precede the suffix \"-nsa\", grammatically it is preceded by a word controlled by a back vowel. As shown in the examples, neutral vowels make the system unsymmetrical, as they are front vowels phonologically, but leave the front/back control to any grammatical front or back vowels. There is little or no change in the actual vowel quality of the neutral vowels.\n\nAs a consequence, Finnish speakers often have problems with pronouncing foreign words which do not obey vowel harmony. For example, \"olympia\" is often pronounced \"olumpia\". The position of some loans is unstandardized (e.g. \"chattailla\"/\"chättäillä\" ) or ill-standardized (e.g. \"polymeeri\", sometimes pronounced \"polumeeri\", and \"autoritäärinen\", which violate vowel harmony). Where a foreign word violates vowel harmony by not using front vowels because it begins with a neutral vowel, then last syllable generally counts, although this rule is irregularly followed. Experiments indicate that e.g. \"miljonääri\" always becomes (front) \"miljonääriä\", but \"marttyyri\" becomes equally frequently both \"marttyyria\" (back) and \"marttyyriä\" (front), even by the same speaker.\n\nWith respect to vowel harmony, compound words can be considered separate words. For example, \"syyskuu\" (\"autumn month\" i.e. September) has both \"u\" and \"y\", but it consists of two words \"syys\" and \"kuu\", and declines \"syys·kuu·ta\" (not *\"syyskuutä\"). The same goes for enclitics, e.g. \"taaksepäin\" \"backwards\" consists of the word \"taakse\" \"to back\" and \"-päin\" \"-wards\", which gives e.g. \"taaksepäinkään\" (not *\"taaksepäinkaan\" or *\"taaksepainkaan\"). If fusion takes place, the vowel is harmonized by some speakers, e.g. \"tälläinen\" pro \"tällainen\" ← \"tämän lainen\".\n\nSome Finnish words whose stems contain only neutral vowels exhibit an alternating pattern in terms of vowel harmony when inflected or forming new words through derivation. Examples include \"meri\" \"sea\", \"meressä\" \"in the sea\" (inessive), but \"merta\" (partitive), not *\"mertä\"; \"veri\" \"blood\", \"verestä\" \"from the blood\" (elative), but \"verta\" (partitive), not *\"vertä\"; \"pelätä\" \"to be afraid\", but \"pelko\" \"fear\", not *\"pelkö\"; \"kipu\" \"pain\", but \"kipeä\" \"sore\", not *\"kipea\".\n\nHelsinki slang has slang words that have roots violating vowel harmony, e.g. \"Sörkka\". This can be interpreted as Swedish influence.\n\nVowel harmony is present in all Yokutsan languages and dialects. For instance, Yawelmani has 4 vowels (which additionally may be either long or short). These can be grouped as in the table below.\n\nVowels in suffixes must harmonize with either or its non- counterparts or with or non- counterparts. For example, the vowel in the aorist suffix appears as when it follows a in the root, but when it follows all other vowels it appears as . Similarly, the vowel in the nondirective gerundial suffix appears as when it follows a in the root; otherwise it appears as .\n\nIn addition to the harmony found in suffixes, there is a harmony restriction on word stems where in stems with more than one syllable all vowels are required to be of the same lip rounding and tongue height dimensions. For example, a stem must contain all high rounded vowels or all low rounded vowels, etc. This restriction is further complicated by (i) long high vowels being lowered and (ii) an epenthetic vowel which does not harmonize with stem vowels.\n\nThere is some evidence for vowel harmony according to vowel height or ATR in the prefix i/e- in inscriptions from pre-Sargonic Lagash (the specifics of the pattern have led a handful of scholars to postulate not only an phoneme, but even an and, most recently, an ) Many cases of partial or complete assimilation of the vowel of certain prefixes and suffixes to one in the adjacent syllable are reflected in writing in some of the later periods, and there is a noticeable though not absolute tendency for disyllabic stems to have the same vowel in both syllables. What appears to be vowel contraction in hiatus (*/aa/, */ia/, */ua/ > a, */ae/ > a, */ue/ > u, etc.) is also very common.\n\nVowel harmony occurs to some degree in many other languages, such as\n\nAlthough vowel harmony is the most well-known harmony, not all types of harmony that occur in the world's languages involve only vowels. Other types of harmony involve consonants (and is known as consonant harmony). Rarer types of harmony are those that involve tone or both vowels and consonants (e.g. \"postvelar harmony\").\n\nSome languages have harmony processes that involve an interaction between vowels and consonants. For example, Chilcotin has a phonological process known as \"vowel flattening\" (i.e. post-velar harmony) where vowels must harmonize with uvular and pharyngealized consonants.\n\nChilcotin has two classes of vowels:\n\n\nAdditionally, Chilcotin has a class of pharyngealized \"flat\" consonants . Whenever a consonant of this class occurs in a word, all preceding vowels must be flat vowels.\n\nIf flat consonants do not occur in a word, then all vowels will be of the non-flat class:\n\nOther languages of this region of North America (the Plateau culture area), such as St'át'imcets, have similar vowel-consonant harmonic processes.\n\nSyllabic synharmony was a process in the Proto-Slavic language ancestral to all modern Slavic languages. It refers to the tendency of frontness (palatality) to be generalised across an entire syllable. It was therefore a form of consonant–vowel harmony in which the property 'palatal' or 'non-palatal' applied to an entire syllable at once rather than to each sound individually.\n\nThe result was that back vowels were fronted after \"j\" or a palatal consonant, and consonants were palatalised before \"j\" or a front vowel. Diphthongs were harmonized as well, although they were soon monophthongized because of a tendency to end syllables with a vowel (syllables were or became open). This rule remained in place for a long time, and ensured that a syllable containing a front vowel always began with a palatal consonant, and a syllable containing \"j\" was always preceded by a palatal consonant and followed by a front vowel.\n\nA similar process occurs in Skolt Sami, where palatalization of consonants and fronting of vowels is a suprasegmental process applying to a whole syllable. Suprasegmental palatalization is marked with the letter \"ʹ\", which is a freestanding acute accent, for example in the word \"vääʹrr\" 'mountain, hill'.\n\n\n\n"}
{"id": "22786953", "url": "https://en.wikipedia.org/wiki?curid=22786953", "title": "Xhosa Wikipedia", "text": "Xhosa Wikipedia\n\nThe Xhosa Wikipedia is the Xhosa language edition of Wikipedia. It has articles, which as of 25 August 2018 makes it the 260th largest Wikipedia.\n\nThe Xhosa edition of Wikipedia was started in June 2003. Its low number of articles has led to proposals to close it in 2008 and 2013 (both rejected).\n\nAs Xhosa is mutually intelligible with Zulu, both of which are Nguni languages, it is possible for articles in the Zulu edition to be easily translated into Xhosa for the Xhosa Wikipedia. Similar trans-wiki efforts have been made for Scandinavian-language editions, such as the Swedish, Norwegian, and Danish through Wikimedia's \"\" collaboration tool.\n\n\n"}
