{"id": "9835444", "url": "https://en.wikipedia.org/wiki?curid=9835444", "title": "Abellen language", "text": "Abellen language\n\nAbellen, Abenlen, Aburlin, or Ayta Abellen, is a Sambalic language. It has about 3,500 speakers and is spoken in a few Aeta communities in Tarlac province, Philippines Ayta Abellen itself is part of the Sambalic language family in the Philippines and is closely related to not only the 5 other Ayta dialects, but also the Botolan dialect of Sambal.\n\nThe Ayta Abellen people are historically a semi-nomadic people. Also known as Negritos, they are said to be descendants of the earliest inhabitants of the Philippines, dating back to the late Pleistocene Era. The Ayta Abellen are distinguishable by their curly black hair, and darker skin tone as compared to other Filipinos. Since their language is similar to Austronesian languages, there is a theory of an Austronesian migration that occurred. In this theory, there were two different migrations, one from the southern coast of Sundaland eastward and from Wallacea to Mindanao, causing there to be a separation of Ayta people and the Mamanwa for about 20,000 to 30,000 years. Prior to the Austronesian migration, there was not much similarity between the original languages of the Negritos.\n\nAfter the eruption of Mt. Pinatubo in the 1990s, some of the Ayta Abellen have rellocated from the mountains and have intermarried and mixed in with the local Ilocano people. As a result, there are Ilocano loan words in the language. Much of the population also speaks Ilocano as a second language along with Tagalog as well. They Ayta people rely on natural resources, however, due to shrinking forests, it has become harder to sustain that life style. This problem along with diseases, and its remoteness from modern health care centers are correlated with the higher death rate as compared to birth rate in the Ayta Abellen people\n\nCurrently, Elizabeth City State University Professors John Luton Jose Gil are helping Wycliffe Global Alliance translate the Bible in hopes to preserve the language. The translation process is also aided by a linguist missionary, Robert Stone, who is on the field. The text is first translated from Ayta Abellen to Simple English, which is then fact checked in the United States to the Hebrew and Greek versions of the Bible, and afterwards, translated back into Ayta Abellen.\n\nAdditionally, s, r, c (for [k]), j,among other phonemes are used in loan words and names. In Sambal and Ayta languages, the glottal stop tends to replace a word final non-obstruent when proceeded by a stressed high central vowel.\n\nAyta Abellen shares the same Verb-Subject-Object sentence structure as other languages in the Philippines. It shares similar phonology with other Ayta dialects as well as Botolan Sambal. Not only does it share an identical pronoun system with other Sambalic languages, but between other Ayta languages, it is around 70% similar. This language is a CV(consonant and vowel) and CVC language, although sometimes, it is ambiguously a VC and V language. In this language, vowel deletion as well as consonant deletion are evident when words are combined. In this language, placement of stress can be unpredictable. Poly-syllabic words have primary stress whereas words with more than three syllables contain a secondary stress. However, suffixation also causes a shift in stress placement.\n\nAyta Abellen is written using Latin text. Ilocano is a second language to much of the Abellen and the lingua franca of where many of the Abellen people reside, while Tagalog is the national language of the Philippines, transcribers are trying to document the language in text that is similar to both Ilocano and Tagalog. Much of the hymnals used in that area are written in Botolan Sambal, and thus they are also trying to have Ayta Abellen orthography conform to it as well.\n\nAbellen Ayta speakers in the following locations of\n\n\n"}
{"id": "38243319", "url": "https://en.wikipedia.org/wiki?curid=38243319", "title": "Abu Abd al-Rahman Ibn Aqil al-Zahiri", "text": "Abu Abd al-Rahman Ibn Aqil al-Zahiri\n\nMuhammad bin Umar bin Abd al-Rahman bin Abd Allah al-Aqil, better known as Abu Abd al-Rahman Ibn Aqil al-Zahiri, is a Saudi Arabian polymath. He has, at various times, been referred to as a theologian, jurist, historian, ethnographer, geographer, poet, critic and author. As a member of Saudi Arabia's \"Golden Generation,\" he knew of life both during the poverty of the pre-oil boom era and the prosperity of the 1950s onward.\n\nIbn Aqil was born in the city of Shaqraa in Saudi Arabia's central Najd region in 1942. His has been married three times, during which he sired twenty-six children. His current wife is from Egypt. Ibn Aqil also owns a bookstore, \"Dar Ibn Hazm,\" in the Al-Suwaidi district where he currently lives, and is the prayer leader of a nearby mosque.\n\nIbn Aqil had a complicated friendship and, later, rivalry with fellow Arab philosopher Abdullah al-Qasemi. Having known al-Qasemi before he converted from Islam to atheism, Ibn Aqil met al-Qasemi for a debate in the Garden City district of Downtown Cairo. After a long discussion regarding the existence of God and Theodicy, Ibn Aqil authored the book \"A Night in Garden City\" as an account of the debate.\n\nAfter receiving his primary and secondary education in Shaqraa, Ibn Aqil relocated to Riyadh and enrolled in Imam Muhammad ibn Saud Islamic University, which at the time was a brand new institution. He earned a Bachelor of Science in Law from the college of Islamic law, and a Master of Theology degree in exegesis of the Qur'an. During this time, Ibn Aqil was a student of former Saudi Grand Mufti Abd al-Aziz ibn Baz and Ibn Humaid, another high-ranking cleric. Zahiri spent most of his tutelage under Abu Turab al-Zahiri.\n\nIn his twenties and early thirties, Ibn Aqil worked as a lawyer within Saudi Arabia's theocratic justice system. He was eventually placed in administrative positions for public education in the country's eastern province in Dammam, and then later moved to the legal department in the Ministry of Municipal and Rural Affairs. Upon returning to Riyadh, he founded and served as president of the Riyadh Literary Society, and began writing a regular column for the Arabic daily Al Jazirah; while he continues the latter endeavor, he relinquished his presidency of the Society and joined the general membership. From the 1960s to the 1980s, Ibn Aqil served in several posts including that of a legal adviser to the Riyadh Municipal Agency, auditor of the General Employees Bureau and Director of Services for the General Administration of Girls' Education.\n\nIn the past, he was the host of \"Tafsir al-Tafasir\" or \"exegesis of the exegeses,\" a religious program which was broadcast daily on the radio and weekly on television. Building on his graduate background, Ibn Aqil would systematically collect all major explanations of the Qur'an within Sunni Islam and attempt to integrate all of them, weighing the views of various theologians. Although the program was discontinued in the late 1980s, Ibn Aqil restarted his broadcasts in 2010 from where he had left off. The King Faisal Center for Research and Islamic Studies had invited Ibn Aqil to grant a symposium on the topic of comparative exegesis five years prior, likely reigniting public interest.\n\nCurrently, Ibn Aqil has mostly retired from public life. In addition to his renewed Qur'an study broadcasts, he is a member of the Academy of the Arabic Language in Cairo, the Arabic Language Academy at Mecca, and still serves as the editor-in-chief of an academic journal named after the UNESCO World Heritage Site Diriyah, which he founded and which holds its headquarters on his family estate.\n\nIbn Aqil has defined the problems of Saudi society as coming both from secularists on one end of the spectrum and Muslim clerics delivering hasty and erroneous proclamations on the other. Being a part of Saudi Arabia's \"Golden Generation,\" Ibn Aqil has generally been supportive of the House of Saud and the Saudi government, and an opponent of its critics among both liberal modernists and radical extremists.\n\nRecently, Ibn Aqil called for the Saudi government to strip a dissident journalist of his citizenship due to his sharp criticisms of the Consultative Assembly of Saudi Arabia. On the other end of the spectrum, Ibn Aqil engaged in a public series of exchanges with fellow cleric Abdul-Rahman al-Barrak in 2011 due to the former's refusal to adopt a formal position on theological issues debated during the Mihna, a rare Medieval-era inquisition within Islam perpetrated by rationalists against their orthodox counterparts. Ibn Aqil has also fallen into conflict with Egyptian cleric Yusuf al-Qardawi in a series of back-and-forth columns, though Qardawi did not mention Ibn Aqil by name. Ibn Aqil, who has expressed skepticism about the goals and results of the Arab Spring, considered Qardawi's various positions during the movement hypocritical and contradictory, charges which Qardawi denied.\n\nBeing a jurist and scholar of the Zahirite school of law within Sunni Islam, Ibn Aqil is also the current era's primary biography of Zahirite theologian Ibn Hazm, having written detailed accounts even of Ibn Hazm's individual conflicts with rival jurist Abu al-Walid al-Baji. His bookstore is named after the Andalusian author, and Ibn Aqil has authored a number of books on the life and career of Ibn Hazm. The largest of these books is \"Nawadir al-Imam Ibn Hazm\", a collection of Ibn Hazm's smaller, harder-to-find works, such as his poem on the fundamental principles of Zahirite law. He has also delivered a lecture explaining Ibn Rushd's attempts to reconcile philosophy and religion at the International Averroes Symposium, co-sponsored by UNESCO in Carthage between February 16 and 22 in 1998.\n\nIn addition to \"A Night in Garden City\", other titles of some note are \"Descartes Between Scepticism and Certainty\" and \"The History of Najd During the Colloquial Epoch\". Perhaps stemming from his philosophical debates with al-Qasemi, reconciliation between reason and revelation has been a recurring theme in Ibn Aqil's work.\n\n\n\n\n"}
{"id": "1552945", "url": "https://en.wikipedia.org/wiki?curid=1552945", "title": "Assignment (law)", "text": "Assignment (law)\n\nAn assignment is a legal term used in the context of the law of contract and of property. In both instances, assignment is the process whereby a person, the \"assignor\", transfers rights or benefits to another, the \"assignee\". An assignment may not transfer a duty, burden or detriment without the express agreement of the assignee. The right or benefit being assigned may be a gift (such as a waiver) or it may be paid for with a contractual consideration such as money. \n\nThe rights may be vested or contingent, and may include an equitable interest. Mortgages and loans are relatively straightforward and amenable to assignment. An assignor may assign rights, such as a mortgage note issued by a third party borrower, and this would require the latter to make repayments to the assignee.\n\nA related concept of assignment is novation wherein, by agreement with all parties, one contracting party is replaced by a new party. While novation requires the consent of all parties, assignment needs no consent from other non-assigning parties. However, in the case of assignment, the consent of the non-assigning party may be required by a contractual provision.\n\nThe assignment does not necessarily have to be in writing; however, the assignment agreement must show an intent to transfer rights. The effect of a valid assignment is to extinguish privity (in other words, contractual relationship, including right to sue) between the assignor and the third-party obligor and create privity between the obligor and the assignee.\n\nUnless the contractual agreement states otherwise, the assignee typically does not receive more rights than the assignor, and the assignor may remain liable to the original counterparty for the performance of the contract. The assignor often delegates duties in addition to rights to the assignee, but the assignor may remain ultimately responsible.\n\nHowever, in the United States, there are various laws that limit the liability of the assignee, often to facilitate credit, as assignees are typically lenders. Notable examples include a provision in the Truth in Lending Act and provisions in the Consumer Leasing Act and the Home Ownership Equity Protection Act.\n\nIn other cases, the contract may be a negotiable instrument in which the person receiving the instrument may become a holder in due course, which is similar to an assignee except that issues, such as lack of performance, by the assignor may not be a valid defense for the obligor. As a response, the United States Federal Trade Commission promulgated Rule 433, formally known as the \"Trade Regulation Rule Concerning Preservation of Consumers' Claims and Defenses\", which \"effectively abolished the [holder in due course] doctrine in consumer credit transactions\". In 2012, the commission reaffirmed the regulation.\n\nAfter the assignment of contractual rights, the assignee will receive all benefits that had accrued to the assignor. For example, if A contracts to sell his car for $100 to B, A may assign the benefits (the right to be paid $100) to C. In this case, Party C is \"not\" a \"third party beneficiary\", because the contract was not made for C's benefit. Assignment takes place after the contract was formed; they may not precede them.\nThe common law favors the freedom of assignment, so an assignment will generally be permitted unless there is an express prohibition against assignment in the contract. Where assignment is thus permitted, the assignor need not consult the other party to the contract. An assignment cannot have any effect on the duties of the other party to the contract, nor can it reduce the possibility of the other party receiving full performance of the same quality. Certain kinds of performance, therefore, \"cannot\" be assigned, because they create a unique relationship between the parties to the contract. For example, the assignment of a legal malpractice claim is void since an assignee would be a stranger to the attorney-client relationship, who was owed no duty by the attorney and would imperil the sanctity of the highly confidential and fiduciary relationship existing between attorney and client.\n\nTorts are not assignable as public policy, and various statutes may prohibit assignment in certain instances. In addition, the Restatement (Second) of Contracts lists prohibitions in §317(2)(a) based upon the effect to the nonassigning party (obligor), with similar prohibitions in the Uniform Commercial Code §2-210. For example, UCC §2-210 states the following:\nFor assignment to be effective, it must occur in the present. No specific language is required to make such an assignment, but the assignor must make some clear statement of intent to assign clearly identified contractual rights to the assignee. A promise to assign in the future has no legal effect. Although this prevents a party from assigning the benefits of a contract that has not yet been made, a court of equity may enforce such an assignment where an established economic relationship between the assignor and the assignee raised an expectation that the assignee would indeed form the appropriate contract in the future.\n\nA contract may contain a non-assignment clause, which prohibits the assignment of specific rights and some various rights, or of the entire contract, to another. However, such a clause does not necessarily destroy the power of either party to make an assignment. Instead, it merely gives the other party the ability to sue for breach of contract if such an assignment is made. However, an assignment of a contract containing such a clause will be ineffective if the assignee \"knows\" of the non-assignment clause, or if the non-assignment clause specifies that \"all assignments are void\".\n\nTwo other techniques to prevent the assignment of contracts are \"rescission clauses\" or clauses creating a \"condition subsequent\". The former would give the other party to the contract the power to rescind the contract if an assignment is made; the latter would rescind the contract automatically in such circumstances.\n\nThere are certain situations in which the assignment must be in writing.\n\nA parallel concept to assignment is \"delegation\", which occurs when one party transfers his \"duties or liabilities\" under a contract to another. A delegation and an assignment can be accomplished at the same time, although a non-assignment clause may also bar delegation.\n\nLegal remedies may be available if the nonassigning party's rights are affected by the assignment.\n\nAssignments made for consideration are irrevocable, meaning that the assignor permanently gives up the legal right to take back the assignment once it has been made. Donative assignments, on the other hand, are generally revocable, either by the assignor giving notice to the assignee, taking performance directly from the obligor, or making a subsequent assignment of the same right to another. There are some exceptions to the revocability of a donative assignment:\n\nA cause of action for breach on the part of the obligor lies with the assignee, who will hold the exclusive right to commence a cause of action for any failure to perform or defective performance. At this stage, because the assignee \"stands in the shoes\" of the assignor, the obligor can raise any defense to the contract that the obligor could have raised against the assignor. Furthermore, the obligor can raise against the assignee counterclaims and setoffs that the obligor had against the assignor. For example, suppose that A makes a contract to paint B's house in exchange for $500. A then assigns the right to receive the $500 to C, to pay off a debt owed to C. However, A does such a careless job painting the house that B has to pay another painter $400 to correct A's work. If C sues B to collect the debt, B can raise his counterclaim for the expenses caused by the poor paint job, and can reduce the amount owed to C by that $400, leaving only $100 to be collected.\n\nWhen the assignor makes the assignment, he makes with it an implied warranty that the right to assign was not subject to defenses. If the contract had a provision that made the assignment ineffective, the assignee could sue the assignor for breach of this implied warranty. Similarly, the assignee could also sue under this theory if the assignor wrongfully revoked the assignment.\n\nOccasionally, an unscrupulous assignor will asof the assignment, and on the timing of the assignments relative to certain other actions.\n\nIn a quirk left over from the common law, if the assignment was donative, the \"last assignee\" is the true owner of the rights. However, if the assignment was for consideration, the \"first assignee\" to actually \"collect against the assigned contract\" is the true owner of the rights. Under the modern \"American rule\", now followed in most U.S. jurisdictions, the first assignor with equity (i.e. the first to have paid for the assignment) will have the strongest claim, while remaining assignees may have other remedies. In some countries, the rights of the respective assignees are determined by the old common law rule in \"Dearle v Hall\".\n\n\nSee interpleader.\n\nReal property rights can be assigned just as any other contractual right. However, special duties and liabilities attach to transfers of the right to possess property. With an assignment, the assignor transfers the complete remainder of the interest to the assignee. The assignor must not retain any sort of reversionary interest in the right to possess. The assignee's interest must abut the interest of the next person to have the right to possession. If any time or interest is reserved by a tenant assignor then the act is not an assignment, but is instead a sublease.\n\nThe liability of the assignee depends upon the contract formed when the assignment takes place. However, in general, the assignee has privity of estate with a lessor. With privity of estate comes the duty on the part of the assignee to perform certain obligations under covenant, e.g. pay rent. Similarly, the lessor retains the obligations to perform on covenants to maintain or repair the land.\n\nIf the assignor agrees to continue paying rent to the lessor and subsequently defaults, the lessor can sue both the assignor under the original contract signed with the lessor as well as the assignee because by taking possession of the property interest, the assignee has obliged himself to perform duties under covenant such as the payment of rent.\n\nUnlike a Novation where consent of both the lessor and lesse is required for the third party to assume all obligations and liabilities of the original lessee, an assignment does not always need the consent of all parties. If the contract terms state specifically that the lessor's consent is not needed to assign the contract, then the lesee can assign the contract to whomever the lesee wants to.\n\nAbsent language to the contrary, a tenant may assign their rights to an assignee without the landlord's consent. In the majority of jurisdictions, when there is a clause that the landlord may withhold consent to an assignment, the general rule is that the landlord may not withhold consent unreasonably unless there is a provision that states specifically that the Landlord may withhold consent at Landlord's sole discretion.\n\nA person can also assign their rights to receive the benefits owed to a partner in a partnership. However, the assignee can \"not\" thereby gain any of the assignor's rights with respect to the operation of the partnership. The assignee may not vote on partnership matters, inspect the partnership books, or take possession of partnership property; rather, the assignee can only be given the right is to collect distributions of income, unless the remaining partners consent to the assignment of a new general partner with operational, management, and financial interests. If the partnership is dissolved, the assignee can also claim the assignor's share of any distribution accompanying the dissolution.\n\nOwnership of intellectual property, including patents, copyrights, and trademarks, may be assigned, but special conditions attach to the assignment of patents and trademarks. In the United States, assignment of a patent is governed by statute, . Patent rights are assignable by an \"instrument in writing.\" Title in a patent can also be transferred as a result of other financial transactions, such as a merger or a takeover, or as a result of operation of law, such as in an inheritance process, or in a bankruptcy. An assignment of a patent can be recorded with the United States Patent and Trademark Office. Although such recording is not required, if an assignment is not recorded at the USPTO within three (3) months or prior to a subsequent assignment, the assignment will be void against a subsequent assignee without notice of the earlier, unrecorded assignment.\n\nWith respect to a trademark, the owner of the mark may not transfer ownership of the mark without transferring the goodwill associated with the mark.\n\nCompanies sometimes request from employees that they assign all intellectual property they create while under the employment of the company. This is typically done within an Employment Agreement, but is sometimes done through a specific agreement called Proprietary Information and Inventions Agreement (PIIA).\n\nThe standard rule is that personal injury tort causes of action are nonassignable as a matter of public policy. These should be distinguished from final settlements or judgments resulting from lawsuits brought on such causes of action, which may be assignable.\n\nIn the majority of jurisdictions, assignments involving fraud or legal malpractice causes of action are void as against public policy.\n\nAn equitable assignment is an assignment, or transfer of rights, in equity.\n\nThere are numerous requirements that exist for an equitable assignment of property, outside the 'standard' \"clear and unconditional intention to assign\". These requirements are fundamental characteristics of a statutory assignment: Absolute assignment (an unconditional transfer: conditions precedent or part of a debt are not absolute) and the assignment must be made in writing and signed by the assignor, and in particular, this applies to real property.\n\nAssigning future property in equity cannot be gratuitous. The assignor must receive consideration for the agreement, otherwise the assignment will be ineffective. However, an absolute assignment does not require consideration to be given. Secondly, between the period of agreement between assignor and assignee and acquisition by the assignor, the assignees rights are not contractual, but rather a proprietary right to the property. This means the assignee has an interest in this future property, in the same manner any owner has over property.\n\nIn equity, these principles operate to protect both the assignor and the assignee. In \"Norman v Federal Commissioner of Taxation\", a taxpayer attempted to assign by deed, to his wife certain moneys which he was eventually going to receive. This included dividends and interest due on loans. The court held the interest and the dividends were expectancies or possibilities which could not be assigned without consideration. The court's worry was that assignments without consideration might be used as instruments of fraud, to avoid creditors and tax collection.\n\nCourts will not enforce a contract to assign an expectancy unless there is a valuable consideration. For example, under a settlement of property the respondent \"the son\" would have been entitled to an equal portion of properties along with his other siblings which was gained in a settlement by his mother. This portion was only his when allocated to him at his mothers discretion. Prior to this allocation being made, the respondent allotted his benefit to trustees for a voluntary settlement. He was assigning or purporting to assign something which he might become entitled to in the future, not a contingent interest. The judgment held it ineffective and elaborated on previous points to state the respondent cannot be compelled to allow the trustees to retain the appointed sum.\n"}
{"id": "13236418", "url": "https://en.wikipedia.org/wiki?curid=13236418", "title": "Bantawa language", "text": "Bantawa language\n\nThe Bantawa Language (also referred to as An Yüng, Bantaba, Bantawa Dum, Bantawa Rai, Bantawa Yong, Bantawa Yüng, Bontawa, Kirawa Yüng), is an endangered Kiranti language spoken in the eastern Himalayan hills of eastern Nepal by Bantawa ethnic groups. They use a syllabic alphabet system known as Kirat Rai. Among the Kirat Rai people of Eastern Nepal, Bantawa is the largest language spoken. According to the 2001 National Census, at least 1.63% of the Nepal's total population speaks Bantawa. About 370,000 speak Bantawa Language mostly in eastern hilly regions of Nepal (2001). Although Bantawa Rai is among the more widely used variety of the Bantawa language, it falls in the below-100,000 category of endangered languages. It is experiencing language shift to Nepali, especially in the northern region.\n\nBantawa is spoken in subject-object-verb order, and has no noun classes or genders.\n\nMost of the Bantawa clan are now settled in Bhojpur, Dharan, Illam, and Dhankuta. Recent figures show most of them are settled in Dharan. Bantawa is spoken in the following districts of Nepal (\"Ethnologue\").\n\nDialects are as follows (\"Ethnologue\").\n\nBantawa is also considered as a superior clan in the Kiranti family. Bantawa is also reportedly in use as a \"lingua franca\" among Rai minorities in Himalayan India and Bhutan. Meanwhile, the language is just being introduced in a few schools at the primary level (Year 1- Year 5)\nWords Corrected by: Kiran Bantawa (Mangphang-Lokchwawa)\n\nhttp://www.raisujan.com.np/landing.php?_page=article&article_id=1\n\n\n"}
{"id": "57661999", "url": "https://en.wikipedia.org/wiki?curid=57661999", "title": "Bapulal Nayak", "text": "Bapulal Nayak\n\nBapulal Nayak (25 March 1879 – 4 December 1947) was an Indian stage actor, director and manager of the early Gujarati theatre. Born into a family of traditional folk theatre performers, he joined the theatre company Mumbai Gujarati Natak Mandali at a young age. His acting was well received in his initial roles. He was involved in stage planning and managing and later became a partner in the company. He rose to fame and acted in several successful plays with Jaishankar Bhojak 'Sundari', who played female roles opposite him. He acted in plays written by Mulshankar Mulani, Gajendrashnakar Pandya and Nrisinh Vibhakar. He wrote and directed several plays and eventually bought the theatre company. After a career lasting five decades, he retired after his company suffered heavy loss with the advent of the cinema.\n\nNayak was born in Gerita near Mehsana on 25 March 1879 and was named Narayan by his parents Bhabhaldas Khemchand Nayak and Narbhiben. He studied till the fifth standard in the Gujarati school in his native village Undhai. He was nicknamed Bapulal by his father. In Februatry 1890, at the age of eleven, he quit the family tradition of performing Bhavai (folk theatre) and farming, and started his stage career with Dayashankar Visanji's Mumbai Gujarati Natak Mandali for a salary of three rupees per month. He given a role of Jayant, son of Indra, in a play, \"Harishchandra\" (1890). He next appeared in \"Rajbeej\" (King's Progeny, 1891), a play written by Mulshankar Mulani specifically for him which premiered at the Geity Theatre in Bombay. It was successful. His performance as Mularaja in \"Mularaj Solanki\" (1895) was well received. In the next decade, he acted \"Ramcharitra\" (1989), Raman in \"Lakshadhipati-no Raman\", \"Jayraj\" (1898) and other plays, as well as becoming involved in stage planning and the management of a theatre company. In 1899, he and Mulani became partners in the company, each holding a 6% share of the Mumbai Gujarati Natak Mandali. He also acted in the acclaimed play, \"Ajabkumari\" (1899), opposite female impersonator actor Jaishankar Bhojak 'Sundari' who had recently joined their company. The pair soon rose to fame and acted together in several successful plays including \"Saubhagya Sundari\" (Fortunate Sundari, 1901), \"Vikram Charitra\" (1901, directed by him), \"Dage Hasrat\" (1901), \"Jugal Jugari\" (Jugal the Gambler, 1903), \"Kamlata\" (1904), \"Sneh Sarita\" (1915), \"Madhubansari\" (1917). Around the end of the 19th-century, he was guided by Mulshankar and Dayashankar Visanji. He learned direction from Sorabji Katrak. He trained many actors as well.\n\n\"Nand-Batrisi\" (1906) was a first play written by him which was well received. He also wrote \"Chandrabhaga\" (1909), a farce entitled \"Navalsha Hirji\" (1909), \"Anandlahari\" (1919) and \"Saubhagya-no Sinh\" (1925). When Mulani's three plays failed consequently, he chose to stage nationalistic plays written by Nrisinh Vibhakar. These plays experimented with story and theme but enactment stayed unchanged. During this period, Mahatma Gandhi had arrived in India from South Africa and the Indian independence movement was gathering steam. He acquired Mumbai Gujarati Natak Mandali in April 1922.\n\nBapulal Nayak started directing his plays and started adapting literature into plays. He chose Ramanbhai Neelkanth's play \"Raino Parvat\" written in 1911 and staged it in 1926. The songs of the play were written by Rasiklal Parikh and four shows of it were staged. Later he staged four plays written by Champshi Udeshi, four plays written by Gajendrashankar Pandya as well as many Parsi theatre styled plays. Gajendrashankar Pandya's play \"College Kanya\" was staged by Bapulal and it created controversy due to some of its dialogue about females; Narsinhrao Divetia, Chandravadan Mehta and Hansa Jivraj Mehta led the public protests against the play.\n\nWith the advent of the cinema, the theatre started to lose its audience. Bapulal was forced to sell his company in 1938 due to it suffering heavy losses. In 1944, he tried to revive his company with the help of a financier. He retired after staging his last play \"Ladakvayo\", written by Prafulla Desai, in 1946. He had acted in more than a hundred plays, directed forty seven plays and written six plays during his career. He also wrote some poems. He died on 4 December 1947 in Undhai near Mehsana, Baroda State.\n\nRasiklal Parikh, Chandravadan Mehta and Pragji Dosa have praised the excellence of his directing.\n"}
{"id": "32198893", "url": "https://en.wikipedia.org/wiki?curid=32198893", "title": "Brajanath Ratha", "text": "Brajanath Ratha\n\nBrajanath Ratha (12 January 1936 – 31 May 2014) was an Indian poet who wrote in Odia. Brajanath Ratha is internationally recognised and is the recipient of many prestigious awards like the Odisha Sahitya Academy Award, Vishuba Award, Gokarnika Award, First Shudramuni Sahitya Award and Honoured by South Korea's Ambassador, from Global Cooperation Society International, Seol, Republic of Korea for Contribution in World welfare, Cooperation and Services.\n\nRatha awarded Tagore Literature Awards in 2010 for Samanya Asamanya, a poetry collection containing three types of poems: progressive, satirical and philosophical. This unique collection carries the message of hope to mankind. His first poem was written to welcome India's independence in 1947. He has been conferred with the highest honours from the Odisha Sahitya Academy Award for Manara Manachitra (Map of the Mind) to the Silver Jubilee Award for poetry by Prajatantra Prachar Samiti, Cuttack.\n\n\n\n\n"}
{"id": "17344429", "url": "https://en.wikipedia.org/wiki?curid=17344429", "title": "Buddha Sayami", "text": "Buddha Sayami\n\nBuddha Sayami (; 1944 – 26 December 2016) was a Nepalese poet and Newar politician, born in Kathmandu. He wrote poetry in Nepal Bhasa, the Newari language. Sayami was the president of Newaa Deygoo. He was awarded with Rastriya Pratibha Puraskar and was elected in 2008 as representative to the Constituent Assembly election by the Nepa Rastriya Party. He died at a hospital in Jawalakhel in 2016 at the age of 72, from complications of diabetes.\n"}
{"id": "41668914", "url": "https://en.wikipedia.org/wiki?curid=41668914", "title": "Center for the Evaluation of Language and Communication Technologies", "text": "Center for the Evaluation of Language and Communication Technologies\n\nThe Center for the Evaluation of Language and Communication Technologies (CELCT) was an organisation devoted to the evaluation of language technologies, located in Povo, Trento (Italy).\n\nCELCT was established in 2003 by FBK (Fondazione Bruno Kessler) and DFKI (Deutsches Forschungszentrum für Künstliche Intelligenz), and was funded by the Autonomous Province of Trento. The goals of CELCT were \"to set up infrastructures and develop skills in order to operate successfully in the field of the evaluation of language and communication technologies, becoming a reference point in the field at the national and European levels.\"\nCELCT interpreted its mission by carrying out several activities in the field of HLT evaluation, mainly focusing on the organization of national and international evaluation campaigns and on the creation of speech and text corpora in different languages and at different linguistic annotation levels.\n\nCELCT's activities were closed on December 31, 2013. The staff working at CELCT at the time of its closure is continuing their research activities within FBK.\n\n\n\nCELCT was involved in the following initiatives devoted to the evaluation of Natural Language Processing tools, collaborating with various organizations and networks of excellence both at the national and international level:\n\nCELCT produced a number of scientific publications in all its activity fields.\n"}
{"id": "3675986", "url": "https://en.wikipedia.org/wiki?curid=3675986", "title": "Citrus Project", "text": "Citrus Project\n\nThe CITRUS (Comprehensive I18N Framework Towards Respectable Unix Systems) project aims to implement a complete multilingual programming environment for BSD-based operating systems. The goals include the creation of the following things for FreeBSD, NetBSD, OpenBSD, BSD/OS and DragonFly BSD:\n\n\n, the aim is to reach the same level of functionality as Solaris 7.\n\n"}
{"id": "2037473", "url": "https://en.wikipedia.org/wiki?curid=2037473", "title": "Clerical script", "text": "Clerical script\n\nThe clerical script (; Japanese: 隷書体, \"reishotai\"; Vietnamese: lệ thư), also formerly chancery script, is an archaic style of Chinese calligraphy which evolved from the Warring States period to the Qin dynasty, was dominant in the Han dynasty, and remained in use through the Wei-Jin periods. Due to its high legibility to modern readers, it is still used for artistic flavor in a variety of functional applications such as headlines, signboards, and advertisements. This legibility stems from the highly rectilinear structure, a feature shared with modern regular script (kaishu). In structure and rectilinearity, it is generally similar to the modern script; however, in contrast with the tall to square modern script, it tends to be square to wide, and often has a pronounced, wavelike flaring of isolated major strokes, especially a dominant rightward or downward diagonal stroke. Some structures are also archaic.\n\nClerical script is popularly but mistakenly thought to have developed or been invented in the early Han dynasty from the small seal script. The process of change between small seal script and clerical script is referred to as the \"Libian\" (lit: Clerical Evolution) (隸變). There are also historical traditions dating to the Hàn dynasty which mistakenly attributed the creation of clerical script to the Qín dynasty and in particular to Chéng Miǎo, who was said to have invented it at the behest of Qin Shi Huang. Another traditional account is that it was invented by government scribes, in particular those involved in the justice and penal systems. However, from written materials unearthed by archaeologists, it is now known that \"all\" stages of Chinese writing underwent periods of natural evolution, and none of them were inventions by one person; this is true of clerical script as well. Furthermore, rather than being established by government scribes, it has been argued that clerical script was already in popular use, and the Qín dynasty use by scribes merely reflects this trend. Archaeological discoveries now clearly show that an immature form of clerical script (\"proto-clerical\") was already developing in the state of Qín during the Warring States period, and into the early Western Hàn; this can be seen on a number of bamboo books unearthed recently. Furthermore, the writing immediately preceding clerical script was not merely seal script alone; rather, there was a coexistence of seal script (the at-first dominant and formal style) alongside an increasingly popular but secondary form of \"vulgar\", \"popular\", or \"common\" writing, which was very roughly executed and which was generally rectilinear. The popularity of this vulgar writing grew as the use of writing itself became more widespread. The structures and style of many of the characters executed in this vulgar writing were similar or even identical to their later clerical script counterparts, leading some to conclude that proto-clerical (and therefore clerical) script evolved not from seal script but from the vulgar writing of Qín, which coexisted with seal script in Warring States to Qín dynasty. The Qín bamboo script is a good example of this transition, having evolved from vulgar Qín writing and considered by some to constitute Qín clerical script.\n\nThe etymology of the Chinese name for the script lìshū () is uncertain. \"Lì\" meant a slave or prisoner serving the state, and thus, some infer that the script was used in recording the affairs related to such slaves, while others infer that it was used by prisoners conscripted as scribes.\n\nDuring Warring States, proto-clerical script emerged in casual, informal usage. During the Qin dynasty it appears to have also been used in some scribal capacity, but never in formal usage. Maturing into clerical script in the early Han, it soon became the dominant script for general purposes, while seal script remained in use for the most formal purposes such as some stelae, signet seals (name chops), and especially the titles of written works and stelae; some cursive was also in use at the time. At roughly the same time, the clerical script was used and inscribed onto many stelae which later influenced subsequent development of Chinese calligraphic styles. Out of clerical script, a new form then emerged in the middle of the Eastern Han dynasty, which Qiu (2000, p. 113) terms \"neo-clerical\" script; it was from this neo-clerical and from cursive that by late in the Eastern Han semi-cursive would then evolve, out of which then emerged the modern standard script. Thus, according to Qiu, the evolution from clerical script to standard script was not a direct step as commonly supposed.\n\n"}
{"id": "30230830", "url": "https://en.wikipedia.org/wiki?curid=30230830", "title": "Clientelism", "text": "Clientelism\n\nClientelism is the exchange of goods and services for political support, often involving an implicit or explicit quid-pro-quo. Clientelism involves an asymmetric relationship between groups of political actors described as \"patrons, brokers\", and \"clients\". Richard Graham has defined clientelism as a set of actions based on the principle \"take there, give here\", with the practice allowing both clients and patrons to gain advantage from the other's support. Moreover, clientelism is typified by \"exchange systems where voters trade political support for various outputs of the public decision-making process\".\n\nThe origin of the practice has been traced to ancient Rome. Here relationships between the patron \"(patronus)\" and client \"(cliens)\" were seen as crucial to understanding the political process. While the obligations between these were mutual, the key point is they were hierarchical. These relationships might be best viewed not as an entity but rather as a network \"(clientela)\", with the \"patronus\" himself perhaps being obligated to someone of greater power, and the \"cliens\" perhaps having more than one patron. These extensions increase the possibilities of conflicting interests arising. While the \"familia\" was the basic unit underlying Roman society, the interlocking networks \"(clientela)\" acted as restrictions on their autonomy but allowed a more complex society to develop. Historians of the late medieval period evolved the concept into bastard feudalism. There is, as is usual, ambiguity in the use of political terminology and the terms \"clientelism\", the \"patron-client relationship\", \"patronage\" and the political machine are sometimes used to describe similar or related concepts.\n\nThe reigns of Julius Caesar (49-44 BCE) and Tiberius (14-16 AD) have been characterized as examples of widespread clientelism. In the 1500s, French political theorist Étienne de La Boétie did not use the term \"clientelism\", but described the practice of emperors who used gifts to the public to gain loyalty from those who were eager to accept what amounted to bribery:\n\nStokes et al. distinguish clientelism as a form of non-programmatic policy within distributive politics. It meets the criteria through failing to meet the two requirements of programmatic distribution, that are (1) 'formalized and public' and (2) 'shape actual distribution of benefits or resources'. Within non-programmatic policy, clientelism is then distinguished from 'pork-barrel politics' in that voters are given a benefit or are able to avoid a cost conditional on their returning the favor with a vote. The patron/client system can be defined as a mutual arrangement between a person that has authority, social status, wealth, or some other personal resource (patron) and another who benefits from their support or influence (client). The patron provides selective access to goods and opportunities, and place themselves or their support in positions from which they can divert resources and services in their favor. Their partners-clients- are expected to buy support, and in some cases, votes. Patrons target low-income families to exchange their needed resources for their abundant resources: time, a vote, and insertion into networks of other potential supporters whom they can influence. However, patrons are unable to access the information needed to effectively form the exchange; thus they hire intermediaries, brokers, that more equipped to find out what the targeted voter needs, which voters will require less prodding, and if the voter followed through on their end of the bargain. As Stokes, Dunning, Nazareno, and Brusco emphasize, brokers in turn serve political leaders, and they may also not target resources exactly as leaders would wish; the resulting principal-agent problems can have important implications for understanding how clientelism works.\n\nPatronage, turnout buying, abstention buying, and vote buying are subcategories of clientelism. Patronage refers to an intra-party flow of benefits to members. Turnout buying, coined by Nichter, treats or bribes voters to the polls whereas abstention buying treats or bribes voters to keep them from going to the polls. Vote buying is a direct transfer of goods or services, in exchange for one's support and vote. The result for the good or service is a question of did you or will you vote for me?\nA key to understanding clientelism might come in stressing not only the mutually beneficial relationships of exchange but also asymmetries in power or standing. Implied is a certain selectivity in access to key resources and markets. Those with access, the \"patrons\" (and/or sometimes \"sub-patrons\" or \"brokers\") rely on the subordination and dependence of the clients. In return for receiving some benefits the clients should provide political support.\n\nStokes' research on clientelism in Argentina assumed that the Peronist party was providing financial support to prospective voters to buy their votes. It was hypothesized that Peronists targeted moderately opposed voters because they were thought to be easily persuaded to change sides at the party's minimal expense. Stokes elaborated on the need of the Argentinian Peronist party to be able to track who their clientele in fact voted for amidst the secret ballot system. Stokes' argument is that the potential for vote buying depends on the accuracy with which the patron party, the Peronists in the case of Argentina, are able to monitor votes. She uses evidence to show that overall smaller communities offer less anonymity, making it easier for the patrons to find out who committed to supporting them. Thus, Stokes concludes that this is one of the reasons why vote buying is more frequent in relatively small communities. Another reason is that smaller communities are generally more poor. Furthermore, smaller communities, which are generally more poor and have a greater need for resources, are a more attractive target.\n\nResearch by Nichter promoted a simpler hypothesis for the Argentinian election cycle: to prove Peronists were solely buying supporting voters' turnout, not all the people's votes. He dismissed Stokes' arguments on patrons spying on smaller and poorer communities, instead saying the Peronists initially targeted votes assumed to be their strong supporters. In this case the patrons would be reasonably sure they receive a vote from a person if this person receives a good from them.\n\nNumerous factors which lead to a clientelist political system have been identified. One large one is poverty. As the wealth of the average citizen increases, patrons must spend greater and greater sums of money to gain their votes. Therefore, clientelist strategies are most effective in societies with a prevalence of poverty, when the cost of giving constituents gifts is low. What is more, the electoral system also heavily affects the viability of clientelism. Candidate-focused elections allow patrons to enforce direct trades of support for favors flowing from office. This helps foster personal relationships necessary in clientelism. In more politicized bureaucracies, elected officials have greater control over government services, meaning that patrons are better able to redirect public resources to their constituencies.\n\nIn short, clientelism is much more likely to occur in high poverty states where elections are personalized and elected officials have large control over public resources.\n\nClientelism has generally negative consequences on democracy and government while also having more uncertain consequences on the economy.\n\nThe accountability relationship in a democracy, where voters hold elected officials accountable for their actions, is undermined by clientelism. This is because under clientelism, votes are contingent on gifts to clients rather than the performance of elected officials in office. Clientelism also degrades democratic institutions such as the secret ballot and administrative oversight. These factors both weaken democratic institutions and negatively impact the efficiency of government.\n\nCorruption and the perception of corruption have also been established as strongly correlated with clientelist systems. There are many reasons for this. For one, patrons often appear above the law in many clientelist systems. What is more, some acts in clientelist systems such as vote buying, could be inherently illegal. Finally, resources needed for patrons to maintain the clientelist system could necessitate illicit means of obtaining goods.\n\nSome scholars believe that because patrons focus on the control and procurement of private goods, they also neglect public goods such as roads and public schools which aid economic development. Scholars also note that rent seeking and corruption, prevalent in clientelist systems, could negatively impact the economy as well. Nevertheless, there is still great uncertainty in the economic effects of clientelism.\n\nIt is common to link clientelism with corruption; both involve political actors using public and private resources for personal gain, but they are not synonymous. Corruption is commonly defined as \"dishonest and fraudulent conduct by those in power, typically involving bribery\", while political clientelism is seen as \"the distribution of benefits targeted to individuals or groups in exchange for electoral support\". It is common to associate the two together because they moderately overlap. There are different forms of corruptions that have nothing to do with clientelism, such as voter intimidation or ballot stuffing. \"Clientelism is considered negative because its intention is to generate 'private' revenue for patrons and clients and, as a result obstruct 'public' revenue for members of the general community who are not a part of the patron-client arrangement.\"\n\nClientelism as a strategy of political organisation is substantially different from other strategies which rely on appeals to wider programmatic objectives or simply emphasize higher degrees of competence. It is often assumed that clientelism is a vestige of political underdevelopment, a form of corruption, and that political modernization will reduce or end it. But alternative views stressing the persistence of clientelism – and the patronage associated with it – have been recognized.\n\n"}
{"id": "10249042", "url": "https://en.wikipedia.org/wiki?curid=10249042", "title": "Coaxial power connector", "text": "Coaxial power connector\n\nA coaxial power connector is an electrical power connector used for attaching extra-low voltage devices such as consumer electronics to external electricity. Also known as barrel connectors, concentric barrel connectors or tip connectors, these small cylindrical connectors come in an enormous variety of sizes.\n\nBarrel plug connectors are commonly used to interface the secondary side of a power supply with the device. Some of these jacks contain a normally closed switch; the switch can disconnect internal batteries whenever the external power supply is connected.\n\nThe connector pairs for barrel connectors are defined in terms of 'plugs' and 'receptacles'; receptacles are more commonly called 'sockets' or 'jacks' (US). Receptacles may be panel-mounted or circuit board-mounted. Plugs are on cables. Some 'in-line' receptacles are also cable-mounted.\n\nThere is a long history in electrical engineering of referring to such power plugs\"—that is to say, plugs with holes instead of prongs—\"as female, particularly regarding coaxial transmission of electricity. Type N connectors, and all EC 60320#Appliance couplers IEC 60320 \"appliance coupler\" plugs are examples of this. That said, while IEC 60320 provides gender-based standards for higher-voltage plugs (such as the cable plugged into a standard computer power supply), they have not yet defined gender-based standards for low-voltage coaxial power connectors such as those discussed herein; I.E., which component is \"male\" and which \"female.\" As a result, there are varying opinions in this regard. Many industrial suppliers avoid gender terminology but many do not. Similarly, some people view the corded plug as female and some perceive it as male. Some, after consideration and surveys, found that user perception of which was male and which female was evenly split.\n\nPower is generally supplied \"by\" a plug \"to\" a receptacle. Cables are available with one in-line receptacle fanning out to a number of plugs, so that many devices may be supplied by one supply. As the use of a plug implies a cable, even a short stub, some power supplies carry panel-mounted receptacles instead to avoid this cable, i.e. the normal convention of power from plug to receptacle is reversed. Cables for such cases are available with a plug at each end, although cables or adapters with two \"receptacles\" are not widely available.\n\nOn the female plug, the outer body is metallic and cylindrical in shape, and comprises one of the two contacts. The second, inside contact is a hollow metallic cylinder constructed to accept insertion of the pin in the corresponding male connector. The inner and outer barrels are separated by an insulating layer. The outer contact is generally called the barrel, sleeve or ring, and the inner contact is called the tip.\n\nThere is typically a single spring-loaded contact at the side of the male connector and a pin in the center corresponding to the intended female plug.\n\nThere are many different sizes of coaxial power connectors (see table at end of this article).\n\nContact ratings commonly vary from unspecified up to 5 amperes (11 amperes for special high-power versions). Voltage is often unspecified, but may be up to 48V with 12V typical. The smaller types usually have lower current and voltage ratings.\n\nIt is quite possible that new sizes will continue to appear and disappear. One possible reason that a particular manufacturer may use a new size is to discourage use of third-party power supplies, either for technical reasons or to force use of their own accessories, or both.\n\nThe sizes and shapes of connectors do not consistently correspond to the same power specifications across manufacturers and models. Two connectors from different manufacturers with different sizes could potentially be attached to power supplies with the same voltage and current. Alternatively, connectors of the same size can be part of power supplies with different voltages and currents. Use of the wrong power supply may cause severe equipment damage, or even fire.\n\nGeneric plugs are often described by their inside diameter, such as \"2.1mm DC plugs\" and \"2.5mm DC (direct current) plugs\".\n\nAfter the two common 5.5mm OD (outer diameter) plugs, the next-most common size is 3.5mm OD with a 1.3mm ID (inner diameter), usually about 9.5mm in length, although both longer and shorter versions also exist. These 3.5mm OD plugs are normally used for lower voltages and currents.\n\nA ring-shaped 'locking detent' or 'high-retention feature', present on the barrel of some DC coaxial connectors, is a feature intended to prevent accidental disconnection. Typically, this feature is a conical cut-back section of the tip, just behind the insulator that separates the inner from outer contact surfaces.\n\nA 'lock-ring DC coaxial connector' uses a captive threaded ring or collar to secure the connection between the plug and jack. This design offers strong resistance to unplugging when used properly.\nA 'lock-tab DC coaxial connector' (also called 'bayonet lock') offers a compromise that resists unplugging, but which will disengage when pulled hard enough. This connector uses small metal tab protrusions on the connector barrel to lock the plug in place, requiring a special push-and-rotate motion to engage the locks.\n\nThere are several standards in existence, such as IEC, EIAJ in Japan and DIN in Germany. More recently, some manufacturers appear to have implemented their own system correlating voltage and plug size. In addition, there appears to be a trend to standardize DC connector to negative barrel (or sleeve) of a coaxial power connector.\n\nIEC 60130-10:1971 defines five DC power connectors.\n\n\nFive plug and matching socket or jack designs are defined by the EIAJ standard RC-5320A (also called JEITA RC-5320A). Each of these plugs is used with a specified voltage range. Most manufacturers use a yellow insulating material to distinguish these plugs from other similar-looking DC plugs.\n\n\nEIAJ-04 and 05 have an internal male pin in the plug. The 01 through 03 sizes do not and are similar to the generic plugs in structure. These five EIAJ plugs are 9.5 mm in length and have a current rating of 2A.\n\nThere are two other, less common, connectors defined by EIAJ; RC-5321 and RC-5322. The latter is designed for both 12 V and 24 V automotive applications.\n\nThe German national standards organization DIN (Deutsches Institut für Normung—German Institute for Standardization) issued DIN 45323, which defines two DC power plug and jack (respectively) sizes. At least one of these sizes has a maximum rating of 34 V and 3 A. The information here is inferred from catalog references, as the German standard has not been translated into English yet.\n\n\nThis list attempts to show all known sizes, and is annotated with some manufacturers producing selected types, since each manufacturer makes its own unique subset of the known types. Note that the example part numbers given may have different connector barrel (sleeve) lengths, and are not necessarily exact equivalents. There are many more design variants than can be listed in this table, so only a small sampling of part numbers is given.\n\nConnector size is often listed in the format OD (outer diameter) x ID (inner diameter) x L (length of barrel) and expressed in millimeters. Designations may vary between manufacturers.\n\nCoaxial plugs that have a male center pin will have another measurement, Center Pin Diameter (CPD). These plugs are often used for higher power applications such as portable computers.\n\nThere are a number of sizes listed below that appear to be quite similar, and while the tolerances of these connectors are typically indicated as ±0.05 or ±0.03 mm by the manufacturers, there is still ambiguity as to whether two sizes differing by only 0.05 mm (or where the specification is only given to the nearest 0.10 mm) warrants listing them separately here.\nRadioShack sold a line of adapter plugs for universal AC adapters. Each \"Adaptaplug\" had a single-letter code, but did not provide any other official designation, nor did RadioShack publish the complete specifications and tolerances on barrel and pin dimensions. RadioShack's web site listed the diameters to the nearest 0.1 mm, and sometimes differs slightly from the official EIAJ RC-5320A standard dimensions. This list may include some parts RadioShack has discontinued but are retained here for completeness.\n\n\n"}
{"id": "23944214", "url": "https://en.wikipedia.org/wiki?curid=23944214", "title": "Codex Vaticanus Ottobonianus Latinus 1829", "text": "Codex Vaticanus Ottobonianus Latinus 1829\n\nCodex Vaticanus Ottobonianus Latinus 1829 is one of the three most important manuscripts preserving the poems of Catullus. Among students of the matter it is commonly known as Codex Romanus (or \"R\").\n\nIt is a Latin manuscript, written in Gothic minuscule script on parchment, dated to around 1390. It consists of 40 leaves (80 pages), 37 of them containing the poems of Catullus. It is the youngest of the three most important manuscripts of Catullus, the other two being: \"codex Oxoniensis\" (O) preserved in the Bodleian Library in Oxford and \"codex Sangermanensis\" (G) in the Bibliothèque nationale de France in Paris. Considering the stemma codicum, the Vatican codex is of the same rank as the latter one (the Oxford manuscript being one step closer to the lost archetype, known as \"codex Veronensis\" or \"V\").\n\nThe first owner of the manuscript was an Italian humanist, Coluccio Salutati. Yet in the middle 16th century Achilles Statius in his edition of Catullan poems shows the acquaintance with this codex. Later the codex was lost: it was probably housed in the Vatican Library for a very long time, hidden under a false catalogue number, until it was rediscovered in 1896 by William Gardner Hale. Hale promised to collate the codex, but failed to do so before his death in 1928 - this in turn delayed the now general acceptance of R as one of the first rank Catullan codices. The codex has finally been collated by a Canadian scholar D. F. S. Thomson in 1970.\n\n\n"}
{"id": "394976", "url": "https://en.wikipedia.org/wiki?curid=394976", "title": "Culture shock", "text": "Culture shock\n\nCulture shock is an experience a person may have when one moves to a cultural environment which is different from one's own; it is also the personal disorientation a person may feel when experiencing an unfamiliar way of life due to immigration or a visit to a new country, a move between social environments, or simply transition to another type of life. One of the most common causes of culture shock involves individuals in a foreign environment. Culture shock can be described as consisting of at least one of four distinct phases: honeymoon, negotiation, adjustment, and adaptation. \n\nCommon problems include: information overload, language barrier, generation gap, technology gap, skill interdependence, formulation dependency, homesickness (cultural), boredom (job dependency), response ability (cultural skill set). There is no true way to entirely prevent culture shock, as individuals in any society are personally affected by cultural contrasts differently.\n\nDuring this period, the differences between the old and new culture are seen in a romantic light. For example, in moving to a new country, an individual might love the new food, the pace of life, and the locals' habits. During the first few weeks, most people are fascinated by the new culture. They associate with nationals who speak their language, and who are polite to the foreigners. Like most honeymoon periods, this stage eventually ends.\n\nAfter some time (usually around three months, depending on the individual), differences between the old and new culture become apparent and may create anxiety. Excitement may eventually give way to unpleasant feelings of frustration and anger as one continues to experience unfavorable events that may be perceived as strange and offensive to one's cultural attitude. Language barriers, stark differences in public hygiene, traffic safety, food accessibility and quality may heighten the sense of disconnection from the surroundings.\n\nWhile being transferred into a different environment puts special pressure on communication skills, there are practical difficulties to overcome, such as circadian rhythm disruption that often leads to insomnia and daylight drowsiness; adaptation of gut flora to different bacteria levels and concentrations in food and water; difficulty in seeking treatment for illness, as medicines may have different names from the native country's and the same active ingredients might be hard to recognize.\n\nStill, the most important change in the period is communication: People adjusting to a new culture often feel lonely and homesick because they are not yet used to the new environment and meet people with whom they are not familiar every day. The language barrier may become a major obstacle in creating new relationships: special attention must be paid to one's and others' culture-specific body language signs, linguistic faux pas, conversation tone, linguistic nuances and customs, and false friends. \n\nIn the case of students studying abroad, some develop additional symptoms of loneliness that ultimately affect their lifestyles as a whole. Due to the strain of living in a different country without parental support, international students often feel anxious and feel more pressure while adjusting to new cultures—even more so when the cultural distances are wide, as patterns of logic and speech are different and a special emphasis is put on rhetoric.\n\nAgain, after some time (usually 6 to 12 months), one grows accustomed to the new culture and develops routines. One knows what to expect in most situations and the host country no longer feels all that new. One becomes concerned with basic living again, and things become more \"normal\". One starts to develop problem-solving skills for dealing with the culture and begins to accept the culture's ways with a positive attitude. The culture begins to make sense, and negative reactions and responses to the culture are reduced.\n\nIn the mastery stage individuals are able to participate fully and comfortably in the host culture. Mastery does not mean total conversion; people often keep many traits from their earlier culture, such as accents and languages. It is often referred to as the bicultural stage.\n\nReverse culture shock (also known as \"re-entry shock\" or \"own culture shock\") may take place—returning to one's home culture after growing accustomed to a new one can produce the same effects as described above. These are results from the psychosomatic and psychological consequences of the readjustment process to the primary culture. The affected person often finds this more surprising and difficult to deal with than the original culture shock. This phenomenon, the reactions that members of the re-entered culture exhibit toward the re-entrant, and the inevitability of the two are encapsulated in the following saying, which is also the title of a book by Thomas Wolfe, \"You Can't Go Home Again\".\n\nReverse culture shock is generally made up of two parts: idealization and expectations. When an extended period of time is spent abroad we focus on the good from our past, cut out the bad, and create an idealized version of the past. Secondly, once removed from our familiar setting and placed in a foreign one we incorrectly assume that our previous world has not changed. We expect things to remain exactly the same as when we left them. The realization that life back home is now different, that the world has continued without us, and the process of readjusting to these new conditions as well as actualizing our new perceptions about the world with our old way of living causes discomfort and psychological anguish. \n\nThere are three basic outcomes of the Adjustment Phase:\n\nCulture shock has many different effects, time spans, and degrees of severity. Many people are handicapped by its presence and do not recognize what is bothering them.\n\nCulture shock is a subcategory of a more universal construct called transition shock. Transition shock is a state of loss and disorientation predicated by a change in one's familiar environment that requires adjustment. There are many symptoms of transition shock, including:\n\n"}
{"id": "4472307", "url": "https://en.wikipedia.org/wiki?curid=4472307", "title": "Domari language", "text": "Domari language\n\nDomari is an endangered Indic language, spoken by older Dom people scattered across the Middle East and North Africa. The language is reported to be spoken as far north as Azerbaijan and as far south as central Sudan, in Turkey, Iran, Iraq, Palestine, Israel, Jordan, Egypt, Sudan, Libya, Tunisia, Algeria, Morocco, Syria and Lebanon. Based on the systematicity of sound changes, we know with a fair degree of certainty that the names \"Domari\" and \"Romani\" derive from the Indic word \"ḍom\". The language itself actually derives from an Indo-Aryan language. It shares many similarities to Punjabi and Rajasthani, two languages that originated in India. The Arabs referred to them as \"nawar\" as they were a nomadic people that originally immigrated to the Middle East from India.\n\nDomari is also known as \"Middle Eastern Romani\", \"Tsigene\", \"Luti\", or \"Mehtar\". There is no standard written form. In the Arab world, it is occasionally written using the Arabic script and has many Arabic and Persian loanwords. Descriptive work was done by Yaron Matras, who published a comprehensive grammar of the language along with an historical and dialectological evaluation of secondary sources (Matras 2012).\n\nDomari is an endangered language and is currently being shifted away from in younger generations, according to Yaron Matras. In certain areas such as Jerusalem, only about 20% of these Dom people, known as “Middle Eastern Gypsies”, speak the Domari language in everyday interactions. The language is mainly spoken by the elderly in the Jerusalem community. The younger generation are more influenced by Arabic, therefore most only know basic words and phrases. The modern-day community of Doms in Jerusalem was established by the nomadic people deciding to settle inside the Old City from 1940 until it came under Israeli administration in 1967 (Matras 1999).\n\nThe best-known variety of Domari is Palestinian Domari, also known as \"Syrian Gypsy\", the dialect of the Dom community of Jerusalem, which was described by R.A. S. Macalister in the 1910s. Palestinian Domari is an endangered language, with fewer than 200 speakers, the majority of the 1,200 members of the Jerusalem Domari community being native speakers of Palestinian Arabic.\n\nOther dialects include:\n\nSome dialects may be highly divergent and not mutually intelligible. Published sources often lump together dialects of Domari and the various unrelated in-group vocabularies of diverse peripatetic populations in the Middle East. Thus there is no evidence at all that the Lyuli, for example, speak a dialect of Domari, not is there any obvious connection between Domari and the vocabulary used by the Helebi of Egypt (see discussion in Matras 2012, chapter 1).\n\nThe small Seb Seliyer language of Iran is distinctive in its core vocabulary.\n\nJerusalem Domari is fluently spoken only among the elder generation in the \"Dom\" community. These nomadic people have been bilingual for many generations, however recently there has been a language shift towards the dominant geographic language, Arabic. In the 1940s, the Dom began to abandon their nomadic culture and began settling and working in the local economy. This led to the next phenomenon, the assimilation of \"Dom\" children in the primary school system which marked the first generation to grow up in an academic environment alongside Arab children. Consequently, this 1940 generation do not fluently speak the Domari language. Arabic replaced their native Domari and became the language of cross-generation communication. In Jerusalem, it is estimated that there are about 600-900 members of the \"Dom\" population in Jerusalem. Less than 10% can effectively communicate in Jerusalem Domari.\n\nDomari was once thought to be the \"sister language\" of Romani, the two languages having split after the departure from the Indian subcontinent, but more recent research suggests that the differences between them are significant enough to treat them as two separate languages within the Central zone (Hindustani) group of languages. The Dom and the Rom are therefore likely to be descendants of two different migration waves out of India, separated by several centuries.\n\nThere are nevertheless remarkable similarities between the two beyond their shared Central zone Indic origin, indicating a period of shared history as itinerant populations in the Middle East. These include shared archaisms that have been lost in the Central Indo-Aryan languages over the millennium since Dom/Rom emigration, a series of innovations connecting them with the Northwestern zone group, indicating their route of migration out of India, and finally a number of radical syntactical changes due to superstrate influence of Middle Eastern languages, including Persian, Arabic and Byzantine Greek.\n\nSince Domari is a minority Middle-Eastern language for a specific community of speakers, it did not have a standard orthography for many years; therefore many writers have used differing spelling systems (similarly to what happened with Ladino). Most Middle-Easterners used the Arabic script, while scholars made do with a modified Pan-Vlakh Latin-based alphabet.\n\nIn 2012, Yaron Matras used such a system in his recent publications on this subject where the Pan-Vlakh orthography served as a basis, with several modifications:\n\nA new Semitic-flavored Latin-based pan-alphabet has recently been introduced by some scholars for the purpose of codifying written Domari.\n\nThe Pan-Domari Alphabet, which was invented in 2015, is a Semitic-flavored simplification of the previous Matras notation:\n\nThe Pan-Domari Alphabet is shown in this table:\n\"NOTES\"\n\n§ Spelling alternates are shown for certain of these sounds (i.e.: when typing on an ASCII or typeweriter keyboard, or when/where computers cannot show the proper accented Domari letters); these alternates are also used on the KURI’s \"Learn Domari\" article series.\n\n\nThere are five main vowel sounds, however this inventory shows the variation and quantity of short vowels. Most are interchangeable with a vowel sound next to it, however all of the sounds produced above are identical to the local Palestinian Arabic (Matras 1999).\nMost of these consonants are influenced by Palestinian Arabic such as gemination; however, consonants such as [p], [g], [tʃ] and [h] are not found in the local dialect. There is speculation among linguists that these sounds are considered a part of the pre-Arabic component. Alveopalatal affricates such as [tʃ] and [dʒ] are also consonants that differ in sound from Arabic.\nThe biggest difference in expression of language between Arabic and Domari is where the stress is placed. Arabic has phoneme-level stress while Domari is a language of word-level stress. The Domari language emphasizes stress on the final syllable, as well as grammatical markers for gender and number. Most nouns, besides proper nouns, adopted from Arabic sound distinct because of the unique stresses in Domari (Matras 1999). Domari is thought to have borrowed a lot of words and grammatical structure from Arabic; however, this is not entirely true. Complex verbs and most core prepositions did not transfer into the realms of grammar of the Domari language. The syntactic typology remains independent of Arabic influence. It also important to note that the numerals used by the \"Doms\" were inherited from Kurdish. Even though Domari was influenced by local Arabic, the language also felt the impacts of Kurdish and certain dialects of Iranian in the grammar of the language.\n\nHere is a table of the numerals (1-10, 20, and 100) in Hindi, Romani, Domari, Lomavren, and Persian for comparison.\n\n"}
{"id": "3717895", "url": "https://en.wikipedia.org/wiki?curid=3717895", "title": "Edgeworth conjecture", "text": "Edgeworth conjecture\n\nIn economics, the Edgeworth conjecture is the idea, named after Francis Ysidro Edgeworth, that the core of an economy shrinks to the set of Walrasian equilibria as the number of agents increases to infinity.\n\nThe core of an economy is a concept from cooperative game theory defined as the set of feasible allocations in an economy that cannot be improved upon by subset of the set of the economy's consumers (a coalition). For general equilibrium economies typically the core is non-empty (there is at least one feasible allocation) but also \"large\" in the sense that there may be a continuum of feasible allocations that satisfy the requirements. The conjecture basically states that if the number of agents is also \"large\" then the only allocations in the core are precisely what a competitive market would produce. As such, the conjecture is seen as providing some game-theoretic foundations for the usual assumption in general equilibrium theory of price taking agents. In particular, it means that in a \"large\" economy people act as if they were price takers, even though theoretically they have all the power to set prices and renegotiate their trades. Hence, the fictitious Walrasian auctioneer of general equilibrium, while strictly speaking completely unrealistic, can be seen as a \"short-cut\" to getting the right answer.\n\nEdgeworth himself did not quite prove this result—hence the term \"conjecture\" rather than \"theorem\"—although he did provide most of the necessary intuition and went some way towards it. In the 1960s formal proofs were presented under different assumptions by Debreu and Scarf (1963) as well as Aumann (1964). Both of these results however showed that the conditions sufficient for this result to hold were a bit more stringent than Edgeworth anticipated. Debreu and Scarf considered the case of a \"replica economy\" where there is a finite number of agent types and the agents added to the economy to make it \"large\" are of the same type and in the same proportion as those already in it. Aumann's result relied on an existence of a continuum of agents.\n\nThese proofs of the Edgeworth conjecture are seen as providing some qualified support for the idea that a large economy functions approximately as a price taking competitive economy of general equilibrium theory, even though agents have the power to set prices.\n\n"}
{"id": "1658091", "url": "https://en.wikipedia.org/wiki?curid=1658091", "title": "Electronic field production", "text": "Electronic field production\n\nElectronic field production (EFP) is a television industry term referring to a video production which takes place in the field, outside of a formal television studio, in a practical location or special venue. Zettl defines EFP as using \"both ENG (electronic news gathering) and studio techniques. From ENG it borrows its mobility and flexiblity; from the studio it borrows its production care and quality control. EFP takes place on location (which may include shooting in someone's living room) and has to adapt to the location conditions... Good lighting and audio are always difficult to achieve in EFP, regardless of whether you are outdoors or indoors. Compared to ENG, in which you simply respond to a situation, EFP needs careful planning.\"\n\nTypical applications of electronic field production include awards shows, concerts, major interviews for newsmagazine shows like Inside Edition, Extra (TV program) and Dateline NBC, large conventions such as the Democratic National Convention, Republican National Convention or San Diego Comic-Con International, celebrity red-carpet events and sporting events.\n\nEFP ranges from a camera operator or crew of two (camera operator with sound mixer) capturing high-quality imagery, to a multiple-camera setup utilizing videography, photography, advanced graphics and sound.\n\nSports television is one facet of EFP. Major television networks once owned their own production trucks for covering major events, but today, with the explosion in networks on cable and over-the-air, they rent television production trucks by the day or week from broadcast rental companies for more routine or remote broadcast productions.\n\nA typical sports production truck includes:\n\nTelevision News magazines are longer and more in-depth TV programming than shorter \"breaking news\" clips that focus on an issue in a documentary style. They are driven by interviews of people who are directly involved in the topic covered and last for from 30 minutes to three hours.\n\nThe first known television news magazine was Panorama on the BBC in 1953. Since then, the genre rose in popularity through the years including CBS’s 60 Minutes, debuting in 1968. Its spin-off, 60 Minutes II debuted in 1999.\n\nElectronic Field Production for a typical news magazine story may include one or several interviews with B-roll gathered typically by a three-person crew (producer, camera operator and audio technician/boompole operator). Locations vary. Typically the crew shoots the interview at the home or workplace of the interviewee. They may also go to additional locations that are a backdrop to the story. Lighting and shooting style are consistent with each's show's \"look\" or criteria.\n\nAfter the interviews and B-Roll have been gathered, the producer may either hand-deliver the media to the studio, ship it by messenger service or a shipping company, or \"feed it\" in real time via a local satellite service.\n\n\n"}
{"id": "985646", "url": "https://en.wikipedia.org/wiki?curid=985646", "title": "Functional shift", "text": "Functional shift\n\nIn linguistics, functional shift occurs when an existing word takes on a new syntactic function. For example, the word \"like\", formerly only used as a preposition in comparisons (as in \"eats like a pig\"), is now also used in the same way as the subordinating conjunction \"as\" in many dialects of English (as in \"sounds like he means it\"). The boundary between functional shift and conversion (the derivation of a new word from an existing word of identical form) is not well-defined, but it could be construed that conversion changes the lexical meaning and functional shift changes the syntactic meaning.\n\nShakespeare uses functional shift, for example using a noun to serve as a verb. Researchers found that this technique allows the brain to understand what a word means before it understands the function of the word within a sentence.\n"}
{"id": "69495", "url": "https://en.wikipedia.org/wiki?curid=69495", "title": "Ge'ez", "text": "Ge'ez\n\nGe'ez (; , ' ; also transliterated Gi'iz) is an ancient South Semitic language of the Ethiopic branch. The language originates from the region encompassing southern Eritrea and northern Ethiopia in the Horn of Africa.\n\nToday, Ge'ez is used only as the main language of liturgy of the Ethiopian Orthodox Tewahedo and Eritrean Orthodox Tewahedo churches, the Ethiopian and Eritrean Catholic churches, and the Beta Israel Jewish community. However, in Ethiopia, Amharic or other local languages, and in Eritrea and Ethiopia's Tigray Region, Tigrinya may be used for sermons. Amharic, Tigrinya, and Tigre are closely related to Ge'ez. \n\nThe closest living languages to Ge'ez are Tigre and Tigrinya with lexical similarity at 71% and 68%, respectively. Some linguists do not believe that Ge'ez constitutes a common ancestor of modern Ethiosemitic languages, but that Ge'ez became a separate language early on from another hypothetical unattested language, which can be seen as an extinct sister language of Amharic, Tigre and Tigrinya. The foremost Ethiopian experts such as Amsalu Aklilu point to the vast proportion of inherited nouns that are unchanged, and even spelled identically in both Ge'ez and Amharic (and to a lesser degree, Tigrinya).\n\nAlso transliterated as ä, ū/û, ī/î, a, ē/ê, e/i, ō/ô.\n\nGe'ez is transliterated according to the following system:\n\nBecause Ge'ez is no longer a spoken language, the pronunciation of some consonants is not completely certain. Gragg (1997:244) writes \"The consonants corresponding to the graphemes (Ge'ez ) and (Ge'ez ) have merged with ሰ and ጸ respectively in the phonological system represented by the traditional pronunciation—and indeed in all modern Ethiopian Semitic. ... There is, however, no evidence either in the tradition or in Ethiopian Semitic [for] what value these consonants may have had in Ge'ez.\"\n\nA similar problem is found for the consonant transliterated . Gragg (1997:245) notes that it corresponds in etymology to velar or uvular fricatives in other Semitic languages, but it was pronounced exactly the same as in the traditional pronunciation. Though the use of a different letter shows that it must originally have had some other pronunciation, what that pronunciation was is not certain.\nThe chart below lists and as possible values for () and () respectively. It also lists as a possible value for (). These values are tentative, but based on the reconstructed Proto-Semitic consonants that they are descended from.\n\nIn the chart below, IPA values are shown. When transcription is different from the IPA, the character is shown in angular brackets. Question marks follow phonemes whose interpretation is controversial (as explained in the preceding section).\n\n\nGe'ez consonants have a triple opposition between voiceless, voiced, and ejective (or emphatic) obstruents. The Proto-Semitic \"emphasis\" in Ge'ez has been generalized to include emphatic p̣. Ge'ez has phonologized labiovelars, descending from Proto-Semitic biphonemes. Ge'ez ś Sawt (in Amharic, also called \"śe-nigūś\", i.e. the \"se\" letter used for spelling the word \"nigūś\" \"king\") is reconstructed as descended from a Proto-Semitic voiceless lateral fricative . Like Arabic, Ge'ez merged Proto-Semitic š and s in (also called \"se-isat\": the \"se\" letter used for spelling the word \"isāt\" \"fire\"). Apart from this, Ge'ez phonology is comparably conservative; the only other Proto-Semitic phonological contrasts lost may be the interdental fricatives and ghayn.\n\nGe'ez distinguishes two genders, masculine and feminine, which in certain words is marked with the suffix \"-t\". These are less strongly distinguished than in other Semitic languages, in that many nouns not denoting persons can be used in either gender: in translated Christian texts there is a tendency for nouns to follow the gender of the noun with a corresponding meaning in Greek.\nThere are two numbers, singular and plural. The plural can be constructed either by suffixing \"-āt\" to a word, or by internal plural.\nNouns also have two cases, the nominative which is not marked and the accusative which is marked with final \"-a\" (e.g. bet, bet-a).\n\nInternal plurals follow certain patterns. Triconsonantal nouns follow one of the following patterns.\n\nQuadriconsonantal and some triconsonantal nouns follow the following pattern. Triconsonantal nouns that take this pattern must have at least one long vowel\n\nNoun phrases have the following overall order:\nAdjectives and determiners agree with the noun in gender and number:\nRelative clauses are introduced by a pronoun which agrees in gender and number with the preceding noun:\n\nAs in many Semitic languages, possession by a noun phrase is shown through the construct state. In Ge'ez, this is formed by suffixing /-a/ to the possessed noun, which is followed by the possessor, as in the following examples (Lambdin 1978:23):\nPossession by a pronoun is indicated by a suffix on the possessed noun, as seen in the following table:\n\nThe following examples show a few nouns with pronominal possessors:\n\nAnother common way of indicating possession by a noun phrase combines the pronominal suffix on a noun with the possessor preceded by the preposition /la=/ 'to, for' (Lambdin 1978:44):\n\nLambdin (1978:45) notes that in comparison to the construct state, this kind of possession is only possible when the possessor is definite and specific. Lambdin also notes that the construct state is the unmarked form of possession in Ge'ez.\n\nGe'ez is a prepositional language, as in the following example (Lambdin 1978:16):\n\nThere are three special prepositions, /ba=/ 'in, with', /la=/ 'to, for', /'əm=/ 'from', which always appear as proclitics on the following noun, as in the following examples:\nThese proclitic prepositions in Ge'ez are similar to the inseparable prepositions in Hebrew.\n\nThe normal word order for declarative sentences is VSO. Objects of verbs show accusative case marked with the suffix /-a/:\n\nQuestions with a wh-word ('who', 'what', etc.) show the question word at the beginning of the sentence:\nThe common way of negation is the prefix ʾi- which descends from ʾey- (which is attested in Axum inscriptions) from ʾay from Proto-Semitic *ʾal by palatalization. It is prefixed to verbs as follows:\nGe'ez is written with Ethiopic or the Ge'ez abugida, a script that was originally developed specifically for this language. In languages that use it, such as Amharic and Tigrinya, the script is called \"\", which means script or alphabet.\n\nGe'ez is read from left to right.\n\nThe Ge'ez script has been adapted to write other languages, usually ones that are also Semitic. The most widespread use is for Amharic in Ethiopia and Tigrinya in Eritrea and Ethiopia. It is also used for Sebatbeit, Meʻen, Agew and most other languages of Ethiopia. In Eritrea it is used for Tigre, and it is often used for Bilen, a Cushitic language. Some other languages in the Horn of Africa, such as Oromo, used to be written using Ge'ez but have switched to Latin-based alphabets.\nIt also uses 4 symbols for labialized velar consonants, which are variants of the non-labialized velar consonants:\n\nAlthough it is often said that Ge'ez literature is dominated by the Bible including the Deuterocanonical books, in fact there are many medieval and early modern original texts in the language. Most of its important works are also the literature of the Ethiopian Orthodox Tewahedo Church, which include Christian liturgy (service books, prayers, hymns), hagiographies, and Patristic literature. For instance, around 200 texts were written about indigenous Ethiopian saints from the fourteenth through the nineteenth century. This religious orientation of Ge'ez literature was a result of traditional education being the responsibility of priests and monks. \"The Church thus constituted the custodian of the nation's culture\", notes Richard Pankhurst, and describes the traditional education as follows:\n\nHowever, works of history and chronography, ecclesiastical and civil law, philology, medicine, and letters were also written in Ge'ez.\n\nThe Ethiopian collection in the British Library comprises some 800 manuscripts dating from the 15th to the 20th centuries, notably including magical and divinatory scrolls, and illuminated manuscripts of the 16th to 17th centuries. It was initiated by a donation of 74 codices by the Church of England Missionary Society in the 1830s and 1840s, and substantially expanded by 349 codices, looted by the British from the Emperor Tewodros II's capital at Magdala in the 1868 Expedition to Abyssinia. The Metropolitan Museum of Art in New York City has at least two illuminated manuscripts in Ge'ez.\n\nThe Ge'ez language is classified as a South Semitic language. It evolved from an earlier proto-Ethio-Semitic ancestor used to write royal inscriptions of the kingdom of Dʿmt in the Epigraphic South Arabian script. The Ge'ez language is no longer universally thought of, as previously assumed, to be an offshoot of Sabaean or Old South Arabian, and there is some linguistic (though not written) evidence of Semitic languages being spoken in Eritrea and Ethiopia since approximately 2000 BC. However, the Ge'ez script later replaced Epigraphic South Arabian in the Kingdom of Aksum. Epigraphic South Arabian letters were used for a few inscriptions into the 8th century, though not any South Arabian language since Dʿmt. Early inscriptions in Ge'ez and Ge'ez script have been dated to as early as the 5th century BC, and in a sort of proto-Ge'ez written in ESA since the 9th century BC. Ge'ez literature properly begins with the Christianization of Ethiopia (and the civilization of Axum) in the 4th century, during the reign of Ezana of Axum.\n\nThe oldest known example of the old Ge'ez script is found on the Hawulti obelisk in Matara, Eritrea. The oldest surviving Ge'ez manuscript is thought to be the 5th or 6th century Garima Gospels.\nAlmost all texts from this early \"Aksumite\" period are religious (Christian) in nature, and translated from Greek. The Ethiopic Bible contains 81 Books: 46 of the Old Testament and 35 of the New. A number of these Books are called \"deuterocanonical\" (or \"apocryphal\" according to certain Western theologians), such as the Ascension of Isaiah, Jubilees, Enoch, the Paralipomena of Baruch, Noah, Ezra, Nehemiah, Maccabees, and Tobit. The Book of Enoch in particular is notable since its complete text has survived in no other language.\nAlso to this early period dates Qerlos, a collection of Christological writings beginning with the treatise of Saint Cyril (known as \"Hamanot Rete’et\" or \"De Recta Fide\"). These works are the theological foundation of the Ethiopic Church. In the later 5th century, the Aksumite Collection—an extensive selection of liturgical, theological, synodical and historical materials—was translated into Ge'ez from Greek, providing a fundamental set of instructions and laws for the developing Ethiopian Church. Another important religious document is \"Ser'ata Paknemis\", a translation of the monastic Rules of Pachomius. Non-religious works translated in this period include \"Physiologus\", a work of natural history also very popular in Europe.\n\nAfter the decline of the Aksumites, a lengthy gap follows; no works have survived that can be dated to the years of the 8th through 12th centuries. Only with the rise of the Solomonic dynasty around 1270 can we find evidence of authors committing their works to writings. Some writers consider the period beginning from the 14th century an actual \"Golden Age\" of Ge'ez literature—although by this time Ge'ez was no longer a living language. While there is ample evidence that it had been replaced by Amharic in the south and by Tigrigna and Tigre in the north, Ge'ez remained in use as the official written language until the 19th century, its status comparable to that of Medieval Latin in Europe.\nImportant hagiographies from this period include:\nAlso at this time the \"Apostolic Constitutions\" was retranslated into Ge'ez from Arabic. Another translation from this period is Zena 'Ayhud, a translation (probably from an Arabic translation) of Joseph ben Gurion's \"History of the Jews\" (\"Sefer Josippon\") written in Hebrew in the 10th century, which covers the period from the Captivity to the capture of Jerusalem by Titus.\nApart from theological works, the earliest contemporary Royal Chronicles of Ethiopia are date to the reign of Amda Seyon I (1314–44). With the appearance of the \"Victory Songs\" of Amda Seyon, this period also marks the beginning of Amharic literature.\nThe 14th century \"Kebra Nagast\" or \"Glory of the Kings\" by the Nebura’ed Yeshaq of Aksum is among the most significant works of Ethiopian literature, combining history, allegory and symbolism in a retelling of the story of the Queen of Sheba (i.e. Saba), King Solomon, and their son Menelik I of Ethiopia. Another work that began to take shape in this period is the \"Mashafa Aksum\" or \"Book of Axum\".\n\nThe early 15th century \"Fekkare Iyasus\" \"The Explication of Jesus\" contains a prophecy of a king called \"Tewodros\", which rose to importance in 19th century Ethiopia as Tewodros II chose this throne name.\nLiterature flourished especially during the reign of Emperor Zara Yaqob. Written by the Emperor himself were \"Mats'hafe Berhan\" (\"The Book of Light\") and \"Matshafe Milad\" (\"The Book of Nativity\"). Numerous homilies were written in this period, notably \"Retu’a Haimanot\" (\"True Orthodoxy\") ascribed to John Chrysostom. Also of monumental importance was the appearance of the Ge'ez translation of the Fetha Negest (\"Laws of the Kings\"), thought to have been around 1450, and ascribed to one Petros Abda Sayd — that was later to function as the supreme Law for Ethiopia, until it was replaced by a modern Constitution in 1931.\n\nBy the beginning of the 16th century, the Islamic invasions put an end to the flourishing of Ethiopian literature.\nA letter of Abba 'Enbaqom (or \"Habakkuk\") to Ahmad ibn Ibrahim al-Ghazi, entitled \"Anqasa Amin\" (\"Gate of the Faith\"), giving his reasons for abandoning Islam, although probably first written in Arabic and later rewritten in an expanded Ge'ez version around 1532, is considered one of the classics of later Ge'ez literature. During this period, Ethiopian writers begin to address differences between the Ethiopian and the Roman Catholic Church in such works as the \"Confession\" of Emperor Gelawdewos, \"Sawana Nafs\" (\"Refuge of the Soul\"), \"Fekkare Malakot\" (\"Exposition of the Godhead\") and \"Haymanote Abaw\" (\"Faith of the Fathers\"). Around the year 1600, a number of works were translated from Arabic into Ge'ez for the first time, including the \"Chronicle\" of John of Nikiu and the \"Universal History\" of George Elmacin.\n\nGe'ez is the liturgical language of Ethiopian Orthodox Tewahedo, Eritrean Orthodox Tewahedo, Ethiopian Catholic and Eritrean Catholic Christians, and is used in prayer and in scheduled public celebrations. It is also used liturgically by the Beta Israel (Falasha Jews).\n\nThe liturgical rite used by the Christian churches is referred to as the Ethiopic Rite or the Ge'ez Rite.\n\nThe first sentence of the Book of Enoch:\n\n\n\n• Zerezghi Haile, Learn Basic Geez Grammar (2015) for Tigrinya readers available at: https://uwontario.academia.edu/WedGdmhra\n\n"}
{"id": "439840", "url": "https://en.wikipedia.org/wiki?curid=439840", "title": "Gostak", "text": "Gostak\n\nGostak is a meaningless noun that is used in the phrase \"the gostak distims the doshes\", which is an example of how it is possible to derive meaning from the syntax of a sentence even if the referents of the terms are entirely unknown. \n\nThe phrase was coined in 1903 by Andrew Ingraham but is best known through its quotation in 1923 by C. K. Ogden and I. A. Richards in their book \"The Meaning of Meaning\", and has been since referred to in a number of cultural contexts.\n\nCoined in 1903 by Andrew Ingraham, the sentence became more widely known through its quotation in 1923 by C. K. Ogden and I. A. Richards in their book \"The Meaning of Meaning\" (p. 46). \n\nOgden and Richards refer to Ingraham as an \"able but little known writer\", and quote his following dialogue:\n\nThis can be seen in the following dialogue:\n\nIn this case, it is possible to describe the relationships between the terms in the sentence—that the gostak is that which distims the doshes, that distimming is what the gostak does to the doshes, and so on—even though there is no fact of the matter about what a gostak or doshes actually are.\n\nThe phrase appears in a number of subsequent cultural contexts including:\n\nDr. Miles Breuer wrote a story, published in \"Amazing Stories\" for March 1930 and now considered a classic, titled \"The Gostak and the Doshes\" whose protagonist pops into an alternative world in which the phrase is a political slogan that induces sufficient umbrage throughout the populace to declare justified, righteous war. Other writers have picked up on the reference, notably David Gerrold.\n\nThe phrase is the namesake of an interactive fiction game called \"The Gostak\", written by Carl Muckenhoupt. Most of the text of the game is in an entirely unknown language (fundamentally English in syntax and grammar, but with much of the vocabulary and even idiomatic constructions changed) which the player must decipher, not only to understand the game's text but also to type commands in the same language. For example, the game opens with the following text:\n\n\"The Gostak\" won the 2001 XYZZY Awards for Best Use of Medium and Best Individual Puzzle.\n\n\"The Gostak Distims the Doshes\" is a three movement sonata for prepared piano composed by Hiawatha in 1984. The three movements are: I. Doshes ; II. Distimming ; III. The Gostak\n\nThe piece is in the collection of the Knight Library of the University of Oregon.\n\n\n"}
{"id": "16001007", "url": "https://en.wikipedia.org/wiki?curid=16001007", "title": "Gude language", "text": "Gude language\n\nGude is an Afro-Asiatic language spoken in Nigeria in Adamawa State in Mubi LGA and in Borno State in Askira-Uba LGA. It is also spoken in neighboring Cameroon. Different dialects are spoken in Nigeria and Cameroon.\n\n"}
{"id": "38483742", "url": "https://en.wikipedia.org/wiki?curid=38483742", "title": "Gumawana language", "text": "Gumawana language\n\nGumawana is an Austronesian language spoken by the Gabobora people along Cape Vogel in the Milne Bay Province of Papua New Guinea.\n"}
{"id": "22113607", "url": "https://en.wikipedia.org/wiki?curid=22113607", "title": "Halmahera Sea languages", "text": "Halmahera Sea languages\n\nThe Halmahera Sea languages, also known as the Raja Ampat-South Halmahera languages, are a branch of Malayo-Polynesian languages spoken on islands in the Halmahera Sea, and on its margins from the south-eastern coast of Halmahera to the Raja Ampat Islands of the western tip of New Guinea.\n\nThe languages of the Raja Ampat Islands show a strong Papuan substratum influence; it is not clear that they are actually Austronesian as opposed to relexified Papuan languages.\n\nRemijsen (2001) and Blust (1978) linked the languages of Raja Ampat to the South Halmahera languages. David Kamholz (2014) breaks up Raja Ampat, so that the structure of the Halmahera Sea languages is as follows:\n\n"}
{"id": "1518227", "url": "https://en.wikipedia.org/wiki?curid=1518227", "title": "Horizontal progression", "text": "Horizontal progression\n\nIn Western handwriting, horizontal progression is the gradual movement from left to right during writing a line of text. In Hebrew and Arabic writing systems, the movement is from right to left.\n\n"}
{"id": "25254314", "url": "https://en.wikipedia.org/wiki?curid=25254314", "title": "JAPE (linguistics)", "text": "JAPE (linguistics)\n\nIn computational linguistics, JAPE is the Java Annotation Patterns Engine, a component of the open-source General Architecture for Text Engineering (GATE) platform. JAPE is a finite state transducer that operates over annotations based on regular expressions. Thus it is useful for pattern-matching, semantic extraction, and many other operations over syntactic trees such as those produced by natural language parsers.\n\nJAPE is a version of CPSL – Common Pattern Specification Language.\n\nA JAPE grammar consists of a set of phases, each of which consists of a set of pattern/action rules. The phases run sequentially and constitute a cascade of finite state transducers over annotations. The left-hand-side (LHS) of the rules consist of an annotation pattern description. The right-hand-side (RHS) consists of annotation manipulation statements. Annotations matched on the LHS of a rule may be referred to on the RHS by means of labels that are attached to pattern elements. \n\nDhaval Thakker, Taha Osman, Phil Lakin, JAPE Grammar Tutorial, http://gate.ac.uk/sale/thakker-jape-tutorial/GATE%20JAPE%20manual.pdf\n"}
{"id": "7215856", "url": "https://en.wikipedia.org/wiki?curid=7215856", "title": "Jackstaff", "text": "Jackstaff\n\nA jack staff (also spelled as jackstaff) is a small vertical spar (pole) on the bow of a ship or smaller vessel on which a particular type of flag, known as a jack, is flown. The jack staff was introduced in the 18th century. The jack is typically flown from military vessels, including submarines, while at anchor or moored pierside, but not while underway. Civilian vessels such as private yachts have also been known to fly the jack of the nation of their homeport, also from a jackstaff, while moored or at anchor.\n"}
{"id": "19812138", "url": "https://en.wikipedia.org/wiki?curid=19812138", "title": "Kokota language", "text": "Kokota language\n\nKokota is an Austronesian language spoken by perhaps as many as 1,200 people in three villages on Santa Isabel in the Solomon Islands. These villages are, the villages of Goveo and Sisiga, which lie on the north coast, and Hurepelo which lies on the south coast. People in all three villages use the language daily, but may eventually shift to neighboring Cheke Holo to the west, a language spoken by many more people who have recently settled between Goveo and Sisiga .\n\nThe vowel inventory of Kokota is remarkably uninteresting - reflecting the Oceanic five-vowel system - but the actual sound of each may vary according to the phonetic environment. Despite a lack of phonemic length distinction in Kokota, one does find long vowels; however, this is due to a sequence of two identical vowels, rather than one long vowel – this distinction is demonstrated by the optional insertion of an epenthetic glottal stop between the two vowels (.\nKokota doesn’t contain any phonemic diphthongs; however they do occur in normal speech. Only certain vowel sequences are eligible for diphthonisation. Sequences may only diphthongise if the second vowel present is higher than the first. Front-back and back-front movements are not eligible to become diphthongs. This leaves six diphthongs able to occur : /ae/, /ai/, /ao/, /au/, /ei/ and /ou/. Diphthongisation is also not restricted by morpheme boundaries. Thus, any sequence of eligible vowels may diphthongise.\n\nKokota orthography is heavily influenced by that of Cheke Holo. For instance, glottal stops are not phonemic in Kokota but are often written with an apostrophe (as in Cheke Holo) when they occur in certain nondistinctive environments, such as to mark morpheme boundaries between neighboring vowels. Similarly, Cheke Holo distinguishes \"j\" and \"z\" but Kokota does not. Nevertheless, Kokota speakers tend to use either letter to write phonemic /z/. The macron is used to write the voiced velar plosive and the velar nasal .\n\nMost consonants distinguish voiceless and voiced versions (left and right respectively in each cell in the table). Kokota presents a rather uncommon set of consonant phonemes in that each and every phoneme exists in a pair with its voiced or voiceless opposite. There are 22 consonant phonemes in total – 11 place and manner pairs of voiced and voiceless . The amount of voiced and voiceless consonants and vowels is nearly equal with the percentage being 52% voiced and 48% voiceless. There are 5 different manner classes in the Kokota language. Two are obstruent classes which are fricative and plosive and three are sonorant classes which are lateral, nasal, and rhotic. Its six fricative phonemes make Kokota a relative outlier in Oceanic, where 2-3 fricatives are usual.\n\nIn the Kokota language there are two layers to the verb complex: an inner layer and an outer layer. The inner layer is the verb core which is transparent to any sentence modifiers. The outer layer can alter the verb core all together. Constituent modifiers can modify the verb complex in a sentence in addition to the inner and outer layers of verb complexes.\n\nCompound verbs stem from multiple verbs. The left-hand root is the verb and the right-hand can be a noun, verb, or adjective. The phrase all together acts as a verb phrase.\n\nTable retrieved from, Kokota Grammar by Bill Palmer, Honolulu, US: University of Hawaii Press, 2008.\n\nKokomo shows full and partial reduplication of disyllabic roots.\n\nIn some cases partial reduplication shows the change of a noun to a verb; nouns from verbs; slight noun from noun differentiation; slight verb from verb differentiation; derived form of a habitual, ongoing, or diminutive event.\n\nTables retrieved from, Kokota Grammar by Bill Palmer, Honolulu, US: University of Hawaii Press, 2008.\n\nThere is only a small number of full reduplication of disyllabic roots in the Kokota language. Below are examples of full reduplication where the relationship is idiosyncratic:\n\nTables retrieved from, Kokota Grammar by Bill Palmer, Honolulu, US: University of Hawaii Press, 2008.\n\nOne example shows full reduplication deriving verbs from transitive roots, and nouns from verbs:\n\nTables retrieved from, Kokota Grammar by Bill Palmer, Honolulu, US: University of Hawaii Press, 2008.\n\nEquative clauses represent a characteristic of the subject in the sentence. In the Kokota language moods are unmarked. In equatives, the subject agreement component in verb clauses are excluded.\n\nWhen telling the time; time is the subject. Telling time smaller than an hour is expressed by a NP that expresses the minutes numerically attached to a possessor that expresses the hour. Using the terms like ‘half past’ or ‘quarter to’ cannot be determined in Kokota language.\n\nTable retrieved from, Kokota Grammar by Bill Palmer, Honolulu, US: University of Hawaii Press, 2008.\n\nThe topicalized subject in Kokota language is in the preverbal position. Any subject can be tropicalized but rarely in natural conversation.\n\nTable retrieved from, Kokota Grammar by Bill Palmer, Honolulu, US: University of Hawaii Press, 2008.\n\nBelow is a table of the breakdown position occurrence of the first 100 verbal clauses in a normal text:\n\nTable retrieved from, Kokota Grammar by Bill Palmer, Honolulu, US: University of Hawaii Press, 2008.\n\nThere exist four sets of pronominal forms: preverbal subject indexed auxiliaries, post verbal object indexing, possessor indexing and independent pronouns . Complying with typical Oceanic features, Kokota distinguishes between four person categories: first person inclusive, first person exclusive, second person, and third person. The preverbal subject indexing auxiliaries do not differentiate between singular and plural, whereas possessor and postverbal object indexing do – except in first person inclusive, where no singular is possible .\n\nThe preverbal subject-indexing pronouns do not distinguish number .\nThe object-indexing pronouns are postverbal clitics .\nThe possessor-indexing pronouns are suffixed to nouns .\nThe independent pronouns, however, go one step further and differentiate between singular, dual, trial and plural numbers .\nSimilarly to many Oceanic languages, Kokota makes the distinction between alienable possession and inalienable possession.\n\nInalienable possession consists of possessor indexing enclitics attaching to the nominal core of the possessed noun phrase as follows ):\nAlienable possession is formed with a possessive base that is indexed to the possessor. This entire unit precedes the possessed noun phrase. Alienable possession is further broken down into two categories, consumable, whose base is \"ge-\", and non-consumable, whose base is \"no-\" .\n\nBelow are phrases spoken in Kokota by a native speaker named Nathaniel Boiliana as he reminisced about World War II:\n\nn-e-ge tor-i b=ana manei goi?\n\nRL-3SGS-PRS open-TR ALT=thatN s/he VOC\n\nHas he opened it [i.e., started the tape recorder]?\n\nau bla n-a-ke=u [goveo] banesokeo\n\nexist LMT RL-IEXCS-PFv=be.thus PNLOC PNLOC\n\nI was living in [Goveo] Banesokeo,\n\n\"tana aḡe ira mane ta zuke leba\"\n\nthen go thePL man SBO seek labor\n\nthen the men came to look for labor.\n\nḡ-e-la ara-hi ka vaka kabani-na amerika\n\nNT-3s-go I-EMPH LOC ship company-3sGP PNLOC\n\nSo I was on an American company ship\n\n\"aḡe hod-i=au banesokeo\",\n\ngo take-TR=ISGO PNLOC\n\nthat took me from Banesokeo,\n\nrauru raasalo, kepmasi\n\ngo.seaward PNLOC PNLOC\n\n[we] went seaward to Russell, to Cape Masi.\n\nn-e la au=nau sare. au bla ge au\n\nRL-3s go exist=lsGO therep exist LMT SEQ exist\n\nI went and stayed there. Staying and staying\n\nka frin̄he=na mane amerika=re maḡra maneri.\n\nLOC work=thatN man PNLOC=thoseN fight they\n\nin the work of those American men in the fight.\n\ngu ḡ-au-gu rasalo e=u.\n\nbe.thus NT-exist-CNT PNLOC 3s=be.thus\n\nLike that, living on Russell.\n\nThe numeral system of Kokota has many typologically odd features and shows significant lexical replacement. In the numbers up to 10, only \"7\" \"fitu\" (< *pitu) is a clear Proto-Oceanic reflex. The higher numerals also alternate between multiples of 10 (e.g. \"tulufulu\" \"30\" from POc *tolu-puluq \"3 x 10\") and 20 (\"tilotutu\" \"60\" or \"3 x \"tutu\"\"), including two distinct morphemes with the meanings \"10\" (\"-fulu\" from Proto-Oceanic and \"-salai\", used only on numbers above 60 and likely from a substrate) and \"20\" (\"varedake\" \"20\" and \"-tutu\", also likely from a substrate\")\". Ross describes it as one of the most bizarre numeral systems attested for an Oceanic language.\n"}
{"id": "14766384", "url": "https://en.wikipedia.org/wiki?curid=14766384", "title": "Languages of Iraq", "text": "Languages of Iraq\n\nThere are a number of languages spoken in Iraq, but Mesopotamian Arabic (Iraqi Arabic) is by far the most widely spoken in the country.\n\nThe most widely spoken language in Iraq is the Arabic language (specifically Mesopotamian Arabic); the second most spoken language is Kurdish (mainly Sorani and Kurmanji dialects), followed by the Iraqi Turkmen/Turkoman dialect of Turkish, and the Neo-Aramaic languages (specifically Chaldean and Ashuri). \n\nArabic is written using the Arabic script and Kurdish is written with a modified Perso-Arabic script (see Sorani alphabet). In 1997 the Iraqi Turkmen/Turkoman adopted the Turkish alphabet as the formal written language and by 2005 the community leaders decided that the Turkish language would replace traditional Turkmeni (which had used the Arabic script) in Iraqi schools. In addition, the Neo-Aramaic languages use the Syriac script. \n\nOther smaller minority languages include Mandaic, Shabaki, Armenian, Feyli Lurish and Persian.\n\nArabic and Kurdish are the official languages, while the Turkmen/Turkoman dialect and Assyrian Neo-Aramaic are recognized regional languages. In addition, any region or province may declare other languages official if a majority of the population approves in a general referendum.\n\nThe language with the longest recorded period of use in Iraq is Aramaic, which has a written tradition dating back for 3200 years or more and survives today in its descendants, the Neo-Aramaic languages.\n\nThe earliest recorded languages of Iraq were Sumerian and Akkadian (including ancient Assyrian-Babylonian). Sumerian was displaced by Akkadian by 1700 BCE, and Akkadian was displaced by Aramaic gradually, from 1200 BCE to 100 CE. Sumerian and Akkadian (including all Assyrian and Babylonian dialects) were written in the cuneiform script from 3300 BCE onwards. The latest positively identified Akkadian text comes from the first century CE.\n"}
{"id": "51537828", "url": "https://en.wikipedia.org/wiki?curid=51537828", "title": "List of Bodo-language films", "text": "List of Bodo-language films\n\nThis is a list of films in the Bodo language organised by year of release.\n\n"}
{"id": "52382744", "url": "https://en.wikipedia.org/wiki?curid=52382744", "title": "Magie Faure-Vidot", "text": "Magie Faure-Vidot\n\nMagie Faure-Vidot (sometimes Maggie Vijay-Kumar) (born 1958) is a French-language poet from the Seychelles who has also published work in English and Seychellois Creole.\n\nFaure-Vidot was born in Victoria. She is a member of the Institut Académique de Paris and the Académie Internationale de Lutèce. She has won numerous prizes over the course of her career, including the Coupe de la Ville de Paris, a Lyre d'honneur, and six silver and numerous bronze medals in various international literary competitions, and she has represented her home country at many international poetry festivals and other initiatives. Her work has been discussed in critical studies of Seychellois literature. She has also achieved some fame as an oral performer.\n\nAfter living for some time in the United States, Lebanon, England, Italy, and France, Faure-Vidot returned to the Seychelles. There she cofounded, and continues to codirect, both the online literary review \"Vents Alizés\" and the online publishing house Edisyon Losean Endyen, both of which she runs in conjunction with Hungarian poet Károly Sándor Pallai. Her work is regularly published in \"Seychelles Nation\" and \"The People\", and she is the editor of \"Sipay\", the only Seychellois literary magazine. She is also heavily engaged in the cultural life of her country, including showing her work at exhibitions of art by local women. Her poems were published in the international poetry anthology Amaravati Poetic Prism in India. In 2017, she received the prestigious Seychelles Arts Award in literature for her outstanding literary work and achievements.\n\nShe is a member of the World Nations Writers Union (WNWU) Kazakhstan. Her work was featured in the \"Family Eternal Treasure\" international anthology (2018).\n\n\n"}
{"id": "15436056", "url": "https://en.wikipedia.org/wiki?curid=15436056", "title": "Mara language", "text": "Mara language\n\nMara is a Kuki-Chin language spoken by Mara people living in 60 villages of Chhimtuipui district, southern Mizoram, India and the adjacent people living in Burma.\n\nThe Mara language belongs to the Kuki-Chin branch of the Sino-Tibetan language family. The speakers of the language are also known as Mara.\n\nMara is a recognised language in the School curriculum of Mara Autonomous District Council (MADC). Mara is a compulsory subject for all schools up to Class VII (Middle School) under Board of School Education, MADC.\n\n\nMara Alphabet (capital letters): A, AW, Y, B, CH, D, E, F, H, I, K, L, M, N, NG, O, Ô, P, R, S, T, U, V, Z Mara Alphabet (small letters):a, aw, y, b, ch, d, e, f, h, i, k, l, m, n, ng, o, ô, p, r, s, t, u, v, z Mara diphthongs:ao, yu, ai, ei, ia, ie, ua\n\nThe plural form of a noun is formed by affixing one of the following terms to the end of the noun:\nWords inside bracket were how a foreign author N.E. Parry (1937) wrote according to his understanding of the sound. But now the Maras have their own alphabet and the correct usages are put up there.\n\nWhat : Khâpa, Khâpa e, Khâpa maw\nWhere : Khataih lâ, Khataih liata\nHow : kheihta, kheihawhta, Khatluta, Kheihta maw\nHow much? : Khazie?\nHow long? : Khachâ e, Khachâ maw?\nWhen : Khatita, khatita e, Khâpa nota, nota, tita, nahta, pata, Conj. thlaita, khati nota\nWhy : Khazia, Khazia-e, Khazia maw, Khâpa vâta\nWhy not : Khazia a châ vei chheih aw\nWhose : Kheihawhpa, Kheihawhpa he, Kheihawhpa-e, Kheihawhpa maw, ahy he maw\nWhich : Kheihawhpa, Kheihawhpa he, Kheihawhpa-e, Kheihawhpa maw, ahy he maw\nFriend : Viasa\nMale Friend : Viasa Paw\nFemale Friend: Viasa Nô\nWalk/Go : Sie (Phei ta Sie)\nRun : Arâ, â râ\nSleep : Amô, Azia, Apazawh, â mô, â zia, â pazawh\nSee : Mo, hmô\nSit : Â tyuh, atyuh\nStand : Â duah, aduah\nJump : Â pathluah, apathluah\nHit : Â chô, achô\nEat : Nie\nDrink : Doh\n\nSingular:\nPlural:\n\nPossessive Pronouns\n\n\nhttp://www.marasaw.com/english-mara.html\n"}
{"id": "44629958", "url": "https://en.wikipedia.org/wiki?curid=44629958", "title": "Meaning-making", "text": "Meaning-making\n\nIn psychology, meaning-making is the process of how people construe, understand, or make sense of life events, relationships, and the self.\n\nThe term is widely used in constructivist approaches to counseling psychology and psychotherapy, especially during bereavement in which people attribute some sort of meaning to an experienced death or loss. The term is also used in educational psychology.\n\nIn a broader sense, meaning-making is the main research object of semiotics, biosemiotics, and other fields. Social meaning-making is the main research object of social semiotics and related disciplines.\n\nPsychiatrist and holocaust survivor Viktor Frankl, founder of logotherapy in the 1940s, posited in his 1946 book \"Man's Search for Meaning\" that the primary motivation of a person is to discover meaning in life. Frankl insisted that meaning can be discovered under all circumstances, even in the most miserable experiences of loss and tragedy. He said that people could discover meaning through doing a deed, experiencing a value, and experiencing suffering. Although Frankl did not use the term \"meaning-making\", his emphasis on the making of meaning influenced later psychologists.\n\nNeil Postman and Charles Weingartner, both of whom were educational critics and promoters of inquiry education, published a chapter called \"Meaning Making\" in their 1969 book \"Teaching as a Subversive Activity\". In this chapter, they described why they preferred the term \"meaning making\" to any other metaphors for teaching and learning:\n\nBy the end of the 1970s, the term \"meaning-making\" was used with increasing frequency, especially in constructivist learning theory which posits that knowledge is something that is actively created by people as they experience new things and integrate new information with their current knowledge. Developmental psychologist Robert Kegan used the term \"meaning-making\" as a key concept in several widely cited texts on counseling and human development published in the late 1970s and early 1980s. Kegan wrote: \"\"Human\" being is \"meaning making\". For the human, what \"evolving\" amounts to is \"the evolving of systems of meaning\"; the business of organisms is to organize, as Perry (1970) says.\" The term \"meaning-making\" has also been used by psychologists influenced by George Kelly's personal construct theory.\n\nIn a review of the meaning-making literature published in 2010, psychologist Crystal L. Park noted that there was a rich body of theory on meaning-making, but empirical research had not kept pace with theory development. In 2014, the first Congress on the Construction of Personal Meaning was held as part of the eighth Biennial International Meaning Conference convened by the International Network on Personal Meaning.\n\nThe term \"meaning-making\" has been used in constructivist educational psychology to refer to the personal epistemology that people create to help them to make sense of the influences, relationships and sources of knowledge in their world.\n\nFor example, psychologist Robert Kegan developed a theoretical framework that posited five levels of meaning-making; each level describes a more advanced way of understanding experiences, and people may come to master each level as they develop psychologically. Similarly, according to the transformative learning theory of sociologist and educator Jack Mezirow, adults interpret the meaning of their experiences through a lens of deeply held assumptions. When they experience something that contradicts or challenges their way of negotiating the world they have to go through the transformative process of evaluating their assumptions and processes of making meaning. Experiences that force individuals to engage in this critical self-reflection, or what Mezirow called \"disorienting dilemmas\", can be events such as loss, trauma, stressful life transitions or other interruptions.\n\nWith the experience of a death, people often have to create new meaning of their loss. Interventions that promote meaning-making may be beneficial to grievers, as some interventions have been found to improve both mental health and physical health. However, according to some researchers, \"for certain individuals from challenging backgrounds, efforts after meaning might not be psychologically healthy\" when those efforts are \"more similar to rumination than to resolution\" of problems.\n\nSome researchers report that meaning-making can help people feel less distressed, and allows people to become more resilient in the face of loss. On the converse, failing to attribute meaning to death leads to more long-term distress for some people.\n\nThere are various strategies people can utilize for meaning-making; many of them are summarized in the book \"Techniques of Grief Therapy\". One study developed a \"Meaning of Loss Codebook\" which clusters common meaning-making strategies into 30 categories. Amongst these meaning-making strategies, the most frequently used categories include: personal growth, family bonds, spirituality, valuing life, negative affect, impermanence, lifestyle changes, compassion, and release from suffering.\n\nIndividuals using existing family bonds for meaning-making have a \"change in outlook and/or behavior towards family members\". With this meaning-making strategy, individuals create meaning of loss through their interactions with family members, and make more efforts to spend more time with them. When individuals use family to give meaning to loss, more meaning-making strategies emerge within the family system. A couple of strategies that family members use to help each other cope are discussing the legacy of the deceased, and talking to non-family members about the loss.\n\nWhen family members are able to openly express their attitudes and beliefs, it can lead to a better well-being and less disagreement in the family. Meaning-making with one's family also increases marital satisfaction by reducing family tension, especially if the deceased was another family member.\n\nMeaning-making through spirituality and religiosity is significant because it helps individuals cope with their loss, as well as develop their own spiritual or religious beliefs. Spirituality and religiosity helps grievers think about a transcendental reality, share their worldview, and feel a sense of belonging to communities with shared beliefs.\n\nWhen individuals with a divinity worldview make meaning through spirituality and religiosity, those \"individuals perceive the divine to be involved in a major stressful life event\" and use the divine to develop a meaning for the loss. There are three main ways in which a theistic individual may create meaning through religion: benevolent religious reappraisals, punishing God reappraisals, and reappraisals of God's power. Benevolent religious reappraisals cast God in a positive light and grievers may see the death as a part of God's plan. Punishing God reappraisals cast God in a dark light and grievers may blame God for the loss or feel punished by God. Reappraisals of God's power questions God's ability to intervene on the situation. All of these appraisals contribute to how the griever may create meaning of their loss.\n\nAnother meaning-making strategy people use is to create meaning by valuing their own life. People who create meaning in this way may try to cherish the life they have, try to find their purpose, or change their lifestyles.\n\nGrievers can make meaning of death through philanthropic services such as charities, foundations, and organizations. Meaning-making through philanthropy can create financial support, social support, emotional support, and helps create positive results from the negative experience of the death. For example, one couple that lost a child described how they developed \"Nora's Project\" after their daughter with a disability died, in order to help provide wheelchairs for children with disabilities around the world. The mother said: \"With Nora's Project, I am also healing. I am able to turn something that was horrific, the way she died, into something that will do good in the world\". Like this mother, it is common for individuals to want to create or do something positive for others. Philanthropy helps people make meaning by continuously and altruistically honoring a life while simultaneously helping others going through a similar experience.\n\n"}
{"id": "636062", "url": "https://en.wikipedia.org/wiki?curid=636062", "title": "Meänkieli dialects", "text": "Meänkieli dialects\n\nMeänkieli (literally \"our language\") is a group of distinct Finnish dialects spoken in the northernmost part of Sweden along the valley of the Torne River. In Sweden it is recognized as one of the country's five minority languages.\n\nLinguistically, Meänkieli consists of two dialect subgroups, the Torne Valley dialects (also spoken on the Finnish side of the Torne River) and the Gällivare dialects, which both belong to the larger Peräpohjola dialect group (\"see Dialect chart\"). For historical reasons it has the status of a minority language in Sweden. In modern Swedish the language is normally referred to officially as \"meänkieli\", although colloquially an older name, \"tornedalsfinska\" (\"Torne Valley Finnish\"), is still commonly used. Sveriges Radio tends to use \"tornedalsfinska\" for the culture generally and \"meänkieli\" specifically for the language.\n\nMeänkieli is distinguished from Standard Finnish by the absence of 19th- and 20th-century developments in Finnish. Meänkieli also contains many loanwords from Swedish pertaining to daily life. However, the frequency of loanwords is not exceptionally high when compared to some other Finnish dialects: for example, the dialect of Rauma has roughly as many loanwords as Meänkieli. Meänkieli lacks two of the grammatical cases used in Standard Finnish, the comitative and the instructive (they are used mostly in literary, official language in Finland). In Finland, Meänkieli is generally seen as a dialect of Northern Finnish. There is also a dialect of Meänkieli spoken around Gällivare that differs even more from Standard Finnish.\n\nBefore 1809, all of what is today Finland was an integral part of Sweden. The language border went west of the Torne Valley area, so a small part of today's Sweden, along the modern border, was historically Finnish speaking (just like most areas along the eastern coast of the Gulf of Bothnia, areas that were ceded to Russia and are part of modern Finland, were historically Swedish speaking, and to a large extent still are). The area where Meänkieli is spoken that is now Finnish territory (apart from the linguistically Sami and Swedish parts of this geographical area), formed a dialect continuum within the Realm of Sweden. Since the area east of Torne River was ceded to Russia in 1809, the language developed in partial isolation from standard Finnish. In 1826 the state Church of Sweden appointed the priest and amateur botanist Lars Levi Laestadius to be the Vicar over the Karesuando parish, which is situated along the Muonio River north of the Arctic Circle on the border of Finland in Swedish Lapland. The population of Karesuando was predominantly Finnish-speaking people of Sami, Finnish, and Swedish mixed descent. Laestadius reported that the local dialect was notably different from standard Finnish, though he did not give it a name.\n\nIn the 1880s, the Swedish state decided that all citizens of the country should speak Swedish. Part of the reason was military; people close to the border speaking the language of the neighbouring country rather than the major language in their own country might not be trusted in case of war. Another reason was that Finns were regarded as being of another \"race.\" The official Swedish opinion was that \"the Sami and the Finnish tribes belong[ed] more closely to Russia than to Scandinavia\". Beginning around this time, the schools in the area only taught in Swedish, and children were forbidden under penalty of physical punishment from speaking their own language at school even during class breaks. Native Meänkieli speakers were prevented by the authorities from learning Standard Finnish as a school subject for decades, which resulted in the survival of the language only in oral form.\n\nOn April 1, 2000, Meänkieli became one of the now five nationally recognized minority languages of Sweden, which means it can be used for some communication with local and regional authorities in the communities along the Finnish border. In other words, its minority language status only applies in certain designated local communities and areas, not in all of Sweden.\n\nFew people today speak Meänkieli as their only language. Estimates of how many people speak Meänkieli vary from 30,000 to 70,000, of whom most live in Norrbotten. Many people in the northern parts of Sweden understand some Meänkieli, but fewer people speak it regularly. People with Meänkieli roots are often referred to as Tornedalians although the Finnish-speaking part of Norrbotten is a far larger area than the Torne River Valley; judging by the names of towns and places, the Finnish-speaking part of Norrbotten stretches as far west as the city of Gällivare.\n\nToday Meänkieli is declining. Few young people speak Meänkieli as part of daily life though many have passive knowledge of the language from family use. The language is taught at Stockholm University, Luleå University of Technology, and Umeå University. Bengt Pohjanen is a trilingual author from the Torne Valley. In 1985 he wrote the first Meänkieli novel, \"Lyykeri\". He has also written several novels, dramas, grammars, and songs in Meänkieli; he has also written and directed films.\n\nThe author Mikael Niemi's novels and a film based on one of his books in Swedish have improved awareness of this minority among Swedes. Since the 1980s, people who speak Meänkieli have become more aware of the importance of the language as a marker of identity. Today there are grammar books, a Bible translation, drama performances, and there are some TV programmes in Meänkieli. \n\nOn radio, programmes in Meänkieli are broadcast regularly from regional station P4 Norrbotten (as well as local station P6 in Stockholm) on Mondays to Thursdays between 17.10 and 18.00, while on Sundays further programmes are carried by P6 between 8.34 and 10.00 (also on P2 nationwide from 8.34 to 9.00). All of these programmes are also available via the internet.\n\nLiteral English translation:\n\nSweden is a democracy. The word democracy means rule by the people. It means that people in Sweden are allowed to participate in deciding how Sweden is to be governed. It is said in our constitution that all power in Sweden comes from the people and that the Riksdag is the most important representative of the people. Every four years the people choose those who will represent them in the Riksdag, county councils, and municipalities.\n\n"}
{"id": "53156890", "url": "https://en.wikipedia.org/wiki?curid=53156890", "title": "Muireann Ní Bhrolcháin", "text": "Muireann Ní Bhrolcháin\n\nMuireann Ní Bhrolcháin (15 May 1955 – 14 April 2015) was an Irish academic and activist.\n\nA native of Salthill, Galway City, Ní Bhrolcháin was a historian who researched early Irish literature, history, and genealogy, with a particular interest in Gaelic women. Her father, Cillian Ó Brolcháin, was professor of physics at UCG (now National University of Ireland, Galway). Her mother was domestic science teacher Mairéad Coughlan of Macroom, County Cork.\n\nHer funeral service was attended by, among others, by President of Ireland Michael D. Higgins. She was survived by her partner and two daughters.\n\n\n\n"}
{"id": "22461423", "url": "https://en.wikipedia.org/wiki?curid=22461423", "title": "Neosexual", "text": "Neosexual\n\nNeosexual is a neologism used to describe a subset of the heterosexual male population. A neosexual relates to a departure from metrosexual, back towards more traditional masculine characteristics. A neosexual is described as \"James Bond with a sense of humor\".\n\nThe traits of a neosexual include:\n\nA neosexual is described as sensitive to his partner's needs without losing his masculinity.\n\n"}
{"id": "33211066", "url": "https://en.wikipedia.org/wiki?curid=33211066", "title": "Nyong language", "text": "Nyong language\n\nNyong (Daganyonga) is a Leko language spoken in two well-separated enclaves in Cameroon and Nigeria. Cameroonian speakers consider themselves to be ethnically Chamba.\n"}
{"id": "45688233", "url": "https://en.wikipedia.org/wiki?curid=45688233", "title": "Perak Malay", "text": "Perak Malay\n\nPerak Malay (Standard Malay: \"Bahasa Melayu Perak\"; Jawi script: بهاس ملايو ڤيراق) is one of the Malay dialects spoken within the state of Perak, Malaysia. Although it is neither the official language nor the standard dialect in the whole state of Perak, its existence which co-exists with other major dialects in the state of Perak still plays an important role in maintaining the identity of Perak. In spite of the fact that there are five main dialects traditionally spoken in Perak, only one of which is intended by the name \"Perak Malay\". There are subtle phonetic, syntactic and lexical distinctions from other major Malay dialects. Perak Malay can be divided into two sub-dialects, Kuala Kangsar and Perak Tengah, named after the \"daerah\" (districts) where they are predominantly spoken.\n\nLinguistically, the Malay dialects spoken in the state of Perak are diverse. In fact, there is still no definite classification of the type of Malay dialects used in Perak. Ismail Hussein (1973) classified the Malay dialects in Perak into five types segregated into five different areas. While Harun Mat Piah (1983) categorized them into six. Although Asmah Haji Omar (1985) divided the Malay dialects in Perak into five types, the specifications of the division did not coincide with that of Ismail's.\n\nPerak Malay is spoken throughout the whole state except in the northwestern parts of Perak (Kerian, Larut, Matang and Selama), and a few parts of Manjung district including Pangkor Island where the northern dialect is predominantly spoken.\n\nIn the northeastern part of Perak (Hulu Perak) and some parts of Selama and Kerian, the Malay people natively speak a distinct variant of Malay language which is most closely related to Kelantan-Pattani Malay and the Malay dialects of southern Thailand due to geographical borders and historical assimilation. This variant is occasionally classified as a sub-dialect of Yawi. The district of Hulu Perak once was ruled by the Kingdom of Reman. Reman was historically a part of Greater Pattani (which is now a province of Thailand) before gaining independence in 1810 from the Pattani Kingdom via a rebellion by the Royal Family.\n\nWhile in the southern parts of Perak (Hilir Perak and Batang Padang) and also in the districts of Kampar and Kinta and several parts of Manjung, the dialect is heavily influenced by southern Malay dialects of the peninsula such as Selangor, Malacca and Johore-Riau Malay and various languages of Indonesian archipelago namely Javanese, Banjar, Rawa, Mandailing and Buginese as a result of historical immigration, civil war such as Klang War and other inevitable factors.\n\nWhilst there are many Malay dialects significantly found in Perak, all Malay dialectologists basically agreed that Perak Malay is spoken by the native Malay people who traditionally have long been subsisting along the riverine system of Perak which comprises Perak River valley and its vicinity except those at the upper stream. Historically, it was a tradition for the Malay peasants in Perak to settle along the Perak River. Royal residences also were built at various sites along the river basin, and there was never any attempt to move to another tributary.\n\nIt has been said that in general, the Malay people in Malaya distinguish the dialect of Perak by the final vowel in Standard Malay substituted into strong 'e': , in contrast to , , and in the other Malay dialects, similar to inland Terengganu dialect. So as for the word (eye) which is shown by the phonemes in Standard Malay, is pronounced as in Perak Malay notably in central Perak region. It appears that Perak Malay has a vowel raising rule which changes word final vowel of Standard Malay to .\n\nException of this rule occurs for some words as shown in the table below. This exception is regarded as common amongst most Malay dialects in the peninsula.\nAs the prevalence of Perak Malay, the diphthongs presented by the graphemes and are often articulated as varied forms of monophthongs. Still and all, diphthongization of monophthongs occurs in certain conditions instead. For instance, the final vowels sound /-i/ and /-u/ are articulated to some extent as diphthongs [-iy] and [-uw] respectively. The monophthongization patterns phonetically vary by the sub-dialects.\nThe pattern /-ai̯/ transformed to [-aː] is particularly restricted to some areas within the district of Perak Tengah. Typically in most villages in Parit and southward to Bota, this pattern is applied. While in the sub-districts of Kampung Gajah and northward to Lambor, the speakers tend to utter in the similar form as in Kuala Kangsar sub-dialect.\n\nThere is a phonological rule in Perak Malay that neutralizes the final nasals to alveolar nasal. The final nasals and phonetically exist in certain environments. In other circumstances, the nasals are neutralized to . This neutralizing rule operates only if the final nasals are directly preceded by or . In addition, the and are allophones of and in closed final syllables in general Malaysian phonology.\nMost of Malay dialects particularly in Malaysia are non-rhotic. Perak Malay is one of non-rhotic variants of Malay language and the 'r' is guttural. In Perak Malay, if the 'r' appears in the initial and middle position of a word, it will be pronounced as French 'r' specifically voiced uvular fricative, [ʁ] but if it comes in the final position of a word and in a postvocalic setting, it will be dropped or deleted and then substituted into an open vowel; usually 'o' by affecting the open vowel preceding it.\n\nPerak Malay differs lexically from Standard Malay for some personal pronouns. The suffix\" '-me' \"indicates plural pronoun. Possibly\" '-me' \"is derived from the word that means 'all' in Malay.\n\"Notes:\"<br>\n\"* Kuala Kangsar variant\"<br>\n\"** Influence of the northern dialect\"\n\nInstead of using \" or \" as intensifier for an adjective, Perak Malay speakers also use specific intensifiers for some adjectives.\nPerak Malay also differs phonetically and lexically from Standard Malay for some animals.\nPerak Malay has distinct names for specific fruits and plants. Some differ in pronunciation from Standard Malay.\n"}
{"id": "12521430", "url": "https://en.wikipedia.org/wiki?curid=12521430", "title": "Profane Swearing Act 1694", "text": "Profane Swearing Act 1694\n\nThe Profane Swearing Act 1694 (6 & 7 Will. & Mar., c.11) was an Act of the Parliament of England in effect from 24 June 1695 and repealed in 1746. It established a system of fines payable for \"suppressing prophane Cursing and Swearing\".\n\nThe preamble recited the provisions of the Profane Swearing Act 1623, noting that it had not been effective at suppressing \"those detestable sins\" due to various perceived deficiencies in the Act.\n\nThe Act provided that any person who profanely swore or cursed in the presence of a justice of the peace, or a town mayor, and was convicted on the oath of one witness or by their own confession, was to pay a fine. The fines were established at 1\"s\" for a servant, labourer, common soldier or seaman, and 2\"s\" for any other person; a second offence was to be fined at double the rate, and a third or later offence at treble. The monies thus received were to be used for the poor relief of that parish. Should an offender not pay the fine or give security, they were to be set in the stocks for an hour (or for two hours, for multiple offences); if under sixteen, they were to be whipped by the parish constable.\n\nAny justice or magistrate who avoided carrying out their duties under the Act were to be fined 5\"l\", half going to the informant. All convictions were to take place within ten days of the offence, and be recorded in a special book kept for the purpose. The Act was to be read four times a year in all parish churches and public chapels, with the parson or curate liable to a fine of 20\"s\" if this duty was neglected.\n\nThe Act was repealed by section 15 of the Profane Oaths Act 1745, which restated its general provisions, increase the fines for gentlemen and higher ranks, and provided for stricter enforcement.\n\n"}
{"id": "9606406", "url": "https://en.wikipedia.org/wiki?curid=9606406", "title": "Proto-Indo-European phonology", "text": "Proto-Indo-European phonology\n\nThe phonology of the Proto-Indo-European language (PIE) has been reconstructed by linguists, based on the similarities and differences among current and extinct Indo-European languages. Because PIE was not written, linguists must rely on the evidence of its earliest attested descendants, such as Hittite, Sanskrit, Ancient Greek, and Latin, to reconstruct its phonology.\n\nThe reconstruction of abstract units of PIE phonological systems (i.e. segments, or phonemes in traditional phonology) is mostly uncontroversial, although areas of dispute remain. Their phonetic interpretation is harder to establish; this pertains especially to the vowels, the so-called laryngeals, and the voiced stops.\n\nProto-Indo-European is traditionally reconstructed to have used the following phonemes. See the article on Indo-European sound laws for a summary of how these phonemes reflected in the various Indo-European languages.\n\nThe table gives the most common notation in modern publications; variant transcriptions are given below. Raised stands for aspiration, and raised for labialization. The *y corresponds to the palatal semivowel whose IPA transcription is [j] (and not to IPA [y]).\n\nFormer reconstructions involved series of four stops: voiceless unaspirated and aspirated, and voiced unaspirated and aspirated: *t, *tʰ, *d, *dʰ. The voiceless aspirated stops, however, came to be reinterpreted as sequences of stop and laryngeal and so the standard reconstruction now includes series of only three, with the traditional phonetic descriptions of \"voiceless\", \"voiced\" and \"voiced aspirated\". However, such a system is not found in any descendant language (Sanskrit had all three, along with a fourth voiceless aspirated series), and it is vanishingly rare in \"any\" recorded languages. The absence or rarity of *b (see below) is also unusual. Additionally, Proto-Indo-European roots have a constraint that forbids roots from mixing voiceless and voiced aspirate stops or from containing two voiced stops. All that has led some scholars to change the reconstruction by replacing the voiced stops by \"glottalized\" and the voiced aspirated stops by \"plain\" voiced.\n\nDirect evidence for glottalization is limited, but there is some indirect evidence, including Winter's law in Balto-Slavic as well as the parallel development of voiceless consonants and voiced aspirate consonants in Germanic: both became fricatives and glottalized (plain voiced in the earlier theory) consonants remained stops.\n\nPIE are grouped with the cover symbol \"P\". The phonemic status of is disputed: it seems not to appear as an initial consonant (except in a few dubious roots such as *bel-, noted below), while reconstructed roots with internal *b are usually restricted to Western branches, casting doubt on their validity for PIE.\n\nSome have attempted to explain away the few roots with *b as a result of later phonological developments. Suggested such developments include\n\nAt best, PIE remains a highly marginal phoneme.\n\nThe standard reconstruction identifies three coronal, or dental, stops: . They are symbolically grouped with the cover symbol \"T\".\n\nAccording to the traditional reconstruction, such as the one laid out in Brugmann's \"Grundriss der vergleichenden Grammatik der indogermanischen Sprachen\" more than a century ago, three series of velars are reconstructed for PIE:\n\nThe actual pronunciation of these sounds in PIE is not certain. One current idea is that the \"palatovelars\" were in fact simple velars, i.e. , while the \"plain velars\" were pronounced farther back, perhaps as uvular consonants, i.e. . If the labiovelars were just labialized forms of the \"plain velars', they would then have been pronounced . For arguments in support of this view, see .\n\nAnother theory is that there may have been only two series (plain velar and labiovelar) in PIE, with the palatalized velars arising originally as a conditioned sound change in satem languages. See .\n\nThe satem languages merged the labiovelars with the plain velar series , while the palatovelars became sibilant fricatives or affricates of various types, depending on the individual language. In some phonological conditions, depalatalization occurred, yielding what appears to be a centum reflex in a satem language. For example, in Balto-Slavic and Albanian, palatovelars were depalatalized before resonants unless the latter were followed by a front vowel. The reflexes of the labiovelars are generally indistinguishable from those of the plain velars in satem languages, but there are some words where the lost labialization has left a trace, such as by u-coloring the following vowel.\n\nThe centum group of languages, on the other hand, merged the palatovelars with the plain velar series , while the labiovelars were kept distinct. Analogous to the depalatalization of the satem languages, the centum languages show delabialisation of labiovelars when adjacent to *w (or its allophone *u), according to a rule known as the boukólos rule.\n\nThe only certain PIE fricative phoneme was a strident sound, whose phonetic realization could range from [s] to palatalized <nowiki>[</nowiki>ɕ<nowiki>]</nowiki> or <nowiki>[</nowiki>ʃ<nowiki>]</nowiki>. It had a voiced allophone *z that emerged by assimilation in words such as \"*nisdós\" ('nest'), and which later became phonemicized in some daughter languages. Some PIE roots have variants with *s appearing initially: such *s is called s-mobile.\n\nThe \"laryngeals\" may have been fricatives, but there is no consensus as to their phonetic realization.\n\nThe phonemes , with cover symbol \"\" also denoting \"unknown laryngeal\" (or and ), stand for three \"laryngeal\" phonemes. The term \"laryngeal\" as a phonetic description is out of date, retained only because its usage has become standard in the field.\n\nThe phonetic values of the laryngeal phonemes are disputable; various suggestions for their exact phonetic value have been made, ranging from cautious claims that all that can be said with certainty is that represented a fricative pronounced far back in the mouth, and that exhibited lip-rounding up to more definite proposal; e.g. Meier-Brügger writes that realizations of = , = and = or \"are in all probability accurate\". Another commonly cited speculation for is (e.g. Beekes). Simon (2013) has argued that the Hieroglyphic Luwian sign *19 stood for /ʔa/ (distinct from /a/) and represents the reflex of . It is possible, however, that all three laryngeals ultimately fell together as a glottal stop in some languages. Evidence for this development in Balto-Slavic comes from the eventual development of post-vocalic laryngeals into a register distinction commonly described as \"acute\" (vs. \"circumflex\" register on long vocalics not originally closed by a laryngeal) and marked in some fashion on all long syllables, whether stressed or not; furthermore, in some circumstances original acute register is reflected by a \"broken tone\" (i.e. glottalized vowel) in modern Latvian.\n\nThe \"schwa indogermanicum\" symbol is sometimes used for a laryngeal between consonants, in a \"syllabic\" position.\n\nIn a phonological sense, sonorants in Proto-Indo-European were those segments that could appear both in the syllable nucleus (i.e. they could be syllabic) and out of it (i.e. they could be non-syllabic). PIE sonorants are the liquids, nasals and glides: , all grouped with the cover symbol \"R\".\n\nAll of them had allophones in a syllabic position, which is generally between consonants, word-initially before consonants and word-finally after a consonant. They are marked as . Even though *i and *u were phonetically certainly vowels, phonologically they were syllabic sonorants.\n\nSome of the changes undergone by the PIE consonants in daughter languages are the following:\n\nSanskrit, Greek, and Germanic, along with Latin to some extent, are the most important for reconstructing PIE consonants, as all of these languages keep the three series of stops (voiceless, voiced and voiced-aspirated) separate. In Germanic, Verner's law and changes to labiovelars (especially outside of Gothic) obscure some of the original distinctions; but on the other hand, Germanic is not subject to the dissimilations of Grassmann's law, which affects both Greek and Sanskrit. Latin also keeps the three series separate, but mostly obscures the distinctions among voiced-aspirated consonants in initial position (all except /gʰ/ become /f/) and collapses many distinctions in medial position. Greek is of particular importance for reconstructing labiovelars, as other languages tend to delabialize them in many positions.\n\nAnatolian and Greek are the most important languages for reconstructing the laryngeals. Anatolian directly preserves many laryngeals, while Greek preserves traces of laryngeals in positions (e.g. at the beginning of a word) where they disappear in many other languages, and reflects each laryngeal different from the others (the so-called \"triple reflex\") in most contexts. Balto-Slavic languages are sometimes valuable in reconstructing laryngeals since they are relatively directly represented in the distinction between \"acute\" and \"circumflex\" vowels. Old Avestan faithfully preserves numerous relics (e.g. laryngeal hiatus, laryngeal aspiration, laryngeal lengthening) triggered by ablaut alternations in laryngeal-stem nouns, but the paucity of the Old Avestan corpus prevents it from being more useful. Vedic Sanskrit preserves the same relics rather less faithfully, but in greater quantity, making it sometimes useful.\n\nIt is disputed how many vowels Proto-Indo-European has or even what counts as a \"vowel\" in the language. It is generally agreed that at least four vowel segments existed, which are normally denoted as *e, *o, *ē and *ō. All of them are morphologically conditioned to varying extents. The two long vowels are less common than the short vowels, and their morphological conditioning is especially strong, suggesting that in an earlier stage there may not have been a length opposition, and a system with as few as two vowels (or even only one vowel, according to some researchers) may have existed.\n\nIn addition, the surface vowels *i and *u were extremely common, and syllabic sonorants existed. All of them alternated in a syllabic position with sonorant consonants *y, *w, *r, *l, *m, *n. For example, the root of the PIE word *yugóm ('yoke') with a *u also appears in the verb *yewg- ('to yoke, harness, join') with *w. Similarly, the PIE word *dóru ('tree, wood') is reconstructed with genitive singular *dréws and dative plural *drúmos. Some authors (e.g. ) have argued that there is substantial evidence for reconstructing a non-alternating phoneme *i in addition to an alternating phoneme *y as well as weaker evidence for a non-alternating phoneme *u.\n\nFurthermore, all the daughter languages have a segment *a, and those with long vowels generally have long . Until the mid-20th century, PIE was reconstructed with all of those vowels. Modern versions incorporating the laryngeal theory, however, tend to view the vowels as later developments of sounds that should be reconstructed in PIE as laryngeals . For example, what used to be reconstructed as PIE is now reconstructed as ; are now reconstructed as , *H representing any laryngeal; and has various origins, among which are a \"syllabic\" (any laryngeal not adjacent to a vowel) or an *e next to the \"a-coloring\" laryngeal . (Though they may have \"phonetically\" contained the vowel in spoken PIE, it would, in fact, be an allophone of *e, not an independent phoneme.) Some researchers, however, have argued that an independent phoneme *a must be reconstructed, and it cannot be traced back to any laryngeal.\n\nAny sonorant consonant can comprise the second part of a complex syllable nucleus; all can form diphthongs with any of the vowels *e, *o, *ē, *ō (such as , etc.).\n\nIt is generally accepted that PIE did not allow vowels word-initially; the vowel-initial words in earlier reconstructions are now usually reconstructed as beginning with one of the three laryngeals; they disappeared in all daughter languages except Hittite before a vowel (after coloring it, if possible).\n\nIn particular morphological (such as a result of Proto-Indo-European ablaut) and phonological conditions (like in the last syllable of nominative singular of a noun ending on sonorant, in root syllables in the sigmatic aorist, etc.; compare Szemerényi's law, Stang's law) vowels *e and *o would lengthen, yielding respective lengthened-grade variants. The basic lexical forms of words contained therefore only short vowels; on the basis of well-established morphophonological rules forms with long vowels, *ē and *ō appeared.\n\nLengthening of vowels may have been a phonologically-conditioned change in Early Proto-Indo-European, but at the period just before the end of Proto-Indo-European, which is usually reconstructed, it is no longer possible to predict the appearance of all long vowels phonologically, as the phonologically-justified resulting long vowels have begun to spread analogically to other forms without being phonologically justified. The prosodically-long *e in 'father' results by the application of Szemerényi's law, a synchronic phonological rule that operated within PIE, but prosodically-long *o in 'foot' was analogically levelled.\n\nIt is possible that Proto-Indo-European had a few morphologically-isolated words with the vowel *a: *dap- 'sacrifice' (Latin \"daps\", Ancient Greek \"dapánē\", Old Irish \"dúas\") or appearing as a first part of a diphthong *ay: *laywos 'left' (Latin \"laevus\", Ancient Greek \"laiós\", OCS \"lěvъ\"). The phonemic status of *a has been fiercely disputed; Beekes concludes: \"There are thus no grounds for PIE phoneme *a\"; the same conclusion is reached by his former student, Alexander Lubotsky.\n\nAfter the discovery of Hittite and the development of the laryngeal theory, almost every instance of previous *a could be reduced to the vowel *e, preceded or followed by the laryngeal *h₂ (rendering the previously reconstructed short and long *a, respectively). Against the possibility of PIE phoneme *a, still today held by some Indo-Europeanists, the following can be said: vowel *a does not participate in ablaut alternations (it does not alternate with other vowels, as the \"real\" PIE vowels *e, *o, *ē, *ō do), it makes no appearance in suffixes and endings, it appears in very confined set of positions (usually after initial *k, which could be the result of that phoneme being a-coloring, particularly likely if it was uvular /q/), and the reflexes of words upon which *a is reconstructed are usually confined only to a few Indo-European languages. For example, *bʰardʰéh₂ 'beard,' is confined to the western and northern daughter families. That makes it possible to ascribe it to some late PIE dialectalism or of expressive character (like the interjection *wai 'alas') and so is not suitable for comparative analysis, or they are argued to have been borrowed from some other language which had phonemic *a (like Proto-Semitic *θawru > PIE *táwros ('aurochs')).\n\nHowever, others, like Manfred Mayrhofer, argue that and phonemes existed independently of . This phoneme appears to be present in reconstructions such as *albʰós (\"white\"), or *átta (\"father\"), where the absence of a laryngeal is confirmed by the respective Hittite descendants; 𒀠𒉺𒀸 (\"al-pa-aš\", \"cloud\") and 𒀜𒋫𒀸 (\"at-ta-aš\", \"father\").\n\nAncient Greek reflects the original PIE vowel system most faithfully, with few changes to PIE vowels in any syllable; but its loss of certain consonants, especially *s, *w and *y, often triggered a compensatory lengthening or contraction of vowels in hiatus, which can complicate reconstruction.\n\nSanskrit and Avestan merge *e, *a and *o into a single vowel *a (with a corresponding merger in the long vowels) but reflect PIE length differences (especially from the ablaut) even more faithfully than Greek, and they do not have the same issues with consonant loss as Greek. Furthermore, *o can often be reconstructed by Brugmann's law and *e by its palatalization of a preceding velar (see Proto-Indo-Iranian language).\n\nGermanic languages show a merger of long and short *a and *o as well as the merger of *e and *i in non-initial syllables, but (especially in the case of Gothic) they are still important for reconstructing PIE vowels. Balto-Slavic languages have a similar merger of short *a and *o, and Slavic languages a merger of long *ā and *ō.\n\nEvidence from Anatolian and Tocharian can be significant because of their conservatism but are often difficult to interpret; Tocharian, especially, has complex and far-reaching vowel innovations.\n\nItalic languages and Celtic languages do not unilaterally merge any vowels but have such far-reaching vowel changes (especially in Celtic and the extreme vowel reduction of early Latin) that they are somewhat less useful. Albanian and Armenian are the least useful, as they are attested relatively late, have borrowed heavily from other Indo-European languages and have complex and ill-understood vowel changes.\n\nIn Proto-Balto-Slavic, short PIE vowels were preserved, with the change of *o > *a, as in Proto-Germanic. A separate reflex of the original *o or *a is, however, argued to have been retained in some environments as a lengthened vowel because of Winter's law. Subsequently, Early Proto-Slavic merged *ō and *ā, which were retained in the Baltic languages. Additionally, accentual differences in some Balto-Slavic languages indicate whether the post-PIE long vowel originated from a genuine PIE lengthened grade or is a result of compensatory lengthening before a laryngeal.\n\nPIE had a free pitch accent, which could appear on any syllable and whose position often varied among different members of a paradigm (e.g. between singular and plural of a verbal paradigm, or between nominative/accusative and oblique cases of a nominal paradigm). The location of the pitch accent is closely associated with ablaut variations, especially between normal-grade vowels (/e/ and /o/) and zero-grade vowels (i.e. lack of a vowel).\n\nGenerally, thematic nouns and verbs (those with a \"thematic vowel\" between root and ending, usually /e/ or /o/) had a \"fixed accent\", which (depending on the particular noun or verb) could be either on the root or the ending. These words also had no ablaut variations within their paradigms. (However, accent and ablaut were still associated; for example, thematic verbs with root accent tended to have e-grade ablaut in the root, while those ending accent tended to have zero-grade ablaut in the root.) On the other hand, athematic nouns and verbs usually had \"mobile accent\", with varied between \"strong forms\", with root accent and full grade in the root (e.g. the singular active of verbs, and the nominative and accusative of nouns), and \"weak forms\", with ending accent and zero grade in the root (e.g. the plural active and all forms of the middle of verbs, and the oblique cases of nouns). Some nouns and verbs, on the other hand, had a different pattern, with ablaut variation between lengthened and full grade and mostly fixed accent on the root; these are termed \"Narten stems\". Additional patterns exist for both nouns and verbs. For example, some nouns (so-called \"acrostatic nouns\", one of the oldest classes of noun) has fixed accent on the root, with ablaut variation between o-grade and e-grade, while \"hysterodynamic nouns\" have zero-grade root with a mobile accent that varies between suffix and ending, with corresponding ablaut variations in the suffix.\n\nThe accent is best preserved in Vedic Sanskrit and (in the case of nouns) Ancient Greek. It is also reflected to some extent in the accentual patterns of the Balto-Slavic languages (e.g. Latvian, Lithuanian and Serbo-Croatian). It is indirectly attested in a number of phenomena in other PIE languages, especially the Verner's law variations in the Germanic languages. In other languages (e.g. the Italic languages and Celtic languages) it was lost without a trace. Other than in Modern Greek, the Balto-Slavic languages and (to some extent) Icelandic, few traces of the PIE accent remain in any modern languages.\n\nA number of phonological rules can be reconstructed for Proto-Indo-European. Some of them are disputed to be valid for \"PIE proper,\" and are claimed to be later innovations in some of the daughter branches. Some of these laws are:\n\nSzemerényi's law deleted word-final \"s\" or \"h₂\" when preceded by a sonorant and a vowel, triggering compensatory lengthening of the vowel: -VRs, -VRh₂ > VːR. For example:\nThis rule was no longer productive in late PIE, and many potential examples were restored by analogy. For example, the genitive singular of neuter nouns in \"-men-\" is reconstructed as \"-mén-s\" rather than \"-mḗn\". It was grammaticalised for the nominative singulars of nouns ending in a sonorant, as well as the nominoaccusative of neuter collectives. By analogy, several nouns ending in other consonants also acquired a long vowel in the nominative singular, but retained the \"-s\" ending where possible, e.g. \"*pṓd-s\", \"*dyḗw-s\".\n\nStang's law affects sequences of final consonants, much like Szemerényi's law, but the result is to delete the second-last consonant rather than the final one. Specifically, \"w\" is deleted when between a vowel and a final \"m\", again with compensatory lengthening: Vwm > *Vːm.\n\nSome linguists include an additional rule to delete \"h₂\" before final \"m\": *Vh₂m > *Vːm.\n\nPIE generally disallowed two of the same consonant to appear next to each other. Various rules were employed in order to eliminate such sequences.\n\nWhen two of the same sonorant or \"*s\" appeared in sequence, and were preceded by a vowel, one of the two was deleted. Additionally, if the sequence was word-final, the preceding vowel received compensatory lengthening.\n\nIn a sequence of dental stops, an epenthetic \"*s\" was inserted between them.\nThis rule has been preserved in Hittite where cluster *tst is spelled as \"z\" (pronounced as [ts]). The cluster was often simplified to -ss- in the later descendants (Latin and Germanic among others). Sanskrit does not have the rule (Bartholomae's law takes precedence instead), but it does occur in Iranian.\n\nIf a dental sequence was followed by a sonorant, one of the dentals was deleted. The evidence is conflicting on which dental was deleted.\n\nBartholomae's law is an assimilation law which caused sequences of aspirated plus unaspirated stop to become entirely aspirated: > . For example:\nThe law has been preserved in the Indo-Iranian branch where it operates as a synchronic rule. There are some traces of it in Ancient Greek and Germanic, and possibly in Latin.\n\nSiebs' law related to the feature of s-mobile: whenever it is added to a root that begins with a voiced or aspirated stop, that stop is devoiced. If the stop was aspirated, it may retain its aspiration in some branches. For example:\n\nA thorn cluster is any sequence of a dental stop followed by a velar stop. In the IE branches other than Anatolian and Tocharian, thorn clusters undergo metathesis, and in many, the dental also assibilates. For example, for the noun \"*dʰéǵʰ-ōm\", genitive \"*dʰǵʰ-m-és\", Hittite has \"tēkan\", \"tagnās\", \"dagān\" and Tocharian A \"tkaṃ\", \"tkan-\", but these forms appear in Sanskrit \"kṣā́ḥ\" and in Ancient Greek as \"khthṓn\". Sanskrit has assibilation of the cluster \"*kt\" to \"kṣ\", while Greek has metathesis alone.\n\nSome possible outcomes of the metathesis are illustrated by the following cases:\n\nThorn clusters presented a problem in the reconstruction of some cognate sets in which Indo-Iranian sibilants in clusters with dorsals exceptionally correspond to coronal stops in certain other branches (particularly the Hellenic languages). 'Bear' and 'decaying' above are examples; another is Sanskrit \"tákṣan\" 'artisan' vs. Greek \"téktōn\" 'carpenter'. As was the case with the laryngeal theory, these cognate sets were first noted prior to the connection of Anatolian and Tocharian to PIE, and early reconstructions posited a new series of consonants to explain these correspondences. Brugmann 1897's systematic explanation augmented the PIE consonant system with a series of interdentals (nowhere directly attested) appearing only in clusters with dorsals, *kþ *kʰþʰ *gð *gʰðʰ. The use of the letter thorn led to the name \"thorn cluster\" for these groups.\n\nOnce discovered, Anatolian and Tocharian evidence suggested that the original form of the thorn clusters was, in fact, *TK, so that the development outside Anatolian and Tocharian involved a metathesis. The conventional notations *þ *ð *ðʰ for the second elements of these metathesised clusters are still found, and some, including Fortson, continue to hold to the view that interdental fricatives were involved at some stage of PIE. An alternative interpretation (e.g. Vennemann 1989, Schindler 1991 (informally and unpublished)) identifies these segments as alveolar affricates . In this view, thorn clusters developed as TK > TsK > KTs and then variously in daughter languages; this has the advantage that the first change can be identified with the dental assibilation rule above, which is then broadened in application to affrication of dental stops before any stops. Melchert has interpreted the Cuneiform Luwian \"īnzagan-\" 'inhumation', probably [ind͡zɡan], from * 'in the earth', as preserving the intermediate stage of this process.\n\nOnce the laryngeal theory was developed, and the rules for sound change of laryngeals worked out, it was clear that there were a number of exceptions to the rules, in particular with regard to \"syllabic\" laryngeals (former \"schwa indogermanicum\") that occurred in non-initial syllables. It was long suggested that such syllabic laryngeals were simply deleted in particular of the daughters; this is based especially on the PIE word * \"daughter\", which appears in a number of branches (e.g. Germanic, Balto-Slavic) with no vowel in place of expected /a/ for \"syllabic\" /h₂/ (cf. English \"daughter\", Gothic \"daúhtar\"). With a better understanding of the role of ablaut, however, and a clearer understanding of which roots did and did not have laryngeals in them, it became apparent that this suggestion cannot be correct. In particular, there are some cases where syllabic laryngeals in medial syllables delete in most or all daughter languages, and other cases where they do not delete even in Germanic and/or Balto-Slavic.\n\nThis has led to the more recent idea that PIE had a number of synchronic \"laryngeal deletion\" rules, where syllabic laryngeals in particular contexts were deleted even in the protolanguage. In the case of *, for example, it appears that PIE had an alternation between a \"strong\" stem * and a \"weak\" stem *, where a deletion rule eliminated the laryngeal in the latter context but not the former one. Forms in daughter languages with the laryngeal (Ancient Greek \"thugátēr\", Sanskrit \"duhitṛ\") or without the laryngeal (Gothic \"dauhtar\", Lithuanian \"duktė̃\") are due to analogical generalization of one or the other protoforms.\n\nThis is a new area, and as a result, there is no consensus on the number and nature of the deletion rules. A wide variety of rules have been proposed; Ringe (2006) identifies the following three as the most likely candidates (where C=any consonant, V=any vowel, H=any laryngeal, R=any resonant):\n\n\nIt seems unlikely that this is a correct and complete description of the actual phonological rules underlying laryngeal deletion. These rules do not account for all the potential cases of laryngeal deletion (hence the many other rules that have been proposed); for example, the laryngeal in the desiderative suffixes *-h₁s- and *-h₁sy- appears to delete after an obstruent but not a resonant. In any case it is difficult to determine when a particular laryngeal loss is due to a protolanguage rule versus an instance of later analogy. In addition, as synchronic phonological rules the set of above rules is more complicated than what is expected from a cross-linguistic standpoint, suggesting that some of the rules may have already been \"morphologized\" (incorporated into the morphology of certain constructions, such as the o-grade noun-forming rule or the rule forming y-presents); the above-mentioned laryngeal deletion in the desiderative suffixes may be an example of such morphologization.\n\n\n"}
{"id": "9974786", "url": "https://en.wikipedia.org/wiki?curid=9974786", "title": "Proto-Turkic language", "text": "Proto-Turkic language\n\nThe Proto-Turkic language is the linguistic reconstruction of the common ancestor of the Turkic languages. It was spoken by the Proto-Turks before their divergence into the various Turkic peoples. Proto-Turkic separated into Oghur (western) and Common Turkic (eastern) branches. One estimate postulates Proto-Turkic to have been spoken 2,500 years ago in East Asia.\n\nThe oldest records of a Turkic language, the Old Turkic Orkhon inscriptions of the 7th century Göktürk khaganate, already shows characteristics of eastern Common Turkic, and reconstruction of Proto-Turkic must rely on comparisons of Old Turkic with early sources of the western Common Turkic branches, such as Oghuz and Kypchak, as well as the western Oghur proper (Bulgar, Chuvash, Khazar). Because early attestation of these non-easternmost languages is much more sparse, reconstruction of Proto-Turkic still rests fundamentally on the easternmost Old Turkic of the Göktürks.\n\nThe consonant system had a two-way contrast of stop consonants (fortis vs. lenis), \"k, p, t\" vs. \"g, b, d\", with verb-initial \"b-\" becoming \"h-\" still in Proto-Turkic. There was also an affricate consonant, \"č\"; at least one sibilant \"s\"; and sonorants \"m, n, ń, ŋ, r, ŕ, l, ĺ\" with a full series of nasal consonants.\n\nThe sounds denoted by \"ń, ĺ, ŕ\" refer to palatalized sounds and have been claimed by Altaicists to be direct inheritances from Proto-Altaic. The last two can be reconstructed with the aid of the Oghur languages, which show for *ŕ, *ĺ, while Common Turkic has *z, *š. Oghuric is thus sometimes referred to as Lir-Turkic and Common Turkic as Shaz-Turkic.\n\nHowever, an alternate theory holds that Common Turkic is closer to the original state of affairs, and reconstructs Proto-Turkic *z, *š. The glottochronological reconstruction based on analysis of isoglosses and Sinicisms points to the timing of the \"r/z\" split at around 56 BCE–48 CE. This, as A. V. Dybo puts it may be associated with:\n\nthe historical situation that can be seen in the history of the Huns' division onto the Northern and Southern [groups]: the first separation and withdrawal of the Northern Huns to the west has occurred, as was stated above, in 56 BC, ... the second split of the (Eastern) Huns into the northern and southern groups happened in 48 AD.\n\nDybo suggests that during that period, the Northern branch steadily migrated from western Mongolia through southern Xinjiang into the north's Dzungaria and then finally into Kazakhstan's Zhetysu until the 5th century.\nLike most of its descendants, Proto-Turkic exhibited vowel harmony, distinguishing vowel qualities \"e, i, o, u\" vs. \"ë, ï, ö, ü\" besides \"a\", as well as two vowel quantities.\n\n"}
{"id": "44116507", "url": "https://en.wikipedia.org/wiki?curid=44116507", "title": "Rekandar Nageswara Rao", "text": "Rekandar Nageswara Rao\n\nRekandar Nageswara Rao, popularly known as Surabhi Babji, is an Indian thespian, and director, known for his works in Telugu theatre. He was honored by the Government of India, in 2013, by bestowing on him the Padma Shri, the fourth highest civilian award, for his contributions to the field of art.\n\nRekander Nageswar Rao, born in a theatre owning family, in the remote village of Gimidi Peta in Srikakulam district, in Andhra Pradesh, in India, is a fourth generation theatre owner. His forefathers, viz. Rekander Chiina Venkatrao, who founded the \"Sri Venkateswara Natya Mandali\" (Surabhi) in 1937, Rekandar Dasaradhi Rao and Rekandar Bhoja Raju wee ll known theatre personalities. He takk charge of running the theatre group in 1973.\n\nSome of his notable plays are \"Lavakusa\", \"Mayabazar\", \"Anasuya\", \"Sri Veera Brahmam gari Charitra\", \"Harishnandra\", \"Bobbili Yuddham\", \"Balanagamma\", \"Chintamani\", and \"Rangoon rowdy\". He has also assisted B. V. Karanth, renowned Kannada director, in a play by name, \"Chandi Priya\".\n\nRekander Nageshwar Rao is a recipient of the Sangeet Natak Akademi Award, which he received in 2011. A year later, the Government of India honoured him with the civilian award of Padma Shri, in 2013.\n"}
{"id": "34348472", "url": "https://en.wikipedia.org/wiki?curid=34348472", "title": "Richard Spencer (journalist)", "text": "Richard Spencer (journalist)\n\nRichard John Spencer (born in London, England 3 June 1965) is a British journalist. He was the Middle East Editor for \"The Daily Telegraph\".\n\nSpencer was educated at Sherborne School and Lincoln College, Oxford. He has previously worked for six years as the newspaper's Beijing correspondent before moving to Dubai, United Arab Emirates to take up his new post as one of their Middle East correspondents. Spencer moved to Cairo, Egypt in the wake of the Arab Spring for ease of coverage. He has been based in London since 2014.\n\nSpencer is married to writer and poet, Dr Helen Wing. Spencer and Wing have three children together.\n\nA well known blogger for \"The Daily Telegraph\"s blog, he is known for his witty anecdotes and dry sense of humour. Spencer was the first Western journalist to reach Yingxiu after the 2008 Sichuan earthquake where 80% of the town had been destroyed.\n\n"}
{"id": "23835943", "url": "https://en.wikipedia.org/wiki?curid=23835943", "title": "Simcha Lieberman", "text": "Simcha Lieberman\n\nRabbi Simcha Binem Lieberman (29 December 1929 – 28 June 2009) was an Israeli Talmudic scholar, lecturer at Jews' College, London, and a prolific writer. He was one of the last survivors of the Warsaw Ghetto.\n\nSimcha Binem was born in Warsaw, Poland on 29 December 1926 (24 Teveth 5687 in the Hebrew calendar) to his father Rabbi Brachya Lieberman, a notable Gerrer hasid. He received the traditional education in chasidic families, steeped in the study of the Talmud and its commentators. This ended abruptly in 1939 with the Nazi invasion of Poland.\n\nWith the enclosure of Warsaw Jewry in a confined ghetto, his education continued along with the fight for survival entailed in ghetto life. When the bulk of the ghetto population was sent to the Treblinka extermination camp, Simcha, as an able-bodied teenager, was transferred to Majdanek, where he worked as a slave labourer. He was tortured brutally on account of his involvement in numerous acts of sabotage. Ultimately he was imprisoned in seven concentration camps including Dachau and Theresienstadt.\n\nIn 1945 he was rescued by Rabbi Dr. Solomon Schonfeld, Director of the Chief Rabbi's Emergency Council, and brought to England. He returned to his studies and eventually became a Fellow of Gateshead Kollel. He married Chava Sosha, a survivor of the Auschwitz concentration camp.\n\nIn 1960 he was appointed head of the Hendon Kolel.\n\nIn 1971 he was appointed to the faculty of Jews' College, London as a lecturer in Talmud and Codes, a post he held until 1984, when he was 'made redundant' by the then Principal of the college, Jonathan Sacks (now Chief Rabbi of Great Britain). He then used his vast Talmudic knowledge to start writing a series of volumes titled \"Bishvilei Oraiso\" (in the paths of the Torah) and delivering public lectures on the fruits of his research.\n\nIn 1992 Rabbi Simcha emigrated from England and settled in the Har Canaan district of Tzfat, a mountain-top city in the Galilee, Israel. He established an institute for the publication of his writings, eventually publishing 20 volumes in the \"Bishvilei Oraiso\" series.\n\nHis wife Chava predeceased him. He died on 28 June 2009, aged 79, leaving 11 children.\n\n"}
{"id": "26629701", "url": "https://en.wikipedia.org/wiki?curid=26629701", "title": "Strange to Relate", "text": "Strange to Relate\n\nStrange to Relate was the name of a weekly syndicated newspaper column written by Rabbi Philip R. Alstat, that appeared in the Jewish press for almost 40 years, from 1938 through 1976, the year of Alstat's death. It first appeared in \"The Jewish Youth Journal\" and \"The American Examiner\".\nThe column was sometimes referred to as a mixture of journalism, Jewish education and \"Ripley's Believe It or Not!\"\n\nIn the approximately 1500 weekly columns that Alstat wrote, \"Strange to Relate\" revealed fascinating and little-known information about Judaism, its history, its people, and their intersection with American and World events. The columns appeared in both English and Yiddish papers, including \"The American Examiner,\" and \"The New York Jewish Week.\" Quoting poetry, literature, and the latest news stories, ranging from scientific discoveries to international events, he wrote articles about the often surprising and usually unanticipated \"Jewish connections\" in the news.\n\nThe subjects of the column were wide-ranging, dealing with facts about the Bible and its stories, the American and world Jewish communities, and historic events in the secular and Jewish calendars. Some examples include:\n\n\nExamples of the titles of his columns further reveal the wide range of his topics:\n\nIn view of the difficulties encountered in introducing Hebrew as a subject in the high schools and colleges of New York City, one would never suspect that there was a time when the sacred tongue was readily accorded a place of honor in American higher education. This early American reverence for Hebraic scholarship was imported by the Puritans on the Mayflower from its European sources, the general cultural renaissance and the Protestant Reformation. Here in America it was then intensified by the extreme Puritan piety which regarded the Hebrew Scriptures as the direct revelation of God's will.\n\nConsequently, when Harvard, the oldest of America's colleges, was founded in 1636 for the training of ministers, it was inevitable that Hebrew should play a significant role as a required course of study for the B.A. degree, in the daily scriptural lessons, and in oratorical and declamation contests (For 38 years, 1722–1760, it was taught by Judah Monis, a baptized Jewish hardware merchant of Cambridge, Mass.) Moreover, at the Commencement Exercises in 1685, both the President of Harvard, Increase Mather, and his son, Nathanael, delivered their orations in Hebrew.\n\nHowever, the task of mastering this difficult semitic language proved so unpopular with the students that in 1825 the faculty was constrained to make the study of Hebrew optional (which innovation was incidentally the beginning of the elective system at Harvard).\n\nIn recent years, two Jewish philanthropists, Jacob H. Schiff and Lucius N. Littauer, attempted to revive interest in Hebraism at Harvard by endowing respectively, a Semitic Museum and a chair in Jewish literature and philosophy.\n\nVery few people, either Jewish or gentile, know that there was once a state in the Union where Jews were denied complete equality until 1826. That place was the State of Maryland. Though it was one of the thirteen original colonies that raised the flag of revolution against British tyranny, though its representatives were among the signatories to the Declaration of Independence which in 1776 declared that \"all men were created equal,\" yet intolerance and religious bigotry persisted for half a century longer.\n\nThrough the colonial period (1634–1776) the Jews of Maryland were legally (de jure) not only without any civil rights, but even subject to the penalty of death for merely professing Judaism. Actually (de facto), however, they were tacitly granted undisturbed domicile and gradually allowed certain undefined rights.\n\nWith the adoption of a state constitution in 1776, the official association of the government and the Christian church was ended. The new law abolished the death penalty for professing Judaism and even granted to Jews the right to vote, but virtually denied them the right to hold office. For in the minds of the people, citizenship and church membership were still so closely identified that those elected or appointed to political office were required by law to take an oath ending with the doctrinal affirmation \"of belief in the Christian religion.\"\n\nBeginning with 1797, the Jews of Maryland were naturally persistent in their efforts for the removal of all their civil disabilities; but the House of Delegates was equally consistent in rejecting their petitions and defeating the bills designed to bring them relief. Thus the struggle continued, with the aid of influential Christians the pre press of the country, till February 26, 1825, when the House of Delegates, by a vote of 26 to 25, finally passed a bill which provided that Jewish citizens taking the oath of office shall substitute for the affirmation of \"belief in the Christian religion,\" another declaration of belief in a future world of rewards and punishments. When this law became effective in 1826, the Jewish emancipation in Maryland was complete. Subsequently, constitutional conventions abolished the religious test altogether.\n\nHis columns were frequently quoted by rabbis throughout the country in sermons and columns. Additionally, in letters to the editor and personal correspondence, readers would write about \"their indebtedness to him for their revived interest in Torah and the people of Israel.\". The columns were frequently reprinted in the works of others during his lifetime, and long after his death. For example, this story of the 13th century Jewish philosopher, Abraham Abulafia, was included in the 1995 collection, \"A Treasury of Jewish Anecdotes\":\nIn the summer of 1280, Abraham Abulafia went to Rome to convert the Pope to Judaism. He wanted to meet Pope Nicklaus III on the eve of the Jewish New Year and persuade the leader of the world's Roman Catholics to become a Jew. The Pope, then at a summer house, heard of the plan, and ordered that Abulafia be burned at the stake. Abulafia arrived at the gate of the papal residence, but he was not arrested. The Pope had died as a result of an apoplectic stroke during the preceding night. Abulafia was jailed for 28 days and then released.\n"}
{"id": "46968026", "url": "https://en.wikipedia.org/wiki?curid=46968026", "title": "The Hague dialect", "text": "The Hague dialect\n\nThe Hague dialect (Standard Dutch: \"Haags\", \"het Haagse dialect\"; The Hague dialect: \"Haags\", \"et Haagse dialek\") is a dialect of Dutch mostly spoken in The Hague. It differs from Standard Dutch almost exclusively in pronunciation.\n\nIt has two subvarieties:\n\n\nRijswijk and Voorburg are for the most part Haags-speaking.\n\nScheveningen has its own dialect (\"Schevenings\"), which is different than the traditional The Hague dialect. However, some people also speak The Hague dialect there, or a mixture between the Scheveningen dialect and The Hague dialect (\"Nieuw-Schevenings\").\n\nLoosduinen also has its own dialect (\"Loosduins\"), which is very similar to The Hague dialect. It differs from the latter by having a diphthongal pronunciation of and .\n\nSome people also speak The Hague dialect in Zoetermeer. That is because an influx of people from The Hague to Zoetermeer took place in the 1960s, multiplying the population of the latter twelve times.\n\nApart from Tilburg, The Hague is the only Dutch city with an official dialectal spelling, used e.g. in the \"Haagse Harry\" comic series written by Marnix Rueb.\n\nApart from that, The Hague dialect is rather rarely written. The Haagse Harry spelling works as follows:\n\nThe sound inventory of The Hague dialect is very similar to that of Standard Dutch.\n\n\n\n\n\nThe following list contains only a few examples.\n\nEt Haags is et stasdialek dat doâh de âhtogtaune \"volleksklasse\" van De Haag wogt gesprauke. Et behoâht tot de Zùid-Hollandse dialekte.\n\nHet Haags is het stadsdialect dat door de autochtone \"volksklasse\" van Den Haag wordt gesproken. Het behoort tot de Zuid-Hollandse dialecten.\n\nThe Hague dialect is a city dialect that is spoken by the autochthonous working class of The Hague. It belongs to the South Hollandic dialects.\n"}
{"id": "3533439", "url": "https://en.wikipedia.org/wiki?curid=3533439", "title": "Wild card (sports)", "text": "Wild card (sports)\n\nA wild card (variously spelled wildcard or wild-card, also known as at-large berth) is a tournament or playoff berth awarded to an individual or team that fails to qualify in the normal way, for example by having a high ranking or winning a qualifying stage. In some events, wild cards are chosen freely by the organizers. Other events have fixed rules. Some North American professional sports leagues compare the records of teams which did not qualify directly by winning a division or conference. A wild card game is not a playoff game!\n\nIn international sports, the term is perhaps best known in reference to big international sporting events such as the Olympic Games and tennis tournaments such as Wimbledon. Countries which fail to produce athletes who meet qualification standards are granted \"wild cards\", which allow them to enter competitors whose proven abilities are below the standard otherwise required. In some instances, wild cards are given to the host nation in order to boost its chances.\n\nIn Olympic and World Championship competitions in track and field and swimming, however, nations are automatically allowed to enter two competitors, so these instances are technically not wild cards. In some other Olympic sports, such as judo, archery, and badminton, wild cards are in use, and they are granted by the respective sport federations.\n\nOn rare occasions, a competitor who had gained entry by wild card succeeds in winning a medal or the championship. For example, Kye Sun-Hui won gold in judo at the 1996 Summer Olympics, Ding Junhui won the 2005 China Open snooker championship, Goran Ivanišević won the 2001 Wimbledon Championships, Kim Clijsters won the 2009 US Open, and Lin Dan won the 2013 BWF World Championships.\n\nIn North American professional sports leagues, \"wild card\" refers to a team that qualifies for the championship playoffs without winning their specific conference or division outright. The number of wild card teams varies. In most cases, the rules of the league call for the wild card team to survive an extra round or to play the majority of their postseason games away from home.\n\nThe term \"wild card\" does not apply to postseason formats where a set number of teams per division qualify. Former examples include: the American Football League's 1969 playoffs (qualifying the top two finishers from each division), the National Basketball Association's 1967-through-1970 playoffs (top four finishers from each division) and 1971–1972 playoffs (top two finishers in each division), and the National Hockey League's 1968–1974 and 1982–1993 playoffs (top four finishers from each division) are not true wild-card formats. When a wild-card playoff format is used, the number of teams in a division that qualify is not fixed; the divisional champion automatically qualifies, but non-division winners qualify, based either on league record or conference record.\n\nIn Major League Baseball (MLB), wild-card playoff spots are given to the two teams in each league (four teams overall) with the best records among the non-division winners. The initial wild-card format was implemented after MLB expanded to 28 teams and realigned its two leagues to each have three divisions. Since a three-team playoff would require one team to receive a bye, the wild card was created to allow a fourth team. The wild card has been in effect since 1995, although it was supposed to be used in 1994; the postseason was canceled due to the players' strike. In 2012, a second wild card was added to each league. The two wild card teams in each league face each other in a one-game playoff, with the winner facing the number 1 seed in the Division Series.\n\nThe advantages of the wild card format are that it allows a second- (or third-) place team a chance to win the World Series, even if there is a dominant division winner. As the wild cards are not awarded by division, the additional teams are part of league-wide races for the fourth and fifth spots. Critics of the wild card, such as broadcaster Bob Costas in his book \"Fair Ball: A Fan's Case for Baseball\", have argued that, of the four major North American sports, baseball, having the most regular-season games (now 162), places the largest importance on the regular season, and the wild cards diminish the importance of the regular season by permitting a \"second banana\" team to make the playoffs, and that while it creates a league-wide race, it is for second place (and maybe third place) in a division, and takes away what would otherwise be a pennant race between first- and second-place teams, and can lead to teams playing for the wild card rather than to win the division. The second wild card was added in 2012 to address the issue of teams being content to rest players and win the wild card instead of trying to win the division. Also, because of the \"sudden-death\" round, these teams often use their best starting pitcher, leaving them unavailable for much of the Division Series.\n\nA wild-card team must surrender home-field advantage the first two rounds of the playoffs. For the World Series, however, home-field advantage is determined without reference to wild-card status. Prior to 2003, it was decided by alternating each year between the American and National Leagues. From 2003 to 2016, it was granted to the winner of the All-Star Game. Since 2017, it has been granted to the team with the better record. In the 2002 World Series, both the Anaheim Angels and the San Francisco Giants were wild-card teams, as were the Giants and the Kansas City Royals in the 2014 World Series. The World Series champions in 1997, 2003, 2004, and 2011 were also wild-card teams.\n\n\n\nIn the National Football League (NFL), each of the two conferences sends two wild-card teams along with four division champions to its postseason. The first round of the playoffs is called the \"Wild Card Round\". In this round, each conference's two best (by regular-season record) division champions are exempted from play and granted automatic berths in the \"Divisional Round\". The four division champions are seeded from #1 through #4, while the two wild card teams are seeded #5 and #6; within these separations, seeding is by regular-season record. In the \"Wild Card Round\", the #6 team (a wild card team) plays against the #3 team (a division champion), and the #5 team (a wild card team) plays against the #4 team (a division champion). The division champions have automatic home-field advantage in these games. In the \"Divisional Round\", the worst seeded remaining team plays the #1 seeded team, while the best seeded remaining team that played in the wildcard round plays the #2 seed. Both the #1 seed and #2 seed have home-field advantage in the divisional round.\n\nThe NFL was the first league ever to use the wild-card format. The decision to implement a Wild Card coincided with the completion of the AFL-NFL merger in 1970. Prior to the merger, the right to compete in the postseason for the NFL title was restricted to division/conference champions. Until 1967, a tiebreaker game was played to resolve a deadlock for first place in either of the two conferences. When the league expanded to 16 teams, it realigned into four divisions and expanded the playoffs to two rounds. Tiebreaker games were eliminated in favor of the use of performance-based criteria to determine division champions. The rival American Football League, which reached a final size of ten teams in two divisions, also restricted its postseason to division winners until the 1969 season (the AFL's last as a separate league) when it expanded the playoffs to include division runners-up. The runners-up played the winners of the opposite divisions for the right to contest the AFL Championship Game.\n\nFollowing AFL upsets in the last two Super Bowls prior to the merger, the merged league realigned into two conferences of thirteen teams each, with three \"old-line\" NFL teams joining the AFL teams in the newly-formed American Football Conference. The decision to make the conferences equal in size meant they could not feasibly align into anything except three divisions of four and five teams each. This led to a debate as to how the postseason of the merged league should be structured. Both the NFL and AFL playoff formats of 1969 had attracted fierce critics. The NFL format was criticized for its ability to cause a team tied for first overall in the league to miss the playoffs (this happened once, in 1967, when the Baltimore Colts missed the postseason despite a .917 winning percentage after losing a tiebreaker to the Los Angeles Rams). The AFL's 1969 playoffs were criticized by NFL purists for breaking with longstanding tradition, also, due to the fact that they allowed runners-up to qualify no matter how much disparity existed between the divisions, the AFL playoff structure could allow a mediocre team to qualify - this did occur when the Houston Oilers, a .500 team, finished second in the Eastern Division - the Oilers were throttled in the playoffs 56-7 by the Western champion Oakland Raiders. The Raiders went on to lose the AFL title game to the Western runner-up (and eventual Super Bowl IV champion) Kansas City Chiefs.\n\nDespite Kansas City's win, some purists argued for the tradition of having only division champions contest the playoffs to continue. Had they prevailed, the post-merger NFL playoffs would have consisted of six teams and might have closely resembled the playoffs of the modern Canadian Football League, with the regular season champion of each conference earning the right to host the championship game against the winner of a game between the champions of the other two divisions. However, the old-line NFL owners, who still expected their teams to dominate the merged league for at least the first half of the 1970's, thought a repeat of the 1967 Colts-Rams fiasco would be very likely under the new alignment combined with a six team format. In any event, most owners in both conferences wanted to keep the even four-team playoff field in each conference. This was established by having the three division champions in each conference joined by the best second-place finisher in the conference.\n\nAs with much of the NFL's nomenclature, the \"wild card\" was not initially referred to as such and was instead referred as the \"Best Second-Place Team\" (or sometimes simply as the \"Fourth Qualifier\"). The media, however, began referring to the qualifying teams as \"wild cards\". Eventually, the NFL officially adopted the term. During the 1975, 1976, and 1977 seasons, the divisional playoffs featured the #1 seed hosting the wild card team and the #2 seed hosting the #3 seed unless the #1 seed and wild card team were divisional rivals. In that case, the #1 seed hosted the #3 seed and the #2 seed hosted the wild card team. This was also the format used in Major League Baseball from 1995 through 2011.\n\nIn 1978, the playoffs were expanded to 10 teams; however, the restriction against teams in the same division playing each other in the divisional round continued until the playoffs expanded to 12 teams in 1990. During this time, the #1 seed hosted the winner of the #4 vs #5 wild card game, while the #2 seed played the #3 seed. If the #1 seed and the winner of the #4 vs #5 wild card game were in the same division, then the #1 seed played the #3 seed, while the #2 seed played the #4 vs #5 winner. When Major League Baseball expanded its playoffs to 10 teams in 2012, it also used this format, although teams in the same division could play each other in the Division Series. From 1970 through 1974, the NFL used a rotation to determine which teams would host conference semifinal and final games, and which teams would play which other teams (coincidentally, baseball also used a rotation when it began to have this number of teams, for both of the aforementioned purposes, from 1995–1997 before switching to the seeding method).\n\nThe number of wild-card qualifiers was expanded to two per conference in 1978 — the divisional winners were granted a bye week while the wild card teams played (hence the origin of the phrase \"Wild Card Round\"). Like wild card teams before, the wild card game winner played the #1 seed, or the #2 seed if they and the #1 seed were divisional rivals. The playoffs were expanded again to three wild cards per conference in 1990 (or 12 teams total, which remains now) with the lowest ranked divisional winner losing its bye. Following the addition of the Houston Texans in 2002, the league added a fourth division to each conference. The league decided not to change the number of playoff teams, and thus the number of wild card qualifiers was reduced to two per conference, with the two lowest ranked divisional winners not receiving byes. The term \"Wild Card Round\" continues to be used for the opening weekend of NFL playoffs, even though that weekend has involved both wild card and non-wild card teams since 1990.\n\nAs of the start of the 2018 season, there has never been a meeting of two wild card teams in either conference's championship game or in the Super Bowl. By extension, this means that two wild card teams have not met in the playoffs (and, by further extension, that a wild card team has not hosted a playoff game) since the league expanded to 32 teams in 2002.\n\n\n\nThe 1980 Raiders, 2005 Steelers, and 1992 Bills tied for first in their division but lost a tiebreaker.\n\nWhile not a wild card team, the 1969 Kansas City Chiefs were the first non-division winner to win the Super Bowl. They finished second in the Western Division of the American Football League, and in that season, the last before the merger, the AFL went from having its two division winners meeting for the league title to adding a second round in which the second place team in each division qualified for the post-season. These teams played cross-division in the semifinal round. Thus the Chiefs, who finished second in the West, defeated the East Division champion New York Jets in the AFL semifinals and then defeated the West Division champion Oakland Raiders to advance to Super Bowl IV, where they beat the Minnesota Vikings. Because the term \"wild card\" was not instituted until the following year, the Chiefs are not included in the above list, but are recognized as the first team to win the Super Bowl without winning a division title.\n\nAlthough the National Basketball Association (NBA) include wild-card teams in their playoff structures, the term \"wild card\" is seldom used; instead, each playoff team is most commonly denoted by its seeding position within the conference.\n\nIn the NBA, division champions within each conference were given the #1-3 seeds based on their regular-season records. The two fourth-placed wild-card teams are awarded the #7 and #8 seeds, respectively, also based on their regular-season records. In the NBA playoffs, home court advantage is determined strictly by regular-season record, without regard to seeding.\n\nBefore the 2006–07 NBA season, the NBA seeded its teams in the same manner as the NHL. Until 2015, the NBA seeds the three division winners and the wild-card team with the best record by regular-season record. This means that the wild-card with the best record got a seed as high as #2 (if that team is in the same division as the team with the best record in the conference); however, the next four wild-card teams will still be limited to the #5 through #8 seeds. This change was made to ensure that the two best teams in each conference could not meet until the conference final, and also (allegedly) to try and eliminate incentives for a playoff-bound team to deliberately lose games at the end of the regular season in order to \"choose\" a higher-seeded team that has won fewer games (and, due to the unique home-court rules of the NBA, possibly gain home-court advantage for that series).\n\nThe notion of \"wild cards\" was essentially abolished the 2015–16 NBA season, as changes made prior to the season mean the top eight teams in each conference qualify regardless of divisional rank, with the seeded teams ranked by percentage. The only particular advantage to winning a division now is that a divisional title serves as the first tiebreaker for qualification seeding purposes. Unlike some other leagues, there is no tie-breaker advantage at all to finishing in any divisional rank lower than first - meaning (for example) that while a division winner \"will\" automatically win a tie-breaker over another division's runner-up, a division runner-up \"will not\" automatically win a tie-breaker over teams finishing third, fourth or fifth in other divisions. The new format means it is possible for an especially weak division to send \"no\" teams (not even its champion) to the NBA playoffs, although as of the start of the 2018–19 season this has not yet occurred.\n\nIn the NBA, the winner of the #1 vs. #8 series goes on to face the winner of the #5 vs. #4 series, while the winner of the #2 vs. #7 series faces the winner of the #6 vs. #3 series. Notice that the winner of the #1 vs. #8 series will usually play against a wild-card team in the Conference Semifinals; this is arranged deliberately to \"reward\" the #1 seeded team by giving it the most winnable matchups in the first and second rounds.\n\nIn the National Hockey League (NHL), the first, second, and third place teams in each division qualify for the playoffs automatically, and two additional teams, regardless of divisional alignment, also qualify by having the best records among the remaining teams in the conference. These teams are referred to as the Wild Cards. The division champions play the Wild Cards, while the second and third placed teams in each division play each other; therefore the bracket is fixed, like the NBA. Home ice advantage is given to the higher seed in the divisional rounds, with the better record being used in the Conference Finals and Stanley Cup Finals.\n\nThe NHL's current format is similar in some respects to the \"cross-over rule\" used by the Canadian Football League since 1997 in that it the format emphasizes intra-divisional ranking and brackets in the playoff structure and yet allows two teams from one division to qualify for the playoffs at the expense of the two teams finishing with worse records and in the same divisional ranks in another division. The main difference is that the CFL only allows the lowest ranked playoff qualifying team from a division to cross over into the other division's playoffs, whereas in the NHL it is possible for either Wild Card team to \"cross over\" to the other division, or even (in cases where four teams qualify from each division) for the Wild Card teams to swap divisional playoff brackets. Also, unlike the CFL the NHL does not require the second Wild Card qualifier to have an outright better record than a superior-ranked team in the other division - in the event of such a tie at the end of the NHL season standard tie-breaking procedures are used to determine playoff qualification.\n\nFrom 1999 until 2013, division champions within each conference were given the #1-3 seeds based on their regular-season records. Among the remaining teams within each conference, five additional teams with the best records are awarded seeds #4 through #8. The division champions (first-third seeds) and the team with the best record that isn't a division champion (fourth seed) were given home ice advantage in the opening playoff series, in which they face the eighth-seeded through fifth-seeded teams, respectively. However, the playoff format differed slightly from that of the NBA. In the NHL, the highest winning seed of the first round played the lowest winning seed of the first round in the next round of the playoffs. For example, if the #1, #4, #6, and #7 seeds win their respective first round series then the second round of the playoffs matched the #1 seed (highest) versus the #7 seed (lowest) and the #4 seed (2nd highest) versus the #6 seed (second lowest). Home ice advantage in each NHL playoff series prior to the Stanley Cup Finals was granted by superior seed, even if the \"wild card\" team had a better regular season record. For the Finals, the team with the better record will receive home ice advantage.\n\nMajor League Soccer (MLS), the top level of soccer (football) in both countries, used a wild card format starting in its 2011 playoffs. The top three teams from each of its two conferences automatically qualified for the conference semifinals, while the four remaining teams with the highest point totals in league play, without regard to conference, earned \"wild cards\" into the playoffs. The wild card matches were single games, with the #7 seed hosting the #10 seed and the #8 seed hosting the #9 seed. The lowest surviving seed then played the Supporters' Shield winner (i.e., the team with the highest point total), while the other surviving wild card played the top seed in the other conference.\n\nThe \"wild card\" format was revamped for the 2012 season. Since 2015, the top six teams from each conference qualify for the playoffs, with the #1 & #2 seeds in each conference automatically qualifying for the conference semifinals, and seeds #3-6 in each conference being wild cards. The lowest-seeded winner (played between the #4 & #5, and #3 & #6 seeds) in each conference plays the #1 seed, and the next-lowest playing the #2 seed in the conference semifinals.\n\nCurling Canada introduced Wild Card teams starting with the 2018 Scotties Tournament of Hearts and 2018 Tim Hortons Brier. The change was made as part of a wider set of changes which expanded the tournaments to 17 teams and eliminated the unpopular Pre-Qualifying Tournaments. From 2018, the round robin stage of the Tournament of Hearts and Brier will consist of two seeded \"pools\" of eight teams as opposed to the old format consisting a single group of twelve teams. This allows the main tournament to include \"Team Canada\" (either the defending champions or, when the champions decline to or are unable to defend their title, the runners-up) and teams representing all fourteen constituent associations representing the ten provinces and three territories plus Northern Ontario. The remaining two participants in the tournament are the Wild Cards, which compete in an MLB-style play-in game prior to the main tournament to determine the sixteenth team in the main tournament. Just as is the case with MLB division titles, the format is designed to give teams an incentive to win their provincial championships. The Wild Cards are the top two teams in the Canadian Team Ranking System (CTRS) standings that did not win either the previous year's tournament or their respective provincial or territorial championship. The top ranked of these two teams receives the hammer (last rock) to start the game. \n\nThe CTRS standings are also used to determine the seeding of all teams in the main tournament, with one important caveat - for the purposes of seeding the round robin pools and so as to allow the main round robin schedule to be drawn up prior to the Wild Card game, the ranking of the top Wild Card team is the ranking that is used for seeding purposes regardless of who wins the game. Whereas teams in the Tournament of Hearts and Brier are traditionally referred to by their respective province or territory (other than Northern Ontario and Team Canada), the team that wins the Wild Card game is referred to as the \"Wild Card\" for the duration of the tournament. As is the case with Team Canada, the Wild Card retains that designation even if the team that is representing the same province or territory as the Wild Card team is eliminated prior to the Wild Card team.\n\nWith the introduction of pools, the round robin portion of the Tournament of Hearts and Brier now consists of two stages. The top four teams in each pool qualify for the second stage, formally known as the \"Championship Pool.\" Unlike most tournaments which use a similar format, teams carry over their entire round robin records from the preliminary stage as opposed to only those results against teams that also qualify. This ensures that each Championship Pool team still plays eleven games that count for the purposes of determining playoff qualification.\n\nThe format is designed to ensure that a competitive team fills the Wild Card slot - due to the significant disparity in playing caliber between the top teams of Canada's fourteen member associations, it is widely expected that the Wild Card will consistently come from one of the provinces with the toughest fields in the playdowns, and that it will consistently be a championship contending team.\n\nWhile the Canadian Football League does not officially use the term \"wild card\" to denote any playoff qualifier, its crossover rule acts similar to a wild card in many respects.\n\nCalls to change the CFL's playoff format came about soon after the CFL finished its evolution from two regional conferences, which were originally the Interprovincial Rugby Football Union in the East and the Western Interprovincial Football Union in the West. Although the CFL was officially founded in 1958, its constituent sections did not fully merge until 1981. At the time, it was agreed that three teams from each division would qualify, regardless of overall league standings. This quickly proved controversial, as a wide disparity in playing caliber had emerged between the East and West divisions. Since the league had also implemented a fully balanced schedule (each of the nine teams played each opponent once at home and once on the road), this disparity (made even worse by the fact the West had one more team than the East) was fully exposed in the standings - in each of the first three seasons of the new format, the fourth place team missed the playoffs with records as good as 9-7 in the West, while in the East records as bad as 3-13 were good enough for third place and a playoff berth. In 1981, even the fifth place Western team's record of 6-10 was good enough for outright possession of sixth place overall.\n\nIn 1986, the playoff format was changed. The new format the fourth place team in one division to qualify if it finished with an outright better record than the third place team in the other division. The Eastern owners agreed in exchange for expanding the schedule to 18 games, and also with a stipulation that the qualifying fourth-place team would stay in its own division for the playoffs. As a result, the change introduced the possibility of a four team bracket in one division and a two game total point series in the other (the two game total point format was nothing new in Canadian football - it was commonly used until the early 1970's). It also introduced the possibility of the first place teams losing their traditional byes based on results elsewhere in the league. This occurred in 1986, when the 11-7 Calgary Stampeders qualified in place of the 4-14 Montreal Alouettes. The Alouettes folded before the start of the following season. Although it is highly questionable whether a 1986 playoff appearance would have saved the floundering Montreal franchise, the CFL quickly re-instated the traditional playoff format for the 1987 season. It also moved the Winnipeg Blue Bombers (the West's easternmost team) to the Eastern Division. This balanced the divisions both in numbers as well as, to a considerable extent, in playing caliber, and the reduction in teams also caused the schedule to be changed to emphasize more divisional games. As a result, the three top finishers of the two divisions finishers always had the six best league records from 1987 up until the start of the league's U.S. expansion experiment, which started in the 1993.\n\nThe current rule was adopted after the league re-activated the Alouettes and reverted to an all-Canadian alignment in 1996. It allows the fourth place team of one division to \"cross over\" and take the place of the third place team in the other divisional bracket, provided the fourth place team has more points (i.e. an outright better record) than the third place team. Since the cross over team enters as the third place team, it never receives home field advantage in the playoffs, even if its record is better than that of one or both of the qualifying teams in the other division.\n\nAs of 2018, all teams to qualify under this rule have crossed over from the Western Division to the Eastern bracket, although there have been a handful of occasions where a fourth placed Eastern team was in mathematical contention for a Western cross-over berth late in the season. Cross-over teams have advanced as far as the Eastern Final, but as of 2018 have never advanced to the Grey Cup game. There is no provision for a fifth placed team in one division to cross over in place of the other division's runner-up, even if it has a better record - a somewhat academic point until 2018, as since 1981 this scenario has yet to recur although on occasion it has been a possibility up to the final week of the regular season. In 2018 the Edmonton Eskimos finished fifth in the West with a 9-9 record and missed the playoffs while the Hamilton Tiger-Cats finished 8-10 and qualified as Eastern runners-up.\n\nIn professional tennis tournaments, a wild card refers to a tournament entry awarded to a player at the discretion of the organizers. All ATP and WTA tournaments have a few spots set aside for wild cards in both the main draw, and the qualifying draw, for players who otherwise would not have made either of these draws with their professional ranking. They are usually awarded to players from the home and/or sponsoring country (sometimes after a tournament where the winner is awarded the wild card), promising young players, players that are likely to draw a large crowd, have won the tournament earlier or players who were once ranked higher and are attempting a comeback (for instance, following a long-term injury). High ranked players can also ask for a wild card if they want to enter a non-mandatory tournament after the normal entry deadline, for example because they lost early in another tournament. This means a wild card player sometimes becomes the top seed.\n\nThree of the Grand Slam tournaments swap some wild cards: the Australian Open, French Open, and US Open. A New York Times journalist has described this practice as \"nothing more than mutual back scratching\" and \"an outdated symbol of elitism\".\n\n\nIn motorcycle racing the term 'wild card' is used for competitors only involved in individual rounds of a championship, usually their local round. Local riders taking advantage of their local knowledge (often having raced that circuit on that bike before) and affording to take risks without planning for a championship, often upset established runners. Makoto Tamada and Shaky Byrne have both taken double victories in Superbike World Championship rounds in their home countries. \nThe most famous wild card entry perhaps was the late Daijiro Kato with finishing 3rd at his first appearance in 1996 and then winning the Japanese 250cc Grand Prix back to back in 1997 and 1998 on his way to become the most successful 250cc World Champion of all time in 2001.\n\nGrand Prix motorcycle racing\n\nEach Grand Prix host Federation (FMNR) may nominate 3 wild card entries for the Moto3 and Moto2 classes in their own Grand Prix only.\n\nThe MSMA (Motorcycle Sport Manufacturers’ Association) may, at each event, nominate 1 wild card entry for the Moto2 and MotoGP classes.\n\nThe FIM may, at each event, nominate 2 wild card entries for the Moto3 and Moto2 classes and FIM/DORNA may, at each event, nominate 1 wild card entry for the MotoGP class.\n\nSuperbike World Championship\n\nEach Event host Federation (FMNR) may nominate 4 wild card entries for the Superbike class and 2 wild card entries for the Supersport and Superstock classes, in their own event only.\n\nThe FIM may nominate 2 wild card entries for the Superbike class.\n\nMotorcycle Speedway\n\nIn Motorcycle Speedway, wild cards compete in the Speedway Grand Prix events in which there is 1 wild card per competition (until 2005 there were 2 per Grand Prix). six wild cards have won a Grand Prix: Mark Loram in 1999, Martin Dugard in 2000, Hans Andersen in 2006 (later that year he replaced a permanent rider and went on to win another GP), Michael Jepsen Jensen in 2012, Adrian Miedziński in 2013 and Bartosz Zmarzlik in 2014.\n\nWild Card entries are not unknown in auto racing either, although the Concorde Agreement in modern-day Formula One requires all teams to participate in every event. John Love came close to winning the 1967 South African Grand Prix in a wild card type situation, long before the term had been coined. Although the term is rarely used in NASCAR, the concept of a road course ringer is similar. Before the late-1990s, NEXTEL Cup and Busch Series races in the West and Northeast respectively would have several drivers from the Winston West and Busch North series, as the series regulations were very similar, and until the mid-2000s, ARCA drivers would usually attempt Cup races in the Midwest and at restrictor-plate races.\n\nDuring the period of the mid-1980s until 2004, individual NASCAR races utilized the \"Promoter's Option\" (also known as Provisionals) to allow a top driver/team that did not qualify for the race, the opportunity for a \"wild card\" type starting position at the end of the grid. This allowed track owners to advertise and guarantee to fans that the most popular drivers would participate in the race (pleasing fans in attendance, and preventing no-shows) even if the driver had an unfortunate mishap (e.g., blown engine) or crash during time trials. Starting in 2005, only the Former Champion's Provisional remains.\n\nDuring the NASCAR Sprint All-Star Race (a non-points exhibition event) one driver who fails to qualify for the race is awarded a wild card spot via \"Fans Choice\" vote. In 2008, Kasey Kahne, was selected as a wild card via fan vote, and went on to win the race.\n\nFrom 2011 to 2013, NASCAR's top-level Sprint Cup Series, since renamed the Monster Energy NASCAR Cup Series, used \"wild cards\" in a different context, namely that of qualifying for the season-ending Chase for the Sprint Cup, now rebranded as the NASCAR playoffs. In previous seasons, the top 12 drivers in championship points after the first 26 races of the season automatically qualified for the Chase, with their points reset to a point unreachable by any other driver. Under the 2011–2013 system, only the top 10 drivers automatically qualified. The other two Chase qualifiers were the two drivers ranked from 11th through 20th after 26 races with the most race wins, with tiebreakers used as necessary to restrict the number of \"wild cards\" to two. Major changes to the Chase format that took effect in 2014, most notably determining the newly expanded Chase field of 16 mainly by race wins, eliminated this type of \"wild card\".\n\nNCAA tournaments in all of its sports have included wild card berths, typically known as \"at-large berths\" at that level. Winners of each athletic conference's tournament (or, in the case of basketball's National Invitation Tournament, the team with the best regular season record in that conference) are granted automatic bids into the tournament, and a selection committee fills the remaining slots in the tournament bracket with who it determines to be the best teams who did not win their tournament (in practice, major conferences with stronger reputations and more revenue are invariably favored over mid-majors with similar records).\n\nAlthough the term \"wild card\" is not generally used in this context outside North America, a few competitions effectively employ such a system to determine one or more places in a future phase of a competition.\n\nIn the Olympics, several sport governing bodies award wild cards to nations in order to further promote their sport. Sports governing bodies will either make selections or hold a tournament to determine the wild cards. One such notable wild card selection was Equatorial Guinea swimmer Eric Moussambani, who finished last in the 100m meter event in the 2000 Summer Olympics.\n\nThe Euroleague, a Europe-wide competition for elite basketball clubs, once had one \"wild card\" advancing from its first phase, officially the Regular Season, to its second, called the Top 16. The rule was in place through the 2007–08 season.\n\nAt that time, the competition began each year with 24 clubs, divided into three groups. (Today, the competition starts with a preliminary stage of 16 teams playing down to two survivors, who join 22 other teams in the Regular Season.) Then as now, the groups played a double round-robin for the Regular Season, with eight clubs eliminated and the remaining clubs advancing to the Top 16.\n\nUnder the rules in place through 2007–08, the top five clubs in each group automatically advanced. The final \"wild card\" spot in the Top 16 went to the sixth-place club with the best overall record, with three potential tiebreaking steps. A coin toss is not indicated as a possible step.\n\nStarting in 2008–09, the \"wild card\" was abolished when the Regular Season was reorganized into four groups with 6 teams apiece. Now, the top four teams in each group advance to the Top 16. No change to the tiebreakers was made.\n\nThe world championship for basketball, the FIBA Basketball World Cup, invites four wild cards to complete its 24-team field. Teams have to participate in qualifying for the World Cup, have to apply to be one, and FIBA is not allowed more than three teams from the same continent in order to be selected. This setup began in 2006, where Italy, Puerto Rico, Serbia and Montenegro, and Turkey were selected by FIBA; Turkey made the best performance, reaching the quarterfinals. In 2010, FIBA selected Germany, Lithuania, Lebanon, and Russia as the wild cards, with Lithuania finishing third, and Russia making it to the quarterfinals. For the 2014 FIBA Basketball World Cup, FIBA selected Brazil, Finland, Greece, and Turkey; 2014 will be the last time FIBA will select wild cards, as the 2019 FIBA Basketball World Cup would no longer have wild cards when it expands to 32 teams. The perennial top two FIBA Oceania team namely Australia and New Zealand as wild card teams of FIBA Asia Cup 2017 in Lebanon. These two teams are also part of FIBA Asia in Basketball tournaments including FIBA World Qualifying Tournament for FIBA World Cup 2019 in China.\n\nRugby union's analogue to the Euroleague is the European Rugby Champions Cup, which replaced the previous top-level club competition, the Heineken Cup, starting with the 2014–15 season. The Champions Cup maintains a system originally created for the Heineken Cup in which some \"wild card\" teams advance to the competition's knockout stages. Also starting in 2014–15, the organiser of the Champions Cup, European Professional Club Rugby, introduced this type of \"wild card\" to the second-level European Rugby Challenge Cup.\n\nDuring the last five seasons of the Heineken Cup (2009–10 to 2013–14), another \"wild card\" system allowed teams to parachute into the original European Challenge Cup, which has now been replaced by the current Challenge Cup. This was scrapped with the creation of the current Challenge Cup.\n\nBoth the Champions Cup and current Challenge Cup involve 20 clubs (compared to 24 in the Heineken Cup and 20 in the original Challenge Cup), divided into pools of four clubs with each club playing a double round-robin within its pool. In both competitions, eight clubs advance to the knockout stages. The top club in each pool advances; the three \"wild card\" places are filled by the second-place clubs with the best overall records. For the Champions Cup, the number of wild cards increased by one from the Heineken Cup era; both versions of the Challenge Cup had three wild cards, but the original version filled them in an entirely different manner.\n\nIn the final years of the Heineken Cup, starting in 2009–10 and ending with the 2014 reorganisation of European club rugby, the three second-place teams with the next-best records after those that advanced to the Heineken Cup knockout stage parachuted into the Challenge Cup.\n\nThe tiebreaking procedure used to determine overall seeding, which was devised in the Heineken Cup era and carried over intact into the current era, is almost as elaborate as that of the NFL, with a total of seven steps (a coin flip is the last).\n\nPrior to 2009–10, the original Challenge Cup also had \"wild card\" teams entering its knockout stages. The top club in each pool advanced to the knockout stage, along with the three second-place teams with the best records, using the same tiebreaking procedure as the Heineken Cup. Starting in 2009–10, only the winner of each pool entered the knockout stage, to be joined by the teams parachuting in from the Heineken Cup. As noted above, with the creation of the new Challenge Cup, that competition abandoned this system in favour of the system used in the Champions Cup.\n\nThe Super Rugby competition, involving regional franchises from Australia, New Zealand, and South Africa, adopted a new playoff system with \"wild cards\" when it expanded to 15 teams in 2011.\n\nIn its previous incarnations as Super 12 and Super 14 (each number reflecting the number of teams in the competition), it used a Shaughnessy playoff system in which the top four teams advanced to a knockout stage. The expansion to 15 teams led to major changes in the competition format.\n\nThrough the 2015 season, the competition was divided into three conferences of five teams each, with every conference consisting solely of teams from one of the participating countries. At the end of the regular season, the winners of each conference received playoff berths. These teams were joined by three \"wild cards\", specifically the three non-winners with the most competition points without regard to conference. (Tiebreakers were employed as necessary.)\n\nWith the expansion of Super Rugby to 18 teams in 2016, featuring a permanent sixth franchise for South Africa and new teams based in Argentina and Japan, the competition format was changed again.\n\nThe competition is now divided into the Australasian Group, including all Australian and New Zealand teams, and the African Group, consisting of the South African teams plus the Argentine and Japanese franchises. In turn, the Australasian Group is divided into Australia and New Zealand Conferences, and the African Group is split into Africa 1 and Africa 2 Conferences. As in the 2011–15 system, the conference winners will receive playoff berths. The number of wild cards will increase to four, with the three top non-winners from the Australasian Group and the top non-winner from the African Group, again based on competition points, earning those spots.\n\nIn the Philippine Basketball Association, the playoffs are done after an elimination (in 2005-06, a classification) round where the top two teams with the best records are given semi-final byes, the next 3 are given quarterfinal byes, the next 4 are given entry to the wildcard phase, and the tenth team is eliminated.\n\nThe winner of the wild card playoffs, varying in format from a round-robin, a single-elimination or sudden death, usually meets the strongest quarterfinalist (the 3rd seed). The wild card winner's next opponent for the quarterfinals rested while the wild card phase was ongoing so the chance of advancing to the semi-finals (in which a team rested longer) is slim.\n\nThe only wild card champion are the 7th-seeded Barangay Ginebra Kings in the 2004 PBA Fiesta Conference after 7 years of championship drought they made an epic run all the way to the throne, in which the top 2 teams were given semifinal byes while the bottom eight went through a knock-out wild card tournament. Since the addition of the quarterfinal bye, no wild card has entered the Finals, although the Air21 Express won the third-place trophy at the 2005-06 PBA Fiesta Conference.\n\nThe wild card set up was no longer used when the league reverted to the 3-conference format starting from the 2010–11 PBA season.\n\nFor both the junior and senior Grand Prix of Figure Skating Final (which starting in the 2008–2009 figure skating season will be merged into a single two-division event), the hosting federation may issue a wild card invitation to one of their own skaters should no skater from the host country qualify for the event through the Grand Prix circuit. Use of the wild card has not been common; however, it was used at the 2007–2008 Junior Grand Prix Final by the Polish federation.\n\nThe same rationale exists in international association football, specifically FIFA World Cup qualifying stages. In FIFA World Cup qualifying stages in Europe, for example, 2nd placed teams are all ranked by number of points. The team with the most points is guaranteed automatic qualification to the FIFA World Cup, while the team with the least points is eliminated (points from victories against the last-placed team in each country's respective group being deducted), while teams in between generally play a 2-game playoff to determine qualification.\n\nOther qualifying regions which use a wild card format include CONMEBOL, CONCACAF, and the AFC.\n\nIn the All-Ireland Senior Football Championship, the premier competition in Gaelic football, each of the thirty-two counties in Ireland as well as London and New York play in their respective Provincial Championships through a knock-out cup competition format without seeds. The winners of each of the four Provincial Championships earn one of eight places in the All-Ireland Quarter Finals.\n\nThe thirty teams that fail to win their respective Provincial Championships receive a second opportunity to reach the All-Ireland Series via the All Ireland Qualifiers (also known as the 'back door', similar to a Wild Card).\n\nIn road cycling (teams), a wild card refers to an invitation to a race which a particular team would not normally be able to enter. Usually used for top division (currently UCI World Tour) races where the organization want more teams, lower league teams will be invited. It is very common to offer a wild card for teams from the same country to help local sport and to boost national pride. For example, for the 100th \"Tour de France\" in 2013, the organisers (the Amaury Sport Organisation) awarded three wild cards to French teams: Cofidis, Sojasun and Team Europcar, all of which were UCI Professional Continental teams at the time and therefore not automatically invited, unlike the UCI ProTeams which made up the vast majority of the entry list.\nTeams can apply for a wild card.\n\nIn January 2015, Team MTN-Qhubeka from South Africa accepted an invitation to participate in the 2015 edition of \"Tour de France\". MTN-Qhubeka was the first African team to receive a wild card entry into the event that was held from 4 to 26 July 2015.\n\nIn the current format of the Rugby World Cup, a team that finishes 3rd in their group automatically gains a berth in the next Rugby World Cup (although they do not advance to the next round).\n\nAdditionally, the Rugby World Cup qualifying format uses a repechage, in which teams from other regions that did not gain the automatic spot play each other for the final spots in the World Cup.\n"}
{"id": "43285791", "url": "https://en.wikipedia.org/wiki?curid=43285791", "title": "Wilhelm Münter Rolfsen", "text": "Wilhelm Münter Rolfsen\n\nWilhelm Münter Rolfsen (11 May 1913 – 8 December 2002) was a Norwegian barrister, resistance member and film producer. During the German occupation of Norway he was actively involved in the resistance movement, particularly by organizing a network for escorting refugees to Sweden. He took part as a prosecutor in the legal purge in Norway after World War II, and he wrote two books about his wartime experiences. He was involved in film productions, including \"Nine Lives\" and \"Struggle for Eagle Peak\"\n\nRolfsen was born in Kristiania, a son of wholesaler Christen Rolfsen and Astrid Münter. He finished his secondary education in 1931, finished officer's training in 1932 and graduated from the Royal Frederick University with the cand.jur. degree in law in 1937. In 1937 he married banker's daughter Randi Kvaal.\n\nRolfsen worked as a journalist for the newspaper \"Morgenbladet\", and established himself as a lawyer from 1941. During the German occupation of Norway he took part in the resistance movement. He joined the Hjemmefrontens Sentralledelse in 1943. For a period in 1943, Rolfsen was leader of Milorg's refugee escort network, called \"Edderkoppen\" (\"The Spider\"), until he eventually had to flee to Sweden later in 1943. He was a lieutenant for the Norwegian troops in Sweden from 1943 to 1945.\n\nHe published the book \"Fra Oscarsborg til Hegra\" in 1945, on the Norwegian Campaign in southern Norway. The book was based on lectures he had given in Sweden during the war. In 1946 he published \"Usynlige Veier\" (\"Invisible paths\"), on refugee escorts and courier traffic between Norway and Sweden during the war.\n\nAfter the war he continued in his law firm, Rolfsen & Joys with Einar Joys. He took part as a prosecutor in the legal purge in Norway after World War II. In 1952 he became a barrister with access to working with Supreme Court cases. Through the company Nordsjøfilm he was involved in the film productions \"Shetlandsgjengen\", \"Ni Liv\" from 1957 and \"Venner\".\n\nHe was a board member of the Oslo branch of the Norwegian Bar Association from 1950 to 1956, of the Norwegian Film Producers' Association from 1955 to 1958 as well as the Riksmål organs \"Norsk Lytterforening\" (chairman 1955–1957 and 1958–1960) and \"Frisprog\". He also chaired the Riksmål Society from 1966. In business he was a board member of Jernløkkens Mekaniske Verksted, Tandhjulfabriken, B.W.B. Braathen & Co., Norgear and Norfinn.\n\nFor his contributions during World War II he was decorated with the Norwegian Defence Medal 1940–1945 with rosette as well as the British King George VI Commendation for Brave Conduct. He also received the Knighthood of the Order of the Lion of Finland. He died in December 2002 and was buried at Vestre gravlund.\n"}
{"id": "67065", "url": "https://en.wikipedia.org/wiki?curid=67065", "title": "Word-sense disambiguation", "text": "Word-sense disambiguation\n\nIn computational linguistics, word-sense disambiguation (WSD) is an open problem of natural language processing and ontology. WSD is identifying which sense of a word (i.e. meaning) is used in a sentence, when the word has multiple meanings. The solution to this problem impacts other computer-related writing, such as discourse, improving relevance of search engines, anaphora resolution, coherence, inference, \"et cetera\".\n\nThe human brain is quite proficient at word-sense disambiguation. That natural language is formed in a way that requires so much of it is a reflection of that neurologic reality. In other words, human language developed in a way that reflects (and also has helped to shape) the innate ability provided by the brain's neural networks. In computer science and the information technology that it enables, it has been a long-term challenge to develop the ability in computers to do natural language processing and machine learning.\n\nA rich variety of techniques have been researched, from dictionary-based methods that use the knowledge encoded in lexical resources, to supervised machine learning methods in which a classifier is trained for each distinct word on a corpus of manually sense-annotated examples, to completely unsupervised methods that cluster occurrences of words, thereby inducing word senses. Among these, supervised learning approaches have been the most successful algorithms to date.\n\nAccuracy of current algorithms is difficult to state without a host of caveats. In English, accuracy at the coarse-grained (homograph) level is routinely above 90%, with some methods on particular homographs achieving over 96%. On finer-grained sense distinctions, top accuracies from 59.1% to 69.0% have been reported in evaluation exercises (SemEval-2007, Senseval-2), where the baseline accuracy of the simplest possible algorithm of always choosing the most frequent sense was 51.4% and 57%, respectively.\n\nDisambiguation requires two strict inputs: a dictionary to specify the senses which are to be disambiguated and a corpus of language data to be disambiguated (in some methods, a training corpus of language examples is also required). WSD task has two variants: \"lexical sample\" and \"all words\" task. The former comprises disambiguating the occurrences of a small sample of target words which were previously selected, while in the latter all the words in a piece of running text need to be disambiguated. The latter is deemed a more realistic form of evaluation, but the corpus is more expensive to produce because human annotators have to read the definitions for each word in the sequence every time they need to make a tagging judgement, rather than once for a block of instances for the same target word.\n\nTo give a hint how all this works, consider three examples of the distinct senses that exist for the (written) word \"\"bass\":\nand the sentences:\n\nTo people who understand English, the first sentence is using the word \"bass (fish)\", as in the former sense above and in the second sentence, the word \"bass (instrument)\" is being used as in the latter sense below. Developing algorithms to replicate this human ability can often be a difficult task, as is further exemplified by the implicit equivocation between \"bass (sound)\" and \"bass (instrument)\".\n\nWSD was first formulated into as a distinct computational task during the early days of machine translation in the 1940s, making it one of the oldest problems in computational linguistics. Warren Weaver, in his famous 1949 memorandum on translation, first introduced the problem in a computational context. Early researchers understood the significance and difficulty of WSD well. In fact, Bar-Hillel (1960) used the above example to argue that WSD could not be solved by \"electronic computer\" because of the need in general to model all world knowledge.\n\nIn the 1970s, WSD was a subtask of semantic interpretation systems developed within the field of artificial intelligence, starting with Wilks' preference semantics. However, since WSD systems were at the time largely rule-based and hand-coded they were prone to a knowledge acquisition bottleneck.\n\nBy the 1980s large-scale lexical resources, such as the Oxford Advanced Learner's Dictionary of Current English (OALD), became available: hand-coding was replaced with knowledge automatically extracted from these resources, but disambiguation was still knowledge-based or dictionary-based.\n\nIn the 1990s, the statistical revolution swept through computational linguistics, and WSD became a paradigm problem on which to apply supervised machine learning techniques.\n\nThe 2000s saw supervised techniques reach a plateau in accuracy, and so attention has shifted to coarser-grained senses, domain adaptation, semi-supervised and unsupervised corpus-based systems, combinations of different methods, and the return of knowledge-based systems via graph-based methods. Still, supervised systems continue to perform best.\n\nOne problem with word sense disambiguation is deciding what the senses are. In cases like the word \"bass\" above, at least some senses are obviously different. In other cases, however, the different senses can be closely related (one meaning being a metaphorical or metonymic extension of another), and in such cases division of words into senses becomes much more difficult. Different dictionaries and thesauruses will provide different divisions of words into senses. One solution some researchers have used is to choose a particular dictionary, and just use its set of senses. Generally, however, research results using broad distinctions in senses have been much better than those using narrow ones. However, given the lack of a full-fledged coarse-grained sense inventory, most researchers continue to work on fine-grained WSD.\n\nMost research in the field of WSD is performed by using WordNet as a reference sense inventory for English. WordNet is a computational lexicon that encodes concepts as synonym sets (e.g. the concept of car is encoded as { car, auto, automobile, machine, motorcar }). Other resources used for disambiguation purposes include Roget's Thesaurus and Wikipedia. More recently, BabelNet, a multilingual encyclopedic dictionary, has been used for multilingual WSD.\n\nIn any real test, part-of-speech tagging and sense tagging are very closely related with each potentially making constraints to the other. And the question whether these tasks should be kept together or decoupled is still not unanimously resolved, but recently scientists incline to test these things separately (e.g. in the Senseval/SemEval competitions parts of speech are provided as input for the text to disambiguate).\n\nIt is instructive to compare the word sense disambiguation problem with the problem of part-of-speech tagging. Both involve disambiguating or tagging with words, be it with senses or parts of speech. However, algorithms used for one do not tend to work well for the other, mainly because the part of speech of a word is primarily determined by the immediately adjacent one to three words, whereas the sense of a word may be determined by words further away. The success rate for part-of-speech tagging algorithms is at present much higher than that for WSD, state-of-the art being around 95% accuracy or better, as compared to less than 75% accuracy in word sense disambiguation with supervised learning. These figures are typical for English, and may be very different from those for other languages.\n\nAnother problem is inter-judge variance. WSD systems are normally tested by having their results on a task compared against those of a human. However, while it is relatively easy to assign parts of speech to text, training people to tag senses is far more difficult. While users can memorize all of the possible parts of speech a word can take, it is often impossible for individuals to memorize all of the senses a word can take. Moreover, humans do not agree on the task at hand – give a list of senses and sentences, and humans will not always agree on which word belongs in which sense.\n\nAs human performance serves as the standard, it is an upper bound for computer performance. Human performance, however, is much better on coarse-grained than fine-grained distinctions, so this again is why research on coarse-grained distinctions has been put to test in recent WSD evaluation exercises.\n\nSome AI researchers like Douglas Lenat argue that one cannot parse meanings from words without some form of common sense ontology. This linguistic issue is called pragmatics.\nFor example, comparing these two sentences:\nTo properly identify senses of words one must know common sense facts. Moreover, sometimes the common sense is needed to disambiguate such words like pronouns in case of having anaphoras or cataphoras in the text.\n\nA task-independent sense inventory is not a coherent concept: each task requires its own division of word meaning into senses relevant to the task. For example, the ambiguity of 'mouse' (animal or device) is not relevant in English-French machine translation, but is relevant in information retrieval. The opposite is true of 'river', which requires a choice in French (fleuve 'flows into the sea', or rivière 'flows into a river').\n\nAlso, completely different algorithms might be required by different applications. In machine translation, the problem takes the form of target word selection. Here, the \"senses\" are words in the target language, which often correspond to significant meaning distinctions in the source language (\"bank\" could translate to the French \"banque\"—that is, 'financial bank' or \"rive\"—that is, 'edge of river'). In information retrieval, a sense inventory is not necessarily required, because it is enough to know that a word is used in the same sense in the query and a retrieved document; what sense that is, is unimportant.\n\nFinally, the very notion of \"word sense\" is slippery and controversial. Most people can agree in distinctions at the coarse-grained homograph level (e.g., pen as writing instrument or enclosure), but go down one level to fine-grained polysemy, and disagreements arise. For example, in Senseval-2, which used fine-grained sense distinctions, human annotators agreed in only 85% of word occurrences. Word meaning is in principle infinitely variable and context sensitive. It does not divide up easily into distinct or discrete sub-meanings. Lexicographers frequently discover in corpora loose and overlapping word meanings, and standard or conventional meanings extended, modulated, and exploited in a bewildering variety of ways. The art of lexicography is to generalize from the corpus to definitions that evoke and explain the full range of meaning of a word, making it seem like words are well-behaved semantically. However, it is not at all clear if these same meaning distinctions are applicable in computational applications, as the decisions of lexicographers are usually driven by other considerations. Recently, a task – named lexical substitution – has been proposed as a possible solution to the sense discreteness problem. The task consists of providing a substitute for a word in context that preserves the meaning of the original word (potentially, substitutes can be chosen from the full lexicon of the target language, thus overcoming discreteness).\n\nAs in all natural language processing, there are two main approaches to WSD – deep approaches and shallow approaches.\n\nDeep approaches presume access to a comprehensive body of world knowledge. Knowledge, such as \"you can go fishing for a type of fish, but not for low frequency sounds\" and \"songs have low frequency sounds as parts, but not types of fish\", is then used to determine in which sense the word \"bass\" is used. These approaches are not very successful in practice, mainly because such a body of knowledge does not exist in a computer-readable format, outside very limited domains. However, if such knowledge did exist, then deep approaches would be much more accurate than the shallow approaches. Also, there is a long tradition in computational linguistics, of trying such approaches in terms of coded knowledge and in some cases, it is hard to say clearly whether the knowledge involved is linguistic or world knowledge. The first attempt was that by Margaret Masterman and her colleagues, at the Cambridge Language Research Unit in England, in the 1950s. This attempt used as data a punched-card version of Roget's Thesaurus and its numbered \"heads\", as an indicator of topics and looked for repetitions in text, using a set intersection algorithm. It was not very successful, but had strong relationships to later work, especially Yarowsky's machine learning optimisation of a thesaurus method in the 1990s.\n\nShallow approaches don't try to understand the text. They just consider the surrounding words, using information such as \"if \"bass\" has words \"sea\" or \"fishing\" nearby, it probably is in the fish sense; if \"bass\" has the words \"music\" or \"song\" nearby, it is probably in the music sense.\" These rules can be automatically derived by the computer, using a training corpus of words tagged with their word senses. This approach, while theoretically not as powerful as deep approaches, gives superior results in practice, due to the computer's limited world knowledge. However, it can be confused by sentences like \"The dogs bark at the tree\" which contains the word \"bark\" near both \"tree\" and \"dogs\".\n\nThere are four conventional approaches to WSD:\n\nAlmost all these approaches normally work by defining a window of \"n\" content words around each word to be disambiguated in the corpus, and statistically analyzing those \"n\" surrounding words. Two shallow approaches used to train and then disambiguate are Naïve Bayes classifiers and decision trees. In recent research, kernel-based methods such as support vector machines have shown superior performance in supervised learning. Graph-based approaches have also gained much attention from the research community, and currently achieve performance close to the state of the art.\n\nThe Lesk algorithm is the seminal dictionary-based method. It is based on the hypothesis that words used together in text are related to each other and that the relation can be observed in the definitions of the words and their senses. Two (or more) words are disambiguated by finding the pair of dictionary senses with the greatest word overlap in their dictionary definitions. For example, when disambiguating the words in \"pine cone\", the definitions of the appropriate senses both include the words evergreen and tree (at least in one dictionary). A similar approach searches for the shortest path between two words: the second word is iteratively searched among the definitions of every semantic variant of the first word, then among the definitions of every semantic variant of each word in the previous definitions and so on. Finally, the first word is disambiguated by selecting the semantic variant which minimizes the distance from the first to the second word.\n\nAn alternative to the use of the definitions is to consider general word-sense relatedness and to compute the semantic similarity of each pair of word senses based on a given lexical knowledge base such as WordNet. Graph-based methods reminiscent of spreading activation research of the early days of AI research have been applied with some success. More complex graph-based approaches have been shown to perform almost as well as supervised methods or even outperforming them on specific domains. Recently, it has been reported that simple graph connectivity measures, such as degree, perform state-of-the-art WSD in the presence of a sufficiently rich lexical knowledge base. Also, automatically transferring knowledge in the form of semantic relations from Wikipedia to WordNet has been shown to boost simple knowledge-based methods, enabling them to rival the best supervised systems and even outperform them in a domain-specific setting.\n\nThe use of selectional preferences (or selectional restrictions) is also useful, for example, knowing that one typically cooks food, one can disambiguate the word bass in \"I am cooking basses\" (i.e., it's not a musical instrument).\n\nSupervised methods are based on the assumption that the context can provide enough evidence on its own to disambiguate words (hence, common sense and reasoning are deemed unnecessary). Probably every machine learning algorithm going has been applied to WSD, including associated techniques such as feature selection, parameter optimization, and ensemble learning. Support Vector Machines and memory-based learning have been shown to be the most successful approaches, to date, probably because they can cope with the high-dimensionality of the feature space. However, these supervised methods are subject to a new knowledge acquisition bottleneck since they rely on substantial amounts of manually sense-tagged corpora for training, which are laborious and expensive to create.\n\nBecause of the lack of training data, many word sense disambiguation algorithms use semi-supervised learning, which allows both labeled and unlabeled data. The Yarowsky algorithm was an early example of such an algorithm. It uses the ‘One sense per collocation’ and the ‘One sense per discourse’ properties of human languages for word sense disambiguation. From observation, words tend to exhibit only one sense in most given discourse and in a given collocation.\n\nThe bootstrapping approach starts from a small amount of seed data for each word: either manually tagged training examples or a small number of surefire decision rules (e.g., 'play' in the context of 'bass' almost always indicates the musical instrument). The seeds are used to train an initial classifier, using any supervised method. This classifier is then used on the untagged portion of the corpus to extract a larger training set, in which only the most confident classifications are included. The process repeats, each new classifier being trained on a successively larger training corpus, until the whole corpus is consumed, or until a given maximum number of iterations is reached.\n\nOther semi-supervised techniques use large quantities of untagged corpora to provide co-occurrence information that supplements the tagged corpora. These techniques have the potential to help in the adaptation of supervised models to different domains.\n\nAlso, an ambiguous word in one language is often translated into different words in a second language depending on the sense of the word. Word-aligned bilingual corpora have been used to infer cross-lingual sense distinctions, a kind of semi-supervised system.\n\nUnsupervised learning is the greatest challenge for WSD researchers. The underlying assumption is that similar senses occur in similar contexts, and thus senses can be induced from text by clustering word occurrences using some measure of similarity of context, a task referred to as word sense induction or discrimination. Then, new occurrences of the word can be classified into the closest induced clusters/senses. Performance has been lower than for the other methods described above, but comparisons are difficult since senses induced must be mapped to a known dictionary of word senses. If a mapping to a set of dictionary senses is not desired, cluster-based evaluations (including measures of entropy and purity) can be performed. Alternatively, word sense induction methods can be tested and compared within an application. For instance, it has been shown that word sense induction improves Web search result clustering by increasing the quality of result clusters and the degree diversification of result lists. It is hoped that unsupervised learning will overcome the knowledge acquisition bottleneck because they are not dependent on manual effort.\n\nOther approaches may vary differently in their methods:\n\n\nThe knowledge acquisition bottleneck is perhaps the major impediment to solving the WSD problem. Unsupervised methods rely on knowledge about word senses, which is barely formulated in dictionaries and lexical databases. Supervised methods depend crucially on the existence of manually annotated examples for every word sense, a requisite that can so far be met only for a handful of words for testing purposes, as it is done in the Senseval exercises.\n\nTherefore, one of the most promising trends in WSD research is using the largest corpus ever accessible, the World Wide Web, to acquire lexical information automatically. WSD has been traditionally understood as an intermediate language engineering technology which could improve applications such as information retrieval (IR). In this case, however, the reverse is also true: Web search engines implement simple and robust IR techniques that can be successfully used when mining the Web for information to be employed in WSD. Therefore, the lack of training data provoked appearing some new algorithms and techniques described here:\nKnowledge is a fundamental component of WSD. Knowledge sources provide data which are essential to associate senses with words. They can vary from corpora of texts, either unlabeled or annotated with word senses, to machine-readable dictionaries, thesauri, glossaries, ontologies, etc. They can be classified as follows:\n\nStructured:\n\n\nUnstructured:\n\n\nComparing and evaluating different WSD systems is extremely difficult, because of the different test sets, sense inventories, and knowledge resources adopted. Before the organization of specific evaluation campaigns most systems were assessed on in-house, often small-scale, data sets. In order to test one's algorithm, developers should spend their time to annotate all word occurrences. And comparing methods even on the same corpus is not eligible if there is different sense inventories.\n\nIn order to define common evaluation datasets and procedures, public evaluation campaigns have been organized. Senseval (now renamed SemEval) is an international word sense disambiguation competition, held every three years since 1998: Senseval-1 (1998), Senseval-2 (2001), Senseval-3 (2004), and its successor, SemEval (2007). The objective of the competition is to organize different lectures, preparing and hand-annotating corpus for testing systems, perform a comparative evaluation of WSD systems in several kinds of tasks, including all-words and lexical sample WSD for different languages, and, more recently, new tasks such as semantic role labeling, gloss WSD, lexical substitution, etc. The systems submitted for evaluation to these competitions usually integrate different techniques and often combine supervised and knowledge-based methods (especially for avoiding bad performance in lack of training examples).\n\nIn recent years , the WSD evaluation task choices had grown and the criterion for evaluating WSD has changed drastically depending on the variant of the WSD evaluation task. Below enumerates the variety of WSD tasks:\n\nAs technology evolves, the Word Sense Disambiguation (WSD) tasks grows in different flavors towards various research directions and for more languages:\n\n\n\n\n"}
