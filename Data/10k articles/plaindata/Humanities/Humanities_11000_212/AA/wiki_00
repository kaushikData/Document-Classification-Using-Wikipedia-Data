{"id": "58221244", "url": "https://en.wikipedia.org/wiki?curid=58221244", "title": "Amarna letter EA 205", "text": "Amarna letter EA 205\n\nAmarna letter EA 205, titled: \"Ready for Marching Orders (5)\" is a short letter from the \"Ruler\" of city Ṭubu. The title references that six mostly identical, very short, letters were scribed by the same scribe, from small regional towns; the scribe also is the writer of Amarna letter EA 195. It is not known if each letter was written at the location of each town, or from an alternative site, or sites.\n\nThe six towns are: \n\nThe Amarna letters, about 300, numbered up to EA 382, are a mid 14th century BC, about 1350 BC and 20–25 years later, correspondence. The initial corpus of letters were found at Akhenaten's city Akhetaten, in the floor of the Bureau of Correspondence of Pharaoh; others were later found, adding to the body of letters.\n\nEA 205, letter number one of one, from the small town of Tubu (Biblical Tob). (Not a linear, line-by-line translation.)\n\n\"Obverse\" \n\n\"Reverse\" \n\n\n\n"}
{"id": "19346935", "url": "https://en.wikipedia.org/wiki?curid=19346935", "title": "Amish", "text": "Amish\n\nThe Amish (; Pennsylvania German: \"Amisch\", ) are a group of traditionalist Christian church fellowships with Swiss German Anabaptist origins. They are closely related to, but distinct from, Mennonite churches. The Amish are known for simple living, plain dress, and reluctance to adopt many conveniences of modern technology.\n\nThe history of the Amish church began with a schism in Switzerland within a group of Swiss and Alsatian Anabaptists in 1693 led by Jakob Ammann. Those who followed Ammann became known as Amish. In the second half of the 19th century, the Amish divided into Old Order Amish and Amish Mennonites. The latter mostly assimilated into the main society during the 20th century, whereas the Old Order Amish retained much of their traditional culture. When it is spoken of Amish today, normally only the Old Order Amish are meant.\n\nIn the early 18th century, many Amish and Mennonites immigrated to Pennsylvania for a variety of reasons. Today, the Old Order Amish, but also the New Order Amish and the Old Beachy Amish continue to speak Pennsylvania German, also known as \"Pennsylvania Dutch\", although two different Alemannic dialects are used by Old Order Amish in Adams and Allen County, Indiana.\n\n, over 165,000 Old Order Amish lived in the United States and about 1,500 lived in Canada. A 2008 study suggested their numbers had increased to 227,000, and in 2010, a study suggested their population had grown by 10 percent in the past two years to 249,000, with increasing movement to the West. Most of the Amish continue to have 6–7 children while benefitting from the major decrease in infant and maternal mortality in the 20th century. Between 1992 and 2017, the Amish population increased by 149%, while the U.S. population increased by 23%.\n\nAmish church membership begins with baptism, usually between the ages of 19 and 23. It is a requirement for marriage within the Amish church. Once a person is baptized within the church, he or she may marry only within the faith. Church districts average between 20 and 40 families and worship services are held every other Sunday in a member's home. The district is led by a bishop and several ministers and deacons. The rules of the church, the \"Ordnung\", must be observed by every member and cover many aspects of day-to-day living, including prohibitions or limitations on the use of power-line electricity, telephones, and automobiles, as well as regulations on clothing. Most Amish do not buy commercial insurance or participate in Social Security. As present-day Anabaptists, Amish church members practice nonresistance and will not perform any type of military service. The Amish value rural life, manual labor, and humility, all under the auspices of living what they interpret to be God's word.\n\nMembers who do not conform to these community expectations and who cannot be convinced to repent are excommunicated. In addition to excommunication, members may be shunned, a practice that limits social contacts to shame the wayward member into returning to the church. Almost 90 percent of Amish teenagers choose to be baptized and join the church. During an adolescent period of \"rumspringa\" (\"running around\") in some communities, nonconforming behavior that would result in the shunning of an adult who had made the permanent commitment of baptism, may be met with a degree of forbearance. Amish church groups seek to maintain a degree of separation from the non-Amish world, i.e. American and Canadian society. Non-Amish people are generally referred to as 'English'. There is generally a heavy emphasis on church and family relationships. They typically operate their own one-room schools and discontinue formal education after grade eight, at age 13/14. Until the children turn 16, they have vocational training under the tutelage of their parents, community, and the school teacher. Higher education is generally discouraged as it can lead to social segregation and the unraveling of the community.\n\nThe Anabaptist movement, from which the Amish later emerged, started in circles around Huldrych Zwingli (1484 – 1531) who led the early Reformation in Switzerland. In Zurich on 21 January 1525, Conrad Grebel and George Blaurock practiced adult baptism to each other and then to others. This Swiss movement, part of the Radical Reformation, later became known as Swiss Brethren.\n\nThe term Amish was first used as a \"Schandename\" (a term of disgrace) in 1710 by opponents of Jakob Amman. The first informal division between Swiss Brethren was recorded in the 17th century between \"Oberländers\" (those living in the hills) and \"Emmentaler\" (those living in the Emmental valley). The \"Oberländers\" were a more extreme congregation; their zeal pushing them into more remote areas and their solitude making them more zealous.\n\nSwiss Anabaptism developed, from this point, in two parallel streams, most clearly marked by disagreement over the preferred treatment of \"fallen\" believers. The Emmentalers (sometimes referred to as Reistians, after bishop Hans Reist, a leader among the Emmentalers) argued that fallen believers should only be withheld from communion, and not regular meals. The \"Amish\" argued that those who had been banned should be avoided even in common meals. The Reistian side eventually formed the basis of the Swiss Mennonite Conference. Because of this common heritage, Amish and Mennonites from southern Germany and Switzerland retain many similarities. Those who leave the Amish fold tend to join various congregations of Conservative Mennonites.\n\nAmish began migrating to Pennsylvania, then known for its religious toleration, in the 18th century as part of a larger migration from the Palatinate and neighboring areas. This migration was a reaction to religious wars, poverty, and religious persecution in Europe. The first Amish immigrants went to Berks County, Pennsylvania, but later moved, motivated by land issues and by security concerns tied to the French and Indian War. Many eventually settled in Lancaster County, Pennsylvania. Other groups later settled elsewhere in North America.\n\nMost Amish communities that were established in North America did not ultimately retain their Amish identity. The major division that resulted in the loss of identity of many Amish congregations occurred in the third quarter of the 19th century. The forming of factions worked its way out at different times at different places. The process was rather a \"sorting out\" than a split. Amish people are free to join another Amish congregation at another place that fits them best.\n\nIn the years after 1850, tensions rose within individual Amish congregations and between different Amish congregations. Between 1862 and 1878 yearly \"Dienerversammlungen\" (ministerial conferences) were held at different places, concerning how the Amish should deal with the tensions caused by the pressures of modern society. The meetings themselves were a progressive idea; for bishops to assemble to discuss uniformity was an unprecedented notion in the Amish church. By the first several meetings, the more traditionally minded bishops agreed to boycott the conferences.\n\nThe more progressive members, comprising approximately two-thirds of the group, became known by the name Amish Mennonite, and eventually united with the Mennonite Church, and other Mennonite denominations, mostly in the early 20th century. The more traditionally minded groups became known as the Old Order Amish. The Egli Amish had already started to withdraw from the Amish church in 1858. They soon drifted away from the old ways and changed their name to \"Defenseless Mennonite\" in 1908. Congregations that took no side in the division after 1862 formed the Conservative Amish Mennonite Conference in 1910 but dropped the word \"Amish\" from their name in 1957.\n\nBecause there was no division in Europe, the Amish congregations remaining there took the same way as the change-minded Amish Mennonites in North America and slowly merged with the Mennonites. The last Amish congregation in Germany to merge was the Ixheim Amish congregation, which merged with the neighboring Mennonite Church in 1937. Some Mennonite congregations, including most in Alsace, are descended directly from former Amish congregations.\n\nEven though there were splits among the Old Order in the 19th century in Mifflin County, Pennsylvania, it took until the time of the World War I until there was a major split among the Old Orders. At that time two very conservative affiliations emerged: the Swartzentruber Amish in Holmes County, Ohio and the Buchanan Amish in Iowa. The Buchanan Amish soon were joined by like-minded congregations all over the country.\n\nWith World War I came the massive suppression of the German language in the US that eventually led to language shift of most Pennsylvania German speakers, leaving the Amish and other Old Orders as almost the only speakers by the end of the 20th century. This created a language barrier around the Amish that didn't exist before in that form.\n\nIn the late 1920s the more change minded faction of the Old Order Amish, that wanted to adopt the car, broke away from the mainstream and organized under the name Beachy Amish.\n\nDuring the Second World War the old question of military service for the Amish came up again. Because Amish young men in general refused military service they ended up in the Civilian Public Service (CPS), where they worked mainly in forestry and hospitals. The fact that many young men worked in hospitals, where they had a lot of contact with more progressive Mennonites and the outside world, had the result that many of these men never joined the Amish church.\n\nIn the 1950s the Beachy Amish transformed into an evangelical church. The ones who wanted to preserve the old way of the Beachy became the Old Beachy Amish.\n\nUntil about 1950 almost all Amish children attended small local non-Amish schools. But then school consolidation and mandatory schooling beyond eighth grade caused Amish opposition. Amish communities opened their own Amish schools. In 1972, the United States Supreme Court exempted Amish pupils from compulsory education past 8th grade. By the end of the 20th century almost all Amish children attended Amish schools.\n\nIn the last quarter of the 20th century a growing number of Amish men left farm working and started small businesses because of increasing pressure on small scale farming. Even though there is a wide variety of small businesses among the Amish, construction work and woodworking are quite widespread. In many Amish settlements, especially the larger ones, farmers are now a minority.\n\nUntil the early 20th century Old Order Amish identity was not linked to the use of technologies, as the Old Order Amish and their rural neighbors used the same farm and household technologies. Questions about the use of technologies also did not play a role in the Old Order division of the second half of the 19th century. Telephones were the first important technology that was rejected, soon followed by the rejection of cars, tractors, radios and many other technological inventions of the 20th century.\n\nTwo key concepts for understanding Amish practices are their rejection of \"Hochmut\" (pride, arrogance, haughtiness) and the high value they place on \"Demut\" (humility) and \"Gelassenheit\" (calmness, composure, placidity), often translated as \"submission\" or \"letting-be\". Gelassenheit is perhaps better understood as a reluctance to be forward, to be self-promoting, or to assert oneself. The Amish's willingness to submit to the \"Will of Jesus\", expressed through group norms, is at odds with the individualism so central to the wider American culture. The Amish anti-individualist orientation is the motive for rejecting labor-saving technologies that might make one less dependent on the community. Modern innovations like electricity might spark a competition for status goods, or photographs might cultivate personal vanity. Electricity lines would be going against the Bible, which says that you shall not be \"Conformed to the world\" (Romans 12:2).\n\nAmish lifestyle is regulated by the (\"order\"), which differs slightly from community to community, and, within a community, from district to district. What is acceptable in one community may not be acceptable in another. It is agreed upon within the community by the elders prior to the annual Communion. These include matters such as dress, permissible uses of technology, religious duties, and rules regarding interaction with outsiders. These elders are generally men.\n\nBearing children, raising them, and socializing with neighbors and relatives are the greatest functions of the Amish family. Amish typically believe that large families are a blessing from God. Community is central to the Amish way of life.\n\nWorking hard is considered godly, and some technological advancements have been considered undesirable because they reduce the need for hard work. Machines such as automatic floor cleaners in barns have historically been rejected as this provides young farmhands with too much free time.\n\nAmish cuisine is noted for its simplicity and traditional qualities. Food plays an important part in Amish social life and is served at potlucks, weddings, fundraisers, farewells, and other events. Many Amish foods are sold at markets including pies, preserves, bread mixes, pickled produce, desserts, and canned goods. Many Amish communities have also established restaurants for visitors.\n\nOver the years, the Amish churches have divided many times over doctrinal disputes. The largest group, the \"Old Order\" Amish, a conservative faction that separated from other Amish in the 1860s, are those that have most emphasized traditional practices and beliefs. The New Order Amish are a group of Amish that some scholars see best described as a subgroup of Old Order Amish, despite the name.\n\nThere are about 40 different Old Order Amish affiliations, the eight major affiliations are below, with Lancaster as the largest one in number of districts and population:\n\nThe table below indicates the use of certain technologies by different Amish affiliations. The use of cars is not allowed by any Old and New Order Amish, nor are radio, television or in most cases the use of the Internet. The three affiliations: \"Lancaster\", \"Holmes Old Order\" and \"Elkhart-LaGrange\" are not only the three largest affiliations, they also represent the mainstream among the Old Order Amish. The most conservative affiliations are above, the most modern ones below. Technologies used by very few are on the left; the ones used by most are on the right. The percentage of all Amish who use a technology is also indicated approximately.\n\nMost Old Order Amish speak Pennsylvania Dutch, and refer to non-Amish people as \"English\", regardless of ethnicity. Some Amish who migrated to the United States in the 1850s speak a form of Bernese German or a Low Alemannic Alsatian dialect. According to one scholar, \"today, almost all Amish are functionally bilingual in Pennsylvania Dutch and English; however, domains of usage are sharply separated. Pennsylvania Dutch dominates in most in-group settings, such as the dinner table and preaching in church services. In contrast, English is used for most reading and writing. English is also the medium of instruction in schools and is used in business transactions and often, out of politeness, in situations involving interactions with non-Amish. Finally, the Amish read prayers and sing in Standard German (which, in Pennsylvania Dutch, is called \"Hochdeitsch\") at church services. The distinctive use of three different languages serves as a powerful conveyor of Amish identity. \"Although 'the English language is being used in more and more situations,' Pennsylvania Dutch is 'one of a handful of minority languages in the United States that is neither endangered nor supported by continual arrivals of immigrants.'\"\n\nThe Amish largely share a German or Swiss-German ancestry. They generally use the term \"Amish\" only for members of their faith community and not as an ethnic designation. However some Amish descendants recognize their cultural background knowing that their genetic and cultural traits are uniquely different from other ethnicities. Those who choose to affiliate with the church, or young children raised in Amish homes, but too young to yet be church members, are considered to be Amish. Certain Mennonite churches have a high number of people who were formerly from Amish congregations. Although more Amish immigrated to North America in the 19th century than during the 18th century, most of today's Amish descend from 18th-century immigrants. The latter tended to emphasize tradition to a greater extent, and were perhaps more likely to maintain a separate Amish identity. There are a number of Amish Mennonite church groups that had never in their history been associated with the Old Order Amish because they split from the Amish mainstream in the time when the Old Orders formed in the 1860s and '70s. The former Western Ontario Mennonite Conference (WOMC) was made up almost entirely of former Amish Mennonites who reunited with the Mennonite Church in Canada. Orland Gingerich's book \"The Amish of Canada\" devotes the vast majority of its pages not to the Beachy or Old Order Amish, but to congregations in the former WOMC.\n\nThere are also several groups, called \"para-Amish\" by G. C. Waldrep and others that share many characteristics with the Amish, like horse and buggy transportation, plain dress, and the preservation of the German language. The members of these groups are largely of Amish origin, but these groups are not in fellowship with other Amish groups because they adhere to theological doctrines (e.g., assurance of salvation) or practices (community of goods) that are normally not accepted among mainstream Amish. One such former Amish group is the Bergholz Community.\n\nBecause the Amish are usually baptized no earlier than 18 and children are not counted in local congregation numbers, it is hard to estimate their numbers. Rough estimates from various studies placed their numbers at 125,000 in 1992; 166,000 in 2000; and 221,000 in 2008. Thus, from 1992 to 2008, population growth among the Amish in North America was 84 percent (3.6 percent per year). During that time they established 184 new settlements and moved into six new states. In 2000, about 165,620 Old Order Amish resided in the United States, of whom 73,609 were church members. The Amish are among the fastest-growing populations in the world, with an average of seven children per family.\n\nIn 2010, a few religious bodies, including the Amish, changed the way their adherents were reported to better match the standards of the Association of Statisticians of American Religious Bodies (ASARB). When looking at all Amish adherents and not solely Old Order Amish, there were about 241,000 Amish adherents in 28 U.S. states in 2010.\n\nIn 2017 there were Old Order communities in 31 U.S. states. Pennsylvania has the largest population (74,300), followed by Ohio (73,800) and Indiana (53,100), . The largest Amish settlements are in Lancaster County in southeastern Pennsylvania (38,095), Holmes County and adjacent counties in northeastern Ohio (35,850), and Elkhart and LaGrange counties in northeastern Indiana (24,955). Nearly 50% of the population in Holmes County is Amish.\n\nThe largest concentration of Amish west of the Mississippi River is in Missouri, with other settlements in eastern Iowa and southeast Minnesota. The largest Amish settlements in Iowa are located near Kalona and Bloomfield. The largest settlement in Wisconsin is near Cashton, Wisconsin with 13 congregations, i.e. about 2,000 people in 2009.\n\nBecause of rapid population growth in Amish communities, new settlements are formed to obtain enough affordable farmland. Other reasons for new settlements include locating in isolated areas that support their lifestyle, moving to areas with cultures conducive to their way of life, maintaining proximity to family or other Amish groups, and sometimes to resolve church or leadership conflicts.\n\nThe adjacent table shows the eight states with the largest Amish population in the years 1992, 2000, 2010 and 2018.\n\nThere are Amish settlements in four Canadian provinces: Ontario, Prince Edward Island, Manitoba and New Brunswick. The majority of Old Order settlements is located in the province of Ontario, namely Oxford (Norwich Township) and Norfolk counties. A small community is also established in Bruce County (Huron-Kinloss Township) near Lucknow.\n\nIn 2016, several dozen Old Order Amish families founded two new settlements in Kings County in the province of Prince Edward Island. Increasing land prices in Ontario had reportedly limited the ability of members in those communities to purchase new farms. At about the same time a new settlement was founded near Perth-Andover in New Brunswick, only about a dozen kilometers far from Amish setllements in Maine. In 2017 an Amish settlement was founded in Manitoba near Stuartburn.\n\nThe first attempt by Old Order Amish to settle in Latin America was in Paradise Valley, near Galeana, Nuevo León, Mexico but the settlement only lasted from 1923 to 1929. There was an Amish settlement in Honduras from about 1968 to 1978, but this settlement failed too. In 2015 new settlements of New Order Amish were founded east of Catamarca, Argentina, and Colonia Naranjita, Bolivia, about southwest of Santa Cruz. Most of the members of these new communities come from Old Colony Mennonite background and have been living in the area for several decades.\n\nIn Europe there was no split between Old Order Amish and Amish Mennonites; like the Amish Mennonites in North America, the European Amish assimilated into the Mennonite mainstream during the second half of the 19th century through the first decades of the 20th century. Eventually they dropped the word \"Amish\" from the names of their congregations and lost their Amish identity and culture. The last European Amish congregation joined the Mennonites in 1937 in Ixheim, today part of Zweibrücken in the Palatinate region.\n\nOnly a few outsiders, so-called seekers, have ever joined the Amish. Since 1950 only some 75 people have joined and remained members of the Amish. Since 1990 some twenty people of Russian Mennonite background have joined the Amish in Aylmer, Ontario.\n\nTwo whole Christian communities have joined the Amish: The Church at Smyrna, Maine, one of the five Christian Communities of Elmo Stoll after Stoll's death and the Church at Manton, Michigan, which belonged to a community that was founded by Harry Wanner (1935–2012), a minister of Stauffer Old Order Mennonite background. The \"Michigan Churches\", with which Smyrna and Manton affiliated, are said to be more open to seekers and converts than other Amish churches. Most of the members of these two para-Amish communities originally came from Plain churches, i. e. Old Order Amish, Old Order Mennonite or Old German Baptist Brethren.\n\nMore people have tested Amish life for weeks, months, or even years, but in the end decided not to join. Others remain close to the Amish but never think of joining.\n\nStephen Scott, himself a convert to the Old Order River Brethren, distinguishes four types of seekers:\n\nAmish populations have higher incidences of particular conditions, including dwarfism, Angelman syndrome, and various metabolic disorders, as well as an unusual distribution of blood types. The Amish represent a collection of different demes or genetically closed communities. Although the Amish do not have higher rates of genetic disorders than the general population, since almost all Amish descend from about 200 18th-century founders, genetic disorders resulting from inbreeding exist in more isolated districts (an example of the founder effect). Some of these disorders are rare or unique, and are serious enough to increase the mortality rate among Amish children. The Amish are aware of the advantages of exogamy, but for religious reasons marry only within their communities. The majority of Amish accept these as \"Gottes Wille\" (God's will); they reject the use of preventive genetic tests prior to marriage and genetic testing of unborn children to discover genetic disorders. However, Amish are willing to participate in studies of genetic diseases. Their extensive family histories are useful to researchers investigating diseases such as Alzheimer's, Parkinson's, and macular degeneration.\n\nWhile the Amish are at an increased risk for some genetic disorders, researchers have found their tendency for clean living can lead to better health. Overall cancer rates in the Amish are reduced and tobacco-related cancers in Amish adults are 37 percent and non-tobacco-related cancers are 72 percent of the rate for Ohio adults. The Amish are protected against many types of cancer both through their lifestyle and through genes that may reduce their susceptibility to cancer. Even skin cancer rates are lower for Amish, despite the fact many Amish make their living working outdoors where they are exposed to sunlight. They are typically covered and dressed by wearing wide-brimmed hats and long sleeves which protect their skin.\n\nTreating genetic problems is the mission of Clinic for Special Children in Strasburg, Pennsylvania, which has developed effective treatments for such problems as maple syrup urine disease, a previously fatal disease. The clinic is embraced by most Amish, ending the need for parents to leave the community to receive proper care for their children, an action that might result in shunning. Another clinic is DDC Clinic for Special Needs Children, located in Middlefield, Ohio, for special-needs children with inherited or metabolic disorders. The DDC Clinic provides treatment, research, and educational services to Amish and non-Amish children and their families.\n\n\"People's Helpers\" is an Amish-organized network of mental health caregivers who help families dealing with mental illness and recommend professional counselors. Suicide rates for the Amish are about half that of the general population.\n\nThe Old Order Amish do not typically carry private commercial health insurance. A handful of American hospitals, starting in the mid-1990s, created special outreach programs to assist the Amish.\n\nAlthough not forbidden, most Amish do not practice any form of birth control. They are against abortion and also find \"artificial insemination, genetics, eugenics, and stem cell research\" to be \"inconsistent with Amish values and beliefs\".\n\nAs time has passed, the Amish have felt pressures from the modern world. Issues such as taxation, education, law and its enforcement, and occasional discrimination and hostility are areas of difficulty.\n\nThe Amish way of life in general has increasingly diverged from that of modern society. On occasion, this has resulted in sporadic discrimination and hostility from their neighbors, such as throwing of stones or other objects at Amish horse-drawn carriages on the roads.\n\nThe Amish do not usually educate their children past the eighth grade, believing that the basic knowledge offered up to that point is sufficient to prepare one for the Amish lifestyle. Almost no Amish go to high school and college. In many communities, the Amish operate their own schools, which are typically one-room schoolhouses with teachers (usually young, unmarried women) from the Amish community. On May 19, 1972, Jonas Yoder and Wallace Miller of the Old Order Amish, and Adin Yutzy of the Conservative Amish Mennonite Church were each fined $5 for refusing to send their children, aged 14 and 15, to high school. In \"Wisconsin v. Yoder\" (1972), the Wisconsin Supreme Court overturned the conviction, and the U.S. Supreme Court affirmed this, finding the benefits of universal education were not sufficient justification to overcome scrutiny under the Free Exercise Clause of the First Amendment.\n\nThe Amish are subject to sales and property taxes. As they seldom own motor vehicles, they rarely have occasion to pay motor vehicle registration fees or spend money in the purchase of fuel for vehicles. Under their beliefs and traditions, generally the Amish do not agree with the idea of Social Security benefits and have a religious objection to insurance. On this basis, the United States Internal Revenue Service agreed in 1961 that they did not need to pay Social Security-related taxes. In 1965, this policy was codified into law. Self-employed individuals in certain sects do not pay into or receive benefits from the United States Social Security system. This exemption applies to a religious group that is conscientiously opposed to accepting benefits of any private or public insurance, provides a reasonable level of living for its dependent members, and has existed continuously since December 31, 1950. The U.S. Supreme Court clarified in 1982 that Amish employers are not exempt, but only those Amish individuals who are self-employed.\n\nIn 1964 Pathway Publishers was founded by two Amish farmers to print more print material about the Amish and Anabaptists in general. It is located in Lagrange, Indiana, and Aylmer, Ontario. Pathway has become the major publisher of Amish material. Pathway publishes a number of school textbooks, general reading books, and periodicals. There are also a number of private enterprises who publish everything from general reading to reprints of older literature that has been considered of great value to Amish families. Some Amish read the Pennsylvania German newspaper \"Hiwwe wie Driwwe\", and some of them even contribute dialect texts.\n\nGroups that sprang from the same late 19th century Old Order Movement as the Amish share their Pennsylvania German heritage and often still retain similar features in dress. These Old Order groups include different subgroups of Old Order Mennonites, traditional Schwarzenau Brethren and Old Order River Brethren. The Noah Hoover Old Order Mennonites are so similar in outward aspects to the Old Order Amish (dress, beards, horse and buggy, extreme restrictions on modern technology, Pennsylvania German language), that they are often perceived as Amish and even called Amish.\n\nConservative \"Russian\" Mennonites and Hutterites who also dress plain and speak German dialects emigrated from other European regions at a different time with different German dialects, separate cultures, and related but different religious traditions. Particularly, the Hutterites live communally and are generally accepting of modern technology.\n\nThe few remaining Plain Quakers are similar in manner and lifestyle, including their attitudes toward war, but are unrelated to the Amish. Early Quakers were influenced, to some degree, by the Anabaptists, and in turn influenced the Amish in colonial Pennsylvania. Almost all modern Quakers have since abandoned their traditional dress.\n\nThe Northkill Amish Settlement, established in 1740 in Berks County, Pennsylvania, was the first identifiable Amish community in the new world. During the French and Indian War, the so-called Hochstetler Massacre occurred: Local Indian tribes attacked the Jacob Hochstetler homestead in the Northkill settlement on September 19, 1757. The sons of the family took their arms but father Jacob did not allow them to shoot. Jacob Sr.'s wife, Anna (Lorentz) Hochstetler, a daughter (name unknown) and Jacob Jr. were killed by the Indians. Jacob Sr. and sons Joseph and Christian were taken captive. Jacob escaped after about 8 months, but the boys were held for several years.\n\nAs early as 1809 Amish were farming side by side with Native American farmers in Pennsylvania. According to Cones Kupwah Snowflower, a Shawnee genealogist, the Amish and Quakers were known to incorporate Native Americans into their families to prevent them from ill treatment, especially after the Removal Act of 1832.\n\nThe Amish, as pacifists, did not engage in warfare with Native Americans, nor displace them directly, but were part of a wave of European immigrants who forced Native Americans westward.\n\nIn 2012, the Lancaster Mennonite Historical Society collaborated with the Native American community to construct a replica Iroquois Longhouse.\n\n\n\n\n"}
{"id": "6995889", "url": "https://en.wikipedia.org/wiki?curid=6995889", "title": "Armenian Genocide denial", "text": "Armenian Genocide denial\n\nArmenian Genocide denial is the act of denying the planned systematic genocide of 1.5 million Armenians during World War I, conducted by the Ottoman government. Turkey similarly denies the genocides perpetrated against indigenous Assyrians and Greeks during the same period. As form of denialism, it can be compared to similar negationist historical revisionisms such as Holocaust denial and Nanking Massacre denial.\n\nThe Armenian Genocide is almost unanimously acknowledged as a historical fact by historians and genocide scholars alike. It is also widely considered to have been the first modern genocide, with the word \"genocide\" itself having been invented by Raphael Lemkin to describe the sheer scale and success of the plan organized to systematically eliminate the Armenians. Revisionists typically argue the academic consensus of it being a genocide as anti-Turkish propaganda or as a conspiracy spread by the Armenians, instead claiming that it either did not occur or that it was somehow justified at the time.\n\nDenial of the Armenian Genocide is officially outlawed in France, Switzerland, Greece, Cyprus, and Slovakia.\n\nCurrently, only the governments of Turkey and Azerbaijan deny that there was an Armenian genocide, with their ally Pakistan not even recognizing Armenia as a country. Many other countries, most controversially the United States (pressured by the Turkish lobby, Israel, and, in the past, the Anti-Defamation League), have deliberately avoided officially recognizing it as a genocide to avoid harming relations with Turkey. In 2016, however, Anti-Defamation League CEO Jonathan Greenblatt unequivocally acknowledged the veracity of the Armenian Genocide, and stated that the organization supports U.S. recognition. The Turkish government has spent millions of dollars on Washington lobbying over the past decade, much of it focused on the Armenian genocide issue, and has in the past threatened politicians from other countries with strong retaliation to prevent them from using the word \"genocide\". The Turkish Republic has also been accused of attempting to intimidate and silence foreign investigative journalists and genocide scholars.\n\nAccording to historian Yair Auron, \"there can be no doubt about the fact of [Armenian] genocide itself. In this sense, the denial of the Armenian genocide is very similar to the denial of the Holocaust.\"\n\nOf the notable scholars that dispute its designation, Bernard Lewis, Stanford Shaw and Guenter Lewy acknowledge the historical event and its implications but reject a genocidal intent in favor of \"uniqueness\" of the Holocaust as only true genocide. Justin McCarthy, Heath Lowry and Eberhard Jäckel reject the designation altogether, and have met much criticism and accusations from other scholars as promoting Armenian Genocide denial.\n\nThe term \"genocide\" was coined by the Polish Jew Raphael Lemkin in 1943, who had escaped Nazi rule, although the full extent of the Holocaust was not yet known at the time. He later used it to describe what he had heard about the Armenian Genocide: in a 1949 CBS interview with Quincy Howe, Lemkin explained, \"I became interested in genocide because it happened so many times. It happened to the Armenians, then after the Armenians, Hitler took action.\"\n\nTurkish denialists claim that the \"intent to destroy\" clause of the Genocide Convention has not been met, and that it is therefore not a genocide.\n\nAfter vague claims made by a speaker from the United Kingdom, Geoffrey Robertson, a noted British barrister and specialist in the field of human rights, observed that the British government refused to acknowledge the Armenian Genocide by saying that evidence for it was \"not sufficiently unequivocal\". He pointed out that this phrase 1) was an oxymoron and 2) represented an invented standard of proof. He explained: \"There are only two standards of proof in UK law: the civil standard (on the balance of probabilities; i.e. more likely than not) and the criminal standard (beyond reasonable doubt)\". He further observed that recent British governments have not taken into account that the terms used by the British government of the time in referring to 1915 entirely anticipated the modern definition of genocide and that the drafters of the Genocide Convention had 1915 in mind when drafting the new international crime.\n\nCurrently, regarding the activities performed under the Tehcir Law of May 1915, the Republic of Turkey rejects the use of the word \"deportation\" and \"refugee\". Turkey instead uses the words \"relocation\" and \"immigrant\", respectively. Turkey claims in its state-supported \"Views Against Genocide Allegations\" that all the destination regions were within the Ottoman Empire's borders, and that the Ottoman government recognized these \"immigrants\" as its citizens and took extensive measures to record the type, quantity, and value of their property, as well as the names of the owners and where they were sent.\n\nIn 2016 Turkish President Recep Tayyip Erdogan said \"Our attitude on the Armenian issue has been clear from the beginning. We will never accept the accusations of genocide\". The Turkish government does not deny that many Armenians were killed by the Ottoman military, but disputes the death toll, and emphasizes that there were deaths on both sides during World War I.\n\nScholars give several reasons for the Turkish government's denial including the preservation of national identity, but also territorial concerns (called \"Sevres Syndrome\"). Turkey's territorial concerns are exacerbated by Armenia's refusal to recognize Turkey's eastern borders. Another reason is the demand for reparations. Armenian diaspora groups have in recent years become more focused on financial reparations. The Armenian Genocide Reparations Study Group has released a study that was partly funded by Armenian advocacy organizations which includes various recommendations for how to calculate a possible reparations package. Genocide scholar Henry C. Theriault who chaired the panel has said that the question of reparations is \"obviously a pretty central one\". The Turkish government position is that reparations do not need to paid for the events of 1915. Human rights historians have said that recognition by Turkey would undermine any legal defense Turkey might have to future compensation claims.\n\nTaner Akcam has written the following:\n\nIn Turkish discourse, the following argument is commonly heard: \"If we accept the Genocide, then the claim for reparations will soon follow.\" It shows that the main fear is not what we should call the event, but what comes after the event.\n\nAccording to Fatma Muge Gocek, many Turkish journalists have viewed the issue of recognition as \"an imposition on the Turkish state and society, one that would solely benefit the Armenians\". In one editoral a Turkish journalist wrote \"If you once acknowledge, then see what will happen next? From demands for restitution to land...\".\n\nThe Ottoman Empire wanted to remove the threat of Armenian resistance and the Turkish authorities today hold the position that the deaths incurred by Armenians as a whole were the result of the turmoil of World War I and that the Ottoman Empire was fighting against Russia, Armenian volunteer units, and the Armenian militia. However, the Armenians had neither a police force nor an army. Heather Rae noted that scholars have long been denied access to Ottoman archives, which Turkish sources often refer to in their works. In the late 1980s access was granted to some archives by the Turkish government, but it appears that the material was limited and the government took a very selective approach to who was allowed to study the material. Historian Taner Akcam also writes about the \"careful selection\" of Ottoman archive materials. \"While we are missing a significant portion of these papers, what remains in the Ottoman archives and in court records is sufficient to show that the CUP Central Committee, and the Special Organization is set up to carry out its plan, did deliberately attempt to destroy the Armenian population\".\n\nAccording to McCarthy, the genocide was a two sided battle: \"when they [the Armenians] advanced victoriously under the protection of the Russian Army, the same spectacle occurred as in 1915, but this time it was Turks who were attacked by Armenians, aided and possibly commanded and directed by Russia.\"\n\nThe Turkish authorities maintain the position that the Ottoman Empire did not exercise the degree of control which the opposing parties claim. Turkey accepts that there were Armenian deaths as a result of Ottoman decisions, but states that the responsible Ottoman bureaucrats and military personnel were tried. Bernard Lewis believes that what he names the \"tremendous massacres\"\nwere not \"a deliberate preconceived decision of the Ottoman government\".\n\nTurkish scholars and other denialists reject the academic consensus of up to 1.5 million Armenian deaths attributed to the genocide. McCarthy calculated an estimate of the pre-war Armenian population, then subtracted his estimate of survivors, arriving at a figure of less than 600,000 for Armenian casualties for the period 1914 to 1922. However, in a more recent essay, he projected that if the Armenian records of 1913 were accurate, 250,000 more deaths should be added, for a total of 850,000.\n\nMcCarthy's numbers were highly criticized by academia for underrepresenting the actual numbers. Some of them, like Frédéric Paulin, have severely criticized McCarthy's methodology and suggested that it is flawed. Hilmar Kaiser another specialist has made similar claims, as have professor Vahakn N. Dadrian and professor Levon Marashlian. The critics not only question McCarthy's methodology and resulting calculations, but also his primary sources, the Ottoman censuses. They point out that there was no official statistic census in 1912; rather those numbers were based on the records of 1905 which were conducted during the reign of Sultan Hamid. While Ottoman censuses claimed an Armenian population of 1.2 million, Fa'iz El-Ghusein (the Kaimakam of Kharpout) wrote that there were about 1.9 million Armenians in the Ottoman Empire, and some modern scholars estimate over 2 million. German official Max Erwin von Scheubner-Richter wrote that fewer than 100,000 Armenians survived the genocide, the rest having been exterminated (). \n\nThe Turkish authorities have put forth certain conditions before attempting to reconcile with Armenia. Turkey closed its border with Armenia in 1993 following the Nagorno-Karabakh War between Armenia and Turkic-speaking Azerbaijan. The borders have remained closed because the Nagorno-Karabakh dispute has not been settled to this day.\n\nIn 2005 Turkish Prime Minister Recep Tayyip Erdoğan invited Turkish, Armenian and international historians to form a commission to reevaluate the events of 1915 by using archives in Turkey, Armenia and other countries. Armenian president Robert Kocharian responded, \n\nYour proposal to address the past can't be effective if it does not refer to the present and the future. To start an effective dialog, we should create a favorable political environment. The governments are responsible for the development of bilateral relations, and we have no right to delegate that responsibility to the historians. Thus, we have proposed and we again propose to establish normal relations between our countries without preconditions.\nIn this regard, an inter-governmental commission can be formed to discuss the outstanding issues to resolve them and maintain mutual understanding.\n\nThe Concerned Scholars and Writers says the Turkish government attempts \"to sanitize its history now include the funding of chairs in Turkish studies – with strings attached – at American universities\".\n\nMany references that cite genocidal intent use the \"Talat Pasha telegrams\", which are a series of documents by the Interior Minister Mehmed Talat Pasha, to constitute concrete evidence that the deaths were implemented as a state policy. Pasha was tied to the \"Kill every Armenian man, woman, and child without concern\" order in these documents.\n\nOn 19 May 1985, \"The New York Times\" and \"The Washington Post\" ran an advertisement in which a group of 69 American historians called on Congress not to adopt the resolution on the Armenian Genocide. Bernard Lewis, along with Heath Lowry, was among them and so the case was named after him. The advertisement was paid for by the Committee of the Turkish Associations. Both Lewis and Lowry have been included among the \"key deniers\" of the Armenian Genocide. According to Roger W. Smith, Eric Markusen and Robert Jay Lifton, Lowry was also advising on how to prevent mention of the Armenian Genocide in scholarly works, and was discovered ghost writing for the Turkish ambassador in Washington on issues regarding the Embassy's denial of the Armenian Genocide. The Armenian Assembly of America found that many or most of the 69 academics apparently benefited directly or indirectly from Turkish government research grants.\nAccording to Yair Auron, an Israeli historian, scholar and expert specializing in genocide studies and racism, this advertisement is a good example of one of many Turkish attempts to influence academia, a project on which Turkey has spent enormous funds.\n\nAfter publication of the statement, professor Gérard Chaliand of University expressed disappointment that Lewis had signed. Lewis responded that the statement was an attempt to avoid damaging Turkish-American relationships and that it included a call for Turkey to open its archives, but the former was not mentioned in the statement. Some of the other signatories confessed later that there are deliberate attempts by the Turkish government and its allies to muddle and deny the issue. Others confirm that there have been massacres but say they avoid the use of the term Genocide. However, Henry Morgenthau Sr. wrote that \"When the Turkish authorities gave the orders for these deportations, they were merely giving the death warrant to a whole race; they understood this well, and, in their conversations with me, they made no particular attempt to conceal the fact.\"\n\nIn October 2000, when the House of Representatives of the US was to discuss the resolution on the Armenian Genocide, Turkish politician Şükrü Elekdağ admitted that the statement had become useless because none of the original signatories besides Justin McCarthy would agree to sign a new, similar declaration.\n\nOne of the 69 signatories of the 1985 statement to the US Congress was Donald Quataert. He resigned from the position of the chairman of the board of directors of the Institute of Turkish Studies, which he had held since 2001. As he announced, he had to resign due to the pressure of the Turkish ambassador Nabi Shensoy after he characterised the massacres of Armenians in Turkey as genocide. Shensoy rejected the allegations. Quataert's resignation created a scandal in academia and a number of members of the board of directors of the Institute resigned as well after the announcement. Mervat Hatem the director of Middle East Studies Association addressed the Prime Minister of Turkey Erdogan a harsh letter, whereby he expressed grave concerns with the announcements of Turkish officials to stop the financing of the Institute if Quataert didn't renounce his assessments publicly. Hatem also noted, that \"the resignations are in contradiction with those many requests to leave the discussion and the assessment of the Armenian Genocide to the academia (instead of discussing it on the political arena) that Turkey has been making.\" According to the announcement by Quataert, the members of the board of directors on the Institute of Turkish Studies were surprised to find out, that the funding of the institute by Turkey is not a sign of trust but a gift, that can be annulled at any moment.\n\nOfficially the state of Israel neither recognizes nor denies the Armenian Genocide. Politicians from primarily left wing and centrist parties such as Meretz and Kadima, but also occasionally right wing parties such as Likud, have been promoting recognition and commemoration of the Armenian Genocide. This cooperation is significant since it includes activists and politicians who usually are on the opposing sides of the political spectrum.\nYet the official line of all Israeli governments has been to keep the status quo, partially because of modern-day real-politik reasons. Right-wing party Yisrael Beiteinu (Israel Our Home) claims that Genocide discussions would jeopardise Israel-Azerbaijan and Israel-Turkish relations and hurt close economic and military cooperation with them. These two countries are essential for Israel's regional policy and interests opposing Iran. In 2008, Yosef Shagal, an Azerbaijani Jew and now retired Israeli parliamentarian from Israel Our Home stated in an interview to Azerbaijan media (which officially denies the genocide): \"I find it deeply offensive, and even blasphemous to compare the Holocaust of European Jewry during the Second World War with the mass extermination of the Armenian people during the First World War. Jews were killed because they were Jews, but Armenians provoked Turkey and should blame themselves.\"\n\nDespite this controversy, there are several prominent Armenian Genocide Memorials in the State of Israel. To commemorate the 100th anniversary of the genocide, the Jerusalem Symphony Orchestra performed music written by Armenian composers. Many Israeli and Jewish historians also draw parallels between the genocides. Hebrew University scholar Yehuda Bauer wrote:\n\nIsrael's president Rivlin once campaigned for Israel to recognize the Armenian Genocide. In 2012, he said \"It is our moral duty to remember and remind of the tragedy that befell the Armenian people, who lost more than a million of its sons during the First World War, and we must not make this a political issue. I am aware of the sensitivity of this issue. But let us be clear: This is not an accusation of Turkey today or of the current Turkish government.\" As president he has been less vocal on this issue. Concerned about the negative reaction of Turkey if the president signed the petition, unnamed officials of the Foreign Ministry welcomed what they called Rivlin's \"statesmanship.\"\n\nThe Islamist Hani al-Sibai cited Justin McCarthy's work while engaging in Armenian Genocide denial.\n\nAccording to the \"Encyclopedia of Genocide and Crimes Against Humanity\", the denial of Armenian genocide is \"the most patent example of a state's denial of its past\".\n\nHistorians mark that \"the genocide of the Armenians has been denied to this day by successive Turkish governments, with the exception of the short-lived imperial government that existed between the end of World War I and the ascendance of the Kemalist nationalist regime in the early 1920s.\" To deny the Armenian genocide \"is like Holocaust denial, \" notes Gregory Stanton, vice president of the International Association of Genocide Scholars and president of Genocide Watch.\n\nAccording to Intelligence Report journal of Southern Poverty Law Center, \n\nrevisionist historians who conjure doubt about the Armenian genocide and are paid by the Turkish government provided the politicians with the intellectual cover they needed to claim they were refusing to dictate history rather than caving in to a foreign government's present-day interests.\n\nMark Potok, the editor of Intelligence Report, wrote:\n\nSome semi-official Turkish narratives now claim, in effect, that the Armenians actually carried out genocidal attacks on the Turks. Neo-Nazis and their scholarly enablers say that \"the Jews\" manufactured tall tales of the Holocaust in order to extort money and other concessions from postwar Germany. Neo-Confederates like Doug Wilson, a far-right pastor in Moscow, Idaho, tell their listeners with a straight face that the Civil War was nothing less than a defense of righteous Christian civilization and that blacks really didn't mind slavery. These lies all serve current agendas—to demonize and minimize the historical claims of Armenians, Jews, and African Americans.\n\nColin Tatz, Professor of Macquarie University, considers the nature of Turkish denial industry as \"pernicious, outrageous and continued\": \"Here is a modern state, totally dedicated, at home and abroad, to extraordinary actions to have every hint or mention of an Armenian genocide removed, contradicted, explained, countered, justified, mitigated, rationalised, trivialised and relativised.\" In their book \"Criminological Perspectives\", E. McLaughlin, J. Muncie and G. Hughes conclude: \n\nIf the Turkish government can deny that the Armenian genocide happened; if revisionist historians and neo-Nazis deny that Holocaust took place; if powerful states all around the world today can systematically deny the systematic violations of human rights they are carrying out – then we know that we're in bad shape.\n\nIn 1990, psychologist Robert Jay Lifton received a letter from Nuzhet Kandemir, Turkish ambassador to the United States, questioning his inclusion of references to the Armenian Genocide in one of his books. The ambassador inadvertently included a draft of a letter, presented by denier Heath W. Lowry, advising the ambassador on how to prevent mention of the Armenian Genocide in scholarly works. Lowry was later named to the Atatürk chair of Ottoman Studies at Princeton University, which had been endowed with a $750,000 grant from the Republic of Turkey. The incident has been the subject of numerous reports as to ethics in scholarship.\n\nAnother source notes: \n\nIn order to institutionalize this campaign of denial and try to invest it with an aura of legitimacy, a \"think-tank\" was established in Ankara in April 2001. Operating under the name \"Institute for Armenian Research\" as a subsidiary of The Center For Eurasian Studies, with a staff of nine, this new outfit is now proactively engaged in contesting all claims of genocide by organizing a series of conferences, lectures, and interviews, and above all, through the medium of publications, including a quarterly.\n\nOpen University of Israel scholar Yair Auron has addressed the various means employed by the Turkish government to obscure the reality of the Armenian Genocide:\n\nSince the 1980s, the Turkish government has supported the establishment of \"institutes\" affiliated with respected universities, whose apparent purpose is to further research on Turkish history and culture, but which also tend to act in ways that further denial.\n\nUniversity of California, Los Angeles scholar Leo Kuper in a review on Ervin Staub's \"The Roots of Evil: The Origins of Genocide and Other Group Violence\" research, wrote:\n\nThe Armenian genocide is a contemporary current issue, given the persistent aggressive denial of the crime by the Turkish government-not withstanding its own judgment in courts martial after the first World War, that its leading ministers had deliberately planned and carried out the annihilation of Armenians, with the participation of many regional administrators.\n\nAccording to American scholars Roger W. Smith, Eric Markusen and Robert Jay Lifton,\n\nThe government of Turkey has channeled funds into a supposedly objective research institute in the United States, which in turn paid the salary of a historian who served that government in its campaign to discredit scholarship on the Armenian genocide.\n\n\"Given the indisputable documentary record of the Armenian genocide, it would appear that at least some of those who refuse to go on record recognizing Turkey's genocide of Armenians are, like those who refuse to recognize Germany's genocide of European Jews, motivated by ignorance and bigotry\", claims American scholar Stephen Zunes.\n\nOn 9 June 2000, in a full-page statement in The New York Times, 126 scholars, including Nobel Prize-winner Elie Wiesel, historian Yehuda Bauer, and sociologist Irving Horowitz, signed a document \"affirming that the World War I Armenian genocide is an incontestable historical fact and accordingly urge the governments of Western democracies to likewise recognize it as such.\"\n\nWiesel himself has repeatedly called Turkey's 90-year-old campaign to cover up the Armenian genocide a double killing, since it strives to kill the memory of the original atrocities.\n\nIn an open letter by the \"Danish Department for Holocaust and Genocide Studies and the denial and relativization of the Armenian genocide\", historians Torben Jorgensen and Matthias Bjornlund wrote:\n\nWhen it comes to the historical reality of the Armenian genocide, there is no \"Armenian\" or \"Turkish\" side of the \"question, \" any more than there is a \"Jewish\" or a \"German\" side of the historical reality of the Holocaust: There is a scientific side, and an unscientific side acknowledgment or denial. In the case of the denial of the Armenian genocide, it is even founded on a massive effort of falsification, distortion, cleansing of archives, and direct threats initiated or supported by the Turkish state, making any \"dialogue\" with Turkish deniers highly problematic.\n\nPhilip L. Kohl and Clare Fawcett write that the \"Armenian cultural remains in neighboring Turkey are frequently dismissed or referred to as \"Ottoman period\" monuments\", and that the continued denial of the state-sponsored genocide is \"related to these practices\".\n\nAccording to Taner Akçam, Turkey \"tried to erase the traces of a recent past that had become undesirable\" through a series of reforms, so the collective memory \"was replaced by an official history written by a few authorised academics, which became the sole recognised reference. Events prior to 1928 and the writings of past generations became a closed book.\"\n\nIn a lecture he delivered in June 2011, Akçam stated that he was told by a Turkish foreign ministry official that the Turkish government was trying to bribe historians and academics in the United States to deny the Armenian Genocide. Though he did not make any direct accusations, he noted the timing between what his source said with the recent publication of American historian Michael M. Gunter's book \"Armenian History and the Question of Genocide\". He also raised the point that the four individuals who praised Gunter's book – Hakan Yavuz of University of Utah, Guenter Lewy of University of Massachusetts, Jeremy Salt of Bilkent University, Ankara, and Edward J. Ericson of Marine Corps Command & Staff College, Virginia – \"are well known for their denialist position and works regarding the genocide of 1915.\"\n\nSome countries, including Cyprus have adopted laws that punish genocide denial. In October 2006, the French National Assembly, despite opposition from foreign minister Philippe Douste-Blazy, passed a bill which if approved by the Senate would make Armenian Genocide denial a crime. On 7 October 2011 French President Nicolas Sarkozy said that Turkey's refusal to recognize the genocide would force France to make such denials a criminal offense. On 22 December 2011, the lower house of the French legislature approved a bill making it a crime (punishable by a year in prison and a fine of 45,000 euros) to publicly deny as genocide the killing of Armenians by troops of Turkey's former Ottoman Empire. On 23 January 2012, the French Senate adopted the law criminalizing genocide denial. However, on 28 February 2012, the Constitutional Council of France invalidated the law, stating, among other things, that it curbs freedom of speech. After that the French President Sarkozy called on his cabinet to draft new legislation to punish those who deny that the mass killing of Armenians by Ottoman troops is a genocide. In 2016 the French Parliament adopted the new bill criminalizing the Armenian Genocide denial, which was put down by the French Constitutional Court in January 2017. The Council said the \"ruling causes uncertainty regarding expressions and comments on historical matters. Thereby, this ruling is an unnecessary and disproportionate attack against freedom of speech.\"\n\nThe first person convicted in a court of law for denying the Armenian genocide is Turkish politician Doğu Perinçek, found guilty of racial discrimination by a Swiss district court in Lausanne in March 2007. At the trial, Perinçek denied the charge thus: \"I have not denied genocide because there was no genocide.\". After the court's decision, he said, \"I defend my right to freedom of expression.\" Ferai Tinç, a foreign affairs columnist with Turkey's \"Hürriyet\" newspaper, commented, \"we find these type of [penal] articles against freedom of opinion dangerous because we are struggling in our country to achieve freedom of thought.\" Perinçek appealed the verdict. In December 2007, the Swiss Federal Court confirmed the sentence given to Perinçek. Perinçek then appealed to the European Court of Human Rights, and in 2013 the Court ruled that Perinçek's freedom of expression, as enshrined in Article 10 of the European Convention on Human Rights, had been violated.<ref name=\"ECHR 27510/08\"></ref> The European Court of Human Rights's Grand Chamber ruled in favour of Perinçek on 15 October 2015. (see Perinçek v. Switzerland).\n\nIn October, 2008 the Swiss court ruled that three Turks were guilty of racial discrimination after having claimed that the Armenian Genocide was an \"international lie.\" The European representative of the Party of Turkish Workers, Ali Mercan, was sentenced to pay a fine of 4,500 Swiss francs ($3,900), two others were ordered to pay 3,600 Swiss francs. In October 2010, the Swiss Federal Court confirmed the verdict.\n\nIn November 1993 American historian Bernard Lewis said in an interview that calling the massacres committed by the Turks in 1915 a genocide was just \"the Armenian version of this history\". In a 1995 civil proceeding a French court censured his remarks as a denial of the Armenian Genocide and fined him one franc, as well as ordering the publication of the judgment at Lewis' cost in \"Le Monde\". The court ruled that while Lewis has the right to his views, they did damage to a third party and that \"it is only by hiding elements which go against his thesis that the defendant was able to state that there was no 'serious proof' of the Armenian Genocide; consequently, he failed in his duties of objectivity and prudence by expressing himself without qualification on such a sensitive subject\".\n\nIn 6 June 2005 edition of \"Time Europe\", the Ankara Chamber of Commerce included—along with a tourism in Turkey advertisement—a DVD containing a 70-minute presentation denying the Armenian Genocide. \"Time Europe\" later apologized for allowing the inclusion of the DVD and published a critical letter signed by five French organizations. The apology stated that the DVD had not been adequately reviewed by anyone at \"Time Europe\" because it was believed to be a benign promotion piece, and that it would not have been distributed if the magazine had been aware of its content. The magazine described the DVDs contents as a \"so-called documentary\" that \"presents a one-sided view of history that does not meet our standards for fairness and accuracy\". The 12 February 2007 edition of \"Time Europe\" included a full-page announcement and a DVD of a documentary about the Armenian Genocide by French director Laurence Jourdan, with an interview with Yves Ternon.\n\nThe Turkish government, in advance of the anniversary of 100 years from the genocide at 2015, has reverted to the position that the matter should be subject to further study by historians, sponsoring the website www.lethistorydecide.org. The website was part of the wider \"Let History Decide\" campaign which has been organized by the Turkish American Steering Committee in the USA. The committee also launched the Twitter hashtag #lethistorydecide. The campaign had a strong social media presence, including Twitter (@historydecide), Instagram and Facebook. The main slogan of the campaign was: \"Unite us, not divide us.\"\n\n\n\n\n"}
{"id": "44661257", "url": "https://en.wikipedia.org/wiki?curid=44661257", "title": "Art market", "text": "Art market\n\nThe art market is represented by a marketplace of buyers and sellers trading in the commodities, services, and works-of-art commonly associated with the various arts. The art market is also concerned with the production of new art which enters the art market. The art market is an example of one type of marketplace, among many different types of markets which occur in economics. In particular, the art market has many similarities with other marketplaces where buyers and sellers meet, as well as significant distinguishing factors indicative of its differences from other types of markets in economics.\n\nThe art market operates in an economic model that considers more than supply and demand: it is a hybrid type of prediction market where art is bought and sold for values based not only on a work's perceived cultural value, but on both its past monetary value as well as its predicted future value. The market has been described as one where producers don't make work primarily for sale, where buyers often have no idea of the value of what they buy, and where middlemen routinely claim reimbursement for sales of things they have never seen to buyers they have never dealt with. Moreover, the market is not transparent; private sales data is not systematically available and private sales represent about half of market transactions.\n\nUnlike the volumes in the securities market where millions of people and firms participate in buying and selling financial interests, or the commodities market where measures of raw or primary products are exchanged using standardized contracts, art market activity largely follows the demands of a more limited array of private collectors, museums, and large corporate interests as the principal market participants. Corporate collectors, however, can have a disparately large market impact, for instance, \"Spear's\" reported in 2015 that British Rail began investing in art for its pension fund beginning in 1974 (prior to privatization), spending about £40M or approximately 3% of its funds on art, before selling those assets between 1987–1999. British Rail's efforts realized profits, particularly due to the Impressionist portfolio, but the collection was liquidated because it came to be seen as an illegitimate investment area, particularly as alternative investments became available. Also, because original artworks are not fungible like stocks, they have valuation challenges not similarly affecting securities, with dynamics of what Karpik calls singularities.\n\nThus, because the art market's participants are far more limited in number than the securities or commodities markets, because artworks are not fungible, and because art valuation relies to a great extent on the advice and enthusiasm of a variety of specialized market analysts, these limitations each in turn dictate the size of the market and increase the risk that some items may be over or undervalued.\n\nThe art market moves in cycles with activity generally peaking in the spring and autumn when the major auction houses traditionally schedule auctions, and results in the market being seasonal rather than ongoing. While private sales take place all year, those sales are often not publicized as auctions are and thus do not affect the market until they become known.\n\nArt valuations made for an autumn auction may be unrealistic for the following spring auction season because fortunes in the financial markets during one season can affect the art market in the following season, and equity markets do significantly impact the art market. Volatility in the financial markets often causes volatility in the art market as happened in the contraction of the art market during the 2008-2009 recession when sales at Sotheby's, Christie's, and Phillips de Pury & Company were less than half the previous year: November 2008, $803.3 million compared to November 2007, $1.75 billion; and between 2000 and 2003 when the annual volume of art works sold at auction dropped 36%. In other instances, the art market can fare reasonably well despite volatility in the stock market such as happened from January 1997 through May 2004 when the average quarterly fluctuation in the Artprice Global Index was two to three times smaller than the same statistic for the Dow Jones Industrial Average and the S&P 500.\n\nAs art market participants' fortunes wax and wane in the financial markets, buying power evolves and affects participants' ability to afford highly valued works, resulting in new buyers and sellers entering, leaving, or re-entering the market, and an artwork sold to offset losses in the financial market might be sold for substantially more or substantially less than its last at auction. In the late 1980s during the stock-market boom, the art market expanded in turn with prices soaring to new heights, and investment firms took a greater interest in the art market and began to study it in-depth. Concurrently, the previously non-transparent art market became more accessible via the increasing availability of indices and online data although researchers discovered biased price estimates in the auction houses.\n\nArt sometimes has transient fashionability that also can affect its value: what sells well for a time may be supplanted in the market by new styles and ideas in short order. For instance, in the spring of 2008 a collector offered over $80 million for Jeff Koons' stainless-steel \"Rabbit\", and yet a year later, of four works in the fall auctions at Christie's and Sotheby's in New York, only two of his pieces sold well and one failed to sell entirely. In 2011, Christie's sold Koons' \"Balloon Flower\" sculpture for $16.9 million.\n\nThe art market as a whole is affected by its two main parts: the primary art market, where new art comes to the market for the first time, and the secondary market, for existing art that has been sold at least once before. Once a work is sold on the primary market it enters the secondary market, and the prices for which it sold in the primary market have a direct bearing on the work's value in the secondary market. Supply and demand affect the secondary market more than the primary market because works new to the market, mainly contemporary art, have no market history for predictive analysis and thus valuation of such work is more difficult, and more speculative. Gallery, dealer, consultant, and agent promotion as well as collectors acting as alpha consumers (trend-setters) are the forces at work in valuing primary market works.\n\nAs with blue-chip stocks, works by \"blue-chip\" or well-known artists are generally valued more highly than works by unknown artists since it is hard to predict how an unknown artist's work will sell, or whether it will sell at all. High barriers to market entry for artists create scarcity in the supply and demand portion of the market, in turn driving up prices and raising questions of efficiency. While a high market entry barrier may result in having a smaller pool of artwork producers in the auction-level portion of the market, and in greater market predictability by virtue of that smaller pool and thus more reliable valuation measures, its axiomatic effect is of lesser artistic diversity negatively impacting the size of the buyer pool. For this reason, gallerists and art dealers consider what types of works are currently in vogue before deciding to represent a new artist and are highly selective in those choices in order to maintain a level of quality that is saleable. All these concerns are in play when gallerists set prices for emerging artists at a much lower level than for established artists.\n\nWith the 2007–2012 global financial crisis, the art market faced criticism for its lack of transparency, its Byzantine valuation methods, and a perceived lack of ethical behavior enabled by structural inadequacies in the market itself. In response, a 2009 debate occurred between valuation-setting members of the art market on the proposition that \"the art market is less ethical than the stock market\". At the end of the debate the audience determined that those debating in agreement with the proposition won the debate. Of particular note in the debate was the identification of \"chandelier bidding\" as a practice perceived as ethically questionable. The debaters described \"chandelier bidding\" as bids from the chandelier, or bids from an unknown source, meaning both the bidding by the auction houses on behalf of the sellers whose items the houses are auctioning (a conflict of interest), and bidding by unidentified bidders having no intention of buying but bidding in order to drive prices up, all practiced because the auction houses keep secret from bidders a seller's reserve price.\n\nIn 2011, also in response to criticism on the lack of market transparency and counterarguments that more transparency would ruin the market, \"The Art Newspaper\" in association with the Art Dealers Association of America convened an Art Industry Summit panel discussion between major art market decision makers, where panelists discussed whether there was a need for more transparency. The panelists argued over whether auction houses have built-in conflicts of interest by representing sellers with secret reserves, while at the same time representing to buyers initial valuations on those works at auction time. The debate also included the issue of first and third-party guaranteed bids, and whether sellers' reserve prices should be disclosed so that participants no longer bid on an object they have no chance of buying. In response to criticisms regarding chandelier bidding and unidentified third-party guaranteed bids, Christie's International chairman Edward Dolman countered that, without a secret reserve, illegal cartels of bidders would know in advance information that could facilitate their manipulation of the market and corruption of final valuation by selling price at auction.\n\nWith the art market's weaknesses (especially lack of transparency and conflicts of interests) becoming better known, serious external conversations about market regulation have begun among major market players; for example, the \"Financial Times\" noted that in early 2015, participants at the January World Economic Forum meeting attended a lunch seminar where the speaker warned that the global art market needs to be regulated because of systemic weaknesses which enable inside information trading, tax evasion, and money laundering.\n\nIn terms of academic research, there is work on the opacity of price formation in finance and economics.\n\nThe late 1980s were a boom period for art auction houses. However, in early 1990, the market collapsed. The US overtook the EU as the world's largest art market with a global share of 47 per cent by 2001. Ranking second, the UK's world market share hovers around 25 per cent. In continental Europe, France was the market leader while in Asia, Hong Kong continues its dominance. France’s share of the art market has been progressively eroded since the 1950s, when it was the dominant location and sales at Drouot surpassed those of Sotheby’s and Christie’s combined. In 2004, the global fine art market turnover was estimated at almost billion. Art auction sales reached a record billion in 2007, fueled by speculative bidding for artists such as Damien Hirst, Jeff Koons, and Richard Prince. The recent rise of the Chinese art market, both in terms of the size of its domestic sales and the international significance of its buyers, has, combined with a rich cultural heritage of art and antiques, produced a huge domestic market and ended the duopoly held by London and New York for over 50 years.\n\nChristie's and Sotheby's are the leading auction venues. In 2002, LVMH acquired Swiss art advisory firm de Pury & Luxembourg and merged it with Phillips to form Phillips de Pury & Company, with the aim of breaking the duopoly at the top of the market.\n\nFine art auctions are generally held separately for Impressionist and Modern art as well as for Post-war and Contemporary Art. Pablo Picasso's works remain the most coveted lot as of 2004. In 2008 just over million of art by Damien Hirst was sold at auction, a world record for a living artist; however in 2009, Hirst’s annual auction sales had shrunk by 93%.\n\n\"Estimates\" often reflect the consignor's ambitions as much as the auction specialist's considered opinion. They do not reflect commissions. To secure consignments, auction houses concede high estimates to suit the requirements of art owners. Before an auction, interested buyers typically turn for advice to the auction house specialist who quotes the estimate and often recommends going beyond in order to secure the item.\n\nAuction houses operate contractually on behalf of sellers of goods, charging sellers a fixed commission (fee) amounting to a percentage of the “hammer price” for which a lot is sold. Christie's published its commissions in September 1995, with its fees ranging from 20% on the least expensive lots to 2% on lots sold for over m; Sotheby's followed suit. For Phillips de Pury & Company, final prices include commission of 25% of the first 20% of the next to million, and 12% of the rest, with estimates not reflecting commissions.\nObjects sold are also subject to a further fee called the \"buyer's premium\", 15% being typical, with the term implying that by virtue of selling an object, the auction house performs a service for the buyer subject to remuneration. Thus, both the seller and the buyer of an object or lot sold by the major auction houses pay a fee. First implemented in 1975 by Christie's, the assessment of a buyer's premium is one of several auction-house practices to which art dealers object.\n\nBeginning in 2014, Christie's charged 2 percent of the hammer price of a work that meets or exceeds its high estimate. The fee does not apply to online only sales.\n\nAn auction house may offer a guaranteed selling price, or \"guaranteed minimum\", a practice designed to give sellers confidence to consign works and to give potential bidders reassurance that there are others willing to buy an item. Auction houses have offered guarantees since the early 1970s to encourage collectors to sell their artworks: \"The Art Newspaper\" reported that guarantees were first introduced in 1971 at Sotheby’s, when 47 Kandinskys and other works from the Guggenheim Museum were offered with a guaranteed minimum; similar arrangements followed in 1972 and 1973 for the Ritter and Scull collections. A guaranteed amount is generally close to the lower estimate, with the seller and the auction house sharing any amount exceeding the guaranteed minimum. In autumn 2008 when the market turned sour, Christie's and Sotheby's had to pay out at least million on works for which they guaranteed a minimum price but which failed to sell. In order to reduce their exposure to such losses, boost the market, and reduce volatility, the main auction houses now prefer that third parties take on this financial risk via \"third-party guarantees\" or \"irrevocable bids\": using this practice the auction houses sell a work to a third party for a minimum price prior to the auction and this selling price then becomes the “reserve” below which the artwork will not be sold. If bidding for specified works stops at the minimum price, which remains undisclosed, the \"third party\" acquires the lot; if bidding exceeds the reserve, the third party splits any profit from its sale with the consignor and with the auction house, the percentage going to each party varying with the deal. These proportions, never disclosed to the public, are negotiated before an auction and specified in the contract signed by the auction house and the third party.\n\nIn May 1999, Teo Spiller sold a web art project Megatronix to Ljubljana Municipal Museum, which was by the New York Times announced as the first sell of an Internet art net.art.\n\nIn 2003, Sotheby's abandoned its partnership with eBay after it lost millions through its various attempts to sell fine art over the internet.\nThe art market can also be used to understand what “counts” as part of art history. Art dealers and auctioneers organize material for distribution to collectors. Two of the largest, and oldest, art auction houses are Sotheby's and Christie's, and each hold frequent sales of great antiquities and art objects.\n\nIn addition to upstanding practices, a black market exists for great art, which is closely tied to art theft and art forgery. No auction houses or dealers admit openly to participating in the black market because of its illegality, but exposés suggest widespread problems in the field. Because demand for art objects is high, and security in many parts of the world is low, a thriving trade in illicit antiquities acquired through looting also exists. Although the art community nearly universally condemns looting because it results in destruction of archeological sites, looted art paradoxically remains omnipresent. Warfare is correlated with such looting, as is demonstrated by the recent archaeological looting in Iraq.\n\n\n"}
{"id": "39195435", "url": "https://en.wikipedia.org/wiki?curid=39195435", "title": "Association of Personal Historians", "text": "Association of Personal Historians\n\nThe Association of Personal Historians (APH) was an international non-profit trade association dedicated to developing, supporting and marketing the work of self-employed writers and small businesses who are engaged in preparing print, video, and audio memoirs recording the lives of individuals, families, and communities. Formed in the United States in 1995, it had a global membership of over 650 at its peak, before dissolving in May 2017, reportedly due to \"financial constraints and membership trends\".\n\nThe APH's mission statement was to \"support... its members in recording, preserving and sharing life stories of people, families, communities and organizations around the world.\" According to the organization, its members \"help other people create personal histories, including memoirs, video tributes, autobiographies, biographies, family histories, heritage cookbooks, community histories, corporate and organizational histories, legacy letters, and ethical wills.\"\n\nKitty Axelson-Berry founded the organization in 1995. According to her, \"personal historians will not only write, edit, and design your book to your specifications, they'll make it clear from the get-go that the books they produce are meant to be heirlooms rather than potential bestsellers.\" Increasingly, many personal historians now make use of video and digital formats. Journalist Chris Wright stated: \"The majority of... clients are unabashedly ordinary, and they tell unabashedly mundane tales.\"\n\nPersonal historians record and present clients' memories and biographies as books, in audio or video formats, and/or as personal websites. Prices are reported to vary widely, depending on the services offered in each case. The services of personal historians are also used in preparing histories of businesses and other organizations, and by wealth management companies to help improve bonds with their potential clients. Personal historians also provide input to publicly funded oral history projects.\n\nPersonal historians have been described as comprising \"journalists, psychotherapists, social workers, nurses, videographers, gerontologists, and people from other helping or writing professions\", as \"retired teachers, journalists, genealogists, and therapists...\" and as \"social workers, journalists and others involved in communications... retirees who want to embark on a second career.\" In each case they form \" [g]enerally a one-person conglomerate of ghostwriter, editor, and publishing house...\".\n\nPersonal history work has been reported to be booming in the US, as \"a growing cottage industry of amateurs and professionals eager to preserve the experiences of older generations.\" Paula Stahel, APH President at the time, said in 2008: \"We're seeing an increase both in the number of people who want to do personal historian work and an increase in the number of elders who want to be sure their stories are handed down.\"\n\nAll APH members are expected to abide by the organization's code of ethics. Practitioners often have training in skills such as interviewing techniques, desktop publishing, video and/or audio production, as well as some knowledge of geriatrics or other disciplines.\n\nThe APH was governed by an elected, all-volunteer board of directors with overlapping two-year terms. The organization held an annual conference for its members: the 2016 conference was held in Fort Worth, Texas. The 2017 Board of Directors cited decreasing membership and a growing trend towards online networking and collaboration as reasons for dissolution. In a letter to members, the 2017 Board wrote, \"...APH has achieved its purpose many times over, which, as stated in our Bylaws, was to 'advance the profession of helping individuals, organizations, and communities preserve their histories, memories, and life stories.' APH has helped launch more than a thousand personal history businesses, and its members have produced many thousands of personal history works that will be part of our world’s historical record. APH leaves the field at a time when a broader recognition of the importance of saving life stories has emerged and is flourishing—and is widely known and communicated through the work of many other organizations and media outlets. APH has had a significant role in advancing that conversation. And it was our members, as individual practitioners of personal history, who achieved this in countless ways in countless communities, and we know you will continue to do so.\"\n\nFormer members of APH and current personal historians are encouraged to use the phrase \"personal history\" and \"personal historian\" in search engines in order to find relevant social media groups. Trade associations exist for genealogists, photo archivists, ghostwriters, editors, and biographers, among others.\n\n\n\n"}
{"id": "55692108", "url": "https://en.wikipedia.org/wiki?curid=55692108", "title": "Bibliography of Tenrikyo", "text": "Bibliography of Tenrikyo\n\nThis article presents a selected bibliography of Tenrikyo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTenrikyo has been the subject of several articles in the following academic journals:\n\n\n"}
{"id": "19386262", "url": "https://en.wikipedia.org/wiki?curid=19386262", "title": "Bibliography of the 1837–38 insurrections in Lower Canada", "text": "Bibliography of the 1837–38 insurrections in Lower Canada\n\nThe following is an incomplete bibliography of the 1837-1838 insurrections in Lower Canada in the English and French languages, by publication date and document type.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3452701", "url": "https://en.wikipedia.org/wiki?curid=3452701", "title": "Big Nose Kate", "text": "Big Nose Kate\n\nMary Katherine Horony-Cummings (born as Mária Izabella Magdolna Horony, November 9, 1849 – November 2, 1940), also known as Big Nose Kate, was a Hungarian-born prostitute and longtime companion and common-law wife of Old West gunfighter Doc Holliday.\n\nMary Katherine Horony (also spelled Harony, Haroney, and Horoney) was born on November 9, 1849 in Érsekújvár, in what was then the Kingdom of Hungary, as the second oldest daughter of Hungarian physician and teacher Mihály Horony (1817-1865).\n\nIn 1860, Dr. Horony, his second wife Katharina, and his children left Hungary for the United States, arriving in New York City on the German ship \"Bremen\" in September 1860. Writer Glenn Boyer was the first to state that Kate was descended from nobility and that after her father was appointed personal physician to Emperor Maximilian I of Mexico the family accompanied the monarch's retinue to Mexico. However, in none of his published works did Boyer ever cite a source for these assertions. Patrick A. Bowmaster exposed the fallacy of Boyer's story.\"\n\nThe Horony family settled in a predominantly German area of Davenport, Iowa in 1862. Horony and his wife died only three years later, in 1865, within a month of one another. Mary Katherine and her younger siblings were placed in the home of her brother-in-law, Gustav Susemihl, and in 1870 they were left in the care of attorney Otto Smith. The 1870 United States Census records for Davenport, Iowa show Kate's younger sister, 15-year-old Wilhelmina (Wilma), living with and working as a domestic for Austrian-born David Palter and his Hungarian wife Bettina.\n\nAt age 16, Kate ran away from her foster home and stowed away on a riverboat bound for St. Louis, Missouri. Kate later claimed that while she lived in St. Louis she married a dentist named \"Silas Melvin\" with whom she had a son, and that both died of yellow fever. No record has been found to substantiate marriage, birth of a child, or the death of either Melvin or the child. United States Census records report that a Silas Melvin lived in St. Louis in the mid 1860s but that he was married to a steamship captain's daughter named Mary Bust. The census also shows that another Melvin was employed by a St. Louis asylum. Since Kate met Doc Holliday in the early 1870s, she may have confused the two and their occupations when recalling the facts later in her life.\n\nResearcher Jan Collins states that Kate entered the Ursuline Convent but did not remain long. In 1869, she is recorded as working as a prostitute for madam Blanch Tribole in St. Louis. In 1874, Kate was fined for working as a \"sporting woman\" (prostitute) in a \"sporting house\" (brothel) in Dodge City, Kansas, run by Nellie \"Bessie\" (Ketchum) Earp, James Earp's wife.\n\nIn 1876, Kate moved to Fort Griffin, Texas, where in 1877 she met Doc Holliday. Doc said at one point that he considered Kate his intellectual equal. Kate introduced Holliday to Wyatt Earp. The couple went with Earp to Dodge City and registered as Mr. and Mrs. J.H. Holliday at Deacon Cox's boarding house. Doc opened a dental practice by day but spent most of his time gambling and drinking. The two fought regularly and sometimes violently.\n\nAccording to Kate, the couple later married in Valdosta, Georgia. They traveled to Trinidad, Colorado, and then to Las Vegas, New Mexico, where they lived for about two years. Holliday worked as a dentist by day and ran a saloon on Center Street by night. Kate also occasionally worked at a dance hall in Santa Fe.\n\nBy her own account, Doc and Kate met up again with Wyatt Earp and his brothers on their way to the Arizona Territory. Virgil Earp had already been in Prescott before Wyatt persuaded his brothers to move to Tombstone. Holliday was making money at the gambling tables in Prescott, while Kate worked as a prostitute in the upstairs rooms at The Palace Saloon; he and Kate parted ways when Kate left for Globe, Arizona, but she rejoined Holliday soon after he arrived in Tombstone.\n\nHolliday, like his friend Wyatt Earp, was always looking for an opportunity to make money and joined the Earps in Tombstone during the fall of 1880. On March 15, 1881, at 10:00 pm, three cowboys attempted to rob a Kinnear & Company stagecoach carrying $26,000 in silver bullion (by the inflation adjustment algorithm: $ in today's dollars) near Benson, Arizona, during which the popular driver Eli \"Budd\" Philpot and passenger Peter Roerig were killed. Cochise County Cowboy Bill Leonard, a former watchmaker from New York City, was one of three men implicated in the robbery, and he and Holliday had become good friends. When Kate and Holliday had a fight, County Sheriff Johnny Behan and Milt Joyce, a county supervisor and owner of the Oriental Saloon, decided to exploit the situation.\n\nBehan and Joyce plied Kate with alcohol and suggested to her a way to get even with Holliday. She signed an affidavit implicating Holliday in the murders and attempted robbery. Judge Wells Spicer issued an arrest warrant for Holliday. The Earps found witnesses who could attest to Holliday's whereabouts elsewhere at the time of the murders. Kate said that Behan and Joyce had influenced her to sign a document she didn't understand. With the Cowboy plot revealed, Judge Spicer freed Holliday. The district attorney threw out the charges, labeling them \"ridiculous\". After Holliday was released, he gave Kate money and put her on the stage. Kate returned to Globe for a time, but she returned to Tombstone in October of that year.\n\nIn a 1939 letter to her niece Lillian Rafferty, Kate claimed that she was in the Tombstone area with Holliday during the days before the shootout. According to Kate, she was with Holliday in Tucson when they attended the San Augustin Feast and Fair in Levin Park during October 1881. On October 20, 1881, Morgan Earp rode to Tucson to request Holliday's assistance with dealing with Cochise County Cowboys who had threatened to kill the Earps. She wrote that Holliday asked her to remain in Tucson for her safety, but she refused, and traveled with Holliday and Earp. Kate reminisced in the letter about her stay with Holliday at C.S. Fly's Boarding House which bordered the alley where the Gunfight at the O.K. Corral took place. Kate accurately described minor details of the shootout.\n\nKate wrote that on the day of the gunfight, a man entered Fly's Boarding House with a \"bandaged head\" and a rifle. He was looking for Holliday, who was still in bed after a night of gambling. Kate recalled that the man who was turned away by Mrs. Fly was later identified as Ike Clanton, whom city marshal Virgil Earp had pistol-whipped earlier that day when he found Clanton carrying a rifle and pistol in violation of city ordinances. Clanton's head was bandaged afterward.\n\nVirgil Earp had disarmed him earlier that day and told Ike he would leave Ike's confiscated rifle and revolver at the Grand Hotel, which was favored by cowboys when they were in town. Ike testified afterward that he had tried to buy a new revolver at Spangenberger's gun and hardware store on 4th Street but the owner saw Ike's bandaged head and refused to sell him one. Clanton was unarmed at the time of the shootout later that afternoon. Ike testified that he picked up the weapons from William Soule, the jailer, a couple of days later.\n\nAuthor Glenn Boyer disputes that Kate saw the gunfight through the window of the boarding house. According to him also, Kate stated that after Doc Holliday returned to his room, he sat on the edge of his bed and wept from the shock of what had happened during the close-range gunfight. \"That was awful,\" Kate claims he said. \"Just awful.\" Boyer's work, however, has been rejected by serious scholars.\n\nKate is reported to have made trips to Tombstone to see Holliday until he left for Colorado in April 1882. In 1887, Kate traveled to Redstone, Colorado, close to Glenwood Springs, Colorado, to visit with her brother Alexander. Some historians have tried to connect Kate and Doc to possible reconciliation attempts between the two.\n\nAfter Doc Holliday died in 1887, Kate married Irish blacksmith George Cummings in Aspen, on March 2, 1890. After working several mining camps throughout Colorado, they moved to Bisbee, Arizona, where she briefly ran a bakery. After returning to Willcox, Arizona, in Cochise County, Cummings became an abusive alcoholic and they separated. In 1900, Kate moved to Dos Cabezas or Cochise and worked for John and Lulu Rath, owners of the Cochise Hotel. Cummings committed suicide in Courtland, Arizona, in 1915.\n\nKate is enumerated in the 1910 U.S. Census in Dos Cabezas, Arizona, as a member of the home of miner John J. Howard. When Howard died in 1930, Kate was the executrix of his estate. She contacted his only daughter, who lived in Tempe, Arizona, and settled the inheritance.\n\nIn 1931 the 80 year-old Kate contacted her longtime friend, Arizona Governor George Hunt, and applied for admittance to the Arizona Pioneers' Home in Prescott, Arizona. The home had been established in 1910 by the State of Arizona for destitute and ailing miners and male pioneers of the Arizona Territory. It took Kate six months to be admitted, since the home had a requirement that residents must be American citizens. According to the 1935 Bork interview, Kate was owed money by the Howard estate, but the amount owed was not enough to buy firewood through the winter, as Kate had complained in her letters to the governor.\n\nShe was admitted as one of the first female residents of the home. She lived there and became an outspoken resident, assisting other residents with living comforts. Kate wrote many letters to the Arizona state legislature, often contacting the governor when she was not satisfied with their response. Near the end of her life, several reporters tried to record Kate's life story, her relationship with Doc Holliday and her time in Tombstone. She only talked to Anton Mazzonovich and Prescott historian A. W. Bork.\n\nKate died on November 2, 1940, just five days before her 90th birthday, of acute myocardial insufficiency, a condition she started showing symptoms of the day before her death. Her death certificate states that she also suffered from coronary artery disease and advanced arteriosclerosis. Kate's death certificate contained significant discrepancies regarding her parents' names and her birthplace. Although she was born in Hungary, her death certificate states she was born in Davenport, Iowa, to father Marchal H. Michael and mother Catherine Baldwin. The birthplace of both her parents is shown on the certificate as \"unknown\". The superintendent of the Pioneer Home is named as the informant on the death certificate.\n\nKate was buried on November 6, 1940, under the name \"Mary K. Cummings\" in the Arizona Pioneer Home Cemetery in Prescott, Arizona.\n\nBig Nose Kate was depicted by Jo Van Fleet in \"Gunfight at the O.K. Corral\" (1957 film), by Faye Dunaway in Frank Perry's film \"Doc\" (1971), by Joanna Pacula in \"Tombstone\" (1993 film) and by Isabella Rossellini in \"Wyatt Earp\" (1994 film).\n\nCarol Montgomery Stone played Big Nose Kate, usually referred to as \"Kate Holliday\", in ten episodes in the 1957-1958 season of the ABC/Desilu western television series, \"The Life and Legend of Wyatt Earp\", with Hugh O'Brian as Wyatt Earp and Douglas Fowley as Doc Holliday.\n\nSheena Marshe played Kate Fisher in the 1966 \"Doctor Who\" story \"The Gunfighters\".\n\nChristine Doidge played Kate in the 2017 independent film \"Tombstone Rashomon\".\n\nChantel Riley portrays Kate in the Syfy series \"Wynonna Earp\".\n\n\n"}
{"id": "2370625", "url": "https://en.wikipedia.org/wiki?curid=2370625", "title": "Bristol board", "text": "Bristol board\n\nBristol board (also referred to as Bristol paper or Super white paper) is an uncoated, machine-finished paperboard. It is named after the city of Bristol in the southwest of England as that is where it was first produced. Common sizes include and its bulk thickness is or higher and A4, A3, A2 and A1. Bristol board may be rated by the number of plies it contains or, in Europe, by its grammage of 220 to 250 g/m. It is normally white, but is also made in different colours.\n\nBristol paper is used for printing documents, brochures, promotional materials and envelopes. It is often used for water color painting. It is also used for paperback book or catalog covers, file folders, tags, and tickets. Another use is for scale models; some students use this kind of paper for the walls in their scale models. One-ply Bristol is thin enough to be translucent, and two and three ply bristol are the most popular thicknesses. \n\nBristol board is commonly used for technical drawing, illustration projects, comic book art, and other two-dimensional art forms. It provides two working surfaces, front and back. This quality separates it from illustration board, which has only a front working surface. \n\nThe surface texture is either plate or vellum. \"Plate\" finish is as smooth as glass, and is very good for pen and ink. \"Vellum\" (or \"kid\") finish is a medium texture more appropriate to friction-based media, such as crayon, chalks, or charcoal. A third finish, \"engravers\" or \"wedding\", may be used for formal engraved wedding invitations.\n"}
{"id": "6001461", "url": "https://en.wikipedia.org/wiki?curid=6001461", "title": "Causes of transsexuality", "text": "Causes of transsexuality\n\nThe study of the causes of transsexuality investigates gender identity formation of transgender people, especially those who are transsexual. Transsexual people have a gender identity that does not match their assigned sex, often resulting in gender dysphoria.<section begin=\"factors\" /> The causes of transsexuality have been studied for decades. The most studied factors are biological. Certain brain structures in trans women have been found to be similar to cisgender women's as opposed to cis men's, and trans men's have been found to be similar to cis men's, even controlling for hormone use, which can also cause trans people's brains to become closer to those of cis people of the same gender. However, these studies are limited as they include a small number of tested individuals. Brain structure differences have also been noted between gay and heterosexual men, as well as lesbian and heterosexual women as part of extensive research on biology and sexual orientation. Studies have also found that both androphilic and gynephilic trans women's brain function and responses are like cis women's and unlike cis men's, or are intermediate between the two. Likewise, studies such as Rametti's have found that trans men have male-like white matter patterns (even before using hormones), regardless of sexual orientation.\n\nWith regard to genetic factors, a study by Hare reported that trans women have a longer androgen receptor gene than cis men, which is less effective at binding testosterone, potentially preventing complete masculinization of the brain (prenatal androgen exposure or sensitivity, or lack thereof, is an often cited mechanism to explain observed brain-structure differences). A study by Bentz found that trans men have a CYP17 allele distribution like cis men and unlike cis women. A twin study published in the \"International Journal of Transgenderism\" found that 33% of identical twin pairs were both trans, compared to only 2.6% of non-identical twins who were raised in the same family at the same time, but were not genetically identical.\n\nEnvironmental factors have also been proposed. The failure of an attempt to raise David Reimer from infancy through adolescence as a girl after his genitals were accidentally mutilated is cited as disproving the theory that gender identity is determined by upbringing. Ray Blanchard developed a taxonomy of male-to-female transsexualism that proposes two distinct etiologies for androphilic and gynephilic individuals that has become highly controversial, supported by J. Michael Bailey, Anne Lawrence, James Cantor, Richard F. Docter and others, but opposed by Charles Allen Moser, Larry Nuttbrock, Julia Serano, and the World Professional Association for Transgender Health.<section end=\"factors\" />\n\nA 2008 study compared 112 male-to-female transsexuals (both androphilic and gynephilic), mostly already undergoing hormone treatment, with 258 cisgender male controls. Male-to-female transsexuals were more likely than cisgender males to have a longer version of a receptor gene (longer repetitions of the gene) for the sex hormone androgen or testosterone, which reduced its effectiveness at binding testosterone. The androgen receptor (NR3C4) is activated by the binding of testosterone or dihydrotestosterone, where it plays a critical role in the forming of primary and secondary male sex characteristics. The research suggests reduced androgen and androgen signaling contributes to the female gender identity of male-to-female transsexuals. The authors say that a decrease in testosterone levels in the brain during development might prevent complete masculinization of the brain in male-to-female transsexuals and thereby cause a more feminized brain and a female gender identity.\n\nA variant genotype for a gene called CYP17, which acts on the sex hormones pregnenolone and progesterone, has been found to be linked to female-to-male transsexuality but not MtF transsexuality. Most notably, the FtM subjects not only had the variant genotype more frequently, but had an allele distribution equivalent to male controls, unlike the female controls. The paper concluded that the loss of a female-specific CYP17 T -34C allele distribution pattern is associated with FtM transsexuality.\n\nIn 2013, a twin study combined a survey of pairs of twins where one or both had undergone, or had plans and medical approval to undergo, gender transition, with a literature review of published reports of transgender twins. The study found that one third of identical twin pairs in the sample were both transgender: 13 of 39 (33%) monozygotic or identical pairs of assigned males and 8 of 35 (22.8%) pairs of assigned females. Among dizygotic or genetically non-identical twin pairs, there was only 1 of 38 (2.6%) pairs where both twins were trans. The significant percent of identical twin pairs in which both twins are trans and the virtual absence of dizygotic twins (raised in the same family at the same time) in which both were trans would provide evidence that transgender identity is significantly influenced by genetics if both sets were raised in different families.\n\nSeveral studies have found a correlation between gender identity and brain structure. A first-of-its-kind study by Zhou \"et al.\" (1995) found that in a region of the brain called the bed nucleus of the stria terminalis (BSTc), a region which is known for sex and anxiety responses (and which is affected by prenatal androgens), cadavers of six persons who were described as having been male-to-female transsexual or transgender persons in life had female-normal BSTc size, similar to the study's cadavers of cisgender women. While the transsexuals studied had taken hormones, this was accounted for by including cadavers of non-transsexual male and female controls who, for a variety of medical reasons, had experienced hormone reversal. The controls still had sizes typical for their gender. No relationship to sexual orientation was found.<ref name=\"Zhou/Gooren\"></ref>\n\nIn a follow-up study, Kruijver \"et al.\" (2000) looked at the number of neurons in BSTc instead of volumes. They found the same results as Zhou \"et al.\" (1995), but with even more dramatic differences. One MtF subject, who had never gone on hormones, was also included and matched up with the female neuron counts nonetheless.\n\nIn 2002, a follow-up study by Chung \"et al.\" found that significant sexual dimorphism (variation between sexes) in BSTc did not become established until adulthood. Chung \"et al.\" theorized that either changes in fetal hormone levels produce changes in BSTc synaptic density, neuronal activity, or neurochemical content which later lead to size and neuron count changes in BSTc, or that the size of BSTc is affected by the generation of a gender identity inconsistent with one's assigned sex.\n\nIn a review of the evidence in 2006, Gooren confirmed the earlier research as supporting the concept of transsexuality as a sexual differentiation disorder of the sex dimorphic brain. Dick Swaab (2004) concurs.\n\nIn 2008, a new region with properties similar to that of BSTc in regards to transsexuality was found by Garcia-Falgueras and Swaab: the interstitial nucleus of the anterior hypothalamus (INAH3), part of the hypothalamic uncinate nucleus. The same method of controlling for hormone usage was used as in Zhou \"et al.\" (1995) and Kruijver \"et al.\" (2000). The differences were even more pronounced than with BSTc; control males averaged 1.9 times the volume and 2.3 times the neurons as control females, yet once again, regardless of hormone exposure, MtF transsexuals lay within the female range and the FtM transsexual within the male range.\n\nA 2009 MRI study by Luders et al. of 24 MtF transsexuals not yet treated with cross-sex hormones found that regional gray matter concentrations were more similar to those of cisgender men than to those of cisgender women, but there was a significantly larger volume of gray matter in the right putamen compared to cisgender men. Like earlier studies, it concluded that transsexuality was associated with a distinct cerebral pattern. (MRI allows easier study of larger brain structures, but independent nuclei are not visible due to lack of contrast between different neurological tissue types, hence other studies on e.g. BSTc were done by dissecting brains post-mortem.)\n\nAn additional feature was studied in a group of FtM transsexuals who had not yet received cross-sex hormones: fractional anisotropy values for white matter in the medial and posterior parts of the right superior longitudinal fasciculus (SLF), the forceps minor, and the corticospinal tract. Rametti \"et al.\" (2010) discovered that, \"Compared to control females, FtM showed higher FA values in posterior part of the right SLF, the forceps minor and corticospinal tract. Compared to control males, FtM showed only lower FA values in the corticospinal tract.\"\n\nHulshoff Pol \"et al.\" (2006) studied the gross brain volume of 8 male-to-female transsexuals and in 6 female-to-male transsexuals undergoing hormone treatment. They found that hormones changed the sizes of the hypothalamus in a gender consistent manner: treatment with male hormones shifted the hypothalamus towards the male direction in the same way as in male controls, and treatment with female hormones shifted the hypothalamus towards the female direction in the same way as female controls. They concluded: \"The findings suggest that, throughout life, gonadal hormones remain essential for maintaining aspects of sex-specific differences in the human brain.\"\n\nBrain-based research has repeatedly shown that female-to-male transsexuals have several male-like characteristics in neuroanatomy. In 2010, a team of neuroscientists compared 18 female-to-male transsexuals with 24 male and 19 female gynephilic controls, using an MRI technique called diffusion tensor imaging or DTI. DTI is a specialized technique for visualizing white matter of the brain, and white matter structure is one of the differences in neuroanatomy between men and women. The study found that the white matter pattern in female-to-male transsexuals was shifted in the direction of biological males, even before the female-to-male transsexuals started taking male hormones (which can also modify brain structure).\n\nSimilar brain structure differences have been noted between gay and heterosexual men, and between lesbian and heterosexual women. Studies have also found that circumstance and repeated activities such as meditation modify brain structures in a process called brain plasticity or neuroplasticity. In May 2014, the Proceedings of the National Academy of Sciences reported that parenting \"rewires the male brain\" for fathers.\n\nStudies have shown that androphilic male-to-female transsexuals show a shift towards the female direction in brain anatomy. In 2009, a German team of radiologists led by Gizewski compared 12 androphilic transsexuals with 12 cisgender males and 12 cisgender females. Using functional magnetic resonance imaging (fMRI), they found that when shown erotica, the cisgender men responded in several brain regions that the cisgender women did not, and that the sample of androphilic transsexuals was shifted towards the female direction in brain responses.\n\nIn another study, Rametti and colleagues used diffusion tensor imaging (DTI) to compare 18 androphilic male-to-female transsexuals with 19 gynephilic males and 19 androphilic cisgender females. The androphilic transsexuals differed from both control groups in multiple brain areas, including the superior longitudinal fasciculus, the right anterior cingulum, the right forceps minor, and the right corticospinal tract. The study authors concluded that androphilic transsexuals were halfway between the patterns exhibited by male and female controls.\n\nWhile MRI taken on gynephilic male-to-female transsexuals have likewise shown differences in the brain from non-transsexuals, no feminization of the brain's structure have however been identified.\nResearchers of the Karolinska Institute of Stockholm used MRI to compare 24 gynephilic male-to-female transsexuals with 24 cisgender male and 24 cisgender female controls. None of the study participants were on hormone treatment. The researchers found sex-typical differentiation between the MtF transsexuals and cisgender males, and the cisgender females; but the gynephilic transsexuals \"displayed also singular features and differed from both control groups by having reduced thalamus and putamen volumes and elevated GM volumes in the right insular and inferior frontal cortex and an area covering the right angular gyrus\".\n\nThese researchers concluded that:\nContrary to the primary hypothesis, no sex-atypical features with signs of 'feminization' were detected in the transsexual group ... The present study does not support the dogma that [male-to-female transsexuals] have atypical sex dimorphism in the brain but confirms the previously reported sex differences. The observed differences between MtF-TR and controls raise the question as to whether gender dysphoria may be associated with changes in multiple structures and involve a network (rather than a single nodal area).\n\nBerglund \"et al.\" (2008) tested the response of gynephilic MtF transsexuals to two sex pheromones: the progestin-like 4,16-androstadien-3-one (AND) and the estrogen-like 1,3,5(10),16-tetraen-3-ol (EST). Despite the difference in sexual orientation, the MtFs' hypothalamic networks activated in response to the AND pheromone, like the androphilic female control groups. Both groups experienced amygdala activation in response to EST. Gynephilic male control groups experienced hypothalamic activation in response to EST. However, the MtF subjects also experienced limited hypothalamic activation to EST. The researchers concluded that in terms of pheromone activation, MtFs occupy an intermediate position with predominantly female features. The MtF transsexual subjects had not undergone any hormonal treatment at the time of the study, according to their own declaration beforehand, and confirmed by repeated tests of hormonal levels.\n\nAnother team of neuroscientists, led by Nawata in Japan, used a technique called single-photon emission computed tomography (SPECT) to compare the regional cerebral blood flow (rCBF) of 11 gynephilic FtM transsexuals with that of 9 androphilic cis females. Although the study did not include a sample of biological males so that a conclusion of \"male shift\" could be made, the study did reveal that the gynephilic FtM transsexuals showed significant decrease in blood flow in the left anterior cingulate cortex and a significant increase in the right insula, two brain regions known to respond during sexual arousal.\n\nPhantom limb syndrome is a common, often painful experience after the loss of an external organ. Ramachandran (2008) found that while nearly two thirds of non-transsexual males who have a penis surgically removed experience the sensation of a phantom penis, only one third of MtF transsexuals do so after sex reassignment surgery. However, this study overlooks differences between an amputation, where nerves connecting the penis and brain are severed, and reassignment surgery, where some of the penis and scrotum may be reused to create a vaginal canal, labia and a clitoris. In this case, some nerves connecting the genitalia to the brain remain intact. Two thirds of FtM transsexuals reported the sensation of a phantom penis from childhood onwards, complete with phantom erections and other phenomena.\n\nPrenatal androgen exposure, the lack thereof, or poor sensitivity to prenatal androgens are commonly cited mechanisms to explain the above discoveries. Schneider, Pickel, and Stalla (2006) found a correlation between digit ratio (a generally accepted marker for prenatal androgen exposure) and male-to-female transsexuality. MtF transsexuals were found to have a higher digit ratio than control males, but one that was comparable to control females.\n\nCongenital adrenal hyperplasia in persons with XX sex chromosomes results in what is considered to be excess exposure to prenatal androgens, resulting in masculinization of the genitalia and, typically, controversial prenatal hormone treatment and postnatal surgical interventions. Individuals with CAH are usually raised as girls and tend to have similar cognitive abilities to the typical female, including spatial ability, verbal ability, language lateralization, handedness and aggression. Research has shown that people with CAH and XX chromosomes will be more likely to be same sex attracted, and at least 5.2% of these individuals develop serious gender dysphoria.\n\nIn males with 5-alpha-reductase deficiency, conversion of testosterone to dihydrotestosterone is disrupted, decreasing the masculinization of genitalia. Individuals with this condition are typically raised as females due to their feminine appearance at a young age. However, more than half of males with this condition raised as females become males later in their life. Scientists speculate that the definition of masculine characteristics during puberty and the increased social status afforded to men are two possible motivations for a female-to-male transition.\n\nFor many years, people such as psychiatrist and sexologist David Oliver Cauldwell and Harry Benjamin argued that transsexuality was a psychological/emotional disorder caused by psychological and environmental factors and personality conflicts. The failure of an attempt to raise David Reimer from infancy through adolescence as a girl after his genitals were accidentally mutilated is cited as disproving this theory that gender identity is determined by parenting. However, no studies have been able to demonstrate this at a large scale, in part due to widespread agreement among scholars that the Reimer study's methodology was unethical. Reimer's case is used by organizations such as the Intersex Society of North America to caution against needlessly modifying the genitals of unconsenting minors.\n\nIn 2015, the American Academy of Pediatrics released a webinar series on gender, gender identity, gender expression, transgender, etc. In the first lecture Dr. Sherer explains that parents' influence (through punishment and reward of behavior) can influence gender \"expression\" but not gender \"identity\". She cites a Smithsonian article that shows a photo of a 3 year old President Franklin D. Roosevelt with long hair, wearing a dress. Children as old as 6 wore gender neutral clothing, consisting of white dresses, until the 1940s. In 1927, \"Time\" magazine printed a chart showing sex-appropriate colors, which consisted of pink for boys and blue for girls. Dr. Sherer argued that kids will modify their gender expression to seek reward from their parents and society but this will not affect their gender identity (their internal sense of self).\n\nRay Blanchard has developed a taxonomy of male-to-female transsexualism built upon the work of his colleague Kurt Freund, which assumes that trans women have one of two motivations for transition. Blanchard theorizes that \"homosexual transsexuals\" transition because they are attracted to men, and characterizes them as displaying overt and obvious femininity since childhood; he then characterizes \"non-homosexual transsexuals\" as transitioning because they are autogynephilic (sexually aroused by the thought or image of themselves as a woman), and as being either attracted to women, attracted to both women and men, or asexual. By contrast, a 2009 study found that over 90% of cis women are also attracted to the thought of themselves as women. \n\nThe theory has gained support from J. Michael Bailey, Anne Lawrence, James Cantor, and others who argue that there are significant differences between the two groups, including sexuality, age of transition, ethnicity, IQ, fetishism, and quality of adjustment. However, the theory has been criticized in papers from Veale, Nuttbrock, Moser, and others who argue that it is poorly representative of MtF transsexuals and non-instructive, and that the experiments behind it are poorly controlled and/or contradicted by other data. Many authorities, including some supporters of the theory, criticize Blanchard's choice of wording as confusing or degrading. Transsexuals themselves overwhelmingly reject the theory, with evolutionary biologist and trans woman Julia Serano writing that \"Blanchard's controversial theory is built upon a number of incorrect and unfounded assumptions, and there are many methodological flaws in the data he offers to support it.\" Blanchard's ideas about trans women have also been rejected by the World Professional Association for Transgender Health (WPATH), the largest association of medical professionals who provides care for transgender people, as lacking empirical evidence. \n\nThe DSM-5 \"Sexual and Gender Identity Disorders\" workgroup, of which Blanchard is a member, has said:\n\nIn contemporary clinical practice, sexual orientation per se plays only a minor role in treatment protocols or decisions. Also, changes as to the preferred gender of sex partner occur during or after treatment (DeCuypere, Janes, & Rubens, 2005; Lawrence, 2005; Schroder & Carroll, 1999). It can be difficult to assess sexual orientation in individuals with a GI diagnosis, as they preoperatively might give incorrect information in order to be approved for hormonal and surgical treatment (Lawrence, 1999). Because sexual orientation subtyping is of interest to researchers in the field, it is recommended that reference to it be addressed in the text, but not as a specifier. It should also be assessed as a dimensional construct. \n\nAutogynephilia, a propensity to be aroused by the thought of being a woman, has been proposed as an etiology of male-to-female transsexuality. Autogynephilia is common among late-onset transsexuals. A study on autogynephilic men found that they were more gender dysphoric than non-autogynephilic men. Another study using phallometry found that gynephilic male-to-female gender identity patients were autogynephilic even if they claimed to have never been aroused by crossdressing. Charles Moser, a physician, has expressed skepticism about the validity of phallometry, however.\n\n"}
{"id": "847462", "url": "https://en.wikipedia.org/wiki?curid=847462", "title": "Critical applied linguistics", "text": "Critical applied linguistics\n\nCritical applied linguistics (CALx) is an interdisciplinary critical approach to English applied linguistics. One of the central concerns in this approach is exposing the political dimensions and power relations involved in mainstream applied linguistics, in areas like language teaching, language policy and planning, language testing, language rights, and so on. \n"}
{"id": "5443055", "url": "https://en.wikipedia.org/wiki?curid=5443055", "title": "Culture of Barbados", "text": "Culture of Barbados\n\nThe culture of Barbados is a blend of West African and British cultures present in Barbados. English is the official language of the nation, reflecting centuries of British influence, but the Bajan dialect in which it is spoken is an iconic part of the Barbadian culture. This dialect is a combination of the languages from the different inhabitants in its history.\n\nThe island's British influence stretches back almost 400 years to 1625, when Captain John Powell claimed it in the name of King James I. The first British colonists arrived two years later, founding a settlement of 80 civilians and 10 African slaves. From the start, Barbados adopted the British style of government, creating a Parliamentary democracy in 1639. During the colonial period, all members of the Legislative Assembly were members of the elite-plantocracy. \n\nAfter Britain abolished slavery in 1838, non-whites quickly began to play a role in the island's government, with the first non-white member elected in 1843. \n\nBarbados gained full political independence from Britain in 1966, but chose to retain its traditional parliamentary democracy governmental style and remains a member of the Commonwealth of Nations. \n\nThe love of the sport of cricket continues to be reflected as an essential part of Barbados' culture. The most popular sport in Barbados, its cricket team has won numerous regional titles. Many players on the team go on to greater success on the West Indies team to compete in international games. One of the most highly regarded cricket players of all time, Sir Garfield Sobers, is a Barbados native. \n\nThe country's architecture pays further establishment testament to Britain, with many historic buildings still standing. In addition to traditional wood and stone, coral was also used in construction, lending a unique Barbadian flair. Jacobean, Georgian, and Victorian styles dominate. But slaves constructed many of these buildings, as well as their own chattel houses, so they were an integral part of the island's architectural legacy. Built of wood, chattel houses were set atop blocks instead of permanent foundations so they could be easily moved from place to place. The vivid colours of these chattel houses show the West African influence.\n\nReligion plays a significant role in life on the island. Up to 95% of the populace identifies itself as \"Christian\" (whether practicing or otherwise), and with its long British ties, the Anglican church comprises the largest segment of the population. However, Roman Catholic, Baptist, Methodist, and other Christian denominations also support congregations. The Christian population celebrates its deeply rooted faith in an annual festival, Gospelfest. \nSmaller Jewish, Hindu, and Muslim communities add some religious diversity. The Rastafarian faith also has its community of adherents, sometimes complaining of discrimination in schooling and employment.\n\nIn addition to Gospelfest, Barbados holds many other carnivals and festivals. The Landship is a Barbadian tradition. It mimics and parodies the Royal Navy, and incorporates music, dance and games. The largest and most important festival in Barbados is Crop Over, which celebrates the end of the sugarcane harvest. Lasting three weeks, it includes fairs, parades, and contests.\n\nMusic is an important part of the country's culture. Modern Barbados has produced popular stars of calypso and the indigenous spouge style, and also has a large jazz scene. Reggae, soca, and tuk are popular as well. \n\nThe vast majority of contemporary Bajan calypso and soca music centers around the five-week Crop Over festival, whose events begin in late May and run throughout the summer, climaxing in the first week of August with the Grand Kadooment (also known as Kadooment Day), a national holiday in Barbados.\n\nEvery January, Barbados hosts the Barbados Jazz Festival. In mid-February, Barbados hosts the Barbados Holetown Festival which celebrates the arrival of the first English settlers.\n\nSinger Rihanna was born and raised in Barbados. Although the better portion of her work mainly appeals to R&B audiences, her first album Music of the Sun contains a mixture of Barbadian rhythms and American urban-pop songwriting, just as her Loud album has a mixture of Ragga / Ska rhythms, along with Pop music and R&B / Hip Hop. Robyn \"Rihanna\" Fenty was also declared Barbados' ambassador of Tourism, which secured her a seat in the island's political arena from 2011 - 2014.\n\nThere are music, and sports festivals. At some of the festivals people wear costumes.\n\nBajan cuisine includes a unique blend of foods with African, Indian and British influences.\n\nThe national dish of Barbados is Cou-Cou & Flying Fish.\n\nIn addition to flying fish, many other varieties of fish are found in the waters surrounding Barbados, including kingfish, swordfish, red snapper, yellow-fin tuna, albacore tuna, marlin, shark and mahi-mahi commonly called dolphin. Staples include sweet potato, yam, breadfruit, cassava, rice, English potato, pasta and cou-cou.\n\nOther very popular dishes include fried fish cakes, fish & chips, souse (a pickled pork dish), black pudding, macaroni pie, and sweet desserts such as tamarind balls and baked custard.\n\nFood sold by street vendors is popular on the island, and key locations include Baxter's Road near Bridgetown, and Oistins, with its Friday Night Fish Fry.\n\n"}
{"id": "41818196", "url": "https://en.wikipedia.org/wiki?curid=41818196", "title": "Devotional articles", "text": "Devotional articles\n\nDevotional objects (also, devotional articles, devotional souvenirs, devotional artifacts) are religious souvenirs (figurines, pictures, votive candles, books, amulets, and others), owned and carried by the faithful, who see them as imbued with spiritual values, and use them for votive offering. Production and sales of devotional articles have become a widespread industry in the vicinity of various religious sites all over the world.\n\nDevotional articles have a long history; in Christianity they have been mentioned in historical works such as those related to Paul the Apostle and in older religions they have been traced as far back as the times of ancient Egypt and ancient Mesopotamia. International law defines \"devotional articles\" as including \"the Bible, the Koran, prayer and service books, hymnals, ritual articles, sacramental wine, crucifixes and rosaries\". Such items may be natural and hardly processed (such as earth from the Holy Land), but majority of modern devotional articles are mass-produced (strips of paper with prayers, pictures of holy figures, prayer books, etc.) Such items are usually seen as having little artistic value, as their primary function is not decorative but spiritual.\n\nAmerican sociologist Charles H. Lippy observed that such articles are \"means of access to the supernatural\", and are criticized by some as superstition. Devotional articles owned by famous religious figures, such as Catholic Saints, commonly become religious relics. Widespread popularity of certain devotional articles has, throughout centuries, influenced the public popular image of certain religious symbols, such as angels. \n"}
{"id": "36165680", "url": "https://en.wikipedia.org/wiki?curid=36165680", "title": "Discursive dominance", "text": "Discursive dominance\n\nThe word \"\" is closely related to the word discourse, which refers to \"communication of ideas\". In a society there are competing discourses (or narratives) regarding anything and everything such as feminism, racism, casteism, communalism, regionalism, economic development, democracy, governance, etc. These competing discourses struggle for dominance. Ultimately, one of the discourse emerges as dominant. This is known as discursive dominance.\n\nA dominant discourse is a winning discursive formation. It is the one that survives the widest range of criticisms in various forums and media.\n\n"}
{"id": "51325570", "url": "https://en.wikipedia.org/wiki?curid=51325570", "title": "Eastern Wall", "text": "Eastern Wall\n\nThe Eastern Wall is an ancient structure in Jerusalem that is both part of the eastern side of the city wall of Jerusalem and the eastern wall of the ancient Temple Mount.\n\nThe Eastern Wall is the oldest of the four visible walls of the Temple Mount; the Northern, Western and Southern Walls date from the period of Herod the Great, who expanded the area of the Temple Mount to the north, west and south. Older walls on these sides are presumed to survive underground. The Eastern Wall now visible was built in at least four stages, during the reign of Hezekiah, during the time of Zerubbabel, in the Hasmonean period and in the Herodian period. Repairs and major renovations were made in later periods. Major renovations to the Golden Gate were made in the Umayyad period.\n\nArchitectural archaeologist Leen Ritmeyer identifies specific courses of visible ashlars located on to the northern and south of the Golden Gate as Judean Iron Age in style, dating them to the construction of this wall by King Hezekiah. More such stones are supposed to survive underground. According to Hershel Shanks, \"most scholars,\" think that Ritmeyer is \"correct.\"\n\nRitmeyer has pointed out that the Dome of the Rock is seated on a square platform atop the Temple Mount, the sides of which, defined by short flights of steps, are square and parallel to the modern walls of the Mount with one exception: the western steps deviate from parallel. Moreover, the bottom step on the western side of the Dome of the Rock platform is composed of a single line of distinctively large and \"beautifully polished\" ashlars. According to Ritmeyer, the measurements given in the Mishna, tractate Middot, \"The Temple Mount measured 500 cubits by 500 cubits,\" can be traced on the modern Temple Mount, with this step the outline of the western side of the square and the Eastern Wall the eastern side. The \"precise\" measurement of an ancient Judean royal cubit, 20.67 inches, outlines these landmarks area exactly. The northern edge of the ancient square was demarcated by Charles Warren, the last archaeologist permitted by the local waqf to explore the underground areas of the Mount, in his the underground structure he labeled as No. 29 in surveys he carried out in the 1860s. The southern side of the 500 cubit ancient platform square is marked by he the so-called \"Straight Joint,\" a visible bend in the eastern wall. Ritmeyer proposes that this 500 cubit walled square was constructed by King Hezekiah c. 700 BCE to expand the flat area in which the faithful could gather at the Solomonic-era Temple. The Foundation Stone around which is the ancient Jewish Temple was built and which is now sheltered under the Dome of the Rock, is a natural rock outcrop at the highest point of a Mount Moriah; the natural contour of the land fell away steeply on all sides, although on the eastern side the natural contour formed a flat plateau before falling sharply to the Kidron Valley along the line where the Eastern Wall stands.\n\nThe \"Straight Joint\" where the wall bends very slightly, demarcating the line between the Hezekiahan wall and the Hasmonean extension, is marked by a round column protruding from the wall near the top.\n\nThe Hasmonean dynasty expanded the 500 cubit Temple platform toward the south; distinctively Hasmonean ashlars are visible in the Eastern Wall. The seam between the Hasmonean and Herodian extensions of the wall is visible as a vertical row of ashlars 32 meters north of the southeast corner.\n\nKing Herod expanded the Temple Mount still further toward the south; distinctively Herodian ashlars are visible in the Eastern Wall, in the last stretch before the southeastern corner.\n\nThe magnificent Muslim period Golden Gate (sealed) replaced the ancient Golden Gate. The present gate is understood to have been constructed during the Umayyad period atop the ancient footings.\n\nThere is a Muslim cemetery along the southern stretch of the Eastern Wall. A path through the cemetery and parallel to the wall lies atop the ancient city wall, explored by Charles Warren in excavations since covered over, which once lay just outside the Eastern Wall of the Temple Mount.\n"}
{"id": "29560533", "url": "https://en.wikipedia.org/wiki?curid=29560533", "title": "Eifeler Regel", "text": "Eifeler Regel\n\nThe Eifeler Regel (, ; meaning \"Eifel Rule\"; in Luxembourgish also spelled Äifler Regel ) is a linguistic phenomenon originally documented in the dialects of the Eifel region in the far west of Germany during the late 19th century. The rule describes a phonological process in the languages which causes the deletion of final in certain contexts, and may be reflected in spelling.\n\nMore generally called n-apocope, it appears to varying extents in all dialects of the Western group of High German, including West Central German (notably Luxembourgish, Colognian and Hessian), High Franconian and Alemannic; and excludes all dialects of the Eastern group, such as Austro-Bavarian and the colonial dialects east of the Elbe-Saale line (including Standard German and Yiddish). N-apocope is a linguistic change originating in speech during the Middle High German period.\n\nThe Eifel Rule is pervasive in Luxembourgish and its effects are indicated in the standard orthography. Final ⟨n⟩ or ⟨nn⟩ are often lost when followed by another consonant other than ⟨n⟩, ⟨d⟩, ⟨t⟩, ⟨z⟩ or ⟨h⟩. Compare the following examples involving the definite article \"den\" (\"the\"):\n\nSince Luxembourgish orthography strives for phonetic accuracy, the deletion of \"n\" is also reflected in writing. Now, the \"Eifeler Regel\" is presented as a spelling rule, but its correct application still depends on a knowledge of spoken Luxembourgish. The rule targets words ending in \"-n\" or \"-nn\", and since that is an extremely common ending for verbs, plural nouns, and function words (e.g. articles, pronouns, prepositions) in Luxembourgish, its effects are widespread. The basic rule can be described as follows:\n\n\nIt is important to know that many words ending in \"-n\" or \"-nn\" are not affected by the \"Eifeler Regel\":\nIn fact, \"n\" as a stem consonant (as opposed to part of a grammatical ending) is generally stable in content words, with notable exceptions such as \"Wäi(n)\" (wine), \"Stee(n)\" (stone), \"geschwë(nn)\" (soon).\n\nWhen final \"-n\" is dropped from a plural noun whose singular form also ends in \"-e\" (which occurs mostly in loanwords), a diaeresis must be used to distinguish the plural:\n\nIn Colognian, the Eifeler Regel is of lesser impact than further south. This is due in part to slight morphological differences between the Moselle Franconian languages of the upper Eifel regions (High Eifel and Schneifel), and the Ripuarian languages of the North- and Vordereifel region and the Cologne Lowland, to which Colognian belongs.\n\nThere are several ways to write Colognian, and the Eifeler Regel may be reflected in writing when it follows phonetic reality, but more often is not, since the majority of people do not write very phonetically.\n\nIn comparison to standard German, Colognian is often described as having historically omitted the trailing \"n\". This is oversimplified, and not always true, but makes it necessary to note that the Colognian version of liaison sometimes inserts an \"n\". In fact, Colognian multisyllabic base words or lexemes regularly drop \"-n\" when related languages, such as Standard German and neighboring dialects to the North such as Low German, Dutch and Limburgish do not. Liaison is often optional, and there is hardly any liaison on stressed words within a sentence. For example, with the words ' (up, up there) and ' (in, into), one may build the phrase: \"\" (up there into the cupboard) which depending on stress and voice flow inside a complete sentence is spoken as either or .\n\nThe general rule is that monosyllabic words most often keep their trailing \"n\", while otherwise \"-en\" endings are transformed to \"-e\" in Colognian unless the following word starts with a glottal stop, a dental consonant, a vocal, or an \"h\", and neither of the two words is being stressed inside the sentence. There are exceptions, the most notable being that speakers do not use \"liaison\" even if they could when speaking very slowly or solemnly, e.g. preaching or praying.\n\nHigh Franconian is a transitional dialect group between the Rhine Franconian dialects of West Central German to the North and the Swabian dialects of Alemannic to the South. The High Franconian group divides into South Franconian and East Franconian. N-apocope can be documented in the following sentence from Standard German:\nThe comparison with the above mentioned dialects demonstrates:\n\nThe Eifeler Regel (Alemannic n-apocope) applies in all variants of Alemannic in the same fashion as described for Luxembourgish and is subject to the same exceptions. The earliest report on the phenomenon in Alemannic goes back to 1881.\n\n\nCertain southern and southeastern dialects of Low Franconian (that is, Dutch) have a similar phenomenon. It is notable in Limburgish and some areas of Brabantian, and is called the \"bdht-vowel-rule\". Final -n is also deleted in these dialects, except when followed by b, d, h, t or a vowel. This is similar to the Eifeler regel.\n\n"}
{"id": "238777", "url": "https://en.wikipedia.org/wiki?curid=238777", "title": "Ghostwriter", "text": "Ghostwriter\n\nA ghostwriter is hired to write literary or journalistic works, speeches, or other texts that are officially credited to another person as the author. Celebrities, executives, participants in timely news stories, and political leaders often hire ghostwriters to draft or edit autobiographies, memoirs, magazine articles, or other written material. In music, ghostwriters are often used to write songs, lyrics, and instrumental pieces. Screenplay authors can also use ghostwriters to either edit or rewrite their scripts to improve them. \n\nUsually, there is a confidentiality clause in the contract between the ghostwriter and the credited author that obligates the former to remain anonymous. Sometimes the ghostwriter is acknowledged by the author or publisher for his or her writing services, euphemistically called a \"researcher\" or \"research assistant\", but often the ghostwriter is not credited.\n\nGhostwriting (or simply \"ghosting\") also occurs in other creative fields. Composers have long hired ghostwriters to help them to write musical pieces and songs; Wolfgang Amadeus Mozart is an example of a well-known composer who was paid to ghostwrite music for wealthy patrons. Ghosting also occurs in popular music. A pop music ghostwriter writes lyrics and a melody in the style of the credited musician. In hip hop music, the increasing use of ghostwriters by high-profile hip-hop stars has led to controversy. In the visual arts, it is not uncommon in either fine art or commercial art such as comics for a number of assistants to do work on a piece that is credited to a single artist. However, when credit is established for the writer, the acknowledgement of their contribution is public domain and the writer in question would not be considered a ghostwriter.\n\nA consultant or career-switcher may pay a ghostwriter to write a book on a topic in their professional area, to establish or enhance credibility as an 'expert' in their field. Public officials and politicians employ \"correspondence officers\" to respond to the large volume of official correspondence. A number of papal encyclicals have been written by ghostwriters. A controversial and scientifically unethical practice is medical ghostwriting, where biotech or pharmaceutical companies pay professional writers to produce papers and then recruit (via a payment or as a perk) other scientists or physicians to attach their names to these articles before they are published in medical or scientific journals. Some university and college students hire ghostwriters from essay mills to write entrance essays, term papers, theses, and dissertations. This is largely considered unethical unless the actual ghostwriting work is just light editing.\n\nGhostwriters are hired for numerous reasons. In many cases, celebrities or public figures do not have the time, discipline, or writing skills to write and research a several-hundred page autobiography or \"how-to\" book. Even if a celebrity or public figure has the writing skills to pen a short article, they may not know how to structure and edit a several-hundred page book so that it is captivating and well-paced. In other cases, publishers use ghostwriters to increase the number of books that can be published each year under the name of well-known, highly marketable authors, or to quickly release a topical book that ties in with a recent or upcoming newsworthy event.\n\nGhostwriters will often spend from several months to a full year researching, writing, and editing nonfiction and fiction works for a client, and they are paid based on a price per hour, per word or per page, with a flat fee, a percentage of the royalties of the sales, or some combination thereof. Some ghostwriters charge for articles \"$4 per word and more depending on the complexity\" of the article. Literary agent Madeleine Morel states that the average ghostwriter's advance for work for major book publishers is \"between $15,000 and $75,000\". These benchmark prices are mirrored approximately in the film industry by the Writer's Guild, where a Minimum Basic Agreement gives a starting price for the screenplay writer of $37,073 (non-original screenplay, no treatment).\n\nHowever, the recent shift into the digital age (15–20% world market share of books by 2015) has brought some changes, by opening newer markets that bring their own opportunities for authors and writers—especially on the more affordable side of the ghostwriting business. One such market is the shorter book, best represented at the moment by Amazon's Kindle Singles imprint: texts of 30,000 words and under. Such a length would have been much harder to sell before digital reader-technologies became widely available, but is now quite acceptable. Writers on the level of Ian McEwan have celebrated this recent change, mainly for artistic reasons.\n\nAs a consequence, the shorter format makes a project potentially more affordable for the client/author. Manhattan Literary, a ghostwriting company, states that \"book projects on the shorter side, tailored to new markets like the Kindle Singles imprint and others (30,000–42,000 words) start at a cost of $15,000\". And this shorter book appears to be here to stay. It was once financially impractical for publishers to produce such novella-length texts (they would have to charge too much); but this new market is, by 2015, already substantial and has been projected to be a solid part of the future of book publishing. So, with its appearance the starting price for the professional book writer has come down by about half, but only if this shorter format makes sense for the client.\n\nOn the upper end of the spectrum, with celebrities that can all but guarantee a publisher large sales, the fees can be much higher. In 2001, the \"New York Times\" stated that the fee that the ghostwriter for Hillary Clinton's memoirs will receive is probably about $500,000 of her book's $8 million advance, which \"is near the top of flat fees paid to collaborators\".\n\nThere is also the consideration of different benchmarks in different countries. In Canada, The Writers' Union has established a minimum fee schedule for ghostwriting, starting at $40,000 for a 200–300 page book, paid at various stages of the drafting of the book. Research fees are an extra charge on top of this minimum fee. In Germany, the average fee for a confidential ghostwriting service is about $100 per page. The Editorial Freelancers Association also suggests rates of 26 cents to 50 cents per word, which would be about $15,000 to $30,000 for a 250-page book.\n\nA recent availability also exists, of outsourcing many kinds of jobs, including ghostwriting, to offshore locations like India, China, and the Philippines where the customer can save money. Outsourced ghostwriters, whose quality levels vary widely, complete 200-page books for fees ranging between $3000 and $5000, or $12–$18 per page. The true tests of credibility—the writer's track record, and samples of his or her craft—become even more important in these instances, when the writer comes from a culture and first language that are entirely different from the client's.\n\nIn some cases, ghostwriters are allowed to share credit. For example, a common method is to put the client/author's name on a book cover as the main byline (by \"Author's Name\") and then to put the ghostwriter's name underneath it (as told to \"Ghostwriter's Name\"). Sometimes this is done in lieu of pay or in order to decrease the amount of payment to the book ghostwriter for whom the credit has its own intrinsic value. Also, the ghostwriter can be cited as a coauthor of a book, or listed in the movie or film credits when having ghostwritten the script or screenplay for a film production.\n\nFor nonfiction books, the ghostwriter may be credited as a \"contributor\" or a \"research assistant\". In other cases, the ghostwriter receives no official credit for writing a book or article; in cases where the credited author or the publisher or both wish to conceal the ghostwriter's role, the ghostwriter may be asked to sign a nondisclosure contract that legally forbids any mention of the writer's role in a project. Some have made the distinction between 'author' and 'writer,' as ghostwriter Kevin Anderson explains in a \"Washington Post\" interview: \"A ghostwriter is an interpreter and a translator, not an author, which is why our clients deserve full credit for authoring their books.\"\n\nGhostwriters are widely used by celebrities and public figures who wish to publish their autobiographies or memoirs. The degree of involvement of the ghostwriter in nonfiction writing projects ranges from minor to substantial. Various sources explain the role of the ghostwriter and how competent writers can get this kind of work. In some cases, a ghostwriter may be called in just to clean up, edit, and polish a rough draft of an autobiography or a \"how-to\" book. In other cases, the ghostwriter will write an entire book or article based on information, stories, notes, an outline, or interview sessions with the celebrity or public figure. The credited author also indicates to the ghostwriter what type of style, tone, or \"voice\" they want in the book.\n\nIn some cases, such as with some \"how-to\" books, diet guides, or cookbooks, a book will be entirely written by a ghostwriter, and the celebrity (e.g., a well-known musician or sports star) will be credited as author. Publishing companies use this strategy to increase the marketability of a book by associating it with a celebrity or well-known figure. In several countries before elections, candidates commission ghostwriters to produce autobiographies for them so as to gain visibility and exposure. Two of John F. Kennedy's books are almost entirely credited to ghostwriters. Donald Trump's famous was produced by a ghostwriter. Several of Hillary Clinton's books were also produced by ghost writers.\nA consultant or career-switcher may pay to have a book ghostwritten on a topic in their professional area, to establish or enhance their credibility as an 'expert' in their field. For example, a successful salesperson hoping to become a motivational speaker on selling may pay a ghostwriter to write a book on sales techniques. Often this type of book is published by a self-publishing press (or \"vanity press\"), which means that the author is paying to have the book published. This type of book is typically given away to prospective clients as a promotional tool, rather than being sold in bookstores.\n\nGhostwriters are employed by fiction publishers for several reasons. In some cases, publishers use ghostwriters to increase the number of books that can be published each year by a well-known, highly marketable author. Ghostwriters are mostly used to pen fiction works for well-known \"name\" authors in genres such as detective fiction, mysteries, and teen fiction.\n\nAdditionally, publishers use ghostwriters to write new books for established series where the 'author' is a pseudonym. For example, the purported authors of the Nancy Drew and Hardy Boys mysteries, \"Carolyn Keene\" and \"Franklin W. Dixon\", respectively, are actually pseudonyms for a series of ghostwriters who write books in the same style using a template of basic information about the book's characters and their fictional universe (names, dates, speech patterns), and about the tone and style that are expected in the book (for more information, see the articles on pseudonyms or pen names). In addition, ghostwriters are often given copies of several of the previous books in the series to help them match the style.\n\nThe estate of romance novelist V. C. Andrews hired ghostwriter Andrew Neiderman to continue writing novels after her death, under her name and in a similar style to her original works. Many of action writer Tom Clancy's books from the 2000s bear the names of two people on their covers, with Clancy's name in larger print and the other author's name in smaller print. Various books bearing Clancy's name were written by different authors under the same pseudonym. The first two books in the \"Tom Clancy's Splinter Cell\" franchise were written by Raymond Benson under the pseudonym David Michaels.\n\nSometimes famous authors will ghostwrite for other celebrities as well, such as when H. P. Lovecraft ghostwrote \"Imprisoned with the Pharaohs\" (also known as \"Under the Pyramids\") for Harry Houdini in \"Weird Tales\" in the 1920s.\n\nA number of papal encyclicals have been written by ghostwriters. \"Pascendi\", for instance, was written by Joseph Lemius (1860–1923), the procurator in Rome of the Oblates of Mary Immaculate. In June 1938, Pius XI summoned American Jesuit John La Farge, who began to prepare a draft of \"Humani generis unitas\", which LaFarge and two other Jesuits—Gustav Gundlach and Gustave Desbuquois—on in Paris; the draft was approximately 100 pages long. Another Jesuit translated the draft encyclical into Latin, presenting it to Wlodimir Ledóchowski, then the General of the Society of Jesus who had chosen Gundlach and Desbuquois for the project. The draft encyclical was delivered to the Vatican in September 1938. Sebastian Tromp, a Dutch Jesuit, a solid Thomist theologian and close to Pope Pius XII, is considered to be the main ghostwriter of \"Mystici corporis\".\n\nThere are ghostwriting companies and freelancers that sell entrance essays, term papers, theses and dissertations to students. Such services are sometimes offered by what is referred to as essay mills and frequently transacted through online interfaces. Despite being considered unethical and leading to repercussions if detected by universities, academic ghostwriting does not represent illegal activity in the United States and United Kingdom.\n\nAlthough academic ghostwriting involves the sale of academic texts that are written on demand, it cannot be equated with plagiarism, since it does not involve an undisclosed appropriation of existing texts. As opposed to cases of plagiarism that stem from a copy-and-paste reuse of previous work, essays and assignments that are obtained through ghostwriting services as a rule have the originality of their text confirmed by plagiarism detection software packages or online services that are widely used by universities.\n\nUniversities have developed strategies to combat this type of academic services, which can be associated with academic fraud, that are offered to students and researchers. Some universities allow professors to give students oral examinations on papers which a professor believes to be 'ghostwritten.’ If the student is unfamiliar with the content of an essay that he or she has submitted, then the student can be charged with academic fraud.\n\nWith medical ghostwriting, pharmaceutical companies pay professional writers to produce papers and then pay other scientists or physicians to attach their names to these papers before they are published in medical or scientific journals. Medical ghostwriting has been criticized by a variety of professional organizations representing the drug industry, publishers, and medical societies, and it may violate American laws prohibiting off-label promotion by drug manufacturers as well as anti-kickback provisions within the statutes governing Medicare. Recently, it has attracted scrutiny from the lay press and from lawmakers, as well. It is permitted at some institutions, including the University of Washington School of Medicine, while it is prohibited and considered a particularly pernicious form of plagiarism at others, such as Tufts University School of Medicine.\n\nProfessional medical writers can write papers without being listed as authors of the paper and without being considered ghostwriters, provided their role is acknowledged. The European Medical Writers Association have published guidelines which aim to ensure professional medical writers carry out this role in an ethical and responsible manner. The use of properly acknowledged medical writers is accepted as legitimate by organisations such as the World Association of Medical Editors and the \"British Medical Journal\". Moreover, professional medical writers' expertise in presenting scientific data may be of benefit in producing better quality papers.\n\nSome websites, including blogs, are ghostwritten, because not all authors have the information technology skills or the time to dedicate to running a website. Nonetheless, the style, tone and content is modeled on that of the credited author. Many website ghostwriters are freelance but some are freelancers who work under contract, as with radio presenters and television presenters.\nOccasionally a \"house pseudonym\", or collective name is used by the author of the website.\n\nSome celebrities, CEOs, or public figures set up blog websites—sometimes as a marketing, public relations, or lobbying tool. However, since these individuals are typically too busy to write their blog posts, they hire discreet ghostwriters to post to the blog under the celebrity or CEO's name. As with nonfiction ghostwriting, the blog ghostwriter models their writing style, content and tone on that of the credited author. This goes for social media as well. Many public figures have ghostwriters at least partially handle their Facebook and Twitter accounts, among others.\n\nWolfgang Amadeus Mozart is an example of a well-known composer who was paid to ghostwrite music for wealthy patrons. More recently, composers such as the UK-based Patric Standford (born in 1939) have ghostwritten for symphonic recordings and films such as the Rod McKuen Cello Concerto. In the film industry, a music ghostwriter is a \"person who composes music for another composer but is not credited on the cue sheet or in the final product in any way.\" The practice is considered one of the \"dirty little secrets of the film and television music business\" that is considered unethical, but has been common since the early stages of the film industry. In the early years of film, David Raksin worked as music ghostwriter and orchestrator for Charlie Chaplin; even though Chaplin was credited as the score writer, he was considered to be a \"hummer\" (pejorative film industry slang for a person who purports to be a film score composer but who in fact only gives a general idea of the melodies to a ghostwriter).\n\nThe practice is also common in television, as composers listed on cue sheets are entitled to music royalties every time an episode or theme score appears on television. A 1998 investigation by \"The Hollywood Reporter\" revealed that it was especially prevalent among animation companies such as Saban Entertainment, DiC, Ruby-Spears Productions and Hanna-Barbera, which often listed company executives as musicians for the purpose of royalties. Several composers later filed a multimillion-dollar lawsuit against Saban Entertainment president Haim Saban, for allegedly taking ownership and credit for their musical compositions.\n\nMusical ghostwriting also occurs in popular music. When a record company wants to market an inexperienced young singer as a singer-songwriter, or help a veteran bandleader coping with writer's block (or a lack of motivation to finish the next album), an experienced songwriter may be discreetly brought in to help. In other cases, a ghostwriter writes lyrics and a melody in the style of the credited musician, with little or no input from the credited musician. A ghostwriter providing this type of service may be thanked, without reference to the service provided, in the album credits, or they may be a true 'ghost', with no acknowledgement in the album.\n\nLegal disputes have arisen hiwhen musical ghostwriters have tried to claim royalties, when an allegedly ghostwritten song becomes a money-making hit. In 1987, Darryl Neudorf was asked to work on a project for Nettwerk Productions involving a newly signed artist in their repertoire named Sarah McLachlan. This recording, the album \"Touch\", resulted in garnering the interest of Arista Records. She signed a multi-album contract with them and two of the songs that Neudorf worked on with her became commercial hits in Canada. In 1991, Neudorf was invited back to work with McLachlan on her second album, \"Solace\". In 1993, he filed a lawsuit against McLachlan and her label, Nettwerk, alleging that he had made a significant and uncredited contribution to the songwriting on \"Touch\", and alleging that he wasn't paid properly for work done on \"Solace\". The judge in this suit eventually ruled in McLachlan's favor on the songs; though Neudorf may have contributed to the songwriting, neither regarded each other as joint authors. The judge ruled in Neudorf's favour on the payment issue.\nIn hip hop music, the increasing use of ghostwriters by high-profile hip hop stars has led to controversy. Critics view the increasing use of hip hop ghostwriters as the \"perversion of hip-hop by commerce.\" This is because of the limiting definition of \"rapping\" as \"...about you expressing yourself through your own words, not someone else’s.\" Chuck D of Public Enemy thinks this point of view is mistaken because \"...not everyone is equipped to be a lyricist and not everyone is equipped to be a vocalist.\" He points out that creating a rap song may require multiple talents. Frank Ocean started his career as a ghostwriter for artists such as Justin Bieber, Damienn Jones, John Legend and Brandy.\nCurrently in hip-hop, the credit given to ghostwriters varies: \"silent pens might sign confidentiality clauses, appear obliquely in the liner notes, or discuss their participation freely.\" In some cases, liner notes credit individuals for \"vocal arrangement\", which may be a euphemism for ghostwriting. In the early 2010s, hip-hop ghostwriting services like Rap Rebirth have appeared online, which provide recording artists who wish to purchase ghostwritten rhymes a greater degree of anonymity.\n\nGhost-authorship also applies to the visual arts, most commonly paintings. The extent of the master artist's contribution varies widely, as little as composition adjustments and corrective brush strokes, or as much as entire works. A common practice is use of the art instruction class milieu in which the master artist makes significant contributions to the work of the student who then signs that work as his or her own. Services addressing complete works have historically been highly confidential. Less prevalent are advertised commercial services which may use the term \"vanity artwork\" as suggestive of \"vanity publishing\".\nIn countries where the freedom of speech is not upheld and authors that have somehow displeased the ruling regime are \"blacklisted\" (i.e. forbidden from having their works published), the blacklisted authors or composers may ghostwrite material for other authors or composers who are in the good graces of the regime. Some blacklisted communist sympathisers have won Academy Awards, for example:\n\n\nMovies and novels about ghostwriters include:\n\n\n"}
{"id": "1177323", "url": "https://en.wikipedia.org/wiki?curid=1177323", "title": "Grave robbery", "text": "Grave robbery\n\nGrave robbery, tomb robbing, or tomb raiding is the act of uncovering a grave, tomb or crypt to steal matter. It is usually perpetrated to take and profit from valuable artifacts or personal effects. A related act is body snatching, a term denoting the contested or unlawful taking of a body (seldom from a grave), which can be extended to the unlawful taking of organs alone. These acts carry two stigmas from the evolution of morality: selfishness and psychological trauma to which the behavioural immune system adds the stigma of disgust to those coming into contact with part-decayed, particularly human, bodies.\n\nGrave robbing has caused great difficulty to the study of archaeology, art history, and history. Countless precious grave sites and tombs have been robbed before scholars were able to examine them. In any way, the archaeological context and the historical and anthropological information are destroyed:\nGrave robbers who are not caught usually sell relatively modern items anonymously and artifacts on the black market. Those intercepted, in a public justice domain, are inclined to deny their guilt due to the three stigmas mentioned. Though some artifacts may make their way to museums or scholars, the majority end up in private collections.\n\nChinese jade burial suits were believed to be myths for many years until two were discovered in 1968; it is now believed that most jade burial suits were removed long ago by grave robbers.\n\nGrave robbing is still problematic in 21st century China. The increase in technology, such as night vision goggles, air breathing equipment, and metal detectors allows grave robbers to better find and rob ancient gravesites. There are institutions in which you can learn how to rob graves– “for about 200 yuan (about $30) a day. Land surveying skills are first taught, before progressing to probes and shovels, then finally explosives. After 10 days, adepts have the chance to assist an instructor in a real tomb robbery”.\n\nAncient Egyptian tombs are one of the most common examples of tomb or grave robbery. Most of the tombs in Egypt's Valley of the Kings were robbed within one hundred years of their sealing (including the tomb of the famous King Tutankhamen, which was raided at least twice before it was discovered in 1922). As most of the artifacts in these ancient burial sites have been discovered, it is through the conditions of the tombs and presumed articles that are missing in which historians and archaeologists are able to determine whether the tomb has been robbed. Egyptian pharaohs often kept records of the precious items in their tombs, so an inventory check is presumed for archaeologists. Oftentimes, warnings would be left by the Pharaohs in the tombs of calamities and curses that would be laid upon any who touched the treasure, or the bodies, which did little to deter grave robbers. There are many examples of grave robbing in the Ancient World outside of Egypt. \n\nThe Romans (Byzantium) also suffered decades of theft and destruction of tombs, crypts, and graves.\n\nIn Europe, graves are robbed on an accelerating and alarming scale. Many grave robbers works with metal detectors and some of the groups are organised criminals, feeding the black market with highly prized archaeological artifacts.\n\nMerovingian graves in France and Germany and Anglo-Saxon graves in England contain many metal grave goods, mostly of iron. Grave robbers often leave them, being only interested in gold and silver. Grave contexts, ceramics, iron weapons and skeletons are destroyed.\n\nIn Eastern Europe, including Southeast Europe and the European part of Russia, grave robbers target all kinds of historically important graves, from pre-historic tombs to World War II graves.\n\nModern grave robbing in North America also involves long-abandoned or forgotten private Antebellum Period to pre-Great Depression era grave sites. These sites are often desecrated by grave robbers in search of old, hence valuable, jewelry. Affected sites are typically in rural, forested areas where once-prominent, wealthy landowners and their families were interred. The remote and often undocumented locations of defunct private cemeteries make them particularly susceptible to grave robbery. The practice may be encouraged by default upon the discovery of a previously unknown family cemetery by a new landowner.\n\nOne historical incident occurred during the evening of November 7, 1876, when a group of counterfeiters tried to abscond with Abraham Lincoln's mortal remains from his grave in Springfield, Illinois, in order to secure the release of their imprisoned leader, counterfeit engraver Benjamin Boyd. However, a secret service agent was present and had notified the police beforehand, so the attempted grave robbers only succeeded in the dislodgment of the lid of his coffin. As a consequence, when reburied, additional security measures prevented further depredations against Lincoln's body \n\nGrave robbers often sold stolen Aztec or Mayan goods on the black market for an extremely high price. The buyers (museum curators, historians, etc.) did not often suffer the repercussions of being in possession of stolen goods and that the blame (and charges) are put upon the lower-class grave robbers. Today's antiquities trade has become a streamlining industry – and the speed these artifacts enter the market has grown exponentially. Laws have been enacted in these regions, but due to extreme poverty, these grave robbings continue to grow each year.\n\nAfrican Americans would often bury their dead in a potter's field; not having the access or money for a proper funeral. When buried in potter’s fields, the dead were not normally buried very deep. A grave robber could just wait in the distance until everyone left and dig up the body from its shallow grave.\n\nOnce the railroad was invented and tracks laid—the sale of African American slaves from the South for dissection began; being sent to medical schools in the northern part of the United States. One Professor of Anatomy in New England reported that, in the 1880s and 1890s, he entered into an arrangement in which he received, twice each semester, a shipment of 12 bodies of southern African Americans. “They came in barrels labeled turpentine and were shipped to a local hardware store that dealt in painting materials”.\n\nAfter the Emancipation Act, African American Union soldiers that died while serving in the military were dissected by white military surgeons.\n\nState laws in Mississippi and North Carolina were passed in the 19th century which allowed medical schools to use the remains of those at the bottom of society’s hierarchy—the unclaimed bodies of poor persons, residents of alms houses, and those buried in potter’s fields. The option to dissect Confederate soldiers was also not available, being that Mississippi and North Carolina legally released the bodies to the families. The North Carolina law also provided that the body of whites never be sent to an African American medical college (such as the Leonard Medical School). These African American Medical schools typically obtained unclaimed Black ‘‘potter’s field bodies’’.\n\nThe geography and placement of burial grounds became a deterrent within itself. This is because without the accessibility of the automobile (in the early 19th century), the transportation of bodies was difficult.\n\nA perfect example of this is Mount Auburn Cemetery, in Cambridge Massachusetts. It was the first rural cemetery inside the United States. The rural location of the cemetery created transportation issues. In addition, the terrain of and around the cemetery was formidable. Further, Henry Alexander Scammell Dearborn, the designer wanted to leave the natural terrain (including ponds and hills) within the cemetery. If someone wanted to rob a grave they would have to maneuver around these obstacles for over large stretches of land, while in the dark. Note that Mount Auburn Cemetery is over 175 acres. Other cemeteries, of the time, that were originally built away from populated areas for similar reasons, include: Mount Hope Cemetery in Bangor, Maine (1834); Laurel Hill Cemetery in Philadelphia, Pennsylvania (1836); Mount Pleasant Cemetery in Taunton, Massachusetts (1836); Mount Hope Cemetery in Rochester, New York (1838); Green-Wood Cemetery in Brooklyn, New York (1838); and, Green Mount Cemetery in Baltimore, Maryland (1838).\n\nA mortsafe or mort safe was an iron coffin or framework which helped to protect a grave by preventing the body from being dug up and taken away. Mortsafes were specific for the task of preventing bodies from being stolen for purposes of medical dissections. These deterrents, used commonly in Scotland, would be only available for the rich to protect their loved ones, since iron was so expensive. After the body would decompose to a certain extent, the Mortsafe would be removed. These were not a commodity that were sold and bought; rather, they were rented.\n\nA mort house or dead house was used to store bodies until decomposed enough to no longer be targets for grave robbing. Up to 31 recorded mort houses were scattered throughout Scotland and northern England. Usually these structures were built within or near cemeteries to make transportation easier. Prior to grave robbers, they were used to store dead bodies in the winter, being that the ground was too cold and in some cases impossible to dig into. An example is the Udny Mort House built in 1832, Aberdeenshire, north-east Scotland and still standing today.\n\nThe coffin collar was an iron collar often fixed to a piece of wood. It was fixed around the neck of a corpse and then bolted to the bottom of a coffin. Most common reports of these collars being used came from Scotland around the 1820s.\n\nHistorically mausoleums have been used as a sign of a family’s wealth and a symbol of gentry and nobility in many countries. In the mid and late 19th century in North America, more and more families began to buy mausoleums. The belief was that it would be easier for a Resurrectionist or grave robber to dig up a grave rather than to topple down iron or steel doors guarding the mausoleum. A flaw in the design of the mausoleum was the stained glass or other windows within. Almost every family between the 18th and 19th century had a religious affiliation. As such, many of these families (usually with a Christian affiliation) would put stained glass within the mausoleums. The grave robbers would then just have to smash the glass to break in and to retrieve the body. Making it even easier, around the 1830s families began to fear burying family members. The living relatives would stand guard inside the mausoleum and would sometimes get trapped—only to be discovered upon the death of the next family member [citation needed]. To remedy this, families would put a spare key somewhere within the mausoleum and create doors with two way locks. In short, grave robbers could break a window, recover the body, find the key, and walk straight out the front door of the mausoleum.\n\nOne of the most simplistic and low-tech methods to prevent grave robbing were to have an individual guard over the newly buried body. This was done until decomposition of the body was brought to a point where they would no longer be desirable for medical use. If families did not have enough money to hire an individual to watch over the grave for a select number of days, the family would delegate this duty amongst them and close friends. As grave robbing became a lucrative business in the 19th century, a bribe would convince some guards to look the other way.\n\nWithin the Great Pyramid of Giza (completed around 2560 BC), an Egyptian deterrent system was built to guard the tomb of Pharaoh Khufu. This system consists of blocks and grooves to protect the King’s Chamber from tomb robbers. Some experts believe that Pharaoh Khufu’s tomb has actually not been found because of the deterrent system; instead, what had been found by grave robbers were fake rooms.\n\n\n\n"}
{"id": "54682673", "url": "https://en.wikipedia.org/wiki?curid=54682673", "title": "Head music", "text": "Head music\n\nThe idea of head music versus body music is an aesthetic idea in musicology. The distinction has been illustrated by comparing rock n roll with progressive rock, where the intention turned to innovation and experimentation, and \"to offer 'head music' for thinking rather than body music for dancing\".\n"}
{"id": "10326", "url": "https://en.wikipedia.org/wiki?curid=10326", "title": "Human evolution", "text": "Human evolution\n\nHuman evolution is the evolutionary process that led to the emergence of anatomically modern humans, beginning with the evolutionary history of primates – in particular genus \"Homo\" – and leading to the emergence of \"Homo sapiens\" as a distinct species of the hominid family, the great apes. This process involved the gradual development of traits such as human bipedalism and language, as well as interbreeding with other hominins, which indicate that human evolution was not linear but a web.\n\nThe study of human evolution involves several scientific disciplines, including physical anthropology, primatology, archaeology, paleontology, neurobiology, ethology, linguistics, evolutionary psychology, embryology and genetics. Genetic studies show that primates diverged from other mammals about , in the Late Cretaceous period, and the earliest fossils appear in the Paleocene, around .\n\nWithin the Hominoidea (apes) superfamily, the Hominidae family diverged from the Hylobatidae (gibbon) family some 15–20 million years ago; African great apes (subfamily Homininae) diverged from orangutans (Ponginae) about ; the Hominini tribe (humans, \"Australopithecines\" and other extinct biped genera, and chimpanzee) parted from the Gorillini tribe (gorillas) between 8-9 million years ago; and, in turn, the subtribes Hominina (humans and biped ancestors) and Panina (chimps) separated 4-7.5 million years ago.\n\nHuman evolution from its first separation from the last common ancestor of humans and chimpanzees is characterized by a number of morphological, developmental, physiological, and behavioral changes.\nThe most significant of these adaptations are bipedalism, increased brain size, lengthened ontogeny (gestation and infancy), and decreased sexual dimorphism. The relationship between these changes is the subject of ongoing debate. Other significant morphological changes included the evolution of a power and precision grip, a change first occurring in \"H. erectus\".\n\nBipedalism is the basic adaptation of the hominid and is considered the main cause behind a suite of skeletal changes shared by all bipedal hominids. The earliest hominin, of presumably primitive bipedalism, is considered to be either \"Sahelanthropus\" or \"Orrorin\", both of which arose some 6 to 7 million years ago. The non-bipedal knuckle-walkers, the gorilla and chimpanzee, diverged from the hominin line over a period covering the same time, so either of \"Sahelanthropus\" or \"Orrorin\" may be our last shared ancestor. \"Ardipithecus\", a full biped, arose somewhat later. \n\nThe early bipeds eventually evolved into the australopithecines and still later into the genus \"Homo\". There are several theories of the adaptation value of bipedalism. It is possible that bipedalism was favored because it freed the hands for reaching and carrying food, saved energy during locomotion, enabled long distance running and hunting, provided an enhanced field of vision, and helped avoid hyperthermia by reducing the surface area exposed to direct sun; features all advantageous for thriving in the new savanna and woodland environment created as a result of the East African Rift Valley uplift versus the previous closed forest habitat. A new study provides support for the hypothesis that walking on two legs, or bipedalism, evolved because it used less energy than quadrupedal knuckle-walking. However, recent studies suggest that bipedality without the ability to use fire would not have allowed global dispersal. This change in gait saw a lengthening of the legs proportionately when compared to the length of the arms, which were shortened through the removal of the need for brachiation. Another change is the shape of the big toe. Recent studies suggest that Australopithecines still lived part of the time in trees as a result of maintaining a grasping big toe. This was progressively lost in Habilines.\n\nAnatomically, the evolution of bipedalism has been accompanied by a large number of skeletal changes, not just to the legs and pelvis, but also to the vertebral column, feet and ankles, and skull. The femur evolved into a slightly more angular position to move the center of gravity toward the geometric center of the body. The knee and ankle joints became increasingly robust to better support increased weight. To support the increased weight on each vertebra in the upright position, the human vertebral column became S-shaped and the lumbar vertebrae became shorter and wider. In the feet the big toe moved into alignment with the other toes to help in forward locomotion. The arms and forearms shortened relative to the legs making it easier to run. The foramen magnum migrated under the skull and more anterior.\n\nThe most significant changes occurred in the pelvic region, where the long downward facing iliac blade was shortened and widened as a requirement for keeping the center of gravity stable while walking; bipedal hominids have a shorter but broader, bowl-like pelvis due to this. A drawback is that the birth canal of bipedal apes is smaller than in knuckle-walking apes, though there has been a widening of it in comparison to that of australopithecine and modern humans, permitting the passage of newborns due to the increase in cranial size but this is limited to the upper portion, since further increase can hinder normal bipedal movement.\n\nThe shortening of the pelvis and smaller birth canal evolved as a requirement for bipedalism and had significant effects on the process of human birth which is much more difficult in modern humans than in other primates. During human birth, because of the variation in size of the pelvic region, the fetal head must be in a transverse position (compared to the mother) during entry into the birth canal and rotate about 90 degrees upon exit. The smaller birth canal became a limiting factor to brain size increases in early humans and prompted a shorter gestation period leading to the relative immaturity of human offspring, who are unable to walk much before 12 months and have greater neoteny, compared to other primates, who are mobile at a much earlier age. The increased brain growth after birth and the increased dependency of children on mothers had a big effect upon the female reproductive cycle, and the more frequent appearance of alloparenting in humans when compared with other hominids. Delayed human sexual maturity also led to the evolution of menopause with one explanation providing that elderly women could better pass on their genes by taking care of their daughter's offspring, as compared to having more children of their own.\n\nThe human species eventually developed a much larger brain than that of other primates—typically in modern humans, nearly three times the size of a chimpanzee or gorilla brain. After a period of stasis with \"Australopithecus anamensis\" and \"Ardipithecus\", species which had smaller brains as a result of their bipedal locomotion, the pattern of encephalization started with \"Homo habilis\", whose brain was slightly larger than that of chimpanzees. This evolution continued in \"Homo erectus\" with , and reached a maximum in Neanderthals with , larger even than modern \"Homo sapiens\". This brain increase manifested during postnatal brain growth, far exceeding that of other apes (heterochrony). It also allowed for extended periods of social learning and language acquisition in juvenile humans, beginning as much as 2 million years ago.\n\nFurthermore, the changes in the structure of human brains may be even more significant than the increase in size.\n\nThe increase in volume of the neocortex also included a rapid increase in size of the cerebellum. Its function has traditionally been associated with balance and fine motor control, but more recently with speech and cognition. The great apes, including hominids, had a more pronounced cerebellum relative to the neocortex than other primates. It has been suggested that because of its function of sensory-motor control and learning complex muscular actions, the cerebellum may have underpinned human technological adaptations, including the preconditions of speech.\n\nThe immediate survival advantage of encephalization is difficult to discern, as the major brain changes from \"Homo erectus\" to \"Homo heidelbergensis\" were not accompanied by major changes in technology. It has been suggested that the changes were mainly social and behavioural, including increased empathic abilities, increases in size of social groups, and increased behavioural plasticity \n\nThe reduced degree of sexual dimorphism in humans is visible primarily in the reduction of the male canine tooth relative to other ape species (except gibbons) and reduced brow ridges and general robustness of males. Another important physiological change related to sexuality in humans was the evolution of hidden estrus. Humans are the only hominoids in which the female is fertile year round and in which no special signals of fertility are produced by the body (such as genital swelling or overt changes in proceptivity during estrus).\n\nNonetheless, humans retain a degree of sexual dimorphism in the distribution of body hair and subcutaneous fat, and in the overall size, males being around 15% larger than females. These changes taken together have been interpreted as a result of an increased emphasis on pair bonding as a possible solution to the requirement for increased parental investment due to the prolonged infancy of offspring.\n\nThe ulnar opposition – the contact between the thumb and the tip of the little finger of the same hand – is unique to anatomically modern humans. In other primates the thumb is short and unable to touch the little finger. The ulnar opposition facilitates the precision grip and power grip of the human hand, underlying all the skilled manipulations.\n\nA number of other changes have also characterized the evolution of humans, among them an increased importance on vision rather than smell; a longer juvenile developmental period and higher infant dependency; a smaller gut; faster basal metabolism; loss of body hair; evolution of sweat glands; a change in the shape of the dental arcade from being u-shaped to being parabolic; development of a chin (found in \"Homo sapiens\" alone); development of styloid processes; and the development of a descended larynx.\n\nThe word \"homo\", the name of the biological genus to which humans belong, is Latin for \"human\". It was chosen originally by Carl Linnaeus in his classification system. The word \"human\" is from the Latin \"humanus\", the adjectival form of \"homo\". The Latin \"homo\" derives from the Indo-European root *\"dhghem\", or \"earth\". Linnaeus and other scientists of his time also considered the great apes to be the closest relatives of humans based on morphological and anatomical similarities.\n\nThe possibility of linking humans with earlier apes by descent became clear only after 1859 with the publication of Charles Darwin's \"On the Origin of Species\", in which he argued for the idea of the evolution of new species from earlier ones. Darwin's book did not address the question of human evolution, saying only that \"Light will be thrown on the origin of man and his history.\"\n\nThe first debates about the nature of human evolution arose between Thomas Henry Huxley and Richard Owen. Huxley argued for human evolution from apes by illustrating many of the similarities and differences between humans and apes, and did so particularly in his 1863 book \"Evidence as to Man's Place in Nature\". However, many of Darwin's early supporters (such as Alfred Russel Wallace and Charles Lyell) did not initially agree that the origin of the mental capacities and the moral sensibilities of humans could be explained by natural selection, though this later changed. Darwin applied the theory of evolution and sexual selection to humans when he published \"The Descent of Man\" in 1871.\n\nA major problem in the 19th century was the lack of fossil intermediaries. Neanderthal remains were discovered in a limestone quarry in 1856, three years before the publication of \"On the Origin of Species\", and Neanderthal fossils had been discovered in Gibraltar even earlier, but it was originally claimed that these were human remains of a creature suffering some kind of illness. Despite the 1891 discovery by Eugène Dubois of what is now called \"Homo erectus\" at Trinil, Java, it was only in the 1920s when such fossils were discovered in Africa, that intermediate species began to accumulate. In 1925, Raymond Dart described \"Australopithecus africanus\". The type specimen was the Taung Child, an australopithecine infant which was discovered in a cave. The child's remains were a remarkably well-preserved tiny skull and an endocast of the brain.\n\nAlthough the brain was small (410 cm), its shape was rounded, unlike that of chimpanzees and gorillas, and more like a modern human brain. Also, the specimen showed short canine teeth, and the position of the foramen magnum (the hole in the skull where the spine enters) was evidence of bipedal locomotion. All of these traits convinced Dart that the Taung Child was a bipedal human ancestor, a transitional form between apes and humans.\n\nDuring the 1960s and 1970s, hundreds of fossils were found in East Africa in the regions of the Olduvai Gorge and Lake Turkana. The driving force of these searches was the Leakey family, with Louis Leakey and his wife Mary Leakey, and later their son Richard and daughter-in-law Meave—all successful and world-renowned fossil hunters and paleoanthropologists. From the fossil beds of Olduvai and Lake Turkana they amassed specimens of the early hominins: the australopithecines and \"Homo\" species, and even \"Homo erectus\".\n\nThese finds cemented Africa as the cradle of humankind. In the late 1970s and the 1980s, Ethiopia emerged as the new hot spot of paleoanthropology after \"Lucy\", the most complete fossil member of the species \"Australopithecus afarensis\", was found in 1974 by Donald Johanson near Hadar in the desertic Afar Triangle region of northern Ethiopia. Although the specimen had a small brain, the pelvis and leg bones were almost identical in function to those of modern humans, showing with certainty that these hominins had walked erect. Lucy was classified as a new species, \"Australopithecus afarensis\", which is thought to be more closely related to the genus \"Homo\" as a direct ancestor, or as a close relative of an unknown ancestor, than any other known hominid or hominin from this early time range; \"see\" terms \"hominid\" and \"hominin\". (The specimen was nicknamed \"Lucy\" after the Beatles' song \"Lucy in the Sky with Diamonds\", which was played loudly and repeatedly in the camp during the excavations.) The Afar Triangle area would later yield discovery of many more hominin fossils, particularly those uncovered or described by teams headed by Tim D. White in the 1990s, including \"Ardipithecus ramidus\" and \"Ardipithecus kadabba\".\n\nIn 2013, fossil skeletons of \"Homo naledi\", an extinct species of hominin assigned (provisionally) to the genus \"Homo\", were found in the Rising Star Cave system, a site in South Africa's Cradle of Humankind region in Gauteng province near Johannesburg. , fossils of at least fifteen individuals, amounting to 1550 specimens, have been excavated from the cave. The species is characterized by a body mass and stature similar to small-bodied human populations, a smaller endocranial volume similar to \"Australopithecus\", and a cranial morphology (skull shape) similar to early \"Homo\" species. The skeletal anatomy combines primitive features known from australopithecines with features known from early hominins. The individuals show signs of having been deliberately disposed of within the cave near the time of death. The fossils were dated close to 250,000 years ago, and thus are not a direct ancestor but a contemporary with the first appearance of larger-brained anatomically modern humans.\n\nThe genetic revolution in studies of human evolution started when Vincent Sarich and Allan Wilson measured the strength of immunological cross-reactions of blood serum albumin between pairs of creatures, including humans and African apes (chimpanzees and gorillas). The strength of the reaction could be expressed numerically as an immunological distance, which was in turn proportional to the number of amino acid differences between homologous proteins in different species. By constructing a calibration curve of the ID of species' pairs with known divergence times in the fossil record, the data could be used as a molecular clock to estimate the times of divergence of pairs with poorer or unknown fossil records.\n\nIn their seminal 1967 paper in \"Science\", Sarich and Wilson estimated the divergence time of humans and apes as four to five million years ago, at a time when standard interpretations of the fossil record gave this divergence as at least 10 to as much as 30 million years. Subsequent fossil discoveries, notably \"Lucy\", and reinterpretation of older fossil materials, notably \"Ramapithecus\", showed the younger estimates to be correct and validated the albumin method.\n\nProgress in DNA sequencing, specifically mitochondrial DNA (mtDNA) and then Y-chromosome DNA (Y-DNA) advanced the understanding of human origins. Application of the molecular clock principle revolutionized the study of molecular evolution.\n\nOn the basis of a separation from the orangutan between 10 and 20 million years ago, earlier studies of the molecular clock suggested that there were about 76 mutations per generation that were not inherited by human children from their parents; this evidence supported the divergence time between hominins and chimps noted above. However, a 2012 study in Iceland of 78 children and their parents suggests a mutation rate of only 36 mutations per generation; this datum extends the separation between humans and chimps to an earlier period greater than 7 million years ago (Ma). Additional research with 226 offspring of wild chimp populations in 8 locations suggests that chimps reproduce at age 26.5 years, on average; which suggests the human divergence from chimps occurred between 7 and 13 million years ago. And these data suggest that \"Ardipithecus\" (4.5 Ma), \"Orrorin\" (6 Ma) and \"Sahelanthropus\" (7 Ma) all may be on the hominid lineage, and even that the separation may have occurred outside the East African Rift region.\n\nFurthermore, analysis of the two species' genes in 2006 provides evidence that after human ancestors had started to diverge from chimpanzees, interspecies mating between \"proto-human\" and \"proto-chimps\" nonetheless occurred regularly enough to change certain genes in the new gene pool:\nThe research suggests:\n\nIn the 1990s, several teams of paleoanthropologists were working throughout Africa looking for evidence of the earliest divergence of the hominin lineage from the great apes. In 1994, Meave Leakey discovered \"Australopithecus anamensis\". The find was overshadowed by Tim D. White's 1995 discovery of \"Ardipithecus ramidus\", which pushed back the fossil record to .\n\nIn 2000, Martin Pickford and Brigitte Senut discovered, in the Tugen Hills of Kenya, a 6-million-year-old bipedal hominin which they named \"Orrorin tugenensis\". And in 2001, a team led by Michel Brunet discovered the skull of \"Sahelanthropus tchadensis\" which was dated as , and which Brunet argued was a bipedal, and therefore a hominid—that is, a hominin ( Hominidae; terms \"hominids\" and hominins).\n\nAnthropologists in the 1980s were divided regarding some details of reproductive barriers and migratory dispersals of the genus \"Homo\". Subsequently, genetics has been used to investigate and resolve these issues. According to the Sahara pump theory evidence suggests that genus \"Homo\" have migrated out of Africa at least three and possibly four times (e.g. \"Homo erectus\", \"Homo heidelbergensis\" and two or three times for \"Homo sapiens\"). Recent evidence suggests these dispersals are closely related to fluctuating periods of climate change.\n\nRecent evidence suggests that humans may have left Africa half a million years earlier than previously thought. A joint Franco-Indian team has found human artifacts in the Siwalk Hills north of New Delhi dating back at least 2.6 million years. This is earlier than the previous earliest finding of genus \"Homo\" at Dmanisi, in Georgia, dating to 1.85 million years. Although controversial, tools found at a Chinese cave strengthen the case that humans used tools as far back as 2.48 million years ago. This suggests that the Asian \"Chopper\" tool tradition, found in Java and northern China may have left Africa before the appearance of the Acheulian hand axe.\n\nUp until the genetic evidence became available there were two dominant models for the dispersal of modern humans. The multiregional hypothesis proposed that the genus \"Homo\" contained only a single interconnected population as it does today (not separate species), and that its evolution took place worldwide continuously over the last couple of million years. This model was proposed in 1988 by Milford H. Wolpoff. In contrast the \"out of Africa\" model proposed that modern \"H. sapiens\" speciated in Africa recently (that is, approximately 200,000 years ago) and the subsequent migration through Eurasia resulted in nearly complete replacement of other \"Homo\" species. This model has been developed by Chris B. Stringer and Peter Andrews.\n\nSequencing mtDNA and Y-DNA sampled from a wide range of indigenous populations revealed ancestral information relating to both male and female genetic heritage, and strengthened the Out of Africa theory and weakened the views of Multiregional Evolutionism. Aligned in genetic tree differences were interpreted as supportive of a recent single origin. Analyses have shown a greater diversity of DNA patterns throughout Africa, consistent with the idea that Africa is the ancestral home of mitochondrial Eve and Y-chromosomal Adam, and that modern human dispersal out of Africa has only occurred over the last 55,000 years.\n\n\"Out of Africa\" has thus gained much support from research using female mitochondrial DNA and the male Y chromosome. After analysing genealogy trees constructed using 133 types of mtDNA, researchers concluded that all were descended from a female African progenitor, dubbed Mitochondrial Eve. \"Out of Africa\" is also supported by the fact that mitochondrial genetic diversity is highest among African populations.\n\nA broad study of African genetic diversity, headed by Sarah Tishkoff, found the San people had the greatest genetic diversity among the 113 distinct populations sampled, making them one of 14 \"ancestral population clusters\". The research also located a possible origin of modern human migration in south-western Africa, near the coastal border of Namibia and Angola. The fossil evidence was insufficient for archaeologist Richard Leakey to resolve the debate about exactly where in Africa modern humans first appeared. Studies of haplogroups in Y-chromosomal DNA and mitochondrial DNA have largely supported a recent African origin. All the evidence from autosomal DNA also predominantly supports a Recent African origin. However, evidence for archaic admixture in modern humans, both in Africa and later, throughout Eurasia has recently been suggested by a number of studies.\n\nRecent sequencing of Neanderthal and Denisovan genomes shows that some admixture with these populations has occurred. Modern humans outside Africa have 2–4% Neanderthal alleles in their genome, and some Melanesians have an additional 4–6% of Denisovan alleles. These new results do not contradict the \"out of Africa\" model, except in its strictest interpretation, although they make the situation more complex. After recovery from a genetic bottleneck that could possibly be due to the Toba supervolcano catastrophe, a fairly small group left Africa and later briefly interbred on three separate occasions with Neanderthals, probably in the middle-east, on the Eurasian steppe or even in North Africa before their departure. Their still predominantly African descendants spread to populate the world. A fraction in turn interbred with Denisovans, probably in south-east Asia, before populating Melanesia. HLA haplotypes of Neanderthal and Denisova origin have been identified in modern Eurasian and Oceanian populations. The Denisovan EPAS1 gene has also been found in Tibetan populations.\n\nThere are still differing theories on whether there was a single exodus from Africa or several. A multiple dispersal model involves the Southern Dispersal theory, which has gained support in recent years from genetic, linguistic and archaeological evidence. In this theory, there was a coastal dispersal of modern humans from the Horn of Africa crossing the Bab el Mandib to Yemen at a lower sea level around 70,000 years ago. This group helped to populate Southeast Asia and Oceania, explaining the discovery of early human sites in these areas much earlier than those in the Levant. This group seems to have been dependent upon marine resources for their survival.\n\nStephen Oppenheimer has proposed a second wave of humans may have later dispersed through the Persian Gulf oases, and the Zagros mountains into the Middle East. Alternatively it may have come across the Sinai Peninsula into Asia, from shortly after 50,000 yrs BP, resulting in the bulk of the human populations of Eurasia. It has been suggested that this second group possibly possessed a more sophisticated \"big game hunting\" tool technology and was less dependent on coastal food sources than the original group. Much of the evidence for the first group's expansion would have been destroyed by the rising sea levels at the end of each glacial maximum. The multiple dispersal model is contradicted by studies indicating that the populations of Eurasia and the populations of Southeast Asia and Oceania are all descended from the same mitochondrial DNA L3 lineages, which support a single migration out of Africa that gave rise to all non-African populations.\n\nStephen Oppenheimer, on the basis of the early date of Badoshan Iranian Aurignacian, suggests that this second dispersal, may have occurred with a pluvial period about 50,000 years before the present, with modern human big-game hunting cultures spreading up the Zagros Mountains, carrying modern human genomes from Oman, throughout the Persian Gulf, northward into Armenia and Anatolia, with a variant travelling south into Israel and to Cyrenicia.\n\nThe evidence on which scientific accounts of human evolution are based comes from many fields of natural science. The main source of knowledge about the evolutionary process has traditionally been the fossil record, but since the development of genetics beginning in the 1970s, DNA analysis has come to occupy a place of comparable importance. The studies of ontogeny, phylogeny and especially evolutionary developmental biology of both vertebrates and invertebrates offer considerable insight into the evolution of all life, including how humans evolved. The specific study of the origin and life of humans is anthropology, particularly paleoanthropology which focuses on the study of human prehistory.\n\nThe closest living relatives of humans are bonobos and chimpanzees (both genus \"Pan\") and gorillas (genus \"Gorilla\"). With the sequencing of both the human and chimpanzee genome, estimates of the similarity between their DNA sequences range between 95% and 99%. By using the technique called the molecular clock which estimates the time required for the number of divergent mutations to accumulate between two lineages, the approximate date for the split between lineages can be calculated.\n\nThe gibbons (family Hylobatidae) and then orangutans (genus \"Pongo\") were the first groups to split from the line leading to the hominins, including humans—followed by gorillas, and, ultimately, by the chimpanzees (genus \"Pan\"). The splitting date between hominin and chimpanzee lineages is placed by some between , that is, during the Late Miocene. Speciation, however, appears to have been unusually drawn-out. Initial divergence occurred sometime between , but ongoing hybridization blurred the separation and delayed complete separation during several millions of years. Patterson (2006) dated the final divergence at .\n\nGenetic evidence has also been employed to resolve the question of whether there was any gene flow between early modern humans and Neanderthals, and to enhance our understanding of the early human migration patterns and splitting dates. By comparing the parts of the genome that are not under natural selection and which therefore accumulate mutations at a fairly steady rate, it is possible to reconstruct a genetic tree incorporating the entire human species since the last shared ancestor.\n\nEach time a certain mutation (single-nucleotide polymorphism) appears in an individual and is passed on to his or her descendants a haplogroup is formed including all of the descendants of the individual who will also carry that mutation. By comparing mitochondrial DNA which is inherited only from the mother, geneticists have concluded that the last female common ancestor whose genetic marker is found in all modern humans, the so-called mitochondrial Eve, must have lived around 200,000 years ago.\n\nHuman evolutionary genetics studies how one human genome differs from the other, the evolutionary past that gave rise to it, and its current effects. Differences between genomes have anthropological, medical and forensic implications and applications. Genetic data can provide important insight into human evolution.\n\nThere is little fossil evidence for the divergence of the gorilla, chimpanzee and hominin lineages. The earliest fossils that have been proposed as members of the hominin lineage are \"Sahelanthropus tchadensis\" dating from , \"Orrorin tugenensis\" dating from , and \"Ardipithecus kadabba\" dating to . Each of these have been argued to be a bipedal ancestor of later hominins but, in each case, the claims have been contested. It is also possible that one or more of these species are ancestors of another branch of African apes, or that they represent a shared ancestor between hominins and other apes.\n\nThe question then of the relationship between these early fossil species and the hominin lineage is still to be resolved. From these early species, the australopithecines arose around and diverged into robust (also called \"Paranthropus\") and gracile branches, one of which (possibly \"A. garhi\") probably went on to become ancestors of the genus \"Homo\". The australopithecine species that is best represented in the fossil record is \"Australopithecus afarensis\" with more than one hundred fossil individuals represented, found from Northern Ethiopia (such as the famous \"Lucy\"), to Kenya, and South Africa. Fossils of robust australopithecines such as \"Au. robustus\" (or alternatively \"Paranthropus robustus\") and \"Au./P. boisei\" are particularly abundant in South Africa at sites such as Kromdraai and Swartkrans, and around Lake Turkana in Kenya.\n\nThe earliest member of the genus \"Homo\" is \"Homo habilis\" which evolved around . \"Homo habilis\" is the first species for which we have positive evidence of the use of stone tools. They developed the Oldowan lithic technology, named after the Olduvai Gorge in which the first specimens were found. Some scientists consider \"Homo rudolfensis\", a larger bodied group of fossils with similar morphology to the original \"H. habilis\" fossils, to be a separate species while others consider them to be part of \"H. habilis\"—simply representing intraspecies variation, or perhaps even sexual dimorphism. The brains of these early hominins were about the same size as that of a chimpanzee, and their main adaptation was bipedalism as an adaptation to terrestrial living.\n\nDuring the next million years, a process of encephalization began and, by the arrival (about ) of \"Homo erectus\" in the fossil record, cranial capacity had doubled. \"Homo erectus\" were the first of the hominins to emigrate from Africa, and, from , this species spread through Africa, Asia, and Europe. One population of \"H. erectus\", also sometimes classified as a separate species \"Homo ergaster\", remained in Africa and evolved into \"Homo sapiens\". It is believed that these species, \"H. erectus\" and \"H. ergaster\", were the first to use fire and complex tools.\n\nThe earliest transitional fossils between \"H. ergaster/erectus\" and archaic \"H. sapiens\" are from Africa, such as \"Homo rhodesiensis\", but seemingly transitional forms were also found at Dmanisi, Georgia. These descendants of African \"H. erectus\" spread through Eurasia from ca. 500,000 years ago evolving into \"H. antecessor\", \"H. heidelbergensis\" and \"H. neanderthalensis\". The earliest fossils of anatomically modern humans are from the Middle Paleolithic, about 200,000 years ago such as the Omo remains of Ethiopia; later fossils from Es Skhul cave in Israel and Southern Europe begin around 90,000 years ago ().\n\nAs modern humans spread out from Africa, they encountered other hominins such as \"Homo neanderthalensis\" and the so-called Denisovans, who may have evolved from populations of \"Homo erectus\" that had left Africa around . The nature of interaction between early humans and these sister species has been a long-standing source of controversy, the question being whether humans replaced these earlier species or whether they were in fact similar enough to interbreed, in which case these earlier populations may have contributed genetic material to modern humans.\n\nThis migration out of Africa is estimated to have begun about 70,000 years BP and modern humans subsequently spread globally, replacing earlier hominins either through competition or hybridization. They inhabited Eurasia and Oceania by 40,000 years BP, and the Americas by at least 14,500 years BP.\n\nThe hypothesis of interbreeding, also known as hybridization, admixture or hybrid-origin theory, has been discussed ever since the discovery of Neanderthal remains in the 19th century. The linear view of human evolution began to be abandoned in the 1970s as different species of humans were discovered that made the linear concept increasingly unlikely. In the 21st century with the advent of molecular biology techniques and computerization, whole-genome sequencing of Neanderthal and human genome were performed, confirming recent admixture between different human species. In 2010, evidence based on molecular biology was published, revealing unambiguous examples of interbreeding between archaic and modern humans during the Middle Paleolithic and early Upper Paleolithic. It has been demonstrated that interbreeding happened in several independent events that included Neanderthals, Denisovans, as well as several unidentified hominins. Today, approximately 2% of DNA from most Europeans and Asians is Neanderthal, with traces of Denisovan heritage. Also, 4-6% of modern Melanesian genetics are Denisovan. Comparisons of the human genome to the genomes of Neandertals, Denisovans and apes can help identify features that set modern humans apart from other hominin species. In a 2016 comparative genomics study, a Harvard Medical School/UCLA research team made a world map on the distribution and made some predictions about where Denisovan and Neanderthal genes may be impacting modern human biology.\n\nFor example, comparative studies in the mid-2010s found several traits related to neurological, immunological, developmental, and metabolic phenotypes, that were developed by archaic humans to European and Asian environments and inherited to modern humans through admixture with local hominins.\nAlthough the narratives of human evolution are often contentious, several discoveries since 2010 show that human evolution should not be seen as a simple linear or branched progression, but a mix of related species. In fact, genomic research has shown that hybridization between substantially diverged lineages is the rule, not the exception, in human evolution. Furthermore, it is argued that hybridization was an essential creative force in the emergence of modern humans.\n\nEvolutionary history of the primates can be traced back 65 million years. One of the oldest known primate-like mammal species, the \"Plesiadapis\", came from North America; another, \"Archicebus\", came from China. Other similar basal primates were widespread in Eurasia and Africa during the tropical conditions of the Paleocene and Eocene.\n\nDavid R. Begun concluded that early primates flourished in Eurasia and that a lineage leading to the African apes and humans, including to \"Dryopithecus\", migrated south from Europe or Western Asia into Africa. The surviving tropical population of primates—which is seen most completely in the Upper Eocene and lowermost Oligocene fossil beds of the Faiyum depression southwest of Cairo—gave rise to all extant primate species, including the lemurs of Madagascar, lorises of Southeast Asia, galagos or \"bush babies\" of Africa, and to the anthropoids, which are the Platyrrhines or New World monkeys, the Catarrhines or Old World monkeys, and the great apes, including humans and other hominids.\n\nThe earliest known catarrhine is \"Kamoyapithecus\" from uppermost Oligocene at Eragaleit in the northern Great Rift Valley in Kenya, dated to 24 million years ago. Its ancestry is thought to be species related to \"Aegyptopithecus\", \"Propliopithecus\", and \"Parapithecus\" from the Faiyum, at around 35 million years ago. In 2010, \"Saadanius\" was described as a close relative of the last common ancestor of the crown catarrhines, and tentatively dated to 29–28 million years ago, helping to fill an 11-million-year gap in the fossil record.\n\nIn the Early Miocene, about 22 million years ago, the many kinds of arboreally adapted primitive catarrhines from East Africa suggest a long history of prior diversification. Fossils at 20 million years ago include fragments attributed to \"Victoriapithecus\", the earliest Old World monkey. Among the genera thought to be in the ape lineage leading up to 13 million years ago are \"Proconsul\", \"Rangwapithecus\", \"Dendropithecus\", \"Limnopithecus\", \"Nacholapithecus\", \"Equatorius\", \"Nyanzapithecus\", \"Afropithecus\", \"Heliopithecus\", and \"Kenyapithecus\", all from East Africa.\n\nThe presence of other generalized non-cercopithecids of Middle Miocene from sites far distant—\"Otavipithecus\" from cave deposits in Namibia, and \"Pierolapithecus\" and \"Dryopithecus\" from France, Spain and Austria—is evidence of a wide diversity of forms across Africa and the Mediterranean basin during the relatively warm and equable climatic regimes of the Early and Middle Miocene. The youngest of the Miocene hominoids, \"Oreopithecus\", is from coal beds in Italy that have been dated to 9 million years ago.\n\nMolecular evidence indicates that the lineage of gibbons (family Hylobatidae) diverged from the line of great apes some 18–12 million years ago, and that of orangutans (subfamily Ponginae) diverged from the other great apes at about 12 million years; there are no fossils that clearly document the ancestry of gibbons, which may have originated in a so-far-unknown South East Asian hominoid population, but fossil proto-orangutans may be represented by \"Sivapithecus\" from India and \"Griphopithecus\" from Turkey, dated to around 10 million years ago.\n\nSpecies close to the last common ancestor of gorillas, chimpanzees and humans may be represented by \"Nakalipithecus\" fossils found in Kenya and \"Ouranopithecus\" found in Greece. Molecular evidence suggests that between 8 and 4 million years ago, first the gorillas, and then the chimpanzees (genus \"Pan\") split off from the line leading to the humans. Human DNA is approximately 98.4% identical to that of chimpanzees when comparing single nucleotide polymorphisms (see human evolutionary genetics). The fossil record, however, of gorillas and chimpanzees is limited; both poor preservation—rain forest soils tend to be acidic and dissolve bone—and sampling bias probably contribute to this problem.\n\nOther hominins probably adapted to the drier environments outside the equatorial belt; and there they encountered antelope, hyenas, dogs, pigs, elephants, horses, and others. The equatorial belt contracted after about 8 million years ago, and there is very little fossil evidence for the split—thought to have occurred around that time—of the hominin lineage from the lineages of gorillas and chimpanzees. The earliest fossils argued by some to belong to the human lineage are \"Sahelanthropus tchadensis\" (7 Ma) and \"Orrorin tugenensis\" (6 Ma), followed by \"Ardipithecus\" (5.5–4.4 Ma), with species \"Ar. kadabba\" and \"Ar. ramidus\".\n\nIt has been argued in a study of the life history of \"Ar. ramidus\" that the species provides evidence for a suite of anatomical and behavioral adaptations in very early hominins unlike any species of extant great ape. This study demonstrated affinities between the skull morphology of \"Ar. ramidus\" and that of infant and juvenile chimpanzees, suggesting the species evolved a juvenalised or paedomorphic craniofacial morphology via heterochronic dissociation of growth trajectories. It was also argued that the species provides support for the notion that very early hominins, akin to bonobos (\"Pan paniscus\") the less aggressive species of chimpanzee, may have evolved via the process of self-domestication. Consequently, arguing against the so-called \"chimpanzee referential model\" the authors suggest it is no longer tenable to use common chimpanzee (\"Pan troglodytes\") social and mating behaviors in models of early hominin social evolution. When commenting on the absence of aggressive canine morphology in \"Ar. ramidus\" and the implications this has for the evolution of hominin social psychology, they wrote:\n\nThe authors argue that many of the basic human adaptations evolved in the ancient forest and woodland ecosystems of late Miocene and early Pliocene Africa. Consequently, they argue that humans may not represent evolution from a chimpanzee-like ancestor as has traditionally been supposed. This suggests many modern human adaptations represent phylogenetically deep traits and that the behavior and morphology of chimpanzees may have evolved subsequent to the split with the common ancestor they share with humans.\n\nThe genus \"Australopithecus\" evolved in eastern Africa around 4 million years ago before spreading throughout the continent and eventually becoming extinct 2 million years ago. During this time period various forms of australopiths existed, including \"Australopithecus anamensis\", \"Au. afarensis\", \"Au. sediba\", and \"Au. africanus\". There is still some debate among academics whether certain African hominid species of this time, such as \"Au. robustus\" and \"Au. boisei\", constitute members of the same genus; if so, they would be considered to be \"Au. robust australopiths\" whilst the others would be considered \"Au. gracile australopiths\". However, if these species do indeed constitute their own genus, then they may be given their own name, the \"Paranthropus\".\nA new proposed species \"Australopithecus deyiremeda\" is claimed to have been discovered living at the same time period of \"Au. afarensis\". There is debate if Au. deyiremeda is a new species or is \"Au. afarensis.\" \"Australopithecus prometheus\", otherwise known as Little Foot has recently been dated at 3.67 million years old through a new dating technique, making the genus \"Australopithecus\" as old as \"afarensis\". Given the opposable big toe found on Little Foot, it seems that he was a good climber, and it is thought given the night predators of the region, he probably, like gorillas and chimpanzees, built a nesting platform at night, in the trees.\n\nThe earliest documented representative of the genus \"Homo\" is \"Homo habilis\", which evolved around , and is arguably the earliest species for which there is positive evidence of the use of stone tools. The brains of these early hominins were about the same size as that of a chimpanzee, although it has been suggested that this was the time in which the human SRGAP2 gene doubled, producing a more rapid wiring of the frontal cortex. During the next million years a process of rapid encephalization occurred, and with the arrival of \"Homo erectus\" and \"Homo ergaster\" in the fossil record, cranial capacity had doubled to 850 cm. (Such an increase in human brain size is equivalent to each generation having 125,000 more neurons than their parents.) It is believed that \"Homo erectus\" and \"Homo ergaster\" were the first to use fire and complex tools, and were the first of the hominin line to leave Africa, spreading throughout Africa, Asia, and Europe between .\nAccording to the recent African origin of modern humans theory, modern humans evolved in Africa possibly from \"Homo heidelbergensis\", \"Homo rhodesiensis\" or \"Homo antecessor\" and migrated out of the continent some 50,000 to 100,000 years ago, gradually replacing local populations of \"Homo erectus\", Denisova hominins, \"Homo floresiensis\" and \"Homo neanderthalensis\". Archaic \"Homo sapiens\", the forerunner of anatomically modern humans, evolved in the Middle Paleolithic between 400,000 and 250,000 years ago. Recent DNA evidence suggests that several haplotypes of Neanderthal origin are present among all non-African populations, and Neanderthals and other hominins, such as Denisovans, may have contributed up to 6% of their genome to present-day humans, suggestive of a limited inter-breeding between these species.<ref name=\"10.1126/science.1209202\"></ref> The transition to behavioral modernity with the development of symbolic culture, language, and specialized lithic technology happened around 50,000 years ago according to some anthropologists although others point to evidence that suggests that a gradual change in behavior took place over a longer time span.\n\n\"Homo sapiens\" is the only extant species of its genus, \"Homo\". While some (extinct) \"Homo\" species might have been ancestors of \"Homo sapiens\", many, perhaps most, were likely \"cousins\", having speciated away from the ancestral hominin line. There is yet no consensus as to which of these groups should be considered a separate species and which should be a subspecies; this may be due to the dearth of fossils or to the slight differences used to classify species in the genus \"Homo\". The Sahara pump theory (describing an occasionally passable \"wet\" Sahara desert) provides one possible explanation of the early variation in the genus \"Homo\".\n\nBased on archaeological and paleontological evidence, it has been possible to infer, to some extent, the ancient dietary practices of various \"Homo\" species and to study the role of diet in physical and behavioral evolution within \"Homo\".\n\nSome anthropologists and archaeologists subscribe to the Toba catastrophe theory, which posits that the supereruption of Lake Toba on Sumatran island in Indonesia some 70,000 years ago caused global consequences, killing the majority of humans and creating a population bottleneck that affected the genetic inheritance of all humans today.\n\n\"Homo habilis\" lived from about 2.8 to 1.4 Ma. The species evolved in South and East Africa in the Late Pliocene or Early Pleistocene, 2.5–2 Ma, when it diverged from the australopithecines. \"Homo habilis\" had smaller molars and larger brains than the australopithecines, and made tools from stone and perhaps animal bones. One of the first known hominins was nicknamed 'handy man' by discoverer Louis Leakey due to its association with stone tools. Some scientists have proposed moving this species out of \"Homo\" and into \"Australopithecus\" due to the morphology of its skeleton being more adapted to living on trees rather than to moving on two legs like \"Homo sapiens\".\n\nIn May 2010, a new species, \"Homo gautengensis\", was discovered in South Africa.\n\nThese are proposed species names for fossils from about 1.9–1.6 Ma, whose relation to \"Homo habilis\" is not yet clear.\n\nThe first fossils of \"Homo erectus\" were discovered by Dutch physician Eugene Dubois in 1891 on the Indonesian island of Java. He originally named the material \"Anthropopithecus erectus\" (1892-1893, considered at this point as a chimpanzee-like fossil primate) and \"Pithecanthropus erectus\" (1893-1894, changing his mind as of based on its morphology, which he considered to be intermediate between that of humans and apes). Years later, in the 20th century, the German physician and paleoanthropologist Franz Weidenreich (1873-1948) compared in detail the characters of Dubois' Java Man, then named \"Pithecanthropus erectus\", with the characters of the Peking Man, then named \"Sinanthropus pekinensis\". Weidenreich concluded in 1940 that because of their anatomical similarity with modern humans it was necessary to gather all these specimens of Java and China in a single species of the genus \"Homo\", the species \"Homo erectus\". \"Homo erectus\" lived from about 1.8 Ma to about 70,000 years ago—which would indicate that they were probably wiped out by the Toba catastrophe; however, nearby \"Homo floresiensis\" survived it. The early phase of \"Homo erectus\", from 1.8 to 1.25 Ma, is considered by some to be a separate species, \"Homo ergaster\", or as \"Homo erectus ergaster\", a subspecies of \"Homo erectus\".\n\nIn Africa in the Early Pleistocene, 1.5–1 Ma, some populations of \"Homo habilis\" are thought to have evolved larger brains and to have made more elaborate stone tools; these differences and others are sufficient for anthropologists to classify them as a new species, \"Homo erectus\"—in Africa. The evolution of locking knees and the movement of the foramen magnum are thought to be likely drivers of the larger population changes. This species also may have used fire to cook meat. suggests that the fact that Homo seems to have been ground dwelling, with reduced intestinal length, smaller dentition, \"and swelled our brains to their current, horrendously fuel-inefficient size\", suggest that control of fire and releasing increased nutritional value through cooking was the key adaptation that separated Homo from tree-sleeping Australopithecines.\n\nA famous example of \"Homo erectus\" is Peking Man; others were found in Asia (notably in Indonesia), Africa, and Europe. Many paleoanthropologists now use the term \"Homo ergaster\" for the non-Asian forms of this group, and reserve \"Homo erectus\" only for those fossils that are found in Asia and meet certain skeletal and dental requirements which differ slightly from \"H. ergaster\".\n\nThese are proposed as species that may be intermediate between \"H. erectus\" and \"H. heidelbergensis\".\n\n\"H. heidelbergensis\" (\"Heidelberg Man\") lived from about 800,000 to about 300,000 years ago. Also proposed as \"Homo sapiens heidelbergensis\" or \"Homo sapiens paleohungaricus\".\n\n\n\"Homo neanderthalensis\", alternatively designated as \"Homo sapiens neanderthalensis\", lived in Europe and Asia from 400,000 to about 28,000 years ago.\nThere are a number of clear anatomical differences between anatomically modern humans (AMH) and Neanderthal populations. Many of these relate to the superior adaptation to cold environments possessed by the Neanderthal populations. Their surface to volume ratio is an extreme version of that found amongst Inuit populations, indicating that they were less inclined to lose body heat than were AMH. From brain Endocasts, Neanderthals also had significantly larger brains. This would seem to indicate that the intellectual superiority of AMH populations may be questionable. More recent research by Eiluned Pearce, Chris Stringer, R. I. M. Dunbar, however, have shown important differences in Brain architecture. For example, in both the orbital chamber size and in the size of the occipital lobe, the larger size suggests that the Neanderthal had a better visual acuity than modern humans. This would give a superior vision in the inferior light conditions found in Glacial Europe. It also seems that the higher body mass of Neanderthals had a correspondingly larger brain mass required for body care and control.\n\nThe Neanderthal populations seem to have been physically superior to AMH populations. These differences may have been sufficient to give Neanderthal populations an environmental superiority to AMH populations from 75,000 to 45,000 years BP. With these differences, Neanderthal brains show a smaller area was available for social functioning. Plotting group size possible from endocrainial volume, suggests that AMH populations (minus occipital lobe size), had a Dunbars number of 144 possible relationships. Neanderthal populations seem to have been limited to about 120 individuals. This would show up in a larger number of possible mates for AMH humans, with increased risks of inbreeding amongst Neanderthal populations. It also suggests that humans had larger trade catchment areas than Neanderthals (confirmed in the distribution of stone tools). With larger populations, social and technological innovations were easier to fix in human populations, which may have all contributed to the fact that modern Homo sapiens replaced the Neanderthal populations by 28,000 BP.\n\nEarlier evidence from sequencing mitochondrial DNA suggested that no significant gene flow occurred between \"H. neanderthalensis\" and \"H. sapiens\", and that the two were separate species that shared a common ancestor about 660,000 years ago. However, a sequencing of the Neanderthal genome in 2010 indicated that Neanderthals did indeed interbreed with anatomically modern humans \"circa\" 45,000 to 80,000 years ago (at the approximate time that modern humans migrated out from Africa, but before they dispersed into Europe, Asia and elsewhere). The genetic sequencing of a 40,000 year old human skeleton from Romania showed that 11% of its genome was Neanderthal, and it was estimated that the individual had a Neanderthal ancestor 4-6 generations previously, in addition to a contribution from earlier interbreeding in the Middle East. Though this interbred Romanian population seems not to have been ancestral to modern humans, the finding indicates that interbreeding happened repeatedly.\n\nNearly all modern non-African humans have 1% to 4% of their DNA derived from Neanderthal DNA, and this finding is consistent with recent studies indicating that the divergence of some human alleles dates to one Ma, although the interpretation of these studies has been questioned. Neanderthals and \"Homo sapiens\" could have co-existed in Europe for as long as 10,000 years, during which human populations exploded vastly outnumbering Neanderthals, possibly outcompeting them by sheer numerical strength.\n\nIn 2008, archaeologists working at the site of Denisova Cave in the Altai Mountains of Siberia uncovered a small bone fragment from the fifth finger of a juvenile member of Denisovans. Artifacts, including a bracelet, excavated in the cave at the same level were carbon dated to around 40,000 BP. As DNA had survived in the fossil fragment due to the cool climate of the Denisova Cave, both mtDNA and nuclear DNA were sequenced.\n\nWhile the divergence point of the mtDNA was unexpectedly deep in time, the full genomic sequence suggested the Denisovans belonged to the same lineage as Neanderthals, with the two diverging shortly after their line split from the lineage that gave rise to modern humans. Modern humans are known to have overlapped with Neanderthals in Europe and the Near East for possibly more than 40,000 years, and the discovery raises the possibility that Neanderthals, Denisovans, and modern humans may have co-existed and interbred. The existence of this distant branch creates a much more complex picture of humankind during the Late Pleistocene than previously thought. Evidence has also been found that as much as 6% of the DNA of some modern Melanesians derive from Denisovans, indicating limited interbreeding in Southeast Asia.\n\nAlleles thought to have originated in Neanderthals and Denisovans have been identified at several genetic loci in the genomes of modern humans outside of Africa. HLA haplotypes from Denisovans and Neanderthal represent more than half the HLA alleles of modern Eurasians, indicating strong positive selection for these introgressed alleles. Corinne Simoneti at Vanderbilt University, in Nashville and her team have found from medical records of 28,000 people of European descent that the presence of Neanderthal DNA segments may be associated with a likelihood to suffer depression more frequently.\n\nThe flow of genes from Neanderthal populations to modern human was not all one way. Sergi Castellano of the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, has in 2016 reported that while Denisovan and Neanderthal genomes are more related to each other than they are to us, Siberian Neanderthal genomes show similarity to the modern human gene pool, more so than to European Neanderthal populations. The evidence suggests that the Neanderthal populations interbred with modern humans possibly 100,000 years ago, probably somewhere in the Near East.\n\nStudies of a Neanderthal child at Gibraltar show from brain development and teeth eruption that Neanderthal children may have matured more rapidly than is the case for Homo sapiens.\n\n\"H. floresiensis\", which lived from approximately 190,000 to 50,000 years before present, has been nicknamed \"hobbit\" for its small size, possibly a result of insular dwarfism. \"H. floresiensis\" is intriguing both for its size and its age, being an example of a recent species of the genus \"Homo\" that exhibits derived traits not shared with modern humans. In other words, \"H. floresiensis\" shares a common ancestor with modern humans, but split from the modern human lineage and followed a distinct evolutionary path. The main find was a skeleton believed to be a woman of about 30 years of age. Found in 2003, it has been dated to approximately 18,000 years old. The living woman was estimated to be one meter in height, with a brain volume of just 380 cm (considered small for a chimpanzee and less than a third of the \"H. sapiens\" average of 1400 cm). \n\nHowever, there is an ongoing debate over whether \"H. floresiensis\" is indeed a separate species. Some scientists hold that \"H. floresiensis\" was a modern \"H. sapiens\" with pathological dwarfism. This hypothesis is supported in part, because some modern humans who live on Flores, the Indonesian island where the skeleton was found, are pygmies. This, coupled with pathological dwarfism, could have resulted in a significantly diminutive human. The other major attack on \"H. floresiensis\" as a separate species is that it was found with tools only associated with \"H. sapiens\".\n\nThe hypothesis of pathological dwarfism, however, fails to explain additional anatomical features that are unlike those of modern humans (diseased or not) but much like those of ancient members of our genus. Aside from cranial features, these features include the form of bones in the wrist, forearm, shoulder, knees, and feet. Additionally, this hypothesis fails to explain the find of multiple examples of individuals with these same characteristics, indicating they were common to a large population, and not limited to one individual. \n\n\"H. sapiens\" (the adjective \"sapiens\" is Latin for \"wise\" or \"intelligent\") emerged around 300,000 years ago, likely derived from \"Homo heidelbergensis\". Between 400,000 years ago and the second interglacial period in the Middle Pleistocene, around 250,000 years ago, the trend in intra-cranial volume expansion and the elaboration of stone tool technologies developed, providing evidence for a transition from \"H. erectus\" to \"H. sapiens\". The direct evidence suggests there was a migration of \"H. erectus\" out of Africa, then a further speciation of \"H. sapiens\" from \"H. erectus\" in Africa. A subsequent migration (both within and out of Africa) eventually replaced the earlier dispersed \"H. erectus\". This migration and origin theory is usually referred to as the \"recent single-origin hypothesis\" or \"out of Africa\" theory. \n\"H. sapiens\" interbred with archaic humans both in Africa and in Eurasia, in Eurasia notably with Neanderthals and Denisovans.\n\nThe Toba catastrophe theory, which postulates a population bottleneck for \"H. sapiens\" about 70,000 years ago, was controversial from its first proposal in the 1990s and by the 2010s had very little support.\nDistinctive human genetic variability has arisen as the result of the founder effect, by archaic admixture and by recent evolutionary pressures.\n\nThe use of tools has been interpreted as a sign of intelligence, and it has been theorized that tool use may have stimulated certain aspects of human evolution, especially the continued expansion of the human brain. Paleontology has yet to explain the expansion of this organ over millions of years despite being extremely demanding in terms of energy consumption. The brain of a modern human consumes about 13 watts (260 kilocalories per day), a fifth of the body's resting power consumption. Increased tool use would allow hunting for energy-rich meat products, and would enable processing more energy-rich plant products. Researchers have suggested that early hominins were thus under evolutionary pressure to increase their capacity to create and use tools.\n\nPrecisely when early humans started to use tools is difficult to determine, because the more primitive these tools are (for example, sharp-edged stones) the more difficult it is to decide whether they are natural objects or human artifacts. There is some evidence that the australopithecines (4 Ma) may have used broken bones as tools, but this is debated.\n\nMany species make and use tools, but it is the human genus that dominates the areas of making and using more complex tools. The oldest known tools are flakes from West Turkana, Kenya, which date to 3.3 million years ago. The next oldest stone tools are from Gona, Ethiopia, and are considered the beginning of the Oldowan technology. These tools date to about 2.6 million years ago. A \"Homo\" fossil was found near some Oldowan tools, and its age was noted at 2.3 million years old, suggesting that maybe the \"Homo\" species did indeed create and use these tools. It is a possibility but does not yet represent solid evidence. The third metacarpal styloid process enables the hand bone to lock into the wrist bones, allowing for greater amounts of pressure to be applied to the wrist and hand from a grasping thumb and fingers. It allows humans the dexterity and strength to make and use complex tools. This unique anatomical feature separates humans from apes and other nonhuman primates, and is not seen in human fossils older than 1.8 million years.\n\nBernard Wood noted that \"Paranthropus\" co-existed with the early \"Homo\" species in the area of the \"Oldowan Industrial Complex\" over roughly the same span of time. Although there is no direct evidence which identifies \"Paranthropus\" as the tool makers, their anatomy lends to indirect evidence of their capabilities in this area. Most paleoanthropologists agree that the early \"Homo\" species were indeed responsible for most of the Oldowan tools found. They argue that when most of the Oldowan tools were found in association with human fossils, \"Homo\" was always present, but \"Paranthropus\" was not.\n\nIn 1994, Randall Susman used the anatomy of opposable thumbs as the basis for his argument that both the \"Homo\" and \"Paranthropus\" species were toolmakers. He compared bones and muscles of human and chimpanzee thumbs, finding that humans have 3 muscles which are lacking in chimpanzees. Humans also have thicker metacarpals with broader heads, allowing more precise grasping than the chimpanzee hand can perform. Susman posited that modern anatomy of the human opposable thumb is an evolutionary response to the requirements associated with making and handling tools and that both species were indeed toolmakers.\n\nStone tools are first attested around 2.6 Million years ago, when hominins in Eastern Africa used so-called core tools, choppers made out of round cores that had been split by simple strikes. This marks the beginning of the Paleolithic, or Old Stone Age; its end is taken to be the end of the last Ice Age, around 10,000 years ago. The Paleolithic is subdivided into the Lower Paleolithic (Early Stone Age), ending around 350,000–300,000 years ago, the Middle Paleolithic (Middle Stone Age), until 50,000–30,000 years ago, and the Upper Paleolithic, (Late Stone Age), 50,000-10,000 years ago.\n\nArchaeologists working in the Great Rift Valley in Kenya have discovered the oldest known stone tools in the world. Dated to around 3.3 million years ago, the implements are some 700,000 years older than stone tools from Ethiopia that previously held this distinction.\n\nThe period from 700,000–300,000 years ago is also known as the Acheulean, when \"H. ergaster\" (or \"erectus\") made large stone hand axes out of flint and quartzite, at first quite rough (Early Acheulian), later \"retouched\" by additional, more-subtle strikes at the sides of the flakes. After 350,000 BP the more refined so-called Levallois technique was developed, a series of consecutive strikes, by which scrapers, slicers (\"racloirs\"), needles, and flattened needles were made. Finally, after about 50,000 BP, ever more refined and specialized flint tools were made by the Neanderthals and the immigrant Cro-Magnons (knives, blades, skimmers). In this period they also started to make tools out of bone.\n\nUntil about 50,000–40,000 years ago, the use of stone tools seems to have progressed stepwise. Each phase (\"H. habilis\", \"H. ergaster\", \"H. neanderthalensis\") started at a higher level than the previous one, but after each phase started, further development was slow. Currently paleoanthropologists are debating whether these \"Homo\" species possessed some or many of the cultural and behavioral traits associated with modern humans such as language, complex symbolic thinking, technological creativity etc. It seems that they were culturally conservative maintaining simple technologies and foraging patterns over very long periods.\n\nAround 50,000 BP, modern human culture started to evolve more rapidly. The transition to behavioral modernity has been characterized by most as a Eurasian \"Great Leap Forward\", or as the \"Upper Palaeolithic Revolution\", due to the sudden appearance of distinctive signs of modern behavior and big game hunting in the archaeological record. Some other scholars consider the transition to have been more gradual, noting that some features had already appeared among archaic African \"Homo sapiens\" since 200,000 years ago. Recent evidence suggests that the Australian Aboriginal population separated from the African population 75,000 years ago, and that they made a sea journey of up to 160 km 60,000 years ago, which may diminish the evidence of the Upper Paleolithic Revolution.\n\nModern humans started burying their dead, using animal hides to make clothing, hunting with more sophisticated techniques (such as using trapping pits or driving animals off cliffs), and engaging in cave painting. As human culture advanced, different populations of humans introduced novelty to existing technologies: artifacts such as fish hooks, buttons, and bone needles show signs of variation among different populations of humans, something that had not been seen in human cultures prior to 50,000 BP. Typically, \"H. neanderthalensis\" populations do not vary in their technologies, although the Chatelperronian assemblages have been found to be Neanderthal innovations produced as a result of exposure to the Homo sapiens Aurignacian technologies.\n\nAmong concrete examples of modern human behavior, anthropologists include specialization of tools, use of jewellery and images (such as cave drawings), organization of living space, rituals (for example, burials with grave gifts), specialized hunting techniques, exploration of less hospitable geographical areas, and barter trade networks. Debate continues as to whether a \"revolution\" led to modern humans (\"the big bang of human consciousness\"), or whether the evolution was more \"gradual\".\n\nEvolution has continued in anatomically modern human populations, which are affected by both natural selection and genetic drift. Although selection pressure on some traits, such as resistance to smallpox, has decreased in modern human life, humans are still undergoing natural selection for many other traits. Some of these are due to specific environmental pressures, while others are related to lifestyle changes since the development of agriculture (10,000 years ago), urban civilization (5,000), and industrialization (250 years ago). It has been argued that human evolution has accelerated since the development of agriculture 10,000 years ago and civilization some 5,000 years ago, resulting, it is claimed, in substantial genetic differences between different current human populations.\n\nParticularly conspicuous is variation in superficial characteristics, such as Afro-textured hair, or the recent evolution of light skin and blond hair in some populations, which are attributed to differences in climate. Particularly strong selective pressures have resulted in high-altitude adaptation in humans, with different ones in different isolated populations. Studies of the genetic basis show that some developed very recently, with Tibetans evolving over 3,000 years to have high proportions of an allele of EPAS1 that is adaptive to high altitudes.\n\nOther evolution is related to endemic diseases: the presence of malaria selected for sickle cell trait (the heterozygote form of sickle cell gene), while the absence of malaria and the health effects of sickle-cell anemia select against this trait. For example, the population at risk of the severe debilitating disease kuru has significant over-representation of an immune variant of the prion protein gene G127V versus non-immune alleles. The frequency of this genetic variant is due to the survival of immune persons.\n\nRecent human evolution related to agriculture includes genetic resistance to infectious disease that has appeared in human populations by crossing the species barrier from domesticated animals, as well as changes in metabolism due to changes in diet, such as lactase persistence.\n\nIn contemporary times, since industrialization, some trends have been observed: for instance, menopause is evolving to occur later. Other reported trends appear to include lengthening of the human reproductive period and reduction in cholesterol levels, blood glucose and blood pressure in some populations.<ref name=\"doi10.1073/pnas.0906199106\"></ref>\n\nThis list is in chronological order across the table by genus. Some species/subspecies names are well-established, and some are less established – especially in genus \"Homo\". Please see articles for more information.\n\n\n"}
{"id": "22771176", "url": "https://en.wikipedia.org/wiki?curid=22771176", "title": "Islamic views on sin", "text": "Islamic views on sin\n\nSin is an important concept in Islamic ethics. Muslims see sin as anything that goes against the commands of Allah (God), a breach of the laws and norms laid down by religion. Islam teaches that sin is an act and not a state of being. It is believed that Allah weighs an individual’s good deeds and against his or her sins on the Day of Judgement and punishes those individuals whose evil deeds outweigh their good deeds. These individuals are thought to be sentenced to afterlife in the fires of جهنم jahannam (Hell).\n\nThe Quran describes these sins throughout the text and demonstrates that some sins are more punishable than others. A clear distinction is made between major and minor sins (53:31–32), indicating that if an individual stays away from the major sins, then he/she will be forgiven of the minor sins. Regardless, Islam teaches that God is merciful and individuals can be forgiven of their sins if they repent.\n\nSources differ on the exact meanings of the different terms for sin used in the Islamic tradition.\n\nA number of different words for sin are used in the Islamic tradition.\n\nAccording to A.J. Wensinck's entry in the Encyclopedia of Islam, Islamic terms for sin include \"dhanb\" and \"khaṭīʾa\", which are synonymous and refer to intentional sins; \"khiṭʾ\", which means simply a sin; and \"ithm\", which is used for grave sins.\n\nAccording to Cyril Glasse, Islam recognizes two kinds of sin (\"khati'ah\"): \"dhanb\", a fault or shortcoming which is to be sanctioned; and \"ithm\", a willful transgression which is to be punished.\n\nSeveral different words are used in the Quran to describe sin—1) \"Dhanb\" 2) \"Ithm\" 3) \"Khati’ah\" 4) \"Jurm\" 5) \"Junah/Haraj\". By examining the choice of words in Quranic verses used in connection with these terms, scholars have attempted to determine which sins are associated with which terms.\n\n\"Dhanb\" (plural \"dhunub\") is frequently applied to heinous sins committed against God. One of the main examples of \"Dhanb\" in the Quran is of “crying lies of God’s signs”, or having excessive pride that prevents an individual from believing the signs of God.\n\nThis use of \"dhanb\" in the Quran exemplifies that this type of sin is punishable in the afterlife. In fact, \"dhanb\" is considered a ‘great’ sin and is often used in the Quran to contrast with \"sayyi’a\", which denotes a ‘smaller’ sin. The Quran states that if you avoid these great sins, your lesser evil deeds or sayyi’at will be forgiven.\n\nSome scholars believe the basic meaning of \"ithm\" to be an unlawful deed that is committed intentionally. This contrasts to \"dhanb\" in that \"dhanb\" can be both intentional and unintentional. However, this definition is somewhat nebulous and the best description of the word is based on the contextual situations. In the Quran, i\"thm\" is found quite frequently in legislative descriptions. For example, falsely accusing your own wife in order to gain money is constituted as an \"ithm\" (Quran 4: 24/20). However, \"ithm\" is also used in connection with \"haram\", or committing an unlawful deed, a taboo, such as consuming food or drink that is forbidden by God:\n\n\"Ithm\" is also associated with what is considered the worst sin of all, \"shirk\". \"Shirk\" signifies the accepting of a presence of other divinities at the side of God. The Quran states that:\n\nThis association with \"shirk\" is noteworthy for \"shirk\" is considered unforgivable if not repented of.\n\n\"Khati’ah\" is considered by many scholars to be a “moral lapse” or a “mistake” This interpretation has led some scholars to believe that \"Khati’ah\" is a lesser sin than ithm; however, the word \"Khati’ah\" is frequently used in conjunction with \"ithm\" in the Quran.\n\nThis Quranic verse indicates that \"khati’ah\" is considered an \"ithm\", a grave sin. In fact, the word \"khati’ah\" is associated with some of the most heinous religious sins in the Quran. In one Quranic verse this word is used to describe the sin of slaying one’s own children for fear of poverty. (Quran 17:33/31). Scholars believe that \"dhanb\" or \"ithm\" could be used in place of \"khati’ah\" in this instance; however, the word choice indicates that \"khati’ah\" is more than just a moral lapse or mistake and is punishable.\n\nThe word \"Jurum\" is often considered to be a synonym of dhanb for it is used to describe some of the same sins: crying lies of God and not believing the signs of God. In the Quran, the word mostly appears in the form of \"mujrim\", one who commits a \"jurm\". These individuals are described in the Quran as having arrogance towards the believers.\n\n\"Junah\" and \"Haraj\" have a similar meaning to that of \"ithm\", a sin that warrants a punishment. In fact, these words are used almost interchangeably with \"ithm\" in the same chapters in the Quran. Like \"ithm\", these words are found frequently in legislative portions of the Quran, particularly relating to regulations regarding marriage and divorce.\n\nSin is discussed extensively in the hadith, (the collection of Muhammad's sayings). It is reported by An-Nawwas bin Sam'an: \nWabisah bin Ma’bad reported: \nIn Sunan al-Tirmidhi, a Hadith is narrated:\nIn Sahih Muslim, Abu Ayyub al-Ansari and Abu Huraira narrated:\n\nThe effects of sins are so many to the extent that they are uncountable. Yet some of the effects are:\n\nThere are some sins which its ill-consequences were stated in the Qur'an and hadith, we shall quote some of them here: \n\nAccording to Islam, one can be forgiven of sins through genuine \"tawbah\" (repentance) which literally means \"to return.\"\n\nUnlike the Catholic concept of atonement, \"tawbah\" does not entail formal, eccelesiastical confession to a religious leader. Like Protestantism, Islam allows followers to repent directly to God. In addition, while Christianity and Islam considers humans as prone to sin, Islam ultimately views them as responsible for their actions and refutes the Christian concept of original sin.\n\nMore so, in Islam Muslims are discouraged from confessing their sins and sharing the wrongdoings of others.\nAlso, according to Islam, Blood sacrifice cannot add to Divine Grace nor replace the necessity of repentance. However, sacrifice is done to help the poor and to remember Abraham’s willingness to sacrifice his son at God's command.\nWhen a human has violated another human’s rights, ḥuqūq al-ʿibād, compensation is necessary in order to show that one has made amends.\n\nWhen a human has offended or disobeyed God, ḥuqūq Allāh, penitence, remorse, and resolution are necessary in order to show that one is sincere, and will not repeat the wrongdoing in the future.\n\nAccording to Shaddad ibn Aws:\nFrom a traditionalist perspective, sin is applied to an individual’s actions. Through belief and good works, an individual can remove his/her sin and attain God’s good favor. \nClassical legal scholar Muhammad al-Shafi'i (767 – 820) derived this understanding from Quranic passages such as:\n\nFrom a modernist perspective, sin has also been applied to a group or community’s collective behavior. Through public acknowledgement of wrongdoing, people can take responsibility for the lack of morality within their society and enact social reform. Egyptian reformer Muḥammad ʿAbduh (1849–1905) and his disciple Muḥammad Rashīd Ridā (1865–1935) derived this understanding from Quranic passages such as:\n\nOther modern reformers, such as Sayyid Qutb, held that repentance involved a renewed, holistic commitment to Islam, rather than admission of sin for the sake of being pardoned of punishment. This understanding draws from classical Sufi thought, whereby one experiences a personality transformation and his/her sinful impulses are replaced by virtue. Qutb derived this understanding from Quranic passages such as:\n\nRepentance for sin can be accomplished through acts such as, “fasting, giving charity, sacrificing an animal, and freeing a slave.” In addition, going on the hajj can serve as a form of repentance.\n\nAccording to Shaddad ibn Aws:\nHowever, regardless of one's outward deeds, God does not accept the forgiveness of those who are insincere in their repentance and only do so in order to avoid jahannam.\n\nThe most heinous sins in Islam are known as Al-Kabirah () which translates to the great or major one. Some authors use the term enormity. While every sin is seen as an offense to Allah, the al-Kaba'ir are the gravest of the offenses. Allah’s power is thought to be only eclipsed by his mercy and thus small sins are tacitly understood to be forgiven after repentance. Not every sin is equal however and some are thought to be more spiritually damning than others. The greatest of the sins described as al-Kaba'ir is the association of others with Allah or Shirk. Scholar differ as to how many major sins there are.\nIn contrasting major sins with minor sins (\"al-sagha'ir\"), the eighth-century Shafi'i scholar Al-Dhahabi found the hadith collections of Sahih al-Bukhari and Muslim ibn al-Hajjaj listed seven major sins, while the tradition from Abd Allah ibn Abbas stated that there were closer to seventy major sins.\nSome of the major or al-Kaba'ir sins in Islam are as follows:\n\n\nIt should be noted that these are only the opinion of particular scholars and do not wholly represent Islam.\n\nAlthough many of the ideas for what is unacceptable overlap, the seven major sins of Islam differs from the seven deadly sins of Christianity. The Islamic sins refer more to specific undesirable behavior rather than to the general negative characteristics or actions of the cardinal Christian sins. Despite the similar names, the seven main sins in Islam are more comparable to the Ten Commandments rather than the seven deadly sins. They both provide the bottom line for believers in terms of what is acceptable behavior in the faith. The actions themselves differ most of the major crimes in Islam relate to subservience to Allah. Any form of polytheism is seen to be the most severe offense in the religion and all of the other transgressions are in some form of association with Allah. Witchcraft, for example, is the taking on of supernatural powers in order to make the practitioner a being above the normal human. This challenges the power of Allah as the person in question has superseded their mortal position to become something greater and akin to a god. The same can be said of murder, as ultimately the power to decide who shall live and die is believed to belong solely to Allah. Life is thought to be a gift from Allah and the unjust taking of life is a severe spiritual offense, as it is not only seen as morally wrong but also as an affront to God.\n\nIn addition to what Muslim scholars agree are the principal seven sins, the idea exists that the major sins extend far past the seven. These additional transgressions, potentially up to seventy, are not universally settled upon nor are they explicitly stated in the Qur'an, however they are thought to be implied by the text. The supplementary sins as a whole lack the spiritual gravity of the original seven and include things such as drinking alcohol and eavesdropping.\n\n"}
{"id": "677361", "url": "https://en.wikipedia.org/wiki?curid=677361", "title": "James Beckwourth", "text": "James Beckwourth\n\nJames Pierson Beckwourth, born James Beckwith and generally known as, Jim Beckwourth (April 26, 1798 or 1800 – October 29, 1866 or 1867) was an American mountain man, fur trader, and explorer. James was also famously known as \"Bloody Arm\" because of his skill as a fighter. He was mixed-race and born into slavery in Virginia, he was freed by his father (and master) and apprenticed to a blacksmith. As a young man, he moved to the American West first making connections with fur traders in St. Louis, Missouri. As a fur trapper, he lived with the Crow Nation for years. He is credited with the discovery of Beckwourth Pass, through the Sierra Nevada (U.S.) Mountains, between present-day Reno, Nevada, and Portola, California, during the California Gold Rush years, and improved the Beckwourth Trail, which thousands of settlers followed to central California.\n\nHe narrated his life story to Thomas D. Bonner, an itinerant justice of the peace. The book was published in New York City and London in 1856 as \"The Life and Adventures of James P. Beckwourth: Mountaineer, Scout and Pioneer, and Chief of the Crow Nation of Indians\". A translation was published in France in 1860.\n\nEarly historians of the Old West originally considered the book little more than campfire lore. It has since been reassessed as a valuable source of social history, especially for life among the Crow, although not all its details are reliable or accurate. The civil rights movement of the 1960s celebrated Beckwourth as an early African-American pioneer. He has since been featured as a role model in children's literature and textbooks.\n\nJames was born into slavery in Frederick County, Virginia, but sources differ as to the year: 1798 or 1800. Being born of mixed race, he had a mother who was an enslaved African-American woman, and a white father who was their master, Sir Jennings Beckwith, a descendant of Irish and English nobility. Little was known about Beckwourth's mother, but James was said to be third of her thirteen children. When James was a boy, his father arranged to apprentice him to a blacksmith so that he could learn a good trade. He acknowledged James as his son. Beckwourth was apprenticed to a blacksmith until age 19 to learn a trade. James was fired by the artisan after getting into an argument with him.\n\nJennings Beckwith moved to Missouri around 1809, when James was young, taking his mother and all their children with him. Although Beckwith raised his mixed-race children as his own, he legally held them as master. He freed James Beckworth by manumission, by deed of emancipation in court in 1824, 1825, and 1826. The young Beckwourth, as he later came to spell his surname, attended school in St. Louis for four years. When and why James changed his name to Beckwourth is unknown.\n\nIn 1824 as a young man, Beckwourth joined Gen. William Ashley's Rocky Mountain Fur Company, as a wrangler on Ashley's expedition to explore the Rocky Mountains. In the following years, Beckwourth became known as a prominent trapper and mountain man. He worked with the Rocky Mountain Fur Company and was an Indian fighter. He was well known for telling tales about his adventures.\n\nIn July 1825, rendezvous, trapper and colleague Caleb Greenwood told the campfire story of Beckwourth's being the child of a Crow chief. He claimed Beckwourth had been stolen as a baby by raiding Cheyenne and sold to whites. This lore was widely believed, as Beckwourth had adopted Native American dress and was taken by some people as an Indian.\nLater that year, Beckwourth claimed to have been captured by Crow Indians while trapping in the border county between the territories of Crow, Cheyenne, and Blackfoot. According to his account, he was mistaken for the lost son of a Crow chief, so they admitted him to the nation. Independent accounts suggest his stay with the Crow was planned by the Rocky Mountain Fur Company to advance its trade with the tribe. Beckwourth married the daughter of a chief, and may have had multiple wives. (Marriages between Native Americans and fur trappers and traders were common for the valuable alliances they provided both parties.)\n\nFor the next eight to nine years, Beckwourth lived with a Crow band. He rose in their society from warrior to chief (a respected man) and leader of the \"Dog Clan\". According to his book, he eventually ascended to the highest-ranking war chief of the Crow Nation. He still trapped but did not sell his or Crow furs to his former partners of the Rocky Mountain Fur Company. Instead, he sold to John Jacob Astor's competing American Fur Company. Beckwourth participated in raids by the Crow on neighboring nations and the occasional white party. Sometimes such raids escalated to warfare, most often against bands of their traditional Blackfoot enemy.\n\nIn 1837, when the American Fur Company did not renew his contract, Beckwourth returned to St. Louis. He volunteered with the United States Army to fight in the Second Seminole War in Florida. In his book, he claimed to have been a soldier and courier. According to historical records, he was a civilian wagon master in the baggage division.\n\nFrom 1838 to 1840, Beckwourth was an Indian trader against the Cheyenne, on the Arkansas River, working out of Fort Vasquez, Colorado, near Platteville. In 1840, he moved to the Bent & St. Vrain Company (the Bent brothers built Fort Bent on the Arkansas River). Later that same year, Beckwourth became an independent trader. Together with other partners, he built a trading post in Colorado. It was the center of development of the community of Pueblo, Colorado.\n\nIn 1844, Beckwourth traded on the Old Spanish Trail between the Arkansas River and California, then controlled by Mexico. When the Mexican–American War began in 1846, Beckwourth returned to the United States. He brought along nearly 1,800 stolen Mexican horses, as spoils of war. In the war, he served as a courier with the US Army and helped suppress the Taos Revolt. His former employer, Charles Bent, then interim governor of New Mexico, was slain in that revolt.\n\nBy 1848 and the start of the Gold Rush, Beckwourth went to California. He opened a store at Sonoma, but he soon sold up and went to Sacramento, then a boomtown close to the mines, to live as a professional card player.\n\nIn 1850, Beckwourth was credited with discovering what came to be called Beckwourth Pass, a low-elevation pass through the Sierra Nevada Mountain chain. In 1851, he improved what became the Beckwourth Trail, originally a Native American path through the mountains. It began near Pyramid Lake and the Truckee Meadows east of the mountains, climbed to the pass named for him, and went along a ridge, between two forks of Feather River, before passing down through the gold fields of northern California, and on to Marysville. The trail spared the settlers and gold seekers, about and several steep grades and dangerous passes, such as Donner Pass.\n\nBy his account, the business communities of the gold towns in California were supposed to fund the making of the trail. However, when Beckwourth tried to collect his payment in 1851 after leading a party through, Marysville had suffered from two huge fires and town leaders were unable to pay. (In 1996, in recognition of his contribution to the city's development and of the outstanding debt to him, the City of Marysville officially renamed the town's largest park Beckwourth Riverfront Park.)\n\nBeckwourth began ranching in the Sierra. His ranch, trading post and hotel, in today's Sierra Valley, were the starting of the settlement of Beckwourth, California. In the winter of 1854/55, the itinerant judge, Thomas D. Bonner stayed in the hotel, and on winter nights Beckwourth told him his life story. Bonner wrote it down, edited the material the following year, and offered the book to Harper & Brothers in New York. \"The Life and Adventures of James P. Beckwourth\" was published in 1856. According to the contract, Beckwourth was entitled to one half of the proceeds, but he never received any income from Bonner.\n\nIn 1859, Beckwourth returned to Missouri briefly, but settled later, that year in Denver, Colorado Territory. He was a storekeeper and was appointed as local agent for Indian affairs. In 1864, Beckwourth was hired as a scout, by Colonel John M. Chivington, commander of the 3rd Colorado Cavalry Regiment for a campaign against the Cheyenne and Apache leading a frontier para-military volunteer militia formed to annihilate hostile Indian resistance in the Territory and eliminate future attacks against American settlers. The Colorado Territory campaign resulted in the Sand Creek Massacre, in which the hostile militia killed an estimated 70-163 friendly Cheyenne men, women and children, who had camped in an area suggested by the previous commander of Fort Lyon as a safe place and flying an American flag to show their peaceful intentions. Outraged by his association with the massacre, the Cheyenne banned Beckwourth from trading with them. Well into his 60s by then, Beckwourth returned to trapping. In 1866 during Red Cloud's War the U.S. Army also employed him as a scout at Fort Laramie and Fort Phil Kearny.\n\nWhile guiding a military column to a Crow band in Montana, James Beckwourth complained of severe headaches and suffered nosebleeds, most probably the result of a severe case of hypertension. He returned to the Crow village, where he died on October 29, 1866, with unstoppable nose bleeding. William Byers, a personal friend and the founder of the \"Rocky Mountain News\", claimed the Crow had poisoned Beckwourth, as the tribe felt they could not trust him because of his involvement in the Sand Creek Massacre. However, Byers had no supporting evidence, which made the claim pure speculation. James Beckwourth died in Denver, Colorado Territory, now present-day Denver, Colorado. Beckwourth was left to the elements elevated on a platform in the traditional funerary custom of the Crow Tribe at the Crow Indian Settlement Burial Ground, Laramie, Albany County, Wyoming.\n\nAt different times, Beckwourth had married at least four women: two Native Americans, an Hispanic, and an African American. He had numerous children by them, although he spent most of his time on the move exploring and trapping beaver and bear.\n\nBeckwourth recounted his life history to Thomas D. Bonner, who wrote the book \"The Life and Adventures of James P. Beckwourth: Mountaineer, Scout, Pioneer and Chief of the Crow Nation\". Beckwourth's language and style (as written by Bonner) were as notable as the reported adventures. The book provides historical information on how US government officials used alcohol; how occupations affect those who work in the field; the historical relationship among diseases, wildlife, and the environment; as well as reports dealing with massacres and war.\n\nJim Beckwourth, who knew, said that though the Indian could never become a white man, the white man lapsed easily into an Indian.\n\nIn the James Michener 1978 NBC television miniseries \"Centennial\" Jim Beckworth appears briefly being portrayed by actor Carl Franklin. In the 2015 film \"The Revenant\", an unnamed African-American is depicted, as part of Ashley's 100. Since the chronology of events in the life of Hugh Glass was changed slightly for the film, it is unclear if the African-American shown was intended to be James Beckwourth, Edward Rose, a lesser known black mountain man, or simply a representation of the wider acceptance and equality of blacks on the western frontier that gave rise to historical figures like Beckwourth. Hugh Glass' legendary return, after being abandoned and left for dead, occurred in 1823, and Beckwourth did not join the expedition until 1824. However, there was an intervening period of time, between the return of Glass and his confrontation with Bridger and Fitzgerald, that did occur subsequent to 1824, that was changed in the film for the sake of brevity.\n\n\n\n\n"}
{"id": "55534194", "url": "https://en.wikipedia.org/wiki?curid=55534194", "title": "James Felton Keith", "text": "James Felton Keith\n\nJames Felton Keith (born September 25, 1981, in Detroit, Michigan) commonly referred to by his initials JFK, is an American engineer, author, and serial entrepreneur. James was the first African-American representative of the LGBT community to run for United States House of Representatives in New York's 13th congressional district. Keith incubated and founded many companies including the conference Personal Data Week, FinTech analytics firm \"Accrue.com\", the Detroit Regional LGBT Chamber of Commerce, and the TV network Slay TV. He was one of the earliest advocates for individual ownership of personal data, and the economic value of it.\n\nKeith defined '\"personal data\" as a micro-personalized form of big data while searching for a mechanism to measure the value of people's contribution to the productivity of their surrounding society. He is noted saying that his wildest dream would be \"Americans are now making trade-offs for personhood, not privacy. In the land of the free, we have to ask the question, who owns us?\" His 2017 book on personal data \"The People's Asset class\" was a collection of essays built on the premise that: \"value is like that of energy. It cannot be created nor destroyed, but can change form.\"\n\nOn the notion that personal data is a natural resource, Keith founded the International Personal Data Trade Association and produced the conference series Personal Data Week. When interviewed by the British data industry paper \"Internet Of Me\", Keith elaborated on thoughts about human value measured by data: \"I'm not necessarily as concerned about control over my data as much as I am of having the right to have some agency over its cumulative value and the right to retaliate when I think my data is being used in inequitable or unethical ways.\"\n\nIn 2013 he established the Keith Institute with the objective of establishing economic and educational inclusion alongside his sister Kharena Keith Coleman, an educator and researcher. The institute is used to divide his economic and education work. Keith has founded multiple social and for-profit enterprises that still exist after his exit. During public talks on entrepreneurship he frequently says that \"all problems are distribution problems\", when explaining how we should think about solutions to those problems. He has spent what he calls his second career, building enterprises that deliver economic resources to the people in the most need.\n\nA economic activist, he is responsible for the first LGBT Pride games in all four major professional sports leagues in the United States and Canada. During the first pride night at an NFL franchise, he was noted to have engaged the \"great equalizer\" for LGBT rights in the same way civil rights era activists engaged the business of professional sports. Keith implemented what he calls \"economic activism as CEO of Detroit Regional LGBT Chamber of Commerce an affiliate of the National LGBT Chamber of Commerce while advocating to include the \"B\" and \"T\" in the LGBT chamber to represent bisexual community members. Keith alleged that he was fired from the Mayor of Detroit Mike Duggan's cabinet for building the chamber of commerce.\n\nIn 2015 he cofounded Slay TV with Sean Torrington and Terry Torrington, and it is the primary digital television destination content from Queer people of color. In 2016 he founded the Personal Data Week conference via the International Personal Data Trade Association to explore data as a natural resource among all corporate productivity.\n\n\n"}
{"id": "11119607", "url": "https://en.wikipedia.org/wiki?curid=11119607", "title": "John Beverley (Latin Americanist)", "text": "John Beverley (Latin Americanist)\n\nJohn Randolph Beverley II is a literary and cultural critic at the University of Pittsburgh, where he is a professor of Spanish and Latin American Literature and Cultural Studies as well as an adjunct professor in the English and communication departments. He was influential in co-founding the Latin American subaltern studies group as well as a founding member of the Graduate Program in Cultural Studies at the University of Pittsburgh.\n\nHe is a U.S.-based Latin Americanist cultural and literary theorist. In his work he is committed to revolutionary changes that would end the differences between rich and poor in Latin America and make a new and revolutionary democratic culture corresponding to the people’s economic and political democratic revolutions. He has a dual emphasis on democracy and the people—-the workers, the masses, \"los de abajo\", the multitude, and what he designates the subalter.\n\nBorn into a prosperous Anglo American family residing in South America, he became sensitive to the poverty and misery in which so many lived even as he had all the benefits of his class and caste. In this sense, his life goal has been to negate such differences. As a non-Hispanic student of Spanish literature, he gradually turned to Latin American themes, within larger contexts. At Princeton and then at the University of California, San Diego, he focused on Spanish Peninsular literature of Américo Castro, Carlos Blanco Aguinaga, and Claudio Guillén; and studied Fredric Jameson who was developing methods for a Marxist approach to cultural and literary phenomena. He published a Marxist interpretation of Gongora’s \"Soledades\" as his dissertation and first book. \n\nThe center of his interests shifted from Spain to Latin America, impelled by the political hopes of the 1960s and 1970s. He sought the application of his understanding of the Baroque to the development and structural situation of literature as a colonial and postcolonial institutions in the Americas. As a self-proclaimed Marxist and activist, he developed his literary work in relation to the Institute of Ideologies and Literatures in Minnesota, seeking to find progressive dimensions of literature and criticism that transcended state-centered powers of structure. That effort culminated in his \"Del Lazarillo a Sandinismo\" and his book with Marc Zimmerman, \"Literature and Politics in the Central American Revolutions\". \n\nBeverley has written a number of texts on the \"testimonio\", which can concern popular representation in literature and politics. He has taken the position that Latin America’s own ideological structures have prevented the area's most progressive intellectuals from grasping their own reality. With the end of the cold war, the defeat of the Sandinistas and the full emergence of postmodern perspectives in Latin Americanist discourse, he produced a collection entitled \"The Post-Modern Debate in Latin America\". While working on that text, he along with Ileana Rodríguez and others, co-founded the Latin American Subaltern Studies group, seeking a new post-cold war/post-sandinista post/postmodedrn theorization of the relations between culture, literature and political possibility, which he and other members (following Ernesto Laclau and others involved in cultural studies theory, but above all the South Asian Subaltern studies Group—at first through Gayatri Spivack and then more directly through R. Guha and others) saw as centered not directly on social classes but on the social groups and movements that struggled for empowerment and expression in the Americas. \n\nIn \"Against Literature\", he writes from a subalternist perspective, and considers literature and existing literary studies (even leftwing versions) as implicated in hegemonic modernization projects at odds with subaltern positions. This view, now developed in relation to developing Latin American cultural studies discourse and in relation to the full emergence of globalization as the new macro-narrative of the post-postmodern period, became the subject of \"Subalternity and Representation\" (1999). The Latin American subaltern group dissolved early in the 21st century, but Beverley has continued working, co-developing a Pittsburgh University Press book series called “Illuminations: Cultural Formations of the Americas,” publishing a new collection on Cuban literature, re-publishing his book with Hugo Achugar on \"testimonio\", and completing \"Testimonio: The Politics of Truth\" (2004). In \"Latin Americanism after 9/11\" (2014), he argues for a new situation for Latin America in the emerging global order, especially in view of Hugo Chávez, Evo Morales and other new left figures who have challenged older paradigms of left and right of previous decades. He critiques what he considers the failed politics of Zapatismo, and the “neo-conservative turn.” \n\n"}
{"id": "6461907", "url": "https://en.wikipedia.org/wiki?curid=6461907", "title": "Khertvisi", "text": "Khertvisi\n\nKhertvisi fortress () is one of the oldest fortresses in Georgia and was functional throughout the Georgian feudal period. It is situated in Southern Georgia, in Meskheti region. The fortress was first built in the 2nd century BC. The church was built in 985, and the present walls were built in 1354. As the legend says, Khertvisi was destroyed by Alexander the Great.\n\nIn the 10th-11th centuries it was the center of Meskheti region. During the 12th century it became a town. In the 13th century Mongols destroyed it and until the 15th century it lost its power. In the 15th century it was owned by Meskheti landlords from Jakeli family. In the 16th century the southern region of Georgia was invaded by Turks. During next 300 years they have owned Khertvisi too.\n\nAt the end of the 19th century Georgian and Russian army returned the lost territories and Khertvisi became the military base for Russian and Georgian troops. Khertvisi fortress is situated on the high rocky hill in the narrow canyon at the confluence of the Mtkvari and Paravani Rivers.\n\n"}
{"id": "639239", "url": "https://en.wikipedia.org/wiki?curid=639239", "title": "Langdale axe industry", "text": "Langdale axe industry\n\nThe Langdale axe industry is the name given by archaeologists to specialised stone tool manufacturing centred at Great Langdale in England's Lake District during the Neolithic period (beginning about 4000 BC in Britain). The existence of a production site was originally suggested by chance discoveries in the 1930s, which were followed by more systematic searching in the 1940s and 1950s by Clare Fell and others. The finds were mainly reject axes, rough-outs and blades created by knapping large lumps of the rock found in the scree or perhaps by simple quarrying or opencast mining. Hammerstones have also been found in the scree and other lithic debitage from the industry such as blades and flakes.\n\nThe area has outcrops of fine-grained greenstone or hornstone suitable for making polished stone axes. Such axes have been found distributed across Great Britain. The rock is an epidotised greenstone quarried or perhaps just collected from the scree slopes in the Langdale Valley on Harrison Stickle and Pike of Stickle. The nature and extent of the axe-flaking sites making up the Langdale Axe Factory complex are still under investigation.\nGeological mapping has established that the volcanic tuff used for the axes outcrops along a narrow range of the highest peaks in the locality. Other outcrops in the area are known to have been worked, especially on Harrison Stickle, and Scafell Pike where rough-outs and flakes have been found on platforms below the peaks at and above the 2000- or 3000-foot level.\n\nArchaeologists are able to identify the unique nature of the Langdale stone by taking sections and examining them using microscopy. The minerals in the rock have a characteristic pattern, using a method known as petrography. They have been able to reconstruct the production methods and trade patterns employed by the axe makers. The Langdale industry produced roughly hewn (or so-called \"rough-outs\") axes and simple blocks. The highly polished final product were usually made elsewhere, such as at Ehenside tarn in the western fringes of the Lake District, and all were traded on throughout Britain and Ireland. The Langdale tuff was among the most common of the various rocks used to make axes in the Neolithic period, and are known as Group VI axes. Flint was also commonly used to make polished axes, and mined at several places, but especially at Grimes Graves and Cissbury, and in continental Europe at Spiennes in Belgium, and Krzemionki in Poland.\n\nPolishing the rough surfaces will have improved the mechanical strength of the axe as well as lowering friction when used against wood. Fractures occur more easily in brittle materials like stone when rough owing to the stress concentrations present at sharp corners, holes and other defects in the axe surface. Removing those defects by polishing makes the axe much stronger, and able to withstand impact and shock loads from use. Sandstone was usually used for polishing axes, and whetstones have been found nearby at Ehenside tarn, for example where the rough-outs were polished. Large fixed outcrops were also widely used for polishing, and there are numerous examples across Europe, but relatively few in Britain. That at Fyfield Down near Avebury is an exception, but there must be many more awaiting discovery and publication.\n\nThe stone axes from Langdale have been found at archaeological sites across Britain and Ireland. An unusual concentration of finds occurs in the East of England, particularly Lincolnshire. Francis Pryor attributes this to these axes being particularly valued in this region. He mentions possible religious significance of the axes, perhaps related to the high peaks from which they came. He compares this with confirmed Neolithic flint mines which, apart from Grimes Graves (where flint of exceptionally high quality was mined), were all at prominent elevated locations.\n\nOf all the Neolithic polished stone axes that have been examined in the UK, around 27% come from the Langdale region. This is notable considering there were over 30 sources of material for stone axes from Cornwall to northern Scotland and Ireland.\n\nWhether religious objects or not, the axes must have been of high value, given that they have been \"traded\" so widely. Some axes appear worn whilst others appear unused, again implying that they were regarded as sacred objects or, perhaps, simply as a display of visible wealth. Some though were used as practical tools. The shape of the polished axes suggests that they were bound in wooden staves and used for forest clearance.\n\nFrancis Pryor discusses a flint axe that he found north of Peterborough with fantastic swirling patterns that had been brought out by polishing – but this axe was totally impractical as the patterns were fault lines, making the flint very fragile. However, it must have been valued by its owner and/or maker, bearing in mind the work involved in making it. These facts suggest various interpretations of the purpose of the Langdale axes, which were both beautiful and practical, as well as being traded many miles from their place of production.\n\nThe Langdale industry was one of many which extracted hard stone for manufacture into polished axes. The Neolithic period was a time of settlement on the land, and the development of farming on a large scale. Maintenance of the forest cover was necessary in order to plant crops and rear animals, so axes were a staple tool, not just for clearance but also for wood working timber for houses, boats and other structures. Flint was probably the most widely used, simply because it was available from numerous flint mines in the downlands, such as Grimes Graves, Cissbury and Spiennes. Blades from roughing-out from flint and chert could also be used as small knives, arrowheads and other small sharp tools such as burins and awls.\n\nBut other hard and tough stones were used, such as igneous rocks from Penmaenmawr in North Wales, and similar working areas to Langdale have been found there. Many other locations for production of axes have been suggested (but not always found) across the country including Tievebulliagh in County Antrim, sites in Cornwall, Scotland and the Charnwood Forest in Leicestershire. It is also likely that bluestone axes were exported from the Preseli hills in Pembrokeshire. The industry was also widely developed elsewhere in the world, such as in Australia at Mount William stone axe quarry which used a similar rock until relatively recent times.\nThe variety of rocks used in polished tools and other artefacts is evident in museum collections, not all of the sources of the rocks having been positively identified. Taking sections is necessarily destructive of part of the artefact, and thus discouraged by many museums. Likewise, the rocks or anvils used to polish the axes are rare in Britain but common in France and Sweden.\n\nRadiocarbon dating at the Langdale stone axe factory site suggests that it was in operation for about 1,000 years during the Neolithic period.\n\nCurrent thinking links the manufacturers of the axes to some of the first Neolithic stone circles such as that at Castlerigg.\n\nThe altitude and rough terrain of the archaeological sites have protected them from types of damage caused by human settlement in lowland areas. However, Great Langdale is much visited by walkers. People have removed axes (although current thinking is that they should be left in situ) and have caused inadvertent damage to stone scatters by walking. \n\nAn attempt to schedule the sites as ancient monuments in the 1980s was thwarted by the lack of reliable mapping. However, English Heritage has been considering questions on how the sites should be managed. Particular attention has been paid to the siting of footpaths to avoid damage to axeworking sites. \nSince the 1990s eroded paths in the Lake District, including Great Langdale, have been repaired by a \"Fix the Fells\" project in which the National Trust is the major partner.\n\nLangdale axes are displayed in Cumbria at Kendal Museum and Tullie House Museum and Art Gallery, Carlisle, and in other collections such as the British Museum.\n\n\n\n"}
{"id": "130918", "url": "https://en.wikipedia.org/wiki?curid=130918", "title": "Leadership", "text": "Leadership\n\nLeadership is both a research area and a practical skill encompassing the ability of an individual or organization to \"lead\" or guide other individuals, teams, or entire organizations. Specialist literature debates various viewpoints, contrasting Eastern and Western approaches to leadership, and also (within the West) United States versus European approaches. U.S. academic environments define leadership as \"a process of social influence in which a person can enlist the aid and support of others in the accomplishment of a common task\".\n\nStudies of leadership have produced theories involving traits, situational interaction, function, behavior, power, vision and values, charisma, and intelligence, among others.\n\nSanskrit literature identifies ten types of leaders. Defining characteristics of the ten types of leaders are explained with examples from history and mythology.\n\nAristocratic thinkers have postulated that leadership depends on one's \"blue blood\" or genes. Monarchy takes an extreme view of the same idea, and may prop up its assertions against the claims of mere aristocrats by invoking divine sanction (see the divine right of kings). Contrariwise, more democratically inclined theorists have pointed to examples of meritocratic leaders, such as the Napoleonic marshals profiting from careers open to talent.\n\nIn the autocratic/paternalistic strain of thought, traditionalists recall the role of leadership of the Roman \"pater familias\". Feminist thinking, on the other hand, may object to such models as patriarchal and posit against them emotionally attuned, responsive, and consensual empathetic guidance, which is sometimes associated with matriarchies.\n\nComparable to the Roman tradition, the views of Confucianism on \"right living\" relate very much to the ideal of the (male) scholar-leader and his benevolent rule, buttressed by a tradition of filial piety.\nLeadership is a matter of intelligence, trustworthiness, humaneness, courage, and discipline ... Reliance on intelligence alone results in rebelliousness. Exercise of humaneness alone results in weakness. Fixation on trust results in folly. Dependence on the strength of courage results in violence. Excessive discipline and sternness in command result in cruelty. When one has all five virtues together, each appropriate to its function, then one can be a leader. — Sun Tzu\nMachiavelli's \"The Prince\", written in the early 16th century, provided a manual for rulers (\"princes\" or \"tyrants\" in Machiavelli's terminology) to gain and keep power.In the 19th century the elaboration of anarchist thought called the whole concept of leadership into question. (Note that the \"Oxford English Dictionary\" traces the word \"leadership\" in English only as far back as the 19th century.) One response to this denial of élitism came with Leninism, which demanded an élite group of disciplined cadres to act as the vanguard of a socialist revolution, bringing into existence the dictatorship of the proletariat.\n\nOther historical views of leadership have addressed the seeming contrasts between secular and religious leadership. The doctrines of Caesaro-papism have recurred and had their detractors over several centuries. Christian thinking on leadership has often emphasized stewardship of divinely provided resources—human and material—and their deployment in accordance with a Divine plan. Compare servant leadership.\n\nFor a more general take on leadership in politics, compare the concept of the statesperson.\n\nThe search for the characteristics or traits of leaders has continued for centuries. Philosophical writings from Plato's \"Republic\" to Plutarch's \"Lives\" have explored the question \"What qualities distinguish an individual as a leader?\" Underlying this search was the early recognition of the importance of leadership and the assumption that leadership is rooted in the characteristics that certain individuals possess. This idea that leadership is based on individual attributes is known as the \"trait theory of leadership\".\n\nA number of works in the 19th century – when the traditional authority of monarchs, lords and bishops had begun to wane – explored the trait theory at length: note especially the writings of Thomas Carlyle and of Francis Galton, whose works have prompted decades of research. In \"Heroes and Hero Worship\" (1841), Carlyle identified the talents, skills, and physical characteristics of men who rose to power. Galton's \"Hereditary Genius\" (1869) examined leadership qualities in the families of powerful men. After showing that the numbers of eminent relatives dropped off when his focus moved from first-degree to second-degree relatives, Galton concluded that leadership was inherited. In other words, leaders were born, not developed. Both of these notable works lent great initial support for the notion that leadership is rooted in characteristics of a leader.\n\nCecil Rhodes (1853–1902) believed that public-spirited leadership could be nurtured by identifying young people with \"moral force of character and instincts to lead\", and educating them in contexts (such as the collegiate environment of the University of Oxford) which further developed such characteristics. International networks of such leaders could help to promote international understanding and help \"render war impossible\". This vision of leadership underlay the creation of the Rhodes Scholarships, which have helped to shape notions of leadership since their creation in 1903.\n\nIn the late 1940s and early 1950s, a series of qualitative reviews of these studies (e.g., Bird, 1940; Stogdill, 1948; Mann, 1959) prompted researchers to take a drastically different view of the driving forces behind leadership. In reviewing the extant literature, Stogdill and Mann found that while some traits were common across a number of studies, the overall evidence suggested that persons who are leaders in one situation may not necessarily be leaders in other situations. Subsequently, leadership was no longer characterized as an enduring individual trait, as situational approaches (see alternative leadership theories below) posited that individuals can be effective in certain situations, but not others. The focus then shifted away from traits of leaders to an investigation of the leader behaviors that were effective. This approach dominated much of the leadership theory and research for the next few decades.\n\nNew methods and measurements were developed after these influential reviews that would ultimately reestablish trait theory as a viable approach to the study of leadership. For example, improvements in researchers' use of the round robin research design methodology allowed researchers to see that individuals can and do emerge as leaders across a variety of situations and tasks. Additionally, during the 1980s statistical advances allowed researchers to conduct meta-analyses, in which they could quantitatively analyze and summarize the findings from a wide array of studies. This advent allowed trait theorists to create a comprehensive picture of previous leadership research rather than rely on the qualitative reviews of the past. Equipped with new methods, leadership researchers revealed the following:\n\nWhile the trait theory of leadership has certainly regained popularity, its reemergence has not been accompanied by a corresponding increase in sophisticated conceptual frameworks.\n\nSpecifically, Zaccaro (2007) noted that trait theories still:\n\nConsidering the criticisms of the trait theory outlined above, several researchers have begun to adopt a different perspective of leader individual differences—the leader attribute pattern approach. In contrast to the traditional approach, the leader attribute pattern approach is based on theorists' arguments that the influence of individual characteristics on outcomes is best understood by considering the person as an integrated totality rather than a summation of individual variables. In other words, the leader attribute pattern approach argues that integrated constellations or combinations of individual differences may explain substantial variance in both leader emergence and leader effectiveness beyond that explained by single attributes, or by additive combinations of multiple attributes..\n\nIn response to the early criticisms of the trait approach, theorists began to research leadership as a set of behaviors, evaluating the behavior of successful leaders, determining a behavior taxonomy, and identifying broad leadership styles. David McClelland, for example, posited that leadership takes a strong personality with a well-developed positive ego. To lead, self-confidence and high self-esteem are useful, perhaps even essential.\nKurt Lewin, Ronald Lipitt, and Ralph White developed in 1939 the seminal work on the influence of leadership styles and performance. The researchers evaluated the performance of groups of eleven-year-old boys under different types of work climate. In each, the leader exercised his influence regarding the type of group decision making, praise and criticism (feedback), and the management of the group tasks (project management) according to three styles: authoritarian, democratic, and laissez-faire.\n\nIn 1945, Ohio State University conducted a study which investigated observable behaviors portrayed by effective leaders, They would then identify if these particular behaviors reflective in leadership effectiveness. They were able to narrow their findings to two identifiable distinctions The first dimension was identified as \"Initiating Structure\", which described how a leader clearly and accurately communicates with their followers, defines goals, and determine how tasks are performed. These are considered \"task oriented\" behaviors The second dimension is \"Consideration\", which indicates the leader's ability to build an interpersonal relationship with their followers, to establish a form of mutual trust. These are considered \"social oriented\" behaviors.\n\nThe Michigan State Studies, which were conducted in the 1950s, made further investigations and findings that positively correlated behaviors and leadership effectiveness. Although they similar findings as the Ohio State studies, they did contribute an additional behavior identified in leaders. This was participative behavior; allowing the followers to participate in group decision making and encouraged subordinate input. Another term used to describe this is \"Servant Leadership\", which entails the leader to reject a more controlling type of leadership and allow more personal interaction between themselves and their subordinates.\n\nThe managerial grid model is also based on a behavioral theory. The model was developed by Robert Blake and Jane Mouton in 1964 and suggests five different leadership styles, based on the leaders' concern for people and their concern for goal achievement.\n\nB. F. Skinner is the father of behavior modification and developed the concept of positive reinforcement. Positive reinforcement occurs when a positive stimulus is presented in response to a behavior, increasing the likelihood of that behavior in the future. The following is an example of how positive reinforcement can be used in a business setting. Assume praise is a positive reinforcer for a particular employee. This employee does not show up to work on time every day. The manager of this employee decides to praise the employee for showing up on time every day the employee actually shows up to work on time. As a result, the employee comes to work on time more often because the employee likes to be praised. In this example, praise (the stimulus) is a positive reinforcer for this employee because the employee arrives at work on time (the behavior) more frequently after being praised for showing up to work on time.\n\nThe use of positive reinforcement is a successful and growing technique used by leaders to motivate and attain desired behaviors from subordinates. Organizations such as Frito-Lay, 3M, Goodrich, Michigan Bell, and Emery Air Freight have all used reinforcement to increase productivity. Empirical research covering the last 20 years suggests that reinforcement theory has a 17 percent increase in performance. Additionally, many reinforcement techniques such as the use of praise are inexpensive, providing higher performance for lower costs.\n\nSituational theory also appeared as a reaction to the trait theory of leadership. Social scientists argued that history was more than the result of intervention of great men as Carlyle suggested. Herbert Spencer (1884) (and Karl Marx) said that the times produce the person and not the other way around. This theory assumes that different situations call for different characteristics; according to this group of theories, no single optimal psychographic profile of a leader exists. According to the theory, \"what an individual actually does when acting as a leader is in large part dependent upon characteristics of the situation in which he functions.\"\n\nSome theorists started to synthesize the trait and situational approaches. Building upon the research of Lewin et al., academics began to normalize the descriptive models of leadership climates, defining three leadership styles and identifying which situations each style works better in. The authoritarian leadership style, for example, is approved in periods of crisis but fails to win the \"hearts and minds\" of followers in day-to-day management; the democratic leadership style is more adequate in situations that require consensus building; finally, the laissez-faire leadership style is appreciated for the degree of freedom it provides, but as the leaders do not \"take charge\", they can be perceived as a failure in protracted or thorny organizational problems. Thus, theorists defined the style of leadership as contingent to the situation, which is sometimes classified as contingency theory. Four contingency leadership theories appear more prominently in recent years: Fiedler contingency model, Vroom-Yetton decision model, the path-goal theory, and the Hersey-Blanchard situational theory.\n\nThe Fiedler contingency model bases the leader's effectiveness on what Fred Fiedler called \"situational contingency\". This results from the interaction of leadership style and situational favorability (later called \"situational control\"). The theory defined two types of leader: those who tend to accomplish the task by developing good relationships with the group (relationship-oriented), and those who have as their prime concern carrying out the task itself (task-oriented). According to Fiedler, there is no ideal leader. Both task-oriented and relationship-oriented leaders can be effective if their leadership orientation fits the situation. When there is a good leader-member relation, a highly structured task, and high leader position power, the situation is considered a \"favorable situation\". Fiedler found that task-oriented leaders are more effective in extremely favorable or unfavorable situations, whereas relationship-oriented leaders perform best in situations with intermediate favorability.\n\nVictor Vroom, in collaboration with Phillip Yetton (1973) and later with Arthur Jago (1988), developed a taxonomy for describing leadership situations, which was used in a normative decision model where leadership styles were connected to situational variables, defining which approach was more suitable to which situation. This approach was novel because it supported the idea that the same manager could rely on different group decision making approaches depending on the attributes of each situation. This model was later referred to as situational contingency theory.\n\nThe path-goal theory of leadership was developed by Robert House (1971) and was based on the expectancy theory of Victor Vroom. According to House, the essence of the theory is \"the meta proposition that leaders, to be effective, engage in behaviors that complement subordinates' environments and abilities in a manner that compensates for deficiencies and is instrumental to subordinate satisfaction and individual and work unit performance\". The theory identifies four leader behaviors, \"achievement-oriented\", \"directive\", \"participative\", and \"supportive\", that are contingent to the environment factors and follower characteristics. In contrast to the Fiedler contingency model, the path-goal model states that the four leadership behaviors are fluid, and that leaders can adopt any of the four depending on what the situation demands. The path-goal model can be classified both as a contingency theory, as it depends on the circumstances, and as a transactional leadership theory, as the theory emphasizes the reciprocity behavior between the leader and the followers.\n\nThe Situational Leadership® Model proposed by Hersey suggests four leadership-styles and four levels of follower-development. For effectiveness, the model posits that the leadership-style must match the appropriate level of follower-development. In this model, leadership behavior becomes a function not only of the characteristics of the leader, but of the characteristics of followers as well.\n\nFunctional leadership theory (Hackman & Walton, 1986; McGrath, 1962; Adair, 1988; Kouzes & Posner, 1995) is a particularly useful theory for addressing specific leader behaviors expected to contribute to organizational or unit effectiveness. This theory argues that the leader's main job is to see that whatever is necessary to group needs is taken care of; thus, a leader can be said to have done their job well when they have contributed to group effectiveness and cohesion (Fleishman et al., 1991; Hackman & Wageman, 2005; Hackman & Walton, 1986). While functional leadership theory has most often been applied to team leadership (Zaccaro, Rittman, & Marks, 2001), it has also been effectively applied to broader organizational leadership as well (Zaccaro, 2001). In summarizing literature on functional leadership (see Kozlowski et al. (1996), Zaccaro et al. (2001), Hackman and Walton (1986), Hackman & Wageman (2005), Morgeson (2005)), Klein, Zeigert, Knight, and Xiao (2006) observed five broad functions a leader performs when promoting organization's effectiveness. These functions include environmental monitoring, organizing subordinate activities, teaching and coaching subordinates, motivating others, and intervening actively in the group's work.\n\nA variety of leadership behaviors are expected to facilitate these functions. In initial work identifying leader behavior, Fleishman (1953) observed that subordinates perceived their supervisors' behavior in terms of two broad categories referred to as consideration and initiating structure. Consideration includes behavior involved in fostering effective relationships. Examples of such behavior would include showing concern for a subordinate or acting in a supportive manner towards others. Initiating structure involves the actions of the leader focused specifically on task accomplishment. This could include role clarification, setting performance standards, and holding subordinates accountable to those standards.\n\nThe Integrated Psychological theory of leadership is an attempt to integrate the strengths of the older theories (i.e. traits, behavioral/styles, situational and functional) while addressing their limitations, largely by introducing a new element – the need for leaders to develop their leadership presence, attitude toward others and behavioral flexibility by practicing psychological mastery. It also offers a foundation for leaders wanting to apply the philosophies of servant leadership and authentic leadership.\n\nIntegrated Psychological theory began to attract attention after the publication of James Scouller's Three Levels of Leadership model (2011).\nScouller argued that the older theories offer only limited assistance in developing a person's ability to lead effectively.\nHe pointed out, for example, that:\n\nScouller proposed the Three Levels of Leadership model, which was later categorized as an \"Integrated Psychological\" theory on the Businessballs education website. In essence, his model aims to summarize what leaders have to do, not only to bring leadership to their group or organization, but also to develop themselves technically and psychologically as leaders.\n\nThe three levels in his model are Public, Private and Personal leadership:\n\nScouller argued that self-mastery is the key to growing one's leadership presence, building trusting relationships with followers and dissolving one's limiting beliefs and habits, thereby enabling behavioral flexibility as circumstances change, while staying connected to one's core values (that is, while remaining authentic). To support leaders' development, he introduced a new model of the human psyche and outlined the principles and techniques of self-mastery, which include the practice of mindfulness meditation.\n\nBernard Bass and colleagues developed the idea of two different types of leadership, transactional that involves exchange of labor for rewards and transformational which is based on concern for employees, intellectual stimulation, and providing a group vision.\n\nThe transactional leader (Burns, 1978) is given power to perform certain tasks and reward or punish for the team's performance. It gives the opportunity to the manager to lead the group and the group agrees to follow his lead to accomplish a predetermined goal in exchange for something else. Power is given to the leader to evaluate, correct, and train subordinates when productivity is not up to the desired level, and reward effectiveness when expected outcome is reached.\n\nThis LMX theory addresses a specific aspect of the leadership process is the leader–member exchange (LMX) theory, which evolved from an earlier theory called the vertical dyad linkage (VDL) model. Both of these models focus on the interaction between leaders and individual followers. Similar to the transactional approach, this interaction is viewed as a fair exchange whereby the leader provides certain benefits such as task guidance, advice, support, and/or significant rewards and the followers reciprocate by giving the leader respect, cooperation, commitment to the task and good performance. However, LMX recognizes that leaders and individual followers will vary in the type of exchange that develops between them. LMX theorizes that the type of exchanges between the leader and specific followers can lead to the creation of \"in-groups\" and \"out-groups\". In-group members are said to have \"high-quality exchanges\" with the leader, while out-group members have \"low-quality exchanges\" with the leader.\n\nIn-group members are perceived by the leader as being more experienced, competent, and willing to assume responsibility than other followers. The leader begins to rely on these individuals to help with especially challenging tasks. If the follower responds well, the leader rewards him/her with extra coaching, favorable job assignments, and developmental experiences. If the follower shows high commitment and effort followed by additional rewards, both parties develop mutual trust, influence, and support of one another. Research shows the in-group members usually receive higher performance evaluations from the leader, higher satisfaction, and faster promotions than out-group members. In-group members are also likely to build stronger bonds with their leaders by sharing the same social backgrounds and interests.\n\nOut-group members often receive less time and more distant exchanges than their in-group counterparts. With out-group members, leaders expect no more than adequate job performance, good attendance, reasonable respect, and adherence to the job description in exchange for a fair wage and standard benefits. The leader spends less time with out-group members, they have fewer developmental experiences, and the leader tends to emphasize his/her formal authority to obtain compliance to leader requests. Research shows that out-group members are less satisfied with their job and organization, receive lower performance evaluations from the leader, see their leader as less fair, and are more likely to file grievances or leave the organization.\n\nLeadership can be perceived as a particularly emotion-laden process, with emotions entwined with the social influence process. In an organization, the leader's mood has some effects on his/her group. These effects can be described in three levels:\nIn research about client service, it was found that expressions of positive mood by the leader improve the performance of the group, although in other sectors there were other findings.\n\nBeyond the leader's mood, her/his behavior is a source for employee positive and negative emotions at work. The leader creates situations and events that lead to emotional response. Certain leader behaviors displayed during interactions with their employees are the sources of these affective events. Leaders shape workplace affective events. Examples – feedback giving, allocating tasks, resource distribution. Since employee behavior and productivity are directly affected by their emotional states, it is imperative to consider employee emotional responses to organizational leaders. Emotional intelligence, the ability to understand and manage moods and emotions in the self and others, contributes to effective leadership within organizations.\n\nThe neo-emergent leadership theory (from the Oxford Strategic Leadership Programme) sees leadership as created through the emergence of information by the leader or other stakeholders, not through the true actions of the leader himself. In other words, the reproduction of information or stories form the basis of the perception of leadership by the majority. It is well known that the naval hero Lord Nelson often wrote his own versions of battles he was involved in, so that when he arrived home in England he would receive a true hero's welcome. In modern society, the press, blogs and other sources report their own views of leaders, which may be based on reality, but may also be based on a political command, a payment, or an inherent interest of the author, media, or leader. Therefore, one can argue that the perception of all leaders is created and in fact does not reflect their true leadership qualities at all.\n\nMany personality characteristics were found to be reliably associated with leadership emergence. The list include, but is not limited to following (list organized in alphabetical order): assertiveness, authenticity, Big Five personality factors, birth order, character strengths, dominance, emotional intelligence, gender identity, intelligence, narcissism, self-efficacy for leadership, self-monitoring and social motivation.\nLeadership emergence is the idea that people born with specific characteristics become leaders, and those without these characteristics do not become leaders. People like Mahatma Gandhi, Abraham Lincoln, and Nelson Mandela all share traits that an average person does not. This includes people who choose to participate in leadership roles, as opposed to those who do not. Research indicates that up to 30% of leader emergence has a genetic basis.\nThere is no current research indicating that there is a “leadership gene”, instead we inherit certain traits that might influence our decision to seek leadership. Both anecdotal, and empirical evidence support a stable relationship between specific traits and leadership behavior. Using a large international sample researchers found that there are three factors that motivate leaders; affective identity (enjoyment of leading), non-calculative (leading earns reinforcement), and social-normative (sense of obligation).\n\nThe relationship between assertiveness and leadership emergence is curvilinear; individuals who are either low in assertiveness or very high in assertiveness are less likely to be identified as leaders.\n\nIndividuals who are more aware of their personality qualities, including their values and beliefs, and are less biased when processing self-relevant information, are more likely to be accepted as leaders. See Authentic Leadership.\n\nThose who emerge as leaders tend to be more (order in strength of relationship with leadership emergence): extroverted, conscientious, emotionally stable, and open to experience, although these tendencies are stronger in laboratory studies of leaderless groups. Agreeableness, the last factor of the Big Five personality traits, does not seem to play any meaningful role in leadership emergence \n\nThose born first in their families and only children are hypothesized to be more driven to seek leadership and control in social settings. Middle-born children tend to accept follower roles in groups, and later-borns are thought to be rebellious and creative \n\nThose seeking leadership positions in a military organization had elevated scores on a number of indicators of strength of character, including honesty, hope, bravery, industry, and teamwork.\n\nIndividuals with dominant personalities – they describe themselves as high in the desire to control their environment and influence other people, and are likely to express their opinions in a forceful way – are more likely to act as leaders in small-group situations.. \n\nIndividuals with high emotional intelligence have increased ability to understand and relate to people. They have skills in communicating and decoding emotions and they deal with others wisely and effectively. Such people communicate their ideas in more robust ways, are better able to read the politics of a situation, are less likely to lose control of their emotions, are less likely to be inappropriately angry or critical, and in consequence are more likely to emerge as leaders.\n\nMasculine individuals are more likely to emerge as leaders than are feminine individuals.\n\nIndividuals with higher intelligence exhibit superior judgement, higher verbal skills (both written and oral), quicker learning and acquisition of knowledge, and are more likely to emerge as leaders. Correlation between IQ and leadership emergence was found to be between .25 and .30. However, groups generally prefer leaders that do not exceed intelligence prowess of average member by a wide margin, as they fear that high intelligence may be translated to differences in communication, trust, interests and values\n\nIndividuals who take on leadership roles in turbulent situations, such as groups facing a threat or ones in which status is determined by intense competition among rivals within the group, tend to be narcissistic: arrogant, self-absorbed, hostile, and very self-confident.\n\nConfidence in one's ability to lead is associated with increases in willingness to accept a leadership role and success in that role.\n\nHigh self-monitors are more likely to emerge as the leader of a group than are low self-monitors, since they are more concerned with status-enhancement and are more likely to adapt their actions to fit the demands of the situation\n\nIndividuals who are both success-oriented and affiliation-oriented, as assessed by projective measures, are more active in group problem-solving settings and are more likely to be elected to positions of leadership in such groups\n\nA leadership style is a leader's style of providing direction, implementing plans, and motivating people. It is the result of the philosophy, personality, and experience of the leader. Rhetoric specialists have also developed models for understanding leadership (Robert Hariman, \"Political Style\", Philippe-Joseph Salazar, \"L'Hyperpolitique. Technologies politiques De La Domination\").\n\nDifferent situations call for different leadership styles. In an emergency when there is little time to converge on an agreement and where a designated authority has significantly more experience or expertise than the rest of the team, an autocratic leadership style may be most effective; however, in a highly motivated and aligned team with a homogeneous level of expertise, a more democratic or Laissez-faire style may be more effective. The style adopted should be the one that most effectively achieves the objectives of the group while balancing the interests of its individual members.\nA field in which leadership style has gained strong attention is that of military science, recently expressing a holistic and integrated view of leadership, including how a leader's physical presence determines how others perceive that leader. The factors of physical presence are military bearing, physical fitness, confidence, and resilience. The leader's intellectual capacity helps to conceptualize solutions and acquire knowledge to do the job. A leader's conceptual abilities apply agility, judgment, innovation, interpersonal tact, and domain knowledge. Domain knowledge for leaders encompasses tactical and technical knowledge as well as cultural and geopolitical awareness.\n\nUnder the autocratic leadership style, all decision-making powers are centralized in the leader, as with dictators.\n\nAutocratic leaders do not entertain any suggestions or initiatives from subordinates. The autocratic management has been successful as it provides strong motivation to the manager. It permits quick decision-making, as only one person decides for the whole group and keeps each decision to him/herself until he/she feels it needs to be shared with the rest of the group.\n\nThe democratic leadership style consists of the leader sharing the decision-making abilities with group members by promoting the interests of the group members and by practicing social equality. This has also been called shared leadership.\n\nIn Laissez-faire or free-rein leadership, decision-making is passed on to the sub-ordinates. The sub-ordinates are given complete right and power to make decisions to establish goals and work out the problems or hurdles.\n\nTask-oriented leadership is a style in which the leader is focused on the tasks that need to be performed in order to meet a certain production goal. Task-oriented leaders are generally more concerned with producing a step-by-step solution for given problem or goal, strictly making sure these deadlines are met, results and reaching target outcomes.\n\nRelationship-oriented leadership is a contrasting style in which the leader is more focused on the relationships amongst the group and is generally more concerned with the overall well-being and satisfaction of group members. Relationship-oriented leaders emphasize communication within the group, show trust and confidence in group members, and show appreciation for work done.\n\nTask-oriented leaders are typically less concerned with the idea of catering to group members, and more concerned with acquiring a certain solution to meet a production goal. For this reason, they typically are able to make sure that deadlines are met, yet their group members' well-being may suffer. Relationship-oriented leaders are focused on developing the team and the relationships in it. The positives to having this kind of environment are that team members are more motivated and have support. However, the emphasis on relations as opposed to getting a job done might make productivity suffer.\n\nAnother factor that covaries with leadership style is whether the person is male or female. When men and women come together in groups, they tend to adopt different leadership styles. Men generally assume an :agentic leadership style. They are task-oriented, active, decision focused, independent and goal oriented. Women, on the other hand, are generally more communal when they assume a leadership position; they strive to be helpful towards others, warm in relation to others, understanding, and mindful of others' feelings. In general, when women are asked to describe themselves to others in newly formed groups, they emphasize their open, fair, responsible, and pleasant communal qualities. They give advice, offer assurances, and manage conflicts in an attempt to maintain positive relationships among group members. Women connect more positively to group members by smiling, maintaining eye contact and respond tactfully to others' comments. Men, conversely, describe themselves as influential, powerful and proficient at the task that needs to be done. They tend to place more focus on initiating structure within the group, setting standards and objectives, identifying roles, defining responsibilities and standard operating procedures, proposing solutions to problems, monitoring compliance with procedures, and finally, emphasizing the need for productivity and efficiency in the work that needs to be done. As leaders, men are primarily task-oriented, but women tend to be both task- and relationship-oriented. However, it is important to note that these sex differences are only tendencies, and do not manifest themselves within men and women across all groups and situations.\n\nIn the past, some researchers have argued that the actual influence of leaders on organizational outcomes is overrated and romanticized as a result of biased attributions about leaders (Meindl & Ehrlich, 1987). Despite these assertions, however, it is largely recognized and accepted by practitioners and researchers that leadership is important, and research supports the notion that leaders do contribute to key organizational outcomes (Day & Lord, 1988; Kaiser, Hogan, & Craig, 2008). To facilitate successful performance it is important to understand and accurately measure leadership performance.\n\nJob performance generally refers to behavior that is expected to contribute to organizational success (Campbell, 1990). Campbell identified a number of specific types of performance dimensions; leadership was one of the dimensions that he identified. There is no consistent, overall definition of leadership performance (Yukl, 2006). Many distinct conceptualizations are often lumped together under the umbrella of leadership performance, including outcomes such as leader effectiveness, leader advancement, and leader emergence (Kaiser et al., 2008). For instance, leadership performance may be used to refer to the career success of the individual leader, performance of the group or organization, or even leader emergence. Each of these measures can be considered conceptually distinct. While these aspects may be related, they are different outcomes and their inclusion should depend on the applied or research focus.\n\n\"Another way to conceptualize leader performance is to focus on the outcomes of the leader’s followers, group, team, unit, or organization. In evaluating this type of leader performance, two general strategies are typically used. The first relies on subjective perceptions of the leader’s performance from subordinates, superiors, or occasionally peers or other parties. The other type of effectiveness measures are more objective indicators of follower or unit performance, such as measures of productivity, goal attainment, sales figures, or unit financial performance (Bass & Riggio, 2006, p. 47).\"\nA toxic leader is someone who has responsibility over a group of people or an organization, and who abuses the leader–follower relationship by leaving the group or organization in a worse-off condition than when he/she joined it.\n\nMost theories in the 20th century argued that great leaders were born, not made. Current studies have indicated that leadership is much more complex and cannot be boiled down to a few key traits of an individual. Years of observation and study have indicated that one such trait or a set of traits does not make an extraordinary leader. What scholars have been able to arrive at is that leadership traits of an individual do not change from situation to situation; such traits include intelligence, assertiveness, or physical attractiveness. However, each key trait may be applied to situations differently, depending on the circumstances. The following summarizes the main leadership traits found in research by Jon P. Howell, business professor at New Mexico State University and author of the book \"Snapshots of Great Leadership\".\n\nDetermination and drive include traits such as initiative, energy, assertiveness, perseverance and sometimes dominance. People with these traits often tend to wholeheartedly pursue their goals, work long hours, are ambitious, and often are very competitive with others. Cognitive capacity includes intelligence, analytical and verbal ability, behavioral flexibility, and good judgment. Individuals with these traits are able to formulate solutions to difficult problems, work well under stress or deadlines, adapt to changing situations, and create well-thought-out plans for the future. Howell provides examples of Steve Jobs and Abraham Lincoln as encompassing the traits of determination and drive as well as possessing cognitive capacity, demonstrated by their ability to adapt to their continuously changing environments.\n\nSelf-confidence encompasses the traits of high self-esteem, assertiveness, emotional stability, and self-assurance. Individuals who are self-confident do not doubt themselves or their abilities and decisions; they also have the ability to project this self-confidence onto others, building their trust and commitment. Integrity is demonstrated in individuals who are truthful, trustworthy, principled, consistent, dependable, loyal, and not deceptive. Leaders with integrity often share these values with their followers, as this trait is mainly an ethics issue. It is often said that these leaders keep their word and are honest and open with their cohorts. Sociability describes individuals who are friendly, extroverted, tactful, flexible, and interpersonally competent. Such a trait enables leaders to be accepted well by the public, use diplomatic measures to solve issues, as well as hold the ability to adapt their social persona to the situation at hand. According to Howell, Mother Teresa is an exceptional example who embodies integrity, assertiveness, and social abilities in her diplomatic dealings with the leaders of the world.\n\nFew great leaders encompass all of the traits listed above, but many have the ability to apply a number of them to succeed as front-runners of their organization or situation.\n\nOne of the more recent definitions of leadership comes from Werner Erhard, Michael C. Jensen, Steve Zaffron, and Kari Granger who describe leadership as \"an exercise in language that results in the realization of a future that wasn't going to happen anyway, which future fulfills (or contributes to fulfilling) the concerns of the relevant parties...\". This definition ensures that leadership is talking about the future and includes the fundamental concerns of the relevant parties. This differs from relating to the relevant parties as \"followers\" and calling up an image of a single leader with others following. Rather, a future that fulfills on the fundamental concerns of the relevant parties indicates the future that wasn't going to happen is not the \"idea of the leader\", but rather is what emerges from digging deep to find the underlying concerns of those who are impacted by the leadership.\n\nAn organization that is established as an instrument or means for achieving defined objectives has been referred to as a \"formal organization\". Its design specifies how goals are subdivided and reflected in subdivisions of the organization. Divisions, departments, sections, positions, jobs, and tasks make up this work structure. Thus, the formal organization is expected to behave impersonally in regard to relationships with clients or with its members. According to Weber's definition, entry and subsequent advancement is by merit or seniority. Employees receive a salary and enjoy a degree of tenure that safeguards them from the arbitrary influence of superiors or of powerful clients. The higher one's position in the hierarchy, the greater one's presumed expertise in adjudicating problems that may arise in the course of the work carried out at lower levels of the organization. It is this bureaucratic structure that forms the basis for the appointment of heads or chiefs of administrative subdivisions in the organization and endows them with the authority attached to their position.\n\nIn contrast to the appointed head or chief of an administrative unit, a leader emerges within the context of the \"informal organization\" that underlies the formal structure. The informal organization expresses the personal objectives and goals of the individual membership. Their objectives and goals may or may not coincide with those of the formal organization. The informal organization represents an extension of the social structures that generally characterize human life — the spontaneous emergence of groups and organizations as ends in themselves.\n\nIn prehistoric times, humanity was preoccupied with personal security, maintenance, protection, and survival. Now humanity spends a major portion of waking hours working for organizations. The need to identify with a community that provides security, protection, maintenance, and a feeling of belonging has continued unchanged from prehistoric times. This need is met by the informal organization and its emergent, or unofficial, leaders.\n\nLeaders emerge from within the structure of the informal organization. Their personal qualities, the demands of the situation, or a combination of these and other factors attract followers who accept their leadership within one or several overlay structures. Instead of the authority of position held by an appointed head or chief, the emergent leader wields influence or power. Influence is the ability of a person to gain co-operation from others by means of persuasion or control over rewards. Power is a stronger form of influence because it reflects a person's ability to enforce action through the control of a means of punishment.\n\nA leader is a person who influences a group of people towards a specific result. It is not dependent on title or formal authority. (Elevos, paraphrased from Leaders, Bennis, and Leadership Presence, Halpern & Lubar.) Ogbonnia (2007) defines an effective leader \"as an individual with the capacity to consistently succeed in a given condition and be viewed as meeting the expectations of an organization or society.\" Leaders are recognized by their capacity for caring for others, clear communication, and a commitment to persist. An individual who is appointed to a managerial position has the right to command and enforce obedience by virtue of the authority of their position. However, she or he must possess adequate personal attributes to match this authority, because authority is only potentially available to him/her. In the absence of sufficient personal competence, a manager may be confronted by an emergent leader who can challenge her/his role in the organization and reduce it to that of a figurehead. However, only authority of position has the backing of formal sanctions. It follows that whoever wields personal influence and power can legitimize this only by gaining a formal position in the hierarchy, with commensurate authority. Leadership can be defined as one's ability to get others to willingly follow. Every organization needs leaders at every level.\n\nOver the years the philosophical terminology of \"management\" and \"leadership\" have, in the organizational context, been used both as synonyms and with clearly differentiated meanings. Debate is fairly common about whether the use of these terms should be restricted, and generally reflects an awareness of the distinction made by Burns (1978) between \"transactional\" leadership (characterized by emphasis on procedures, contingent reward, management by exception) and \"transformational\" leadership (characterized by charisma, personal relationships, creativity).\n\nIn contrast to individual leadership, some organizations have adopted group leadership. In this so-called shared leadership, more than one person provides direction to the group as a whole. It is furthermore characterized by shared responsibility, cooperation and mutual influence among the team members. Some organizations have taken this approach in hopes of increasing creativity, reducing costs, or downsizing. Others may see the traditional leadership of a boss as costing too much in team performance. In some situations, the team members best able to handle any given phase of the project become the temporary leaders. Additionally, as each team member has the opportunity to experience the elevated level of empowerment, it energizes staff and feeds the cycle of success.\n\nLeaders who demonstrate persistence, tenacity, determination, and synergistic communication skills will bring out the same qualities in their groups. Good leaders use their own inner mentors to energize their team and organizations and lead a team to achieve success.\n\nAccording to the National School Boards Association (USA):\n\nThese Group Leaderships or Leadership Teams have specific characteristics:\n\nCharacteristics of a Team\n\nTen characteristics of well-functioning teams:\n\nSelf-leadership is a process that occurs within an individual, rather than an external act. It is an expression of who we are as people.\n\nMark van Vugt and Anjana Ahuja in \"Naturally Selected: The Evolutionary Science of Leadership\" (2011) present evidence of leadership in non-human animals, from ants and bees to baboons and chimpanzees. They suggest that leadership has a long evolutionary history and that the same mechanisms underpinning leadership in humans appear in other social species, too. They also suggest that the evolutionary origins of leadership are different from that of dominance. In a study Mark van Vugt and his team looked at the relation between basal testosterone and leadership versus dominance. They found that testosterone correlates with dominance but not with leadership. This was replicated in a sample of managers in which there was no relation between hierarchical position and testosterone level.. \nRichard Wrangham and Dale Peterson, in \"\" (1996), present evidence that only humans and chimpanzees, among all the animals living on Earth, share a similar tendency for a cluster of behaviors: violence, territoriality, and competition for uniting behind the one chief male of the land. This position is contentious. Many animals apart from apes are territorial, compete, exhibit violence, and have a social structure controlled by a dominant male (lions, wolves, etc.), suggesting Wrangham and Peterson's evidence is not empirical. However, we must examine other species as well, including elephants (which are matriarchal and follow an alpha female), meerkats (which are likewise matriarchal), sheep (which follow castrated bellwethers) and many others.\n\nBy comparison, bonobos, the second-closest species-relatives of humans, do \"not\" unite behind the chief male of the land. The bonobos show deference to an alpha or top-ranking female that, with the support of her coalition of other females, can prove as strong as the strongest male. Thus, if leadership amounts to getting the greatest number of followers, then among the bonobos, a female almost always exerts the strongest and most effective leadership. (Incidentally, not all scientists agree on the allegedly peaceful nature of the bonobo or with its reputation as a \"hippie chimp\".\n\nLeadership, although largely talked about, has been described as one of the least understood concepts across all cultures and civilizations. Over the years, many researchers have stressed the prevalence of this misunderstanding, stating that the existence of several flawed assumptions, or myths, concerning leadership often interferes with individuals' conception of what leadership is all about (Gardner, 1965; Bennis, 1975).\n\nAccording to some, leadership is determined by distinctive dispositional characteristics present at birth (e.g., extraversion; intelligence; ingenuity). However, according to Forsyth (2009) there is evidence to show that leadership also develops through hard work and careful observation. Thus, effective leadership can result from nature (i.e., innate talents) as well as nurture (i.e., acquired skills).\n\nAlthough leadership is certainly a form of power, it is not demarcated by power \"over\" people – rather, it is a power \"with\" people that exists as a reciprocal relationship between a leader and his/her followers (Forsyth, 2009). Despite popular belief, the use of manipulation, coercion, and domination to influence others is not a requirement for leadership. In actuality, individuals who seek group consent and strive to act in the best interests of others can also become effective leaders (e.g., class president; court judge).\n\nThe validity of the assertion that groups flourish when guided by effective leaders can be illustrated using several examples. For instance, according to Baumeister et al. (1988), the bystander effect (failure to respond or offer assistance) that tends to develop within groups faced with an emergency is significantly reduced in groups guided by a leader. Moreover, it has been documented that group performance, creativity, and efficiency all tend to climb in businesses with designated managers or CEOs. However, the difference leaders make is not always positive in nature. Leaders sometimes focus on fulfilling their own agendas at the expense of others, including his/her own followers (e.g., Pol Pot; Josef Stalin). Leaders who focus on personal gain by employing stringent and manipulative leadership styles often make a difference, but usually do so through negative means.\n\nIn Western cultures it is generally assumed that group leaders make \"all\" the difference when it comes to group influence and overall goal-attainment. Although common, this romanticized view of leadership (i.e., the tendency to overestimate the degree of control leaders have over their groups and their groups' outcomes) ignores the existence of many other factors that influence group dynamics. For example, group cohesion, communication patterns among members, individual personality traits, group context, the nature or orientation of the work, as well as behavioral norms and established standards influence group functionality in varying capacities. For this reason, it is unwarranted to assume that all leaders are in complete control of their groups' achievements.\n\nDespite preconceived notions, not all groups need have a designated leader. Groups that are primarily composed of women, are limited in size, are free from stressful decision-making, or only exist for a short period of time (e.g., student work groups; pub quiz/trivia teams) often undergo a diffusion of responsibility, where leadership tasks and roles are shared amongst members (Schmid Mast, 2002; Berdahl & Anderson, 2007; Guastello, 2007).\n\nAlthough research has indicated that group members' dependence on group leaders can lead to reduced self-reliance and overall group strength, most people actually prefer to be led than to be without a leader (Berkowitz, 1953). This \"need for a leader\" becomes especially strong in troubled groups that are experiencing some sort of conflict. Group members tend to be more contented and productive when they have a leader to guide them. Although individuals filling leadership roles can be a direct source of resentment for followers, most people appreciate the contributions that leaders make to their groups and consequently welcome the guidance of a leader (Stewart & Manz, 1995).\n\nIn most cases, these teams are tasked to operate in remote and changeable environments with limited support or backup (action environments). Leadership of people in these environments requires a different set of skills to that of front line management. These leaders must effectively operate remotely and negotiate the needs of the individual, team, and task within a changeable environment. This has been termed action oriented leadership. Some examples of demonstrations of action oriented leadership include extinguishing a rural fire, locating a missing person, leading a team on an outdoor expedition, or rescuing a person from a potentially hazardous environment.\n\nOther examples include modern technology deployments of small/medium-sized IT teams into client plant sites. Leadership of these teams requires hands on experience and a lead-by-example attitude to empower team members to make well thought out and concise decisions independent of executive management and/or home base decision makers. Zachary Hansen was an early adopter of Scrum/Kanban branch development methodologies during the mid 90's to alleviate the dependency that field teams had on trunk based development. This method of just-in-time action oriented development and deployment allowed remote plant sites to deploy up-to-date software patches frequently and without dependency on core team deployment schedules satisfying the clients need to rapidly patch production environment bugs as needed.\n\nCarlyle's 1840 \"Great Man theory\", which emphasized the role of leading individuals, met opposition in the 19th and 20th centuries.\n\nKarl Popper noted in 1945 that leaders can mislead and make mistakes - he warns against deferring to \"great men\".\n\nNoam Chomsky and others\nhave subjected the concept of leadership to critical thinking and have provided an analysis that asserts that people abrogate their responsibility to think and will actions for themselves. While the conventional view of leadership may satisfy people who \"want to be told what to do\", these critics say that one should question why they are being subjected to a will or intellect other than their own if the leader is not a subject-matter expert (SME).\n\nConcepts such as autogestion, employeeship, and common civic virtue, etc., challenge the fundamentally anti-democratic nature of the leadership principle by stressing individual responsibility and/or group authority in the workplace and elsewhere and by focusing on the skills and attitudes that a person needs in general rather than separating out \"leadership\" as the basis of a special class of individuals.\n\nSimilarly, various historical calamities (such as World War II) can be attributed\nto a misplaced reliance on the principle of leadership as exhibited in dictatorship.\n\nThe idea of leaderism paints leadership and its excesses in a negative light.\n\nExecutives are energetic, outgoing, and competitive. They can be visionary, hard-working, and decisive. However, managers need to be aware of unsuccessful executives who once showed management potential but who are later dismissed or retired early. They typically fail because of personality factors rather than job performances.\n\n\"Terms fallacies in their thinking are:\"\n\nNotes\nBooks\n\nJournal articles\n"}
{"id": "5378130", "url": "https://en.wikipedia.org/wiki?curid=5378130", "title": "Mac Wellman", "text": "Mac Wellman\n\nMac Wellman, born John McDowell Wellman on March 7, 1945 in Cleveland, Ohio, is an American playwright, author, and poet. He is best known for his experimental work in the theater which rebels against theatrical conventions, often abandoning such traditional elements as plot and character altogether.\n\nIn 1967 Wellman earned a baccalaureat International Relations at the American University, marrying his first wife, Nancy Roesch, the same year. Moving to the University of Wisconsin, he earned a Masters degree in English focusing on poetry. After teaching several years, he sought professional renewal by touring Europe. In The Netherlands, Wellman met Annemarie Prins, a Dutch theatrical director/producer, and they began a collaboration, creating radio plays. In 1975 they directed a stage production, \"Fama Combinatoria\", at Theatre de Brakke Grand in Amsterdam.\n\nDuring the late seventies Wellman moved to New York City and married a Dutch journalist, Yolanda Gerritsen. Wellman continued writing poetry and plays, and in 1977 published a collection of poetry, \"In Praise of Secrecy\", while in 1979 his play, \"Starluster\" was produced in New York.\n\nWellman's plays frequently resemble a moving collage of events which has more in common with an avant-garde dance production than Broadway-style theater. Wellman has stated, \"More and more I think all theater is site-specific. When plays work, they work in the space.\" Helen Shaw wrote, \"Since a 1984 essay, 'The Theatre of Good Intentions', [Wellman] has been the cynosure in a heaven full of experimental playwrights who rail against what Jonathan Lear, in his book \"Open Minded\", called a 'tyranny' of 'the already known'.\"\n\nDiscussing his style with \"BOMB Magazine\", Wellman said that he uses words as objects in his writing. \"I found if you try to write totally in cliches and things that don't sound right,\" Wellman clarified, \"you deal with a language that frankly is 98% of what people speak, think, and hear. So it's enormously enjoyable.\" This type of language has been positively characterized as \"an untrammeled flow of logorrhea: plain words, fancy words, space-age words, Victorian words and words that defy the dictionary\" by \"The New York Times\" reviewer Ben Brantley. In terms of production, Wellman experiments with stage direction. Some directions are spoken and others are not, blurring the line between action and direction. Wellman notes, \"That's something I'm really interested in. I like it when people talk about what's going on in a play. Sometimes it's more interesting than trying to enact everything.\"\n\nWellman is the I. Fine Professor of Play Writing at Brooklyn College, New York City, and in 2010 he became a CUNY Distinguished Professor. Wellman is author of more than forty plays, including:\n\nIn addition to several collaborations with composer/percussionist David Van Tieghem in the 1990s, he collaborated with Bang on a Can composer David Lang in 2006 on the opera \"The Difficulty of Crossing a Field\", adapted from a very short story by Ambrose Bierce. He has received grants from the National Endowment for the Arts, New York Foundation for the Arts, the Rockefeller Foundation, the McKnight Foundation and a Guggenheim Fellowship. In 1990, he received an Obie Award for Best New American Play (for \"Bad Penny\", \"Terminal Hip\", and \"Crowbar\"). In 1991, he received another Obie Award for \"Sincerity Forever\". He has received a Lila Wallace-Readers' Digest Writers Award, and most recently the 2003 Obie Award for Lifetime Achievement, as well as the Foundation for Contemporary Arts Grants to Artists award (2003). He is a co-founder of The Flea Theater in New York City.\n\n\n\n"}
{"id": "48920474", "url": "https://en.wikipedia.org/wiki?curid=48920474", "title": "Meher Mount", "text": "Meher Mount\n\nMeher Mount is a universal spiritual center dedicated to Avatar Meher Baba in Ojai, California, United States. The site has a panoramic view of Sulphur Mountain, California. Located about of Los Angeles at above the Pacific Ocean, it holds a 360-degree view, including the nearby peak of Topatopa Mountains, the Channel Islands, Los Padres National Forest, and the Ojai Valley. Meher Mount is a spiritual center open to all religions for inspiration, education, and work programs in agriculture, ecology, and humanitarian service. \n\nMeher Mount was founded in 1946 by Meher Mount Corporation owned by Agnes Baron, and co-signers at the request of Avatar Meher Baba. Meher Baba visited Meher Mount on August 2, 1956. In 1958, he named the area Meher Mount and said it would become a place of world pilgrimage. There are opportunities for day visits, group events, and individual retreats as well as resident work programs. In 1989 Baron Trust, Meher Mount Corporation was established after it suffered fire destruction on October 15, 1985. Meher Mount is one of four main centers set up worldwide, the other being Meher Spiritual Center, Avatar's Abode in Australia, and the \"samadhi\" (tomb-shrine) in Meherabad, India.\n"}
{"id": "26516550", "url": "https://en.wikipedia.org/wiki?curid=26516550", "title": "Mirage Tavern", "text": "Mirage Tavern\n\nThe Mirage Tavern was a drinking establishment at 731 N. Wells St. in Chicago purchased by the \"Chicago Sun-Times\" in 1977 to investigate widespread allegations of official corruption and shakedowns visited on small businesses by city officials. The journalists used hidden cameras to help ensure that city inspectors caught accepting payoffs for ignoring safety hazards were all properly documented.\n\nIn 1978, the \"Sun-Times\" broke the story in a 25-part series that documented the many abuses and crimes committed at the tavern, which was shaken down repeatedly by state and local officials. The series was initially nominated for the Pulitzer Prize for general reporting, but the Pulitzer board decided not to award the \"Sun-Times\" when editor Ben Bradlee of the \"Washington Post\" led an attack on the grounds that the reporters used undercover reporting, a form of deception, to report the story. \n\nThe Mirage gave rise to major reforms including city code revisions, new procedures in city inspections and investigations at federal, state and city levels. The IRS sent in 20 agents to take a closer look at tax fraud by cash businesses. The Illinois Department of Revenue formed a new investigative unit: the Mirage Audit Unit. An ongoing federal investigation, spurred by the Mirage findings, managed indictments of a third of the city’s electrical inspectors in 1978, with more indictments to come later.\n\nThe project was overseen by editors James Hoge, Ralph Otwell, Stuart H. Loory and Joseph Reilly. In May 1977, journalist Pam Zekman and Better Government Association chief investigator Bill Recktenwald purchased the tavern under the aliases \"Mr. and Mrs. Ray Patterson\". Reporter Zay N. Smith, who wrote the series, and BGA investigator Jeff Allen posed as the bartender and manager, respectively. \"Sun-Times\" photographers Gene Pesek and Jim Frost posed as repairmen and were in charge of photographing the tavern's activities from a hidden section of the tavern built over the washrooms. \n\nCorrupt practices ran the gamut from shakedowns to tax fraud. \n\nThe shakedown amounts were small, typically less than $100, as the reporters learned of what they later called \"the supermarket approach to graft--low prices, high volume\" that inspectors tended to prefer as the safest way of doing illegal business.\n\nAmong others, a city electrical inspector agreed to overlook the tavern's faulty wiring. A fire department lieutenant agreed to sign off on the tavern's grand opening, despite the loose electrical wiring hanging from rafters and a basement piled high with trash against regulations. A city health inspector ignored maggots and sink drains that emptied down to the basement floor. A state liquor inspector ignored fruit flies in the liquor.\n\nAlso reported were illegal kickbacks from pinball operators and jukebox operators (A.A. Swingtime Music Company), as well as tax skimming. Philip J. Barasch, a local accountant, gave the new owners of the bar extensive lessons on how to keep two sets of account books to skim profits without paying tax and advised them exactly what time of day inspectors showed up and how much their shakedowns would typically cost. He also suggested including his business card with any payoffs to help smooth the shakedown process. The only officials he warned against bribing were the police, noting that \"if you pay off a cop, they keep coming around every month, like flies, looking for a payoff\". The Mirage, after hearing Barash's tax advice, hired six more accountants specializing in small cash businesses and was counseled by all of them to commit fraud.\n\nThe tavern, which has had more than one owner since the \"Sun-Times\" investigation, is now known, after a number of improvements, as the Brehon Pub.\n"}
{"id": "21479754", "url": "https://en.wikipedia.org/wiki?curid=21479754", "title": "Mitteilungen des Instituts für Österreichische Geschichtsforschung", "text": "Mitteilungen des Instituts für Österreichische Geschichtsforschung\n\nMitteilungen des Instituts für Österreichische Geschichtsforschung is an Austrian academic journal established in 1880 by the Institut für Österreichische Geschichtsforschung (Institute for Austrian historic research). Recent editors include Anton Scharer, Georg Scheibelreiter, and Andrea Sommerlechner.\n\n\n"}
{"id": "51704205", "url": "https://en.wikipedia.org/wiki?curid=51704205", "title": "Mongolian studies", "text": "Mongolian studies\n\nMongolian studies is an interdisciplinary field of scholarly inquiry concerning Mongolian language, Mongolian history, and Mongolian culture. Scholars who work in the field of Mongolian studies are often referred to as Mongolists.\n\nIsaac Jacob Schmidt is generally regarded as the \"founder\" of Mongolian studies as an academic discipline. Schmidt, a native of Amsterdam who emigrated to Russia on account of the French invasion, began his exposure to the Mongolic languages as a missionary of the Moravian Church among the Kalmyks, and translated the Gospel of Matthew into the Kalmyk language. Afterwards he moved to Moscow and then Saint Petersburg, where he produced his most famous work: the first translation of the \"Erdeniin Tobchi\" into a European language. He also compiled a dictionary of Mongolian and a translation of the seven then-known chapters of the \"Epic of King Gesar\". Other major figures in the early history of Mongolian studies in Russia were Józef Kowalewski of Poland (who founded the Mongolian studies department at Kazan University) and Matthias Castrén of Finland (who wrote the first grammar of a modern Mongolic language, published after his death by Franz Anton Schiefner at Saint Petersburg University).\n\nChina had far longer direct contact with Mongolic peoples than Russia or other European countries had, and thus a longer history of studying their languages. However, the modern academic tradition of Mongolian studies in China faced a variety of early setbacks. 19th-century studies of Mongolia by Chinese scholars were closely tied to Qing dynasty rule over Mongolia. The threat from Russian imperialism was a major spur for Chinese scholars to study the region, both as part of the project of \"map[ping] and classify[ing] the frontier\", and from their desire to emphasise affinity between the Han Chinese and peoples of the frontier and their common contrast with Japanese and European powers who sought influence in the region. Thus, as Stephen Kotkin describes it, in the aftermath of the 1911 Xinhai Revolution which overthrew the Qing and established the Republic of China, the whole field of study was seen as \"closely tied to the Manchus and imperial rule\" and became discredited, a state of affairs made worse by the opposition to the 1911 revolution of major Chinese scholars of Mongolia such as Wang Guowei. The development of Mongolian studies in China in the early years after the establishment of the People's Republic of China drew heavily on Russian works. One of the first tertiary-level centres for Mongolian studies in China, the Institute of Mongolia at Inner Mongolia University, was founded in 1964.\n\nSome scholars in the United States did work in Mongolian studies in the early 20th century, such as Jeremiah Curtin, Berthold Laufer, and Roy Chapman Andrews. The University of California, Berkeley offered the U.S.' first course in the Mongolian language in 1936, taught by Ferdinand Lessing. Harvard University also had some scholars who worked in the field, such as Francis Woodman Cleaves and Antoine Mostaert; Joseph Fletcher was one of Cleaves' students. However, U.S. institutions for Mongolian studies were not founded until after World War II. Such institutions received a major boost from the post-war influx of refugees from communism, which included Diluwa Khutugtu Jamsrangjab, John Gombojab Hangin of Inner Mongolia and former Soviet Academy of Sciences member Nicholas Poppe. Poppe taught at the Far Eastern and Russian Institute at University of Washington; John Krueger was one of his students there. Denis Sinor of Hungary, who taught at the University of Cambridge after the war, arrived in the U.S. in 1962 and founded the Department of Ural and Altaic Studies at Indiana University (now known as the Department of Central Eurasian Studies), and later recruited Krueger and Hangin to join the department.\n\n\n\n"}
{"id": "25415730", "url": "https://en.wikipedia.org/wiki?curid=25415730", "title": "Nayereh Tohidi", "text": "Nayereh Tohidi\n\nProfessor Nayereh Tohidi is Professor and former Chair at the Department of Gender & Women Studies, California State University, Northridge. She is also the Research Associate at the Center for Near Eastern Studies of UCLA, where she has been coordinating the Bilingual Lecture Series on Iran since 2003.\n\nHer teaching and research areas include sociology of gender, religion (Islam), ethnicity and democracy in the Middle East and post-Soviet Central Eurasia, especially Iran and Azerbaijan Republic. She is the recipient of several grants, fellowships and research awards, including a year of Fulbright lectureship and research at the Academy of Sciences of the Soviet Republic of Azerbaijan; post-doctoral fellowships at Harvard University; the Hoover Institute of Stanford University; the Kennan Institute of the Woodrow Wilson International Center for Scholars; and the Keddie-Balzan Fellowship at the Center for Near Eastern Studies at UCLA. She has held visiting positions at Universities of Iowa, Minnesota, Harvard, UCLA, and USC. Recently she has been awarded the National Endowment Grant for Humanities to develop and launch a minor in Middle Eastern and Islamic Studies in California State University, Northridge.\n\nTohidi’s publications include editorship or authorship of \"Globalization, Gender and Religion: The Politics of Women’s Rights in Catholic and Muslim Contexts\"; \"Women in Muslim Societies: Diversity within Unity\"; and \"Feminism, Democracy and Islamism in Iran\".\n\n\nGender, Islam, Feminism, Modernity and Democracy; Ethnicity and Ethno-Religious Movements; \nHuman/Women Rights in the Persianate and Turkic Societies of the Middle East, the Caucasus and Central Asia\n\n\n"}
{"id": "27547792", "url": "https://en.wikipedia.org/wiki?curid=27547792", "title": "Oh, with the verbing!", "text": "Oh, with the verbing!\n\nOh, with the verbing! is a phrase commonly used in TV shows and movies, first used by comedian Jerry Lewis. The literal phrase \"Oh, with the verbing!\" itself is normally used with a verb replacing \"verbing,\" such as \"screaming, stabbing, bleeding,\" hence the name of the phrase. Similar lines related to the phrase are spoken as \"The verbing, and the verbing\" and \"Again with the verbing\" and other similar dialogue.\n\nThe most frequent usage of this phrase is of Professor Frink, of \"The Simpsons\", as it is arguably the character's trademark.\n\nZoidberg uses it in \"Futurama\".\n\nIt is used in the fourth \"An American Tail\" movie \"The Mystery of the Night Monster\".\n\nMort Goldman of \"Family Guy\" sometimes speaks the line.\n\n\"Homestar Runner\" uses a similar line in an episode.\n\nEvery episode of the sitcom \"Alright Already\" had a title with some variant of \"again with the verbing.\"\n\n"}
{"id": "718597", "url": "https://en.wikipedia.org/wiki?curid=718597", "title": "Phatic expression", "text": "Phatic expression\n\nIn linguistics, a phatic expression is communication which serves a social function, such as social pleasantries that don't seek or offer any information of value. Phatic expressions are a socio-pragmatic function and are used in everyday conversational exchange typically expressed in situational instances that call for social cues. In speech communication the term means \"small talk\" (conversation for its own sake) and has also been called \"grooming talking.\" \n\nFor example, greetings such as \"hello\" and \"how are you?\" are phatic expressions. In phatic expressions, speech acts are not communicative, since no content is communicated. According to anthropologist Bronisław Malinowski, apparently \"purposeless\" speech acts—polite small talk, like \"how are you?\" or \"have a nice day\"—even though their content may be trivial or irrelevant to the situation, perform the important function of establishing, maintaining, and managing bonds of sociality between participants.\n\nIn Roman Jakobson's work, the 'phatic' function of language concerns the channel of communication; for instance, when one says \"I can't hear you, you're breaking up\" in the middle of a cell-phone conversation. This usage appears in research on online communities and micro-blogging.\n\nThe term \"phatic communion\" ('bonding by language') was coined by anthropologist Bronisław Malinowski in his essay \"The Problem of Meaning in Primitive Languages\", which appeared in 1923 as a supplementary contribution to \"The Meaning of Meaning\" by C. K. Ogden and I. A. Richards. The term \"phatic\" means \"linguistic\" (i.e. \"by language\") and comes from the Greek φατός \"phatós\" (\"spoken, that may be spoken\"), from φημί \"phēmí\" (\"I speak, say\").\n\n\"You're welcome\", in its phatic usage, is not intended to convey the message that the hearer is welcome; it is a phatic response to being thanked, which in turn is a phatic whose function is to acknowledge the receipt of a benefit.\n\nSimilarly, the question \"how are you?\" is usually an automatic component of a social encounter. Although there are times when \"how are you?\" is asked in a sincere, concerned manner and does in fact anticipate a detailed response regarding the respondent's present state, this needs to be pragmatically inferred from context and intonation.\n\nExample: a simple, basic exchange between two acquaintances in a non-formal environment:\n\nOr:\n\nNeither speaker expects an actual answer to the question but rather it is an indication that each has recognized the other's presence and has therefore sufficiently performed that particular social duty.\n\nIn Japanese, phatic expressions play a significant role in communication, where they are referred to as \"aizuchi.\"\n\nTaarof is a complex set of expressions and other gestures in Persian society, primarily reflected in the language.\n\nNot all phatic expressions are done with spoken utterances. Non-verbal phatic expressions are used without spoken utterances to emphasize or add detail to the message that a person conveys or expresses. Common examples of these are smiling, gesturing, waving, etc. According to Dr. Carola Surkamp, professor at University of Cologne, non-verbal phatic communication can be expressed with involuntary physical features such as direction of gaze, blushing, posture, etc. and that these have a vital function in regulating conversation.\n\nPhatic expressions are used on different communication platforms on the internet such as social media networks where certain platforms require and prompt certain actions to be made between users to communicate or implicate certain messages between people without direct utterances. Examples for this would be: 'likes', comments/replies, shares/reblogs, emoji use, etc. These 'phatic posts' as Radovanovic and Ragnedda like to call them, are again used a social function of social communicative upkeep that has no real value but expresses social connection, relationships between users and recognition.\n"}
{"id": "1942340", "url": "https://en.wikipedia.org/wiki?curid=1942340", "title": "Plateau Penutian languages", "text": "Plateau Penutian languages\n\nPlateau Penutian (also Shahapwailutan, Lepitan) is a family of languages spoken in northern California, reaching through central-western Oregon to northern Washington and central-northern Idaho.\n\nPlateau Penutian consists of four languages:\n\nPlateau Penutian as originally proposed was one branch of the hypothetical Penutian phylum as proposed by Edward Sapir. The original proposal also included Cayuse (which was grouped with Molala into a Waiilatpuan branch); however, this language has little documentation and that which is documented is inadequately recorded. Thus, the status of Cayuse within Penutian (or any other genealogical relation for that matter) may very well forever remain unclassified.\n\nThe Sahaptian grouping of Sahaptin and Nez Percé has long been uncontroversial. Several linguists have published mounting evidence in support of a connection between Klamath (a.k.a. Klamath-Modoc) and Sahaptian. Howard Berman provides rather convincing evidence to include Molala within Plateau Penutian. Recent appraisals of the Penutian hypothesis find Plateau Penutian to be \"well supported\" by specialists (DeLancey & Golla (1997: 181); Campbell 1997), with DeLancey & Golla (1997: 180) cautiously stating \"while all subgroupings at this stage of Penutian research must be considered provisional, several linkages show considerable promise\" (Campbell 1997 likewise mentions similar caveats). Other researchers have pointed out promising similarities between Plateau Penutian and the Maiduan family, although this proposal is still not completely demonstrated. A connection with Uto-Aztecan has also been suggested (Rude 2000).\n\n"}
{"id": "42237941", "url": "https://en.wikipedia.org/wiki?curid=42237941", "title": "Rawiya", "text": "Rawiya\n\nRawi(ya) (, meaning \"female and male teller\") is a collective of documentary photographers from the Middle East (West Asia and North Africa). Today its members are Myriam Abdelaziz (New York City), Tamara Abdul Hadi (Beirut), Ghaith Abdul Hadad (Istanbul), Zeid Ben Romdhane (Tunis), Laura Boushnak (Sarajevo), Tanya Habjouqa (East Jerusalem), and Tasneem Alsultan (Jubail). It is the first cooperative of its kind with that started as an all female photographer group from the Arab world and opened up to male members in 2016.\n\nNewsha Tavakolian got together with Tamara Abdul Hadi and Dalia Khamissy in Beirut in 2009 with the idea of the collective, thereafter Boushnak and Habjouqa joined the conversation and Rawiya was born. In August 2011, following the Egyptian revolution, Myriam Abdelaziz joined the group. The collective made its official debut at the FORMAT International Photography Festival in Derby, U.K. in March 2011, which led to international exhibitions across the Greater Middle East, Europe, and the United States. In 2016 Tasneem Alsultan became a member of Rawiya. Tasneem became Grantee of Magnum/Prince Claus/AFAC with Tanya Habjouqa as her mentor. Gaith Abdul Hadad and Zeid Ben Romdhane were invited to join in 2016, opening the collective to male members.\n\n"}
{"id": "1120048", "url": "https://en.wikipedia.org/wiki?curid=1120048", "title": "Scroll", "text": "Scroll\n\nA scroll (from the Old French \"escroe\" or \"escroue\"), also known as a roll, is a roll of papyrus, parchment, or paper containing writing.\n\nA scroll is usually divided up into pages, which are sometimes separate sheets of papyrus or parchment glued together at the edges, or may be marked divisions of a continuous roll of writing material. The scroll is usually unrolled so that one page is exposed at a time, for writing or reading, with the remaining pages rolled up to the left and right of the visible page. It is unrolled from side to side, and the text is written in lines from the top to the bottom of the page. Depending on the language, the letters may be written left to right, right to left, or alternating in direction (boustrophedon).\n\nSome scrolls are simply rolled up pages; others may have wooden rollers on each end: Torah scrolls have rather elaborate rollers befitting their ceremonial function.\n\nScrolls were the first form of editable record keeping texts, used in Eastern Mediterranean ancient Egyptian civilizations. Parchment scrolls were used by the Israelites among others before the codex or bound book with parchment pages was invented by the Romans, which became popular around the 1st century AD. Scrolls were more highly regarded than codices until well into Roman times, where they were usually written in single latitudinal column.\n\nThe ink used in writing scrolls had to adhere to a surface that was rolled and unrolled, so special inks were developed. Even so, ink would slowly flake off of scrolls.\n\nShorter pieces of parchment or paper are called \"rolls\" or \"rotuli\", although usage of the term by modern historians varies with periods. Historians of the classical period tend to use \"roll\" instead of \"scroll\". Rolls may still be many meters or feet long, and were used in the medieval and Early Modern period in Europe and various West Asian cultures for manuscript administrative documents intended for various uses, including accounting, rent-rolls, legal agreements, and inventories. A distinction that sometimes applies is that the lines of writing in rotuli run across the width of the roll (that is to say, are parallel with any unrolled portion) rather than along the length, divided into page-like sections. Rolls may be wider than most scrolls, up to perhaps 60 cm or two feet wide. Rolls were often stored together in a special cupboard on shelves.\n\nA special Chinese form of short book, called the \"whirlwind book,\" consists of several pieces of paper bound at the top with bamboo and then rolled up.\n\nIn Scotland, the term \"scrow\" was used from about the 13th to the 17th centuries for scroll, writing, or documents in list or schedule form. There existed an office of Clerk of the Scrow (\"Rotulorum Clericus\") meaning the Clerk of the Rolls or Clerk of the Register.\n\nThe Romans invented the \"codex\" form of the book, folding the scroll into pages which made reading and handling the document much easier. Legend has it that Julius Caesar was the first to fold scrolls, concertina-fashion, for dispatches to his forces campaigning in Gaul. Scrolls were awkward to read if a reader wished to consult material at opposite ends of the document. Further, scrolls were written only on one side, while both sides of the codex page were used. \n\nEventually, the folds were cut into sheets, or \"leaves,\" and bound together along one edge. The bound pages were protected by stiff covers, usually of wood enclosed with leather. \"Codex\" is Latin for a \"block of wood\": the Latin \"liber\", the root of \"library,\" and the German \"Buch\", the source of \"book,\" both refer to wood. The codex was not only easier to handle than the scroll, but it also fit conveniently on library shelves. The spine generally held the book's title, facing out, affording easier organization of the collection.\n\nThe term \"codex\" technically refers only to manuscript books-those that, at one time, were handwritten. More specifically, a codex is the term used primarily for a bound manuscript from Roman times up through the Middle Ages.\n\nFrom the fourth century on, the codex became the standard format for books, and scrolls were no longer generally used. After the contents of a parchment scroll were copied in codex format, the scroll was seldom preserved. The majority that did survive were found by archaeologists in burial pits and in the buried trash of forgotten communities.\n\nThe oldest complete Torah scroll was discovered stored in an academic library in Bolonia, Italy by Professor Mauro Perani in 2013. It had been mislabeled in 1889 as dating from the 17th century, but Perani suspected it was actually older as it was written in an earlier Babylonian script. Two tests conducted by laboratories at Italy’s University of Salento and at the University of Illinois confirmed that the scroll dates from the second half of the 12th century to the first quarter of the 13th century. Ancient Torah scrolls are rare because when they are damaged they stop being used for liturgies and are buried. \n\nThe scroll is made up of 58 sections of soft sheep leather. It is 36 meters long and 64 centimeters wide. \n\nModern technology may be able to assist in reading ancient scrolls. In January 2015, computer software may be making progress in reading 2,000-year-old Herculaneum scrolls, computer scientists report. After working for more than 10 years on unlocking the contents of damaged Herculaneum scrolls, researchers may be able to progress towards reading the scrolls, which cannot be physically opened.\n\n\n"}
{"id": "2518059", "url": "https://en.wikipedia.org/wiki?curid=2518059", "title": "Season ticket", "text": "Season ticket\n\nA season ticket, or season pass, is a ticket that grants privileges over a defined period of time.\n\nThe \"Oxford English Dictionary\" has illustrative quotations which show the term used in the United States in 1820 for theatre tickets; and in the United Kingdom in 1836 for boat travel and 1862 for rail transport.\n\nIn sports, such as Association football or American football, a season ticket grants the holder access to all regular-season home games for one season without additional charges. The ticket usually offers a discounted price over purchasing a ticket for each of the home games for a season individually. In some sports, season ticket holders are usually allowed to buy tickets for other home games (such the playoffs) earlier than other fans, and may be given priority when buying tickets for their team's allocation at a road game. Seats assigned to season tickets are generally the better ones in their seating section. Season ticket holders are frequently offered preferred seating at special events or extra games.\n\nSeason passes are commonly used for winter sports, but were originally in American ski resorts a privilege for club members and investors. However in 2000 a discounting movement across the US triggered a price war and increased the widespread use of season passes.\n\nA season ticket is also an option for many music venues (including Opera, Ballet, Symphony houses) and repertory theatre companies. The season subscription usually offers a discounted price over purchasing a ticket for each concert or play in a series or all concerts or plays in a season. (Typically, season tickets are only offered to donors who support the cultural institution).\n\nIn public transport, a season ticket allows the user to travel by public transport an unlimited number of times within a period of time. The term \"commuter pass\" is used in some countries. Season tickets are typically sold for a week, month or year. The validity of season tickets varies. At one extreme it may only allow travel between two points (A to B) by only one operator and one route (if there are more than one competing). At the other extreme, it may allow unlimited travel within a geographic area, or even a whole country, allowing free choice of method of transportation (bus, tram, train, etc.) and free choice of operating company. See integrated ticketing.\n\nIn television, a season ticket refers to the term invented by the manufacturers of the TiVo digital video recorder for the function which allows a user to program the device to record all the episodes of a season of a television show, even if their airings are rescheduled or pre-empted. Similar functions are available on competitive digital video recorder systems and software packages, such as ReplayTV and IceTV. With the advent of digital streaming services, such as Netflix and digital video stores like iTunes and Google Play Store, one can also purchase a season pass to gain the ability to watch every episode of a chosen season at one's leisure on a computer or mobile device.\n\nOther examples of venues that often offer season passes include amusement parks, recreational sports venues (ski areas), and paid-admission parks (state and national parks). Some passes may also grant additional perks, such as free or prepaid parking, or coupons exclusive to pass-holders.\n\n"}
{"id": "17461829", "url": "https://en.wikipedia.org/wiki?curid=17461829", "title": "Seated Bishop", "text": "Seated Bishop\n\nSeated Bishop is a lindenwood statue carved by Tilman Riemenschneider. Completed in 1495 during the transition period between late Gothic and Renaissance, it currently resides in the Metropolitan Museum of Art as part of the Cloisters Collection.\n\nKeeping in the lindenwood sculpting tradition of the time, the statue was not painted, only a few details were stained in black for emphasis.\n\n"}
{"id": "1307800", "url": "https://en.wikipedia.org/wiki?curid=1307800", "title": "Subaltern Studies", "text": "Subaltern Studies\n\nThe Subaltern Studies Group (SSG) or Subaltern Studies Collective is a group of South Asian scholars interested in the postcolonial and post-imperial societies which started at the University of Sussex in 1979–80. The term Subaltern Studies is sometimes also applied more broadly to others who share many of their views. Their anti-essentialist approach is one of history from below, focused more on what happens among the masses at the base levels of society than among the elite.\n\nThe term \"subaltern\" in this context is an allusion to the work of Italian Marxist Antonio Gramsci (1891–1937). It refers to any person or group of inferior rank or station, whether because of race, class, gender, sexual orientation, ethnicity, or religion. \n\nThe SSG arose in the 1980s, influenced by the scholarship of Eric Stokes and Ranajit Guha, to attempt to formulate a new narrative of the history of India and South Asia. The group started at the University of Sussex and then continued and traveled, mainly through Guha's students. This narrative strategy most clearly inspired by the writings of Gramsci was explicated in the writings of their \"mentor\" Ranajit Guha, most clearly in his \"manifesto\" in Subaltern Studies I and also in his classic monograph \"The Elementary Aspects of Peasant Insurgency\". Although they are, in a sense, on the left, they are very critical of the traditional Marxist narrative of Indian history, in which semi-feudal India was colonized by the British, became politicized, and earned its independence. In particular, they are critical of the focus of this narrative on the political consciousness of elites, who in turn inspire the masses to resistance and rebellion against the British. \n\nInstead, they focus on non-elites — subalterns — as agents of political and social change. They have had a particular interest in the discourses and rhetoric of emerging political and social movements, as against only highly visible actions like demonstrations and uprisings.\n\nOne of the group's early contributors, Sumit Sarkar, later began to critique it. He entitled one of his essays \"Decline of the Subaltern in Subaltern Studies\", criticizing the turn to Foucauldian studies of power-knowledge that left behind many of the empiricist and Marxist efforts of the first two volumes of \"Subaltern Studies\". He writes that the socialist inspiration behind the early volumes led to a greater impact in India itself, while the later volumes' focus on western discourse reified the subaltern-colonizer divide and then rose in prominence mainly in western academia. Even Gayatri Spivak, one of the most prominent names associated with the movement, has called herself a critic of \"metropolitan post-colonialism\".\n\nIndian sociologist Vivek Chibber has criticized the premise of Subaltern Studies for its obfuscation of class struggle and class formation in its analysis, and accused it of excising class exploitation from the story of the oppression of the subaltern. His critique, explained in his book Postcolonial Theory and the Specter of Capital, is focused on the works of two Indian scholars: Ranajit Guha and Dipesh Chakrabarty.\n\nRajiv Malhotra, an Indologist, has fiercely criticized Subaltern Studies as being hijacked by vested interests with left and far-left leaning as a tool for political gain, spreading communist ideology and, even, diverted to spread neocolonial ideas in India..\n\nScholars associated with Subaltern Studies include:\n\n\n\n\n"}
{"id": "39851960", "url": "https://en.wikipedia.org/wiki?curid=39851960", "title": "The Australian Journal", "text": "The Australian Journal\n\n\"The Australian Journal\" was one of Australia's most successful and influential magazines, running for ninety-seven years from 1865 to its final issue printed in 1962. The magazine began as 'A Weekly Record of Amusing and Instructive Literature, Science and the Arts', but gradually became a more focussed publication of popular short stories written by Australian writers for readers across both genders and age groups. \n\n\"The Australian Journal\" began as a weekly publication for its first four years before stretching out to monthly issues. The monthly issues sold for 6d for a number of years, offering value for money in a marketplace where it was competing with publications from England. Each issue contained a variety or departments for both sexes and all ages, which attributed to its success. During the Depression and into World War II, the magazine maintained a circulation of around 100,000 in the 1930s and 40s and peaked at 120,000 in 1945. A circulation that was second only to The Bulletin. \"The Australian Journal\" supplied popular fiction to all Australians by offering a wide range of fiction of varying genres - adventure, romance, mystery, and crime/detective stories set in Australian cities or in the Bush. A typical issue of \"The Australian Journal\" was likely to include: a few serials headed by illustrations, a comic tale, half-a-dozen pages of advertisements, some full-page illustrations, several poems and short stories, a paper pattern illustration for a lady's frock, as well as a few non-fiction articles. The quality of the work varied throughout the issues, which likely played a part in the success of the magazine. The works ranged from the 'Sixpenny Dreadful' class of stories through to works of the highest literary standard. This allowed the journal a wide readership and works that would appeal to a whole family or peer group.\n\nBy the 1920s \"The Australian Journal\" was marketing itself as a literary magazine. The front cover of the August 1926 issue sports an illustration of a cowboy on horseback with a revolver in hand, with a line from a featured short story at the bottom of the page which reads - \"'Shoot! And be d--- to you!' 'PARTNERS' - A Great Short Story in This Issue.\" The cover also advertises the inclusion of works by 'popular authors' Arthur J. Palk, W.D. Flannery, Rex Grayson, and H.G. Barwick. Although being aimed at both men and women, this particular issue seems to target adolescent boys. The journal had a wide range of subject matter on its covers over the ninety-seven years of its publication, with each issue perhaps targeting a specific audience to keep its readership as widespread as possible.\n\nIn the 1950s editorial changes were made to modernise the magazine for a changing audience. Crossword puzzles were introduced, as well as a children's page, recipes, and fashion articles. This left less room for fiction works and blurred the magazine's focus. As the readership began to decline the size of the magazine reduced from eighty-two to seventy four pages, and again to sixty-six pages until it folded in 1962. Television has been accused of aiding in the magazine's decline, but it is more likely the magazine failed due to a combination of issues, including changing habits in its readership and the magazine's dilution of its original concept and features in an attempt to move with the times. \n\n\nMarcus Andrew Hislop Clarke was born in London on the 24th of April, 1846 and died in 1881. His father was a barrister and his mother passed away a few months after his birth. In 1864, Clarke set off for Melbourne, initially staying with his uncle. After a short stint working at a bank, he moved out to work on a station and discovered the beauty of the Australian bush, which would have a great influence on his writing. He continued to write and sketch, being a talented cartoonist and illustrator as well as a writer, and had his work published under the pen name Marcus Scrivener. It is said that Clarke lost this job as a station hand in part because his influence over the other workers was showing in their eagerness to take more regular breaks to read novels under a tree. Whether this is true or not, Clarke's time as a station hand would have reached its end sooner or later as his literary ambitions began to grow. Not long after leaving the station, Clarke found work in Melbourne as a member of the literary staff of the \"Argus\" journal.\n\nClarke's first (although unfinished) novel, \"Long Odds\", appeared in serial form in the \"Colonial Monthly,\" yet he was only able to write a few chapters before being thrown from his horse and fracturing his skull. In 1869 Clarke took on the editorship of Humbug and around the same time married Marian Dunn. Shortly after this, Clarke began work on His Natural Life and spent a brief stint as the editor of \"The Australian Journal\". Under Clarke's leadership of \"The Australian Journal\", the magazine lent a focus toward accepting submissions set in the colonies and by domestic writers. \n\nMarcus Clarke greatly assisted the popularity of \"The Australian Journal\" by publishing his celebrated work, \"His Natural LIfe\" in serial format. Clarke later altered the story to better suit the longer form of a novel and renamed it \"For The Term of his Natural Life.\" The novel went on to garner widespread success in Australia, Britain and America and was also translated into German. \"The Australian Journal\" declared in 1881 that \"For The Term of his Natural Life\" should be \"read by the youth of Australia and accepted as a classic.\" Mark Twain made a similar statement to this when giving a visiting lecture in Melbourne in October, 1895. In his lecture, Twain referred to Clarke as a literary genius, and argued that \"no works of such a man should be left unpublished.\" Twain also commented on Clarke's popularity in Australia, suggesting that \"we think a deal more of Marcus Clarke in our country than I am sorry to think you do here.\" Perhaps Clarke would have been better off living outside of Australia, as he spent a fair deal of his life dealing with pecuniary difficulties, despite the widespread success of his work. Clarke passed away at the early age of 35, robbing Australian literature of many more great works. \n\nClarke contributed to many periodicals, including the popular Australian publication, \"The Bulletin\". \"The Bulletin\" published a short article following Clarke's death stating their willingness to accept subscriptions in aid of his widow and children. They also released a memorial volume of Clarke's collected writings, sold for one guinea. They declared Clarke to be \"the most brilliant man of letters this country has yet seen.\" \n\nRon Campbell was a school teacher in the 1920s with the ambition of writing the great Australian novel. He submitted work to \"The Australian Journal\" and worked as a teacher and writer between 1922 and 1926 until he took over the editorship of \"The Australian Journal\" from his 81-year-old predecessor, Mr. Adcock.\n\nCampbell was editor of \"The Australian Journal\" for just under thirty years, from 1926-1955. During this period the opportunities for freelance short story and serial writers peaked, with Campbell also placing a strong focus on publishing Australian writers and writing. In the decades before he was appointed editor, the magazine relied on a mixture of domestic work as well as syndicated fiction from overseas, in particular England and the United States. Campbell took his work seriously and although the publication aimed for a wide audience he begrudged the \"'academics and highbrows' for suggesting that the \"Australian Journal\" 'was a trivial publication suitable only for the less knowledgeable type of housewife.'\" Yet he, himself, wrote that \"The Australian Journal\" readers were \"mainly women, with limited literary tastes and expectations.\" Campbell endeavoured to develop continued relationships with the Australian writers that contributed to the Journal during his editorship, and to encourage younger writers trying to build their careers. By the 1940s, \"The Australian Journal\" was one of the few Australian periodicals that was willing to pay its contributors a competitive rate for their submissions. However, it was during this time that Campbell complained of the declining number of Australian writers able to produce quality work in the short story format, stating that \"the fact remains that of late years the number of writers who can turn out the well-constructed and characteristic yarn of between 5,000 and 6,000 words seems to be diminishing.\" Campbell went on to create an anthology of works featured in \"The Australian Journal\" during his editorship. The collection was titled \"The Australian Journal Story Book\", but was never published. Campbell had a semi-regular editorial column in the Journal that he titled 'In Passing'.\n\nThe importance of Campbell's work as editor of \"The Australian Journal\" and his contribution to Australian literature can be seen in the dedications to Campbell in novels from authors such as Robert S. Close and S.H. Courtier. \n"}
{"id": "5883015", "url": "https://en.wikipedia.org/wiki?curid=5883015", "title": "The Lost City (1935 serial)", "text": "The Lost City (1935 serial)\n\nThe Lost City is an independently made science fiction film serial created and produced in 1935 by Sherman S. Krellberg and directed by Harry Revier.\n\nScientist Bruce Gordon comes to a secluded area in Africa after concluding that a series of electrically induced natural disasters had originated from in the area. There he finds the crazed Zolok, last of the Lemurians, in a secret complex inside a mountain.\nZolok had created the natural disasters as a prelude to his attempt to take over the world, holding a brilliant scientist, Dr. Manyus, there hostage, along with his daughter, Natcha. He had forced Manyus to create mindless \"giant\" slaves out of the natives as a private army and as the serial progresses we learn Manyus also turned another tribe, the spider-worshipping Wangas, into thin, impotent whites. Gordon helps Manyus and his daughter to escape Zolok, but they encounter Ben Ali, a malignant slave trader; meet the sexy native Queen Rama, who tries to help them; and survive harrowing jungle adventures before returning to the Lost City and stopping Zolok's plan.\n\n\nThe film took the premise of that year's \"The Phantom Empire\" but transferred the lost civilization motif from the west to another popular serial locale, the African jungle.\n\nSherman S. Krellberg had the serial edited into four different feature versions over time, perhaps setting a record for feature versions of a serial. The first feature consisted of the first three episodes of the serial and the first reel of the fourth episode edited together, and supplemented with footage not part of the serial itself which drew the adventure to a loose conclusion; and the second was compiled from material in the first and last four chapters of the serial, omitting the adventures with the slave traders, the spider people and Queen Rama, but ending as did the serial. Both these features were made and released in 1935 and both were also called The Lost City. The first of these was also designed so that it could be followed over successive weeks by the remaining chapters in the serial.\n\nIn the early '40s Krellberg created a new feature version that incorporated material from the adventures with the slavers, spider people and jungle queen, and released this under the title \"City of Lost Men\". Finally, in the 1970s, he took the first feature version and clumsily edited in, at the end, most of the footage from the last chapter, creating what goes beyond a continuity gap and is rather a continuity \"abyss\", and attached the City of Lost Men title to this feature.\n\nIt's not clear whether the last feature had an actual theatrical release or went directly to television. The first City of Lost Men appears to be lost, and videos and DVDs being sold under that title are sourced from film prints of this final feature. Since it incorporates the entire first feature version entitled Lost City, that film cannot fairly be said to be lost, although no separate video issue of that version under its own titles, is known. Video/DVD offerings of The Lost City as a feature are from prints of the second feature version described.\n\n\n\n\n\n\n"}
{"id": "391239", "url": "https://en.wikipedia.org/wiki?curid=391239", "title": "Truism", "text": "Truism\n\nA truism is a claim that is so obvious or self-evident as to be hardly worth mentioning, except as a reminder or as a rhetorical or literary device, and is the opposite of falsism.\n\nIn philosophy, a sentence which asserts incomplete truth conditions for a proposition may be regarded as a truism. An example of such a sentence would be \"Under appropriate conditions, the sun rises.\" Without contextual supporta statement of what those appropriate conditions arethe sentence is true but incontestable. A statement which is true by definition (for example, the Lapalissade \"If he were not dead, he would still be alive\") would also be considered a truism.\n\nThe word may also be used with a different sense in rhetoric, to disguise the fact that a proposition is really just an opinion. \n"}
{"id": "14179099", "url": "https://en.wikipedia.org/wiki?curid=14179099", "title": "Walt Disney's World War II propaganda production", "text": "Walt Disney's World War II propaganda production\n\nBetween 1942 and 1945, during World War II, Walt Disney Productions was involved in the production of propaganda films for the U.S. government. The widespread familiarity of Disney's productions benefited the U.S. government in producing pro-American war propaganda in an effort to increase support for the war.\n\nDuring World War II, Disney made films for every branch of the U.S. military and government. The government looked to Walt Disney more than any other studio chief as a builder of public morale providing instruction and training the sailors and soldiers.\" This was accomplished through the use of animated graphics by means of expediting the intelligent mobilization of servicemen and civilians for the cause of the war. Over 90% of Disney employees were devoted to the production of training and propaganda films for the government. Throughout the duration of the war, Disney produced over 400,000 feet of educational war films, most at cost, which is equal to 68 hours of continuous film. In 1943 alone, 204,000 feet of film was produced. \n\nIn 1942, Disney was approached with requests from the U.S. services. The Navy was the first, and other branches of the government, including the Army, the Army Air Forces, the Department of Agriculture, and the Treasury Department, rapidly caught on to Disney’s creative approach to generating educational films, propaganda and insignias.\n\nAs well as producing films for different government divisions from 1942 to 1943, Disney was asked to create animation for a series of pictures produced by Colonel Frank Capra for the U.S. Army. This series included films such as \"Prelude to War\" and \"America goes to War\". Although these films were originally intended for servicemen, they were released to theaters because of their popularity.\n\nThe Navy first requested 90,000 feet of film to be ready in three months. The purpose of these films was to educate sailors on navigation tactics. This was a shock for Disney, as he was used to creating 27,000 feet of film in a year.\n\nThe Office of the Coordinator of Inter-American Affairs also requested educational films for aviation branches of the government. The subjects of these films varied widely from aerology and not compact tactics to ground crew aircraft maintenance.\n\nDisney created \"The New Spirit\" (1942) after a request from the Secretary of the Treasury, Henry Morgenthau, Jr., to make Americans accept the payment of income taxes. The film was followed by \"The Spirit of '43\" (1943). In this film, Donald Duck deals with income taxes and shows their benefit to the American war effort. The film was seen by 26 million people. In a later Gallup poll 37% admitted that the film played a factor on their willingness to pay taxes. Disney also made a book for children to try to encourage them to purchase War Savings stamps.\n\nAerology film production was supervised by naval aviation experts and some members of Disney's team learned how to fly to better understand the problems the Army Air Forces encountered. \"Victory Through Air Power\" (1943) is one of the propaganda films Disney produced for air warfare. This film is an attempt to sell Major Alexander de Seversky's theories about the practical uses of long range strategic bombing. The animated film humorously tells about the development of air warfare and then switches to the Major illustrating how his ideas could win the war for the Allies.\n\nAs requested by the US Government, Walt Disney created a number of anti-German and anti-Japanese films for both the soldiers and the US public. He wanted to portray these countries and their leaders as manipulative without morals. A few of the films he produced were \"Reason and Emotion\" (1943), \"Der Fuehrer's Face\" (1942), \"Education for Death - The Making of a Nazi\" (1943), and \"Commando Duck\" (1944). \nIn \"Der Fuehrer’s Face\", Donald Duck experiences a day in a Nazi country where he has to make do with eating ridiculous Nazi food rations (smell of bacon and eggs, coffee made with one bean, and a slice of stale bread) experiences a day at a Nazi artillery factory and breaks down. He wakes up realizing that the experience was a nightmare, embraces a model of the Statue of Liberty and exclaims \"Am I glad to be a citizen of the United States of America!\"\n\n\"Education for Death - The Making of a Nazi\" was a wartime propaganda film that takes on the perspective of Hans, a young German boy. As the movie progresses and Hans is exposed to Hitler youth and the Nazi culture, his ability to value human life decreases. In \"Commando Duck\", Donald, by himself, destroys an entire Japanese airbase.\n\n\n\n"}
{"id": "58731901", "url": "https://en.wikipedia.org/wiki?curid=58731901", "title": "William Farrar (settler)", "text": "William Farrar (settler)\n\nWilliam Farrar was an early settler and member of the House of Burgesses of Colonial Jamestown. He was born April 28, 1583 in Croxton, Lincolnshire, England. He died on June 11, 1637 in Jordan's Journey, Colonial Virginia. He came to Virginia.along with Lord Delawareaboard the \"Neptune\" in August 1618. Farrar was a member of the King’s Council, appointed a commissioner of the upper part of the James River community. He was one of a committee of 20 that arrested Governor John Harvey and returned him to England. The Council was considered as the most important in the government of the colony, for laws were passed and the representative form of government which the United States has today became well established at that time.\n\nWilliam Farrar was the 3rd son of John Farrer the Elder, Esquire of London and Croxton, Lincolnshire, a wealthy merchant and gent of London. At the time of Farrar's venture to the New World, Virginia was still a joint stock company, the Virginia Company of London, sanctioned by Royal Charter.\n\nFarrar was a subscriber to the Third Charter of the Virginia Company. His name appears among the citizens and merchants of London listed in Article V of the Charter, \"So that posterity may hereafter know who have adventured and not been sparing of their purses in such a noble and generous action for the general good of their country...\" Alexander Brown wrote:\nOn March 16, 1618, William Farrar sailed from London to Virginia aboard the \"Neptune\" with Lord Delaware, who had been urged by the settlers to return to Virginia as a governor and who had persuaded many of the gentry to emigrate to Virginia. Although the ship was a large one, with 200 passengers, specially equipped by the Virginia Company for Lord Delaware's return, the voyage was a long, perilous one lasting sixteen weeks.\n\nFarrar was granted 100 acres where the Appomattox flowed into the James River, at a location known now as Hopewell.  In colonial times Hopewell was part of Bermuda Hundred, Virginia. At the time of the 1622 Jamestown Massacre, William Farrar was living with 21 others at a community located on the south bank of the Appomattox as it emptied into the James River, the patent was named Bermuda's Hundred, hundred being an old Saxon description of a land that could field 100 men for a fyrd or support 100 families.\n\nDuring the Indian massacre of 1622, which began on Good Friday, March 22, 1622, ten people were killed at William Farrar's house on the Appomattox River. Being forewarned by Richard Pace of Paces Paines, Farrar escaped with ten others. They rowed down the James River to Beggars Bush which apparently was well fortified and protected. Beggars Bush became known as Jordans Journey, today Jordan Point, Virginia. William Farrar quickly made a place for himself in the colony acting as appraiser, executor of estates, a member of the King's Council and justice of two counties. William Farrar was first granted 100 acres on the Appomattox River, Charles City County, Virginia about three miles from where it flows into the James River. Listed in the minutes of the Virginia Company, May 1625: \"Land laid out for ye Company below Shirley Hundred land: Wm. ffarrar uppon Appomatucke River 100 acres.\n\nFarrar is found in the 1623/24 Jamestown Muster. as fferrar William\n\nSamuel Jordan died in March 1623. His wife Cecily was with child. Farrar sought the hand of Samuel Jordan's widow, whom Reverend Greville Pooley had already claimed, thus leading to the first Breach of promise suit filed in North America. Pooley was persuaded by the Reverend Samuel Purchase to drop the case. On January 3, 1624/25 he signed an agreement freely acquitting Mrs. Jordan of her former promises. William and Cecily married.\n\nWilliam Farrar and the widow Cecily Jordan had three children: Colonel William Farrar, born 1627, married Mary Baugh, Cecily Farrar, born 1629, and John Farrar born before 1631. John served as Justice of the Peace and master of the ship Lever of Leverpool.\n\nThe Farrar (also spelled Ferrar) family are of Yorkshire origin. William Farrar's father was John Farrer the elder, a stockholder in the Virginia Company. John Ferrar died on November 11, 1627. In his will he stipulated: \"William Farrar all those messuages, land, etc., in Hoddesden, Bloxeborne and Amwell or elsewhere in the countie of Hertford heretofore conveyed to Henry and John Farrer my sons to use, to my son Willian and his heirs. To him also and his wife and children 20 pounds annuity a yeare during the terme of their lives and longest liver of them to be paid out of Greate Ewood and Little Ewood at ye feaste of ye Annunciation of ye blessed Virgin and St. Michaell the Archangel by my sonne Henry Farrer his heirs or assigns.\"\n\n6 Sep 1631: Indenture between William Farrar of London gent of the one part and Henry Farrer of Reading, Berks, Esquire, of the other part. Whereas John Farrer the elder of London, Esquire, deceased, bequeathed to Willima Farrar and to Cecily his wife and Ciciely and William his children one annuite or yearly rent of 20 pounds from the lands of the said John Farrer called Great Ewood and Little Ewood in the parish of Halifax, Yorks. And, whereas, William Farrar had by his \"deed in writinge bearing date of the eight and twentieth day of June last past\" for the sum of 240 pounds of good and lawful money of England\" had released (his inheritance) unto the said Henry and John Farrer, his brothers, then owners of the lands called Great Ewood and Little Ewood. \"William Farrar acknowledges the receipt of 200 pounds paid to him by Henry Farrar for the purchase of \"all those messuages, howses, buildings, lands, meadowes, pstures with all and everie thier appurtenances, scituate lying and being in Hoddesdon, Broxbourne and Amwell or any of them in the county of Hertf., \"which Henry and John Farrar did, in accordance with their father's will. convey to William Farrar.\"Henry Farrar, his heirs or assignes will pay to William Farrar \"or his executors if he be not living\" such further soms of money as with money already paid unto him for the true value of the land: otherwise upon repayment to Henry Farrer or his heris by William Farrar or his heires, of the said 200 pouns. plus any epense Henry may have had in repairing the house and said buildins. etc... Henry will reoconvey the property to William free of any incumbrances.\"Signed and sealed \"the day and yeare first above written Annoque domini Abstracted from transcription by Miss Mary Flower, of a Crown copyright by permission of the Public Record Office\".\n\nWilliam was granted a 2,000 acre headright patent for his payment of the transportation of 40 indentured servants from England. A headright was 50 acres a head. He died before he could exercise his patent. His son William filed the claim in 1637.\n\nSince William Farrar and Cecily Jordan had married, his bond to administer Samuel Jordan's estate was ordered canceled: \"At a Court, 2 May 1625, 'Yt is ordered yt Mr. William Farrar's bonde shall be cancelled as overseer of the Estate of Samuel Jordan dec'd.\"\nOn March 14, 1625/6 Charles I of England appointed him Justice of Charles City and Henrico Counites, and a member of the King's Council, a position he held until 1632. He attended quarterly court at Jamestown and was closely associated with the governor, councillors and burgesses. Shortly after William Farrar's appointment to the Council, he was made commissioner of the Upper Partes on August 7, 1626: \"Monthlie Courtes to be kept above Percies hundred shalbe kept at the discretione of Mr. William ffarrar, one of his Majesty's Councill of State, either at Jourdan's Journey of Shirley Hundred.\" William Farrar's appointment, in 1626, as commissioner of the Upper Partes was affirmed in 1628: \"Minutes of the Council and General Court 1622–29: At a Court at James Citty the 7th of March 1628, present John Potts Esqr, Govenor and Captain General, Captain Smyth, Captain Mathews, Mr. Claybourne, Mr. ffarrar ffor the ease of the People and according to the order established in General Assembly it is ordered that a Commission be drawen for a Monthly COrt to bee holden in the Upper Partes. The Commissioners to bee vizt: Mr. ffarrar, Capt. Eppes; Capt. Davis; Capt: Mr. Thomas Palmer; Henry Throgmorton; Mr. ffarrar to bee alwaies one.\"\n\nThe important Virginia Assembly, established by the Great Charter in 1619, had functioned five years when James I dissolved the Virginia Company in 1624, and was not called to reconvene until 1628. During this period of great uncertainty and insecurity for the colonists, not knowing what to expect under Royal rule, the King's Council, formed to represent the Royal government, made the laws and all decisions, most of which were later ratified by the Assembly when it was recalled. As late as 1632, Charles I appointed a commission, which included Nicholas Ferrar. the younger and John Ferrar Esquire, \"as Council of Superintendence over Virginia, empowering them to ascertain the state of its laws, commerce and government and report back to his Majesty.\" It was during this critical period, 1625-1635,that William Farrar served on the Third Council, the most important in the government of the colony,{by reason of it permitting private ownership of property and representative government. Rights not granted or recognized in the first two King's Council\n\nIn the list of burgesses for 1631/32, Arrowhattocks, Neck-of-Land and Curles were represented by Capt. Thomas Osborne, while \"both Shirley Hundreds, Mr. ffarrars and Chaplaynes were represented by Francis Eppes and Walter Afton\". Thus William Farrar was not at the Neck-of Land (Farrar's Island) and it may be that it was only after the sale of his inheritance in London in 1631 that the 2,000 acre grant was patented, apparently from money received from his inheritance. Whatever the date, the delay proved fortunate for William Farrar, for he was able to select one of the choicest locations, the site of Henricus Towne, the second settlement in the colony. His land extending to Varina, the county seat, and his duties as \"chief\" justice of the county made him a close neighbor and associate of the leading families of Henrico as well as Charles City County, Virginia.\n\nWilliam Farrar died before 10 June 1637, the date on which his son William received a patent in Virginia as his heir for 2000 acres in Henrico County. His will: \"William Farrar, sonne & heire to William Farrar, late of Henrico, deed 2000 acs. Henrico Co., 11 June 1637, p. 436. Abutting Ely. upon the Gleab land of Varina, extending Wly. to the bottome of Island, Sly. Upon the maine river & Nly. into the woods. Trans, at his owne costs of 40 pers:\"\nBaker, Jon Hooke, Edward\nBaker, William Howman, Jon\nBrownrdige, Matthew Hues, Jon\nColeman, Robert Lewd, Richard\nDawson, William* Pead, Jan*\nCrump, Giles Johnson, Richard\nDimock, Martin Penborne, Christe\nDowenes, Eustace Posey, Frank\nEdmonds, Howell Pratt, Jon\nFewson, Richard Price, Jon\nFoster, Elizabeth Richardson, William\nFrame*France)Jon Rigsby, James\nGarner, James Roberts, James\nGarner, Richard Robinson, Patrick\nGibson, Jon Smith, Jon\nGreeke, Richard Thomas, William\nGyllom, Henry Thomas, William\nHaswell, Henry Turner, Robert*\nHely, Jon* Waroner, Matthew\nHaynes, Mary Williams, Thomas\" Names with asterisks appear in the Muster of 1624/25\n\nOne of the most dramatic events occurring during William Farrar's tenure on the Council was the arrest and deportation of Governor John Harvey (Virginia) \"a Royal governor who had exercised unbearable tyrannical and arbitrary power.\" After an eventful decade during which the Virginia Company was overthrown along with the loss of a representative form of government which it had attempted to establish there was uncertainty about what to expect from Royal rule. In March 1634 the Council reluctantly voted to accept the loss of prime territories to Lord Baltimore, but rebelled against Gov. Harvey. William Farrar was one of a committee of 20 appointed to arrest Gov. Harvey and return him to England in protest.\n\n"}
{"id": "48739899", "url": "https://en.wikipedia.org/wiki?curid=48739899", "title": "Yasmin Jiwani", "text": "Yasmin Jiwani\n\nYasmin Jiwani is a feminist academic and activist. In her research, she examines the intersectionality of race and gender in media narratives of violence against women and representations of racialized peoples. Currently, Dr. Jiwani is a full professor in the Department of Communication Studies at Concordia University in Montreal, Quebec. She is the author of Discourses of Denial: Mediations of Race, Gender and Violence.\n\nIn 1979, Jiwani graduated from University of British Columbia with a Bachelor of Arts in psychology. In 1983, she attained her master's degree in sociology from Simon Fraser University. Her thesis topic was entitled “The Forms of Jah: The Mystic Collectivity of the Rastafarians.” In 1988, Jiwani received a certificate from the Summer Institute for Semiotic and Structural Studies from UBC. Four years later, she also obtained a certificate from the New Initiatives in Film & Video Program, Studio D, from the National Film Board of Canada in Montreal, Canada. In 1993, Jiwani completed a PhD in communication studies at Simon Fraser. Her doctoral dissertation was entitled “By Omission and Commission: ‘Race’ and Representation in Canadian Television News.”\n\nFrom 1978 to 1980, Jiwani was a teaching assistant (TA) in the Department of Psychology at UBC. For the next few years, she worked as a TA and guest lecturer at both Simon Fraser and McMaster University. From 1986 to 1988, Jiwani became a sessional instructor in the School of Communication at SFU. From 1995 to 1998, Jiwani became a lecturer in Women’s Studies at UBC. In addition, she was a research scholar for the Centre for Research in Women’s Studies and Gender Relations. From 1997 to 2001, Jiwani worked as an adjunct professor at Simon Fraser in the School of Criminology.\n\nSince 2003, she has been a research fellow at the Simone de Beauvoir Institute at Concordia University. In addition, Jiwani is an academic research associate for the Centre for Research & Education on Violence Against Women & Children at University of Western Ontario.\nFrom 2001 to 2005, Jiwani was an assistant professor in Communication Studies at Concordia. From 2005 to 2012, she became an associate professor in the same department. In 2012, Jiwani was made a full professor.\n\nFrom 1989 to 1990, Jiwani worked as the communications director for the In Visible Colours International Film and Video Society. For the next year, she was the Ethnic Liaison Officer for Canada’s national statistical agency, Statistics Canada, in the Pacific Region. From 1991 to 1994, Jiwani was the Coordinator of the Women’s Program at the National Film Board of Canada.\n\nFrom 1994 to 1995, Jiwani became a research coordinator for the BC/Yukon FREDA Centre for Research on Violence Against Women and Children. The FREDA Centre represents a joint venture between grassroots community and women’s organizations and academics at SFU. From 1995 to 2001, she became the executive coordinator and principal researcher at the FREDA Centre.\n\nAlongside Sherene Razack and Sunera Thobani, Jiwani has been involved in Researchers and Academics of Colour for Equality/Equity (R.A.C.E.). R.A.C.E. is an organization dedicated to anti-racist, anti-colonial, and feminist scholarship and praxis. In 2009, as a member of the National Steering Committee, Jiwani co-organized the 9th R.A.C.E. conference “Compassion, Complicity and Conciliation: The Politics, Cultures, and Economics of Doing Good.”\n\n\n\n"}
