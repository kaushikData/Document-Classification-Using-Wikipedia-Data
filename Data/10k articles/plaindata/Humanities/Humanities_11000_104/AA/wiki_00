{"id": "487334", "url": "https://en.wikipedia.org/wiki?curid=487334", "title": "African-American Vernacular English", "text": "African-American Vernacular English\n\nAfrican-American Vernacular English (AAVE), known less precisely as Black Vernacular, Black English Vernacular (BEV), Black Vernacular English (BVE), or colloquially Ebonics (a controversial term), is the variety (dialect, ethnolect and sociolect) of English natively spoken by most working- and middle-class African Americans and some Black Canadians, particularly in urban communities. Having its own unique grammatical, vocabulary, and accent features, African-American Vernacular English is employed by middle-class African Americans as the more informal and casual end of a sociolinguistic continuum; on the formal end of this continuum, middle-class African-Americans switch to more standard English grammar and vocabulary, usually while retaining elements of the nonstandard accent.\n\nAs with most African-American English, African-American Vernacular English shares a large portion of its grammar and phonology with the rural dialects of the Southern United States, and especially older Southern American English, due to historical connections to the region. Mainstream linguists maintain that the parallels between African-American Vernacular English and West African and English-based creole languages are real but minor, with African-American Vernacular English genealogically still falling under the English language, demonstrably tracing back to the diverse nonstandard dialects of early English settlers in the Southern United States. However, a minority of linguists argue that the vernacular shares so many characteristics with African creole languages spoken around the world that it could have originated as its own English-based creole or semi-creole language, distinct from the English language, before undergoing a process of decreolization.\n\nWhile it is clear that there is a strong relationship between AAVE and earlier Southern U.S. dialects, the origins of AAVE are still a matter of debate.\n\nOne theory is that AAVE arose from one or more slave creole languages that arose from the Atlantic slave trade and the need for African captives, who spoke many different languages, to communicate among themselves and with their captors. According to this theory, these captives first developed what are called pidgins, simplified mixtures of languages. Since pidgins form from close contact between speakers of different languages, the slave trade would have been exactly such a situation. Dillard quotes, for example, slave ship Captain William Smith describing the sheer diversity of mutually unintelligible languages just in Gambia. By 1715, an African pidgin had made its way into novels by Daniel Defoe, in particular, \"The Life of Colonel Jacque\". In 1721, Cotton Mather conducted the first attempt at recording the speech of slaves in his interviews regarding the practice of smallpox inoculation. By the time of the American Revolution, varieties among slave creoles were not quite mutually intelligible. Dillard quotes a recollection of \"slave language\" toward the latter part of the 18th century: \"Kay, massa, you just leave me, me sit here, great fish jump up into da canoe, here he be, massa, fine fish, massa; me den very grad; den me sit very still, until another great fish jump into de canoe; but me fall asleep, massa, and no wake 'til you come...\" Not until the time of the American Civil War did the language of the slaves become familiar to a large number of educated whites. The abolitionist papers before the war form a rich corpus of examples of plantation creole. In \"Army Life in a Black Regiment\" (1870), Thomas Wentworth Higginson detailed many features of his black soldiers' language.\n\nAnother theory, the presiding one in the linguistics community, however, is that AAVE did not originate from English-based creole languages that \"decreolized\" back into a dialect of English; rather, most linguists maintain, AAVE has always been a dialect of English. In the early 2000s, Shana Poplack provided corpus-based evidence—evidence from a body of writing—from isolated enclaves in Samaná and Nova Scotia peopled by descendants of migrations of early AAVE-speaking groups (see Samaná English) that suggests that the grammar of early AAVE was closer to that of contemporary British dialects than modern urban AAVE is to other current American dialects, suggesting that the modern language is a result of divergence from mainstream varieties, rather than the result of decreolization from a widespread American creole.\n\nLinguist John McWhorter maintains that the contribution of West African languages to AAVE is minimal. In an interview on National Public Radio's \"Talk of the Nation\", Dr. McWhorter characterized AAVE as a \"hybrid of regional dialects of Great Britain that slaves in America were exposed to because they often worked alongside the indentured servants who spoke those dialects...\" According to Dr. McWhorter, virtually all linguists who have carefully studied the origins of AAVE \"agree that the West African connection is quite minor.\"\n\nMany pronunciation features distinctly set AAVE apart from other forms of American English (particularly, General American). John McWhorter argues that what truly unites all AAVE accents is a uniquely wide-ranging intonation pattern or \"melody\", which characterizes even the most \"neutral\" or light African-American accent. A handful of multisyllabic words in AAVE differ from General American in their stress placement so that, for example, \"police\", \"guitar\" and \"Detroit\" are pronounced with initial stress instead of ultimate stress. The following are phonological differences in AAVE vowel and consonant sounds.\n\n\n\nJohn McWhorter discusses an accent continuum from \"a 'deep' Black English through a 'light' Black English to standard English,\" saying the sounds on this continuum may vary from one African American speaker to the next or even in a single speaker from one situational context to the next. McWhorter regards the following as rarer features, characteristic only of a deep Black English but which speakers of light Black English may occasionally \"dip into for humorous or emotive effect\":\n\nAlthough AAVE does not necessarily have the simple past-tense marker of other English varieties (that is, the \"-ed\" of \"work\"ed\"\"), it does have an optional tense system with at least four aspects of the past tense and two aspects of the future tense.\nSyntactically, \"I bought it\" is grammatical, but \"done\" (always unstressed, pronounced as /dən/) is used to emphasize the completed nature of the action.\n\nAs phase auxiliary verbs, \"been\" and \"done\" must occur as the first auxiliary; when they occur as the second, they carry additional aspects:\n\nThe latter example shows one of the most distinctive features of AAVE: the use of \"be\" to indicate that performance of the verb is of a habitual nature. In most other American English dialects, this can only be expressed unambiguously by using adverbs such as \"usually\".\n\nThis aspect-marking form of \"been\" or BIN is stressed and semantically distinct from the unstressed form: \"She BIN running\" ('She has been running for a long time') and \"She been running\" ('She has been running'). This aspect has been given several names, including \"perfect phase\", \"remote past\", and \"remote phase\" (this article uses the third). As shown above, \"been\" places action in the distant past. However, when \"been\" is used with stative verbs or gerund forms, \"been\" shows that the action began in the distant past and that it is continuing now. suggests that a better translation when used with stative verbs is \"for a long time\". For instance, in response to \"I like your new dress\", one might hear \"Oh, I been had this dress\", meaning that the speaker has had the dress for a long time and that it isn't new.\n\nTo see the difference between the simple past and the gerund when used with \"been\", consider the following expressions:\nIn addition to these, \"come\" (which may or may not be an auxiliary) may be used to indicate speaker indignation, such as in \"Don't come acting like you don't know what happened and you started the whole thing\" ('Don't try to act as if you don't know what happened, because you started the whole thing').\n\nNegatives are formed differently from most other varieties of English:\n\nWhile AAVE shares these with Creole languages, use data from early recordings of African Nova Scotian English, Samaná English, and the recordings of former slaves to demonstrate that negation was inherited from nonstandard colonial English.\n\n\nAAVE shares most of its lexicon with other varieties of English, particularly that of informal and Southern dialects; for example, the relatively recent use of \"y'all\". However, it has also been suggested that some of the vocabulary unique to AAVE has its origin in West African languages, but etymology is often difficult to trace and without a trail of recorded usage, the suggestions below cannot be considered proven. Early AAVE contributed a number of African-originated words to the American English mainstream, including \"gumbo\", \"goober\", \"yam\", and \"banjo\". AAVE has also contributed slang expressions such as \"cool\" and \"hip\". In many cases, the postulated etymologies are not recognized by linguists or the Oxford English Dictionary, such as \"to dig\", \"jazz\", \"tote\", and \"bad-mouth\", a calque from Mandinka.\n\nAAVE also has words that either are not part of most other American English dialects or have strikingly different meanings. For example, there are several words in AAVE referring to white people that are not part of mainstream American English; these include \"gray\" as an adjective for whites (as in \"gray dude\"), possibly from the color of Confederate uniforms; and \"paddy\", an extension of the slang use for \"Irish\". \"Ofay,\" which is pejorative, is another general term for a white person; it might derive from the Ibibio word \"afia\", which means \"light-colored\", from the Yoruba word \"ofe\", spoken in hopes of disappearing from danger, or via Pig Latin from \"foe\". However, most dictionaries simply say its etymology is unknown. \"Kitchen\" refers to the particularly curly or kinky hair at the nape of the neck, and \"siditty\" or \"seddity\" means \"snobbish\" or \"bourgeois\".\n\nAAVE has also contributed various words and phrases to other varieties of English, including \"chill out\", \"main squeeze\", \"soul\", \"funky\", and \"threads\".\n\nAfrican-American Vernacular English has influenced the development of other dialects of English. The AAVE accent, New York accent, and Spanish-language accents have together yielded the sound of New York Latino English, some of whose speakers use an accent indistinguishable from an AAVE one. AAVE has also influenced certain Chicano accents and Liberian Settler English, directly derived from the AAVE of the original 16,000 African Americans who migrated to Liberia in the 1800s. In the United States, urban youth participating in hip-hop culture or marginalized as ethnic minorities, aside from Latinos, are also well-studied in adopting African-American Vernacular English, or prominent elements of it: for example, Southeast-Asian Americans embracing hip-hop identities.\n\nAfrican-American Vernacular English began as mostly rural and Southern, yet today is mostly urban and nationally widespread, and its more recent urban features are now even diffusing into rural areas. Urban AAVE alone is intensifying with the grammatical features exemplified in these sentences: \"He be the best\" (intensified equative \"be\"), \"She be done had her baby\" (resultative \"be done\"), and \"They come hollerin\" (indignant \"come\"). On the other hand, rural AAVE alone shows certain features too, such as: \"I was a-huntin\" (\"a\"-prefixing); \"It riz above us\" (different irregular forms); and \"I want for to eat it\" (\"for to\" complement). Using the word \"bees\" even in place of \"be\" to mean \"is\" or \"are\" in standard English, as in the sentence \"That's the way it bees\" is also one of the rarest of all deep AAVE features today, and most middle-class AAVE speakers would recognize the verb \"bees\" as part of only a deep \"Southern\" or \"country\" speaker's vocabulary.\n\nNew York City AAVE incorporates some local features of the New York accent, including its high vowel; meanwhile, conversely, Pittsburgh AAVE may merge this same vowel with the vowel, matching the cot-caught merger of white Pittsburgh accents. AAVE accents traditionally do not have the cot-caught merger. Memphis, Atlanta, and Research Triangle AAVE incorporates the vowel raising and vowel lowering associated with white Southern accents. Memphis and St. Louis AAVE is developing, since the mid-twentieth century, an iconic merger of the vowels in and, making \"there\" sound like \"thurr\".\n\nAlthough the distinction between AAVE and General American accents is clear to most English speakers, some characteristics, notably double negatives and the omission of certain auxiliaries (see below) such as the \"has\" in \"has been\" are also characteristic of many colloquial dialects of American English, though still more likely in AAVE. There is near-uniformity of AAVE grammar, despite its vast geographic spread across the whole country. This may be due in part to relatively recent migrations of African Americans out of the American South (see Great Migration and Second Great Migration) as well as to long-term racial segregation that kept black people living together in largely homogeneous communities.\n\nMisconceptions about AAVE are, and have long been, common, and have stigmatized its use. One myth is that AAVE is grammatically \"simple\" or \"sloppy\". However, like all dialects, AAVE shows consistent internal logic and grammatical complexity, and is used naturally by a group of people to express thoughts and ideas. Prescriptively, attitudes about AAVE are often less positive; since AAVE deviates from the standard, its use is commonly misinterpreted as a sign of ignorance, laziness, or both. Perhaps because of this attitude (as well as similar attitudes among other Americans), most speakers of AAVE are bidialectal, being able to speak with more standard English features, and perhaps even a General American accent, as well as AAVE. Such linguistic adaptation in different environments is called code-switching—though argues that the situation is actually one of diglossia: each dialect, or code, is applied in different settings. Generally speaking, the degree of exclusive use of AAVE decreases with increasing socioeconomic status (although AAVE is still used by even well-educated African Americans).\n\nAnother myth is that AAVE is the native dialect (or even more inaccurately, a linguistic fad) employed by all African Americans. Wheeler (1999) warns that \"AAVE should not be thought of as the language of Black people in America. Many African Americans neither speak it nor know much about it\".\n\nBefore the substantial research of the 1960s and 1970s—including William Labov's groundbreakingly thorough grammatical study, \"Language in the Inner City\"—there was doubt as to the existence of a distinct variety of English spoken by African Americans; noted that distinctive features of African American speech were present in the speech of Southerners and argued that there were really no substantial vocabulary or grammatical differences between the speech of blacks and that of other English dialects.\n\nThe United States courts are divided over how to admit statements of ambiguous tense made in AAVE under evidence. In \"United States v. Arnold\", the United States Court of Appeals for the Sixth Circuit held that \"he finna shoot me\" was a statement made in the present tense, so it was admissible hearsay under the excited utterance exception; however, the dissent held that past or present tense could not be determined by the statement, so the statement should not have been admitted into evidence.\n\nIn US courts, an interpreter is only routinely available for speakers of \"a language other than English\". Rickford and King (2016) argue that a lack of familiarity with AAVE (and other minority dialects of English) on the part of jurors, stenographers, and others can lead to misunderstandings in court. They especially focus on the Trayvon Martin case and how the testimony of Rachel Jeantel was perceived as incomprehensible and not credible by the jury due to her dialect.\n\nSpirituals, blues, jazz, R&B, and most recently, hip-hop are all genres associated with African American music; as such, AAVE usually appears, through singing, speaking, or rapping, in these musical forms. Examples of morphosyntactic features of AAVE in genres other than hip-hop are given below:\nMore recently, AAVE has been used heavily in hip-hop to show \"street cred\". Examples of morphosyntactic AAVE features used by black hip-hop artists are given below:\n\nIn addition to grammatical features, lexical items specific to AAVE are often used in hip-hop:\n\nLexical items taken from \n\nBecause hip-hop is so intimately related to the African American oral tradition, non-black hip-hop artists also use certain features of AAVE; for example, in an MC battle, Eyedea said, \"What that mean, yo?\" displaying lack of subject-verb inversion and also the \"auxiliary \"do\"\". However, they tend to avoid the term \"nigga\", even as a marker of solidarity. White hip-hop artists such as Eyedea can choose to accentuate their whiteness by hyper-articulating postvocalic \"r\" sounds (i.e. the retroflex approximant).\n\nAAVE is also used by non-black artists in genres other than hip-hop, if less frequently. For instance, in \"Tonight, Tonight\", Hot Chelle Rae uses the term \"dime\" to mean \"an attractive woman\". Jewel's \"Sometimes It Be That Way\" employs habitual \"be\" in the title to indicate habitual aspect. If they do not employ similar features of AAVE in their speech, then it can be argued that they are modeling their musical performance to evoke aspects of particular musical genres such as R&B or the blues (as British pop musicians of the 1960s and beyond did to evoke rock, pop, and the blues).\n\nSome research suggests that non-African American young adults learn AAVE vocabulary by listening to hip-hop music.\n\nOn Twitter, AAVE is used as a framework from which sentences and words are constructed, in order to accurately express oneself. Grammatical features and word pronunciations stemming from AAVE are preserved. Spellings based on AAVE have become increasingly common, to the point where it has become a normalized practice. Some examples include, \"you\" (you're), \"they\" (their/they're), \"gon/gone\" (going to), and \"yo\" (your). \n\nEducators traditionally have attempted to eliminate AAVE usage through the public education system, perceiving the dialect as grammatically defective. In 1974, the teacher-led Conference on College Composition and Communication issued a position statement affirming students' rights to their own dialects and the validity of all dialects. Mainstream linguistics has long agreed with this. In 1979, a judge ordered the Ann Arbor School District to find a way to identify AAVE speakers in the schools and to \"use that knowledge in teaching such students how to read standard English\". In 1996, Oakland Unified School District made a controversial resolution for AAVE, which they called \"Ebonics\", to be recognized as an African-American language, sparking mixed reactions from linguists, educators, and the nation.\n\n\n"}
{"id": "30456429", "url": "https://en.wikipedia.org/wiki?curid=30456429", "title": "And the Band Played On", "text": "And the Band Played On\n\nAnd the Band Played On: Politics, People, and the AIDS Epidemic is a 1987 book by \"San Francisco Chronicle\" journalist Randy Shilts. The book chronicles the discovery and spread of the human immunodeficiency virus (HIV) and acquired immune deficiency syndrome (AIDS) with a special emphasis on government indifference and political infighting—specifically in the United States—to what was then perceived as a specifically gay disease. Shilts' premise is that AIDS was allowed to happen: while the disease is caused by a biological agent, incompetence and apathy toward those initially affected allowed its spread to become much worse.\n\nThe book is an extensive work of investigative journalism, written in the form of an encompassing time line; the events that shaped the epidemic are presented as sequential matter-of-fact summaries. Shilts describes the impact and the politics involved in battling the disease on particular individuals in the gay, medical, and political communities. Shilts begins his discussion in 1977 with the first confirmed case of AIDS, that of Grethe Rask, a Danish doctor working in Africa. He ends with the announcement by actor Rock Hudson in 1985 that he was dying of AIDS, when international attention on the disease exploded.\n\n\"And the Band Played On\" was critically acclaimed and became a best-seller. Judith Eannarino of the \"Library Journal\" called it \"one of the most important books of the year\", upon its release. It made Shilts both a star and a pariah for his coverage of the disease and the bitter politics in the gay community. He described his motivation to undertake the writing of the book in an interview after its release, saying, \"Any good reporter could have done this story, but I think the reason I did it, and no one else did, is because I am gay. It was happening to people I cared about and loved.\" The book was later adapted into an HBO film of the same name in 1993. Shilts was tested for HIV while he was writing the book; he died of complications from AIDS in 1994.\n\nShilts decided to write \"And the Band Played On\" after attending an awards ceremony in 1983 where he was to receive a commendation for his coverage on AIDS. As described in the book, television announcer Bill Kurtis gave the keynote address and told a joke: \"What's the hardest part about having AIDS? Trying to convince your wife that you're Haitian.\" Shilts responded to the joke by saying that it \"says everything about how the media had dealt with AIDS. Bill Kurtis felt that he could go in front of a journalists' group in San Francisco and make AIDS jokes. First of all, he could assume that nobody there would be gay and, if they were gay, they wouldn't talk about it and that nobody would take offense at that. To me, that summed up the whole problem of dealing with AIDS in the media. Obviously, the reason I covered AIDS from the start was that, to me, it was never something that happened to those other people.\"\n\nAfter publication of the book, Shilts explained his use of the title: \"\"And the Band Played On\" is simply a snappier way of saying 'business as usual'. Everyone responded with an ordinary pace to an extraordinary situation.\" The phrase itself is originally from The Temptations' popular 1970 song about encroaching chaos, \"Ball of Confusion (That's What the World Is Today)\"; in the song, the phrase repeatedly signals that no one is paying proper attention to world problems.\n\nShilts focuses on several organizations and communities that were either hit hardest by AIDS—and were given the task of finding the cause of the disease—or begging the government for money to fund research and provide social services to people who were dying. He often uses an omniscient point of view to portray individuals' thoughts and feelings.\n\nAIDS in the United States first struck gay men and IV drug users in Los Angeles, New York City, and San Francisco due to unsafe sexual and drug-taking practices. Shilts' sources in the gay community tried to remember the last time everyone they knew was healthy, which was the United States Bicentennial celebration in 1976, when sailors came from all over the world to New York. Some of them carried sexually transmitted diseases and rare tropical fevers. A marked difference in these cities arose in two phases of consciousness in the gay community: \"Before\" in 1980, and \"After\" by 1985. \"Before\", according to Shilts, was characterized by a care-free innocence, preceding the period when gay men were aware of a deadly infectious disease. \"After\" signified the realization that gay men knew most or all of their friends were infected with AIDS, and the syndrome became pervasive throughout the media.\n\nIn San Francisco, particularly in the Castro District, gay community activists such as Bill Kraus and Cleve Jones found a new direction in gay rights when so many men came down with strange illnesses in 1980. The San Francisco Department of Public Health began tracing the disease, linked it to certain sexual practices, and made recommendations—stop having sex—to gay men to avoid getting sick, a directive that defied the chief reason why many gay men had migrated to the Castro, and for what gay rights activists in San Francisco had fought for years. Kraus and Jones often found themselves fighting a two-fronted battle: against city politicians who would rather not deal with a disease that affected gay men, who were seen as an undesirable population, and the gay men themselves, who refused to listen to doomsday projections and continued their unsafe behavior.\n\nIn New York City, men like Larry Kramer and Paul Popham, who had previously shown no desire for leadership, were forced by bureaucratic apathy into forming the Gay Men's Health Crisis to raise money for medical research and to provide social services for scores of gay men who began getting sick with opportunistic infections. Shilts describes the desperate actions of the group to get recognition by Mayor Ed Koch and assistance from the city's Public Health Department to provide social services and preventive education about AIDS and unsafe sex.\n\nIn these cities, however, the sizable gay communities in most instances were responsible for raising the most money for research, providing the money for and subsequently the social services for the dying, and educating themselves and other high-risk groups. Kramer would go on to form AIDS Coalition to Unleash Power (ACT-UP), a political activist organization that forced government and media to pay attention to AIDS. Jones formed the NAMES Project that created the AIDS Memorial Quilt, the largest folk art display in the world.\n\nDoctors were the first to deal with the toll that AIDS would take in the United States. Some—like Marcus Conant, James Curran, Arye Rubenstein, Michael S. Gottlieb, and Mathilde Krim—would also realize their professional life's courses in dealing with patient after patient who showed up in their offices with baffling illnesses, most notably lymphadenopathy, pneumocystis carinii pneumonia, Kaposi's Sarcoma, toxoplasmosis, cytomegalovirus, cryptosporidia, and other opportunistic infections that caused death by a grisly combination of ailments overtaxing a compromised immune system. With no information on how the disease was spread, hospital staff were often reluctant to handle AIDS patients, and Shilts reported that some medical personnel refused to treat them at all.\n\nShilts praised the Public Health Department of San Francisco's handling of the new communicable disease as they tracked down people who were sick and linked them to other people who had symptoms, although some of them were living in different parts of the country. He criticized the New York City Public Health Department for doing very little, specifically when Public Health Director David Sencer refused to call AIDS an emergency and stated that the Public Health Department need not do anything because the gay community was handling it sufficiently.\n\nAround the same time gay men were getting sick in the United States, doctors in Paris were receiving patients who were African or who had lived in Africa with the same symptoms as the Americans. Parisian researchers Jean-Claude Chermann, Françoise Barre, Luc Montagnier, and doctor Willy Rozenbaum began taking biopsies of HIV-infected lymph nodes and discovered a new retrovirus. As a scientific necessity to compare it to the American version of HIV, French doctors representing the Pasteur Institute sent a colleague to the National Cancer Institute, where Robert Gallo was also working on the virus. The colleague switched the samples, Shilts reported, because of a grudge he had against the Pasteur Institute. Instead of Gallo comparing his samples with the French samples, he found the very same retrovirus as the French sample, putting back any new results in AIDS research for at least a year.\n\nDepartmental ego and pride, according to Shilts, also confounded research as the Centers for Disease Control and the National Cancer Institutes battled over funding and who might get credit for medical discoveries that were to come from the isolation of HIV, blood tests to find HIV, or any possible vaccine. Once AIDS became known as a \"gay disease\" there was particular difficulty for many doctors in different specialties to get other medical professionals to acknowledge that AIDS could be transmitted to people who were not gay, such as infants born from drug-using mothers, children and adults who had hemophilia (and later, their wives), Haitians, and people who had received blood transfusions.\n\nThe discovery of AIDS in the nation's blood supply and subsequent lack of response by blood bank leadership occurred as early as 1982, yet it was not until 1985, when AIDS antibody testing was approved by the Food and Drug Administration (FDA), that blood bank industry leaders acknowledged that HIV could be transmitted through blood transfusions. Shilts' coverage revealed the feeling among blood bank industry leaders that screening donors for hepatitis alone might offend the donors, and that the cost of screening all the blood donations provided across the country every year was too high to be feasible.\n\nThe Centers for Disease Control (CDC), the agency responsible for tracking down and reporting all communicable diseases in the U.S., faced governmental apathy in the face of mounting crisis. Shilts reported how CDC epidemiologists forged ahead blindly after being denied funding for researching the disease repeatedly. Shilts expressed particular frustration describing instances of the CDC fighting with itself over how much time and attention was being paid to AIDS issues.\n\nAlthough Reagan Administration officials like Health and Human Services Secretary Margaret Heckler and Assistant Secretary Edward Brandt spoke publicly about the epidemic, calling it in 1983 its \"Number One Health Priority\" no extra funding was given to the Centers for Disease Control or the National Institutes of Health for research. What the U.S. Congress pushed through was highly politicized and embattled, and a fraction of what was spent on similar public health problems.\n\nShilts made comparisons to the government's disparate reaction to the Chicago Tylenol murders, and the recent emergence of Legionnaire's Disease in 1977. In October 1982, seven people died after ingesting cyanide-laced Tylenol capsules. The \"New York Times\" wrote a front-page story about the Tylenol scare every day in October, and produced 33 more stories about the issue after that. More than 100 law enforcement agents, and 1,100 Food and Drug Administration employees worked on the case. Johnson & Johnson disclosed they spent $100 million attempting to uncover who had tampered with the bottles. In October 1982, 634 people were reported having AIDS, and of those, 260 had died. The \"New York Times\" wrote three stories in 1981 and three more stories in 1982 about AIDS, none on the front page. The Tylenol Crisis was a criminal act of product-tampering; Legionnaire's Disease was a public health emergency. Twenty-nine members of the American Legion died in 1976 at a convention in Philadelphia. The National Institute of Health spent $34,841 per death of Legionnaire's Disease. In contrast, the NIH spent $3,225 in 1981 and about $8,991 in 1982 for each person who died of AIDS.\n\nShilts accused Ronald Reagan of neglecting to address AIDS to the American people until 1987—calling his behavior \"ritualistic silence\"—even after Reagan called friend Rock Hudson to tell him to get well. After Hudson's death and in the face of increasing public anxiety, Reagan directed Surgeon General C. Everett Koop to provide a report on the epidemic. Though Koop was a political conservative, his report was nevertheless clear about what causes AIDS and what people and the U.S. government should do to stop it, including sex and AIDS education provided for all people.\n\nOn a civic level, the closure of gay bathhouses in San Francisco became a bitter political fight in the gay community. Activists put pressure on the San Francisco Public Health director to educate people about how AIDS is transmitted, and demanded he close bathhouses as a matter of public health.\n\nShilts was assigned to AIDS full-time at \"The San Francisco Chronicle\" in 1982. It was from this unique vantage point that he repeatedly criticized the U.S. news media for ignoring the medical crisis because it did not affect people who mattered, only gays and drug addicts. Shilts noted most newspapers would print stories about AIDS only when it affected heterosexuals, sometimes taking particular interest in stories about AIDS in prostitutes. AIDS was not reported in the \"Wall Street Journal\" until it involved heterosexuals. Many stories called AIDS a \"gay plague\" or \"homosexual disease\" in articles that pointed to it showing up in new populations, like hemophiliacs or people who had received blood transfusions. Shilts recounted the irony of a reporter commenting on how little was reported about the disease, then linking it once more to rarer instances of transmission to non-drug-using heterosexuals. On the other end of the extreme, a general phobia of AIDS was exacerbated by the news media who erroneously reported that AIDS could be contracted by household contact, without checking any facts in their stories, which prompted mass hysteria across the United States.\n\nThe book became a commercial success, contrary to Shilts' own expectations. It remained on the \"New York Times Bestseller List\" for five weeks, was translated into seven languages, nominated for a National Book Award, and made Shilts an \"AIDS celebrity\". In \"Rolling Stone\", Shilts is compared to great American writers whose careers were made by the circumstances surrounding them, such as Thomas Paine in the American Revolution, Edward R. Murrow during the Blitz, and David Halberstam during the Vietnam War. Writer Jon Katz explains, \"No other mainstream journalist has sounded the alarm so frantically, caught the dimensions of the AIDS tragedy so poignantly or focused so much attention on government delay, the nitpickings of research funding and institutional intrigue\". In the \"American Journal of Public Health\", Howard Merkel characterizes \"And the Band Played On\" as the first volume of the historiography of AIDS. Because the content expanded into law and science, reviews were published not only in literary sources but legal and medical journals as well.\n\nLiterary reviews of the work were generally positive, with reviewers commenting on the \"hypnotic\" and \"thriller-like\" qualities of the book. Shilts' investigative and journalistic endeavors were praised, and reviewers seemed genuinely moved by the personal stories of the major players. \"And the Band Played On\" won the Stonewall Book Award for 1988. It earned the 10th spot on \"100 Lesbian and Gay Books That Changed Our Lives\", compiled by the \"Lambda Book Report\". In 1999, The New York City Public Library topped its list of \"21 New Classics for the 21st Century\" with \"And the Band Played On\". Two years after it was published however, Shilts remained \"fundamentally disappointed\" when a radical response to the AIDS crisis did not materialize, despite the reaction to his book.\n\nIn a 1988 book review, Jack Geiger of \"The New York Times\" commented that the detail in Shilts' work was too confusing, being told \"in five simultaneous but disjointed chronologies, making them all less coherent\", and notes that Shilts neglected to dedicate as much detail to black and Hispanic intravenous drug users, their partners and their children as to gay men. Geiger also expressed doubts that a swifter response by the government would have stemmed the spread of AIDS as quickly as Shilts was implying. Woodrow Myers from the \"Los Angeles Times\" was frustrated by Shilts not asking the right questions: \"Shilts fails to probe the broader questions and stops where far too many of us stop: We don't ask why the Department of Defense and the entitlements like Social Security are getting all the money when the homosexuals and the IV drug abusers with AIDS and the multiple sclerosis patients are not.\" The \"Gay Community News\" in Boston also criticized the book's implications that a diagnosis of HIV indicated that death was sure and imminent. Richard Rouilard, editor of \"The Advocate\" in 1992 criticized Shilts for being out of touch with the contemporary style of activism and its sexual overtones.\n\nShilts' book has been used as a standard by the lay press when reviewing books chronicling subsequent medical crises including breast cancer, chronic fatigue syndrome, Agent Orange, and continued response to AIDS. However, the academic and scientific communities have been somewhat more critical. Howard Merkel, in the \"American Journal of Public Health\", notes Shilts' tendency to assign blame, writing \"A requirement of the journalist, and certainly the historian, however, is to explain human society rather than to point fingers\". Jon Katz in \"Rolling Stone\" refutes this by stating \"[Shilts] fused strong belief with the gathering of factual information and the marshaling of arguments, the way the founders of the modern press did. In doing so, he has exposed the notion of objectivity as bankrupt, ineffective, even lethal\".\n\nAlthough Sandra Panem in the journal \"Science\" praised Shilts' efforts and the attention the book brought to AIDS, she criticized his simplistic interpretation of science and the ways research is fostered and accomplished in the U.S. Panem furthermore believes Shilts gives appropriate weight to the issue of homophobia hampering attention on the disease, but remarks that even if AIDS had struck a more socially acceptable group of people, similar delays and confusion would have slowed medical progress.\n\nWendy Parmet, a professor at Northeastern University Law School, highlights the greatest strengths of \"And the Band Played On\" to be \"the pain and courage of individual confronted with AIDS\" and how it \"eloquently portrays the human side of the crisis\" and believes the blame others criticized to be justified; but Parmet considers his technique of assigning an omniscient point of view a weakness, suggesting that it blurs the lines between fact and fiction. In \"Contemporary Sociology\", Peter Manning and Terry Stein also call Shilts' narrative method into question, and ask why, for a syndrome that affects people beyond race, class, and sexual orientation, that Shilts focuses so narrowly on AIDS as it is related to homosexuality. The writers, however, were mostly impressed with the book, calling it an \"informative, often brilliant, overview of the emergent meanings of the AIDS epidemic\".\n\nShilts is often quoted as claiming that Ronald Reagan neglected to mention AIDS publicly until 1987. However, Reagan briefly mentioned AIDS research in questions and answers during a news conference on September 17, 1985.\n\nThe book includes extensive discussion of Gaëtan Dugas, a Canadian flight attendant who died in 1984. Dugas was labeled Patient Zero of AIDS, because he was linked directly or indirectly with 40 of the first 248 reported cases of AIDS in the United States, and after he was told of his ability to infect others, defiantly continued to have unprotected sex. Many book reviews concentrated their material on Dugas, or led their assessment of the book with discussion of his behavior. Some reviewers interpreted Shilts' naming Dugas \"Patient Zero\" to mean that Dugas brought AIDS to North America; the \"National Review\" called Dugas the \"Columbus of AIDS\" and in their review of \"And the Band Played On\" states, \"[Dugas] picked up the disease in Europe through sexual contact with Africans. Traveling on his airline-employee privileges, he spread it here from coast to coast.\" Shilts never stated this in the book, instead writing, \"Whether Gaëtan Dugas actually was the person who brought AIDS to North America remains a question of debate and is ultimately unanswerable ... there's no doubt that Gaëtan played a key role in spreading the new virus from one end of the United States to the other.\" \"Time\" titled its review of \"And the Band Played On\" \"The Appalling Saga of Patient Zero\", erroneously restating the claim that Dugas had brought AIDS to the continent. Even a press release by St. Martin's Press made the connection between Dugas and the introduction of AIDS to the Western World in its title, but not its text.\n\nWhen the book was released, Dugas' story became a controversial subject in the Canadian media. Shilts claimed that \"the Canadian press went crazy over the story\" and that \"Canadians... saw it as an offense to their nationhood.\" The original study identifying Dugas as the index case had been completed by William Darrow, but it was called into question by University of California San Francisco epidemiologist Andrew Moss. Moss wrote in a letter to the editor of \"The New York Review of Books\", \"There is very little evidence that Gaetan was 'patient zero' for the US or for California,\" while also stating that Shilts did not overstress Dugas' lack of personal responsibility. Sandra Panem in \"Science\" uses Shilts' approach toward Dugas' behavior as an example of his \"glib\" treatment of the science involved in the epidemic. Author Douglas Crimp suggests that Shilts' representation of Dugas as \"murderously irresponsible\" is in actuality \"Shilts' homophobic nightmare of himself\", and that Dugas is offered as a \"scapegoat for his heterosexual colleagues, in order to prove that [Shilts], like them, is horrified by such creatures.\" Many years later, in the 2000s, it was shown, by tracing the roots of the virus, that it had spread from Africa to Haiti, and then to the U.S. in the mid 1960s, before Dugas would have been very sexually active, if at all, and before he was working as a flight attendant. Even the labelling of Dugas as \"Patient Zero\" was due to an misunderstanding of the study of sexual contacts amongst a group of men indicating how the disease was transmitted – he was identified in the study as ‘Patient [letter] O’, for \"Out of California\" – but people reading and discussing the research began referring to and thinking about a \"Patient Zero\" as the origin of the disease.\n\nIn 2016, a study of early AIDS cases demonstrated that Dugas could not have been \"Patient Zero\".\n\nWhile Shilts was writing the book he was tested for HIV but insisted his doctor not tell him the results until the book was finished so it would not affect his journalistic integrity and judgment. On the day he sent the final manuscript to the publisher, he learned he was HIV-positive. He also revealed that he received abuse from gays for the articles he wrote for the \"San Francisco Chronicle\" supporting the bathhouse closures, as well as for \"And the Band Played On\", saying it was common for him to be spat upon in the Castro District. He was openly booed when he attended the premiere of \"The Times of Harvey Milk\"—based on his book \"The Mayor of Castro Street\"—at the Castro Theatre. Footage he had shot as a television reporter was included in the film, but during the construction of the documentary he was so controversial that the film's editors removed him from footage showing him with Milk. Following the publication of \"And the Band Played On\", however, he was \"worshipped\" by many in the gay community for writing the book, but also seen as someone who pandered to publicity.\n\nShilts declared while promoting the book in Australia in 1988 that AIDS in the western world could be eradicated, and by 1994, \"AIDS could be as manageable as diabetes\". However, in reference to Africa, Shilts noted, \"At this point it's inconceivable that there will be an AIDS-free world in Central Africa, as we're looking at a death rate on the scale of the Holocaust.\" Shilts gave an interview in 1991 where he noticed, \"the stellar AIDS reporters in the early years...the people who did the best job—and the reporters who wanted to cover AIDS but their male editors wouldn't let them—tended to be women\", and made a connection that if more women were allowed to write about the epidemic, media coverage would have been vastly different.\n\nShilts died from complications of AIDS in 1994, age 42. Upon his death he was eulogized by Cleve Jones, who said \"Randy's contribution was so crucial. He broke through society's denial and was absolutely critical to communicating the reality of AIDS.\" Larry Kramer said of him, \"He single-handedly probably did more to educate the world about AIDS than any single person.\"\n\n\"And the Band Played On\" was used as the basis for a 1993 Primetime Emmy Award-winning HBO television film of the same name. It was produced by Aaron Spelling, directed by Roger Spottiswoode, and starred Matthew Modine as epidemiologist Don Francis and Richard Masur as William Darrow at the Centers for Disease Control. Alan Alda portrayed controversial viral researcher Robert Gallo, and many other stars appeared in supporting and cameo roles, who agreed to appear in the film for union-scale pay. The film was released the same year as \"Philadelphia\", and the play \"\" premiered, which prompted one reviewer to note it a triumph and a loss: 12 years after the epidemic had begun, such works of art were necessary still to draw attention to it. Reviews of the film were mixed, claiming that it was a noble try, but failed to be comprehensive enough to cover all the intricacies of the response to AIDS. However, \"And the Band Played On\", along with other well-received films at the time, was noted for raising the standards of HBO-produced films.\n\n\n"}
{"id": "26475183", "url": "https://en.wikipedia.org/wiki?curid=26475183", "title": "Andrew Delbanco", "text": "Andrew Delbanco\n\nAndrew H. Delbanco (born 1952) is the Alexander Hamilton Professor of American Studies at Columbia University. He is the author of several books, including \"College: What It Was, Is, and Should Be\" (2012), which has been translated into Chinese, Korean, Turkish, Russian, and Hebrew. \"Melville: His World and Work\" (2005), a finalist for the Los Angeles Times Book Prize in Biography, was awarded the Lionel Trilling Award by Columbia University, and has been translated into German and Spanish. He has written many essays in journals of culture and opinion, especially \"The New York Review of Books\" and \"The New Republic\", on American literature and religion, as well as the history and current state of U.S. higher education.\n\nA graduate of Harvard University (BA 1973 and PhD 1980), Delbanco taught at Harvard (1981-1985) and since 1985 has been teaching at Columbia University, where, for twenty years, he held the Julian Clarence Levi chair in the Humanities and, from 2005 to 2015, was director of American Studies.\n\nDelbanco is a fellow of the American Academy of Arts and Sciences and of the American Philosophical Society. He has received fellowships from the Guggenheim Foundation (1990), the American Council of Learned Societies, the National Endowment for the Humanities, the National Humanities Center, and the New York Public Library Cullman Center for Scholars and Writers.\n\nHe serves as a trustee of the Teagle Foundation and of the Library of America, and is the Trustee Emeritus of the National Humanities Center. He has also served as Vice President of PEN American Center.\n\nIn 2012, Delbanco was awarded a National Humanities Medal by President Barack Obama \"for his writings on higher education and the place classic authors hold in history and contemporary life.\" In 2006, he received the Great Teacher Award from the Society of Columbia Graduates. He was selected as the 2003 New York State Scholar of the Year by the New York Council for the Humanities. In 2001, he was named by \"Time Magazine\" as \"America's Best Social Critic.\"\n\n\n\n"}
{"id": "31404649", "url": "https://en.wikipedia.org/wiki?curid=31404649", "title": "Archaeological Museum of the American University of Beirut", "text": "Archaeological Museum of the American University of Beirut\n\nThe Archaeology Museum of the American University of Beirut in Beirut, Lebanon is the third oldest museum in the Near East after Cairo and Constantinople.\n\nThe Archaeological Museum of the American University of Beirut (AUB Archaeological Museum) was formed in 1868, after Luigi Palma di Cesnola gifted a collection of Cypriot pottery to the newly formed American University of Beirut. Georges Post was the first curator of this collection and Morris Jesup donated the funds for construction of Post Hall (pictured) which opened in 1902. There was much archaeological plundering in Lebanon due to weak governmental control, and people arrived daily at the museum with suggested artefacts plundered from clandestine excavations. Between 1902 and 1938 the Museum acquired collections from all around the Middle East. The museum remained closed during World War II and re-opened in 1948. It expanded in the 1950s and doubled its floor space with a refurbishment under curator D.C. Baramki, which opened to the public in 1964. The museum remained open during the years of crisis in Lebanon between 1975 and 1990 and underwent another complete renovation in 2006 under the present director, Leila Badre. A mezzanine level was added that increased the space by one fifth using funds secured from the Joukowsky Family Foundation. The AUB Archaeological Museum is the third oldest museum in the Near East, after Cairo and Constantinople\n\nThe collections are organized by chronology and themes, with displays along the sides of the gallery displaying the evolution of pottery. Other displays include the Cesnola Collection, showing pottery from Cyprus from the Bronze Age to the Roman era. The prehistoric collection includes Paleolithic and Neolithic eras. The Ksar Akil collection was donated by the University of Boston team who excavated this archaeological site in 1948. The display shows a stratigraphic sequence of thirty seven layers and flint tools belonging to several cultures. The sequence is radiocarbon dated between 50,000–18,000 BP, and contained a human jaw dated to 40,000 BP and a complete skull dated to 35,000 BP.\n\nThe Paleolithic showcase displays the journey of man through the stone age, covering important events such as the discovery of fire, hunting and cave paintings. The Neolithic showcase covers the dawn of agriculture, animal domestication, the beginnings of pottery, villages and religion. The terracotta figurines collection shows their evolution from the Bronze Age to the Roman era, and their importance in the development of religion. The metal figurines collection includes mostly males and gods, used as symbols of power. The Bronze Age displays show artefacts dated between 3000 BC and 1200 BC including evidence of early writing, trade and urbanization. The Iron Age displays shows evidence of the invasions of seafaring raiders and city states during the period between 1200 BC and 400 BC. The Phoenician showcases display the extraction of purple dye from murex shells, pottery and Phoenician glass. Phoenician religion is represented by a large stelae of a priest, a throne of Astarte, libation spoons and a glass amulet. Another notable feature of this section is the Ford Mandible dating from the 5th century BC showing the earliest known example of dentistry. The Bodashtar inscription is also displayed along with an explanation of the development of the linear alphabet. The Classical period collection includes funerary reliefs from Palmyra, Egypt and the Levant, a Byzantine mosaic and collection of funerary sarcophagi displayed on the staircase leading to the mezzanine. The Islamic period displays materials from the Umayyad Period in 656 AD to the Ottoman Empire in the 19th century where glazed tiles and plates are shown. The newly-added mezzanine includes table cases displaying small objects such as a collection of coins, scarabs and seals, lamps, amulets, cosmetics, jewelry, tools and weapons.\n\nThe museum has been involved in archaeological research and recovery projects. In 1956–1974, the museum was involved in excavations at Tell el-Ghassil in the Beqaa Valley, an agrarian site with levels dating from 1800–600 BC. Some of the Iron Age material recovered is displayed in the museum including a goblet with an incised decoration of birds and ducks discovered at Tell el Yehudiyeh and dating from 1730–1550 BC. The goblet was found next to a skeleton and is presumed to be a funerary gift for use in the afterlife.\n\nThe museum has also carried out a number of excavations in Beirut Central District under the directorship of Leila Badre. These have included the ancient tell of Beirut, site BEY 003. The purpose of this excavation was to discover the “Biruta” of the Amarna Letters. Evidence was found of a fortification system that was constructed in the second millennium BC up to the Hellenistic period, along with the remains of a building dating back into the third millennium BC and a hoard of Egyptian objects. Another site the museum has been involved with is BEY 012, Saint Georges Cathedral of the Greek Orthodox, where excavations were carried out in 2001. Eight layers showed occupation from the Hellenistic period onwards and the remains of five, possibly six, successive churches. Another site investigated was BEY 215, the An-Nahar building, revealing six levels of occupation dating from the Persian to Byzantine eras, showing continuous inhabitation since the 4th century BC. Tell Kazel in Syria has also been excavated and studied by Leila Badre since 1985. Likely the ancient Simyra, levels from the Mameluk Period to the Bronze Age were discovered. Finds included a temple and rooms with sea shell-paved floors. Visitors to the museum can view relics such as cylinder seals, necklaces, pottery and temple offerings organized according to their site location. The museum has also embarked on the restoration of the wall paintings of Mar Sarkis and Bakhos in Kaftoun with the University of Warsaw.\n\n\n\n\n\n\n\n\nThe museum's hours are 0900–1700 in the winter and 0900–1600 in the summer, Monday through Friday. The Museum is closed on public holidays and during university holidays. Tours last approximately 1 hour. Group tours and school visits can be made by appointment by e-mail to the Museum assistant. Entrance and tours are free of charge.\n\n"}
{"id": "1435984", "url": "https://en.wikipedia.org/wiki?curid=1435984", "title": "Association of Caribbean States", "text": "Association of Caribbean States\n\nThe Association of Caribbean States (ACS; ; ) is a union of nations centered on the Caribbean Basin. It was formed with the aim of promoting consultation, cooperation, and concerted action among all the countries of the Caribbean. The primary purpose of the ACS is to develop greater trade between the nations, enhance transportation, develop sustainable tourism, and facilitate greater and more effective responses to local natural disasters.\n\nIt comprises twenty-five member states and seven associate members. The convention establishing the ACS was signed on July 24, 1994, in Cartagena de Indias, Colombia. The secretariat of the organisation is located in Port of Spain, Trinidad and Tobago.\n\nThe Association of Caribbean States is intended to promote regionalism amongst the member states. The success and functionality of the ACS is greatly debated among scholars. The main goals of the association are \"to confirm the new concept of the Caribbean Basin by (A) accentuating those interests the Caribbean nations hold in common and (B) working to eliminate barriers left over from its colonial past.\"\n\nThe organization seeks to use geographic proximity and regional cooperation (regionalism) for political and economic advantage with respect to the global economy and trade blocs such as the North American Free Trade Agreement (NAFTA), European Union and South Asia. The ACS has four distinct areas of interest: Trade, Transport, Sustainable Tourism, and Natural Disasters. Each is pursued by a Special Committee which meets at least twice yearly in order to discuss current regional issues and draft treaties.\n\n\nOne agenda adopted by the ACS has been an attempt to secure the designation of the Caribbean Sea as a special zone in the context of sustainable development, it is pushing for the UN to consider the Caribbean sea as an invaluable asset that is worth protecting and treasuring. The organisation has sought to form a coalition among member states to devise a United Nations General Assembly resolution to ban the transshipment of nuclear materials through the Caribbean Sea and the Panama Canal.\n\nThe success of the ACS is debated by many scholars on both sides. Those who suggest the ACS is successful would point to the many initiatives the developmental coalition has undertaken, as well as its large membership and relations with other international organisations like the European Union. Those who suggest it is unsuccessful note how by the end of the 1990s, unlike CARICOM, the ACS had failed to establish a track record which was worthy enough to allow for the evaluation of the ACS as a developmental coalition. Furthermore, some scholars suggest that the ACS is unlikely to become a true player on the international level. Skeptics often point to other failed attempts at economic coalition building like the Central American Common Market (CACM) as an example of the instability of the region. The influence of NAFTA on the Caribbean outlines the future struggle of the ACS. The future of the ACS in relation to the western hemisphere is uncertain. \"Despite governmental statements of commitment to liberalisation, it will be difficult for Caribbean countries to succeed in putting their economies on a firmer footing that would enable them to compete effectively.\"\n\nThe ACS has held five summits involving heads of state and/or government:\n\n\n\n\n\n\n"}
{"id": "38474859", "url": "https://en.wikipedia.org/wiki?curid=38474859", "title": "BC The Archaeology of the Bible Lands", "text": "BC The Archaeology of the Bible Lands\n\nBC The Archaeology of the Bible Lands was a BBC television series from the 1970s. It investigated the archaeology of the Bible lands. It was presented by Magnus Magnusson. A book of the programme was published in 1977.\n"}
{"id": "18626487", "url": "https://en.wikipedia.org/wiki?curid=18626487", "title": "Biomedical waste", "text": "Biomedical waste\n\nBiomedical waste is any kind of waste containing infectious (or potentially infectious) materials. It may also include waste associated with the generation of biomedical waste that visually appears to be of medical or laboratory origin (e.g., packaging, unused bandages, infusion kits, etc.), as well research laboratory waste containing biomolecules or organisms that are restricted from environmental release. As detailed below, discarded sharps are considered biomedical waste whether they are contaminated or not, due to the possibility of being contaminated with blood and their propensity to cause injury when not properly contained and disposed of. Biomedical waste is a type of biowaste.\n\nBiomedical waste may be solid or liquid. Examples of infectious waste include discarded blood, sharps, unwanted microbiological cultures and stocks, identifiable body parts (including those as a result of amputation), other human or animal tissue, used bandages and dressings, discarded gloves, other medical supplies that may have been in contact with blood and body fluids, and laboratory waste that exhibits the characteristics described above. Waste sharps include potentially contaminated used (and unused discarded) needles, scalpels, lancets and other devices capable of penetrating skin.\n\nBiomedical waste is generated from biological and medical sources and activities, such as the diagnosis, prevention, or treatment of diseases. Common generators (or producers) of biomedical waste include hospitals, health clinics, nursing homes, emergency medical services, medical research laboratories, offices of physicians, dentists, and veterinarians, home health care, and morgues or funeral homes. In healthcare facilities (i.e., hospitals, clinics, doctor's offices, veterinary hospitals and clinical laboratories), waste with these characteristics may alternatively be called medical or clinical waste.\n\nBiomedical waste is distinct from normal trash or general waste, and differs from other types of hazardous waste, such as chemical, radioactive, universal or industrial waste. Medical facilities generate waste hazardous chemicals and radioactive materials. While such wastes are normally not infectious, they require proper disposal. Some wastes are considered \"multihazardous,\" such as tissue samples preserved in formalin.\n\nDisposal of this waste is an environmental concern, as many medical wastes are classified as \"infectious\" or \"biohazardous\" and could potentially lead to the spread of infectious disease. The most common danger for humans is the infection which also affects other living organisms in the region. Daily exposure to the waste (landfill) leads to accumulation of harmful substances or microbes in the person's body.\nA 1990 report by the U.S. Agency for Toxic Substances and Disease Registry concluded that the general public is not likely to be adversely affected by biomedical waste generated in the traditional healthcare setting. They found, however, that biomedical waste from those settings may pose an injury and exposure risks via occupational contact with medical waste for doctors, nurses, and janitorial, laundry and refuse workers. Further, there are opportunities for the general public to come into contact medical waste, such as needles used illicitly outside healthcare settings, or biomedical waste generated via home health care.\n\nBiomedical waste must be properly managed and disposed of to protect the environment, general public and workers, especially healthcare and sanitation workers who are at risk of exposure to biomedical waste as an occupational hazard. Steps in the management of biomedical waste include generation, accumulation, handling, storage, treatment, transport and disposal.\n\nThe development and implementation of a national waste management policy can improve biomedical waste management in health facilities in a country\n\nDisposal occurs off-site, at a location that is different from the site of generation. Treatment may occur on-site or off-site. On-site treatment of large quantities of biomedical waste usually requires the use of relatively expensive equipment, and is generally only cost effective for very large hospitals and major universities who have the space, labor and budget to operate such equipment. Off-site treatment and disposal involves hiring of a biomedical waste disposal service (also called a truck service) whose employees are trained to collect and haul away biomedical waste in special containers (usually cardboard boxes, or reusable plastic bins) for treatment at a facility designed to handle biomedical waste.\n\nBiomedical waste should be collected in containers that are leak-proof and sufficiently strong to prevent breakage during handling. Containers of biomedical waste are marked with a biohazard symbol. The container, marking, and labels are often red.\n\nDiscarded sharps are usually collected in specialized boxes, often called \"needle boxes\".\n\nSpecialized equipment is required to meet OSHA 29 CFR 1910.1450 and EPA 40 CFR 264.173. standards of safety. Minimal recommended equipment include a fume hood and primary and secondary waste containers to capture potential overflow. Even beneath the fume hood, containers containing chemical contaminants should remain closed when not in use. An open funnel placed in the mouth of a waste container has been shown to allow significant evaporation of chemicals into the surrounding atmosphere, which is then inhaled by laboratory personnel, and contributes a primary component to the threat of completing the fire triangle. To protect the health and safety of laboratory staff as well as neighboring civilians and the environment, proper waste management equipment, such as the Burkle funnel in Europe and the ECO Funnel in the U.S., should be utilized in any department which deals with chemical waste. It is to be dumped after treatment.\n\nStorage refers to keeping the waste until it is treated on-site or transported off-site for treatment or disposal. There are many options and containers for storage. Regulatory agencies may limit the time for which waste can remain in storage. Handling is the act of moving biomedical waste between the point of generation, accumulation areas, storage locations and on-site treatment facilities. Workers who handle biomedical waste must observe \"standard precautions.\"\n\nThe goals of biomedical waste treatment are to reduce or eliminate the waste's hazards, and usually to make the waste unrecognizable. Treatment should render the waste safe for subsequent handling and disposal. There are several treatment methods that can accomplish these goals.\n\nBiomedical waste is often incinerated. An efficient incinerator will destroy pathogens and sharps. Source materials are not recognizable in the resulting ash.\n\nAn autoclave may also be used to treat biomedical waste. An autoclave uses steam and pressure to sterilize the waste or reduce its microbiological load to a level at which it may be safely disposed of. Many healthcare facilities routinely use an autoclave to sterilize medical supplies. If the same autoclave is used to sterilize supplies and treat biomedical waste, administrative controls must be used to prevent the waste operations from contaminating the supplies. Effective administrative controls include operator training, strict procedures, and separate times and space for processing biomedical waste.\n\nMicrowave disinfection can also be employed for treatment of Biomedical wastes. Microwave irradiation is a type of non-contact heating technologies for disinfection. Microwave chemistry is based on efficient heating of materials by microwave dielectric heating effects. When exposed to microwave frequencies, the dipoles of the water molecules present in cells re-align with the applied electric field. As the field oscillates, the dipoles attempts to realign itself with the alternating electric field and in this process, energy is lost in the form of heat through molecular friction and dielectric loss. Microwave disinfection is a recently developed technology which provides advantage over old existing technologies of autoclaves as microwave based disinfection has less cycle time, power consumption and it requires minimal usage of water and consumables as compared to autoclaves. \n\nFor liquids and small quantities, a 1–10% solution of bleach can be used to disinfect biomedical waste. Solutions of sodium hydroxide and other chemical disinfectants may also be used, depending on the waste's characteristics. Other treatment methods include heat, alkaline digesters and the use of microwaves.\n\nFor autoclaves and microwave systems, a shredder may be used as a final treatment step to render the waste unrecognizable. Some autoclaves have built in shredders.\n\nIn the UK, clinical waste and the way it is to be handled is closely regulated. Applicable legislation includes the Environmental Protection Act 1990 (Part II), Waste Management Licensing Regulations 1994, and the Hazardous Waste Regulations (England & Wales) 2005, as well as the Special Waste Regulations in Scotland. A scandal erupted in October 2018 when it emerged that Healthcare Environment Services, which had contracts for managing clinical waste produced by the NHS in Scotland and England, was in breach of the environmental permits at four of its six sites by having more waste on site than their permit allows and storing waste inappropriately. 17 NHS trusts in Yorkshire terminated their contracts immediately. The company sued for compensation. Amputated limbs were said to be among 350 tonnes of clinical waste stockpiled instead of incinerated in Normanton. The company maintains that the problem is caused by a reduction in incineration capacity, and the re-classification of clinical waste as “offensive”, which meant more needed incineration. The government’s contingency plans include installing temporary storage units at hospitals, but the company say that this is more dangerous than allowing them to exceed their permitted allowances. The company still has contracts with 30 other trusts in England, and a waste disposal contract with NHS England for primary care and pharmacy.\n\nIn the United States, biomedical waste is usually regulated as medical waste. In 1988 the U.S. federal government passed The Medical Waste Tracking Act which allowed the EPA to establish rules for management of medical waste in some parts of the country. After the Act expired in 1991, responsibility to regulate and pass laws concerning the disposal of medical waste returned to the individual states. The states vary in their regulations from none to very strict.\n\nIn addition to on-site treatment or pickup by a biomedical waste disposal firm for off-site treatment, a mail-back disposal option allows generators of waste to return it to the manufacturer. For instance, waste medicines and equipment can be returned. The waste is shipped through the U.S. postal service. While available in all 50 U.S. states, mail-back medical waste disposal is limited by very strict postal regulations (i.e., collection and shipping containers must be approved by the postal service for use).\n\nThe Bio-medical Waste (Management and Handling) Rules, 1998 and further amendments were passed for the regulation of bio-medical waste management. On 28 th Mar 2016 Biomedical Waste Management Rules 2016 were also notified by Central Govt. Each state's Pollution Control Board or Pollution control Committee will be responsible for implementing the new legislation.\n\nIn India,though there are a number of different disposal methods,the situation is desultory and most are harmful rather than helpful. If body fluids are present, the material needs to be incinerated or put into an autoclave. Although this is the proper method, most medical facilities fail to follow the regulations. It is often found that biomedical waste is dumped into the ocean, where it eventually washes up on shore, or in landfills due to improper sorting or negligence when in the medical facility. Improper disposal can lead to many diseases in animals as well as humans. For example, animals, such as cows in Pondicherry, India, are consuming the infected waste and eventually, these infections can be transported to humans who consume their meat or milk. Large number of unregistered clinics and institutions also generate bio-medical waste which is not controlled. \n\nDue to the competition to improve quality and so as to get accreditation from agencies like ISO, NABH, JCI, many private organizations have initiated proper bio-medical waste disposal but still the gap is huge.<br>\n\nMany studies took place in Gujarat, India regarding the knowledge of workers in facilities such as hospitals, nursing homes, or home health. It was found that 26% of doctors and 43% of paramedical staff were unaware of the risks related to biomedical wastes. After extensively looking at the different facilities, many were undeveloped in the area regarding biomedical waste. The rules and regulations in India work with The Bio-medical Waste (Management and Handling) Rules from 1998, yet a large number of health care facilities were found to be sorting the waste incorrectly. \n\nThe latest guidelines for segregation of bio-medical waste recommend the following color coding - \n\n"}
{"id": "45287496", "url": "https://en.wikipedia.org/wiki?curid=45287496", "title": "Bloor Street Culture Corridor", "text": "Bloor Street Culture Corridor\n\nThe Bloor Street Culture Corridor is a cluster of arts and cultural organizations in Toronto, Ontario, Canada. It is located on Bloor St. W, between Bathurst and Bay Streets.\n\nThe Bloor Street Culture Corridor has a wide variety of art genres, from museum experiences to films, art exhibitions to music concerts. The area also is culturally diverse, including Aboriginal, French, Jewish, Italian, Japanese, Estonian, African and Caribbean arts and culture.\n\nOfficially launched in April 2014, the collective shares a website, social media and a mobile app to promote exhibitions at its member institutions. In 2016, the Corridor was successful in working with the City of Toronto to have the section of Bloor St. West designated an official City of Toronto cultural corridor. Each year more than three million persons visit the Corridor's arts and culture destinations, and attend exhibitions, performances, and events. Together, the Bloor St. Culture Corridor organizations employ more than 5,500 culture workers and generate more than $629,500,000 in economic impact each year.\n\nBloor St. Culture Corridor Partner Destinations\n\n"}
{"id": "22786566", "url": "https://en.wikipedia.org/wiki?curid=22786566", "title": "Bogdan Bogdanović (architect)", "text": "Bogdan Bogdanović (architect)\n\nBogdan Bogdanović (; 20 August 1922 − 18 June 2010) was a Serbian architect, urbanist and essayist. He taught architecture at the University of Belgrade Faculty of Architecture, where he also served as dean. Bogdanović wrote numerous articles about urbanism, especially about its mythic and symbolic aspects, some of which appeared in international journals such as \"El País\", \"Die Zeit\", and others. He was also involved in politics, as a partisan in World War II, later as mayor of Belgrade. When Slobodan Milošević rose to power and nationalism gained ground in Yugoslavia, Bogdanović became a dissident.\n\nBogdanović is best known for designing monuments and memorials commemorating victims and resistance fighters of World War II built all over Yugoslavia from the early 1950s to 1980s. In particular, the monumental concrete sculpture titled \"Stone Flower\" near the site of Jasenovac concentration camp gained international attention.\n\nBogdanović was born into a family of leftist intellectuals. His father Milan was a literary critic, long-time president of the Association of Writers and director of the National Theatre. Beginning in 1940, Bogdan studied architecture at the University of Belgrade. He participated in World War II (\"a bit\" in his words) as a partisan, becoming a member of the Communist Party, and was seriously wounded in eastern Bosnia. Despite his injuries, he continued his academic career after the war, graduating in 1950, becoming a teaching assistant at the department for urbanism (from 1953), then a docent in 1960, extraordinary professor and president of the Yugoslav Union of Architects in 1964, dean of the Faculty of Architecture and a corresponding member of the Serbian Academy of Sciences and Arts (SANU) in 1970, and full professor in 1973. In 1981 he resigned from SANU, and he was conferred emeritus status in 1987.\n\nBeing an ardent leftist, Bogdanović opposed the increasing nationalism espoused by state leaders since the early 1980s. Nonetheless, he became Mayor of Belgrade in 1982 on the initiative of Ivan Stambolić, then chairman of the League of Communists of Serbia. Bogdanović served one term in office, until 1986. During this time, he organised an international competition for the complete redevelopment of New Belgrade, a planned area on the left bank of the Sava river. All submissions to this competition have since disappeared.\n\nAfter his term of office, he was appointed by Slobodan Milošević as a member of the Central Committee of the League of Communists of Yugoslavia, the party's supreme governing body. He accepted the post under the condition that he would not be required to attend committee meetings because he \"had more important things to do\". In the following year he sent Milošević an anti-nationalist letter over 60 pages long, including a \"Stalino-dictionary\", an appendix satirising the recipient's nationalist rhetoric, and the famous \"Lamentation for Serbia\", which discussed the theme of Serbia \"being tired\" (of its leaders). The Central Committee replied, \"You can send the letter, in which you criticise the work of the eighth meeting and which has not reached us, to the Central Committee if you consider it necessary\". The letter, in combination with other remarks about Milošević, led to attempts of breaking into Bogdanović's apartment, death threats, and his exclusion from the Central Committee. This, however, did not prevent him from renewing his anti-nationalist statements when the Yugoslav wars started at the beginning of the 1990s, once more turning Bogdanović into a target for violent attacks and a defamation campaign run by the Serbian state media.\n\nIn 1993 Bogdanović went into self-imposed exile to Paris with his wife Ksenija. However, since the Yugoslav émigré circle there had strong nationalistic tendencies, the couple moved on to settle in Vienna upon invitation of his friend, the writer and translator Milo Dor. Bogdanović died in a hospital in Vienna on 18 June 2010, following a heart attack.\n\nAt the University of Belgrade, Bogdanović held the lecture course \"The development of housing schemes\" (later called \"History of town\"), starting in 1962. As professor and dean, he tried to reform the teaching of architecture and introduce grassroots democracy at the university, but the party forced him to abdicate before he could put his plans into practice.\n\nIn 1976 he began to teach in an abandoned village school in Mali Popović near Belgrade to realise an alternative project, namely his \"village school for the philosophy of architecture\". The course was called \"Symbolic forms\" in allusion to Ernst Cassirer, had no fixed timetable and employed the invention of new writing systems, the interpretation of non-existent texts, as well as methods akin to free association and gematria. 14 years later, when henchmen of Milošević raided the school in the aftermath of Bogdanović's letter, much of the collected material – the documentation of the lessons, drawings, audio- and videotapes, optical devices – was destroyed.\n\nThe architectonic and literary work of Bogdanović is characterised by an abundance of ornaments. It is influenced by Romanticism and Victorian architecture, surrealism, metaphysics, Jewish symbolism and Kabbalah. Bogdanović has opposed the architectural theories of Adolf Loos developed in the essay \"Ornament and Crime\", and argued for the \"semantic dignity of the ornamental sign\".\n\nIn 1951 Bogdan Bogdanović won a competition for the design of a memorial to the Jewish victims of fascism, to be built on the Sephardic cemetery in Belgrade. Although not religious himself, this contact with Jewish esotericism strongly influenced his further work. From then on until 1981, he was assigned by Josip Broz Tito to devise more than 20 monuments and memorial places against fascism and militarism, which were erected in all republics of Yugoslavia. To work as cenotaphs for all victims of fascism, regardless of nationality and religion, they lack any symbols of communism or other ideologies. Instead, they rely on archaic, mythological forms, sharply contrasting with the principles of Socialist realism. This contrast also served Tito's wish to emphasise his country's independence from the Soviet Union.\n\nAll of the memorials are built of stone, shaped by local untrained chisellers whom Bogdanović preferred to ones with formal education, who were inflexible in his opinion. The notable exception, the Jasenovac monument, consists of prestressed concrete, the formwork for which was constructed by shipwrights. Somewhat incongruously, it is known as the \"Flower of Stone\".\n\nExamples of these monuments are:\n\nBogdanović refused to participate in the planning of national housing estates which looked like \"coffins of concrete\" to him and had \"only two types of windows\". Consequently, he built only a single settlement: a housing estate for the hydrotechnical institute \"Jaroslav Černi\" at the foot of the mountain Avala near Belgrade, finished in 1953. The houses are mostly built of stone; and with their surrealistic, old-fashioned style, heavily framed windows and oversized chimneys, they are deliberately set apart from the international style that dominated in post-WW2 Yugoslavia.\n\nOther settlements were planned in great detail, but never really intended to be built. Among those is a town in northern Montenegro, designed for local clients, and a mythological \"town at the bottom of the lake (Biograd)\" which Bogdanović designed for his own pleasure.\n\nOther works of architecture include the reconstruction of the villa of Queen Natalija (Smederevo, 1961), Adonis' altar (Labin, 1974) and the Tomb of Dušan Petrović-Šane (Aranđelovac, 1980).\n\nBooks and essays in Serbo-Croatian include:\n\nSix of his books were published in German by Zsolnay and Wieser:\n\nOf the essays written by Bogdanović, the following is available in English:\n\nBogdanović was a founder member of the International Academy of Architecture which was established in 1987 and a foreign member of the Russian Academy of Architecture (from 1994), a corresponding member of the Bavarian Academy of Fine Arts (from 1998), and a member of the Collegium Europaeum Jenense (University of Jena; from 2000). In 2002 he was elected an honorary member of the Academy of Sciences and Arts of Bosnia and Herzegovina.\n\nAwards and prizes include:\n\n"}
{"id": "29157928", "url": "https://en.wikipedia.org/wiki?curid=29157928", "title": "Cathy J. Cohen", "text": "Cathy J. Cohen\n\nCathy J. Cohen (born 1962) is an American political scientist, author, feminist, and social activist, whose work has focused on the African-American experience in politics from a perspective which is underlined by intersectionality. She is currently the David and Mary Winton Green Professor in Political Science and the College at the University of Chicago, and is the former Director of the Center for the Study of Race (2002–05).\n\nShe received her BA from Miami University, Ph.D. from the University of Michigan in 1993 and began her academic career at Yale University where she received tenure. Cohen joined the faculty of the University of Chicago in 2002.\n\nCohen frequently writes and speaks about gender, sexuality, class, ethnicity, and their interrelatedness and connection to power. This approach puts her in a class of leftist intellectuals who work to have social and public policy influence on the lives of marginalized groups in a positive way. Cohen, a black lesbian and parent, is the principal researcher on the Black Youth Project, a nationwide survey which focuses on factors that influence black youth decision-making, norms, etc., and has a central focus on understanding how black youth feel political challenges significantly impact them. Cohen is the author of \"Democracy Remixed: Black Youth and The Future of American Politics\" and \"Boundaries of Blackness: AIDS and the Breakdown of Black Politics\" and \"Punks, Bulldaggers, and Welfare Queens: The Radical Potential of Queer Politics?\". Cohen is also the co-editor of \"Women Transforming Politics: An Alternative Reader\" with Kathleen Jones and Joan Tronto and the co-author of a study on New Media and Youth Political Action, which is part of the Youth and Participatory Politics survey project. She was also on the board of as well as the Center for Lesbian and Gay Studies (CLAGS) at CUNY. \n\nHer book \"Boundaries of Blackness: AIDS and the Breakdown of Black Politics\" explores how issues such as age, gender, sexuality and the growing AIDs epidemic shape the acceptance boundaries within the African-American community. \n\nIn \"Democracy Remixed: Black Youth and The Future of American Politics,\" Cohen uses findings from the Black Youth Project to provide a detailed description of what black youth want, how they understand intersecting challenges of opportunity and discrimination, and how we can begin to help transform the lived experiences and future outcomes of African American youth\".\" \n\nIn \"Punks, Bulldaggers, and Welfare Queens: The Radical Potential of Queer Politics?\", Cohen encourages queer politics to focus not just heteronormative oppression, but on other forms of interlocking and overlapping systemic oppressions, such as race, gender, sexual orientation, (dis)ability, etc. for a more inclusive political activism.\n\nCohen is one of the founding board members of the Audre Lorde Project, which focuses on providing adequate representation, community wellness, and efficient economic and social justice for the LGBT+ communities they serve. Cohen is active in a number of organizations working on social justice issues; she has moderated the Applied Research Center's 2010 conference \"Popularizing Racial Justice\", and served as secretary of the American Political Science Association. Cohen has also been member of the Black Radical Congress, African American Women in Defense of Ourselves and the United Coalition Against Racism. She currently serves as a board member of the Arcus Foundation and of the University of Chicago’s four charter schools.\n\nShe has received a number of awards, including the Robert Wood Johnson Investigator’s Award, and the Robert Wood Johnson Scholars in Health Policy Research Fellowship.\n\nCohen is the recipient of two research grants from the Ford Foundation for her work as principal investigator of the Black Youth Project and the Mobilization, Change and Political and Civic Engagement Project. Cohen serves on a number of national and local advisory boards and is the co-editor with Frederick Harris of a book series at Oxford University Press entitled \"Transgressing Boundaries: Studies in Black Politics and Black Communities\".\n\nIn 2004, Cohen was awarded the Race, Politics, and Adolescent Health: Understanding the Health Attitudes and Behaviors of African American Youth Award. In 2004, Cohen was also interviewed for the Global Feminisms Project Comparative Case Studies Of Women's Activism and Scholarships, which is an archive of oral histories given by transnational women scholars and activists.\n\nIn 2013, Cohen gave the Martin Luther King Jr. Memorial Lecture, entitled \"Dr. Martin Luther King Jr. in the Age of Obama: Building a New Movement for the 21st Century\", at Gustavus Adolphus College.\n\n\n"}
{"id": "31372875", "url": "https://en.wikipedia.org/wiki?curid=31372875", "title": "Cave of Nicanor", "text": "Cave of Nicanor\n\n[[File:Nikanor inscription.jpg|250px|thumb|Nicanor inscription:<br>\n\n[[Category:Mount Scopus]]\n[[Category:Archaeological sites in Jerusalem]]\n[[Category:Burial monuments and structures]]\n[[Category:Jewish mausoleums]]\n[[Category:Rock-cut tombs]]\n[[Category:Middle Eastern objects in the British Museum]]\n[[Category:National cemeteries]]"}
{"id": "138585", "url": "https://en.wikipedia.org/wiki?curid=138585", "title": "Chert", "text": "Chert\n\nChert () is a hard, fine-grained sedimentary rock composed of crystals of quartz (silica) that are very small (microcrystalline or cryptocrystalline). Quartz (silica) is the mineral form of silicon dioxide (SiO). Chert is usually of biological origin, being the petrified remains of Siliceous ooze, the biogenic sediment that covers large areas of the deep ocean floor, and which contains the silicon skeletal remains of diatoms, silicoflagellates, and radiolarians. Depending on its origin, it can contain either microfossils, small macrofossils, or both. It varies greatly in color (from white to black), but most often manifests as gray, brown, grayish brown and light green to rusty red (occasionally dark green too); its color is an expression of trace elements present in the rock, and both red and green are most often related to traces of iron (in its oxidized and reduced forms respectively).\n\nChert occurs in carbonate rocks as oval to irregular nodules in greensand, limestone, chalk, and dolostone formations as a replacement mineral, where it is formed as a result of some type of diagenesis. Where it occurs in chalk or marl, it is usually called flint. It also occurs in thin beds, when it is a primary deposit (such as with many jaspers and radiolarites). Thick beds of chert occur in deep marine deposits. These thickly bedded cherts include the novaculite of the Ouachita Mountains of Arkansas, Oklahoma, and similar occurrences in Texas and South Carolina in the United States. The banded iron formations of Precambrian age are composed of alternating layers of chert and iron oxides.\n\nChert also occurs in diatomaceous deposits and is known as diatomaceous chert. Diatomaceous chert consists of beds and lenses of diatomite which were converted during diagenesis into dense, hard chert. Beds of marine diatomaceous chert comprising strata several hundred meters thick have been reported from sedimentary sequences such as the Miocene Monterey Formation of California and occur in rocks as old as the Cretaceous.\n\nIn petrology the term \"chert\" is used to refer generally to all rocks composed primarily of microcrystalline, cryptocrystalline and microfibrous quartz. The term does not include quartzite. Chalcedony is a microfibrous (microcrystalline with a fibrous structure) variety of quartz.\n\nStrictly speaking, the term \"flint\" is reserved for varieties of chert which occur in chalk and marly limestone formations. Among non-geologists, the distinction between \"flint\" and \"chert\" is often one of quality – chert being lower quality than flint. This usage of the terminology is prevalent in North America and is likely caused by early immigrants who brought the terms from England where most true flint (that found in chalk formations) was indeed of better quality than \"common chert\" (from limestone formations).\n\nAmong petrologists, chalcedony is sometimes considered separately from chert due to its fibrous structure. Since many cherts contain both microcrystalline and microfibrous quartz, it is sometimes difficult to classify a rock as completely chalcedony, thus its general inclusion as a variety of chert.\n\nThe cryptocrystalline nature of chert, combined with its above average ability to resist weathering, recrystallization and metamorphism has made it an ideal rock for preservation of early life forms.\n\nFor example:\n\nIn prehistoric times, chert was often used as a raw material for the construction of stone tools. Like obsidian, as well as some rhyolites, felsites, quartzites, and other tool stones used in lithic reduction, chert fractures in a Hertzian cone when struck with sufficient force. This results in conchoidal fractures, a characteristic of all minerals with no cleavage planes. In this kind of fracture, a cone of force propagates through the material from the point of impact, eventually removing a full or partial cone; this result is familiar to anyone who has seen what happens to a plate-glass window when struck by a small object, such as an air gun projectile. The partial Hertzian cones produced during lithic reduction are called flakes, and exhibit features characteristic of this sort of breakage, including striking platforms, bulbs of force, and occasionally eraillures, which are small secondary flakes detached from the flake's bulb of force.\n\nWhen a chert stone is struck against an iron-bearing surface sparks result. This makes chert an excellent tool for starting fires, and both flint and common chert were used in various types of fire-starting tools, such as tinderboxes, throughout history. A primary historic use of common chert and flint was for flintlock firearms, in which the chert striking a metal plate produces a spark that ignites a small reservoir containing black powder, discharging the firearm.\n\nCherts are subject to problems when used as concrete aggregates. Deeply weathered chert develops surface pop-outs when used in concrete that undergoes freezing and thawing because of the high porosity of weathered chert. The other concern is that certain cherts undergo an alkali-silica reaction with high-alkali cements. This reaction leads to cracking and expansion of concrete and ultimately to failure of the material.\n\nIn some areas, chert is ubiquitous as stream gravel and fieldstone and is currently used as construction material and road surfacing. Part of chert's popularity in road surfacing or driveway construction is that rain tends to firm and compact chert while other fill often gets muddy when wet.\n\nChert has been used in late nineteenth-century and early twentieth-century headstones or grave markers in Tennessee and other regions.\n\nThere are numerous varieties of chert, classified based on their visible, microscopic and physical characteristics. Some of the more common varieties are:\nOther lesser used terms for chert (most of them archaic) include firestone, silex, silica stone, chat, and flintstone.\n\n\n"}
{"id": "15959185", "url": "https://en.wikipedia.org/wiki?curid=15959185", "title": "Chibuene", "text": "Chibuene\n\nChibuene is a Mozambiquean archaeological site, located five kilometres south of the coastal city of Vilanculos South Beach. The site was occupied during two distinct phases. The earlier phase of occupation dates to the late first millennium AD. The second phase dates from around 1450 and is contemporaneous with the Great Zimbabwe civilization in the African interior. During both phases of its development Chibuene was a trading settlement. Trade goods obtained from the site include glass beads, painted blue and white ceramics, and glass bottle fragments. The later phase of settlement has yielded remains of ancient structures as well as evidence of metallurgy. Crucibles have been found that were presumably used to melt gold obtained from trade with the Great Zimbabwe civilization. There is evidence that Chibuene traded extensively with the inland settlement of Manyikeni. Mozambique has jointly inscribed these two properties on their tentative version of the World Heritage List.\n\nThe archaeological site was occupied from approximately AD 600 to AD 1700 continuously and into the present, intermittently. This site participated in the Indian Ocean trade network and is currently the most southern located site on the eastern African coast. Archaeological samples at the site revealed that Chibuene's occupation contained two major periods of occupation. The objects presented in the lower deposits contained glazed and unglazed pottery, glass, iron fragments, and beads made of shell and glass. The upper layers contained a distinguishable change in ceramic typology. In addition, two types of imported glazed pottery have been recovered from the site. The main subsistence pattern of the inhabitants of the site appeared to derive from the coast which included fish, marine mammals, and reptiles. Additionally, contemporary farmers in the region produce maize, sorghum, manioc, beans, and peanuts.\n\nThe lower layers of occupation contained the presence of early Matola pottery typically associated with early farming communities in the region. In addition to glass beads which revealed the locations importance as an entry point for glass which later found its way into the interior by the end of the first millennium AD. The site likely contributed to glass beads presented in sites within Shashe River and Limpopo River regions, the Zimbabwe Plateau, and Botswana to about AD 1000. The considerable amount of glass and shell recovered in the lower occupation deposits suggested the site trading extensively within the Indian Ocean trade network in the late first millennium AD.\n\nManyikeni, a Zimbabwean traditional style of stone walled settlement 10 km west of Chibuene, possibly gained control of the site after AD 1200. This is attested by the increased similarity of later occupation deposits containing pottery similar in character to Manyikeni. In addition, this is corroborated by the presence of marine shell and imports from Indian ocean trade in the context of Manyikeni deposits suggesting the coast and hinterlands were connected through trade networks. Chibuene acted as the way point for entry of materials and resources from the eastern coast and the trade network it provided.\n\nThe current estimate for the development of the site is estimated to be around 400 AD as a farming community on the southern coast of Mozambique. Contemporary annual and seasonal rainfall reveals very high variability in the region with most of the rainfall arriving in December and February, averaging 832 mm/per year. The summer rainfall season experiences decadal cycles of wet and dry phases. The high variability of rainfall appears to have remained consistent throughout the last 1600 years. Pollen evidence from the surrounding lakes of Nhaucati and Xiroche suggests a lengthy period of drought between 1400 and 1700, peaking in 1700. This drought accompanied a dramatic change in vegetation cover from forest savanna mosaic to forest savanna woodland. Furthermore, the surrounding area contains relatively nutrient poor dunal sand, susceptible to erosion.\n\nAgriculture was introduced to the region around 400 AD to the present. Poor soil and the unreliability of rainfall reduced the viability of agriculture as a reliable subsistence pattern. Throughout the course of the occupation of Chibuene, the inhabitants practiced a broad subsistence economy with the utilization of domestic animals, marine fauna, and wild plant life to augment agricultural production. Of particular significance to the site was the distinctive emphasis on marine fauna in the diets of the inhabitants. The 1995 excavations from a Swedish sponsored team revealed a rather high proportion of fish remains in comparison to sites in South Africa. The faunal remains of shark and turtle were notable features of the site. Shark fishing and turtle hunting are subsistence strategies more associated with East African, or Swahili coast, sites beginning in the first millennium, revealing a closer affinity of Chibuene to sites further north than the southern interior.\nThe oldest layers of the site contained a high volume of shellfish. In addition domesticated animals such as cattle, sheep, goats, and chickens are represented at the site which attests to an association with southern African sites. Despite the availability of domesticated animals, it appeared that shellfish consisted of the bulk of the protein utilized by the inhabitants of Chibuene.\n\nThe introduction of domesticated chicken illustrates the site’s importance for trade between the Indian Ocean and the southern interior as a possible route of entry for the black-feathered variety of chicken resembling those of India. Thus, the inhabitants of the site made extensive use of their location along the southern Mozambican coast. The poor soil composition and inadequate rainfall only allowed variable agricultural output, causing the inhabitants to procure other means of sustenance. Chibuene inhabitants made use of domesticated animals from southern Africa and successful shark and turtle hunting practices from neighbors from the north in order to adequately exploit the resources of the particular region they inhabited with easy access to the coast and variable land for pasturage in addition to invaluable trade resources procured from the Indian Ocean trade network.\n\nIn the initial years of occupation between 400 and 700 AD clearing of land for agriculture remained relatively small. The years following saw a degree of agricultural intensification between 600 and 1000 AD, but there is no evidence for clearing on a massive scale. Trade played an important role in this period for procuring valuable commodities such as glass and additional food stuffs. Faunal assemblages revealed much more of an emphasis on cattle herding in these early years, although not on a large-scale due to the low availability of pastoral lands. Cattle were possibly traded with the interior to procure extra grain stuffs in times of need. In these years, the landscape was covered in riverine forests and savannah.\n\nThe inhabitants of the site practiced agriculture since the early first millennium AD, but a notable increased occurred in roughly 1200 AD. This appeared to be accompanied by a decrease in foreign trade goods from the Indian Ocean trade network, particularly glass and ceramics from this network. For much of the period between 700-1000 AD, Chibuene was an important site that linked trade with the southern African interior and the trade networks on the coast. At the end of the first millennium trade networks on the Indian Ocean shifted north, causing a marked decline in the site’s significance in this network. This marked a transition period of the site from a significant Indian Ocean trade site to an agricultural and herding economy for the inhabitants. Chibuene remained an important location for trade on a regional level, but the site declined in population with the inhabitants scattering further into the interior. Anneli Ekblom suggests that the site may have been abandoned at this time and reoccupied two hundred years later. Evidences for this derives from the stark discontinuity of previous ceramic styles associated with southern African agriculturalists and the movement toward styles associated with Manyikeni.\n\nDespite the potential abandonment of Chibuene, the surrounding region saw a dramatic shift to increased agricultural subsistence. At the same time of this shift, it is evident that the site began to become under the influence of Manyikeni, a Zimbabwean stone complex 50 km northwest of the site. Chibuene appeared to have become a tributary and redeveloped under the influence of Manyikeni. The increased use of agriculture likely served as an adaptive strategy to make up for the decreased availability of trade in the region. Furthermore, the climactic composition of the region largely remained the same as the previous occupation with sparse and unreliable rainfall, combined with low nutrient soil, further suggesting a relationship. Domesticated animals such as cattle, sheep, and goats remain in the faunal assemblages, suggesting their continued use as a buffer during periods of lower agricultural production. In addition, marine fauna remained an important part of the diets of individuals occupying the site.\n\nThe region surrounding Chibuene through the course of its occupation was a site of dramatic transformations of vegetation cover and climactic shifts. Pollen diagrams deriving from the surrounding lakes of Nhaucati and Xiroche revealed extensive landscape transformations from riverine forests to mostly savannah in the present day. As a result, the individual inhabitants employed a variety of adaptive strategies in order to procure adequate resources for survival. These included agriculture, keeping of domesticated animals, collecting of wild plant food stuff, and making use of their position close to the coast by exploiting marine flora and fauna. The site illustrated nearly 1600 years of such strategies.\n\nThe high concentration of beads in the early occupation levels of the Chibuene site suggest that the site was an important point of entry for trade goods arriving in the interior from 700-1000 AD. Many sites further north have been dated to have participated in trans-oceanic trade in the early first millennium AD, but sites such as Chibuene further south appear to have conducted extensive trade much earlier in the eighth century AD, evidenced from imported glass. Chibuene was the most southern trading port to have participated in the Indian Ocean Trade network. The glass deposits at the site match those of sites in the interior extending 1500 km. In this time frame, Chibuene was a very important gateway linking the coast to the interior, but sometime at the end of the first millennium its role dramatically decreased in the Indian Ocean trade network. Contemporaneously, sites further north, particularly Unguja Ukuu on Zanzibar and Tumbe on Pemba Island experienced a similar decline and trade and period of abandonment.\n\nCeramics\n\nThe earliest ceramics in the lowest levels of occupation contained a distinct pottery style, most associated with early agriculturalists in southern Africa. Much of the first phase of occupation is dominated by locally produced ceramics, mentioned above, Islamic glazed ware, and Ziwa tradition ceramics. The two notable types of glaze ware includes tin-glazed with a splash painted decoration and a light blue glaze. Contained in the artefact assemblage were two fragments of light blue glaze on a buff body found in the lowest occupation in addition to small sherds of similar type. Another two imported ceramics were two bowls of different sizes, one 22 cm in diameter and the other 28 cm in diameter. These were of the same design of a slightly raised ridge found on the inside body and turned out lips, but of differing size. This bowls were characteristic of ceramics found in Period Ia in Kilwa Kisiwani located to the north in Tanzania. It remains unknown as to whether these were imported from Kilwa or produced locally. These ceramic types were only found in the lower levels of occupation.\n\nThe unglazed ware at the site contained motifs ranging from triangles, oblique and horizontal lines, cross hatching, zigzags, and herringbone, typically across the rim, neck, or shoulder of the vessels. These appear to be produced through fine and gross incisions and shell impressions or punctuations. Ceramic evidence in the archaeological assemblage reveals that the site had a degree of contact with sites to the north and south in addition to Indian Ocean traders along the coast.\n\nIn the later occupation levels, ceramic levels begin to take on a new character. The assemblages begin resemble ceramic deposits located in Manyikeni at roughly 1200 AD. Ceramic samples taken from the earliest occupation levels at Manyikeni reveal dissimilarity with ceramics of the earliest levels at Chibuene. The most distinct Manyikeni ceramics are ovaloid vessels with shell impressed motifs and independent restricted vessels with graphite decoration which are absent from the assemblages within Chibuene in the first phase of occupation between 600-1000 AD. The discontinuity of imported glazed ceramics and introduction of Manyikeni styles is suggestive of the site becoming under the influence of Manyikeni. The ceramics in this period appear to be completely dominated by shell stamping in a similar manner to Manyikeni.\n\nGlass and shell beads\n\nThe first occupation phase of Chibuene contained a multitude of glass beads, glass fragments, and shell beads. Glass beads classified as Zhizo beads have been found at sites further south and in limited numbers in sites further north. These same beads appear less frequently in the later occupation levels in the second millennium. Furthermore, glass beads appear most frequently in the early occupation sites and show a dramatic decrease in the later occupation levels. These reveal the significance of Chibuene as an important point of entry for glass and glass beads to sites located in the interior of southern Africa and to a lesser degree regions north of the site. Written sources in from the fifteenth century revealed that ivory, animal skins and slaves were traded for glass beads.\n\nIn archaeological surveys performed between 1995 and 2001 from the lower levels of occupation (600-1000 AD), 2800 beads were collected from the site with the vast majority being of the Zhizo tradition and the discovery of a new typology, named the Chibuene series. The Zhizo beads were made of plant-ash glass which suggests a Near Eastern origin, as only sites west of the Euphrates utilized plant-ash glass at this time, but the beads were manufactured with South Asian technology, making the place of manufacture difficult to ascertain.\n\nThe Chibuene series is distinct from other glass beads in the area in morphology and chemistry. The beads are tubular in shape with ends that have been rounded through reheating and suggested to be older than Zhizo beads at the site. These only match beads located at Nqoma in western Botswana, contemporaneously. The glass used to manufacture the beads appear to have a Near East origin.\n\nArchaeological evidence reveals that Chibuene played an important role in trade in the region, despite the decline of Indian Ocean trade at the end of the first millennium. The site remained important for local trade between the north and south in addition to linking the coast with the interior at Manyikeni in which marine resources have been evidenced in the archaeological record at the site.\n\n"}
{"id": "1826593", "url": "https://en.wikipedia.org/wiki?curid=1826593", "title": "Dead Cities", "text": "Dead Cities\n\nThe Dead Cities () or Forgotten Cities () are a group of 700 abandoned settlements in northwest Syria between Aleppo and Idlib. Around 40 villages grouped in eight archaeological parks situated in north-western Syria provide an insight into rural life in Late Antiquity and during the Byzantine period. Most villages which date from the 1st to 7th centuries, became abandoned between the 8th and 10th centuries. The settlements feature the well-preserved architectural remains of dwellings, pagan temples, churches, cisterns, bathhouses etc. Important dead cities include the Church of Saint Simeon Stylites, Serjilla and al Bara.\n\nThe Dead Cities are situated in an elevated area of limestone known as Limestone Massif. These ancient settlements cover an area wide and some long. The Massif includes three groups of highlands: the first is the northern group of Mount Simeon and Mount Kurd; the second middle group is the group of Harim Mountains; the third southern group is the group of Zawiya Mountain.\n\nChris Wickham, in the authoritative survey of the post-Roman world, \"Framing the Early Middle Ages\" (2006) argues that these were settlements of prosperous peasants which have few or no specifically urban features. The impressive remains of domestic architecture are the result of the prosperity of peasants who benefited from a strong international trade in olive oil at the end of Antiquity.\n\nAnother argument is that these were prosperous cities that flourished because they were located along major trade routes in the Byzantine Empire, and not merely prosperous peasant settlements. After conquest by the Arabs, the trade routes changed, and as a result these towns lost the majority of the business which fostered their economies. On this view, settlers eventually abandoned their towns and headed for other cities that were flourishing under the Arabs and the Umayyads as increasing urbanisation took its toll.\n\nThe ancient villages of the Dead Cities illustrate the transition from the ancient pagan world of the Roman Empire to Byzantine Christianity.\n\nThe majority of the dead cities are well-preserved, and tourists can access the sites quite freely despite the ongoing archaeological excavations and some restoration work, though some of the Dead Cities are quite difficult to reach without a guide.\n\nRelatively few of the Dead Cities have any archaeological excavations taking place, and unfortunately the majority of people living in close proximity to them have no understanding of their importance. However, the local inhabitants are always welcoming to visitors.\n\nRecently, most sites became easily accessible since many roads have been asphalted. There is a guidebook with a detailed map that is extremely useful for finding the lesser known sites; \"The Church of St Simeon Stylites and Other Archaeological Sites in the Mountains of Simeon and Halaqa\" (Arabic text by Abdallah Hadjar, translated by Paul Amish).\n\nDead Cites were inscribed as a UNESCO World Heritage Site in 2011, under the name of \"Ancient Villages of Northern Syria\".\n\nDead cities and archeological sites in Limestone Massif include Church of Saint Simeon Stylites, Serjilla, Bara, Basufan, Barisha, Qalb Loze, Barad, Cyrrhus, Turmanin, Banabil, Kafr Aruq, Kafr Dariyan, Babuline, Hazarin, Jarada, Maghara, Shinan, Syria, Farkya, Ein Laruz, Ebla, Deir Sunbul, Al-Dana, Sarmada and Al-Dana.\n\n"}
{"id": "10302313", "url": "https://en.wikipedia.org/wiki?curid=10302313", "title": "Deccan College Post-Graduate and Research Institute", "text": "Deccan College Post-Graduate and Research Institute\n\nDeccan College Post-Graduate and Research Institute also referred to as Deccan College is a post-graduate institute of Archeology, Linguistics and Sanskrit & Lexicography Pune, India.\n\nEstablished on 6 October 1821 as Hindoo College, it is one of the oldest institutions of modern learning in India. It was started under Mountstuart Elphinstone (Lt. Governor of Bombay Presidency), with funds diverted from the erstwhile Peshwa's Dakshina Fund, later disbursed by Sardar Khanderao Dabhade after the Territories of the Peshwa were annexed in 1818. It was also known as the Poona Sanskrit College. The first principal was Major Thomas Candy.\n\nIn 1837, English and other modern subjects were added to the curriculum. An English school was added to the college in 1842; on 7 June 1851 the English school was merged with the Hindoo College to form Poona College. In 1857, the principal was Sir Edwin Arnold, followed by W.A. Russell in 1860.\n\nFrom its original location in Vishrambaug Wada and later in Wanwadi, the Poona College was shifted to its present large campus near Yerwada. The land was donated by the Bombay government. The foundation stone of the main building was laid on 15 October 1864. A Victorian neo-Gothic building was constructed by Sir Henry Bartle Frere with a munificent 1,00,000 rupees from Sir Jamsetjee Jejeebhoy, 2nd Baronet, between Kirkee and Yerwada.\n\nThe college started functioning on the new campus on 23 March 1868. At this stage it was renamed as Deccan College in recognition of the enrollment of students from the entire Deccan region. Until 1881, Deccan College was staffed by four professors, one acting as principal. Another of the four, the professor of Oriental languages, supervised five traditional Sanskrit shastris and an expert in Zend Pahlevi in an extensive program of research and text publication, in addition to his teaching duties. Student enrollment rose to a peak of 210 in 1885. William Wordsworth (grandson of the poet William Wordsworth) and E.A. Wodehouse (brother of P.G. Wodehouse) were principals of the college during 1862-74 and 1934-39 respectively.\n\nDeccan College temporarily shut down its teaching activities in 1934 due to lack of funding. It was reopened by order of the Bombay High Court on 17 August 1939 as a post-graduate and research institute for promoting higher learning and research in Indology and Social Sciences. The re-opened institute originally had four teaching and research departments: Archaeology, Linguistics, History, and Sociology-Anthropology.\n\nA Transfer Deed was passed by the Hon’ble Bombay High Court on 16 August 1939 by which the court enjoined the state government to run the institute in perpetuity. As per the Transfer Deed the Deccan College Poona Trust came into existence in which were vested the properties including the land and buildings. In accordance with the provision in the Transfer Deed, the appointments of the Trustees today are made by the State Government.\n\nIt was incorporated by the Poona University (now University of Pune) in 1948, becoming one of its recognized institutions.\n\nThe state government was entrusted with preparing the rules for the administration and management of the Deccan College Post-Graduate and Research Institute, which was to cater to studies in post-graduate and research in heritage-related subjects. Thus the Management Council came into existence. In the next half-century the institute, apart from giving instruction to postgraduate students and producing over 500 Ph.D. dissertations, carried out outstanding research in Ancient Indian History, Culture and Archaeology, Linguistics, Medieval and Maratha History, Sociology-Anthropology and Sanskrit Studies.\n\nIn recognition of the excellence achieved by the institute in teaching and research, the H.R.D. Ministry, Government of India, awarded it the status of a Deemed University on 5 March 1990. It started functioning as Deemed University from 1 June 1994. Since then the institute has conducted its own courses for M.A. degree and P.G. diploma in Archaeology, M.A. degree in Linguistics, and M.A. degree in Sanskrit and Lexicography, and has enrolled a large number of students for the Ph.D. degree in these disciplines.\n\nCurrently, Deccan College has only two teaching and research departments: Archaeology and Linguistics. On the premises are two museums: the Museum of Maratha History, and the Museum of Archaeology. As of 2016, it is currently involved in the ongoing multi-year excavation of the largest Indus Valley Civilization site of Rakhigarhi in Hisar district of Haryana.\n\nDeccan College had the oldest boat club in India, called the Poonah Boat Club. The site has since been discontinued and is completely overrun by the slums behind Shadal Baba Dargah.\n\n\n"}
{"id": "49114294", "url": "https://en.wikipedia.org/wiki?curid=49114294", "title": "Ernst v EnCana Corporation", "text": "Ernst v EnCana Corporation\n\nErnst v. EnCana Corporation, 2013 ABQB 537 is a lawsuit by Jessica Ernst against EnCana Corporation, the Energy Resources Conservation Board, and Her Majesty the Queen in Right of Alberta. EnCana is accused of contaminating, by its hydraulic fracturing, the Rosebud aquifer near Rosebud, Alberta, and the Ernst water well. The claim is supported by the rule in \"Rylands v Fletcher\".\n\n\n"}
{"id": "193889", "url": "https://en.wikipedia.org/wiki?curid=193889", "title": "Frank James", "text": "Frank James\n\nAlexander Franklin James (January 10, 1843 – February 18, 1915) was a Confederate soldier, guerrilla, and outlaw. He was the older brother of outlaw Jesse James and was also part of the James–Younger Gang.\n\nJames was born Alexander Franklin James in Kearney, Missouri, to Baptist minister Reverend Robert Sallee James and his wife Zerelda (Cole) James, who had moved from Kentucky. He was the oldest of three children. His father died in 1851 and his mother remarried Benjamin Simms in 1852. After his death she married a third time to Dr. Reuben Samuel in 1855 when Frank was 13 years old. As a child, James showed interest in his late father's sizable library, especially the works of William Shakespeare. Census records show that James attended school regularly, and he reportedly wanted to become a teacher.\n\nThe American Civil War began in 1861, when James was eighteen years old. The secessionists in Missouri, including Governor Claiborne Fox Jackson, attempted to drive the Union army out of the state but were eventually defeated. The James family was from the heavily Confederate western portion of the state. On September 13, 1861, the Missouri State Guard, including private Frank James, besieged Lexington, Missouri. James fell ill and was left behind when the Confederate forces retreated. He surrendered to the Union troops, was paroled, and was allowed to return home. On his arrival, however, he was arrested by the local pro-Union militia and was forced to sign an oath of allegiance to the Union.\n\nAfter the withdrawal of regular Confederate troops in the fall of 1861, a bitter guerrilla conflict soon began between bands of pro-Confederate irregulars (commonly known as bushwhackers) and the Union homeguards. By early 1863, Frank, ignoring his parole and oath of allegiance, had joined the guerrilla band of Fernando Scott, a former saddler. He soon switched to the more active command led by William Clarke Quantrill.\n\nUnion militiamen searching for Fernando Scott raided the Samuel farm and hanged Dr. Reuben Samuel (though not fatally), Frank's stepfather, torturing him to reveal the location of the guerrillas. Shortly afterward, Frank took part with Quantrill's company in the August 21, 1863 Lawrence Massacre where approximately 200 mostly unarmed civilians were killed.\n\nFrank James was paroled July 27, 1865 in Nelson County, Kentucky. There is a report that after his parole, Frank was involved in a gunfight in Brandenburg, Kentucky with four soldiers that resulted in two soldiers killed, one wounded, and Frank wounded in the hip. However, there is an alternative account that claims in the autumn of 1865, Frank, who was in Kentucky going to Missouri, was suspected of stealing horses in Ohio and that Frank shot two members of a posse and escaped.\n\nDuring his years as a bandit, James was involved in at least four robberies between 1868 and 1876 that resulted in the deaths of bank employees or citizens. The most famous incident was the disastrous Northfield, Minnesota, raid on September 7, 1876, that ended with the death or capture of most of the gang.\n\nFive months after the killing of his brother Jesse in 1882, Frank James boarded a train to Jefferson City, Missouri, where he had an appointment with the governor in the state capitol. Placing his holster in Governor Crittenden's hands, he explained,\n\nAccounts say that James surrendered with the understanding that he would not be extradited to Northfield, Minnesota.\n\nHe was tried for only two of the robberies/murders – one in Gallatin, Missouri for the July 15, 1881 robbery of the Rock Island Line train at Winston, Missouri, in which the train engineer and a passenger were killed, and the other in Huntsville, Alabama for the March 11, 1881 robbery of a United States Army Corps of Engineers payroll at Muscle Shoals, Alabama. Among others, former Confederate General Joseph Orville Shelby testified on James' behalf in the Missouri trial. He was acquitted in both Missouri and Alabama. Missouri accepted legal jurisdiction over him for other charges, but they never came to trial. He was never extradited to Minnesota for his connection with the Northfield Raid.\n\nHis New York Times obituary summarized his arrest and acquittal:\n\nIn the last thirty years of his life, James worked a variety of jobs, including as a shoe salesman and then as a Burlesque theater ticket taker in St. Louis. One of the theater's spins to attract patrons was their use of the phrase \"Come get your ticket punched by the legendary Frank James.\" He also served as an AT&T telegraph operator in St. Joseph, Missouri. James took up the lecture circuit, while residing in Sherman, Texas. In 1902, former Missourian Sam Hildreth, a leading thoroughbred horse trainer and owner, hired James as the betting commissioner at the Fair Grounds Race Track in New Orleans. He returned to the North Texas area where he was a shoe salesman at Sanger Brothers in Dallas. The \"Tacoma Times\" reported in July, 1914 that he was picking berries at a local ranch there in Washington state and planned to buy a farm nearby. He was also part of a Chicago investment group which purchased the Fletcher Terrell's Buckskin Bill's Wild West Show, third in size after the Buffalo Bill and Pecos Bill shows.\n\nIn his final years, James returned to the James Farm, giving tours for the sum of 25 cents. He died there on February 18, 1915, aged 72 years. He left behind his wife Annie Ralston James and one son.\n\n\n"}
{"id": "51871034", "url": "https://en.wikipedia.org/wiki?curid=51871034", "title": "Gilles Delouche", "text": "Gilles Delouche\n\nGilles Delouche (3 August 1948 in Orléans), is a French scholar of classical literature of the Rattanakosin Kingdom (Thai language), Professor at the Institut national des langues et civilisations orientales (INALCO) since 1987, having taught from 1971 to 1987 at the Faculty of Arts, Silpakorn University (Thailand), which awarded him an honorary degree.\n\nGilles Delouche served as president of the Institut national des langues et civilisations orientales from 2001 to 2005. \n\nHis teaching has focused on introductory Thai syntax, but also more particularly on Siamese versification and classical works, from their origins to the seventeenth century.\n\nHe is the author of some fifty articles published in French, English and Thai, concerning issues of the dating and restoration of classical Siamese manuscripts, as well as work on the origins of the first embodiment of Siamese unity in the first part of the Ayudhya period (1350–1656). \n\n\n"}
{"id": "210098", "url": "https://en.wikipedia.org/wiki?curid=210098", "title": "Hunter-gatherer", "text": "Hunter-gatherer\n\nA hunter-gatherer is a human living in a society in which most or all food is obtained by foraging (collecting wild plants and pursuing wild animals). Hunter-gatherer societies stand in contrast to agricultural societies, which rely mainly on domesticated species.\n\nHunting and gathering was humanity's first and most successful adaptation, occupying at least 90 percent of human history. Following the invention of agriculture, hunter-gatherers who did not change have been displaced or conquered by farming or pastoralist groups in most parts of the world.\n\nOnly a few contemporary societies are classified as hunter-gatherers, and many supplement their foraging activity with horticulture or pastoralism.\n\nIn the 1970s, Lewis Binford suggested that early humans were obtaining food via scavenging, not hunting. Early humans in the Lower Paleolithic lived in forests and woodlands, which allowed them to collect seafood, eggs, nuts, and fruits besides scavenging. Rather than killing large animals for meat, according to this view, they used carcasses of such animals that had either been killed by predators or that had died of natural causes. Archaeological and genetic data suggest that the source populations of Paleolithic hunter-gatherers survived in sparsely wooded areas and dispersed through areas of high primary productivity while avoiding dense forest cover.\n\nAccording to the endurance running hypothesis, long-distance running as in persistence hunting, a method still practiced by some hunter-gatherer groups in modern times, was likely the driving evolutionary force leading to the evolution of certain human characteristics. This hypothesis does not necessarily contradict the scavenging hypothesis: both subsistence strategies could have been in use – sequentially, alternating or even simultaneously.\n\nHunting and gathering was presumably the subsistence strategy employed by human societies beginning some 1.8 million years ago, by \"Homo erectus\", and from its appearance some 0.2 million years ago by \"Homo sapiens\". Prehistoric hunter-gatherers lived in groups that consisted of several families resulting in a size of a few dozen people. It remained the only mode of subsistence until the end of the Mesolithic period some 10,000 years ago, and after this was replaced only gradually with the spread of the Neolithic Revolution.\n\nStarting at the transition between the Middle to Upper Paleolithic period, some 80,000 to 70,000 years ago, some hunter-gatherers bands began to specialize, concentrating on hunting a smaller selection of (often larger) game and gathering a smaller selection of food. This specialization of work also involved creating specialized tools such as fishing nets, hooks, and bone harpoons. The transition into the subsequent Neolithic period is chiefly defined by the unprecedented development of nascent agricultural practices. Agriculture originated as early as 12,000 years ago in the Middle East, and also independently originated in many other areas including Southeast Asia, parts of Africa, Mesoamerica, and the Andes.\n\nForest gardening was also being used as a food production system in various parts of the world over this period. Forest gardens originated in prehistoric times along jungle-clad river banks and in the wet foothills of monsoon regions. In the gradual process of families improving their immediate environment, useful tree and vine species were identified, protected and improved, whilst undesirable species were eliminated. Eventually superior introduced species were selected and incorporated into the gardens.\n\nMany groups continued their hunter-gatherer ways of life, although their numbers have continually declined, partly as a result of pressure from growing agricultural and pastoral communities. Many of them reside in the developing world, either in arid regions or tropical forests. Areas that were formerly available to hunter-gatherers were—and continue to be—encroached upon by the settlements of agriculturalists. In the resulting competition for land use, hunter-gatherer societies either adopted these practices or moved to other areas. In addition, Jared Diamond has blamed a decline in the availability of wild foods, particularly animal resources. In North and South America, for example, most large mammal species had gone extinct by the end of the Pleistocene—according to Diamond, because of overexploitation by humans, one of several explanations offered for the Quaternary extinction event there.\n\nAs the number and size of agricultural societies increased, they expanded into lands traditionally used by hunter-gatherers. This process of agriculture-driven expansion led to the development of the first forms of government in agricultural centers, such as the Fertile Crescent, Ancient India, Ancient China, Olmec, Sub-Saharan Africa and Norte Chico.\n\nAs a result of the now near-universal human reliance upon agriculture, the few contemporary hunter-gatherer cultures usually live in areas unsuitable for agricultural use.\n\nArchaeologists can use evidence such as stone tool use to track hunter-gatherer activities, including mobility.\n\nMost hunter-gatherers are nomadic or semi-nomadic and live in temporary settlements. Mobile communities typically construct shelters using impermanent building materials, or they may use natural rock shelters, where they are available.\n\nSome hunter-gatherer cultures, such as the indigenous peoples of the Pacific Northwest Coast, lived in particularly rich environments that allowed them to be sedentary or semi-sedentary.\n\nHunter-gatherers tend to have an egalitarian social ethos, although settled hunter-gatherers (for example, those inhabiting the Northwest Coast of North America) are an exception to this rule. Nearly all African hunter-gatherers are egalitarian, with women roughly as influential and powerful as men. Karl Marx defined this socio-economic system as primitive communism.\nThe egalitarianism typical of human hunters and gatherers is never total, but is striking when viewed in an evolutionary context. One of humanity's two closest primate relatives, chimpanzees, are anything but egalitarian, forming themselves into hierarchies that are often dominated by an alpha male. So great is the contrast with human hunter-gatherers that it is widely argued by palaeoanthropologists that resistance to being dominated was a key factor driving the evolutionary emergence of human consciousness, language, kinship and social organization.\n\nAnthropologists maintain that hunter/gatherers don't have permanent leaders; instead, the person taking the initiative at any one time depends on the task being performed. In addition to social and economic equality in hunter-gatherer societies, there is often, though not always, sexual parity as well. Hunter-gatherers are often grouped together based on kinship and band (or tribe) membership. Postmarital residence among hunter-gatherers tends to be matrilocal, at least initially. Young mothers can enjoy childcare support from their own mothers, who continue living nearby in the same camp. The systems of kinship and descent among human hunter-gatherers were relatively flexible, although there is evidence that early human kinship in general tended to be matrilineal.\n\nOne common arrangement is the sexual division of labour, with women doing most of the gathering, while men concentrate on big game hunting. In all hunter-gatherer societies, women appreciate the meat brought back to camp by men. An illustrative account is Megan Biesele's study of the southern African Ju/'hoan, 'Women Like Meat'. Recent archaeological research suggests that the sexual division of labor was the fundamental organisational innovation that gave \"Homo sapiens\" the edge over the Neanderthals, allowing our ancestors to migrate from Africa and spread across the globe.\n\nTo this day, most hunter-gatherers have a symbolically structured sexual division of labour. However, it is true that in a small minority of cases, women hunt the same kind of quarry as men, sometimes doing so alongside men. Among the Ju'/hoansi people of Namibia, women help men track down quarry. Women in the Australian Martu also primarily hunt small animals like lizards to feed their children and maintain relations with other women.\nAt the 1966 \"Man the Hunter\" conference, anthropologists Richard Borshay Lee and Irven DeVore suggested that egalitarianism was one of several central characteristics of nomadic hunting and gathering societies because mobility requires minimization of material possessions throughout a population. Therefore, no surplus of resources can be accumulated by any single member. Other characteristics Lee and DeVore proposed were flux in territorial boundaries as well as in demographic composition.\n\nAt the same conference, Marshall Sahlins presented a paper entitled, \"Notes on the Original Affluent Society\", in which he challenged the popular view of hunter-gatherers lives as \"solitary, poor, nasty, brutish and short\", as Thomas Hobbes had put it in 1651.\nAccording to Sahlins, ethnographic data indicated that hunter-gatherers worked far fewer hours and enjoyed more leisure than typical members of industrial society, and they still ate well. Their \"affluence\" came from the idea that they were satisfied with very little in the material sense. Later, in 1996, Ross Sackett performed two distinct meta-analyses to empirically test Sahlin's view. The first of these studies looked at 102 time-allocation studies, and the second one analyzed 207 energy-expenditure studies. Sackett found that adults in foraging and horticultural societies work, on average, about 6.5 hours a day, where as people in agricultural and industrial societies work on average 8.8 hours a day.\n\nResearchers Gurven and Kaplan have estimated that around 57% of hunter-gatherers reach the age of 15. Of those that reach 15 years of age, 64% continue to live to or past the age of 45. This places the life expectancy between 21 and 37 years. They further estimate that 70% of deaths are due to diseases of some kind, 20% of deaths come from violence or accidents and 10% are due to degenerative diseases.\n\nMutual exchange and sharing of resources (i.e., meat gained from hunting) are important in the economic systems of hunter-gatherer societies. Therefore, these societies can be described as based on a \"gift economy.\"\n\nHunter-gatherer societies manifest significant variability, depending on climate zone/life zone, available technology, and societal structure. Archaeologists examine hunter-gatherer tool kits to measure variability across different groups. Collard \"et al.\" (2005) found temperature to be the only statistically significant factor to impact hunter-gatherer tool kits. Using temperature as a proxy for risk, Collard \"et al.'s\" results suggest that environments with extreme temperatures pose a threat to hunter-gatherer systems significant enough to warrant increased variability of tools. These results support Torrence's (1989) theory that risk of failure is indeed the most important factor in determining the structure of hunter-gatherer toolkits.\n\nOne way to divide hunter-gatherer groups is by their return systems.\nJames Woodburn uses the categories \"immediate return\" hunter-gatherers for egalitarian and \"delayed return\" for nonegalitarian.\nImmediate return foragers consume their food within a day or two after they procure it.\nDelayed return foragers store the surplus food (Kelly, 31).\n\nHunting-gathering was the common human mode of subsistence throughout the Paleolithic, but the observation of current-day hunters and gatherers does not necessarily reflect Paleolithic societies; the hunter-gatherer cultures examined today have had much contact with modern civilization and do not represent \"pristine\" conditions found in uncontacted peoples.\n\nThe transition from hunting and gathering to agriculture is not necessarily a one way process.\nIt has been argued that hunting and gathering represents an adaptive strategy, which may still be exploited, if necessary, when environmental change causes extreme food stress for agriculturalists. In fact, it is sometimes difficult to draw a clear line between agricultural and hunter-gatherer societies, especially since the widespread adoption of agriculture and resulting cultural diffusion that has occurred in the last 10,000 years. This anthropological view has remained unchanged since the 1960s.\n\nNowadays, some scholars speak about the existence within cultural evolution of the so-called mixed-economies or dual economies which imply a combination of food procurement (gathering and hunting) and food production or when foragers have trade relations with farmers.\n\nIn the early 1980s, a small but vocal segment of anthropologists and archaeologists attempted to demonstrate that contemporary groups usually identified as hunter-gatherers do not, in most cases, have a continuous history of hunting and gathering, and that in many cases their ancestors were agriculturalists or pastoralists who were pushed into marginal areas as a result of migrations, economic exploitation, or violent conflict (see, for example, the Kalahari Debate). The result of their effort has been the general acknowledgement that there has been complex interaction between hunter-gatherers and non-hunter-gatherers for millennia.\n\nSome of the theorists who advocate this \"revisionist\" critique imply that, because the \"pure hunter-gatherer\" disappeared not long after colonial (or even agricultural) contact began, nothing meaningful can be learned about prehistoric hunter-gatherers from studies of modern ones (Kelly, 24-29; see Wilmsen)\n\nLee and Guenther have rejected most of the arguments put forward by Wilmsen. Doron Shultziner and others have argued that we can learn a lot about the life-styles of prehistoric hunter-gatherers from studies of contemporary hunter-gatherers—especially their impressive levels of egalitarianism.\n\nMany hunter-gatherers consciously manipulate the landscape through cutting or burning undesirable plants while encouraging desirable ones, some even going to the extent of slash-and-burn to create habitat for game animals. These activities are on an entirely different scale to those associated with agriculture, but they are nevertheless domestication on some level. Today, almost all hunter-gatherers depend to some extent upon domesticated food sources either produced part-time or traded for products acquired in the wild.\n\nSome agriculturalists also regularly hunt and gather (e.g., farming during the frost-free season and hunting during the winter). Still others in developed countries go hunting, primarily for leisure. In the Brazilian rainforest, those groups that recently did, or even continue to, rely on hunting and gathering techniques seem to have adopted this lifestyle, abandoning most agriculture, as a way to escape colonial control and as a result of the introduction of European diseases reducing their populations to levels where agriculture became difficult.\n\nThere are nevertheless a number of contemporary hunter-gatherer peoples who, after contact with other societies, continue their ways of life with very little external influence or with modifications that perpetuate the viability of hunting and gathering in the 21st century. One such group is the Pila Nguru (Spinifex people) of Western Australia, whose habitat in the Great Victoria Desert has proved unsuitable for European agriculture (and even pastoralism). Another are the Sentinelese of the Andaman Islands in the Indian Ocean, who live on North Sentinel Island and to date have maintained their independent existence, repelling attempts to engage with and contact them. The Savanna Pumé of Venezuela also live in an area that is inhospitable to large scale economic exploitation and maintain their subsistence based on hunting and gathering, as well as incorporating a small amount of manioc horticulture that supplements, but is not replacing, reliance on foraged foods.\n\nEvidence suggests big-game hunter gatherers crossed the Bering Strait from Asia (Eurasia) into North America over a land bridge (Beringia), that existed between 47,000–14,000 years ago. Around 18,500–15,500 years ago, these hunter-gatherers are believed to have followed herds of now-extinct Pleistocene megafauna along ice-free corridors that stretched between the Laurentide and Cordilleran ice sheets. Another route proposed is that, either on foot or using primitive boats, they migrated down the Pacific coast to South America.\n\nHunter-gatherers would eventually flourish all over the Americas, primarily based in the Great Plains of the United States and Canada, with offshoots as far east as the Gaspé Peninsula on the Atlantic coast, and as far south as Chile, Monte Verde. American hunter-gatherers were spread over a wide geographical area, thus there were regional variations in lifestyles. However, all the individual groups shared a common style of stone tool production, making knapping styles and progress identifiable. This early Paleo-Indian period lithic reduction tool adaptations have been found across the Americas, utilized by highly mobile bands consisting of approximately 25 to 50 members of an extended family.\n\nThe Archaic period in the Americas saw a changing environment featuring a warmer more arid climate and the disappearance of the last megafauna. The majority of population groups at this time were still highly mobile hunter-gatherers. Individual groups started to focus on resources available to them locally, however, and thus archaeologists have identified a pattern of increasing regional generalization, as seen with the Southwest, Arctic, Poverty Point, Dalton and Plano traditions. These regional adaptations would become the norm, with reliance less on hunting and gathering, with a more mixed economy of small game, fish, seasonally wild vegetables and harvested plant foods.\n\nContrary to common misconception, hunters and gatherers are mostly well fed, rather than starving.\n\n\n\n\n"}
{"id": "30672962", "url": "https://en.wikipedia.org/wiki?curid=30672962", "title": "IPhone art", "text": "IPhone art\n\niPhone art is a form of Interactive art that takes place on the screen of the iPhone, iPad, or iPod Touch. It is distinct from pictorial works of art produced with an iPhone using paint apps such as Brushes or ArtRage.\n\niPhone Art evolved from screen-based interactive art that formerly appeared on PC computer screens or on wall-mounted displays in galleries and museums. Due to the portability and ease of distribution with the iTunes App Store, these forms of art are currently experiencing a renaissance as interactive works of art from the 1990s and 2000s are adapted to the iPhone and iPad, some even becoming bestsellers in the Entertainment and Music categories where these apps normally appear, since there is currently no Art category in the iTunes App Store.\n\nSome of the first iPhone artists include Miltos Manetas and Memo Atken who created the JacksonPollock app, Theo Watson who created FATTAG, Scott Snibbe who created Gravilux and Bubble Harp, and Golan Levin, creator of Yellowtail.\n\nArtists such as David Hockney, Corliss Blakely and Meri Aaron Walker (iPhoneArtGirl) have held art exhibits with art made exclusively on their iPads. Musician Damon Albarn recorded the entirety of the new Gorillaz album, The Fall, on his iPad with various apps while on his North American tour.\n\niPhone art may pose a threat to traditional gallery distribution of digital art because individual artist can distribute their apps directly to the general public without working through a gallery dealer.\n\n"}
{"id": "17788945", "url": "https://en.wikipedia.org/wiki?curid=17788945", "title": "Ideas y Valores", "text": "Ideas y Valores\n\nIdeas y Valores is an academic journal of philosophy edited and published by the National University of Colombia. It appears three times per year and publishes articles in all areas of philosophy.\n\nThe \"Revista Ideas y Valores\" was founded in 1951 by Cayetano Betancurt, the dean of the School of Philosophy (how it was called at that time) at the National University of Colombia. The journal was initially named \"Ideas\", a title that was meant to evoke Plato and that reflected the speculative orientation that Betancurt wanted to give to the journal. The name was changed for the second issue due to the existence of another journal at the university that had the same name. Publication was interrupted between 1954 and 1962, and between 1972 and 1974.\n\nThe \"Revista Ideas y Valores\" is indexed in Publindex of COLCIENCIAS (Category A2), Philosopher's Index, Ulrich's, The International Philosophical Bibliography, Biblioteca Electrónica Scielo Colombia, DIALNET, Redalyc, Latindex, and the Rèpertoire Bibliographique de la Philosophie.\n\n"}
{"id": "1363068", "url": "https://en.wikipedia.org/wiki?curid=1363068", "title": "Isis Unveiled", "text": "Isis Unveiled\n\nIsis Unveiled: A Master-Key to the Mysteries of Ancient and Modern Science and Theology, published in 1877, is a book of esoteric philosophy and Helena Petrovna Blavatsky's first major work and a key text in her Theosophical movement. \n\nThe work has often been criticized as a plagiarized occult work, with scholars noting how Blavatsky extensively copied from a large number of sources popular among occultists at the time. However, \"Isis Unveiled\" is nevertheless also understood by modern scholars to be a milestone in the history of Western Esotericism.\n\nThe work was originally entitled \"The Veil of Isis\", a title which remains on the heading of each page, but had to be renamed once Blavatsky discovered that this title had already been used for an 1861 Rosicrucian work by W.W. Reade. \"Isis Unveiled\" is divided into two volumes. Volume I, \"The 'Infallibility' of Modern Science\", discusses occult science and the hidden and unknown forces of nature, exploring such subjects as forces, elementals, psychic phenomena, and the Inner and Outer Man. Volume II, \"Theology\", discusses the similarity of Christian scripture to Eastern religions such as Buddhism, Hinduism, the Vedas, and Zoroastrianism. It follows the Renaissance notion of \"prisca theologia\", in that all these religions purportedly descend from a common source; the ancient \"Wisdom-Religion\". Blavatsky writes in the preface that \"Isis Unveiled\" is \"a plea for the recognition of the Hermetic philosophy, the anciently universal Wisdom-Religion, as the only possible key to the Absolute in science and theology.\"\n\n\"Isis Unveiled\" is argued by many modern scholars such as Bruce F. Campbell and Nicholas Goodrick-Clarke to be a milestone in the history of Western Esotericism. Blavatsky gathered a number of themes central to the occult tradition—perennial philosophy, a Neo-Platonic emanationist cosmology, adepts, esoteric Christianity—and reinterpreted them in relation to current developments in science and new knowledge of non-Western faiths. In doing so, \"Isis Unveiled\" reflected many contemporary controversies—such as Darwin's theories on evolution and their impact on religion—and engaged in a discussion that appealed to intelligent individuals interested in religion but alienated from conventional Western forms. Blavatsky's combination of original insights, backed by scholarly and scientific sources, accomplished a major statement of modern occultism's defiance of materialist science.\n\nIn later theosophical works some of the doctrines originally stated in \"Isis Unveiled\" appeared in a significantly altered form, drawing out confusion among readers and even causing some to perceive contradiction. Specifically, the few and—according to many—ambiguous statements on reincarnation as well as the threefold conception of man as body, soul and spirit of \"Isis Unveiled\" stand in contrast to the elaborate and definite conception of reincarnation as well as the sevenfold conception of man in \"The Secret Doctrine\" (1888). Blavatsky later asserted the correctness of her statements on reincarnation and the constitution of man in \"Isis Unveiled\", attributing the resulting confusion and alleged contradictions to the more superficial or simplified conceptions of the ideas in \"Isis Unveiled\" compared to those of later works.\n\nModern Theosophists hold the book as a revealed work dictated to Blavatsky by Theosophy's Masters.\n\nDetractors often accuse the book of extensive unattributed plagiarism, a view first seriously put forth by William Emmette Coleman shortly after publication and still expressed by modern scholars such as Mark Sedgwick. Similarly, Geoffrey Ashe notes that \"Isis Unveiled\" combines \"comparative religion, occultism, pseudoscience, and fantasy in a mélange that shows genuine if superficial research but is not free from unacknowledged borrowing and downright plagiarism.\" Indeed, \"Isis Unveiled\" makes use of a large number of sources popular among occultists at the time, often directly copying significant amounts of text. However, rather than dwelling on the plagiarism, scholars such as Bruce Campbell argue: \"Blavatsky was a person who had an original set of insights but who lacked the literary skills and knowledge of English sufficient to create a work on her own. Relying on written sources and help from friends, she formulated a unique and powerful expression of occult ideas.\" Joscelyn Godwin and K. Paul Johnson note that early scholarship seemed obsessed with the agenda of exposing Helena Blavatsky as a plagiarist and imposter, but such labels do not properly assess the Theosophical Society's place in the cultural, political, religious, and intellectual history of modern times. The work belongs to a broader movement that seeks to integrate the history of the occult sciences and of esoteric movements with more established subdisciplines. Modern copies of \"Isis Unveiled\" are often annotated, fully delineating Blavatsky's sources and influences.\n\nHistorian Ronald H. Fritze considers \"Isis Unveiled\" to be a work of pseudohistory. Likewise, Henry R. Evans, a contemporaneous journalist and magician, described the book as a \"hodge-podge of absurdities, pseudo-science, mythology and folk-lore, arranged in helter-skelter fashion, with an utter disregard of logical sequence.\" One of Blavatsky's original goals in writing \"Isis Unveiled\" and founding the Theosophical Society was to reconcile contemporary advances in science with occultism, and this synthesis was one of the main appeals of Blavatsky's work for individuals interested in religion but alienated from conventional Western forms at the time. Theosophy adopted and addressed many ideas from late nineteenth century science. Some, like Darwin's theory of evolution, have continued to be accepted by the scientific community, while others, like the continent of Lemuria, though based on contemporaneous scientific theories, have long since been rendered obsolete by modern advances. Theosophy and Occultism as a whole gained a level of sophistication through the adoption of religious terms largely absent from the preceding Spiritualism movement. However, as Theosophy continued to grow as a religion, it became stuck with certain scientific ideas even after they had been discarded by the scientific community. The inability to adapt to scientific progress presents a disparity between modern Theosophy and the society's original motivations. K. Paul Johnson also notes that many of the more mythical elements of Blavatsky's works, like her later Masters, rather than being outright inventions, were reformulations of preexisting esoteric ideas and the casting of a large group of individuals—who helped, encouraged, or collaborated with her—under a mythological context; all driven by Blavatsky's search for spiritual truth.\n\nSten Bodvar Liljegren notes that in addition to contemporaneous occult sources and the prevailing orientalism of the period, the novels of Edward Bulwer-Lytton heavily influenced Blavatsky's Theosophical ideas.\n\n\n\n"}
{"id": "18964328", "url": "https://en.wikipedia.org/wiki?curid=18964328", "title": "Jezik", "text": "Jezik\n\nJezik (lit. \"Language\") is a Croatian language literary magazine published in Croatia by the Croatian Philological Society since 1952. Its editors-in-chief have included Ljudevit Jonke and Stjepan Babić.\n\nThe magazine is known for its annual Dr. Ivan Šreter Award for the best neologism.\n\n\n"}
{"id": "4807742", "url": "https://en.wikipedia.org/wiki?curid=4807742", "title": "Legal debate", "text": "Legal debate\n\nA legal debate is a discussion between lawyers, legal academics, jurists, politicians, and others who might have an interest or expertise in the law, about a particular legal issue.\n\nLegal debates can take many forms, and do not necessarily need to be face-to-face debates. Most legal debates take place on paper—judges within a court, for example, might debate each other most effectively when the court publishes a decision. Legal debates include (but are not limited to) the following:\n\n\nDebates in Western societies often follow broad themes, including\n\n\nIn the United States, legal debates over the past decade have concerned the following important topics:\n\n\nIn general, the variety of debates—ranging from basic social policy to grander theory about constitutional design and democratic theory—suggests that legal debates overlap with several other social institutions and expectations.\n\n"}
{"id": "1348555", "url": "https://en.wikipedia.org/wiki?curid=1348555", "title": "Legal origins theory", "text": "Legal origins theory\n\nThe legal origins theory claims that the two main legal traditions or origins, civil law and common law, crucially shape lawmaking and dispute adjudication and have not been reformed after the initial exogenous transplantation by Europeans. Therefore, they affect economic outcomes to date. According to the evidence reported by the initial proponents of such a theory, countries that received civil law would display today less secure investor rights, stricter regulation, and more inefficient governments and courts than those that inherited common law. These differences would reflect both a stronger historical emphasis of common law on private ordering and the higher adaptability of judge-made law. Recent contributions however have criticized the idea that transplanted legal institutions remained intact and have documented that indeed they evolve moved by how each country solves the trade-off between the uncertainty of judge-made law and the bias possibly injected into civil law by inefficient political institutions. Crucially, these latest studies show that considering both the endogeneity between legal traditions and the economy and the evolution of legal systems over time implies that civil law can often economically dominate common law.\n\nWhile English common law originated in thirteenth century England and has then been transplanted through colonization and occupation to England’s ex-colonies (United States, Canada, Australia, and several countries in Central America, Africa and Asia), the Scandinavian common law was developed in Denmark and Sweden and the German common law sprang in Germany and Switzerland [Guerriero 2016a, p. 54]. These last four countries then exported their common law model to the respective colonies or to those jurisdictions (China, Greece, Japan, Romania, South Korea, Taiwan, Thailand, and Turkey), which were never colonized but borrowed their initial legal order from the European codes considered most advanced at the time [Guerriero 2016a, p. 54]. Civil law instead has its roots in Roman law, was incorporated by the Napoleonic codes first and then by both the Austrian and Russian Civil codes, and has been then introduced via mainly colonization and occupation into continental Europe, the Near East, Latin America, Africa, and Indochina. Bulgaria, Ethiopia, Iran, and Kazakhstan instead purposely borrowed their initial legal order from either France, Russia, or England [Guerriero 2016a, p. 54].\n\nStructurally, the two legal traditions constitute a well-defined bundle of lawmaking and adjudication institutions and operate in quite different ways [Merryman 1969, p. 52, 123–127; Zweigert and Kötz 1998, p. 272]. While common law entrusts a key role to the precedents selected by appellate judges and allows more procedural discretion to lower adjudicating courts, civil law relies on legal codes designed by political representatives and bright-line adjudication rules.\n\nIn a series of influential papers published between 1997 and 2008 (the first one being La Porta et al. (1997) and the last one being La Porta et al. (2008)), Rafael La Porta, Florencio Lopez-de-Silanes, Andrei Shleifer, and Robert Vishny exploited the exogenous assignment of these very different institutions and assumed that they have not been reformed later on to provide evidence consistent with the idea that common law is correlated with\"(a) better investor protection, which in turn is associated with improved financial development […], (b) lighter government ownership and regulation, which are in turn associated with less corruption, better functioning labor markets, and smaller unofficial economies, and (c) less formalized and more independent judicial systems, which are in turn associated with more secure property rights and better contract enforcement \" [La Porta et al. 2008, p. 298]. Operationally, the \"legal origins\" scholars assigned the majority of countries in the world to either the English-common law, the French-civil law, or one among the German, Scandinavian, and Socialist legal traditions and then they calculated correlations between these legal origins dummies and proxies for the aforementioned economic outcomes.\n\nTwo are the justifications given by the \"legal origins\" scholars for the alleged superiority of common law. First, historical events in England and in France built into the common law a stronger emphasis on the independence of the judiciary, private ordering, and human capital. Second, judge-made law would make common law more adaptable to the contracting needs of the economy.\n\nEdward Glaeser and Andrei Shleifer contend that the development of a system of adjudication by lay juries in England and one of adjudication by professional judges in France were conscious choices reflecting the different political power of the English and French barons during the 12th century (Glaeser and Shleifer, 2002). \"The former were concerned about the powerful English king’s ability to interfere in adjudication and bargained for trial by local, lay juries, a right enshrined in Magna Carta. The relatively weak French crown, by contrast, was less a threat than other barons. French barons accordingly desired a centralized adjudication system controlled by royal judges who would not be easily captured by local interests\" [Klerman and Mahoney 2007, p. 279].Napoleon’s attempt to turn through its codes the judiciary into bureaucrats controlled by the State and the post-1688 Glorious Revolution success of the English judiciary in establishing its independence should have reinforced these dissimilarities, instilling at the same time into the common law a stronger emphasis on judicial independence and on private ordering. This divergence would imply that common law will always shore up markets and the civil law will always restrict markets or replace them with state command. This analysis of the medieval European history has been however criticized by Daniel Klerman and Paul Mahoney, who conclude that a system of adjudication by lay juries was initially favored in England because of the low literacy levels and later enforced to place the judicial power in the hands of the crown (Klerman and Mahoney, 2007). Moreover, during the Middle Ages, not only did both French and English judiciaries have the \"de facto\" power to make law through precedent, but French judges enjoyed a greater independence being their office a heritable property. Hence, the only permanent divergence between the legal orders in England and in France originated from the different fortunes of the judiciary in the aftermath of their respective revolutions.\n\nThe key institution differentiating the two legal traditions is the lawmaking institution, which determines the identity of the lawmaker. As aforementioned, common law relies on case law, i.e., the convention that precedents set by appellate courts guide subsequent adjudication by courts of the same or lower standing and can be changed by appellate judges only with a costly justification effort. Civil law instead is grounded on statute law, i.e., which is the act of legislation by political representatives. \"Legal origins\" scholars identify three main advantages of judge-made compared with statute law: (1) since overruling is costly, precedents tend to include both the deciding appellate judge’s opinion and those of the preceding appellate judges in such a way that the long-run law optimally incorporates the different opinions of all appellate judges, whereas statute law can be permanently biased by special interests (Gennaioli and Shleifer, 2007); (2) appellate judges can effectively introduce new information into the law by distinguishing the precedent (Gennaioli and Shleifer, 2007); (3) since inefficient rules tend to be appealed more often, they should be evaluated more often by appellate judges than by politicians (Miceli, 2009).\n\nRecent contributions, however, have criticized the ideas that transplanted legal traditions remained intact and can be measured through legal origins dummies. Inspired by these studies, Carmine Guerriero documents that in a cross-section of 155 transplants, which are countries that received their legal tradition externally, 25 reformed the initial lawmaking institution and 95 reformed at least one among their transplanted lawmaking and adjudication institutions. In particular, in countries that inherited statute law, reforms towards case law have been more likely the largest preference, and in particular both ethnic and genetic, diversity is and reforms towards a pure common law tradition, which is the mix of case law and some discretion in adjudication, are found where the quality of political institutions is the lowest (Guerriero, 2016a). Symmetrically, in countries in which case law was transplanted, reforms towards a pure civil law tradition, which is the mix of statute law and bright-line adjudication rules, are found where the quality of political institutions is the highest (Guerriero, 2016a).\n\nThis evidence is consistent with the idea that appellate judges' offsetting biases make common law unbiased but volatile and thus more efficient than the certain civil law only when the latter is sufficiently distorted by the lobbying activities of special interests, i.e., when preferences are sufficiently heterogeneous and/or the political process sufficiently inefficient (Guerriero, 2016a). These results cast several doubts on the putative primacy of common law and suggest that comparative law and economics should not only take into account the evolving nature of legal traditions and their endogeneity to preference diversity and the quality of political institutions, but also the nature of the performance of interest. Guerriero (2016b) shows that properly considering these points delivers conclusions very different from those drawn by La Porta et al. (2008).\n\nTo illustrate, if preference heterogeneity is limited, civil law is more technologically efficient being unbiased as common law but also certain. If preferences are sufficiently diverse instead, the distance between the biased civil law and the technologically efficient legal rule, which is the social optimal rule that will prevail in a perfectly homogenous society, becomes wider the higher preference heterogeneity is and the lower the quality of the political process is. Thus, civil law loses its technological primacy when preferences are sufficiently diverse and/or the political institutions are sufficiently inefficient (Guerriero, 2016b). Consistent with this prediction, a proxy for preference and, in particular, genetic diversity interacted with a measure of the degree to which the transplant legal system in 2000 was nearer to a perfect common law tradition has a positive and significant impact on the stock market development, the extent of private credit, and the employment level. The estimates also imply that reforms towards a pure common law tradition in developing transplants with smaller than average preference heterogeneity will significantly brake stock market development and the extent of private credit, whereas reforms towards a pure common law tradition in developing transplants with larger than average preference heterogeneity will significantly foster stock market development. Finally, the two legal traditions fare equally well when compared with self-reported managers’ beliefs on how much the legal system is able to hit its efficiency targets and their satisfaction with the law. This last patterns squares with the idea that legal traditions have a tendency towards optimality and so should not differ when compared through a proxy for social welfare. \"This evidence delivers conclusions quite different from those drawn by the legal origins project and raises several concerns for the recent waves of reforms that, inspired by the legal origins literature, have introduced in developing countries institutions typical of a pure common law legal tradition (World Bank, 2004). This is particularly worrisome nowadays given the increasing demand for regulation created by the recent global economic crisis\" [Guerriero 2016, p. 16].\n\n"}
{"id": "33320946", "url": "https://en.wikipedia.org/wiki?curid=33320946", "title": "Linguistic profiling", "text": "Linguistic profiling\n\nLinguistic profiling is the practice of identifying the social characteristics of an individual based on auditory cues, in particular dialect and accent. The theory was first developed by Professor John Baugh to explain discriminatory practices in the housing market based on the auditory redlining of prospective clientele by housing administrators. Linguistic profiling extends to issues of legal proceedings, employment opportunities, and education. The theory is frequently described as the auditory equivalent of racial profiling. The bulk of the research and evidence in support of the theory pertain to racial and ethnic distinctions, though its applicability holds within racial or ethnic groups, perceived gender and sexual orientation, and in distinguishing location of geographic origin.\n\nBaugh's theory is distinct from linguistic profiling as defined by Hans van Halteren from the University of Nijmegen in the Netherlands. Van Halteren's theory deals with the categorization of linguistic features for the purposes of author identification and verification from a text, not necessarily specifically addressing the socially defined categories within which they are included.\n\nAn important distinction exists between the many uses of linguistic profiling and the potential for discriminatory treatment. The power to determine origin or racial identity based on speech can be utilized without overt discrimination, as argued in several court cases where voice was used in the prosecution of a suspect. The negative effects of linguistic profiling are seen in the practice of denying housing or employment based on stereotypes associated with dialect and/or accent. Further negative practices are associated with education and general treatment of individuals speaking stigmatized dialects. A more positive view of the practice is found in Baugh's description of expressions of ethnic pride. Though average people have been shown to be well equipped in measuring social characteristics by means of speech, the failings of those unfamiliar with a speech community and the capability of manipulation of speech should be taken into account when determining the unbiased use of linguistic profiling.\n\nThe primary research done on linguistic profiling was a result of linguist John Baugh's experience searching for housing as an African American. Baugh found a discrepancy between the proclaimed availability of an apartment in a phone interview, in which he utilized Standard American English, and its apparent unavailability upon a face-to-face meeting with the landlord. The changed conception of the housing administrator between auditory and visual cues pointed to overt discrimination based on race.\n\nBaugh, Purnell, and Idsardi completed a set of four experiments based on the identification of dialects in American English. The resulting findings were as follows:\n\n\nThe first experiment involved a series of telephone surveys in which a single speaker requested housing in the chosen dialects of Chicano English, African American Vernacular English, and Standard American English. Each landlord selected was subject to three requests in these three dialects, and the correlating negative and positive responses to call-back appointments were shown to favor speakers of Standard American English. Their findings for the percent of call-backs for the two cities of Palo Alto and Woodside, which had African American and Hispanic Americans populations less than 5%, were as follows:\nOf the four geographical locations chosen in the study, those with the lowest populations of African Americans and Hispanic Americans were shown to have the greatest bias towards the non-standard dialects.\n\nIn order to determine the ability of people to distinguish dialect, a separate experiment was conducted. Fifty undergraduate students, all Caucasian speakers of Standard American English, were asked to identify the ethnicity behind a recording of the word \"hello\" spoken in either Chicano English, African American Vernacular English, and Standard American English.\n\nRespondents were able to identify the correct dialect more than 70% of the time.\nChicano English was found to be more easily identifiable than African American Vernacular English.\n\nWhile much evidence has been collected describing linguistic profiling between racial groups within a speech community, linguistic profiling also extends to members within a racial or ethnic group. This is evidenced by a study conducted by Jaquelyn Rahman describing the perception of middle class African Americans to African American Vernacular English, or AAVE, and Standard American English. She found that subjects associated AAVE with their heritage, while perceiving African Americans who used Standard English as \"acting white\".\n\nAn intra-racial distinction was researched by Newman and Wu, who conducted a study in which subjects were asked to identify various speakers based on race; the speakers included Latinos, African Americans, Chinese Americans, Korean Americans, and white speakers. Listeners tended to successfully categorize speakers as Latino, African American, white or Asian; often, they could not discern between Chinese American and Korean American English speakers, although phonetic differences exist.\n\nIt has been found that Korean American and Chinese American English speakers tend to have a longer voice onset time (VOT), or the length of time between a plosive and voicing, than other speakers of Standard American English. Furthermore, Korean American speakers tend to have a longer VOT than Chinese American speakers. This distinction is apparent when considering the VOT of the phonemes [p], [k] and [t].\nAnother distinction between Korean American and Chinese American English speakers can be found in the timing of spoken syllables, or rhythm. Chinese American speakers (in particular, males), tended to speak with a more regular timing of syllables than Korean American speakers.\n\nLinguistic profiling also applies to gender and sexual orientation. Munson conducted a study in which naïve listeners were asked to distinguish between heterosexual male and female speakers, and gay male and bisexual or lesbian female speakers. He found that listeners tended to classify male and female speakers by masculinity and femininity, respectively; male speakers were perceived as gay if they sounded less masculine, while female speakers were identified as bisexual or lesbian if they sounded less feminine.\n\nLinguistic features of perceived femininity include the following:\nFemale speakers perceived as bisexual or lesbian exhibited opposite characteristics. Furthermore, speakers who are identified as bisexual or lesbian are not necessarily perceived as masculine.\n\nLinguistic features of perceived masculinity include the following:\nMale speakers perceived as gay, tended to exhibit opposite characteristics.\n\nIn addition, male speakers who were perceived as gay exhibited greater breathiness and hyperarticulation of stressed syllables than male speakers who were perceived as heterosexual. It is important to note that speakers who are identified as gay are not necessarily perceived as feminine.\n\nLinguistic profiling occurs beyond the spheres of race and ethnicity in the identification of geographic origin. Indeed, evidence suggests that listeners may successfully categorize speakers based upon dialect. Clopper and Pisoni (2003) found that naïve (or inexperienced) listeners could successfully categorize speakers as hailing from New England, the South, or the West, but had greater difficulty discerning geographic origin when a larger number of dialects were provided: New England, North, North Midland, South Midland, South, West, New York City, or Army Brat. Listeners were only able to identify speakers correctly 30% of the time. They also found evidence suggesting that residential history of the listener affected speaker categorization, and that listeners tended to use a small set of phonetic cues to make these distinctions.\n\nBaker et al. had similar findings in a study in which Utah residents and non-Utah residents were asked to discern the degree of residency of a sample of speakers. Perhaps unsurprisingly, they found that Utah residents and western non-Utah residents tended to correctly identify speakers as being from Utah; the difficulty of other non-Utah residents in identifying Utah speakers was attributed to lack of expertise. However, the western non-Utah residents tended to use more stereotypical phonetic cues to identify speakers than Utah residents. Such findings point to the importance of experience when correctly identifying dialect or region of origin.\n\nSpeakers of Utah English tend to utilize more mergers than speakers of Western American English; this is to say that speakers of Utah English will pronounce certain phonemes, that are distinct in Western American English, the same way. Some examples include \"fail-fell\", \"pool-pull\", \"card-cord\", \"pin-pen\" and \"heel-hill\". Such mergers are used more by older speakers.\n\nA well-known example of the identification of race based on auditory sample in a legal setting occurred during the prosecution of O.J. Simpson. A witness testified against Simpson based on his memory of hearing a \"male Black\" voice. The objection of Simpson’s lawyer, Mr. Cochran, was overruled by the presiding judge.\n\nA major precedent was formed on the use of linguistic profiling in the case of \"Sanchez v. People\". A witness testified against a suspect based on his overhearing of an argument between two apparent Spanish speakers where the killer was identified as having a Dominican rather than a Puerto Rican accent. The New York Superior Court ruled that distinguishing between accents was permissible based on the fact that \"human experience has taught us to discern the variation in the mode of speech of certain individuals.\" The court found that a certain degree of familiarity with the accents and dialects of a region or ethnic group qualified an individual to identify ethnicity or race in a court based on auditory evidence.\n\nA similar justification was used in the later case of \"Clifford v. Kentucky\". A white police officer testified against Charles Clifford, an African American appellant at the Kentucky Supreme Court based on his evaluation of race from spoken language. The presiding Judge cited the findings of \"Sanchez v. People\" in justifying the officer's claim of identifying the suspect based on overheard speech. A similar case is that of \"Clifford v. Commonwealth\", where a testimony of linguistic profiling was allowed based on the caveat that \"the witness is personally familiar with the general characteristics, accents, or speech patterns of the race or nationality in question, i.e. so long as the opinion is 'rationally based on the perception of the witness'\".\n\nLinguist Dennis Preston has presented an expansion of the rulings set down on the use of linguistic profiling in legal contexts. Preston argues for the further definition of \"personal familiarity\" with a dialect to an individual as a member of the speech community within which the identification is taking place. The person identified must be an authentic speaker with no perceived imitation of other dialects within the language. Further, there should be no evidence of overt stereotypes connecting the speaker to a particular style of language.\n\nLinguistic profiling is very apparent in employment, as evidenced by the Supreme Court case \"United States v. Ferril\". Shirley Ferril, a former employee of the telemarketing firm TPG, filed suit against the firm after being fired on the basis of her race. Ferril was hired by TPG, a firm that generates 60% of its revenue from providing pre-election \"get-out-the-vote\" phone calls to prospective voters, for the November 1994 election. She was subsequently fired after the election was over. The particular controversy about the case was TPG’s practice of matching callers to voters based upon race; with the rationale that voters would respond best when the caller was perceived to be a member of their own racial group. This was done with the particular belief that white voters would respond negatively to black callers. Indeed, African American employees would be given a \"black\" script to read to voters, while white employees read off of a \"white script.\" Ferril, an African American, primarily called African American voters. Though the suit clearly displayed the fact that Ferril's work was based primarily on her race, the court allowed TPG to continue to assign callers to voters based upon dialect, accent, or speech pattern though acknowledging the practice was engaging in racial stereotypes.\n\nThere is also evidence of a relationship between wages and perceived race. Jeffrey Grogger conducted a study in which listeners were to categorize English-speakers based upon race; listeners would then give opinions regarding the speakers’ level of education, region of origin, and native language. Listeners could correctly perceive race, but not level of education. Furthermore, there was a correlation between the perceived race of the speaker and the speaker’s total earnings: African American workers who could be identified as black in the study based upon speech earned 12% less than African American workers who were not identified as black; those African American workers that could not be identified by phonetic cues earned as much white workers.\n\nLinguistic profiling is also evident in education. Michael Sheperd’s study on teacher's perceptions of student responses compares how favorably teachers from the Los Angeles area viewed a response with the race and gender of the student speaker. Students were grouped based on white or minority and male or female. Teachers of various racial and ethnic backgrounds tended to view responses attributed to white females as being most favorable, followed by white boys, then minority girls. Students who were perceived as minority boys were ranked least favorably. Particularly noteworthy is the fact that Black and Hispanic teachers tended to rank responses given by minority boys, minority girls, and white boys, significantly lower than other teachers. While indicative of on overall stigmatization of boys, the study also provides evidence that the negative associations with minority students (who are identified through linguistic profiling) are held by members of all racial groups.\n\nIn higher education, linguistic profiling has been found to impede student comprehension. In a 1992 study, D. Rubin found that undergraduate university students would comprehend material more poorly if they heard a non-accented lecture presented with a picture of an Asian female. When the same non-accented lecture was presented with a European American teaching assistant, students had a greater ability to comprehend the material. This suggests that face identification may be enough to make students believe that language performance will be accented, which corresponded with a belief that comprehension would be reduced.\n\nMuch of the research regarding the effects of linguistic profiling relates to housing. A study at the University of Pennsylvania found that discrepancies existed not only between white speakers of Standard American English and black speakers of African American Vernacular English, but in addition in between females and males and speakers of Black Accented English and African American Vernacular English when applying for housing. African Americans as a whole were also more likely to be told about the problems of creditworthiness when applying for a lease. An explanation offered by the researcher suggests the linkage between low socio-economic backgrounds and African American Vernacular English, while Black Accented English was associated with higher middle class status. Speech closer to the standard form yielded greater acceptance.\n\nThe many instances of discrimination suits have failed to form a major precedent relating to this issue. Examples of individual cases include \"Alexander v. Riga\" involving the refusal of calls to African American applicants in addition to \"United States v. Lorantffy Care Center\" in which African Americans were denied admittance to nursing homes.\n\nThe Fair Housing Act makes explicit the unlawfulness of discrimination against any member of a protected class, including religion, age, disability, gender, and race. Refusal of housing based on the profiling of linguistic traits is clearly illegal, yet evidence must be found that the housing authority in question could indeed effectively determine the race or ethnicity of the applicant. In this way linguistic studies on the ability of lay persons to correctly identify race or ethnic groups based on auditory cues proves helpful to anti-discrimination law.\n\nThis practice occurs in regions outside the United States, as evidenced in a 2009 study done in Athens, Greece. A telephone field experiment showed the increased difficulty for Albanians, in particular female Albanians, in securing housing. This study also showed a tendency for segregation based on discriminatory housing practices.\n"}
{"id": "4847167", "url": "https://en.wikipedia.org/wiki?curid=4847167", "title": "List of unsolved problems in linguistics", "text": "List of unsolved problems in linguistics\n\nThis article discusses currently unsolved problems in linguistics.\n\nSome of the issues below are commonly recognized as unsolved problems; i.e. it is generally agreed that no solution is known. Others may be described as controversies; i.e. although there is no common agreement about the answer, there are established schools of thought that believe they have a correct answer.\n\n\n\n\n\n\n\n\n"}
{"id": "3241128", "url": "https://en.wikipedia.org/wiki?curid=3241128", "title": "Montefiascone", "text": "Montefiascone\n\nMontefiascone is a town and \"comune\" of the province of Viterbo, in Lazio, central Italy. It stands on a hill on the southeast side of Lake Bolsena, about north of Rome.\n\nThe name of the city derives from that of the Falisci (\"Mons Faliscorum\", \"Mountain of the Falisci\"). Later, it was controlled by the Etruscans. It was suggested that Montefiascone occupies the site of the Etruscan Temple called Fanum Voltumnae, at which the representatives of the twelve chief cities of Etruria met in the days of their independence. Under the Empire, the festival was held near Volsinii.\n\nThe first documents mentioning Montefiascone are from 853 CE, when it belonged to the bishop of Tuscania. In 1058 and 1074 the Popes Stephen IX and Gregory VII, respectively, stopped here. In 1093 the fortress was besieged by Emperor Henry IV. The importance of the fortress was confirmed by Emperor Frederick Barbarossa's visit in 1185.\n\nIn the following two centuries, as a Papal possession, Montefiascone lived its period of highest splendour. The Castle was often residence of Popes, and was consequently enlarged and embellished. During Avignon Papacy, it was the main residence of the Papal legate Cardinal Albornoz. In 1463, however, it was already decaying, as in the words of by Pope Pius II. The decline increased after the plague of 1657 and the earthquake of 1697.\n\nIt became part of the new Kingdom of Italy in 1870. It was damaged by two Allied bombings in May 1944.\n\n\n\n<br>\n"}
{"id": "52636031", "url": "https://en.wikipedia.org/wiki?curid=52636031", "title": "Oliver Lepsius", "text": "Oliver Lepsius\n\nOliver Lepsius (born 2 February 1964) is a German professor of jurisprudence at the University of Bayreuth.\n\nHis public profile was raised in 2011 by the scandal involving Germany's Defence Minister, Karl-Theodor zu Guttenberg. It was determined that the youthful minister's doctoral dissertation, awarded in 2007, had been over-dependent on plagiarism. The university revoked the doctorate and the minister resigned. In public interviews Oliver Lepsius, the university's professor of jurisprudence expressed his anger very powerfully over the affair.\n\nOliver Nicolai Lepsius was born in Munich. By the time he completed his school leaving exams (\"Abitur\") he was attending school at Weinheim (near Heidelberg). He then undertook his military service. Moving on, he studied Jurisprudence at Bonn, later switching to Munich which is where he passed the appropriate state professional exams (\"Staatsexamen\") at both levels. It was also at Munich that he received his doctorate in 1993. By this time his education had also included a year at the University of Chicago, from where he was awarded a Master of Laws (LL/B.) degree. It was also from Munich that he received his habilitation (higher academic qualification) for work on property rights in public law.\n\nHabilitation cleared the way for an academic career, and in 2001 he took a position as professor for Public Law at Heidelberg University. In 2002 he accepted a teaching chair in Public and Comparative Law at University of Bayreuth in succession to Peter Häberle. It was Häberle who had supervised zu Guttenberg for the latter's 2007 dissertation, but without at that stage spotting the issues that gave rise to the subsequent revocation of the resulting doctorate.\n\nLepsius' academic work is focused in contemporary German administrative and constitutional law and its historical underpinnings. He is also concerned with the philosophy and comparative study of public law.\n\nOliver Lepsius is married to , who is a professor of international jurisprudence at the Ludwig Maximilian University of Munich. His father was the sociology professor Mario Rainer Lepsius (1920–2014). His mother, Renate Lepsius (born Renate Meyer: 1927–2004), was a journalist, historian and politician (SPD). \n"}
{"id": "46840291", "url": "https://en.wikipedia.org/wiki?curid=46840291", "title": "Petre P. Panaitescu", "text": "Petre P. Panaitescu\n\nPetre P. Panaitescu (March 11, 1900 – November 14, 1967) was a Romanian literary historian. A native of Iași, he spent most of his adult life in the national capital Bucharest, where he rose to become a professor at its main university. As such, he challenged various aspects of the dominant nationalist historiography. However, he also joined the ultra-nationalist Iron Guard, and headed the university during the movement's brief time in power. After the Guard was violently suppressed at the beginning of 1941, he lost his professorial position. When a communist-dominated government entered office in early 1945, he was arrested and imprisoned. Panaitescu was freed by the end of the year, the new authorities finding useful his theories of Slavic influence on Romania's national trajectory. He worked as a researcher in the latter part of his career, retiring in 1965, two years before his death.\n\nBorn in Iași to engineer Panait Panaitescu and his wife Leonia (\"née\" Greceanu), he attended primary school in his native city, followed by high school in Bucharest. He attended the literature and philosophy faculty of the University of Bucharest from 1918 to 1922, and took specialty courses at Jagiellonian University in Kraków from 1923 to 1924. From 1924 to 1926, he was a member of the Romanian school at Fontenay-aux-Roses. His first published work appeared in \"Revista istorică\" in 1917; the article dealt with a court case in the Danubian Principalities. Other magazines to which he contributed include \"Convorbiri Literare\", \"Studii\", \"Arhiva românească\", \"Buletinul Comisiei Istorice a României\", \"Romanoslavica\", \"Studii și cercetări de istorie medie\", \"Revista Fundațiilor Regale\", \"Memoriile Secției Istorice a Academiei\", \"Mélanges de l’École Roumaine en France\" and \"Viața Românească\", as well as Polish and Soviet reviews. His first book, from 1923, was a biographical study of Nicolae Bălcescu.\n\nIn 1925, he earned a doctorate in history; his thesis analyzed the Polish influence on the works and personalities of the chroniclers Grigore Ureche and Miron Costin. Subsequently, he became a professor at his alma mater, and was elected a corresponding member of the Romanian Academy in 1934.\n\nTogether with Gheorghe I. Brătianu and Constantin C. Giurescu, Panaitescu was a member of the \"new school\" of Romanian history that published in \"Revista istorică română\" and defined itself in opposition to Nicolae Iorga and his \"Revista istorică\". He wrote a 1936 study of Michael the Brave that de-emphasized the dominant narrative of Michael as hero, and focused instead on the social class that dictated his actions, namely the \"boyars\". The book drew a harsh review from Iorga, who claimed Panaitescu was bringing Michael down from his pedestal, and even committing lèse-majesté by claiming he was not the son of Pătrașcu the Good.\n\nHe questioned major elements of other Romanian historical myths, prioritizing material, social and cultural structures over the heroic and personalized approach. In a 1944 article, he asserted that the Ottoman Empire failed to directly incorporate the Principalities not because of the struggles of Romanians against the Turks (an important theme in mainstream historiography), but because the Ottomans' thrust into Europe lay along a different path, and they found it more advantageous to exploit the area indirectly. Like Ioan Bogdan, he considered that the Slavs were important in medieval Romanian history, even considering the indigenous boyar class to be of Slav origin; on the other hand, he followed Dimitrie Onciul in downplaying the notion of Daco-Roman continuity. Challenging Alexandru Dimitrie Xenopol's thesis regarding the Byzantine influence on national culture, he asserted that Romanians between the ninth and the eighteenth century had adopted a Slavo-Byzantine culture. For him, far from being a misfortune of history, this development was necessary given the prevailing social, economic and spiritual conditions. It also fostered national cohesion, allowing Romanians in the three historical provinces of Moldavia, Wallachia and Transylvania to resist foreign invasion and denationalization. He added that early Romanians failed to adopt Western culture because its technical and urban nature was alien to them.\n\nDespite his anti-nationalist stance as a historian, Panaitescu belonged to the extreme nationalist Iron Guard for a time. Under the National Legionary State (September 1940-January 1941), he was the University of Bucharest's rector as well as editor of \"Cuvântul\" newspaper, which was replete with historical-mythological constructs. The sole full professor in the literature faculty who belonged to the Guard, he had kept his position and perhaps his life during the National Renaissance Front regime's wave of repression against the movement in 1938-1939 thanks to the intervention of Giurescu, Mihai Ralea and Alexandru Rosetti. Ralea, a close friend of Interior Minister Armand Călinescu, spent more than three hours arguing with Călinescu until the latter removed Panaitescu's name from a list of Guardists to be interned. Many of those interned were subsequently killed. Following the assassination of Iorga in late November 1940, Panaitescu and dean Alexandru Marcu did fly the flag at half-mast, but this was quickly replaced by Guardist students with the movement's green banner.\n\nAs a result of the January 1941 suppression of the Guard, Panaitescu's university career was over, and he was suspended from his department effective March 1. Starting in June 1943, he worked at the Peace Bureau, an office created by Foreign Minister Mihai Antonescu with the scope of formulating Romanian demands at the peace conference that was bound to follow when the ongoing World War II came to an end.\n\nDue to his enthusiasm for the Iron Guard and his articles in \"Cuvântul\", he was arrested in April 1945, under the new Romanian Communist Party-dominated government; following an agreement between former Guard leaders and Soviet agent Alexandru Nicolschi, Panaitescu and those imprisoned alongside him were released that December. Starting in 1946 and through the end of 1948, he was a technical adviser at the Romanian-Russian Museum. Meanwhile, in the summer of 1948, he became section director of the Balkan studies and research institute, which was soon folded into the Academy's history institute, where he remained until his retirement in 1965. Also that summer, he was stripped of his Academy membership.\n\nIt was only in 1954 that he managed to resume work openly as a researcher, at the Nicolae Iorga Institute. For several years prior, he was obliged to write under the pseudonym Al. Grecu. Despite his undesirable past, the regime found him useful as a Slavist who focused on historical ties between Romanians and Russians, or the activities of the peasantry. In his later years, he wrote several weighty volumes about early Romanian history, including a 1958 study of Dimitrie Cantemir's life and work, a 1965 analysis of written Romanian's beginnings and a posthumous 1969 introduction to Romanian cultural history.\n\n"}
{"id": "32773511", "url": "https://en.wikipedia.org/wiki?curid=32773511", "title": "Potomac Palisades Site", "text": "Potomac Palisades Site\n\nThe Potomac Palisades Site is an archaeological site in Washington, D.C., United States. Measuring approximately in area, the site lies near the intersection of MacArthur Boulevard and Foxhall Road, along the Potomac River. It is one of many archaeological sites located in the present-day Potomac Palisades; a 1984 field survey revealed evidence that supported earlier ideas of the archaeological richness of the northern bank of the Potomac in this area.\n\nAmong the artifacts found during excavation at the site is a triangle-shaped projectile point. The primary use of the site appears to have been during the Late Archaic period, during which time it was heavily used as a lithic workshop. In recognition of its archaeological value, the Potomac Palisades Site was listed on the National Register of Historic Places in 1982.\n"}
{"id": "42043290", "url": "https://en.wikipedia.org/wiki?curid=42043290", "title": "Res Publica (journal)", "text": "Res Publica (journal)\n\nRes Publica is a quarterly peer-reviewed academic journal of moral, legal, social, and political philosophy. It was established in 1995 and is published by Springer Science+Business Media. The editors-in-chief are Philip Cook (University of Edinburgh) and Sune Lægaard (Roskilde University). It is the official journal of the Association for Social and Political Philosophy (formerly the Association for Legal and Social Philosophy).\n\nThe journal is abstracted and indexed in Scopus, Academic OneFile, Index to Foreign Legal Periodicals, International Bibliography of Periodical Literature, International Political Science Abstracts, and The Philosopher's Index.\n\n"}
{"id": "4367338", "url": "https://en.wikipedia.org/wiki?curid=4367338", "title": "Review of International Law and Politics", "text": "Review of International Law and Politics\n\nReview of International Law and Politics (Turkish: \"Uluslararası Hukuk ve Politika\") is a quarterly peer-reviewed law journal that was established in 2004. It is published by the International Strategic Research Organization.\n\nThe journal publishes scholarly articles and book reviews in English, German, and Turkish. It focuses on international law and international relations, but also covers area studies (Balkans, Caucasus, Europe, Central Asia, etc.), international security, sociology, and anthropology in general from all over the world. The journal encourages interdisciplinary studies.\n\nThe journal is abstracted and indexed in:\n"}
{"id": "16724318", "url": "https://en.wikipedia.org/wiki?curid=16724318", "title": "Shocking gum", "text": "Shocking gum\n\nShocking gum is a practical joke device that delivers a mild electric shock. The victim is offered a stick of gum from a box, and touching this triggers the shock. A few novelty companies in the 1950s produced these 'Shocking gum' packages. The most popular brands of Shocking Gum are \"Fruit Juicy\" and \"JB\".\n\nIn 2005, the US Military reported that insurgents in Iraq were using shock chewing gum as a form of torture, forcing prisoners to bite down on the sticks.\n\n"}
{"id": "29529070", "url": "https://en.wikipedia.org/wiki?curid=29529070", "title": "Social construction of gender", "text": "Social construction of gender\n\nThe social construction of gender is a notion in feminism and sociology about the operation of gender and gender differences in societies. According to this view, society and culture create gender roles, and these roles are prescribed as ideal or appropriate behavior for a person of that specific sex. \n\nSome supporters of this idea argue that the differences in behavior between men and women are entirely social conventions, whereas others believe that behavior is influenced by universal biological factors to varying degrees, with social conventions having a major effect on gendered behavior.\n\nThe roots of the social constructionist movement in psychology are related to the criticism of the objectivism assumed by positivist/empiricist concepts of knowledge (Gergen, 1985).\nAmong the most popular variations of the social constructionist theories is the gender role theory, considered by Alsop, Fitzsimons and Lennon (2002) as an early form of social constructionism.\nThe focus on power and hierarchy reveals inspiration stemming from a Marxist framework, utilized for instance by materialist feminism, and Foucault's writings on discourse.\nSocial constructionism, briefly, is the concept that there are many things that people \"know\" or take to be \"reality\" that are at least partially, if not completely, socially situated. For example, Harvard psychologist Steven Pinker writes that \"some categories really are social constructions: they exist only because people tacitly agree to act as if they exist. Examples include money, tenure, citizenship, decorations for bravery, and the presidency of the United States.\"\n\nThe basic assumptions of social constructionism, as described by Marecek, Crawford & Popp, are:\n\nAlsop, Fitzsimmons & Lennon also note that the constructionist accounts of gender creation can be divided into two main streams:\n\nThey also argue that both the materialist and discursive theories of social construction of gender can be either essentialist or non-essentialist. This means that some of these theories assume a clear biological division between women and men when considering the social creation of masculinity and femininity, while other contest the assumption of the biological division between the sexes as independent of social construction.\n\nGender, according to West and Zimmerman, is not a personal trait; it is \"an emergent feature of social situations: both as an outcome of and a rationale for various social arrangements, and as a means of legitimating one of the most fundamental divisions of society.\" Historically, the term gender was adopted as means of distinguishing between biological sex and socialized aspects of femininity and masculinity. Moreover, gender was considered achieved and more or less stable after it is acquired in early childhood. Contemporary constructionist perspective, as proposed by Fenstermaker and West, proposes treating gender as an activity (\"doing\") of utilizing normative prescriptions and beliefs about sex categories based on situational variables. These \"gender activities\" constitute our belonging to a sex as based on the socially accepted dichotomy of \"women\" and \"men\". It is noted, however, that these activities are not always perceived (by the audience) as being either \"masculine\" or \"feminine\", they are at constant risk of being assessed as more or less \"womanly\" or \"manly\"; ultimately, any behavior may be judged based upon its \"manly\" or \"womanly\" nature. \"Doing gender\" is in fact based on these interactions that are constituted of ongoing assessments in various situations. This in turn points to the situational nature of gender rather than its inherent, essentialist and individual nature.\n\nGender roles are often centred around the conceptions of femininity or masculinity. In our society today, women are socialized as being the caretakers of the house, who nurture the children, cook and clean. With men, they \"should\" be the workhorse, the provider, protector, a leader, and a teacher to his family.\n\nEmpirical investigations suggest that gender roles are \"social constructs that vary significantly across time, context, and culture\". Ronald F. Levant and Kathleen Alto write: \n\nA study in 2017 found that health risks are set by the behaviors that are instilled in males and females by the time they're 10 or 11.\n\nGender roles, according to Berkowitz, are an acceptance of social construction as it pertains to gender and the roles we perform. \"The gender order is hierarchical in that, overall, men dominate women in terms of power and privilege; yet multiple and conflicting sources of power and oppression are intertwined, and not all men dominate all women. Intersectionality theorizes how gender intersects with race, ethnicity, social class, sexuality, and nation in variegated and situationally contingent ways\".\n\nThe constructionism of gender and stereotyped roles can be examined through a given environment. A certain gendered patriarchy turns abstraction into material reality. This reality is negotiated into each interaction we have. For example, based on a simulation discussed in “Walk Like a Man, Talk Like a Woman”, the simulation used “demonstrates the social constructiveness of gender, maintaining that gender should be conceptualized and portrayed as a process, system of stratification, and social structure”. The perceptions of the social world in which these students view the world around them is as an “objective reality rather than as a product of human interaction and interpretation that is institutionalized and transformed over time”. One of the most powerful notions that this simulation encourages is teaching from a constructionist perspective that requires instructors to “challenge perceptions by requiring students to unpack the “hows and whys” of sociological phenomena”.\n\nLisa M. Diamond argues that gender identity is not a stable, fixed trait – rather, it is socially constructed and may vary over time for an individual. A study by Bandura and Bussey shows that kids want to be like others of their sex. Social conformity has been widely studied on adolescents. Results showed that 6-year-old children tend to conform to choices that their peers find more popular. They begin labeling objects as \"for girls\" or \"for boys\" and conform to what is expected of them. West and Zimmerman argue that the notion of womanhood or femininity is accomplished through an active process of creating gender through interacting with others in a particular social context. Society typically only recognizes two genders. Therefore, when transgender individuals want to have a sex change operation, they must prove that they can \"pass\" as a man or woman – so even the choice of changing one's gender is socially constructed.\n\nIn recent years, elementary schools in the U.S. have started carrying chapter books that include either non-traditional families with same-sex parents, homosexual role models, or (in fewer cases) an adolescent who is dealing with their own sexuality/sexual orientation. Hermann-Wilmarth and Ryan acknowledge this rise in representation, while critiquing the way that the limited selection of books present these characters with an eye towards popularized characterizations of homosexuality. The authors characterize this style of representation as \"Homonormative,\" and in the only example of a book where the protagonist questions their gender identity, it is left ambiguous as to whether or not they are a transman or that they were simply pretending.\n\nDiamond and Butterworth argue that gender identity and sexual identity are fluid and do not always fall into two essentialist categories (man or woman and gay or straight); they came to this conclusion via interviews with sexual minority women over the course of ten years. One woman had a relatively normal early childhood but around adolescence questioned her sexuality and remained stable in her gender and sexual identity until she started working with men and assumed a masculine \"stance\" and started to question her gender identity. When 'she' became a 'he' he began to find men attractive and gradually identified as a homosexual man.\n\nThe perception of sexuality by others is an extension of others' perceptions of one's gender. Heterosexuality is assumed for those individuals who appear to act appropriately masculine or appropriately feminine. If one wants to be perceived as a lesbian, one must first be perceived as a woman; if one wants to be seen as a gay man, one has to be seen as a man.\n\nThe sense of one's gender identity is acquired through the internalization of external knowledge. However, it is in fact never fully acquired – it has to be constantly performed and reenacted in social interactions. According to Alsop, Fitzsimmons & Lennon, \"Gender is part of an identity woven from a complex and specific social whole, and requiring very specific and local readings\". Thus, gender identity can be defined as part of socially situated understanding of gender. LaFrance, Paluck and Brescoll note that as a term, \"gender identity\" allows individuals to express their attitude towards and stance in relation to their current status as either women or men. Turning the scope of gender from a social consensus to objectivity to one's self-identification with a certain gender expression leaves much more space for describing variation among individuals.\n\nThe way gender is constructed for an individual depends on gendered interactions the individual has with others as well as other identities or roles he or she may have. Gender, race, class, and other oppressions are all potential omnirelevant categories, though they are not ALL identically salient in every set of social relationships in which inequality is done. Multiple oppressions are not seen as having \"additive\" or \"multiplicative\" effects but are seen as simultaneously depending on each other to create a unique form of oppression. Although West and Fenstermaker do not elaborate on exactly how intersectionality can be incorporated into social constructionist theory, they do say that intersecting social identities are constant \"interactional accomplishments\".\n\nWhile men and women are held accountable for normative conceptions of gender, this accountability can differ in content based on ethnicity, race, age, class, etc. Hurtado argues that white women and women of color experience gender differently because of their relationship to males of different races and that both groups of women have traditionally been used to substantiate male power in different ways. Some women of color are subordinated through rejection, or denial of the \"patriarchal invitation to privilege\". For instance, some white men may see women of color as workers and objects of sexual aggression; this would allow the men to display power and sexual aggression without the emotional attachment that they have with white women. White women are accountable for their gendered display as traditionally subservient to white men while women of color may be held accountable for their gendered performance as sexual objects and as recalcitrant and bawdy women in relations with white men. West and Fenstermaker conclude that doing gender involves different versions of accountability, depending on women's \"relational position\" to white men.\n\nGender, according to West and Zimmerman, is not simply what one is, but what one does – it is actively produced within social interactions. Gender is an accomplishment : \"the activity of managing situated conduct in light of normative conceptions of attitudes and activities appropriate for one's sex category\". People do not have to be in mixed gender groups or in groups at all for the performance of gender to occur; the production of gender occurs with others and is even performed alone, in the imagined presence of others. \"Doing\" gender is not just about conforming to stereotypical gender roles – it is the active engagement in any behavior that is gendered, or behavior that may be evaluated as gendered.\n\nThe performance of gender varies given the context: time, space, social interaction, etc. The enactment of gender roles is context dependent – roles are \"situated identities\" instead of \"master identities\". The sociology of knowledge must first of all concern itself with what people \"know\" as \"reality\" in their everyday, non- or pre-theoretical lives. In other words, individual perceptions of \"\"knowledge\" or reality...must be the central focus.\"\n\nThese performances normalize the essentialism of sex categories. In other words, by doing gender, we reinforce the essential categories of gender – that there are only two categories that are mutually exclusive. The idea that men and women are essentially different is what makes men and women behave in ways that appear essentially different. Though sex categorization is based on biological sex, it is maintained as a category through socially constructed displays of gender (for example, you could identify a transgender person as female when in fact she is assigned male at birth).\n\nInstitutions also create normative conceptions of gender. In other words, gender is simultaneously created and maintained – \"both a process and a product, medium and outcome of such power relations\". In his examination of blue and white-collar workers, Mumby argued that hegemonic or dominant masculinity provides a standard of acceptable behavior for men, and at the same time, is the product of men's behavior. This can be said for constructions of any identity in certain contexts (e.g. femininity, race, Black femininity, etc.).\n\nPeople hold themselves and each other accountable for their presentations of gender (how they 'measure up'). They are aware that others may evaluate and characterize their behavior. This is an interactional process (not just an individual one). Social constructionism asserts that gender is a category that people evaluate as omnirelevant to social life. Gender as omnirelevant means that people can always be judged by what they do as a man or as a woman. This is the basis for the reasoning that people are always performing gender and that gender is always relevant in social situations.\n\nAccountability can apply to behaviors that do conform to cultural conceptions as well as those behaviors that deviate – it is the \"possibility\" of being held accountable that is important in social constructionism. For example, Stobbe examined the rationale that people gave for why there were small numbers of women in the auto industry. Men cited the idea that such dirty work was unsuitable for women and women were unable to train because of family duties. Stobbe argues that the male workers created a machismo masculinity to distinguish themselves from women who might have been qualified to work in the auto shop. Women who do work in male-dominated professions have to carefully maintain and simultaneously balance their femininity and professional credibility.\n\nEven though gender seems more salient in some situations – for instance, when a woman enters a male-dominated profession – gender categories also become salient in contexts in which gender is less obvious. For instance, gender is maintained before the woman enters the male-dominated group through conceptions of masculinity.\n\nRace, class, and other oppressions can also be omnirelevant categories, though they are not \"all\" identically salient in every set of social relationships in which inequality is done. People have preconceived notions about what particular racial groups look like (although there is no biological component to this categorization). Accountability is interactional because it does not occur solely within the individual. It is also institutional because individuals may be held accountable for their behaviors by institutions or by others in social situations, as a member of any social group (gender, race, class, etc.). This notion of accountability makes gender dynamic because what is considered appropriate behavior for men and women changes and is reproduced over time and is reproduced differently depending on context. Gender is created in different ways among uneducated and educated African Americans.\n\nWest and Zimmerman give this definition for sex in their paper \"Doing Gender\": \"Sex is a determination made through the application of socially agreed upon biological criteria for classifying persons as females and males. The criteria for classification can be genitalia at birth or chromosomal typing before birth, and they do not necessarily agree with one another\". The differentiation between gender and sex did not arise until the late 1970s, when researchers began using \"gender\" and \"sex\" as two separate terms, with \"gender\" referring to one's self-identity and \"sex\" referring to one's chromosomal makeup and sex organs. The binary of male and female leaves out everyone who does not fit into these categories because of genital make up, chromosomes, or hormone levels. Anne Fausto-Sterling addresses the issues facing intersex people in her article \"The Five Sexes\". She claims that there is at minimum five sexes but probably more; this is based on the vast range of ways bodies show up in nature. She points out that, \"recent advances in physiology and surgical technology now enable physicians to catch most intersexuals at birth...infants are entered into a program of hormonal and surgical management...\" This highlights the intense adherence to the binary instead of allowing bodies to present in the world without intervention.\n\nWest and Zimmerman also give a definition for sex category: \"achieved through application of the sex criteria, but in everyday life, categorization is established and sustained by the socially required identificatory displays that proclaim one's membership in one or the other category\". Sex category is applied to a person in everyday life through commonly recognized cues that are not necessarily fulfilling biological criteria of sex.\n\nThe term \"gender performativity\" was first coined in American philosopher and gender theorist Judith Butler's 1990 book \"\". In \"Gender Trouble\", Butler sets out to criticize what she considers to be an outdated perception of gender. This outdated perception, according to Butler, is limiting in that it adheres to the dominant societal constraints that label gender as binary. In scrutinizing gender, Butler introduces a nuanced perception in which she unites the concepts of performativity and gender. In chapter one of the text, Butler introduces the unification of the terms gender and performativity in stating that \"gender proves to be performance—that is, constituting the identity it is purported to be. In this sense, gender is always a doing, though not a doing by a subject who might be said to pre-exist the deed\". In demystifying this concept, Butler sets out to clarify that there is indeed a difference in the terms gender performance and gender performativity. In doing so, Butler states in an interview: \"When we say that gender is performed, we usually mean that we've taken on a role; we're acting in some way…To say that gender is performative is a little different…For something to be performative means that it produces a series of effects. We act and walk and speak and talk that consolidate an impression of being a man or being a woman…we act as if that being of a man or that being of a woman is actually an internal reality or simply something that is true about us. Actually, it is a phenomenon that is being produced all the time and reproduced all the time.\" Thus, Butler perceives gender as being constructed through a set of acts that are said to be in compliance with dominant societal norms. Butler is, however, not stating that gender is a sort of performance in which an individual can terminate the act; instead, what Butler is stating is that this performance is ongoing and out of an individual's control. In fact, rather than an individual producing the performance, the opposite is true. The performance is what produces the individual. Specifically, Butler states that \"there is no 'being' behind doing… 'the doer' is merely a fiction added to the deed – the deed is everything.\" Thus, the emphasis is placed not on the individual producing the deed but on the deed itself. Although a seemingly difficult concept to grasp, gender performativity is realized throughout many aspects of our lives, specifically in our infancy and young childhood, our teen years, and finally our adult lives.\n\nOn Butler's hypothesis, the socially constructed aspect of gender performativity is perhaps most obvious in drag performance, which offers a rudimentary understanding of gender binaries in its emphasis on gender performance. Butler understands drag cannot be regarded as an example of subjective or singular identity, where \"there is a 'one' who is prior to gender, a one who goes to the wardrobe of gender decides with deliberation which gender it will be today\". Consequently, drag should not be considered the honest expression of its performer's intent. Rather, Butler suggests that what is performed \"can only be understood through reference to what is barred from the signifier within the domain of corporeal legibility\".\n\nAmelia Jones proposes that this mode of viewing gender offered a way to move beyond the theories of the gaze and sexual fetishism, which had attained much prominence in academic feminism, but which by the 1980s Jones viewed as outdated methods of understanding women's societal status. Jones believes the performative power to act out gender is extremely useful as a framework, offering new ways to consider images as enactments with embodied subjects rather than inanimate objects for men's viewing pleasure.\n\nThe idea around gender performativity, when applied to infancy and young childhood, deals with the idea that from the moment one is conceived, arguably even before that, who they are and who they will become is predetermined. Children learn at a very young age what it means to be a boy or girl in our society. Individuals are either given masculine or feminine names based on their sex, are assigned colors that are deemed appropriate only when utilized by a particular sex and are even given toys that will aid them in recognizing their proper places in society. According to Barbara Kerr and Karen Multon, many parents would be puzzled to know \"the tendency of little children to think that it is their clothing or toys that make them boy or girl\". Parents are going as far as coordinating their daughter with the color pink because it's feminine, or blue for their son because it's masculine. In discussing these points, Penelope Eckert, in her text titled \"Language and Gender\", states: \"the first thing people want to know about a baby is its sex, and social convention provides a myriad of props to reduce the necessity of asking\". Thus, this reinforces the importance and emphasis that society places not only on sex but also on ways in which to point towards one's sex without implicitly doing so. Eckert furthers this in stating that determining sex at one's birth is also vital of how one presents themselves in society at an older age because \"sex determination sets the stage for a lifelong process of gendering\". Eckert's statement points to Judith Butler's view of gender as being performative. Similar to Butler, Eckert is hinting to the fact that gender is not an internal reality that cannot be changed. What Eckert is instead stating is that this is a common misconception that a majority of the population unknowingly reinforces, which sees its emergence during infancy.\n\nButler suggests in both \"Critically Queer\" and \"Melancholy Gender\", that the child/subject's ability to grieve the loss of the same-sex parent as a viable love object is barred. Following from Sigmund Freud's notion of melancholia, such a repudiation results in a heightened identification with the Other that cannot be loved, resulting in gender performances which create allegories of, and internalize the lost love that the subject is subsequently unable to acknowledge or grieve. Butler explains that \"a masculine gender is formed from the refusal to grieve the masculine as a possibility of love; a feminine gender is formed (taken on, assumed) through the fantasy which the feminine is excluded as a possible object of love, an exclusion never grieved, but 'preserved' through the heightening of feminine identification itself\".\n\nOne's teen years are the prime time in which socialization occurs as well as the time in which how one presents themselves in society is of high concern. Often, this is the time in which one's ability to master their gender performance labels them as successful, and thus normal, or unsuccessful, and thus strange and unfitting. One of the sources that demonstrate how successful performance is acted out is magazines, specifically magazines targeting young girls. According to Eckert, \"When we are teenagers, the teen magazines told girls how to make conversation with boys…\". This not only emphasizes the fact that gender is something that is taught to us and is continuously being shaped by society's expectations, but it also points to one of the ways in which individuals are being subconsciously trained to be ideal participants in the gender binary. Thus calling back to Butler's perception that gender is not a fact about us but is something that is taught to us and is being constantly reinforced. This idea that gender is constantly shaped by expectations is relevant in the online community. Teenagers are easily able to formulate relationships and friendships online, thus increasing the probability of a teenager's delicate identity to be manipulated and distorted. Teenagers often come across situations in real life and online that cause them to question themselves when facing society, including gender performance. \n\nThe Butlerian model presents a queer perspective on gender performance and explores the possible intersection between socially constructed gender roles and compulsory heterosexuality. This model diverges from the hegemonic analytical framework of gender that many claim as heteronormative, contending with the ways in which queer actors problematize the traditional construction of gender. Butler adapts the psychoanalytical term of melancholia to conceptualize homoerotic subtext as it exists in western literature and especially the relationship between women writers, their gender, and their sexuality. Melancholia deals with mourning, but for homosexual couples it is not just mourning the death of the relationship, instead it is the societal disavowal of the relationship itself and the ability to mourn, thus leading to repression of these feelings. This idea is reflected in the activism of organized by political groups such as ACT UP during the AIDS crisis. Many of the survivors that participated in this activism were homosexuals whom has lost their partners to the disease. The survivors commemorated the dead by quilting together their rags, repurposing their possessions, and displaying their own bodies for premature mourning. All of these protests amounted to a message that some part of them will be left in the world after they have expired.\n\nQueer Failure is a concept in queer theory that also calls gender into question, because it examines queer art and the bodies of LGBTQ+ people through the lens of what a parental figure may identify as \"failure\" on the part of their character. Instead of recognizing these instances as moral or psychological failures, this concept frames them as the resultants of a conflict between a person's sexuality and their gender.\n\nButler suggests that \"[t]he critical promise of drag does not have to do with the proliferation of genders…but rather with the exposure of the failure of heterosexual regimes ever fully to legislate or contain their own ideals\", although such remarks fail to indicate how the inadequacies of heterosexual regimes might be explicitly exposed. \n\nAccording to Butler, gender performance is only subversive because it is \"the kind of effect that resists calculation\", which is to say that signification is multiplicitous, that the subject is unable to control it, and so subversion is always occurring and always unpredictable. Moya Lloyd suggests that the political potential of gender performances can be evaluated relative to similar past acts in similar contexts in order to assess their transgressive potential: \"Even if we accept that there are incalculable effects to all (or most) statements or activities, this does not mean that we need to concede that there are no calculable effects.\" Conversely, Rosalyn Diprose lends a hard-line Foucauldian interpretation to her understanding of gender performance's political reach, as one's identity \"is built on the invasion of the self by the gestures of others, who, by referring to other others, are already social beings\". Diprose implies that the individual's will, and the individual performance, is always subject to the dominant discourse of an Other (or Others), so as to restrict the transgressive potential of performance to the inscription of simply another dominant discourse.\n\nMartha Nussbaum criticizes Butler's concepts of gender performativity as a misguided retreat from engaging with real-world concerns:\n\n\"Butler suggests to her readers that this sly send-up of the \"status quo\" is the only script for resistance that life offers [...] Butlerian feminism is in many ways easier than the old feminism. It tells scores of talented young women that they need not work on changing the law, or feeding the hungry, or assailing power through theory harnessed to material politics. They can do politics in safety of their campuses, remaining on the symbolic level, making subversive gestures at power through speech and gesture. This, the theory says, is pretty much all that is available to us anyway, by way of political action, and isn't it exciting and sexy?\"\n\nGender features strongly in most societies and is a significant aspect of self-definition for most people. One way to analyze the social influences that affect the development of gender is through the perspective of the social cognitive theory. According to Kay Bussey, social cognitive theory describes \"how gender conceptions are developed and transformed across the life span\". The social cognitive theory views gender roles as socially constructed ideas that are obtained over one's entire lifetime. These gender roles are \"repeatedly reinforced through socialization\". Hackman verifies that these gender roles are instilled in us from \"the moment we are born\". For the individual, gender construction starts with assignments to a sex category on the basis of biological genitalia at birth. Following this sexual assignment, parents begin to influence gender identity by dressing children in ways that clearly display this biological category. Therefore, biological sex becomes associated with a gender through naming, dress, and the use of other gender markers. Gender development continues to be affected by the outlooks of others, education institutions, parenting, media, etc. These variations of social interactions force individuals to \"learn what is expected, see what is expected, act and react in expected ways, and thus simultaneously construct and maintain the gender order\".\n\nIn high schools, gender-based harassment serves as a form of gender boundary policing. Girls are expected to conform to stereotypical gendered appearances, as are boys. Both male and female students regularly take part in policing gender boundaries through bullying. Male students frequently harass male and female students, while female students generally only harass other female students. The practice of male students bullying other male students is explicitly linked to machismo that boys are expected to subscribe to in order to be constructed and related to as 'normal' boys. Many girls report that boys tease and ridicule them on the basis of their appearance, which is linked to boys asserting masculine power through sexist practices of denigrating girls. This also serves to perpetuate the idea that appearance is a female's most important asset. The way in which girls harass other girls is through gossiping, instead of confronting the other girls directly. Unique appearances and attempts to stand out among girls are regarded very negatively. This type of female on female bullying sets the standard for appearance norms and the importance of appearance for females. Overall, gender-based harassment serves to define and enforce gender boundaries of high school students by high school students.\n\nGender is a cultural construction which creates an environment where an adolescent's performance in high school is related to their life goals and expectations. Because some young women believe that they want to be mothers and wives, the choice of professions and future goals can be inherently flawed by the gender constraints. Because a girl may want to be a mother later, her academics in high school can create clear gender differences because \"higher occupational expectations, educational expectations, and academic grades were more strongly associated with the expected age of parenthood for girls than for boys\". With \"young women recognizing potential conflicts between the demands of work and family\", they will not try as hard in high school allowing males to achieve higher academic achievement then girls. Crocket and Beal in their article \"The Life Course in the Making: Gender and the Development of Adolescents\", \"gender differences in the anticipated timing of future role transitions, the impact of expectations and values on these expected timings, and the extent to which expectations foreshadow actual behavior\". The actions of a youth in high school greatly impact the choices the individual will have over a lifetime. Women especially are constrained in the way they view their adulthood even at a young age because of motherhood.\n\nMales can also be subject to gender construction due to social expectations of masculinity. According to Jack Halberstam (under the name Judith), people correlate masculinity with \"maleness and to power to domination”, something that he believes is a result of patriarchy. In a 2015 study published in the \"American Journal of Public Health\", researchers stated that gender construct can differ depending on the man's race or ethnicity and stated that for white men there was an emphasis on \"education,employment, and socioeconomic status\" whereas the expectations for black men focused on \"sexual prowess, physical dominance, and gamesmanship”. These expectations can make it harder for males to display emotions without receiving criticism and being seen as less of a man.\n\nAdolescents view on adulthood is also determined by their employment in high school. Many boys work during high school and \"unlike young women, young men who had not worked during high school did not quite match their peers\". Because many other boys are working, those who don't work may not be as successful after graduation. In the book \"Working and Growing Up in America\", Jeylan T. Mortimer explains \"youth who work during high school, and those who devote more hours to work, are more vocationally successful after leaving high school\". This creates a distinct gender difference in which men are more likely to be employed after high school than women if they have worked during high school. This means women may be at an academic advantage if they do not work in high school and focus on school work.\n\nHigh school continues to become a more high-pressure environment with academic and social triggers increasing the expectations of adolescents. High school is a large transitional period for teenagers causing them to \"cope with these various transitions in different ways; some negotiate the passages easily whereas others develop serious behavioral and psychological problems\". One of these psychological problems is depression. While the environment of high school can be stressful biological functions also play a large role is psychological well-being. Negriff and Susman explain in their article \"Pubertal Timing, Depression, and Externalizing Problems\" that \"the same hormones that increase during puberty are also related to depression and aggressive tendencies. Higher levels of testosterone are associated with increased aggression in boys and girls, whereas higher estrogen for girls is associated with increased depressive symptoms\". The gender differences observed may not just be due to the cultural expectations, but rather a biological function of the sex the individuals are born with. Self-esteem has also been linked to depression in high school students. One study done by James Battle in 1980 took 26 student ages 15–18 showed a correlation between depression and self-esteem. In the 80s, research had not looked past adults and Battle's research was some of the first of its kind which showed a direct correlation between self-esteem and depression. Self-esteem is not a product of our biology but rather is culturally constructed. Girls in high school also tend to have lower self-esteem due to body image. With depression and self-esteem being so closely linked the potential for having the disease can result in an educational experience which can be compromised. Depression can be isolating, and without proper academics and societal support, high school can be challenging. Along with higher rates of self-esteem issues in adolescents, this can adversely affect girls' academics and social life in high school.\n\nHigh school is a major transitional period for girls and boys as their bodies transition into men and women. The end of high school is usually marked by the 18th birthday, a major milestone in an individual's life. Boys and girls go through this transformation within high school where each gender faces body satisfaction differently. There are many different factors that affect body image, \"including sex, media, parental relationship, and puberty as well as weight and popularity\". The intersectionality of these factors causes unique experiences for adolescents during this period within their lives. As their body changes, so does the environment in which they live in. Body image is closely linked to psychological well-being during adolescence and can cause harmful effects when a child has body dissatisfaction. Helen Winfield in her article \"Body Image and Psychological Well-Being in Adolescents: The Relationship between Gender and School Type\" explains an adolescences high school experience is closely linked to their perceived body image. She analyzed over 336 teenagers and found \"ratings of physical attractiveness and body image remain relatively stable across the early teenage years, but become increasingly negative around age 15–18 years because of pubertal changes\". This shift during the high school years can cause serious psychological problems for adolescence. These psychological problems can manifest as bulimia and anorexia causing serious lifelong problems. These body image issues are especially prevalent in girls but as boys enter puberty expectations of height and muscle mass change as well. Geoffrey H. Cohane, Harrison G. Pope Jr. in their article \"Body image in boys: A review of the literature\" argue \"girls typically wanted to be thinner, boys frequently wanted to be bigger\". This, they argue, shows the gender difference in body image cause different beauty ideals. An adolescent's gender affects their body image and their high school experience.\n\nDue to the amount of time that children spend in school, \"teachers are influential role models for many aspects of children's educational experiences, including gender socialization\". Teachers who endorse the culturally dominant gender-role stereotype regarding the distribution of talent between males and females distort their perception of their students' mathematical abilities and effort resources in mathematics, in a manner that is consistent with their gender-role stereotype and to a greater extent than teachers who do not endorse the stereotype.\n\nAccording to the 1994 report \"\" by the American Psychological Association, \"[m]ost standard tests of intelligence have been constructed so that there are no overall score differences between females and males.\" Differences have been found, however, in specific areas such as mathematics and verbal measures. Even within mathematics, it is noted that significant differences in performance as a result of gender do not occur until late in high school, a result of biological differences, the exhibition of stereotypes by teachers, and the difference in chosen coursework between individual students. While, on average, boys and girls perform similarly in math, boys are over represented among the very best performers as well as the very worst. Teachers have found that when certain types of teaching (such as experiments that reflect daily life), work for girls, they generally work for boys as well.\n\nAlthough little difference in mathematics performance was found among younger students, a study of students grade 1-3 by Fennema et al. noted that significant differences in problem-solving strategies were found, with girls tending to use more standard algorithms than the boys. They suggest that this may be due to both the teachers' stereotypical beliefs about mathematics and gender, as well as the study's design permitting \"the children's stereotypical beliefs to influence strategy use and thus the development of understanding in these classrooms\". A study conducted at Illinois State University examined the effects of gender stereotypes on the teaching practices of three third grade teachers, noting that \"[the teachers] claimed gender neutrality, yet they expressed numerous beliefs about gender difference during the study\", such as allowing boys (but not girls) to respond to questions without raising their hand or providing reading selections that promoted women in non-traditional roles, but not doing the same for men.\n\nOverall, differences in student performance that arise from gender tend to be smaller than that of other demographic differences, such as race or socioeconomic class. The results of the 1992 NAEP 12th grade science tests, on a 500-point scale, show that the differences of scores between white and African American students were around 48 points, while differences between male and female students were around 11 points.\n\nSocial gender construction (specifically for younger audiences) is also influenced by media. In the 21st century, modern technology is abundant in developed countries. In 2018, roughly 42% of tweens and teens experience feelings of anxiety when not near their phones. There is a growing amount of teens that spend an average of 6.5 hours on media daily. This data reflects how much of a teenager's personality is dependent on media. Media influencing gender construction can be seen in advertising, social networking, magazines, television, music, and music videos. \n\nThese platforms can affect how a developing human views themselves and those around them. There is both positive and negative media and each type can be perceived differently. Media will often portray men and women in a stereotypical manner, reflecting their \"ideal image\" for society. These images often act as an extreme expectation for many developing teenagers.\n\nMen are typically portrayed as assertive, powerful, and strong. Particularly in television, men are usually shown as being nonemotional and detached. Women are often portrayed as the opposite. Gender roles are generally more enforced for women in media than they are for men. Women are typically represented as the backbone of the household, the caretaker, and often even as stay at home mothers. Females in media are often given weak, dependent, and passive personalities. Media presence often perpetuates that men are not allowed to be caring and that women are not allowed to be strong and demanding. These gender influences from the media can mislead a growing child or teenager because while they are still trying to construct their identities and genders in a social environment, they are surrounded by biased influences.\n\nAnatomical studies have shown that the larynx of a child, and by extension the fundamental frequency, is likely to vary directly as a result of size and height, rather than sex. Sachs et al. suggest that if there is no difference between the size of the articulatory mechanism in children, differences in formant production between boys and girls may be a result of \"culturally determined patterns that are viewed as appropriate for each sex\" and a result of the speaker's deliberate phonetic variation in vowel production or changing the configuration of the lips.\n\nInclusiveness and acceptance play significant roles in social constructionist practice – examples include sharing work with others in a cooperative manner, including a diverse sample, being open to other interpretations of data, and blurring the lines between scientific research, participatory research and social activism. The blurring of scientific research also means incorporating other disciplines into psychological work (e.g. performative psychology includes artistic expression or humor) and thinking in terms that go beyond traditional scientific language. These methods are not currently valued in psychology because they are not seen as \"scientific.\"\n\nA social constructionist psychologist can make it explicit that his or her perspective is not universally true in all contexts across historical periods. Social constructionists recognize that every researcher has an opinion and is biased in some way. They acknowledge that their own views and findings/results of a study are open to deconstructive critique – no grand truth can be found because everything is context-specific and has potential to change across time periods and different situations. Related to this is the idea that social constructionists must constantly question their own work because their work can be constantly reinterpreted and have different meanings at different times.\n\nThe gender dichotomy is so ingrained that it is impossible for research findings to remain unaffected by it. People are often convinced that there are inherent differences between men and women, which skews both studies and their findings. That is, research questions are framed in ways that look for a difference between genders, and thus their methods will be constrained by this framework as well. Moreover, the actual outcome of the study, even if the claims are dubious or modest at best, often come to be accepted as facts if they support the gender discourse narrative and are often cited and discussed. This phenomenon is labeled the \"hall of mirrors\" effect.\n\nIn order to fully and accurately record the socialization processes at play regarding gender construction, ethnographic and longitudinal studies are ideal. However, these methods have their constraints. It is costly and time consuming to carry out such studies that would yield significant results, and there is an abundance of factors that influence an individual's gender construction. Thus, more research is needed regarding the social construction of gender.\n\nResearch can either be qualitative or quantitative. Qualitative data is beneficial because it can give a voice to the subjects of the study. However, poorly-constructed qualitative research can lead to reproduction of race and class biases if findings are inappropriately generalized. For example, qualitative research methods often involve small, homogeneous samples. Therefore, it would be inappropriate to generalize the findings of a study conducted on a specific group of people and then apply them to all people of that gender.\n\nQuantitative data is useful when hard data is needed, such as addressing policy issues, when hard data is needed to convince people unfamiliar with the topics. However, quantitative research can reinforce gender and cultural assumptions as well through item construction. That is, for data to be quantitatively analysed, they must fit into specific categories. However, such categories can be based on or at least influenced by gender stereotypes.\n\nGender often means adhering to gender normative behavior and roles. The performance of gender reinforces the essentialism of gender categories. Essentialism argues that there are essential differences between genders which manifest themselves in differences in gender performance. Gender performance consists of a stylized practice involving gestures, language, and speech and serves to form and build an identity. When an individual performs their gender to the standards set by societal norms, this bolsters the argument of gender essentialism. Historically, men have assumed a dominant gender role, and women have been prescribed a role submissive to men. In order for subordination to go unquestioned, the structure must not appear as a cultural product – it must seem natural. Social movements can challenge the categories that appear \"natural.\" Certain legislation can promote equality for men and women, which could call into question whether there needs to be two categories of gender at all (if both are treated equally). Social change relies on an understanding of how inequality is rooted in gender accomplishment.\n\nThroughout history, women have fought for their rights regarding various issues. One of the most significant revolutions of this century is the feminist movement. The first wave, which began in 1854, was a fight for women's rights to education and to the vote by the suffragettes. This movement was then followed by Second-wave feminism and Third-wave feminism which furthered the feminist cause. The feminist movement was not only about fighting for women's rights, but more essentially about earning recognition and respect from the general public acknowledging the fact that they are not inferior than men and thus deserving to be treated equally and granted fair opportunities. Feminism emerged and started to challenge the idea that a woman's appropriate place was confined to that of the domestic and private sphere. Over time, men and women's attitudes have been becoming more liberalized with regard to gender roles. Men and women are agreeing on a more egalitarian responsibility distribution within the family sphere. They are also in agreement that women should and can have roles in the public sphere, especially in leadership positions and that men can have and involved role in the private and domestic sphere. These markers of increasingly liberalized attitudes toward gender roles indicate the trajectory of social change in terms of what is deemed normative.\n\nBecause the theory says that one can \"do\" gender whether they conform to gender norms or not (and is always held accountable for behaving in accordance with gender norms), change seems impossible. If essential differences between the sexes are problematic, a society where gender is omnirelevant could be argued to always uphold gender inequality. The language of \"doing\" gender implies doing difference instead of unraveling it. Most studies that rely on social constructionism explore the ways in which gender is constructed but nevertheless demonstrate how those gender constructions uphold gender as a construct and gender inequality.\n\nHowever, because gender is \"done\" or constructed, it can also be \"undone\" or deconstructed. The study of the interactional level could expand beyond simply documenting the persistence of inequality to examine: (1) when and how social interactions become less gendered, not just differently gendered, (2) the conditions under which gender is irrelevant in social interactions, (3) whether all gendered interactions reinforce inequality, (4) how the structural (institutional) and interactional levels might work together to produce change, and (5) interaction as the site of change.\n\nTheories that imply that gendered behavior is totally or mostly due to social conventions and culture fall into the nurture end of the nature versus nurture debate. Much empirical research has been done on to what extent gendered behavior stems from biological factors.\n"}
{"id": "26954", "url": "https://en.wikipedia.org/wiki?curid=26954", "title": "Stephen King", "text": "Stephen King\n\nStephen Edwin King (born September 21, 1947) is an American author of horror, supernatural fiction, suspense, science fiction and fantasy. His books have sold more than 350 million copies, many of which have been adapted into feature films, miniseries, television series, and comic books. King has published 58 novels, including seven under the pen name Richard Bachman, and six non-fiction books. He has written around 200 short stories, most of which have been published in book collections.\n\nKing has received Bram Stoker Awards, World Fantasy Awards, and British Fantasy Society Awards. In 2003, the National Book Foundation awarded him the Medal for Distinguished Contribution to American Letters. He has also received awards for his contribution to literature for his entire \"oeuvre\", such as the World Fantasy Award for Life Achievement (2004), and the Grand Master Award from the Mystery Writers of America (2007). In 2015, King was awarded with a National Medal of Arts from the United States National Endowment for the Arts for his contributions to literature. He has been described as the \"King of Horror\".\n\nKing was born September 21, 1947, in Portland, Maine. His father, Donald Edwin King, was a merchant seaman. Donald was born under the surname Pollock, but as an adult, used the surname King. King's mother was Nellie Ruth (née Pillsbury).\n\nWhen Stephen King was two years old, his father left the family under the pretense of \"going to buy a pack of cigarettes,\" leaving his mother to raise Stephen and his older brother, David, by herself, sometimes under great financial strain. The family moved to De Pere, Wisconsin, Fort Wayne, Indiana, and Stratford, Connecticut. When King was 11, his family returned to Durham, Maine, where his mother cared for her parents until their deaths. She then became a caregiver in a local residential facility for the mentally challenged. King was raised Methodist but lost his belief in organised religion while in high school. While no longer religious, King chooses to believe in the existence of a God.\n\nAs a child, King apparently witnessed one of his friends being struck and killed by a train, though he has no memory of the event. His family told him that after leaving home to play with the boy, King returned, speechless and seemingly in shock. Only later did the family learn of the friend's death. Some commentators have suggested that this event may have psychologically inspired some of King's darker works, but King makes no mention of it in his memoir \"\" (2000).\n\nKing related in detail his primary inspiration for writing horror fiction in his non-fiction \"Danse Macabre\" (1981), in a chapter titled \"An Annoying Autobiographical Pause.\" King compares his uncle's dowsing for water using the bough of an apple branch with the sudden realization of what he wanted to do for a living. That inspiration occurred while browsing through an attic with his elder brother, when King uncovered a paperback version of an H. P. Lovecraft collection of short stories he remembers as \"The Lurker in the Shadows\", that had belonged to his father. King told Barnes & Noble Studios during a 2009 interview, \"I knew that I'd found home when I read that book.\"\n\nKing attended Durham Elementary School and graduated from Lisbon Falls High School, in Lisbon Falls, Maine. He displayed an early interest in horror as an avid reader of EC's horror comics, including \"Tales from the Crypt\" (he later paid tribute to the comics in his screenplay for \"Creepshow\"). He began writing for fun while still in school, contributing articles to \"Dave's Rag\", the newspaper his brother published with a mimeograph machine, and later began selling to his friends stories based on movies he had seen (though when discovered by his teachers, he was forced to return the profits). The first of his stories to be independently published was \"I Was a Teenage Grave Robber\"; it was serialized over four issues (three published and one unpublished) of a fanzine, \"Comics Review\", in 1965. That story was published the following year in a revised form as \"In a Half-World of Terror\" in another fanzine, \"Stories of Suspense\", edited by Marv Wolfman. As a teen, King also won a Scholastic Art and Writing Award.\n\nFrom 1966, King studied at the University of Maine, graduating in 1970 with a Bachelor of Arts in English. That year, his daughter Naomi Rachel was born. He wrote a column, \"Steve King's Garbage Truck\", for the student newspaper, \"The Maine Campus\" and participated in a writing workshop organized by Burton Hatlen. King held a variety of jobs to pay for his studies, including janitor, gas pump attendant, and worker at an industrial laundry.\n\nKing sold his first professional short story, \"The Glass Floor,\" to \"Startling Mystery Stories\" in 1967. The Fogler Library at the University of Maine now holds many of King's papers.\n\nAfter leaving the university, King earned a certificate to teach high school but, unable to find a teaching post immediately, initially supplemented his laboring wage by selling short stories to men's magazines such as \"Cavalier\". Many of these early stories have been republished in the collection \"Night Shift\". The short story \"The Raft\" was published in \"Adam\", a men's magazine. After being arrested for driving over a traffic cone, he was fined $250 and had no money to pay the petty larceny fine. Luckily payment arrived for the short story \"The Raft\", then entitled \"The Float\", and \"all I did was cash the check and pay the fine.\" In 1971, King married Tabitha Spruce, a fellow student at the University of Maine whom he had met at the University's Fogler Library after one of Professor Hatlen's workshops. That fall, King was hired as a teacher at Hampden Academy in Hampden, Maine. He continued to contribute short stories to magazines and worked on ideas for novels. During that time, King developed a drinking problem which would plague him for more than a decade.\n\nIn 1973, King's first novel \"Carrie\" was accepted by publishing house Doubleday. King had thrown an early draft of the novel into the trash after becoming discouraged with his progress writing about a teenage girl with psychic powers. His wife retrieved the manuscript and encouraged him to finish it. His advance for \"Carrie\" was $2,500; King's paperback rights later earned $400,000.\n\nKing and his family moved to southern Maine because of his mother's failing health. At this time, he began writing a book titled \"Second Coming\", later titled \"Jerusalem's Lot\", before finally changing the title to \"Salem's Lot\" (published 1975). In a 1987 issue of \"The Highway Patrolman\" magazine, he stated, \"The story seems sort of down home to me. I have a special cold spot in my heart for it!\" Soon after \"Carrie\"s release in 1974, King's mother died of uterine cancer. His Aunt Emrine had read the novel to her before she died. King has written of his severe drinking problem at this time, stating that he was drunk delivering the eulogy at his mother's funeral.\n\nAfter his mother's death, King and his family moved to Boulder, Colorado, where King wrote \"The Shining\" (published 1977). The family returned to western Maine in 1975, where King completed his fourth novel, \"The Stand\" (published 1978). In 1977, the family, with the addition of Owen Phillip (his third and last child), traveled briefly to England, returning to Maine that fall, where King began teaching creative writing at the University of Maine. He has kept his primary residence in Maine ever since.\n\nIn 1985, King wrote his first work for the comic book medium, writing a few pages of the benefit X-Men comic book \"Heroes for Hope Starring the X-Men\". The book, whose profits were donated to assist with famine relief in Africa, was written by a number of different authors in the comic book field, such as Chris Claremont, Stan Lee, and Alan Moore, as well as authors not primarily associated with that industry, such as Harlan Ellison. The following year, King published \"It\" (1986), which was the best-selling hard-cover novel in the United States that year, and wrote the introduction to \"Batman\" No. 400, an anniversary issue in which he expressed his preference for that character over Superman.\n\nIn the late 1970s, King began what became a series of interconnected stories about a lone gunslinger, Roland, who pursues the \"Man in Black\" in an alternate-reality universe that is a cross between J. R. R. Tolkien's Middle-earth and the American Wild West as depicted by Clint Eastwood and Sergio Leone in their spaghetti Westerns. The first of these stories, \"\", was initially published in five installments by \"The Magazine of Fantasy & Science Fiction\" under the editorship of Edward L. Ferman, from 1977 to 1981. \"The Gunslinger\" was continued as an eight-book epic series called \"The Dark Tower\", whose books King wrote and published infrequently over four decades.\n\nIn the late 1970s and early 1980s, King published a handful of short novels—\"Rage\" (1977), \"The Long Walk\" (1979), \"Roadwork\" (1981), \"The Running Man\" (1982) and \"Thinner\" (1984)—under the pseudonym Richard Bachman. The idea behind this was to test whether he could replicate his success again and to allay his fears that his popularity was an accident. An alternate explanation was that publishing standards at the time allowed only a single book a year. He picked up the name from the hard rock band Bachman-Turner Overdrive, of which he is a fan.\n\nRichard Bachman was exposed as King's pseudonym by a persistent Washington, D.C. bookstore clerk, Steve Brown, who noticed similarities between the works and later located publisher's records at the Library of Congress that named King as the author of one of Bachman's novels. This led to a press release heralding Bachman's \"death\"—supposedly from \"cancer of the pseudonym\". King dedicated his 1989 book \"The Dark Half\", about a pseudonym turning on a writer, to \"the deceased Richard Bachman\", and in 1996, when the Stephen King novel \"Desperation\" was released, the companion novel \"The Regulators\" carried the \"Bachman\" byline.\n\nIn 2006, during a press conference in London, King declared that he had discovered another Bachman novel, titled \"Blaze\". It was published on June 12, 2007. In fact, the original manuscript had been held at King's alma mater, the University of Maine in Orono, for many years and had been covered by numerous King experts. King rewrote the original 1973 manuscript for its publication.\n\nKing has used other pseudonyms. The short story \"The Fifth Quarter\" was published under the pseudonym John Swithen (the name of a character in the novel \"Carrie\"), that was published in \"Cavalier\" in April 1972. The story was reprinted in King's collection \"Nightmares & Dreamscapes\" in 1993 under his own name. In the introduction to the Bachman novel \"Blaze\", King claims, with tongue-in-cheek, that \"Bachman\" was the person using the Swithen pseudonym.\n\nThe \"children's book\" \"Charlie the Choo-Choo: From the World of The Dark Tower\" was published under the pseudonym Beryl Evans, who was portrayed by actress Allison Davies during a book signing at San Diego Comic-Con, and illustrated by Ned Dameron. It is adapted from a fictional book central to the plot of King's previous novel \"\" and published in 2016.\n\nIn 2000, King published online a serialized horror novel, \"The Plant\". At first the public presumed that King had abandoned the project because sales were unsuccessful, but King later stated that he had simply run out of stories. The unfinished epistolary novel is still available from King's official site, now free. Also in 2000, he wrote a digital novella, \"Riding the Bullet\", and has said he sees e-books becoming 50% of the market \"probably by 2013 and maybe by 2012\". But he also warns: \"Here's the thing—people tire of the new toys quickly.\"\n\nIn August 2003, King began writing a column on pop culture appearing in \"Entertainment Weekly\", usually every third week. The column, called \"The Pop of King\" (a play on the nickname \"The King of Pop\" commonly attributed to Michael Jackson).\n\nIn 2006, King published an apocalyptic novel, \"Cell\". The book features a sudden force in which every cell phone user turns into a mindless killer. King noted in the book's introduction that he does not use cell phones.\n\nIn 2008, King published both a novel, \"Duma Key\", and a collection, \"Just After Sunset\". The latter featured 13 short stories, including a novella, \"N.\", which was later released as a serialized animated series that could be seen for free, or, for a small fee, could be downloaded in a higher quality; it then was adopted into a limited comic book series.\n\nIn 2009, King published \"Ur\", a novella written exclusively for the launch of the second-generation Amazon Kindle and available only on Amazon.com, and \"Throttle\", a novella co-written with his son Joe Hill and released later as an audiobook titled \"Road Rage\", which included Richard Matheson's short story \"Duel\". King's novel \"Under the Dome\" was published on November 10 of that year; it is a reworking of an unfinished novel he tried writing twice in the late 1970s and early 1980s, and at 1,074 pages, it is the largest novel he has written since \"It\" (1986). \"Under the Dome\" debuted at No. 1 in \"The New York Times\" Bestseller List.\n\nOn February 16, 2010, King announced on his Web site that his next book would be a collection of four previously unpublished novellas called \"Full Dark, No Stars\". In April of that year, King published \"Blockade Billy\", an original novella issued first by independent small press Cemetery Dance Publications and later released in mass-market paperback by Simon & Schuster. The following month, DC Comics premiered \"American Vampire\", a monthly comic book series written by King with short-story writer Scott Snyder, and illustrated by Rafael Albuquerque, which represents King's first original comics work. King wrote the background history of the very first American vampire, Skinner Sweet, in the first five-issues story arc. Scott Snyder wrote the story of Pearl.\n\nKing's next novel, \"11/22/63\", was published November 8, 2011, and was nominated for the 2012 World Fantasy Award Best Novel. The eighth \"Dark Tower\" volume, \"\", was published in 2012. King's next book was \"Joyland\", a novel about \"an amusement-park serial killer\", according to an article in \"The Sunday Times\", published on April 8, 2012. It was followed by the sequel to \"The Shining\" (1977), titled \"Doctor Sleep\", published in September 2013.\n\nDuring his Chancellor's Speaker Series talk at University of Massachusetts Lowell on December 7, 2012, King indicated that he was writing a crime novel about a retired policeman being taunted by a murderer. With a working title \"Mr. Mercedes\" and inspired by a true event about a woman driving her car into a McDonald's restaurant, it was originally meant to be a short story just a few pages long. In an interview with \"Parade\", published May 26, 2013, King confirmed that the novel was \"more or less\" completed he published it in June 2013. Later, on June 20, 2013, while doing a video chat with fans as part of promoting the upcoming \"Under the Dome\" TV series, King mentioned he was halfway through writing his next novel, \"Revival\", which was released November 11, 2014.\n\nKing announced in June 2014 that \"Mr. Mercedes\" is part of a trilogy; the second book, \"Finders Keepers\", was released on June 2, 2015. On April 22, 2015, it was revealed that King was working on the third book of the trilogy which name was later revealed to be \"End of Watch\". The book was released on June 7, 2016, and hit the top of the \"New York Times\" bestseller list.\n\nOn November 3, 2015, King released his tenth collection of short stories, \"The Bazaar of Bad Dreams\". The book was released to critical acclaim and commercial success.\n\nDuring a tour to promote \"End of Watch\", King revealed that he had collaborated on a novel, set in a women's prison in West Virginia, with his son, Owen King to be titled \"Sleeping Beauties\". When the novel was released in October 2017, it reached the top of the \"New York Times\" Best Seller List.\n\nKing has written two novels with horror novelist Peter Straub: \"The Talisman\" (1984) and a sequel, \"Black House\" (2001). King has indicated that he and Straub will likely write the third and concluding book in this series, the tale of Jack Sawyer, but has set no deadline for its completion.\n\nKing produced an artist's book with designer Barbara Kruger, \"My Pretty Pony\" (1989), published in a limited edition of 250 by the Library Fellows of the Whitney Museum of American Art. Alfred A. Knopf released it in a general trade edition and the short story was later included in King's collection \"Nightmares & Dreamscapes\" published in 1993.\n\n\"\" (2001) was a paperback tie-in for the King-penned miniseries \"Rose Red\" (2002). Published under anonymous authorship, the book was written by Ridley Pearson. The novel is written in the form of a diary by Ellen Rimbauer, and annotated by the fictional professor of paranormal activity, Joyce Reardon. The novel also presents a fictional afterword by Ellen Rimbauer's grandson, Steven. Intended to be a promotional item rather than a stand-alone work, its popularity spawned a 2003 prequel television miniseries to \"Rose Red\", titled \"The Diary of Ellen Rimbauer\". This spin-off is a rare occasion of another author's being granted permission to write commercial work using characters and story elements invented by King. The novel tie-in idea was repeated on Stephen King's next project, the miniseries \"Kingdom Hospital\". Richard Dooling, King's collaborator on \"Kingdom Hospital\" and writer of several episodes in the miniseries, published a fictional diary, \"The Journals of Eleanor Druse\", in 2004. Eleanor Druse is a key character in \"Kingdom Hospital\", much as Dr. Joyce Readon and Ellen Rimbauer are key characters in \"Rose Red.\"\n\nKing also wrote the nonfiction book, \"Faithful\" (2004), with novelist and fellow Red Sox fanatic Stewart O'Nan.\n\n\"Throttle\" (2009), a novella written in collaboration with his son Joe Hill, appears in the anthology \"He Is Legend: Celebrating Richard Matheson\". Their second novella collaboration, \"In the Tall Grass\" (2012), was published in two parts in \"Esquire\". It was later released in e-book and audiobook formats, the latter read by Stephen Lang.\n\nStephen King and Richard Chizmar co-wrote \"Gwendy's Button Box\" which was released in May 2017 from Cemetery Dance Publications (in trade hardcover format) and in audiobook from Simon & Schuster Audio (the audiobook has a bonus short story \"The Music Room\" which was originally published in \"Playboy\").\n\nKing and his son Owen King wrote the novel \"Sleeping Beauties\", released in 2017, that is set in a women's prison.\n\nKing is a fan of the Ramones, to the extent that he wrote the liner notes for the 2003 Ramones tribute album \"\". He states that he agreed to write them because he \"loved The Ramones from the first time (he) heard them\". Furthermore, King has referred to the band several times in his writing, both in his fiction and non-fiction. Non-fiction references include a mention in King's book \"Danse Macabre\" where he calls the Ramones \"an amusing punk-rock band that surfaced some four years ago\". He also wrote about them in \"On Writing\", making reference to \"dancing to the Ramones—gabba gabba hey\" as one of the reasons he has maintained a good marriage. King included further Ramones references in his fictional work. He quotes the lyrics to the Ramones' debut single \"Blitzkrieg Bop\" in his novel \"Pet Sematary\" on numerous occasions, as in the sentence \"What is it the Ramones say? Hey-ho, let's go\"! In \"The Dark Tower\" novel \"\" the Ramones get a further mention by the character Eddie Dean who states that \"Roland stage-dives like Joey Ramone\". Critics have also noted the Ramones references. \"Entertainment Weekly\", for example, in their review of \"Black House\" by King and Peter Straub, note that King's \"trademark references\" are in evidence, quoting Dee Dee Ramone. In turn, the Ramones have referenced King on their song \"It's Not My Place (In the 9 to 5 World)\", from their \"Pleasant Dreams\" album of 1981 in the line: \"Ramones are hangin' out in Kokomo / Roger Corman's on a talk show / With Allan Arkush and Stephen King\". Further, Dee Dee Ramone wrote the song \"Pet Sematary\" in King's basement after King handed him a copy of the novel. The song was eventually featured as the title song for the \"Pet Sematary\" (1989) film and also appeared on the Ramones album \"Brain Drain\" (1989).\n\nKing is also a fan of hard rock such as AC/DC; he arranged for their album \"Who Made Who\" to feature as the score for the film he directed in 1986, \"Maximum Overdrive\". King has also stated that he likes heavy metal and has named bands like Anthrax, Judas Priest and Metallica as amongst his favourites to write to. In 1988, the band Blue Öyster Cult recorded an updated version of its 1974 song \"Astronomy\". The single released for radio play featured a narrative intro spoken by King. The Blue Öyster Cult song \"(Don't Fear) The Reaper\" was also used in the King TV series \"The Stand\".\n\nKing collaborated with Michael Jackson to create \"Ghosts\" (1996), a 40-minute musical video. King states he was motivated to collaborate as he is \"always interested in trying something new, and for (him), writing a minimusical would be new\". In 2012 King collaborated with musician Shooter Jennings and his band Hierophant, providing the narration for their album, \"Black Ribbons\". King played guitar for the rock band Rock Bottom Remainders, several of whose members are authors. Other members include Dave Barry, Ridley Pearson, Scott Turow, Amy Tan, James McBride, Mitch Albom, Roy Blount, Jr., Matt Groening, Kathi Kamen Goldmark, Sam Barry, and Greg Iles. King and the other band members collaborated to release an e-book called \"Hard Listening: The Greatest Rock Band Ever (of Authors) Tells All\" (June 2013). King wrote a musical play \"Ghost Brothers of Darkland County\" (2012) with musician John Mellencamp.\n\nKing's formula for learning to write well is: \"Read and write four to six hours a day. If you cannot find the time for that, you can't expect to become a good writer.\" He sets out each day with a quota of 2000 words and will not stop writing until it is met. He also has a simple definition for talent in writing: \"If you wrote something for which someone sent you a check, if you cashed the check and it didn't bounce, and if you then paid the light bill with the money, I consider you talented.\"\n\nShortly after his accident, King wrote the first draft of the book \"Dreamcatcher\" with a notebook and a Waterman fountain pen, which he called \"the world's finest word processor\".\n\nWhen asked why he writes, King responds: \"The answer to that is fairly simple—there was nothing else I was made to do. I was made to write stories and I love to write stories. That's why I do it. I really can't imagine doing anything else and I can't imagine not doing what I do.\" He is also often asked why he writes such terrifying stories and he answers with another question: \"Why do you assume I have a choice?\" King usually begins the story creation process by imagining a \"what if\" scenario, such as what would happen if a writer is kidnapped by a sadistic nurse in Colorado.\n\nKing often uses authors as characters, or includes mention of fictional books in his stories, novellas and novels, such as Paul Sheldon who is the main character in \"Misery\", adult Bill Denbrough in \"It\", Ben Mears in \"Salem's Lot\", and Jack Torrance in \"The Shining\". He has extended this to breaking the fourth wall by including \"himself\" as a character in the \"Dark Tower\" series from \"Wolves of the Calla\" onwards. See also List of fictional books in the works of Stephen King for a complete list. In September 2009 it was announced he would serve as a writer for \"Fangoria\".\n\nKing has called Richard Matheson \"the author who influenced me most as a writer.\" In a current edition of Matheson's \"The Shrinking Man\", King is quoted: \"A horror story if there ever was one...a great adventure story—it is certainly one of that select handful that I have given to people, envying them the experience of the first reading.\" Ray Bradbury is another influence, with King himself stating \"without Ray Bradbury, there is no Stephen King\".\n\nKing refers to H. P. Lovecraft several times in \"Danse Macabre\". \"Gramma\", a short story made into a film in the 1980s anthology horror show \"The New Twilight Zone\", mentions Lovecraft's notorious fictional creation \"Necronomicon\", also borrowing the names of a number of the fictional monsters mentioned therein. \"I Know What You Need\" from the 1976 collection \"Night Shift\", and \"'Salem's Lot\" also mention the tome. Despite this, in \"On Writing\", King is critical of Lovecraft's dialogue-writing skills, using passages from \"The Colour Out of Space\" as particularly poor examples. There are also several examples of King's referring to Lovecraftian characters and settings in his work, such as Nyarlathotep and Yog-Sothoth.\n\nKing acknowledges the influence of Bram Stoker, particularly on his novel \"Salem's Lot\", which he envisioned as a retelling of \"Dracula\". Its related short story \"Jerusalem's Lot\" is reminiscent of Stoker's \"The Lair of the White Worm\". He also gives Joseph Payne Brennan credit for being one of his inspirations; \"Joseph Payne Brennan is one of the most effective writers in the horror genre, and he is certainly one of the writers I have patterned my own career upon; one of the writers whom I studied and with whom I kept school.\"\n\nKing's \"The Shining\" is immersed in gothic influences, including \"The Masque of the Red Death\" by Edgar Allan Poe (which was directly influenced by the first gothic novel, Horace Walpole's \"The Castle of Otranto\"). The Overlook Hotel acts as a replacement for the traditional gothic castle, and Jack Torrance is a tragic villain seeking redemption.\n\nKing has also referred to author Shirley Jackson. \"Salem's Lot\" opens with a quotation from Jackson's \"The Haunting of Hill House\", and a character in \"\" references the Jackson book \"We Have Always Lived in the Castle\". King's book \"11/22/63\" mentions the Jackson story \"The Summer People\". King is a fan of John D. MacDonald, and dedicated the novella \"Sun Dog\" to MacDonald, saying \"I miss you, old friend.\" For his part, MacDonald wrote an admiring preface to \"Night Shift\", and even had his famous character, Travis McGee, reading \"Cujo\" in one of the last McGee novels and \"Pet Sematary\" in the last McGee novel, \"The Lonely Silver Rain.\"\n\nIn 1987, King's Philtrum Press published Don Robertson's novel \"The Ideal, Genuine Man\". In his forenote to the novel, King wrote, \"Don Robertson was and is one of the three writers who influenced me as a young man who was trying to 'become' a novelist (the other two being Richard Matheson and John D. MacDonald).\" Robert A. Heinlein's book \"The Door into Summer\" is repeatedly mentioned in King's \"Wolves of the Calla\" (2003), as are several other works. \"Wolves of the Calla\" is the King work in which \"The Dark Tower\" begins to follow a meta-fictional path.\n\nIn an interview with King, published in the \"USA Weekend\" in March 2009, the author stated, \"People look on writers that they like as an irreplaceable resource. I do. Elmore Leonard, every day I wake up and—not to be morbid or anything, although morbid is my life to a degree—don't see his obituary in the paper, I think to myself, \"Great! He's probably working somewhere. He's gonna produce another book, and I'll have another book to read. Because when he's gone, there's nobody else.\"\n\nKing partly dedicated his book \"Cell\" to film director George Romero, and wrote an essay for the Elite DVD version of \"Night of the Living Dead\".\nHis favorite books are (in order): \"The Golden Argosy\"; \"Adventures of Huckleberry Finn\"; \"The Satanic Verses\"; \"McTeague\"; \"Lord of the Flies\"; \"Bleak House\"; \"Nineteen Eighty-Four\"; \"The Raj Quartet\"; \"Light in August\"; and \"Blood Meridian\".\n\nAlthough critical reaction to King's work has been mostly positive, he has occasionally come under fire from academic writers.\n\nScience fiction editors John Clute and Peter Nichols offer a largely favorable appraisal of King, noting his \"pungent prose, sharp ear for dialogue, disarmingly laid-back, frank style, along with his passionately fierce denunciation of human stupidity and cruelty (especially to children) [all of which rank] him among the more distinguished 'popular' writers.\"\n\nIn his book \"The Philosophy of Horror\" (1990), Noël Carroll discusses King's work as an exemplar of modern horror fiction. Analyzing both the narrative structure of King's fiction and King's non-fiction ruminations on the art and craft of writing, Carroll writes that for King, \"the horror story is always a contest between the normal and the abnormal such that the normal is reinstated and, therefore, affirmed.\"\n\nIn his analysis of post–World War II horror fiction, \"The Modern Weird Tale\" (2001), critic S. T. Joshi devotes a chapter to King's work. Joshi argues that King's best-known works (his supernatural novels), are his worst, describing them as mostly bloated, illogical, maudlin and prone to \"deus ex machina\" endings. Despite these criticisms, Joshi argues that since \"Gerald's Game\" (1993), King has been tempering the worst of his writing faults, producing books that are leaner, more believable and generally better written. Joshi suggests that King's strengths as a writer include the accessible \"everyman\" quality of his prose, and his unfailingly insightful observations about the pains and joys of adolescence. Joshi cites two early non-supernatural novels—\"Rage\" (1977) and \"The Running Man\" (1982)—as King's best, suggesting both are riveting and well-constructed suspense thrillers, with believable characters.\n\nIn 1996, King won an O. Henry Award for his short story \"The Man in the Black Suit\".\n\nIn his short story collection \"A Century of Great Suspense Stories\", editor Jeffery Deaver noted that King \"singlehandedly made popular fiction grow up. While there were many good best-selling writers before him, King, more than anybody since John D. MacDonald, brought reality to genre novels. He has often remarked that \"'Salem's Lot\" was \"\"Peyton Place\" meets \"Dracula\". And so it was. The rich characterization, the careful and caring social eye, the interplay of story line and character development announced that writers could take worn themes such as vampirism and make them fresh again. Before King, many popular writers found their efforts to make their books serious blue-penciled by their editors. 'Stuff like that gets in the way of the story,' they were told. Well, it's stuff like that that has made King so popular, and helped free the popular name from the shackles of simple genre writing. He is a master of masters.\"\n\nIn 2003, King was honored by the National Book Awards with a lifetime achievement award, the Medal of Distinguished Contribution to American Letters. Some in the literary community expressed disapproval of the award: Richard E. Snyder, the former CEO of Simon & Schuster, described King's work as \"non-literature\" and critic Harold Bloom denounced the choice:\n\nThe decision to give the National Book Foundation's annual award for \"distinguished contribution\" to Stephen King is extraordinary, another low in the shocking process of dumbing down our cultural life. I've described King in the past as a writer of penny dreadfuls, but perhaps even that is too kind. He shares nothing with Edgar Allan Poe. What he is is an immensely inadequate writer on a sentence-by-sentence, paragraph-by-paragraph, book-by-book basis.\n\nHowever, others came to King's defense, such as writer Orson Scott Card, who responded:\n\nLet me assure you that King's work most definitely is literature, because it was written to be published and is read with admiration. What Snyder really means is that it is not the literature preferred by the academic-literary elite.\n\nKing himself later stated:\n\n[Harold] Bloom never pissed me off because there are critics out there, and he's one of them, who take their ignorance about popular culture as a badge of intellectual prowess. He might be able to say that Mark Twain is a great writer, but it's impossible for him to say that there's a direct line of descent from, say, Nathaniel Hawthorne to Jim Thompson because he doesn't read guys like Thompson. He just thinks, \"I never read him, but I know he's terrible.\"\n\nIn Roger Ebert's review of the 2004 movie \"Secret Window\", he stated, \"A lot of people were outraged that [King] was honored at the National Book Awards, as if a popular writer could not be taken seriously. But after finding that his book \"On Writing\" had more useful and observant things to say about the craft than any book since Strunk and White's \"The Elements of Style\", I have gotten over my own snobbery.\"\n\nIn 2008, King's book \"On Writing\" was ranked 21st on \"Entertainment Weekly\" list of \"The New Classics: The 100 Best Reads from 1983 to 2008\".\n\nKing and his wife Tabitha own Zone Radio Corp, a radio station group consisting of WZON/620 AM, WKIT-FM/100.3 & WZLO/103.1.\n\nKing has stated that his favorite book-to-film adaptations are \"Stand by Me\", \"The Shawshank Redemption\", and \"The Mist\".\n\nKing's first film appearance was in George Romero's \"Knightriders\" as a buffoonish audience member. His first featured role was in \"Creepshow\", in particular the segment \"The Lonesome Death of Jordy Verrill\" (King also having written the original story), where he plays the titular character. He has since made cameos in several adaptations of his works. He appeared in \"Pet Sematary\" as a minister at a funeral, in \"Thinner\" as a pharmacist, in \"Rose Red\" as a pizza deliveryman, as a news reporter in \"The Storm of the Century\", in \"The Stand\" as \"Teddy Wieszack,\" in the \"Shining\" miniseries as a band member, in \"The Langoliers\" as Tom Holby; in \"Sleepwalkers\" as the cemetery caretaker and \"Golden Years\" as a bus driver. He has also appeared in \"Chappelle's Show\" and, along with fellow author Amy Tan, on \"The Simpsons\" as himself. In addition to acting, King tried his hand at directing with \"Maximum Overdrive\", in which he also made a cameo appearance as a man using a malfunctioning ATM. King had also been approached to appear in the 1985 Romero film \"Day of the Dead\" as a zombie. Although King declined due to scheduling conflicts, a copy of one of his works makes an appearance being held by the foremost zombie \"Bub\". King would once again work with Romero in 1993 when his work \"The Dark Half\" was filmed and directed by George Romero.\n\nKing produced and acted in a television series, \"Kingdom Hospital\", which is based on the Danish miniseries \"Riget\" by Lars von Trier. He also co-wrote \"The X-Files\" season-5 episode \"Chinga\" with the creator of the series Chris Carter.\n\nKing made an appearance as a contestant on \"Celebrity Jeopardy!\" in 1995, playing to benefit the Bangor Public Library.\n\nKing provided the voice of Abraham Lincoln in the audiobook version of \"Assassination Vacation\".\n\nIn 2010, King appeared in a cameo role as a cleaner named Bachman (a reference to his pen name \"Richard Bachman\") on the FX series \"Sons of Anarchy\".\n\nThe Syfy TV series \"Haven\" is based on King's novella, \"The Colorado Kid\".\n\nOn June 19, 1999, at about 4:30 p.m., King was walking on the shoulder of Maine State Route 5, in Lovell, Maine. Driver Bryan Edwin Smith, distracted by an unrestrained dog moving in the back of his minivan, struck King, who landed in a depression in the ground about 14 feet (four meters) from the pavement of Route 5. According to Oxford County Sheriff deputy Matt Baker, King was hit from behind and some witnesses said the driver was not speeding, reckless, or drinking. In his book \"On Writing\" King states he was heading north, walking against the traffic. Shortly before the accident took place, a woman in a car also northbound passed King first and then the light blue Dodge van. The van was looping from one side of the road to the other and the woman told her passenger she hoped \"that guy in the van doesn't hit him.\"\n\nKing was conscious enough to give the deputy phone numbers to contact his family, but was in considerable pain. The author was first transported to Northern Cumberland Hospital in Bridgton and then flown by air ambulance to Central Maine Medical Center (CMMC) in Lewiston. His injuries—a collapsed right lung, multiple fractures of his right leg, scalp laceration and a broken hip—kept him at CMMC until July 9. His leg bones were so shattered that doctors initially considered amputating his leg, but stabilized the bones in the leg with an external fixator. After five operations in 10 days and physical therapy, King resumed work on \"On Writing\" in July, though his hip was still shattered and he could sit for only about 40 minutes before the pain became unbearable.\n\nKing's lawyer and two others purchased Smith's van for $1,500, reportedly to prevent it from appearing on eBay. The van was later crushed at a junkyard, much to King's disappointment, as he fantasized about smashing it up. King later mentioned during an interview with \"Fresh Air's\" Terry Gross that he wanted the vehicle destroyed at a charity event in which individuals would donate money for an opportunity to smash it with a sledgehammer.\n\nDuring this time, Tabitha King was inspired to redesign his studio. King visited the space while his books and belongings were packed away. What he saw was an image of what his studio would look like if he died, providing a seed for his novel \"Lisey's Story\" (2006).\n\nThe driver of the vehicle that struck King, Bryan Edwin Smith, was found dead at his Maine home in September 2000 in an apparent suicide. Smith had told friends shortly before that he \"could not face another winter\".\n\nIn 2002, King announced he would stop writing, apparently motivated in part by frustration with his injuries, which had made sitting uncomfortable and reduced his stamina. He has since resumed writing, but states on his Web site:\n\nIn April 2008, King spoke out against HB 1423, a bill pending in the Massachusetts state legislature that would restrict or ban the sale of violent video games to anyone under the age of 18. Although King stated that he had no personal interest in video games as a hobby, he criticized the proposed law, which he sees as an attempt by politicians to scapegoat pop culture, and to act as surrogate parents to other people's children, which he asserted is usually \"disastrous\" and \"undemocratic.\" He also saw the law as inconsistent, as it would forbid a 17-year-old, legally able to see \"\", from buying or renting \"\", which is violent but less graphic. While conceding that he saw no artistic merit in some violent video games, King also opined that such games reflect the violence that already exists in society, which would not be lessened by such a law, and would be redundant in light of the ratings system that already exists for video games. King argued that such laws allow legislators to ignore the economic divide between the rich and poor, and the easy availability of guns, which he felt were the more legitimate causes of violence. Regarding video games, he later stated that he enjoys playing light gun shooter arcade games such as \"Time Crisis\".\n\nA controversy emerged on May 5, 2008, when Noel Sheppard posted a clip of King at a Library of Congress reading event on the Web site NewsBusters. King, talking to high-school students, had said: \"If you can read, you can walk into a job later on. If you don't, then you've got the Army, Iraq, I don't know, something like that.\" The comment was described by the blog as \"another in a long line of liberal media members bashing the military,\" and likened to John Kerry's similar remark from 2006. King responded later that day, saying, \"That a right-wing-blog would impugn my patriotism because I said children should learn to read, and could get better jobs by doing so, is beneath contempt...I live in a national guard town, and I support our troops, but I don't support either the war or educational policies that limit the options of young men and women to any one career—military or otherwise.\" King again defended his comment in an interview with the \"Bangor Daily News\" on May 8, saying, \"I'm not going to apologize for promoting that kids get better education in high school, so they have more options. Those that don't agree with what I'm saying, I'm not going to change their minds.\" King later expressed regret for the remark, saying that he misspoke. He characterized the comment as originating from a \"brain cramp\", and the reality of no longer living in the world he grew up in, saying that during the Vietnam War, serving in the military was a great career for some, and for others, a sacrifice of two years of one's life. King added that he does believe that each person should be obligated to some type of government service or altruism.\n\nKing's website states that he is a supporter of the Democratic Party. During the 2008 presidential election, King voiced his support for Democratic candidate Barack Obama. King was quoted as calling conservative commentator Glenn Beck \"Satan's mentally challenged younger brother.\"\n\nOn March 8, 2011, King spoke at a political rally in Sarasota aimed against Governor Rick Scott (R-FL), voicing his opposition to the Tea Party movement.\n\nOn April 30, 2012, King published an article in \"The Daily Beast\" calling for rich Americans, including himself, to pay more taxes, citing it as \"a practical necessity and moral imperative that those who have received much should be obligated to pay ... in the same proportion\".\n\nOn January 25, 2013, King published an essay titled \"Guns\" via Amazon.com's Kindle single feature, which discusses the gun debate in the wake of the Sandy Hook Elementary School shooting. King called for gun owners to support a ban on automatic and semi-automatic weapons, writing, \"Autos and semi-autos are weapons of mass destruction...When lunatics want to make war on the unarmed and unprepared, these are the weapons they use.\" The essay became the fifth-bestselling non-fiction title for the Kindle.\n\nKing has criticized Donald Trump and Rep. Steve King, deeming them racists.\nKing had endorsed Shenna Bellows in the 2014 U.S. Senate election for the seat held by Republican Susan Collins.\n\nKing is a public critic of Paul LePage, the Republican Governor of Maine, and has referred to LePage as one of the Three Stooges, along with Florida Governor Rick Scott and Wisconsin Governor Scott Walker. He was critical of LePage for incorrectly suggesting in a weekly radio address on March 18, 2015, that King avoided paying Maine income taxes by living out of state for part of the year. The statement was later corrected by the Governor's office but no apology was issued. King said LePage was \"full of the stuff that makes the grass grow green\" and demanded that LePage \"man up and apologize\". LePage declined to apologize to King, stating \"I never said Stephen King did not pay income taxes. What I said was, Stephen King's not in Maine right now. That's what I said.\" LePage further told King that he should \"make me the villain of your next book and I won't charge you royalties\".\n\nThe attention garnered by the LePage criticism has led to efforts to encourage King to run for Governor of Maine in 2018. Bangor city councilor Joe Baldacci posted on his Facebook page that he was starting a Draft Stephen King effort, and Democratic State Rep. Diane Russell launched a petition drive to encourage King to run. His spokeswoman posted to Baldacci's Facebook comment that he would likely decline to run, and King himself stated he would not run or serve on March 23 while still criticizing what he said was the \"laziness that made him mad\" about not checking his tax payments and that LePage had \"a problem finding a comfortable pair of big-boy pants\".\n\nKing sent a tweet on June 30, 2015, stating that LePage is \"a terrible embarrassment to the state I live in and love. If he won't govern, he should resign.\" He later clarified that he was not calling on LePage to resign, but to \"go to work or go back home.\" On August 27, 2016, King sent another tweet about LePage, calling him \"a bigot, a homophobe, and a racist\".\n\nKing has stated that he donates approximately $4 million per year \"to libraries, local fire departments that need updated lifesaving equipment (Jaws of Life tools are always a popular request), schools, and a scattering of organisations that underwrite the arts.\"\n\nThe Stephen and Tabitha King Foundation, chaired by the author and his wife, ranks sixth among Maine charities in terms of average annual giving with over $2.8 million in grants per year, according to The Grantsmanship Center.\n\nIn November 2011, the STK Foundation donated $70,000 in matched funding via his radio station to help pay the heating bills for families in need in his home town of Bangor, Maine, during the winter.\n\nKing married Tabitha Spruce in 1971. She too is a novelist and philanthropic activist. The couple own and divide their time between three houses: one in Bangor, Maine, one in Lovell, Maine, and for the winter a waterfront mansion located off the Gulf of Mexico in Sarasota, Florida. The Kings have three children, a daughter and two sons, and four grandchildren. Their daughter Naomi is a Unitarian Universalist Church minister in Plantation, Florida, with her lesbian partner, Rev. Dr. Thandeka. Both of the Kings' sons are authors: Owen King published his first collection of stories, \"We're All in This Together: A Novella and Stories\", in 2005. Joseph Hillstrom King, who writes as Joe Hill, published a collection of short stories, \"20th Century Ghosts\", in 2005. His debut novel, \"Heart-Shaped Box\" (2007), was optioned by Warners Bros.\n\nKing's addictions to alcohol and other drugs were so serious during the 1980s that, as he acknowledged in \"On Writing\" in 2000, he can barely remember writing \"Cujo\". Shortly after the novel's publication, King's family and friends staged an intervention, dumping on the rug in front of him evidence of his addictions taken from his office including beer cans, cigarette butts, grams of cocaine, Xanax, Valium, NyQuil, dextromethorphan (cough medicine) and marijuana. As King related in his memoir, he then sought help, quit all drugs (including alcohol) in the late 1980s, and has remained sober since. The first novel he wrote after becoming sober was \"Needful Things\".\n\nKing is a fan of baseball, and of the Boston Red Sox in particular; he frequently attends the team's home and away games, and occasionally mentions the team in his novels and stories. He helped coach his son Owen's Bangor West team to the Maine Little League Championship in 1989. He recounts this experience in the \"New Yorker\" essay \"Head Down\", which appears also in the collection \"Nightmares & Dreamscapes\". In 1999, King wrote \"The Girl Who Loved Tom Gordon,\" featuring former Red Sox pitcher Tom Gordon as the protagonist's imaginary companion. In 2004, King co-wrote a book titled \"Faithful: Two Diehard Boston Red Sox Fans Chronicle the Historic 2004 Season\" with Stewart O'Nan, recounting the authors' roller-coaster reaction to the Red Sox's 2004 season, a season culminating in the Sox winning the 2004 American League Championship Series and World Series. In the 2005 film \"Fever Pitch,\" about an obsessive Boston Red Sox fan, King tosses out the first pitch of the Sox's opening-day game.\n\n\n\n\n\n"}
{"id": "10915787", "url": "https://en.wikipedia.org/wiki?curid=10915787", "title": "Subordination (linguistics)", "text": "Subordination (linguistics)\n\nIn linguistics, subordination (abbreviated variously , , or ) is a principle of the hierarchical organization of linguistic units. While the principle is applicable in semantics, syntax, morphology, and phonology, most work in linguistics employs the term \"subordination\" in the context of syntax, and that is the context in which it is considered here. The syntactic units of sentences are often either subordinate or coordinate to each other. Hence an understanding of subordination is promoted by an understanding of coordination, and vice versa.\n\nSubordination as a concept of syntactic organization is associated closely with the distinction between \"coordinate\" and \"subordinate\" clauses. One clause is subordinate to another if it depends on it. The dependent clause is called a \"subordinate clause\" and the independent clause is called the \"main clause\" (= matrix clause). Subordinate clauses are usually introduced by subordinators (= subordinate conjunctions) such as \"after\", \"because\", \"before\", \"if\", \"so that\", \"that\", \"when\", \"while\", etc. For example:\n\nThe strings in bold are subordinate clauses, and the strings in non-bold are the main clauses. Sentences must consist of at least one main clause, whereas the number of subordinate clauses is hypothetically without limitation. Long sentences that contain many subordinate clauses are characterized in terms of hypotaxis, the Greek term meaning the grammatical arrangement of \"unequal\" constructs (\"hypo\"=\"beneath\", \"taxis\"=\"arrangement\"). Sentences that contain few or no subordinate clauses but that may contain coordinated clauses are characterized in terms of parataxis.\n\nIn a broader sense, subordination is a relation existing between two syntactic units, whereby the one unit is subordinate to the other and the latter is superordinate to the former. An adjective that modifies a noun is subordinate to the noun and the noun is superordinate to the adjective; a noun phrase (NP) that is the complement of a preposition is subordinate to the preposition and the preposition is superordinate to the NP; a prepositional phrase (PP) that modifies a verb phrase (VP) is subordinate to the VP and the VP is superordinate to the PP; etc. The subordinate unit is called the \"dependent\", and the superordinate unit the \"head\". Thus anytime two syntactic units are in a head-dependent relationship, subordination obtains. For example:\n\nThe word in bold in each case is dependent on the other word, which is its head. Subordination in this sense should be compared with coordination. Two units or more are coordinate to each other if there is no hierarchical relation between them and they have equal functional status, e.g.\n\nThe words in brackets are coordinate to each other, and both coordinates are subordinate to the word that is not enclosed in brackets. Note that while the coordinated units are not organized hierarchically, they are organized linearly, the one preceding the other.\n\nMost theories of syntax represent subordination (and coordination) in terms of tree structures. A head is positioned above its dependents in the tree, so that it immediately \"dominates\" them. One of two competing principles is employed to construct the trees: either the constituency relation of phrase structure grammars or the dependency relation of dependency grammars. Both principles are illustrated here with the following trees. The a-trees on the left illustrate constituency, and the b-trees on the right dependency:\n\nConstituency shows subordination by way of projections. One of the two words projects its category status up to the root node of the entire structure and is therefore the head of the structure. Dependency also shows subordination, but it does so with fewer nodes in the tree. The head directly dominates its dependent. These trees illustrating subordination can be compared with trees illustrating coordination. There are various proposals concerning the tree representations of coordinate structures. The following trees are just suggestive in this regard. The constituency relation is again shown in the a-trees on the left, and the dependency relation in the b-trees on the right:\n\nThe constituency trees show that both parts of the coordinate structure project up to the root node of the entire tree, and the dependency trees illustrate that each word again projects just a single node. Both representation formats illustrate the equal status of the coordinated units insofar as they are placed on the same level; they are equi-level. From an organizational point of view, subordination is grouping words together in such a manner that includes hierarchical and linear order, whereas coordination is grouping words together just in terms of linear order.\n\n"}
{"id": "3205309", "url": "https://en.wikipedia.org/wiki?curid=3205309", "title": "Temporal lobe epilepsy", "text": "Temporal lobe epilepsy\n\nTemporal lobe epilepsy (TLE) is a chronic disorder of the nervous system characterized by recurrent, unprovoked focal seizures that originate in the temporal lobe of the brain and last about one or two minutes. TLE is the most common form of epilepsy with focal seizures. A focal seizure in the temporal lobe may spread to other areas in the brain when it may become a \"focal to bilateral seizure\".\n\nTLE is usually diagnosed in childhood or adolescence. TLE is diagnosed by taking a medical history, blood tests, and brain imaging. It can have a number of causes such as head injury, stroke, brain infections, structural lesions in the brain, or brain tumors, or it can be of \"unknown onset\". The first line of treatment is through anticonvulsants. Surgery may be an option, especially when there is an observable abnormality in the brain. Another treatment option is electrical stimulation of the brain through an implanted device called the vagus nerve stimulator (VNS).\n\nOver forty types of epilepsy are recognized and these are divided into two main groups: focal seizures and generalized seizures. Focal seizures account for approximately sixty percent of all adult cases. Temporal lobe epilepsy (TLE) is the single most common form of focal seizure.\n\nThe International League Against Epilepsy (ILAE) recognizes two main types of temporal lobe epilepsy: mesial temporal lobe epilepsy (MTLE), arising in the hippocampus, the parahippocampal gyrus and the amygdala which are located in the inner (medial) aspect of the temporal lobe and lateral temporal lobe epilepsy (LTLE), the rarer type, arising in the neocortex at the outer (lateral) surface of the temporal lobe. The seizures of LTLE are characterized by auditory or visual features. Autosomal dominant lateral temporal lobe epilepsy (ADLTLE) is a rare hereditary condition, often associated with mutations in the LGI1 gene.\n\nWhen a seizure begins in the temporal lobe, its effects depend on the precise location of its point of origin, its \"locus\". In 1981, the ILAE recognized three types of seizures occurring in temporal lobe epilepsy. The classification was based on EEG findings. However as of 2017 the general classification of seizures has been revised. The newer classification uses three key features: where the seizures begin, the level of awareness during a seizure, and other features.\n\nFocal seizures in the temporal lobe involve small areas of the lobe such as the amygdala and hippocampus.\n\nThe newer classification gives two types of \"focal onset seizures\", as \"focal aware\" and \"focal impaired awareness\".\n\n\"Focal aware\" means that the level of consciousness is not altered during the seizure. In temporal lobe epilepsy, a focal seizure usually causes abnormal sensations only.\n\nThese may be:\nOlfactory hallucinations often seem indescribable to patients beyond \"pleasant\" or \"unpleasant\".\n\nFocal aware seizures are often called \"auras\" when they serve as a warning sign of a subsequent seizure. Regardless an \"aura\" is actually a seizure itself, and such a focal seizure may or may not progress to a focal impaired awareness seizure. People who only experience focal aware seizures may not recognize what they are, nor seek medical care.\n\nFocal impaired awareness seizures are seizures which impair consciousness to some extent: they alter the person's ability to interact normally with their environment. They usually begin with a focal aware seizure, then spread to a larger portion of the temporal lobe, resulting in impaired consciousness. They may include autonomic and psychic features present in focal aware seizures.\n\nSigns may include:\nThese seizures tend to have a warning or aura before they occur, and when they occur they generally tend to last only 1–2 minutes. It is not uncommon for an individual to be tired or confused for up to 15 minutes after a seizure has occurred, although postictal confusion can last for hours or even days. Though they may not seem harmful, due to the fact that the individual does not normally seize, they can be extremely harmful if the individual is left alone around dangerous objects. For example, if a person with complex partial seizures is driving alone, this can cause them to run into the ditch, or worse, cause an accident involving multiple people. With this type, some people do not even realize they are having a seizure and most of the time their memory from right before or after the seizure is wiped. First-aid is only required if there has been an injury or if this is the first time a person has had a seizure.\n\nSeizures which begin in the temporal lobe, and then spread to involve both sides of the brain are termed \"focal to bilateral\". (Where both sides of the brain or the whole brain are involved from the onset the seizures are known as generalized seizures and may be tonic clonic. The arms, trunk, and legs stiffen (the tonic phase), in either a flexed or extended position, and then jerk (the clonic phase). These were previously known as \"grand mal\" seizures. The word \"grand mal\" comes from the French term, meaning \"major affliction.\"\n\nThere is some period of recovery in which neurological function is altered after each of these seizure types. This is the \"postictal state\". The degree and length of postictal impairment directly correlates with the severity of the seizure type. Focal aware seizures often last less than sixty seconds; focal with impaired awareness seizures may last up to two minutes; and generalized tonic clonic seizures may last up to three minutes. The postictal state in seizures other than \"focal aware\" may last much longer than the seizure itself.\n\nBecause a major function of the temporal lobe is short-term memory, a focal with impaired awareness seizure, and a focal to bilateral seizure can cause amnesia for the period of the seizure, meaning that the seizure may not be remembered.\n\nIndividuals with temporal lobe epilepsy have a higher prevalence of depression than the general population. Although the psychosocial impacts of epilepsy may be causative, there are also links in the phenomenology and neurobiology of TLE and depression.\n\nThe temporal lobe and particularly the hippocampus plays an important role in memory processing. Declarative memory (memories which can be consciously recalled) is formed in the area of the hippocampus called the \"dentate gyrus\".\n\nTemporal lobe epilepsy is associated with memory disorders and loss of memory. Animal models and clinical studies show that memory loss correlates with temporal lobe neuronal loss in temporal lobe epilepsy. Verbal memory deficit correlates with pyramidal cell loss in TLE. This is more so on the left in verbal memory loss. Neuronal loss on the right is more prominent in non-verbal (visuospatial memory loss).\n\nAfter childhood onset, one third will \"grow out\" of TLE, finding a lasting remission up to an average of 20 years. The finding of a lesion such as hippocampal sclerosis (a scar in the hippocampus), tumour, or dysplasia, on magnetic resonance imaging (MRI) predicts the intractability of seizures.\n\nThe effect of temporal lobe epilepsy on personality is an historical observation dating to the 1800s. Personality and behavioural change in temporal lobe epilepsy is seen as a chronic condition when it persists for more than three months.\n\nGeschwind syndrome is a set of behavioural phenomena seen in some people with TLE. Documented by Norman Geschwind, signs include: hypergraphia (compulsion to write (or draw) excessively), hyperreligiosity (intense religious or philosophical experiences or interests), hyposexuality (reduced sexual interest or drive), circumstantiality (result of a non-linear thought pattern, talks at length about irrelevant and trivial details). The personality changes generally vary by hemisphere.\n\nThe existence of a \"temporal lobe epileptic personality\" and Geschwind syndrome has been disputed and research is inconclusive.\n\nThe diagnosis of temporal lobe epilepsy can include the following methods: Magnetic resonance imaging (MRI), CT scans, positron emission tomography (PET), EEG, and magnetoencephalography.\n\nOther medical conditions with similar symptoms include panic attacks, psychosis spectrum disorders, tardive dyskinesia, and occipital lobe epilepsy.\n\nThe causes of TLE include mesial temporal sclerosis, traumatic brain injury, brain infections, such as encephalitis and meningitis, hypoxic brain injury, stroke, cerebral tumours, and genetic syndromes. Temporal lobe epilepsy is not the result of psychiatric illness or fragility of the personality.\n\nAlthough the theory is controversial, there is a link between febrile seizures (seizures coinciding with episodes of fever in young children) and subsequent temporal lobe epilepsy, at least epidemiologically.\n\nIn the mid 1980s, human herpesvirus 6 (HHV-6) was suggested as a possible causal link between febrile convulsions and mesial temporal lobe epilepsy. However, although the virus is found in temporal lobe tissue at surgery for TLE, it has not been recognised as a major factor in febrile seizures or TLE.\n\nDispersion of the granule cell layer in the hippocampal dentate gyrus is occasionally seen in temporal lobe epilepsy and has been linked to the downregulation of reelin, a protein that normally keeps the layer compact by containing neuronal migration. It is unknown whether changes in reelin expression play a role in epilepsy.\n\nIn TLE, there is loss of neurons in region CA1 and CA3 of the hippocampus. There is also damage to mossy cells and inhibitory interneurons in the hilar region of the hippocampus (region IV) and to the granule cells of the dentate gyrus. In animal models, neuronal loss occurs during seizures but in humans, neuronal loss predates the first seizure and does not necessarily continue with seizure activity. The loss of the GABA-mediated inhibitory interneurons may increase the hyperexcitability of neurons of the hippocampus leading to recurrent seizures. According to the \"dormant basket cell\" hypothesis, mossy cells normally excite basket cells which in turn, inhibit granule cells. Loss of mossy cells lowers the threshold of action potentials of the granule cells.\n\nIn certain patients with temporal lobe epilepsy it has been found that the subiculum could generate epileptic activity. It has been found that GABA reversal potential is depolarising in the subpopulation of the pyramidal cells due to the lack of KCC2 co-transporter. It has been shown that it is theoretically possible to generate seizures in the neural networks due to down-regulation of KCC2, consistent with the chloride measurements during the transition to seizure and KCC2 blockade experiments.\n\nGranule cell dispersion is a type of developmental migration and a pathological change found in the TLE brain which was first described in 1990. The granule cells of the dentate gyrus are tightly packed forming a uniform, laminated layer with no monosynaptic connections. This structure provides a filter for the excitability of neurons.\n\nIn TLE, granule cells are lost, the structure is no longer closely packed and there are changes in the orientation of dendrites. These changes may or may not be epileptogenic. For instance, if the dendrites of granule cells reconnect, it may be in a way (through the laminar planes) that allows hyperexcitability. However, not all patients have granule cell dispersion.\n\nMossy fibers are the axons of granule cells. They project into the hilus of the dentate gyrus and stratum lucidum in the CA3 region giving inputs to both excitatory and inhibitory neurons.\n\nIn the TLE brain, where granule cells are damaged or lost, axons, the \"mossy\" fibres, 'sprout' in order to reconnect to other granule cell dendrites. This is an example of \"synaptic reorganization\". This was noted in human tissue in 1974 and in animal models in 1985. In TLE, the sprouting mossy fibres are larger than in the normal brain and their connections may be aberrant. Mossy fibre sprouting continues from one week to two months after injury.\n\nAberrant mossy fibre sprouting may create excitatory feedback circuits that lead to temporal lobe seizures. This is evident in intracellular recordings. Stimulation of aberrant mossy fibre areas increases the excitatory postsynaptic potential response.\n\nHowever, aberrant mossy fiber sprouting may inhibit excitatory transmission by synapsing with basket cells which are inhibitory neurons and by releasing GABA and neuropeptide Y which are inhibitory neurotransmitters. Also, in animal models, granule cell hyper-excitability is recorded before aberrant mossy fibre sprouting has occurred.\n\nMany anticonvulsant oral medications are available for the management of temporal lobe seizures. Most anticonvulsants function by decreasing the excitation of neurons, for example, by blocking fast or slow sodium channels or by modulating calcium channels; or by enhancing the inhibition of neurons, for example by potentiating the effects of inhibitory neurotransmitters like GABA.\n\nIn TLE, the most commonly used older medications are phenytoin, carbamazepine, primidone, valproate, and phenobarbital. Newer drugs, such as gabapentin, topiramate, levetiracetam, lamotrigine, pregabalin, tiagabine, lacosamide, and zonisamide promise similar effectiveness, with possibly fewer side-effects. Felbamate and vigabatrin are newer, but can have serious adverse effects so they are not considered as first-line treatments.\n\nUp to one third of patients with medial temporal lobe epilepsy will not have adequate seizure control with medication alone. For patients with medial TLE whose seizures remain uncontrolled after trials of several types of anticonvulsants (that is, the epilepsy is \"intractable\"), surgical excision of the affected temporal lobe may be considered.\n\nEpilepsy surgery has been performed since the 1860s and doctors have observed that it is highly effective in producing freedom from seizures. However, it was not until 2001 that a scientifically sound study was carried out to examine the effectiveness of temporal lobectomy.\n\nTemporal lobe surgery can be complicated by decreased cognitive function. However, after temporal lobectomy, memory function is supported by the opposite temporal lobe; and recruitment of the frontal lobe. Cognitive rehabilitation may also help.\n\nWhere surgery is not recommended, further management options include new (including experimental) anticonvulsants, and vagus nerve stimulation. The ketogenic diet is also recommended for children, and some adults. Other options include brain cortex responsive neural stimulators, deep brain stimulation, stereotactic radiosurgery, such as the gamma knife, and laser ablation.\n\nThe first to record and catalog the abnormal symptoms and signs of TLE was Norman Geschwind. He found a constellation of symptoms that included hypergraphia, hyperreligiosity, collapse, and pedantism, now called \"Geschwind syndrome\".\n\nVilayanur S. Ramachandran explored the neural basis of the hyperreligiosity seen in TLE using the galvanic skin response (GSR), which correlates with emotional arousal, to determine whether the hyperreligiosity seen in TLE was due to an overall heightened emotional state or was specific to religious stimuli. Ramachandran presented two subjects with neutral, sexually arousing and religious words while measuring GSR. Ramachandran was able to show that patients with TLE showed enhanced emotional responses to the religious words, diminished responses to the sexually charged words, and normal responses to the neutral words. This study was presented as an abstract at a neuroscience conference and referenced in Ramachandran's book, \"Phantoms in the Brain\", but it has never been published in the peer-reviewed scientific press.\n\nA study in 2015, reported that intrinsic religiosity and religiosity outside of organized religion were higher in patients with epilepsy than in controls. Lower education level, abnormal background EEG activity, and hippocampal sclerosis have been found to be contributing factors for religiosity in Temporal Lobe Epilepsy.\n\nTemporal lobe epilepsy has been suggested as a physical explanation for the revelatory experiences of prominent religious figures such as Abraham, Moses, Jesus, Mohammed, Saint Paul, and Joseph Smith. These experiences are described as complex interactions with their visions, but lacking the stereotypy, amnestic periods, and automatisms or generalized motor events, which are characteristic of TLE. Psychiatric conditions with psychotic spectrum symptoms may be a more plausible physical explanation of these experiences. Pope Pius IX's doctrine of the immaculate conception is thought to have been influenced by his forensically diagnosed partial epilepsy. It has also been suggested that the visions of Joan of Arc were probably an expression of partial epilepsy. In 2016, a case history found that a temporal lobe epileptic experienced a vision of God following a temporal lobe seizure, while undergoing EEG monitoring. The patient reported that God had sent him to the world to \"bring redemption to the people of Israel\". The purported link between TLE and religiosity has inspired work by Michael Persinger and many other researchers in the field of neurotheology, but some have questioned the evidence for a link between temporal lobe epilepsy and religiosity. The novel, \"Lying Awake\", by Mark Salzman, deals with topic of temporal lobe epilepsy and religion.\n"}
{"id": "42056865", "url": "https://en.wikipedia.org/wiki?curid=42056865", "title": "Teramo Castelli", "text": "Teramo Castelli\n\nTeramo Cristoforo Castelli (1597 – 3 October 1659) was an Italian Theatine missionary, born of a noble family, who spent twenty-two years in Georgia from 1632 to 1654. He left seven volumes of travel notes and pen-and-ink sketches and other illustrations, mainly of the people and landscapes of Georgia. This manuscript was discovered and delivered to the municipal library of Palermo by the priest Gioacchino di Marzo in 1878 and brought to the attention of scholars of Georgia by Michel Tamarati in 1910.\n"}
{"id": "41783096", "url": "https://en.wikipedia.org/wiki?curid=41783096", "title": "The Black Panther of Sivanipalli and Other Adventures of the Indian Jungle", "text": "The Black Panther of Sivanipalli and Other Adventures of the Indian Jungle\n\nThe Black Panther of Sivanipalli and Other Adventures of the Indian Jungle is the third book of jungle tales and man-eaters written by Kenneth Anderson, first published in 1959 by George Allen & Unwin Ltd.\n\n\"To all those who love the still wild places of the earth - the tropical jungles, the towering mountains and rolling hills, the open skies and to all those who love peace, stillness and solitude, wild life and Nature - I dedicate this book\"\n\nIntroduction\n\nAuthor Kenneth Anderson introduces his third book, and explains his reasons for devoting the first five chapters to panthers.\nA Panther's Way\n\nAnderson discusses the habitual differences of the panther and tiger, and the methods adopted for tracking them. \nMan-Eating Panther of the Yellagiri Hills\n\nA cattle-lifting panther turns man-eater when wounded by a local man's gunshot, and Kenneth Anderson heads to the Yellagiri Hills to investigate. Over the course of many weeks he returns to the Yellagiri Hills and sits up over goat and donkey baits awaiting a successful shot. On a few occasions the panther charges at Anderson, and on one such charge Anderson successfully gets a kill shot in. \nOld Munuswamy & The Panther of Magadi\n\nA local shikari guide, Munuswamy (who earns his living by exploiting panther hunters) attempts to gain local notoriety by shooting a cattle lifting panther himself. Failing to kill the animal, the wounded panther turns to attacking humans. The local authorities find out who is responsible for wounding the panther and Munuswamy is given four days to shoot the panther or face jail. Munuswamy's friend Kenneth Anderson arrives to help, and they head to a cave which they believe to be the panther's home. \nThe Black Panther of Sivanipalli\n\nAnderson heads to Sivanipalli on the trail of a jet black panther which has been killing local cattle. Locating the panther soon enough, Anderson struggles to make a clean shot in the dark due to the panther's fur being black. The next day Anderson follows the trail of the wounded black panther to the mouth of a cave, but in firing a further shot a bee hive opens up and Anderson is attacked by a swarm of bees. \nSnakes and Other Jungle Creatures\n\nAnderson discusses his experiences and knowledge of various Indian wildlife, from elephants and wild boar to the king cobra and Russell's viper. \nThe Killer From Hyderabad\n\nA man-eating tiger starts killing along the railway line in Chelama and over the course of three and a half years is responsible for over eighty human deaths. Anderson arrives on the scene and discovers a pattern in the kill sites, suggesting a four month cycle that the man-eater uses in passing through different locales. After sitting up over baits for many nights, Anderson finally shoots a large tiger. Anderson has his doubts that this is the man-eater, but the locals are convinced enough to drop their guard and return to normal. The man-eater strikes again, killing the wife of a local man, Bala who had also lost his father to the same man-eater. Anderson convinces the distraught man to leave his wife's body out during the night for him to sit over and await the man-eater to return. The only site for Anderson to sit in, is inside the hollow of an old rotten tree. When the tiger arrives Anderson is unable to gain a neat killing position and has to allow the tiger to eat the body of Bala's wife whilst he tries to gain a better sight. Finally Anderson manages to get some shots off, but only manages to wound the tiger. The next day he follows the tiger's blood trail, but when the trail runs out Anderson loses track of the wounded animal. Anderson returns home, and months later human kills are still being reported in the area, and Anderson is always left wondering if it is the same tiger or not. \nThe Big Bull Bison of Gedesal\n\nAnderson tells the tale of a big bull bison with a deformed, inwards pointing horn. He recounts his many encounters with the bull, ending in the scene of a huge fight the bison had with a tiger. \nThe Maned Tiger of Chordi\n\nA tiger with an outstanding ruff of hair around his neck turns man-eater, and Anderson recounts his experiences tracking the killer over a period of 5 years. \nThe Maneater of Pegepalyam\n\nAnderson visits Pegepalyam where he makes the connection of a reported man-eater to be the same tiger who started as just a mauler in his earlier story, 'The Mauler of Rajnagara' (published in his previous book 'Man Eaters and Jungle Killers'). Anderson again fails to kill the man-eater, though the tale concludes in his fourth book 'The Call of the Man Eater' (in the story, 'From Mauler to Man-Eater'). \n"}
{"id": "30220306", "url": "https://en.wikipedia.org/wiki?curid=30220306", "title": "The Celestial Railroad", "text": "The Celestial Railroad\n\n\"The Celestial Railroad\" is short story written as an allegory by American author Nathaniel Hawthorne. In it, Hawthorne parodies the seventeenth-century book \"The Pilgrim's Progress\" by John Bunyan, which portrays a Christian's spiritual \"journey\" through life. In this story, the pilgrim journeys by iron horse rather than by foot, the burden of sin that Bunyan portrays is pulled by the same train, and Bunyan's figure Evangelist, preaching a message of conversion, is replaced by a figure known as \"Mr. Smooth-it-away.\" Hawthorne mostly wrote against his own religious belief, popular at the time, Unitarianism or Transcendentalism, but according to some educators, several of his comments also indicate his dissatisfaction with Bunyan's religiously exclusive theology. In addition to this underlying view, however, he states \"we were rushing by the place where Christian's burden fell from his shoulders at the sight of the Cross...for our burdens were rich in many things esteemed precious throughout the world.\" The story ends with the traveler's relief that what he'd seen was just a dream and an element of hope that is rare in Hawthorne's romantic era literature.\n\nThe American composer Charles Ives based the second movement of his Fourth Symphony on Hawthorne's story, expanding on his earlier piece for solo piano, also entitled \"The Celestial Railroad\".\n\n"}
{"id": "54893941", "url": "https://en.wikipedia.org/wiki?curid=54893941", "title": "Travis Dixon", "text": "Travis Dixon\n\nTravis Lemar Dixon is an African-American media studies scholar and Professor of Communication at the University of Illinois at Urbana-Champaign. He is known for researching racial and religious stereotyping in television news in the United States, as well as audiences' reception of rap music.\n\n"}
{"id": "1433395", "url": "https://en.wikipedia.org/wiki?curid=1433395", "title": "Triangulation station", "text": "Triangulation station\n\nA triangulation station, also known as a triangulation pillar, trigonometrical station, trigonometrical point, trig station, trig beacon, or trig point, and sometimes informally as a trig, is a fixed surveying station, used in geodetic surveying and other surveying projects in its vicinity. The nomenclature varies regionally; they are generally known as \"trigonometrical\" or \"triangulation stations\" in North America, \"trig points\" in the United Kingdom, \"trig pillars\" in Ireland, \"trig stations\" or \"points\" in Australia and New Zealand, and \"trig beacons\" in South Africa; \"triangulation pillar\" is the more formal term for the concrete columns found in the UK.\n\nThe station is usually set up by a government with known coordinate and elevation published. Many stations are located on hilltops for the purposes of visibility. A graven metal plate on the top of a pillar may provide a mounting point for a theodolite or reflector.\n\nTrigonometrical stations are grouped together to form a network of triangulation. Positions of all land boundaries, roads, railways, bridges and other infrastructure can be accurately located by the network, a task that is essential to the construction of modern infrastructure. Apart from the known stations set up by government, some temporary trigonometrical stations are set up near construction sites for monitoring the precision and progress of construction.\n\nSome trigonometrical stations use the Global Positioning System for convenience; however, the accuracy depends on factors such as ionospheric and tropospheric propagation delay errors.\n\nAlthough stations are no longer required for many surveying purposes, they remain useful to hikers as navigational aids.\n\nA national geodetic survey and adjustment carried out in the early 1970s in Australia has left a legacy of trig stations, many consisting of a ground mark with a white quadripod supporting a black disc above the ground mark. Sometimes these trig stations are clearly visible for many kilometres and useful for hikers.\n\nIn Japan, there are five classes of :\n\nSouth Africa has a network of approximately 28,000 trig beacons, established by the (historically known as the Trigonometrical Survey). These beacons are typically white-painted concrete pillars supporting black metal plates in a cross shape, installed on mountains, hills or tall buildings.\n\nIn Spain there are 11,000 triangulation stations, concrete buildings which typically consist of a cylinder 120 cm high and 30 cm diameter over a concrete cubic base.\n\nThey were erected by the Instituto Geográfico Nacional, usually painted in white, and can be marked with a metallic label with the warning: \"The destruction of this sign is punishable by law.\"\n\nIn the United Kingdom, trig points are typically concrete pillars, and were erected by the Ordnance Survey.\n\nThe process of placing trig points on top of prominent hills and mountains began in 1935 to assist in the accurate retriangulation of Great Britain. The Ordnance Survey's first trig point was erected on 18 April 1936 near Cold Ashby, Northamptonshire. In low-lying or flat areas some trig points are only a few metres above sea level and one is even at -1 m (near Little Ouse, Cambridgeshire, TL61718 89787). When all the trig points were in place, it was possible, in clear weather, to see at least two other trig points from any one trig point, but subsequent vegetation growth means that this is not necessarily still the case. Careful measurements of the angles between the lines-of-sight of the other trig points then allowed the construction of a system of triangles which could then be referenced back to a single baseline to construct a highly accurate measurement system that covered the entire country.\n\nIn most of the UK, trig points are truncated square concrete (occasionally stone) pyramids or obelisks tapering towards the top. On the top a brass plate with three arms and a central depression is fixed: it is used to mount and centre a theodolite used to take angular measurements to neighbouring trig points. A benchmark is usually set on the side, marked with the letters \"O S B M\" (Ordnance Survey Bench Mark) and the reference number of the trig point. Within and below the visible trig point, there are concealed reference marks whose National Grid References are precisely known. The standard trig point design is credited to Brigadier Martin Hotine (1898–1968), head of the Trigonometrical and Levelling Division of the Ordnance Survey. Many of them are now disappearing from the countryside as their function has largely been superseded by aerial photography and digital mapping using lasers and GPS. To quote from a page at the OS site: \"Like an iceberg, there is more of trig pillar below the surface than above it.\" From the same source: \"Today the receivers that make up the OS Net network are coordinated to an accuracy of just 3 mm over the entire length of Great Britain.\"\n\n"}
{"id": "417063", "url": "https://en.wikipedia.org/wiki?curid=417063", "title": "V. S. Ramachandran", "text": "V. S. Ramachandran\n\nVilayanur Subramanian Ramachandran (born 10 August 1951) is a neuroscientist known primarily for his work in the fields of behavioral neurology and visual psychophysics. He is currently a Professor in the Department of Psychology and the Graduate Program in Neurosciences at the University of California, San Diego. Ramachandran is the author of several books that have garnered widespread public interest. These include \"Phantoms in the Brain\" (1998), \"A Brief Tour of Human Consciousness\" (2004) and \"The Tell-Tale Brain\" (2010).\n\nRamachandran has achieved both professional and popular recognition. He has published papers on a wide variety of topics in neuroscience. His books, interviews, and lectures have helped build public interest in contemporary neuroscience. In 2011, \"Time\" listed him as one of \"the most influential people in the world\" on the \"Time 100 list\".\n\nRamachandran (in accordance with some Tamil family name traditions, the town of his family's origin, Vilayanur, is placed first) was born in 1951 in Tamil Nadu, India. His father, V. M. Subramanian, was an engineer who worked for the U.N. Industrial Development Organization and served as a diplomat in Bangkok, Thailand. Ramachandran attended schools in Madras, and British schools in Bangkok. Ramachandran obtained an M.B.B.S. from the University of Madras in Chennai, India, and subsequently obtained a Ph.D. from Trinity College at the University of Cambridge. He then spent two years at Caltech, as a research fellow working with Jack Pettigrew. He was appointed Assistant Professor of Psychology at the University of California, San Diego in 1983, and has been a full professor there since 1998.\n\nRamachandran's early research was on human visual perception using psychophysical methods to draw clear inferences about the brain mechanisms underlying visual processing. In the early 1990s Ramachandran began to focus on neurological syndromes such as phantom limbs, body integrity identity disorder and the Capgras delusion. He has also contributed to the understanding of synesthesia and is known for inventing the mirror box. \n\nRamachandran is noted for his use of experimental methods that make relatively little use of complex technologies such as neuroimaging. Despite the apparent simplicity of his approach, he has generated many new ideas about the brain. Ramachandran has encountered skepticism about some of his theories. Ramachandran has responded that \"I have—for better or worse—roamed the whole landscape of visual perception, stereopsis, phantom limbs, denial of paralysis, Capgras syndrome, synaesthesia, and many others.\" \n\nIn addition to his academic research Ramachanran has served as a consultant in areas such as forensic psychology and the neuroscience of weight reduction. In 2007, Ramachandran served as an expert witness on pseudocyesis (false pregnancy) at the trial of Lisa M. Montgomery. Ramachandran is currently serving as a consultant to a company (Modius) that is developing weight reduction technology that relies on electrically stimulating parts of the brain that control weight loss.\n\nRamachandran is the director of a research group at the University of California, San Diego, known as the Center for Brain and Cognition. This group, made up of students and researchers from different universities, is affiliated with the Department of Psychology at UCSD. Members of the CBC have published articles on a range of emerging theories related to neuroscience. In 2012 Laura Case and Ramachancran published a theory about the possible role of brain plasticity in bigender alternation. In 2017 Baland Jalal and Ramachandran published an article in which they speculated about the role of mirror neurons in the experience of the bedroom intruder during sleep paralysis.\n\nWhen an arm or leg is amputated, patients often continue to feel vividly the presence of the missing limb as a \"phantom limb\" (an average of 80%). Building on earlier work by Ronald Melzack (McGill University) and Timothy Pons (NIMH), Ramachandran theorized that there was a link between the phenomenon of phantom limbs and neural plasticity in the adult human brain. In 1993, working with T.T. Yang who was conducting MEG research at the Scripps Research Institute, Ramachandran demonstrated that there had been measurable changes in the somatosensory cortex of a patient who had undergone an arm amputation. Ramachandran theorized that there was a relationship between the cortical reorganization evident in the MEG image and the referred sensations he had observed in other subjects. Neuroscientists continue to investigate the question of which neural processes are related to phantom limb phenomena.\n\nRamachandran is credited with the invention of the mirror box and the introduction of mirror visual feedback (mirror therapy) as a treatment for phantom limb paralysis. Ramachandran found that in some cases restoring movement to a paralyzed phantom limb reduced pain as well.\n\nSystematic reviews of the research literature on mirror therapy (MT) have arrived at conflicting conclusions about the effectiveness of MT. A 2014 review found that MT can exert a strong influence on the motor network, mainly through increased cognitive penetration in action control. However, a 2016 review concluded that the level of evidence is insufficient to recommend MT as a first intention treatment for phantom limb pain. \n\nRamachandran was one of the first scientists to theorize that grapheme-color synesthesia arises from a cross-activation between brain regions. Ramachandran and his graduate student, Ed Hubbard, conducted research with functional magnetic resonance imaging that found increased activity in the color recognition areas of the brain in synesthetes compared to non-synesthetes.\nRamachandran has speculated that conceptual metaphors may have a neurological basis in cortical cross-activation, as well. However,the neurological basis of synesthesia is not well understood.\n\nRamachandran's theories about the role of mirror neurons have attracted a great deal of discussion and debate. (Mirror neurons were first reported in a paper published in 1992 by a team of researchers led by Giacomo Rizzolatti at the University of Parma.) Ramachandran has speculated that research into the role of mirror neurons will help explain a variety of human mental capacities such as empathy, imitation learning, and the evolution of language. In 2000, Ramachandran made a prediction that \"mirror neurons will do for psychology what DNA did for biology: they will provide a unifying framework and help explain a host of mental abilities that have hitherto remained mysterious and inaccessible to experiments.\" However, over the past ten years, many of the exciting theories about mirror neurons have not held up under scrutiny. \n\nIn 1999, Ramachandran, in collaboration with then post-doctoral fellow Eric Altschuler and colleague Jaime Pineda, hypothesized that a loss of mirror neurons might be the key deficit that explains many of the symptoms and signs of autism spectrum disorders. Between 2000 and 2006 Ramachandran and his colleagues at UC San Diego published a number of articles in support of this theory, which became known as the \"Broken Mirrors\" theory of autism. Ramachandran and his colleagues did not measure mirror neuron activity directly; rather they demonstrated that children with ASD showed abnormal EEG responses (known as Mu wave suppression) when they observed the activities of other people. Ramachandran's \"broken mirrors hypothesis\" explanation for autism remains controversial.\n\nIn 2008, Ramachandran, along with David Brang and Paul McGeoch, published the first paper to theorize that apotemnophilia is a neurological disorder caused by damage to the right parietal lobe of the brain. This rare disorder, in which a person desires the amputation of a limb, was first identified by John Money in 1977. Building on medical case studies that linked brain damage to syndromes such as somatoparaphrenia (lack of limb ownership) the authors speculated that the desire for amputation could be related to changes in the right parietal lobe. In 2011 McGeoch, Brang and Ramachandran reported a functional imaging experiment involving four subjects who desired lower limb amputations. MEG scans demonstrated that their right superior parietal lobules were significantly less active in response to tactile stimulation of a limb that the subjects wished to have amputated, as compared to age/sex matched controls. The authors introduced the word \"Xenomelia\" to describe this syndrome, which is derived from the Greek for \"foreign\" and \"limb\".\n\nAs of 2014, there was no medical consensus as to the cause of this condition. \n\nRamachandran was elected to a visiting fellowship at All Souls College, Oxford (1998–1999). In addition, he was a Hilgard visiting professor at Stanford University in 2005. He has received honorary doctorates from Connecticut College (2001) and the Indian Institute of Technology, Madras (2004). Ramachandran received the annual Ramon y Cajal award (2004) from the International Neuropsychiatric Society, and the Ariëns Kappers Medal from the Royal Netherlands Academy of Sciences for his contributions to Neuroscience (1999). He shared the 2005 Henry Dale Prize with Michael Brady of Oxford, and, as part of the award was elected an honorary life member of the Royal institution for \"outstanding research of an interdisciplinary nature\". In 2007, the President of India conferred on him the third highest civilian award and honorific title in India, the Padma Bhushan. In 2014, Ramachandran was appointed an Honorary Fellow of the Royal College of Physicians.\n\n\n\n\n"}
{"id": "7217838", "url": "https://en.wikipedia.org/wiki?curid=7217838", "title": "Vancouver system", "text": "Vancouver system\n\nThe Vancouver system, also known as Vancouver reference style or the author–number system, is a citation style that uses numbers within the text that refer to numbered entries in the reference list. It is popular in the physical sciences and is one of two referencing systems normally used in medicine, the other being the author–date, or \"Harvard\", system. Vancouver style is used by MEDLINE and PubMed.\n\nHundreds of scientific journals use author-number systems. They all follow the same essential logic (that is, numbered citations pointing to numbered list entries), although the trivial details of the output mask, such as punctuation, casing of titles, and italic, vary widely among them. They have existed for over a century; the names \"Vancouver system\" or \"Vancouver style\" have existed since 1978. The latest version of the latter is \"Citing Medicine\", per the \"References > Style and Format\" section of the ICMJE Recommendations.\n\nIn the broad sense, the Vancouver system refers to any author-number system regardless of the formatting details. A narrower definition of the Vancouver system refers to a specific author-number format specified by the ICMJE Recommendations (Uniform Requirements for Manuscripts, URM). For example, the AMA reference style is Vancouver style in the broad sense because it is an author-number system that conforms to the URM, but not in the narrow sense because its formatting differs in some minor details from the NLM/PubMed style (such as what is italicized and whether the citation numbers are bracketed).\n\nAuthor–number systems have existed for over a century and throughout that time have been one of the main types of citation style in scientific journals (the other being author–date). In 1978, a committee of editors from various medical journals, the International Committee of Medical Journal Editors (ICMJE), met in Vancouver, BC, Canada to agree to a unified set of requirements for the articles of such journals. This meeting led to the establishment of the Uniform Requirements for Manuscripts Submitted to Biomedical Journals (URMs). Part of the URMs is the reference style, for which the ICMJE selected the long-established author–number principle.\n\nThe URMs were developed 15 years before the World Wide Web debuted. During those years, they were published as articles or supplements in various ICMJE member journals. These included the 1991 BMJ publication, the 1995 \"CMAJ\" publication and the 1997 \"Annals of Internal Medicine\" publication. In the late 1990s and early 2000s, journals were asked to cite the 1997 \"JAMA\" version when reprinting the \"Uniform requirements\".\n\nIn the early 2000s, with the Web having become a major force in academic life, the idea gradually took hold that the logical home for the latest edition of the URMs would be the ICMJE website itself (as opposed to whichever journal article or supplement had most recently published an update). For example, as of 2004, the editors of \"Haematologica\" decided simply to invite their authors to visit www.icmje.org for the 2003 revision of the \"Uniform requirements\".\n\nSince the early to mid-2000s, the United States National Library of Medicine (which runs MEDLINE and PubMed) has hosted the ICMJE's \"Sample References\" pages. Around 2007, the NLM created \"Citing Medicine\", its style guide for citation style, as a new home for the style's details. The ICMJE Recommendations now point to \"Citing Medicine\" as the home for the formatting details of Vancouver style. For example, in the December 2013 edition of the ICMJE Recommendations, the relevant paragraph is IV.A.3.g.ii. (\"References > Style and Format\").\n\nReferences are numbered consecutively in order of appearance in the text – they are identified by Arabic numerals in parentheses (1), square brackets [1], superscript, or a combination. The number usually appears at the end of the material it supports, and an entry in the reference list would give full bibliographical information for the source:\n\nAnd the entry in the reference list would be: 1. \n\nSeveral descriptions of the Vancouver system say that the number can be placed \"outside\" the text punctuation to avoid disruption to the flow of the text, \"or\" be placed \"inside\" the text punctuation, and that there are different cultures in different traditions. The first method is recommended by some universities and colleges, while the latter method is required by scientific publications such as the MLA and IEEE except for in the end of a block quotation. (IEEE are using Vancouver style labels within brackets, for example [1] to cite the first reference in the list, but otherwise refer to Chicago Style Manual.) The original Vancouver system documents (the ICMJE recommendations and Uniform Requirements for Manuscripts Submitted to Biomedical Journals) do not discuss placement of the citation mark.\n\nDifferent formats exist for different types of sources, e.g. books, journal articles etc. Author names are abbreviated to at most two initials. Although \"Citing Medicine\" does not explicitly mandate merging initials (e.g. \"R. K.\" would be merged into \"RK\"), the examples used throughout the book do.\n\n\nAs an option, if a journal carries continuous pagination throughout a volume (as many medical journals do), the month and issue number may be omitted.\n\n\nThe NLM lists all authors for all articles, because it is appropriate for capturing all authors and all of their publications in the MEDLINE database to be found by searches. However, in the reference lists of articles, most journals truncate the list after 3 or 6 names, followed by \"et al.\" (which most medical journals do not italicize):\n\n\nOptionally, a unique identifier (such as the article's DOI or PMID) may be added to the citation:\n\n\nNLM elides ending page numbers and uses a hyphen as the range indicating character (184-5). Some journals do likewise, whereas others expand the ending page numbers in full (184-185), use an en dash instead of a hyphen (184–5), or both (184–185).\n\nVirtually all medical journal articles are published online. Many are published online only, and many others are published online ahead of print. For the date of online publication, at the end of the citation NLM puts \"[Epub Year Mon Day]\" (for online-only publication) or \"[Epub ahead of print]\" for online ahead of print (with the month and day following the year in its normal position). In contrast, AMA style puts \"[published online Month Day, Year]\" at the end of the article title. It no longer uses the term \"Epub\" and no longer includes the words \"ahead of print\". It omits the year from its normal location after the journal title abbreviation if there is no print data to give (online-only publication).\n\nThe titles of journals are abbreviated. There are no periods in the abbreviation. A period comes after the abbreviation, delimiting it from the next field. The abbreviations are standardized. The standardization was formerly incomplete and internal to organizations such as NLM. It is now formalized at the supraorganizational level by documents including \"Citing Medicine\" at Appendix A: Abbreviations for Commonly Used English Words in Journal Titles, ANSI Z39.5, ISO 4: Information and documentation -- Rules for the abbreviation of title words and titles of publications, and the ISSN.org List of Title Word Abbreviations (LTWA).\n\nAs per journal articles in English:\n\n\nThe NLM adds an English translation of the title enclosed in square brackets right after the title. The language is specified in full after the location (pagination), followed by a period.\n\n\n\n\n\nMany medical institutions maintain their own style guides, with information on how to cite sources:\n"}
{"id": "53626404", "url": "https://en.wikipedia.org/wiki?curid=53626404", "title": "William and Mary style", "text": "William and Mary style\n\nWhat later came to be known as the William and Mary style is a furniture design common from 1700 to 1725 in the Netherlands, the Kingdom of England, the Kingdom of Scotland, and later, in England's American colonies. It was a transitional style between Mannerist furniture and Queen Anne furniture. Sturdy, emphasizing both straight lines and curves, and featuring elaborate carving and woodturning, the style was one of the first to imitate Asian design elements such as japanning.\n\nIn 1688, James II of England was deposed by his daughter, Mary, and her husband, William of Orange, in what came to be known as the \"Glorious Revolution\". From birth in 1650, William had reigned over five provinces of the Dutch Republic, and Mary had lived in the Netherlands with him after their marriage in 1677. William and Mary brought to their kingdoms a taste for Dutch furniture styles, as well as a number of Dutch furniture-makers. Although movement toward what would come to be called the William and Mary style had begun during the reign of Charles II of England, primarily due to the influence of his Portuguese-born queen, Catherine of Braganza, the style became defined and widely accepted during the reigns of William (d. 1702) and Mary (d. 1694), initially jointly and then after Mary's death, of William alone.\n\nThe William and Mary style was influenced by recent French furniture traditions, which in turn were influenced by Italian Baroque furniture designs. William and Mary style furniture emphasized unity, so that all elements contributed to an overall shape or look. It also featured high relief carving, strong curves, and elaborate woodturning. Despite these elements, the style was fairly squat, heavy-looking, and obviously sturdy. Straight lines are common. Paint, stains, or different kind of wood were used to create contrasting colors, which was another element of this style. Japanning, a technique of varnishing which was very popular at the time, was also used on this furniture design. For chairs, woven cane seats and heavily-scrolled backs predominated. Toward the end of the style, cane-woven seats and backs had given way to leather, and straight or slightly angled backs had given way to serpentine forms.\n\nOther decorative arts such as architecture, ceramics, silver, and textiles could also feature elements of the William and Mary style. The design movement had an extremely positive impact on the craftsmanship and quality of British furniture.\n\nThe William and Mary style was a transitional style between Mannerist and Queen Anne furniture. The William and Mary style was very popular in Britain from 1700 to 1725, and in America until about 1735. It was largely supplanted in both nations by Queen Anne style furniture.\n\nDaniel Marot, a French Huguenot, was employed by King William and Queen Mary to design furniture for them, and became deeply influential on English, Scottish, and Welsh furniture during this period. Dutch furniture craftsman Gerrit Jensen was appointed royal Cabinet Maker to the king and queen, and a great many works of his design were sold to wealthy British citizens of the day.\n\nIn Britain, case furniture in the William and Mary style tended to feature simple flat surfaces but exquisitely carved trim. Provincial furniture-makers in Britain moved away from the woven cane seat, and developed the leather-covered wooden seat as a vernacular design. Split spindles also came into use, first rurally and then urbanly.\n\nThe daybed was developed in Britain as part of the William and Mary style. So, too, was the writing desk, which was an adaptation of the bureau-cabinet.\n\nAmerican craftsmen working in the William and Mary style favored a tapered scroll foot for their designs. Walnut and, to a lesser extent, maple were the preferred woods, with walnut burl veneers and \"ebonization\" (black japanning) common.\n\nOver time, American forms of William and Mary furniture became simplified. Although the Baroque influence was still seen in the crests, feet, and scrolls, other elements and the overall look of pieces began to shed this influence in favor of plain but strong curves. American chairmakers began using woven cane in the splats of chairs as well. For armchairs, American designers favored seats and splats covered in leather, attached with brass nails. In parts of America like New York and New Jersey, which had a heavy Dutch cultural influence, the \"kast\" became popular. The \"kast\" was of Dutch origin, and featured a large drawer in the base unit. Atop the base were shelves concealed behind one or two heavy doors. An elaborate cornice usually ran along the upper edges. Influenced by the William and Mary style, the American \"kast\" featured removable feet, simplified the cornice, and eliminated the intricate inlays favored by the Dutch.\n\nThe \"Boston chair\" became one of the best-known examples of a William and Mary style chair made in America. This spoon-back chair with leather-covered seat and splat featured turned front legs and a turned stretcher between them. The side and rear stretcher as well as the rear legs, however, were undecorated straight lines. The corners of the frame around the splat were usually rounded down (although not turned), and the crest was a simplified geometric or curving design. They were usually painted black or red. Made primarily in Boston, Massachusetts, these chairs were manufactured in large numbers and very popular in America. They were also widely exported to Britain. Benches and settees manufactured in America were less influenced by the William and Mary style. Panels, developed in the 1600s, were used for the seat, back, and (where used) arms, with trim and legs reflecting the new style. Leather seats were, however, sometimes added.\n\nAnother innovation was the highboy. Essentially two chests of drawers, the lower slightly larger than the upper, American highboys often featured Solomonic or trumpet-shaped legs. It was somewhat common for the faces of the drawers to have a walnut burl veneer.\n\nThe William and Mary style lasted past the mid-1700s in rural America, often incorporating both Mannerist and Queen Anne styles. Slats began to be used in backs, and yoke-shaped crests became common.\n\nThe William and Mary style has long been overshadowed in both the United Kingdom and United States by the far more popular styles which came after it. Few reproductions of the furniture may be found today. However, numerous examples of William and Mary style furniture can still widely be found in British rural homes.\n\n"}
{"id": "10730759", "url": "https://en.wikipedia.org/wiki?curid=10730759", "title": "World Heritage sites of Sri Lanka", "text": "World Heritage sites of Sri Lanka\n\nEight sites of Sri Lanka have been inscribed in the UNESCO World Heritage, namely, the ancient city of Polonnaruwa (1982), the ancient city of Sigiriya (1982), the Golden Temple of Dambulla (1991), the old town of Galle and its fortifications (1988), the sacred city of Anuradhapura (1982), the sacred city of Kandy (1988), Sinharaja Forest Reserve (1988) and the Central Highlands of Sri Lanka (2010).\n\nThe Sri Dalada Maligawa or The Temple of the Sacred Tooth Relic is a temple in the city of Kandy in Sri Lanka. It was built within the royal palace complex which houses the tooth relic of the Buddha, a tooth, which is venerated by Buddhists. The relic has played an important role in the local politics since ancient times, it's believed that whoever holds the relic holds the governance of the country, which caused the ancient kings to protect it with great effort. Kandy was the capital of the Sinhalese Kings from 1592 to 1815, fortified by the terrain of the mountains and the difficult approach. The city is a world heritage site declared by UNESCO, in part due to the temple.\n\nMonks of the two chapters of Malwatte and Asgiriya conduct daily ritual worship in the inner chamber of the temple, in annual rotation. They conduct these services three times a day: at dawn, at noon and in the evening.\n\nOn Wednesdays there is a symbolic bathing of the Sacred Relic with an herbal preparation made from scented water and flagrant flowers, called Nanumura Mangallaya. This holy water is believed to contain healing powers and is distributed among those present.\n\nThe Temple has sustained damage from multiple bombings by terrorists in the past, but has been fully restored each time..\n\nSigiriya, considered by some as the eighth wonder of the world, consists of an ancient castle used by King Kashyapa of the 5th century AD. The Sigiriya site has the remains of an upper Sky Palace sited on the flat top of the rock, a mid-level terrace that includes the Lion Gate and the Mirror Wall and the Sigiriya Frescoes, the lower palace that clings to the slopes below the rock, and the moats, walls and gardens that extend for some hundreds of metres out from the base of the rock.\n\nThe site is both a palace and fortress. Sufficient remains to provide the visitor with a stunning insight into the ingenuity and creativity of its builders.\n\nThe upper palace on the top of the rock includes cisterns cut into the rock that still retain water. The moats and walls that surround the lower palace are still exquisitely beautiful.\n\nAnuradhapura, (අනුරාධපුර in Sinhala), is the first ancient capital of Sri Lanka which lasted for the longest period as the capital in the country.It is important to locals for religion, history, and the culture and world-famous for its well preserved ruins of the Great Sri Lankan Civilization. The Civilization which was built upon this city was one of the greatest civilizations of Asia and in the world. The city now a UNESCO heritage site, lies north of the current capital Colombo in the North Central Province of Sri Lanka, on the banks of the historic Malwathu Oya. Founded in the 4th century BC, it was the capital of the Anuradhapura Kingdom until the beginning of the 11th century CE. During this period it remained one of the most stable and durable centers of political power and urban life in South Asia. It was also a wealthy city which created a unique culture and a great civilization. Today this ancient city of Sri Lanka, which is sacred to the Buddhist world, which its surrounding monasteries covers an area of over sixteen square miles (40 km²) and is one of the world's major archaeological sites\n\nGalle (; , , ) is a town situated on the southwestern tip of Sri Lanka, from Colombo. Galle was known as Gimhathiththa (although Ibn Batuta in the 14th century refers to it as Qali) before the arrival of the Portuguese in the 16th century, when it was the main port on the island. Galle reached the height of its development in the 18th century, before the arrival of the British, who developed the harbor at Colombo.\n\nOn 26 December 2004 the city was devastated by the massive Boxing Day tsunami caused by the 2004 Indian Ocean earthquake that occurred a thousand miles away, off the coast of Indonesia. Thousands were killed in the city alone.\n\nThe second most ancient of Sri Lanka's kingdoms, Polonnaruwa was first declared the capital city by King Vijayabahu I, who defeated the Chola invaders in 1070 CE to reunite the country once more under a local leader. While Vijayabahu's victory and shifting of Kingdoms to the more strategic Polonnaruwa is considered significant, the real Polonnaruwa Hero of the history books is actually his grandson, Parakramabahu I. The city Polonnaruwa was also called as Jananathamangalam during the short Chola reign.\n\nHowever, with the exception of his immediate successor, Nissankamalla I, all other monarchs of Polonnaruwa were slightly weak-willed and rather prone to picking fights within their own court. They also went on to form more intimiate matrimonial alliances with stronger South Indian Kingdoms, until these matrimonial links superseded the local royal lineage and gave rise to the Kalinga invasion by King Magha in 1214 and the eventual passing of power into the hands of a Pandyan King following the Arya Chakrawarthi invasion of Sri Lanka in 1284. The capital was then shifted to Dambadeniya.\n\nToday the ancient city of Polonnaruwa remains one of the best planned archeological relic sites in the country, standing testimony to the discipline and greatness of the kingdom's first rulers.\n\nDambulla Cave temple\n(also known as the Golden Temple of Dambulla) is a world heritage site (1991) in Sri Lanka, situated in the central part of the country. This site is situated east of Colombo and north of Kandy. It is the largest and best-preserved cave temple complex in Sri Lanka. The rock towers over the surrounding plains.There are more than 80 documented caves in the surrounding. Major attractions are spread over 5 caves, which contain statues and paintings. This paintings and statues are related to Lord Buddha and his life. There are total of 153 Buddha statues, 3 statues of Sri Lankan kings and 4 statues of gods and goddesses. The later 4 include two statues of Hindu gods, god Vishnu and god Ganesh. The murals, covers an area of 2,100 square meters. Depictions in the walls of the caves include Buddha's temptation by Mara (demon) and Buddha's first sermon.\n\nSinharaja Forest Reserve is a national park in Sri Lanka. It is of international significance and has been designated a Biosphere Reserve and World Heritage Site by UNESCO.\nThe hilly virgin rainforest, part of the Sri Lanka lowland rain forests ecoregion, was saved from the worst of commercial logging by its inaccessibility, and was designated a World Biosphere Reserve in 1978 and a World Heritage Site in 1989. The reserve's name translates as Kingdom of the Lion.\n\nThe reserve is only from east to west, and a maximum of from north to south, but it is a treasure trove of endemic species, including trees, insects, amphibians, reptiles, birds and mammals.\n\nBecause of the dense vegetation, wildlife is not as easily seen as at dry-zone national parks such as Yala. There are no elephants, and the 15 or so leopards are rarely seen. The most common larger mammal is the endemic Purple-faced Langur.\n\nThis site comprises the Peak Wilderness Protected Area, the Horton Plains National Park and the Knuckles Conservation Forest. Central Highlands was added to the list in 2010 and qualified because of its biodiversity.\n\n\n"}
{"id": "23364375", "url": "https://en.wikipedia.org/wiki?curid=23364375", "title": "World Oral Literature Project", "text": "World Oral Literature Project\n\nThe World Oral Literature Project was \"an urgent global initiative to document and disseminate endangered oral literatures before they disappear without record\". Directed by Dr Mark Turin and co-located at the Museum of Archaeology and Anthropology, at the University of Cambridge and Yale University, the project was established in January 2009.\n\nFrom March 2013 the organization ceased funding projects, whilst maintaining online resources.\n\nThe World Oral Literature Project provided small grants to fund the collecting of oral literature, with a particular focus on the peoples of Asia and the Pacific, and on areas of cultural disturbance. In addition, the Project hosted training workshops for grant recipients and other engaged scholars. The World Oral Literature Project also publishes oral texts and occasional papers, and makes collections of oral traditions accessible through online media platforms such as Cambridge Streaming Media Service and DSpace.\n\nFourteen funded oral literature fieldwork and documentation projects were completed between 2009-2013.\n\nThe World Oral Literature Project collected data gathered by grantees and anthropology fieldworkers as well as historic collections. This data is primarily audio and visual files that are either born digital or are digitised by the Project. This material is archived using DSpace and, where culturally appropriate, disseminated to the public through the World Oral Literature Project websites and streaming media services.\n\nPapers published by the World Oral Literature Project and Open Book Publishers:\n\nResearchers at the World Oral Literature Project have compiled a database of language endangerment levels, including references to collections and recordings of oral literature that exist in archives around the world. Data on language endangerment are drawn from the \"online Ethnologue\", the \"UNESCO Atlas of the World’s Languages in Danger\", and from a 'red list' compiled by Professor William Sutherland in the Department of Zoology at the University of Cambridge.\n\nHowever the project states \"The World Oral Literature Project does not take responsibility for the accuracy of the materials that our researchers have compiled from these three sources, and the Project does not have the staffing capacity to keep these resources up to date.\".\n\n\n"}
{"id": "25501679", "url": "https://en.wikipedia.org/wiki?curid=25501679", "title": "Yohanan Levi", "text": "Yohanan Levi\n\nYohanan Levi (; 1901 – 20 July 1945) was a Hebrew linguist and historian, specialising in the Second Temple period.\n\nLevi was born in Berlin, Germany in 1901. He studied at Berlin University and received a doctorate in 1926. He emigrated to Mandate Palestine (now Israel) in 1934 and taught at the Hebrew University of Jerusalem, where he was professor of Roman language and literature. He died, age 44, in 1945. A number of his articles were collected by his students and published some fifteen years after his death.\n\n\n"}
