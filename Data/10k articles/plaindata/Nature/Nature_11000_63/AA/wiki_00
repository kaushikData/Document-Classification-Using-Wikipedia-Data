{"id": "29637793", "url": "https://en.wikipedia.org/wiki?curid=29637793", "title": "Aerospace materials", "text": "Aerospace materials\n\nAerospace materials are materials, frequently metal alloys, that have either been developed for, or have come to prominence through, their use for aerospace purposes.\n\nThese uses often require exceptional performance, strength or heat resistance, even at the cost of considerable expense in their production or machining. Others are chosen for their long-term reliability in this safety-conscious field, particularly for their resistance to fatigue.\n\nThe field of materials engineering is an important one within aerospace engineering. Its practice is defined by the international standards bodies who maintain standards for the materials and processes involved. Engineers in this field may often have studied for degrees or post-graduate qualifications in it as a speciality.\n\nThe first aerospace materials were those long-established and often naturally occurring materials used to construct the first aircraft. These included such mundane materials as timber for wing structures and fabric and dope to cover them. Their quality was of utmost importance and so the timber would be of carefully selected sitka spruce and the covering of irish linen. Standards were required for the selection, manufacture, and use of these materials. These standards were developed informally by manufacturers or government groups such as HM Balloon Factory, later to become RAE Farnborough, often with the assistance of university engineering departments.\n\nThe next stage in the development of aerospace materials was to adopt newly developed materials, such as Duralumin the first age hardening aluminium alloy. These offered attributes not previously available. Many of these new materials also required study to determine the extent of these new properties, their behaviour and how to make the best use of them. This work was often carried out through the new government-funded national laboratories, such as the \"\" (German Imperial Institute) or the British National Physical Laboratory (NPL).\n\nThe NPL was also responsible for perhaps the first deliberately engineered aerospace material, Y alloy. This first of the nickel-aluminium alloys was discovered after a series of experiments during World War I, deliberately setting out to find a better material for the manufacture of pistons for aircraft engines.\n\nBetween the wars, many aerospace innovations were in the field of manufacturing processes, rather than just an inherently stronger material, although these too benefited from improved materials. One of the R.R. alloys, R.R.53B, had added silicon which improved its fluidity when molten. This allowed its use for die casting as well as the previous sand casting, a means of making parts that were both far cheaper and also more accurate in shape and finish. Better control of their shape allowed designers to shape them more precisely to their tasks, leading to parts that were also thinner and lighter.\n\nMany interwar developments were to aircraft engines, which benefited from the vast improvements being made for the growing car industry. Although not strictly an 'aerospace' innovation, the use of refractory alloys like Stellite and Brightray for the hard-facing of exhaust valves offered huge gains in the reliability of aircraft engines. This itself encouraged long-range commercial flights, as the new engines were reliable enough to be considered safe for long flights across oceans or mountain ranges.\n\nThe de Havilland \"Albatross\" airliner of 1936 had a fuselage of wooden sandwich construction: wafers of birch plywood were spaced apart by a balsa sheet. This same construction achieved fame with its wartime use in the \"Mosquito\" fast bomber. As well as being a construction of light weight and high performance, it also avoided the use of aluminium, a strategic material during wartime, and could use the skills of woodworkers, rather than those of specialised aircraft metalworkers. When Germany attempted to copy this aircraft as the \"Moskito\" it was a failure, primarily for materials reasons. The original phenolic \"Tego film\" adhesive was only produced by a factory that was destroyed by bombing. Its replacement led directly to catastrophic failures and loss of the aircraft.\n\nRadar became small enough to be carried on board aircraft, but the fragile feed horns and reflectors needed to be protected and streamlined from the airstream. Moulded radomes were constructed, using the Perspex acrylic plastic that was already in use for cockpit windows. This could be heated to soften it, then moulded or vacuum formed to shape. Other polymers developed at this time, notably Nylon, found uses in compact radio equipment as high-voltage insulators or dielectrics.\n\nHoneycomb structures were developed as flat sandwich sheets used for bulkheads and decking. These were long established with wood and paper board construction, but required a more robust material for aerospace use. This was achieved towards the end of the war, with all-aluminium honeycomb sandwiches.\n\nNew lightweight materials include Ceramic matrix composites, metal matrix composites, polymer aerogels and CNT-yarns, along the evolution of polymer composites.\n\nThe term \"aerospace grade\" has come to be a fashionable marketing slogan for luxury goods, particularly for cars and sporting goods. Bicycles, golf clubs, sailing yachts and even torches are all sold on the basis of their high-performance materials, whether these are relevant or not. Since their appearance in 1979, Maglite have advertised their use of 6061 aluminium for their torch bodies, one of the first to make a deliberate feature of aerospace materials for a non-performance reason.\n\nSome sporting uses have been for the material's actual qualities. Many ski makers have produced skis wholly from cloth and resin composite materials, using the tailorability of such construction to vary the stiffness, damping and torsional stiffness of a ski along its length. Hexcel, a manufacturer of aluminium honeycomb sheet, became well known for its branded skis, using this same advanced material.\n\nSporting uses may be every bit as demanding as aerospace needs. Particularly in cycling, materials may be loaded \"more\" highly than in aerospace use, the risk of possible failure being seen as more acceptable than for aircraft.\n\nMany uses of aerospace materials for sporting goods have been as the result of a 'peace dividend'. After World War II, Hiduminium alloy appeared in bicycle brake components as its maker sought to expand new markets to replace their previous military aircraft. In the 1990s, both smelters and recyclers of titanium sought new non-military markets after the end of the Cold War, finding them in both bicycle frames and golf clubs.\n\nCarbon fibre composite, and its distinctive weave pattern, has become a popular decorative choice on cars and motorbikes, even in purely decorative contexts such as dashboards. This has extended to the use of flexible stick-on patterned vinyl to skeuomorphically reproduce the appearance, without any of the physical properties.\n"}
{"id": "30875386", "url": "https://en.wikipedia.org/wiki?curid=30875386", "title": "Agência Brasil", "text": "Agência Brasil\n\nAgência Brasil (ABR) is the national public news agency, run by the Brazilian government. It is a part of the public media corporation Empresa Brasil de Comunicação (EBC), created in 2007 to unite two government media enterprises Radiobrás and TVE (Televisão Educativa). It is publishing contents under CC-BY.\n\nABr is one of the most important Brazilian news agencies, that feeds thousands of regional newspapers and websites throughout Brazil but also national media outlets like Estadao, O Globo, Folha de S.Paulo, UOL and Terra.\n\nIts headquarters are located in Brazilian capital, Brasília. There are also two regional offices located in São Paulo and Rio de Janeiro.\n\n"}
{"id": "49660332", "url": "https://en.wikipedia.org/wiki?curid=49660332", "title": "Analysis of similarities", "text": "Analysis of similarities\n\nAnalysis of similarities (ANOSIM) is a non-parametric statistical test widely used in the field of ecology. The test was first suggested by K. R. Clarke as an ANOVA-like test, where instead of operating on raw data, operates on a ranked dissimilarity matrix.\n\nGiven a matrix of rank dissimilarities between a set of samples, each solely belong to one treatment group, the ANOSIM tests whether we can reject the null hypothesis that the similarity between groups is greater than or equal to the similarity within the groups.\n\nThe test statistic \"R\" is calculated in the following way:\n\nwhere is the average of rank similarities of pairs of samples (or replicates) originating from different sites, is the average of rank similarity of pairs among replicates within sites, and \"M\" = \"n\"(\"n\" − 1)/2 where \"n\" is the number of samples.\n\nThe test statistic \"R\" is constrained between the values −1 to 1, where positive numbers suggest more similarity within sites and values close to zero represent no difference between within sites and within sites similarities. Negative \"R\" values suggest more similarity between sites than within sites and may raise the possibility of wrong assignment of samples to sites.\n\nFor the purpose of hypothesis testing, where the null hypothesis is that the similarities within sites are smaller or equal to the similarities between sites, the \"R\" statistic is usually compared to a set of \"R′\" values that are achieved by means of randomly shuffling site labels between the samples and calculating the resulting \"R′\", repeated many times. The percent of times that the actual \"R\" surpassed the permutations derived \"R′\" values is the p-value for the actual \"R\" statistic.\n\nRanking of dissimilarity in ANOSIM and NMDS (non-metric multidimensional scaling) go hand in hand.\nCombining both methods complement visualisation of group differences along with significance testing.\n\nANOSIM is implemented in several statistical software including PRIMER, R Vegan package and PAST.\n\n"}
{"id": "18836858", "url": "https://en.wikipedia.org/wiki?curid=18836858", "title": "Antiferroelectricity", "text": "Antiferroelectricity\n\nAntiferroelectricity is a physical property of certain materials. It is closely related to ferroelectricity; the relation between antiferroelectricity and ferroelectricity is analogous to the relation between antiferromagnetism and ferromagnetism.\n\nAn antiferroelectric material consists of an ordered (crystalline) array of electric dipoles (from the ions and electrons in the material), but with adjacent dipoles oriented in opposite (antiparallel) directions (the dipoles of each orientation form interpenetrating sublattices, loosely analogous to a checkerboard pattern). This can be contrasted with a ferroelectric, in which the dipoles all point in the same direction.\n\nIn an antiferroelectric, unlike a ferroelectric, the total, macroscopic spontaneous polarization is zero, since the adjacent dipoles cancel each other out.\n\nAntiferroelectricity is a property of a material, and it can appear or disappear (more generally, strengthen or weaken) depending on temperature, pressure, external electric field, growth method, and other parameters. In particular, at a high enough temperature, antiferroelectricity disappears; this temperature is known as the Néel point or Curie point.\n"}
{"id": "1743216", "url": "https://en.wikipedia.org/wiki?curid=1743216", "title": "Antipodes Subantarctic Islands tundra", "text": "Antipodes Subantarctic Islands tundra\n\nThe Antipodes Subantarctic Islands tundra ecoregion, within the Tundra Biome, includes five remote island groups in the Southern Ocean south of New Zealand: the Bounty Islands, Auckland Islands, Antipodes Islands and Campbell Island groups of New Zealand, and Macquarie Island of Australia.\n\nThe islands comprising this ecoregion share a long history of isolation, both from other landmasses and each other. The isolation, combined with harsh climates characterised by low temperatures, strong westerly winds and few hours of sunlight in winter, have resulted in the evolution of many endemic plants and animals, though species richness is relatively low. Wind speeds reach an average of while even in summer the thick cloud cover prevents much sunlight from penetrating.\nThe Bounty Islands are small granite rocks (with a maximum height of ), while the small Antipodes Islands group (maximum height 366m), the largest group the Auckland Islands () and Campbell Island () are volcanic in origin. Macquarie Island () is the furthest south and the coldest. Where present, soils are mainly boggy peats, up to deep in flat areas. None of the islands are inhabited although there are ongoing research projects including a permanent base of the Australian Antarctic Division on Macquarie Island.\n\nVegetation may include low forests of Southern rātā in the more sheltered areas of the Aucklands and parts of Campbell Island, with tussock grassland, shrubland, herbfield, feldmark and cushion plants elsewhere. The islands represent a transition zone between the Antarctic to the south and temperate climates to the north. Individual species include many endemics, such as a \"Cyathea\" tree fern, which are not found any further south in the world, along with others that also occur in New Zealand and further north. Macquarie Island, being colder (average annual temperature ), does not sustain any wooded plants, while the small Bounty Islands lack soils and their flora is largely restricted to algae and lichens on the rocks. The islands are home to a number of rare plants, including a unique genus, the Auckland Island \"Pleurophyllum\", and the only subantarctic orchids, \"Nematoceras dienemum\" and \"Nematoceras sulcatum\" of Macquarie Island.\n\nThere are no native land mammals, nor amphibians or reptiles. Marine mammals include five breeding species of seal; the southern elephant seal, Australasian fur seal, subantarctic fur seal, Antarctic fur seal and the rare New Zealand sea lion, 95% of the world's population of which breed on the Auckland Islands. \n\nThere are also large numbers of breeding penguins and other seabirds, including almost half of the world's species of albatross, especially the world's only breeding colonies of the Antipodean albatross (\"Diomedea exulans antipodensis\"), southern royal albatross (\"Diomedea epomophora epomophora\"), Campbell albatross (\"Thalassarche impavida\"), white-capped albatross (\"Thalassarche steadi\"), and Salvin's albatross (\"Thalassarche salvini\"). The large colonies of Salvin's albatross on the Bounty Islands build nests of feathers as there is no vegetation to use. There are also isolated populations of land birds that have presumably settled here, having been blown off course by ocean winds. Many of these have since evolved into unique species, including two endemic parakeets on Antipodes Island; the Antipodes parakeet (\"Cyanoramphus unicolor\") and Reischek's parakeet (\"Cyanoramphus hochstetteri\"). \n\nSimilarly, a high proportion of the Lepidoptera and other insects of the islands have evolved into unique endemic species. \n\nA number of species have disappeared since the islands were discovered by humans, including the Macquarie Island rail and the Macquarie Island parakeet.\n\nAlthough the islands have been partially occupied at various times the habitats remain largely unspoilt. However introduced animals prey on native wildlife and graze on the plant cover while both mammals and seabirds are vulnerable to entanglement in deep-sea fishing equipment. Longline fishing for tuna and trawling for squid are particularly damaging. \n\nCurrent predators on the islands include rats and cats and these are being systematically removed while cautionary procedures are in place to prevent more alien species becoming established. All cats have now been removed from Macquarie Island and there appears to have been an immediate increase in some seabird populations. All the islands are nature reserves, World Heritage Sites and (except for the Bounty Islands) a Centre of Plant Diversity. Permission to land must be obtained from the Department of Conservation (New Zealand) for the New Zealand islands and the Tasmania Parks and Wildlife Service for Macquarie.\n"}
{"id": "13904287", "url": "https://en.wikipedia.org/wiki?curid=13904287", "title": "Chiemgau impact hypothesis", "text": "Chiemgau impact hypothesis\n\nChiemgau impact hypothesis is an obsolete scientific theory that claimed the Tüttensee lake in southern Bavaria, Germany, to be the result of an Holocene meteorite impact. This claim has been refuted by geological research and the finding of a soil horizon of undisturbed peat and sedimentation since the end of the last glaciation period. The lake is in fact one of many kettles under the foothills of the Bavarian alps.\n\nThe claims of an impact crater had been raised by a team of hobby-archaeologists, calling themselves the CIRT (Chiemgau impact research team), and have resulted in some media reports in Germany and discussions in the local tourism industry, but are not accepted beyond the CIRT team today. \n"}
{"id": "24709684", "url": "https://en.wikipedia.org/wiki?curid=24709684", "title": "Colloidal fuel", "text": "Colloidal fuel\n\nColloidal fuel is an emulsion of powdered coal in kerosene. It was used in World War I aboard ships as kerosene supplies ran low.\n"}
{"id": "52228281", "url": "https://en.wikipedia.org/wiki?curid=52228281", "title": "Energy in the Faroe Islands", "text": "Energy in the Faroe Islands\n\nEnergy in the Faroe Islands is produced primarily from fossil fuels, with further contributions from hydro and wind power. Oil products are the main energy source, mainly consumed by fishing vessels and sea transport. Electricity is produced by oil, hydropower and wind farms, mainly by the SEV, which is owned by all the municipalities of the Faroe Islands. The Faroe Islands are not connected by power lines with continental Europe, and thus the archipelago cannot import or export electricity.\n\nPer capita annual consumption of primary energy in the Faroe Islands was 67 MWh in 2011, almost 60% above the comparable consumption in continental Denmark. After taking a dip in the early 1990s the electricity production in the Faroe Islands has steadily been on the rise since then, going from 174,422 MWh in 1994 to 314,409 MWh in 2015. Wind power was introduced in 1993, producing as little as 423 MWh at first, but rising to 55,789 MWh by 2015. The energy sector employed 154 people or 0.6% of the islands' total workforce as of November 2015.\n\nThe islands have 6 hydroelectric plants, 4 diesel plants and several wind power plants with a capacity factor above 40%. Demand (and thus, production) varies between 15 MW at night and 40 MW at daytime peak. In 2014, the DKK 180 million 12MW Húsahagi wind farm with Enercon turbines became operational near Torshavn and increased wind capacity from 6.6 to 18.6MW; this decreased oil consumption by 8,000 ton (approximately 4M€) per year. A 2.3MW 700kWh lithium-ion battery at €2 million near Húsahagi became operational in 2016.\n\nPlanners also consider converting the existing hydropower to pumped-storage hydroelectricity, as rain and wind are high in winter and low in summer. Tidal power and thermal energy storage solutions are also being considered, as the islands have a goal of 100% green electricity production by 2030.\n\nThe municipality-owned company SEV is the main electricity supplier in the Faroe Islands with 97% of the total production, with private producers supplying the rest.\nThe main electricity grid on the Faroe Islands has the highest voltage of 60 kiloVolt, of which there is 90 km overhead wire and 6 km cable. The 20kV system is 460 km and reaches most towns in the main islands, whereas the 10 kV system covers the connected outlying islands, and Torshavn. Due to extreme weather conditions and its lack of interconnections, the Faroe Islands experience one to three total blackouts annually, a ratio higher than that of continental Europe. Most of the powerlines have therefore been buried underground as cables for better protection, improving grid stability. When SEV detects grid issues, automatic demand response at large consumers reduce consumption to increase grid stability.\nSuðuroy has its own grid with 20 and 10 kV, and is powered by the 3.3 MW Botnur power plant and 8 MW diesel at Vágur and 2 MW at Trongisvágur.\n\nFugloy, Hestur, Mykines, Skúvoy and Stóra Dímun are not part of the main grid, and are electrified through their own fossil fuel powerplants.\n\nIn 2014 50.8% of the electricity production of SEV in the Faroe Islands came from green energy like hydro (mostly Eiði and Vestmanna) and wind, while 49.2% was produced by the thermal power plants, which was 12.4% less than in 2013.\n\nTotal annual production: 305.4 GWh (2014) of which the production of thermal, hydropower and wind power was:\n\nIn 2014, 217,547 tonnes of oil products were consumed in the Faroe Islands. Of these, 31.58% was consumed by fishing vessels, 14.73% was used by SEV for electricity production, 23.23% was consumed in air, sea or land transport, 9.6% was used in the industry, and the rest was used by public or private buildings. Oil and gas exploration has been taking place around the Faroe Islands since 2001, with the expectation that significant oil reserves will be found.\n\nThere are coal reserves on Suðuroy, which were considered for energy production. The reserves are between 10 and 15 million tonnes and they could replace oil in the Sund power-station for 100 years.\n\nThe Faroe Islands have set a goal of producing their entire electrical energy needs from renewable energy sources by 2030. Since energy consumption has been rising steadily during the last few decades, the \"Ministry of Trade and Industry\" has conducted a study for the future development of electricity production projects. Apart from the development of new hydropower plants and wind farms, the study proposes the investigation of the possibility to produce electricity from LNG and biogas. The University of the Faroe Islands has undertaken research into the feasibility of tidal power at several sites which have a high energy potential, leading the Ministry of Trade and Industry to consider tidal power as a possibility. The privatisation of electricity production was not promoted, although consideration was given to introducing competition and transparency into electricity production.\n\n\n"}
{"id": "10257677", "url": "https://en.wikipedia.org/wiki?curid=10257677", "title": "Hardy Perennials and Old Fashioned Flowers", "text": "Hardy Perennials and Old Fashioned Flowers\n\nHardy Perennials and Old Fashioned Flowers — Describing the Most Desirable Plants, for Borders, Rockeries, and Shrubberies is a horticulture and gardening book published in 1884 by John Wood. \n\nThe book was also published by the Project Gutenberg Literary Archive Foundation in 2006.\n"}
{"id": "41191476", "url": "https://en.wikipedia.org/wiki?curid=41191476", "title": "Hiärneite", "text": "Hiärneite\n\nHiärneite is an oxide mineral named after the Swedish geologist Urban Hiärne (1641-1727). The mineral can be found in rocks that mainly consists of fine grained phlogopite. Hiärneite is the first known mineral that contains both of the chemical elements antimony and zirconium. The mineral was described in 1997 for its occurrence in a skarn environment in Långban iron–manganese deposit of the Filipstad district, Värmland, Sweden.\n"}
{"id": "34022009", "url": "https://en.wikipedia.org/wiki?curid=34022009", "title": "Ilgaz Mountains", "text": "Ilgaz Mountains\n\nIlgaz Mountains () is a mountain range in northwest Anatolia, Turkey.\n\nIn west Black Sea region, there are three ranges of mountains, which run parallel to the Black Sea coast. Ilgaz Mountains constitute the eastern part of the second range from the coast line at an average distance of . The northern slopes of the mountains are in Kastamonu Province and the southern slopes are in Çankırı Province. The length of the mountain system from west to east is about with a width of about . Situated at , the mountain peak, known as \"Hacettepe\", is high. The state highway , which connects Black Sea coast to Central Anatolia is west of the peak. The altitude of the highest pass on the highway is .\n\nThe Mount Ilgaz National Park () at the west of the highway pass was opened on June 2, 1976 and is easily accessible from the highway . Total area of the park is . At the highest elevation of the park, there are a number of hotels servicing to skiers. The skiers may use a long chairlift to the ski area. The distance from Ankara is , which makes the park nearest winter sports resort to the capital city citizens. During the summertime, the visitors may fish in the Baldıran Valley within the national park.\n\nIlgaz Mountains, especially the northern slopes, are covered with dense forestry. The popular name of the forestry around Ilgaz Mountains is \"sea of trees\" (). Some of the wild animals living in the wooded ranges are red deer, roe deer, fallow deer, wild boar, brown bear, gray wolf, European jackal, chamois and red fox. In 1996, a new insect species was discovered in Ilgaz Mountain ecology and in 2010 it was named as \"Merodon Ilgazense\".\n\nThe theme of a popular song \"Ilgaz\" composed by Ahmet Samim Bilgen and lyrics by Cemil Türkarman is about Ilgaz Mountains.\n"}
{"id": "1352320", "url": "https://en.wikipedia.org/wiki?curid=1352320", "title": "Interplanetary medium", "text": "Interplanetary medium\n\nThe interplanetary medium is the material which fills the Solar System, and through which all the larger Solar System bodies, such as planets, dwarf planets, asteroids, and comets, move.\n\nThe interplanetary medium includes interplanetary dust, cosmic rays and hot plasma from the solar wind. The temperature of the interplanetary medium varies. For dust particles within the asteroid belt, typical temperatures range from 200 K (−73 °C) at 2.2 AU down to 165 K (−108 °C) at 3.2 AU.\nThe density of the interplanetary medium is very low, about 5 particles per cubic centimeter in the vicinity of the Earth; it decreases with increasing distance from the Sun, in inverse proportion to the square of the distance. It is variable, and may be affected by magnetic fields and events such as coronal mass ejections. It may rise to as high as 100 particles/cm³.\n\nSince the interplanetary medium is a plasma, it has the characteristics of a plasma, rather than a simple gas; for example, it carries with it the Sun's magnetic field, is highly electrically conductive (resulting in the heliospheric current sheet), forms plasma double layers where it comes into contact with a planetary magnetosphere or at the heliopause, and exhibits filamentation (such as in aurorae).\n\nThe plasma in the interplanetary medium is also responsible for the strength of the Sun's magnetic field at the orbit of the Earth being over 100 times greater than originally anticipated. If space were a vacuum, then the Sun's 10 tesla magnetic dipole field would reduce with the cube of the distance to about 10 tesla. But satellite observations show that it is about 100 times greater at around 10 tesla. Magnetohydrodynamic (MHD) theory predicts that the motion of a conducting fluid (e.g., the interplanetary medium) in a magnetic field induces electric currents which in turn generate magnetic fields, and in this respect it behaves like an MHD dynamo.\n\nThe outer edge of the Solar System is the boundary between the flow of the solar wind and the interstellar medium. This boundary is known as the heliopause and is believed to be a fairly sharp transition of the order of 110 to 160 astronomical units from the Sun. The interplanetary medium thus fills the roughly spherical volume contained within the heliopause.\n\nHow the interplanetary medium interacts with planets depends on whether they have magnetic fields or not. Bodies such as the Moon have no magnetic field and the solar wind can impact directly on their surface. Over billions of years, the lunar regolith has acted as a collector for solar wind particles, and so studies of rocks from the Moon's surface can be valuable in studies of the solar wind.\n\nHigh energy particles from the solar wind impacting on the Moon's surface also cause it to emit faintly at X-ray wavelengths.\n\nPlanets with their own magnetic field, such as the Earth and Jupiter, are surrounded by a magnetosphere within which their magnetic field is dominant over the Sun's. This disrupts the flow of the solar wind, which is channelled around the magnetosphere. Material from the solar wind can 'leak' into the magnetosphere, causing aurorae and also populating the Van Allen Belts with ionised material.\n\nThe interplanetary medium is responsible for several effects which can be seen from Earth. The Zodiacal light is a broad band of faint light sometimes seen after sunset and before sunrise, stretched along the ecliptic and brightest near the horizon. It is caused by sunlight scattering off dust particles in the interplanetary medium between the Earth and the Sun.\n\nA similar effect is the Gegenschein, which is seen directly opposite to the Sun's position in the sky. It is much fainter than the Zodiacal light, and is caused by sunlight reflecting off dust particles outside the Earth's orbit.\n\nThe term \"interplanetary\" appears to have been first used in print in 1691 by the scientist Robert Boyle: \"The air is different from the æther (or vacuum) in the... interplanetary spaces\" Boyle \"Hist. Air\".\n\nThe notion that space is considered to be a vacuum filled with an \"aether\", or just a cold, dark vacuum continued up until the 1950s (see below).\n\nIn 1898, American astronomer Charles Augustus Young wrote: \"Inter-planetary space is a vacuum, far more perfect than anything we can produce by artificial means...\" (\"The Elements of Astronomy\", Charles Augustus Young, 1898).\n\nAnd Akasofu recounted that: \"The view that interplanetary space is a vacuum into which the Sun intermittently emitted corpuscular streams was changed radically by Ludwig Biermann (1951, 1953) who proposed on the basis of comet tails, that the Sun continuously blows its atmosphere out in all directions at supersonic speed\" (Syun-Ichi Akasofu, \"Exploring the Secrets of the Aurora\", 2002)\n\nTufts University Professor of astronomy, Kenneth R. Lang, writing in 2000 noted, \"Half a century ago, most people visualized our planet as a solitary sphere traveling in a cold, dark vacuum of space around the Sun\".\n\n\n"}
{"id": "24755469", "url": "https://en.wikipedia.org/wiki?curid=24755469", "title": "Island ecology", "text": "Island ecology\n\nIsland ecology is the study of island organisms and their interactions with each other and the environment. Islands account for nearly 1/6 of earth’s total land area, yet the ecology of island ecosystems is vastly different from that of mainland communities. Their isolation and high availability of empty niches leads to increased speciation. As a result, island ecosystems comprise 30% of the world’s biodiversity hotspots, 50% of marine tropical diversity, and some of the most unusual and rare species. Many species still remain unknown.\n\nThe diversity of species on islands is highly impacted by human activities such as deforestation and introduction of exotic species. In response, ecologists and managers are directing attention towards conservation and restoration of island species. Because they are simple systems, islands provide an opportunity to study processes of extinction that can be extrapolated to larger ecosystems.\n\nIslands are attractive sites for ecological research because they provide clear examples of evolution in action. They show interesting patterns of colonization, adaptation, and speciation.\n\nIslands are surrounded by water, and may or may not exist as part of a continental land mass. Oceanic islands arise due to volcanic activity or reef growth, and usually subside over time due to erosion and changing sea levels. When islands emerge, they undergo the process of ecological succession as species colonize the island (see theory of island biogeography). New species cannot immigrate via land, and instead must arrive via air, water, or wind. As a result, organisms with high dispersal capabilities, such as plants and birds, are much more common on islands than are poorly dispersing taxa like mammals. However, some mammals are present on islands, presumably from swimming or riding on natural “rafts” that are washed away from the mainland.\n\nOf the species that arrive, only some will be able to survive and establish populations. As a result, islands have fewer species than mainland habitats. Island populations are small and exhibit low genetic variability (see founder effect), but are isolated from the predators and competitors that they initially evolved with. This can lead to a process called ecological release, where a species is released from its ancestral community interactions and then colonizes new niches.\n\nIn response to these changing ecological pressures, island species can become much more docile than their mainland counterparts, and may grow larger (see island gigantism) or smaller (see island dwarfism). Some of these unique adaptations are reflected in charismatic island species such as the giant tortoise, Komodo dragon, or pygmy mammoths. \n\nOther adaptations to life on islands include increased poikilothermy, relaxed anti-predator behavior, and reduced sexual selection in animals, and loss of herbivore defenses and reduced dispersal in plants.\n\nThe formation of new islands and their isolation from the mainland provides many unoccupied niches for species to adapt to. Since immigration of predators and competitors is limited, many organisms are able to persist in these new niches. This results in a high occurrence of endemism, where species are unique to a localized area. For example, 50% of endemic bird areas are found on islands.\n\nEndemism is often the result of adaptive radiation. Adaptive radiation is when a single species colonizes an area and rapidly diversifies to fill all of the available niches. A common example is the assemblage of finch species documented by Charles Darwin in the Galapagos Islands. Darwin’s finches exhibited adaptive radiation by evolving different beak sizes to exploit the diversity of seeds present on the different islands. \n\nBecause the distributions of these populations are limited by their island habitats, they tend to have fewer individuals than their mainland counterparts and lower genetic variation. This, along with the behavioral and ecological factors mentioned above, makes island species more vulnerable to extinction.\n\nThe continued survival of species on islands depends on factors such as natural selection, genetic variation, natural disturbances (hurricanes, volcanic eruptions) and human-caused disturbances (introduced species, habitat loss). Human-caused disturbances tend to be the greatest cause of mortality, and understanding the causes of extinction facilitates conservation efforts.\n\nThe movement of humans to islands has led to rapid extinction of native island species either from hunting, habitat destruction, or introduced species.\n\nMany large animals on islands have been hunted to extinction by humans. A well-known example is the dodo, once found on the island of Mauritius. It evolved to become large, flightless and docile, and was subsequently driven to extinction by humans and introduced predators.\n\nThe depletion of natural resources can have dramatic effects on island ecology. On Easter Island, the depletion of the forest by humans not only resulted in widespread loss of species, but also the collapse of the island civilization. Today there are over 500 million people on islands, all dependent on local resources either directly (traditional use) or indirectly (ecotourism revenue). Population growth and development result in heavy deforestation, pollution, and over-exploitation. Overharvesting of ocean fauna is particularly troubling as yields of coral reef fish species are an important food source for island populations.\n\nHumans have contributed to globalization and decreased effective isolation of island communities, allowing for invasion of exotic species. This can have a profound effect on the native species. In Guam, the introduced brown tree snake ate nearly all of the native vertebrate species to extinction. Feral cats and dogs have also greatly diminished native vertebrate populations on islands, through both predation and disease. Introduced ungulates are another major threat, as they graze on native vegetation and can destroy entire forests. Exotic grasses can out-compete native understory species and increase the risk of fire. Lastly, social insects such as ants also cause major problems.\n\nGlobal warming is emerging as a strong cause of species loss on islands. This can be due to sea level rise, intrusion of salt water into freshwater habitats, or species inability to adapt to increasing temperatures and extreme weather events. Plant species are particularly susceptible. In more isolated areas, such as the Southern Ocean Islands, indirect effects such as invasive species and global warming can play a greater role in influencing populations than overexploitation, pollution and habitat loss.\n\nHuman activities and the introduction of non-native species often cause trophic cascades, where direct effects on one species result in indirect effects on other species in the food web. An example is on Santa Cruz Island of the California Channel Islands, where DDT poisoning reduced bald eagle populations. This, along with an abundance of introduced feral pigs for prey, allowed golden eagles to colonize the island and replace bald eagles. However, the golden eagles also ate native island foxes. Fox population levels decreased to near extinction, while skunk populations increased due to relaxed competition with foxes.\n\nSince island ecosystems are self-contained, it should be possible to mitigate many of the threats to species. Ecologists and managers are working together to prioritize areas for conservation and to quickly design and implement action plans. Not everything can be put into a reserve, so it is important to first compile pertinent information and prioritize areas of concern. Once an area has been chosen, managers must then acquire ownership and gain support. Local experts and indigenous populations should also be involved in this process. Having clearly defined goals will facilitate the many necessary interactions between people and agencies. Once a reserve is in place, managers can then practice adaptive management and do continued community education. \n\nOn land, island conservation focuses on the protection of species and their habitat. In some cases, conservation can be integrated with agricultural production. For example, the \"Acacia koa\" plantations and wooded pastures in Hawaii are anthropogenically altered ecosystems, yet allow connectivity between forest fragments and thus maintain higher diversity than would open pasture. Other directions include habitat restoration, and eradication of introduced predators, ungulates, and exotic plants (via hunting, removal or biological control).\n\nIn marine ecosystems, there has been increasing establishment of “no-take” reserves. This allows for reestablishment of native species, and also augmentation of commercially harvested species. However, in both terrestrial and marine systems, these actions are expensive and do not always result in the desired outcomes. For example, some non-natives become keystone species and their removal can cause more harm than good to the ecosystem. To be more effective, managers of island ecosystems should share information and learn from each other’s mistakes. \n\nIsland conservation tends to focus on preservation of individual species and their habitats. However, many ecologists caution that ecological and evolutionary processes should be conserved as well. The conservation of island communities as a whole is closely linked to restoration. \n\nActive restoration on islands can be done for both animal species (translocations, induced breeding) and plant species (reforestation). Creating goals for restoration can be challenging because it is often impossible to restore the ecosystem to its “historic” or “normal” state, if that state can even be clearly defined. Restoration is never complete, as ecological communities are always in a state of change.\n\nAs resource depletion is a major issue on islands, the needs of human populations must also be taken into account. On many islands, scientists and managers are studying traditional practices of indigenous populations as potential conservation solutions. In some cases, limited-take systems that serve the community may provide a better alternative to fully closed protected areas, if there are not enough resources for proper enforcement. Public education plays an important role.\n\n\n"}
{"id": "9334910", "url": "https://en.wikipedia.org/wiki?curid=9334910", "title": "Kavu", "text": "Kavu\n\nKavu is the traditional name given for sacred groves across the Malabar Coast in Kerala, South India. Kavus are notable for Theyyam, the centuries-old ritual dance.\n\nA Sarpa Kavu (meaning \"Abode of Snakes\") is a traditional natural sacred space seen near traditional homes in Kerala state of South India. The site is believed to be inhabited by snakes, and the area usually contains a representation of \"Naga Raja\" (\"King of the Snakes\") and other \"Naga Devatas\" (\"snake deities\"), where offerings and rites are performed during special ceremonies. This is a Hindu ritual performed by certain sects of Nambudiris, and all castes hold the Sarpa Kavu in reverence, with access forbidden to the area unless for due ceremonies.\n\nMythology says that Kerala was created from the Arabian Sea and given to the Brahmins (Namboothiris) as a \"donation\" by Parasurama to save himself from the sins of killing numerous kshathriya kings. The land was full of forests and poisonous snakes were found in plenty. So the Brahmins refused to stay there. Parasurama requested Lord Shiva to provide a solution. Shiva told Parasurama to start worshipping Anantha and vasuki the king of snakes. Parasurama did so and Anantha advised him to start snake worship in Kerala and provide some forest especially for snakes in the form of Sarppakkavu (Snake forests). Parasurama later installed the idols of Anantha and Vasuki at Vettikkottu (near Kayamkulam in Alappuzha district) and Mannarassala(near Harippadu in Alappuzha district) and started worshipping them. The Brahmins also worshipped Anantha and Vasuki and the pleased snake gods made Kerala suitable for living.\n\nSarpa Kavus even help in soil and water conservation besides preserving its rich biological wealth. The ponds and streams adjoining the groves are perennial water sources. These are the last resorts to many of the animals and birds for their water requirements, especially during summer. Sacred groves also enrich the soil through its rich litter composition. The nutrients generated thus are not only recycled within the sacred grove ecosystem but also find their way into the adjoining agroeco systems.\n\nA Kavu is a South Indian version of an Indian sacred grove. \n\nSacred groves of India are forest fragments of varying sizes, which are communally protected, and which usually have a significant religious connotation for the protecting community. Hunting and logging are usually strictly prohibited within these patches. Other forms of forest usage like honey collection and deadwood collection are sometimes allowed on a sustainable basis. Sacred groves did not enjoy protection via federal legislation in India. Some NGOs work with local villagers to protect such groves. Traditionally, and in some cases even today, members of the community take turns to protect the grove. However, the introduction of the protected area category community reserves under the Wild Life (Protection) Amendment Act, 2002 has introduced legislation for providing government protection to community held lands, which could include sacred groves.\n\nIndian sacred groves are sometimes associated with temples / monasteries / shrines or with burial grounds (which is the case in Shinto and Ryukyuan religion-based sacred groves respectively in Japan). Sacred groves may be loosely used to refer to other natural habitat protected on religious grounds, such as Alpine Meadows.\n\nHistorical references to sacred groves can be obtained from ancient classics as far back as Kalidasa's Vikramuurvashiiya. There has been a growing interest in creating green patches such as Nakshatravana.\n\nTypically, such groves are associated with the concept of a \"presiding deity\". While most of these sacred deities are associated with local Hindu gods, sacred groves of Islamic and Buddhist origins, and some based on smaller local religions and folk religions (like the folk deities \"ayyanar\" and \"amman\" ) are also known of. There are over 1000 deities associated with sacred groves in the states of Kerala and Karnataka alone. In Kodagu district in Karnataka from time immemorial the martial community of Kodavas had maintained over a 1000 Deva kadus dedicated to Aiyappa the forest god.\n\nThe Hindu tradition considers forests (\"Van\"/ \"Ban\") to be of three types - \"Tapovan\", \"Mahavan\" and \"Sreevan\". \"Tapovan\" are forests associated with penance (\"Tapas\"), and are inhabited by saints and \"rishis\". \"Mahavan\" refers to the grand natural forests. \"Tapovan\" and \"Mahavan\" are considered to be a \"Raksha\" (\"sanctuary\") for flora and fauna as ordinary human beings are not allowed to enter these forests. \"Sreevan\", which means, \"forests of prosperity\", consists of dense forests and groves. From the former, people would collect dry wood, leaves, forest produce and a limited amount of timber, though natural ecosystem would not be unnecessarily disturbed. Groves were considered as spaces of forests from where harvesting could be done. Sometimes, specific trees like mango trees could be planted and nurtured here. Groves were associated with religious rites, festivals and recreation. Typical recreational activities associated with these groves included \"jhoola\"/ \"jhoolan\". In the villages, \"Panchavati\", or a cluster of five trees that represented the forests, were maintained. These trees represented the five elements of Earth, Water, Fire, Air and Space.\n\nPlanting and nurturing of trees has been a highly evolved practice in ancient India. \"Vrukshayurveda\", the science of plant life and also a 10th-century treatise of that title on the subject ascribed to Surapala, dealt with various species of trees and their growth. Verses 9-23 from this text indicate how mystical beliefs and conservation of ecology was inter-connected.\n\nSacred groves are scattered all over the country, and are referred to by different names in different parts of India. Sacred groves occur in a variety of places – from scrub forests in the Thar Desert of Rajasthan maintained by the Bishnois, to rain forests in the Western Ghats of Kerala. Himachal Pradesh in the north and Kerala in the south are specifically known for their large numbers of sacred groves. The Kodavas of Karnataka alone maintained over 1000 sacred groves in their region. The Gurjar people of Rajasthan have a unique practice of neem (Azadirachta indica) planting and worshipping as abode of God Devnarayan.Thus, a Gurjjar settlement appears like a human-inhabited sacred grove. Similarly Mangar Bani, last surviving natural forest of Delhi is protected by Gurjars of nearby area. 14,000 sacred groves have been reported from all over India, which act as reservoirs of rare fauna, and more often rare flora, amid rural and even urban settings. Experts believe that the total number of sacred groves could be as high as 100,000.\n\nIt is estimated that around 1000 km² of unexploited land is inside sacred groves. Some of the more famous groves are the \"kavu\"s of Kerala, which are located in the Western Ghats and have enormous biodiversity; and the \"law kyntang\"s of Meghalaya – sacred groves associated with every village (two large groves being in Mawphlang and Mausmai) to appease the forest spirit.\n\nAmong the largest sacred groves of India are the ones in Hariyali, near Ganchar in Chamoli District of Uttarakhand, and the Deodar grove in Shipin near Simla in Himachal Pradesh. Kodagu, a small region of about 4000 km² in Karnataka, had over 1000 sacred groves.\n\nAll numbers are quoted from the records of the \"C.P.R. Environmental Education Centre\" of the Government of India. Starred numbers are likely to increase. The centre also maintains a complete list of identified sacred groves in India, most of which is online.\n\nTraditional uses: One of the most important traditional uses of sacred groves was that it acted as a repository for various Ayurvedic medicines. Other uses involved a source of replenishable resources like fruits and honey. However, in most sacred groves it was taboo to hunt or chop wood. The vegetation cover helps reduce soil erosion and prevents desertification, as in Rajasthan. The groves are often associated with ponds and streams, and meet water requirements of local communities. They sometimes help in recharging aquifers as well.\n\nModern uses: In modern times, sacred groves have become biodiversity hotspots, as various species seek refuge in the areas due to progressive habitat destruction, and hunting. Sacred groves often contain plant and animal species that have become extinct in neighboring areas. They therefore harbor great genetic diversity. Besides this, sacred groves in urban landscapes act as \"lungs\" to the city as well, providing much needed vegetation cover.\n\nThreats to the grove include urbanization, over-exploitation of resources (like overgrazing and excessive firewood collection), and environmental destruction due to religious practices. While many of the groves are looked upon as abodes of Hindu gods, in the recent past a number of them have been partially cleared for construction of shrines and temples. Other threats to the sacred groves include invasion by invasive species, like the invasive weeds \"Chromolaena odorata\", \"Lantana camara\" and \"Prosopis juliflora\".\n\n\nA large number of distinct local art forms and folk traditions are associated with the deities of sacred groves, and are an important cultural aspect closely associated with sacred traditions. Ritualistic dances and dramatizations based on the local deities that protect the groves are called \"Theyyam\" in Kerala and \"Nagmandalam\", among other names, in Karnataka. Often, elaborate rituals and traditions are associated with sacred groves, as are associated folk tales and folk mythology.\n\n"}
{"id": "40167806", "url": "https://en.wikipedia.org/wiki?curid=40167806", "title": "Kilonova", "text": "Kilonova\n\nA kilonova (also called a macronova or r-process supernova) is a transient astronomical event that occurs in a compact binary system when two neutron stars or a neutron star and a black hole merge into each other. Kilonovae are thought to emit short gamma-ray bursts and strong electromagnetic radiation due to the radioactive decay of heavy r-process nuclei that are produced and ejected fairly isotropically during the merger process.\n\nThe term \"kilonova\" was introduced by Metzger \"et al.\" in 2010 to characterize the peak brightness, which they showed reaches 1000 times that of a classical nova. They are 1/10th to 1/100th the brightness of a typical supernova, the self-detonation of a massive star.\n\nThe first kilonova to be found was detected as a short gamma-ray burst, sGRB 130603B, by instruments on board the Swift Gamma-Ray Burst Explorer and KONUS/WIND spacecrafts and then observed using the Hubble Space Telescope.\n\nIn October 2018, astronomers reported that GRB 150101B, a gamma-ray burst event detected in 2015, may be analogous to the historic GW170817, a gravitational wave event detected in 2017, and associated with the merger of two neutron stars. The similarities between the two events, in terms of gamma ray, optical and x-ray emissions, as well as to the nature of the associated host galaxies, are considered \"striking\", and this remarkable resemblance suggests the two separate and independent events may both be the result of the merger of neutron stars, and both may be a hitherto-unknown class of kilonova transients. Kilonova events, therefore, may be more diverse and common in the universe than previously understood, according to the researchers.\n\nThe inspiral and merging of two compact objects are a strong source of gravitational waves (GW). Kilonovae are thought to be progenitors of short gamma-ray bursts (GRB) and the predominant source of stable r-process elements in the Universe. The basic model for neutron star mergers was introduced by Li-Xin Li and Bohdan Paczyński in 1998.\n\nThe first observational suggestion of a kilonova came in 2008 following the short-hard gamma-ray burst GRB 080503, where a faint object appeared in optical and infrared light after one day and rapidly faded. Another kilonova was suggested in 2013, in association with the short-duration gamma-ray burst GRB 130603B, where the faint infrared emission from the distant kilonova was detected using the Hubble Space Telescope. \nOn October 16, 2017, the LIGO and Virgo collaborations announced the first simultaneous detections of gravitational waves (GW170817) and electromagnetic radiation (GRB 170817A, SSS17a) of any phenomena, and demonstrated that the source was a kilonova caused by a binary neutron star merger. This short GRB was followed by a longer transient visible for weeks in the optical electromagnetic spectrum (AT 2017gfo) located in a relatively nearby galaxy, NGC 4993.\n\n\n"}
{"id": "35574265", "url": "https://en.wikipedia.org/wiki?curid=35574265", "title": "Kotmale Biyagama transmission line", "text": "Kotmale Biyagama transmission line\n\nKotmale Biyagama transmission line is one of Sri Lanka's critical transmission lines that connects the load center Colombo to hydroelectricity generation of Mahaweli Complex.\n"}
{"id": "55811206", "url": "https://en.wikipedia.org/wiki?curid=55811206", "title": "List of Ixora species", "text": "List of Ixora species\n\nThe genus \"Ixora\" is one of the largest genera of flowering plants and contains around 562 species from the Rubiaceae family. Detailed, up to date information can be found on the World Checklist of Rubiaceae.\n\n"}
{"id": "46819171", "url": "https://en.wikipedia.org/wiki?curid=46819171", "title": "List of asteroid close approaches to Earth in 2010", "text": "List of asteroid close approaches to Earth in 2010\n\nBelow is the list of asteroid close approaches to Earth in 2010.\n\nA list of known near-Earth asteroid close approaches less than 1 lunar distance (384,400 km or 0.00256 AU) from Earth in 2010.\n\n may have passed as close as (0.05 Lunar Distances) from the Earth on January 15, 2010, but the nominal distance suggests it only passed 5 LD away.\n\n"}
{"id": "26003459", "url": "https://en.wikipedia.org/wiki?curid=26003459", "title": "List of drainage basins of South Africa", "text": "List of drainage basins of South Africa\n\nA drainage basin is an extent of land where water from rain and melting snow or ice drains downhill into a body of water, such as a river, lake, reservoir, estuary, wetland, sea or ocean. The drainage basin includes both the streams and rivers that convey the water as well as the land surfaces from which water drains into those channels, and is separated from adjacent basins by a drainage divide.\n\nThe drainage basin acts like a funnel, collecting all the water within the area covered by the basin and channelling it into a waterway. Each drainage basin is separated topographically from adjacent basins by a geographical barrier such as a ridge, hill or mountain, which is known as a water divide.\n\nOther terms that are used to describe a drainage basin are catchment, catchment area, catchment basin, drainage area, river basin, water basin and watershed.\n\nThe drainage basins in South Africa do not correspond with the Water Management Areas, and have the letters A, B, C, D, E, F, G, H, J, K, L, M, N, P, Q, R, S, T, U, V, W, and X. The Area A comes close to the same area that the Limpopo WMA seems to cover. Apart from these letters they seem to have no name referring to them. What seems to be the case though is that each area refers to some major river systems and their tributaries (a region for each major river system). \n\n\n\n"}
{"id": "45470045", "url": "https://en.wikipedia.org/wiki?curid=45470045", "title": "List of earthquakes in Egypt", "text": "List of earthquakes in Egypt\n\nThis is a list of earthquakes in Egypt, including earthquakes that either had their epicenter in Egypt, or caused significant damage in Egypt.\n\nSeismic hazard in Egypt is highest at the southern end of the Gulf of Suez, the northern Red Sea and around the Gulf of Aqaba, the location of the active plate boundaries. The highest risk is the southern end of the Dead Sea Transform.\n"}
{"id": "21133197", "url": "https://en.wikipedia.org/wiki?curid=21133197", "title": "List of galaxies named after people", "text": "List of galaxies named after people\n\nA small number of galaxies or galaxy groups have been named after individual people. In most cases, the named individual was the person who discovered the object, who first brought attention to it, or who first studied it scientifically.\n\nMany of the brighter galaxies visible from the Northern Hemisphere have Messier numbers, named after Charles Messier. For instance, the Andromeda Galaxy is Messier 31 and the Whirlpool Galaxy is Messier 51. There are a few other comprehensive catalogs that assign the cataloguer's name to galaxies. For instance, Markarian galaxies, named after Benjamin Markarian, are galaxies with excess blue and ultraviolet emission; galaxies in the Atlas of Peculiar Galaxies are assigned an Arp number after Halton Arp who produced the catalog; etc. Objects in these catalogs are excluded below, except in cases where they carry the name of an additional person.\n\n\n"}
{"id": "21303666", "url": "https://en.wikipedia.org/wiki?curid=21303666", "title": "List of glaciers in Canada", "text": "List of glaciers in Canada\n\nThis is a list of glaciers in Canada.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "5381994", "url": "https://en.wikipedia.org/wiki?curid=5381994", "title": "List of globular clusters", "text": "List of globular clusters\n\nThis is a list of globular clusters. The apparent\nmagnitude does not include an extinction correction.\nThese are globular clusters within the halo of the Milky Way galaxy. The diameter is in minutes of arc as seen from Earth. For reference, the J2000 epoch celestial coordinates of the Galactic Center are R.A., Dec. . A high proportion of globular clusters are located in the Ophiuchus and Sagittarius constellations, both of which lie in the direction of the galactic core.\n\n\n"}
{"id": "34223952", "url": "https://en.wikipedia.org/wiki?curid=34223952", "title": "List of mountains in Myanmar", "text": "List of mountains in Myanmar\n\nThe following is a list of mountains in Myanmar (Burma). The elevations are in metres. For the names of the mountains in the Latin script the most common transcription has been adopted.\n\nNote:\n\nMany mountains in the country are important not because of their height, but because of their symbolic and cultural significance. Some mountains have Buddhist worship places on top. Since the order of height is convenient, the list follows this order, without in any way intending to diminish or promote the importance of any particular mountain.\n\n\n\n"}
{"id": "15113198", "url": "https://en.wikipedia.org/wiki?curid=15113198", "title": "List of national geoparks", "text": "List of national geoparks\n\nThis list includes areas designated as \"geopark\" on the national level. This should not be confused with members of either the European Geoparks Network or the UNESCO-assisted Global Geoparks Network.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "38001930", "url": "https://en.wikipedia.org/wiki?curid=38001930", "title": "List of pipeline accidents in the United States (1975–1999)", "text": "List of pipeline accidents in the United States (1975–1999)\n\nThe following is a partial list of pipeline accidents in the United States (1975–1999). More information can be obtained from the Pipeline and Hazardous Materials Safety Administration (PHMSA), an agency of the U.S. Department of Transportation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "49912901", "url": "https://en.wikipedia.org/wiki?curid=49912901", "title": "List of psychoactive plants, fungi, and animals", "text": "List of psychoactive plants, fungi, and animals\n\nList of psychoactive plants, fungi, and animals.\n\nMinimally psychoactive plants which contain mainly caffeine and theobromine:\n\nMost known psychoactive plants:\n\n\"Solanaceae\" plants—contain atropine, hyoscyamine and scopolamine\n\nCacti with mescaline:\n\nOther plants:\n\nFungi:\n\nPsychoactive animals:\n\n\n"}
{"id": "860732", "url": "https://en.wikipedia.org/wiki?curid=860732", "title": "List of rivers of China", "text": "List of rivers of China\n\nThis incomplete list of rivers that flow through China is organized according to the body of water into which each river empties, beginning with the Sea of Okhotsk in the northeast, moving clockwise on a map and ending with the Arctic Ocean.\n\n River\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "35474298", "url": "https://en.wikipedia.org/wiki?curid=35474298", "title": "List of rivers of Niger", "text": "List of rivers of Niger\n\nThis is a list of rivers in Niger. This list is arranged by drainage basin, with respective tributaries indented under each larger stream's name.\n\n\n\n"}
{"id": "85296", "url": "https://en.wikipedia.org/wiki?curid=85296", "title": "Marica (mythology)", "text": "Marica (mythology)\n\nIn Roman mythology, Marica was a nymph, the mother of Latinus. Latinus was fathered by Faunus, who was also occasionally referred to as the son of Marica. The sacred forest near Minturnae was dedicated to Marica. A lake nearby was also named after her. Various Roman authors claims that she was a form of Diana or Venus.\n\n"}
{"id": "577296", "url": "https://en.wikipedia.org/wiki?curid=577296", "title": "Mass concentration (astronomy)", "text": "Mass concentration (astronomy)\n\nIn astronomy and astrophysics, a mass concentration (or mascon) is a region of a planet or moon's crust that contains a large positive gravitational anomaly. In general, the word \"mascon\" can be used as a noun to refer to an excess distribution of mass on or beneath the surface of an astronomical body (with respect to some suitable average), such as is found around Hawaii on Earth. However, this term is most often used to describe a geologic structure that has a positive gravitational anomaly associated with a feature (e.g. depressed basin) that might otherwise have been expected to have a negative anomaly, such as the \"mascon basins\" on the Moon.\n\nTypical examples of mascon basins on the Moon are the Imbrium, Serenitatis, Crisium and Orientale impact basins, all of which exhibit significant topographic depressions and positive gravitational anomalies. Examples of mascon basins on Mars include the Argyre, Isidis, and Utopia basins. Theoretical considerations imply that a topographic low in isostatic equilibrium would exhibit a slight negative gravitational anomaly. Thus, the positive gravitational anomalies associated with these impact basins indicate that some form of positive density anomaly must exist within the crust or upper mantle that is currently supported by the lithosphere. One possibility is that these anomalies are due to dense mare basaltic lavas, which might reach up to 6 kilometers in thickness for the Moon. While these lavas certainly contribute to the observed gravitational anomalies, uplift of the crust-mantle interface is also required to account for their magnitude. Indeed, some mascon basins on the Moon do not appear to be associated with any signs of volcanic activity. Theoretical considerations in either case indicate that all the lunar mascons are super-isostatic (that is, supported above their isostatic positions). The huge expanse of mare basaltic volcanism associated with Oceanus Procellarum does not possess a positive gravitational anomaly.\n\nBecause of its mascons, the Moon has only four \"frozen orbit\" inclination zones where a lunar satellite can stay in a low orbit indefinitely. Lunar subsatellites were released on two of the last three Apollo manned lunar landing missions in 1971 and 1972; the subsatellite PFS-2 released from Apollo 16 was expected to stay in orbit for one and a half years, but lasted only 35 days before crashing into the lunar surface. It was only in 2001 that the mascons were mapped and the frozen orbits were discovered.\n\nSince their identification in 1968, the origin of the mascons beneath the surface of the Moon has been subject to much debate, but is now regarded as being the result of the impact of asteroids during the Late Heavy Bombardment \n\nLunar mascons alter the local gravity above and around them sufficiently that low and uncorrected satellite orbits around the Moon are unstable on a timescale of months or years. The small perturbations in the orbits accumulate and eventually distort the orbit enough that the satellite impacts the surface.\n\nThe Luna-10 orbiter was the first artificial object to orbit the Moon and it returned tracking data indicating that the lunar gravitational field caused larger than expected perturbations presumably due to 'roughness' of the lunar gravitational field. The Lunar mascons were discovered by Paul M. Muller and William L. Sjogren of the NASA Jet Propulsion Laboratory (JPL) in 1968 from a new analytic method applied to the highly precise navigation data from the unmanned pre-Apollo Lunar Orbiter spacecraft. This discovery observed the consistent 1:1 correlation between very large positive gravity anomalies and depressed circular basins on the Moon. This fact places key limits on models attempting to follow the history of the Moon's geological development and explain the current lunar internal structures.\n\nAt that time, one of NASA's highest priority \"tiger team\" projects was to explain why the Lunar Orbiter spacecraft being used to test the accuracy of Project Apollo navigation were experiencing errors in predicted position of ten times the mission specification (2 kilometers instead of 200 meters). This meant that the predicted landing areas were 100 times as large as those being carefully defined for reasons of safety. Lunar orbital effects principally resulting from the strong gravitational perturbations of the mascons were ultimately revealed as the cause. William Wollenhaupt and Emil Schiesser of the NASA Manned Spacecraft Center in Houston then worked out the \"fix\" that was first applied to Apollo 12 and permitted its landing within 535 feet of the target, the previously-landed Surveyor 3 spacecraft.\n\nIn May 2013 a NASA study was published with results from the twin GRAIL probes, that mapped mass concentrations on Earth's Moon.\n\n"}
{"id": "57421004", "url": "https://en.wikipedia.org/wiki?curid=57421004", "title": "Mineral evolution", "text": "Mineral evolution\n\nMineral evolution is a theory that provides historical context to mineralogy. It postulates that mineralogy on planets and moons becomes increasingly complex as a result of changes in the physical, chemical and biological environment. In the Solar System, the number of mineral species has grown from about a dozen to over 5300 as a result of three processes: separation and concentration of elements; greater ranges of temperature and pressure coupled with the action of volatiles; and new chemical pathways provided by living organisms.\n\nOn Earth, there were three eras of mineral evolution. The birth of the Sun and formation of asteroids and planets increased the number of minerals to about 250. Repeated reworking of the crust and mantle through processes such as partial melting and plate tectonics increased the total to about 1500. The remaining minerals, more than 2/3 of the total, were the result of chemical changes mediated by living organisms, with the largest increase occurring after the Great Oxygenation Event.\nIn the 2008 paper that introduced the term \"mineral evolution\", Robert Hazen and co-authors recognized that an application of the word \"evolution\" to minerals is likely to be controversial, although there were precedents as far back as the 1928 book \"The Evolution of the Igneous Rocks\" by Norman Bowen. They used the term in the sense of an irreversible sequence of events leading to increasingly complex and diverse assemblages of minerals. Unlike biological evolution, it does not involve mutation, competition or passing of information to progeny. Hazen et al. explored some other analogies, including the idea of extinction. Some mineral-forming processes no longer occur, such as those that produced certain minerals in enstatite chondrites that are unstable on Earth in its oxidized state. Also, the runaway greenhouse effect on Venus may have led to permanent losses of mineral species. However, mineral extinction is not truly irreversible; a lost mineral could emerge again if suitable environmental conditions were re-established.\n\nIn the early Universe, there were no minerals because the only elements available were hydrogen, helium and trace amounts of lithium. Mineral formation became possible after heavier elements, including carbon, oxygen, silicon and nitrogen, were synthesized in stars. In the expanding atmospheres of red giants and the ejecta from supernovae, microscopic minerals formed at temperatures above 1500 degrees Celsius (°C).\n\nEvidence of these minerals can be found in interstellar grains incorporated into primitive meteorites called chondrites, which are \"essentially cosmic sedimentary rocks\". The number of known species is roughly a dozen, although several more materials have been identified but not classified as minerals. Because it has a high crystallization temperature (about 4400 degrees Celsius), diamond was probably the first mineral to form. this was followed by graphite, oxides (rutile, corundum, spinel, hibonite), carbides (moissanite), nitrides (osbornite and silicon nitride) and silicates (forsterite and silicate perovskite (MgSiO)). These \"ur-minerals\" seeded the molecular clouds from which the Solar system was formed.\n\nAfter the formation of the Solar system, mineral evolution was driven by three primary mechanisms: the separation and concentration of elements; greater ranges of temperature and pressure combined with chemical action of volatiles; and new reaction pathways driven by living organisms.\n\nThe highest level in the classification of minerals is based on chemical composition. However, the defining elements for many mineral groups, such as boron in borates and phosphorus in phosphates, were at first only present in concentrations of parts per million or less. This left little or no chance for them to come together and form minerals until external influences concentrated them. Processes that separate and concentrate elements include planetary differentiation (for example, separation into layers such as a core and mantle); outgassing; fractional crystallization; and partial melting.\n\nAllowable combinations of elements in minerals are determined by thermodynamics; for an element to be added to a crystal at a given location, it must reduce the energy. At higher temperatures, many elements are interchangeable in minerals such as olivine. As a planet cools, minerals became exposed to a greater range of intensive variables such as temperature and pressure, allowing the formation of new phases and more specialized combinations of elements such as clay minerals and zeolites. New minerals are formed when volatile compounds such as water, carbon dioxide and O react with them. Environments such as ice caps, dry lakes, and exhumed metamorphic rock have distinctive suites of minerals.\n\nLife has made dramatic changes in the environment. Most dramatic was the Great Oxygenation Event, about 2.4 billion years ago, in which photosynthetic organisms flooded the atmosphere with oxygen. Living organisms also catalyze reactions, creating minerals such as aragonite that are not in equilibrium with their surroundings.\n\nBefore the formation of the Solar System, there were about 12 minerals. The estimate for the current number of minerals has been changing rapidly. In 2008, it was 4300, but as of April 2018 there were 5312 officially recognized mineral species.\n\nIn their chronology for Earth, Hazen et al. (2008) separated the changes in mineral abundance into three broad intervals: planetary accretion up to 4.55 Ga (billion years ago); reworking of Earth's crust and mantle between 4.55 Ga and 2.5 Ga; and biological influences after 2.5 Ga. They further divided the ages into 10 intervals, some of which overlap. In addition, some of the dates are uncertain; for example, estimates of the onset of modern plate tectonics range from 4.5 Ga to 1.0 Ga.\nIn the first era, the Sun ignited, heating the surrounding molecular cloud. 60 new minerals were produced and were preserved as inclusions in chondrites. The accretion of dust into asteroids and planets, bombardments, heating and reactions with water raised the number to 250.\n\nBefore 4.56 Ga, the presolar nebula was a dense molecular cloud consisting of hydrogen and helium gas with dispersed dust grains. When the Sun ignited and entered its T-Tauri phase, it melted nearby dust grains. Some of the melt droplets were incorporated into chondrites as small spherical objects called chondrules. Almost all chondrites also contain calcium–aluminium-rich inclusions (CAIs), the earliest materials formed in the Solar System. From an examination of chondrites from this era, 60 new minerals can be identified with crystal structures from all of the crystal systems. These included the first iron-nickel alloys, sulfides, phosphides, and several silicates and oxides. Among the most important were magnesium-rich olivine, magnesium-rich pyroxene, and plagioclase. Some rare minerals, produced in oxygen-poor environments no longer found on Earth, can be found in enstatite chondrites.\n\nSoon after the new minerals formed in Stage 1, they began to clump together, forming asteroids and planets. One of the most important new minerals was ice; the early Solar System had a \"snow line\" separating rocky planets and asteroids from ice-rich gas giants, asteroids and comets. Heating from radionuclides melted the ice and the water reacted with olivine-rich rocks, forming phyllosilicates, oxides such as magnetite, sulfides such as pyrrhotite, the carbonates dolomite and calcite, and sulfates such as gypsum. Shock and heat from bombardment and eventual melting produced minerals such as ringwoodite, a major component of Earth's mantle.\n\nEventually, asteroids heated enough for partial melting to occur, producing melts rich in pyroxene and plagioclase (capable of producing basalt) and a variety of phosphates. Siderophile (metal-loving) and lithophile (silicate-loving) elements separated, leading to the formation of a core and crust, and incompatible elements were sequestered in the melts. The resulting minerals have been preserved in a type of stony meteorite, eucrite (quartz, potassium feldspar, titanite and zircon) and in iron-nickel meteorites (iron-nickel alloys such as kamacite and taenite; transition metal sulfides such as troilite; carbides and phosphides). An estimated 250 new minerals formed in this stage.\n\nThe second era in the history of mineral evolution began with the massive impact that formed the Moon. This melted most of the crust and mantle. Early mineralogy was determined by crystallization of igneous rocks and further bombardments. This phase was then replaced by extensive recycling of crust and mantle, so that at the end of this era there were about 1500 mineral species. However, few of the rocks survived from this period so the timing of many events remains uncertain.\n\nStage 3 began with a crust made of mafic (high in iron and magnesium) and ultramafic rocks such as basalt. These rocks were repeatedly recycled by fractional melting, fractional crystallization and separation of magmas that refuse to mix. An example of such a process is Bowen's reaction series.\n\nOne of the few sources of direct information on mineralogy in this stage is mineral inclusions in zircon crystals, which date back as far as 4.4 Ga. Among the minerals in the inclusions are quartz, muscovite, biotite, potassium feldspar, albite, chlorite and hornblende.\n\nIn a volatile-poor body such as Mercury and the Moon, the above processes give rise to about 350 mineral species. Water and other volatiles, if present, increase the total. Earth was volatile-rich, with an atmosphere composed of N, CO and water, and an ocean that became steadily more saline. Volcanism, outgassing and hydration gave rise to hydroxides, hydrates, carbonates and evaporites. For Earth, where this stage coincides with the Hadean Eon, the total number of widely occurring minerals is estimated to be 420, with over 100 more that were rare. Mars probably reached this stage of mineral evolution.\n\nGiven sufficient heat, basalt was remelted to form granitoids, coarse-grained rocks similar to granite. Cycles of melting concentrated rare elements such as lithium, beryllium, boron, niobium, tantalum and uranium to the point where they could form 500 new minerals. Many of these are concentrated in exceptionally coarse-grained rocks called pegmatites that are typically found in dikes and veins near larger igneous masses. Venus may have achieved this level of evolution.\n\nWith the onset of plate tectonics, subduction carried crust and water down, leading to fluid-rock interactions and more concentration of rare elements. In particular, sulfide deposits were formed with 150 new sulfosalt minerals. Subduction also carried cooler rock into the mantle and exposed it to higher pressures, resulting in new phases that were later uplifted and exposed as metamorphic minerals such as kyanite and sillimanite.\n\nThe inorganic processes described in the previous section produced about 1500 mineral species. The remaining more than 2/3 of Earth's minerals are the result of the transformation of Earth by living organisms. The largest contribution was from the enormous increase in the oxygen content of the atmosphere, starting with the Great Oxygenation Event. Living organisms also started to produce skeletons and other forms of biomineralization. Minerals such as calcite, metal oxides and many clay minerals could be considered biosignatures, along with gems such as turquoise, azurite and malachite.\n\nBefore about 2.45 Ga, there was very little oxygen in the atmosphere. Life may have played a role in the precipitation of massive carbonate layers near continental margins and in the deposition of banded iron formations, but there is no unambiguous evidence of the effect of life on minerals.\n\nStarting around 2.45 Ga and continuing to about 2.0 or 1.9 Ga, there was a dramatic rise in the oxygen content of the lower atmosphere, continents and oceans called the Great Oxygenation Event or Great Oxidation Event (GOE). Before the GOE, elements that can be in multiple oxidation states were restricted to the lowest state, and that limited the variety of minerals they could form. In older sediments, the minerals siderite (FeCO), uraninite (UO) and pyrite (FeS) are commonly found. These oxidize rapidly when exposed to an atmosphere with oxygen, yet this did not occur even after extensive weathering and transport.\n\nWhen the concentration of oxygen molecules in the atmosphere reached 1% of the present level, the chemical reactions during weathering were much like they are today. Siderite and pyrite were replaced by the iron oxides magnetite and hematite; dissolved Fe ions that had been carried out to sea were now deposited in extensive banded iron formations. However, this did not result in new iron minerals, just a change in their abundance. By contrast, oxidization of uraninite resulted in over 200 new species of uranyl minerals such as soddyite and weeksite, as well as mineral complexes such as gummite.\n\nOther elements that have multiple oxidation states include copper (which occurs in 321 oxides and silicates), boron, vanadium, magnesium, selenium, tellurium, arsenic, antimony, bismuth, silver and mercury. In total, about 2500 new minerals formed.\n\nThe next roughly billion years (1.85 – 0.85 Ga) are often referred to as the \"Boring Billion\" because little seemed to happen. The more oxidized layer of ocean water near the surface slowly deepened at the expense of the anoxic depths, but there did not seem to be any dramatic change in climate, biology or mineralogy. However, some of this perception may be due to poor preservation of rocks from that time span. Many of the world's most valuable reserves of lead, zinc and silver, are found in rocks from this time, as well as rich sources of beryllium, boron and uranium minerals. This interval also saw the formation of the supercontinent Columbia, its breakup, and the formation of Rodinia. In some quantitative studies of beryllium, boron and mercury minerals, there are no new minerals during the Great Oxidation Event, but a pulse of innovation during the assembly of Columbia. The reasons for this are not clear, although it may have had something to do with the release of mineralizing fluids during mountain building.\n\nBetween 1.0 and 0.542 Ga, the Earth experienced at least two \"Snowball Earth\" events in which much (possibly all) of the surface was covered by ice (making it the dominant surface mineral). Associated with the ice were cap carbonates, thick layers of limestone or dolostone, with aragonite fans. Clay minerals were also produced in abundance, and volcanoes managed to pierce through the ice and add to the stock of minerals.\n\nThe last stage coincides with the Phanerozoic era, in which biomineralization, the creation of minerals by living organisms, became widespread. Although some biominerals can be found in earlier records, it was during the Cambrian explosion that most of the known skeletal forms developed, and the major skeletal minerals (calcite, aragonite, apatite and opal). Most of these are carbonates, but some are phosphates or calcite. In all, over 64 mineral phases have been identified in living organisms, including metal sulfides, oxides, hydroxides and silicates; over two dozen have been found in the human body.\n\nBefore the Phanerozoic, land was mostly barren rock, but plants began to populate it in the Silurian Period. This led to an order-of-magnitude increase in the production of clay minerals. In the oceans, plankton transported calcium carbonate from shallow waters to the deep ocean, inhibiting the production of cap carbonates and making future snowball Earth events less likely. Microbes also became involved in the geochemical cycles of most elements, making them biogeochemical cycles. The mineralogical novelties included organic minerals that have been found in carbon-rich remnants of life such as coal and black shales.\n\nStrictly speaking, purely biogenic minerals are not recognized by the International Mineralogical Association (IMA) unless geological processes are also involved. Purely biological products such as the shells of marine organisms are not accepted. Also explicitly excluded are anthropogenic compounds. However, humans have had such an impact on the surface of the planet that geologists are considering the introduction of a new geological epoch, the Anthropocene, to reflect these changes.\n\nIn 2015, Zalasiewicz and co-authors proposed that the definition of minerals be extended to include human-minerals and that their production constitutes an 11th stage of mineral evolution. Subsequently, Hazen and co-authors catalogued 208 minerals that are officially recognized by the IMA but are primarily or exclusively the result of human activities. Most of these have formed in association with mining. In addition, some were created when metal artefacts sank and interacted with the seafloor. A few would probably not be officially recognized today but are allowed to remain in the catalog; these include two (niobocarbide and tantalcarbide) that may have been a hoax.\n\nHazen and co-authors identified three ways that humans have had a large impact on the distribution and diversity of minerals. The first is through manufacture. A long list of synthetic crystals have mineral equivalents, including synthetic gems, ceramics, brick, cement and batteries. Many more have no mineral equivalent; over 180,000 inorganic crystalline compounds are listed in the Inorganic Crystal Structure Database. For mining or building of infrastructure, humans have redistributed rocks, sediments and minerals on a scale rivalling that of glaciation, and valuable minerals have been redistributed and juxtaposed in ways that would not occur naturally.\n\nOver 2/3 of mineral species owe their existence to life, but life may also owe its existence to minerals. They may have been needed as templates to bring organic molecules together; as catalysts for chemical reactions; and as metabolites. Two prominent theories for the origin of life involve clays and transition metal sulfides. Another theory argues that calcium-borate minerals such as colemanite and borate, and possibly also molybdate, may have been needed for the first ribonucleic acid (RNA) to form. Other theories require less common minerals such as mackinawite or greigite. A catalog of the minerals that were formed during the Hadeon Eon includes clay minerals and iron and nickel sulfides, including mackinawite and greigite; but borates and molybdates were unlikely.\n\nMinerals may also have been necessary to the survival of early life. For example, quartz is more transparent than other minerals in sandstones. Before life developed pigments to protect it from damaging ultraviolet rays, a thin layer of quartz could shield it while allowing enough light through for photosynthesis. Phosphate minerals may also have been important to early life. Phosphorus is one of the essential elements in molecules such as adenosine triphosphate (ATP), an energy carrier found in all living cells; RNA and DNA; and cell membranes. Most of Earth's phosphorus is in the core and mantle. The most likely mechanism for making it available to life would be the creation of phosphates such as apatite through fractionation, followed by weathering to release the phosphorus. This may have required plate tectonics.\n\nSince the original paper on mineral evolution, there have been several studies of minerals of specific elements, including uranium, thorium, mercury, carbon, beryllium, and the clay minerals. These reveal information about different processes; for example, uranium and thorium are heat producers while uranium and carbon indicate oxidation state. The records reveal episodic bursts of new minerals such as those during the Boring Billion, as well as long periods where no new minerals appeared. For example, after a jump in diversity during the assembly of Columbia, there were no new mercury minerals between 1.8 Ga and 600 million years ago. This remarkably long hiatus is attributed to a sulfide-rich ocean, which led to rapid deposition of the mineral cinnabar.\n\nMost of the mineral evolution papers have looked at the first appearance of minerals, but one can also look at the age distribution of a given mineral. Millions of zircon crystals have been dated, and the age distributions are nearly independent of where the crystals are found (e.g., igneous rocks, sedimentary or metasedimentary rocks or modern river sands). They have highs and lows that are linked with the supercontinent cycle, although it is not clear whether this is due to changes in subduction activity or preservation.\n\nOther studies have looked at time variations of mineral properties such as isotope ratios, chemical compositions, and relative abundances of minerals, although not under the rubric of \"mineral evolution\".\n\nFor most of its history, mineralogy has had no historical component. It has been concerned with classifying minerals according to their chemical and physical properties (such as the chemical formula and crystal structure) and defining conditions for stability of a mineral or group of minerals. However, there were exceptions where publications looked at the distribution of ages of minerals or of ores. In 1960, Russell Gordon Gastil found cycles in the distribution of mineral dates. Charles Meyer, finding that the ores of some elements are distributed over a wider time span than others, attributed the difference to the effects of tectonics and biomass on the surface chemistry, particularly free oxygen and carbon. In 1979, A. G. Zhabin introduced the concept of stages of mineral evolution in the Russian-language journal Doklady Akademii Nauk and in 1982, N. P. Yushkin noted the increasing complexity of minerals over time near the surface of the Earth. Then, in 2008, Hazen and colleagues introduced a much broader and more detailed vision of mineral evolution. This was followed by a series of quantitative explorations of the evolution of various mineral groups. These led in 2015 to the concept of mineral ecology, the study of distributions of minerals in space and time.\n\nIn April 2017, the Natural History Museum in Vienna opened a new permanent exhibit on mineral evolution.\n\n"}
{"id": "208999", "url": "https://en.wikipedia.org/wiki?curid=208999", "title": "Non-renewable resource", "text": "Non-renewable resource\n\nA non-renewable resource (also called a finite resource) is a resource that does not renew itself at a sufficient rate for sustainable economic extraction in meaningful human time-frames. An example is carbon-based, organically-derived fuel. The original organic material, with the aid of heat and pressure, becomes a fuel such as oil or gas. Earth minerals and metal ores, fossil fuels (coal, petroleum, natural gas) and groundwater in certain aquifers are all considered non-renewable resources, though individual elements are almost always conserved.\n\nOn the other hand, resources such as timber (when harvested sustainably) and wind (used to power energy conversion systems) are considered renewable resources, largely because their localized replenishment can occur within time frames meaningful to humans.\n\nEarth minerals and metal ores are examples of non-renewable resources. The metals themselves are present in vast amounts in Earth's crust, and their extraction by humans only occurs where they are concentrated by natural geological processes (such as heat, pressure, organic activity, weathering and other processes) enough to become economically viable to extract. These processes generally take from tens of thousands to millions of years, through plate tectonics, tectonic subsidence and crustal recycling.\n\nThe localized deposits of metal ores near the surface which can be extracted economically by humans are non-renewable in human time-frames. There are certain rare earth minerals and elements that are more scarce and exhaustible than others. These are in high demand in manufacturing, particularly for the electronics industry.\n\nMost metal ores are considered vastly greater in supply to fossil fuels, because metal ores are formed by crustal-scale processes which make up a much larger portion of the Earth's near-surface environment, than those that form fossil fuels which are limited to areas where carbon-based life forms flourish, die, and are quickly buried.\n\nNatural resources such as coal, petroleum (crude oil) and natural gas take thousands of years to form naturally and cannot be replaced as fast as they are being consumed. Eventually it is considered that fossil-based resources will become too costly to harvest and humanity will need to shift its reliance to other sources of energy such as solar or wind power, see renewable energy.\n\nAn alternative hypothesis is that carbon based fuel is virtually inexhaustible in human terms, if one includes all sources of carbon-based energy such as methane hydrates on the sea floor, which are vastly greater than all other carbon based fossil fuel resources combined. These sources of carbon are also considered non-renewable, although their rate of formation/replenishment on the sea floor is not known. However their extraction at economically viable costs and rates has yet to be determined.\n\nAt present, the main energy source used by humans is non-renewable fossil fuels. Since the dawn of internal combustion engine technologies in the 19th century, petroleum and other fossil fuels have remained in continual demand. As a result, conventional infrastructure and transport systems, which are fitted to combustion engines, remain prominent throughout the globe. The continual use of fossil fuels at the current rate is believed to increase global warming and cause more severe climate change.\n\nIn 1987, the World Commission on Environment and Development (WCED) an organization set up by but independent from the United Nations classified fission reactors that produce more fissile nuclear fuel than they consume -i.e. breeder reactors, and when it is developed, fusion power, among conventional renewable energy sources, such as solar and falling water. The American Petroleum Institute likewise does not consider conventional nuclear fission as renewable, but that breeder reactor nuclear power fuel is considered renewable and sustainable, before explaining that radioactive waste from used spent fuel rods remains radioactive, and so has to be very carefully stored for up to a thousand years. With the careful monitoring of radioactive waste products also being required upon the use of other renewable energy sources, such as geothermal energy.\n\nThe use of nuclear technology relying on fission requires Naturally occurring radioactive material as fuel. Uranium, the most common fission fuel, and is present in the ground at relatively low concentrations and mined in 19 countries. This mined uranium is used to fuel energy-generating nuclear reactors with fissionable uranium-235 which generates heat that is ultimately used to power turbines to generate electricity.\n\nAs of 2013 only a few kilograms (picture available) of uranium have been extracted from the ocean in pilot programs and it is also believed that the uranium extracted on an industrial scale from the seawater would constantly be replenished from uranium leached from the ocean floor, maintaining the seawater concentration at a stable level. In 2014, with the advances made in the efficiency of seawater uranium extraction, a paper in the journal of \"Marine Science & Engineering\" suggests that with, light water reactors as its target, the process would be economically competitive if implemented on a large scale.\n\nNuclear power provides about 6% of the world's energy and 13–14% of the world's electricity. Nuclear energy production is associated with potentially dangerous radioactive contamination as it relies upon unstable elements. In particular, nuclear power facilities produce about 200,000 metric tons of low and intermediate level waste (LILW) and 10,000 metric tons of high level waste (HLW) (including spent fuel designated as waste) each year worldwide.\n\nIssues entirely separate from the question of the sustainability of nuclear fuel, relate to the use of nuclear fuel and the high-level radioactive waste the nuclear industry generates that if not properly contained, is highly hazardous to people and wildlife. The United Nations (UNSCEAR) estimated in 2008 that average annual human radiation exposure includes 0.01 millisievert (mSv) from the legacy of past atmospheric nuclear testing plus the Chernobyl disaster and the nuclear fuel cycle, along with 2.0 mSv from natural radioisotopes and 0.4 mSv from cosmic rays; all exposures vary by location. natural uranium in some inefficient reactor nuclear fuel cycles, becomes part of the nuclear waste \"once through\" stream, and in a similar manner to the scenario were this uranium remained naturally in the ground, this uranium emits various forms of radiation in a decay chain that has a half-life of about 4.5 billion years, the storage of this unused uranium and the accompanying fission reaction products have raised public concerns about risks of leaks and containment, however the knowledge gained from studying the Natural nuclear fission reactor in Oklo Gabon, has informed geologists on the proven processes that kept the waste from this 2 billion year old natural nuclear reactor that operated for hundreds of thousands of years, from negatively impacting the surrounding plant and animal life.\n\nNatural resources, known as renewable resources, are replaced by natural processes and forces persistent in the natural environment. There are intermittent and reoccurring renewables, and recyclable materials, which are utilized during a cycle across a certain amount of time, and can be harnessed for any number of cycles.\n\nThe production of goods and services by manufacturing products in economic systems creates many types of waste during production and after the consumer has made use of it. The material is then either incinerated, buried in a landfill or recycled for reuse. Recycling turns materials of value that would otherwise become waste into valuable resources again.\nThe natural environment, with soil, water, forests, plants and animals are all renewable resources, as long as they are adequately monitored, protected and conserved. Sustainable agriculture is the cultivation of plant and animal materials in a manner that preserves plant and animal ecosystems over the long term. The overfishing of the oceans is one example of where an industry practice or method can threaten an ecosystem, endanger species and possibly even determine whether or not a fishery is sustainable for use by humans. An unregulated industry practice or method can lead to a complete resource depletion.\nThe renewable energy from the sun, wind, wave, biomass and geothermal energies are based on renewable resources. Renewable resources such as the movement of water (hydropower, tidal power and wave power), wind and radiant energy from geothermal heat (used for geothermal power) and solar energy (used for solar power) are practically infinite and cannot be depleted, unlike their non-renewable counterparts, which are likely to run out if not used sparingly.\n\nThe potential wave energy on coastlines can provide 1/5 of world demand. Hydroelectric power can supply 1/3 of our total energy global needs. Geothermal energy can provide 1.5 more times the energy we need. There is enough wind to power the planet 30 times over, wind power could power all of humanity's needs alone. Solar currently supplies only 0.1% of our world energy needs, but there is enough out there to power humanity's needs 4,000 times over, the entire global projected energy demand by 2050.\n\nRenewable energy and energy efficiency are no longer niche sectors that are promoted only by governments and environmentalists. The increasing levels of investment and that more of the capital is from conventional financial actors, both suggest that sustainable energy has become mainstream and the future of energy production, as non-renewable resources decline. This is reinforced by climate change concerns, nuclear dangers and accumulating radioactive waste, high oil prices, peak oil and increasing government support for renewable energy. These factors are commercializing renewable energy, enlarging the market and growing demand, the adoption of new products to replace obsolete technology and the conversion of existing infrastructure to a renewable standard.\n\nIn economics, a non-renewable resource is defined as goods, where greater consumption today implies less consumption tomorrow. David Ricardo in his early works analysed the pricing of exhaustible resources, where he argued that the price of a mineral resource should increase over time. He argued that the spot price is always determined by the mine with the highest cost of extraction, and mine owners with lower extraction costs benefit from a differential rent. The first model is defined by Hotelling's rule, which is a 1931 economic model of non-renewable resource management by Harold Hotelling. It shows that efficient exploitation of a nonrenewable and nonaugmentable resource would, under otherwise stable conditions, lead to a depletion of the resource. The rule states that this would lead to a net price or \"Hotelling rent\" for it that rose annually at a rate equal to the rate of interest, reflecting the increasing scarcity of the resources.\nThe Hartwick's rule provides an important result about the sustainability of welfare in an economy that uses non-renewable source.\n\n\n"}
{"id": "23483242", "url": "https://en.wikipedia.org/wiki?curid=23483242", "title": "Orbital Piloted Assembly and Experiment Complex", "text": "Orbital Piloted Assembly and Experiment Complex\n\nThe Orbital Piloted Assembly and Experiment Complex (, \"Orbital'nyj Pilotirujemyj Sborochno-Eksperimental'nyj Kompleks\") (ОПСЭК, OPSEK) is a Russian proposed third-generation modular space station in Low Earth orbit.\n\nThe proposal would use OPSEK to assemble components of manned interplanetary spacecraft destined for Mars, the Moon, and possibly Saturn. The returning crew would also recover on the station before landing on Earth. This OPSEK could form part of a future network of stations supporting manned exploration of the Solar System.\n\nIn early plans, the station would at first consist of modules from the Russian Orbital Segment of the International Space Station (ISS). However, in September 2017, the head of Roscosmos Igor Komarov said that the technical feasibility of separating the station to form OPSEK had been studied and there were now \"no plans to separate the Russian segment from the ISS ... We keep the same position, that we should work on the ISS together with our partners.\"\n\nAround the predicted decommissioning of the International Space Station in the late 2020s, the Russian Federal Space Agency (Roscosmos) plans to construct a successor station in low earth orbit.\n\nEarly proposals considered re-using some ISS modules to form the first parts of a new station, which would later be replaced by new modules. On 17 June 2009, Roscosmos officially informed its ISS partner NASA about its intention to \"build and prepare for operation the first elements of the orbital assembly and experimental piloted space complex by the end of the ISS life cycle.\". As of 2017, those plans had been abandoned, and the new station was to be composed entirely of new purpose-built modules.\n\nAccording to the Russian manned spaceflight contractor RKK Energia, the new station must be able to perform the following tasks:\n\nOPSEK would follow the Salyut and Almaz series, Kosmos 557, and Mir as the 12th Russian space station launched. OPSEK is a third generation modular space station.\n\nOther examples of modular station projects include the Soviet/Russian MIR, the International Space Station, and the Chinese space station. The first space station, Salyut 1, and other one-piece or \"monolithic\" first generation space stations, such as Salyut 2, 3, 4, 5, DOS-2, Kosmos 557, Almaz, and NASA's Skylab station, were not designed for re-supply. Generally, each crew had to depart the station to free the only docking port for the next crew to arrive. Skylab had more than one docking port but was not designed for resupply. Salyut 6 and 7 had more than one docking port and were designed to be resupplied routinely during crewed operation. Modular stations can allow the mission to be changed over time and new modules can be added or removed from the existing structure, allowing greater flexibility.\n\nExpected Russian Orbital Segment modules around the time of OPSEK separation (2020 or later) arranged by launch dates:\nPoisk (; lit. \"Search\"), also known as the Mini-Research Module 2 (MRM 2), , or \"МИМ 2\". Poisk is a Russian airlock module with two identical hatches. Its predecessor, Pirs, is used to store, service, and refurbish Russian Orlan suits. The outermost docking ports on both airlocks allow docking of Soyuz and Progress spacecraft, and the automatic transfer of propellants to and from storage on the station. \n\nNauka (; lit. Science), also known as the Multipurpose Laboratory Module (MLM) or FGB-2, (Russian: Многофункциональный лабораторный модуль, or МЛМ), is the major Russian laboratory module. This module will be separated from the ISS before de-orbit with support modules to become the OPSEK space station. It contains an additional set of life support systems and orientation control. Nauka's mission has changed over time; during the mid-1990s it was intended as a backup for the first FGB, and later as a universal docking module (UDM). Its docking ports will be able to support automatic docking of both spacecraft, additional modules and fuel transfer. Prior to the arrival of the MLM, a Progress robotic spacecraft will dock with the ISS PIRS module, depart with that module, and both will be discarded. Nauka will then use its own engines to attach itself to the ROS after 2014. The European Robotic Arm, which will service the Russian Orbital Segment, will be launched alongside the MLM. \n\nNode Module (UM)/(NM) This 4-ton ball shaped module will support the docking of two scientific and power modules during the final stage of the station assembly and provide the Russian segment additional docking ports to receive Soyuz TMA (transportation modified anthropometric) and Progress M spacecraft. NM is to be incorporated into the ISS in 2016. It will be integrated with a special version of the Progress cargo ship and launched by a standard Soyuz rocket. The Progress would use its own propulsion and flight control system to deliver and dock the Node Module to the nadir (Earth-facing) docking port of the Nauka MLM/FGB-2 module. One port is equipped with an active hybrid docking port, which enables docking with the MLM module. The remaining five ports are passive hybrids, enabling docking of Soyuz and Progress vehicles, as well as heavier modules and future spacecraft with modified docking systems. More importantly, the node module was conceived to serve as the only permanent element of OPSEK. Equipped with six docking ports, the Node Module would serve as a single permanent core of the future station with all other modules coming and going as their life span and mission required. Uzlovoy will be launched after Nauka MLM; launch dates will be 2017 or later \n\nRussian Orbital Segment modules scheduled for de-orbiting:\n\nRussian Orbital Segment modules that are neither scheduled for de-orbit nor included in the OPSEK proposals:\n\n\n\n\n European Space Agency, \n Russia (Energia), \n Russia (Federal),\n"}
{"id": "35516605", "url": "https://en.wikipedia.org/wiki?curid=35516605", "title": "Photometeor", "text": "Photometeor\n\nA photometeor is a topic in atmospheric optics. These can be bright objects or phenomena appearing in Earth's atmosphere when sunlight or moonlight creates a reflection, refraction, diffraction or interference under particular circumstances. The most frequent are halos, rainbows, fogbows, cloud iridescences (or irisation), glories, Bishop's rings, coronas, crepuscular rays, parhelia, light pillars, mirages, scintillations, green flashes, etc.\n\nPhotometeors are not reported in routine weather observation.\n\n\n"}
{"id": "33316231", "url": "https://en.wikipedia.org/wiki?curid=33316231", "title": "Pouillet effect", "text": "Pouillet effect\n\nIn physics, the term Pouillet effect refers to an exothermic reaction that takes place when a liquid is added to a powder. It was first observed by Leslie in 1802 when dry sawdust was wetted with water. Claude Pouillet later described this phenomenon in 1822 when it came to be known as the Pouillet effect in France.\n"}
{"id": "11931603", "url": "https://en.wikipedia.org/wiki?curid=11931603", "title": "Records of heads of state", "text": "Records of heads of state\n\nHeads of state throughout the world and at all periods of history may be ranked according to characteristics such as length of time holding that position; age of accession or death; or physical attributes. In this way world records in these characteristics may be identified, although the historical basis for such claims is frequently uncertain.\n\nThe longest-reigning male monarch ever known is disputed between the following candidates: \n\n\nThe longest undisputed reigning male monarch known is Sobhuza II, who ruled the Kingdom of Swaziland as an absolute monarch under the title of Paramount Chief of Swaziland and later King of Swaziland. He ruled for 82 years, 8 months, 11 days.\n\nThe longest current reigning male monarch is Hassanal Bolkiah, who is the Sultan and Yang di-Pertuan of Brunei (\"(he) who is Lord\"), an absolute monarch of Brunei Darussalam.\n\nThe longest current reigning constitutional male monarch is Carl XVI Gustaf of Sweden, who is the King of Sweden of the Kingdom of Sweden.\n\nThe longest reigning female monarch ever known was Eleanor of Aquitaine, who ruled the Duchy of Aquitaine as a feudal absolute monarch under the title of Duchess of Aquitaine. She ruled for 66 years, 11 months, and 23 days.\n\nThe longest reigning female constitutional monarch ever is Elizabeth II, who is currently the Queen of the United Kingdom and other commonwealth realms. She has been Queen of the United Kingdom, Australia, Canada, and New Zealand, since February 6, 1952, but all of the other countries she is at present queen of had yet to gain independence at the time of her accession.\n\nThe longest current reigning female monarch is Elizabeth II, who is the Queen of the United Kingdom and other commonwealth realms, and is a constitutional monarch. She has been Queen of the United Kingdom, Australia, Canada and New Zealand, since February 6, 1952, but all of the other countries she is at present queen of had yet to gain independence at the time of her accession.\n\nThe longest-serving non-royal head of state in the 20th and 21st centuries was Fidel Castro, who held the titles of Prime Minister of Cuba, First Secretary of the Integrated Revolutionary Organizations, First Secretary of the Central Committee of the United Party for the Socialist Revolution of Cuba, First Secretary of the Central Committee of the Communist Party of Cuba, President of the Council of State, and President of the Council of Ministers of the Republic of Cuba. He served for 52 years, 2 months, and 3 days.\n\nThe longest-serving and longest current serving male president ever is Teodoro Obiang Nguema Mbasogo, who is currently the President of Equatorial Guinea of the Republic of Equatorial Guinea.\n\nThe longest serving female non-royal head of state and longest serving female president ever was Vigdís Finnbogadóttir, who was the President of the Republic of Iceland. She served for 16 years.\n\nThe shortest serving monarch of all time is believed to be Louis XIX of France. After his father's abdication during the July Revolution on August 2, 1830, he ascended to the throne, but abdicated around 19 minutes later. This reign is disputed, as some historians believe this reign is too short to be valid. The next contender is the unnamed daughter of Emperor Xiaoming of Northern Wei who was appointed by her grandmother, Empress Dowager Hu. She reigned for a matter of hours until being replaced by Yuan Zhou.\n\nMexican politician Pedro Lascuráin served as the 34th President of Mexico for a short period of time ranging from 15 to 56 minutes before he quit in a coup d'état in order to make General Victoriano Huerta the next President.\n\nOfficially, the current Emperor of Japan, Akihito is the 125th in line from the first emperor Jimmu, who is variously believed to have reigned in the 1st or 7th century BC. However, the earliest documentary evidence is only for the 29th emperor, Kinmei (AD 509–571).\n\nQueen Elizabeth II of the United Kingdom is well-documented as being descended from Arnulf of Metz (c. AD 582–640), forefather of Charlemagne, thus representing a lineage of 47 generations. (See Descent of Elizabeth II from the Franks.)\n\nThe Ottoman Empire lasted for 36 sultans in 21 generations, from Osman I to Mehmed VI for 623 years. (See List of sultans of the Ottoman Empire.)\n\nThe highest post-nominal number representing a member of a royal house is 75, used by Count Heinrich LXXV Reuss (r. 1800–1801). All male members of the branch were named Heinrich, and were successively numbered from 1 upwards, from the beginning of each century.\n\nThe heaviest monarch is believed to have been Taufa'ahau Tupou IV, King of Tonga from 1965 to 2006 who at his peak in 1976 was measured as , though he subsequently lost around 40% of his weight.\n\nSancho VII of Navarre was the tallest head of state. He was the King of Kingdom of Navarre. His remains were measured to indicate a height of at least .\n\nPresident Benito Juárez of Mexico was reportedly the shortest world leader, standing at .\n\nAccording to legends, the youngest ruler is Shapur II who was crowned \"in utero\" when a crown was placed on the belly of Hormizd II 's wife after Hormizd II died. However, according to Shapur Shahbazi, it is unlikely. Other claims as the youngest ruler include John I of France and Alfonso XIII of Spain who were both crowned on the day of their birth.\n\n"}
{"id": "438602", "url": "https://en.wikipedia.org/wiki?curid=438602", "title": "Rossby wave", "text": "Rossby wave\n\nRossby waves, also known as planetary waves, are a natural phenomenon in the atmospheres and oceans of planets that largely owe their properties to rotation of the planet. Rossby waves are a subset of inertial waves. They were first identified by Carl-Gustaf Arvid Rossby.\n\nAtmospheric\" Rossby waves on Earth are giant meanders in high-altitude winds that have a major influence on weather. These waves are associated with pressure systems and the jet stream. Oceanic\" Rossby waves move along the thermocline: the boundary between the warm upper layer and the cold deeper part of the ocean.\n\nAtmospheric Rossby waves result from the conservation of potential vorticity and are influenced by the Coriolis force and pressure gradient. The rotation causes fluids to turn to the right as they move in the northern hemisphere and to the left in the southern hemisphere. For example, a fluid that moves from the equator toward the north pole will deviate toward the east; a fluid moving toward the equator from the north will deviate toward the west. These deviations are caused by the Coriolis force and conservation of potential vorticity which leads to changes of relative vorticity. This is analogous to conservation of angular momentum in mechanics. In planetary atmospheres, including Earth, Rossby waves are due to the variation in the Coriolis effect with latitude. Carl-Gustaf Arvid Rossby first identified such waves in the Earth's atmosphere in 1939 and went on to explain their motion. \n\nOne can identify a terrestrial Rossby wave as its phase velocity, marked by its wave crest, always has a westward component. However, the collected set of Rossby waves may appear to move in either direction with what is known as its group velocity. In general, shorter waves have an eastward group velocity and long waves a westward group velocity. \n\nThe terms \"barotropic\" and \"baroclinic\" are used to distinguish the vertical structure of Rossby waves. Barotropic Rossby waves do not vary in the vertical, and have the fastest propagation speeds. The baroclinic wave modes, on the other hand, do vary in the vertical. They are also slower, with speeds of only a few centimeters per second or less.\n\nMost investigations of Rossby waves have been done on those in Earth's atmosphere.\nRossby waves in the Earth's atmosphere are easy to observe as (usually 4-6) large-scale meanders of the jet stream. When these deviations become very pronounced, masses of cold or warm air detach, and become low-strength cyclones and anticyclones, respectively, and are responsible for day-to-day weather patterns at mid-latitudes. The action of Rossby waves partially explains why eastern continental edges in the Northern Hemisphere, such as the Northeast United States and Eastern Canada, are colder than Western Europe at the same latitudes.\n\nDeep convection (heat transfer) to the troposphere is enhanced over very warm sea surfaces in the tropics, such as during El Niño events. This tropical forcing generates atmospheric Rossby waves that have a poleward and eastward migration.\n\nPoleward-propagating Rossby waves explain many of the observed statistical connections between low- and high-latitude climates. One such phenomenon is sudden stratospheric warming. Poleward-propagating Rossby waves are an important and unambiguous part of the variability in the Northern Hemisphere, as expressed in the Pacific North America pattern. Similar mechanisms apply in the Southern Hemisphere and partly explain the strong variability in the Amundsen Sea region of Antarctica. In 2011, a \"Nature Geoscience\" study using general circulation models linked Pacific Rossby waves generated by increasing central tropical Pacific temperatures to warming of the Amundsen Sea region, leading to winter and spring continental warming of Ellsworth Land and Marie Byrd Land in West Antarctica via an increase in advection.\n\nAtmospheric Rossby waves, like Kelvin waves, can occur on any rotating planet with an atmosphere. The Y-shaped cloud feature on Venus is attributed to Kelvin and Rossby waves.\n\nOceanic Rossby waves are large-scale waves within an ocean basin. They have a low amplitude, on the order of centimetres (at the surface) to metres (at the thermocline), compared to a very long wavelength, on the order of hundreds of kilometres of atmospheric Rossby waves. They may take months to cross an ocean basin. They gain momentum from wind stress at the ocean surface layer and are thought to communicate climatic changes due to variability in forcing, due to both the wind and buoyancy. Both barotropic and baroclinic waves cause variations of the sea surface height, although the length of the waves made them difficult to detect until the advent of satellite altimetry. Satellite observations have confirmed the existence of oceanic Rossby waves.\n\nBaroclinic waves also generate significant displacements of the oceanic thermocline, often of tens of meters. Satellite observations have revealed the stately progression of Rossby waves across all the ocean basins, particularly at low- and mid-latitudes. These waves can take months or even years to cross a basin like the Pacific.\n\nRossby waves have been suggested as an important mechanism to account for the heating of the ocean on Europa, a moon of Jupiter.\n\nRossby wave instabilities are also thought to be found in astrophysical discs, for example, around newly forming stars.\n\nIt has been proposed that a number of regional weather extremes in the Northern Hemisphere associated with blocked atmospheric circulation patterns\nmay have been caused by quasiresonant amplification of Rossby waves. Examples include the 2013 European floods, the 2012 China floods, the 2010 Russian heat wave, the 2010 Pakistan floods and the 2003 European heat wave. Even taking global warming into account, the 2003 heat wave would have been highly unlikely without such a mechanism.\n\nNormally freely travelling synoptic-scale Rossby waves and quasistationary planetary-scale Rossby waves exist in the mid-latitudes with only weak interactions. The hypothesis, proposed by Vladimir Petoukhov, Stefan Rahmstorf, Stefan Petri, and Hans Joachim Schellnhuber, is that under some circumstances these waves interact to produce the static pattern. For this to happen, they suggest, the zonal (east-west) wave number of both types of wave should be in the range 6–8, the synoptic waves should be arrested within the troposphere (so that energy does not escape to the stratosphere) and mid-latitude waveguides should trap the quasistationary components of the synoptic waves. In this case the planetary-scale waves may respond unusually strongly to orography and thermal sources and sinks because of \"quasiresonance\".\n\nA 2017 study by Mann, Rahmstorf, et al. connected the phenomenon of manmade Arctic amplification to planetary wave resonance and extreme weather events.\n\nTo start with, a zonal mean flow, \"U\", can be considered to be perturbed where \"U\" is constant in time and space. Let formula_1 be the total horizontal wind field, where \"u\" and \"v\" are the components of the wind in the \"x\"- and \"y\"- directions, respectively. The total wind field can be written as a mean flow, \"U\", with a small superimposed perturbation, \"u′\" and \"v′\".\n\nThe perturbation is assumed to be much smaller than the mean zonal flow.\n\nRelative vorticity \"η\", \"u and \"v can be written in terms of the stream function formula_5 (assuming non-divergent flow, for which the stream function completely describes the flow):\n\nConsidering a parcel of air that has no relative vorticity before perturbation (uniform \"U\" has no vorticity) but with planetary vorticity \"f\" as a function of the latitude, perturbation will lead to a slight change of latitude, so the perturbed relative vorticity must change in order to conserve potential vorticity. Also the above approximation \"U\" » \"u\"' ensures that the perturbation flow does not advect relative vorticity.\n\nwith formula_8. Plug in the definition of stream function to obtain:\n\nUsing the method of undetermined coefficients one can consider a traveling wave solution with zonal and meridional wavenumbers \"k\" and \"ℓ\", respectively, and frequency formula_10:\n\nThis yields the dispersion relation:\n\nThe zonal (\"x\"-direction) phase speed and group velocity of the Rossby wave are then given by\n\nwhere \"c\" is the phase speed, \"c\" is the group speed, \"U\" is the mean westerly flow, formula_14 is the Rossby parameter, \"k\" is the zonal wavenumber, and \"ℓ\" is the meridional wavenumber. It is noted that the zonal phase speed of Rossby waves is always westward (traveling east to west) relative to mean flow \"U\", but the zonal group speed of Rossby waves can be eastward or westward depending on wavenumber.\n\nThe Rossby parameter is defined:\n\nformula_16 is the latitude, \"ω\" is the angular speed of the Earth's rotation, and \"a\" is the mean radius of the Earth.\n\nIf formula_17, there will be no Rossby Waves; Rossby Waves owe their origin to the gradient of the tangential speed of the planetary rotation (planetary vorticity). A \"cylinder\" planet has no Rossby Waves. It also means that at the equator of any rotating, sphere-like planet, including Earth, one will still have Rossby Waves, despite the fact that formula_18, because formula_19. (Equatorial Rossby wave).\n\n\n\n"}
{"id": "27743", "url": "https://en.wikipedia.org/wiki?curid=27743", "title": "Solar energy", "text": "Solar energy\n\nSolar energy is radiant light and heat from the Sun that is harnessed using a range of ever-evolving technologies such as solar heating, photovoltaics, solar thermal energy, solar architecture, molten salt power plants and artificial photosynthesis.\n\nIt is an important source of renewable energy and its technologies are broadly characterized as either passive solar or active solar depending on how they capture and distribute solar energy or convert it into solar power. Active solar techniques include the use of photovoltaic systems, concentrated solar power and solar water heating to harness the energy. Passive solar techniques include orienting a building to the Sun, selecting materials with favorable thermal mass or light-dispersing properties, and designing spaces that naturally circulate air.\n\nThe large magnitude of solar energy available makes it a highly appealing source of electricity. The United Nations Development Programme in its 2000 World Energy Assessment found that the annual potential of solar energy was 1,575–49,837 exajoules (EJ). This is several times larger than the total world energy consumption, which was 559.8 EJ in 2012.\n\nIn 2011, the International Energy Agency said that \"the development of affordable, inexhaustible and clean solar energy technologies will have huge longer-term benefits. It will increase countries’ energy security through reliance on an indigenous, inexhaustible and mostly import-independent resource, enhance sustainability, reduce pollution, lower the costs of mitigating global warming, and keep fossil fuel prices lower than otherwise. These advantages are global. Hence the additional costs of the incentives for early deployment should be considered learning investments; they must be wisely spent and need to be widely shared\".\n\nThe Earth receives 174 petawatts (PW) of incoming solar radiation (insolation) at the upper atmosphere. Approximately 30% is reflected back to space while the rest is absorbed by clouds, oceans and land masses. The spectrum of solar light at the Earth's surface is mostly spread across the visible and near-infrared ranges with a small part in the near-ultraviolet. Most of the world's population live in areas with insolation levels of 150–300 watts/m², or 3.5–7.0 kWh/m² per day.\n\nSolar radiation is absorbed by the Earth's land surface, oceans – which cover about 71% of the globe – and atmosphere. Warm air containing evaporated water from the oceans rises, causing atmospheric circulation or convection. When the air reaches a high altitude, where the temperature is low, water vapor condenses into clouds, which rain onto the Earth's surface, completing the water cycle. The latent heat of water condensation amplifies convection, producing atmospheric phenomena such as wind, cyclones and anti-cyclones. Sunlight absorbed by the oceans and land masses keeps the surface at an average temperature of 14 °C. By photosynthesis, green plants convert solar energy into chemically stored energy, which produces food, wood and the biomass from which fossil fuels are derived.\n\nThe total solar energy absorbed by Earth's atmosphere, oceans and land masses is approximately 3,850,000 exajoules (EJ) per year. In 2002, this was more energy in one hour than the world used in one year. Photosynthesis captures approximately 3,000 EJ per year in biomass. The amount of solar energy reaching the surface of the planet is so vast that in one year it is about twice as much as will ever be obtained from all of the Earth's non-renewable resources of coal, oil, natural gas, and mined uranium combined,\n\nThe potential solar energy that could be used by humans differs from the amount of solar energy present near the surface of the planet because factors such as geography, time variation, cloud cover, and the land available to humans limit the amount of solar energy that we can acquire.\n\nGeography affects solar energy potential because areas that are closer to the equator have a greater amount of solar radiation. However, the use of photovoltaics that can follow the position of the sun can significantly increase the solar energy potential in areas that are farther from the equator. Time variation effects the potential of solar energy because during the nighttime there is little solar radiation on the surface of the Earth for solar panels to absorb. This limits the amount of energy that solar panels can absorb in one day. Cloud cover can affect the potential of solar panels because clouds block incoming light from the sun and reduce the light available for solar cells.\n\nIn addition, land availability has a large effect on the available solar energy because solar panels can only be set up on land that is otherwise unused and suitable for solar panels. Roofs have been found to be a suitable place for solar cells, as many people have discovered that they can collect energy directly from their homes this way. Other areas that are suitable for solar cells are lands that are not being used for businesses where solar plants can be established.\n\nSolar technologies are characterized as either passive or active depending on the way they capture, convert and distribute sunlight and enable solar energy to be harnessed at different levels around the world, mostly depending on distance from the equator. Although solar energy refers primarily to the use of solar radiation for practical ends, all renewable energies, other than Geothermal power and Tidal power, derive their energy either directly or indirectly from the Sun.\n\nActive solar techniques use photovoltaics, concentrated solar power, solar thermal collectors, pumps, and fans to convert sunlight into useful outputs. Passive solar techniques include selecting materials with favorable thermal properties, designing spaces that naturally circulate air, and referencing the position of a building to the Sun. Active solar technologies increase the supply of energy and are considered supply side technologies, while passive solar technologies reduce the need for alternate resources and are generally considered demand side technologies.\n\nIn 2000, the United Nations Development Programme, UN Department of Economic and Social Affairs, and World Energy Council published an estimate of the potential solar energy that could be used by humans each year that took into account factors such as insolation, cloud cover, and the land that is usable by humans. The estimate found that solar energy has a global potential of 1,575–49,837 EJ per year \"(see table below)\".\n\nSolar thermal technologies can be used for water heating, space heating, space cooling and process heat generation.\n\nIn 1878, at the Universal Exposition in Paris, Augustin Mouchot successfully demonstrated a solar steam engine, but couldn't continue development because of cheap coal and other factors. \n\nIn 1897, Frank Shuman, a U.S. inventor, engineer and solar energy pioneer, built a small demonstration solar engine that worked by reflecting solar energy onto square boxes filled with ether, which has a lower boiling point than water, and were fitted internally with black pipes which in turn powered a steam engine. In 1908 Shuman formed the Sun Power Company with the intent of building larger solar power plants. He, along with his technical advisor A.S.E. Ackermann and British physicist Sir Charles Vernon Boys, developed an improved system using mirrors to reflect solar energy upon collector boxes, increasing heating capacity to the extent that water could now be used instead of ether. Shuman then constructed a full-scale steam engine powered by low-pressure water, enabling him to patent the entire solar engine system by 1912.\n\nShuman built the world's first solar thermal power station in Maadi, Egypt, between 1912 and 1913. His plant used parabolic troughs to power a engine that pumped more than of water per minute from the Nile River to adjacent cotton fields. Although the outbreak of World War I and the discovery of cheap oil in the 1930s discouraged the advancement of solar energy, Shuman's vision and basic design were resurrected in the 1970s with a new wave of interest in solar thermal energy. In 1916 Shuman was quoted in the media advocating solar energy's utilization, saying:\nSolar hot water systems use sunlight to heat water. In low geographical latitudes (below 40 degrees) from 60 to 70% of the domestic hot water use with temperatures up to 60 °C can be provided by solar heating systems. The most common types of solar water heaters are evacuated tube collectors (44%) and glazed flat plate collectors (34%) generally used for domestic hot water; and unglazed plastic collectors (21%) used mainly to heat swimming pools.\n\nAs of 2007, the total installed capacity of solar hot water systems was approximately 154 thermal gigawatt (GW). China is the world leader in their deployment with 70 GW installed as of 2006 and a long-term goal of 210 GW by 2020. Israel and Cyprus are the per capita leaders in the use of solar hot water systems with over 90% of homes using them. In the United States, Canada, and Australia, heating swimming pools is the dominant application of solar hot water with an installed capacity of 18 GW as of 2005.\n\nIn the United States, heating, ventilation and air conditioning (HVAC) systems account for 30% (4.65 EJ/yr) of the energy used in commercial buildings and nearly 50% (10.1 EJ/yr) of the energy used in residential buildings. Solar heating, cooling and ventilation technologies can be used to offset a portion of this energy.\nThermal mass is any material that can be used to store heat—heat from the Sun in the case of solar energy. Common thermal mass materials include stone, cement and water. Historically they have been used in arid climates or warm temperate regions to keep buildings cool by absorbing solar energy during the day and radiating stored heat to the cooler atmosphere at night. However, they can be used in cold temperate areas to maintain warmth as well. The size and placement of thermal mass depend on several factors such as climate, daylighting and shading conditions. When properly incorporated, thermal mass maintains space temperatures in a comfortable range and reduces the need for auxiliary heating and cooling equipment.\n\nA solar chimney (or thermal chimney, in this context) is a passive solar ventilation system composed of a vertical shaft connecting the interior and exterior of a building. As the chimney warms, the air inside is heated causing an updraft that pulls air through the building. Performance can be improved by using glazing and thermal mass materials in a way that mimics greenhouses.\n\nDeciduous trees and plants have been promoted as a means of controlling solar heating and cooling. When planted on the southern side of a building in the northern hemisphere or the northern side in the southern hemisphere, their leaves provide shade during the summer, while the bare limbs allow light to pass during the winter. Since bare, leafless trees shade 1/3 to 1/2 of incident solar radiation, there is a balance between the benefits of summer shading and the corresponding loss of winter heating. In climates with significant heating loads, deciduous trees should not be planted on the Equator-facing side of a building because they will interfere with winter solar availability. They can, however, be used on the east and west sides to provide a degree of summer shading without appreciably affecting winter solar gain.\n\nSolar cookers use sunlight for cooking, drying and pasteurization. They can be grouped into three broad categories: box cookers, panel cookers and reflector cookers. The simplest solar cooker is the box cooker first built by Horace de Saussure in 1767. A basic box cooker consists of an insulated container with a transparent lid. It can be used effectively with partially overcast skies and will typically reach temperatures of . Panel cookers use a reflective panel to direct sunlight onto an insulated container and reach temperatures comparable to box cookers. Reflector cookers use various concentrating geometries (dish, trough, Fresnel mirrors) to focus light on a cooking container. These cookers reach temperatures of and above but require direct light to function properly and must be repositioned to track the Sun.\n\nSolar concentrating technologies such as parabolic dish, trough and Scheffler reflectors can provide process heat for commercial and industrial applications. The first commercial system was the Solar Total Energy Project (STEP) in Shenandoah, Georgia, USA where a field of 114 parabolic dishes provided 50% of the process heating, air conditioning and electrical requirements for a clothing factory. This grid-connected cogeneration system provided 400 kW of electricity plus thermal energy in the form of 401 kW steam and 468 kW chilled water, and had a one-hour peak load thermal storage. Evaporation ponds are shallow pools that concentrate dissolved solids through evaporation. The use of evaporation ponds to obtain salt from seawater is one of the oldest applications of solar energy. Modern uses include concentrating brine solutions used in leach mining and removing dissolved solids from waste streams. Clothes lines, clotheshorses, and clothes racks dry clothes through evaporation by wind and sunlight without consuming electricity or gas. In some states of the United States legislation protects the \"right to dry\" clothes. Unglazed transpired collectors (UTC) are perforated sun-facing walls used for preheating ventilation air. UTCs can raise the incoming air temperature up to and deliver outlet temperatures of . The short payback period of transpired collectors (3 to 12 years) makes them a more cost-effective alternative than glazed collection systems. As of 2003, over 80 systems with a combined collector area of had been installed worldwide, including an collector in Costa Rica used for drying coffee beans and a collector in Coimbatore, India, used for drying marigolds.\n\nSolar distillation can be used to make saline or brackish water potable. The first recorded instance of this was by 16th-century Arab alchemists. A large-scale solar distillation project was first constructed in 1872 in the Chilean mining town of Las Salinas. The plant, which had solar collection area of , could produce up to per day and operate for 40 years. Individual still designs include single-slope, double-slope (or greenhouse type), vertical, conical, inverted absorber, multi-wick, and multiple effect. These stills can operate in passive, active, or hybrid modes. Double-slope stills are the most economical for decentralized domestic purposes, while active multiple effect units are more suitable for large-scale applications.\n\nSolar water disinfection (SODIS) involves exposing water-filled plastic polyethylene terephthalate (PET) bottles to sunlight for several hours. Exposure times vary depending on weather and climate from a minimum of six hours to two days during fully overcast conditions. It is recommended by the World Health Organization as a viable method for household water treatment and safe storage. Over two million people in developing countries use this method for their daily drinking water.\n\nSolar energy may be used in a water stabilization pond to treat waste water without chemicals or electricity. A further environmental advantage is that algae grow in such ponds and consume carbon dioxide in photosynthesis, although algae may produce toxic chemicals that make the water unusable.\n\nMolten salt can be employed as a thermal energy storage method to retain thermal energy collected by a solar tower or solar trough of a concentrated solar power plant, so that it can be used to generate electricity in bad weather or at night. It was demonstrated in the Solar Two project from 1995–1999. The system is predicted to have an annual efficiency of 99%, a reference to the energy retained by storing heat before turning it into electricity, versus converting heat directly into electricity. The molten salt mixtures vary. The most extended mixture contains sodium nitrate, potassium nitrate and calcium nitrate. It is non-flammable and nontoxic, and has already been used in the chemical and metals industries as a heat-transport fluid, so experience with such systems exists in non-solar applications.\n\nThe salt melts at . It is kept liquid at in an insulated \"cold\" storage tank. The liquid salt is pumped through panels in a solar collector where the focused sun heats it to . It is then sent to a hot storage tank. This is so well insulated that the thermal energy can be usefully stored for up to a week.\n\nWhen electricity is needed, the hot salt is pumped to a conventional steam-generator to produce superheated steam for a turbine/generator as used in any conventional coal, oil, or nuclear power plant. A 100-megawatt turbine would need a tank about tall and in diameter to drive it for four hours by this design.\n\nSeveral parabolic trough power plants in Spain and solar power tower developer SolarReserve use this thermal energy storage concept. The Solana Generating Station in the U.S. has six hours of storage by molten salt. The María Elena plant is a 400 MW thermo-solar complex in the northern Chilean region of Antofagasta employing molten salt technology.\n\nSolar power is the conversion of sunlight into electricity, either directly using photovoltaics (PV), or indirectly using concentrated solar power (CSP). CSP systems use lenses or mirrors and tracking systems to focus a large area of sunlight into a small beam. PV converts light into electric current using the photoelectric effect.\n\nSolar power is anticipated to become the world's largest source of electricity by 2050, with solar photovoltaics and concentrated solar power contributing 16 and 11 percent to the global overall consumption, respectively. In 2016, after another year of rapid growth, solar generated 1.3% of global power.\n\nCommercial concentrated solar power plants were first developed in the 1980s. The 392 MW Ivanpah Solar Power Facility, in the Mojave Desert of California, is the largest solar power plant in the world. Other large concentrated solar power plants include the 150 MW Solnova Solar Power Station and the 100 MW Andasol solar power station, both in Spain. The 250 MW Agua Caliente Solar Project, in the United States, and the 221 MW Charanka Solar Park in India, are the world's largest photovoltaic plants. Solar projects exceeding 1 GW are being developed, but most of the deployed photovoltaics are in small rooftop arrays of less than 5 kW, which are connected to the grid using net metering and/or a feed-in tariff.\n\nIn the last two decades, photovoltaics (PV), also known as solar PV, has evolved from a pure niche market of small scale applications towards becoming a mainstream electricity source. A solar cell is a device that converts light directly into electricity using the photoelectric effect. The first solar cell was constructed by Charles Fritts in the 1880s. In 1931 a German engineer, Dr Bruno Lange, developed a photo cell using silver selenide in place of copper oxide. Although the prototype selenium cells converted less than 1% of incident light into electricity, both Ernst Werner von Siemens and James Clerk Maxwell recognized the importance of this discovery. Following the work of Russell Ohl in the 1940s, researchers Gerald Pearson, Calvin Fuller and Daryl Chapin created the crystalline silicon solar cell in 1954. These early solar cells cost 286 USD/watt and reached efficiencies of 4.5–6%. By 2012 available efficiencies exceeded 20%, and the maximum efficiency of research photovoltaics was in excess of 40%.\n\nConcentrating Solar Power (CSP) systems use lenses or mirrors and tracking systems to focus a large area of sunlight into a small beam. The concentrated heat is then used as a heat source for a conventional power plant. A wide range of concentrating technologies exists; the most developed are the parabolic trough, the concentrating linear fresnel reflector, the Stirling dish and the solar power tower. Various techniques are used to track the Sun and focus light. In all of these systems a working fluid is heated by the concentrated sunlight, and is then used for power generation or energy storage.\n\nSunlight has influenced building design since the beginning of architectural history. Advanced solar architecture and urban planning methods were first employed by the Greeks and Chinese, who oriented their buildings toward the south to provide light and warmth.\n\nThe common features of passive solar architecture are orientation relative to the Sun, compact proportion (a low surface area to volume ratio), selective shading (overhangs) and thermal mass. When these features are tailored to the local climate and environment they can produce well-lit spaces that stay in a comfortable temperature range. Socrates' Megaron House is a classic example of passive solar design. The most recent approaches to solar design use computer modeling tying together solar lighting, heating and ventilation systems in an integrated solar design package. Active solar equipment such as pumps, fans and switchable windows can complement passive design and improve system performance.\n\nUrban heat islands (UHI) are metropolitan areas with higher temperatures than that of the surrounding environment. The higher temperatures result from increased absorption of solar energy by urban materials such as asphalt and concrete, which have lower albedos and higher heat capacities than those in the natural environment. A straightforward method of counteracting the UHI effect is to paint buildings and roads white, and to plant trees in the area. Using these methods, a hypothetical \"cool communities\" program in Los Angeles has projected that urban temperatures could be reduced by approximately 3 °C at an estimated cost of US$1 billion, giving estimated total annual benefits of US$530 million from reduced air-conditioning costs and healthcare savings.\n\nAgriculture and horticulture seek to optimize the capture of solar energy in order to optimize the productivity of plants. Techniques such as timed planting cycles, tailored row orientation, staggered heights between rows and the mixing of plant varieties can improve crop yields. While sunlight is generally considered a plentiful resource, the exceptions highlight the importance of solar energy to agriculture. During the short growing seasons of the Little Ice Age, French and English farmers employed fruit walls to maximize the collection of solar energy. These walls acted as thermal masses and accelerated ripening by keeping plants warm. Early fruit walls were built perpendicular to the ground and facing south, but over time, sloping walls were developed to make better use of sunlight. In 1699, Nicolas Fatio de Duillier even suggested using a tracking mechanism which could pivot to follow the Sun. Applications of solar energy in agriculture aside from growing crops include pumping water, drying crops, brooding chicks and drying chicken manure. More recently the technology has been embraced by vintners, who use the energy generated by solar panels to power grape presses.\n\nGreenhouses convert solar light to heat, enabling year-round production and the growth (in enclosed environments) of specialty crops and other plants not naturally suited to the local climate. Primitive greenhouses were first used during Roman times to produce cucumbers year-round for the Roman emperor Tiberius. The first modern greenhouses were built in Europe in the 16th century to keep exotic plants brought back from explorations abroad. Greenhouses remain an important part of horticulture today, and plastic transparent materials have also been used to similar effect in polytunnels and row covers.\n\nDevelopment of a solar-powered car has been an engineering goal since the 1980s. The World Solar Challenge is a biannual solar-powered car race, where teams from universities and enterprises compete over across central Australia from Darwin to Adelaide. In 1987, when it was founded, the winner's average speed was and by 2007 the winner's average speed had improved to .\nThe North American Solar Challenge and the planned South African Solar Challenge are comparable competitions that reflect an international interest in the engineering and development of solar powered vehicles.\n\nSome vehicles use solar panels for auxiliary power, such as for air conditioning, to keep the interior cool, thus reducing fuel consumption.\n\nIn 1975, the first practical solar boat was constructed in England. By 1995, passenger boats incorporating PV panels began appearing and are now used extensively. In 1996, Kenichi Horie made the first solar-powered crossing of the Pacific Ocean, and the \"Sun21\" catamaran made the first solar-powered crossing of the Atlantic Ocean in the winter of 2006–2007. There were plans to circumnavigate the globe in 2010.\n\nIn 1974, the unmanned AstroFlight Sunrise airplane made the first solar flight. On 29 April 1979, the \"Solar Riser\" made the first flight in a solar-powered, fully controlled, man-carrying flying machine, reaching an altitude of . In 1980, the \"Gossamer Penguin\" made the first piloted flights powered solely by photovoltaics. This was quickly followed by the \"Solar Challenger\" which crossed the English Channel in July 1981. In 1990 Eric Scott Raymond in 21 hops flew from California to North Carolina using solar power. Developments then turned back to unmanned aerial vehicles (UAV) with the \"Pathfinder\" (1997) and subsequent designs, culminating in the \"Helios\" which set the altitude record for a non-rocket-propelled aircraft at in 2001. The \"Zephyr\", developed by BAE Systems, is the latest in a line of record-breaking solar aircraft, making a 54-hour flight in 2007, and month-long flights were envisioned by 2010. As of 2016, Solar Impulse, an electric aircraft, is currently circumnavigating the globe. It is a single-seat plane powered by solar cells and capable of taking off under its own power. The design allows the aircraft to remain airborne for several days.\n\nA solar balloon is a black balloon that is filled with ordinary air. As sunlight shines on the balloon, the air inside is heated and expands causing an upward buoyancy force, much like an artificially heated hot air balloon. Some solar balloons are large enough for human flight, but usage is generally limited to the toy market as the surface-area to payload-weight ratio is relatively high.\n\nSolar chemical processes use solar energy to drive chemical reactions. These processes offset energy that would otherwise come from a fossil fuel source and can also convert solar energy into storable and transportable fuels. Solar induced chemical reactions can be divided into thermochemical or photochemical. A variety of fuels can be produced by artificial photosynthesis. The multielectron catalytic chemistry involved in making carbon-based fuels (such as methanol) from reduction of carbon dioxide is challenging; a feasible alternative is hydrogen production from protons, though use of water as the source of electrons (as plants do) requires mastering the multielectron oxidation of two water molecules to molecular oxygen. Some have envisaged working solar fuel plants in coastal metropolitan areas by 2050 the splitting of sea water providing hydrogen to be run through adjacent fuel-cell electric power plants and the pure water by-product going directly into the municipal water system. Another vision involves all human structures covering the earth's surface (i.e., roads, vehicles and buildings) doing photosynthesis more efficiently than plants.\n\nHydrogen production technologies have been a significant area of solar chemical research since the 1970s. Aside from electrolysis driven by photovoltaic or photochemical cells, several thermochemical processes have also been explored. One such route uses concentrators to split water into oxygen and hydrogen at high temperatures (). Another approach uses the heat from solar concentrators to drive the steam reformation of natural gas thereby increasing the overall hydrogen yield compared to conventional reforming methods. Thermochemical cycles characterized by the decomposition and regeneration of reactants present another avenue for hydrogen production. The Solzinc process under development at the Weizmann Institute of Science uses a 1 MW solar furnace to decompose zinc oxide (ZnO) at temperatures above . This initial reaction produces pure zinc, which can subsequently be reacted with water to produce hydrogen.\n\nThermal mass systems can store solar energy in the form of heat at domestically useful temperatures for daily or interseasonal durations. Thermal storage systems generally use readily available materials with high specific heat capacities such as water, earth and stone. Well-designed systems can lower peak demand, shift time-of-use to off-peak hours and reduce overall heating and cooling requirements.\n\nPhase change materials such as paraffin wax and Glauber's salt are another thermal storage medium. These materials are inexpensive, readily available, and can deliver domestically useful temperatures (approximately ). The \"Dover House\" (in Dover, Massachusetts) was the first to use a Glauber's salt heating system, in 1948. Solar energy can also be stored at high temperatures using molten salts. Salts are an effective storage medium because they are low-cost, have a high specific heat capacity and can deliver heat at temperatures compatible with conventional power systems. The Solar Two project used this method of energy storage, allowing it to store in its 68 m³ storage tank with an annual storage efficiency of about 99%.\n\nOff-grid PV systems have traditionally used rechargeable batteries to store excess electricity. With grid-tied systems, excess electricity can be sent to the transmission grid, while standard grid electricity can be used to meet shortfalls. Net metering programs give household systems a credit for any electricity they deliver to the grid. This is handled by 'rolling back' the meter whenever the home produces more electricity than it consumes. If the net electricity use is below zero, the utility then rolls over the kilowatt hour credit to the next month. Other approaches involve the use of two meters, to measure electricity consumed vs. electricity produced. This is less common due to the increased installation cost of the second meter. Most standard meters accurately measure in both directions, making a second meter unnecessary.\n\nPumped-storage hydroelectricity stores energy in the form of water pumped when energy is available from a lower elevation reservoir to a higher elevation one. The energy is recovered when demand is high by releasing the water, with the pump becoming a hydroelectric power generator.\n\nBeginning with the surge in coal use which accompanied the Industrial Revolution, energy consumption has steadily transitioned from wood and biomass to fossil fuels. The early development of solar technologies starting in the 1860s was driven by an expectation that coal would soon become scarce. However, development of solar technologies stagnated in the early 20th century in the face of the increasing availability, economy, and utility of coal and petroleum.\n\nThe 1973 oil embargo and 1979 energy crisis caused a reorganization of energy policies around the world and brought renewed attention to developing solar technologies. Deployment strategies focused on incentive programs such as the Federal Photovoltaic Utilization Program in the U.S. and the Sunshine Program in Japan. Other efforts included the formation of research facilities in the U.S. (SERI, now NREL), Japan (NEDO), and Germany (Fraunhofer Institute for Solar Energy Systems ISE).\n\nCommercial solar water heaters began appearing in the United States in the 1890s. These systems saw increasing use until the 1920s but were gradually replaced by cheaper and more reliable heating fuels. As with photovoltaics, solar water heating attracted renewed attention as a result of the oil crises in the 1970s but interest subsided in the 1980s due to falling petroleum prices. Development in the solar water heating sector progressed steadily throughout the 1990s and annual growth rates have averaged 20% since 1999. Although generally underestimated, solar water heating and cooling is by far the most widely deployed solar technology with an estimated capacity of 154 GW as of 2007.\n\nThe International Energy Agency has said that solar energy can make considerable contributions to solving some of the most urgent problems the world now faces:\n\nThe development of affordable, inexhaustible and clean solar energy technologies will have huge longer-term benefits. It will increase countries’ energy security through reliance on an indigenous, inexhaustible and mostly import-independent resource, enhance sustainability, reduce pollution, lower the costs of mitigating climate change, and keep fossil fuel prices lower than otherwise. These advantages are global. Hence the additional costs of the incentives for early deployment should be considered learning investments; they must be wisely spent and need to be widely shared.\nIn 2011, a report by the International Energy Agency found that solar energy technologies such as photovoltaics, solar hot water and concentrated solar power could provide a third of the world's energy by 2060 if politicians commit to limiting climate change. The energy from the sun could play a key role in de-carbonizing the global economy alongside improvements in energy efficiency and imposing costs on greenhouse gas emitters. \"The strength of solar is the incredible variety and flexibility of applications, from small scale to big scale\".\n\nThe International Organization for Standardization has established several standards relating to solar energy equipment. For example, ISO 9050 relates to glass in building while ISO 10217 relates to the materials used in solar water heaters.\n\n\n"}
{"id": "37364206", "url": "https://en.wikipedia.org/wiki?curid=37364206", "title": "Sunanda Devi", "text": "Sunanda Devi\n\nSunanda Devi () previously known as Nanda Devi East is the lower of the two adjacent peaks of the highest mountain in Uttarakhand and second highest mountain in India; Nanda Devi is its higher twin peak. Nanda Devi and Sunanda Devi are part of the Garhwal Himalayas, and are located in the state of Uttarakhand. The graceful peaks of twin mountains are visible from almost everywhere in Kumaon. The first ascent to the Sunanda Devi peak in recorded history appears to be in 1939 by Jakub Bujak and Janusz Klarner. The elevation of Sunanda Devi is and its prominence is .\n\nSunanda Devi is the lower eastern summit of the twin peaks of Nanda Devi a two-peaked massif, forming a 2 kilometres long ridge, oriented east-west. The western summit is higher, and the eastern summit earlier called Nanda Devi East is now also referred to as Sunanda Devi. Together the peaks may be referred to as the peaks of the goddesses Nanda and Sunanda. These goddesses have occurred together in ancient Sanskrit literature, Srimad Bhagvatam or Bhagavata Purana (Gita Press has a two-volume English and Hindi translation) and are frequently worshipped together in the Kumaon and Garhwal as well as elsewhere in India. Regarding certain mountains as sacred and associating them with specific Gods and Goddesses is a practice prevalent in other parts of Asia as well e.g. the volcanic Mount Fuji in Japan appears to have been named after the fire goddess. The first published reference to Nanda Devi East as Sunanda Devi appears to be in a recent novel (Malhotra 2011) that has the Kumaon region as backdrop. An annual Nanda Devi Raj Jat festival celebrating the two goddesses is popular in Uttarakhand.\n\nThe Himalaya have also been personified as the Lord Himavata, the God of snow, who is mentioned in the Mahabharata. He is father of Ganga and Saraswati, that became rivers, and Parvati an avatar of the great Mother Goddess Durga, who married Shiva and the goddesses Nanda and Sunanda who too are avatars or close spiritual associates of the goddess Durga.\n\nA four-member Polish expedition led by Adam Karpiński climbed the Sunanda Devi peak in 1939 from Longstaff Col which is the standard route on the peak. The summit party was Jakub Bujak and Janusz Klarner. Another attempt to reach the Sunanda Devi peak in 1951 resulted in the death of two members of a French expedition in 1951. Tenzing Norgay who first climbed Mount Everest was a part of the support team. He and Louis Dubost climbed Sunanda Devi to look for the missing pair. Tenzing Norgay later stated that it was the most difficult climb of his life, even more difficult than Everest. Since then the peak has been reached by an Indo-French group in 1975 and perhaps also an Indian Army expedition in 1981 but the mountaineers in this last case did not survive to tell the story. The standard approach to the south ridge route is from the Milam Valley to the east, that passes through Lawan Glacier and onwards to Longstaff Col. The trek goes through the picturesque villages of Munsyari and Bhadeligwar.\n\nMarco Dalla Longa led a large Italian expedition of twelve members to Sunanda Devi Summit in 2005. They approached the peak from Munsyari and the Milam valley. Camps were set up to 5400m. The Italian team made good progress on Sunanda Devi, through the central pillar on the east face. They were proceeding towards the summit when a long spell of bad weather from 9 September to 18 September made them sit up at the higher camps. Then tragedy struck the Italian team on Nanda Devi. Expedition leader Marco Dalla Longa died suddenly. He died by a coma stroke on 24 September. The team’s doctor suspected cerebral oedema. Longa was young and fit, with no health problems reported during the expedition up to that time. The entire expedition was evacuated by air from 27 September to Munsyari and to Delhi by air the next day.\n\nNanda Devi National Park along with the Valley of Flowers National Park are some of the most spectacular wilderness areas in the Himalayas. It is dominated by the peaks of Nanda Devi and Sunanda Devi of India’s second highest mountain which is approached through the Rishiganga gorge, one of the deepest in the world. No humans live in the Park which has remained more or less intact because of its rugged inaccessibility. It has a very diverse flora and is the habitat of several endangered mammals, among them the snow leopard, serow, himalayan musk deer and bharal. Nanda Devi National Park lies in eastern Uttarakhand, near the Tibetan border in the Garhwal Himalaya, 300 km northeast of Delhi.\n\n\n"}
{"id": "51659014", "url": "https://en.wikipedia.org/wiki?curid=51659014", "title": "Survival (series)", "text": "Survival (series)\n\nSurvival () is a Manhwa series. The series have sold more than 28 million copies worldwide.\n"}
{"id": "25019655", "url": "https://en.wikipedia.org/wiki?curid=25019655", "title": "The Birds of Australia (Mathews)", "text": "The Birds of Australia (Mathews)\n\nThe Birds of Australia is a 12-volume ornithological handbook covering the birds of Australia. It was the second of three monumental illustrated works dealing with the avifauna of the continent and was published midway between the other two, the first being Gould’s identically titled \"The Birds of Australia\" (1840-1848), and the third the \"Handbook of Australian, New Zealand and Antarctic Birds\" (1990-2006).\n\nIt was sponsored and authored by wealthy Australia amateur ornithologist Gregory Mathews, with considerable assistance from his collaborator and private secretary Tom Iredale, and was published by H. F. & G. Witherby of London over a 17-year period from 1910 to 1927. The text and plates, comprising 12 volumes, were issued serially in 75 parts in royal quarto format in an edition of 225 numbered copies. The five supplements issued at various times during the long publication period fill a 13th, supplementary, volume; the first three supplements comprising the \"Check-List of Australian Birds\", and the last two the \"Bibliography of the Birds of Australia\".\n\nWhen the publication was complete it was reviewed in the RAOU journal \"The Emu\" by J. A. Leach (as J.A.L.) who wrote:\n\"In these twelve splendid volumes, Mr Mathews has stressed largely the nomenclatural aspect, a phase of ornithology which received little attention from John Gould in the eight folio volumes of his highly valued work, \"The Birds of Australia\". Gould seldom listed a date, and therefore he failed to recognize occasionally that another name listed by him was really older than the name used by him. He was a firm believer in the use of the prior name; this he showed by changing when necessary to an older name. These two great ornithological works which have the same title, and of which Australians are justly proud are thus complementary. Gould emphasized the field and natural history sides, while Mathews stressed the academic and nomenclatural aspects. An Australian student having the use of these fine volumes is well equipped with material on which to base future studies.\"\n\nMathews’ approach to nomenclature was controversial and not always consistent. In a review in the AOU journal \"The Auk\", the editor Witmer Stone comments:\n\n\"It is interesting in view of Mr Mathews's many discussions of nomenclature to see how his attitude on certain points changed as his work progressed. In the opening volume he congratulates the authorities of the British Museum upon their intention of ignoring many of the \"useless generic names\" of the late Dr Bowdler Sharpe and yet in a few years we see Mr Mathews as one of the most extreme genus splitters that ornithology has known. So again in spite of his vigorous plea for the universal use of subspecies we find him, by the time Vol. V is reached, refusing to give them the full recognition in the text that they had previously received and simply discussing them at the end of each species. And what is far worse placing them in the synonymy where they cannot be distinguished from the real synonyms. The number and treatment of subspecies however are ornithological problems, always subject to personal opinion, with no possible \"code\" to govern them.\n\n\"We have felt that the great amount of space devoted to nomenclatural discussion in the 'Birds of Australia' was unfortunate as most of the facts could usually have been stated without nearly so much verbiage and often the very fact that the author was endeavoring to bring out has been obscured by useless repetition. It seems as if some parts of the text may have been printed from a hastily prepared manuscript without revision. We have discussed Mr Mathews’ great work from a nomenclatural point of view because that seems to have been the author's chief concern in its production and that is the feature that will be remembered in the future. He has, however, collected a great deal of valuable and interesting data on the lives and habits of the birds but as he tells us the adequate life histories of the Australian birds are yet to be written and his aim has been to clear away the technical difficulties in Australian ornithology and set up the species and their names on a permanent basis. This we feel that he has done or at least has presented all of the necessary information on the subject, an achievement of which he may well be proud.\"\nAs well as the extensive scientific text, in which Mathews described several new species and subspecies, the 12 volumes are illustrated with some 600 hand-coloured lithographed plates by J.G. Keulemans (who completed 163 illustrations for the first four volumes before his death on 29 March 1912), H. Grönvold, Roland Green, Herbert Goodchild and G.E. Lodge. Stone commented on the plates by saying that as artistic productions they could not be compared with the great folios of John Gould, though those by Keulemans were probably the best.\n\nAfter completing the publication of the 12 volumes, in 1928 Mathews produced The Birds of Norfolk and Lord Howe Islands and the Australian South Polar Quadrant, in the same format and with the same publisher, containing 45 lithographic plates. It was followed in 1936 by A Supplement to the Birds of Norfolk and Lord Howe Islands to which is Added those Birds of New Zealand not figured by Buller, containing 57 plates. Although not technically part of \"The Birds of Australia\", these two volumes extend its coverage to Australia’s Norfolk Island and Lord Howe Island in the Tasman Sea, and even attempt to fill in the gaps left in Walter Buller’s coverage of New Zealand in his similarly ambitious \"A History of the Birds of New Zealand\" (1872-1873, 2nd edition 1887-1888).\n\nPublication dates of the various parts are as follows:\n\n\n\n\n\n"}
{"id": "18490682", "url": "https://en.wikipedia.org/wiki?curid=18490682", "title": "Thermal low", "text": "Thermal low\n\nThermal lows, or heat lows, are non-frontal low-pressure areas that occur over the continents in the subtropics during the warm season, as the result of intense heating when compared to their surrounding environments. Thermal lows occur near the Sonoran Desert, on the Mexican plateau, in California's Great Central Valley, the Sahara, over north-west Argentina in South America, over the Kimberley region of north-west Australia, the Iberian peninsula, and the Tibetan plateau.\n\nOver land, intense, rapid solar heating of the land surface results in heating of the lowest layers of the atmosphere via reradiated energy in the infrared spectrum. The resulting hotter air is less dense than surrounding cooler air. This, combined with the rising of the hot air, results in the formation of a low pressure area. Elevated areas can enhance the strength of the thermal low as they warm more quickly than the atmosphere which surrounds them at the same altitude. Over the water, instability lows form during the winter when the air overlying the land is colder than the warmer water body. Thermal lows tend to have weak circulations, and can extend to in height. Thermal lows over the western and southern portions of North America, northern Africa, and southeast Asia are strong enough to lead to summer monsoon conditions. Development of thermal lows inland of the coastline lead to the development of sea breezes. Sea breezes combined with rugged topography near the coast can encourage poor air quality.\n\nIn deserts, lack of ground and plant moisture that would normally provide evaporative cooling can lead to intense, rapid solar heating of the lower layers of air. The hot air is less dense than surrounding cooler air. This, combined with the rising of the hot air, results in a low pressure area called a thermal low. Over elevated surfaces, heating of the ground exceeds the heating of the surrounding air at the same altitude above sea level, which creates an associated heat low over the terrain and enhances any thermal lows which would have otherwise existed. During the cold season, (winter), warm water bodies such as the Great Lakes can induce an instability low. Thermal lows which develop near sea level can build in height during the warm season, or summer, to the elevation of the 700 hPa pressure surface, which lies near above sea level. Heat lows normally are stationary and have a weak cyclonic circulation. As they are strongest at the surface and warm near their center, and weaker aloft where the air is more stable, the thermal low is considered warm core. The strongest versions of these features globally are over Arabia, the northern portion of the Indian subcontinent, Arizona, Mexican plateau, northwest Argentina, southwestern Spain, Australia, and northern Africa. The formation of the heat low over northern Africa leads to a low-level westerly jet stream from June into October.\n\nMonsoons are caused by the larger amplitude of the seasonal cycle of land temperature compared to that of nearby oceans. This differential warming happens because heat in the ocean is mixed vertically through a \"mixed layer\" that may be fifty meters deep, through the action of wind and buoyancy-generated turbulence, whereas the land surface conducts heat slowly, with the seasonal signal penetrating perhaps a meter or so. Additionally, the specific heat capacity of liquid water is significantly higher than that of most materials that make up land. Together, these factors mean that the heat capacity of the layer participating in the seasonal cycle is much larger over the oceans than over land, with the consequence that the air over the land warms faster and reaches a higher temperature than the air over the ocean. The hot air over the land tends to rise, creating an area of low pressure. This creates a steady wind blowing toward the land, bringing the moist near-surface air over the oceans with it. Similar rainfall is caused by the moist ocean air being lifted upwards by mountains, surface heating, convergence at the surface, divergence aloft, or from storm-produced outflows at the surface. However the lifting occurs, the air cools due expansion in lower pressure, which in turn produces condensation.\n\nIn winter, the land cools off quickly, but the ocean keeps the heat longer due to its higher specific heat. The hot air over the ocean rises, creating a low pressure area and a breeze from land to ocean while a large area of drying high pressure is formed over the land, increased by wintertime cooling. Monsoons are similar to sea and land breezes, a term usually referring to the localized, diurnal (daily) cycle of circulation near coastlines everywhere, but they are much larger in scale, stronger and seasonal.\n\nThe sea is warmed by the sun to a greater depth than the land due to its greater specific heat. The sea therefore has a greater capacity for absorbing heat than the land, so the surface of the sea warms up more slowly than the land's surface. As the temperature of the surface of the land rises, the land heats the air above it. The warm air is less dense and so it rises. This rising air over the land lowers the sea level pressure by about 0.2%. The cooler air above the sea, now with higher sea level pressure, flows towards the land into the lower pressure, creating a cooler breeze near the coast. The strength of the sea breeze is directly proportional to the temperature difference between the land and the sea. If the environmental wind field is greater than and opposing the direction of a possible sea breeze, the sea breeze is not likely to develop.\n\nAlong the California coast, the cooler water sets up a surface marine layer that is much cooler than inland areas during the summer. At the same time, the intense heating inland creates a pronounced thermal trough aligned with the Great Central Valley and typically linked to the broader thermal low across the North American deserts. As a consequence, a strong pressure gradient is created which draws cool marine air landward. As temperatures plummet, fog and stratus stream in and through the gaps of the Coast Ranges, and especially through the Golden Gate at San Francisco (\"see\" San Francisco fog). The same thermal trough is sometimes pushed toward the coast, especially in late Fall as higher pressure develops to the east due to cooling further east. This setup often brings the warmest temperatures of the year to the normally cool coastline as the seabreeze stops or is even replaced by a dangerously dry land breeze.\n\nIn areas where it is hilly or mountainous near the coastline, thermally-forced sea breezes combined with wind circulations up the sides of the mountains can encourage the production of chemicals which can lead to the development of smog. Pollution has been tracked into the mid-levels of the troposphere in the form of ozone, which is concentrated over the circulation of the thermal low as well as adjacent oceanic areas.\n"}
{"id": "18240273", "url": "https://en.wikipedia.org/wiki?curid=18240273", "title": "Tussock grasslands of New Zealand", "text": "Tussock grasslands of New Zealand\n\nTussock grasslands form expansive and distinctive landscapes in the South Island and to a lesser extent in the central plateau region of the North Island of New Zealand. Most of the plants referred to as tussocks are in the genera \"Carex\", \"Chionochloa\", \"Festuca\", and \"Poa\".\n\nWhat would be termed \"herbfields\" for European mountains, and bunchgrass meadows in North America, are referred to as tussock herbfields in New Zealand due to a dominance of this type of plant. Species of the genus \"Chionochloa\" dominate in these areas. The larger tussocks are called snow grass (or less commonly as snow tussocks) and may grow up to 2 metres in height. They grow slowly and some specimens are estimated to be several centuries old.\n\n"}
{"id": "41567629", "url": "https://en.wikipedia.org/wiki?curid=41567629", "title": "Victor Bonham-Carter", "text": "Victor Bonham-Carter\n\nVictor Bonham-Carter (13 December 1913 – 13 March 2007) was an English author, farmer and publisher. He was the son of General Sir Charles Bonham-Carter, who was Governor of Malta (1936-1940).\n\n"}
{"id": "18009604", "url": "https://en.wikipedia.org/wiki?curid=18009604", "title": "William Humphrey (writer)", "text": "William Humphrey (writer)\n\nWilliam Humphrey (June 18, 1924 – August 20, 1997) was an American novelist, memoirist, short story writer, and author of literary sporting and nature stories. His published works, while still available in French translation, largely have been out of print until recently. \"Home from the Hill\" and \"The Ordways\" are available from LSU Press. In 2015, Open Road Media published the complete works of William Humphrey in digital form.\n\nOf significant interest to readers of Humphrey are \"Wakeful Anguish, A Literary Biography of William Humphrey\" by Ashby Bland Crowder as well as \"Far From Home, Selected Letters of William Humphrey\" edited by Crowder, both available from Louisiana State University Press.\n\nWilliam Humphrey was born on 18 June 1924 to Clarence and Nell (Varley) Humphrey in Clarksville, Texas, a region that is culturally southern rather than western. His parents were poor and uneducated, and they moved from house to house because they were unable to keep up with the rent. His father eventually owned and operated an auto repair shop in Clarksville. By the 1950s, Humphrey had escaped his origins: He was thought of as a member of the glittering literati of the northeast, and \"Vogue\" magazine featured him in its “gallery of international charmers among men,” along with Marlon Brando, Sir Edmund Hillary, Leonard Bernstein, and John F. Kennedy. But Humphrey thought little of such “honors” and took no opportunity to capitalize on such chances at fame. He preferred to retreat to his desk and write, thinking any recognition should come from his writing. Unlike Truman Capote and Norman Mailer, and despite his profound desire to be remembered for his literary contributions, Humphrey made very little effort to promote himself.\n\nThe central event in Humphrey’s childhood was the death of his father in a car wreck when the boy was 13. His memoir \"Farther Off from Heaven\", published in 1977, is a moving account of this event’s effect on him. He and his mother, Nell Varley Humphrey, moved to Dallas because there was no work for her in Clarksville. Humphrey attended Southern Methodist University and the University of Texas (perhaps at the Austin campus since his papers are archived in their library), but never graduated. He left Texas as soon as he could.\n\nHumphrey move Chicago and then New York City with his play \"Ambassador Ben\" in hand to see if he could become a Broadway success. This was in 1945. The play never was performed and never published. Humphrey began to write stories and left New York City to write in Brewster, New York. There Humphrey worked on the farm belonging to Donald Peterson, the producer and director of \"The Ave Maria Hour\" on WMCA radio. Humphrey published \"The Last Husband and Other Stories\", his first book of stories, in 1953.\n\nHumphrey secured a teaching post at Bard College in Annandale-on-Hudson, New York in 1949, the same year he married Dorothy Feinman Cantine, a painter of considerable talent who had a daughter Toni. He taught at Bard until 1958 when the success of his first novel, \"Home from the Hill\" (1958), and its 1960 film adaptation, gave him enough money to quit teaching and devote himself to writing full-time.\n\nHumphrey wrote 13 books, including five novels, collections of short stories and a memoir. His first novel, \"Home from the Hill\", was made into a 1960 MGM film. While the movie betrays the original intent of the author, and Humphrey claimed never to have seen it, the sale of the movie rights enabled the struggling Humphrey family to pursue a literary life. His second novel, \"The Ordways\", was reviewed by the \"'New York Times\" as \"Funny, vivid and moving, this is a fine piece of work and a delight to read,\" and was compared to the writings of William Faulkner and Mark Twain. His books received high praise when they were first published, even from fellow writers. He went on to publish a dozen more books.\n\nHumphrey wrote fiction that addressed the Southern past. He once asserted, “I am a destroyer of myths. My whole work has shown the danger and falseness of myths..[especially] the myth of the South” (“Notes on the Orestia,” 38; MS at Harry Ransom Humanities Research Center, University of Texas at Austin).\n\n\"Home from the Hill\" (1958) is Humphrey’s first and most famous novel. It is the story of the aristocratic Hunnicutt family, a holdover from the Old South. The family is fated to end in destruction for the same reason that the Old South itself was destroyed—because of a moral corruption at its core.\n\nThe novel \"Hostages to Fortune\" (1985) represents a return to the tragic mode. Humphrey’s first novel set outside the South, it portrays a man named Ben Curtis on the day he reenters life after a two-year descent into darkness resulting from his son’s suicide. His effort to understand why his son committed suicide leads to his own attempted suicide. Richard Lipez said of this novel:\n\n\"To pick up Humphrey’s extraordinary new novel is to hold an embodiment of grief in your hands. The unrelenting anguish that suffuses this story [is] almost unbearable to behold. It is possible to get through it because the stark poetry of Humphrey’s work is enthralling.\" (Newsweek)\n\nHis last book was \"September Song\" (1992), a collection of short stories about old age. The collection of Humphrey’s letters, \"Far from Home\" (2008), provides enlightening analysis of his own works. They also display his relationship with other writers, including Katherine Anne Porter, Theodore Weiss, and Rust Hill.\n\nJonathan Yardley, writing in The Washington Post (issue of 5 July 1992), remarked of Humphrey:\n\n\"Minor, but interesting and admirable. It has been a long time since Humphrey has enjoyed a commercial success, but he has dedicated his life to his writing with a fidelity all too rare in a culture that encourages facile success and empty honor.\"\n\nNote: The titles are listed referencing the original hard cover publishers. All are now published in digital form by Open Road Media\n.Further reading\n\n"}
{"id": "4197326", "url": "https://en.wikipedia.org/wiki?curid=4197326", "title": "Women's World Golf Rankings", "text": "Women's World Golf Rankings\n\nThe Women's World Golf Rankings, also known for sponsorship reasons as the Rolex Rankings, were introduced in February 2006. They are sanctioned by eight women's golf tours and the organisations behind them: Ladies Professional Golf Association (LPGA Tour), Ladies European Tour, Ladies Professional Golfers' Association of Japan (LPGA of Japan Tour), Korea Ladies Professional Golf Association (LPGA of Korea Tour), Australian Ladies Professional Golf (ALPG Tour), Symetra Tour, China Ladies Professional Golf Association Tour, the Ladies European Tour Access Series and also by the Ladies' Golf Union, which administers the Women's British Open and the United States Golf Association which conducts the U.S. Women's Open.\n\nThe idea of introducing a set of women's rankings similar to the Official World Golf Ranking was developed at the May 2004 World Congress of Women's Golf, and was first planned for 2005, but then put back to 2006.\n\nThe rankings are based on performances on the eight major tours (LPGA, JLPGA, KLPGA, LET, ALPG, Symetra Tour, LETAS, CLPGA) over a two-year period. Amateur players are eligible. The system for calculating the rankings is similar to that for the men's Official World Golf Ranking. Players receive points for each good finish on the relevant tours, with the number of points available in each event depending on the strength of the field, as determined by the competitors' existing rankings (when the rankings were introduced rankings were calculated for earlier periods; the first ever set showed notional changes since the previous week). The only exceptions are the five LPGA majors and all Symetra Tour, CLPGA and LETAS events, which have a fixed-point allocation. Rankings are tapered so the recent results are more important.\n\nWhen the rankings were first introduced in February 2006, a player's ranking as calculated in the above description was divided by the number of events played, with a minimum required events of 15 over the previous two years. In addition, players were required to play in a minimum of 15 eligible events over the previous two-year period to be included in the rankings.\n\nOn 2 August 2006 the Rolex Rankings Board and Technical Committee announced following its bi-annual meeting two changes to the ranking formula. \n\nMany commentators saw the latter change as directed at Michelle Wie, who at the time was ranked second in the world despite having competed in only 16 women's professional events in the two-year period. However, the chairman of the Rolex Rankings Technical Committee defended the change as one designed to make the women's rankings more comparable to the Official World Golf Ranking for men, which use a minimum divisor of 40 events.\n\nOn 16 April 2007, another modification in the formula was introduced. Instead of points being awarded on an accumulated 104-week rolling period, with the points awarded in the most recent 13-week period carrying a stronger value, points began to be reduced in 91 equal decrements following week 13 for the remaining 91 weeks of the two-year Rolex Ranking period rather than the seven equal 13 week decrements previously used. This modification did not have an immediate impact on the rankings.\n\nWhen they were introduced the rankings attracted considerable criticism on two grounds. First, it was widely felt that members of the LPGA of Japan Tour were ranked too high, since few of them had competed successfully outside Japan. Second, the minimum of 15 events needed to qualify for a ranking was widely seen as having been selected purely to enable Michelle Wie to be highly ranked because she had played exactly that number in the preceding two years, while every other highly ranked player had played many more events. If the women's rankings used the same system used for the men's rankings – that is a minimum number of events of one but a minimum denominator of 40 to calculate the average points per tournament – Wie would have been just outside the top 10. But under the women's ranking system where only players who had played a minimum number of events were included, if the minimum number of events had been set higher than 15, Wie would not have been ranked at all.\n\nThe August 2006 revised formula addressed the second criticism. The technical committee that administers the rankings urged patience with regard to the first criticism, since the continuing \"strength of the field\" weighting of tournaments may correct the issue without any technical changes being made.\n\nThe rankings are used by each of the sponsoring tours to determine eligibility criteria for certain events. For example, 40 of the 144 places in the Women's British Open are currently awarded on the basis of the rankings—10 to LET members and 30 to LPGA members. Four of the 12 places in the European Solheim Cup team are allocated on the basis of the rankings.\n\nSince 2013, the rankings at the end of each LPGA Tour season in odd-numbered years have determined the eight countries that will compete in the following year's International Crown, a LPGA-sponsored team event scheduled in even-numbered years and first held in 2014. More specifically, the countries whose top four players have the highest cumulative rankings are invited to compete. The individual participants from each qualified country are determined by the rankings immediately prior to the ANA Inspiration (known before 2015 as the Kraft Nabisco Championship) in the year of the event.\n\n\"As of 26 November 2018\"\nChange column indicates change in rank from previous week.\nNotes \n\n\"As of 26 November 2018\"\nActive players are in bold.</small>\n\nAnnika Sörenstam of Sweden topped the first set of rankings, which was released on Tuesday 21 February 2006. Paula Creamer (United States); Michelle Wie (United States); Yuri Fudoh (Japan); and Cristie Kerr (United States) took the other places in the top 5. The top one hundred players in the initial rankings came from the following countries:\n\n\n"}
{"id": "18711093", "url": "https://en.wikipedia.org/wiki?curid=18711093", "title": "Wunderlich (vacuum tube)", "text": "Wunderlich (vacuum tube)\n\nWunderlich refers to a series of vacuum tubes introduced in the early 1930s. Wunderlichs were designed to be used as full-wave detectors in AM radio receivers. However, because of their unusual design, they were rarely used in commercially manufactured receivers. The tube is named for its inventor, Norman Wunderlich.\n\nThe Wunderlich tube is a twin medium-mu triode. The tube has two identical control grids that operate in tandem with a common heater, indirectly heated cathode and plate. \n\nTypically, the two grids are connected to opposite ends of the center-tapped secondary of the final IF transformer. The center tap of the secondary is then connected to ground through a parallel-connected resistor and capacitor circuit. This causes the tube to act as a full-wave grid leak detector. In some circuits, the center tap also provides AVC bias voltage to the converter and/or IF amplifier. Some Wunderlichs, like the Wunderlich B, have a diode plate or a second grid that provide AVC bias voltage.\n\n"}
{"id": "33940560", "url": "https://en.wikipedia.org/wiki?curid=33940560", "title": "Wyndham Important Bird Area", "text": "Wyndham Important Bird Area\n\nThe Wyndham Important Bird Area comprises a 28 km tract of land in the north-east of the Kimberley region of Western Australia. The site lies in the Bastion Hills close to the town of Wyndham, a port on the West Arm of the Cambridge Gulf. It is an important site for Gouldian finches.\n\nThe site is characterised by gently sloping ranges, vegetated with tropical savanna woodlands and grasslands, with sandstone outcrops. The woodland has a high density of cavity-bearing old-growth eucalypts suitable as finch nest-sites; the grassland provides food for the birds; and the proximity of Wyndham provides reliable sources of drinking water. The area has a tropical monsoon climate with a mean minimum temperature of 17°C in July, a mean maximum of 40°C in November, with the mean annual rainfall of 780 mm falling mainly from November to March.\n\nThe site has been identified as an Important Bird Area (IBA) by BirdLife International because it supports the largest known population of endangered Gouldian finches. It also contains populations of, northern rosellas, white-gaped, yellow-tinted and bar-breasted honeyeaters, silver-crowned friarbirds, masked and long-tailed finches and yellow-rumped munias.\n\nEleven \"Estrildidae\" finch in the Family \"Ploceidae\" are distributed in the Kimberley region of Western Australia. Commercial finch trapping in the Kimberley, principally around Wyndham, commenced in 1897. By 1901 finches were trapped around Wyndham and shipped overseas to Europe in consignments of approximately 5,000 by the persons trapping them. All Kimberley finches were partially or fully protected from 1902 under the Western Australian \"Game Act, 1892.\" Commonwealth Customs regulations first introduced in 1911 failed to curb large scale exports by private finch traders until 1932. One of the largest commercial traders of wild caught Kimberley finches in the late 1920s and 1930s was the South Perth Zoo which exploited customs' law to export for 'scientific and educational purposes'. Licenses to trap finches in the Kimberley were first issued in or after 1913 and continued until 15 November 1986 when finch trapping was banned by Barry Hodge, the environment minister. Trapping of certain finches ceased before 1986: the yellow-rumped mannikin after 15 November 1975 because of its scarcity; the zebra finch after 15 November 1981 because sufficient numbers were sourced from breeding stocks; and the Gouldian finch after 15 November 1981 because of its decline in numbers. Customs regulations in 1960 prohibited the export of live Australian fauna for commercial purposes and strict standards were applied to exports of specimens of native fauna for scientific research or zoological display. In 1971 Australia became a signatory to the Convention on International Trade in Endangered Species (CITES) and in 1976 Australia introduced the Customs (Endangered Species) Regulations to enforce import and export of species covered by CITES.\n"}
