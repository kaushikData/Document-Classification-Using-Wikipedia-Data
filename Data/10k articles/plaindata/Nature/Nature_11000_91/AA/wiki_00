{"id": "57134450", "url": "https://en.wikipedia.org/wiki?curid=57134450", "title": "2018 GE3", "text": "2018 GE3\n\n is a member of the near-Earth population of asteroids known as Apollos. Apollo asteroids cross the orbit of Earth and are the largest group of near-Earth objects with nearly 10 thousand known members. Based on an observation arc of 4 days, it orbits the Sun at a distance of 0.3–3.4 AU once every 2 years and 6 months (918 days; semi-major axis of 1.85 AU). Its orbit has an unusually high eccentricity of 0.83 and an inclination of 9° with respect to the ecliptic. It is also a Mercury-, Venus- and Mars-crosser, reaching its furthest point from the Sun in the outer asteroid belt. The body's observation arc begins at Steward Observatory's Catalina Station with its first observation in April 2018.\n\nIn observational history, and other than possibly 2002 MN and , this asteroid is the largest known object to ever pass that close to Earth, as well as the Moon \"(also see History of closest approaches of large near-Earth objects)\". 99942 Apophis will break both of these records when it approaches only from Earth on 13 April 2029.\n\n was first observed on 14 April 2018, at 09:23 UT by astronomers at Steward Observatory's Catalina Station, Arizona, the day prior to its close encounter with Earth.\n\nIt had been more than 120 degrees from the Sun since March 2018, but was simply too far and too faint to be detected by automated surveys. Despite coming from directly away from the Sun, it was not discovered until 14 April 2018, only one day prior to its closest approach. If the most advanced survey telescopes had been looking at its location, it could have been discovered as early as 30 March. On 15 April 2018, at 06:41 UT, this object passed Earth at a nominal distance of which corresponds to a distance of , at a speed of . The object also approached the Moon at an even closer distance of a few hours later, at 09:59 UT.\n\nIt was the 32nd known asteroid to flyby Earth within 1 lunar distance (LD) since the start of 2018 and 16th closest, although it was the largest known asteroid to pass within half a lunar distance. After closest approach its apparent magnitude dropped from 12 to 35 in less than 12 hours, heading towards the Sun. Coming from the opposite direction, it would have been impossible to observe before its approach. A preliminary analysis of the orbit of shows that this is the closest this particular asteroid has come to Earth since at least 1930.\n\nAsteroid 2002 MN passed closer to Earth than in 2002, and had a brighter absolute magnitude (H) of 23.6, and could be either larger or smaller than , depending on their albedos and thus exact sizes. (H=20.7) may have also passed closer in 2001, although the distance of its approach is very uncertain and it was not discovered until 2017.\n\nThe diameter can only be estimated based on the brightness and distance. The albedo is currently unknown. Based on a generic magnitude-to-diameter conversion, measures between in diameter, for an absolute magnitude of 23.8, and an assumed albedo between 0.05 and 0.24, which represent typical values for carbonaceous and stony asteroids, respectively.\n\nThis asteroid is about three to six times the diameter of the meteor that exploded in the skies above Chelyabinsk, Russia in February 2013, which damaged over 7,200 buildings and injured 1,500 people, mostly from flying glass. If an asteroid of this size were to enter Earth's atmosphere, a good portion of it would likely disintegrate due to friction with the air. The remnants could survive entry however and impact the surface, thus causing regional damage dependent on various factors such as composition, speed, entry angle, and location of impact.\n\nAs of 2018, no rotational lightcurve of has been obtained from photometric observations. The body's rotation period, pole and shape remain unknown.\n\nThis minor planet has neither been numbered nor named.\n\n\n"}
{"id": "41330767", "url": "https://en.wikipedia.org/wiki?curid=41330767", "title": "Accelerationism", "text": "Accelerationism\n\nIn political and social theory, accelerationism is the idea that either the prevailing system of capitalism, or certain technosocial processes that have historically characterised it, should be expanded, repurposed, or accelerated in order to generate radical social change. Some contemporary accelerationist philosophy takes as its starting point the Deleuzo-Guattarian theory of deterritorialisation, aiming to identify, deepen, and radicalise the forces of deterritorialisation with a view to overcoming the countervailing tendencies that suppress the possibility of far-reaching social transformation. Accelerationism may also refer more broadly, and usually pejoratively, to support for the deepening of capitalism in the belief that this will hasten its self-destructive tendencies and ultimately lead to its collapse.\n\nAccelerationist theory has been divided into mutually contradictory left-wing and right-wing variants. \"Left-accelerationism\" attempts to press \"the process of technological evolution\" beyond the constrictive horizon of capitalism, for example by repurposing modern technology for socially beneficial and emancipatory ends; \"right-accelerationism\" supports the indefinite intensification of capitalism itself, possibly in order to bring about a technological singularity.\n\nA number of philosophers have expressed apparently accelerationist attitudes, including Karl Marx in his 1848 speech \"On the Question of Free Trade\":\nIn a similar vein, Friedrich Nietzsche argued that \"the leveling process of European man is the great process which should not be checked: one should even accelerate it...\", a statement often simplified, following Deleuze and Guattari, to a command to \"accelerate the process\".\n\nProminent theorists include right-accelerationist Nick Land. The Cybernetic Culture Research Unit (CCRU), an unofficial research unit at the University of Warwick from 1995–2003, of which Land was a member, is considered a key progenitor in both left- and right-accelerationist thought. Prominent contemporary left-accelerationists include Nick Srnicek and Alex Williams, authors of the \"Manifesto for an Accelerationist Politics\", and the Laboria Cuboniks collective, who authored the manifesto \"Xenofeminism: A Politics for Alienation\".\n\nAlong accelerationist lines, Paul Mason, in works such as \"\", has tried to speculate about futures after capitalism. He declares that \"[a]s with the end of feudalism 500 years ago, capitalism’s replacement by postcapitalism will be accelerated by external shocks and shaped by the emergence of a new kind of human being. And it has started.\" He considers that the rise of collaborative production will eventually help capitalism to kill itself.\n\nFocusing on how information technology infrastructures undermine modern political geographies, and proposing an open-ended \"design brief\", Benjamin H. Bratton's book \"The Stack: On Software and Sovereignty\" is associated with accelerationism. Tiziana Terranova's \"Red Stack Attack!\" links Bratton's stack model and left accelerationism.\n\n\n"}
{"id": "2432697", "url": "https://en.wikipedia.org/wiki?curid=2432697", "title": "Advanced Configuration and Power Interface", "text": "Advanced Configuration and Power Interface\n\nIn a computer, the Advanced Configuration and Power Interface (ACPI) provides an open standard that operating systems can use to discover and configure computer hardware components, to perform power management by (for example) putting unused components to sleep, and to perform status monitoring. First released in December 1996, ACPI aims to replace Advanced Power Management (APM), the MultiProcessor Specification, and the Plug and Play BIOS (PnP) Specification. ACPI brings the power management under the control of the operating system, as opposed to the previous BIOS-centric system that relied on platform-specific firmware to determine power management and configuration policies. The specification is central to the Operating System-directed configuration and Power Management (OSPM) system, an implementation for ACPI which removes device management responsibilities from legacy firmware interfaces via a UI.\n\nInternally, ACPI advertises the available components and their functions to the operating system kernel using instruction lists (\"methods\") provided through the system firmware (Unified Extensible Firmware Interface (UEFI) or BIOS), which the kernel parses. ACPI then executes the desired operations (such as the initialization of hardware components) using an embedded minimal virtual machine.\n\nIntel, Microsoft and Toshiba originally developed the standard, while HP, Huawei and Phoenix also participated later. In October 2013 the original developers of the ACPI standard agreed to transfer all assets to the UEFI Forum, in which all future development will take place.\n\nThe UEFI Forum published of the standard, \"Revision 6.2 Errata A\", in September 2017.\n\nThe firmware-level ACPI has three main components: the ACPI tables, the ACPI BIOS, and the ACPI registers. Unlike its predecessors, such as the APM or PnP BIOS, the ACPI implements little of its functionality in the ACPI BIOS code, whose main role is to load the ACPI tables in system memory. Instead, most of the firmware ACPI functionality is provided in \"ACPI Machine Language\" (AML) bytecode stored in the ACPI tables. To make use of these tables, the operating system must have an interpreter for the AML bytecode. A reference AML interpreter implementation is provided by the ACPI Component Architecture (ACPICA). At the BIOS development time, AML bytecode is compiled from the ASL (ACPI Source Language) code.\n\nAs ACPI also replaces PnP BIOS, it also provides a hardware enumerator, mostly implemented in the Differentiated System Description Table (DSDT) ACPI table. The advantage of a bytecode approach is that unlike PnP BIOS code (which was 16-bit), the ACPI bytecode may be used in any operating system, even in 64-bit long mode.\n\nOverall design decision was not without criticism. In November 2003, Linus Torvalds—author of the Linux kernel—described ACPI as \"a complete design disaster in every way\". In 2001, other senior Linux software developers like Alan Cox expressed concerns about the requirements that bytecode from an external source must be run by the kernel with full privileges, as well as the overall complexity of the ACPI specification. In 2014, Mark Shuttleworth, founder of the Ubuntu Linux distribution, compared ACPI with Trojan horses.\n\nThe ACPI Component Architecture (ACPICA), mainly written by Intel's engineers, provides an open-source platform-independent reference implementation of the operating system–related ACPI code. The ACPICA code is used by Linux, Haiku and FreeBSD, which supplement it with their operating-system specific code.\n\nThe first revision of the ACPI specification was released in December 1996, supporting 16 and 32-bit addressing spaces. It was not until August 2000 that ACPI received 64-bit address support as well as support for multiprocessor workstations and servers with revision 2.0.\n\nIn September 2004, revision 3.0 was released, bringing to the ACPI specification support for SATA controllers, PCI Express bus, multiprocessor support for more than 256 processors, ambient light sensors and user-presence devices, as well as extending the thermal model beyond the previous processor-centric support.\n\nReleased in June 2009, revision 4.0 of the ACPI specification added various new features to the design; most notable are the USB 3.0 support, logical processor idling support, and x2APIC support.\n\nRevision 5.0 of the ACPI specification was released in December 2011, followed by the revision 5.1 that was released in July 2014.\n\nThe latest specification revision is 6.2 Errata A, which was released in September 2017.\n\nMicrosoft's Windows 98 was the first operating system to implement ACPI, but its implementation was somewhat buggy or incomplete, although some of the problems associated with it were caused by the first-generation ACPI hardware. Windows 98 first edition disabled ACPI by default except on a whitelist of systems. Other operating systems, including later versions of Windows, eComStation, FreeBSD, NetBSD, OpenBSD, HP-UX, OpenVMS, Linux, and PC versions of Solaris, have at least some support for ACPI. Some newer operating systems, like Windows Vista, require an ACPI-compliant BIOS to in order to work at all. However, Windows Vista sometimes will not work with a motherboards ACPI.\n\nThe 2.4 series of the Linux kernel had only minimal support for ACPI, with better support implemented (and enabled by default) from kernel version 2.6.0 onwards. Old ACPI BIOS implementations tend to be quite buggy, and consequently are not supported by later operating systems. For example, Windows 2000, Windows XP, and Windows Server 2003 only use ACPI if the BIOS date is after January 1, 1999, and for Windows 98 Second Edition this date is December 1, 1999. Similarly, Linux kernel 2.6 blacklisted any ACPI BIOS from before January 1, 2001.\n\nOnce an OSPM-compatible operating system activates ACPI, it takes exclusive control of all aspects of power management and device configuration. The OSPM implementation must expose an ACPI-compatible environment to device drivers, which exposes certain system, device and processor states.\n\nThe ACPI specification defines the following four global \"Gx\" states and six sleep \"Sx\" states for an ACPI-compliant computer system:\n\n\nThe specification also defines a \"Legacy\" state: the state on an operating system which does not support ACPI. In this state, the hardware and power are not managed via ACPI, effectively disabling ACPI.\n\nThe device states \"D0\"–\"D3\" are device dependent:\n\nThe CPU power states \"C0\"–\"C3\" are defined as follows:\n\n\nWhile a device or processor operates (D0 and C0, respectively), it can be in one of several power-performance states. These states are implementation-dependent. Though, P0 is always the highest-performance state; with P1 to P\"n\" being successively lower-performance states, up to an implementation-specific limit of \"n\" no greater than 16.\n\nP-states have become known as SpeedStep in Intel processors, as PowerNow! or Cool'n'Quiet in AMD processors, and as PowerSaver in VIA processors.\n\n\nACPI-compliant systems interact with hardware through either a \"Function Fixed Hardware (FFH) Interface\", or a platform-independent hardware programming model which relies on platform-specific ACPI Machine Language (AML) provided by the original equipment manufacturer (OEM).\n\nFunction Fixed Hardware interfaces are platform-specific features, provided by platform manufacturers for the purposes of performance and failure recovery. Standard Intel-based PCs have a fixed function interface defined by Intel, which provides a set of core functionality that reduces an ACPI-compliant system's need for full driver stacks for providing basic functionality during boot time or in the case of major system failure.\n\nACPI Platform Error Interface (APEI) is a specification for reporting of hardware errors, e.g. from the chipset, to the operating system.\n\nACPI defines many tables that provide the interface between an ACPI-compliant operating system, and system firmware. This includes Differentiated System Description Table (DSDT), Secondary System Description Table (SSDT), and Static Resource Affinity Table (SRAT), for example.\n\nThe tables allow description of system hardware in a platform-independent manner, and are presented as either fixed-formatted data structures or in AML. The main AML table is the DSDT (differentiated system description table).\n\nThe Root System Description Pointer is located in a platform-dependent manner, and describes the rest of the tables.\n\nUbuntu Linux founder Mark Shuttleworth has likened ACPI to Trojan horses. He has described proprietary firmware (ACPI-related or any other firmware) as a security risk, saying that \"firmware on your device is the NSA's best friend\" and calling firmware (ACPI or non-ACPI) \"a Trojan horse of monumental proportions\". He has pointed out that low quality, closed source firmware is a major threat to system security: \"Your biggest mistake is to assume that the NSA is the only institution abusing this position of trust — in fact, it's reasonable to assume that all firmware is a cesspool of insecurity, courtesy of incompetence of the highest degree from manufacturers, and competence of the highest degree from a very wide range of such agencies\".\n\nAs a solution to this problem, he has called for declarative firmware (ACPI or non-ACPI). Firmware should be open-source so that the code can be checked and verified. Firmware should be declarative, meaning that it should describe \"hardware linkage and dependencies\" and should not include executable code.\n\n"}
{"id": "44512671", "url": "https://en.wikipedia.org/wiki?curid=44512671", "title": "Asia-Pacific Journal of Atmospheric Sciences", "text": "Asia-Pacific Journal of Atmospheric Sciences\n\nThe Asia-Pacific Journal of Atmospheric Sciences is a quarterly peer-reviewed scientific journal covering the field of atmospheric science. It was established in 1965 as the \"Journal of the Korean Meteorological Society\", obtaining its current title in 2008. It is published by Springer Science+Business Media on behalf of the Korean Meteorological Society and the editor-in-chief is Song-You Hong (Korea Institute of Atmospheric Prediction Systems). According to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 1.65.\n"}
{"id": "28779877", "url": "https://en.wikipedia.org/wiki?curid=28779877", "title": "Atmospheric optics", "text": "Atmospheric optics\n\nAtmospheric optics deals with how the unique optical properties of Earth's atmosphere cause a wide range of spectacular optical phenomena. The blue color of the sky is a direct result of Rayleigh scattering, which redirects higher frequency (blue) sunlight back into the field of view of the observer. Because blue light is scattered more easily than red light, the Sun takes on a reddish hue when it is observed through a thick atmosphere, as during a sunrise or sunset.\n\nAdditional particulate matter in the sky can scatter different colors at different angles, creating colorful, glowing skies at dusk and dawn. Scattering off of ice crystals and other particles in the atmosphere are responsible for halos, afterglows, coronas, crepuscular rays, and sun dogs. The variation in these kinds of phenomena is due to different particle sizes and geometries.\n\nMirages are optical phenomena in which light rays are bent due to thermal variations in the refraction index of air, producing displaced or heavily distorted images of distant objects. Other optical phenomena associated with this include the Novaya Zemlya effect, where the Sun appears to rise earlier or set later than predicted with a distorted shape. A spectacular form of refraction, called the Fata Morgana, occurs with a temperature inversion, in which objects on the horizon or even beyond the horizon (e.g. islands, cliffs, ships, and icebergs) appear elongated and elevated, like \"fairy tale castles\".\n\nRainbows are the result of a combination of internal reflection and dispersive refraction of light in raindrops. Because rainbows are seen on the opposite side of the sky as the sun, rainbows are more prominent the closer the sun is to the horizon due to their greater distance apart.\n\nIn the Book of Optics (1011–22 AD), Ibn al-Haytham argued that vision occurs in the brain, and that personal experience has an effect on what people see and how they see, and that vision and perception are subjective. Arguing against Ptolemy's refraction theory for why people perceive the Sun and Moon larger at the horizon than when they are higher in the sky, he redefined the problem in terms of perceived, rather than real, enlargement. He said that judging the distance of an object depends on there being an uninterrupted sequence of intervening bodies between the object and the observer. With the Moon, however, there are no intervening objects. Therefore, since the size of an object depends on its observed distance, which is in this case inaccurate, the Moon appears larger on the horizon. Through works by Roger Bacon, John Pecham and Witelo based on Ibn al-Haytham's explanation, the Moon illusion gradually came to be accepted as a psychological phenomenon, with Ptolemy's theory being rejected in the 17th century.\nFor over 100 years, research on the Moon illusion has been conducted by vision scientists who invariably have been psychologists specializing in human perception. After reviewing the many different explanations in their 2002 book \"The Mystery of the Moon Illusion\", Ross and Plug conclude \"No single theory has emerged victorious\".\n\nLight from the sky is a result of the Rayleigh scattering of sunlight, which results in a blue color perceived by the human eye. On a sunny day, Rayleigh scattering gives the sky a blue gradient, where it is darkest around the zenith and bright near the horizon. Light rays incoming from overhead encounters of the air mass that those coming along a horizontal path encounter. Hence, fewer particles scatter the zenithal sunbeam, and thus the light remains a darker blue. The blueness is at the horizon because the blue light coming from great distances is also preferentially scattered. This results in a red shift of the distant light sources that is compensated by the blue hue of the scattered light in the line of sight. In other words, the red light scatters also; if it does so at a point a great distance from the observer it has a much higher chance of reaching the observer than blue light. At distances nearing infinity, the scattered light is therefore white. Distant clouds or snowy mountaintops will seem yellow for that reason; that effect is not obvious on clear days, but very pronounced when clouds are covering the line of sight reducing the blue hue from scattered sunlight.\n\nThe scattering due to molecule sized particles (as in air) is greater in the forward and backward directions than it is in the lateral direction. Individual water droplets exposed to white light will create a set of colored rings. If a cloud is thick enough, scattering from multiple water droplets will wash out the set of colored rings and create a washed out white color. Dust from the Sahara moves around the southern periphery of the subtropical ridge moves into the southeastern United States during the summer, which changes the sky from a blue to a white appearance and leads to an increase in red sunsets. Its presence negatively impacts air quality during the summer since it adds to the count of airborne particulates.\n\nThe sky can turn a multitude of colors such as red, orange, pink and yellow (especially near sunset or sunrise) and black at night. Scattering effects also partially polarize light from the sky, most pronounced at an angle 90° from the sun.\n\nSky luminance distribution models have been recommended by the International Commission on Illumination (CIE) for the design of daylighting schemes. Recent developments relate to “all sky models” for modelling sky luminance under weather conditions ranging from clear sky to overcast.\n\nThe color of a cloud, as seen from the Earth, tells much about what is going on inside the cloud. Dense deep tropospheric clouds exhibit a high reflectance (70% to 95%) throughout the visible spectrum. Tiny particles of water are densely packed and sunlight cannot penetrate far into the cloud before it is reflected out, giving a cloud its characteristic white color, especially when viewed from the top. Cloud droplets tend to scatter light efficiently, so that the intensity of the solar radiation decreases with depth into the gases. As a result, the cloud base can vary from a very light to very dark grey depending on the cloud's thickness and how much light is being reflected or transmitted back to the observer. Thin clouds may look white or appear to have acquired the color of their environment or background. High tropospheric and non-tropospheric clouds appear mostly white if composed entirely of ice crystals and/or supercooled water droplets.\n\nAs a tropospheric cloud matures, the dense water droplets may combine to produce larger droplets, which may combine to form droplets large enough to fall as rain. By this process of accumulation, the space between droplets becomes increasingly larger, permitting light to penetrate farther into the cloud. If the cloud is sufficiently large and the droplets within are spaced far enough apart, it may be that a percentage of the light which enters the cloud is not reflected back out before it is absorbed. A simple example of this is being able to see farther in heavy rain than in heavy fog. This process of reflection/absorption is what causes the range of cloud color from white to black.\n\nOther colors occur naturally in clouds. Bluish-grey is the result of light scattering within the cloud. In the visible spectrum, blue and green are at the short end of light's visible wavelengths, while red and yellow are at the long end. The short rays are more easily scattered by water droplets, and the long rays are more likely to be absorbed. The bluish color is evidence that such scattering is being produced by rain-sized droplets in the cloud. A cumulonimbus cloud emitting green is a sign that it is a severe thunderstorm, capable of heavy rain, hail, strong winds and possible tornadoes. The exact cause of green thunderstorms is still unknown, but it could be due to the combination of reddened sunlight passing through very optically thick clouds. Yellowish clouds may occur in the late spring through early fall months during forest fire season. The yellow color is due to the presence of pollutants in the smoke. Yellowish clouds caused by the presence of nitrogen dioxide are sometimes seen in urban areas with high air pollution levels.\n\nRed, orange and pink clouds occur almost entirely at sunrise and sunset and are the result of the scattering of sunlight by the atmosphere. When the angle between the sun and the horizon is less than 10 percent, as it is just after sunrise or just prior to sunset, sunlight becomes too red due to refraction for any colors other than those with a reddish hue to be seen. The clouds do not become that color; they are reflecting long and unscattered rays of sunlight, which are predominant at those hours. The effect is much like if one were to shine a red spotlight on a white sheet. In combination with large, mature thunderheads this can produce blood-red clouds. Clouds look darker in the near-infrared because water absorbs solar radiation at those wavelengths.\n\nA halo (ἅλως; also known as a nimbus, icebow or gloriole) is an optical phenomenon produced by the interaction of light from the sun or moon with ice crystals in the atmosphere, resulting in colored or white arcs, rings or spots in the sky. Many halos are positioned near the sun or moon, but others are elsewhere and even in the opposite part of the sky. They can also form around artificial lights in very cold weather when ice crystals called diamond dust are floating in the nearby air.\n\nThere are many types of ice halos. They are produced by the ice crystals in cirrus or cirrostratus clouds high in the upper troposphere, at an altitude of to , or, during very cold weather, by ice crystals called diamond dust drifting in the air at low levels. The particular shape and orientation of the crystals are responsible for the types of halo observed. Light is reflected and refracted by the ice crystals and may split into colors because of dispersion. The crystals behave like prisms and mirrors, refracting and reflecting sunlight between their faces, sending shafts of light in particular directions. For circular halos, the preferred angular distance are 22 and 46 degrees from the ice crystals which create them.\nAtmospheric phenomena such as halos have been used as part of weather lore as an empirical means of weather forecasting, with their presence indicating an approach of a warm front and its associated rain.\n\nSun dogs are a common type of halo, with the appearance of two subtly-colored bright spots to the left and right of the sun, at a distance of about 22° and at the same elevation above the horizon. They are commonly caused by plate-shaped hexagonal ice crystals. These crystals tend to become horizontally aligned as they sink through the air, causing them to refract the sunlight to the left and right, resulting in the two sun dogs.\n\nAs the sun rises higher, the rays passing through the crystals are increasingly skewed from the horizontal plane. Their angle of deviation increases and the sundogs move further from the sun. However, they always stay at the same elevation as the sun. Sun dogs are red-colored at the side nearest the sun. Farther out the colors grade to blue or violet. However, the colors overlap considerably and so are muted, rarely pure or saturated. The colors of the sun dog finally merge into the white of the parhelic circle (if the latter is visible).\n\nIt is theoretically possible to predict the forms of sun dogs as would be seen on other planets and moons. Mars might have sundogs formed by both water-ice and CO-ice. On the giant gas planets — Jupiter, Saturn, Uranus and Neptune — other crystals form the clouds of ammonia, methane, and other substances that can produce halos with four or more sundogs.\n\nA common optical phenomenon involving water droplets is the glory. A glory is an optical phenomenon, appearing much like an iconic Saint's halo about the head of the observer, produced by light backscattered (a combination of diffraction, reflection and refraction) towards its source by a cloud of uniformly sized water droplets. A glory has multiple colored rings, with red colors on the outermost ring and blue/violet colors on the innermost ring.\n\nThe angular distance is much smaller than a rainbow, ranging between 5° and 20°, depending on the size of the droplets. The glory can only be seen when the observer is directly between the sun and cloud of refracting water droplets. Hence, it is commonly observed while airborne, with the glory surrounding the airplane's shadow on clouds (this is often called \"The Glory of the Pilot\"). Glories can also be seen from mountains and tall buildings, when there are clouds or fog below the level of the observer, or on days with ground fog. The glory is related to the optical phenomenon anthelion.\nA rainbow is an optical and meteorological phenomenon that causes a spectrum of light to appear in the sky when the Sun shines on to droplets of moisture in the Earth's atmosphere. It takes the form of a multicolored arc. Rainbows caused by sunlight always appear in the section of sky directly opposite the sun, but originate no further than 42 degrees above the horizon for observers on the ground. To see them at higher angles, an observer would need to be in an airplane or near a mountaintop since the rainbow would otherwise be below the horizon. The bigger the droplets which formed the rainbow, the brighter it will be. Rainbows are most common near afternoon thunderstorms during the summer.\n\nA single reflection off the backs of an array of raindrops produces a rainbow with an angular size on the sky that ranges from 40° to 42° with red on the outside. Double rainbows are produced by two internal reflections with angular size of 50.5° to 54° with violet on the outside. Within the \"primary rainbow\" (the lowest, and also normally the brightest rainbow) the arc of a rainbow shows red on the outer (or upper) part of the arc, and violet on the inner section. This rainbow is caused by light being reflected once in droplets of water. In a double rainbow, a second arc may be seen above and outside the primary arc, and has the order of its colors reversed (red faces inward toward the other rainbow, in both rainbows). This second rainbow is caused by light reflecting twice inside water droplets. The region between a double rainbow is dark. The reason for this dark band is that, while light \"below\" the primary rainbow comes from droplet reflection, and light \"above\" the upper (secondary) rainbow also comes from droplet reflection, there is no mechanism for the region \"between\" a double rainbow to show any light reflected from water drops, at all.\n\nA rainbow spans a continuous spectrum of colors; the distinct bands (including the number of bands) are an artifact of human color vision, and no banding of any type is seen in a black-and-white photograph of a rainbow (only a smooth gradation of intensity to a maxima, then fading to a minima at the other side of the arc). For colors seen by a normal human eye, the most commonly cited and remembered sequence, in English, is Newton's sevenfold red, orange, yellow, green, blue, indigo and violet (popularly memorized by mnemonics like Roy G. Biv). However, color-blind persons will see fewer colors.\n\nRainbows can be caused by many forms of airborne water. These include not only rain, but also mist, spray, and airborne dew.\n\nA mirage is a naturally occurring optical phenomenon in which light rays are bent to produce a displaced image of distant objects or the sky. The word comes to English via the French \"mirage\", from the Latin \"mirare\", meaning \"to look at, to wonder at\". This is the same root as for \"mirror\" and \"to admire\". Also, it has its roots in the Arabic \"mirage\".\n\nIn contrast to a hallucination, a mirage is a real optical phenomenon which can be captured on camera, since light rays actually are refracted to form the false image at the observer's location. What the image appears to represent, however, is determined by the interpretive faculties of the human mind. For example, inferior images on land are very easily mistaken for the reflections from a small body of water.\n\nMirages can be categorized as \"inferior\" (meaning lower), \"superior\" (meaning higher) and \"Fata Morgana\", one kind of superior mirage consisting of a series of unusually elaborate, vertically stacked images, which form one rapidly changing mirage.\n\nGreen flashes and green rays are optical phenomena that occur shortly after sunset or before sunrise, when a green spot is visible, usually for no more than a second or two, above the sun, or a green ray shoots up from the sunset point. Green flashes are actually a group of phenomena stemming from different causes, and some are more common than others. Green flashes can be observed from any altitude (even from an aircraft). They are usually seen at an unobstructed horizon, such as over the ocean, but are possible over cloud tops and mountain tops as well.\n\nA green flash from the moon and bright planets at the horizon, including Venus and Jupiter, can also be observed.\n\nThis optical phenomenon occurs because rays of light are strongly bent when they pass through air layers of different temperatures in a steep thermal inversion where an atmospheric duct has formed. A thermal inversion is an atmospheric condition where warmer air exists in a well-defined layer above a layer of significantly cooler air. This temperature inversion is the opposite of what is normally the case; air is usually warmer close to the surface, and cooler higher up. In calm weather, a layer of significantly warmer air can rest over colder dense air, forming an atmospheric duct which acts like a refracting lens, producing a series of both inverted and erect images.\n\nA Fata Morgana is an unusual and very complex form of mirage, a form of superior mirage, which, like many other kinds of superior mirages, is seen in a narrow band right above the horizon. It is an Italian phrase derived from the vulgar Latin for \"fairy\" and the Arthurian sorcerer Morgan le Fay, from a belief that the mirage, often seen in the Strait of Messina, were fairy castles in the air, or false land designed to lure sailors to their death created by her witchcraft. Although the term Fata Morgana is sometimes incorrectly applied to other, more common kinds of mirages, the true Fata Morgana is not the same as an ordinary superior mirage, and is certainly not the same as an inferior mirage.\n\nFata Morgana mirages tremendously distort the object or objects which they are based on, such that the object often appears to be very unusual, and may even be transformed in such a way that it is completely unrecognizable. A Fata Morgana can be seen on land or at sea, in polar regions or in deserts. This kind of mirage can involve almost any kind of distant object, including such things as boats, islands, and coastline.\n\nA Fata Morgana is not only complex, but also rapidly changing. The mirage comprises several inverted (upside down) and erect (right side up) images that are stacked on top of one another. Fata Morgana mirages also show alternating compressed and stretched zones.\n\nThe Novaya Zemlya effect is a polar mirage caused by high refraction of sunlight between atmospheric thermoclines. The Novaya Zemlya effect will give the impression that the sun is rising earlier or setting later than it actually should (astronomically speaking). Depending on the meteorological situation the effect will present the sun as a line or a square (which is sometimes referred to as the \"rectangular sun\"), made up of flattened hourglass shapes. The mirage requires rays of sunlight to have an inversion layer for hundreds of kilometres, and depends on the inversion layer's temperature gradient. The sunlight must bend to the Earth's curvature at least to allow an elevation rise of 5 degrees for sight of the sun disk.\n\nThe first person to record the phenomenon was Gerrit de Veer, a member of Willem Barentsz' ill-fated third expedition into the polar region. Novaya Zemlya, the archipelago where de Veer first observed the phenomenon, lends its name to the effect.\n\nCrepuscular rays are near-parallel rays of sunlight moving through the Earth's atmosphere, but appear to diverge because of linear perspective. They often occur when objects such as mountain peaks or clouds partially shadow the sun's rays like a cloud cover. Various airborne compounds scatter the sunlight and make these rays visible, due to diffraction, reflection, and scattering.\n\nCrepuscular rays can also occasionally be viewed underwater, particularly in arctic areas, appearing from ice shelves or cracks in the ice. Also they are also viewed in days when the sun hits the clouds in a perfect angle shining upon the area.\n\nThere are three primary forms of crepuscular rays:\n\nThey are commonly seen near sunrise and sunset, when tall clouds such as cumulonimbus and mountains can be most effective at creating these rays.\n\nAnticrepuscular rays while parallel in reality are sometimes visible in the sky in the direction opposite the sun. They appear to converge again at the distant horizon.\n\nAtmospheric refraction influences the apparent position of astronomical and terrestrial objects, usually causing them to appear higher than they actually are. For this reason navigators, astronomers, and surveyors observe positions when these effects are minimal. Sailors will only shoot a star when 20° or more above the horizon, astronomers try to schedule observations when an object is highest in the sky, and surveyors try to observe in the afternoon when refraction is minimum.\n\n"}
{"id": "54672735", "url": "https://en.wikipedia.org/wiki?curid=54672735", "title": "BRAC Onnesha", "text": "BRAC Onnesha\n\nBRAC Onnesha is the first nanosatellite built in Bangladesh to be launched into space. The satellite was designed and built in conjunction with Kyushu Institute of Technology Birds-1 program, which has the goal of helping countries build their first satellite. It was designed and built over a two year period.\n\nThe satellite has imaging capabilities and can transmit songs to Earth that are uploaded to its memory. It was launched on a Falcon 9 rocket to the International Space Station on 3 June 2017, after which it was released from the \"Kibō\" module. The satellite completes an orbit once every 90 minutes.\n\nJapan supports non-spacefaring countries to build their first satellite through a program called The Joint Global Multi-Nation Birds Satellite project (BIRDS). Besides Japan, four countries participated in the Birds-1 program: Ghana, Mongolia, Nigeria, and Bangladesh. The five satellites were identical in their design.\n\nThe idea to develop a satellite was conceived in 2013. On 15 June 2016, Syed Saad Andaleeb, Vice Chancellor at BRAC University, signed a contract with the Kyushu Institute of Technology (Kyutech), Japan, on behalf of BRAC University. This led to the collaborative building of the first experimental university-made nano-satellite of Bangladesh, designed, developed and assembled by three Bangladeshi students at the Kyushu Institute of Technology. On 8 February 2017, Andaleeb received \"BRAC Onnesha\" from Kyutech's President Yuji Oie and Mengu Cho, Kyutech's Director of the Laboratory of Spacecraft Environment Interaction Engineering.\n\nBRAC University took up an initiative to start space and remote sensing research in collaboration with Kyutech and the Space Research and Remote Sensing Organization (SPARRSO). BRAC University has built a ground station at its Mohakhali campus to analyse data and photographs sent from space for further research purposes.\n\nProfessor Mengu Cho of Kyutech said, \"\"BRAC ONNESHA\" was easy to build and affordable and their prime objective was to educate the students so that they could go back to build one completely by themselves, presumably in October 2017.\"\n\nThe two-year period spanning the development, construction, launch and operation of the satellites engaged three university students from each of the five participating countries. All five satellites had to be identical to each other in the class of a 1U CubeSat. The satellite cost about to manufacture and launch.\n\nSpaceX launched the satellite on its CRS-11 mission to the International Space Station (ISS) on 3 June 2017. The satellite was carried in a Dragon spacecraft on a Falcon 9 rocket, launched from NASA's Kennedy Space Center Pad 39A. This was the 100th launch from Pad 39A and the first time SpaceX reused one of its Dragon capsules. Once on the ISS, the satellite was deployed from the Japanese \"Kibō\" module.\n\nThe satellite orbits the Earth at an altitude of approximately and at an inclination of 51.6 degrees. The satellite travels around the Earth every 92 minutes at a velocity of \n\nThe satellite communicates with seven ground stations: one in each of the countries participating in the Birds-1 program, and one each in Thailand and Taiwan. Bangladesh's ground station, inaugurated 25 May 2017, is on the top of a building at BRAC University.\n\n\"BRAC Onnesha\" is a nanosatellite shaped as a cube capable of completing one orbit above the ground in 90 minutes and passing over Bangladesh four to six times a day. The primary objective of the satellite is to image vegetation, urbanization, flood, water resources, and forestry.\n\n"}
{"id": "22232973", "url": "https://en.wikipedia.org/wiki?curid=22232973", "title": "Bali Declaration by Climate Scientists", "text": "Bali Declaration by Climate Scientists\n\nThe 2007 Bali Declaration by Climate Scientists was a statement signed by over 200 climate scientists advocating specific targets for greenhouse gas emissions for the 21st century. The statement was based on the United Nations Framework Convention on Climate Change Article 2 that committed signatories to the \"...stabilization of greenhouse gas concentrations in the atmosphere at a level that would prevent dangerous anthropogenic interference with the climate system\" and on the science available in the Intergovernmental Panel on Climate Change Fourth Assessment report (IPCC AR4). The Bali Declaration was released to coincide with the 2007 United Nations Climate Change Conference which took place in Bali 3–15 December 2007.\n"}
{"id": "36750503", "url": "https://en.wikipedia.org/wiki?curid=36750503", "title": "Beroe (mythology)", "text": "Beroe (mythology)\n\nBeroe (Greek: Βερόη) in Greek mythology is a nymph of Beirut, the daughter of Aphrodite and Adonis, and sister of Golgos. She was wooed by both Dionysus and Poseidon, eventually marrying Poseidon.\n\nAt the birth of Beroe, Hermes acted as the midwife and assisted in the delivery of Beroe then the Virgin Astraia (lady of justice) took the infant Beroe and fed her with the wise breast and told her words of law, feeding her honey and washing her with sacred water. As she grew up, she was highly regarded as an outstanding beauty and destined to marry Poseidon. Eros struck her twice with arrows of love and a confrontation took place for her love. Beroe wore no ornaments or make-up, and she was not vain and never examined herself in the mirror. Beroe was a mortal but often her beauty was compared to that of goddesses.\n\n"}
{"id": "44337959", "url": "https://en.wikipedia.org/wiki?curid=44337959", "title": "Bessang Pass Natural Monument", "text": "Bessang Pass Natural Monument\n\nThe Bessang Pass Natural Monument is a protected area and memorial that commemorates the victory on 14 June 1945 by Filipino soldiers serving the U.S. Army Forces in the Philippines Northern Luzon (USAFIP-NL) over the Imperial Japanese Army in the Battle of Bessang Pass which led to Japan's eventual surrender and end to World War II in the Philippines. It covers an area of and a buffer zone of in the municipality of Cervantes in Ilocos Sur. The mountain pass was initially a component of the \"Tirad Pass National Park\", declared in 1938 through Proclamation No. 294 by then President Manuel Luis Quezon. On 10 August 1954, it was established as the Bessang Pass National Shrine with an area of by virtue of Proclamation No. 55 signed by President Ramon Magsaysay. The national shrine was finally declared and reclassified as a natural monument under the National Integrated Protected Areas System in April 2000 through Proclamation No. 284 by President Joseph Estrada.\nBessang Pass lies along Route 4, which is now known as the Tagudin–Cervantes–Sabangan Road (N205) in the barangay of Malaya. The pass lies on the southeast side of Langiatan Hill, which reaches a height of . South of the pass, Mount Namogoian rises to . East of Langiatan Hill is Magun Hill at .\n\nThe park contains pine forests as well as mossy type forests. It is crossed by the Bessang Creek and Matukbo River which provides the water supply for Cervantes and other surrounding communities. The park is also the habitat of 29 bird species, 5 mammals, and reptiles such as the monitor lizard and different species of snakes.\n\nA monument honoring the 1,395 USAFIP-NL members killed during the battle was unveiled in the park in 1954.\n\n"}
{"id": "417610", "url": "https://en.wikipedia.org/wiki?curid=417610", "title": "Charles Wilkes", "text": "Charles Wilkes\n\nCharles Wilkes (April 3, 1798 – February 8, 1877) was an American naval officer, ship's captain, and explorer. He led the United States Exploring Expedition, 1838-1842 and commanded the ship in the \"Trent\" Affair during the American Civil War (1861–1865), where he attacked a Royal Mail Ship, almost leading to war between the US and the UK. His behavior led to two convictions by court-martial, one stemming from the massacre of almost 80 Fijians on Malolo in 1840.\n\nWilkes was born in New York City, on April 3, 1798, as the great nephew of the former Lord Mayor of London John Wilkes. His mother was Mary Seton, who died in 1802 when Charles was just three years old. As a result, Charles was raised by his aunt, Elizabeth Ann Seton, who would later convert to Roman Catholicism and become the first American-born woman canonized a saint by the Catholic Church. When Elizabeth was left widowed with five children, Charles was sent to a boarding school, and later attended Columbia College, which is the present-day Columbia University. He entered the United States Navy as a midshipman in 1818, and became a lieutenant in 1826.\n\nIn 1833, for his survey of Narragansett Bay, he was placed in charge of the Navy's Department of Charts and Instruments, out of which developed the Naval Observatory and Hydrographic Office. Wilkes' interdisciplinary expedition (1838–1842) set a physical oceanography benchmark for the office's first superintendent Matthew Fontaine Maury.\n\nDuring the 1820s, Wilkes was a member of the prestigious Columbian Institute for the Promotion of Arts and Sciences, which counted among its members presidents Andrew Jackson and John Quincy Adams and many prominent men of the day, including well-known representatives of the military, government service, medical and other professions.\n\nIn 1838, although not yet a seasoned naval line officer, Wilkes was experienced in nautical survey work, and was working with civilian scientists. Upon this background, he was given command of the government exploring expedition \"... for the purpose of exploring and surveying the Southern Ocean... as well to determine the existence of all doubtful islands and shoals, as to discover, and accurately fix, the position of those which [lay] in or near the track of our vessels in that quarter, and [might] have escaped the observation of scientific navigators.\" The US Exploring Squadron was authorized by act of the Congress on May 18, 1836.\n\nThe Exploring Expedition, commonly known as the \"Wilkes Expedition,\" included naturalists, botanists, a mineralogist, taxidermists, artists and a philologist, and it was carried by (780 tons) and (650 tons), the brig (230 tons), the store-ship , and two schooners, (110 tons) and (96 tons).\n\nDeparting from Hampton Roads on August 18, 1838, the expedition stopped at the Madeira Islands and Rio de Janeiro; visited Tierra del Fuego, Chile, Peru, the Tuamotu Archipelago, Samoa, and New South Wales; from Sydney, Australia sailed into the Antarctic Ocean in December 1839 and reported the discovery \"of an Antarctic continent west of the Balleny Islands\" of which it sighted the coast on January 25, 1840. Next the expedition visited Fiji and the Hawaiian Islands. In Fiji, the expedition kidnapped the chief Ro Veidovi, charging him with the murder of a crew of American whalers. And, in July 1840, two sailors, one of whom was Wilkes' nephew, Midshipman Wilkes Henry, were killed while bartering for food on Fiji's Malolo Island. Wilkes' retribution was swift and severe. According to an old man of Malolo Island, nearly 80 Fijians were killed in the incident.\n\nFrom December 1840 to March 1841, he employed hundreds of native Hawaiian porters and many of his men to haul a pendulum to the summit of Mauna Loa to measure gravity. Instead of using the existing trail, he blazed his own way, taking much longer than he anticipated. The conditions on the mountain reminded him of Antarctica. Many of his crew suffered snow blindness, altitude sickness and foot injuries from wearing out their shoes.\nHe explored the west coast of North America, including the Strait of Juan de Fuca, Puget Sound, the Columbia River, San Francisco Bay and the Sacramento River, in 1841.\n\nHe held the first American Independence Day celebration west of the Mississippi River in Dupont, Washington on July 5, 1841.\n\nThe United States Exploring Expedition passed through the Ellice Islands and visited Funafuti, Nukufetau and Vaitupu in 1841. The expedition returned by way of the Philippines, the Sulu Archipelago, Borneo, Singapore, Polynesia and the Cape of Good Hope, reaching New York on June 10, 1842.\n\nAfter having completely encircled the globe (his was the last all-sail naval mission to do so), Wilkes had logged some 87,000 miles and lost two ships and 28 men. Wilkes was court-martialled upon his return for the loss of one of his ships on the Columbia River bar, for the regular mistreatment of his subordinate officers, and for excessive punishment of his sailors. A major witness against him was ship doctor Charles Guillou.\nHe was acquitted on all charges except illegally punishing men in his squadron. For a short time, he was attached to the Coast Survey, but from 1844 to 1861, he was chiefly engaged in preparing the report of the expedition.\n\nHis \"Narrative of the United States Exploring Expedition\" (5 volumes and an atlas) was published in 1844. He edited the scientific reports of the expedition (19 volumes and 11 atlases, 1844–1874) and was the author of Vol. XI (Meteorology) and Vol. XXIII (Hydrography).\nAlfred Thomas Agate, engraver and illustrator, was the designated portrait and botanical artist of the expedition. His work was used to illustrate the \"Narrative of the United States Exploring Expedition\".\n\nThe \"Narrative\" contains much interesting material concerning the manners, customs, political and economic conditions in many places then little known. Wilkes' 1841 Map of the Oregon Territory pre-dated John Charles Fremont's first Oregon Trail pathfinder expedition guided by Kit Carson during 1842.\n\nOther valuable contributions were the three reports of James Dwight Dana on \"Zoophytes\" (1846), \"Geology\" (1849) and \"Crustacea\" (1852–1854). Moreover, the specimens and artifacts brought back by expedition scientists ultimately formed the foundation for the Smithsonian Institution collection. In addition to many shorter articles and reports, Wilkes published the major scientific works \"Western America, including California and Oregon\" in 1849, and \"Theory of the Winds\" in 1856.\n\nWilkes was promoted to the rank of commander in 1843 and that of captain in 1855. At the outbreak of the American Civil War, he was assigned to the command of to search for the Confederate commerce destroyer .\n\nAs part of these duties he visited the British colony of Bermuda. Acting on orders, Wilkes remained in port for nearly a week aboard his flagship, , violating the British rule that allowed American naval vessels (of either side) to remain in port for only a single day. While Wilkes remained in port, his gunboats and blockaded Saint George's harbor, a key Confederate blockade runner base. The gunboats opened fire at the Royal Mail Ship \"Merlin\".\n\nWhen Wilkes learned that James Murray Mason and John Slidell, two Confederate commissioners to England, were bound for England on a British packet boat, , he ordered the steam frigate \"San Jacinto\" to stop them. On November 8, 1861, \"San Jacinto\" met \"Trent\" and fired two shots across its bow, forcing the ship to stop. A boarding party from \"San Jacinto\" led by its captain then boarded \"Trent\" and arrested Mason and Slidell. The diplomats were taken to Fort Warren in Boston Harbor.\n\nThe actions of \"The Notorious Wilkes,\" as Bermuda media branded him, convinced many that full-scale war between the United States and the United Kingdom was inevitable.\n\nHe was officially thanked by Congress \"for his brave, adroit and patriotic conduct\". However, his action was later disavowed by President Lincoln due to diplomatic pressure by the British Government. (Mason and Slidell were released.) His next service was in the James River flotilla and he was placed on the retired list on December 21, 1861. Subsequently, after reaching the rank of commodore on July 16, 1862, he was assigned to duty against blockade runners in the West Indies.\n\nWilkes acquired a reputation for sometimes acting arrogant and capriciously, perhaps partly because of his open conflict with Gideon Welles, who was the Secretary of the Navy.\nWelles recommended that Wilkes had been too old to receive the rank of commodore under the act then governing promotions. Wilkes wrote a scathing letter to Welles in response. The controversy ended in his court-martial in 1864. He was found guilty of disobedience of orders, insubordination, and other specifications. He was sentenced to public reprimand and suspension for three years. However, Lincoln reduced the suspension to one year, and the balance of charges were dropped. On July 25, 1866, he was promoted to the rank of rear admiral on the retired list.\n\nSome historians speculate that Wilkes' obsessive behavior and harsh code of shipboard discipline shaped Herman Melville's characterization of Captain Ahab in \"Moby-Dick\". Such speculation is not mentioned in the U.S. Naval historical archives.\n\nIn addition to his contribution to U.S. Naval history and scientific study in his official \"Narrative of the Exploration Squadron\" (6 volumes), Wilkes wrote his autobiography.\n\nWilkes died in Washington, DC, with the rank of Rear Admiral.\n\nIn August 1909, the United States moved his remains to Arlington National Cemetery. His gravestone says that \"he discovered the Ant-arctic continent.\"\n\nThe US Navy named four ships for Wilkes: torpedo boat served around the turn of the 20th century, destroyer served during World War I, and destroyer served during World War II.\nAn oceanographic survey vessel, USS \"Wilkes\" (T-AGS-33), was launched in 1969, sponsored by Mrs. Hollis Lyons Joy (Deborah Wilkes Joy), Wilkes' great granddaughter.\n\nIn 1923, Wilkes Island, one of the three islands surrounding the lagoon at Wake Atoll was named for Wilkes by Alexander Wetmore, lead scientist of the Tanager Expedition.\n\nCaptain Charles Wilkes Elementary in Bainbridge Island, Washington is his namesake.\n\nWilkes Boulevard in Columbia, Missouri is named in his honor.\n\n\n\n\n\n\n"}
{"id": "14285729", "url": "https://en.wikipedia.org/wiki?curid=14285729", "title": "Chondritic uniform reservoir", "text": "Chondritic uniform reservoir\n\nThe CHondritic Uniform Reservoir or CHUR is a scientific model in astrophysics and geochemistry for the mean chemical composition of the part of the Solar Nebula from which, during the formation of the Solar System, chondrites formed. This hypothetical chemical reservoir is thought to have been similar in composition to the current photosphere of the Sun.\n\nWhen the Sun formed from its protostar, around 4.56 billion years ago, the solar wind blew all gas particles from the central part of the Solar Nebula. In this way most lighter volatiles (e.g. hydrogen, helium, oxygen, carbon dioxide), that had not yet condensed in the inner, warmer regions of the nebula, were lost. This fractionation process is the reason why the terrestrial planets and asteroid belt are relatively enriched in heavy elements in respect to the Sun or the gas planets.\n\nA certain type of meteorites, CI-chondrites, have a chemical composition that is almost identical to the solar photosphere, except for the abundances of volatiles. Because the Sun contains 99.86% of the mass of the Solar System, they are considered to have the same composition as the solar nebula with the exception of volatile loss and are therefore representative of the material from which the terrestrial planets, including the Earth, were formed.\n\n"}
{"id": "53514234", "url": "https://en.wikipedia.org/wiki?curid=53514234", "title": "Cueva Alfredo Jahn Natural Monument", "text": "Cueva Alfredo Jahn Natural Monument\n\nThe Cueva Alfredo Jahn Natural Monument () Also Alfredo Jahn Cave Natural Monument or Tapa de Cambural Cave It is a protected area with the status of a natural monument that is located 4 km west of the town of Birongo, Miranda State, at the eastern end of the Coastal Range of the Cordillera de la Costa. With a 4.29 km gallery development, it is the largest cave in central Venezuela, the sixth in Venezuela and one of the most visited in the country.\n\nIt was decreed as a Natural Monument on December 12, 1978 with Decree No. 2989 published in Official Gazette No. 2,417 of March 7, 1979. The monument was named in honor of Alfredo Jahn, pioneer of various scientific disciplines in Venezuela as Geography, geography, topography, astronomy, anthropology, linguistics and botany, and who was also founder of the Venezuelan Society of Natural Sciences.\n\nIt is a moist cave, still active, which has been formed by the action of the Cambural Gorge. Its calcite walls are covered with spectacular stalagmites, stalactites and columns, which reach its maximum development in the Hall of the Chaguaramo or Hall of the Rain.\n\nThe temperature inside the cave ranges between 22 °C and 26 °C. The cave is surrounded by a pre-montane seasonal semideciduous forest and presents three dense tree layers.\n"}
{"id": "37793839", "url": "https://en.wikipedia.org/wiki?curid=37793839", "title": "Ecobee", "text": "Ecobee\n\nEcobee is a Canadian home automation company that makes thermostats for residential and commercial use. The thermostats are controlled by using the built-in touchscreen, using a registered login at https://www.ecobee.com/consumerportal, or using a companion app available for iOS, Android and the Apple Watch.\n\nThe ecobee4 is ecobee's flagship product which was originally launched May 3, 2017. It is a touchscreen thermostat that works with up to 32 remote temperature/motion sensors to adjust the thermostat based on where you are. It also has IFTTT integration. An updated version of the ecobee3 was released in 2015 that works with Apple HomeKit. The ecobee3 lite was released on October 17, 2016. The ecobee3 lite is a less expensive thermostat that resembles the ecobee3, but does not include any remote temperature sensors. Support for remote temperature sensors was added to the ecobee3 lite in March 2017.\n\nOn May 3, 2017, the company announced the unveiling of its 4th-generation product (ecobee4), which includes built-in Amazon Alexa Voice Service.\n\nThe ecobee4, ecobee3 (and lite) allows the user to set different schedules each day for various modes, including home, away, and sleep. The remote sensors detect temperature and occupancy and can engage a Smart Away mode if no movement is detected. The ecobee3/4 integrates the remote sensors by controlling to the average room temperature for all sensors that are included in the mode setting (and detect occupancy, if enabled). A vacation mode can be programmed for extended times away from home.\n\nWith this smart thermostat, you can set convenient reminders for HVAC maintenance, Furnace filter replacement, UV Lamp replacement, as well as alerts for Low Temperature, High Temperature, Low Humidity, and High Humidity.\n\nSwitch+ is a smart light switch announced in May 2017. The switch has a microphone with built-in Amazon Alexa, along with occupancy and daylight sensors. It was released on March 26, 2018.\n\nEcobee was founded in 2007. It has been recognized with a number of awards, including the Deloitte Technology Green 15 Award for Canadian green technology companies, and the 2011 AHR Expo Innovation Award in the category of building automation.\n\nIn March 2018, ecobee raised a CA$80 million series C round of funding.\n\nEcobee products integrate with: Microsoft's Cortana, Amazon Alexa, Apple HomeKit, Google Assistant, Samsung SmartThings, Wink, Haiku Fans, IFTTT, Logitech Harmony, Vera, and Control4. Ecobee uses an open API for additional integration options.\n\n"}
{"id": "23476307", "url": "https://en.wikipedia.org/wiki?curid=23476307", "title": "Ecology and Law", "text": "Ecology and Law\n\nEcology and Law (\"Экология и Право\") is a quarterly magazine published by the St. Petersburg branch of the Environmental Rights Center Bellona. Lina Grain has been its editor-in-chief since 2008. It commenced publication in 2002. \n\nThe main focus of the magazine is \"protection of citizens' environmental rights\" in Russia.\n\nThe magazine's founding editor was Grigory Pasko, who served in that role from 2002-2008. He was succeeded briefly by Egorenko Alexander (2008). According to the magazine's website, Pasko was imprisoned in 2002 for \"coverage of cases of violations of nuclear safety at the [naval] bases of the [Russian] Pacific Fleet.\"\n\n"}
{"id": "4632932", "url": "https://en.wikipedia.org/wiki?curid=4632932", "title": "Edwin Way Teale", "text": "Edwin Way Teale\n\nEdwin Way Teale (June 2, 1899 – October 18, 1980) was an American naturalist, photographer and writer. Teale's works serve as primary source material documenting environmental conditions across North America from 1930 - 1980. He is perhaps best known for his series \"The American Seasons\", four books documenting over of automobile travel across North America following the changing seasons.\n\nBorn Edwin Alfred Teale in Joliet, Illinois, to Oliver Cromwell and Clara Louise (Way) Teale, his interest in the natural world was fostered by childhood summers spent at his grandparents' \"Lone Oak\" farm in Indiana's dune country—experiences recalled in his book \"Dune Boy\" (1943). At the age of nine, Teale declared himself a naturalist and at 12 changed his name to Edwin Way Teale.\n\nHe received a B.A. from Earlham College in English literature in 1922, then took a job at Friends University in Wichita, Kansas. Teale taught at Friends from 1922–1924 and served as men's and women's debate coach, yearbook adviser and chairman of the campus Peace Contest. In 1923 he married Nellie Imogene Donovan, also on the Friends faculty, whom he had met while at Earlham College.\n\nIn 1924, Edwin and Nellie moved to New York so Edwin could pursue his education at Columbia University. Teale chose Columbia in part\n\n... because it was in New York and it wouldn't take two months to get a manuscript back from a magazine. \n\nIn 1926 he received his Master of Arts degree from Columbia University.\n\nIn New York, Teale spent 13 years in his first full-time writing job, as a staff writer for \"Popular Science\", working on a wide variety of assignments.\nIn 1937, Teale's first photographic nature study, \"Grassroots Jungle\", was published from among 200 of Teale's insect photographs, many of which were taken on a plot of land near his home on Park Avenue in Baldwin, Long Island This was followed, in 1941, by \"The Golden Throng\", a combination of text and photographs on bees.\n\nAt the age of 42, Teale left \"Popular Science\" to become a freelance photographer and nature writer.\n\nIn 1942 he wrote \"Byways to Adventure: A Guide to Nature Hobbies\" as well as \"Near Horizons,\" which received the 1943 John Burroughs Medal for distinguished natural history writing.\n\nIn March 1945 Edwin's son David was killed in action in Germany. The Teales began a series of trips across the country, in part to deal with their grief. That same year, \"Lost Woods\" was published and received positive reviews.\n\nOn February 14, 1947, the Teales set off in their black Buick for a roadtrip. They headed first to the Florida Everglades, then zigzagged northward following the advance of spring. Teale wrote about the adventure in \"North with the Spring\". The book was followed by three others on the North American seasons: \"Journey Into Summer\", \"Autumn Across America\", and \"Wandering Through Winter\", which won the Pulitzer Prize for General Non-Fiction in 1966.\n\nTeale served as president of the New York Entomological Society from 1944-1949 and the Brooklyn Entomological Society (later incorporated into the New York Entomological Society) from 1949-1953.\n\nTeale worked as a co-writer for a segment titled \"Vernal Equinox\" on the March 20, 1955 episode of \"Omnibus\", a TV-Radio Workshop of the Ford Foundation produced by Robert Saudek and hosted by Alistair Cooke on the CBS Television Network.\n\nTeale became president of the Thoreau Society in 1958, the same year that \"Autumn Across America\" was presented to the White House Library. He received an Indiana Author's Day award in 1960 and the Doctor of Humane Letters (LHD) honorary degree from Indiana University in 1970. Earlham College honored Teale with an Honorary Doctor of Letters degree.\n\nIn 1959, the Teales left the increasing suburbanization of their Long Island home for a farm in Hampton, Connecticut, which they named \"Trail Wood,\" and which Teale chronicled in \"A Naturalist Buys an Old Farm\" (1974). The property was further described in \"A Walk through the Year\" (1978). Situated next to the Natchaug State Forest, Trail Wood is now managed as a nature preserve by the Connecticut Audubon Society.\n\nIn 1975, Teale received the Ecology Award from the Massachusetts Horticultural Society and the Conservation Medal from the New England Wildflower Society.\n\nTeale was an elected fellow of the American Association for the Advancement of Science and the New York Academy of Sciences, and an associate of the Royal Photographic Society.\n\nIn 1980 while working with author Ann Zwinger on the book \"A Conscious Stillness: Two Naturalists on Thoreau's Rivers\", Teale died. Teale's portion of the book was nearly complete at the time of his death, and he was included as co-author when the book was published in 1982.\n\nTeale's body was buried at North Cemetery, Hampton, Connecticut.\n\nNellie Teal died in July, 1993 at the age of 92.\n\nTeale's papers consume in the University of Connecticut Archives & Special Collections at the Thomas J. Dodd Research Center in Storrs, Connecticut and include:\n\n... field notes and drafts for each of his books, early childhood writings, professional writings for magazines, newspapers and book reviews, correspondence- both personal and professional, personal and family documents, scrapbooks, and memorabilia, as well as his photographs (prints, negatives, and transparencies) and his personal library. There is also one box of original John Burroughs material Teale collected over the years.\n\nTeale's last will and testament of September, 1980, bequested to The Concord Free Public Library, Concord, Massachusetts, his\n\n... collection of Henry Thoreau books, letters, correspondence, momentos [sic] and any other material dealing with Henry Thoreau, all ... material dealing with Ralph Waldo Emerson and all other material ... dealing with or relating to Concord, Massachusetts. The collection consumes including 12 containers, plus 108 printed books and pamphlets.\n\n\nBooks About Edwin Way Teale\n\n"}
{"id": "19272020", "url": "https://en.wikipedia.org/wiki?curid=19272020", "title": "Gaia", "text": "Gaia\n\nIn Greek mythology, Gaia ( or ; from Ancient Greek , a poetical form of Γῆ \"Gē\", \"land\" or \"earth\"), also spelled Gaea (), is the personification of the Earth and one of the Greek primordial deities. Gaia is the ancestral mother of all life: the primal Mother Earth goddess. She is the immediate parent of Uranus (the sky), from whose sexual union she bore the Titans (themselves parents of many of the Olympian gods) and the Giants, and of Pontus (the sea), from whose union she bore the primordial sea gods. Her equivalent in the Roman pantheon was Terra.\n\nThe Greek name Γαῖα (\"Gaĩa\") is a mostly epic, collateral form of Attic Γῆ (\"Gê\"), Doric Γᾶ (\"Gã\", perhaps identical to Δᾶ \"Dã\") meaning \"Earth\", a word of uncertain origin. Robert S. P. Beekes has suggested a Pre-Greek origin. It, however, could be related to the Avestan word \"gaiia\" \"life\" (cf. \"gaēθā\" \"[material] world, totality of creatures\" and \"gaēθiia\" \"belonging to, residing in the worldly or material sphere, material\") or perhaps to Avestan \"gairi\" \"mountain\".\n\nIn Mycenean Greek \"Ma-ka\" (transliterated as \"Ma-ga\", \"Mother Gaia\") also contains the root \"ga-\".\n\nHesiod's \"Theogony\" tells how, after Chaos, \"wide-bosomed\" Gaia (Earth) arose to be the everlasting seat of the immortals who possess Olympus above, and the depths of Tartarus below (as some scholars interpret it). He then tells that Gaia brought forth her equal Uranus (Heaven, Sky) to \"cover her on every side\" and to be the abode of the gods. Gaia also bore the hills (ourea), and Pontus (Sea), \"without sweet union of love\" (i.e., with no father). Afterwards with Uranus she gave birth to the Titans, as Hesiod tells it:\"She lay with Heaven and bore deep-swirling Oceanus, Coeus and Crius and Hyperion and Iapetus, Theia and Rhea, Themis and Mnemosyne and gold-crowned Phoebe and lovely Tethys. After them was born Cronos (Cronus) the wily, youngest and most terrible of her children, and he hated his lusty sire.\"According to Hesiod, Gaia conceived further offspring with Uranus, first the giant one-eyed Cyclopes: Brontes (\"Thunder\"), Steropes (\"Lightning\") and Arges (\"Bright\"); then the Hecatonchires: Cottus, Briareos and Gyges, each with a hundred arms and fifty heads. As each of the Cyclopes and Hecatonchires were born, Uranus hid them in a secret place within Gaia, causing her great pain. So Gaia devised a plan. She created a grey flint (or adamantine) sickle. And Cronus used the sickle to castrate his father Uranus as he approached Gaia to have sex with her. From Uranus' spilled blood, Gaia produced the Erinyes, the Giants and the Meliae (ash-tree nymphs). From the testicles of Uranus in the sea came forth Aphrodite.\n\nBy her son Pontus, Gaia bore the sea-deities Nereus, Thaumas, Phorcys, Ceto, and Eurybia.\n\nBecause Cronus had learned from Gaia and Uranus that he was destined to be overthrown by one of his children, he swallowed each of the children born to him by his Titan sister Rhea. But when Rhea was pregnant with her youngest child, Zeus, she sought help from Gaia and Uranus. When Zeus was born, Rhea gave Cronus a stone wrapped in swaddling-clothes in his place, which Cronus swallowed, and Gaia took the child into her care.\n\nWith the help of Gaia's advice, Zeus defeated the Titans. But afterwards, Gaia, in union with Tartarus, bore the youngest of her sons Typhon, who would be the last challenge to the authority of Zeus.\n\nAccording to Hyginus, Earth (Gaia), along with Heaven and Sea were the children of Aether and Day (Hemera). According to Apollodorus, Gaia and Tartarus were the parents of Echidna.\n\nZeus hid Elara, one of his lovers, from Hera by stowing her under the earth. His son by Elara, the giant Tityos, is therefore sometimes said to be a son of Gaia, the earth goddess.\n\nGaia also made Aristaeus immortal.\n\nIn classical art Gaia was represented in one of two ways. In Athenian vase painting she was shown as a matronly woman only half risen from the earth, often in the act of handing the baby Erichthonius,a future king of Athens, to Athena to foster). In mosaic representations, she appears as a woman reclining upon the earth surrounded by a host of Carpi, infant gods of the fruits of the earth.\n\nOaths sworn in the name of Gaia, in ancient Greece, were considered the most binding of all.\n\nShe was also worshipped under the epithet \"Anesidora\", which means \"giver of gifts\". Other epithets was Calligeneia, Eurusternos, and Pandôros.\n\nIn ancient times, Gaia was mainly worshipped alongside Demeter and as a part of the cult of Demeter, and does not seem to have had a separate cult. Being a chthonic deity, black animals were sacrificed to her: \n\nGaia is believed by some sources to be the original deity behind the Oracle at Delphi. It was thus said: \"That word spoken from tree-clad mother Gaia's (Earth's) navel-stone [Delphoi].\" Depending on the source, Gaia passed her powers on to Poseidon, Apollo, or Themis. Pausanias wrote:\n\nApollo is the best-known as the oracle power behind Delphi, long established by the time of Homer, having killed Gaia's child Python there and usurped the chthonic power. Hera punished Apollo for this by sending him to King Admetus as a shepherd for nine years.\n\nGaia or Ge had at least three sanctuaries in Greece, which where mentioned by Pausanias. There was a temple of Ge Eurusternos on the Crathis near Aegae in Achaia, with \"a very ancient statue\":\n\nPausanias also mention the sanctuary of Ge Gasepton in Sparta, and a sanctuary of Ge Kourotrophe (Nurse of the Young) at Athens.\n\nAside from her temples, Gaia also had altars as well as sacred spaces in the sanctuaries of other gods. Close to the sanctuary of Eileithyia in Tegea was an altar of Ge; Phlya and Myrrhinos had an altar to Ge under the name Thea Megale (Great goddess);, as well as Olympia which additionally, similar to Delphi, also said to have had an oracle to Gaia: \n\nHer statue where naturally to be found in the temples of Demeter, such as the Temple of Demeter in Achaia: \"They [the Patraians of Akhaia (Achaea)] have also a grove by the sea, affording in summer weather very agreeable walks and a pleasant means generally of passing the time. In this grove are also two temples of divinities, one of Apollon, the other of Aphrodite . . . Next to the grove is a sanctuary of Demeter; she and her daughter [Persephone] are standing, but the image of Ge (Earth) is seated.\" The Temple of Zeus Olympios in Athens reportedly had an enclosure of Ge Olympia: \n\nIn Athens, there was a statue of Gaia on the Acropolis decpicting her besieging Zeus for rain, as well as an image of her close to the court of the Areopagos in Athens, alongside the statues of Plouton and Hermes, \"by which sacrifice those who have received an acquittal on the Areopagos\".\n\nSome modern sources, such as James Mellaart, Marija Gimbutas and Barbara Walker, claim that Gaia as Mother Earth is a later form of a pre-Indo-European Great Mother, venerated in Neolithic times. Her existence is a speculation, and controversial in the academic community. Some modern mythographers, including Karl Kerenyi, Carl A. P. Ruck and Danny Staples interpret the goddesses Demeter the \"mother,\" Persephone the \"daughter\" and Hecate the \"crone,\" as aspects of a former Great goddess identified by some as Rhea or as Gaia herself. In Crete, a goddess was worshiped as \"Potnia Theron\" (the \"Mistress of the Animals\") or simply Potnia (\"Mistress\"), speculated as Rhea or Gaia; the title was later applied in Greek texts to Demeter, Artemis or Athena. The mother-goddess Cybele from Anatolia (modern Turkey) was partly identified by the Greeks with Gaia, but more so with Rhea and Demeter.\n\nMany Neopagans worship Gaia. Beliefs regarding Gaia vary, ranging from the belief that Gaia is the Earth to the belief that she is the spiritual embodiment of the earth, or the Goddess of the Earth.\n\nThe mythological name was revived in 1979 by James Lovelock, in \"Gaia: A New Look at Life on Earth\"; his Gaia hypothesis was supported by Lynn Margulis. The hypothesis proposes that living organisms and inorganic material are part of a dynamical system that shapes the Earth's biosphere, and maintains the Earth as a fit environment for life. In some Gaia theory approaches, the Earth itself is viewed as an organism with self-regulatory functions. Further books by Lovelock and others popularized the Gaia Hypothesis, which was embraced to some extent by New Age environmentalists as part of the heightened awareness of environmental concerns of the 1990s.\n\nGaia is the personification of the Earth and these are her offspring as related in various myths. Some are related consistently, some are mentioned only in minor variants of myths, and others are related in variants that are considered to reflect a confusion of the subject or association.\n\n<nowiki>*</nowiki> Some said that those marked with a * were born from Uranus' blood when Cronus castrated him.\n\n^ Kouretes were born from rainwater (Uranus fertilizing Gaia)\n\n\n\n"}
{"id": "13021878", "url": "https://en.wikipedia.org/wiki?curid=13021878", "title": "Geothermal power", "text": "Geothermal power\n\nGeothermal power is power generated by geothermal energy. Technologies in use include dry steam power stations, flash steam power stations and binary cycle power stations. Geothermal electricity generation is currently used in 24 countries, while geothermal heating is in use in 70 countries.\n\nAs of 2015, worldwide geothermal power capacity amounts to 12.8 gigawatts (GW), of which 28 percent or 3,548 megawatts are installed in the United States. International markets grew at an average annual rate of 5 percent over the three years to 2015, and global geothermal power capacity is expected to reach 14.5–17.6 GW by 2020. Based on current geologic knowledge and technology the GEA publicly discloses, the Geothermal Energy Association (GEA) estimates that only 6.9 percent of total global potential has been tapped so far, while the IPCC reported geothermal power potential to be in the range of 35 GW to 2 TW. Countries generating more than 15 percent of their electricity from geothermal sources include El Salvador, Kenya, the Philippines, Iceland, New Zealand and Costa Rica.\n\nGeothermal power is considered to be a sustainable, renewable source of energy because the heat extraction is small compared with the Earth's heat content. The greenhouse gas emissions of geothermal electric stations are on average 45 grams of carbon dioxide per kilowatt-hour of electricity, or less than 5 percent of that of conventional coal-fired plants.\n\nAs a source of renewable energy for both power and heating, geothermal has the potential to meet 3-5% of global demand by 2050. With economic incentives, it is estimated that by 2100 it will be possible to meet 10% of global demand.\n\nIn the 20th century, demand for electricity led to the consideration of geothermal power as a generating source. Prince Piero Ginori Conti tested the first geothermal power generator on 4 July 1904 in Larderello, Italy. It successfully lit four light bulbs. Later, in 1911, the world's first commercial geothermal power station was built there. Experimental generators were built in Beppu, Japan and the Geysers, California, in the 1920s, but Italy was the world's only industrial producer of geothermal electricity until 1958.\n\nIn 1958, New Zealand became the second major industrial producer of geothermal electricity when its Wairakei station was commissioned. Wairakei was the first station to use flash steam technology. Over the past 60 years, net fluid production has been in excess of 2.5 km. Subsidience at Wairakei-Tauhara has been an issue in a number of formal hearings related to environmental consents for expanded development of the system as a source of renewable energy.\n\nIn 1960, Pacific Gas and Electric began operation of the first successful geothermal electric power station in the United States at The Geysers in California. The original turbine lasted for more than 30 years and produced 11 MW net power.\n\nThe binary cycle power station was first demonstrated in 1967 in the Soviet Union and later introduced to the United States in 1981, following the 1970s energy crisis and significant changes in regulatory policies. This technology allows the use of much lower temperature resources than were previously recoverable. In 2006, a binary cycle station in Chena Hot Springs, Alaska, came on-line, producing electricity from a record low fluid temperature of 57 °C (135 °F).\n\nGeothermal electric stations have until recently been built exclusively where high temperature geothermal resources are available near the surface. The development of binary cycle power plants and improvements in drilling and extraction technology may enable enhanced geothermal systems over a much greater geographical range. Demonstration projects are operational in Landau-Pfalz, Germany, and Soultz-sous-Forêts, France, while an earlier effort in Basel, Switzerland was shut down after it triggered earthquakes. Other demonstration projects are under construction in Australia, the United Kingdom, and the United States of America.\n\nThe thermal efficiency of geothermal electric stations is low, around 7–10%, because geothermal fluids are at a low temperature compared with steam from boilers. By the laws of thermodynamics this low temperature limits the efficiency of heat engines in extracting useful energy during the generation of electricity. Exhaust heat is wasted, unless it can be used directly and locally, for example in greenhouses, timber mills, and district heating. The efficiency of the system does not affect operational costs as it would for a coal or other fossil fuel plant, but it does factor into the viability of the station. In order to produce more energy than the pumps consume, electricity generation requires high temperature geothermal fields and specialized heat cycles. Because geothermal power does not rely on variable sources of energy, unlike, for example, wind or solar, its capacity factor can be quite large – up to 96% has been demonstrated. However the global average capacity factor was 74.5% in 2008, according to the IPCC.\n\nThe Earth’s heat content is about . This heat naturally flows to the surface by conduction at a rate of 44.2 TW and is replenished by radioactive decay at a rate of 30 TW. These power rates are more than double humanity’s current energy consumption from primary sources, but most of this power is too diffuse (approximately 0.1 W/m on average) to be recoverable. The Earth's crust effectively acts as a thick insulating blanket which must be pierced by fluid conduits (of magma, water or other) to release the heat underneath.\n\nElectricity generation requires high-temperature resources that can only come from deep underground. The heat must be carried to the surface by fluid circulation, either through magma conduits, hot springs, hydrothermal circulation, oil wells, drilled water wells, or a combination of these. This circulation sometimes exists naturally where the crust is thin: magma conduits bring heat close to the surface, and hot springs bring the heat to the surface. If no hot spring is available, a well must be drilled into a hot aquifer. Away from tectonic plate boundaries the geothermal gradient is 25–30 °C per kilometre (km) of depth in most of the world, so wells would have to be several kilometres deep to permit electricity generation. The quantity and quality of recoverable resources improves with drilling depth and proximity to tectonic plate boundaries.\n\nIn ground that is hot but dry, or where water pressure is inadequate, injected fluid can stimulate production. Developers bore two holes into a candidate site, and fracture the rock between them with explosives or high-pressure water. Then they pump water or liquefied carbon dioxide down one borehole, and it comes up the other borehole as a gas. This approach is called hot dry rock geothermal energy in Europe, or enhanced geothermal systems in North America. Much greater potential may be available from this approach than from conventional tapping of natural aquifers.\n\nEstimates of the electricity generating potential of geothermal energy vary from 35 to 2000 GW depending on the scale of investments. This does not include non-electric heat recovered by co-generation, geothermal heat pumps and other direct use. A 2006 report by the Massachusetts Institute of Technology (MIT) that included the potential of enhanced geothermal systems estimated that investing 1 billion US dollars in research and development over 15 years would allow the creation of 100 GW of electrical generating capacity by 2050 in the United States alone. The MIT report estimated that over would be extractable, with the potential to increase this to over 2,000 ZJ with technology improvements – sufficient to provide all the world's present energy needs for several millennia.\n\nAt present, geothermal wells are rarely more than deep. Upper estimates of geothermal resources assume wells as deep as . Drilling near this depth is now possible in the petroleum industry, although it is an expensive process. The deepest research well in the world, the Kola superdeep borehole (KSDB-3), is deep. This record has recently been imitated by commercial oil wells, such as Exxon's Z-12 well in the Chayvo field, Sakhalin.\nWells drilled to depths greater than generally incur drilling costs in the tens of millions of dollars. The technological challenges are to drill wide bores at low cost and to break larger volumes of rock.\n\nGeothermal power is considered to be sustainable because the heat extraction is small compared to the Earth's heat content, but extraction must still be monitored to avoid local depletion. Although geothermal sites are capable of providing heat for many decades, individual wells may cool down or run out of water. The three oldest sites, at Larderello, Wairakei, and the Geysers have all reduced production from their peaks. It is not clear whether these stations extracted energy faster than it was replenished from greater depths, or whether the aquifers supplying them are being depleted. If production is reduced, and water is reinjected, these wells could theoretically recover their full potential. Such mitigation strategies have already been implemented at some sites. The long-term sustainability of geothermal energy has been demonstrated at the Lardarello field in Italy since 1913, at the Wairakei field in New Zealand since 1958, and at The Geysers field in California since 1960.\n\nGeothermal power stations are similar to other steam turbine thermal power stations in that heat from a fuel source (in geothermal's case, the Earth's core) is used to heat water or another working fluid. The working fluid is then used to turn a turbine of a generator, thereby producing electricity. The fluid is then cooled and returned to the heat source.\n\nDry steam stations are the simplest and oldest design. This type of power station is not found very often, because it requires a resource that produces dry steam, but is the most efficient, with the simplest facilities. In these sites, there may be liquid water present in the reservoir, but no water is produced to the surface, only steam. Dry Steam Power directly uses geothermal steam of 150 °C or greater to turn turbines. As the turbine rotates it powers a generator which then produces electricity and adds to the power field. Then, the steam is emitted to a condenser. Here the steam turns back into a liquid which then cools the water. After the water is cooled it flows down a pipe that conducts the condensate back into deep wells, where it can be reheated and produced again. At The Geysers in California, after the first thirty years of power production, the steam supply had depleted and generation was substantially reduced. To restore some of the former capacity, supplemental water injection was developed during the 1990s and 2000s, including utilization of effluent from nearby municipal sewage treatment facilities.\n\nFlash steam stations pull deep, high-pressure hot water into lower-pressure tanks and use the resulting flashed steam to drive turbines. They require fluid temperatures of at least 180 °C, usually more. This is the most common type of station in operation today. Flash steam plants use geothermal reservoirs of water with temperatures greater than 360 °F (182 °C). The hot water flows up through wells in the ground under its own pressure. As it flows upward, the pressure decreases and some of the hot water boils into steam. The steam is then separated from the water and used to power a turbine/generator. Any leftover water and condensed steam may be injected back into the reservoir, making this a potentially sustainable resource.\n\nBinary cycle power stations are the most recent development, and can accept fluid temperatures as low as 57 °C. The moderately hot geothermal water is passed by a secondary fluid with a much lower boiling point than water. This causes the secondary fluid to flash vaporize, which then drives the turbines. This is the most common type of geothermal electricity station being constructed today. Both Organic Rankine and Kalina cycles are used. The thermal efficiency of this type station is typically about 10–13%.\n\nThe International Geothermal Association (IGA) has reported that 10,715 megawatts (MW) of geothermal power in 24 countries is online, which is expected to generate 67,246 GWh of electricity in 2010. This represents a 20% increase in geothermal power online capacity since 2005. IGA projected this would grow to 18,500 MW by 2015, due to the large number of projects that were under consideration, often in areas previously assumed to have little exploitable resource.\n\nIn 2010, the United States led the world in geothermal electricity production with 3,086 MW of installed capacity from 77 power stations; the largest group of geothermal power plants in the world is located at The Geysers, a geothermal field in California. The Philippines follows the US as the second highest producer of geothermal power in the world, with 1,904 MW of capacity online; geothermal power makes up approximately 27% of the country's electricity generation.\n\nAl Gore said in The Climate Project Asia Pacific Summit that Indonesia could become a super power country in electricity production from geothermal energy. India has announced a plan to develop the country's first geothermal power facility in Chhattisgarh.\n\nCanada is the only major country on the Pacific Ring of Fire which has not yet developed geothermal power. The region of greatest potential is the Canadian Cordillera, stretching from British Columbia to the Yukon, where estimates of generating output have ranged from 1,550 MW to 5,000 MW.\n\nThe largest group of geothermal power plants in the world is located at The Geysers, a geothermal field in California, United States. As of 2004, five countries (El Salvador, Kenya, the Philippines, Iceland, and Costa Rica) generate more than 15% of their electricity from geothermal sources.\n\nGeothermal electricity is generated in the 24 countries listed in the table below. During 2005, contracts were placed for an additional 500 MW of electrical capacity in the United States, while there were also stations under construction in 11 other countries. Enhanced geothermal systems that are several kilometres in depth are operational in France and Germany and are being developed or evaluated in at least four other countries.\n\nFluids drawn from the deep earth carry a mixture of gases, notably carbon dioxide (), hydrogen sulfide (), methane (), ammonia () and radon (). These pollutants contribute to global warming, acid rain, radiation and noxious smells if released.\n\nExisting geothermal electric stations, that fall within the 50th percentile of all total life cycle emissions studies reviewed by the IPCC, produce on average 45 kg of equivalent emissions per megawatt-hour of generated electricity (kg eq/MW·h). For comparison, a coal-fired power plant emits 1,001 kg of per megawatt-hour when not coupled with carbon capture and storage (CCS).\n\nStations that experience high levels of acids and volatile chemicals are usually equipped with emission-control systems to reduce the exhaust. Geothermal stations could theoretically inject these gases back into the earth, as a form of carbon capture and storage.\n\nIn addition to dissolved gases, hot water from geothermal sources may hold in solution trace amounts of toxic chemicals, such as mercury, arsenic, boron, antimony, and salt. These chemicals come out of solution as the water cools, and can cause environmental damage if released. The modern practice of injecting geothermal fluids back into the Earth to stimulate production has the side benefit of reducing this environmental risk.\n\nStation construction can adversely affect land stability. Subsidence has occurred in the Wairakei field in New Zealand. Enhanced geothermal systems can trigger earthquakes due to water injection. The project in Basel, Switzerland was suspended because more than 10,000 seismic events measuring up to 3.4 on the Richter Scale occurred over the first 6 days of water injection. The risk of geothermal drilling leading to uplift has been experienced in Staufen im Breisgau.\n\nGeothermal has minimal land and freshwater requirements. Geothermal stations use 404 square meters per GW·h versus 3,632 and 1,335 square meters for coal facilities and wind farms respectively. They use 20 litres of freshwater per MW·h versus over 1000 litres per MW·h for nuclear, coal, or oil.\n\nGeothermal power stations can also disrupt the natural cycles of geysers. For example, the Beowawe, Nevada geysers, which were uncapped geothermal wells, stopped erupting due to the development of the dual-flash station.\n\nGeothermal power requires no fuel; it is therefore immune to fuel cost fluctuations. However, capital costs tend to be high. Drilling accounts for over half the costs, and exploration of deep resources entails significant risks. A typical well doublet in Nevada can support 4.5 megawatts (MW) of electricity generation and costs about $10 million to drill, with a 20% failure rate.\nIn total, electrical station construction and well drilling costs about 2–5 million € per MW of electrical capacity, while the levelised energy cost is 0.04–0.10 € per kW·h. Enhanced geothermal systems tend to be on the high side of these ranges, with capital costs above $4 million per MW and levelized costs above $0.054 per kW·h in 2007.\n\nGeothermal power is highly scalable: a small power station can supply a rural village, though initial capital costs can be high.\n\nThe most developed geothermal field is the Geysers in California. In 2008, this field supported 15 stations, all owned by Calpine, with a total generating capacity of 725 MW.\n\n"}
{"id": "34317728", "url": "https://en.wikipedia.org/wiki?curid=34317728", "title": "Houtermans Award", "text": "Houtermans Award\n\nThe Houtermans Award is given annually by the European Association of Geochemistry for outstanding contributions to geochemistry made by scientists under 35 years old or within 6 years of their PhD award. The award is named after Fritz Houtermans and consists of an engraved medal and an honorarium of 1000 Euros.\n\nSource: ERG\n"}
{"id": "33490363", "url": "https://en.wikipedia.org/wiki?curid=33490363", "title": "ISO 2921", "text": "ISO 2921\n\nIS0 2921 is a specification created by the International Organization for Standardization for a method in determining the temperature-retraction characteristics of stretched vulcanized rubber.\n"}
{"id": "153625", "url": "https://en.wikipedia.org/wiki?curid=153625", "title": "IUCN Red List", "text": "IUCN Red List\n\nThe IUCN Red List of Threatened Species (also known as the IUCN Red List or Red Data List), founded in 1965, has evolved to become the world's most comprehensive inventory of the global conservation status of biological species. It uses a set of criteria to evaluate the extinction risk of thousands of species and subspecies. These criteria are relevant to all species and all regions of the world. With its strong scientific base, the IUCN Red List is recognized as the most authoritative guide to the status of biological diversity. A series of Regional Red List are produced by countries or organizations, which assess the risk of extinction to species within a political management unit.\n\nThe IUCN Red List is set upon precise criteria to evaluate the extinction risk of thousands of species and subspecies. These criteria are relevant to all species and all regions of the world. The aim is to convey the urgency of conservation issues to the public and policy makers, as well as help the international community to try to reduce species extinction. According to the International Union for Conservation of Nature (IUCN) (1996), the formally stated goals of the Red List are (1) to provide scientifically based information on the status of species and subspecies at a global level, (2) to draw attention to the magnitude and importance of threatened biodiversity, (3) to influence national and international policy and decision-making, and (4) to provide information to guide actions to conserve biological diversity.\n\nMajor species assessors include BirdLife International, the Institute of Zoology (the research division of the Zoological Society of London), the World Conservation Monitoring Centre, and many Specialist Groups within the IUCN Species Survival Commission (SSC). Collectively, assessments by these organizations and groups account for nearly half the species on the Red List.\n\nThe IUCN aims to have the category of every species re-evaluated every five years if possible, or at least every ten years. This is done in a peer reviewed manner through IUCN Species Survival Commission (SSC) Specialist Groups, which are Red List Authorities responsible for a species, group of species or specific geographic area, or in the case of BirdLife International, an entire class (Aves).\n\nThe 1964 IUCN Red List of Threatened Plants used the older pre-criteria Red List assessment system. Plants listed may not, therefore, appear in the current Red List. IUCN advise that it is best to check both the online Red List and the 1997 plants Red List publication.\n\nThe 2006 Red List, released on 4 May 2006 evaluated 40,168 species as a whole, plus an additional 2,160 subspecies, varieties, aquatic stocks, and subpopulations.\n\nOn 12 September 2007, the World Conservation Union (IUCN) released the 2007 IUCN Red List of Threatened Species. In this release, they have raised their classification of both the western lowland gorilla (\"Gorilla gorilla gorilla\") and the Cross River gorilla (\"Gorilla gorilla diehli\") from endangered to critically endangered, which is the last category before extinct in the wild, due to Ebola virus and poaching, along with other factors. Russ Mittermeier, chief of Swiss-based IUCN's Primate Specialist Group, stated that 16,306 species are endangered with extinction, 188 more than in 2006 (total of 41,415 species on the Red List). The Red List includes the Sumatran orangutan (\"Pongo abelii\") in the Critically Endangered category and the Bornean orangutan (\"Pongo pygmaeus\") in the Endangered category.\n\nThe 2008 Red List was released on 6 October 2008, at the IUCN World Conservation Congress in Barcelona, and \"has confirmed an extinction crisis, with almost one in four [mammals] at risk of disappearing forever\". The study shows at least 1,141 of the 5,487 mammals on Earth are known to be threatened with extinction, and 836 are listed as Data Deficient.\n\nThe Red List of 2012 was released 19 July 2012 at Rio+20 Earth Summit; nearly 2,000 species were added, with 4 species to the extinct list, 2 to the rediscovered list. The IUCN assessed a total of 63,837 species which revealed 19,817 are threatened with extinction. 3,947 were described as \"critically endangered\" and 5,766 as \"endangered,\" while more than 10,000 species are listed as \"vulnerable.\" At threat are 41% of amphibian species, 33% of reef-building corals, 30% of conifers, 25% of mammals, and 13% of birds. The IUCN Red List has listed 132 species of plants and animals from India as \"Critically Endangered.\"\n\nSpecies are classified by the IUCN Red List into nine groups, specified through criteria such as rate of decline, population size, area of geographic distribution, and degree of population and distribution fragmentation.\n\n\nIn the IUCN Red List, \"threatened\" embraces the categories of Critically Endangered, Endangered, and Vulnerable.\n\nThe older 1994 has only a single \"Lower Risk\" category which contained three subcategories:\n\n\nIn the 2001 system Near Threatened and Least Concern have now become their own categories, while Conservation Dependent is no longer used and has been merged into Near Threatened.\n\nThe tag of \"possibly extinct\" (PE) is used by Birdlife International, the Red List Authority for birds for the IUCN Red List. BirdLife International has recommended PE become an official tag for Critically Endangered species, and this has now been adopted, along with a \"Possibly Extinct in the Wild\" tag for species with populations surviving in captivity but likely to be extinct in the wild (e.g. Spix's macaw).\n\nThere have been a number of versions, dating from 1991, including:\n\n\nFor plants, the 1997 Red List is the most important source.\n\nIn 1997, the IUCN Red List came under criticism on the grounds of secrecy (or at least poor documentation) surrounding the sources of its data. These allegations have led to efforts by the IUCN to improve its documentation and data quality, and to include peer reviews of taxa on the Red List. The list is also open to petitions against its classifications, on the basis of documentation or criteria. A \"Nature\" editorial defended the Red List's relevance in October 2008.\n\nIt has been suggested that the IUCN Red List and similar works are prone to misuse by governments and other groups that draw possibly inappropriate conclusions on the state of the environment or to effect exploitation of natural resources.\n"}
{"id": "277665", "url": "https://en.wikipedia.org/wiki?curid=277665", "title": "Jack Frost", "text": "Jack Frost\n\nJack Frost is a personification of frost, ice, snow, sleet, winter, and freezing cold. He is a variant of Old Man Winter who is held responsible for frosty weather, nipping the fingers and toes in such weather, coloring the foliage in autumn, and leaving fern-like patterns on cold windows in winter.\n\nStarting in late 19th century literature, more developed characterizations of Jack Frost depict him as a sprite-like character, sometimes appearing as a sinister mischief-maker or as a hero.\n\nJack Frost is traditionally said to leave the frosty, fern-like patterns on windows on cold winter mornings (window frost or fern frost) and nipping the extremities in cold weather. Over time, window frost has become far less prevalent in the modern world due to the advance of double-glazing, but Jack Frost remains a well-known figure in popular culture. He is sometimes described or depicted with paint brush and bucket coloring the autumnal foliage red, yellow, brown, and orange. Sometimes he is portrayed as a dangerous giant:The Hindus derive the name of Hindu Kush from the tradition that a giant used to lie there in wait to kill (\"kesh\") all the Hindus who passed that way. This giant was probably the same whom we, in the Arctic Regions, used to call “Old Zero,” better known in England as “Jack Frost.” The horrors of the snow-covered wastes probably gave rise to the tradition.\"\n\nHe may originate from Anglo-Saxon and Norse winter customs and has an entire chapter named after him in Kalevala, the Finnish national epic compiled from their ancient oral tradition.\n\nIn Russia however, he has taken on a different form as Grandfather Frost, and in Germany there is instead a different entity altogether known as Mrs. Holle. There are various other mythological beings who take on a similar role yet have different folklore to them.\n\nJack Frost has appeared as a character in television and movies. He was mentioned in the wintertime song \"The Christmas Song\" (aka \"Chestnuts Roasting on an Open Fire\"). He has been presented as a villain in some media and a hero in others.\n\n\n\n\n\nJack Frost has appeared in many video games including:\n\nJack Frost is also the official corporate mascot for the Japanese video game company, Atlus.\n\n\n\n"}
{"id": "215148", "url": "https://en.wikipedia.org/wiki?curid=215148", "title": "John Muir", "text": "John Muir\n\nJohn Muir (; April 21, 1838 – December 24, 1914) also known as \"John of the Mountains\" and \"Father of the National Parks\", was an influential Scottish-American naturalist, author, environmental philosopher, glaciologist, and early advocate for the preservation of wilderness in the United States of America.\n\nHis letters, essays, and books describing his adventures in nature, especially in the Sierra Nevada, have been read by millions. His activism has helped to preserve the Yosemite Valley, Sequoia National Park and many other wilderness areas. The Sierra Club, which he co-founded, is a prominent American conservation organization. The John Muir Trail, a hiking trail in the Sierra Nevada, was named in his honor. Other such places include Muir Woods National Monument, Muir Beach, John Muir College, John Muir Charter School, Mount Muir, Camp Muir, Muir Grove, and Muir Glacier. In Scotland, the John Muir Way, a 130-mile-long route, was named in honor of him.\n\nIn his later life, Muir devoted most of his time to the preservation of the Western forests. As part of the campaign to make Yosemite a national park, Muir published two landmark articles on wilderness preservation in \"The Century Magazine\", \"The Treasures of the Yosemite\" and \"Features of the Proposed Yosemite National Park\"; this helped support the push for U.S. Congress to pass a bill in 1890 establishing Yosemite National Park. The spiritual quality and enthusiasm toward nature expressed in his writings has inspired readers, including presidents and congressmen, to take action to help preserve large nature areas.\n\nJohn Muir has been considered \"an inspiration to both Scots and Americans\". Muir's biographer, Steven J. Holmes, believes that Muir has become \"one of the patron saints of twentieth-century American environmental activity,\" both political and recreational. As a result, his writings are commonly discussed in books and journals, and he is often quoted by nature photographers such as Ansel Adams. \"Muir has profoundly shaped the very categories through which Americans understand and envision their relationships with the natural world,\" writes Holmes.\n\nMuir was noted for being an ecological thinker, political spokesman, and religious prophet, whose writings became a personal guide into nature for countless individuals, making his name \"almost ubiquitous\" in the modern environmental consciousness. According to author William Anderson, Muir exemplified \"the archetype of our oneness with the earth\", while biographer Donald Worster says he believed his mission was \"saving the American soul from total surrender to materialism.\" On April 21, 2013, the first ever John Muir Day was celebrated in Scotland, which marked the 175th anniversary of his birth, paying homage to the conservationist.\n\nJohn Muir's Birthplace is a four-story stone house in Dunbar, East Lothian, Scotland. His parents were Daniel Muir and Ann Gilrye. He was the third of eight children: Margaret, Sarah, David, Daniel, Ann and Mary (twins), and the American-born Joanna. His earliest recollections were of taking short walks with his grandfather when he was three. In his autobiography, he described his boyhood pursuits, which included fighting, either by re-enacting romantic battles from the Wars of Scottish Independence or just scrapping on the playground, and hunting for birds' nests (ostensibly to one-up his fellows as they compared notes on who knew where the most were located). Author Amy Marquis notes that he began his \"love affair\" with nature while young, and implies that it may have been in reaction to his strict religious upbringing. \"His father believed that anything that distracted from Bible studies was frivolous and punishable.\" But the young Muir was a \"restless spirit\" and especially \"prone to lashings.\" As a young boy, Muir became fascinated with the East Lothian landscape, and spent a lot of time wandering the local coastline and countryside. It was during this time that he became interested in natural history and the works of Scottish naturalist Alexander Wilson.\n\nAlthough he spent the majority of his life in America, Muir never forgot his roots in Scotland. He held a strong connection with his birthplace and Scottish identity throughout his life and was frequently heard talking about his childhood spent amid the East Lothian countryside. He greatly admired the works of Thomas Carlyle and poetry of Robert Burns; he was known to carry a collection of poems by Burns during his travels through the American wilderness. He returned to Scotland on a trip in 1893, where he met one of his Dunbar schoolmates and visited the places of his youth that were etched in his memory. He also never lost his strong Scottish accent despite having lived in America for many years.\n\nIn 1849, Muir's family immigrated to the United States, starting a farm near Portage, Wisconsin, called Fountain Lake Farm. It has been designated a National Historic Landmark. Stephen Fox recounts that Muir's father found the Church of Scotland insufficiently strict in faith and practice, leading to their immigration and joining a congregation of the Campbellite Restoration Movement, called the Disciples of Christ. By the age of 11, the young Muir had learned to recite \"by heart and by sore flesh\" all of the New Testament and most of the Old Testament. In maturity, while remaining a deeply spiritual man, Muir may have changed his orthodox beliefs. He wrote, \"I never tried to abandon creeds or code of civilization; they went away of their own accord ... without leaving any consciousness of loss.\" Elsewhere in his writings, he described the conventional image of a Creator, \"as purely a manufactured article as any puppet of a half-penny theater.\"\nWhen he was 22 years old, Muir enrolled at the University of Wisconsin–Madison, paying his own way for several years. There, under a towering black locust tree beside North Hall, Muir took his first botany lesson. A fellow student plucked a flower from the tree and used it to explain how the grand locust is a member of the pea family, related to the straggling pea plant. Fifty years later, the naturalist Muir described the day in his autobiography. \"This fine lesson charmed me and sent me flying to the woods and meadows in wild enthusiasm.\" As a freshman, Muir studied chemistry with Professor Ezra Carr and his wife Jeanne; they became lifelong friends and Muir developed a lasting interest in chemistry and the sciences. Muir took an eclectic approach to his studies, attending classes for two years but never being listed higher than a first-year student due to his unusual selection of courses. Records showed his class status as \"irregular gent\" and, even though he never graduated, he learned enough geology and botany to inform his later wanderings.\n\nIn 1863, his brother Daniel left Wisconsin and moved to Southern Ontario (then known as \"Canada West\" in the United Canadas), to avoid the draft during the U.S. Civil War. Muir left school and travelled to the same region in 1864, and spent the spring, summer, and fall exploring the woods and swamps, and collecting plants around the southern reaches of Lake Huron's Georgian Bay. Muir hiked along the Niagara Escarpment, including much of today's Bruce Trail. With his money running low and winter coming, he reunited with his brother Daniel near Meaford, Ontario, who persuaded him to work with him at the sawmill and rake factory of William Trout and Charles Jay. Muir lived with the Trout family in an area called Trout Hollow, south of Meaford, on the Bighead River. While there, he continued \"botanizing\", exploring the escarpment and bogs, collecting and cataloging plants. One source appears to indicate he worked at the mill/factory until the summer of 1865, while another says he stayed on at Trout Hollow until after a fire burned it down in February 1866.\n\nIn March 1866, Muir returned to the United States, settling in Indianapolis to work in a wagon wheel factory. He proved valuable to his employers because of his inventiveness in improving the machines and processes; he was promoted to supervisor, being paid $25 per week. In early-March 1867, an accident changed the course of his life: a tool he was using slipped and struck him in the eye. The file slipped and cut the cornea in his right eye and then his left eye sympathetically failed. He was confined to a darkened room for six weeks to regain his sight, worried about whether he would ever regain his sight. When he did, \"he saw the world—and his purpose—in a new light\". Muir later wrote, \"This affliction has driven me to the sweet fields. God has to nearly kill us sometimes, to teach us lessons.\" From that point on, he determined to \"be true to [himself]\" and follow his dream of exploration and study of plants.\nIn September 1867, Muir undertook a walk of about from Kentucky to Florida, which he recounted in his book \"A Thousand-Mile Walk to the Gulf\". He had no specific route chosen, except to go by the \"wildest, leafiest, and least trodden way I could find.\" When Muir arrived at Cedar Keys, he began working for Richard Hodgson at Hodgson's sawmill. However, three days after accepting the job at Hodgson's, Muir almost died of a malarial sickness.\n\nOne evening in early January 1868, Muir climbed onto the Hodgson house roof to watch the sunset. He saw a ship, the Island Belle, and learned it would soon be sailing for Cuba. Muir boarded the ship, and while in Havana, he spent his hours studying shells and flowers and visiting the botanical garden in the city. Afterwards, he sailed to New York City and booked passage to California. Muir served as an officer in the United States Coast Survey, a uniformed government service agency.\n\nFinally settling in San Francisco, Muir immediately left for a week-long visit to Yosemite, a place he had only read about. Seeing it for the first time, Muir notes that \"He was overwhelmed by the landscape, scrambling down steep cliff faces to get a closer look at the waterfalls, whooping and howling at the vistas, jumping tirelessly from flower to flower.\" He later returned to Yosemite and worked as a shepherd for a season. He climbed a number of mountains, including Cathedral Peak and Mount Dana, and hiked an old trail down Bloody Canyon to Mono Lake.\n\nMuir built a small cabin along Yosemite Creek, designing it so that a section of the stream flowed through a corner of the room so he could enjoy the sound of running water. He lived in the cabin for two years and wrote about this period in his book \"First Summer in the Sierra\" (1911). Muir's biographer, Frederick Turner, notes Muir's journal entry upon first visiting the valley and writes that his description \"blazes from the page with the authentic force of a conversion experience.\"\n\nDuring these years in Yosemite, Muir was unmarried, often unemployed, with no prospects for a career, and had \"periods of anguish,\" writes naturalist author John Tallmadge. He did marry in 1880 to Louisa Strentzel. He went into business for 10 years with his father-in-law managing the orchards on the family 2600 acre farm near Oakland. John and Louisa had two daughters. He was sustained by the natural environment and by reading the essays of naturalist author Ralph Waldo Emerson, who wrote about the very life that Muir was then living. On excursions into the back country of Yosemite, he traveled alone, carrying \"only a tin cup, a handful of tea, a loaf of bread, and a copy of Emerson.\" He usually spent his evenings sitting by a campfire in his overcoat, reading Emerson under the stars. As the years passed, he became a \"fixture in the valley,\" respected for his knowledge of natural history, his skill as a guide, and his vivid storytelling. Visitors to the valley often included scientists, artists, and celebrities, many of whom made a point of meeting with Muir.\n\nIn 1871, after Muir had lived in Yosemite for three years, Emerson, with a number of academic friends from Boston, arrived in Yosemite during a tour of the Western United States. The two men met, and according to Tallmadge, \"Emerson was delighted to find at the end of his career the prophet-naturalist he had called for so long ago ... And for Muir, Emerson's visit came like a laying on of hands.\" Emerson spent one day with Muir, and he offered him a teaching position at Harvard, which Muir declined. Muir later wrote, \"I never for a moment thought of giving up God's big show for a mere profship!\"\n\nMuir also spent time with photographer Carleton Watkins and studied his photographs of Yosemite.\n\nPursuit of his love of science, especially geology, often occupied his free time. Muir soon became convinced that glaciers had sculpted many of the features of the Yosemite Valley and surrounding area. This notion was in stark contradiction to the accepted contemporary theory, promulgated by Josiah Whitney (head of the California Geological Survey), which attributed the formation of the valley to a catastrophic earthquake. As Muir's ideas spread, Whitney tried to discredit Muir by branding him as an amateur. But Louis Agassiz, the premier geologist of the day, saw merit in Muir's ideas and lauded him as \"the first man I have ever found who has any adequate conception of glacial action.\"\nIn 1871, Muir discovered an active alpine glacier below Merced Peak, which helped his theories gain acceptance.\n\nA large earthquake centered near Lone Pine in Owens Valley strongly shook occupants of Yosemite Valley in March 1872. The quake woke Muir in the early morning, and he ran out of his cabin \"both glad and frightened,\" exclaiming, \"A noble earthquake!\" Other valley settlers, who believed Whitney's ideas, feared that the quake was a prelude to a cataclysmic deepening of the valley. Muir had no such fear and promptly made a moonlit survey of new talus piles created by earthquake-triggered rockslides. This event led more people to believe in Muir's ideas about the formation of the valley.\n\nIn addition to his geologic studies, Muir also investigated the plant life of the Yosemite area. In 1873 and 1874, he made field studies along the western flank of the Sierra on the distribution and ecology of isolated groves of Giant Sequoia. In 1876, the American Association for the Advancement of Science published Muir's paper on the subject.\n\nMuir made four trips to Alaska, as far as Unalaska and Barrow. Muir, Mr Young (Fort Wrangell missionary) and a group of Native American Guides first traveled to Alaska in 1879 and were the first Euro-Americans to explore Glacier Bay. Muir Glacier was later named after him. He traveled into British Columbia a third of the way up the Stikine River, likening its Grand Canyon to \"a Yosemite that was a hundred miles long\". Muir recorded over 300 glaciers along the river's course.\n\nHe returned for further explorations in southeast Alaska in 1880 and in 1881 was with the party that landed on Wrangel Island on the USS \"Corwin\" and claimed that island for the United States. He documented this experience in journal entries and newspaper articles—later compiled and edited into his book \"The Cruise of the Corwin\". In 1888 after seven years of managing the Strentzel fruit ranch in Alhambra Valley, California, his health began to suffer. He returned to the hills to recover, climbing Mount Rainier in Washington and writing \"Ascent of Mount Rainier\".\n\nMuir threw himself into the preservationist role with great vigor. He envisioned the Yosemite area and the Sierra as pristine lands. He thought the greatest threat to the Yosemite area and the Sierra was domesticated livestock—especially domestic sheep, which he referred to as \"hoofed locusts\". In June 1889, the influential associate editor of \"The Century\" magazine, Robert Underwood Johnson, camped with Muir in Tuolumne Meadows and saw firsthand the damage a large flock of sheep had done to the grassland. Johnson agreed to publish any article Muir wrote on the subject of excluding livestock from the Sierra high country. He also agreed to use his influence to introduce a bill to Congress to make the Yosemite area into a national park, modeled after Yellowstone National Park.\n\nOn September 30, 1890, the U.S. Congress passed a bill that essentially followed recommendations that Muir had suggested in two \"Century\" articles, \"The Treasures of the Yosemite\" and \"Features of the Proposed National Park\", both published in 1890. But to Muir's dismay, the bill left Yosemite Valley under state control, as it had been since the 1860s.\n\nIn early 1892, Professor Henry Senger, a philologist at the University of California, Berkeley, contacted Muir with the idea of forming a local 'alpine club' for mountain lovers. Senger and San Francisco attorney Warren Olney sent out invitations \"for the purpose of forming a 'Sierra Club.' Mr. John Muir will preside.\" On May 28, 1892, the first meeting of the Sierra Club was held to write articles of incorporation. One week later Muir was elected president, Warren Olney was elected vice-president, and a board of directors was chosen that included David Starr Jordan, president of the new Stanford University. Muir remained president until his death 22 years later.\n\nThe Sierra Club immediately opposed efforts to reduce Yosemite National Park by half, and began holding educational and scientific meetings. At one meeting in the fall of 1895 that included Muir, Joseph LeConte, and William R. Dudley, the Sierra Club discussed the idea of establishing 'national forest reservations', which were later called National Forests. The Sierra Club was active in the successful campaign to transfer Yosemite National Park from state to federal control in 1906. The fight to preserve Hetch Hetchy Valley was also taken up by the Sierra Club, with some prominent San Francisco members opposing the fight. Eventually a vote was held that overwhelmingly put the Sierra Club behind the opposition to Hetch Hetchy Dam.\n\nIn July 1896, Muir became associated with Gifford Pinchot, a national leader in the conservation movement. Pinchot was the first head of the United States Forest Service and a leading spokesman for the sustainable use of natural resources for the benefit of the people. His views eventually clashed with Muir's and highlighted two diverging views of the use of the country's natural resources. Pinchot saw conservation as a means of managing the nation's natural resources for long-term sustainable commercial use. As a professional forester, his view was that \"forestry is tree farming,\" without destroying the long-term viability of the forests. Muir valued nature for its spiritual and transcendental qualities. In one essay about the National Parks, he referred to them as \"places for rest, inspiration, and prayers.\" He often encouraged city dwellers to experience nature for its spiritual nourishment. Both men opposed reckless exploitation of natural resources, including clear-cutting of forests. Even Muir acknowledged the need for timber and the forests to provide it, but Pinchot's view of wilderness management was more resource-oriented.\n\nTheir friendship ended late in the summer of 1897 when Pinchot released a statement to a Seattle newspaper supporting sheep grazing in forest reserves. Muir confronted Pinchot and demanded an explanation. When Pinchot reiterated his position, Muir told him: \"I don't want any thing more to do with you.\" This philosophical divide soon expanded and split the conservation movement into two camps: the preservationists, led by Muir; and Pinchot's camp, who co-opted the term \"conservation.\" The two men debated their positions in popular magazines, such as \"Outlook\", \"Harper's Weekly\", \"Atlantic Monthly\", \"World's Work\", and \"Century\". Their contrasting views were highlighted again when the United States was deciding whether to dam Hetch Hetchy Valley. Pinchot favored damming the valley as \"the highest possible use which could be made of it.\" In contrast, Muir proclaimed, \"Dam Hetch Hetchy! As well dam for water-tanks the people's cathedrals and churches, for no holier temple has ever been consecrated by the hearts of man.\"\nIn 1899, Muir accompanied railroad executive E. H. Harriman and esteemed scientists on the famous exploratory voyage along the Alaska coast aboard the luxuriously refitted steamer, the \"George W. Elder.\" He later relied on his friendship with Harriman to pressure Congress to pass conservation legislation.\n\nIn 1903, President Theodore Roosevelt accompanied Muir on a visit to Yosemite. Muir joined Roosevelt in Oakland, California, for the train trip to Raymond. The presidential entourage then traveled by stagecoach into the park. While traveling to the park, Muir told the president about state mismanagement of the valley and rampant exploitation of the valley's resources. Even before they entered the park, he was able to convince Roosevelt that the best way to protect the valley was through federal control and management.\n\nAfter entering the park and seeing the magnificent splendor of the valley, the president asked Muir to show him the real Yosemite. Muir and Roosevelt set off largely by themselves and camped in the back country. The duo talked late into the night, slept in the brisk open air of Glacier Point, and were dusted by a fresh snowfall in the morning. It was a night Roosevelt never forgot. He later told a crowd, \"Lying out at night under those giant Sequoias was like lying in a temple built by no hand of man, a temple grander than any human architect could by any possibility build.\" Muir, too, cherished the camping trip. \"Camping with the President was a remarkable experience,\" he wrote. \"I fairly fell in love with him.\"\n\nMuir then increased efforts by the Sierra Club to consolidate park management. In 1906 Congress transferred the Mariposa Grove and Yosemite Valley to the park.\n\nMuir's attitude toward Native Americans evolved over his life. His earliest encounters, during his childhood in Wisconsin, were with Winnebago Indians, who begged for food and stole his favorite horse. In spite of that, he had a great deal of sympathy for their \"being robbed of their lands and pushed ruthlessly back into narrower and narrower limits by alien races who were cutting off their means of livelihood.\" His early encounters with the Paiute in California left him feeling ambivalent after seeing their lifestyle, which he described as \"lazy\" and \"superstitious\". Ecofeminist philosopher Carolyn Merchant has criticized Muir, believing that he wrote disparagingly of the Native Americans he encountered in his early explorations. Later, after living with Indians, he praised and grew more respectful of their low impact on the wilderness, compared to the heavy impact by European-Americans.\n\nMuir was given the Stickeen (Muir's spelling, coastal tribe) name \"Ancoutahan\" meaning \"adopted chief\".\n\nWith population growth continuing in San Francisco, political pressure increased to dam the Tuolumne River for use as a water reservoir. Muir passionately opposed the damming of Hetch Hetchy Valley because he found Hetch Hetchy as stunning as Yosemite Valley. Muir, the Sierra Club and Robert Underwood Johnson fought against inundating the valley. Muir wrote to President Roosevelt pleading for him to scuttle the project. Roosevelt's successor, William Howard Taft, suspended the Interior Department's approval for the Hetch Hetchy right-of-way. After years of national debate, Taft's successor Woodrow Wilson signed the bill authorizing the dam into law on December 19, 1913. Muir felt a great loss from the destruction of the valley, his last major battle. He wrote to his friend Vernon Kellogg, \"As to the loss of the Sierra Park Valley [Hetch Hetchy] it's hard to bear. The destruction of the charming groves and gardens, the finest in all California, goes to my heart.\"\n\nIn his life, Muir published six volumes of writings, all describing explorations of natural settings. Four additional books were published posthumously. Several books were subsequently published that collected essays and articles from various sources. Miller writes that what was most important about his writings was not their quantity, but their \"quality\". He notes that they have had a \"lasting effect on American culture in helping to create the desire and will to protect and preserve wild and natural environments.\"\n\nHis first appearance in print was by accident, writes Miller; a person he did not know submitted, without his permission or awareness, a personal letter to his friend Jeanne Carr, describing \"Calypso borealis\", a rare flower he had encountered. The piece was published anonymously, identified as having been written by an \"inspired pilgrim\". Throughout his many years as a nature writer, Muir frequently rewrote and expanded on earlier writings from his journals, as well as articles published in magazines. He often compiled and organized such earlier writings as collections of essays or included them as part of narrative books.\n\nMuir's friendship with Jeanne Carr had a lifelong influence on his career as a naturalist and writer. They first met in the fall of 1860, when, at age 22, he entered a number of his homemade inventions in the Wisconsin State Agricultural Society Fair. Carr, a fair assistant, was asked by fair officials to review Muir's exhibits to see if they had merit. She thought they did and \"saw in his entries evidence of genius worthy of special recognition,\" notes Miller. As a result, Muir received a diploma and a monetary award for his handmade clocks and thermometer. During the next three years while a student at the University of Wisconsin, he was befriended by Carr and her husband, Ezra, a professor at the same university. According to Muir biographer Bonnie Johanna Gisel, the Carrs recognized his \"pure mind, unsophisticated nature, inherent curiosity, scholarly acumen, and independent thought.\" Jeanne Carr, 35 years of age, especially appreciated his youthful individuality, along with his acceptance of \"religious truths\" that were much like her own.\nMuir was often invited to the Carrs' home; he shared Jeanne's love of plants. In 1864, he left Wisconsin to begin exploring the Canadian wilderness and, while there, began corresponding with her about his activities. Carr wrote Muir in return and encouraged him in his explorations and writings, eventually having an important influence over his personal goals. At one point she asked Muir to read a book she felt would influence his thinking, Lamartine's \"The Stonemason of Saint Point\". It was the story of a man whose life she hoped would \"metabolize in Muir,\" writes Gisel, and \"was a projection of the life she envisioned for him.\" According to Gisel, the story was about a \"poor man with a pure heart,\" who found in nature \"divine lessons and saw all of God's creatures interconnected.\"\n\nAfter Muir returned to the United States, he spent the next four years exploring Yosemite, while at the same time writing articles for publication. During those years, Muir and Carr continued corresponding. She sent many of her friends to Yosemite to meet Muir and \"to hear him preach the gospel of the mountains,\" writes Gisel. The most notable was naturalist and author Ralph Waldo Emerson. The importance of Carr, who continually gave Muir reassurance and inspiration, \"cannot be overestimated,\" adds Gisel. It was \"through his letters to her that he developed a voice and purpose.\" She also tried to promote Muir's writings by submitting his letters to a monthly magazine for publication. Muir came to trust Carr as his \"spiritual mother,\" and they remained friends for 30 years. In one letter she wrote to Muir while he was living in Yosemite, she tried to keep him from despairing as to his purpose in life.\n\nThe value of their friendship was first disclosed by a friend of Carr's, clergyman and writer G. Wharton James. After obtaining copies of their private letters from Carr, and despite pleadings from Muir to return them, he instead published articles about their friendship, using those letters as a primary source. In one such article, his focus was Muir's debt to Carr, stating that she was his \"guiding star\" who \"led him into the noble paths of life, and then kept him there.\"\n\nMuir's friend, zoologist Henry Fairfield Osborn, writes that Muir's style of writing did not come to him easily, but only with intense effort. \"Daily he rose at 4:30 o'clock, and after a simple cup of coffee labored incessantly. ... he groans over his labors, he writes and rewrites and interpolates.\" Osborn notes that he preferred using the simplest English language, and therefore admired above all the writings of Carlyle, Emerson and Thoreau. \"He is a very firm believer in Thoreau and starts by reading deeply of this author.\" His secretary, Marion Randall Parsons, also noted that \"composition was always slow and laborious for him. ... Each sentence, each phrase, each word, underwent his critical scrutiny, not once but twenty times before he was satisfied to let it stand.\" Muir often told her, \"This business of writing books is a long, tiresome, endless job.\"\n\nMiller speculates that Muir recycled his earlier writings partly due to his \"dislike of the writing process.\" He adds that Muir \"did not enjoy the work, finding it difficult and tedious.\" He was generally unsatisfied with the finished result, finding prose \"a weak instrument for the reality he wished to convey.\" However, he was prodded by friends and his wife to keep writing and as a result of their influence he kept at it, although never satisfied. Muir wrote in 1872, \"No amount of word-making will ever make a single soul to 'know' these mountains. One day's exposure to mountains is better than a cartload of books.\" In one of his essays, he gave an example of the deficiencies of writing versus experiencing nature.\n\nMuir believed that to discover truth, he must turn to what he believed were the most accurate sources. Muir had a strict, Scottish Presbyterian upbringing. In his book, \"The Story of My Boyhood and Youth\" (1913), he writes that during his childhood, his father made him read the Bible every day. Muir eventually memorized three-quarters of the Old Testament and all of the New Testament. Muir's father read Josephus's \"War of the Jews\" to understand the culture of first-century Palestine, as it was written by an eyewitness, and illuminated the culture during the period of the New Testament. But as Muir became attached to the American natural landscapes he explored, Williams notes that he began to see another \"primary source for understanding God: the Book of Nature.\" According to Williams, in nature, especially in the wilderness, Muir was able to study the plants and animals in an environment that he believed \"came straight from the hand of God, uncorrupted by civilization and domestication.\" As Tallmadge notes, Muir's belief in this \"Book of Nature\" compelled him to tell the story of \"this creation in words any reader could understand.\" As a result, his writings were to become \"prophecy, for [they] sought to change our angle of vision.\"\n\nWilliams notes that Muir's philosophy and world view rotated around his perceived dichotomy between civilization and nature. From this developed his core belief that \"wild is superior\". His nature writings became a \"synthesis of natural theology\" with scripture that helped him understand the origins of the natural world. According to Williams, philosophers and theologians such as Thomas Dick suggested that the \"best place to discover the true attributes of deity was in Nature.\" He came to believe that God was always active in the creation of life and thereby kept the natural order of the world. As a result, Muir \"styled himself as a John the Baptist,\" adds Williams, \"whose duty was to immerse in 'mountain baptism' everyone he could.\" Williams concludes that Muir saw nature as a great teacher, \"revealing the mind of God,\" and this belief became the central theme of his later journeys and the \"subtext\" of his nature writing.\n\nDuring his career as writer and while living in the mountains, Muir continued to experience the \"presence of the divine in nature,\" writes Holmes His personal letters also conveyed these feelings of ecstasy. Historian Catherine Albanese stated that in one of his letters, \"Muir's eucharist made Thoreau's feast on wood-chuck and huckleberry seem almost anemic.\" Muir was extremely fond of Thoreau and was probably influenced more by him than even Emerson. Muir often referred to himself as a \"disciple\" of Thoreau.\n\nDuring his first summer in the Sierra as a shepherd, Muir wrote field notes that emphasized the role that the senses play in human perceptions of the environment. According to Williams, he speculated that the world was an unchanging entity that was interpreted by the brain through the senses, and, writes Muir, \"If the creator were to bestow a new set of senses upon us ... we would never doubt that we were in another world ...\" While doing his studies of nature, he would try to remember everything he observed as if his senses were recording the impressions, until he could write them in his journal. As a result of his intense desire to remember facts, he filled his field journals with notes on precipitation, temperature, and even cloud formations.\n\nHowever, Muir took his journal entries further than recording factual observations. Williams notes that the observations he recorded amounted to a description of \"the sublimity of Nature,\" and what amounted to \"an aesthetic and spiritual notebook.\" Muir felt that his task was more than just recording \"phenomena,\" but also to \"illuminate the spiritual implications of those phenomena,\" writes Williams. For Muir, mountain skies, for example, seemed painted with light, and came to \"... symbolize divinity.\" He often described his observations in terms of light.\n\nMuir biographer Steven Holmes notes that Muir used words like \"glory\" and \"glorious\" to suggest that light was taking on a religious dimension: \"It is impossible to overestimate the importance of the notion of glory in Muir's published writings, where no other single image carries more emotional or religious weight,\" adding that his words \"exactly parallels its Hebraic origins,\" in which biblical writings often indicate a divine presence with light, as in the burning bush or pillar of fire, and described as \"the glory of God.\"\n\nMuir often used the term \"home\" as a metaphor for both nature and his general attitude toward the \"natural world itself,\" notes Holmes. He often used domestic language to describe his scientific observations, as when he saw nature as providing a home for even the smallest plant life: \"the little purple plant, tended by its Maker, closed its petals, crouched low in its crevice of a home, and enjoyed the storm in safety.\" Muir also saw nature as his own home, as when he wrote friends and described the Sierra as \"God's mountain mansion.\" He considered not only the mountains as home, however, as he also felt a closeness even to the smallest objects: \"The very stones seem talkative, sympathetic, brotherly. No wonder when we consider that we all have the same Father and Mother.\"\n\nIn his later years, he used the metaphor of nature as home in his writings to promote wilderness preservation.\n\nNot surprisingly, Muir's deep-seated feeling about nature as being his true home led to tension with his family at his home in Martinez, California. He once told a visitor to his ranch there, \"This is a good place to be housed in during stormy weather, ... to write in, and to raise children in, but it is not my home. Up there,\" pointing towards the Sierra Nevada, \"is my home.\"\n\nIn 1878, when he was nearing the age of 40, Muir's friends \"pressured him to return to society.\" Soon after he returned to the Oakland area, he was introduced by Jeanne Carr to Louisa Strentzel, daughter of a prominent physician and horticulturist with a fruit orchard in Martinez, California, northeast of Oakland. In 1880, after he returned from a trip to Alaska, Muir and Strentzel married. John Muir went into partnership with his father-in-law, Dr. John Strentzel, and for ten years directed most of his energy into managing this large fruit ranch. Although Muir was a loyal, dedicated husband, and father of two daughters,\"his heart remained wild,\" writes Marquis. His wife understood his needs, and after seeing his restlessness at the ranch would sometimes \"shoo him back up\" to the mountains. He sometimes took his daughters with him.\n\nThe house and part of the ranch are now the John Muir National Historic Site. In addition, the W.H.C. Folsom House, where Muir worked as a printer, is also listed on the National Register of Historic Places.\n\nJohn Muir died at California Hospital (now California Hospital Medical Center) in Los Angeles on December 24, 1914, of pneumonia at age 76, after a brief visit to Daggett, California, to see his daughter Helen Muir Funk. His grandson Ross Hanna lived until 2014, when he died at age 91.\n\nDuring his lifetime John Muir published over 300 articles and 12 books. He co-founded the Sierra Club, which helped establish a number of national parks after he died. Today the club has over 2.4 million members.\n\nMuir has been called the \"patron saint of the American wilderness\" and its \"archetypal free spirit.\" As a dreamer and activist, his eloquent words changed the way Americans saw their mountains, forests, seashores, and deserts, said nature writer Gretel Ehrlich. He not only led the efforts to protect forest areas and have some designated as national parks, but his writings presented \"human culture and wild nature as one of humility and respect for all life.\"\n\nRobert Underwood Johnson, editor of \"Century Magazine\", which published many of Muir's articles, states that he influenced people's appreciation of nature and national parks, which became a lasting legacy:\n\nMuir exalted wild nature over human culture and civilization, believing that all life was sacred. Turner describes him as \"a man who in his singular way rediscovered America. ... an American pioneer, an American hero.\" The primary aim of Muir's nature philosophy, writes Wilkins, was to challenge mankind's \"enormous conceit,\" and in so doing, he moved beyond the Transcendentalism of Emerson to a \"biocentric perspective on the world\". He did so by describing the natural world as \"a conductor of divinity,\" and his writings often made nature synonymous with God. His friend, Henry Fairfield Osborn, observed that as a result of his religious upbringing, Muir retained \"this belief, which is so strongly expressed in the Old Testament, that all the works of nature are directly the work of God.\" In the opinion of Enos Mills, a contemporary who established Rocky Mountain National Park, Muir's writings would \"likely to be the most influential force in this century.\"\n\nCalifornia celebrates John Muir Day on April 21 each year. Muir was the first person honored with a California commemorative day when legislation signed in 1988 created John Muir Day, effective from 1989 onward. Muir is one of three people so honored in California, along with Harvey Milk Day and Ronald Reagan Day. East Lothian in Scotland also celebrates John Muir day, the play \"Thank God for John Muir\", by Andrew Dallmeyer is based on his life.\n\nThe following places are named after Muir:\n\nJohn Muir was featured on two U.S. commemorative postage stamps. A 5-cent stamp issued on April 29, 1964, was designed by Rudolph Wendelin, and showed Muir's face superimposed on a grove of redwood trees, and the inscription, \"John Muir Conservationist\". A 32-cent stamp issued on February 3, 1998, was part of the \"Celebrate the Century\" series, and showed Muir in Yosemite Valley, with the inscription \"John Muir, Preservationist\". An image of Muir, with the California condor and Half Dome, appears on the California state quarter released in 2005. A quotation of his appears on the reverse side of the Indianapolis Prize Lilly Medal for conservation. On December 6, 2006, California Governor Arnold Schwarzenegger and First Lady Maria Shriver inducted John Muir into the California Hall of Fame located at The California Museum for History, Women, and the Arts.\n\nMuir and Hudson Stuck are honored with a feast day on the liturgical of the Episcopal Church in the United States of America on April 22.\n\nThe John Muir Trust is a Scottish charity established as a membership organisation in 1983 to conserve wild land and wild places. It has more than 11,000 members internationally.\n\nThe John Muir Birthplace Charitable Trust is a Scottish charity whose aim is to support John Muir's birthplace in Dunbar and develop it as an interpretative centre focused on Muir's work.\n\nMuirite (a mineral), \"Erigeron muirii\", \"Carlquistia muirii\" (two species of aster), \"Ivesia muirii\" (a member of the rose family), \"Troglodytes troglodytes muiri\" (a wren), \"Ochotona princeps muiri\" (a pika), \"Thecla muirii\" (a butterfly), and \"Amplaria muiri\" (a millipede) were all named after John Muir.\n\n\n\n\n"}
{"id": "58413242", "url": "https://en.wikipedia.org/wiki?curid=58413242", "title": "Kangaroo: A Love Hate Story", "text": "Kangaroo: A Love Hate Story\n\nKangaroo: A Love-Hate Story, is an Australian environmental documentary produced by Second Nature Films, co-written and directed by the team of Mick McIntyre and Kate McIntyre Clere. The dramatic documentary centers around the relationship that Australians share with kangaroos. The documentary brings in experts on different sides of the issue, and features interviews with Tim Flannery, Australia's leading conservationist, and Terri Irwin, owner of the Australia Zoo. The film opened in Australia on February 5, 2017 and in 2018 \"Kangaroo\" opened in limited release to theatres in the United States on January 19.\n\n\"Kangaroo\" began as an interest to delve deeper into the spilt opinion concerning the animal, with Kate McIntyre Clere saying that they were surprised to learn just how many kangaroos are shot and sold for profit each year. The film opens in the middle of the action, with home video that was shot and provided by one of the interviewees in the film, showing the violent and brutal shooting of kangaroos on the edge of the individual’s property. Kangaroos are seen as the icon of Australia, and the marsupial is featured in everything from tourism advertisements, sports teams, and Qantas, the national airline of Australia. The crux of the documentary is to shed light on the dark and violent truth that lies within the commercial kangaroo industry, and highlights the culling of the icon. The film does not shy away from the graphic, and gets up close and personal with the aftermath of kangaroo harvesting, explaining that while there are regulations put in place to ensure that the kangaroos are killed in a humane way (a bullet to the head), it is revealed that a sizeable percentage of culled kangaroos were shot in the neck or the jaw, rather than the head, causing prolonged suffering. Another important point that is made in the film is that the systemic algorithm currently in place to track and monitor kangaroo populations, is complicated and flawed as it does include factors such as drought, illegal shooting, climate change, or slow reproduction rates. \"Kangaroo\" includes voices from all sides of the issue, including those from a political and economic perspective, as well as from a humanitarian and scientific perspective, interviewing members of Australian parliament and environmental experts. \n\nDue to the documentary nature of the film, the cast does not feature a list of characters, but rather a list of credible sources who lent their time and expertise to appear in the film. Listed here are some of the featured Australians that were interviewed.\nThe film received a mix of critical reviews when it first premiered. Many have been in positive support of the film, with the \"New York Times\" saying that Kate and Mick \"sound a wake-up siren\" and that the film \"isn't always pretty, but it is necessary.\" \"Variety\" as well had positive comments, praising the documentary, exclaiming that it \"has the potential to help bring kangaroo welfare and management into much sharper focus in Australia and internationally,\" if a solution to the slaughter was to ever be found. Others, however, did not receive the film positively, especially farmers and those working in the commercial kangaroo industry, saying that the documentary was a \"beat up\" and expressed fears that it could ruin the industry. \"Kangaroo\" currently holds a 78% total film score on Rotten Tomatoes and a score of 66 on Metacritic.\n\nDue to the main content of the film, \"Kangaroo\" has caused its fair share of controversy since its release. The topic of the film in itself, the dark reality behind the kangaroo culling industry, was already controversial even before the documentary was made, with Mick and Kate stating that they were shocked at how polarising the documentary was, saying that they \"knew it would be polarising, but not this polarising.\" Those in government positions, as well as those who make a living in the commercial kangaroo industry, openly criticised the film. When NSW Greens senator Lee Rhiannon, one of the politicians featured in the documentary, spoke at one of the premieres with several other animal activists, her support and promotion of the film were labeled as \"disgusting\" by the minister of Federal Agriculture, David Littleproud. A negative reaction was also received from the National Farmers' Federation (NFF) and its president, Fiona Simson, who slammed the documentary for \"misrepresenting the situation,\" and \"ignoring basic facts,\" claiming that the film was \"very damaging to Australia.\" Many other farmers and meat processors have come forward, declaring that Kangaroo uses \"shock tactics\" and that the film was a complete joke, questioning the motives of the filmmakers.\n\n\nOne of the film's distributors, Indivillage, recently announced that \"Kangaroo\" has qualified for the 2019 Academy Awards. The creators have decided to launch a \"For Your Consideration\" campaign in order to catch the Academy's interest and nomination. As part of the campaign, the documentary will be shown at additional screenings in Los Angeles, California.\n\n\n"}
{"id": "863044", "url": "https://en.wikipedia.org/wiki?curid=863044", "title": "Kay Cottee", "text": "Kay Cottee\n\nKay Cottee (born 25 January 1954) is an Australian sailor, who was the first woman to perform a single-handed, non-stop and unassisted circumnavigation of the world. She performed this feat in 1988 in her yacht \"Blackmores First Lady\", taking 189 days.\n\nBorn Kay McLaren—the youngest of four daughters—in Sydney on 25 January 1954, Cottee grew up in the southern Sydney suburb of Sans Souci. She was born into a yachting family and was taken sailing for the first time when only a few weeks old. For secondary schooling, she attended Moorefield Girls High School in Kogarah, New South Wales.\n\nCottee now lives in Yamba on the far NSW north coast with television producer husband Peter Sutton. She is an international motivational speaker, skilled boat builder, writer, painter and sculptor.\n\nOn 5 June 1988 at age 34, Kay Cottee became the first woman to sail round the world alone non-stop and unassisted when she sailed through Sydney heads. She was greeted by tens of thousands of well-wishers. Cottee had left the harbour 189 days earlier, on 29 November 1987.\n\nThe historic voyage on her 37 ft yacht \"Blackmores First Lady\" was also the fastest sailing trip around the world by a woman and the first solo, non-stop and unassisted voyage around the world by a woman.\n\nIn the Southern Ocean, Cottee's boat was knocked down continuously and she was washed overboard. When Cottee rounded Cape Horn, the southernmost tip of South America, she celebrated with a lunch of crab, mayonnaise and self baked bread, and a bottle of Grange, a prestigious Australian wine.\n\nCottee and her major sponsor Blackmores Limited used the voyage to raise over $1M for the Rev. Ted Noffs' Life Education Program. Cottee also undertook an 18-month national schools tour, speaking to over 40,000 senior high school students, imparting the message you can achieve your dreams if you work steadily towards them.\n\nSince her round the world trip, Kay Cottee has received numerous accolades.\n\nIn 1991, Cottee joined the advisory board of the Australian National Maritime Museum. She was chair of the museum from 1995 until 2001. In 2000, \"Blackmores First Lady\", was acquired by the museum and placed on permanent display.\n\nCottee is the author of two books. Her first book, \"First Lady\", was published by Macmillan in 1989. Her second book, \"All at Sea on Land\", was published by Pan Macmillan in 1998, about her life in the ten years since the voyage.\n"}
{"id": "46548086", "url": "https://en.wikipedia.org/wiki?curid=46548086", "title": "List of Lilium species", "text": "List of Lilium species\n\nList of \"Lilium\" species.\n\nThe \"Lilium\" genus is within the Lilieae tribe of the Lilioideae subfamily, in the Liliaceae family of the Liliales order.\n\nSpecies of \"Lilium\" currently accepted, with approximate native ranges, include:\n"}
{"id": "11887314", "url": "https://en.wikipedia.org/wiki?curid=11887314", "title": "List of New York hurricanes", "text": "List of New York hurricanes\n\n84 tropical or subtropical cyclones have affected the state of New York since the 17th century. The state of New York is located along the East Coast of the United States, in the Northeastern portion of the country. The strongest of these storms was the 1938 New England hurricane, which struck Long Island as a Category 3 storm on the Saffir–Simpson hurricane scale. Killing more than 600 people, it was also the deadliest. Tropical cyclones have affected the state primarily in September but have also hit during every month of the hurricane season, June through November. Tropical cyclones rarely make landfall on the state, although it is common for remnants of tropical cyclones to produce heavy rainfall and flooding.\n\n\n\n\n\n\n\n\n\n\nThe following table includes all storms which caused fatalities in New York State.\n\n\n"}
{"id": "14915618", "url": "https://en.wikipedia.org/wiki?curid=14915618", "title": "List of crotaline species and subspecies", "text": "List of crotaline species and subspecies\n\nThis is a list of all sure genera, species and subspecies of the subfamily Crotalinae, otherwise referred to as crotalines, pit vipers or pitvipers. It follows the taxonomy currently provided by ITIS, which is based on the continuing work of Dr. Roy McDiarmid.\n\n\n"}
{"id": "31510863", "url": "https://en.wikipedia.org/wiki?curid=31510863", "title": "List of ecoregions in Ivory Coast", "text": "List of ecoregions in Ivory Coast\n\nThe following is a list of ecoregions in Ivory Coast, according to the Worldwide Fund for Nature (WWF).\n\n\"By major habitat type:\"\n\n\n\n\n\"By bioregion:\"\n\n\n"}
{"id": "13390482", "url": "https://en.wikipedia.org/wiki?curid=13390482", "title": "List of historical maps", "text": "List of historical maps\n\nThe following is a list of notable extant historical maps.\n\n\n\n\n\n"}
{"id": "10966502", "url": "https://en.wikipedia.org/wiki?curid=10966502", "title": "Mabel Osgood Wright", "text": "Mabel Osgood Wright\n\nMabel Osgood Wright (January 26, 1859 – July 16, 1934) was an American author. She was an early leader in the Audubon movement who wrote extensively about nature and birds.\n\nMabel Osgood was the daughter of Samuel and Ellen Haswell (Murdock) Osgood. She was born in New York City on January 26, 1859, and was educated at home and in private schools.\n\nOn September 25, 1884, she was married to James Osborne Wright, an Englishman; after an extended visit to England, the couple moved to Fairfield, Connecticut.\n\nWright's first printed work (apart from a few verses), was the essay \"A New England May Day\", which appeared in the New York \"Evening Post\" in 1893. This work was collected with other pieces into her first book, \"The Friendship of Nature\", published by Macmillan in 1894. The following year, Wright released \"Birdcraft: A Field Book of Two Hundred Song, Game, and Water Birds\". A prototype of the modern field guide to birds for a popular audience, \"Birdcraft\" featured color reproductions from John James Audubon and other artists to illustrate species commonly encountered at home or in a neighboring park. A later edition credits Louis Agassiz Fuertes as a contributing artist. Frank M. Chapman described it as \"one of the first and most successful bird manuals.\" Two years later, Wright's \"Citizen Bird: Scenes from Bird-life in Plain English for Beginners,\" a collaboration with Elliott Coues, appeared.\n\nFrom its inception in 1899, Wright contributed to Chapman's \"Bird-Lore\", co-editing its Audubon department with William Dutcher. She served as a contributing editor until her death. She helped organize the Connecticut Audubon Society, became its first president in 1898, and served for many years. From 1905 to 1928, Wright was a director of the National Association of Audubon Societies (now the National Audubon Society). Wright became an associate member of the American Ornithologists' Union in 1895, and was one of the first three women raised to elective membership in 1901. Joining her were Florence Merriam Bailey and Olive Thorne Miller. Wright pioneered bird protection by establishing Birdcraft Sanctuary in 1914, near her home in Fairfield. The refuge is the oldest private songbird sanctuary in the United States.\n\nFrom her beginnings as a writer about children, nature, and outdoor life, Wright's reception from the public was cordial. However, when she began to publish works of fiction, she concealed her identity as their author until they had won recognition independently, taking the pseudonym of \"Barbara\". Much of the material to which she gave attractive literary expression she found in the large garden at her home in Fairfield. Although Wright is remembered more for her nature writing, some aspects of her fiction are notable. Some of these romances were unconventional in form, combining passages of fictional narrative with letters, diary entries, and nonfictional pieces of autobiography, social criticism, and gardening lore. It is true that her fictional range was narrow, limited demographically to the upper classes of Manhattan and New England and emotionally to scenes of domestic piety and sentimentality. But her observations of changing social patterns (the \"new magnates\" of the new century and increased suburbanization) and of the growth of feminism are worthwhile. Her ambivalence toward the changing role of women is interesting, with sympathy on the one hand and shrill attacks on careerism on the other.\n\nOn July 16, 1934, she succumbed to hypertensive myocardial disease with angina, and died in Fairfield. She is buried in Oaklawn Cemetery in that town.\n\n\nMabel Osgood Wright's work also includes the following. Several of the works of fiction first appeared under the pseudonym of \"Barbara\".\n\n\n"}
{"id": "57544988", "url": "https://en.wikipedia.org/wiki?curid=57544988", "title": "Nedjib (Ned) Djilali", "text": "Nedjib (Ned) Djilali\n\nNedjib (Ned) Djilali (born August 1, 1953) is a Canadian engineering professor and researcher specializing in sustainable energy and thermofluid sciences. He holds the Canada Research Chair in Advanced Energy Systems Design and Computational Modelling at the University of Victoria. Djilali is a Highly Cited Researcher, and a fellow of both the Canadian Academy of Engineering (2010) and the Royal Society of Canada (2013). \n\nDjilali was born and raised in Algeria and educated in the UK and Canada. After completing a BSc (Hon.) in Aeronautical Engineering at the University of Hertfordshire and a MSc in Aeronautics at Imperial College, London he served with the Air Force (compulsory military service) and then worked as an airworthiness engineer and as a lecturer at the Ecole Nationale des Techniques de l'Aviation Civile, Algeria. He moved to Canada in 1982, earned a PhD in experimental and computational fluid dynamics from the University of British Columbia in 1987, and joined the Advanced Aerodynamics Department of Bombardier Aerospace, Montreal in 1989, where he worked on the design of the Canadair Regional Jet and on the development of advanced CFD methods. He was appointed at the University of Victoria in 1991. \n\nProf. Djilali’s earliest work focused on computational and experimental fluid mechanics and heat transfer, including fundamental aspects of complex turbulence, thermosolutal transport in epitaxial crystal growth of semiconductors, and membrane separation processes for desalination and water purification. He is particularly known for his contributions to fuel cell science and technology, and for his work on sustainable energy modeling. His seminal work includes pioneering computational modeling of transport phenomena in fuel cells, and novel fuel cell architectures. His energy systems analysis work has focused on demand response methods to achieve high penetration of renewable energy in electric power systems, and the water-energy nexus. \n\nDjilali has served as Director of UVic’s Institute for Integrated Energy Systems and of the Pacific Institute for Climate Solutions, leading and facilitating the development and implementation of low carbon energy systems, and forming collaborative partnerships with automotive and clean energy technology companies and organizations around the world including Ballard, Toyota, AECL, and CFD Research Corporation. Djilali was a member of the task force that developed the “BC Hydrogen & Fuel Cell Industry Strategy” reporting to the Premier’s Technology Council. He was a High Level Visiting Researcher with the CNRS Institut de Mécanique des Fluides de Toulouse (France) in 1997-1998, an ERCOFTAC visiting Fellow with ETH in 2003, a Visiting Professor with the NRC Institute for Fuel Cell Innovation in 2004, a Professor in Residence with Angstrom Power Inc. in 2005, and a Visiting Professor with NEXT Energy, University of Oldenburg in 2016. Djilali was also appointed Guest Professor at Chongqing University and Shanghai University, and Honorary Professor at Tianjin University. He was a member of the founding editorial board of the ASME Journal of Fuel Cell Science & Technology (now Journal of Electrochemical Energy Conversion and Storage), and served on the board of several other journals. Prof. Djilali was President of the CFD Society of Canada from 2000-2002, and chaired the CFD97 Conference and ISTP-20 (Int. Symposium on Transport Phenomena). \n\n"}
{"id": "35886761", "url": "https://en.wikipedia.org/wiki?curid=35886761", "title": "Omicron Cygni", "text": "Omicron Cygni\n\nThe Bayer designation Omicron Cygni (ο Cyg / ο Cygni) is shared by two or three star systems in the constellation Cygnus. Application of the superscripts to the three stars varies in different publications; the Flamsteed designations are unambiguous:\n"}
{"id": "1692768", "url": "https://en.wikipedia.org/wiki?curid=1692768", "title": "Parts of Animals", "text": "Parts of Animals\n\nParts of Animals (or On the Parts of Animals; Greek Περὶ ζῴων μορίων; Latin \"De Partibus Animalium\") is one of Aristotle's major texts on biology. It was written around 350 BC. The whole work is roughly a study in animal anatomy and physiology; it aims to provide a scientific understanding of the parts (organs, tissues, fluids, etc.) of animals.\n\n\n"}
{"id": "38530392", "url": "https://en.wikipedia.org/wiki?curid=38530392", "title": "Per Fugelli", "text": "Per Fugelli\n\nPer Fugelli (7 December 1943 – 13 September 2017) was a Norwegian physician and professor of General Practice at the University of Bergen from 1984 to 1992, and social medicine at the University of Oslo from 1992 until his death in 2017.\n\nFugelli was born in Stavanger, Norway, on December 7, 1943. He studied medicine at University of Oslo.\n\nFrom 1971–73 Fugelli was a general practitioner in Værøy and Røst, and from 1977 to 1980 in Porsanger. During this time he earned his PhD and graduated in 1978. In 1984, he became a Professor of General Practice at the University of Bergen, where he stayed until 1992. He became a Professor of social medicine at University of Oslo´s Institute of Health and Society. In 2013, he became Emeritus.\n\nIn 1993 Fugelli wrote: \"The patient Earth is sick. Global environmental disruptions can have serious consequences for human health. It's time for doctors to give a world diagnosis and advise on treatment,\" predating the founding of planetary health. He is the subject of the documentary \"I die\" by filmmaker Erik Poppe.\n\nHe was a frequent contributor to the public debate on health and medical questions. Among his early books are \"Tilbake til huslegen\" from 1975, \"Doktor på Værøy og Røst\" from 1977, and \"Helsetilstand og helsetjeneste på Værøy og Røst\" from 1978.\n\nHe published the essay collections \"Med sordin og kanon\" and \"Helse og rettferdighet\" in 1990, \"0-visjonen\" in 2003, and \"Nokpunktet\" in 2008. He has been editor or co-editor of several works, including \"Huslegen\" from 1985, \"Medisinsk leksikon\" from 1990, \"Medisin og helse\" from 1993, and \"Verdier og penger i helsetjenesten\" from 2009.\n\nFugelli was married, had two children, and three grandchildren by the time he died.\n\nIn 2009, he was diagnosed with colorectal cancer. It metastasized into his lungs and by 2012, the cancer was declared terminal. Nevertheless, Fugelli continued to write and work as long as he was able, with his final published article written six weeks before his death. He died at Jæren on 13 September 2017, aged 73.\n\nFugelli won the 2010 Karl Evang Prize and in 2013, the Freedom of Expression Foundation Prize. \n"}
{"id": "24944", "url": "https://en.wikipedia.org/wiki?curid=24944", "title": "Plate tectonics", "text": "Plate tectonics\n\nPlate tectonics (from the Late Latin \"tectonicus\", from the \"pertaining to building\") is a scientific theory describing the large-scale motion of seven large plates and the movements of a larger number of smaller plates of the Earth's lithosphere, since tectonic processes began on Earth between 3 and 3.5 billion years ago. The model builds on the concept of continental drift, an idea developed during the first decades of the 20th century. The geoscientific community accepted plate-tectonic theory after seafloor spreading was validated in the late 1950s and early 1960s.\n\nThe lithosphere, which is the rigid outermost shell of a planet (the crust and upper mantle), is broken into tectonic plates. The Earth's lithosphere is composed of seven or eight major plates (depending on how they are defined) and many minor plates. Where the plates meet, their relative motion determines the type of boundary: convergent, divergent, or transform. Earthquakes, volcanic activity, mountain-building, and oceanic trench formation occur along these plate boundaries (or faults). The relative movement of the plates typically ranges from zero to 100 mm annually.\n\nTectonic plates are composed of oceanic lithosphere and thicker continental lithosphere, each topped by its own kind of crust. Along convergent boundaries, subduction, or one plate moving under another, carries the lower one down into the mantle; the material lost is roughly balanced by the formation of new (oceanic) crust along divergent margins by seafloor spreading. In this way, the total surface of the lithosphere remains the same. This prediction of plate tectonics is also referred to as the conveyor belt principle. Earlier theories, since disproven, proposed gradual shrinking (contraction) or gradual expansion of the globe.\n\nTectonic plates are able to move because the Earth's lithosphere has greater mechanical strength than the underlying asthenosphere. Lateral density variations in the mantle result in convection; that is, the slow creeping motion of Earth's solid mantle. Plate movement is thought to be driven by a combination of the motion of the seafloor away from spreading ridges due to variations in topography (the ridge is a topographic high) and density changes in the crust (density increases as newly formed crust cools and moves away from the ridge). At subduction zones the relatively cold, dense crust is \"pulled\" or sinks down into the mantle over the downward convecting limb of a mantle cell. Another explanation lies in the different forces generated by tidal forces of the Sun and Moon. The relative importance of each of these factors and their relationship to each other is unclear, and still the subject of much debate.\n\nThe outer layers of the Earth are divided into the lithosphere and asthenosphere. The division is based on differences in mechanical properties and in the method for the transfer of heat. The lithosphere is cooler and more rigid, while the asthenosphere is hotter and flows more easily. In terms of heat transfer, the lithosphere loses heat by conduction, whereas the asthenosphere also transfers heat by convection and has a nearly adiabatic temperature gradient. This division should not be confused with the \"chemical\" subdivision of these same layers into the mantle (comprising both the asthenosphere and the mantle portion of the lithosphere) and the crust: a given piece of mantle may be part of the lithosphere or the asthenosphere at different times depending on its temperature and pressure.\n\nThe key principle of plate tectonics is that the lithosphere exists as separate and distinct \"tectonic plates\", which ride on the fluid-like (visco-elastic solid) asthenosphere. Plate motions range up to a typical 10–40 mm/year (Mid-Atlantic Ridge; about as fast as fingernails grow), to about 160 mm/year (Nazca Plate; about as fast as hair grows). The driving mechanism behind this movement is described below.\n\nTectonic lithosphere plates consist of lithospheric mantle overlain by one or two types of crustal material: oceanic crust (in older texts called \"sima\" from silicon and magnesium) and continental crust (\"sial\" from silicon and aluminium). Average oceanic lithosphere is typically thick; its thickness is a function of its age: as time passes, it conductively cools and subjacent cooling mantle is added to its base. Because it is formed at mid-ocean ridges and spreads outwards, its thickness is therefore a function of its distance from the mid-ocean ridge where it was formed. For a typical distance that oceanic lithosphere must travel before being subducted, the thickness varies from about thick at mid-ocean ridges to greater than at subduction zones; for shorter or longer distances, the subduction zone (and therefore also the mean) thickness becomes smaller or larger, respectively. Continental lithosphere is typically about 200 km thick, though this varies considerably between basins, mountain ranges, and stable cratonic interiors of continents.\n\nThe location where two plates meet is called a \"plate boundary\". Plate boundaries are commonly associated with geological events such as earthquakes and the creation of topographic features such as mountains, volcanoes, mid-ocean ridges, and oceanic trenches. The majority of the world's active volcanoes occur along plate boundaries, with the Pacific Plate's Ring of Fire being the most active and widely known today. These boundaries are discussed in further detail below. Some volcanoes occur in the interiors of plates, and these have been variously attributed to internal plate deformation and to mantle plumes.\n\nAs explained above, tectonic plates may include continental crust or oceanic crust, and most plates contain both. For example, the African Plate includes the continent and parts of the floor of the Atlantic and Indian Oceans. The distinction between oceanic crust and continental crust is based on their modes of formation. Oceanic crust is formed at sea-floor spreading centers, and continental crust is formed through arc volcanism and accretion of terranes through tectonic processes, though some of these terranes may contain ophiolite sequences, which are pieces of oceanic crust considered to be part of the continent when they exit the standard cycle of formation and spreading centers and subduction beneath continents. Oceanic crust is also denser than continental crust owing to their different compositions. Oceanic crust is denser because it has less silicon and more heavier elements (\"mafic\") than continental crust (\"felsic\"). As a result of this density stratification, oceanic crust generally lies below sea level (for example most of the Pacific Plate), while continental crust buoyantly projects above sea level (see the page isostasy for explanation of this principle).\n\nThree types of plate boundaries exist, with a fourth, mixed type, characterized by the way the plates move relative to each other. They are associated with different types of surface phenomena. The different types of plate boundaries are:\n\n\nIt has generally been accepted that tectonic plates are able to move because of the relative density of oceanic lithosphere and the relative weakness of the asthenosphere. Dissipation of heat from the mantle is acknowledged to be the original source of the energy required to drive plate tectonics through convection or large scale upwelling and doming. The current view, though still a matter of some debate, asserts that as a consequence, a powerful source of plate motion is generated due to the excess density of the oceanic lithosphere sinking in subduction zones. When the new crust forms at mid-ocean ridges, this oceanic lithosphere is initially less dense than the underlying asthenosphere, but it becomes denser with age as it conductively cools and thickens. The greater density of old lithosphere relative to the underlying asthenosphere allows it to sink into the deep mantle at subduction zones, providing most of the driving force for plate movement. The weakness of the asthenosphere allows the tectonic plates to move easily towards a subduction zone. Although subduction is thought to be the strongest force driving plate motions, it cannot be the only force since there are plates such as the North American Plate which are moving, yet are nowhere being subducted. The same is true for the enormous Eurasian Plate. The sources of plate motion are a matter of intensive research and discussion among scientists. One of the main points is that the kinematic pattern of the movement itself should be separated clearly from the possible geodynamic mechanism that is invoked as the driving force of the observed movement, as some patterns may be explained by more than one mechanism. In short, the driving forces advocated at the moment can be divided into three categories based on the relationship to the movement: mantle dynamics related, gravity related (mostly secondary forces), and earth rotation related.\n\nFor much of the last quarter century, the leading theory of the driving force behind tectonic plate motions envisaged large scale convection currents in the upper mantle, which can be transmitted through the asthenosphere. This theory was launched by Arthur Holmes and some forerunners in the 1930s and was immediately recognized as the solution for the acceptance of the theory as originally discussed in the papers of Alfred Wegener in the early years of the century. However, despite its acceptance, it was long debated in the scientific community because the leading theory still envisaged a static Earth without moving continents up until the major breakthroughs of the early sixties.\n\nTwo- and three-dimensional imaging of Earth's interior (seismic tomography) shows a varying lateral density distribution throughout the mantle. Such density variations can be material (from rock chemistry), mineral (from variations in mineral structures), or thermal (through thermal expansion and contraction from heat energy). The manifestation of this varying lateral density is mantle convection from buoyancy forces.\n\nHow mantle convection directly and indirectly relates to plate motion is a matter of ongoing study and discussion in geodynamics. Somehow, this energy must be transferred to the lithosphere for tectonic plates to move. There are essentially two main types of forces that are thought to influence plate motion: friction and gravity.\n\nLately, the convection theory has been much debated, as modern techniques based on 3D seismic tomography still fail to recognize these predicted large scale convection cells. Alternative views have been proposed.\n\nIn the theory of plume tectonics developed during the 1990s, a modified concept of mantle convection currents is used. It asserts that super plumes rise from the deeper mantle and are the drivers or substitutes of the major convection cells. These ideas, which find their roots in the early 1930s, find resonance in the modern theories which envisage hot spots or mantle plumes which remain fixed and are overridden by oceanic and continental lithosphere plates over time and leave their traces in the geological record (though these phenomena are not invoked as real driving mechanisms, but rather as modulators).\n\nAnother theory is that the mantle flows neither in cells nor large plumes but rather as a series of channels just below the Earth's crust, which then provide basal friction to the lithosphere. This theory, called \"surge tectonics\", became quite popular in geophysics and geodynamics during the 1980s and 1990s. Recent research, based on three-dimensional computer modeling, suggests that plate geometry is governed by a feedback between mantle convection patterns and the strength of the lithosphere.\n\nForces related to gravity are usually invoked as secondary phenomena within the framework of a more general driving mechanism such as the various forms of mantle dynamics described above.\n\nGravitational sliding away from a spreading ridge: According to many authors, plate motion is driven by the higher elevation of plates at ocean ridges. As oceanic lithosphere is formed at spreading ridges from hot mantle material, it gradually cools and thickens with age (and thus adds distance from the ridge). Cool oceanic lithosphere is significantly denser than the hot mantle material from which it is derived and so with increasing thickness it gradually subsides into the mantle to compensate the greater load. The result is a slight lateral incline with increased distance from the ridge axis.\n\nThis force is regarded as a secondary force and is often referred to as \"ridge push\". This is a misnomer as nothing is \"pushing\" horizontally and tensional features are dominant along ridges. It is more accurate to refer to this mechanism as gravitational sliding as variable topography across the totality of the plate can vary considerably and the topography of spreading ridges is only the most prominent feature. Other mechanisms generating this gravitational secondary force include flexural bulging of the lithosphere before it dives underneath an adjacent plate which produces a clear topographical feature that can offset, or at least affect, the influence of topographical ocean ridges, and mantle plumes and hot spots, which are postulated to impinge on the underside of tectonic plates.\n\nSlab-pull: Current scientific opinion is that the asthenosphere is insufficiently competent or rigid to directly cause motion by friction along the base of the lithosphere. Slab pull is therefore most widely thought to be the greatest force acting on the plates. In this current understanding, plate motion is mostly driven by the weight of cold, dense plates sinking into the mantle at trenches. Recent models indicate that trench suction plays an important role as well. However, the fact that the North American Plate is nowhere being subducted, although it is in motion, presents a problem. The same holds for the African, Eurasian, and Antarctic plates.\n\nGravitational sliding away from mantle doming: According to older theories, one of the driving mechanisms of the plates is the existence of large scale asthenosphere/mantle domes which cause the gravitational sliding of lithosphere plates away from them. This gravitational sliding represents a secondary phenomenon of this basically vertically oriented mechanism. This can act on various scales, from the small scale of one island arc up to the larger scale of an entire ocean basin.\n\nAlfred Wegener, being a meteorologist, had proposed tidal forces and centrifugal forces as the main driving mechanisms behind continental drift; however, these forces were considered far too small to cause continental motion as the concept was of continents plowing through oceanic crust. Therefore, Wegener later changed his position and asserted that convection currents are the main driving force of plate tectonics in the last edition of his book in 1929.\n\nHowever, in the plate tectonics context (accepted since the seafloor spreading proposals of Heezen, Hess, Dietz, Morley, Vine, and Matthews (see below) during the early 1960s), the oceanic crust is suggested to be in motion \"with\" the continents which caused the proposals related to Earth rotation to be reconsidered. In more recent literature, these driving forces are:\n\nForces that are small and generally negligible are:\n\n\nFor these mechanisms to be overall valid, systematic relationships should exist all over the globe between the orientation and kinematics of deformation and the geographical latitudinal and longitudinal grid of the Earth itself. Ironically, these systematic relations studies in the second half of the nineteenth century and the first half of the twentieth century underline exactly the opposite: that the plates had not moved in time, that the deformation grid was fixed with respect to the Earth equator and axis, and that gravitational driving forces were generally acting vertically and caused only local horizontal movements (the so-called pre-plate tectonic, \"fixist theories\"). Later studies (discussed below on this page), therefore, invoked many of the relationships recognized during this pre-plate tectonics period to support their theories (see the anticipations and reviews in the work of van Dijk and collaborators).\n\nOf the many forces discussed in this paragraph, tidal force is still highly debated and defended as a possible principal driving force of plate tectonics. The other forces are only used in global geodynamic models not using plate tectonics concepts (therefore beyond the discussions treated in this section) or proposed as minor modulations within the overall plate tectonics model.\n\nIn 1973, George W. Moore of the USGS and R. C. Bostrom presented evidence for a general westward drift of the Earth's lithosphere with respect to the mantle. He concluded that tidal forces (the tidal lag or \"friction\") caused by the Earth's rotation and the forces acting upon it by the Moon are a driving force for plate tectonics. As the Earth spins eastward beneath the moon, the moon's gravity ever so slightly pulls the Earth's surface layer back westward, just as proposed by Alfred Wegener (see above). In a more recent 2006 study, scientists reviewed and advocated these earlier proposed ideas. It has also been suggested recently in that this observation may also explain why Venus and Mars have no plate tectonics, as Venus has no moon and Mars' moons are too small to have significant tidal effects on the planet. In a recent paper, it was suggested that, on the other hand, it can easily be observed that many plates are moving north and eastward, and that the dominantly westward motion of the Pacific Ocean basins derives simply from the eastward bias of the Pacific spreading center (which is not a predicted manifestation of such lunar forces). In the same paper the authors admit, however, that relative to the lower mantle, there is a slight westward component in the motions of all the plates. They demonstrated though that the westward drift, seen only for the past 30 Ma, is attributed to the increased dominance of the steadily growing and accelerating Pacific plate. The debate is still open.\n\nThe vector of a plate's motion is a function of all the forces acting on the plate; however, therein lies the problem regarding the degree to which each process contributes to the overall motion of each tectonic plate.\n\nThe diversity of geodynamic settings and the properties of each plate result from the impact of the various processes actively driving each individual plate. One method of dealing with this problem is to consider the relative rate at which each plate is moving as well as the evidence related to the significance of each process to the overall driving force on the plate.\n\nOne of the most significant correlations discovered to date is that lithospheric plates attached to downgoing (subducting) plates move much faster than plates not attached to subducting plates. The Pacific plate, for instance, is essentially surrounded by zones of subduction (the so-called Ring of Fire) and moves much faster than the plates of the Atlantic basin, which are attached (perhaps one could say 'welded') to adjacent continents instead of subducting plates. It is thus thought that forces associated with the downgoing plate (slab pull and slab suction) are the driving forces which determine the motion of plates, except for those plates which are not being subducted. This view however has been contradicted by a recent study which found that the actual motions of the Pacific Plate and other plates associated with the East Pacific Rise do not correlate mainly with either slab pull or slab push, but rather with a mantle convection upwelling whose horizontal spreading along the bases of the various plates drives them along via viscosity-related traction forces. The driving forces of plate motion continue to be active subjects of on-going research within geophysics and tectonophysics.\n\nIn line with other previous and contemporaneous proposals, in 1912 the meteorologist Alfred Wegener amply described what he called continental drift, expanded in his 1915 book \"The Origin of Continents and Oceans\" and the scientific debate started that would end up fifty years later in the theory of plate tectonics. Starting from the idea (also expressed by his forerunners) that the present continents once formed a single land mass (which was called Pangea later on) that drifted apart, thus releasing the continents from the Earth's mantle and likening them to \"icebergs\" of low density granite floating on a sea of denser basalt. Supporting evidence for the idea came from the dove-tailing outlines of South America's east coast and Africa's west coast, and from the matching of the rock formations along these edges. Confirmation of their previous contiguous nature also came from the fossil plants \"Glossopteris\" and \"Gangamopteris\", and the therapsid or mammal-like reptile \"Lystrosaurus\", all widely distributed over South America, Africa, Antarctica, India, and Australia. The evidence for such an erstwhile joining of these continents was patent to field geologists working in the southern hemisphere. The South African Alex du Toit put together a mass of such information in his 1937 publication \"Our Wandering Continents\", and went further than Wegener in recognising the strong links between the Gondwana fragments.\n\nBut without detailed evidence and a force sufficient to drive the movement, the theory was not generally accepted: the Earth might have a solid crust and mantle and a liquid core, but there seemed to be no way that portions of the crust could move around. Distinguished scientists, such as Harold Jeffreys and Charles Schuchert, were outspoken critics of continental drift.\n\nDespite much opposition, the view of continental drift gained support and a lively debate started between \"drifters\" or \"mobilists\" (proponents of the theory) and \"fixists\" (opponents). During the 1920s, 1930s and 1940s, the former reached important milestones proposing that convection currents might have driven the plate movements, and that spreading may have occurred below the sea within the oceanic crust. Concepts close to the elements now incorporated in plate tectonics were proposed by geophysicists and geologists (both fixists and mobilists) like Vening-Meinesz, Holmes, and Umbgrove.\n\nOne of the first pieces of geophysical evidence that was used to support the movement of lithospheric plates came from paleomagnetism. This is based on the fact that rocks of different ages show a variable magnetic field direction, evidenced by studies since the mid–nineteenth century. The magnetic north and south poles reverse through time, and, especially important in paleotectonic studies, the relative position of the magnetic north pole varies through time. Initially, during the first half of the twentieth century, the latter phenomenon was explained by introducing what was called \"polar wander\" (see apparent polar wander), i.e., it was assumed that the north pole location had been shifting through time. An alternative explanation, though, was that the continents had moved (shifted and rotated) relative to the north pole, and each continent, in fact, shows its own \"polar wander path\". During the late 1950s it was successfully shown on two occasions that these data could show the validity of continental drift: by Keith Runcorn in a paper in 1956, and by Warren Carey in a symposium held in March 1956.\n\nThe second piece of evidence in support of continental drift came during the late 1950s and early 60s from data on the bathymetry of the deep ocean floors and the nature of the oceanic crust such as magnetic properties and, more generally, with the development of marine geology which gave evidence for the association of seafloor spreading along the mid-oceanic ridges and magnetic field reversals, published between 1959 and 1963 by Heezen, Dietz, Hess, Mason, Vine & Matthews, and Morley.\n\nSimultaneous advances in early seismic imaging techniques in and around Wadati–Benioff zones along the trenches bounding many continental margins, together with many other geophysical (e.g. gravimetric) and geological observations, showed how the oceanic crust could disappear into the mantle, providing the mechanism to balance the extension of the ocean basins with shortening along its margins.\n\nAll this evidence, both from the ocean floor and from the continental margins, made it clear around 1965 that continental drift was feasible and the theory of plate tectonics, which was defined in a series of papers between 1965 and 1967, was born, with all its extraordinary explanatory and predictive power. The theory revolutionized the Earth sciences, explaining a diverse range of geological phenomena and their implications in other studies such as paleogeography and paleobiology.\n\nIn the late 19th and early 20th centuries, geologists assumed that the Earth's major features were fixed, and that most geologic features such as basin development and mountain ranges could be explained by vertical crustal movement, described in what is called the geosynclinal theory. Generally, this was placed in the context of a contracting planet Earth due to heat loss in the course of a relatively short geological time.\n\nIt was observed as early as 1596 that the opposite coasts of the Atlantic Ocean—or, more precisely, the edges of the continental shelves—have similar shapes and seem to have once fitted together.\n\nSince that time many theories were proposed to explain this apparent complementarity, but the assumption of a solid Earth made these various proposals difficult to accept.\n\nThe discovery of radioactivity and its associated heating properties in 1895 prompted a re-examination of the apparent age of the Earth. This had previously been estimated by its cooling rate under the assumption that the Earth's surface radiated like a black body. Those calculations had implied that, even if it started at red heat, the Earth would have dropped to its present temperature in a few tens of millions of years. Armed with the knowledge of a new heat source, scientists realized that the Earth would be much older, and that its core was still sufficiently hot to be liquid.\n\nBy 1915, after having published a first article in 1912, Alfred Wegener was making serious arguments for the idea of continental drift in the first edition of \"The Origin of Continents and Oceans\". In that book (re-issued in four successive editions up to the final one in 1936), he noted how the east coast of South America and the west coast of Africa looked as if they were once attached. Wegener was not the first to note this (Abraham Ortelius, Antonio Snider-Pellegrini, Eduard Suess, Roberto Mantovani and Frank Bursley Taylor preceded him just to mention a few), but he was the first to marshal significant fossil and paleo-topographical and climatological evidence to support this simple observation (and was supported in this by researchers such as Alex du Toit). Furthermore, when the rock strata of the margins of separate continents are very similar it suggests that these rocks were formed in the same way, implying that they were joined initially. For instance, parts of Scotland and Ireland contain rocks very similar to those found in Newfoundland and New Brunswick. Furthermore, the Caledonian Mountains of Europe and parts of the Appalachian Mountains of North America are very similar in structure and lithology.\n\nHowever, his ideas were not taken seriously by many geologists, who pointed out that there was no apparent mechanism for continental drift. Specifically, they did not see how continental rock could plow through the much denser rock that makes up oceanic crust. Wegener could not explain the force that drove continental drift, and his vindication did not come until after his death in 1930.\n\nAs it was observed early that although granite existed on continents, seafloor seemed to be composed of denser basalt, the prevailing concept during the first half of the twentieth century was that there were two types of crust, named \"sial\" (continental type crust) and \"sima\" (oceanic type crust). Furthermore, it was supposed that a static shell of strata was present under the continents. It therefore looked apparent that a layer of basalt (sial) underlies the continental rocks.\n\nHowever, based on abnormalities in plumb line deflection by the Andes in Peru, Pierre Bouguer had deduced that less-dense mountains must have a downward projection into the denser layer underneath. The concept that mountains had \"roots\" was confirmed by George B. Airy a hundred years later, during study of Himalayan gravitation, and seismic studies detected corresponding density variations. Therefore, by the mid-1950s, the question remained unresolved as to whether mountain roots were clenched in surrounding basalt or were floating on it like an iceberg.\n\nDuring the 20th century, improvements in and greater use of seismic instruments such as seismographs enabled scientists to learn that earthquakes tend to be concentrated in specific areas, most notably along the oceanic trenches and spreading ridges. By the late 1920s, seismologists were beginning to identify several prominent earthquake zones parallel to the trenches that typically were inclined 40–60° from the horizontal and extended several hundred kilometers into the Earth. These zones later became known as Wadati–Benioff zones, or simply Benioff zones, in honor of the seismologists who first recognized them, Kiyoo Wadati of Japan and Hugo Benioff of the United States. The study of global seismicity greatly advanced in the 1960s with the establishment of the Worldwide Standardized Seismograph Network (WWSSN) to monitor the compliance of the 1963 treaty banning above-ground testing of nuclear weapons. The much improved data from the WWSSN instruments allowed seismologists to map precisely the zones of earthquake concentration worldwide.\n\nMeanwhile, debates developed around the phenomena of polar wander. Since the early debates of continental drift, scientists had discussed and used evidence that polar drift had occurred because continents seemed to have moved through different climatic zones during the past. Furthermore, paleomagnetic data had shown that the magnetic pole had also shifted during time. Reasoning in an opposite way, the continents might have shifted and rotated, while the pole remained relatively fixed. The first time the evidence of magnetic polar wander was used to support the movements of continents was in a paper by Keith Runcorn in 1956, and successive papers by him and his students Ted Irving (who was actually the first to be convinced of the fact that paleomagnetism supported continental drift) and Ken Creer.\n\nThis was immediately followed by a symposium in Tasmania in March 1956. In this symposium, the evidence was used in the theory of an expansion of the global crust. In this hypothesis the shifting of the continents can be simply explained by a large increase in size of the Earth since its formation. However, this was unsatisfactory because its supporters could offer no convincing mechanism to produce a significant expansion of the Earth. Certainly there is no evidence that the moon has expanded in the past 3 billion years; other work would soon show that the evidence was equally in support of continental drift on a globe with a stable radius.\n\nDuring the thirties up to the late fifties, works by Vening-Meinesz, Holmes, Umbgrove, and numerous others outlined concepts that were close or nearly identical to modern plate tectonics theory. In particular, the English geologist Arthur Holmes proposed in 1920 that plate junctions might lie beneath the sea, and in 1928 that convection currents within the mantle might be the driving force. Often, these contributions are forgotten because:\n\nIn 1947, a team of scientists led by Maurice Ewing utilizing the Woods Hole Oceanographic Institution's research vessel \"Atlantis\" and an array of instruments, confirmed the existence of a rise in the central Atlantic Ocean, and found that the floor of the seabed beneath the layer of sediments consisted of basalt, not the granite which is the main constituent of continents. They also found that the oceanic crust was much thinner than continental crust. All these new findings raised important and intriguing questions.\n\nThe new data that had been collected on the ocean basins also showed particular characteristics regarding the bathymetry. One of the major outcomes of these datasets was that all along the globe, a system of mid-oceanic ridges was detected. An important conclusion was that along this system, new ocean floor was being created, which led to the concept of the \"Great Global Rift\". This was described in the crucial paper of Bruce Heezen (1960), which would trigger a real revolution in thinking. A profound consequence of seafloor spreading is that new crust was, and still is, being continually created along the oceanic ridges. Therefore, Heezen advocated the so-called \"expanding Earth\" hypothesis of S. Warren Carey (see above). So, still the question remained: how can new crust be continuously added along the oceanic ridges without increasing the size of the Earth? In reality, this question had been solved already by numerous scientists during the forties and the fifties, like Arthur Holmes, Vening-Meinesz, Coates and many others: The crust in excess disappeared along what were called the oceanic trenches, where so-called \"subduction\" occurred. Therefore, when various scientists during the early sixties started to reason on the data at their disposal regarding the ocean floor, the pieces of the theory quickly fell into place.\n\nThe question particularly intrigued Harry Hammond Hess, a Princeton University geologist and a Naval Reserve Rear Admiral, and Robert S. Dietz, a scientist with the U.S. Coast and Geodetic Survey who first coined the term \"seafloor spreading\". Dietz and Hess (the former published the same idea one year earlier in \"Nature\", but priority belongs to Hess who had already distributed an unpublished manuscript of his 1962 article by 1960) were among the small handful who really understood the broad implications of sea floor spreading and how it would eventually agree with the, at that time, unconventional and unaccepted ideas of continental drift and the elegant and mobilistic models proposed by previous workers like Holmes.\n\nIn the same year, Robert R. Coats of the U.S. Geological Survey described the main features of island arc subduction in the Aleutian Islands. His paper, though little noted (and even ridiculed) at the time, has since been called \"seminal\" and \"prescient\". In reality, it actually shows that the work by the European scientists on island arcs and mountain belts performed and published during the 1930s up until the 1950s was applied and appreciated also in the United States.\n\nIf the Earth's crust was expanding along the oceanic ridges, Hess and Dietz reasoned like Holmes and others before them, it must be shrinking elsewhere. Hess followed Heezen, suggesting that new oceanic crust continuously spreads away from the ridges in a conveyor belt–like motion. And, using the mobilistic concepts developed before, he correctly concluded that many millions of years later, the oceanic crust eventually descends along the continental margins where oceanic trenches – very deep, narrow canyons – are formed, e.g. along the rim of the Pacific Ocean basin. The important step Hess made was that convection currents would be the driving force in this process, arriving at the same conclusions as Holmes had decades before with the only difference that the thinning of the ocean crust was performed using Heezen's mechanism of spreading along the ridges. Hess therefore concluded that the Atlantic Ocean was expanding while the Pacific Ocean was shrinking. As old oceanic crust is \"consumed\" in the trenches (like Holmes and others, he thought this was done by thickening of the continental lithosphere, not, as now understood, by underthrusting at a larger scale of the oceanic crust itself into the mantle), new magma rises and erupts along the spreading ridges to form new crust. In effect, the ocean basins are perpetually being \"recycled,\" with the creation of new crust and the destruction of old oceanic lithosphere occurring simultaneously. Thus, the new mobilistic concepts neatly explained why the Earth does not get bigger with sea floor spreading, why there is so little sediment accumulation on the ocean floor, and why oceanic rocks are much younger than continental rocks.\n\nBeginning in the 1950s, scientists like Victor Vacquier, using magnetic instruments (magnetometers) adapted from airborne devices developed during World War II to detect submarines, began recognizing odd magnetic variations across the ocean floor. This finding, though unexpected, was not entirely surprising because it was known that basalt—the iron-rich, volcanic rock making up the ocean floor—contains a strongly magnetic mineral (magnetite) and can locally distort compass readings. This distortion was recognized by Icelandic mariners as early as the late 18th century. More important, because the presence of magnetite gives the basalt measurable magnetic properties, these newly discovered magnetic variations provided another means to study the deep ocean floor. When newly formed rock cools, such magnetic materials recorded the Earth's magnetic field at the time.\n\nAs more and more of the seafloor was mapped during the 1950s, the magnetic variations turned out not to be random or isolated occurrences, but instead revealed recognizable patterns. When these magnetic patterns were mapped over a wide region, the ocean floor showed a zebra-like pattern: one stripe with normal polarity and the adjoining stripe with reversed polarity. The overall pattern, defined by these alternating bands of normally and reversely polarized rock, became known as magnetic striping, and was published by Ron G. Mason and co-workers in 1961, who did not find, though, an explanation for these data in terms of sea floor spreading, like Vine, Matthews and Morley a few years later.\n\nThe discovery of magnetic striping called for an explanation. In the early 1960s scientists such as Heezen, Hess and Dietz had begun to theorise that mid-ocean ridges mark structurally weak zones where the ocean floor was being ripped in two lengthwise along the ridge crest (see the previous paragraph). New magma from deep within the Earth rises easily through these weak zones and eventually erupts along the crest of the ridges to create new oceanic crust. This process, at first denominated the \"conveyer belt hypothesis\" and later called seafloor spreading, operating over many millions of years continues to form new ocean floor all across the 50,000 km-long system of mid-ocean ridges.\n\nOnly four years after the maps with the \"zebra pattern\" of magnetic stripes were published, the link between sea floor spreading and these patterns was correctly placed, independently by Lawrence Morley, and by Fred Vine and Drummond Matthews, in 1963, now called the Vine-Matthews-Morley hypothesis. This hypothesis linked these patterns to geomagnetic reversals and was supported by several lines of evidence:\n\nBy explaining both the zebra-like magnetic striping and the construction of the mid-ocean ridge system, the seafloor spreading hypothesis (SFS) quickly gained converts and represented another major advance in the development of the plate-tectonics theory. Furthermore, the oceanic crust now came to be appreciated as a natural \"tape recording\" of the history of the geomagnetic field reversals (GMFR) of the Earth's magnetic field. Today, extensive studies are dedicated to the calibration of the normal-reversal patterns in the oceanic crust on one hand and known timescales derived from the dating of basalt layers in sedimentary sequences (magnetostratigraphy) on the other, to arrive at estimates of past spreading rates and plate reconstructions.\n\nAfter all these considerations, Plate Tectonics (or, as it was initially called \"New Global Tectonics\") became quickly accepted in the scientific world, and numerous papers followed that defined the concepts:\n\nThe Plate Tectonics Revolution was the scientific and cultural change which developed from the acceptance of the plate tectonics theory. The event was a paradigm shift and scientific revolution.\n\nContinental drift theory helps biogeographers to explain the disjunct biogeographic distribution of present-day life found on different continents but having similar ancestors. In particular, it explains the Gondwanan distribution of ratites and the Antarctic flora.\n\nReconstruction is used to establish past (and future) plate configurations, helping determine the shape and make-up of ancient supercontinents and providing a basis for paleogeography.\n\nCurrent plate boundaries are defined by their seismicity. Past plate boundaries within existing plates are identified from a variety of evidence, such as the presence of ophiolites that are indicative of vanished oceans.\n\nTectonic motion is believed to have begun around 3 to 3.5 billion years ago.\n\nVarious types of quantitative and semi-quantitative information are available to constrain past plate motions. The geometric fit between continents, such as between west Africa and South America is still an important part of plate reconstruction. Magnetic stripe patterns provide a reliable guide to relative plate motions going back into the Jurassic period. The tracks of hotspots give absolute reconstructions, but these are only available back to the Cretaceous. Older reconstructions rely mainly on paleomagnetic pole data, although these only constrain the latitude and rotation, but not the longitude. Combining poles of different ages in a particular plate to produce apparent polar wander paths provides a method for comparing the motions of different plates through time. Additional evidence comes from the distribution of certain sedimentary rock types, faunal provinces shown by particular fossil groups, and the position of orogenic belts.\n\nThe movement of plates has caused the formation and break-up of continents over time, including occasional formation of a supercontinent that contains most or all of the continents. The supercontinent Columbia or Nuna formed during a period of and broke up about . The supercontinent Rodinia is thought to have formed about 1 billion years ago and to have embodied most or all of Earth's continents, and broken up into eight continents around . The eight continents later re-assembled into another supercontinent called Pangaea; Pangaea broke up into Laurasia (which became North America and Eurasia) and Gondwana (which became the remaining continents).\n\nThe Himalayas, the world's tallest mountain range, are assumed to have been formed by the collision of two major plates. Before uplift, they were covered by the Tethys Ocean.\n\nDepending on how they are defined, there are usually seven or eight \"major\" plates: African, Antarctic, Eurasian, North American, South American, Pacific, and Indo-Australian. The latter is sometimes subdivided into the Indian and Australian plates.\n\nThere are dozens of smaller plates, the seven largest of which are the Arabian, Caribbean, Juan de Fuca, Cocos, Nazca, Philippine Sea, and Scotia.\n\nThe current motion of the tectonic plates is today determined by remote sensing satellite data sets, calibrated with ground station measurements.\n\nThe appearance of plate tectonics on terrestrial planets is related to planetary mass, with more massive planets than Earth expected to exhibit plate tectonics. Earth may be a borderline case, owing its tectonic activity to abundant water (silica and water form a deep eutectic).\n\nVenus shows no evidence of active plate tectonics. There is debatable evidence of active tectonics in the planet's distant past; however, events taking place since then (such as the plausible and generally accepted hypothesis that the Venusian lithosphere has thickened greatly over the course of several hundred million years) has made constraining the course of its geologic record difficult. However, the numerous well-preserved impact craters have been utilized as a dating method to approximately date the Venusian surface (since there are thus far no known samples of Venusian rock to be dated by more reliable methods). Dates derived are dominantly in the range , although ages of up to have been calculated. This research has led to the fairly well accepted hypothesis that Venus has undergone an essentially complete volcanic resurfacing at least once in its distant past, with the last event taking place approximately within the range of estimated surface ages. While the mechanism of such an impressive thermal event remains a debated issue in Venusian geosciences, some scientists are advocates of processes involving plate motion to some extent.\n\nOne explanation for Venus's lack of plate tectonics is that on Venus temperatures are too high for significant water to be present. The Earth's crust is soaked with water, and water plays an important role in the development of shear zones. Plate tectonics requires weak surfaces in the crust along which crustal slices can move, and it may well be that such weakening never took place on Venus because of the absence of water. However, some researchers remain convinced that plate tectonics is or was once active on this planet.\n\nMars is considerably smaller than Earth and Venus, and there is evidence for ice on its surface and in its crust.\n\nIn the 1990s, it was proposed that Martian Crustal Dichotomy was created by plate tectonic processes. Scientists today disagree, and think that it was created either by upwelling within the Martian mantle that thickened the crust of the Southern Highlands and formed Tharsis or by a giant impact that excavated the Northern Lowlands.\n\nValles Marineris may be a tectonic boundary.\n\nObservations made of the magnetic field of Mars by the \"Mars Global Surveyor\" spacecraft in 1999 showed patterns of magnetic striping discovered on this planet. Some scientists interpreted these as requiring plate tectonic processes, such as seafloor spreading. However, their data fail a \"magnetic reversal test\", which is used to see if they were formed by flipping polarities of a global magnetic field.\n\nSome of the satellites of Jupiter have features that may be related to plate-tectonic style deformation, although the materials and specific mechanisms may be different from plate-tectonic activity on Earth. On 8 September 2014, NASA reported finding evidence of plate tectonics on Europa, a satellite of Jupiter—the first sign of subduction activity on another world other than Earth.\n\nTitan, the largest moon of Saturn, was reported to show tectonic activity in images taken by the \"Huygens\" probe, which landed on Titan on January 14, 2005.\n\nOn Earth-sized planets, plate tectonics is more likely if there are oceans of water. However, in 2007, two independent teams of researchers came to opposing conclusions about the likelihood of plate tectonics on larger super-Earths with one team saying that plate tectonics would be episodic or stagnant and the other team saying that plate tectonics is very likely on super-earths even if the planet is dry.\n\nConsideration of plate tectonics is a part of the search for extraterrestrial intelligence and extraterrestrial life.\n\n\n\n\n"}
{"id": "16801960", "url": "https://en.wikipedia.org/wiki?curid=16801960", "title": "Plating (geology)", "text": "Plating (geology)\n\nIn geology, plating is a hypothesized process whereby asthenospheric mantle hardens beneath crustal material, thereby becoming attached to it and thereafter moving together with the crustal material as part of the lithosphere.\n\nA complementary process, although it does not necessarily always involve the upper mantle, is called delamination.\n\n"}
{"id": "27342482", "url": "https://en.wikipedia.org/wiki?curid=27342482", "title": "Power Hungry", "text": "Power Hungry\n\nPower Hungry: The Myths of \"Green\" Energy and the Real Fuels of the Future is a book by Robert Bryce about energy, mainly from a United States perspective.\nIt was published in 2010 by PublicAffairs. A short essay based on the book was released as an op-ed by the author in \"The Washington Post\".\n\nAs in his earlier book \"Gusher of Lies\" (which was about the idea of energy independence), Bryce argues that the United States needs to continue to use large amounts of fossil fuels including imported oil.\nHowever he does contemplate ways in which reliance on fossil fuels might be reduced:\n\nBryce argues that some renewable sources, such as wind farms, are not truly green and that carbon capture and storage will not work and will prove to be an expensive mistake.\n\nTrevor Butterworth writing in the \"Wall Street Journal\" praised \"Power Hungry\" as a \"brutal, brilliant exploration\" of the quest for green energy.\n\nWilliam Tucker writing for \"The American Spectator\" said that \"Power Hungry\" is filled with little tidbits that \"make endlessly fascinating reading. For instance, In 1971 we consumed twice as much energy from natural gas as from coal, but coal made a comeback under Carter and overtook natural gas in 1986\".\n\nRoger A. Pielke, Jr. wrote on his blog, \"Bryce's book is generally well-written and well-argued, if sprawling and at times more pastiche than systematic argument. His book has three parts. The first surveys our demand for energy and why it is inevitably going to increase. The second seeks to dispel a slew of \"myths\" about green energy—13 myths in all\".\n\n\n"}
{"id": "38908", "url": "https://en.wikipedia.org/wiki?curid=38908", "title": "Proserpina", "text": "Proserpina\n\nProserpina (; ) or Proserpine () is an ancient Roman goddess whose cult, myths and mysteries were combined from those of Libera, and early Roman goddess of wine, and the Greek Persephone and Demeter, goddesses of grain and agriculture. The originally Roman goddess Libera was daughter of the agricultural goddess Ceres and wife to Liber, god of wine and freedom. In 204 BC, a new \"greek-style\" cult to Ceres and Proserpina as \"Mother and Maiden\" was imported from southern Italy, along with Greek priestesses to serve it, and was installed in Libera and Ceres' temple on Rome's Aventine Hill. The new cult and its priesthood were actively promoted by Rome's religious authorities as morally desirable for respectable Roman women, and may have partly subsumed the temple's older, native cult to Ceres, Liber and Libera; but the new rites seem to have functioned alongside the old, rather than replaced them.\n\nJust as Persephone was thought to be a daughter of Demeter, Romans made Proserpina a daughter of Demeter's Roman equivalent, Ceres. Like Persephone, Proserpina is associated with the underworld realm and its ruler; and along with her mother Ceres, with the springtime growth of crops and the cycle of life, death and rebirth or renewal. Her name is a Latinisation of \"Persephone\", perhaps influenced by the Latin \"proserpere\" (\"to emerge, to creep forth\"), with respect to the growing of grain. Her core myths – her forcible abduction by the god of the Underworld, her mother's search for her and her eventual but temporary restoration to the world above – are the subject of works in Roman and later art and literature. In particular, Proserpina's seizure by the god of the Underworld – usually described as the Rape of Proserpina, or of Persephone – has offered dramatic subject matter for Renaissance and later sculptors and painters.\n\nIn early Roman religion, Libera was the female equivalent of Liber (freedom). She was originally an Italic goddess; at some time during Rome's Regal or very early Republican eras, she was paired with Liber, also known as Liber Pater (The Free Father), Roman god of wine, male fertility, and a guardian of plebeian freedoms. She enters Roman history as part of a Triadic cult alongside Ceres and Liber, in a temple established on the Aventine Hill around 493 BCE. The location and context of this early cult mark her association with Rome's commoner-citizens, or plebs; she might have been offered cult on March 17 as part of Liber's festival, Liberalia, or at some time during the seven days of Cerealia (mid- to late April); in the latter festival, she would have been subordinate to Ceres. Otherwise, her relationship to her Aventine cult partners is uncertain; she has no known native mythology.\n\nLibera was officially identified with Proserpina in 205 BCE, when she acquired a Romanised form of the Greek mystery rites and their attendant mythology. In the late Republican era, Cicero described Liber and Libera as Ceres' children. At around the same time, possibly in the context of popular or religious drama, Hyginus equated her with Greek Ariadne, as bride to Liber's Greek equivalent, Dionysus. The older and newer forms of her cult and rites, and their diverse associations, persisted well into the late Imperial era. St. Augustine (AD 354 – 430) observed that Libera is concerned with female fertility, as Liber is with male fertility.\n\nProserpina was officially introduced to Rome around 205 BCE, along with the \"ritus graecia cereris\" (a Greek form of cult dedicated to her mother Ceres), as part of Rome's general religious recruitment of deities as allies against Carthage, towards the end of the Second Punic War. The cult originated in southern Italy (part of Magna Graecia) and was probably based on the women-only Greek Thesmophoria, a mystery cult to Demeter and Persephone as \"Mother and Maiden\". It arrived along with its Greek priestesses, who were granted Roman citizenship so that they could pray to the gods \"with a foreign and external knowledge, but with a domestic and civil intention\". The new cult was installed in the already ancient Temple of Ceres, Liber and Libera, Rome's Aventine patrons of the plebs; from the end of the 3rd century BC, Demeter's temple at Enna, in Sicily, was acknowledged as Ceres' oldest, most authoritative cult centre, and Libera was recognised as Proserpina, Roman equivalent to Demeter's daughter Persephone. Their joint cult recalls Demeter's search for Persephone, after the latter's rape and abduction into the underworld by Hades (or Pluto). At the Aventine, the new cult took its place alongside the old. It made no reference to Liber, whose open and gender-mixed cult continued to play a central role in plebeian culture, as a patron and protector of plebeian rights, freedoms and values. The exclusively female initiates and priestesses of the new \"greek style\" mysteries of Ceres and Proserpina were expected to uphold Rome's traditional, patrician-dominated social hierarchy and traditional morality. Unmarried girls should emulate the chastity of Proserpina, the maiden; married women should seek to emulate Ceres, the devoted and fruitful Mother. Their rites were intended to secure a good harvest, and increase the fertility of those who partook in the mysteries.\n\nA Temple of Proserpina was located in a suburb of Melite, in modern Mtarfa, Malta. The temple's ruins were quarried between the 17th and 18th centuries, and only a few fragments survive.\n\n \n\nThe best-known myth surrounding Proserpina is of her abduction by the god of the Underworld, her mother Ceres' frantic search for her, and her eventual but temporary restitution to the world above. In Latin literature, several versions are known, all similar in most respects to the myths of Greek Persephone's abduction by the King of the underworld, named variously in Greek sources as Hades or Pluto. \"Hades\" can mean both the hidden Underworld and its king (\"The hidden one\"), who in early Greek versions of the myth is a dark, unsympathetic figure; Persephone is \"Kore\" (\"The Maiden\"), taken against her will; in the Greek Eleusinian Mysteries, her captor is known as Pluto; they form a divine couple who rule the underworld together, and receive Eleusinian initiates into some form of better afterlife. Renamed thus, the king of the underworld is distanced from his consort's violent abduction. In the early 1st century Ovid gives two poetic versions of the myth in Latin; one in Book 5 of his \"Metamorphoses\" (Book 5) and another in Book 4 of his \"Fasti\". An early 5th century Latin version of the same myth is Claudian's \"De raptu Proserpinae\"; in most cases, these Latin works identify Proserpina's underworld abductor and later consort by the Roman god of the underworld's traditional Latin name, Dis.\n\nVenus, in order to bring love to Pluto, sent her son Amor (also known as Cupid) to hit Pluto with one of his arrows. Proserpina was in Sicily, at the Pergusa Lake near Enna, where she was playing with some nymphs and collecting flowers, when Pluto came out from the volcano Etna with four black horses named Orphnaeus, Aethon, Nycteus and Alastor. He abducted her in order to marry her and live with her in the underworld of which he was the ruler.\n\nHer mother Ceres, also known as Demeter, the goddess of agriculture or of the Earth, went looking for her across all of the world, and all in vain. She was unable to find anything but a small belt floating upon a little lake made from the tears of the nymphs. In her desperation, Ceres angrily stopped the growth of fruits and vegetables, bestowing a malediction on Sicily. Ceres refused to return to Mount Olympus and started walking the Earth, creating a desert with each step.\n\nWorried, Jupiter sent Mercury to order Pluto (Jupiter's brother) to free Proserpina. Pluto obeyed, but before letting her go he made her eat six pomegranate seeds, because those who have eaten the food of the dead could not return to the world of the living. This meant that she would have to live six months of each year with him, and stay the rest with her mother. This story was undoubtedly meant to illustrate the changing of the seasons: when Ceres welcomes her daughter back in the spring the earth blossoms, and when Proserpina must be returned to her husband it withers.\n\nIn another version of the story, Proserpina ate only four pomegranate seeds, and she did so of her own accord. When Jupiter ordered her return, Pluto struck a deal with Jupiter, saying that since she had stolen his pomegranate seeds, she must stay with him four months of the year in return. For this reason, in spring when Ceres receives her daughter back, the crops blossom, and in summer they flourish.\n\nIn the autumn Ceres changes the leaves to shades of brown and orange (her favorite colors) as a gift to Proserpina before she has to return to the underworld. During the time that Proserpina resides with Pluto, the world goes through winter, a time when the earth is barren.\n\nThe most extensive myth of Proserpina in Latin is Claudian's (4th century AD). It is closely connected with that of Orpheus and Eurydice. In Virgil's Georgics, Orpheus' beloved wife, Eurydice, died from a snake-bite; Proserpina allowed Orpheus into Hades without losing his life; charmed by his music, she allowed him to lead his wife back to the land of the living, as long as he did not look back during the journey. But Orpheus could not resist a backward glance, so Eurydice was forever lost to him.\n\nProserpina's figure inspired many artistic compositions, eminently in sculpture (Bernini, see \"The Rape of Proserpina (Bernini)\" ) in painting (D.G.Rossetti, a fresco by Pomarancio, J.Heintz, Rubens, A. Dürer, Dell'Abbate, Parrish) and in literature (Goethe's \"Proserpina\" and Swinburne's \"Hymn to Proserpine\" and \"The Garden of Proserpine\") The statue of the Rape of Prosepina by Pluto that stands in the Great Garden of Dresden, Germany is also referred to as \"Time Ravages Beauty\". Kate McGarrigle's song about the legend was one of the last things she wrote prior to her death, and received its only performance at her last concert at Royal Albert Hall in December 2009.\n\n26 Proserpina is a Main belt asteroid in diameter, which was discovered by Robert Luther in 1853.\n\n\n\n\n"}
{"id": "51270205", "url": "https://en.wikipedia.org/wiki?curid=51270205", "title": "Ramsay grease", "text": "Ramsay grease\n\nRamsay grease is a vacuum grease, used as a lubrication and a sealant of ground glass joints and cocks on laboratory glassware, e.g. burettes. It is usable to about 10 mbar (about 1 Pa) and about 30 °C. Its vapor pressure at 20 °C is about 10 mbar (0.01 Pa). It is named after Sir William Ramsay.\n\nDifferent grades exist (e.g. thick or viscous, soft). The viscous one is used for standard stopcocks and ground joins. The soft grade is for large stopcocks and ground joints, desiccators, and for lower temperature use. Ramsay grease consists of paraffin wax, vaseline, and crude natural rubber, in ratio 1:3:7 to 1:8:16. Due to the rubber content it has less tendency to flow.\n\nOne recipe for a grease usable up to 25 °C consists of 6 parts of vaseline, 1 part of paraffin wax, and 6 parts of Pará rubber.\n\nThe dropping point of Leybold-brand Ramsay grease is 56 °C; its maximum service temperature is 25-30 °C. Its vapor pressure at 25 °C is 10 torr (0.013 mPa), at 38 °C it is 10 torr (13 mPa).\n\nAn equivalent of Ramsay grease can be made by cooking lanolin with natural rubber extracted from golf balls.\n"}
{"id": "2607588", "url": "https://en.wikipedia.org/wiki?curid=2607588", "title": "Ravenna Cosmography", "text": "Ravenna Cosmography\n\nThe Ravenna Cosmography (,  \"The Cosmography of the Unknown Ravennese\") is a list of place-names covering the world from India to Ireland, compiled by an anonymous cleric in Ravenna around  700. Textual evidence indicates that the author frequently used maps as his source.\n\nThere are three known copies of the Cosmography in existence. The Vatican Library holds a 14th-century copy, there is a 13th-century copy in Paris at the Bibliothèque Nationale, and the library at Basle University has another 14th-century copy. The Vatican copy was used as the source for the first publication of the manuscript in 1688 by Porcheron. The German scholar Joseph Schnetz published the text in 1940, basing it on the Vatican and Paris editions, which he believed to be more reliable than the Basle edition. Parts of the text, notably that covering Britain, have been published by others, including Richmond and Crawford in 1949, but their document showed little regard for which of the manuscripts provided the information. However, it contained photographs of the relevant sections from all three manuscripts, which enabled Keith Fitzpatrick-Matthews to reconstruct the text from scratch in 2013 for his reassessment of its importance for British geography. The work by Schnetz covered the whole document, and was republished in 1990. In addition to the three main manuscripts, the Vatican Library also holds a document containing excerpts from the Cosmography made by Riccobaldus Ferrariensis, and there is a copy of the Paris manuscript held in Leiden.\n\nThe surviving texts are quite challenging. They consist of commentary and lists of names. The Vatican manuscript presents the text in two columns, with placenames being capitalised and terminated by a stop. A small number of the words have been abbreviated. The Paris manuscript also uses two columns, capitalisation and stops, but has many more abbreviations than either of the other two. The text is divided into sections by paragraph marks. The Basle manuscript only has a single column, and is more difficult to read than the others. It has more abbrebiations than the Vatican copy, but fewer than the Paris copy. There is some evidence that the author has tried to correct or clarify words which were not clear in the original, and there are no stops to separate the place names in the lists, but there are underlined headings to divide up the sections. As an indication of the problems of dealing with the text, there are a total of 315 names in the section covering Britain. All three manuscripts agree on the spelling of 200 of these. The Basle and Vatican documents agree on the spelling of a further 50, there are 33 more common to the Basle and Paris documents, and 17 more which appear in the Paris and Vatican documents. There are 8 names for which there is no agreement between the three sources, and 7 names missing from the Paris copy where the other two agree. \n\nIn a paper by Franz Staab, published in 1976, he noted that the original author claimed to have used works by three others, Athanarid, Heldebald and Marcomir, in the compilation of his own work. Stolte, writing in 1956, argued that the cosmography was finished around 732.\n\nThe naming of places in Roman Britain has traditionally relied on Ptolemy’s \"Geography\", the Antonine Itinerary and the Peutinger Table, as the Cosmography was seen as full of corruptions, with the ordering of the lists of placenames being haphazard. However, there are more entries in the Cosmography than in the other documents, and so it has been studied more recently. The antiquary Gale, writing in 1709, was the first to attempt to use it as a source for Romano-British place names, but early attempts relied on the similarity between ancient and modern names, and this method was seen to be suspect by the mid-19th century. Archaeological investigations were uncovering sites that had evidence of occupation in the Roman period, and this correlation became important. The Antonine Itinerary and Richard of Cirencester's \"de Sitû Britanniae\" were increasingly used to corroborate entries, until Richard's work was found to be an 18th century hoax. The Cosmography remained relatively impenetrable until the mid-20th century.\n\nIn 1949, Sir Ian Richmond and O G S Crawford published a paper they had originally submitted to \"Archaeologia\", which suggested that the sources for the document had included maps or road books, and that many place names described geographical features. The book was seen as a significant advance in the study both of the document and of Romano-British placenames. Louis Dillemann's work, which was translated by Professor Colin Smith and published in \"Archaeologia\" in 1979, was the first time that the theories of J Schnetz had been summarised for an English-speaking audience, while A L F Rivet and Colin Smith used their study of the document to publish \" The Place-Names of Roman Britain\" in the same year.\n\nPart of the diffiuclty with the text is its corruption, which probably results from the author failing to understand his sources, or not appreciating the purpose for which they were written. His original sources may have been of poor quality, resulting in many curious-looking names appearing in the lists. Equally, there are some obvious omissions, although the author was not attempting to produce a complete list of places, as his introduction states: \"In that Britain we read that there were many civitates and forts, of which we wish to name a few.\" The suggestion that he was using maps is bolstered by phrases such as \"next to\" which occur frequently, and at one point he states: \"where that same Britain is seen to be narrowest from Ocean to Ocean.\" Richmond and Crawford were the first to argue that rather than being random, the named places are often clustered around a central point, or spread out along a single road. For most of England, the order seems to follow a series of zig-zags, but this arrangement is less obvious for the south-west and for Scotland.\n\n\n\n\n"}
{"id": "11492908", "url": "https://en.wikipedia.org/wiki?curid=11492908", "title": "Renewable energy in Africa", "text": "Renewable energy in Africa\n\nThe developing nations of Africa are popular locations for the application of renewable energy technology. Currently, many nations already have small-scale solar, wind, and geothermal devices in operation providing energy to urban and rural populations. These types of energy production are especially useful in remote locations because of the excessive cost of transporting electricity from large-scale power plants. The applications of renewable energy technology has the potential to alleviate many of the problems that face Africans every day, especially if done in a sustainable manner that prioritizes human rights.\n\nAccess to energy is essential for the reduction of poverty and promotion of economic growth. Communication technologies, education, industrialization, agricultural improvement and expansion of municipal water systems all require abundant, reliable, and cost-effective energy access.\n\nBy investing in the long-term energy solutions that alternative energy sources afford, most African nations would benefit significantly in the longer term by avoiding the pending economic problems developed countries are currently facing.\n\nAlthough in many ways fossil fuels provide a simple, easy to use energy source that powered the industrialization of most modern nations, the issues associated with the widespread use of fossil fuels are now numerous, consisting of some of the world's most difficult and large-scale global political, economic, health and environmental problems. The looming energy crisis results from consuming these fossil fuels at a rate which is unsustainable, with the global demand for fossil fuels expected to increase every year for the next several decades, compounding existing problems.\n\nWhile a great number of projects are currently underway to expand and connect the existing grid networks, too many problems exist to make this a realistic option for the vast majority of people in Africa, especially those who live in rural locations. Distributed generation using renewable energy systems is the only practical solution to meet rural electrification needs. There is a move towards energy decentralisation in African nations, with many looking towards variants of energy decentralisation frameworks, such as District Energy Officers, for example as described in a recommendations paper for District Energy Officers for the country of Malawi.\n\nHydro-electric, wind and solar power all derive their energy from the Sun. The Sun emits more energy in one second (3.827 × 10 J) than is available in all of the fossil fuels present on earth (3.9 × 10 J), and therefore has the potential to provide all of our current and future global energy requirements. Since the solar source for renewable energy is clean and free, African nations can protect their people, their environment, and their future economic development by using renewable energy sources to this end they have a number of possible options.\n\nAfrica is the sunniest continent on Earth, especially as there are many perpetually sunny areas like the huge Sahara Desert. It has much greater solar resources than any other continent. Desert regions stand up as the most sunshiny while rainforests are considerably cloudier but still get a good global solar irradiation because of the proximity with the equator. \n\nThe distribution of solar resources across Africa is fairly uniform, with more than 85% of the continent's landscape receiving at least 2,000 kWh/(m² year). A recent study indicates that a solar generating facility covering just 0.3% of the area comprising North Africa could supply all of the energy required by the European Union. This is the same land area as the state of Maine.\n\nAfrica has a large coastline, where wind power and wave power resources are abundant and underutilized in the north and south. Geothermal power has potential to provide considerable amounts of energy in many eastern African nations.\n\nWind is far less uniformly distributed than solar resources, with optimal locations positioned near special topographical funneling features close to coastal locations, mountain ranges, and other natural channels in the north and south. The availability of wind on the western coast of Africa is substantial, exceeding 3,750 kW·h, and will accommodate the future prospect for energy demands Central Africa has lower than average wind resources to work with.\n\nGeothermal power is mostly concentrated in eastern Africa, but there are many fragmented spots of high intensity geothermal potential spread across the continent. There is enormous potential for geothermal energy in the East African Rift which is roughly 5,900 kilometers in length and spans several countries in East Africa including Eritrea, Ethiopia, Djibouti, Kenya, Uganda, and Zambia.\n\nThe use of biomass fuels endangers biodiversity and risks further damaged or destruction to the landscape. 86% of Africa’s biomass energy is used in the sub-Saharan region, excluding South Africa. Even where other forms of energy are available, it is not harnessed and utilized efficiently, underscoring the need to promote energy efficiency where energy access is available.\n\nThere is, however, an urgent need to address the current levels of respiratory illness from burning biomass in the home. Taking into respect the cost differential between the biomass and fossil fuels, it is far more cost-effective to improve the technology used to burn the biomass than to use fossil fuels.\n\nSolar and wind power are extremely scalable, as there are systems available from less than 1 watt to several megawatts. This makes it possible to initialize the electrification of a home or village with minimal initial capital. It also allows for dynamic and incremental scaling as load demands increases. The component configuration of a wind or solar installation also provides a level of functional redundancy, improving the reliability of the system. If a single panel in a multi-panel solar array is damaged, the rest of the system continues functioning unimpeded. In a similar way, the failure of a single wind tower in a multi-tower configuration does not cause a system-level failure.\n\nBecause solar and wind projects produce power where it is used, they provide a safe, reliable and cost-effective solution. Because transmission equipment is avoided, these systems are more secure, and less vulnerable to attack. This can be an important feature in regions prone to conflict. Wind and solar power systems are simple to set up, easy to operate, easy to repair, and durable. Wind resources and solar resource are abundant enough to provide all of the electrical energy requirements of rural populations, and this can be done in remote and otherwise fragmented low-density areas that are impractical to address using conventional grid-based systems.\n\nPhoto-voltaic panels, wind turbines deep cycle batteries, meters, sockets cables, and connectors are all expensive. Even when the relative difference in buying power, materials cost, opportunity cost, labor cost and overhead is factored in, renewable energy will remain expensive for people who are living on less than US$1 per day. Many rural electrification projects in the past use government subsidies to finance the implementation of rural development programs. It is difficult for rural electrification projects to be accomplished by for-profit companies; in economically impoverished areas these programs must be run at a loss for reasons of practicality. There are several theorized ways in which specific African nations can rally the resources for such projects.\n\nEuropean countries that consume oil refined from African countries have the opportunity to subsidize the costs of individual level, village level, or community level alternative energy systems through emissions trading credits. It has been proposed that for every unit of African origin carbon consumed by the European market, a predetermined amount green credits or carbon credits would be yielded. The European partners could then either supply parts, components, or systems directly, an equivalent amount of investment capital, or lend credits to finance the distribution of renewable energy services, knowledge or equipment.\n\nInternational relief targeted at poverty reduction could also be redirected towards subsidizing renewable energy projects. Because of the integral role that electrification plays in supporting economic and social development, funding of rural electrification can be seen as the core method for addressing poverty. Radios, televisions, telephones, computer networks, and computers all rely on an access to electricity. Because information services allow for the proliferation of education resources, funding the electric backbone to such systems has a derivative effect on their development. In this way, access to communications and education plays a major role in reducing poverty. Additionally, international efforts that supply equipment and services rather than money, are more resistant to resource misappropriation issue that pose problems in less stable governments.\n\nUNEP has developed a loan programme to stimulate renewable energy market forces with attractive return rates, buffer initial deployment costs and entice consumers to consider and purchase renewable technology. After a successful solar loan program sponsored by UNEP that helped 100,000 people finance solar power systems in developing countries like India, UNEP started similar schemes in other parts of the developing world like Africa - Tunisia, Morocco, and Kenya projects are already functional and many projects in other African nations are in the pipeline. In Africa, UNEP assistance to Ghana, Kenya, and Namibia has resulted in the adoption of draft National Climate Awareness Plans, publications in local languages, radio programmes and seminars. The Rural Energy Enterprise Development (REED) initiative is another flagship UNEP effort focused on enterprise development and seed financing for clean energy entrepreneurs in developing countries of West and Southern Africa.\n\nThe Government of South Africa has set up the South African Renewables Initiative (SARi) to develop a financing arrangement that would enable a critical mass of renewables to be developed in South Africa, through a combination of international loans and grants, as well as domestic funding. This has been a highly successful programme now known as the REIPPP (Renewable Energy Independent Power Producer Programme) with four rounds of allocations already completed. In Round 1, 19 projects were allocated, in Round 2, 28 projects were allocated, in Round 3, 17 projects were allocated and in Round 4, 26 projects were allocated. Over 6100MW has been allocated with a total of R194 billion (US$16 billion) being invested in this programme. It is important to note that this investment figure represents full funding from private entities and banks - there are no government subsidies for this programme.\n\nThe funding of renewable energy (RE) projects is dependent on the credibility of the institutions developing and implementing RE policy. This places a particular burden on the energy regulators in Africa, whose professional staff may be few in number and who have track records of only a decade or so. Rules (micro policies) made by regulators are subsidiary to overall government RE policy and depend on some delegation of authority from the state. Nevertheless, there are instances when the sector regulator can pro-active on behalf of customer and utility concerns—providing facts, reports, and public statements that build a case for care in the design of public policy towards RE. Clean and renewable energy is likely to be of concern to a number of organizations. Interaction between multiple authorities requires coordination to align policies, incentives, and administrative processes (including licensing and permitting). Of course, the making of policy by regulators is incidental to and inherent in their duty to decide specific cases or disputes. This micro policy-making role is derived from the fact that macro RE policy cannot reasonably be expected to anticipate all aspects of policy that will have to evolve for the regulatory process to be fully functional. This point is particularly important in the area of renewable energy, with its rapidly changing technologies and ever-changing public (and political) attitudes. Gaps will have to be filled and it is the regulators, with their functional responsibilities, technical expertise, and hands-on experience that are best positioned to accomplish that task in developing countries. Thus, for designing auctions for purchasing power, for establishing feed-in tariffs, or other instruments promoting RE, the energy sector regulator has a significant impact on the penetration of RE in Africa and other regions.\n\nSeveral large-scale solar power facilities are under development in Africa including projects in South Africa and Algeria. Although solar power technology has the potential to supply energy to large numbers of people, and has been used to generate power on a large scale in developed nations, its greatest potential in Africa may be to provide power on a smaller scale and to use this energy to help with day-to-day needs such as small-scale electrification, desalination, water pumping, and water purification.\n\nThe first utility-scale solar farm in Sub-Saharan Africa is the 8.5MW plant at Agahozo-Shalom Youth Village, in the Rwamagana District, Eastern Province of Rwanda. It leased of land from the village which is a charity to house and educate Rwandan genocide victims. The plant uses 28,360 photovoltaic panels and produces 6% of total electrical supply of the country. The project was built with U.S., Israeli, Dutch, Norwegian, Finnish and UK funding and expertise.\n\nThere are several examples of small grid-linked solar power stations in Africa, including the photovoltaic 250 kW Kigali Solaire station in Rwanda. Under the South Africa Renewable Energy Independent Power Producer Procurement Program, several projects have been developed, including the 96MW(DC) Jasper Solar Energy Project, the 75MW(DC) Lesedi PV project, and the 75MW(DC) Letsatsi PV Project, all developed by the American company SolarReserve and completed in 2014. \n\nPower Up Gambia, a non-profit operating in The Gambia, uses solar power technology to provide power to Gambian health care facilities, providing a reliable source of electricity for lighting, diagnostic testing, treatments, and water pumping. Energy For Opportunity (EFO), a non-profit working in West Africa, uses solar power for Schools, Health Clinics and Community Charging Stations, as well as teaches Photovoltaic installation classes at local technical institutes. So far its work has been mainly in Sierra Leone. In particular its solar powered Community Charging Stations have been recognized as an innovative model to provide electricity to rural communities in the region.\n\nSome plans exist to build solar farms in the deserts of North Africa to supply power for Europe. The Desertec project, backed by several European energy companies and banks, planned to generate renewable electricity in the Sahara desert and distribute it through a high-voltage grid for export to Europe and local consumption in North-Africa. Ambitions seek to provide continental Europe with up to 15% of its electricity. The TuNur project would supply 2GW of solar generated electricity from Tunisia to the UK.\n\nOne of the most immediate and lethal problems facing many third world countries is the availability of clean drinking water. Solar powered technologies can help alleviate this problem with minimal cost using a combination of solar powered well pumping, a water tower or other holding tank, and a solar powered water purifier. These technologies require minimal maintenance, have low operational costs, and once set up, will help provide clean water for drinking and agriculture. With large enough reservoirs for the water that has been pumped and purified with solar powered technology, a community will be better able to withstand drought or famine. This reservoir water could be consumed by humans, livestock, or used to irrigate community gardens and fields, thus improving crop yields and community health. A solar powered water purification system can be used to clean many pathogens and germs from groundwater and runoff. A group of these devices, filtering the water from wells or runoff could help with poor sanitation and controlling the spread of waterborne illnesses.\n\nKenya may be a good candidate for testing out these systems because of its progressive and relatively well-funded department of agriculture, including the Kenya Agricultural Research Center, which provides funding and oversight to many projects investigating experimental methods and technologies.\n\nEven though this solar technology may have a higher starting cost than that of conventional fossil fuel, the low maintenance and operation cost and the ability to operate without fuel makes the solar powered systems cheaper to keep running. A small rural community could use a system like this indefinitely, and it would provide clean drinking water at a negligible cost after the initial equipment purchase and setup. In a larger community, it could at least contribute to the water supply and reduce pressures of daily survival. This technology is capable of pumping hundreds of gallons of water per day, and is limited only by the amount of water available in the water table.\n\nWith a minimum of training in operation and maintenance, solar powered water pumping and purification systems have the potential to help rural Africans fulfill one of their most basic needs for survival. Further field test are in progress by organizations like KARI and the many corporations that manufacture the products needed, and these small-scale applications of solar technology are promising. Combined with sustainable agricultural practices and conservation of natural resources, solar power is a prime candidate to bring the benefits of technology to the parched lands of Africa.\n\nSupplementing the well water would be collection of runoff rainwater during the rainy season for later use in drought. Southern Africa has its own network of information sharing called SEARNET, which informs farmers of techniques to catch and store rainwater, with some seeing increased yields and additional harvests. This new network of farmers sharing their ideas with each other has led to a spread of both new and old ideas, and this has led to greater sustainability of water resources in the countries of Botswana, Ethiopia, Kenya, Malawi, Rwanda, Tanzania, Uganda, Zambia and Zimbabwe. This water could be used for agriculture or livestock, or could be fed through a purifier to yield water suitable for human consumption.\n\nA solar powered water pump and holding system was installed in Kayrati, Chad, in 2004 as compensation for land lost to oil development. This system utilizes a standard well pump powered by a photovoltaic panel array. The pumped water is stored in a water tower, providing the pressure needed to deliver water to homes in the area. This use of oil revenue to build infrastructure is an example of using profits to advance the standard of living in rural areas.\n\nHundreds of solar water pumping stations in Sudan fulfil a similar role, involving various applications of different systems for pumping and storage. Over the past 10 years approximately. 250 photovoltaic water pumps have been installed in Sudan. Considerable progress has been made and the present generation of systems appear to be reliable and cost–effective under certain conditions. A photovoltaic pumping system to pump 25 cubic metres per day requires a solar array of approx. 800 Wp. Such a pump would cost US$6000, since the total system comprises the cost of modules, pump, motor, pipework, wiring, control system and array support structure. PV water pumping has been promoted successfully in Kordofan state in Sudan. It shows favorable economics as compared to diesel pumps, and is free from the need to maintain a regular supply of fuel. The only maintenance problems with PV pumping [are] due to the breakdown of pumps and not the failure of the PV devices.\n\nThe Solar Water Purifier, developed and manufactured by an Australian company, is a low-maintenance, low operational cost solution that is able to purify large amounts of water, even seawater, to levels better than human consumption standards set by the World Health Organization. This device works through the processes of evaporation and UV radiation. Light passes through the top layer of glass to the black plastic layer underneath. Heat from the solar radiation is trapped by the water and by the black plastic. This plastic layer is a series of connected troughs that separate the water as it evaporates and trickles down through the levels. The water is also subjected to UV radiation for an extended period of time as it moves through the device, which kills many bacteria, viruses, and other pathogens. In a sunny, equatorial area like much of Africa, this device is capable of purifying up to 45 litres per day from a single array. Additional arrays may be chained together for more capacity.\n\nThe Water School uses SODIS solar disinfection currently in target areas of Kenya and Uganda to help people drink water free of pathogens and disease causing bacteria. SODIS is a UV process that kills microorganisms in the water to prevent water borne disease. The science of the SODIS system is proven with over 20 years of research.\n\nThe Koudia Al Baida Farm in Morocco, is the largest wind farm in the continent. Two other large wind farms are under construction in Tangier and Tarfaya. \n\nKenya is building a wind farm, the Lake Turkana Wind Power (LTWP), in Marsabit County. As Africa’s largest wind farm, the project will increase the national electricity supply while creating jobs and reducing greenhouse gas emissions. LTWP is planned to produce 310 MW of wind power at full capacity.\n\nIn January 2009, the first wind turbine in West Africa was erected in Batokunku, a village in The Gambia. The 150 kilowatt turbine provides electrical power for the 2,000-person village.\n\nThe South African REIPPP has resulted in several wind farms already in commercial operation in the country. These wind farms are currently in operation in the provinces of the Eastern, Northern and Western Cape. It is estimated that 10 farms are already under construction or in operation, with 12 more being approved with the 4th Round of the REIPPP.\n\nSo far, only Kenya has exploited the geothermal potential of the Great Rift Valley. Kenya has been estimated to contain 10,000 MWe of potential geothermal energy, and has twenty potential drilling sites marked for survey in addition to three operational geothermal plants. Kenya was the first country in Africa to adopt geothermal energy, in 1956, and houses the largest geothermal power plant on the continent, Olkaria II, operated by Kengen, who also operate Olkaria I. A further plant, Olkaria III, is privately owned and operated.\n\nEthiopia is home to a single binary-cycle plant but does not utilize its full potential energy output for lack of experience in its operation. Zambia has several sites planned for construction but their projects have stalled due to lack of funds. Eritrea, Djibouti and Uganda have undertaken preliminary exploration for potential geothermal sources but have not constructed any type of power plant.\n\nGeothermal power has been used in agricultural projects in Africa. The Oserian flower farm in Kenya utilizes several steam wells abandoned by Kengen to power its greenhouse. In addition, the heat involved in the geothermal process is used to maintain stable greenhouse temperatures. The heat can also be utilized in cooking, which would help eliminate the dependence on wood burning.\n\nExploration and construction of future geothermal plants present a high cost for poor countries. Drilling potential sites alone costs millions of dollars and can result in zero energy return if the consistency of the heat and steam is unreliable. Return on investments into geothermal power are not as quick as those into fossil fuels and may take years to pay off; however, low-maintenance cost and the renewable nature of geothermal energy mean more benefits in the long term.\n\nAs an early and successful adopter of geothermal power, Kenya now has significant financial backing from the World Bank. The country hosts development conferences between representatives of the UN Environment Program and various African governments.\n\n\n"}
{"id": "23017591", "url": "https://en.wikipedia.org/wiki?curid=23017591", "title": "Resonance (particle physics)", "text": "Resonance (particle physics)\n\nIn particle physics, a resonance is the peak located around a certain energy found in differential cross sections of scattering experiments. These peaks are associated with subatomic particles, which include a variety of bosons, quarks and hadrons (such as nucleons, delta baryons or upsilon mesons) and their excitations. In common usage, \"resonance\" only describes particles with very short lifetimes, mostly high-energy hadrons existing for or less.\n\nThe width of the resonance (\"Γ\") is related to the mean lifetime (\"τ\") of the particle (or its excited state) by the relation\n\nwhere \"h\" is the Planck constant and formula_2.\n\nThus, the lifetime of a particle is the direct inverse of the particle's resonance width. For example, the charged pion has the second-longest lifetime of any meson, at . Therefore, its resonance width is very small, about or about 6.11 MHz. Pions are generally not considered as \"resonances\". The charged rho meson has a very short lifetime, about . Correspondingly, its resonance width is very large, at 149.1 MeV or about 36 ZHz. This amounts to nearly one-fifth of the particle's rest mass.\n\n"}
{"id": "529589", "url": "https://en.wikipedia.org/wiki?curid=529589", "title": "Revillagigedo Islands", "text": "Revillagigedo Islands\n\nThe Revillagigedo Islands (, ) or Revillagigedo Archipelago are a group of four volcanic islands in the Pacific Ocean, known for their unique ecosystem. They lie approximately southwest of Cabo San Lucas, the southern tip of the Baja California Peninsula, and west of Manzanillo. They are located around . Technically part of the Mexican state of Colima, the islands are under Mexican federal jurisdiction.\n\nIn July 2016, the Revillagigedo Archipelago were inscribed as a UNESCO World Heritage Site, and in November 2017 they were declared to be a marine reserve and a national park of Mexico.\n\nThe total area is 157.81 km (60.93 mi), spread over an east-to-west extent of about 420 km (261 mi). A naval station in the south of Socorro Island has a population of 45 (staff). On Clarión is a small naval garrison with 9 men. The islands are otherwise uninhabited. The islands are named after Don Juan Vicente de Güemes, 2nd Count of Revillagigedo, the 53rd viceroy of New Spain.\nThe three eastern islands are called the inner islands. They fall in the time zone UTC-7 (Mountain Time), while the major part of Colima is UTC-6 (Central Time Zone). Clarión is comparatively far to the west, by more than 200 km in comparison with the inner islands, and in UTC-8 (Pacific Time Zone). The Revillagigedo Islands are one of three Mexican island groups in the Pacific Ocean that are not on the continental shelf; the others are Guadalupe Island and Rocas Alijos.\n\nNo evidence of human habitation on Socorro exists before its discovery by Spanish explorers. Hernando de Grijalva and his crew discovered an uninhabited island on 19 December 1533, and named it \"Santo Tomás\" (Socorro Island) and on 28 December they discovered \"Isla de los Inocentes\" (San Benedicto) which owed its name to having been found on the day of the Holy Innocents.\n\nIn November 1542, Ruy López de Villalobos, while exploring new routes across the Pacific, rediscovered \"Inocentes\" and \"Santo Tomás\" and charted the latter as \"Anublada\" (\"Cloudy\"). Villalobos was the first to report sighting of Roca Partida Island giving it its present-day name. In 1608, Martín Yánez de Armida, in charge of another expedition, visited \"Anublada\" and changed its name to Socorro. In 1779 José Camacho was the first to report sighting of the island remaining, that he charted as \"Santa Rosa\" (\"Saint Rose\"). \"Santa Rosa\" was later renamed \"Clarion\" after the vessel commanded by Henry Gyzelaar at that time.\n\nThe Revillagigedo Islands have been visited by a number of other explorers: Domingo del Castillo (1541), Miguel Pinto (1772), Alexander von Humboldt (1811), Benjamin Morrell (1825), Sir Edward Belcher (1839) who made the first botanical collections and Reeve, who witnessed the eruption of Mount Evermann in 1848. On 25 July 1861, President Benito Juárez signed a decree awarding territorial control over the four islands to the state of Colima. His plan was to build an offshore penitentiary on Isla Socorro; although this never happened, the decree whereby they were attached to Colima has never been repealed. In 1865, the island was explored by ornithologist Andrew Jackson Grayson, who discovered the Socorro dove, Socorro mockingbird and the Socorro elf owl which were later given scientific names in his honor.\n\nAt the beginning of the twentieth century, Dr. Barton Warren Evermann, director of the California Academy of Sciences in San Francisco, California, promoted the scientific exploration of the islands. The most comprehensive biological collections were obtained at this time. The volcano on Isla Socorro was renamed in his honor. In 1957 the Mexican Navy established a naval base on Socorro and has had a permanent presence on the island since then. A tiny outpost also exists on Clarión, as noted above. On 21 March 1972, Pablo Silva García became the first Governor of Colima to visit his state's island territories. A plaque was unveiled to mark the event and cement Colima's claim.\n\nThe seas surrounding the larger islands are popular with scuba divers; a variety of marine life such as cetaceans, sharks and manta rays can be observed. Visitors usually stay aboard expedition vessels during their visit to the islands, which is desirable from an ecological standpoint to prevent introduction of further invasive species.\n\nThe islands are occasionally visited by amateur radio operators, who usually use the ITU prefix XF4. Because of their distance from the mainland, for award credit they are considered to be an \"entity\" separate from Mexico. Expeditions from organizations engaged in biological conservation of the islands visit the islands for fieldwork on a regular basis. No tourism facilities exist; the islands have no reliable sources of fresh water of their own.\n\nOn 24 November 2017, President of Mexico Enrique Peña Nieto created North America's largest marine protected area around the Revillagigedo Islands. This protected area covers 57,000 square miles or 150,000 square kilometers around the islands, and bans fishing, mining, and tourism development in the protected area and on the islands.\n\nThe Revillagigedo Islands are home to many endemic plant and animal species, and are sometimes called Mexico's \"little Galápagos\". They are recognized as a distinct terrestrial ecoregion, part of the Neotropic ecozone. Socorro is the most diverse in flora, fauna, and topography. The Mexican Government established the islands as a Biosphere Reserve on June 4, 1994.\nAccording to the World Wide Fund for Nature (WWF), 14 of the islands' 16 generally accepted resident taxa of landbirds as well as one seabird are endemic, as are all of the islands' native terrestrial vertebrates. The latter, however, consist only of a whip snake (\"Masticophis anthonyi\"), a night snake (\"Hypsiglena unaocularis\") and two \"Urosaurus\" iguanids (\"U. auriculatus\" and \"U. clarionensis\"). Numerous seabird taxa breed no further north(east)wards than San Benedicto; storm-petrels are notably absent as breeders though they breed in the region and visit the islands to forage. Albatrosses are also not normally found here. Among landbirds, the absence of the house finch, widespread on northeastern Pacific offshore islands, is the most conspicuous one.\n\nApart from the native birds, migrant shorebirds and others are often found on the islands. \"Bahia Azufre\" (Sulfur Bay) on Clarión seems to be a favorite stopover location, as it is one of the few longer stretches of beach in the islands; mostly, the shoreline is steep cliffs. The archipelago is also a part of wintering grounds for humpback whales in north pacific.\n\nSocorro has numerous endemic plant taxa, whereas Clarión which is farthest from land has but a few. The San Benedicto ecosystem was nearly wiped out in the devastating eruption of Bárcena volcano on August 1, 1952, but has since recovered; apparently just the San Benedicto rock wren became entirely extinct. Most if not all native plants found on San Benedicto today are shared with Clarión, not with the closer Socorro to the south, due to the prevailing winds and ocean currents. The native flora of Clarión is about equally shared with both other large islands.\n\nAs opposed to the interchange between the islands, the animals and plants that colonized them initially are apparently all from mainland populations generally to the northeastward of the Revillagigedos. Plants are most often derived from Baja California founder populations, whereas the endemic nonavian reptiles seem to be rather derived directly from mainland populations of the Sonora-Sinaloa area. The ancestors of the islands' terrestrial birds probably came from the general area of southern North and northern Central America. As illustrated by the fact that no endemic landbird taxon occurs on more than one island and the cases of the Socorro and Clarión wrens as well as the Socorro dove and Clarión mourning dove, each bird population seems to have arisen independently.\n\nAs late as 1956 it was said that\n\"The future of the avifauna of the islands appears to be secure at present. There are no human inhabitants, and no mammals of any kind except the moderate and apparently stable population of sheep on Socorro.\"\nThe unique ecology of the islands has since then come under threat from these and other exotic species. Sheep were introduced to Socorro in 1869, and cats have become established after 1953, probably in the early 1970s. Pigs were introduced to Clarión in 1979, and rabbits became feral at some earlier date.\n\nSeveral endemic species of Socorro are now threatened with extinction. The Socorro mockingbird (\"Mimodes graysoni\") numbers less than 400 individuals altogether. The endemic Socorro parakeet (\"Aratinga brevipes\") and Townsend's shearwater (\"Puffinus auricularis\"), are also endangered. The Socorro dove (\"Zenaida graysoni\") is now extinct in the wild, but is being bred in captivity. The elf owl's Socorro subspecies \"Micrathene whitneyi graysoni\" appears to be extinct. Other plant and animal taxa in the archipelago are also considered threatened or nearly so.\n\nA number of conservation initiatives are dedicated to halting the destruction of the native ecosystems of the islands. Dr. Harmunt Walter of the University of California, Los Angeles (UCLA) and Dr. Luis F. Baptista of the California Academy of Sciences have coordinated breeding and reintroduction efforts for the Socorro dove since 1988, through the Island Endemics Institute. The \"Comité Científico para la Conservación y Restauración del Archipiélago Revillagigedo\" (\"Scientific Committee for the Conservation and Restoration of the Revillagigedo Islands\") was founded in 1996, and is a committee representing several organizations, including the Island Conservation & Ecology Group, Island Endemics Institute, the University of Missouri–St. Louis (UMSL), the National Autonomous University of Mexico (UNAM) and others. It is chaired by Dr. Walter and Dr. Luis Medrano of UNAM is its secretary. The committee has been advocating removal of the exotic species from the islands, especially the estimated 2000 sheep on Socorro, to allow the islands' ecology to recover, and adoption of a management plan to promote the recovery of the islands' native species, including reintroduction of the Socorro dove.\n\nBrattstrom and Howell who gave the optimistic outlook in 1956 went on to caution that\n\"it may be hoped that the Mexican government will guard against the introduction of mammals such as rabbits, cats, goats and others that have invariably brought disaster to the flora and fauna of insular regions.\"\nOn 25 November 2017, President of Mexico Enrique Peña Nieto acted to protect the biodiversity of the region by creating North America's largest marine protected area around the islands, and prohibiting mining, fishing, and tourism development on or near the islands.\n\n"}
{"id": "27752", "url": "https://en.wikipedia.org/wiki?curid=27752", "title": "Spectroscopy", "text": "Spectroscopy\n\nSpectroscopy is the study of the interaction between matter and electromagnetic radiation. Historically, spectroscopy originated through the study of visible light dispersed according to its wavelength, by a prism. Later the concept was expanded greatly to include any interaction with radiative energy as a function of its wavelength or frequency. Spectroscopic data are often represented by an emission spectrum, a plot of the response of interest as a function of wavelength or frequency.\n\nSpectroscopy and spectrography are terms used to refer to the measurement of radiation intensity as a function of wavelength and are often used to describe experimental spectroscopic methods. Spectral measurement devices are referred to as spectrometers, spectrophotometers, spectrographs or spectral analyzers.\n\nDaily observations of color can be related to spectroscopy. Neon lighting is a direct application of atomic spectroscopy. Neon and other noble gases have characteristic emission frequencies (colors). Neon lamps use collision of electrons with the gas to excite these emissions. Inks, dyes and paints include chemical compounds selected for their spectral characteristics in order to generate specific colors and hues. A commonly encountered molecular spectrum is that of nitrogen dioxide. Gaseous nitrogen dioxide has a characteristic red absorption feature, and this gives air polluted with nitrogen dioxide a reddish-brown color. Rayleigh scattering is a spectroscopic scattering phenomenon that accounts for the color of the sky.\n\nSpectroscopic studies were central to the development of quantum mechanics and included Max Planck's explanation of blackbody radiation, Albert Einstein's explanation of the photoelectric effect and Niels Bohr's explanation of atomic structure and spectra. Spectroscopy is used in physical and analytical chemistry because atoms and molecules have unique spectra. As a result, these spectra can be used to detect, identify and quantify information about the atoms and molecules. Spectroscopy is also used in astronomy and remote sensing on Earth. Most research telescopes have spectrographs. The measured spectra are used to determine the chemical composition and physical properties of astronomical objects (such as their temperature and velocity).\n\nOne of the central concepts in spectroscopy is a resonance and its corresponding resonant frequency. Resonances were first characterized in mechanical systems such as pendulums. Mechanical systems that vibrate or oscillate will experience large amplitude oscillations when they are driven at their resonant frequency. A plot of amplitude vs. excitation frequency will have a peak centered at the resonance frequency. This plot is one type of spectrum, with the peak often referred to as a spectral line, and most spectral lines have a similar appearance.\n\nIn quantum mechanical systems, the analogous resonance is a coupling of two quantum mechanical stationary states of one system, such as an atom, via an oscillatory source of energy such as a photon. The coupling of the two states is strongest when the energy of the source matches the energy difference between the two states. The energy formula_1 of a photon is related to its frequency formula_2 by formula_3 where formula_4 is Planck's constant, and so a spectrum of the system response vs. photon frequency will peak at the resonant frequency or energy. Particles such as electrons and neutrons have a comparable relationship, the de Broglie relations, between their kinetic energy and their wavelength and frequency and therefore can also excite resonant interactions.\n\nSpectra of atoms and molecules often consist of a series of spectral lines, each one representing a resonance between two different quantum states. The explanation of these series, and the spectral patterns associated with them, were one of the experimental enigmas that drove the development and acceptance of quantum mechanics. The hydrogen spectral series in particular was first successfully explained by the Rutherford-Bohr quantum model of the hydrogen atom. In some cases spectral lines are well separated and distinguishable, but spectral lines can also overlap and appear to be a single transition if the density of energy states is high enough. Named series of lines include the principal, sharp, diffuse and fundamental series.\n\nSpectroscopy is a sufficiently broad field that many sub-disciplines exist, each with numerous implementations of specific spectroscopic techniques. The various implementations and techniques can be classified in several ways.\n\nThe types of spectroscopy are distinguished by the type of radiative energy involved in the interaction. In many applications, the spectrum is determined by measuring changes in the intensity or frequency of this energy. The types of radiative energy studied include:\n\nThe types of spectroscopy also can be distinguished by the nature of the interaction between the energy and the material. These interactions include:\n\nSpectroscopic studies are designed so that the radiant energy interacts with specific types of matter.\n\nAtomic spectroscopy was the first application of spectroscopy developed. Atomic absorption spectroscopy and atomic emission spectroscopy involve visible and ultraviolet light. These absorptions and emissions, often referred to as atomic spectral lines, are due to electronic transitions of outer shell electrons as they rise and fall from one electron orbit to another. Atoms also have distinct x-ray spectra that are attributable to the excitation of inner shell electrons to excited states.\n\nAtoms of different elements have distinct spectra and therefore atomic spectroscopy allows for the identification and quantitation of a sample's elemental composition. Robert Bunsen and Gustav Kirchhoff discovered new elements by observing their emission spectra. Atomic absorption lines are observed in the solar spectrum and referred to as Fraunhofer lines after their discoverer. A comprehensive explanation of the hydrogen spectrum was an early success of quantum mechanics and explained the Lamb shift observed in the hydrogen spectrum, which further led to the development of quantum electrodynamics.\n\nModern implementations of atomic spectroscopy for studying visible and ultraviolet transitions include flame emission spectroscopy, inductively coupled plasma atomic emission spectroscopy, glow discharge spectroscopy, microwave induced plasma spectroscopy, and spark or arc emission spectroscopy. Techniques for studying x-ray spectra include X-ray spectroscopy and X-ray fluorescence.\n\nThe combination of atoms into molecules leads to the creation of unique types of energetic states and therefore unique spectra of the transitions between these states. Molecular spectra can be obtained due to electron spin states (electron paramagnetic resonance), molecular rotations, molecular vibration, and electronic states. Rotations are collective motions of the atomic nuclei and typically lead to spectra in the microwave and millimeter-wave spectral regions. Rotational spectroscopy and microwave spectroscopy are synonymous. Vibrations are relative motions of the atomic nuclei and are studied by both infrared and Raman spectroscopy. Electronic excitations are studied using visible and ultraviolet spectroscopy as well as fluorescence spectroscopy.\n\nStudies in molecular spectroscopy led to the development of the first maser and contributed to the subsequent development of the laser.\n\nThe combination of atoms or molecules into crystals or other extended forms leads to the creation of additional energetic states. These states are numerous and therefore have a high density of states. This high density often makes the spectra weaker and less distinct, i.e., broader. For instance, blackbody radiation is due to the thermal motions of atoms and molecules within a material. Acoustic and mechanical responses are due to collective motions as well.\nPure crystals, though, can have distinct spectral transitions, and the crystal arrangement also has an effect on the observed molecular spectra. The regular lattice structure of crystals also scatters x-rays, electrons or neutrons allowing for crystallographic studies.\n\nNuclei also have distinct energy states that are widely separated and lead to gamma ray spectra. Distinct nuclear spin states can have their energy separated by a magnetic field, and this allows for nuclear magnetic resonance spectroscopy.\n\nOther types of spectroscopy are distinguished by specific applications or implementations:\n\n\nThe history of spectroscopy began with Isaac Newton's optics experiments (1666–1672). Newton applied the word \"spectrum\" to describe the rainbow of colors that combine to form white light and that are revealed when the white light is passed through a prism. During the early 1800s, Joseph von Fraunhofer made experimental advances with dispersive spectrometers that enabled spectroscopy to become a more precise and quantitative scientific technique. Since then, spectroscopy has played and continues to play a significant role in chemistry, physics, and astronomy.\n\n\n\n\n"}
{"id": "1124901", "url": "https://en.wikipedia.org/wiki?curid=1124901", "title": "Tianxia", "text": "Tianxia\n\nTianxia () or All under Heaven is a Chinese term for an ancient Chinese cultural concept that denoted either the entire geographical world or the metaphysical realm of mortals, and later became associated with political sovereignty. In ancient China, \"tianxia\" denoted the lands, space, and area divinely appointed to the Emperor by universal and well-defined principles of order. The center of this land was directly apportioned to the Imperial court, forming the center of a world view that centered on the Imperial court and went concentrically outward to major and minor officials and then the common citizens, tributary states, and finally ending with the fringe \"barbarians\". \n\nThe center of this world view was not exclusionary in nature, and outer groups, such as ethnic minorities and foreign people, who accepted the mandate of the Chinese Emperor were themselves received and included into the Chinese \"tianxia\". However, as the concept of the Mandate of Heaven in this context was a narrative device facilitating transitions between various ethnic Chinese political dynasties (with notable exceptions) this essentially made such people second-class citizens subservient to an ethno-Chinese polity. In classical Chinese political thought, the \"Son of Heaven\" (Emperor of China) (), having received the Mandate of Heaven (), would nominally be the ruler of the entire world. Although in practice there would be areas of the known world which were not under the control of the Emperor, in Chinese political theory the rulers of those areas derived their power from the Emperor.\n\nThe larger concept of \"tianxia\" is closely associated with civilization and order in classical Chinese philosophy, and has formed the basis for the world view of the Chinese people and nations influenced by them since at least the first millennium BC. \"Tianxia\" has been independently applied by other countries in the East Asian cultural sphere, including Japan, Korea, and Vietnam.\n\nThe \"tianxia\" world view was not fully developed during the Shang dynasty. Only during the Zhou dynasty when Heaven took on human deity traits (or at least when references to Heaven as such enter recorded history) did the concept of \"tianxia\" become common. Terms like \"Four Quarters\" and \"Ten Thousand States\" appear in texts of the time; the term \"Four Quarters\" () means territory established by the royal court and governed by the Zhou kings from the capital, but with peripheral non-Han tribes on the outer borders and Han Chinese in the center. The term \"Ten Thousand States\" () refers to both territory and the subjects who reside therein, both Han and \"barbarian\". The Zhou kings received and empowered these \"Ten Thousand States\" by virtue of the Mandate of Heaven. This is some of the earliest evidence of the Hua-Yi distinction.\n\nDuring the Spring and Autumn and Warring States periods in the latter half of the Zhou dynasty, the power of the feudal lords developed rapidly, and several non-Han regions became powerful states themselves. As many of these feudal states had shared cultural and economic interests, the concept of a great nation centered on the Yellow River Plain gradually expanded. The term \"tianxia\" began to appear in classical texts such as the \"Zuo Zhuan\" and \"Guoyu\".\n\nThe territory and governments of the Zhou dynasty and the Qin dynasty were unified after the conquests of Qin Shi Huang, and the concept of \"tianxia\" was adapted to act as an actual geographic entity. Qin Shi Huang's goal to \"unify all under Heaven\" was, in fact, representative of his desire to control and expand Chinese territory. At the founding of the Han dynasty, the equivalence of \"tianxia\" with the Chinese nation evolved due to the feudal practice of conferring land and autonomy upon the aristocracy to avoid having to expend military expense in their subjugation. Although many areas enjoyed great autonomy, the practice established and spread Chinese language and culture throughout an even wider territory.\n\nUnification theme applied to \"tianxia\" can be seen in Sun Tzu's \"The Art of War\" where the supreme goal of offensive strategy was to conquer without destroying that which you sought to conquer:\n\nUnified China fractured into many different nations during the Southern and Northern Dynasties, and with it went the practical use of the term \"tianxia\". When Emperor Gaozu reunited China under the Tang dynasty in the 7th century, some northern tribes, after being made vassal, referred to him as the \"Khan of Heaven\".\n\nBy the time of the Song dynasty, China's northern borders were met by the Khitan-led Liao dynasty, the Jurchen-led Jin dynasty, and the Tangut-led Western Xia kingdom. After being threatened by these northern states and realizing the possible effects of a war to the country and people, the Song rulers invented a false concept of kinship with the Jurchens in an attempt to improve relations. The Mongols divided Chinese citizens into two types during the Yuan dynasty: those of the south, and those of the north. When the Ming dynasty expelled the Mongols and reunited China under Han rule, the concept of \"tianxia\" returned largely as it was during the Han dynasty.\n\nAt the end of the Ming dynasty, criticisms of Neo-Confucianism and its mantras of \"cultivation of moral character, establishment of family, ordering the state, and harmonizing \"tianxia\"\" (a quote from the Great Learning) became widespread, producing large shifts in Confucianism. Contemporary philosopher Wang Fuzhi believed that tianxia was of a fixed, unchangeable dimension, notwithstanding the fact that the Great Learning's mentioning of \"harmonizing \"tianxia\"\" was actually in reference to government. Using these arguments, Wang was highly critical of Neo-Confucianism. On the other hand, the collapse of the Ming dynasty and the establishment of the Qing dynasty by the Manchus, people previously considered \"fringe barbarians\", heavily influenced people's views of \"tianxia\". Gu Yanwu, a contemporary of Wang Fuzhi, wrote that the destruction of the State was not equivalent to the destruction of \"tianxia\". He argued that the Manchus simply filled the role of Emperor, and that the \"tianxia\" of traditional Chinese culture was thus carried on.\n\nThe idea of the absolute authority of the Chinese emperor and the extension of \"tianxia\" by the assimilation of vassal states began to fade for good with Earl Macartney's embassy to China in 1793. Earl Macartney hoped to deal with China as equal sovereign nations, as Great Britain would with other European nations of the time, and to persuade the Emperor to sign a trade agreement. The Qianlong Emperor rejected his request, and stated that China was the foremost and most divine nation on Earth and had no interest in foreign goods, and rejected the idea that Great Britain could negotiate with China as an equal nation. In the early 19th century, Britain's victory over Qing China in the First Opium War forced China to sign an unequal treaty. This marked the beginning of the end for the \"tianxia\" concept.\n\nFollowing their defeat in the Second Opium War, China was forced to sign the Treaty of Tianjin, in which China was made to refer to Great Britain as a \"sovereign nation\", equal to itself. This made it impossible for China to continue dealing with other nations under the traditional \"tianxia\" system, and forced it to establish a foreign affairs bureau.\n\nBecause Western nations' system of international affairs was based on the idea that the sovereign nations dealt with each other as equals, China's traditional \"tianxia\" world view slowly collapsed. After China's defeat in the First Sino-Japanese War, the Japanese terminated Korea's traditional status as a protectorate of China, and the system of feudal enfeoffment and vassalage that had been practiced since the Han dynasty came to an end, a move that greatly changed attitudes toward the \"tianxia\" concept. At the end of the 19th century, Chinese Ambassador to Great Britain Xue Fucheng took the traditional Hua-Yi distinction in the \"tianxia\" world view and replaced it with a Chinese-foreigner distinction.\n\nReferences to \"tianxia\" first appear in Japanese history during the Kofun period, approximately 250 to 538 AD. At the time, Japanese rulers were respectful and submissive to the Chinese court, and Chinese immigrants (then called \"toraijin\" 渡來人) were received happily and sought after for their knowledge of the Chinese language and culture. The excavated Eda Funayama grave mound in Kumamoto contained an iron sword with engraved characters that dates to the late 5th century. The characters on the sword refer to the king of the time as the \"Grand King who rules all under \"Tianxia\"\" (). This discovery demonstrates that the Kofun-era Japanese (at least of that area) had begun viewing their realm to be a complete and divinely-appointed \"tianxia\" in its own right, separate from the \"tianxia\" of the older and larger Chinese empire.\n\nAccording to the \"Book of Sui\", the Yamato king in 607 sent a hand-written epistle to Emperor Yang of the Sui dynasty in which he called himself the \"Son of Heaven in the Land of the Rising Sun\" (), showing that the Japanese notion of their independent \"tianxia\" had continued to that time.\n\nWith the development of \"Ritsuryō\" in 7th-century Japan, a Sino-centric concept of \"tianxia\" was introduced and replaced older concepts. The hallmark of \"Ritsuryō\" – the concept of citizenship – necessarily accompanied its introduction into Japan, since Neo-Confucianism said that all were \"Equal Citizens Under Heaven\" ().\n\nIn the journals of Fujiwara no Kanezane (藤原兼実、九條兼実), an official of the Kamakura shogunate whose journals became the \"Gyokuyō\" (玉葉), he describes the founding of the Shogunate by Minamoto no Yoritomo as \"beginning \"tianxia\"\". His usage of \"tianxia\" is entirely \"Ritsuryō\" in nature, and his phrase \"beginning \"tianxia\" refers to the establishment of a new nation, jurisprudence, and system of order. However, even if Yoritomo had the intention to become a monarch-level ruler, Japan's \"tianxia\" concept had not achieved the Chinese level of an Emperor who governed feudal kingdoms and was entrusted with the ordering of the world by Heaven. In the journals of Gidō Shūshin (義堂周信), Gidō records a discussion he had with Ashikaga Yoshimitsu where the Shōgun repeatedly referred to his dominion as \"tianxia\"\". In the Muromachi period, people gradually began regarding the Shōgun as the representative of Heaven.\n\nAs the Muromachi shogunate weakened, regional warlords began fighting with each other for control of the nation. More powerful nobles, such as Oda Nobunaga and Toyotomi Hideyoshi, controlled large areas and viewed their domains as \"tianxia\". The term was used with increasing frequency as generals sought to reunify Japan, and came to be equivalent with the land of Japan itself.\n\nBy the Edo period, the \"shōgun\" was referred to as \"Man of \"Tianxia\"\" and the Shogunate as \"Court of \"Tianxia\"\". The widespread adoption of the \"tianxia\" concept helped influence Japan's long period of isolation before the Meiji Restoration.\n\nBased on epitaphs dating to the 4th and 5th centuries, Goguryeo had concepts of Son of Heaven (天帝之子) and independent \"tianxia\". The rulers of Goryeo used the titles of emperor and Son of Heaven and positioned Goryeo at the center of the \"Haedong\" \"East of the Sea\" \"tianxia\", which encompassed the historical domain of the \"Samhan\", another name for the Three Kingdoms of Korea.\n\nIn the 17th century, with the fall of the Ming dynasty in China, a concept of Korea as the cultural center of Confucianism, or the \"Little China\" (), emerged among the Confucian literati of the Joseon dynasty.\n\nThe Vietnamese concept of \"tianxia\" as well as cultural identity originate in the Yuan dynasty's invasion in the 13th century. The Trần dynasty's defeat of the Mongol-Chinese armies gave them the confidence to adopt their own \"tianxia\" view and become the official sustainers of the Kingdom of Vietnam. From that time forward, the area from the Lingnan region of China to northern Vietnam was considered an independent \"tianxia\". However, near the end of the Lê dynasty in the late 18th century, the orthodox idea of Vietnam as the Vietnamese king's dynasty fell out of favor, and Vietnam was referred to as \"Great South\" until the European conquests of Southeast Asia.\n\nThe \"all under the heaven\" expression became the origin for the literary expressions denoting China in a number of Western languages, such as the Russian \"Podnebesnaya\" (Поднебесная, i.e. \"Under the heaven\"). The English term \"Celestial Empire\" is said to have been based on the title of Chinese emperors, \"tian zi\" (Son of Heaven).\n\n\n"}
{"id": "527984", "url": "https://en.wikipedia.org/wiki?curid=527984", "title": "Trinitite", "text": "Trinitite\n\nTrinitite, also known as atomsite or Alamogordo glass, is the glassy residue left on the desert floor after the plutonium-based Trinity nuclear bomb test on July 16, 1945, near Alamogordo, New Mexico. The glass is primarily composed of arkosic sand composed of quartz grains and feldspar (both microcline and smaller amount of plagioclase with small amount of calcite, hornblende and augite in a matrix of sandy clay) that was melted by the atomic blast. It is usually a light green, although color can vary. It is mildly radioactive but safe to handle.\n\nIn the late 1940s and early 1950s, samples were gathered and sold to mineral collectors as a novelty. Traces of the material may be found at the Trinity Site today, although most of it was bulldozed and buried by the United States Atomic Energy Commission in 1953. It is now illegal to take the remaining material from the site; however, material that was taken prior to this prohibition is still in the hands of collectors.\n\nIn 2005 it was theorized by Los Alamos National Laboratory scientist Robert Hermes and independent investigator William Strickfaden that much of the mineral was formed by sand which was drawn up inside the fireball itself and then rained down in a liquid form. In a 2010 article in \"Geology Today\", Nelson Eby of University of Massachusetts at Lowell and Robert Hermes described Trinitite: \n\nThe glass has been described as \"a layer 1 to 2 centimeters thick, with the upper surface marked by a very thin sprinkling of dust which fell upon it while it was still molten. At the bottom is a thicker film of partially fused material, which grades into the soil from which it was derived. The color of the glass is a pale bottle green, and the material is extremely vesicular with the size of the bubbles ranging to nearly the full thickness of the specimen.\"\n\nAn estimated 4.3 × 10 ergs or 4.3 × 10 joules of heat energy went into forming the glass and as the temperature required to melt the sand into the glass form observed was about 1470 Celsius, this was the estimated minimum temperature the sand was exposed to.\n\nOne of the more unusual isotopes found in trinitite, although by no means unique as it may also have formed during the Joe-1 test, which was a partial to complete Soviet replica of the Trinity/Fat Man design, is a barium neutron activation product, the barium in the Trinity device coming from the slow explosive lens employed in the device, known as Baratol.\n\nThere are many known fakes in circulation among collectors. These fakes use a variety of means to achieve the glassy green silica look as well as mild radioactivity; however, only trinitite from a nuclear explosion will contain certain neutron activation products that are not found in naturally radioactive ores and minerals. Gamma spectroscopy can narrow down the potential nuclear explosions from which the material formed.\n\nOccasionally, the name \"trinitite\" is broadly applied to all glassy residues of nuclear bomb testing, not just the Trinity test.\n\nBlack vitreous fragments of fused sand that had been solidified by the heat of the explosion were described from French test site in Algeria (Reggane site).\n\nKharitonchiki (singular: kharitonchik, ) is an analog of trinitite found in Semipalatinsk Test Site in Kazakhstan at ground zeroes of Soviet atmospheric nuclear tests. Also generically called Kharitonchik. They are pieces of molten rock left at ground zeroes after Soviet atmospheric nuclear tests. This porous black material is named after one of the leading Russian nuclear weapons scientists, Yulii Borisovich Khariton.\n\nTrinitite has several similar naturally occurring minerals as it is itself a melt glass.\n\nWhile trinitite and similar materials are anthropogenic, fulgurites, found in many thunderstorm-prone regions and in deserts, are naturally-formed, hollow or solid glassy tubes, masses, droplets, clumps, or crusts composed of quartzose sand, silica, rock, caliche, biomass, clay or other soil and sediment types, and are generated by lightning strikes.\n\nA material similar to trinitite can be formed by meteor impacts, these are impact glasses.\n\nFor a time it was believed that the desert sand had simply melted from the direct radiant thermal energy of the fireball and was not particularly dangerous. Thus it was marketed as suitable for use in jewelry in 1945.\n\n\nRecent onsite gamma measurements at the Trinity Test Site and a comparison to Trinitite samples 2011.PDF\n\n"}
{"id": "53872550", "url": "https://en.wikipedia.org/wiki?curid=53872550", "title": "William Gordon Mackendrick", "text": "William Gordon Mackendrick\n\nLieutenant-colonel William Gordon Mackendrick was a Canadian soldier and Author. He fought in the First World War, the Sinai and Palestine Campaign against the Ottoman Empire in the conquest of Palestine, led by Sir. Edmund Allenby.\n\nWith the pen name \"The Roadbuilder\", William Mackendrick wrote books on British Israelism.\n\n"}
{"id": "149861", "url": "https://en.wikipedia.org/wiki?curid=149861", "title": "Work (physics)", "text": "Work (physics)\n\nIn physics, a force is said to do work if, when acting, there is a displacement of the point of application in the direction of the force. For example, when a ball is held above the ground and then dropped, the work done on the ball as it falls is equal to the weight of the ball (a force) multiplied by the distance to the ground (a displacement).\n\nWork transfers energy from one place to another, or one form to another.\n\nAccording to Jammer, the term \"work\" was introduced in 1826 by the French mathematician Gaspard-Gustave Coriolis as \"weight \"lifted\" through a height\", which is based on the use of early steam engines to lift buckets of water out of flooded ore mines. According to Dugas, it is to Solomon of Caux \"that we owe the term \"work\" in the sense that it is used in mechanics now\".\n\nThe SI unit of work is the joule (J).\n\nThe SI unit of work is the joule (J), which is defined as the work expended by a force of one newton through a displacement of one metre.\n\nThe dimensionally equivalent newton-metre (N⋅m) is sometimes used as the measuring unit for work, but this can be confused with the unit newton-metre, which is the measurement unit of torque. Usage of N⋅m is discouraged by the SI authority, since it can lead to confusion as to whether the quantity expressed in newton metres is a torque measurement, or a measurement of work.\n\nNon-SI units of work include the newton-metre, erg, the foot-pound, the foot-poundal, the kilowatt hour, the litre-atmosphere, and the horsepower-hour. Due to work having the same physical dimension as heat, occasionally measurement units typically reserved for heat or energy content, such as therm, BTU and Calorie, are utilized as a measuring unit.\n\nThe work formula_1 done by a constant force of magnitude formula_2 on a point that moves a displacement formula_3 in a straight line in the direction of the force is the product\n\nFor example, if a force of 10 newtons (formula_2 = 10 N) acts along a point that travels 2 metres (formula_3 = 2 m), then formula_7 This is approximately the work done lifting a 1 kg object from ground level to over a person's head against the force of gravity.\n\nThe work is doubled either by lifting twice the weight the same distance or by lifting the same weight twice the distance.\n\nWork is closely related to energy. The work-energy principle states that an increase in the kinetic energy of a rigid body is caused by an equal amount of positive work done on the body by the resultant force acting on that body. Conversely, a decrease in kinetic energy is caused by an equal amount of negative work done by the resultant force.\n\nFrom Newton's second law, it can be shown that work on a free (no fields), rigid (no internal degrees of freedom) body, is equal to the change in kinetic energy formula_8 of the linear velocity and angular velocity of that body,\nThe work of forces generated by a potential function is known as potential energy and the forces are said to be conservative. Therefore, work on an object that is merely displaced in a conservative force field, without change in velocity or rotation, is equal to \"minus\" the change of potential energy formula_10 of the object,\nThese formulas show that work is the energy associated with the action of a force, so work subsequently possesses the physical dimensions, and units, of energy.\nThe work/energy principles discussed here are identical to Electric work/energy principles.\n\nConstraint forces limit the movement of components in a system, such as constraining an object to a surface (in the case of a slope plus gravity, the object is \"stuck to\" the slope, when attached to a taut string it cannot move in an outwards direction to make the string any 'tauter'). Constraint forces restrict the velocity in the direction of the constraint to zero, which means the constraint forces do not perform work on the system.\n\nFor a mechanical system, constraint forces eliminate movement in directions that characterize the constraint. Thus constraint forces do not perform work on the system, because the component of velocity along the constraint force at each point of application is zero. For example, in a pulley system like the Atwood machine, the internal forces on the rope and at the supporting pulley do no work on the system. Therefore work need only be computed for the gravity forces acting on the bodies. \n\nFor example, the centripetal force exerted \"inwards\" by a string on a ball in uniform circular motion \"sideways\" constrains the ball to circular motion restricting its movement away from the center of the circle. This force does zero work because it is perpendicular to the velocity of the ball.\n\nAnother example is a book on a table. If external forces are applied to the book so that it slides on the table, then the force exerted by the table constrains the book from moving downwards. The force exerted by the table supports the book and is perpendicular to its movement which means that this constraint force does not perform work.\n\nThe magnetic force on a charged particle is , where \"q\" is the charge, v is the velocity of the particle, and B is the magnetic field. The result of a cross product is always perpendicular to both of the original vectors, so . The dot product of two perpendicular vectors is always zero, so the work , and the magnetic force does not do work. It can change the direction of motion but never change the speed.\n\nFor moving objects, the quantity of work/time (power) is integrated along the trajectory of the point of application of the force. Thus, at any instant, the rate of the work done by a force (measured in joules/second, or watts) is the scalar product of the force (a vector), and the velocity vector of the point of application. This scalar product of force and velocity is known as instantaneous power. Just as velocities may be integrated over time to obtain a total distance, by the fundamental theorem of calculus, the total work along a path is similarly the time-integral of instantaneous power applied along the trajectory of the point of application.\n\nWork is the result of a force on a point that follows a curve X, with a velocity v, at each instant. The small amount of work \"δW\" that occurs over an instant of time \"dt\" is calculated as\nwhere the is the power over the instant \"dt\". The sum of these small amounts of work over the trajectory of the point yields the work,\nwhere \"C\" is the trajectory from x(\"t\") to x(\"t\"). This integral is computed along the trajectory of the particle, and is therefore said to be \"path dependent\".\n\nIf the force is always directed along this line, and the magnitude of the force is \"F\", then this integral simplifies to\nwhere \"s\" is displacement along the line. If F is constant, in addition to being directed along the line, then the integral simplifies further to\nwhere \"s\" is the displacement of the point along the line.\n\nThis calculation can be generalized for a constant force that is not directed along the line, followed by the particle. In this case the dot product , where \"θ\" is the angle between the force vector and the direction of movement, that is\n\nIn the notable case of a force applied to a body always at an angle of 90° from the velocity vector (as when a body moves in a circle under a central force), no work is done at all, since the cosine of 90 degrees is zero. Thus, no work can be performed by gravity on a planet with a circular orbit (this is ideal, as all orbits are slightly elliptical). Also, no work is done on a body moving circularly at a constant speed while constrained by mechanical force, such as moving at constant speed in a frictionless ideal centrifuge.\n\nCalculating the work as \"force times straight path segment\" would only apply in the most simple of circumstances, as noted above. If force is changing, or if the body is moving along a curved path, possibly rotating and not necessarily rigid, then only the path of the application point of the force is relevant for the work done, and only the component of the force parallel to the application point velocity is doing work (positive work when in the same direction, and negative when in the opposite direction of the velocity). This component of force can be described by the scalar quantity called \"scalar tangential component\" (formula_17, where formula_18 is the angle between the force and the velocity). And then the most general definition of work can be formulated as follows:\n\nformula_19\n\nA force couple results from equal and opposite forces, acting on two different points of a rigid body. The sum (resultant) of these forces may cancel, but their effect on the body is the couple or torque T. The work of the torque is calculated as\nwhere the is the power over the instant \"δt\". The sum of these small amounts of work over the trajectory of the rigid body yields the work,\nThis integral is computed along the trajectory of the rigid body with an angular velocity ω that varies with time, and is therefore said to be \"path dependent\".\n\nIf the angular velocity vector maintains a constant direction, then it takes the form,\nwhere φ is the angle of rotation about the constant unit vector S. In this case, the work of the torque becomes,\nwhere \"C\" is the trajectory from \"φ\"(\"t\") to \"φ\"(\"t\"). This integral depends on the rotational trajectory \"φ\"(\"t\"), and is therefore path-dependent.\n\nIf the torque T is aligned with the angular velocity vector so that,\nand both the torque and angular velocity are constant, then the work takes the form,\nThis result can be understood more simply by considering the torque as arising from a force of constant magnitude \"F\", being applied perpendicularly to a lever arm at a distance \"r\", as shown in the figure. This force will act through the distance along the circular arc , so the work done is\nIntroduce the torque , to obtain\nas presented above.\n\nNotice that only the component of torque in the direction of the angular velocity vector contributes to the work.\n\nThe scalar product of a force F and the velocity v of its point of application defines the power input to a system at an instant of time. Integration of this power over the trajectory of the point of application, , defines the work input to the system by the force.\n\nTherefore, the work done by a force F on an object that travels along a curve \"C\" is given by the line integral:\nwhere \"dx\"(\"t\") defines the trajectory \"C\" and v is the velocity along this trajectory. In general this integral requires the path along which the velocity is defined, so the evaluation of work is said to be path dependent.\n\nThe time derivative of the integral for work yields the instantaneous power,\n\nIf the work for an applied force is independent of the path, then the work done by the force, by the gradient theorem, defines a potential function which is evaluated at the start and end of the trajectory of the point of application. This means that there is a potential function \"U\"(x), that can be evaluated at the two points x(\"t\") and x(\"t\") to obtain the work over any trajectory between these two points. It is tradition to define this function with a negative sign so that positive work is a reduction in the potential, that is\n\nThe function \"U\"(x) is called the potential energy associated with the applied force. The force derived from such a potential function is said to be conservative. Examples of forces that have potential energies are gravity and spring forces. \n\nIn this case, the gradient of work yields\nand the force F is said to be \"derivable from a potential.\"\n\nBecause the potential \"U\" defines a force F at every point x in space, the set of forces is called a force field. The power applied to a body by a force field is obtained from the gradient of the work, or potential, in the direction of the velocity V of the body, that is\n\nIn the absence of other forces, gravity results in a constant downward acceleration of every freely moving object. Near Earth's surface the acceleration due to gravity is and the gravitational force on an object of mass \"m\" is . It is convenient to imagine this gravitational force concentrated at the center of mass of the object.\n\nIf an object is displaced upwards or downwards a vertical distance , the work \"W\" done on the object by its weight mg is:\nwhere \"F\" is weight (pounds in imperial units, and newtons in SI units), and Δ\"y\" is the change in height \"y\". Notice that the work done by gravity depends only on the vertical movement of the object. The presence of friction does not affect the work done on the object by its weight.\n\nThe force of gravity exerted by a mass \"M\" on another mass \"m\" is given by\nwhere r is the position vector from \"M\" to \"m\".\n\nLet the mass \"m\" move at the velocity v then the work of gravity on this mass as it moves from position r(\"t\") to r(\"t\") is given by\nNotice that the position and velocity of the mass \"m\" are given by\nwhere e and e are the radial and tangential unit vectors directed relative to the vector from \"M\" to \"m\". Use this to simplify the formula for work of gravity to,\nThis calculation uses the fact that\nThe function\nis the gravitational potential function, also known as gravitational potential energy. The negative sign follows the convention that work is gained from a loss of potential energy.\n\nConsider a spring that exerts a horizontal force that is proportional to its deflection in the \"x\" direction independent of how a body moves. The work of this spring on a body moving along the space with the curve , is calculated using its velocity, , to obtain\nFor convenience, consider contact with the spring occurs at , then the integral of the product of the distance \"x\" and the x-velocity, \"xv\", is (1/2)\"x\".\nThe velocity is not a factor here. The work is the product of the distance times the spring force, which is also dependent on distance; hence the \"x\" result.\n\nWhere \"P\" is pressure, \"V\" is volume, and \"a\" and \"b\" are initial and final volumes.\n\nThe principle of work and kinetic energy (also known as the work–energy principle) states that \"the work done by all forces acting on a particle (the work of the resultant force) equals the change in the kinetic energy of the particle.\" That is, the work \"W\" done by the resultant force on a particle equals the change in the particle's kinetic energy formula_42,\nwhere formula_44 and formula_45 are the speeds of the particle before and after the work is done, and \"m\" is its mass.\n\nThe derivation of the \"work–energy principle\" begins with Newton’s second law of motion and the resultant force on a particle. Computation of the scalar product of the forces with the velocity of the particle evaluates the instantaneous power added to the system.\n\nConstraints define the direction of movement of the particle by ensuring there is no component of velocity in the direction of the constraint force. This also means the constraint forces do not add to the instantaneous power. The time integral of this scalar equation yields work from the instantaneous power, and kinetic energy from the scalar product of velocity and acceleration. The fact the work–energy principle eliminates the constraint forces underlies Lagrangian mechanics.\n\nThis section focuses on the work–energy principle as it applies to particle dynamics. In more general systems work can change the potential energy of a mechanical device, the thermal energy in a thermal system, or the electrical energy in an electrical device. Work transfers energy from one place to another or one form to another.\n\nIn the case the resultant force F is constant in both magnitude and direction, and parallel to the velocity of the particle, the particle is moving with constant acceleration \"a\" along a straight line. The relation between the net force and the acceleration is given by the equation \"F\" = \"ma\" (Newton's second law), and the particle displacement \"s\" can be expressed by the equation\n\nwhich follows from formula_47 (see Equations of motion).\n\nThe work of the net force is calculated as the product of its magnitude and the particle displacement. Substituting the above equations, one obtains:\n\nOther derivation:\n\nVertical displacement derivation\n\n\"W = F × S = mg × h\"\n\nIn the general case of rectilinear motion, when the net force F is not constant in magnitude, but is constant in direction, and parallel to the velocity of the particle, the work must be integrated along the path of the particle:\n\nFor any net force acting on a particle moving along any curvilinear path, it can be demonstrated that its work equals the change in the kinetic energy of the particle by a simple derivation analogous to the equation above. Some authors call this result \"work–energy principle\", but it is more widely known as the work–energy theorem:\n\nThe identity formula_54 requires some algebra.\nFrom the identity formula_55 and definition formula_56\nit follows\n\nThe remaining part of the above derivation is just simple calculus, same as in the preceding rectilinear case.\n\nIn particle dynamics, a formula equating work applied to a system to its change in kinetic energy is obtained as a first integral of Newton's second law of motion. It is useful to notice that the resultant force used in Newton's laws can be separated into forces that are applied to the particle and forces imposed by constraints on the movement of the particle. Remarkably, the work of a constraint force is zero, therefore only the work of the applied forces need be considered in the work–energy principle.\n\nTo see this, consider a particle P that follows the trajectory X(\"t\") with a force F acting on it. Isolate the particle from its environment to expose constraint forces R, then Newton's Law takes the form\nwhere \"m\" is the mass of the particle.\n\nNote that n dots above a vector indicates its nth time derivative.\nThe scalar product of each side of Newton's law with the velocity vector yields\nbecause the constraint forces are perpendicular to the particle velocity. Integrate this equation along its trajectory from the point X(\"t\") to the point X(\"t\") to obtain\n\nThe left side of this equation is the work of the applied force as it acts on the particle along the trajectory from time \"t\" to time \"t\". This can also be written as\nThis integral is computed along the trajectory X(\"t\") of the particle and is therefore path dependent.\n\nThe right side of the first integral of Newton's equations can be simplified using the following identity\n(see product rule for derivation). Now it is integrated explicitly to obtain the change in kinetic energy,\nwhere the kinetic energy of the particle is defined by the scalar quantity,\n\nIt is useful to resolve the velocity and acceleration vectors into tangential and normal components along the trajectory X(\"t\"), such that\nwhere\nThen, the scalar product of velocity with acceleration in Newton's second law takes the form\nwhere the kinetic energy of the particle is defined by the scalar quantity,\n\nThe result is the work–energy principle for particle dynamics,\nThis derivation can be generalized to arbitrary rigid body systems.\n\nConsider the case of a vehicle moving along a straight horizontal trajectory under the action of a driving force and gravity that sum to F. The constraint forces between the vehicle and the road define R, and we have\nFor convenience let the trajectory be along the X-axis, so and the velocity is , then , and , where \"F\" is the component of F along the X-axis, so\nIntegration of both sides yields\nIf F is constant along the trajectory, then the integral of velocity is distance, so\n\nAs an example consider a car skidding to a stop, where \"k\" is the coefficient of friction and \"W\" is the weight of the car. Then the force along the trajectory is . The velocity \"v\" of the car can be determined from the length \"s\" of the skid using the work–energy principle,\nNotice that this formula uses the fact that the mass of the vehicle is .\n\nConsider the case of a vehicle that starts at rest and coasts down a mountain road, the work-energy principle helps compute the minimum distance that the vehicle travels to reach a velocity \"V\", of say 60 mph (88 fps). Rolling resistance and air drag will slow the vehicle down so the actual distance will be greater than if these forces are neglected.\n\nLet the trajectory of the vehicle following the road be X(\"t\") which is a curve in three-dimensional space. The force acting on the vehicle that pushes it down the road is the constant force of gravity , while the force of the road on the vehicle is the constraint force R. Newton's second law yields,\nThe scalar product of this equation with the velocity, , yields\nwhere \"V\" is the magnitude of V. The constraint forces between the vehicle and the road cancel from this equation because , which means they do no work.\nIntegrate both sides to obtain\nThe weight force \"W\" is constant along the trajectory and the integral of the vertical velocity is the vertical distance, therefore,\nRecall that V(t)=0. Notice that this result does not depend on the shape of the road followed by the vehicle.\n\nIn order to determine the distance along the road assume the downgrade is 6%, which is a steep road. This means the altitude decreases 6 feet for every 100 feet traveled—for angles this small the sin and tan functions are approximately equal. Therefore, the distance \"s\" in feet down a 6% grade to reach the velocity \"V\" is at least\nThis formula uses the fact that the weight of the vehicle is .\n\nThe work of forces acting at various points on a single rigid body can be calculated from the work of a resultant force and torque. To see this, let the forces F, F ... F act on the points X, X ... X in a rigid body.\n\nThe trajectories of X, \"i\" = 1, ..., \"n\" are defined by the movement of the rigid body. This movement is given by the set of rotations [\"A\"(\"t\")] and the trajectory d(\"t\") of a reference point in the body. Let the coordinates x \"i\" = 1, ..., \"n\" define these points in the moving rigid body's reference frame \"M\", so that the trajectories traced in the fixed frame \"F\" are given by\n\nThe velocity of the points X along their trajectories are\nwhere ω is the angular velocity vector obtained from the skew symmetric matrix\nknown as the angular velocity matrix.\n\nThe small amount of work by the forces over the small displacements \"δ\"r can be determined by approximating the displacement by so\nor\n\nThis formula can be rewritten to obtain\nwhere F and T are the resultant force and torque applied at the reference point d of the moving frame \"M\" in the rigid body.\n\n\n"}
