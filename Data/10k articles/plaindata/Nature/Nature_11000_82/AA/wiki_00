{"id": "53602677", "url": "https://en.wikipedia.org/wiki?curid=53602677", "title": "Abtew Method", "text": "Abtew Method\n\nThe Abtew Method is a remote sensing method for measuring evapotranspiration created by Wossenu Abtew in 1996. It is sometimes referred to as the radiative Abtew model.\n\nThe Abtew Method has advantages over other methods in that it only depends on solar radiation data. This is useful when modeling evaporation in areas where satellite remote sensing solar radiation data is the only data available.\n\nThe equation is represented as\n\nformula_1\n\nwhere\n"}
{"id": "77184", "url": "https://en.wikipedia.org/wiki?curid=77184", "title": "Acantha", "text": "Acantha\n\nAcantha (Ancient Greek: Ἀκάνθα, English translation: \"thorny\") is often claimed to be a minor character in Greek mythology whose metamorphosis was the origin of the \"Acanthus\" plant. The tale goes that Acantha was a nymph loved by the god Apollo. Acantha however rebuffed Apollo's advances and scratched his face. As a result, Apollo transformed her into the Acanthus, a plant with spiny leaves.\n\nThe story has, over the years, been retold in books, encyclopedias, and journals. Compilers have, however, often omitted reference to classical sources. For instance the first edition of John Lemprière's \"Bibliotheca Classica\", an early encyclopaedia of mythological figures, provides no reference for the story. In the updated 1839 edition three references are given. These are to Pliny the Elder's \"Natural History\", Pedanius Dioscorides' \"De Materia Medica\" and Hesychius of Alexandria's \"Lexicon\". On inspection, however, Pliny makes absolutely no reference to Acantha, Dioscorides refers only to the plant and Hesychius simply explains what the word means. A number of latter compilers have similarly not cited classical references when retelling the myth.\n\nThe myth does not appear in the \"Thesaurus Linguae Latinae\", a volume which includes every Latin word, including proper names. The \"Thesaurus Linguae Graecae\", a similarly comprehensive source containing a complete repository of Ancient Greek texts from Homer through to A.D. 200, is also absent the myth. The story is not present in either the \"Lexicon Iconographicum Mythologiae Classicae\", a work praised for its breadth and quality, or \"Der Neue Pauly\", an encyclopaedia considered an unparalleled masterpiece of classical German scholarship.\n"}
{"id": "39", "url": "https://en.wikipedia.org/wiki?curid=39", "title": "Albedo", "text": "Albedo\n\nAlbedo () (, meaning 'whiteness') is the measure of the diffuse reflection of solar radiation out of the total solar radiation received by an astronomical body (e.g. a planet like Earth). It is dimensionless and measured on a scale from 0 (corresponding to a black body that absorbs all incident radiation) to 1 (corresponding to a body that reflects all incident radiation).\n\nSurface albedo is defined as the ratio of irradiance reflected to the irradiance received by a surface. The proportion reflected is not only determined by properties of the surface itself, but also by the spectral and angular distribution of solar radiation reaching the Earth's surface. These factors vary with atmospheric composition, geographic location and time (see position of the Sun). While bi-hemispherical reflectance is calculated for a single angle of incidence (i.e., for a given position of the Sun), albedo is the directional integration of reflectance over all solar angles in a given period. The temporal resolution may range from seconds (as obtained from flux measurements) to daily, monthly, or annual averages.\n\nUnless given for a specific wavelength (spectral albedo), albedo refers to the entire spectrum of solar radiation. Due to measurement constraints, it is often given for the spectrum in which most solar energy reaches the surface (between 0.3 and 3 μm). This spectrum includes visible light (0.39–0.7 μm), which explains why surfaces with a low albedo appear dark (e.g., trees absorb most radiation), whereas surfaces with a high albedo appear bright (e.g., snow reflects most radiation).\n\nAlbedo is an important concept in climatology, astronomy, and environmental management (e.g., as part of the Leadership in Energy and Environmental Design (LEED) program for sustainable rating of buildings). The average albedo of the Earth from the upper atmosphere, its \"planetary albedo\", is 30–35% because of cloud cover, but widely varies locally across the surface because of different geological and environmental features.\n\nThe term albedo was introduced into optics by Johann Heinrich Lambert in his 1760 work \"Photometria\".\n\nAny albedo in visible light falls within a range of about 0.9 for fresh snow to about 0.04 for charcoal, one of the darkest substances. Deeply shadowed cavities can achieve an effective albedo approaching the zero of a black body. When seen from a distance, the ocean surface has a low albedo, as do most forests, whereas desert areas have some of the highest albedos among landforms. Most land areas are in an albedo range of 0.1 to 0.4. The average albedo of Earth is about 0.3. This is far higher than for the ocean primarily because of the contribution of clouds.\nEarth's surface albedo is regularly estimated via Earth observation satellite sensors such as NASA's MODIS instruments on board the Terra and Aqua satellites, and the CERES instrument on the Suomi NPP and JPSS. As the amount of reflected radiation is only measured for a single direction by satellite, not all directions, a mathematical model is used to translate a sample set of satellite reflectance measurements into estimates of directional-hemispherical reflectance and bi-hemispherical reflectance (e.g.,). These calculations are based on the bidirectional reflectance distribution function (BRDF), which describes how the reflectance of a given surface depends on the view angle of the observer and the solar angle. BDRF can facilitate translations of observations of reflectance into albedo.\n\nEarth's average surface temperature due to its albedo and the greenhouse effect is currently about 15 °C. If Earth were frozen entirely (and hence be more reflective), the average temperature of the planet would drop below −40 °C. If only the continental land masses became covered by glaciers, the mean temperature of the planet would drop to about 0 °C. In contrast, if the entire Earth was covered by water — a so-called aquaplanet — the average temperature on the planet would rise to almost 27 °C.\n\nFor land surfaces, it has been shown that the albedo at a particular solar zenith angle \"θ\" can be approximated by the proportionate sum of two terms: the directional-hemispherical reflectance at that solar zenith angle, formula_1, and the bi-hemispherical reflectance, formula_2, with formula_3 being the proportion of direct radiation from a given solar angle, and formula_4 being the proportion of diffuse illumination.\n\nHence, the actual albedo formula_5 (also called blue-sky albedo) can then be given as:\n\nDirectional-hemispherical reflectance is sometimes referred to as black-sky albedo and bi-hemispherical reflectance as white-sky albedo. These terms are important because they allow the albedo to be calculated for any given illumination conditions from a knowledge of the intrinsic properties of the surface.\n\nThe albedos of planets, satellites and minor planets such as asteroids can be used to infer much about their properties. The study of albedos, their dependence on wavelength, lighting angle (\"phase angle\"), and variation in time comprises a major part of the astronomical field of photometry. For small and far objects that cannot be resolved by telescopes, much of what we know comes from the study of their albedos. For example, the absolute albedo can indicate the surface ice content of outer Solar System objects, the variation of albedo with phase angle gives information about regolith properties, whereas unusually high radar albedo is indicative of high metal content in asteroids.\n\nEnceladus, a moon of Saturn, has one of the highest known albedos of any body in the Solar System, with 99% of EM radiation reflected. Another notable high-albedo body is Eris, with an albedo of 0.96. Many small objects in the outer Solar System and asteroid belt have low albedos down to about 0.05. A typical comet nucleus has an albedo of 0.04. Such a dark surface is thought to be indicative of a primitive and heavily space weathered surface containing some organic compounds.\n\nThe overall albedo of the Moon is measured to be around 0.136, but it is strongly directional and non-Lambertian, displaying also a strong opposition effect. Although such reflectance properties are different from those of any terrestrial terrains, they are typical of the regolith surfaces of airless Solar System bodies.\n\nTwo common albedos that are used in astronomy are the (V-band) geometric albedo (measuring brightness when illumination comes from directly behind the observer) and the Bond albedo (measuring total proportion of electromagnetic energy reflected). Their values can differ significantly, which is a common source of confusion.\n\nIn detailed studies, the directional reflectance properties of astronomical bodies are often expressed in terms of the five Hapke parameters which semi-empirically describe the variation of albedo with phase angle, including a characterization of the opposition effect of regolith surfaces.\n\nThe correlation between astronomical (geometric) albedo, absolute magnitude and diameter is:\nformula_7,\n\nwhere formula_8 is the astronomical albedo, formula_9 is the diameter in kilometers, and formula_10 is the absolute magnitude.\n\nAlbedo is not directly dependent on illumination because changing the amount of incoming light proportionally changes the amount of reflected light, except in circumstances where a change in illumination induces a change in the Earth's surface at that location (e.g. through albedo-temperature feedback). That said, albedo and illumination both vary by latitude. Albedo is highest near the poles and lowest in the subtropics, with a local maximum in the tropics.\n\nThe intensity of albedo temperature effects depend on the amount of albedo and the level of local insolation (solar irradiance); high albedo areas in the arctic and antarctic regions are cold due to low insolation, where areas such as the Sahara Desert, which also have a relatively high albedo, will be hotter due to high insolation. Tropical and sub-tropical rainforest areas have low albedo, and are much hotter than their temperate forest counterparts, which have lower insolation. Because insolation plays such a big role in the heating and cooling effects of albedo, high insolation areas like the tropics will tend to show a more pronounced fluctuation in local temperature when local albedo changes.\n\nArctic regions notably release more heat back into space than what they absorb, effectively cooling the Earth. This has been a concern since arctic ice and snow has been melting at higher rates due to higher temperatures, creating regions in the arctic that are notably darker (being water or ground which is darker color) and reflects less heat back into space. This feedback loop results in a reduced albedo effect.\n\nAlbedo affects climate by determining how much radiation a planet absorbs. The uneven heating of Earth from albedo variations between land, ice, or ocean surfaces can drive weather.\n\nWhen an area's albedo changes due to snowfall, a snow–temperature feedback results. A layer of snowfall increases local albedo, reflecting away sunlight, leading to local cooling. In principle, if no outside temperature change affects this area (e.g., a warm air mass), the raised albedo and lower temperature would maintain the current snow and invite further snowfall, deepening the snow–temperature feedback. However, because local weather is dynamic due to the change of seasons, eventually warm air masses and a more direct angle of sunlight (higher insolation) cause melting. When the melted area reveals surfaces with lower albedo, such as grass or soil, the effect is reversed: the darkening surface lowers albedo, increasing local temperatures, which induces more melting and thus reducing the albedo further, resulting in still more heating.\n\nSnow albedo is highly variable, ranging from as high as 0.9 for freshly fallen snow, to about 0.4 for melting snow, and as low as 0.2 for dirty snow. Over Antarctica snow albedo averages a little more than 0.8. If a marginally snow-covered area warms, snow tends to melt, lowering the albedo, and hence leading to more snowmelt because more radiation is being absorbed by the snowpack (the ice–albedo positive feedback).\n\nJust as fresh snow has a higher albedo than does dirty snow, the albedo of snow-covered sea ice is far higher than that of sea water. Sea water absorbs more solar radiation than would the same surface covered with reflective snow. When sea ice melts, either due to a rise in sea temperature or in response to increased solar radiation from above, the snow-covered surface is reduced, and more surface of sea water is exposed, so the rate of energy absorption increases. The extra absorbed energy heats the sea water, which in turn increases the rate at which sea ice melts. As with the preceding example of snowmelt, the process of melting of sea ice is thus another example of a positive feedback. Both positive feedback loops have long been recognized as important to the modern theory of Global warming.\n\nCryoconite, powdery windblown dust containing soot, sometimes reduces albedo on glaciers and ice sheets.\n\nThe dynamical nature of albedo in response to positive feedback, together with the effects of small errors in the measurement of albedo, can lead to large errors in energy estimates. Because of this, in order to reduce the error of energy estimates, it is important to measure the albedo of snow-covered areas through remote sensing techniques rather than applying a single value for albedo over broad regions.\n\nAlbedo works on a smaller scale, too. In sunlight, dark clothes absorb more heat and light-coloured clothes reflect it better, thus allowing some control over body temperature by exploiting the albedo effect of the colour of external clothing.\n\nAlbedo can affect the electrical energy output of solar photovoltaic devices. For example, the effects of a spectrally responsive albedo are illustrated by the differences between the spectrally weighted albedo of solar photovoltaic technology based on hydrogenated amorphous silicon (a-Si:H) and crystalline silicon (c-Si)-based compared to traditional spectral-integrated albedo predictions. Research showed impacts of over 10%. More recently, the analysis was extended to the effects of spectral bias due to the specular reflectivity of 22 commonly occurring surface materials (both human-made and natural) and analyzes the albedo effects on the performance of seven photovoltaic materials covering three common photovoltaic system topologies: industrial (solar farms), commercial flat rooftops and residential pitched-roof applications.\n\nBecause forests generally have a low albedo, (the majority of the ultraviolet and visible spectrum is absorbed through photosynthesis), some scientists have suggested that greater heat absorption by trees could offset some of the carbon benefits of afforestation (or offset the negative climate impacts of deforestation). In the case of evergreen forests with seasonal snow cover albedo reduction may be great enough for deforestation to cause a net cooling effect. Trees also impact climate in extremely complicated ways through evapotranspiration. The water vapor causes cooling on the land surface, causes heating where it condenses, acts a strong greenhouse gas, and can increase albedo when it condenses into clouds Scientists generally treat evapotranspiration as a net cooling impact, and the net climate impact of albedo and evapotranspiration changes from deforestation depends greatly on local climate \n\nIn seasonally snow-covered zones, winter albedos of treeless areas are 10% to 50% higher than nearby forested areas because snow does not cover the trees as readily. Deciduous trees have an albedo value of about 0.15 to 0.18 whereas coniferous trees have a value of about 0.09 to 0.15.\n\nStudies by the Hadley Centre have investigated the relative (generally warming) effect of albedo change and (cooling) effect of carbon sequestration on planting forests. They found that new forests in tropical and midlatitude areas tended to cool; new forests in high latitudes (e.g., Siberia) were neutral or perhaps warming.\n\nWater reflects light very differently from typical terrestrial materials. The reflectivity of a water surface is calculated using the Fresnel equations (see graph).\n\nAt the scale of the wavelength of light even wavy water is always smooth so the light is reflected in a locally specular manner (not diffusely). The glint of light off water is a commonplace effect of this. At small angles of incident light, waviness results in reduced reflectivity because of the steepness of the reflectivity-vs.-incident-angle curve and a locally increased average incident angle.\n\nAlthough the reflectivity of water is very low at low and medium angles of incident light, it becomes very high at high angles of incident light such as those that occur on the illuminated side of Earth near the terminator (early morning, late afternoon, and near the poles). However, as mentioned above, waviness causes an appreciable reduction. Because light specularly reflected from water does not usually reach the viewer, water is usually considered to have a very low albedo in spite of its high reflectivity at high angles of incident light.\n\nNote that white caps on waves look white (and have high albedo) because the water is foamed up, so there are many superimposed bubble surfaces which reflect, adding up their reflectivities. Fresh 'black' ice exhibits Fresnel reflection.\nSnow on top of this sea ice increases the albedo to 0.9.\n\nCloud albedo has substantial influence over atmospheric temperatures. Different types of clouds exhibit different reflectivity, theoretically ranging in albedo from a minimum of near 0 to a maximum approaching 0.8. \"On any given day, about half of Earth is covered by clouds, which reflect more sunlight than land and water. Clouds keep Earth cool by reflecting sunlight, but they can also serve as blankets to trap warmth.\"\n\nAlbedo and climate in some areas are affected by artificial clouds, such as those created by the contrails of heavy commercial airliner traffic. A study following the burning of the Kuwaiti oil fields during Iraqi occupation showed that temperatures under the burning oil fires were as much as 10 °C colder than temperatures several miles away under clear skies.\n\nAerosols (very fine particles/droplets in the atmosphere) have both direct and indirect effects on Earth's radiative balance. The direct (albedo) effect is generally to cool the planet; the indirect effect (the particles act as cloud condensation nuclei and thereby change cloud properties) is less certain. As per the effects are:\nAnother albedo-related effect on the climate is from black carbon particles. The size of this effect is difficult to quantify: the Intergovernmental Panel on Climate Change estimates that the global mean radiative forcing for black carbon aerosols from fossil fuels is +0.2 W m, with a range +0.1 to +0.4 W m. Black carbon is a bigger cause of the melting of the polar ice cap in the Arctic than carbon dioxide due to its effect on the albedo.\n\nHuman activities (e.g., deforestation, farming, and urbanization) change the albedo of various areas around the globe. However, quantification of this effect on the global scale is difficult.\n\nSingle-scattering albedo is used to define scattering of electromagnetic waves on small particles. It depends on properties of the material (refractive index); the size of the particle or particles; and the wavelength of the incoming radiation.\n\n\n"}
{"id": "6225484", "url": "https://en.wikipedia.org/wiki?curid=6225484", "title": "Boris stones", "text": "Boris stones\n\nBoris Stones (, ; ), also called Dvina Stones (), are seven medieval artifacts erected along the bank of the Western Dvina between Polotsk and Drissa, Belarus. They probably predate Christianity in the area, but were inscribed in the 12th century with text and an image of Christ. The largest of the stones is 17 metres in circumference. \n\nAlthough these landmarks were described in the 16th century by Maciej Stryjkowski, it was Georg von Cancrin in 1818 who first brought them to scholarly attention. Cancrin discovered that a boulder near Orsha had the following inscription: \"In the year 1171, on the 7th day of March, was completed this cross. Lord, please help your servant Basil, whose other name is Rogvolod, Boris' son\".\n\nSubsequently, several other boulders with Boris's name were discovered. In the 1930s, two of these were blown up by Communist authorities as religious objects and their remains used to pave the road between Minsk and Moscow. Another one was thrown into the river, where it lay until its discovery in 1988. When an attempt to recover it was made, the stone broke apart into three pieces. Three other boulders were moved to be exhibited near St. Sophia Cathedral in Polotsk, in the Museum of Boulders in Minsk, and in Kolomenskoe near Moscow.\n\nBoth names for the stones are somewhat misleading: only four of them are located along the banks of the Dvina, and one of the stones does not mention Boris at all. What unites them is their programmatic illustration: \"In each case the centrepiece is an enormous cross flanked by abbreviated elements of the conventional Greek legend proclaiming Christ's victory\". It is generally accepted that the Boris mentioned in the inscriptions was Rogvolod Vseslavich (baptismal name \"Boris\"), Vseslav's son, although it is quite likely that such boulders had been venerated by pagan Slavs long before the land was Christianised.\n\n\n"}
{"id": "40713982", "url": "https://en.wikipedia.org/wiki?curid=40713982", "title": "Bromofluorocarbon", "text": "Bromofluorocarbon\n\nBromofluorocarbons (BFCs) are molecules based on carbon, bromine, and fluorine. The most common use has traditionally been in fire suppression systems. The brand name \"Halon\" is frequently used interchangeably for BFCs. However, not all Halons are technically BFCs (some contain chlorine also).\n\nBFCs attack the ozone layer even more aggressively than chlorofluorocarbons (CFCs). Nevertheless, BFCs are still used in some ships and aircraft, because replacements are not as effective. As production of BFCs was banned by the Montreal Protocol, remaining use depends on old inventories and on recycling.\n\nBFCs are extremely inert. In a fire, in addition to physically excluding oxygen, the molecules liberate bromine radicals which interfere with combustion reactions. BFCs tend to have higher melting and boiling points than comparable fully fluorinated molecules.\n"}
{"id": "39383318", "url": "https://en.wikipedia.org/wiki?curid=39383318", "title": "Carbon bubble", "text": "Carbon bubble\n\nThe carbon bubble is a hypothesized bubble in the valuation of companies dependent on fossil-fuel-based energy production, because the true costs of carbon dioxide in intensifying global warming are not yet taken into account in a company's stock market valuation. Currently the price of fossil fuels companies' shares is calculated under the assumption that all fossil fuel reserves will be consumed. An estimate made by Kepler Chevreux puts the loss in value of the fossil fuel companies due to the impact of the growing renewables industry at US$28 trillion over the next two decades-long. A more recent analysis made by Citi puts that figure at $100 trillion.\n\nAnalysts in both the petroleum and financial industries are concluding that the \"age of oil\" has already reached a new stage where the excess supply that appeared in late 2014 may continue to prevail in the future. \nA consensus appears to be emerging that an international agreement will be reached to introduce measures to constrain the combustion of hydrocarbons in an effort to limit global temperature rise to the nominal 2 °C that is consensually predicted to limit environmental harm to tolerable levels.\n\nAccording to the UK's Committee on Climate Change, overvaluing companies that produce fossil fuels and greenhouse gases poses a serious threat to the economy. The committee warned the British government and Bank of England of the risks of the carbon bubble in 2014. The following year, Mark Carney, the Governor of the Bank of England, in his lecture to Lloyd's of London, warned that limiting global warming to 2 °C appears to require that the \"vast majority\" of fossil fuel reserves be \"stranded assets\", or \"literally unburnable without expensive carbon-capture technology\", resulting in \"potentially huge\" exposure to investors in that sector. He concluded that \"the window of opportunity is finite and shrinking\" for responding to the threat that climate change poses to financial resilience and longer-term prosperity, which he called the \"tragedy of the horizon\". That same month, the Prudential Regulation Authority of the Bank of England issued a report discussing the risks and opportunities that climate change presents to the insurance industry.\n\nIn his speech announcing his denial of the proposal to build the Keystone XL oil pipeline, U.S. President Barack Obama gave as one reason for the decision \"... ultimately, if we’re going to prevent large parts of this Earth from becoming not only inhospitable but uninhabitable in our lifetimes, we’re going to have to keep some fossil fuels in the ground...\".\n\nThe term \"carbon bubble\" arose in the early 21st century from the increasing awareness of the impact of fossil fuel combustion on global temperatures. The term was coined by the Carbon Tracker Initiative which published key reports in July 2011 and April 2013. and it was further popularised in the New Scientist magazine in October 2011. \nA widely shared article by Bill McKibben was published in Rolling Stone magazine in July 2012, bringing the idea to the attention of a popular audience.\nThese were followed later in 2013 by a report from the Demos think tank.\n\nAuthor Bill McKibben has estimated that to sustain human life in the world, up to $20 trillion worth of fossil fuel reserves will need to remain in the ground. The Stern report in 2006 stated that the benefits of strong, early action to decrease the use of oil, coal and gas considerably outweigh the costs. Fossil fuel contributors, the building industry, and land use practices ignore the responsibility of the external costs and ignore the polluter pays principle according to which climate change costs will be paid by historical climate polluters.\n\nA planned and orderly transition away from dependence on fossil fuels could prevent a disruptive \"bursting of the carbon bubble\". A number of developments are supporting such a transition.\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "1050882", "url": "https://en.wikipedia.org/wiki?curid=1050882", "title": "Casa Grande Ruins National Monument", "text": "Casa Grande Ruins National Monument\n\nCasa Grande Ruins National Monument ( or \"Sivan Vahki\"), in Coolidge, Arizona, just northeast of the city of Casa Grande, preserves a group of Ancient Pueblo Peoples Hohokam structures of the Pueblo III and Pueblo IV Eras.\n\nThe national monument consists of the ruins of multiple structures surrounded by a compound wall constructed by the ancient people of the Hohokam period, who farmed the Gila Valley in the early 13th century. \"Archeologists have discovered evidence that the ancient Sonoran Desert people who built the Casa Grande also developed wide-scale irrigation farming and extensive trade connections which lasted over a thousand years until about 1450 C.E.\"\n\n\"Casa Grande\" is Spanish for \"big house\" (\"Siwañ Wa'a Ki:\" in O'odham); these names refer to the largest structure on the site, which is what remains of a four-story structure that may have been abandoned by 1450. The structure is made of caliche, and has managed to survive the extreme weather conditions for about seven centuries. The large house consists of outer rooms surrounding an inner structure. The outer rooms are all three stories high, while the inner structure is four stories high. The structures were constructed using traditional adobe processes. The wet adobe is thicker at the base and adds significant strength. Noticeable horizontal cracks define the breaks between courses on the thick outer walls. The process consisted of using damp adobe to form the walls and then waiting for it to dry, and then building it up with more adobe. Casa Grande contained a ball court much like that found at Pueblo Grande de Nevada. Father Eusebio Kino was the first European to view the Hohokam complex in November 1694 and named it Casa Grande. Graffiti from 19th-century passers-by is scratched into its walls; though this is now illegal. Casa Grande now has a distinctive modern roof covering built in 1932.\n\nIn 1891, the monument underwent repairs supervised by Cosmos Mindeleff of the Bureau of American Ethnology, until funds ran out. Proclaimed Casa Grande Reservation by of President Benjamin Harrison on June 22, 1892, Casa Grande Ruins became the first prehistoric and cultural reserve in the US. It was then re-designated a national monument by President Woodrow Wilson on August 3, 1918. As with all historical areas administered by the National Park Service, Casa Grande was listed on the National Register of Historic Places on October 15, 1966.\n\nBetween 1937 and 1940 the Civilian Conservation Corps built several adobe buildings to serve as housing and administrative offices for the national monument. The adobe buildings, constructed using traditional methods, continue in use today and are now listed on the National Register of Historic Places. Because of careful conservation, the physical appearance of Casa Grande Ruins has hardly changed since the 1940s.\n\nIn 1932, a ramada to shelter the ruins from weathering was built by Boston architect Frederick Law Olmsted, Jr. In the early 21st century, a pair of great horned owls took up residence in the rafters of the Olmsted shelter.\n\nThe current protective structure covering the \"Great House\" replaced a wooden similar structure built to protect it in 1903\n. Due to the fragile nature of the \"Great House,\" visitors to the site are not permitted inside. To protect its integrity, observation by visitors is only permitted outside the structure.\n\n\n\n"}
{"id": "3288629", "url": "https://en.wikipedia.org/wiki?curid=3288629", "title": "Charles Clerke", "text": "Charles Clerke\n\nCaptain Charles Clerke (22 August 1741 – 22 August 1779) was an officer in the Royal Navy who sailed on four voyages of exploration, 3 with Captain James Cook. When Cook was killed during his 3rd expedition to the Pacific, Clerke took command but died later in the voyage from tuberculosis.\n\nClerke started studying at the Royal Naval Academy in Portsmouth when he was 13. During the Seven Years' War he served aboard HMS \"Dorsetshire \" and HMS \"Bellona\". He was in the mizzen-top of HMS Bellona when the mast was shot away in 1761 and he became the only survivor of those who consequently fell overboard.\n\nIn June 1764 he joined Captain John Byron, aboard HMS \"Dolphin\", on Byron's expedition to explore the Pacific. The Dolphin returned in May 1766. Its circumnavigation of 22 months was the shortest up to that point. Upon his return Clerke published an account of encountering Patagonian giants, a hoax which the Dictionary of Canadian Biography attributed to his high spirits.\n\nClerke's last three voyages were all under the command of Captain James Cook. He started the first voyage aboard HM Bark \"Endeavour\" (1768–1771) as a master's mate. Cook promoted him to acting lieutenant in 1771, and he was officially confirmed in that rank on 31 July 1771. He was HMS \"Resolution\"'s second lieutenant on Cook's second voyage (1772–1775).\n\nWhile ashore between Cook's 2nd and 3rd voyages Clerke agreed to serve time in the King's Bench debtor's prison for a debt one of his brothers, Sir John Clerke had incurred. While in debtor's prison he was infected with the tuberculosis that eventually killed him. \n\nFor Cook's third expedition, Clerke was placed in command of HMS \"Discovery\", receiving this command on 26 August 1775. When Cook was killed in a skirmish with Hawaiians on 14 February 1779, Clerke took command of the expedition and of HMS \"Resolution\". He continued the expedition's exploration of the Northern Pacific coast, searching for a navigable Northwest Passage. The expedition then proceeded to the Pacific coast of Siberia. Lieutenant James King, one of his subordinates, wrote that Clerke's illness had reduced him to skeletal thinness. On 10 August 1779, Clerke wrote in a letter to Sir Joseph Banks that, \"The disorder I was attacked with in the King's bench prison has proved consumptive, with which I have battled with various [unclear] although without one single days health since I took leave of you ... it has now so far got the better of me that I am not able to turn myself in bed, so that my stay in this world must be of very short duration.\" Clerke died from tuberculosis on his 38th birthday (22 August 1779) en route to Kamchatka from the Bering Strait. He was buried in Kamchatka on 29 August 1779. Clerke's second in command, Lieutenant John Gore took command of the expedition as captain of \"Resolution,\" appointing King as captain of \"Discovery.\" The expedition then sailed via China and the Sunda Strait to Cape Town, returning to England in August 1780.\n\nIn 1913, the British Admiralty erected a small obelisk in Clerke's honour at Petropavlovsk-Kamchatskiy, Russia, with an inscription in English.\n\n\n"}
{"id": "15346132", "url": "https://en.wikipedia.org/wiki?curid=15346132", "title": "Conformal map projection", "text": "Conformal map projection\n\nIn cartography, a conformal map projection is one in which any angle on Earth (a sphere or an ellipsoid) is preserved in the image of the projection, i.e. the projection is a conformal map in the mathematical sense.\n\nWe can define a conformal projection as one that is locally conformal at any point on the earth. Thus, any small figure on the earth is nearly similar to its image on the map. The projection preserves the ratio of two lengths in the small domain. All Tissot's indicatrices of the projections are circles.\n\nConformal projections preserve only small figures. Large figures are distorted, even by conformal projections.\n\nIn a conformal projection, any small figure is similar to the image, but the ratio of similarity (scale) varies by location. This explains the distortion of the conformal projection.\n\nIn a conformal projection, parallels and meridians cross rectangularly on the map. The converse is not necessarily true. The counterexamples are equirectangular and equal-area cylindrical projections (of normal aspects). These projections expand meridian-wise and parallel-wise by different ratios respectively. Thus, parallels and meridians cross rectangularly on the map, but these projections do not preserve other angles; i.e. these projections are not conformal.\n\n\nMany large-scale maps use conformal projections because figures in large-scale maps can be regarded as small enough. The figures on the maps are nearly similar to their physical counterparts.\n\nA non-conformal projection can be used in a limited domain such that the projection is locally conformal. Glueing many maps together restores roundness. To make a new sheet from many maps or to change the center, the body must be re-projected.\n\nSeamless online maps can be very large Mercator projections, so that any place can become the map's center, then the map remains conformal. However, it is difficult to compare lengths or areas of two far-off figures using such a projection.\n\nThe Universal Transverse Mercator coordinate system and the in France are projections that support the trade-off between seamlessness and scale variability.\n\nMaps reflecting directions, such as a nautical chart or an aeronautical chart, are projected by conformal projections. Maps treating values whose gradients are important, such as a weather map with atmospheric pressure, are also projected by conformal projections.\n\nSmall scale maps have large scale variations in a conformal projection, so recent world maps use other projections. Historically, many world maps are drawn by conformal projections, such as Mercator maps or hemisphere maps by stereographic projection.\n\nConformal maps containing large regions vary scales by locations, so it is difficult to compare lengths or areas. However, some techniques require that a length of 1 degree on a meridian = 111 km = 60 nautical miles. In non-conformal maps, such techniques are not available because the same lengths at a point vary the lengths on the map.\n\nIn Mercator or stereographic projections, scales vary by latitude, so bar scales by latitudes are often appended. In complex projections such as of oblique aspect. Contour charts of scale factors are sometimes appended.\n"}
{"id": "23316667", "url": "https://en.wikipedia.org/wiki?curid=23316667", "title": "Datun Sahib", "text": "Datun Sahib\n\nDatun Sahib is the name of a tree in the main bazaar at Leh, Ladakh in Jammu and Kashmir, India. Guru Nanak visited this site around 1516. There is no Gurudwara at the site, but the remains of a large meswak tree are located behind the Jamia Masjid in the main bazaar at Leh. The Datun Sahib is located close to the Leh Palace, on a lane which mainly houses bread makers. \n\nDatun Sahib contains a nishan sahib and a tree wrapped with orange cloth. A yellow board in front of the tree refers to the visit of Rimpoche Nanak (Holy Nanak) around 1516. Guru Nanak was revered by both Buddhists and Muslims. It is said that Leh was devoid of greenery at the time, but Nanak blessed the city with greenery by planting a meswak tree. There are two main Singh Sabha Gurudwaras located within one kilometre of the site.\n\n"}
{"id": "8023222", "url": "https://en.wikipedia.org/wiki?curid=8023222", "title": "European-Mediterranean montane mixed forest", "text": "European-Mediterranean montane mixed forest\n\nThe European-Mediterranean montane mixed forests is a composite ecoregion of southern Europe and North Africa, designated by the World Wildlife Fund as one of their Global 200 ecoregions, a list of priority ecoregions for conservation.\n\nThese forests include temperate coniferous forests and temperate broadleaf and mixed forests covering several major mountain ranges of Europe and northern Africa, including the Alps, Pyrenees, Atlas Mountains, Balkan Mountains, Rhodope Mountains, and the Carpathian Mountains, and including parts of over two dozen different countries.\n\nThe terrestrial ecoregions included within the larger ecoregion include:\n\n"}
{"id": "5382986", "url": "https://en.wikipedia.org/wiki?curid=5382986", "title": "Hydrogen storage", "text": "Hydrogen storage\n\nMethods of hydrogen storage for subsequent use span many approaches including high pressures, cryogenics, and chemical compounds that reversibly release H upon heating. Underground hydrogen storage is useful to provide grid energy storage for intermittent energy sources, like wind power, as well as providing fuel for transportation, particularly for ships and airplanes.\n\nMost research into hydrogen storage is focused on storing hydrogen as a lightweight, compact energy carrier for mobile applications.\n\nLiquid hydrogen or slush hydrogen may be used, as in the Space Shuttle. However liquid hydrogen requires cryogenic storage and boils around 20.268 K (−252.882 °C or −423.188 °F). Hence, its liquefaction imposes a large energy loss (as energy is needed to cool it down to that temperature). The tanks must also be well insulated to prevent boil off but adding insulation increases cost. Liquid hydrogen has less energy density \"by volume\" than hydrocarbon fuels such as gasoline by approximately a factor of four. This highlights the density problem for pure hydrogen: there is actually about 64% more hydrogen in a liter of gasoline (116 grams hydrogen) than there is in a liter of pure liquid hydrogen (71 grams hydrogen). The carbon in the gasoline also contributes to the energy of combustion.\n\nCompressed hydrogen, by comparison, is stored quite differently. Hydrogen gas has good energy density by weight, but poor energy density by volume versus hydrocarbons, hence it requires a larger tank to store. A large hydrogen tank will be heavier than the small hydrocarbon tank used to store the same amount of energy, all other factors remaining equal. Increasing gas pressure would improve the energy density by volume, making for smaller, but not lighter container tanks (see hydrogen tank). Compressed hydrogen costs 2.1% of the energy content to power the compressor. Higher compression without energy recovery will mean more energy lost to the compression step. Compressed hydrogen storage can exhibit very low permeation.\n\nCompressed hydrogen is a storage form where hydrogen gas is kept under pressures to increase the storage density. Compressed hydrogen in hydrogen tanks at 350 bar (5,000 psi) and 700 bar (10,000 psi) is used for hydrogen tank systems in vehicles, based on type IV carbon-composite technology. Car manufacturers have been developing this solution, such as Honda or Nissan.\n\nBMW has been working on liquid hydrogen tanks for cars, producing for example the BMW Hydrogen 7. Japan have liquid hydrogen (LH2) storage at a tanker port in Kobe, and are anticipated to receive the first shipment of liquid hydrogen via LH2 carrier in 2020. Hydrogen is liquified by reducing its temperature to -253°C, similar to liquified natural gas (LNG) which is stored at -162°C. A potential efficiency loss of 12.79% can be achieved, or 4.26kWh/kg out of 33.3kWh/kg.\n\nHydrogen storage technologies can be divided into physical storage, where hydrogen molecules are stored (including pure hydrogen storage via compression and liquefaction), and chemical storage, where hydrides are stored.\n\nChemical storage could offer high storage performance due to the strong binding of hydrogen and the high storage densities. However, the regeneration of storage material is still an issue. A large number of chemical storage systems are under investigation, which involve hydrolysis reactions, hydrogenation/dehydrogenation reactions, ammonia borane and other boron hydrides, ammonia, and alane etc. Storage in hydrocarbons may also be successful in overcoming the issue with low density. For example, supercritical hydrogen at 30 °C and 500 bar only has a density of 15.0 mol/L while methanol has a density of 49.5 mol H/L methanol and saturated dimethyl ether at 30 °C and 7 bar has a density of 42.1 mol H/L dimethyl ether. These liquids would use much smaller, cheaper, safer storage tanks. The most promising chemical approach is electrochemical hydrogen storage, as the release of hydrogen can be controlled by the applied electricity. Most of the materials listed below can be directly used for electrochemical hydrogen storage.\n\nMetal hydrides, such as MgH, NaAlH, LiAlH, LiH, LaNiH, TiFeH and palladium hydride, with varying degrees of efficiency, can be used as a storage medium for hydrogen, often reversibly. Some are easy-to-fuel liquids at ambient temperature and pressure, others are solids which could be turned into pellets. These materials have good energy density, although their specific energy is often worse than the leading hydrocarbon fuels.\n\nMost metal hydrides bind with hydrogen very strongly. As a result, high temperatures around 120 °C (248 °F) – 200 °C (392 °F) are required to release their hydrogen content. This energy cost can be reduced by using alloys which consists of a strong hydride former and a weak one such as in LiNH, LiBH and NaBH. These are able to form weaker bonds, thereby requiring less input to release stored hydrogen. However, if the interaction is too weak, the pressure needed for rehydriding is high, thereby eliminating any energy savings. The target for onboard hydrogen fuel systems is roughly <100 °C for release and <700 bar for recharge (20–60 kJ/mol H).\n\nAn alternative method for reducing dissociation temperatures is doping with activators. This has been successfully used for aluminium hydride but its complex synthesis makes it undesirable for most applications as it is not easily recharged with hydrogen.\n\nCurrently the only hydrides which are capable of achieving the 9 wt% gravimetric goal for 2015 (see chart above) are limited to lithium, boron and aluminium based compounds; at least one of the second-row elements or Al must be added. Research is being done to determine new compounds which can be used to meet these requirements.\n\nProposed hydrides for use in a hydrogen economy include simple hydrides of magnesium or transition metals and complex metal hydrides, typically containing sodium, lithium, or calcium and aluminium or boron. Hydrides chosen for storage applications provide low reactivity (high safety) and high hydrogen storage densities. Leading candidates are lithium hydride, sodium borohydride, lithium aluminium hydride and ammonia borane. A French company McPhy Energy is developing the first industrial product, based on magnesium hydride, already sold to some major clients such as Iwatani and ENEL.\n\n\"New Scientist\" reported that Arizona State University is investigating using a borohydride solution to store hydrogen, which is released when the solution flows over a catalyst made of ruthenium. Researchers at University of Pittsburgh and Georgia Tech performed extensive benchmarking simulations on mixtures of several light metal hydrides to predict possible reaction thermodynamics for hydrogen storage.\n\nThe Italian catalyst manufacturer Acta has proposed using hydrazine as an alternative to hydrogen in fuel cells. As the hydrazine fuel is liquid at room temperature, it can be handled and stored more easily than hydrogen. By storing it in a tank full of a double-bonded carbon-oxygen carbonyl, it reacts and forms a safe solid called hydrazone. By then flushing the tank with warm water, the liquid hydrazine hydrate is released. Hydrazine breaks down in the cell to form nitrogen and hydrogen which bonds with oxygen, releasing water. Silicon hydrides and germanium hydrides are also candidates of hydrogen storage materials, as they can subject to energetically favored reaction to form covalently bonded dimers with loss of a hydrogen molecule. \n\nCarbohydrates (polymeric CHO) releases H in a bioreformer mediated by the enzyme cocktail—cell-free synthetic pathway biotransformation. Carbohydrate provides high hydrogen storage densities as a liquid with mild pressurization and cryogenic constraints: It can also be stored as a solid powder. Carbohydrate is the most abundant renewable bioresource in the world.\n\nIn May 2007 biochemical engineers from the Virginia Polytechnic Institute and State University and biologists and chemists from the Oak Ridge National Laboratory announced a method of producing high-yield pure hydrogen from starch and water. In 2009, they demonstrated to produce nearly 12 moles of hydrogen per glucose unit from cellulosic materials and water. Thanks to complete conversion and modest reaction conditions, they propose to use carbohydrate as a high energy density hydrogen carrier with a density of 14.8 wt%.\n\nAn alternative to hydrides is to use regular hydrocarbon fuels as the hydrogen carrier. Then a small hydrogen reformer would extract the hydrogen as needed by the fuel cell. However, these reformers are slow to react to changes in demand and add a large incremental cost to the vehicle powertrain.\n\nDirect methanol fuel cells do not require a reformer, but provide a lower energy density compared to conventional fuel cells, although this could be counterbalanced with the much better energy densities of ethanol and methanol over hydrogen. Alcohol fuel is a renewable resource.\n\nSolid-oxide fuel cells can operate on light hydrocarbons such as propane and methane without a reformer, or can run on higher hydrocarbons with only partial reforming, but the high temperature and slow startup time of these fuel cells are problematic for automotive applications.\n\nAluminum has been proposed as an energy storage method by a number of researchers. hydrogen can be extracted from aluminum by reacting it with water. To react with water, however, aluminum must be stripped of its natural oxide layer, a process which requires pulverization, chemical reactions with caustic substances, or alloys. The byproduct of the reaction to create hydrogen is aluminum oxide, which can be recycled back into aluminum with the Hall–Héroult process, making the reaction theoretically renewable.\n\nUnsaturated organic compounds can store huge amounts of hydrogen. These \"Liquid Organic Hydrogen Carriers\" (LOHC) are hydrogenated for storage and dehydrogenated again when the energy/hydrogen is needed. Research on LOHC was concentrated on cycloalkanes at an early stage, with its relatively high hydrogen capacity (6-8 wt %) and production of CO-free hydrogen. Heterocyclic aromatic compounds (or N-Heterocycles) are also appropriate for this task. A compound that stands in the focus of the current LOHC research is N-ethylcarbazole (NEC) but many others do exist. More recently dibenzyltoluene, which is already industrially used as a heat transfer fluid in industry, was identified as potential LOHC. With a wide liquid range between -39 °C (melting point) and 390 °C (boiling point) and a hydrogen storage density of 6.2 wt% dibenzyltoluene is ideally suited as LOHC material. More recently, formic acid (FA) has been suggested as a promising hydrogen storage material with a 4.4wt% hydrogen capacity.\n\nUsing LOHCs relatively high gravimetric storage densities can be reached (about 6 wt-%) and the overall energy efficiency is higher than for other chemical storage options such as producing methane from the hydrogen.\nCycloalkanes reported as LOHC include cyclohexane, methyl-cyclohexane and decalin. The dehydrogenation of cycloalkanes is highly endothermic (63-69 kJ/mol H), which means this process requires high temperature. Dehydrogenation of decalin is the most thermodynamically favored among the three cycloalkanes, and methyl-cyclohexane is second because of the presence of the methyl group. Research on catalyst development for dehydrogenation of cycloalkanes has been carried out for decades. Nickel (Ni), Molybdenum (Mo) and Platinum (Pt) based catalysts are highly investigated for dehydrogenation. However, coking is still a big challenge for catalyst’s long-term stability.\nBoth hydrogenation and dehydrogenation of LOHCs requires catalysts. It was demonstrated that replacing hydrocarbons by hetero-atoms, like N, O etc. improves reversible de/hydrogenation properties. The temperature required for hydrogenation and dehydrogenation of drops significantly with increasing numbers of heteroatoms. Among all the N-heterocycles, the saturated-unsaturated pair of dodecahydro-N-ethylcarbazole (12H-NEC) and NEC has been considered as a promising candidate for hydrogen storage with a fairly large hydrogen content (5.8wt%). The figure on the top right shows dehydrogenation and hydrogenation of the 12H-NEC and NEC pair. The standard catalyst for NEC to 12H-NEC is Ru and Rh based. The selectivity of hydrogenation can reach 97% at 7 MPa and 130 °C-150 °C. Although N-Heterocyles can optimize the unfavorable thermodynamic properties of cycloalkanes, a lot of issues remain unsolved, such as high cost, high toxicity and kinetic barriers etc.\nIn 2006 researchers of EPFL, Switzerland, reported the use of formic acid as a hydrogen storage material. Carbon monoxide free hydrogen has been generated in a very wide pressure range (1–600 bar). A homogeneous catalytic system based on water-soluble ruthenium catalysts selectively decompose HCOOH into H and CO in aqueous solution. This catalytic system overcomes the limitations of other catalysts (e.g. poor stability, limited catalytic lifetimes, formation of CO) for the decomposition of formic acid making it a viable hydrogen storage material. And the co-product of this decomposition, carbon dioxide, can be used as hydrogen vector by hydrogenating it back to formic acid in a second step. The catalytic hydrogenation of CO has long been studied and efficient procedures have been developed. Formic acid contains 53 g L hydrogen at room temperature and atmospheric pressure. By weight, pure formic acid stores 4.3 wt% hydrogen. Pure formic acid is a liquid with a flash point 69 °C (cf. gasoline −40 °C, ethanol 13 °C). 85% formic acid is not flammable.\n\nAmmonia (NH) releases H in an appropriate catalytic reformer. Ammonia provides high hydrogen storage densities as a liquid with mild pressurization and cryogenic constraints: It can also be stored as a liquid at room temperature and pressure when mixed with water. Ammonia is the second most commonly produced chemical in the world and a large infrastructure for making, transporting, and distributing ammonia exists. Ammonia can be reformed to produce hydrogen with no harmful waste, or can mix with existing fuels and under the right conditions burn efficiently. Since there is no carbon in ammonia, no carbon by-products are produced; thereby making this possibility a \"carbon neutral\" option for the future. Pure ammonia burns poorly at the atmospheric pressures found in natural gas fired water heaters and stoves. Under compression in an automobile engine it is a suitable fuel for slightly modified gasoline engines. Ammonia is the suitable alternative fuel because it has 18.6 MJ/kg energy density at NTP and carbon-free combustion byproducts. However, ammonia is a toxic gas at normal temperature and pressure and has a potent odor.\n\nIn 2018, researchers at CSIRO in Australia powered a Toyota Mirai and Hyundai Nexo with hydrogen separated from ammonia using a membrane technology. \n\nIn September 2005 chemists from the Technical University of Denmark announced a method of storing hydrogen in the form of ammonia saturated into a salt tablet. They claim it will be an inexpensive and safe storage method.\n\nPrior to 1980, several compounds were investigated for hydrogen storage including complex borohydrides, or aluminohydrides, and ammonium salts. These hydrides have an upper theoretical hydrogen yield limited to about 8.5% by weight. Amongst the compounds that contain only B, N, and H (both positive and negative ions), representative examples include: amine boranes, boron hydride ammoniates, hydrazine-borane complexes, and ammonium octahydrotriborates or tetrahydroborates. Of these, amine boranes (and especially ammonia borane) have been extensively investigated as hydrogen carriers. During the 1970s and 1980s, the U.S. Army and Navy funded efforts aimed at developing hydrogen/deuterium gas-generating compounds for use in the HF/DF and HCl chemical lasers, and gas dynamic lasers. Earlier hydrogen gas-generating formulations used amine boranes and their derivatives. Ignition of the amine borane(s) forms boron nitride (BN) and hydrogen gas. In addition to ammonia borane\n(HBNH), other gas-generators include diborane diammoniate, HB(NH)BH.\n\nIn 2007 Dupont and others reported hydrogen-storage materials based on imidazolium ionic liquids. Simple alkyl(aryl)-3-methylimidazolium N-bis(trifluoromethanesulfonyl)imidate salts that possess very low vapour pressure, high density, and thermal stability and are not inflammable can add reversibly 6–12 hydrogen atoms in the presence of classical Pd/C or Ir0 nanoparticle catalysts and can be used as alternative materials for on-board hydrogen-storage devices. These salts can hold up to 30 g L of hydrogen at atmospheric pressure.\n\nIn 2006 researchers of University of Windsor reported on reversible hydrogen storage in a non-metal phosphonium borate frustrated Lewis pair:\n\nThe phosphino-borane on the left accepts one equivalent of hydrogen at one atmosphere and 25 °C and expels it again by heating to 100 °C. The storage capacity is 0.25 wt% still rather below the 6 to 9 wt% required for practical use.\n\nResearch has proven that graphene can store hydrogen efficiently. After taking up hydrogen, the substance becomes graphane. After tests, conducted by dr André Geim at the University of Manchester, it was shown that not only can graphene store hydrogen easily, it can also release the hydrogen again, after heating to 450 °C.\n\nMetal-organic frameworks represent another class of synthetic porous materials that store hydrogen and energy at the molecular level. MOFs are highly crystalline inorganic-organic hybrid structures that contain metal clusters or ions (secondary building units) as nodes and organic ligands as linkers. When guest molecules (solvent) occupying the pores are removed during solvent exchange and heating under vacuum, porous structure of MOFs can be achieved without destabilizing the frame and hydrogen molecules will be adsorbed onto the surface of the pores by physisorption. Compared to traditional zeolites and porous carbon materials, MOFs have very high number of pores and surface area which allow higher hydrogen uptake in a given volume. Thus, research interests on hydrogen storage in MOFs have been growing since 2003 when the first MOF-based hydrogen storage was introduced. Since there are infinite geometric and chemical variations of MOFs based on different combinations of SBUs and linkers, many researches explore what combination will provide the maximum hydrogen uptake by varying materials of metal ions and linkers.\n\nIn 2006, chemists at UCLA and the University of Michigan have achieved hydrogen storage concentrations of up to 7.5 wt% in MOF-74 at a low temperature of 77 K. In 2009, researchers at University of Nottingham reached 10 wt% at 77 bar (1,117 psi) and 77 K with MOF NOTT-112. Most articles about hydrogen storage in MOFs report hydrogen uptake capacity at a temperature of 77K and a pressure of 1 bar because these conditions are commonly available and the binding energy between hydrogen and the MOF at this temperature is large compared to the thermal vibration energy. Varying several factors such as surface area, pore size, catenation, ligand structure, and sample purity can result in different amounts of hydrogen uptake in MOFs.\n\nCella Energy technology is based around the encapsulation of hydrogen gas and nano-structuring of chemical hydrides in small plastic balls, at room temperature and pressure.\n\nIn this case hydrogen remains in physical forms, i.e., as gas, supercritical fluid, adsorbate, or molecular inclusions. Theoretical limitations and experimental results are considered \nconcerning the volumetric and gravimetric capacity of glass microvessels, microporous, and nanoporous media, as well as safety and refilling-time demands.\n\nActivated carbons are highly porous amorphous carbon materials with high apparent surface area. Hydrogen physisorption can be increased in these materials by increasing the apparent surface area and optimizing pore diameter to around 7 Å. These materials are of particular interest due to the fact that they can be made from waste materials, such as cigarette butts which have shown great potential as precursor materials for high-capacity hydrogen storage materials.\n\nCryo-compressed storage of hydrogen is the only technology that meets 2015 DOE targets for volumetric and gravimetric efficiency (see \"CcH2\" on slide 6 in ).\n\nFurthermore, another study has shown that cryo-compressed exhibits interesting cost advantages: ownership cost (price per mile) and storage system cost (price per vehicle) are actually the lowest when compared to any other technology (see third row in slide 13 of ). For example, a cryo-compressed hydrogen system would cost $0.12 per mile (including cost of fuel and every associated other cost), while conventional gasoline vehicles cost between $0.05 and $0.07 per mile.\n\nLike liquid storage, cryo-compressed uses cold hydrogen (20.3 K and slightly above) in order to reach a high energy density. However, the main difference is that, when the hydrogen would warm-up due to heat transfer with the environment (\"boil off\"), the tank is allowed to go to pressures much higher (up to 350 bars versus a couple of bars for liquid storage). As a consequence, it takes more time before the hydrogen has to vent, and in most driving situations, enough hydrogen is used by the car to keep the pressure well below the venting limit.\n\nConsequently, it has been demonstrated that a high driving range could be achieved with a cryo-compressed tank : more than were driven with a full tank mounted on an hydrogen-fueled engine of Toyota Prius. Research is still on its way in order to study and demonstrate the full potential of the technology.\n\nAs of 2010, the BMW Group has started a thorough component and system level validation of cryo-compressed vehicle storage on its way to a commercial product.\n\nHydrogen carriers based on nanostructured carbon (such as carbon buckyballs and nanotubes) have been proposed. However, since Hydrogen usually amounts up to ~3.0-7.0 wt% at 77K which is far from the value set by US department of Energy (6 wt% at nearly ambient conditions), it makes carbon materials poor candidates for hydrogen storage.\n\nH caged in a clathrate hydrate was first reported in 2002, but requires very high pressures to be stable. In 2004, researchers from Delft University of Technology and Colorado School of Mines showed solid H-containing hydrates could be formed at ambient temperature and 10s of bar by adding small amounts of promoting substances such as THF. These clathrates have a theoretical maximum hydrogen densities of around 5 wt% and 40 kg/m.\n\nA team of Russian, Israeli and German scientists have collaboratively developed an innovative technology based on glass capillary arrays for the safe infusion, storage and controlled release of hydrogen in mobile applications. The C.En technology has achieved the United States Department of Energy (DOE) 2010 targets for on-board hydrogen storage systems.\nDOE 2015 targets can be achieved using flexible glass capillaries and cryo-compressed method of hydrogen storage.\n\nHollow glass microspheres (HGM) can be utilized for controlled storage and release of hydrogen.\n\nUnlike mobile applications, hydrogen density is not a huge problem for stationary applications. As for mobile applications, stationary applications can use established technology:\n\nUnderground hydrogen storage is the practice of hydrogen storage in underground caverns, salt domes and depleted oil and gas fields. Large quantities of gaseous hydrogen have been stored in underground caverns by ICI for many years without any difficulties. The storage of large quantities of liquid hydrogen underground can function as grid energy storage. The round-trip efficiency is approximately 40% (vs. 75-80% for pumped-hydro (PHES)), and the cost is slightly higher than pumped hydro, if only a limited number of hours of storage is required. Another study referenced by a European staff working paper found that for large scale storage, the cheapest option is hydrogen at €140/MWh for 2,000 hours of storage using an electrolyser, salt cavern storage and combined-cycle power plant. The European project Hyunder indicated in 2013 that for the storage of wind and solar energy an additional 85 caverns are required as it cannot be covered by PHES and CAES systems. A German case study on storage of hydrogen in salt caverns found that if the German power surplus (7% of total variable renewable generation by 2025 and 20% by 2050) would be converted to hydrogen and stored underground, these quantities would require some 15 caverns of 500,000 cubic metres each by 2025 and some 60 caverns by 2050 – corresponding to approximately one third of the number of underground gas caverns currently operated in Germany. In the US, Sandia Labs are conducting research into the storage of hydrogen in depleted oil and gas fields, which could easily absorb large amounts of renewably produced hydrogen as there are some 2.7 million depleted wells in existence.\n\nPower to gas is a technology which converts electrical power to a gas fuel. There are two methods: the first is to use the electricity for water splitting and inject the resulting hydrogen into the natural gas grid; the second, less efficient method is used to convert carbon dioxide and hydrogen to methane, (see natural gas) using electrolysis and the Sabatier reaction. A third option is to combine the hydrogen via electrolysis with a source of carbon (either carbon dioxide or carbon monoxide from biogas, from industrial processes or via direct air-captured carbon dioxide) via biomethanation, where biomethanogens (archaea) consume carbon dioxide and hydrogen and produce methane within an anaerobic environment. This process is highly efficient, as the archaea are self-replicating and only require low-grade (60°C) heat to perform the reaction.\n\nAnother process has also been achieved by SoCalGas to convert the carbon dioxide in raw biogas to methane in a single electrochemical step, representing a simpler method of converting excess renewable electricity into storable natural gas. \n\nThe UK has completed surveys and is preparing to start injecting hydrogen into the gas grid as the grid previously carried 'town gas' which is a 50% hydrogen-methane gas formed from coal. Auditors KPMG found that converting the UK to hydrogen gas could be £150bn to £200bn cheaper than rewiring British homes to use electric heating powered by lower-carbon sources.\n\nExcess power or off peak power generated by wind generators or solar arrays can then be used for load balancing in the energy grid. Using the existing natural gas system for hydrogen, Fuel cell maker Hydrogenics and natural gas distributor Enbridge have teamed up to develop such a power to gas system in Canada.\n\nPipeline storage of hydrogen where a natural gas network is used for the storage of hydrogen. Before switching to natural gas, the German gas networks were operated using towngas, which for the most part (60-65%) consisted of hydrogen. The storage capacity of the German natural gas network is more than 200,000 GW·h which is enough for several months of energy requirement. By comparison, the capacity of all German pumped storage power plants amounts to only about 40 GW·h. The transport of energy through a gas network is done with much less loss (<0.1%) than in a power network (8%). The use of the existing natural gas pipelines for hydrogen was studied by NaturalHy\n\nTargets were set by the FreedomCAR Partnership in January 2002 between the United States Council for Automotive Research (USCAR) and U.S. DOE (Targets assume a 5-kg H storage system). The 2005 targets were not reached in 2005. The targets were revised in 2009 to reflect new data on system efficiencies obtained from fleets of test cars. The ultimate goal for volumetric storage is still above the theoretical density of liquid hydrogen.\n\nIt is important to note that these targets are for the hydrogen storage system, not the hydrogen storage material. System densities are often around half those of the working material, thus while a material may store 6 wt% H, a working system using that material may only achieve 3 wt% when the weight of tanks, temperature and pressure control equipment, etc., is considered.\n\nIn 2010, only two storage technologies were identified as having the potential to meet DOE targets: MOF-177 exceeds 2010 target for volumetric capacity, while cryo-compressed H exceeds more restrictive 2015 targets for both gravimetric and volumetric capacity (see slide 6 in ).\n\n\n"}
{"id": "36922522", "url": "https://en.wikipedia.org/wiki?curid=36922522", "title": "Ice segregation", "text": "Ice segregation\n\nIce segregation is the geological phenomenon produced by the formation of ice lenses, which induce erosion when moisture, diffused within soil or rock, accumulates in a localized zone. The ice initially accumulates within small collocated pores or pre-existing cracks, and, as long as the conditions remain favorable, continues to collect in the ice layer or ice lens, wedging the soil or rock apart. Ice lenses grow parallel to the surface and several centimeters to several decimeters (inches to feet) deep in the soil or rock. Studies between 1990 and present have demonstrated that rock fracture by ice segregation (i.e., the fracture of intact rock by ice lenses that grow by drawing water from their surroundings during periods of sustained subfreezing temperatures) is a more effective weathering process than the freeze-thaw process which older texts proposed.\n\nIce lenses play the key role in fracture of bedrock and frost induced heaving of soils, which are fundamental to weathering in cold regions. Frost heaving creates debris and dramatically shapes landscapes into complex patterns. Rock fracture in periglacial regions (alpine, subpolar and polar) has often been attributed to the freezing and volumetric expansion of water trapped within pores and cracks. However the majority of frost heaving and of bedrock fracture results instead from ice segregation in ice lenses in the near-surface frozen regions. Ice segregation results in rock fracture and frost heave.\n\nFrost heave is the process by which the freezing of water-saturated soil causes the deformation and upward thrust of the ground surface. This process can distort and crack pavement, damage the foundations of buildings and displace soil in regular patterns. Moist, fine-grained soil at certain temperatures is most susceptible to frost heaving.\n\nFrost heave is common in arctic tundra because the permafrost maintains ground frozen at depth and prevents snowmelt and rain from draining. As a result, conditions are optimal for deep ice lens formation with large ice accumulations and significant soil displacement.\n\nDifferential frost heave producing complex patterns will occur if the correct conditions exist. Feedback from one year's frost heave influences the effects in subsequent years. For example, a small increase in overburden will affect the depth of ice formation and heaving in the subsequent years. Time-dependent models of the frost heave indicate that over a long enough period the short-separation perturbations damp out, while mid-range perturbations grow and come to dominate the landscape.\n\nBands of sediment or glacial till have been observed below Antarctic ice sheets; these are believed to result from ice lenses forming in the debris. In the faster flowing glacial regions, the ice sheet is sliding over water saturated sediments (glacial till) or actually being floated upon a layer of water. The till and water serve to reduce friction between the base of the ice sheet and the bedrock. These subglacial waters come from surface water which seasonally drains from melting at the surface, as well as from ice-sheet base melting.\n\nIce lens growth within the bedrock below the glacier is projected during the summer months when there is ample water at the base of the glacier. Ice lenses will form within the bedrock, accumulating until the rock is sufficiently weakened that it shears or spalls off. Layers of rock along the interface between glaciers and the bedrock are freed, producing much of the sediments in these basal regions of glaciers. Since the rate of glacier movement is dependent upon the characteristics of this basal ice, research is ongoing to better quantify the phenomena.\n\nThe basic condition for ice segregation and frost heaving is existence of a region in soil or porous rock which is relatively permeable, is in a temperature range which allows the coexistence of ice and water (in a premelted state), and has a temperature gradient across the region.\n\nA key phenomenon for understanding ice segregation in soil or porous rock (also referred to as an ice lens due to its shape) is premelting, which is the development of a liquid film on surfaces and interfaces at temperatures significantly below their bulk melting temperature. The term premelting is used to describe the reduction in the melting temperature (below 0 °C) which results from the surface curvature of porous media confining water (the Gibbs-Thomson effect). Premelted water exists as a thin layer on the surface of ice. Under premelting conditions, ice and water can coexist at temperatures below -10 °C in a porous medium. The Gibbs-Thomson effect results in water migrating down a thermal gradient (from higher temperatures to lower temperatures); Dash states, “…material is carried to colder regions…” This can also be viewed energetically as favoring larger ice particles over smaller (Ostwald ripening). As a result, when conditions exist for ice segregation (ice lens formation) water flows toward the segregated ice and freezes on the surface, thickening the segregated ice layer.\n\nIt is possible to develop analytic models using these principles; they predict the following characteristics, which are consistent with field observations: \n\nRocks routinely contains pores of varying size and shape, regardless of origin or location. Rocks voids are essentially small cracks, and serve as the location from which the crack can propagate if the rock is placed in tension. If ice accumulates in a pore asymmetrically, the ice will place the rock in tension in a plane perpendicular to the ice accumulation direction. Hence the rock will crack along a plane perpendicular to the direction of ice accumulation, which is effectively parallel to the surface.\n\nWalder and Hallet developed models that predicts rock crack-growth locations and rates consistent with fractures actually observed in the field. Their model predicted that marble and granite grow cracks most effectively when the temperatures range from a −4 °C to −15 °C; in this range granite may develop fractures enclosing an ice 3 meters in length in a year. When the temperature is higher the ice which is formed does not apply enough pressure to cause the crack to propagate. When the temperature is below this range the water is less mobile and cracks grow more slowly.\n\nMutron confirmed that ice initially forms in pores and creates small microfractures parallel to the surface. As ice accumulates, the ice layer grows outward in what is frequently characterized as an ice-lens parallel to the surface. Ice will form in water-permeable rock in much the same way as it forms in soil. If the ice layer resulted from a cooling from a single direction (e.g., the top) the rock fracture tends to lie close to the surface(e.g., 1–2 cm in chalk). If the ice layer results from freezing from both sides (e.g., above and below) the rock fracture tends to lie deeper (e.g., 2-3.5 cm in chalk).\n"}
{"id": "351263", "url": "https://en.wikipedia.org/wiki?curid=351263", "title": "Indian summer", "text": "Indian summer\n\nAn Indian summer is a period of unseasonably warm, dry weather that sometimes occurs in autumn in the Northern Hemisphere. Indian summers are common in North America, Europe and Asia. The US National Weather Service defines this as weather conditions that are sunny and clear with above average temperatures, occurring September to November. It is usually described as occurring after a killing frost.\nLate-19th century Boston lexicographer Albert Matthews made an exhaustive search of early American literature in an attempt to discover who coined the expression. The earliest reference he found dated from 1851. He also found the phrase in a letter written in England in 1778, but discounted that as a coincidental use of the phrase.\n\nLater research showed that the earliest known reference to Indian Summer in its current sense occurs in an essay written in the United States in the late 1770s (probably 1778) by J. Hector St. John de Crevecoeur. The letter was first published in French. The essay remained unavailable in the United States until the 1920s.\n\nAlthough the exact origins of the term are uncertain, it was perhaps so-called because it was first noted in regions inhabited by Native Americans (\"Indians\"), or because the Native Americans first described it to Europeans, or it had been based on the warm and hazy conditions in autumn when Native Americans hunted.\n\nIn literature and history, the term is sometimes used metaphorically. The title of Van Wyck Brooks' \"New England: Indian Summer\" (1940) suggests an era of inconsistency, infertility, and depleted capabilities, a period of seemingly robust strength that is only an imitation of an earlier season of actual strength. William Dean Howells' 1886 novel \"Indian Summer\" uses the term to mean a time when one may recover some of the happiness of youth. The main character, jilted as a young man, leads a solitary life until he rediscovers romance in early middle age.\n\nIn British English, the term is used in the same way as in North America. In the UK, observers knew of the American usage from the mid-19th century onwards, and \"The Indian Summer of a Forsyte\" is the metaphorical title of the 1918 second volume of \"The Forsyte Saga\" by John Galsworthy. However, early 20th-century climatologists Gordon Manley and Hubert Lamb used it only when referring to the American phenomenon, and the expression did not gain wide currency in Great Britain until the 1950s. In former times such a period was associated with the autumn feast days of St. Martin and Saint Luke.\n\nIn the English translation of Boris Pasternak's Doctor Zhivago, the term is used to describe the unseasonably warm weather leading up to the Great October Socialist Revolution.\n\nSimilar weather conditions, with local variations also exist. A warm period in autumn is called \"Altweibersommer\" (: \"old women's summer\") in Germany, Austria, Switzerland, Lithuania, Hungary (Hungarian: \"vénasszonyok nyara\"), Estonia (Estonian: \"\"), Finland, and in a number of Slavic-language countries—for example, in Czech republic, Poland, Slovakia, Russia, Serbia, and Croatia—it is known as \"old woman's summer\" ( , , , , ). In Bulgaria, it is known as \"gypsy summer\" or \"poor man's summer\". In Sweden, there's \"Brittsommar\" (out of \"Birgitta\" and \"Britta\", having their name days around the time, October 7). In Gaelic Ireland, the phenomenon is called \"fómhar beag na ngéanna\" (little autumn of the geese).\n\nIn temperate parts of South America—such as southernmost Brazil, Argentina, Chile and Uruguay—the phenomenon is known as \"Veranico\", \"Veranito\" or \"Veranillo\" (literally, \"little summer\"), and usually occurs in early autumn between late April and mid-May, when it is known as \"Veranico de Mayo\" (\"May's little summer\") or as \"Veranito de San Juan\" (\"Saint John's little summer\"). Its onset and duration are directly associated with the occurrence of El Niño.\n\nIn other countries it is associated with autumnal name days or saint days such as Teresa of Ávila (Portugal, Spain and France), St. Martin's Summer (Spain, France, Italy, Portugal and Malta), Michaelmas summer (Serbia and Republika Srpska), St. Martin's Day (Netherlands), Bridget of Sweden in Sweden, and Saint Michael the Archangel in Wales. In Turkey it is called pastirma yazı, meaning pastrami summer, since the month of November was considered to be the best time to make pastrami.\n\n\n\n\n\n\n\n"}
{"id": "50727196", "url": "https://en.wikipedia.org/wiki?curid=50727196", "title": "Iranian Parliament Commission on Energy", "text": "Iranian Parliament Commission on Energy\n\nThe Iranian Parliament Committee on Energy (), or Energy Committee is a standing committee of the Islamic Consultative Assembly of Representatives. The Parliament Committee on Energy has general Oil, gas, electricity, water and electric dams and power plants, nuclear power and renewable energy and it can recommend funding appropriations for various governmental agencies, programs, and activities, as defined by House rules.\n"}
{"id": "25626847", "url": "https://en.wikipedia.org/wiki?curid=25626847", "title": "J. A. Baker", "text": "J. A. Baker\n\nJohn Alec Baker (1926 – 1987) was an English author, best known for \"The Peregrine,\" which won the Duff Cooper Prize in 1967.\n\nRobert Macfarlane deemed \"The Peregrine\" to be \"a masterpiece of twentieth-century non-fiction\" in his introduction to the New York Review Books edition of the book. On the back jacket cover of the same edition, James Dickey states that the book \"transcends any 'nature writing' of our time,\" while Barry Lopez declares the book to be \"one of the most beautifully written, carefully observed and evocative wildlife accounts I have ever read.\" Werner Herzog called it the \"one book I would ask you to read if you want to make films,\" and said elsewhere \"... it has prose of the caliber that we have not seen since Joseph Conrad.\"\n\nIn January 2018, \"The Peregrine\" was included by the Arts and Humanities Research Council in a list of 10 contenders to find the UK's favourite book about nature. When the result was announced at the end of January on the BBC \"Winterwatch\" programme it did not make the top three. The poll was topped by \"Fingers in the Sparkle Jar\" by Chris Packham.\n\nThe book recounts a single year from October to April (probably of 1962/3) from the author's ten-year obsession with the peregrines that wintered near his home in Chelmsford, Essex in eastern England. The writing is lyrically charged throughout, as the author's role of diligent observer gives way to a personal transformation, as Baker becomes, in the words of James Dickey on the book's jacket cover, \"a fusion of man and bird.\"\nBaker's only other book is 1969's \"The Hill of Summer,\" a lyrical and somewhat visionary account of summer's progress across the wilder parts of southern England. Though not as famous as \"The Peregrine,\" it enjoys much the same reputation for literary beauty and naturalist precision.\n\nIn 2011, Collins published a new edition of \"The Peregrine\" which also included \"The Hill of Summer\" and extracts from his diaries. The book includes an introduction by Mark Cocker and notes by John Fanshawe. Prior to this book, little was known about Baker's personal life but this has now changed. He was born on 6 August 1926, to engineering draughtsman Wilfred and his wife Pansy Baker, and lived in Chelmsford. His secondary education was at King Edward VI Grammar School, Chelmsford. His books are based largely on his observations of birds in the Essex countryside especially in the area from Chelmsford to the coast. He was unable to drive (despite working for The Automobile Association) and travelled by bicycle. From around 1970 he suffered from severe rheumatoid arthritis and contracted cancer as a result of the drugs taken to alleviate the arthritis. He died on 26 December 1987.\n\nThe University of Essex holds items associated with Baker. These include his diaries, drafts of his books, corrected proofs, correspondence and his optical equipment used when birdwatching. The archive was catalogued in 2016 by Hetty Saunders and is now open to all those interested in Baker's life and work.\n\nIn October 2017 Little Toller Books published the first biography of Baker, entitled \"My House of Sky - The life and work of J A Baker\" by Hetty Saunders. In addition to the biography, the book includes a selection of Baker's poetry, an article about the J. A. Baker Archive by John Fanshawe, with photographs of some of the items, and a section of photographs of Baker Country taken by local photographer, Christopher Matthews. The preface to the book is by Robert Macfarlane.\n\n"}
{"id": "16125599", "url": "https://en.wikipedia.org/wiki?curid=16125599", "title": "Ken Weber", "text": "Ken Weber\n\nKen J. Weber (November 28, 1943 – August 4, 2007) was a Rhode Island journalist and nature writer. He worked for the Providence Journal from 1971 until 1996, and continued to write a weekly nature article until his death. He has written many books about hiking. His most popular, \"Weekend Walks in Rhode Island\" is in its fourth edition, and is a popular guide for day hikes in the state. Ken held a staff position at the Audubon Society of Rhode Island and offered occasional nature talks.\n\n\n"}
{"id": "3548426", "url": "https://en.wikipedia.org/wiki?curid=3548426", "title": "Limu o Pele", "text": "Limu o Pele\n\nLimu o Pele or Pele's seaweed (Hawaiian, literally, \"seaweed of Pele\", after Pele the Hawaiian fire goddess of volcanoes) is a geological term for thin sheets and subsequently shattered flakes of brownish-green to near-colourless volcanic glass lava spatter that commonly resemble seaweed in appearance, that have been erupted from a volcano. Limu o Pele is formed when water is forced into and trapped inside lava, as when waves wash over the top of the exposed flows of the molten rock. The water boils and is instantly converted to steam, expanding to form bubbles within the lava. The lava rapidly cools and solidifies as the bubbles grow. The volcanic glass bubbles burst and are dispersed by the wind, showering flakes of glass downwind. \n\nLimu o Pele has been found around subaerial littoral volcanic cones and also at submarine volcanoes, for example, on the summit of Lōʻihi seamount. \n\n\n"}
{"id": "22391303", "url": "https://en.wikipedia.org/wiki?curid=22391303", "title": "Liquid nitrogen engine", "text": "Liquid nitrogen engine\n\nA liquid nitrogen vehicle is powered by liquid nitrogen, which is stored in a tank. Traditional nitrogen engine designs work by heating the liquid nitrogen in a heat exchanger, extracting heat from the ambient air and using the resulting pressurized gas to operate a piston or rotary motor. Vehicles propelled by liquid nitrogen have been demonstrated, but are not used commercially. One such vehicle, \"Liquid Air\" was demonstrated in 1902.\n\nLiquid nitrogen propulsion may also be incorporated in hybrid systems, e.g., battery electric propulsion and fuel tanks to recharge the batteries. This kind of system is called a hybrid liquid nitrogen-electric propulsion. Additionally, regenerative braking can also be used in conjunction with this system.\n\nIn June 2016 trials will begin in London, UK on supermarket J Sainsbury's fleet of food delivery vehicles: using a Dearman nitrogen engine to provide power for the cooling of food cargo when the vehicle is stationary and the main engine is off. Currently delivery lorries mostly have 2nd smaller diesel engines to power cooling when the main engine is off.\n\nLiquid nitrogen is generated by cryogenic or reversed Stirling engine coolers that liquefy the main component of air, nitrogen (N). The cooler can be powered by electricity or through direct mechanical work from hydro or\nwind turbines. \nLiquid nitrogen is distributed and stored in insulated containers. The insulation reduces heat flow into the stored nitrogen; this is necessary because heat from the surrounding environment boils the liquid, which then transitions to a gaseous state. Reducing inflowing heat reduces the loss of liquid nitrogen in storage. The requirements of storage prevent the use of pipelines as a means of transport. Since long-distance pipelines would be costly due to the insulation requirements, it would be costly to use distant energy sources for production of liquid nitrogen. Petroleum reserves are typically a vast distance from consumption but can be transferred at ambient temperatures.\n\nLiquid nitrogen consumption is in essence production in reverse. The Stirling engine or cryogenic heat engine offers a way to power vehicles and a means to generate electricity. Liquid nitrogen can also serve as a direct coolant for refrigerators, electrical equipment and air conditioning units. The consumption of liquid nitrogen is in effect boiling and returning the nitrogen to the atmosphere. \n\nIn the Dearman Engine the nitrogen is heated by combining it with the heat exchange fluid inside the cylinder of the engine.\n\nLiquid nitrogen production is an energy-intensive process. Currently practical refrigeration plants producing a few tons/day of liquid nitrogen operate at about 50% of Carnot efficiency. Currently surplus liquid nitrogen is produced as a byproduct in the production of liquid oxygen.\n\nAny process that relies on a phase-change of a substance will have much lower energy densities than processes involving a chemical reaction in a substance, which in turn have lower energy densities than nuclear reactions. Liquid nitrogen as an energy store has a low energy density. Liquid hydrocarbon fuels, by comparison, have a high energy density. A high energy density makes the logistics of transport and storage more convenient. Convenience is an important factor in consumer acceptance. The convenient storage of petroleum fuels combined with its low cost has led to an unrivaled success. In addition, a petroleum fuel is a primary energy source, not just an energy storage and transport medium.\n\nThe energy density — derived from nitrogen's isobaric heat of vaporization and specific heat in gaseous state — that can be realised from liquid nitrogen at atmospheric pressure and zero degrees Celsius ambient temperature is about 97 watt-hours per kilogram (W·h/kg). This compares with 100-250 W·h/kg for a lithium-ion battery and 3,000 W·h/kg for a gasoline combustion engine running at 28% thermal efficiency, 30 times the density of liquid nitrogen used at the Carnot efficiency.\n\nFor an isothermal expansion engine to have a range comparable to an internal combustion engine, a insulated onboard storage vessel is required. A practical volume, but a noticeable increase over the typical gasoline tank. The addition of more complex power cycles would reduce this requirement and help enable frost free operation. However, no commercially practical instances of liquid nitrogen use for vehicle propulsion exist.\n\nUnlike internal combustion engines, using a cryogenic working fluid requires heat exchangers to warm and cool the working fluid. In a humid environment, frost formation will prevent heat flow and thus represents an engineering challenge. To prevent frost build up, multiple working fluids can be used. This adds topping cycles to ensure the heat exchanger does not fall below freezing. Additional heat exchangers, weight, complexity, efficiency loss, and expense, would be required to enable frost free operation.\n\nHowever efficient the insulation on the nitrogen fuel tank, there will inevitably be losses by evaporation to the atmosphere. If a vehicle is stored in a poorly ventilated space, there is some risk that leaking nitrogen could reduce the oxygen concentration in the air and cause asphyxiation. Since nitrogen is a colorless and odourless gas that already makes up 78% of air, such a change would be difficult to detect.\n\nCryogenic liquids are hazardous if spilled. Liquid nitrogen can cause frostbite and can make some materials extremely brittle.\n\nAs liquid N2 is colder than 90.2K, oxygen from the atmosphere can condense. Liquid oxygen can spontaneously and violently react with organic chemicals, including petroleum products like asphalt.\n\nSince the liquid to gas expansion ratio of this substance is 1:694, a tremendous amount of force can be generated if liquid nitrogen is rapidly vaporized. In an incident in 2006 at Texas A&M University, the pressure-relief devices of a tank of liquid nitrogen were sealed with brass plugs. As a result, the tank failed catastrophically, and exploded.\n\nThe tanks must be designed to safety standards appropriate for a pressure vessel, such as ISO 11439.\n\nThe storage tank may be made of:\n\nThe fiber materials are considerably lighter than metals but generally more expensive. Metal tanks can withstand a large number of pressure cycles, but must be checked for corrosion periodically. Liquid nitrogen, LN2, is commonly transported in insulated tanks, up to 50 litres, at atmospheric pressure. These tanks, being non-pressurized tanks, are not subject to inspection. Very large tanks for LN2 are sometimes pressurized to less than 25 psi to aid in transferring the liquid at point of use.\n\nLike other non-combustion energy storage technologies, a liquid nitrogen vehicle displaces the emission source from the vehicle's tail pipe to the central electrical generating plant. Where emissions-free sources are available, net production of pollutants can be reduced. Emission control measures at a central generating plant may be more effective and less costly than treating the emissions of widely dispersed vehicles.\n\nLiquid nitrogen vehicles are comparable in many ways to electric vehicles, but use liquid nitrogen to store the energy instead of batteries. Their potential advantages over other vehicles include:\n\n\nThe principal disadvantage is the inefficient use of primary energy. Energy is used to liquefy nitrogen, which in turn provides the energy to run the motor. Any conversion of energy has losses. For liquid nitrogen cars, electrical energy is lost during the liquefication process of nitrogen.\n\nLiquid nitrogen is not available in public refueling stations; however, there are distribution systems in place at most welding gas suppliers and liquid nitrogen is an abundant by-product of liquid oxygen production.\n\nIn 2008, the US Patent Office granted a patent on a liquid nitrogen powered turbine engine. The turbine flash-expands liquid nitrogen that is sprayed into the high-pressure section of the turbine, and the expanding gas is combined with incoming pressurized air to produce a high-velocity stream of gas that is ejected from the back of the turbine. The resulting gas stream can be used to drive generators or other devices. The system has not been demonstrated to power electric generators of greater than 1 kW, however higher output may possible.\n\n\n\n"}
{"id": "3655849", "url": "https://en.wikipedia.org/wiki?curid=3655849", "title": "List of Lepidoptera that feed on chrysanthemums", "text": "List of Lepidoptera that feed on chrysanthemums\n\nChrysanthemum species are used as food plants by the larvae of a number of Lepidoptera species including:\n\n\n"}
{"id": "15825185", "url": "https://en.wikipedia.org/wiki?curid=15825185", "title": "List of North Carolina hurricanes (1900–1949)", "text": "List of North Carolina hurricanes (1900–1949)\n\nThe list of North Carolina hurricanes between 1900 and 1949 encompasses 75 tropical cyclones or their remnants that affected the U.S. state of North Carolina. Collectively, cyclones in North Carolina during that time period resulted in 53 total fatalities, as well as about $328 million in damage in 2008 USD. Tropical cyclone affected the state in all but nine seasons. In the 1916 season, five storms affected the state, which makes it the season with the most storms impacting the state.\n\nThe strongest hurricanes to affect the state during the time period were the 1933 Outer Banks hurricane and the 1944 Great Atlantic Hurricane, which produced winds of Category 3 status on the Saffir-Simpson Hurricane Scale within the state. The 1933 Outer Banks hurricane was the deadliest hurricane in the state during the time period, which killed 21 people. The remnants of a hurricane in 1940 dropped heavy rainfall in the state, which caused over $150 million in damage (2008 USD) from flooding and landslides. Most storms affected the state in September, though in the first half of the 20th century, cyclones impacted the state between May and December.\n\n\n\n\n\n\nThe table lists hurricanes by death tolls.\n\n"}
{"id": "9132995", "url": "https://en.wikipedia.org/wiki?curid=9132995", "title": "List of Peperomia diseases", "text": "List of Peperomia diseases\n\nThis is a list of diseases that affect the genus \"Peperomia\" which includes radiator plant, baby rubber tree (\"Peperomia obtusifolia\"), emerald ripple peperomia (\"Peperomia caperata\") and others.\n\n"}
{"id": "33072335", "url": "https://en.wikipedia.org/wiki?curid=33072335", "title": "List of ecoregions in Costa Rica", "text": "List of ecoregions in Costa Rica\n\nThe following is a list of ecoregions in Costa Rica. An ecoregion is an ecologically and geographically defined area that is smaller than a bioregion, which in turn is smaller than an ecozone. All three of these are larger than an ecosystem. Ecoregions cover relatively large areas of land or water, and contain characteristic, geographically distinct assemblages of natural communities and species. The biodiversity of flora, fauna and ecosystems that characterise an ecoregion tends to be distinct from that of other ecoregions. Costa Rica is a country in Central America, bordered by Nicaragua to the north, Panama to the southeast, the Pacific Ocean to the west, and the Caribbean Sea to the east. It contains 5% of the world's biodiversity.\n\nThe following terrestrial ecoregions have been identified in Costa Rica:\n\n\n"}
{"id": "36963899", "url": "https://en.wikipedia.org/wiki?curid=36963899", "title": "List of indigenous trees and shrubs of Lithuania", "text": "List of indigenous trees and shrubs of Lithuania\n\nThis is a list of the native woody plant species of Lithuania. The most common trees, shrubs, subshrubs, and liana species are marked with a star (*). The list contains 98 woody and semi-woody plant species.\n\n\n\n\n\n\n\n\n\n"}
{"id": "14746277", "url": "https://en.wikipedia.org/wiki?curid=14746277", "title": "List of international border rivers", "text": "List of international border rivers\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "28244418", "url": "https://en.wikipedia.org/wiki?curid=28244418", "title": "List of national parks of Ghana", "text": "List of national parks of Ghana\n\nGhana has a large system of 21 protected areas which include 7 national parks, 6 Resource Reserves, 2 Wildlife Sanctuaries, 1 Strict Nature Reserve and 5 coastal wetlands.\n\n\n\n"}
{"id": "57354084", "url": "https://en.wikipedia.org/wiki?curid=57354084", "title": "List of nuclear research reactors", "text": "List of nuclear research reactors\n\nThis is an annotated list of all the nuclear research reactors in the world, sorted by country, with operational status. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShut down:\n\nWorking:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder IAEA safeguards\n\nNot under IAEA safeguards\n\n\n\n\n\n\n\n\nA total of 98 nuclear research facilities, including:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3356530", "url": "https://en.wikipedia.org/wiki?curid=3356530", "title": "Maturity (geology)", "text": "Maturity (geology)\n\nIn petroleum geology, the maturity of a rock is a measure of its state in terms of hydrocarbon generation. Maturity is established using a combination of geochemical and basin modelling techniques.\n\nRocks with high total organic carbon, (termed source rocks), will alter under increasing temperature such that the organic molecules slowly mature into hydrocarbons (see diagenesis). Source rocks are therefore broadly categorised as \"immature\" (no hydrocarbon generation), \"sub-mature\" (limited hydrocarbon generation), \"mature\" (extensive hydrocarbon generation) and \"overmature\" (most hydrocarbons have been generated).\n\nThe maturity of a source rock can also be used as an indicator of its hydrocarbon \"potential\". That is, if a rock is sub-mature, then it has a much higher potential to generate further hydrocarbons than one that is overmature.\n\n\n\n"}
{"id": "35006655", "url": "https://en.wikipedia.org/wiki?curid=35006655", "title": "Mean High Water", "text": "Mean High Water\n\nMean High Water (MHW) is the average of all the high water heights observed over a period of several years. For example, in the United States this period spans 19 years and is referred to as the National Tidal Datum Epoch.\n\n\n"}
{"id": "11730924", "url": "https://en.wikipedia.org/wiki?curid=11730924", "title": "Merit order", "text": "Merit order\n\nThe merit order is a way of ranking available sources of energy, especially electrical generation, based on ascending order of price (which may reflect the order of their short-run marginal costs of production) together with amount of energy that will be generated. In a centralized management, the ranking is so that those with the lowest marginal costs are the first ones to be brought online to meet demand, and the plants with the highest marginal costs are the last to be brought on line. Dispatching generation in this way minimizes the cost of production of electricity. Sometimes generating units must be started out of merit order, due to transmission congestion, system reliability or other reasons.\n\nThe high demand for electricity during peak demand pushes up the bidding price for electricity, and the relatively inexpensive baseload power supply mix is supplemented by ‘peaking power plants,' which charge a premium for their electricity.\n\nIncreasing the supply of renewable energy tends to lower the average price per unit of electricity because wind energy and solar energy have very low marginal costs: they do not have to pay for fuel, and the sole contributors to their marginal cost is operational and maintenance. With cost often reduced by feed-in-tariff revenue, their electricity is as a result, less costly on the spot market than that from coal or natural gas, and transmission companies buy from them first. Moreover, solar energy is typically most abundant in the middle of the day, coinciding closely with peak demand in warm climates, so that it is in the best position to displace coal and natural gas electricity when those sources are charging the highest premium. Solar and wind electricity therefore substantially reduce the amount of highly priced peak electricity that transmission companies need to buy, reducing the overall cost. A study by the Fraunhofer Institute found that this \"merit order effect\" had allowed solar power to reduce the price of electricity on the German energy exchange by 10% on average, and by as much as 40% in the early afternoon, in 2007; as more solar electricity is fed into the grid, peak prices will come down even further. By 2006, the \"merit order effect\" meant that the savings in electricity costs to German consumers more than offset for the support payments paid for renewable electricity generation.\n\nA 2013 study estimates the merit order effect of both wind and photovoltaic electricity generation in Germany between the years 2008 and 2012. For each additional GWh of renewables fed into the grid, the price of electricity in the day-ahead market is reduced by 0.11–0.13¢/kWh. The total merit order effect of wind and photovoltaics ranges from 0.5¢/kWh in 2010 to more than 1.1¢/kWh in 2012.\n\nThe zero marginal cost of wind energy does not, however, translate, into zero marginal cost of peak load electricity in a competitive open electricity market system as wind supply cannot be dispatched to meet peak demand. The purpose of the merit order was to enable the lowest net cost electricity to be dispatched first thus minimising overall electricity system costs to consumers. Intermittent wind might be able to supply this economic function provided peak wind supply and peak demand coincide both in time and quantity. On the other hand, solar energy tends to be most abundant during peak energy demand in warm climates, maximizing its ability to displace coal and natural gas power.\n\nA study by the Fraunhofer Institute in Karlsruhe, Germany found that windpower saves German consumers €5billion a year. It is estimated to have lowered prices in European countries with high wind generation by between 3 and 23€/MWh. On the other hand, renewable energy in Germany increased the price for electricity, consumers there now pay 52.8 €/MWh more only for renewable energy (see German Renewable Energy Sources Act), average price for electricity in Germany now is increased to 26¢/kWh. Increasing electrical grid costs for new transmission, market trading and storage associated with wind and solar are not included in the marginal cost of power sources, instead grid costs are combined with source costs at the consumer end.\n\n"}
{"id": "13352752", "url": "https://en.wikipedia.org/wiki?curid=13352752", "title": "Mills Creek", "text": "Mills Creek\n\nMills Creek may refer to:\n\n"}
{"id": "42429011", "url": "https://en.wikipedia.org/wiki?curid=42429011", "title": "Minima naturalia", "text": "Minima naturalia\n\nMinima naturalia (\"natural minima\") were theorized by Aristotle as the smallest parts into which a homogeneous natural substance (e.g., flesh, bone, or wood) could be divided and still retain its essential character. In this context, \"nature\" means formal nature. Thus, \"natural minimum\" may be taken to mean \"formal minimum\": the minimum amount of matter necessary to instantiate a certain form.\n\nSpeculation on \"minima naturalia\" in late Antiquity, in the Islamic world, and by Scholastic and Renaissance thinkers in Europe provided a conceptual bridge between the atomism of ancient Greece and the mechanistic philosophy of early modern thinkers like Descartes, which in turn provided a background for the rigorously mathematical and experimental atomism of modern science.\n\nAccording to Aristotle, the Pre-Socratic Greek philosopher Anaxagoras had taught that every thing, and every portion of a thing, contains within itself an infinite number of like and unlike parts. For example, Anaxagoras maintained that there must be blackness as well as whiteness in snow; how, otherwise, could it be turned into dark water? Aristotle criticized Anaxagoras' theory on multiple grounds, among them the following:\n\nUnlike the atomism of Leucippus, Democritus, and Epicurus, and also unlike the later atomic theory of John Dalton, the Aristotelian natural minimum was not conceptualized as physically indivisible--\"atomic\" in the contemporary sense. Instead, the concept was rooted in Aristotle's hylomorphic worldview, which held that every physical thing is a compound of matter (Greek \"hyle\") and a substantial form (Greek \"morphe\") that imparts its essential nature and structure. For instance, a rubber ball for a hylomorphist like Aristotle would be rubber (matter) structured by spherical shape (form).\n\nAristotle's intuition was that there is some smallest size beyond which matter could no longer be structured as flesh, or bone, or wood, or some other such organic substance that (for Aristotle, living before the microscope) could be considered homogeneous. For instance, if flesh were divided beyond its natural minimum, what would remain might be some elemental water, and smaller amounts of the other elements (e.g., earth) with which water was thought to mix to form flesh. But whatever was left, the water (or earth, etc.), would no longer have the formal \"nature\" of flesh in particular – the remaining matter would have the form of water (or earth, etc.) rather than the substantial form of flesh.\n\nThis is suggestive of modern chemistry, in which, e.g., a bar of gold can be continually divided until one has a single atom of gold, but further division of that atom of gold yields only subatomic particles (electrons, quarks, etc.) which are no longer the chemical element gold. Just as water alone is not flesh, electrons alone are not gold. Although suggestive, the parallel is not exact: the Aristotelian concept of the natural minimum of a substance is not a direct anticipation of the modern concept of an atom of a certain chemical element.\n\nAristotle's brief comments on \"minima naturalia\" in the \"Physics\" and \"Meteorology\" prompted further speculations by later philosophers. The idea was taken up by John Philoponus and Simplicius of Cilicia in late Antiquity and by the Islamic Aristotelian Averroes (Ibn Rushd).\n\n\"Minima naturalia\" were discussed by Scholastic and Renaissance thinkers including Roger Bacon, Albertus Magnus, Thomas Aquinas, Giles of Rome, Siger of Brabant, Boethius of Dacia, Richard of Middleton, Duns Scotus, John of Jandun, William of Ockham, William Alnwick, Walter Bury, Adam de Wodeham, Jean Buridan, Gregory of Rimini, John Dumbleton, Nicole Oresme, John Marsilius Inguen, John Wycliffe, Albert of Saxony, Facinus de Ast, Peter Alboinis of Mantua, Paul of Venice, Gaetano of Thiene, Alessandro Achillini, Luis Coronel, Juan de Celaya, Domingo de Soto, Didacus de Astudillo, Ludovicus Buccaferrea, Francisco de Toledo, and Benedict Pereira. Of this list, the most influential Scholastic thinkers on \"minima naturalia\" were Duns Scotus and Gregory of Rimini.\n\nA chief theme in later commentary is reconciling \"minima naturalia\" with the general Aristotelian principle of infinite divisibility. Commentators like Philoponus and Aquinas reconciled these aspects of Aristotle's thought by distinguishing between mathematical and \"natural\" divisibility. For example, in his commentary on Aristotle's \"Physics\", Aquinas writes of natural minima that, \"although a body, considered mathematically, is divisible to infinity, the natural body is not divisible to infinity. For in a mathematical body nothing but quantity is considered. And in this there is nothing repugnant to division to infinity. But in a natural body the form also is considered, which form requires a determinate quantity and also other accidents. Whence it is not possible for quantity to be found in the species of flesh except as determined within some termini.\"\n\nIn the early modern period, Aristotelian hylomorphism fell out of favor with the rise of the \"mechanical philosophy\" of thinkers like Descartes and John Locke, who were more sympathetic to the ancient Greek atomism of Democritus than to the natural minima of Aristotle. However, the concept of \"minima naturalia\" continued to shape philosophical thinking even among these mechanistic philosophers in the transitional centuries between the Aristotelianism of the medieval Scholastics and the worked-out atomic theory of modern scientists like Dalton.\n\nThe mechanist Pierre Gassendi discussed \"minima naturalia\" in the course of expounding his opposition to Scholastic Aristotelianism, and his own attempted reconciliation between the atomism of Epicurus and the Catholic faith. Aristotle's \"mininima naturalia\" became \"corpuscles\" in the alchemical works of Geber and Daniel Sennert, who in turn influenced the corpuscularian alchemist Robert Boyle, one of the founders of modern chemistry. Boyle occasionally referred to his postulated corpuscles as \"minima naturalia\".\n"}
{"id": "20496138", "url": "https://en.wikipedia.org/wiki?curid=20496138", "title": "Ministry of Energy and Mineral Development (Uganda)", "text": "Ministry of Energy and Mineral Development (Uganda)\n\nThe Ministry of Energy and Mineral Development, also Ministry of Energy, Oil and Mineral Development is one of the governmental bodies of Uganda. The ministry has the function of developing and implementing policies related to electricity, minerals, petroleum and petroleum products. The ministry is part of the national cabinet and is headed by a cabinet minister. The current Cabinet Minister of Energy is Engineer Irene Nafuna Muloni.\n\nThe headquarters of the ministry are located in Amber House on Kampala Road in the Kampala Central Division in Kampala, the capital and largest city of the country. The coordinates of the headquarters are 0°18'48.0\"N, 32°34'55.0\"E (Latitude:0°18'48.0\"N; Longitude:32°34'55.0\"E)\n\nThe ministry is responsible for energy policy, investments in mining, and the establishment of new power generating infrastructure using hydro power, thermal power, solar power, wind power and nuclear power. The two largest power development projects in the country are the 183 megawatt Isimba Hydroelectric Power Station, expected online in 2016, and the 600 megawatt Karuma Hydroelectric Power Station, expected online in 2018. According to a 2012 published report, Uganda was considering the use of nuclear energy for electricity generation.\n\n\nIt is expected that after Isimba and Karuma come on-line, construction of Ayago Power Station will begin. Uganda is increasingly developing other energy sources besides hydroelectricity, including evaluation of nuclear energy. The energy generated is expected to be used internally through the expansion of electricity access in Uganda from estimated 20 percent in 2016 (about 900,000 subscribers) to 40 percent in 2020 (about 3 million subscribers). Any surplus energy is expected to be sold to neighboring countries including South Sudan and DR Congo.\n\n\n\n"}
{"id": "498611", "url": "https://en.wikipedia.org/wiki?curid=498611", "title": "Nile Delta", "text": "Nile Delta\n\nThe Nile Delta ( ' or simply ') is the delta formed in Northern Egypt (Lower Egypt) where the Nile River spreads out and drains into the Mediterranean Sea. It is one of the world's largest river deltas—from Alexandria in the west to Port Said in the east, it covers of Mediterranean coastline and is a rich agricultural region. From north to south the delta is approximately in length. The Delta begins slightly down-river from Cairo.\n\nThe Nile Delta is an area of the world that lacks detailed ground truth data and monitoring stations. Despite the economic importance of the Nile Delta, it could be considered as one of the most data-poor regions with respect to sea level rise.\n\nFrom north to south, the delta is approximately in length. From west to east, it covers some of coastline. The delta is sometimes divided into sections, with the Nile dividing into two main distributaries, the Damietta and the Rosetta, flowing into the Mediterranean at port cities with the same name. In the past, the delta had several distributaries, but these have been lost due to flood control, silting and changing relief. One such defunct distributary is Wadi Tumilat.\n\nThe Suez Canal is east of the delta and enters the coastal Lake Manzala in the north-east of the delta. To the north-west are three other coastal lakes or lagoons: Lake Burullus, Lake Idku and Lake Mariout.\n\nThe Nile is considered to be an \"arcuate\" delta (arc-shaped), as it resembles a triangle or flower when seen from above. Some scholars such as Aristotle have written that the delta was constructed for agricultural purposes due to the drying of the region of Egypt. Although such an engineering feat would be considered equivalent to a wonder of the ancient world, there is insufficient evidence to determine conclusively whether the delta is man-made or was formed naturally.\n\nIn modern day, the outer edges of the delta are eroding, and some coastal lagoons have seen increasing salinity levels as their connection to the Mediterranean Sea increases. Since the delta no longer receives an annual supply of nutrients and sediments from upstream due to the construction of the Aswan Dam, the soils of the floodplains have become poorer, and large amounts of fertilizers are now used. Topsoil in the delta can be as much as in depth.\n\nPeople have lived in the Delta region for thousands of years, and it has been intensively farmed for at least the last five thousand years. The Delta used to flood annually, but this ended with the construction of the Aswan Dam.\n\nRecords from ancient times (such as by Pliny the Elder) show that the delta had seven distributaries or branches, (from east to west): \n\nThere are now only two main branches, due to flood control, silting and changing relief: the Damietta (corresponding to the Phatnitic) to the east, and the Rosetta (corresponding to the Bolbitine) in the western part of the Delta.\n\nThe Rosetta Stone was found in the Nile Delta in 1799 in the port city of Rosetta (anglicized name of Rashid). The delta was a major constituent of Lower Egypt. There are many archaeological sites in and around the Nile Delta.\n\nAbout 39 million people live in the Delta region. Outside of major cities, population density in the delta averages or more. Alexandria is the largest city in the delta with an estimated population of more than 4.5 million. Other large cities in the delta include Shubra El Kheima, Port Said, El Mahalla El Kubra, Mansura, Tanta, and Zagazig.\n\nDuring autumn, parts of the Nile River are red with lotus flowers. The Lower Nile (North) and the Upper Nile (South) have plants that grow in abundance. The Upper Nile plant is the Egyptian lotus, and the Lower Nile plant is the Papyrus Sedge (\"Cyperus papyrus\"), although it is not nearly as plentiful as it once was, and is becoming quite rare.\n\nSeveral hundred thousand water birds winter in the delta, including the world’s largest concentrations of little gulls and whiskered terns. Other birds making their homes in the delta include grey herons, Kentish plovers, shovelers, cormorants, egrets and ibises.\n\nOther animals found in the delta include frogs, turtles, tortoises, mongooses, and the Nile monitor. Nile crocodiles and hippopotamus, two animals which were widespread in the delta during antiquity, are no longer found there. Fish found in the delta include the flathead grey mullet and soles.\n\nThe Delta has a hot desert climate (Köppen: BWh) as the rest of Egypt, but its northernmost part, as is the case with the rest of the northern coast of Egypt which is the wettest region in the country, has relatively moderate temperatures, with highs usually not surpassing in the summer. Only of rain falls on the delta area during an average year, and most of this falls in the winter months. The delta experiences its hottest temperatures in July and August, with maximum average of . Winter temperatures are normally in the range of at nights to in the daytime. With cooler temperatures and some rain, the Nile Delta region becomes quite humid during the winter months.\n\nFurthermore, Egypt’s Mediterranean coastline is being swallowed up by the sea because of global warming and the rise of the sea level, and the lack of sediments being deposited since the construction of the Aswan Dam, in some places as much as a year. As the polar ice caps melt, much of the northern delta, including the ancient port city of Alexandria, will disappear under the Mediterranean. Even a rise in sea level will affect about 6.6% of the total land cover area in the Nile Delta region; At 1 m SLR, an estimated 887 thousand people will be at risk of flooding and displacement and about of vegetation, wetland, cropland, and of urban area land would be destroyed, flooding approximately . The Nile Delta is turning into a salty wasteland by rising sea waters, forcing some farmers off their lands and others to import sand in a desperate bid to turn back the tide. Experts warn that global warming will have a major effect in the delta on agriculture resources, tourism and human migration besides shaking the region's fragile ecosystems. Environmental damage to the Nile Delta is not yet one of Egypt's priorities, but experts say if the situation continues to deteriorate, it will trigger massive food shortages which could turn seven million people into \"climate refugees\" by the end of the century if climate change remains unmitigated.\n\nIn addition to the effect that the dams on the Nile have had on the delta, there has been a tremendous human effect internally with the rise of fisheries, the increased salt production, the building of roads, the heightened agricultural production, and the natural increase in human population in the region.\n\n\nLarge cities located in the Nile Delta:\n\n"}
{"id": "1365774", "url": "https://en.wikipedia.org/wiki?curid=1365774", "title": "OPeNDAP", "text": "OPeNDAP\n\nOPeNDAP is an acronym for \"Open-source Project for a Network Data Access Protocol,\" an endeavor focused on enhancing the retrieval of remote, structured data through a Web-based architecture and a discipline-neutral Data Access Protocol (DAP). Widely used, especially in Earth science, the protocol is layered on HTTP, and its current specification is DAP4, though the previous DAP2 version remains broadly used. Developed and advanced (openly and collaboratively) by the non-profit OPeNDAP, Inc., DAP is intended to enable remote, selective data-retrieval as an easily invoked Web service. OPeNDAP, Inc. also develops and maintains zero-cost (reference) implementations of the DAP protocol in both server-side and client-side software. \n\n\"OPeNDAP\" often is used in place of \"DAP\" to denote the protocol but also may refer to an entire DAP-based data-retrieval architecture. Other DAP-centered architectures, such as THREDDS and ERDDAP, exhibit significant interoperability with one another as well as with systems employing OPeNDAP's own (open-source) servers and software.\n\nA DAP client can be an ordinary browser or even a spreadsheet, though with limited functionality (see OPeNDAP's Web page on Available Client Software). More typically, DAP clients are:\n\nRegardless of their types, and whether developed commercially or by an end-user, clients almost universally link to DAP servers through \"libraries\" that implement the DAP2 or DAP4 protocol in one language or another. OPeNDAP offers open-source libraries in C++ and Java, but many clients rely on community developed libraries such as PyDAP or, especially, the NetCDF suite. Developed and maintained by the Unidata Program at the UCAR in multiple programming languages, all NetCDF libraries include embedded capabilities for retrieving (array-style) data from DAP servers.\n\nA data-using client references a data set by its URL and requests metadata or content by issuing (usually through an embedded DAP library) an HTTP request to a DAP server. Content requests usually are \"preceded\" by requests for metadata describing the structure and other details about the referenced data set. With this information, the client may construct DAP constraint expressions to retrieve specific content (i.e., subsets) from the source. OPeNDAP servers offer various types of responses, depending on the specific form of the client's request, including XML, JSON, HTML and ASCII. In response to requests for \"content\", OPeNDAP servers can respond with multi-part mime documents that include a binary portion with NetCDF or DAP-native encoding. (These binary forms offer compact means to deliver large volumes of content, and the DAP-native form may even be streamed if desired.)\n\nOPeNDAP's software for building DAP servers (on top of Apache) is dubbed Hyrax and includes \"adapters\" that facilitate serving a wide variety of source data. DAP servers most frequently enable (remote) access to (large) HDF or NetCDF files, but the source data can exist in databases or other formats, including user-defined ones. When source data are organized as files, DAP retrievals enable, via subsetting, finer-grained access than does the FTP. Furthermore, OPeNDAP servers can aggregate subsets from multiple files for delivery in a single retrieval. Taken together, subsetting, aggregation and streaming can yield substantial data-access efficiencies, even in the presence of slow networks.\n\nOPeNDAP and other DAP servers are used operationally in government agencies, including NASA and NOAA, for providing access to Earth science data, including satellite imagery and other high-volume information sources. The DAP data model embraces a comprehensive set of data structures, including multidimensional arrays and nested sequences (i.e., records), complemented by a correspondingly rich set of constraint expressions. Hence the OPeNDAP data-retrieval architecture has demonstrated utility across a broad range of scientific data types, including data generated via simulations and data generated via observations (whether remotely sensed or measured in situ).\n\n"}
{"id": "29474315", "url": "https://en.wikipedia.org/wiki?curid=29474315", "title": "Optical conductivity", "text": "Optical conductivity\n\nThe optical conductivity is a material property, which links the current density to the electric field for general frequencies. In this sense, this linear response function is a generalization of the electrical conductivity, which is usually considered in the static limit, i.e., for a time-independent (or sufficiently slowly varying) electric field. While the static electrical conductivity is vanishingly small in insulators (such as Diamond or Porcelain), the optical conductivity always remains finite in some frequency intervals (above the optical gap in the case of insulators); the total optical weight can be inferred from sum rules. The optical conductivity is closely related to the dielectric function, the generalization of the dielectric constant to arbitrary frequencies. \n\nOnly in the simplest case (coarse-graining, long-wavelength limit, cubic symmetry of the material), these properties can be considered as (complex-valued) scalar functions of the frequency only. Then, the electric current density formula_1 (a three-dimensional vector), the scalar optical conductivity formula_2 and the electric field vector formula_3 are linked by the equation \n\nwhile the dielectric function formula_5 relates the electrical displacement to the electric field:\n\nIn SI units, this implies the following connection between the two linear response functions:\n\nwhere formula_8 is the vacuum permittivity and formula_9 denotes the imaginary unit.\n\nThe optical conductivity is most often measured in the optical frequency ranges via the reflectivity of polished samples under normal incidence (in combination with a Kramers–Kronig analysis) or using variable incidence angles. For samples that can be prepared in thin slices, higher precision is usually obtainable using optical transmission experiments. In order to get more complete information about the electronic properties of the material of interest, such measurements have to be combined with other techniques that work in remaining frequency ranges, e.g., in the static limit or at microwave frequencies.\n\n"}
{"id": "17193413", "url": "https://en.wikipedia.org/wiki?curid=17193413", "title": "Province flowers of Sweden", "text": "Province flowers of Sweden\n\nProvince flowers are species of plants selected to represent each province of Sweden. The origin of province flowers came from the American idea of state flowers, and was brought to Sweden by August Wickström and Paul Petter Waldenström in 1908. Waldenström published the proposal to introduce province flowers in the May 288, 1908 edition of the newspaper \"Stockholms Dagblad\", and requested suggestions of species from the country's botanics. A list was put together on June 7, 1908, by professor Veit B. Wittrock from the Botanical Garden in Stockholm. Scania and Hälsingland violently opposed the plants that were selected to represent them; Scania was given European Beech but wanted oxeye daisy, while Hälsingland was given Scots Pine but wanted flax. Erik E:son Hammar, a pastor and politician in Sweden, granted the two provinces' wish to change their province flowers in 1909. There is still debate amongst several other provinces over which species should represent them and they have therefore been given two province flowers.\n\nVilda blommor i Sverige - Flowers in Sweden - Sweden wildflowers and native plants - information and pictures<nowiki>]</nowiki>]\n\n"}
{"id": "56183922", "url": "https://en.wikipedia.org/wiki?curid=56183922", "title": "Renewable Energy Research Centre", "text": "Renewable Energy Research Centre\n\nRenewable Energy Research Centre is an autonomous national research institute, under the University of Dhaka, that carries out research and plans water resource management projects in Bangladesh and is located in Dhaka, Bangladesh. It has a particular focus on solar energy and works with the Bangladesh Solar Energy Society.\n\nRenewable Energy Research Centre was established in 1986 under the Faculty of Science of the University of Dhaka. It is managed by an advisory board that is chaired by the Vice-Chancellor of University of Dhaka. It specialises on solar energy research and provides MSc, MPhil, and PhD degrees. The centre opened an energy park in 1988 on its premises. In 2008 a 1.1kW rooftop solar grid was installed in the research centre with the financial support of the Ministry of Science and Technology. Renewable Energy Resource Assessment is a project under the Renewable Energy Research Centre and is a project of United Nations Environment Programme.\n"}
{"id": "51813215", "url": "https://en.wikipedia.org/wiki?curid=51813215", "title": "Saint Pierre River", "text": "Saint Pierre River\n\nSaint Pierre River may refer to:\n\n"}
{"id": "29800160", "url": "https://en.wikipedia.org/wiki?curid=29800160", "title": "Second Fiji Expedition", "text": "Second Fiji Expedition\n\nThe Second Fiji Expedition was an 1859 United States Navy operation against the native warriors of Seru Epenisa Cakobau on the island of Waya in Fiji. Following the death of two American traders on Waya, the Pacific Squadron launched a punitive expedition against the Wayans and defeated them in a pitched battle at the village of Somatti.\nIn the summer of 1859, two American citizens on Waya were killed and canibalized by the natives so when word of the incident reached the American consulate at Ovalau, the Pacific Squadron sent the sloop-of-war . The warship arrived at Ovalau on 2 October 1859 and it was decided that in order to get to Waya a vessel with a shallower draft was needed. To solve this problem Commander Sinclair chartered the schooner \"Mechanic\" and placed her under the command of veteran Lieutenant Charles Caldwell. A force of 10 marines, forty sailors and a 12-pounder howitzer were mustered for the landing on Waya.\n\nA few Fijian guides and three American merchant sailors also participated. One of whom was Captain Josiah Knowles of the clipper ship \"Wild Wave\" which was wrecked off Oeno Island. Knowles and 40 others were marooned on the island until being rescued by \"Vandalia\" and taken to Fiji.\n\nThe expedition left Ovalau on 6 October 1859 and sailed west around the northern end of the main island of Viti Levu to Waya. During their passage to the island, Lieutenant Caldwell’s men heard many stories from towns and villages about the warriors of Waya. A letter was also received from the Wayan chiefs responsible for the deaths of the two American traders. The message said, “\"Do you suppose we have killed the two white men for nothing? No, we killed them and we have eaten them. We are great warriors, and we delight in war.\"” Caldwell later wrote, “\"...and woe to the members of any strange tribe that falls into their hands... to be clubbed to death and eaten is the only alternative for the captive. It is not a matter of surprise that the tribes along our route learned with feelings of satisfaction the nature of our expedition.\"”\n\nAt 03:00 on 9 October, the Americans made a landing and marched inland toward the village of Somatti over tropical and mountainous terrain. While climbing through the mountains, the 12-pounder was destroyed and left behind when it fell down the side of a hill as the expedition tried to pull it up.\nWhen the column reached Somatti, it was daytime and over 300 native warriors were positioned in front of the village for defense. The Wayans wore white robes and were armed with clubs, rocks, spears, bows and some muskets. The Americans had swords and carbine rifles and the battle began when Lieutenant Caldwell ordered a flanking maneuver on the left side of the mass of warriors. This routed the natives and they dispersed themselves amongst the town or fled into the jungle. After, Master's Mate John K. Bartlett, who led a group of sailors, sang \"Red, White and Blue\" and let out three cheers before charging and capturing the village.\n\nThe crew of the 12-pounder, with no gun to fire, took charge of burning the village and over 115 huts were destroyed. Marines under Lieutenant Alan Ramsey participated by providing a rearguard for the sailors, they repulsed a final Wayan attack from the jungle after they had regrouped. In all fourteen warriors, including the two chiefs, were counted dead after a fierce half an hour battle. At least 36 others were wounded. Two marines were wounded by musketry but survived, two sailors were hurt badly by rocks, one other marine was hit in the leg with an arrow and a sailor from \"Wild Wave\" was hurt as well.\n\nAfter the battle the Americans took until 16 October to return to the coast where the \"Mechanic\" was waiting. They stopped at friendly Fijian fishing villages and spread the news of their victory. Caldwell noted that two ramrods and one bayonet were lost during the march, and a large amount of ammunition was used in battle. The lieutenant received much credit for the operation which is considered one of the most impressive military campaigns launched by the United States in the South Pacific during the nineteenth century.\n\n"}
{"id": "14628602", "url": "https://en.wikipedia.org/wiki?curid=14628602", "title": "Silk Letter Movement", "text": "Silk Letter Movement\n\nThe Silk Letter Movement (تحریکِ ریشمی رومال) refers to a movement organised by the Deobandi leaders between 1913 and 1920, aimed at freeing India from the British rule by allying with Ottoman Turkey, Imperial Germany, and Afghanistan. The plot was uncovered by Punjab CID with the capture of letters from Ubaidullah Sindhi, one of the Deobandi leaders then in Afghanistan, to Mahmud al Hasan, another leader then in Persia. The letters were written in silk cloth, hence the name.\n\nMuhammad Mian Mansoor Ansari went to Hejaz with Mahmood Hasan in September 1915. He returned to India in April 1916 with Ghalib Nama (Silk Letter) which he showed to freedom fighters in India and the autonomous area and then took it to Kabul where he reached in June 1916.\n\nWith the onset of World War I, Ubaidullah Sindhi and Mehmud Hasan (principal of the Darul Uloom Deoband) had proceeded to Kabul in October 1915 with plans to initiate a Muslim insurrection in the tribal belt of India. For this purpose, Ubaid'Allah was to propose that the Amir of Afghanistan declares war against Britain while Mahmud al Hasan sought German and Turkish help. Hasan proceeded to Hijaz. Ubaid Allah, in the meantime, was able to establish friendly relations with Amir. As the plans unfolded in what came to be called the Silk Letter Movement, Ubaid'Allah was able to establish friendly relations with Amir. At Kabul, Ubaid'Allah, along with some students who had preceded him to make way to Turkey to join the Caliph's \"Jihad\" against Britain, decided that the pan-Islamic cause was to be best served by focussing on the Indian Freedom Movement.\n\nThe Berlin-Indian committee (which became the \"Indian Independence Committee\" after 1915) also resulted in an Indo-German-Turkish mission to the Indo-Iranian border to encourage the tribes to strike against British interests. This group met the Deobandis in Kabul in December 1915. The mission, along with bringing members of the Indian movement right to India's border, also brought messages from the Kaiser, Enver Pasha and the displaced Khedive of Egypt, Abbas Hilmi expressing support for Pratap's mission and inviting the Amir to move against India\n\nThe mission's immediate aim was to rally the Amir against British India and to obtain from the Afghan Government a right of free passage. But after the leakage of the plan, the top Deobandi leaders were arrested—Mahmudul-Hasan was arrested from Makkah and together with Husayn Ahmad, was exiled to Malta, from where, he was released in his later stages of T.B.\n\nIn January 2013, The President of India, Pranab Mukherjee released a commemorative postage stamp on the Silk Letter Movement to acknowledge and appreciate the sacrifices of such groups for the Indian independence movement.\n\n\n"}
{"id": "14560232", "url": "https://en.wikipedia.org/wiki?curid=14560232", "title": "Syed Yahya Shah", "text": "Syed Yahya Shah\n\nSyed Yahya Shah سيد يحي (also called Aga Yahya) was a Pakistani politician and stayed as a member of the Gilgit–Baltistan Legislative Assembly from 1975 to 1980.\n\nShah was born in Minapin Pakistan. He acquired his early education in Nomal and Gilgit, and attended high school in Astor and Kashmir. He then studied at Edwardes College in Peshawar. On return to Gilgit he taught at High School Gilgit.\n\nThe people of Nagar elected him to become he first elected Member of Legislative Assembly of Gilgit–Baltistan from Nagar.\n\nHe actively played a role in making Hunza–Nagar a District in Gilgit–Baltistan.\n\nIn addition to his political career, Syed Yahya worked as pioneer nature conservation activist in Gilgit–Baltistan. He was the first person to introduce Trophy Hunting Programme(THP) in Bar Valley in Nagar, which was supported by IUCN, WWF and Government of Pakistan and replicated by other communities and villages of Gilgit–Baltistan. He saved several snow leopards in Nagar when they were caught to kill by villagers.\n\nSyed has also worked on various charity projects to improve his home region. He initiated the connecting a warm spring in Diater Mountains in the Karakoram to Bar Valley in Nagar in collaboration with WWF which not only saved fuel energy but also decreased diseases in women caused by the washing of clothes in cold water during cold weather. As Minapin Community Leader, in Minapin village he motivated Aga Khan Rural Support Programme to initiate a project which restored a deserted mountain called Khaiadar where the canal irrigating to the pastures and agricultural fields at this mountain was cut off from the source of water-glacier by climate changed recession of glacier. He led the community to install a pipeline which reconnected broken water channel after 150 years of desertification. Syed Yahya Shah participated in a historical documentation of customary laws in nature conservation in Gilgit–Baltistan, a project of IUCN and the government of Pakistan.\n\nSyed Yahya Shah was awarded The Quid-e- Azam Award by Aga Khan Rural Support Programme for his social work. Awarded Asad Ali shah award by WWF in 2011 in Lahore on his great contribution on saving wild life.\n\n\n\n"}
{"id": "2879948", "url": "https://en.wikipedia.org/wiki?curid=2879948", "title": "Tau Arietis", "text": "Tau Arietis\n\nThe Bayer designation Tau Arietis (τ Ari, τ Arietis) is shared by two star systems, in the constellation Aries:\nThey are separated by 0.54°.\n"}
{"id": "27828116", "url": "https://en.wikipedia.org/wiki?curid=27828116", "title": "Thalia (nymph)", "text": "Thalia (nymph)\n\nIn Greek mythology, Thalia or Thaleia ( ; \"Tháleia\" or Θάλια \"Thália\", \"the Joyous, the Flourishing\", from θάλλειν / thállein, \"to flourish, to be green\") is a nymph, the child of Hephaestus. She is also given as an anthropomorphic secondary deity of plant life and shoots, possibly as the culmination of the transmission of knowledge on volcanic ash's use as a fertiliser, characteristic of ancient viticulture in volcanic soils such as those of the island of Santorini.\n\nThe tradition surrounding her is confused, but she is probably confused with the Muse, Grace or Nereid of the same name. Macrobius's \"Saturnales\" (song V) states how Zeus seized this Thalia whilst he was in the form of an eagle, as he did with Aegina, Leto and Ganymede. He then made love to her near the river Symethe on Sicily and then buried her in the ground to avoid Hera's jealousy. Her twin children, the Palici, were thus born from the earth, though other authors make the Palici the sons of Hephaestus.\n\n\n"}
{"id": "465539", "url": "https://en.wikipedia.org/wiki?curid=465539", "title": "U.S. state temperature extremes", "text": "U.S. state temperature extremes\n\nThe following table lists the highest and lowest temperatures recorded in each state in the United States, in both Fahrenheit and Celsius during the past two centuries.\n\n<nowiki>*</nowiki>Also on earlier date or dates in that state\n\nCanadian provincial and territorial temperature extremes\n\n"}
{"id": "195748", "url": "https://en.wikipedia.org/wiki?curid=195748", "title": "USS Brooklyn (1858)", "text": "USS Brooklyn (1858)\n\nUSS \"Brooklyn\" (1858) was a sloop-of-war authorized by the U.S. Congress and commissioned in 1859. \"Brooklyn\" was active in Caribbean operations until the start of the American Civil War at which time she became an active participant in the Union blockade of the Confederate States of America.\n\nWith her one 10-inch gun and twenty 9-inch guns, \"Brooklyn \" was a formidable fighting ship that could deliver damaging broadsides, and served on the Atlantic Ocean coast as well as the Gulf Coast of the United States in intercepting blockade runners. \"Brooklyn\" also served gallantly attacking Confederate forts and other installations on the Mississippi River.\n\nPost-war, \"Brooklyn\" remained active, serving for some years in the European theatre, as well as circumnavigating the globe. She was retired in 1889 and sold in 1890 after having well served her country for over three decades.\n\n\"Brooklyn\" – the first ship so-named by the U.S. Navy – was the first of five screw sloops of war authorized by the U.S. Congress on March 3, 1857; laid down later that year by the firm of Jacob A. Westervelt and Son; launched in 1858; and commissioned on January 26, 1859, Capt. David G. Farragut in command.\n\nOn February 5, \"Brooklyn\" got underway for a trial run to Beaufort, South Carolina, where she arrived on the 11th. Following a week's visit to that port, she headed for the West Indies to investigate conditions in Haiti where liberal forces had ousted Emperor Soulouque and installed Fabre Geffrard as President.\n\nFarragut found that the people of Haiti were delighted to be free of the oppressive rule of the former monarch and with the end of a racial war that had bled their nation. Upon the recommendation of the American consul, Farragut sailed for the Isthmus of Panama.\n\nAfter visiting Aspinwall, \"Brooklyn\" set a course for the Mexican coast and reached Veracruz early in April. The legal president of Mexico, Benito Juárez – who had been driven from Mexico City by forces of General Miguel Miramón of the Clerical Party—was making that seaport his temporary capital.\n\nThe United States, which recognized the Juarez government, had sent former Maryland Congressman Robert Milligan McLane to Veracruz as the American minister and ordered Farragut to make \"Brooklyn\" available to McLane so that he might keep abreast of developments in the ongoing civil war and assist American consuls who were striving to protect U.S. citizens and property. During part of the time the screw sloop of war lay off Veracruz, McLane resided on board.\n\nIn July \"Brooklyn\" proceeded to Pensacola, Florida, for coal, provisions, and water, and she reached that port on the 15th. As soon as she finished replenishing, the ship returned to Veracruz, but she was back at Pensacola again by September 7. From there, she sailed for New York and reached the New York Navy Yard on the 26th of that month.\n\nWith McLane—who had returned to the United States for consultations with the U.S. Secretary of State and the U.S. President—on board, \"Brooklyn\" departed New York Harbor on November 8 and headed back toward the Gulf of Mexico. She arrived at Veracruz on the 21st and remained in port while McLane negotiated an agreement with the Juárez Government. After the treaty was signed on December 12, she got underway again and proceeded to New Orleans, Louisiana, where she arrived on the 18th.\n\nWith her bunkers full once more, she headed down the Mississippi River on Christmas Eve and crossed the gulf to Veracruz. However, in mid- January she reembarked McLane and took him to New Orleans so that he might catch a train for Washington, D.C., where he was needed to explain the treaty he had negotiated with Juárez to doubtful senators.\n\nFrom New Orleans, \"Brooklyn\" proceeded to Pensacola to prepare for a return to Mexican waters. However, before McLane could get back to the Gulf Coast from Washington, orders reached Pensacola sending her north. She stood out to sea on February 19, 1860 and reached New York City on the 27th. Underway again on March 11, she arrived at Norfolk, Virginia, the following afternoon and there awaited McLane whom she embarked and delivered back to Veracruz on the 28th.\n\nThe steamer operated along the Mexican coast through the spring and into the summer carrying McLane to various ports where he conferred with the American consuls. Late in July she left the Mexican coast and returned to Norfolk early in August. There, she received orders to prepare for a voyage carrying members of a scientific expedition to the Gulf of Mexico to find a route across the isthmus of Chiriqui. She sailed on the 13th and reached Chiriqui, Boca del Toro, Panama, on the 24th. But for a run to Aspinwall from September 12 to 17, she remained off the expedition base at Chiriqui until mid-October when she returned to Aspinwall. There on October 20, Capt. William S. Walker relieved Farragut in command.\n\nShortly thereafter, \"Brooklyn\" returned to Hampton Roads, Virginia, and she remained in the Norfolk area through the end of 1860 while enthusiasm for secession swept through the deep South in the wake of Abraham Lincoln's election to the presidency. Early in January 1861, Capt. Walker received orders sending \"Brooklyn\" to Charleston, South Carolina, with messages for the steamer \"Star of the West\" which had sailed south to relieve beleaguered Fort Sumter. However, when she reached Charleston Harbor, she found the channel leading into port obstructed and learned that the resupply effort had failed. Consequently, she returned to Hampton Roads.\n\nThe following month, she received orders for a similar mission which she carried out with great success, relieving Fort Pickens, at Pensacola, Florida. After helping to thwart Confederate attempts to wrest that highly valuable Federal toehold on strategic Florida territory from Union hands, \"Brooklyn\" sailed west along the Gulf of Mexico coast to establish the blockade of the Mississippi Passes.\n\nShe, , and two gunboats made a number of captures off Pass a l'Outre and Southwest Pass, but so many ships were getting by them that Comdr. Charles Henry Poor – who relieved Capt. Walker as \"Brooklyn's\" commander in April 1861—tried to go upriver to the Head of Passes where traffic might better be throttled. Low water, however, caused her to run aground twice before she abandoned the effort.\n\nOn June 30, 1861, the Confederate warship CSS \"Sumter\" raced out of Pass a l'Outre while \"Brooklyn\" had left her station in pursuit of another ship. Upon seeing the fleet Southern cruiser, \"Brooklyn\" forsook her first chase and used full sail and maximum steam in an attempt to overtake \"Sumter\" but to no avail, for her quarry soon escaped over the horizon and out of sight. Badly in need of repairs, \"Brooklyn\" sailed north late in the autumn and was decommissioned at the Philadelphia Navy Yard.\n\nRecommissioned on December 19, 1861, the screw sloop—commanded by Capt. Thomas T. Craven—dropped down the Delaware River on the 27th and stood out to sea, bound for the gulf. After stopping at Key West, Florida, she reached Ship Island, Mississippi, on January 22, 1862. On February 2 she sailed for Pass a l'Outre where, on the 19th, she captured the steamer \"Magnolia\" which was attempting to slip out to sea with 1,200 bales of cotton.\n\nMeanwhile, the Navy Department had divided its forces in the gulf into two organizations: the East Gulf Blockading Squadron, commanded by Flag Officer William W. McKean, and the West Gulf Blockading Squadron, commanded by Flag Officer David G. Farragut who arrived at Ship Island in March. Besides carrying out the blockade, Farragut had been instructed to lead a fleet of warships up the Mississippi River to capture New Orleans, Louisiana.\n\nAfter spending the latter part of March and the first part of April getting his deep-draft ocean-going vessels over the bar and into the river, Farragut moved his fleet up the Mississippi to a position just out of range of the guns that guarded the river at Confederate Forts Jackson and St. Philip.\n\nAttached to Farragut's force was a flotilla of small sailing vessels each of which carried a 13-inch mortar. In mid-April these little warships—mostly schooners—began a bombardment of the Southern forts and continued the attack until the early hours of April 24 when they increased the tempo of their firing to their maximum rate while Farragut's deep-draft men-of-war got underway for a dash past the Southern guns. \"Brooklyn\" was\n\nEight men from \"Brooklyn\" were killed in the action and 21 wounded before she reached comparative safety beyond the range of the Rebel artillery. Later that day, after making needed repairs, Farragut's warships resumed their movement upriver and reached New Orleans on April 25. When that city had surrendered, \"Brooklyn\"—which had been damaged more seriously by her collision with the ram \"Manassas\" than Craven had at first realized—received a patch of heavy planking some 24 feet long over a long tear in her hull. One of \"Brooklyn's\" sailors, Quartermaster James Buck, was awarded the Medal of Honor for his actions in the battle.\n\nFarragut's orders called for him to clear the Mississippi of all Confederate forces afloat and of all defensive works along the river banks while moving up stream until meeting another Union squadron—commanded by Flag Officer Charles Henry Davis – which had begun fighting its way downriver from Cairo, Illinois. Hence, early in May after Union Army troops commanded by Major General Benjamin F. Butler had arrived in transports and had taken over New Orleans, \"Brooklyn\" and six other warships ascended the river.\n\nBaton Rouge, Louisiana, and Natchez, Mississippi, surrendered with no resistance, but Vicksburg, Mississippi, proved to be another matter. The Confederate Army had so fortified its riverside hills that it could not be taken without the support of a strong land force. Since the Union Army did not have a sufficient number of troops available in the region to accomplish this purpose, Farragut's men-of-war returned to New Orleans.\n\nThere awaiting him were orders from Secretary of the Navy Gideon Welles reiterating the importance of a junction with Davis's force above Vicksburg, Mississippi. Thus the Union warships again reversed course and painfully worked their way upstream to a position just out of range of Vicksburg's guns. This time they had the support of the Mortar Flotilla which conducted an intense preliminary bombardment of the riverside fortress. At two hours past midnight on June 28, the fleet got underway in two columns and began steaming up stream.\n\nUnfortunately, the steamers that had towed the mortar schooners up stream got in the way of \"Brooklyn\" and two gunboats and prevented their getting upstream past the Vicksburg batteries. As a result they drew much of the Southern fire while Farragut's other ships pushed upstream and out of range. Shortly before dawn, \"Brooklyn\" dropped down stream to a place of greater safety and remained there to be on hand to support Farragut in any way possible should an opportunity to do so occur before the Flag Officer returned below in mid-July. As the hot summer days passed, more and more illness broke out among the ship's crew and the falling water level in the river made it necessary for the ship to retire downstream toward New Orleans.\n\nMeanwhile, on July 2, Capt Henry H. Bell relieved Capt. Craven in command of \"Brooklyn\". On August 6, the screw sloop engaged Confederate batteries at Donaldsonville, Louisiana, driving the Southern artillerymen from their guns; and, on the 9th and 10th, she took part in combined operations which partially destroyed that city in reprisal for guerrilla attacks on Union shipping from that town.\n\nSoon thereafter, \"Brooklyn\" left the Mississippi and steamed to Pensacola for more permanent repairs to the damage she had suffered while fighting her way past Forts Jackson and St. Philip and colliding with Manassas. On October 6, orders sent the ship to blockade duty off Mobile Bay, and she spent the rest of 1862 in that vicinity alert for blockade runners and the appearance of Confederate cruisers which might threaten Union gunboats guarding the coast.\n\nEarly in January 1863, when word reached Farragut that a surprise Southern attack against Union warships at Galveston, Texas, had recaptured that port and broken the blockade there, he placed Bell in charge of the small force sent to reestablish Union control. Shoal water prevented \"Brooklyn\" from participating in a bombardment of Confederate gun positions in Galveston harbor on January 10; and on the night of the 11th, CSS \"Alabama\" sank \"Brooklyn's\" most formidable consort the sidewheel steamer , in a fierce but rapid engagement some 30 miles off Galveston. This setback prompted Bell to give up his plan to retake that port pending the arrival of powerful shallow draft reinforcements. \"Brooklyn\" did continue to blockade the Texas city into the summer.\n\nOn 25 May, Bell \" ... left Commander James Robert Madison Mullany in the in charge of the blockade of Galveston ... and proceeded down the coast of Texas as far as the Rio Grande, to ascertain the amount of interior coast trade and its exit ...\n\n\"On the morning of the 27th, \"Brooklyn\" captured the 17-ton, cotton-laden sloop, \"Blazer\", which was heading for Matamoros, Mexico. The next day, boats from \"Brooklyn\" took the small sloop \"Kate\". Three days later, she anchored off the bar outside Brazos Santiago, Texas\", and sent \" ... an expedition of four boats and 87 men ... to capture vessels there …\" \n\nAs the Union boats approached Point Isabel, the Southerners \" ... set fire to a large schooner.\" They brought out the 100-ton schooner Star and a fishing scow. At Point Isabel, they captured the 100-ton, British sloop \"Victoria\" of Jamaica but ran that vessel aground while attempting to get out to sea and so burned her. After the landing parties had returned to the ship, \"Brooklyn\" returned to Galveston.\n\nLate in July she returned to New Orleans where, on August 2, Lt. Comdr. Chester Hatfield relieved Bell in command to free the commodore to take temporary command of the West Gulf Blockading Squadron while Farragut returned home in for a well-earned leave. On the 10th, Capt. George F. Emmons relieved Hatfield and sailed \"Brooklyn\" north on the 13th to receive badly needed repairs. She emerged from the Southwest Pass the next day; touched at Port Royal, South Carolina, on the 21st, at Charleston, South Carolina, on the 22d, and reached the New York Navy Yard on the 25th.\n\nRecommissioned on April 14, 1864, \"Brooklyn\" put to sea on 10 May under the command of Capt. James Alden, Jr. and rejoined her squadron off Mobile Bay on the last day of the month. There Farragut—who had resumed command—was eager to capture that strategic port, but was held up by the perennial lack of available Union Army troops—needed for the projected combined operation. He was also awaiting the arrival of monitors to strengthen the squadron for the forthcoming battle. \"Brooklyn\" helped to blockade Mobile Bay while Farragut waited for deficiencies to be corrected. Finally, late in July she and her squadron mates received orders to make ready for the long awaited attack.\n\nOn the morning of August 5, Farragut took his squadron of 18 ships, including four monitors, against the heavy Confederate defenses of Mobile Bay. Soon after 6 am, the Union ships crossed the bar and moved into the bay. The four monitors formed a column to starboard of the wooden ships in order to take most of the fire from Fort Morgan, which they had to pass at close range. \"Brooklyn\" led the second column, consisting of the seven smaller wooden ships lashed to the port side of the larger wooden screw steamers, as in the passage of Fort Hudson.\n\nShortly before 7 o'clock, \"Tecumseh\" opened fire on Fort Morgan, and the action quickly became general. As the 4-ship Confederate squadron engaged the attackers, a terrific explosion rocked the Union monitor . She careened violently and went down in seconds, the victim of one of the much-feared torpedoes (Naval mine) laid by the Confederates for harbor defense.\n\nAlden, in \"Brooklyn\", was to \"Tecumseh's\" port when the disaster occurred; the heavy steamer stopped and began backing to clear \"a row of suspecious looking buoys\" directly under \"Brooklyn's\" bow. The entire line of wooden vessels was drifting into confusion immediately under the guns of Fort Morgan. Farragut, lashed in the rigging to observe the action over the smoke billowing from the guns, acted promptly and resolutely. The only course was the boldest—through the torpedo field. \"Damn the torpedoes\", he ordered \"full speed ahead.\" His flagship \"Hartford\" swept past \"Brooklyn\" into the rows of torpedoes; the fleet followed. The Union force steamed into the bay.\n\nIn the ensuing battle, the ironclad CSS \"Tennessee\" attempted in vain to ram \"Brooklyn\". The Union fleet dispatched three of the Confederate ships, leaving \"Tennessee\" as the only defender. The lone ironclad then engaged the entire Union fleet. After a fierce battle lasting more than an hour, \"Tennessee\" was forced to surrender, resulting in a Union victory.\n\nDuring the battle that lasted a bit more than three hours, \"Brooklyn\" suffered 54 men killed and 43 wounded while firing 183 projectiles. Twenty-three of \"Brooklyn\"'s sailors and marines were awarded the Medal of Honor for their part in the battle. Their names were:\n\nAfter spending the next few weeks helping reduce the Confederate land works guarding the entrance, \"Brooklyn\" departed Mobile Bay on September 6 and headed for Hampton Roads for service in the North Atlantic Blockading Squadron. Soon thereafter, Rear Admiral David Dixon Porter began to concentrate his warships for a joint Army-Navy operation against Fort Fisher, North Carolina. The fort guarded the approaches to Wilmington, North Carolina, the last major Confederate port still open for blockade runners. \"Brooklyn\" took part in the attack against that Southern stronghold which began with a bombardment on Christmas Eve. She helped to cover the landing of troops the next day, but the whole effort was brought to naught later that day when the Union Army commanding officer, Major General Benjamin F. Butler, decided that his forces could not carry the Confederate works and ordered his soldiers to re-embark.\n\nPorter strongly disagreed with this decision in dispatches to Washington. General Ulysses S. Grant responded by placing a new commander over a larger Army force earmarked for another attempt to take Fort Fisher. \"Brooklyn\" was in the task force that arrived off Fort Fisher on January 13, 1865, and her guns supported the attack until the fort surrendered on the 15th. Since this victory completed the last major task of the Union Navy during the Civil War, \"Brooklyn\" sailed north and was decommissioned at the New York Navy Yard on January 31, 1865.\n\nLaid up under repairs for the remaining months of the conflict, the screw sloop was recommissioned on October 4, 1865, Comdr. Thomas H. Patterson in command. She stood out to sea on the 27th and proceeded via the Gulf of Mexico to Bahia, Brazil. Following almost two years of service along the Atlantic coast of South America, she returned to Philadelphia, Pennsylvania, late in the summer of 1867 and was decommissioned there on September 11 and placed in ordinary.\n\nRecommissioned on August 24, 1870, Capt. John Guest in command, \"Brooklyn\" sailed eastward across the Atlantic and spent almost three years in European waters, primarily in the Mediterranean. After returning home in the summer of 1873, she was decommissioned at New York City on July 26 for repairs.\n\nReactivated on January 20, 1874, the veteran warship operated along the southern coast of the United States until autumn when she entered the Norfolk Navy Yard to be fitted out for service as flagship of the South Atlantic Squadron. She got underway for the coast of Brazil on January 23, 1875 and operated in South American waters protecting American interests until heading home on December 7. Following service in the Home Squadron, she was decommissioned at New York City on July 21, 1876 and laid up.\n\nRecommissioned on November 11, 1881, \"Brooklyn\" sailed on December 7 for Montevideo, Uruguay, and another tour of duty with the South Atlantic Squadron. On February 5, 1882, she departed that port and headed for the Strait of Magellan. During the month, she visited Possession Bay, Gregory Bay, Elizabeth Island, and Sandy Point before departing Possession Bay on March 2, 1882 and returning via Stanley, Falkland Islands, to Montevideo where she arrived late in March.\n\nWhile operating out of that port during the next 18 months, she made two voyages to Santa Cruz, Patagonia, and one to Rio de Janeiro, Brazil, before getting underway on September 28, 1883 for Cape Town, Africa. During her time in African waters, she also visited Tomatave, Madagascar; Zanzibar; the Johanna Islands; Nassi be Island; Mojanga, Madagascar; Mozambique; Mourondava, Nos Veh, and Tuellear Bay, Madagascar, and Port Elizabeth, Africa, before departing Cape Town on March 13, 1884. After proceeding homeward via St. Helena Island, Montevideo, and Rio de Janeiro, she arrived at New York City on October 8, 1884 and was placed out of commission there on the 25th.\n\nFollowing almost a year in ordinary, \"Brooklyn\" was recommissioned on October 15, 1885 and, on November 21, assigned once more to the South Atlantic Squadron and served in South American waters until heading home again on June 9, 1886.\n\nAt New York, she prepared for duty in the Orient and, on August 12, got underway for the Far East. After crossing the Atlantic and the Mediterranean, she transited the Suez Canal and traversed the Red Sea and the Indian Ocean to East Asian waters.\n\nOn April 4, 1887, Rear Admiral Chandler transferred his flag to her as commander of the Asiatic Squadron, and she showed the flag in ports of the western Pacific Ocean until turning homeward for the last time on August 9, 1888. She returned to the United States via Honolulu; Cape Horn; and St. Thomas. \"Brooklyn\" completed her first circumnavigation of the earth upon her arrival at New York on April 24, 1889 and simultaneously ended her active naval career.\n\nShe was decommissioned at the New York Navy Yard on May 14, 1889, and her name was struck from the Navy List on January 6, 1890. She was sold by public auction at the Norfolk Navy Yard on March 25, 1891 to E. J. Butler.\n\n\n\n"}
{"id": "53921191", "url": "https://en.wikipedia.org/wiki?curid=53921191", "title": "Usuluk Bay Nature Park", "text": "Usuluk Bay Nature Park\n\nUsuluk Bay Nature Park () is a nature park at Usuluk Bay in Muğla Province, southwestern Turkey.\n\nUsuluk Bay is located on the highway Bodrum-Milas at Torba village, northeast of Bodrum in Muğla Province. The area at Usuluk Bay coast was a popular picnic place for the Bodrum residents used free of charge in the past. In 2005, the area was leased to a private company for a lease term of 27 years with the purpose to run the place with entrance fee and payment for campers and caravan travelers. Since the related bylaws did not permit the use of the area with diversified purposes, the residents protested against the ruling of the Ministry of Forest and Water Management. In July 2011, the status of Usuluk Bay was changed from the \"A-grade resort\" to a nature park by the ministry.\n"}
{"id": "26593829", "url": "https://en.wikipedia.org/wiki?curid=26593829", "title": "Volcanic hazards", "text": "Volcanic hazards\n\nA volcanic hazard is the probability that a volcanic eruption or related geophysical event will occur in a given geographic area and within a specified window of time. The risk that can be associated with a volcanic hazard depends on the proximity and vulnerability of an asset or a population of people near to where a volcanic event might occur.\n\nThere are different forms of effusive lava that can provide different hazards. Pahoehoe lava is smooth and ropy while Aa lava is blocky and hard. Lava flows normally follow the topography, sinking into depressions and valleys and flowing down the volcano. Lava flows will bury roads farmlands and other forms of personal property. This lava could destroy homes, cars, and lives standing in the way. Lava flows are dangerous, however, they are slow moving and this gives people time to respond and evacuate out of immediate areas. People can mitigate this hazard by not moving to valleys or depressed areas around a volcano.\n\nTephra is a generalized word for the various bits of debris that are launched out of a volcano during an eruption, regardless of their size. Pyroclastic materials are generally categorized according to size: dust measures at <1/8 mm, ash is 1/8–2 mm, cinders are 2–64 mm, and bombs and blocks are both >64 mm. There are different hazards associated with the different kinds of pyroclastic materials. Dust and ash could coat cars and homes, rendering the car unable to drive with dust accumulation in the engine. They could also layer on homes and add weight to roofs causing the house to collapse. Also, ash and dust inhaled could cause long-term respiratory issues in people inhaling the particles. Cinders are flaming pieces of ejected volcanic material which could set fire to homes and wooded areas. Bombs and blocks run the risk of hitting various objects and people within range of the volcano. Projectiles can be thrown thousands of feet in the air and can be found several miles away from the initial eruption point.\n\nA pyroclastic flow is a fast-moving (up to 700 km/hr) extremely hot (~1000 °C) mass of air and tephra that charges down the sides of a volcano during an explosive eruption.\n\nWhen pyroclastic materials mix with water from a nearby stream or river, they can turn the watercourse into a fast moving mudflows. These are called lahars; when the lahar contains large material such as blocks of rock and trees, it is a volcanic debris flow. Lahars can form directly from a pyroclastic material flow flowing into a river, or could possibly form after the main eruption. The latter is referred to as secondary lahars and form when rain wets the ash and debris already on a landscape and stick together rolling along the topography. It's estimated that it can only take 30% water to initiate ash into a lahar. The thicker and/or more fast-moving a lahar, the more potential to destroy things in its path, thus making it more dangerous than a slower and/or more diluted lahar. Lahars and mudflows can damage buildings, wildlife and cars and can prove difficult to escape once caught in them. The lahars can coat objects, wash objects away and can knock objects down by their force. Lahars, debris flows and mudflows that travel into a river or stream run the potential for crowding the waterway, forcing the water to flow outward and causing a flood. The volcanic matter could also pollute the water, making it unsafe to drink.\n\nThe debris that is ejected from the volcano adds to the sides of the slope with each eruption, making the sides steeper each time. Eventually the slope gets so steep that it fails and an avalanche ensues. These avalanches carry material and debris for very long distances at very short intervals. This makes a warning system nearly immposible because the slope failure could occur at any time. The avalanche will destroy anything in its path including personal property, houses, buildings, vehicles and possibly even wildlife. If the impact of the materials in the avalanche doesn't destroy the person or object at first contact, there could be damage resulting from the weight of prolonged material on the objects.\n\nEarthquakes can occur due to volcanic activity. These earthquakes could produce topographical deformation and/or destruction of buildings, homes, cars, etc. There are two different types of these earthquakes: volcano tectonic earthquakes and long period earthquakes. \"Earthquakes produced by stress changes in solid rock due to the injection or withdrawal of magma (molton rock) are called volcano tectonic earthquakes\". These are hazardous due to the possibility of ground cracks or slope failures, therefore destroying everything in its path. Long period earthquakes, which happen when magma is suddenly forced into the surrounding rocks, are generally seen as a precursor to the actual eruption.\n\nAccording to John Ewert and Ed Miller in a 1995 publication, \"a great majority of the world's potentially active volcanoes are unmonitored\". Of the historically active volcanoes in the world, less than one fourth are monitored. Only twenty-four volcanoes in the entire world are thoroughly monitored for activity. They also state that \"seventy-five percent of the largest explosive eruptions since 1800 occurred at volcanoes that had no previous historical eruptions\".\n\nBy monitoring the seismic and geological activity, the USGS can warn people ahead of time about impending danger. These volcanologists measure the size of an eruption in two ways: the eruption magnitude (by the volume or mass of magma erupted) and eruption intensity (by the rate of magma erupted). There are also various forms of satellites and imagery, such as satellite InSAR imagery, that monnitor the activity that isn't exposed to the naked eye.\n\nHowever, the situation has somewhat changed with the International Decade for Natural Disaster Reduction \nThe Global Assessment of Risk (GAR) report is a biennial review and analysis of natural hazards published by the United Nations Office for Disaster Risk Reduction (UNISDR). The report implements the UN Hyogo Framework for Action. \nZadeh et al. (2014) provide an overview on Risks and Societal Implications of extreme natural hazards and an assessment of the global risk of volcanos and contains an appeal to found a worldwide volcanological organization comparable to the WMO \nThe EU has recently started major research programs dealing with risk assessment, compare: \n\nThe British Geological Survey has various ongoing volcanology programs.\n\n\n"}
{"id": "5830340", "url": "https://en.wikipedia.org/wiki?curid=5830340", "title": "Wallasea Wetlands", "text": "Wallasea Wetlands\n\nWallasea Wetlands is a reclaimed wetlands area located in Essex, England. It has been created as part of a government-funded wetlands scheme to halt the decline of wild and endangered birds caused by the drainage and development of former wetland sites. It is the largest man-made marine wetland area in the United Kingdom.\n\nThe wetland spans an area of 115 hectares and is sited on Wallasea Island, which borders two rivers (River Crouch to the north and River Roach to the south-east). They provide winter grounds for wading birds, as well as breeding and nursery areas for aquatic wildlife, such as bass, mullet, flatfish and herring and even some types of dolphin. The area will also help to reduce the flooding of properties near the River Crouch by providing a run-off area for floodwaters.\n\nIn the process being termed \"managed re-alignment\", the seawall that protects croplands and property was re-established in more tenable positions, three miles behind the new wetlands, which will provide habitat for birds like oystercatchers, avocets and little terns, according to the press release issued at the time.\n\nWalkers and birdwatchers will be able to enjoy the scenery by means of a new footpath that has been built on the top of this new relocated sea wall. Construction was completed in 2006 and by 2011 the land had evolved into wetland, mudflats, saline lagoons and seven artificial islands, allowing the wildlife to reside on these areas.\n\nAn extension to the scheme, using 2,400 shiploads of spoil excavated from London's Crossrail tunnels, was completed in July 2015, when an additional area of land was opened to tidal flow. The whole project is expected to be completed by 2025.\n\nWetlands have existed on Wallasea Island since ancient times, when much of the Essex coastline was bordered by rich breeding grounds for birds. In the 15th century these lands were drained by Dutch settlers for agricultural use with the construction of the original sea wall. Over time more wetland areas were drained for development, leading to the reduction and endangerment of the wildlife that depended on it.\n\nDuring the late 1980s and early 1990s two areas of salt marsh and mud flat at Lappel Bank in the Medway Estuary in Kent and Fagbury Flats in the Orwell Estuary in Suffolk (both on the east coast of England) were drained and port developments at Sheerness and Felixstowe were built in their place. The European Court of Justice ruled that under the European Birds Directive these wetlands had to be replaced, and it was decided that new wetlands should be created. The following criteria for Wallasea Wetlands has been met in accordance with this ruling:\n\n\nIn 2005, the £7.5million project to return the island to its original salt marsh was commenced, beginning with the construction of the new sea defence wall, defining the area where the tides were permitted to flood. Work was completed on 4 July 2006, when 300m of the original sea wall were bulldozed, allowing sea tides to flood the area at high tide.\n\n"}
{"id": "418604", "url": "https://en.wikipedia.org/wiki?curid=418604", "title": "World3", "text": "World3\n\nThe World3 model is a system dynamics model for computer simulation of interactions between population, industrial growth, food production and limits in the ecosystems of the earth. It was originally produced and used by a Club of Rome study that produced the model and the book \"The Limits to Growth\" (1972). The creators of the model were Dennis Meadows, project manager, and a team of 16 researchers. \n\nThe model was documented in the book \"Dynamics of Growth in a Finite World\". It added new features to Jay W. Forrester's World2 model. Since World3 was originally created, it has had minor tweaks to get to the World3/91 model used in the book \"Beyond the Limits\", later improved to get the World3/2000 model distributed by the Institute for Policy and Social Science Research and finally the World3/2004 model used in the book \"Limits to Growth: the 30 year update\".\n\nWorld3 is one of several global models that have been generated throughout the world (Mesarovic/Pestel Model, Bariloche Model, MOIRA Model, SARU Model, FUGI Model) and is probably the model that generated the spark for all later models.\n\nThe model consisted of several interacting parts. Each of these dealt with a different system of the model. The main systems were \n\nThe simplest useful view of this system is that land and fertilizer are used for farming, and more of either will produce more food. In the context of the model, since land is finite, and industrial output required to produce fertilizer and other agricultural inputs can not keep up with demand, there necessarily will be a food collapse at some point in the future.\n\nThe nonrenewable resource system starts with the assumption that the total amount of resources available is finite (about 110 times the consumption at 1990s rates for the World3/91 model). These resources can be extracted and then used for various purposes in other systems in the model. An important assumption that was made is that as the nonrenewable resources are extracted, the remaining resources are increasingly difficult to extract, thus diverting more and more industrial output to resource extraction.\n\nThe \"Dynamics of Growth in a Finite World\" provides several different scenarios. The \"reference run\" is the one that \"represent the most likely behavior mode of the system if the process of industrialization in the future proceeds in a way very similar to its progress in the past, and if technologies and value changes that have already been institutionalized continue to evolve.\" In this scenario, in 2000, the world population reaches six billion, and then goes on to peak at seven billion in 2030. After that population declines because of an increased death rate. In 2015, both industrial output per capita and food per capita peak at US$375 per person (1970s dollars) and 500 vegetable-equivalent kilograms/person. Persistent pollution peaks in the year 2035 at 11 times 1970s levels.\n\nThere has been quite a bit of criticism of the World3 model. Some has come from the model creators themselves, some has come from economists and some has come from other places.\n\nOne of the major criticisms of the model is that it simply has not reflected the reality of the world since the 1970s when the model was first published. At least one study, however, claims that \"30 years of historical data compare favorably with key features of a business-as-usual scenario called the 'standard run' scenario\" produced by the World3 model.\n\nIn the book \"Groping in the Dark: The First Decade of Global Modelling\", Donella Meadows states: We have great confidence in the basic qualitative assumptions and conclusions about the instability of the current global socioeconomic system and the general kinds of changes that will and will not lead to stability. We have relatively great confidence in the feedback-loop structure of the model, with some exceptions which I list below. We have a mixed degree of confidence in the numerical parameters of the model; some are well-known physical or biological constants that are unlikely to change, some are statistically derived social indices quite likely to change, and some are pure guesses that are perhaps only of the right order of magnitude. The structural assumptions in World3 that I consider most dubious and also sensitive enough to be of concern are:\n\n\nA detailed criticism of the model is in the book \"Models of Doom: A Critique of the Limits to Growth\".\n\nBoth Julian Lincoln Simon and Bjørn Lomborg have discussed the assumptions that the model makes. The first assumption that they criticize is the assumption of finite natural resources. They also state that the limits on agriculture are invalid since they are based on the limit of the amount of land.\n\nVaclav Smil disagreed with the combination of physically different processes into simplified equations:\n\nHe does however consider continuous growth in world GDP a problem:\n\nOthers have put forth criticisms, such as Henshaw, King, and Zarnikau who in a 2011 paper, \"Systems Energy Assessment\" point out that the methodology of such models may be valid empirically as a world model, but might not then also be useful for decision making. The impact data being used is generally collected according to where the impacts are recorded as occurring, following standard I/O material processes accounting methods. It is not reorganized according to who pays for or profits from the impacts, so who is actually responsible for economic impacts is never determined. \n\n\nThe authors of the book \"Surviving 1,000 Centuries\" consider some of the predictions too pessimistic, but some of the overall message correct...[We] come to the well-known study, \"Limits to Growth\", published under the sponsorship of the 'Club de Rome' - an influential body of private individuals. A first attempt was made to make a complete systems analysis of the rapidly growing human-biological-resource-pollution system. In this analysis the manifold interactions between the different parts were explicitly taken into account. The conclusion was that disaster was waiting around the corner in a few decades because of resource exhaustion, pollution and other factors. Now, 35 years later, our world still exists, ... So the 'growth lobby' has laughed and proclaimed that \"Limits to Growth\" and, by extension, the environmental movements may be forgotten. This entirely misses the point. Certainly the timescale of the problems was underestimated in \"Limits to Growth\", giving us a little more time than we thought. Moreover, during the last three decades a variety of national or collaborative international measures have been taken that have forced reductions in pollution, as we shall discuss. A shining example of this is the Montreal Protocol (1987) that limited the industrial production of fluorocarbons that damage the ozone layer and generated the 'ozone hole' over Antarctica. The publication of \"Limits to Growth\" has greatly contributed towards creating the general willingness of governments to consider such issues. Technological developments have also lead to improvements in the efficiency of the use of energy and other resources, but, most importantly, the warnings from Malthus onward have finally had their effect as may be seen from the population-limiting policies followed by China and, more hesitantly, by India. Without such policies all other efforts would be in vain. However, the basic message of \"Limits to Growth\", that exponential growth of our world civilization cannot continue very long and that a very careful management of the planet is needed, remain as valid as ever.\n\n"}
