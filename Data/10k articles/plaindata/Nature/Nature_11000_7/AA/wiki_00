{"id": "33073718", "url": "https://en.wikipedia.org/wiki?curid=33073718", "title": "(276033) 2002 AJ129", "text": "(276033) 2002 AJ129\n\n, provisional designation , is a Mercury-crossing asteroid. It has the ninth-smallest perihelion of all numbered asteroids, after asteroids such as , , and . It makes close approaches to all of the inner planets and asteroid 4 Vesta. The asteroid is estimated to be between across. In January 2018 there was much media hype about this asteroid being classified as a potentially hazardous asteroid, although there is no known threat of an impact for hundreds if not thousands of years. The media has compared the size of the asteroid to the Burj Khalifa in Dubai.\n\n was discovered on 15 January 2002, by astronomers of the NEAT team at Haleakala Observatory, Hawaii, United States. It was removed from the Sentry Risk Table on 3 February 2002.\n\nIt is a Mercury-, Venus-, Earth- and Mars-crossing asteroid. With an observation arc of 14 years, it has a well determined orbit and was last observed in 2016. It is classified as an Apollo asteroid because it is a near-Earth asteroid with a semi-major axis larger than Earth's. It is also categorized as a potentially hazardous asteroid, but that does not mean there is a near-term threat of an impact. It is a potentially hazardous asteroid merely as a result of its size (absolute magnitude ) and Earth minimum orbit intersection distance ).\n\nOn 4 February 2018 at 21:31 UT, the asteroid passed about from Earth. The 2018 Earth approach distance was known with a 3-sigma accuracy of ±200 km. Goldstone is scheduled to observe the asteroid from 3–6 February. By 4 February 2018 11:00 UT, the asteroid brightened to apparent magnitude 14 and had a solar elongation of more than 100°.\n\nOn 8 February 2172, the asteroid will pass about from Earth. The 2172 Earth approach distance is known with a 3-sigma accuracy of ±4000 km.\n\nAs we look even further into the future the known trajectory becomes more divergent. By the Earth approach of on 19 February 2196 the uncertainty increases to ±2.4 million km.\n"}
{"id": "1258580", "url": "https://en.wikipedia.org/wiki?curid=1258580", "title": "2002 Vitim event", "text": "2002 Vitim event\n\nThe 2002 Vitim event or Bodaybo event is believed to be an impact by a bolide (fireball) in the Vitim River basin. It occurred near the town of Bodaybo in the Mamsko-Chuisky district of Irkutsk Oblast, Siberia, Russia on September 25, 2002 at approximately 22:00 (local time, UTC/GMT +9 hours: ISO 8601 format 2002-09-25T13:00Z). The event was detected by a US military missile-defense satellite.\n\nAttempts were made to define the magnitude of the explosion. U.S. military analysts calculated it was around . Peter Brown estimates the total yield of both Bodiabo and Tagish Lake at about 2 kilotons—a factor of roughly 10,000 less than the Tunguska event. Russian physicist Andrey Olkhovatov estimates it at 4–5 kilotons.\n\nInformation about the event appeared in the mass media and among scientists after only a week. A small expedition, sent by the Institute of Sun–Earth Physics (Irkutsk), tried to find a meteorite within about 10 km from Bodaybo town (people told them– \"it has fallen beyond the nearest mountain\").\n\n\nOfficial expeditions in 2002–2003 never reached the impact site, situated in remote Siberian taiga.\n\nAs reported by the ufology organization Kosmopoisk, in May 2003 an expedition, performed by Kosmopoisk (leader — Vadim Chernobrov) reached a presumed impact point (about 50 km from Vitimsky settle point). The situation there looked similar to that of the Podkamennaya Tunguska River after the Tunguska event in 1908. Snow and water samples were analyzed and found to contain an abnormal amount of tritium, as well as radioactive isotopes of cobalt and caesium. Chernobrov suggested that the Vitim event could be caused by a low density comet nucleus with a diameter of about 30–100 meters.\n\n\n"}
{"id": "534824", "url": "https://en.wikipedia.org/wiki?curid=534824", "title": "2004 FH", "text": "2004 FH\n\n2004 FH is a micro-asteroid and near-Earth object of the Aten group, approximately 30 meters in diameter, that passed just above the Earth's surface on 18 March 2004, at 22:08 UTC. It was the 11th closest approach to Earth recorded . The asteroid was first observed on 16 March 2004, by astronomers of the Lincoln Near-Earth Asteroid Research at the Lincoln Laboratory's Experimental Test Site near Socorro, New Mexico.\n\n is an Aten asteroid. It passed 43,000 km from the Earth on 18 March 2004. For comparison, geostationary satellites orbit Earth at 35,790 kilometers. Despite its small size, it is still the fourth largest asteroid detected coming closer to the Earth than the Moon. \n\nHad this object hit Earth, it would probably have detonated high in the atmosphere. It might have produced a blast measured in hundreds of kilotons of TNT, but may not have produced any effect on the ground. It could also have been an Earth-grazing fireball if it had been much closer but not close enough to impact.\n\nOn 17 March 2044 the asteroid will pass no closer than from the Earth. also has the distinction of having the lowest inclination of any known near-Earth asteroids.\n\nTwo weeks later another asteroid approached even closer, , which was smaller, and a few years later , which was closer in size passed by at similar distance.\n\n is an assumed stony S-type asteroid.\n\nIn March 2004, two rotational lightcurves of were obtained from photometric observations by astronomers Petr Pravec, Stefano Sposetti and Raoul Behrend. Lightcurve analysis gave a rotation period of 0.0504 hours (3.02 minutes) with a brightness amplitude of 1.16 and 0.75 magnitude, respectively ().\n\nThis makes this object a fast rotator, currently among the Top 100 known to exist. The photometric observations also revealed, that is a tumbler with a non-principal axis rotation.\n\nhas been estimated to measure approximately 30 meters (100 feet) in diameter. The \"Collaborative Asteroid Lightcurve Link\" assumes a standard albedo for stony asteroids of 0.20 and calculates a diameter of 24 meters based on an absolute magnitude of 25.7.\n\n"}
{"id": "4428749", "url": "https://en.wikipedia.org/wiki?curid=4428749", "title": "6N3P", "text": "6N3P\n\nThe 6N3P (Russian: 6Н3П) is a Russian-made direct equivalent of the 2C51 medium gain dual triode vacuum tube. It may be used as an amplifier, mixer, oscillator or multivibrator over a frequency range AF through VHF. The Russian tube is slightly larger in size than the American tube.\n\nUf = 6.3 V, If = 350 mA, µ = 36, Ia = 7.7 mA, S = 4.9 mA/V, Pa = 1.5 W\n\n6N3P was widely used for FM band radio input unit stages (nearly all 1960s Soviet radios with FM band employed the same input unit on a separate sub-chassis). Currently it has found use in DIY preamps. A ruggedized/industrial version of the tube is designated 6N3P-EV (Russian: 6Н3П-ЕВ).\n\neBay has proliferated with pre-amps apparently from Hong Kong that are largely populated with the 6N3, which is said to be the Chinese version of the 6N3P. The 6N3Ps are newly made (unlike the Soviet \"new old stock,\" and the pre-amps appear to be the product of a cottage hifi industry).\n\n\n"}
{"id": "22410726", "url": "https://en.wikipedia.org/wiki?curid=22410726", "title": "Arabian Peninsula coastal fog desert", "text": "Arabian Peninsula coastal fog desert\n\nThe Arabian Peninsula coastal fog desert on the southern coasts of the Arabian Peninsula is an ecoregion which experiences thick fogs where visibility may be reduced to . It is classed as an Afrotropic fog desert \n\nThis ecosystem exists on a strip along the western and eastern coasts of Arabia. It follows the coast of Oman southward from Masirah Island and reaches inland to 120 km in the Jiddat al Harasisi plateau and the Dhofar mountains. From here it continues as a very narrow strip (only 5 km wide) along the coast of Yemen and up the 50 km wide the Tihamah plain along the Red Sea coast of Saudi Arabia. In Oman and Yemen moisture is provided by thick fogs coming off the ocean during the summer khareef monsoon, while the hot Tihamah plain is moisturised by some rainfall and the generally high humidity of the Red Sea.\n\nIn this region, although it rarely rains the fog provides moisture sufficient to nurture a great deal of grassland, shrubs and thick woodland. There are over sixty local species of plant. This coastal strip is of particular importance as further inland where the fog does not have an influence most of the Arabian Peninsula is desert. Vegetation varies progressively away from the coast which features dense woodland of \"Anogeissus dhofarica\", \"Acacia senegal\" and various thorny \"Commiphora\" trees and shrubs. The richest flora can be found in the Dhofar mountains which have 900 plants including 60 endemic species and two endemic genera, \"Cibirhiza\" and \"Dhofaria\". One of these plants, the frankincense tree \"(Boswellia sacra)\" was a source of great wealth for Dhofar in antiquity. In Yemen the side of Jabal Urays facing the sea is covered with \"Euphorbia balsamifera\" shrubs.\n\nThe many mammals found here include the Arabian oryx \"(Oryx leucoryx)\" which was reintroduced to the wild after disappearing, gazelles and the Nubian ibex, a goat antelope. Predators found on the coast include caracals, Arabian wolf, striped hyena and the critically endangered Arabian leopard \"(Panthera pardus nimr)\", which survives on Jebel Samhan in the Dhofar mountains. The Arabian gazelle which once lived on the peninsula is now extinct.\n\nThe main threat to this ecosystem is overgrazing by increasing numbers of cattle and other livestock as well as off-road driving and human encroachment. Urban areas in this ecoregion include: in Oman the port of Duqm and the Dhofar capital of Salalah; in Yemen, the Hadhramaut port capital Mukalla, the former capital and ancient port of Aden, the Red Sea coffee ports of Al Hudaydah (still the largest town on this coast of Yemen) and Mocha, and the World Heritage Site of Zabid; and the city of Jizan, the \"fruit basket of Saudi Arabia\". Protected areas in Oman include the controversial Arabian Oryx Sanctuary where the reintroduction took place, and Jabal Samhan Nature Reserve established for the protection of the leopards. There are a number of Important Bird Areas on the coast of Yemen but none are officially protected.\n\n"}
{"id": "633144", "url": "https://en.wikipedia.org/wiki?curid=633144", "title": "Barremian", "text": "Barremian\n\nThe Barremian is an age in the geologic timescale (or a chronostratigraphic stage) between 129.4 ± 1.5 Ma (million years ago) and 125.0 ± 1.0 Ma). It is a subdivision of the Early Cretaceous epoch (or Lower Cretaceous series). It is preceded by the Hauterivian and followed by the Aptian stage.\n\nThe original type locality for the Barremian stage is in the vicinity of the village of Barrême, Alpes-de-Haute-Provence, France. Henri Coquand defined the stage and named it in 1873. \n\nThe base of the Barremian is determined by the first appearance of the ammonites \"Spitidiscus hugii\" and \"Spitidiscus vandeckii\". The end of the Barremian is determined by the geomagnetic reversal at the start of the M0r chronozone, which is biologically near the first appearance of the ammonite \"Paradeshayesites oglanlensis\".\n\nThe Barremian falls in the Gallic epoch, a subdivision of the Cretaceous that is no longer used by the ICS. It overlaps the lower part of the Urgonian stage, which is sometimes used in western European stratigraphy. In North America, the late Coahulian and the early Comanchean correspond to the Barremian. In New Zealand, it falls within the Mokoiwian, and in Japan it corresponds to the late Aritan.\n\nThe Barremian is often subdivided into two substages or subages, Lower/Early and Upper/Late Barremian.\n\nIn the Tethys domain, the Barremian stage contains eleven ammonite biozones:\n\nMuch knowledge about the Barremian fauna—especially regarding birds, mammals and pterosaurs—derived from the famous Yixian Formation of China, part of which dates from this stage.\n\n\n\n\n\n"}
{"id": "3183005", "url": "https://en.wikipedia.org/wiki?curid=3183005", "title": "Blytt–Sernander system", "text": "Blytt–Sernander system\n\nThe Blytt-Sernander classification, or sequence, is a series of north European climatic periods or phases based on the study of Danish peat bogs by Axel Blytt (1876) and Rutger Sernander (1908). The classification was incorporated into a sequence of pollen zones later defined by Lennart von Post, one of the founders of palynology.\n\nLayers in peat were first noticed by Heinrich Dau in 1829. A prize was offered by the Royal Danish Academy of Sciences and Letters to anyone who could explain them. Blytt hypothesized that the darker layers were deposited in drier times; the lighter, in moister times, applying his terms \"Atlantic\" (warm, moist) and \"Boreal\" (cool, dry). In 1926 C.A. Weber noticed the sharp boundary horizons, or \"Grenzhorizonte\", in German peat, which matched Blytt’s classification. Sernander defined subboreal and subatlantic periods, as well as the late glacial periods. Other scientists have since added other information.\n\nThe classification was devised before the development of more accurate dating methods, such as C-14 dating and oxygen isotope ratio cycles. Currently geologists working in different regions are studying sea levels, peat bogs and ice core samples by a variety of methods, with a view toward further verifying and refining the Blytt-Sernander sequence. They find a general correspondence across Eurasia and North America.\n\nThe fluctuations of climatic change are more complex than Blytt-Sernander periodizations can identify. For example, recent peat core samples at Roskilde Fjord and also Lake Kornerup in Denmark identified 40 to 62 distinguishable layers of pollen, respectively. However, no universally accepted replacement model has been proposed.\n\nToday the Blytt-Sernander sequence has been substantiated by a wide variety of scientific dating methods, mainly radiocarbon dates obtained from peat. Earlier radiocarbon dates were often left uncalibrated; that is, they were derived by assuming a constant concentration of atmospheric radiocarbon. In fact the atmospheric radiocarbon concentration has varied over time and thus radiocarbon dates need to be calibrated.\n\nThe Blytt-Sernander classification has been used as a temporal framework for the archaeological cultures of Europe and America. Some have gone so far as to identify stages of technology in north Europe with specific periods; however, this approach is an oversimplification not generally accepted. There is no reason, for example, why the north Europeans should stop using bronze and start using iron abruptly at the lower boundary of the Subatlantic at 600 BC. In the warm Atlantic period, Denmark was occupied by Mesolithic cultures, rather than Neolithic, notwithstanding the climatic evidence. Moreover, the technology stages vary widely globally.\n\nThe Pleistocene phases and approximate calibrated dates (see above) are:\n\nThe Holocene phases are:\n\nSome marker plant genera/species studied in peat are\n\nMore sphagnum appears in wet periods. Dry periods feature more tree stumps, of birch and pine.\n\n"}
{"id": "10019499", "url": "https://en.wikipedia.org/wiki?curid=10019499", "title": "Burned area emergency response", "text": "Burned area emergency response\n\nBurned area emergency response (BAER) is an emergency risk management reaction to post wildfire conditions that pose risks to human life and property or could further destabilize or degrade the burned lands. Even though wildfires are natural events, the presence of people and man-made structures in and adjacent to the burned area frequently requires continued emergency risk management actions. High severity wildfires pose a continuing flood, debris flow and mudflow risk to people living within and downstream from a burned watershed as well as a potential loss of desirable watershed values.\n\nThe burned area emergency response risk management process begins during or shortly after wildfire containment with risk assessments evaluating the effects of the wildfire against values needing protection. These risk assessments can range from simple to complex. An organized interdisciplinary team of subject matter experts (e.g., hydrologists, soil scientists, botanists, cultural resource specialists, engineers, etc.) used among other assessment tools hydrological modeling and soil burn severity mapping to assess potential flooding and vegetation recovery after the Cerro Grande Fire in 2000.\n\nA BAER plan is developed based on the risk assessments and burned area land management objectives. The BAER Plan identifies the most effective treatments to address the identified risks. Plan implementation timeframes are dictated primarily by anticipated future events (e.g., next significant rainstorm) which also influence treatment options.\n\nBurned area emergency response has mostly concentrated on risk reduction treatments with varying degrees of success. Risk avoidance, transfer and retention treatments are integral in the burned area emergency response risk management process.\n\nRisk reduction treatments are designed to protect human life and safety and reduce flood severity, soil erosion and prevent the establishment of non-native plants. On 10 wildfires studied in Colorado, rainfall amount and intensity followed by bare mineral soil explained 63% of soil erosion variation. Research has shown that the risk of flooding, debris flows and mudflows are significantly increased with increasing rainfall intensities and burn severity and that some risk reduction treatments help for low but not high intensity rainfall events.\n\nMulches, erosion cloth and seeding retard overland flow and protect soil from rain drop impact and increase soil moisture holding capacity. Landscape structures (e.g., log erosion barriers, contour trenches, straw wattles) trap sediment and prevent slope rilling. Strip tillage and chemicals break up or reduce hydrophobic soils and improve infiltration. Wood and straw mulch reduced erosion rates by 60 to 80%, contour-felled log erosion barriers 50 to 70%, hydromulch 19% and post fire seeding had little effect the first year when rainfall events were small and intensities low.\n\nIn stream flood control treatments slow, delay, redistribute, or redirect water, mud and debris. Straw bale check dams, silt screens and debris retention basins slow water flow and trap sediment. Riparian vegetation stabilizes streambanks. Roads and culverts are armored and debris removed as needed. Water diversion implements protect facilities and property.\n\nThe chance of introducing new invasive plants to the burned area is reduced by restricting access or thoroughly cleaning all equipment, people and animals of seeds before entering a burned area. Research has shown that non-native plant cover is positively associated with post-wildfire seeded grass cover. Even though post-wildfire seeding operations require seed mix purity standards and the number of contaminated seeds may be small on a percentage based, that the application of very large amounts of seed (thousands of pounds) ensures that a significant number of non-native plant seeds will be distributed.\n\nAvoidance treatments remove values at risk from risk prone areas. Frequently homes and other values are located on alluvial fans at the base of watersheds. The presence of the alluvial fans indicates a history of significant flooding, debris flows and mudflows with potential personal and property damage potential. Mobile property is temporally or permanently relocated. Evacuation planning and early warning systems are frequently used to protect people at risk. Flood peaks increase more rapidly with increases in rainfall intensity above a threshold value for the maximum 30 min intensity of approximately 10 mm per hour. That this rainfall intensity could be used to set threshold limits in rain gauges that are part of an early warning flood system after wildfire.\n\nOften it is not feasible to avoid or reduce risks. Flood insurance is a means of transferring risk to another party for values with insurable value.\n\nAccepting the risk is an option when values at risk are small and inevitable or when the risks cannot be reduced, avoided or transferred (i.e., infrequent catastrophic events).\n\n\n"}
{"id": "28860826", "url": "https://en.wikipedia.org/wiki?curid=28860826", "title": "Carp River (Michigan)", "text": "Carp River (Michigan)\n\nCarp River is the name of several rivers in the U.S. state of Michigan. \n\n\n"}
{"id": "4635274", "url": "https://en.wikipedia.org/wiki?curid=4635274", "title": "Chatter mark", "text": "Chatter mark\n\nA chatter mark is one or, more commonly, a series of wedge shaped marks left by chipping of a bedrock surface by rock fragments carried in the base of a glacier (glacial plucking). Marks tend to be crescent-shaped and oriented at right angles to the direction of ice movement.\n\nThere are three different types of chatter marks. The crescentic gouge is an upstream concave that is made by the removal of a piece of rock. The crescentic fracture which is a downstream concave that is also made by the removal of rock. The lunate fracture is also a downstream concave made without the removal of rock.\n\n"}
{"id": "22499392", "url": "https://en.wikipedia.org/wiki?curid=22499392", "title": "Cuban dry forests", "text": "Cuban dry forests\n\nThe Cuban dry forests are a tropical dry forest ecoregion that occupies on Cuba and Isla de la Juventud. The ecoregion receives of rainfall annually. Cuban dry forests can be differentiated into evergreen forests, semi-deciduous forests, mogotes, and sclerophyllous low forests.\n\nLess than 30% of all trees lose their leaves in evergreen forests, and there are few epiphytes or lianas. It is classified according to leaf length as being either mesophyllous (leaves ) or microphyllous (leaves ). Mesophyllous forest occurs at elevations from sea level to or . The canopy reaches a height of , while certain trees such as palms emerge at . The upper layer of trees in Sierra del Rosario includes aguacatillo (\"Alchornea latifolia\"), ocuje (\"Calophyllum antillanum\"), jocuma (\"Sideroxylon foetidissimum\") and macurije (\"Matayba oppositifolia\"). Yaya (\"Oxandra lanceolata\"), \"Wallenia laurifolia\", ramón de caballo (\"Trophis racemosa\") and \"Ficus\" species grow in the lower layer. Microphyllous evergreen forest establishes itself over coastal limestone. It has evergreen and deciduous trees that reach a height of or , some thorny shrubs, arborescent cacti, other succulents, epiphytes and dry lianas. Trees include júcaro espinoso (\"Bucida molinetii\"), cúrbana (\"Canella winterana\"), guayacán negro (\"Guaiacum sanctum\"), yaití (\"Gymnanthes lucida\"), cerillo (\"Hypelate trifoliata\"), soplillo (\"Lysiloma latisiliquum\"), guao de costa (\"Metopium toxiferum\"), almácigo (\"Bursera simaruba\"), caguairán amarillo (\"Hymenaea torrei\"), uvillón (\"Coccoloba diversifolia\"), and miraguanos (\"Coccothrinax\" spp.). Tuna (\"Opuntia stricta\") is an important understory species.\n\nAbout half of the trees in semi-deciduous forests are evergreen, along with shrubs, epiphytes, a few herbaceous plants, and many vines. Trees in this type of forest are often mesophyllous, with leaves long. The canopy in forests with consistent moisture reaches a height of and may have emergent species up to high as well as palms. The lower arboreal story includes deciduous and sclerophyllous evergreen trees. Soils are either red rendzinas, black rendzinas, or brown soils. Trees grow rapidly due to heavy rainfall during the summer. The upper layer of trees includes almácigo (\"Bursera simaruba\"), cedro-cheiroso (\"Cedrela odorata\"), dagame (\"Calophyllum candidissimum\"), ceiba (\"Ceiba pentandra\"), baría (\"Cordia gerascanthus\"), ateje (\"C. collococca\"), cuyá (\"Dipholis salicifolia\"), caoba (\"Swietenia mahagoni\"), ayúa (\"Zanthoxylum martinicense\"), guasiriano (\"Celtis trinervia\") and palma real (\"Roystonea regia\"). The lower layer includes jía (\"Casearia hirsuta\"), guara (\"Cupania americana\"), yamagua (\"Guarea trichiloides\"), yaya (\"Oxandra lanceolata\") and siguaraya (\"Trichilia havanensis\"). Forests with fluctuating moisture have an canopy, an understory of microphyllous and thorny deciduous species, and a forest floor covered in herbaceous geophytes.\n\nMogotes are conical mountains composed of karstic limestone and are found in western Cuba. Forests found on mogotes are characterized by a discontinuous story of trees high, as well as palms, plentiful succulents, epiphytes, and lianas. Plant life includes palma barrigona de sierra (\"Gaussia princeps\"), guanito de sierra (\"Thrinax morrisii\"), roble (\"Tabebuia calcicola\"), piñón (\"Erythrina cubensis\"), \"Malpighia roigiana\", palma corcho (\"Microcycas calocoma\"), \"Lantana strigosa\", \"Agave\" spp., and \"Leptocereus\" spp. The vegetation on rock faces is bushy and very open and includes shrubs and trees with specially adapted roots, such as the endemic ceibón (\"Pachira emarginata\").\n\nSclerophyllous low forests are found growing on serpentine soils and represent the transition between the dry forests and xeric scrublands. This is subdivided into charrascales (wet sclerophyllous low forests) and cuabales (dry sclerophyllous low forests). Cuabales can reach heights of , and palms and species with small, hard and very thorny leaves are abundant. Emergent trees can be found. Plant life includes cuabal (\"Leucocroton flavicans\"), anón del cuabal (\"Annona bullata\"), júcaro espinoso (\"Bucida molinetii\"), uverillo (\"Coccoloba praecox\"), chicharrón (\"Pseudocarpidium wrightii\"), palmas jatas (\"Copernicia\" spp.), miraguanos (\"Coccothrinax\" spp.), \"Buxus\" spp. \"Bourreria\" spp., robles (\"Tabebuia\" spp.), \"Guettarda\" spp., \"Rhodogeron coronopifolius\" and \"Agave cajalbanensis\".\n\nBirds of the dry forests include the West Indian woodpecker (\"Melanerpes superciliaris\"), Fernandina's flicker (\"Colaptes fernandinae\"), Cuban green woodpecker (\"Xiphidiopicus percussus\"), and blue-headed quail-dove (\"Starnoenas cyanocephala\"). Reptiles include anoles, geckos, and the Cuban boa (\"Epicrates angulifer\"). Desmarest's hutia (\"Capromys pilorides\") is a common species of mammal.\n"}
{"id": "19908550", "url": "https://en.wikipedia.org/wiki?curid=19908550", "title": "Diffusion", "text": "Diffusion\n\nDiffusion is the net movement of molecules from a region of higher concentration to a region of lower concentration. Diffusion is driven by a gradient in chemical potential of the diffusing species.\n\nA gradient is the change in the value of a quantity e.g. concentration, pressure, or temperature with the change in another variable, usually distance. A change in concentration over a distance is called a concentration gradient, a change in pressure over a distance is called a pressure gradient, and a change in temperature over a distance is called a temperature gradient.\n\nThe word diffusion derives from the Latin word, \"diffundere\", which means \"to spread way out\".\n\nA distinguishing feature of diffusion is that it depends on particle random walk, and results in mixing or mass transport without requiring directed bulk motion. Bulk motion, or bulk flow, is the characteristic of advection.\nThe term convection is used to describe the combination of both transport phenomena.\n\nAn example of a situation in which bulk motion and diffusion can be differentiated is the mechanism by which oxygen enters the body during external respiration known as breathing. The lungs are located in the thoracic cavity, which expands as the first step in external respiration. This expansion leads to an increase in volume of the alveoli in the lungs, which causes a decrease in pressure in the alveoli. This creates a pressure gradient between the air outside the body at relatively high pressure and the alveoli at relatively low pressure. The air moves down the pressure gradient through the airways of the lungs and into the alveoli until the pressure of the air and that in the alveoli are equal i.e. the movement of air by bulk flow stops once there is no longer a pressure gradient.\n\nThe air arriving in the alveoli has a higher concentration of oxygen than the “stale” air in the alveoli. The increase in oxygen concentration creates a concentration gradient for oxygen between the air in the alveoli and the blood in the capillaries that surround the alveoli. Oxygen then moves by diffusion, down the concentration gradient, into the blood. The other consequence of the air arriving in alveoli is that the concentration of carbon dioxide in the alveoli decreases. This creates a concentration gradient for carbon dioxide to diffuse from the blood into the alveoli, as fresh air has a very low concentration of carbon dioxide compared to the blood in the body.\n\nThe pumping action of the heart then transports the blood around the body. As the left ventricle of the heart contracts, the volume decreases, which increases the pressure in the ventricle. This creates a pressure gradient between the heart and the capillaries, and blood moves through blood vessels by bulk flow down the pressure gradient. As the thoracic cavity contracts during expiration, the volume of the alveoli decreases and creates a pressure gradient between the alveoli and the air outside the body, and air moves by bulk flow down the pressure gradient.\n\nThe concept of diffusion is widely used in: physics (particle diffusion), chemistry, biology, sociology, economics, and finance (diffusion of people, ideas and of price values). However, in each case, the object (e.g., atom, idea, etc.) that is undergoing diffusion is “spreading out” from a point or location at which there is a higher concentration of that object.\n\nThere are two ways to introduce the notion of \"diffusion\": either a phenomenological approach starting with Fick's laws of diffusion and their mathematical consequences, or a physical and atomistic one, by considering the \"random walk of the diffusing particles\".\n\nIn the phenomenological approach, \"diffusion is the movement of a substance from a region of high concentration to a region of low concentration without bulk motion\". According to Fick's laws, the diffusion flux is proportional to the negative gradient of concentrations. It goes from regions of higher concentration to regions of lower concentration. Sometime later, various generalizations of Fick's laws were developed in the frame of thermodynamics and non-equilibrium thermodynamics.\n\nFrom the \"atomistic point of view\", diffusion is considered as a result of the random walk of the diffusing particles. In molecular diffusion, the moving molecules are self-propelled by thermal energy. Random walk of small particles in suspension in a fluid was discovered in 1827 by Robert Brown. The theory of the Brownian motion and the atomistic backgrounds of diffusion were developed by Albert Einstein.\nThe concept of diffusion is typically applied to any subject matter involving random walks in ensembles of individuals.\n\nBiologists often use the terms \"net movement\" or \"net diffusion\" to describe the movement of ions or molecules by diffusion. For example, oxygen can diffuse through cell membranes so long as there is a higher concentration of oxygen outside the cell. However, because the movement of molecules is random, occasionally oxygen molecules move out of the cell (against the concentration gradient). Because there are more oxygen molecules outside the cell, the probability that oxygen molecules will enter the cell is higher than the probability that oxygen molecules will leave the cell. Therefore, the \"net\" movement of oxygen molecules (the difference between the number of molecules either entering or leaving the cell) is into the cell. In other words, there is a \"net movement\" of oxygen molecules down the concentration gradient.\n\nIn the scope of time, diffusion in solids was used long before the theory of diffusion was created. For example, Pliny the Elder had previously described the cementation process, which produces steel from the element iron (Fe) through carbon diffusion. Another example is well known for many centuries, the diffusion of colors of stained glass or earthenware and Chinese ceramics.\n\nIn modern science, the first systematic experimental study of diffusion was performed by Thomas Graham. He studied diffusion in gases, and the main phenomenon was described by him in 1831–1833:\n\n\"...gases of different nature, when brought into contact, do not arrange themselves according to their density, the heaviest undermost, and the lighter uppermost, but they spontaneously diffuse, mutually and equally, through each other, and so remain in the intimate state of mixture for any length of time.” \n\nThe measurements of Graham contributed to James Clerk Maxwell deriving, in 1867, the coefficient of diffusion for CO in the air. The error rate is less than 5%.\n\nIn 1855, Adolf Fick, the 26-year-old anatomy demonstrator from Zürich, proposed his law of diffusion. He used Graham's research, stating his goal as \"the development of a fundamental law, for the operation of diffusion in a single element of space\". He asserted a deep analogy between diffusion and conduction of heat or electricity, creating a formalism that is similar to Fourier's law for heat conduction (1822) and Ohm's law for electric current (1827).\n\nRobert Boyle demonstrated diffusion in solids in the 17th century by penetration of zinc into a copper coin. Nevertheless, diffusion in solids was not systematically studied until the second part of the 19th century. William Chandler Roberts-Austen, the well-known British metallurgist and former assistant of Thomas Graham studied systematically solid state diffusion on the example of gold in lead in 1896. :\n\n\"... My long connection with Graham's researches made it almost a duty to attempt to extend his work on liquid diffusion to metals.\"\nIn 1858, Rudolf Clausius introduced the concept of the mean free path. In the same year, James Clerk Maxwell developed the first atomistic theory of transport processes in gases. The modern atomistic theory of diffusion and Brownian motion was developed by Albert Einstein, Marian Smoluchowski and Jean-Baptiste Perrin. Ludwig Boltzmann, in the development of the atomistic backgrounds of the macroscopic transport processes, introduced the Boltzmann equation, which has served mathematics and physics with a source of transport process ideas and concerns for more than 140 years.\n\nIn 1920–1921, George de Hevesy measured self-diffusion using radioisotopes. He studied self-diffusion of radioactive isotopes of lead in the liquid and solid lead.\n\nYakov Frenkel (sometimes, Jakov/Jacob Frenkel) proposed, and elaborated in 1926, the idea of diffusion in crystals through local defects (vacancies and interstitial atoms). He concluded, the diffusion process in condensed matter is an ensemble of elementary jumps and quasichemical interactions of particles and defects. He introduced several mechanisms of diffusion and found rate constants from experimental data.\n\nSometime later, Carl Wagner and Walter H. Schottky developed Frenkel's ideas about mechanisms of diffusion further. Presently, it is universally recognized that atomic defects are necessary to mediate diffusion in crystals.\n\nHenry Eyring, with co-authors, applied his theory of absolute reaction rates to Frenkel's quasichemical model of diffusion. The analogy between reaction kinetics and diffusion leads to various nonlinear versions of Fick's law.\n\nEach model of diffusion expresses the diffusion flux through concentrations, densities and their derivatives. Flux is a vector formula_1. The transfer of a physical quantity formula_2 through a small area formula_3 with normal formula_4 per time formula_5 is\nwhere formula_7 is the inner product and formula_8 is the little-o notation.\nIf we use the notation of vector area formula_9 then\nThe dimension of the diffusion flux is [flux] = [quantity]/([time]·[area]).\nThe diffusing physical quantity formula_2 may be the number of particles, mass, energy, electric charge, or any other scalar extensive quantity. For its density, formula_12, the diffusion equation has the form\nwhere formula_14 is intensity of any local source of this quantity (the rate of a chemical reaction, for example).\nFor the diffusion equation, the no-flux boundary conditions can be formulated as formula_15 on the boundary, where formula_4 is the normal to the boundary at point formula_17.\n\nFick's first law: the diffusion flux is proportional to the negative of the concentration gradient:\nThe corresponding diffusion equation (Fick's second law) is\nwhere formula_20 is the Laplace operator,\n\nFick's law describes diffusion of an admixture in a medium. The concentration of this admixture should be small and the gradient of this concentration should be also small. The driving force of diffusion in Fick's law is the antigradient of concentration, formula_22.\n\nIn 1931, Lars Onsager included the multicomponent transport processes in the general context of linear non-equilibrium thermodynamics. For\nmulti-component transport,\nwhere formula_24 is the flux of the \"i\"th physical quantity (component) and formula_25 is the \"j\"th thermodynamic force.\n\nThe thermodynamic forces for the transport processes were introduced by Onsager as the space gradients of the derivatives of the entropy density \"s\" (he used the term \"force\" in quotation marks or \"driving force\"):\nwhere formula_27 are the \"thermodynamic coordinates\".\nFor the heat and mass transfer one can take formula_28 (the density of internal energy) and formula_27 is the concentration of the \"i\"th component. The corresponding driving forces are the space vectors\nwhere \"T\" is the absolute temperature and formula_32 is the chemical potential of the \"i\"th component. It should be stressed that the separate diffusion equations describe the mixing or mass transport without bulk motion. Therefore, the terms with variation of the total pressure are neglected. It is possible for diffusion of small admixtures and for small gradients.\n\nFor the linear Onsager equations, we must take the thermodynamic forces in the linear approximation near equilibrium:\nwhere the derivatives of \"s\" are calculated at equilibrium \"n\".\nThe matrix of the \"kinetic coefficients\" formula_34 should be symmetric (Onsager reciprocal relations) and positive definite (for the entropy growth).\n\nThe transport equations are\nHere, all the indexes \"i, j, k\" = 0, 1, 2, ... are related to the internal energy (0) and various components. The expression in the square brackets is the matrix formula_36of the diffusion (\"i,k\" > 0), thermodiffusion (\"i\" > 0, \"k\" = 0 or \"k\" > 0, \"i\" = 0) and thermal conductivity (\"i\" = \"k\" = 0) coefficients.\n\nUnder isothermal conditions \"T\" = constant. The relevant thermodynamic potential is the free energy (or the free entropy). The thermodynamic driving forces for the isothermal diffusion are antigradients of chemical potentials, formula_37, and the matrix of diffusion coefficients is\n(\"i,k\" > 0).\n\nThere is intrinsic arbitrariness in the definition of the thermodynamic forces and kinetic coefficients because they are not measurable separately and only their combinations formula_39 can be measured. For example, in the original work of Onsager the thermodynamic forces include additional multiplier \"T\", whereas in the Course of Theoretical Physics this multiplier is omitted but the sign of the thermodynamic forces is opposite. All these changes are supplemented by the corresponding changes in the coefficients and do not affect the measurable quantities.\n\nThe formalism of linear irreversible thermodynamics (Onsager) generates the systems of linear diffusion equations in the form\nIf the matrix of diffusion coefficients is diagonal, then this system of equations is just a collection of decoupled Fick's equations for various components. Assume that diffusion is non-diagonal, for example, formula_41, and consider the state with formula_42. At this state, formula_43. If formula_44 at some points, then formula_45 becomes negative at these points in a short time. Therefore, linear non-diagonal diffusion does not preserve positivity of concentrations. Non-diagonal equations of multicomponent diffusion must be non-linear.\n\nThe Einstein relation (kinetic theory) connects the diffusion coefficient and the mobility (the ratio of the particle's terminal drift velocity to an applied force)\nwhere \"D\" is the diffusion constant, \"μ\" is the \"mobility\", \"k\" is Boltzmann's constant, \"T\" is the absolute temperature.\n\nBelow, to combine in the same formula the chemical potential \"μ\" and the mobility, we use for mobility the notation formula_47.\n\nThe mobility—based approach was further applied by T. Teorell. In 1935, he studied the diffusion of ions through a membrane. He formulated the essence of his approach in the formula:\nThis is the so-called \"Teorell formula\". The term \"gram-ion\" (\"gram-particle\") is used for a quantity of a substance that contains Avogadro's number of ions (particles). The common modern term is mole.\n\nThe force under isothermal conditions consists of two parts:\nHere \"R\" is the gas constant, \"T\" is the absolute temperature, \"n\" is the concentration, the equilibrium concentration is marked by a superscript \"eq\", \"q\" is the charge and \"φ\" is the electric potential.\n\nThe simple but crucial difference between the Teorell formula and the Onsager laws is the concentration factor in the Teorell expression for the flux. In the Einstein–Teorell approach, If for the finite force the concentration tends to zero then the flux also tends to zero, whereas the Onsager equations violate this simple and physically obvious rule.\n\nThe general formulation of the Teorell formula for non-perfect systems under isothermal conditions is\nwhere \"μ\" is the chemical potential, \"μ\" is the standard value of the chemical potential.\nThe expression formula_51 is the so-called activity. It measures the \"effective concentration\" of a species in a non-ideal mixture. In this notation, the Teorell formula for the flux has a very simple form\nThe standard derivation of the activity includes a normalization factor and for small concentrations formula_53, where formula_54 is the standard concentration. Therefore, this formula for the flux describes the flux of the normalized dimensionless quantity formula_55:\n\nThe Teorell formula with combination of Onsager's definition of the diffusion force gives\nwhere formula_58 is the mobility of the \"i\"th component, formula_59 is its activity, formula_34 is the matrix of the coefficients, formula_25 is the thermodynamic diffusion force, formula_62. For the isothermal perfect systems, formula_63. Therefore, the Einstein–Teorell approach gives the following multicomponent generalization of the Fick's law for multicomponent diffusion:\nwhere formula_65 is the matrix of coefficients. The Chapman–Enskog formulas for diffusion in gases include exactly the same terms. Earlier, such terms were introduced in the Maxwell–Stefan diffusion equation.\n\nDiffusion of reagents on the surface of a catalyst may play an important role in heterogeneous catalysis. The model of diffusion in the ideal monolayer is based on the jumps of the reagents on the nearest free places. This model was used for CO on Pt oxidation under low gas pressure.\n\nThe system includes several reagents formula_66 on the surface. Their surface concentrations are formula_67 The surface is a lattice of the adsorption places. Each\nreagent molecule fills a place on the surface. Some of the places are free. The concentration of the free places is formula_68. The sum of all formula_69 (including free places) is constant, the density of adsorption places \"b\".\n\nThe jump model gives for the diffusion flux of formula_70 (\"i\" = 1, ..., \"n\"):\nThe corresponding diffusion equation is:\nDue to the conservation law, formula_73 and we\nhave the system of \"m\" diffusion equations. For one component we get Fick's law and linear equations because formula_74. For two and more components the equations are nonlinear.\n\nIf all particles can exchange their positions with their closest neighbours then a simple generalization gives\nwhere formula_77 is a symmetric matrix of coefficients that characterize the intensities of jumps. The free places (vacancies) should be considered as special \"particles\" with concentration formula_78.\n\nVarious versions of these jump models are also suitable for simple diffusion mechanisms in solids.\n\nFor diffusion in porous media the basic equations are:\nwhere \"D\" is the diffusion coefficient, \"n\" is the concentration, \"m\" > 0 (usually \"m\" > 1, the case \"m\" = 1 corresponds to Fick's law).\n\nFor diffusion of gases in porous media this equation is the formalisation of Darcy's law: the velocity of a gas in the porous media is\nwhere \"k\" is the permeability of the medium, \"μ\" is the viscosity and \"p\" is the pressure. The flux \"J\" = \"nv\" and for formula_82 Darcy's law gives the equation of diffusion in porous media with \"m\" = \"γ\" + 1.\n\nFor underground water infiltration, the Boussinesq approximation gives the same equation with \"m\" = 2.\n\nFor plasma with the high level of radiation, the Zeldovich–Raizer equation gives \"m\" > 4 for the heat transfer.\n\nThe diffusion coefficient formula_83 is the coefficient in the Fick's first law formula_84, where \"J\" is the diffusion flux (amount of substance) per unit area per unit time, \"n\" (for ideal mixtures) is the concentration, \"x\" is the position [length].\n\nLet us consider two gases with molecules of the same diameter \"d\" and mass \"m\" (self-diffusion). In this case, the elementary mean free path theory of diffusion gives for the diffusion coefficient\n\nwhere \"k\" is the Boltzmann constant, \"T\" is the temperature, \"P\" is the pressure, formula_86 is the mean free path, and \"v\" is the mean thermal speed:\nWe can see that the diffusion coefficient in the mean free path approximation grows with \"T\" as \"T\" and decreases with \"P\" as 1/\"P\". If we use for \"P\" the ideal gas law \"P\" = \"RnT\" with the total concentration \"n\", then we can see that for given concentration \"n\" the diffusion coefficient grows with \"T\" as \"T\" and for given temperature it decreases with the total concentration as 1/\"n\".\n\nFor two different gases, A and B, with molecular masses \"m\", \"m\" and molecular diameters \"d\", \"d\", the mean free path estimate of the diffusion coefficient of A in B and B in A is:\n\nIn Boltzmann's kinetics of the mixture of gases, each gas has its own distribution function, formula_89, where \"t\" is the time moment, \"x\" is position and \"c\" is velocity of molecule of the \"i\"th component of the mixture. Each component has its mean velocity formula_90. If the velocities formula_91 do not coincide then there exists \"diffusion\".\n\nIn the Chapman–Enskog approximation, all the distribution functions are expressed through the densities of the conserved quantities:\nThe kinetic temperature \"T\" and pressure \"P\" are defined in 3D space as\nwhere formula_96 is the total density.\n\nFor two gases, the difference between velocities, formula_97 is given by the expression:\nwhere formula_99 is the force applied to the molecules of the \"i\"th component and formula_100 is the thermodiffusion ratio.\n\nThe coefficient \"D\" is positive. This is the diffusion coefficient. Four terms in the formula for \"C\"-\"C\" describe four main effects in the diffusion of gases:\n\nAll these effects are called \"diffusion\" because they describe the differences between velocities of different components in the mixture. Therefore, these effects cannot be described as a \"bulk\" transport and differ from advection or convection.\n\nIn the first approximation,\nThe number formula_108 is defined by quadratures (formulas (3.7), (3.9), Ch. 10 of the classical Chapman and Cowling book)\n\nWe can see that the dependence on \"T\" for the rigid spheres is the same as for the simple mean free path theory but for the power repulsion laws the exponent is different. Dependence on a total concentration \"n\" for a given temperature has always the same character, 1/\"n\".\n\nIn applications to gas dynamics, the diffusion flux and the bulk flow should be joined in one system of transport equations. The bulk flow describes the mass transfer. Its velocity \"V\" is the mass average velocity. It is defined through the momentum density and the mass concentrations:\nwhere formula_110 is the mass concentration of the \"i\"th species, formula_111 is the mass density.\n\nBy definition, the diffusion velocity of the \"i\"th component is formula_112, formula_113.\nThe mass transfer of the \"i\"th component is described by the continuity equation\nwhere formula_115 is the net mass production rate in chemical reactions, formula_116.\n\nIn these equations, the term formula_117 describes advection of the \"i\"th component and the term formula_118 represents diffusion of this component.\n\nIn 1948, Wendell H. Furry proposed to use the \"form\" of the diffusion rates found in kinetic theory as a framework for the new phenomenological approach to diffusion in gases. This approach was developed further by F.A. Williams and S.H. Lam. For the diffusion velocities in multicomponent gases (\"N\" components) they used\nHere, formula_65 is the diffusion coefficient matrix, formula_123 is the thermal diffusion coefficient, formula_124 is the body force per unite mass acting on the \"i\"th species, formula_125 is the partial pressure fraction of the \"i\"th species (and formula_126 is the partial pressure), formula_127 is the mass fraction of the \"i\"th species, and formula_128\n\nWhen the density of electrons in solids is not in equilibrium, diffusion of electrons occurs. For example, when a bias is applied to two ends of a chunk of semiconductor, or a light shines on one end (see right figure), electron diffuse from high density regions (center) to low density regions (two ends), forming a gradient of electron density. This process generates current, referred to as diffusion current.\n\nDiffusion current can also be described by Fick's first law\nwhere \"J\" is the diffusion current density (amount of substance) per unit area per unit time, \"n\" (for ideal mixtures) is the electron density, \"x\" is the position [length].\n\nAnalytical and numerical models that solve the diffusion equation for different initial and boundary conditions have been popular for studying a wide variety of changes to the Earth's surface. Diffusion has been used extensively in erosion studies of hillslope retreat, bluff erosion, fault scarp degradation, wave-cut terrace/shoreline retreat, alluvial channel incision, coastal shelf retreat, and delta progradation. Although the Earth's surface is not literally diffusing in many of these cases, the process of diffusion effectively mimics the holistic changes that occur over decades to millennia. Diffusion models may also be used to solve inverse boundary value problems in which some information about the depositional environment is known from paleoenvironmental reconstruction and the diffusion equation is used to figure out the sediment influx and time series of landform changes.\n\n One common misconception is that individual atoms, ions or molecules move randomly, which they do not. In the animation on the right, the ion on in the left panel has a “random” motion, but this motion is not random as it is the result of “collisions” with other ions. As such, the movement of a single atom, ion, or molecule within a mixture just appears random when viewed in isolation. The movement of a substance within a mixture by “random walk” is governed by the kinetic energy within the system that can be affected by changes in concentration, pressure or temperature.\n\nWhile Brownian motion of multi-molecular mesoscopic particles (like pollen grains studied by Brown) is observable under an optical microscope, molecular diffusion can only be probed in carefully controlled experimental conditions. Since Graham experiments, it is well known that avoiding of convection is necessary and this may be a non-trivial task.\n\nUnder normal conditions, molecular diffusion dominates only on length scales between nanometer and millimeter. On larger length scales, transport in liquids and gases is normally due to another transport phenomenon, convection, and to study diffusion on the larger scale, special efforts are needed.\n\nTherefore, some often cited examples of diffusion are \"wrong\": If cologne is sprayed in one place, it can soon be smelled in the entire room, but a simple calculation shows that this can't be due to diffusion. Convective motion persists in the room because of the temperature [inhomogeneity]. If ink is dropped in water, one usually observes an inhomogeneous evolution of the spatial distribution, which clearly indicates convection (caused, in particular, by this dropping).\n\nIn contrast, heat conduction through solid media is an everyday occurrence (e.g. a metal spoon partly immersed in a hot liquid). This explains why the diffusion of heat was explained mathematically before the diffusion of mass.\n\n"}
{"id": "45653966", "url": "https://en.wikipedia.org/wiki?curid=45653966", "title": "Diwata-1", "text": "Diwata-1\n\nDiwata-1 also known as PHL-Microsat-1 is a Philippine microsatellite launched to the International Space Station (ISS) in March 23, 2016, and was deployed into orbit from the ISS in April 27, 2016. It is the first Philippine microsatellite and the first satellite built and designed by Filipinos.\n\nHokkaido University and Tohoku University of Japan initiated a project to send 50 microsatellites into space by 2050. The project will photograph aftermaths of natural disasters, partnering with governments, universities and other organizations based in Bangladesh, Indonesia, Malaysia, Myanmar, Mongolia, Philippines, Thailand, and Vietnam. Two satellites are commissioned for the Philippine government. \n\nDiwata-1 is the first satellite of the venture made possible through the Philippine Scientific Earth Observation Microsatellite (PHL-Microsat) Program, a three-year program funded by the Department of Science and Technology (DOST). The program is a collaboration between the University of the Philippines, the DOST-Advanced Science and Technology Institute (DOST-ASTI), and Japan's Tohoku University and Hokkaido University. It was initiated on December 2014 by DOST. The satellite is an updated version of the Raijin-2, which was developed by the two Japanese universities.\n\nUploading of commands to Diwata-1 and downloading of the images are done in the Philippines' very own Philippine Earth Data Resources Observation Center (PEDRO) ground receiving station. Image processing is also performed locally.\n\nThere were two Philippine satellites before Diwata-1, Agila-1 and Agila-2 (later renamed ABS-3) but the former was owned and operated by a non-Philippine firm, PT Pasifik Satelit Nusantara, at the time of its launch and the latter was owned by Mabuhay Satellite Corporation, a private local firm, but later acquired by Asia Broadcast Satellite, a foreign firm.\n\nThe government has been availing services from foreign countries for satellite imagery. Carlos Primo David, former Executive Director of the Philippine Council for Industry, Energy and Emerging Technology Research and Development (PCIEERD) called the PHL-Microsat program a \"small investment\" taking note that in 2013, following the aftermath of Typhoon Haiyan (locally known as Typhoon Yolanda), the government had to pay about for satellite imagery of an area affected by the typhoon dubbed as the \"Yolanda Corridor\". This led to the creation of the PHL-Microsat program.\n\nThe satellite was named after a type of divine being from Philippine mythology, the diwata.\n\nA team of nine Filipino engineers from the DOST-Advanced Science and Technology Institute (ASTI) and the University of the Philippines, dubbed the \"Magnificent 9\", were responsible for the production of Diwata-1 and collaborated with scientists and engineers from the two Japanese universities. They were sent to Japan in October 2015. The assembly and testing of Diwata-1 was completed in December 2015.\n\nDiwata-1 was handed over to the Japan Aerospace Exploration Agency (JAXA) on January 13, 2016, at the Tsukuba Space Center in Tsukuba, Japan. On January 18, 2016, JAXA sent the satellite to the National Aeronautics and Space Administration (NASA) in the United States after conducting final tests on the satellite.\n\nComponent tests, first vibration tests, post-vibration electrical tests, off-gas test, and fit checking were conducted on the satellite. Continuous functionality test of modules and sensors and software optimization were also done on the satellite.\n\nDiwata-1 has three scientific instruments: the High Precision Telescope (HPT); Space-borne Multispectral Imager (SMI) with Liquid Crystal Tunable Filter (LCTF); and the Wide Field Camera (WFC). Diwata-1 also has one engineering control instrument, the Middle Field Camera (MFC).\n\nThe HPT – with a ground sample distance (GSD) of at – is currently being studied on how it can be used to monitor the extent of damages from natural disasters such as typhoons. It is also equipped with four CCDs for the red, blue, green, and near infrared regions of light.\n\nThe SMI with LCTF – with a GSD of at – is currently being studied on how it can be used in measuring vegetation changes and phytoplankton biomass in Philippine waters. The instrument is equipped with two CCDs for both visible (420–700 nm) and near infrared (650–1050 nm) regions with a 13 nm interval.\n\nThe WFC – which has a GSD of and a panchromatic CCD with a field view of 1800 × 1340 – is used to give visualizations of large-scale cloud patterns and distributions. Diwata-1 can be used to take daily images using the WFC in case of any upcoming large-scale weather disturbances, such as storms or typhoons.\n\nThe calibration of the attitude determination algorithm will be handled by the MFC. The instrument is equipped with a colored CCD and expected GSD of , and will also aid in locating images captured by the HPT and SMI.\n\nThe launch of Diwata-1 occurred on March 23, 2016, at Cape Canaveral, Florida in the United States. It was a payload of Orbital ATK's Cygnus spacecraft which was launched through the Atlas V rocket as part of a supply mission to the International Space Station (ISS). Initially, the plan was to launch Diwata-1 through a vehicle by SpaceX, from either California or Florida. Earlier, an orbital slot was secured from JAXA for Diwata-1. Cygnus managed to reach the ISS in March 26. The spacecraft unloaded its cargo, including Diwata-1, to the ISS in the span of two weeks.\n\nDiwata-1 was set to be deployed from the International Space Station from the Kibo module. The satellite was inspected on board the station before its deployment in April for at least 18 months of program activity. The deployment mechanism for the satellite was the JEM Small Satellite Orbital Deployer (J-SSOD).\n\nBy January 2016, the Kibo module had already deployed 106 small satellites. The Diwata-1 deployment marked the first attempt of the module to deploy a smaller, 50-kg class, microsatellite. The deployment of Diwata-1 was scheduled on April 20 or 21, 2016. Prior to the Cygnus launch, The DOST has made a request to JAXA to deploy the satellite into space between March 21 and April 30, 2016, at the time the ISS is at its highest altitude. The deployment was later announced to take place in April 27, 7:00 p.m (PST). The actual deployment occurred at 7:45 p.m. with British astronaut Tim Peake involved in the operation to put the satellite into orbit.\n\nIn the occasion of the deployment, the Philippine flag was raised along with the Japanese flag at the Tsukuba Space Center of the JAXA.\n\nThe mission duration of the satellite is expected to take place for around 20 months, 2 months longer than earlier reported. The engineering team behind Diwata-1 at the Tohoku University was able to receive the satellite's first communication hours later after its deployment from the ISS, at 7:45 p.m. PST.\n\nA ground station based in the Philippines, the Philippine Earth Data Resources Observation (PEDRO) Center, has primary control over the satellite with a command line on the UHF band. PEDRO receives telemetry data sent by Diwata-1 via UHF band and receives images via X-band. The Tohoku University Ground station (CRESST) also has access to the satellite.\n\nWeeks into the satellite's deployment since the Cygnus launch, the setting up of a temporary ground receiving station at the DOST ASTI building was being hastened by DOST units, PCIEERD and Advanced Science and Technology Institute. Diwata-1 was operational at least a week after its deployment into orbit.\n\nThe satellite's first images were released in public by the Tohoku University on June 2, 2016, via a Japanese press release. The satellite shot images of Isabela province on the island of Luzon, and parts of Northern Japan.It has also captured images of the coastlines of Palawan, showing signs of siltation on certain parts of the coastline.\n\nAs of October 2018, Diwata-1 has captured 14,492 images in the Philippines covering an area equivalent to 32 percent of the country's land area. Among those captured images was that of Semirara Island and Laguna de Bay. As of the same month, the satellite remains operational and is projected to be still functioning for at least three years given favorable conditions in space.\n\nOne of the major goals of the PHL-Microsat program, to which Diwata-1 belongs, is to boost the progress on the creation of the Philippine Space Agency. Then-DOST secretary Mario Montejo said that the Diwata-1 may pave the way for development of the local electronics and aerospace industries, which would complement a satellite-building industry.\n\nThe University of the Philippines Diliman campus has allocated an area for a space research laboratory for the continued development of microsatellite technology, where the Filipino scientists who were involved in the Diwata-1 project can teach and train local engineers. The facility will be funded by the PCIEERD of DOST.\n\n"}
{"id": "57151017", "url": "https://en.wikipedia.org/wiki?curid=57151017", "title": "Drakoo wave energy converter", "text": "Drakoo wave energy converter\n\nThe Drakoo wave energy converter is a technological device that uses the motion of ocean surface waves to generate electricity.\n\nThe Drakoo WEC does not fall under any of the usual wave energy converter classifications: its working principle, based on a twin-chamber oscillating water column system, is to transform waves into a continuous water flow which drives a hydro turbine generator.\n\nafter being patented in 2008, the Drakoo technology has successfully been tested in NTU lab and, subsequently, in the deep wave flume of NAREC in 2012(UK).\n\nOn December 23, 2016, Hann Ocean Energy, the Singapore wave developer company which invented and patented the technology, announced the first successful power production during a trial in its testing facility in Nantong, with a peak power output of 3.8 kW at a wave height of 0.6m.\n\nThe technology continuously increased its performances along the years, reaching firstly a peak output power of 9.3 kW in November 2017 and of 11.2 kW in March 2018. Moreover, during the World Future Energy Summit 2018, in Abu Dhabi, Hann Ocean Energy reported about sales inquiries from the Persian Gulf for the application of the Drakoo WEC for wellhead platforms.\n"}
{"id": "3895831", "url": "https://en.wikipedia.org/wiki?curid=3895831", "title": "Ecological debt", "text": "Ecological debt\n\nEcological debt refers to the accumulated debt of wealthier countries (from a defined date in the past until present) for having plundered poorer countries by the exploitation of their resources, the degradation of their natural habitat, the beggaring of local people and/or the free occupation of environmental space for waste discharge. The definition in itself has varied over the years and several scholars have attempted a greater specification of the concept.\n\nWithin the ecological debt definition, two types of aspects are understood: the ecological damage caused over time by a country in one or other countries or to ecosystems beyond national jurisdiction through its production and consumption patterns; and the exploitation or use of ecosystems over time by a country at the expense of the equitable rights to these ecosystems by other countries.\n\nThe term 'ecological debt' first appeared on paper in 1985, in a yellow booklet with the title “Women in movement\" made by the German ecofeminist and edited by the Green Party in Germany in 1985. The work was intended to be used for a workshop she gave on 'women, peace and ecology' in Nairobi during the United Nation Women’s Conference (the first workshop of this kind).\n\nIn 1992, the term appeared again in two reports published in different places around the world: “\"Deuda ecológica\"” by Robleto and Marcelo in Chile and “\"Miljöskulden\"” by Jernelöv in Sweden. Robleto and Marcelo's report, published by the critical NGO \"Instituto de Ecologia Politica\" (IEP), was a political and activist response to the global environmental negotiations happening during the Rio Summit. It shed light on the debate occurring in Latin America since the 1980s about the crucial nature's heritage that had been consumed and not returned (i.e. ecological debt). On the other hand, Jernelöv's report goal was to calculate the Swedish debt for future generation and was intended to serve nationally for the Swedish Environmental Advisory. Although the last one had less world-wide influence in the concept's debate, it is important to note that both reports have opposite approach in considering the ecological debt: Robleto and Marcelo's report expresses it in symbolic terms, focusing on the moral and political aspects, whereas Jernelöv's report tries to quantify and monetize it in economic terms.\n\nIn 1994, the Colombian lawyer Borrero, wrote a book on ecological debt. It referred to the environmental liabilities of Northern countries for the excessive per capita production of greenhouse gases, historically and at present. The concept has then been reused by some environmental organizations from the Global South. Campaigns on the ecological debt were launched since 1997 by Accion Ecologica of Ecuador and Friends of the Earth.\n\nOverall, the ecological debt 'movement' was born of the convergence of three main factors during the 80s-90s: 1) the consequences of the debt crisis in the 70s due to the Volcker shocks or the drastic increase of interest rates (followed by structural adjustments made by the US to solve the stagflation in 1981, and thus putting heavily indebted third world countries in an impossible situation in regards to debt repayment); 2) the rising of environmental awareness as seen previously (activists and NGOs attending the Rio Summit in 1992); 3) an increase in recognition of the violence caused by colonialism over the years (the demand of recognition is over 500 years, since Columbus arrived in North America).\n\nIn 2009, ecofeminist scholar Ariel Salleh explained how the capitalist processes at work in the global North exploit nature and people simultaneously, ultimately sustaining a large ecological debt in her article, \"Ecological Debt: Embodied Debt\". At the 1992 Rio Earth Summit, politicians and corporate leaders from the global North introduced the supposed solution for the foreign debt crisis in the global South. They proposed 'debt for nature swaps', which essentially means that those countries that possess abundant biodiversity and environmental resources would give them up to the global North in return for the World Bank reducing their debt.\n\nFeminist environmentalists, Indigenous activists, and peasants from the Global South, exposed how the Global North is much more indebted to the Global South. Salleh justified this by explaining how the 500-year-long colonialisation process involving the extraction of resources has caused immense damage and destruction to the ecosystem of the Global South. In fact, scientists at the US National Academy for Sciences state that in the time period of 1961–2000, by analyzing the cost of greenhouse gas emissions created by the rich (the Global North) alone, it has become apparent that the rich have imposed climate changes on the poor that greatly outweigh the poor's foreign debt. All of this environmental degradation amounts to ecological debt, seizing the people's livelihood resources in the Global South.\n\nIn 2009 as well, Andrew Simms used the ecological debt in a more bio-physical way and defined it as the consumption of resources from within an ecosystem that exceeds the system's regenerative capacity. This is seen in particular in non-renewable resources wherein consumption outstrips production. In a general sense in his work, it refers to the depletion of global resources beyond the Earth's ability to regenerate them. The concept in this sense is based on the bio-physical carrying capacity of an ecosystem; through measuring ecological footprints human society can determine the rate at which it is depleting natural resources. Ultimately, the imperative of sustainability requires human society to live within the means of the ecological system to support life over the long term. Ecological debt is a feature of unsustainable economic systems.\n\nThere have been several debates around the notion of ecological debt, and this is mostly because the concept arises from various social movements in response to distributional injustice of climate change's consequences on the environment and people's livelihood.\n\nSalleh in particular showed how the ecological debt manifested in the destruction of the environment and associated climate change the North has created is made possible through the process of modernization and capitalism. The rise of the nature-culture divide that emerged due to rapid industrialisation is a perfect illustration of a human-nature dualism in which human being has the central role above everything else. The notion of humans being embedded in the ecosystem that they live in is crucial to the discipline of political ecology.\n\nIn political ecology, which reconnects nature and the economy, ecological debt is crucial because it recognizes that colonization has not only resulted in a loss of culture, way of life, and language for Indigenous peoples, but it has shaped the world economy into one that monetizes and commodifies the environment. For example, when the colonization of South America occurred over 500 years ago, European settlers brought with them their Eurocentric values, seeing themselves as better than and therefore entitled to the Indigenous people's knowledge and the land they lived on. In a perceived post colonial world, large corporations and Western governments tend to present solutions to global warming by commodifying nature and hoping to make a profit out of it. This better-than-thou attitude has created the conditions for global warming to occur, making the North’s ecological footprint soar, while also constructing an ecological debt so large as to completely rid the entire Global South of their financial debt.\n\nDuring the Rio Earth Summit in 1992, attending NGOs created the Debt Treaty, a document gathering all information to better define the ecological debt concept. They demanded compensation for damages over 500 years (1992 is exactly 500 years after the arrival of Columbus in North America). It was a first push back, reversing the stream, but it stayed as a draft paper not recognized by international institutions or lead countries at that time.\nIn the 2000s, two networks were created and still exist today: the Southern Peoples Ecological Debt Creditors Alliance (SPEDCA) which is a network of creditors that launched a campaign for the recognition of ecological debt, and the European Network for the Recognition of Ecological Debt (ENRED) which is a network of debtors.\n\nDuring the COP in Copenhagen in December 2009, some governments from developing countries or countries most vulnerable to climate change consequences (such as Bolivia, Mauritania, Chad, or island countries as Maldives or Haiti) have argued that the principle of shared responsibility demands that rich nations or developed economies (such as the United States, some European countries, China) go beyond donations or adaptation credits and make reparations that recognize an ecological debt for excessive emissions over several decades. The top United States ambassador, Todd Stern, flatly rejected arguments by diplomats from these countries that the United States owed such a debt.\n\nThe COP 21 in Paris brought minor progress with an increase in financial aid for developing countries. Although the goal was to prepare future action to be undertaken for adapting to climate change and consider loss and damages (especially displaced people) of some countries, no real action was adopted. There were no recognition of responsibilities but recommendations only.\n\nWhen discussing ecological debt, climate debt appears to be the only example of a scientific attempt to quantify the debt. It incorporates two different elements: the adaptation debt which is the cost to communities of adapting to climate damages they are not responsible for, and the consumption debt or emission's debt which is compensation due for emitting carbon in the present time.\n\nAcademic work on calculations of the ecological debt came later. An article published in 2008 looked at the distribution of ecological impacts for various human activities. Studies were also produced at regional level within countries, for instance for Orissa in India.\n\nAs seen previously, calculation of the ecological debt implies various aspects related to political ecology. While calculation the amount of emissions, some scholars have disregard inequalities of emissions from the past whereas others have considered historical accountability.\n\nIn 2000, Neumayer calculated what he named the 'historical emissions debt', consisting on the difference in emissions of actual historical emissions (from a specific date in the past) and equal per-capita emissions (current emissions).\n\nTheoretically, it may be possible to put a money value on ecological debt by calculating the value of the environmental and social externalities associated with historic resource extraction and adding an estimated value for the share of global pollution problems borne by poor countries as the result of higher consumption levels in rich ones. This includes efforts to value the external costs associated with climate change.\n\nIn 2015, Matthews proposed a method to calculate the ecological debt, by looking at the accumulated `carbon debts' for each country. The model uses historical estimates of national fossil fuel CO emissions and population and this since 1960. Furthermore, it runs a comparison between temperature changes each year by each country's emissions compared to a proportional temperature change of each country's share of the world population (this same year). This gives the accumulated credits and debts related to a larger range of emissions and the 'climate debts' obtained would be the difference between the actual temperature change (caused by each country) and their per-capita share of global temperature change.\n\nOther scholars have proposed a different approach, a `modified equal shares' approach, that would consider each country's basic needs and would weight each ones' share of emissions. However, this approach brings potential ethical and political difficulties to quantitatively defining what would thus be the equal shares.\n\nAlthough some recent emerging countries have participated in the increase of carbon emissions, the situation tend to stay uneven in-between developing and developed countries regarding who is affected the most versus who pollutes the most.\n\nRecent studies on ecological debt focus more on sub-topics as the notion of historical responsibility (whether or not a country is considered ethically responsible or accountable for carbon emissions prior 1990, i.e. when global warming was universally recognized), the components of climate debt (see above sections), the difficulties in deciding when to start counting past emissions and if this debate is slowing the implementation of programs or the legal and political consecration of the debt through treaties.\n\nPresent key debates focus on how is the debt going to be paid back. First, some academia have pushed for financial debt cancellation rather than being paid for ecological damages and then paying back the country's national financial debt. However, financial debts were not even agree by people (in developing countries especially) in the first place, calling it the unfair \"Volcker debt\". Accepting this option could hold the risk of giving legitimize credits to these financial debts. A second solution proposed is the Basic Income Guarantee (BIG) or the universal basic income. It consists on regular cash payments to everyone in a community (or country) and has proven a certain efficacy in some places around the world (like Namibia).\n\nAnother debate addresses the fact that the ecological debt risks “commodifying nature”, exhausting ecosystem services. Researchers have tackled this risk by showing how it will expand the inclination of objectifying, monetizing and ultimately commodifying nature. Moreover, the language of debt, repayments, credits and so forth is understood in Northern countries mostly, and is mostly focused on recognition of wrongdoing but not payment for loss of services for instance.\n\n\n\n\n"}
{"id": "24457667", "url": "https://en.wikipedia.org/wiki?curid=24457667", "title": "Electricity sector in Uruguay", "text": "Electricity sector in Uruguay\n\nThe electricity sector of Uruguay has traditionally been based on domestic hydropower along with thermal power plants, and reliant on imports from Argentina and Brazil at times of peak demand. \nOver the last 10 years, investments in renewable energy sources such as wind power and solar power allowed the country to cover in early 2016 94.5% of its electricity needs with renewable energy sources.\n\nHydropower provides a large percentage of installed production capacity in Uruguay, almost all of it produced by four hydroelectric facilities, three on the Rio Negro and one, the Salto Grande dam shared with Argentina, on the Uruguay River. The production from these hydropower sources is dependent on seasonal rainfall patterns, but under normal hydrological conditions, can supply off-peak domestic demand.\n\nThermal power from petroleum fired power plants, activated during peak demand, used to provide the remaining installed production capacity. \nGeneration from fossil fuel decreased substantially in recent years, with renewables accounting for 94.5% of electricity generation in 2015.\nThermal power from biomass also provides additional power generation capacity.\n\nThe shift to renewable energy sources in recent years has been achieved thanks to modernization efforts, based on legal and regulatory reforms in 1997, 2002, and 2006, which have led to large new investments in electrical production capacity including from the private sector. Wind power capacity has gone from negligible in 2012 to 10% of installed capacity by 2014.\nA new, highly efficient thermal power plant which can run on either gas or oil has been installed.\nA number of photovoltaic solar power plants have been built. \nAdditionally, a new electrical grid interconnection has improved the ability to import or export electricity with Brazil.\n\nInstalled electricity capacity in Uruguay was around 2,500 MW (megawatts) in 2009 and around 2,900 MW in 2013. Of the installed capacity, about 63% is hydro, accounting for 1,538 MW which includes half of the capacity of the Argentina-Uruguay bi-national Salto Grande. The rest of the production capacity is mostly thermal and a small share of wind and biomass.\n\nThe power system exhibits characteristics and issues of hydro-based generation. The apparently wide reserve margin conceals the vulnerability to hydrology. In dry years it is necessary to import over 25% of the demand from Argentinian and Brazilian markets.\n\nAbout 56% of generation capacity is owned and operated by UTE, the national utility. The remaining capacity corresponds to the Salto Grande hydroelectric plant (945 MW), to co-generation or to small private investments in renewable sources. The table below shows the plants that are operated and owned by UTE as of 2008:\n\nInstalled capacity had barely changed between 1995 and 2008. The most recent addition was the 300 MW Punta del Tigre Plant, whose last units started operations in 2008. A 530 MW dual fuel (gas/light oil) CCGT power plant, \"Punta del Tigre B\", is being built in the Punta del Tigre site; construction started in late 2013 and final completion is expected by late 2018. The existing large hydroelectric potential has already been developed and the existing thermal units are low performing. Total generation in the year 2008 was 8,019 GWh, 56.1% of which were from hydroelectric sources, with 42.2% being thermal.\n\nIn the years leading up to 2009, the Uruguayan electricity system has faced difficulties to supply the increasing demand from its domestic market. In years of low rainfall, there is a high dependency on imports from Brazil and Argentina. Exports have historically been negligible. In particular, no electricity has been exported in 2009.The table below shows the evolution of imported electricity since 1999:\n\n(1) January–June 2009\nThese energy exchanges happen through two existing interconnections, a 500kv line with Argentina, through Salto Grande, and a 70kv line with Brazil, through Garabi.\n\nTotal electricity consumption in 2008 was 7,114 GWh, which corresponds to a per capita consumption of 2,729 kWh. Share of consumption by sector was as follows: \n\nIn the period 2002-2007, after the 2002-2003 economic and financial crisis, electricity demand increased 4.9% per year on average. Electricity demand increased by 7.5% between 2006 and 2007, from 6,613 GWh to 7,112 GWh, reaching a per capita value of 2,143 kWh. Yearly demand increase is expected to be about 3.5% during the next ten years.\n\nMaximum demand on the order of 1,500 MW (historic peak demand, 1,668 MW happened in July 2009) is met with a generation system of about 2,200 MW capacity. This apparently wide reserve margin conceals a high vulnerability to hydrology.\n\nAccess to electricity in Uruguay is very high, above 98.7%. This coverage is above average for countries with public electricity services. Quality of service is perceived to be good both by companies and residential users. Companies suffer losses of just about 1.1% of their sales due to electricity service interruptions \n\nInterruption frequency and duration are considerably below the averages for the LAC region. In 2004, the average number of interruptions per subscriber was 7.23, while duration of interruptions per subscriber was 9.8 hours. The weighted averages for LAC were 13 interruptions and 14 hours respectively.\n\nUTE has implemented a series of measures to reduce electricity losses, which were particularly high during the 2002-2003 crisis. In December 2007, losses were still high, about 18%, of which 7% to 8% were of technical nature.\n\nThe National Directorate of Energy and Nuclear Technology (DNTEN) formulates energy-sector policies. The regulatory functions are assigned to URSEA, the regulatory body. Both transmission and distribution activities are fully under the control of UTE, as established by the 1997 law.\n\nCurrently, there are four private companies that generate electricity for their own consumption and sell their surplus to the grid: Botnia (biomass, 161 MW), Agroland (wind, 0.3 MW), Nuevo Manantial (wind, 10 MW) and Zenda (natural gas, 3.2 MW). The Azucarlito plant (5 MW) operates in the spot market. The current 6% private contribution to the generation park is expected to increase as investments in new wind power plants materialize.\n\nRenewables could play a role in future energy supply, in particular wind power, allowing Uruguay to reduce its dependence on imports.\n\nAll the potential for large hydroelectric projects in Uruguay has already been developed. Existing plants are Terra (152 MW), Baygorria (108 MW), Constitucion (333 MW) and the bi-national Salto Grande, with a total capacity of 1,890 MW.\nUruguay has a favorable climate for generating electricity through wind power, but its cost – estimated at US$45–50/MWh for large projects (50-100 MW) - is still uncertain. Consequently, the estimated wind potential of 600 MW cannot yet be taken as a feasible value, from an economic standpoint. Despite those difficulties, according to the Government’s strategic plan, Uruguay will have 300 MW of installed wind capacity in 2011 and should reach 500 MW in 2015. The National Environmental Directorate (DINAMA) has already received several requests for new wind projects and UTE had a very positive response to the bidding process launched in mid-2009 In August 2009, the government of Uruguay approved a Decree that allows UTE to bid 150 MW of wind power. USD 300 million of private investment are expected as a result.\n\nThe first wind farm in Uruguay, the 10 MW Nuevo Manantial project in Rocha, which will sell the electricity generated to UTE, started operations in October 2008. A few months later, in January 2009, UTE’s 10 MW wind farm in Sierra de los Caracoles also started operations.\n\nBiomass based on renewable sources such as rice husk could generate up to 20 MW at competitive prices. Firewood has already been used as a substitute for fuel oil in the 1980s, and cellulose projects expect to generate up to 65 MW for sales to the network.\n\nIn 1997, the national electricity law was updated following the principles of the so-called “standard\nmodel,” which contemplated the separation of regulatory/governance functions from corporate functions, and put in place the regulatory agency URSEA and a market administrator, ADME. The reform contemplated the remuneration of generators in order of merit, the creation of a wholesale market with regulated prices in transmission and distribution, where competition is not possible.\n\nThe reform has not been effectively implemented. After passing the modifications to the electricity law, secondary legislation was not forthcoming and the system continued to operate without any significant change. The new model was regulated in 2002 and it was expected that new operators would enter into a competitive market. The market did not develop as planned and demand actually decreased due to the economic crisis in the region. For instance, natural gas provision, which could have supplied new power generating units, did not materialize. Although URSEA and ADME were established, they cannot yet fulfil most of the functions established in their mandate.\n\nFor a full decade no power capacity was added to the power system. Prior to the completion of the 100 MW Punta del Tigre diesel power plant in August 2005, UTE had not added a power station to the system since 1995, when the last unit of Salto Grande came online. The absence of commissioning of new production facilities during this extended period was the product of a conscious, strategic decision to take advantage of market developments in Argentina and in the region, which would allow imports to fill any Uruguayan shortfalls, while exporting hydropower surplus production to Argentina and Brazil during wet years.\n\nDependence on imports from Argentina started to become problematic in 2004. Before 2004, UTE was able to supply its demand through a combination of contracts and purchases on the Argentinean spot market. As a result of the Argentine energy difficulties, UTE’s contracts with Argentina for firm supply of 365 MW were reduced to 150 MW and were not extended beyond 2007. Notwithstanding this forced reduction in supply from Argentina over the low hydrology period of 2004-06, UTE was able to maintain energy imports through a noticeable increase of imports from Brazil and purchase of energy from the Argentine spot market. In 2008, supply costs increased substantially as the drought, high fuel costs and low availability of power in neighboring countries.\n\nThe Energy Strategy Guidelines for Uruguay were defined in 2006 by the Ministry of Industry, Energy and Mines (MIEM). This strategy includes: (i) diversifying energy sources to reduce costs and emissions, as well as increase energy security; (ii) increasing private participation in new renewable power generation; (iii) increasing regional energy trade; and (iv) facilitating availability and acquisition of energy efficient goods and services, including efforts to raise public awareness regarding demand-side management interventions. According to the National Directorate for Energy and Nuclear Technology (DNETN), grid-connected wind power generation is one of the domestic resources with both medium and long term potential in Uruguay.\n\nThe government has taken action to promote RE development. In March 2006, the executive power issued Decree No.77/2006 to foster private generation through wind, biomass and small hydropower plants. A target of 60 MW was established for the first tender, which was conducted by UTE in August 2006. Although bids received for wind and biomass projects were all higher than US$70/MWh, this can be attributed to the small size of the proposed projects and the uncertainty of contractual arrangements.\n\nInterconnecting with Brazil is also particularly attractive. The expansion of the interconnection capacity with Brazil may be carried out either along the Coast or from Salto Grande. This expansion would contribute to diversifying the supply sources and could be done in order to take advantage of the installation of large thermal (coal) plants in the South of Brazil.\n\nFor 2008, the overall weighted average tariff was US$0.139/kWh. Average tariffs for some sectors are presented below:\n\nOLADE (Organización Latinoamericana de Energía) estimated that CO emissions from electricity production in 2006 were 1.55 million tons of CO. As of September 2009, there were only three registered CDM projects in Uruguay, all of them related to energy: the Montevideo Landfill Gas Capture and Flare Project, the Fray Bentos Biomass Power Generation Project and a project on partial substitution of fossil fuels with biomass in cement manufacture. Total expected emissions reductions are 251,213 tons of COe per year.\n\nThe only active energy project financed by the World Bank in Uruguay is the Energy Efficiency Project (PERMER), with a USD 6.88 million grant from the Global Environmental Facility. The objective this project is to increase the demand for and competitive supply of energy efficiency goods and services, contributing to improved efficiency of energy use, reduced reliance of the Uruguayan economy on imported electricity and fuels, and reduced emissions from the energy sector.\n\n\n\n"}
{"id": "19724626", "url": "https://en.wikipedia.org/wiki?curid=19724626", "title": "EnergyTeachers.org", "text": "EnergyTeachers.org\n\nEnergyTeachers.org is a network of educators interested in energy production and use. It is also the name of the website of the organization. The full corporate name is EnergyTeachers.org Inc.\nEnergyTeachers.org was incorporated in Massachusetts in 2004. It is governed by a board of 3 directors, and run by one person, who acts as president, treasurer, and clerk. The organization is a public charity, designated 501(c)(3) by the IRS in 2005.\n\n\n\nBibliography, annotated links, calendar of relevant events, educator online forum, equipment for loan.\n\nIn 2007 EnergyTeachers.org published a field trip guide for teachers and distributed it for free to over 1400 schools. The book lists places of interest where teachers and students can learn about renewable energy and energy efficiency. The publication was paid for by a grant from the Massachusetts Technology Collaborative, charged with overseeing the state's Renewable Energy Trust.\n\n\n"}
{"id": "27397623", "url": "https://en.wikipedia.org/wiki?curid=27397623", "title": "F-plane", "text": "F-plane\n\nIn geophysical fluid dynamics, the \"f\"-plane approximation is an approximation where the Coriolis parameter, denoted \"f\", is set to a constant value. \n\nThis approximation is frequently used for the analysis of highly idealized tropical cyclones. Using a constant Coriolis parameter prevents the formation of beta gyres which are largely responsible for the North-westward direction of most tropical cyclones. Rossby waves also depend on variations in \"f\", and do not occur in the \"f\"-plane approximation. \n\nIn reality, the Coriolis parameter varies with latitude, and so the \"f\"-plane approximation is not appropriate when considering flows over large lengthscales. The \"f\"-plane approximation is also poor near the equator, where variations in \"f\" are on the same order of magnitude as \"f\". The beta plane approximation is an improvement on the \"f\"-plane approximation which takes leading-order variations in \"f\" into account.\n\n\n"}
{"id": "1202383", "url": "https://en.wikipedia.org/wiki?curid=1202383", "title": "February 13, 1979 windstorm", "text": "February 13, 1979 windstorm\n\nThe February 13, 1979 windstorm is a natural phenomenon that took place on February 13, 1979 in Pacific Canada and the United States. During the early morning of February 13, 1979, an intense wave cyclone moved across southern Vancouver Island, British Columbia. South of the low center, a strong atmospheric pressure gradient was carried across Washington, with associated high winds. With a cold airflow moving toward the northeast interacting with the high terrain of the Olympic Mountains, a lee low developed east of the Olympics. The mesoscale low caused a particularly intense pressure gradient to develop across the Kitsap Peninsula region.\n\nAt 6 mbar over 8 miles, the geostrophic wind potential easily exceeded 200 knots (which roughly translates to about 100 knots in ageostrophic flow over the Earth's rough surface, or 115 mph). As reported by the crew of the Hood Canal Bridge, average winds reached at least 80 mph out of the south, with gusts into the triple digits. These wind velocities were cross-checked on two different anemometers at the bridge control tower.\n\nExtensive damage to trees on surrounding private timberland also corroborate the extreme intensity of this tempest. The pressure of wind and wave on the Hood Canal Bridge stressed the structure enough to cause catastrophic failure. It is suspected that a severe list in the bridge exposed pontoon access hatches to the waves, which subsequently tore the covers loose and allowed water to enter the flotation devices, causing sections to sink. It took nearly three years and over $140 million U.S. to rebuild the lost bridge.\n\n\n"}
{"id": "14372", "url": "https://en.wikipedia.org/wiki?curid=14372", "title": "Hecate", "text": "Hecate\n\nHecate or Hekate (; , \"Hekátē\") is a goddess in ancient Greek religion and mythology, most often shown holding a pair of torches or a key and in later periods depicted in triple form. She was variously associated with crossroads, entrance-ways, light, magic, witchcraft, knowledge of herbs and poisonous plants, ghosts, necromancy, and sorcery. She appears in the Homeric Hymn to Demeter and in Hesiod's \"Theogony\", where she is promoted strongly as a great goddess. The place of origin of her following is uncertain, but it is thought that she had popular followings in Thrace.\n\nHecate was one of the main deities worshiped in Athenian households as a protective goddess and one who bestowed prosperity and daily blessings on the family. In the post-Christian writings of the Chaldean Oracles (2nd–3rd century CE) she was regarded with (some) rulership over earth, sea, and sky, as well as a more universal role as Saviour (Soteira), Mother of Angels and the Cosmic World Soul.\nRegarding the nature of her cult, it has been remarked, \"she is more at home on the fringes than in the center of Greek polytheism. Intrinsically ambivalent and polymorphous, she straddles conventional boundaries and eludes definition.\"\n\nThe etymology of the name \"Hecate\" (Ἑκάτη, \"Hekátē\") is not known. Some suggestions derive the name from a Greek root: from ἑκών \"willing\" (thus, \"she who works her will\" or similar), or from Ἑκατός \"Hekatos\", an obscure epithet of Apollo interpreted as \"the far reaching one\" or \"the far-darter\", whence for the feminine form \"she that operates from afar\" or \"she that removes or drives off\".\n\nR. S. P. Beekes rejected a Greek etymology and suggested a Pre-Greek origin. A possibility for foreign origin of the name may be \"Heqet\", name of an Egyptian goddess of fertility and childbirth.\n\nIn Early Modern English, the name was also pronounced disyllabically (as ) and sometimes spelled \"Hecat\". It remained common practice in English to pronounce her name in two syllables, even when spelled with final \"e\", well into the 19th century.\n\nThe spelling \"Hecat\" is due to Arthur Golding's 1567 translation of Ovid's \"Metamorphoses\", and this spelling without the final E later appears in plays of the Elizabethan-Jacobean period.\nWebster's Dictionary of 1866 particularly credits the influence of Shakespeare for the then-predominant disyllabic pronunciation of the name.\n\nHecate possibly originated among the Carians of Anatolia, the region where most theophoric names invoking Hecate, such as Hecataeus or Hecatomnus, the father of Mausolus, are attested, and where Hecate remained a Great Goddess into historical times, at her unrivalled cult site in Lagina. While many researchers favor the idea that she has Anatolian origins, it has been argued that \"Hecate must have been a Greek goddess.\" The monuments to Hecate in Phrygia and Caria are numerous but of late date.\n\nWilliam Berg observes, \"Since children are not called after spooks, it is safe to assume that Carian theophoric names involving \"hekat-\" refer to a major deity free from the dark and unsavoury ties to the underworld and to witchcraft associated with the Hecate of classical Athens.\" In particular, there is some evidence that she might be derived from the local sun goddesses (see also Arinna), based on similar attributes.\n\nIf Hecate's cult spread from Anatolia into Greece, it is possible it presented a conflict, as her role was already filled by other more prominent deities in the Greek pantheon, above all by Artemis and Selene. This line of reasoning lies behind the widely accepted hypothesis that she was a foreign deity who was incorporated into the Greek pantheon. Other than in the \"Theogony\", the Greek sources do not offer a consistent story of her parentage, or of her relations in the Greek pantheon: sometimes Hecate is related as a Titaness, and a mighty helper and protector of humans.\n\nShrines to Hecate were placed at doorways to both homes and cities with the belief that it would protect from restless dead and other spirits. Likewise, shrines to Hecate at three way crossroads were created where food offerings were left at the new moon to protect those who did so from spirits and other evils.\n\nDogs were sacred to Hecate and associated with roads, domestic spaces, purification, and spirits of the dead. Dogs were also sacrificed to the road.\nThis can be compared to Pausanias' report that in the Ionian city of Colophon in Asia Minor a sacrifice of a black female puppy was made to Hecate as \"the wayside goddess\", and Plutarch's observation that in Boeotia dogs were killed in purificatory rites. Dogs, with puppies often mentioned, were offered to Hecate at crossroads, which were sacred to the goddess.\n\nHecate was a popular divinity, and her cult was practiced with many local variations all over Greece and Western Anatolia. However, she did not have many known sanctuaries or temples dedicated to her aside from her most famous temple in Lagina. There was a Temple of Hecate in Argolis: \"Over against the sanctuary of Eilethyia is a temple of Hekate [the goddess probably here identified with the apotheosed Iphigeneia], and the image is a work of Skopas. This one is of stone, while the bronze images opposite, also of Hekate, were made respectively by Polykleitos and his brother Naukydes.\" \nThere were also a shrine to Hecate in Aigina, where she was very popular:\nAside from her own temples, Hecate was also worshipped in the sanctuaries of other gods, where she was apparently sometimes given her own space. There was an area sacred to Hecate in the precincts of the Temple of Artemis at Ephesus, where the priests, \"megabyzi\", officiated. This sanctuary was called \"Hekatesion\" (Shrine of Hekate). Hecate was also worshipped in the Temple of Athena in Titane: \"In Titane there is also a sanctuary of Athena, into which they bring up the image of Koronis [mother of Asklepios] . . . The sanctuary is built upon a hill, at the bottom of which is an Altar of the Winds, and on it the priest sacrifices to the winds one night in every year. He also performs other secret rites [of Hekate] at four pits, taming the fierceness of the blasts [of the winds], and he is said to chant as well the charms of Medea.\"\nShe was most commonly worshipped in nature, where she had many natural sanctuaries. An important sanctuary of Hecate was a holy cave on the island of Samothrake called Zerynthos: \n\nHecate's most important sanctuary was Lagina, a theocratic city-state in which the goddess was served by eunuchs. \n\nThe temple is mentioned by Strabo:\n\nLagina, where the famous temple of Hecate drew great festal assemblies every year, lay close to the originally Macedonian colony of Stratonikeia, where she was the city's patron. In Thrace she played a role similar to that of lesser-Hermes, namely a ruler of liminal regions,particularly gates, and the wilderness. \n\nHecate was greatly worshipped in Byzantium. She was said to have saved the city from Philip II, warning the citizens of a night time attack by a light in the sky, for which she was known as \"Hecate Lampadephoros\". The tale is preserved in the Suda.\n\nAs Hecate Phosphorus (Venus) she is said to have lit the sky during the Siege of Philip II in 340, revealing the attack to its inhabitants. The Byzantines dedicated a statue to her as the \"lamp carrier.\"\n\nThe Athenian Greeks honored Hekate during the Deipnon. In Greek, deipnon means the evening meal, usually the largest meal of the day. Hekate's Deipnon is, at its most basic, a meal served to Hekate and the restless dead once a lunar month during the new moon. The Deipnon is always followed the next day by the Noumenia, when the first sliver of moon is visible, and then the Agathos Daimon the day after that.\n\nThe main purpose of the Deipnon was to honor Hekate and to placate the souls in her wake who \"longed for vengeance.\" A secondary purpose was to purify the household and to atone for bad deeds a household member may have committed that offended Hekate, causing her to withhold her favor from them. The Deipnon consists of three main parts: 1) the meal that was set out at a crossroads, usually in a shrine outside the entryway to the home 2) an expiation sacrifice, and 3) purification of the household.\n\nHecate was known by a number of bynames:\n\n\nHecate was generally represented as three-formed. This has been speculated as being connected with the appearance of the full moon, half moon, and new moon.\nAs a virgin goddess, she remained unmarried and had no regular consort, though some traditions named her as the mother of Scylla.\n\nThe earliest Greek depictions of Hecate were not three-formed. Farnell states: \"The evidence of the monuments as to the character and significance of Hecate is almost as full as that of to express her manifold and mystic nature.\"\n\nThe earliest known monument is a small terracotta found in Athens, with a dedication to Hecate, in writing of the style of the 6th century. The goddess is seated on a throne with a chaplet bound round her head; she is altogether without attributes and character, and the main historical value of this work, which is evidently of quite a general type and gets a special reference and name merely from the inscription, is that it proves the single shape to be her earlier form, and her recognition at Athens to be earlier than the Persian invasion.\nThe 2nd-century travel writer Pausanias stated that Hecate was first depicted in triplicate by the sculptor Alkamenes in the Greek Classical period of the late 5th century BCE which was placed before the temple of the Wingless Nike in Athens. Greek anthropomorphic conventions of art resisted representing her with three faces: a votive sculpture from Attica of the 3rd century BCE (\"illustration, left\"), shows three single images against a column; round the column of Hecate dance the Charites. Some classical portrayals show her as a triplicate goddess holding a torch, a key, serpents, daggers and numerous other items. Depictions of both a single form Hekate and triple formed, as well as occasional four headed descriptions continued throughout her history.\n\nIn Egyptian-inspired Greek esoteric writings connected with Hermes Trismegistus, and in magical papyri of Late Antiquity she is described as having three heads: one dog, one serpent, and one horse. In other representations her animal heads include those of a cow and a boar. Hecate's triplicity is elsewhere expressed in a more Hellenic fashion in the vast frieze of the great Pergamon Altar, now in Berlin, wherein she is shown with three bodies, taking part in the battle with the Titans. In the Argolid, near the shrine of the Dioscuri, Pausanias saw the temple of Hecate opposite the sanctuary of Eileithyia; He reported the image to be the work of Scopas, stating further, \"This one is of stone, while the bronze images opposite, also of Hecate, were made respectively by Polycleitus and his brother Naucydes, son of Mothon.\" (\"Description of Greece\" 2.22.7)\n\nIn the \"Argonautica\", a 3rd-century BCE Alexandrian epic based on early material, Jason placates Hecate in a ritual prescribed by Medea, her priestess: bathed at midnight in a stream of flowing water, and dressed in dark robes, Jason is to dig a round pit and over it cut the throat of an ewe, sacrificing it and then burning it whole on a pyre next to the pit as a holocaust. He is told to sweeten the offering with a libation of honey, then to retreat from the site without looking back, even if he hears the sound of footsteps or barking dogs. All these elements betoken the rites owed to a chthonic deity.\n\nA 4th-century BCE marble relief from Crannon in Thessaly was dedicated by a race-horse owner.\nIt shows Hecate, with a hound beside her, placing a wreath on the head of a mare. She is commonly attended by a dog or dogs, and the most common form of offering was to leave meat at a crossroads. Images of her attended by a dog are also found at times when she is shown as in her role as mother goddess with child, and when she is depicted alongside the god Hermes and the goddess Kybele in reliefs.\n\nDogs were closely associated with Hecate in the Classical world. \"In art and in literature Hecate is constantly represented as dog-shaped or as accompanied by a dog. Her approach was heralded by the howling of a dog. The dog was Hecate's regular sacrificial animal, and was often eaten in solemn sacrament.\" The sacrifice of dogs to Hecate is attested for Thrace, Samothrace, Colophon, and Athens.\n\nIt has been claimed that her association with dogs is \"suggestive of her connection with birth, for the dog was sacred to Eileithyia, Genetyllis, and other birth goddesses. Although in later times Hecate's dog came to be thought of as a manifestation of restless souls or demons who accompanied her, its docile appearance and its accompaniment of a Hecate who looks completely friendly in many pieces of ancient art suggests that its original signification was positive and thus likelier to have arisen from the dog's connection with birth than the dog's underworld associations.\" The association with dogs, particularly female dogs, could be explained by a metamorphosis myth in Lycophron: the friendly looking female dog accompanying Hecate was originally the Trojan Queen Hekabe, who leapt into the sea after the fall of Troy and was transformed by Hecate into her familiar.\n\nAnother metamorphosis myth explains why the polecat is also associated with Hecate. From Antoninus Liberalis:\n\"At Thebes Proitos had a daughter Galinthias. This maiden was playmate and companion of Alkmene, daughter of Elektryon. As the birth throes for Herakles were pressing on Alkmene, the Moirai (Fates) and Eileithyia (Birth-Goddess), as a favour to Hera, kept Alkmene in continuous birth pangs. They remained seated, each keeping their arms crossed. Galinthias, fearing that the pains of her labour would drive Alkmene mad, ran to the Moirai and Eleithyia and announced that by desire of Zeus a boy had been born to Alkmene and that their prerogatives had been abolished.\n\nAt all this, consternation of course overcame the Moirai and they immediately let go their arms. Alkmene’s pangs ceased at once and Herakles was born. The Moirai were aggrieved at this and took away the womanly parts of Galinthias since, being but a mortal, she had deceived the gods. They turned her into a deceitful weasel (or polecat), making her live in crannies and gave her a grotesque way of mating. She is mounted through the ears and gives birth by bringing forth her young through the throat. Hekate felt sorry for this transformation of her appearance and appointed her a sacred servant of herself.\"\n\nAelian told a different story of a woman transformed into a polecat: \"\"I have heard that the polecat was once a human being. It has also reached my hearing that Gale was her name then; that she was a dealer in spells and a sorceress (Pharmakis); that she was extremely incontinent, and that she was afflicted with abnormal sexual desires. Nor has it escaped my notice that the anger of the goddess Hekate transformed it into this evil creature. May the goddess be gracious to me: fables and their telling I leave to others.\"\n\nAthenaeus of Naucratis, drawing on the etymological speculation of Apollodorus of Athens, notes that the red mullet is sacred to Hecate, \"on account of the resemblance of their names; for that the goddess is \"trimorphos\", of a triple form\". The Greek word for mullet was \"trigle\" and later \"trigla\". He goes on to quote a fragment of verse \"O mistress Hecate, Trioditis / With three forms and three faces / Propitiated with mullets\". In relation to Greek concepts of pollution, Parker observes, \"The fish that was most commonly banned was the red mullet (\"trigle\"), which fits neatly into the pattern. It 'delighted in polluted things,' and 'would eat the corpse of a fish or a man'. Blood-coloured itself, it was sacred to the blood-eating goddess Hecate. It seems a symbolic summation of all the negative characteristics of the creatures of the deep.\" At Athens, it is said there stood a statue of Hecate \"Triglathena\", to whom the red mullet was offered in sacrifice. After mentioning that this fish was sacred to Hecate, Alan Davidson writes, \"Cicero, Horace, Juvenal, Martial, Pliny, Seneca and Suetonius have left abundant and interesting testimony to the red mullet fever which began to affect wealthy Romans during the last years of the Republic and really gripped them in the early Empire. The main symptoms were a preoccupation with size, the consequent rise to absurd heights of the prices of large specimens, a habit of keeping red mullet in captivity, and the enjoyment of the highly specialized aesthetic experience induced by watching the color of the dying fish change.\"\n\nThe frog, which was also the symbol of the similarly-named Egyptian goddess Heqet, has also become sacred to Hecate in modern Pagan literature, possibly due in part to its ability to cross between two elements.\n\nIn her three-headed representations, discussed above, Hecate often has one or more animal heads, including cow, dog, boar, serpent and horse.\n\nHecate was closely associated with plant lore and the concoction of medicines and poisons. In particular she was thought to give instruction in these closely related arts. Apollonius of Rhodes, in the \"Argonautica\" mentions that Medea was taught by Hecate, \"I have mentioned to you before a certain young girl whom Hecate, daughter of Perses, has taught to work in drugs.\"\n\nThe goddess is described as wearing oak in fragments of Sophocles' lost play \"The Root Diggers\" (or \"The Root Cutters\"), and an ancient commentary on Apollonius of Rhodes' Argonautica (3.1214) describes her as having a head surrounded by serpents, twining through branches of oak.\n\nThe yew in particular was sacred to Hecate.\n\nHecate was said to favor offerings of garlic, which was closely associated with her cult. She is also sometimes associated with cypress, a tree symbolic of death and the underworld, and hence sacred to a number of chthonic deities.\n\nA number of other plants (often poisonous, medicinal and/or psychoactive) are associated with Hecate. These include aconite (also called \"hecateis\"), belladonna, dittany, and mandrake. It has been suggested that the use of dogs for digging up mandrake is further corroboration of the association of this plant with Hecate; indeed, since at least as early as the 1st century CE, there are a number of attestations to the apparently widespread practice of using dogs to dig up plants associated with magic.\n\nHecate was associated with borders, city walls, doorways, crossroads and, by extension, with realms outside or beyond the world of the living. She appears to have been particularly associated with being 'between' and hence is frequently characterized as a \"liminal\" goddess. \"Hecate mediated between regimes—Olympian and Titan—but also between mortal and divine spheres.\" This liminal role is reflected in a number of her cult titles: \"Apotropaia\" (that turns away/protects); \"Enodia\" (on the way); \"Propulaia\"/\"Propylaia\" (before the gate); \"Triodia\"/\"Trioditis\" (who frequents crossroads); \"Klêidouchos\" (holding the keys), etc.\n\nThis function would appear to have some relationship with the iconographic association of Hecate with keys, and might also relate to her appearance with two torches, which when positioned on either side of a gate or door illuminated the immediate area and allowed visitors to be identified. \"In Byzantium small temples in her honor were placed close to the gates of the city. Hecate's importance to Byzantium was above all as a deity of protection. When Philip of Macedon was about to attack the city, according to the legend she alerted the townspeople with her ever present torches, and with her pack of dogs, which served as her constant companions.\" This suggests that Hecate's close association with dogs derived in part from the use of watchdogs, who, particularly at night, raised an alarm when intruders approached. Watchdogs were used extensively by Greeks and Romans.\n\nCult images and altars of Hecate in her triplicate or trimorphic form were placed at three-way crossroads (though they also appeared before private homes and in front of city gates). In this form she came to be identified with the Roman goddess Diana Trivia (\"of the three ways\"). In what appears to be a 7th-century indication of the survival of cult practices of this general sort, Saint Eligius, in his \"Sermo\" warns the sick among his recently converted flock in Flanders against putting \"devilish charms at springs or trees or crossroads\", and, according to Saint Ouen would urge them \"No Christian should make or render any devotion to the deities of the trivium, where three roads meet...\".\n\nLike Hecate, \"[t]he dog is a creature of the threshold, the guardian of doors and portals, and so it is appropriately associated with the frontier between life and death, and with demons and ghosts which move across the frontier. The yawning gates of Hades were guarded by the monstrous watchdog Cerberus, whose function was to prevent the living from entering the underworld, and the dead from leaving it.\"\n\nHecate has been characterized as a pre-Olympian chthonic goddess.\nThe first literature mentioning Hecate is the \"Theogony\" by Hesiod:\nAccording to Hesiod, she held sway over many things:\nHesiod emphasizes that Hecate was an only child, the daughter of Perses and Asteria, the sister of Leto (the mother of Artemis and Apollo). Grandmother of the three cousins was Phoebe the ancient Titaness who personified the moon.\n\nHesiod's inclusion and praise of Hecate in the \"Theogony\" has been troublesome for scholars, in that he seems to hold her in high regard, while the testimony of other writers, and surviving evidence, suggests that this may have been the exception. One theory is that Hesiod's original village had a substantial Hecate following and that his inclusion of her in the \"Theogony\" was a way of adding to her prestige by spreading word of her among his readers. Another theory is that Hekate was mainly a household god and humble household worship could have been more pervasive and yet not mentioned as much as temple worship. In Athens Hecate, along with Zeus, Hermes, Hestia, and Apollo, were very important in daily life as they were the main gods of the household. However, it is clear that the special position given to Hecate by Zeus is upheld throughout her history by depictions found on coins depicting Hecate on the hand of Zeus as highlighted in more recent research presented by d'Este and Rankine.\n\nIn the Homeric Hymn to Demeter, Hecate is called the \"tender-hearted\", a euphemism perhaps intended to emphasize her concern with the disappearance of Persephone, when she assisted Demeter with her search for Persephone following her abduction by Hades, suggesting that Demeter should speak to the god of the sun, Helios. Subsequently, she became Persephone's companion on her yearly journey to and from the realms of Hades; serving as a psychopomp. Because of this association, Hecate was one of the chief goddesses of the Eleusinian Mysteries, alongside Demeter and Persephone.\n\nVariations in interpretations of Hecate's role or roles can be traced in classical Athens. In two fragments of Aeschylus she appears as a great goddess. In Sophocles and Euripides she is characterized as the mistress of witchcraft and the Keres.\n\nOne surviving group of stories suggests how Hecate might have come to be incorporated into the Greek pantheon without affecting the privileged position of Artemis. Here, Hecate is a mortal priestess often associated with Iphigeneia. She scorns and insults Artemis, who in retribution eventually brings about the mortal's suicide.\n\nHecate is the primary feminine figure in the \"Chaldean Oracles\" (2nd-3rd century CE), where she is associated in fragment 194 with a \"strophalos\" (usually translated as a spinning top, or wheel, used in magic) \"Labour thou around the Strophalos of Hecate.\" This appears to refer to a variant of the device mentioned by Psellus.\n\nIn Hellenistic syncretism, Hecate also became closely associated with Isis. Lucius Apuleius in \"The Golden Ass\" (2nd century) equates Juno, Bellona, Hecate and Isis:\nIn the syncretism during Late Antiquity of Hellenistic and late Babylonian (\"Chaldean\") elements, Hecate was identified with Ereshkigal, the underworld counterpart of Inanna in the Babylonian cosmography. In the Michigan magical papyrus (inv. 7), dated to the late 3rd or early 4th century CE, \"Hecate Ereschigal\" is invoked against fear of punishment in the afterlife.\n\nStrmiska (2005) claimed that Hecate, conflated with the figure of Diana, appears in late antiquity and in the early medieval period as part of an \"emerging legend complex\" known as \"The Society of Diana\" associated with gatherings of women, the moon, and witchcraft that eventually became established \"in the area of Northern Italy, southern Germany, and the western Balkans.\" This theory of the Roman origins of many European folk traditions related to Diana or Hecate was explicitly advanced at least as early as 1807 and is reflected in etymological claims by early modern lexicographers from the 17th to the 19th century, connecting \"hag, hexe\" \"witch\" to the name of Hecate. Such derivations are today proposed only by a minority\n\nA medieval commentator has suggested a link connecting the word \"jinx\" with Hecate: \"The Byzantine polymath Michael Psellus [...] speaks of a bullroarer, consisting of a golden sphere, decorated throughout with symbols and whirled on an oxhide thong. He adds that such an instrument is called a \"iunx\" (hence \"jinx\"), but as for the significance says only that it is ineffable and that the ritual is sacred to Hecate.\"\n\nShakespeare mentions Hecate both before the end of the 16th century (A Midsummer Night's Dream, 1594-96), and just after, in Macbeth (1605): specifically, in the title character's \"dagger\" soliloquy: \"Witchcraft celebrates pale Hecate's offerings...\"\n\nIn 1929, Lewis Brown, an expert on religious cults, connected the 1920s Blackburn Cult (also known as, \"The Cult of the Great Eleven,\") with Hecate worship rituals. He noted that the cult regularly practiced dog sacrifice and had secretly buried the body of one of its \"queens\" with seven dogs. Researcher Samuel Fort noted additional parallels, to include the cult's focus on mystic and typically nocturnal rites, its female dominated membership, the sacrifice of other animals (to include horses and mules), a focus on the mystical properties of roads and portals, and an emphasis on death, healing, and resurrection.\n\nAs a \"goddess of witchcraft\", Hecate has been incorporated in various systems of modern witchcraft, Wicca and Neopaganism, in some cases associated with the Wild Hunt of Germanic tradition, in others as part of a reconstruction of specifically Greek polytheism, in English also known as \"Hellenismos\". In Wicca, Hecate has in some cases become identified with the \"Crone\" aspect of the \"Triple Goddess\".\n\nHecate is also the namesake of the hundredth numbered asteroid, which was discovered by American astronomer James Craig Watson on July 11, 1868. Its adopted name alludes to it as being the hundredth named asteroid ('hekaton' being the Greek for 'hundred').\n\n\n\n\n"}
{"id": "31146000", "url": "https://en.wikipedia.org/wiki?curid=31146000", "title": "Holeum", "text": "Holeum\n\nHoleums are hypothetical stable, quantized gravitational bound states of primordial or micro black holes. Holeums were proposed by L. K. Chavda and Abhijit Chavda in 2002. They have all the properties associated with cold dark matter. Holeums are not black holes, even though they are made up of black holes.\n\nThe binding energy formula_1 of a holeum that consists of two identical micro black holes of mass formula_2 is given by\n\nin which formula_4 is the principal quantum number, formula_5 and formula_6 is the gravitational counterpart of the fine structure constant. The latter is given by\n\nwhere:\n\nThe \"n\"th excited state of a holeum then has a mass that is given by\n\nThe holeum's atomic transitions cause it to emit gravitational radiation.\n\nThe radius of the \"n\"th excited state of a holeum is given by\n\nwhere:\n\nThe holeum is a stable particle. It is the gravitational analogue of the hydrogen atom. It occupies space. Although it is made up of black holes, it itself is not a black hole. As the holeum is a purely gravitational system, it emits only gravitational radiation and no electromagnetic radiation. The holeum can therefore be considered to be a dark matter particle.\n\nA macro holeum is a quantized gravitational bound state of a large number of micro black holes. The energy eigenvalues of a macro holeum consisting of formula_15 identical micro black holes of mass formula_2 are given by\n\nwhere formula_18 and formula_19. The system is simplified by assuming that all the micro black holes in the core are in the same quantum state described by formula_4, and that the outermost, formula_21 micro black hole is in an arbitrary quantum state described by the principal quantum number formula_22.\n\nThe \"physical radius\" of the bound state is given by\n\nThe mass of the macro holeum is given by\n\nThe Schwarzschild radius of the macro holeum is given by\n\nThe entropy of the system is given by\n\nwhere formula_27 is the entropy of the individual micro black holes that constitute the macro holeum.\n\nThe ground state of macro holeums is characterized by formula_28 and formula_29. The holeum has maximum binding energy, minimum physical radius, maximum Schwarzschild radius, maximum mass, and maximum entropy in this state.\n\nSuch a system can be thought of as consisting of a gas of formula_30 free (formula_28) micro black holes that is bounded and therefore isolated from the outside world by a solitary outermost micro black hole whose principal quantum number is formula_29.\n\nIt can be seen from the above equations that the condition for the stability of holeums is given by\n\nSubstituting the relations formula_34 and formula_35 into this inequality, the condition for the stability of holeums can be expressed as\n\nThe ground state of holeums is characterized by formula_28, which gives us formula_38 as the condition for stability. Thus, the ground state of holeums is guaranteed to be always stable.\n\nA holeum is a black hole if its physical radius is less than or equal to its Schwarzschild radius, i.e. if\n\nSuch holeums are termed black holeums. Substituting the expressions for formula_40 and formula_41, and simplifying, we obtain the condition for a holeum to be a black holeum to be\n\nFor the ground state, which is characterized by formula_29, this reduces to\n\nBlack holeums are an example of black holes with internal structure. Black holeums are quantum black holes whose internal structure can be fully predicted by means of the quantities formula_15, formula_2, formula_4, and formula_22.\n\nHoleums are speculated to be the progenitors of a class of short duration gamma ray bursts. It is also speculated that holeums give rise to cosmic rays of all energies, including ultra-high-energy cosmic rays.\n\n\n"}
{"id": "13277557", "url": "https://en.wikipedia.org/wiki?curid=13277557", "title": "Hummelstown brownstone", "text": "Hummelstown brownstone\n\nHummelstown brownstone is a medium-grain, dense sandstone quarried near Hummelstown in Dauphin County, Pennsylvania, USA. It is a dark brownstone with reddish to purplish hues, and was once widely used as a building stone in the United States.\n\nThe Hummelstown Brownstone Company quarried high quality brownstone near Hummelstown from 1863 to 1929 and sold it across the U.S. as a preferred masonry material of builders. Because of its durability, it was used for a wide range of building projects, especially as trim and ornamentation on large buildings, but also as bridge piers and in the foundations and walls of buildings or the sculptures that decorated them. Frequently, entire buildings were dressed in Hummelstown brownstone. An outstanding example of this is the Barbour County Courthouse (1903–05) in Philippi, West Virginia.\n\nHummelstown brownstone and similar sandstones were known as “freestone” because of properties allowing them to be worked freely in every direction, rather than in one direction along a “grain”. This characteristic made them very popular with stone cutters and masons.\n"}
{"id": "2173511", "url": "https://en.wikipedia.org/wiki?curid=2173511", "title": "Irrawaddy River", "text": "Irrawaddy River\n\nThe Irrawaddy or, officially, Ayeyarwady River (, , also spelt Ayeyarwaddy) is a river that flows from north to south through Myanmar. It is the country's largest river and most important commercial waterway. Originating from the confluence of the N'mai and Mali rivers, it flows relatively straight North-South before emptying through the Irrawaddy Delta into the Andaman Sea. Its drainage basin of about covers a large part of Burma. After Rudyard Kipling's poem, it is sometimes referred to as 'The Road to Mandalay'.\n\nAs early as the sixth century, the river was used for trade and transport. Having developed an extensive network of irrigation canals, the river became important to the British Empire after it had colonized Burma. The river is still as vital today, as a considerable amount of (export) goods and traffic moves by river. Rice is produced in the Irrawaddy Delta, irrigated by water from the river.\n\nIn 2007, Myanmar's military dictatorship signed an agreement for the construction of seven hydroelectric dams, yielding a total 13,360 MW, in the N'mai and Mali Rivers, including the 3,600 MW Myitsone Dam at the confluence of both rivers. Environmental organisations have raised concerns about the ecological impacts on the river's biodiverse ecosystems. Animals potentially impacted include the threatened Irrawaddy dolphin and the Irrawaddy river shark, an endangered species.\n\nThe native Kachin people named the river Mali-Nmai-Hka. The Burmese name of Irrawaddy is derived from a Pali name for the Ravi River of India, \"Irāvatī\". \"Airavati\" (Pali \"Erāvatī\") was the Pali version of the name of the elephant mount of Sakka, and Indra in Hinduism. Saka is an important deva in Buddhism. Elephants were often a symbol for water and was used as the name for several others rivers, such as the Achiravati.\n\nThe Irrawaddy gives its name to the Irrawaddy dolphin (\"Orcaella brevirostris\"), which is found in the lower reaches of the river and known to help fishermen who practice cast-net fishing. Though called Irrawaddy dolphin, it has been also found in the Bay of Bengal and the Indian ocean.\n\nThe Irrawaddy River bisects Myanmar from north to south and empties through the nine-armed Irrawaddy Delta into the Indian Ocean.\n\nThe Irrawaddy River arises by the confluence of the N'mai(Nam Gio) and Mali Rivers in Kachin State. Both the N'mai and Mali Rivers find their sources in the Himalayan glaciers of Upper Burma near 28° N. The eastern branch of the two, N'mai, is the larger and rises in the Languela Glacier north of Putao. It is unnavigable because of the strong current whereas the smaller western branch, the Mali river, is navigable, despite a few rapids. Herefore, the Mali river is still called by the same name as the main river by locals. The controversial Myitsone Dam is currently under construction at the convergence of these rivers.\n\nThe town of Bhamo, about south of the Mali and N'mai river confluence, is the northernmost city reachable by boat all the year round although during the monsoons most of the river cannot be used by boats. The city of Myitkyina lies south of the confluence and can be reached during the dry season.\n\nBetween Myitkyina and Mandalay, the Irrawaddy flows through three well-marked defiles:\nThis sheet of lava is the Singu Plateau, a volcanic field from the Holocene. This field consists of magma from the fissure vents and covers an area of about . The plateau is also known as Letha Taung.\n\nLeaving this plateau at Kyaukmyaung, the river follows a broad, open course through the central dry zone – the ancient cultural heartland – where large areas consist of alluvial flats. From Mandalay (the former capital of the kingdom of Myanmar), the river makes an abrupt westward turn before curving southwest to unite with the Chindwin River, after which it continues in a southwestern direction. It is probable that the upper Irrawaddy originally flowed south from Mandalay, discharging its water through the present Sittaung River to the Gulf of Martaban, and that its present westward course is geologically recent. Below its confluence with the Chindwin, the Irrawaddy continues to meander through the petroleum producing city of Yenangyaung, below which it flows generally southward. In its lower course, between Minbu and Pyay, it flows through a narrow valley between forest-covered mountain ranges—the ridge of the Arakan Mountains to the west and that of the Pegu Yoma Mountains to the east.\n\nThe delta of the Irrawaddy begins about above Hinthada (Henzada) and about from its curved base, which faces the Andaman Sea. The westernmost distributary of the delta is the Pathein (Bassein) River, while the easternmost stream is the Yangon River, on the left bank of which stands Myanmar's former capital city, Yangon (Rangoon). Because the Yangon River is only a minor channel, the flow of water is insufficient to prevent Yangon Harbour from silting up, and dredging is necessary. The relief of the delta's landscape is low but not flat. The soils consist of fine silt, which is replenished continuously by fertile alluvium carried downstream by the river. As a result of heavy rainfall varying from a year in the delta, and the motion and sediment load of the river, the delta surface extends into the Andaman Sea at a rate of about per year.\n\nDue to monsoonal rains, which occur between mid-May and mid-October, the volume of the Irrawaddy and its tributaries varies greatly throughout the year. In summer, the melting of the snow and glaciers in Northern Burma add to the volume. The average discharge near the head of the delta is between a high of and a low of per second. The discharge can be as high as 40,393 cubic meter per second in rainy season. Over a year, the discharge averages . Further North, at Sagaing, the hydrograph shows a 38% decrease in discharge compared to where the river enters the delta. it also silted up around 278 tons of sand every year.\n\nVariation between high and low waterlevel is also great. At Mandalay and Prome, a range of has been measured between low-water level and floodlevel respectively. Because of the monsoonal character of the rain, the highest point is recorded in August, the lowest in February.\n\nThis variation in water level makes it necessary for ports along the river to have separate landing ports for low- and high-water. Still, low water levels have caused problems for ports along the river, as in the Bamaw–Mandalay–Pyay sectors, the shallowest point is as shallow as .\n\nWithin the basin, the average population density is 79 people/km. For these people, the river supply amounts to 18,614 m per person per year.\n\nNo complete and precise list of all the fish in the Irrawaddy river basin currently exists, but in 1996 it was estimated that there are about 200 species. In 2008, it was estimated that the Irrawaddy ecoregion is home to 119–195 species of fish found nowhere else in the world (endemic). Several new species of fish have been described from the Irrawaddy river basin in recent years (for example, the cyprinid \"Danio htamanthinus\" in 2016 and the stone loach \"Malihkaia aligera\" in 2017), and it is likely that undescribed species remain.\n\nAmong the most well-known species in the river is the Irrawaddy dolphin (\"Orcaella brevirostris\"), a euryhaline species of oceanic dolphin with a high and rounded forehead, lacking a beak. It is found in discontinuous sub-populations near sea coasts and in estuaries and rivers in parts of the Bay of Bengal and South-East Asia.\n\nAlong the North-South course of the Irrawaddy River, a number of notably different ecoregions can be distinguished.\n\nThe streams of the Nmai and Mali that form the Irrawaddy originate in high and remote mountains near the border with Tibet. This part of Burma, which extends north from Myitkyina and the Irrawaddy confluence, lies entirely outside the tropics. Rain falls at all seasons of the year, but mostly in the summer. The valleys and lower hill ranges are covered with tropical and subtropical evergreen rainforest instead of monsoon (deciduous) forest. This region is characterised by subtropical and temperate forests of oak and pine are found at elevations above . This evergreen forest passes into sub-tropical pine forest at about feet. Above , are forests of rhododendrons, and that in turn into evergreen conifer forest above feet.\n\nThe Irrawaddy river basin covers an approximate area of 255 . The Central Basin consists of the valley of the middle Irrawaddy and lower Chindwin. It lies within the 'dry zone' and consists almost entirely of plains covered with the teak-dominated Irrawaddy Moist Deciduous Forest ecoregion surrounding drier patches of dry forests. The central basin receives little rain (ave 650mm per year) although it does flood quickly during the July–October storms. The one meteorological factor which does not vary greatly, and which is the most important for plant life, is atmospheric humidity. This is always high, except in the winter in certain localities. Humidity usually does not fall below 75% and is 90% or more for long periods during summer. Another feature is the prevalent southerly summer winds which erode the soil of the basin.\n\nThe natural habitats of this central zone have been much altered for farming and there are few protected areas.\n\nThe predominant trees of the drier patches are the thorny \"Terminalia oliveri\" and the hardwood dahat teak (\"Tectona hamiltoniana\") with stands of Indaing Dipterocarpus tuberculatus which is cut for timber. The wildlife includes many birds, small mammals and reptiles such as the huge Burmese python. However, most of the large animals including the tiger have been hunted out or seen their habitats disappear.\n\nThe Irrawaddy River and its tributaries flow into the Andaman Sea through the Irrawaddy Delta. This ecoregion consists of mangroves and freshwater swamp forests. It is an extremely fertile area because of the river-borne silt deposited in the delta. The upper and central portions of the delta are almost entirely under cultivation, principally for rice. The southern portion of the ecoregion transitions into the Burmese Coast mangroves and is made up of fanlike marshes with oxbow lakes, islands, and meandering streams.\n\nBirds of the delta are both winter visitors and passage migrants including great cormorant (\"Phalacrocorax carbo\"), a wide variety of Anatidae, Eurasian coot (\"Fulica atra\"), about thirty species of migratory shorebirds, the whiskered tern (\"Chlidonias hybrida\"), the Caspian tern (\"Hydroprogne caspia\"), and the brown-headed gull (\"Larus brunnicephalus\"), which is very common. One of the most numerous wintering shorebird is the lesser sand plover (\"Charadrius mongolus\"), which occurs in flocks of many thousands along the outer coast of the delta. The wood sandpiper (\"Tringa glareola\") and red junglefowl (\"Gallus gallus\") are also abundant.\n\nIn the late 19th century, the spot-billed pelican (\"Pelecanus philippensis\") nested in huge numbers in south Burma. One colony on the Sittaung River plain to the east of the delta was described in November 1877 as covering and containing millions of birds. Immense colonies still bred in the area in 1910, but the birds had disappeared completely by 1939. Small numbers were regularly reported in the delta in the 1940s, but no breeding sites were located. , no pelicans have been recorded, and it may well be that the species is now extinct in Burma.\n\nSeveral species of large mammal occur in the delta, but their populations are small and scattered, with the possible exceptions of the Malayan sambar deer (\"Cervus unicolor equinus\"), Indian hog deer (\"C. porcinus\"), and wild boar (\"Sus scrofa\"), which have been reported from all Reserved Forests. Asian elephants (\"Elephas maximus\") were once widespread throughout the country with numbers as high as 10,000 animals, but in the numbers have dwindled, partly due to transferring the animals to logging camps. Other species reported to be present include the leopard, Bengal tiger, crab-eating macaque, wild dog, and otters (\"Panthera pardus, P. tigris, Cuon alpinus\", and \"Lutra\" species).\n\nThe saltwater crocodile (\"Crocodylus porosus\") can be found in the southern part of the delta. The species was formerly abundant in coastal regions, but population numbers have decreased because of a combination of commercial skin hunting, habitat loss, drowning in fishing nets and over-collection of living animals to supply crocodile farms.\n\nIt was at this river that a battle between a saltwater crocodile and a tiger was observed that ended with the reptile devouring the tiger.\n\nDespite recent declines in the sea turtle populations, five species are known to nest in Burma at well known island and mainland beaches known as turtle-banks. These are the olive ridley sea turtle (\"Lepidochelys olivacea\"), the loggerhead sea turtle (\"Caretta caretta\"), the green sea turtle (\"Chelonia mydas\"), the hawksbill sea turtle (\"Eretmochelys imbricata\"), and the leatherback sea turtle (\"Dermochelys coriacea\").\n\nThe Irrawaddy River has five major tributaries. As they flow through the northern tip of Burma – the Kachin State – they cut long north-south alluvial plains and relatively narrow upland valleys between the mountain ridges. The rivers joining the Irrawaddy are, from north to south:\n\n\nAs early as the sixth century, ancestors of the Burmese were using the Irrawaddy river, which runs through the center of Burma, to gain power in the region through trade and transport on the China – India route. By the twelfth century, a well-developed network of canals made for flourishing rice cultivation. Later, the river became a key economic tool of Imperial British interests, who set up trading ports along its shores.\n\nToday, the Irrawaddy is still the country's most important commercial waterway. Despite Mandalay's position as the chief rail and highway focus in northern Burma, a considerable amount of passenger and goods traffic moves by river. As the Irrawaddy Delta is one of the world's major rice-growing areas, one of the most important goods transported is rice. Teak logs – Myanmar is one of the world's top exporters – are floated down the river as large rafts. Before it is transported, teak has to be seasoned, because otherwise it won't float. This happens by girdling, a practice where a deep circular cut through bark and sap is made into the heartwood. Other major goods that are transported from the nation's heartlands to Yangon for export are other foodstuffs, petroleum, cotton, and local commodities.\n\nCommercial transportation on the Irrawaddy is maintained for about : from Hinthada to Bhamo () throughout the year, but from Bhamo to Myitkyina (200 km) for only seven months. More than of navigable waterways exist in the Irrawaddy delta, and there is a system of connecting canals. The Sittang is usable by smaller boats, but the Salween River, because of its rapids, is navigable for less than from the sea. Small steamers and country boats also serve the coasts of the Rakhine State and Tanintharyi Region. On the Chindwin River, transportation is carried on by steam or diesel vessels throughout the year up to Homalin—about 640 km from its confluence with the Irrawaddy. Seasonal navigation is carried on into Tamanthi, which is by river above Homalin.\n\nThe Chindwin valley has no railroad and relies heavily on river transport. Chauk, downstream from the confluence in the oil-field district, is a petroleum port. It is linked to Yangon by road and rail. Hinthada, near the apex of the delta, is the rail junction for lines leading to Kyangin and Bassein (Pathein). A ferry operates between Hinthada on the west bank and the railway station at Tharrawaw on the east bank.\n\nBurma's junta signed an agreement with China Power Investment Corporation in May 2007 for the construction of seven hydroelectric dams along the Irrawaddy, Mali, and N'Mai River in Kachin State. The total planned output of all seven plants will be 15,160 MWs of electricity, making it the largest hydropower project in Burma, surpassing the 7,100 MW Tasang Dam in Shan State.\nThe following data is available for the dam locations:\n\nThe power generated by the dams will be transmitted to other countries in the South-East Asian region, with most going to China. Other countries targeted for power export are Thailand, India and Bangladesh.\n\nThe largest of the seven, the Myitsone Dam, is located at the confluence of the Mali and N'Mai Rivers at the creation of the Irrawaddy. Although the China Power Investment Corporation is project manager of the Confluence Region Hydropower Projects. ParConfluence Region Hydropower Projects, several companies have been or are currently involved in the preparation, construction and financing of the 3,600 MW Myitsone Dam. Asia World Company has a key position, amidst Burmese Suntac Technologies and state-run Myanmar Electrical Power Enterprise, a state-owned utility enterprise responsible for power generation, transmission and distribution\n\nChinese involvement comes from China Power Investment Corporation, China Southern Power Grid, Yunnan Machinery Equipment Import & Export Company Changjiang Institute of Surveying, Planning, Design and Research.\n\nAt least one Japanese company is involved, Kansai Electric Power Company.\n\nDue to its location and size, construction of the Myitsone Dam has raised significant ecological and sociological concerns. According to the Irrawaddy Myitsone Dam Multipurpose Water Utilizing Project study, the maximum water level of the reservoir will be 290 metres. This makes for a flood zone of 766 km, compromising 47 villages.\n\nOther consequences of the inundation include loss of farmland, loss of spawning habitat as fishes can not swim upstream anymore. The Kachin Development Networking Group, a network of civil society groups and development organisations in Kachin State warn this will lead to a loss of income for fishermen. They report locals are also worried about the flooding of cultural sites in the flood zone. As with other large dam projects, the Myitsone Dam construction will alter the hydrological characteristics of the river, e.g. preventing sediment from enriching riverbanks downstream, where it usually enriches the riverside foodproducing plains. This can affect fertility as far downstream as the Irrawaddy Delta, the major rice-producing area of Myanmar.\n\nEcological concerns focus on the inundation of an area that is the border of the Indo-Burma and South Central China biodiversity hotspots. The Mali and N'mai River confluence region falls within the Mizoram-Manipur-Kachin rainforests, added to the WWF list of outstanding examples of biodiverse regions.\n\nThe location of the Myitsone Dam, located less than 100 km from a fault line where the Eurasian and Indian tectonic plates meet, raised concerns about its earthquake resistance. Earthquakes in the region, such as the 5.3 magnitude earthquake that struck near the Burma-China border on 20 August 2008, prompted Naw Lar, the coordinator of the KDNG dam research project, to ask the junta to reconsider its dam projects.\n\nThe river flows through or past the following cities:\n\n\nUntil the construction of the Ava (Innwa) Bridge, a 16 span rail and road cantilever bridge built by the British colonial government in 1934, the only way across the Irrawaddy was by ferry. The bridge was destroyed by the retreating British Army during World War II and was rebuilt in 1954 after Burmese independence and was the only bridge to span the Irrawaddy until recent times when a spate of bridge construction has been carried out by the government.\n\n\n"}
{"id": "10050653", "url": "https://en.wikipedia.org/wiki?curid=10050653", "title": "John Kenneth Terres", "text": "John Kenneth Terres\n\nJohn Kenneth Terres (December 17, 1905 – December 8, 2006), was an American naturalist and author. He is best known for his popular works on North American birds. He authored more than fifty works, usually writing as John K. Terres.\n\nHe was born in Philadelphia, Pennsylvania and spent his early years in New Jersey. He was educated at State Teachers College (Indiana, Pennsylvania), Cornell University and New York University. In 1986, he received an honorary Doctor of Letters from the University of North Carolina. He received the John Burroughs Medal (1971) for \"From Laurel Hill to Siler's Bog\", which detailed his explorations of Mason Farm Biological Reserve, part of the North Carolina Botanical Garden. Terres served as Editor of \"Audubon Magazine\" for twelve years (1948-1960). \n\nHe died shortly before his 101st birthday in 2006.\n\nHe was a contributing editor of \"Birder's World\" magazine, culminating with an article about American Crow behavior observations of his own, plus his own watercolors of crows performing the behaviors in the text. He died with the wish of revising his 1980 \"Audubon Encyclopedia of North American Birds\", about which Roger Tory Peterson said never left his desk side. Birder's World published, before the crow article, a story about him, with a photograph of him at the University of North Carolina-- Chapel Hill biological station, with much concentration examining a specimen.\n\n"}
{"id": "3439019", "url": "https://en.wikipedia.org/wiki?curid=3439019", "title": "Landlocked developing countries", "text": "Landlocked developing countries\n\nLandlocked developing countries (LLDC) are developing countries that are landlocked. The economic and other disadvantages experienced by such countries makes the majority of landlocked countries least developed countries (LDC), with inhabitants of these countries occupying the bottom billion tier of the world's population in terms of poverty. Apart from Europe, there is not a single successful highly developed landlocked country as measured by the Human Development Index (HDI), and nine of the twelve countries with the lowest HDI scores are landlocked. Landlocked European countries are exceptions in terms of development outcomes due to their close integration with the regional European market. Landlocked countries that rely on transoceanic trade usually suffer a cost of trade that is double that of their maritime neighbours. Landlocked countries experience economic growth 6% less than their non-landlocked countries, holding other variables constant.\n\nAbout 468 million people live in current LLDCs.\n\nThe United Nations has an Office of the High Representative for the Least Developed Countries, Landlocked Developing Countries and Small Island Developing States (UN-OHRLLS). It mainly holds the view that high transport costs due to distance and terrain result in the erosion of competitive edge for exports from landlocked countries. In addition, it recognizes the constraints on landlocked countries to be mainly physical, including lack of direct access to the sea, isolation from world markets and high transit costs due to physical distance. It also attributes geographic remoteness as one of the most significant reasons why developing landlocked nations cannot alleviate themselves, while European landlocked cases are mostly developed because of short distances to the sea through well-developed countries. One other commonly cited factor is the administrative burdens associated with border crossings as there is a heavy load of bureaucratic procedures, paperwork, custom charges, and most importantly, traffic delay due to border wait times, which affect delivery contracts. Delays and inefficiency compound geographically, where a 2 to 3 week wait due to border customs between Uganda and Kenya makes it impossible to book ships ahead of time in Mombasa, furthering delivery contract delays. Despite these explanations, it is also important to consider the transit countries that neighbour LLDCs, from whose ports the goods of LLDCs are exported.\n\nAlthough Adam Smith and traditional thought hold that geography and transportation are the culprits for keeping LLDCs from realizing development gains, Faye, Sachs and Snow hold the argument that no matter the advancement of infrastructure or lack of geographic distance to a port, landlocked nations are still dependent on their neighbouring transit nations. Outlying this specific relationship of dependency, Faye et al. insist that though LLDCs vary across the board in terms of HDI index scores, LLDCs almost uniformly straddle at the bottom of HDI rankings in terms of region, suggesting a correlated dependency relationship of development for landlocked countries with their respective regions. In fact, HDI levels decrease as one moves inland along the major transit route that runs from the coast of Kenya, across the country before going through Uganda, Rwanda and then finally Burundi. Just recently, it has been economically modeled that if the economic size of a transit country is increased by just 1%, a subsequent increase of at least 2% is experienced by the landlocked country, which shows that there is hope for LLDCs if the conditions of their transit neighbours are addressed. In fact, some LLDCs are seeing the brighter side of such a relationship, with the Central Asian nations geographic location between three BRIC nations (China, Russia and India) hungry for the region's oil and mineral wealth serving to boost economic development. The three major factors that LLDCs are dependent on their transit neighbours are dependence on transit infrastructure, dependence on political relations with neighbours, and dependence on internal peace and stability within transit neighbours.\n\nBurundi has relatively good internal road networks, but it cannot export its goods using the most direct route to the sea since the inland infrastructure of Tanzania is poorly connected to the port of Dar es Salaam. Thus Burundi relies on Kenya's port of Mombasa for export; but this route was severed briefly in the 1990s when political relations with Kenya deteriorated. Further, Burundi's exports could not pass through Mozambique around the same time due to violent civil conflict. Thus, Burundi had to export its goods using a 4500 km route, crossing several borders and changing transport modes, to reach the port of Durban in South Africa.\n\n\nThe mineral resource-rich countries of Central Asia and Mongolia offer a unique set of landlocked cases to explore in more depth, as these are nations where economic growth has grown exceptionally in recent years. In Central Asia, oil and coal deposits have influenced development: Kazakhstan’s GDI per capita in purchasing power parity was five times greater than Kyrgyzstan's in 2009. Despite substantial development growth, these nations are not on a stable and destined path to being well developed, as the exploitation of their natural resources translates into an overall low average income and disparity of income, and because their limited deposits of resources allow growth only in the short term, and most importantly because dependence on unprocessed materials increases the risk of shocks due to variations in market prices. And though it is widely conceived that free trade can permit faster economic growth, Mongolia is now subjected to a new geopolitical game about the traffic on its railway lines between China and Russia. Russian Railways now effectively owns 50% of Mongolia's rail infrastructure, which could mean more efficient modernization and the laying of new rail lines, but in reality also translates into powerful leverage to pressure the government of Mongolia to concede unfair terms for license grants of coal, copper, and gold mines. Thus, it can be argued that these nations with extraordinary mineral wealth should pursue economic diversification. All of these nations possess education qualifications, as they are inheritors of the Soviet Union's social education system. This implies that it is due to poor economic policies that more than 40% of the labour force is bogged down in the agricultural sector instead of being diverted into secondary or tertiary economic activity. Yet, it cannot be ignored that Mongolia benefits exceptionally from its proximity to two giant BRIC nations, resulting in a rapid development of railway ports along its borders, especially along the Chinese border, as the Chinese seek to direct coking coal from Mongolia to China's northwestern industrial core as well as for transportation to Japan and South Korea, resulting in revenue generation through the port of Tianjin.\n\nNepal is another landlocked country with extreme dependency on its transit neighbour India. India does not have poor relations with Nepal, nor does it lack relevant transport infrastructure or internal stability. In the 1970s, Nepal suffered from large commodity concentration and a high geographic centralization in its export trade: over 98% of its exports were to India, and 90% of its imports came from India. As a result of all this, Nepal had a poor trade bargaining position. In the 1950s, Nepal was forced to comply with India's external tariffs as well as the prices of India's exports. This was problematic since the two countries have different levels of development, resulting in greater gains for India which was larger, more advanced and with more resources. It was feared that a parasitic relationship might emerge, since India had a head start in industrialization, and dominated Nepal in manufacturing, which could reduce Nepal to being just a supplier of raw materials. Because of these problems, and Nepal's inability to develop its own infant industries (as it could not compete with Indian manufactures) treaties were drafted in 1960 and 1971, with amendments to the equal tariffs conditions, and terms of trade have since progressed.\n\nIn August, 2003, the International Ministerial Conference of Landlocked and Transit Developing Countries and Donor Countries on Transit Transport Cooperation (Almaty Ministerial Conference) was held in Almaty, Kazakhstan, setting the necessities of LLDCs in a universal document whereas there were no coordinated efforts on the global scale to serve the unique needs of LLDCs in the past. Other than acknowledging the main forms of dependency that must be addressed, it also acknowledged the additional dependency issue where neighbouring transit countries are often observed to export the same products as their landlocked neighbours. One result of the conference was a direct call for donor countries to step in to direct aid into setting up suitable infrastructure of transit countries to alleviate the burden of supporting LLDCs in regions of poor development in general. The general objectives of the Almaty Program of Action is as follows:\n\n\n\n\n"}
{"id": "285238", "url": "https://en.wikipedia.org/wiki?curid=285238", "title": "Latite", "text": "Latite\n\nLatite is an igneous, volcanic rock, with aphanitic-aphyric to aphyric-porphyritic texture. Its mineral assemblage is usually alkali feldspar and plagioclase in approximately equal amounts. Quartz is less than five percent and is absent in a feldspathoid-bearing latite, and olivine is absent in a quartz-bearing latite. When quartz content is greater than five percent the rock is classified as quartz latite. Biotite, hornblende, pyroxene and scarce olivine or quartz are common accessory minerals.\n\nRhomb porphyries are an unusual variety with gray-white porphyritic rhomb shaped phenocrysts embedded in a very fine grained red-brown matrix. The composition of rhomb porphyry places it in the trachyte - latite classification of the QAPF diagram.\n\nLatite is found, for example, as lavas in Bulgaria and as intrusive laccoliths and sills in South Dakota, USA.\n\n"}
{"id": "1617188", "url": "https://en.wikipedia.org/wiki?curid=1617188", "title": "Laws of motion", "text": "Laws of motion\n\nIn physics, a number of noted theories of the motion of objects have developed. Among the best known are:\n"}
{"id": "888088", "url": "https://en.wikipedia.org/wiki?curid=888088", "title": "List of Asteraceae genera", "text": "List of Asteraceae genera\n\nThis is a list of genera in the plant family Asteraceae, the daisies and sunflowers.\n\n"}
{"id": "4332945", "url": "https://en.wikipedia.org/wiki?curid=4332945", "title": "List of countries by electricity consumption", "text": "List of countries by electricity consumption\n\nThis list of countries by electric energy consumption is mostly based on The World Factbook. \nSeveral non-sovereign entities are also included for informational purposes, with their parent state noted. \nThe per capita data for many countries may be slightly inaccurate as population data may not be for the same year that the consumption data are. \nPopulation data were obtained from the List of countries by population in 2016, except for years other than 2016, in which case they were obtained from the Wikipedia pages for the corresponding countries/territories. Average power per capita was calculated according to the formula: \n\nBased on the above table and the data presented in the Wikipedia article on Electricity generation the table on the right is a comparison of electric energy production versus consumption for the worlds' top 30 energy producing countries.\n\n\n"}
{"id": "15565096", "url": "https://en.wikipedia.org/wiki?curid=15565096", "title": "List of ecoregions in the Republic of the Congo", "text": "List of ecoregions in the Republic of the Congo\n\nThe following is a list of ecoregions in the Republic of the Congo, according to the Worldwide Fund for Nature (WWF).\n\n\"by major habitat type\"\n\n\n\n\"by bioregion\"\n\n\n\n\n"}
{"id": "39689710", "url": "https://en.wikipedia.org/wiki?curid=39689710", "title": "List of environmental protests", "text": "List of environmental protests\n\nThis is a list of notable environmental protests and campaigns:\n\n\n"}
{"id": "57337082", "url": "https://en.wikipedia.org/wiki?curid=57337082", "title": "Lists of canals", "text": "Lists of canals\n\nThere are several lists of canals:\n\n\n\n"}
{"id": "57468789", "url": "https://en.wikipedia.org/wiki?curid=57468789", "title": "Louis J. Halle, Jr.", "text": "Louis J. Halle, Jr.\n\nLouis Joseph Halle, Jr. (17 November 1910, New York City – 13 August 1998, Geneva, Switzerland) was an American naturalist, author, U.S. State Department official, and professor of international studies in Geneva.\n\nHalle received his bachelor's degree from Harvard University in 1932.\n\nHe served in the US Army before WW II and in the Coast Guard during WW II. He was a Latin American specialist employed by the US State Department Policy Planning Staff from the mid 1940s to 1954. From 1954 to 1956 at the University of Virginia, he was a researcher on American foreign policy. He became in 1956 a professor at the Graduate Institute of International Studies in Geneva. He retired there as professor emeritus in 1973 but remained in Geneva.\n\nHe was the author of 22 books. In 1941 he received the John Burroughs Medal for \"Birds Against Men\".\n\nLouis J. Halle, Jr. married Barbara Mark in 1946 and was the father of five children. His father was born in 1873 and immigrated to the USA via Ellis Island on 15 September 1905. The famous inventor and philanthropist Hiram Halle was a brother of Louis J. Halle, Sr. and an uncle of Louis J. Halle, Jr.\n\n"}
{"id": "32908006", "url": "https://en.wikipedia.org/wiki?curid=32908006", "title": "Microbial electrosynthesis", "text": "Microbial electrosynthesis\n\nMicrobial electrosynthesis is a form of microbial electrocatalysis in which electrons are supplied to living microorganisms via a cathode in an electrochemical cell by applying an electric current. The electrons are then used by the microorganisms to reduce carbon dioxide to yield industrially relevant products. The electric current would ideally be produced by a renewable source of power.\nThis process is the opposite to that employed in a microbial fuel cell, in which microorganisms transfer electrons from the oxidation of compounds to an anode to generate an electric current.\n\nMicrobial electrosynthesis is related to microbial electrolysis cells (MEC). Both use the interactions of microorganisms with a cathode to reduce chemical compounds, but differ in the source of power for this process. In microbial\nelectrosynthesis electrons are supplied solely by the external electrical power source. In MECs, an electrical power source is used to augment the electrical potential produced by the microorganisms consuming a source of chemical energy such as acetic acid. The combined potential provided by the power source and the microorganisms is then sufficient to for example reduce hydrogen ions to molecular hydrogen.\n\nMicrobial electrosynthesis may be used to produce fuel from carbon dioxide using electrical energy generated by either traditional power stations or renewable electricity generation. It may also be used to produce speciality chemicals such as drug precursors through microbially assisted electrocatalysis.\n\nMicrobial electrosynthesis can also be used to \"power\" plants. Plants can then be grown without sunlight.\n\n"}
{"id": "6904118", "url": "https://en.wikipedia.org/wiki?curid=6904118", "title": "Morainic drift", "text": "Morainic drift\n\nMorainic drift is the movement of rock debris (talus) (see also Moraine) left by glaciers.\n"}
{"id": "40019661", "url": "https://en.wikipedia.org/wiki?curid=40019661", "title": "Mount Ilgaz National Park", "text": "Mount Ilgaz National Park\n\nThe Mount Ilgaz National Park () is a protected area established on June 2, 1976 and located on the Ilgaz Mountains at the borderline between Kastamonu Province and Çankırı Province in the western Black Sea Region of Turkey. Natural resources and its potential for recreational activities are the main values of the national park, which stretches over an area of .\n\nThe terrain structure of the Mount Ilgaz region, which is on the transient zone from Central Anatolia to North Anatolia, is characterized in general by serpentinite, schist and volcanic rock. There are also interesting examples in the region regarding mountain formation. Turkey's longest and most active geological fracture, the North Anatolian Fault, runs through the southern foot of Mount Ilgaz. The intire region features valleys, slopes and peaks of different characters. Additionally, it has geomorphological structure with a high-level landscape speciality.\n\nThe national park is on the Ilgaz Mountains, a mountain range in the western Black Sea Region. The mountains are bordered in the north by Gökırmak River and in the south by Devrez Creek, forming the hydrographic boundary between the two river basins. The Gökırmak River originates in the northern slopes of the Ilgaz Mountains, and flows in the west-east direction joining Kızılırmak River as one of its main tributaries. Devrez Creek follows the North Anatolian Fault joining also Kızılırmak in the east.\n\nThe highest peaks in the range are Büyükhacettepe at , Küçükhacettepe at , Çeþtepe at and Karataş Hill at . The ridges of the Ilgaz Maountains stretch about in the west-east direction.\n\nAverage annual temperature at the national park is 9.8 °C. January is the coldest month with an average temperature of −0.8 °C, while the warmest month is July with 20 °C followed by August with 19.7 °C. According to the meteorological station in Kastamonu, average annual rainfall is . In the lower parts of the national park as in the valley floors, rainfall is about and at the mountain peaks, it is about . Precipitation is highest in spring and early\nsummer. The north facing slopes of the higher regions receive relative more rainfall. Central Antolian climate causes snow over remains for about six months with snow thickness reaching about on slopes.\n\nThanks to the location of the national park in the transient region between Central Anatolia and Black Sea Region, the national park has a rich ecosystem of flora and fauna.\n\nForests, covering 81.7% of the total area, are the main vegetation group found in the national park's flora formation consisting of forest, underwood and alpine flora in general. The low altitude parts of the northern slopes are generally covered with Turkey oak (\"Quercus cerris\"), European black pine (\"Pinus nigra\") and fir (\"Abies\") forests. At the altitudes of , hornbeam (\"Carpinus\") and beech (\"Fagus\"') become dominant accompanied with some other firewood and deciduous plants. At higher elevations, at and above, Turkish pine (\"Pinus brutia\") and Scots pine (\"Pinus sylvestris\") establish pure or mixed forests. This zone is rich of endemic flora found in northern Turkey. The alpine zone beginning up from is utmost rich consisting of rare and endemic vegetation formed by dwarf shrubs. On the summit of Küçükhacettepe and Büyükhacettepe, which is the highest peak, numerous rare and endemic taxa are found.\nIt is believed that some 30 mammals are found in and around the Ilgaz Mountains. Abundant and all-year-long running streams as well as rich vegetation enable well-matched conditions for the habitat of fauna such as deer (\"Cervidae\"), roe deer (\"Capreolus capreolus\"), wild boar (\"Sus scrofa\"), grey wolf (\"Canis lupus\"), brown bear (\"Ursus arctos\"), red fox (\"Vulpes vulpes\"), wildcat (\"Felis silvestris\"), lynx, European pine marten (\"Martes martes\"), beech marten (\"Martes foina\"), weasel, rabbit, squirrel, hedgehog, mole, bat, European badger (\"Meles meles\") and European otter (\"Lutra lutra\"). Studies showed the existence of 617 taxa in and around the national park.\n\nMount Ilgaz National Park offers opportunities for diverse outdoor sports including hiking, camping and caravaning as well as daily activities. Angling at fishponds situated on Karasu stream in Baldıran Valley is possible between June 15 and September 15. Visitors can also buy trout throughout the year from fish hatcheries in the same area.\n\nAnother important feature of the national park is its potential for winter sports, which is performed at the site since the 1990s. The ski resort attracts visitors from Istanbul and Ankara. The nearest ski resort to Ankara is situated in the national park, called \"Ankara Konağı\" (\"Ankara Lodge\"). The Ilgaz Ski Resort, established officially in 1997 containing the entire national park, has a long ski slope available, which is served by a chairlift and a surface lift, each long.\n\nThe national park is situated on the state road between Çankırı and Kastamonu, which runs from Ankara to Black Sea coast northwards. It is east of Istanbul and northeast of Ankara, and south of Kastamonu, where also an airport is available. The site is north of the town Ilgaz on the Istanbul-Samsun highway ().\n\nThe main entrance to the national park is near the mountain pass at , which is the highest point of the highway .\n\nTo meet the catering and lodging needs of the visitors, the national park consists of a holiday village, social facilities and a hotel, all situated within Kastamonu Province side of the province borderline. In addition, there are accommodation facilities belonging to various public institutions. Ilgaz Mountain Resort offers 118 suites having 446 beds. The total lodging capacity at the national park is 666.\n"}
{"id": "145823", "url": "https://en.wikipedia.org/wiki?curid=145823", "title": "Obduction", "text": "Obduction\n\nObduction was originally defined by Coleman to mean the overthrusting of oceanic lithosphere onto continental lithosphere at a convergent plate boundary where continental lithosphere is being subducted beneath oceanic lithosphere.\n\nSubsequently, this definition has been broadened to mean the emplacement of continental lithosphere by oceanic lithosphere at a convergent plate boundary, such as closing of an ocean or a mountain building episode. This process is uncommon because the denser oceanic lithosphere usually subducts underneath the less dense continental plate.\nObduction occurs where a fragment of continental crust is caught in a subduction zone with resulting overthrusting of oceanic mafic and ultramafic rocks from the mantle onto the continental crust. Obduction may occur where a small tectonic plate is caught between two larger plates, with the lithosphere (both island arc and oceanic) welding onto an adjacent continent as a new terrane. When two continental plates collide, obduction of the oceanic lithosphere between them is often a part of the resulting orogeny.\n\nMost obductions appear to have initiated at back-arc basins above the subduction zones during the closing of an ocean or an orogeny.\n\nThe characteristic rocks of obducted oceanic lithosphere are the ophiolites. Ophiolites are an assemblage of oceanic lithosphere rocks that have been emplaced onto a continent. This assemblage consists of deep-marine sedimentary rock (chert, limestone, clastic sediments), volcanic rocks (pillow lavas, glass, ash, sheeted dykes and gabbros) and peridotite (mantle rock).\n\nThis process is operative beneath and behind the inner walls of oceanic trenches (subduction zone) where slices of oceanic crust and mantle are ripped from the upper part of the descending plate and wedged and packed in high pressure assemblages against the leading edge of the other plate.\n\nWeakening and cracking of oceanic crust and upper mantle is likely to occur in the tensional regime. This results in the incorporation of ophiolite slabs into the overriding plate.\n\nProgressive packing of ophiolite slices and arc fragments against the leading edge of a continent may continue over a long period of time and lead to a form of continental accretion.\n\nThe simplest form of this type of obduction may follow from the development of a subduction zone near the continental margin. Above and behind the subduction zone, a welt of oceanic crust and mantle rides up over the descending plate. The ocean, intervening between the continental margin and the subduction zone is progressively swallowed until the continental margin arrives at the subduction zone and a giant wedge or slice (nappe) of oceanic crust and mantle is pushed across the continental margin. Because the buoyancy of the relatively light continental crust is likely to prohibit its extensive subduction, a flip in subduction polarity will occur yielding an ophiolite sheet lying above a descending plate.\n\nIf however, a large tract of ocean intervenes between the continental margin the subduction zone, a fully developed arc and back arc basin may eventually arrive and collide with the continental margin. Further convergence may lead to overthrusting of the volcanic arc assemblage and may be followed by flipping the subduction polarity.\n\nAccording to the rock assemblage as well as the complexly deformed ophiolite basement and arc intrusions, the Coastal Complex of western Newfoundland may well have been formed by this mechanism.\n\nThis concept involves the progressive uplift of an actively spreading oceanic ridge, the detachment of slices from the upper part of the lithosphere and the subsequent gravity sliding of these slices onto the continental margin as ophiolites. This concept was advocated by Reinhardt for the emplacement of the Semail Ophiolite complex in Oman and argued by Church and Church and Stevens for the emplacement of the Bay of Islands sheet in western Newfoundland. This concept has subsequently been replaced by hypotheses that advocate subduction of the continental margin beneath oceanic lithosphere.\n\nMany ophiolite complexes were emplaced as thin hot obducted sheets of oceanic lithosphere shortly after their generation by plate accretion. The change from a spreading plate boundary to a subduction plate boundary may result from rapid rearrangement of relative plate motion. \nA transform fault may also become a subduction zone, with the side with the higher, hotter, thinner lithosphere riding over the lower, colder lithosphere. This mechanism would lead to obduction of ophiolite complex if it occurred near a continental margin.\n\nIn the situation where a spreading ridge approaches a subduction zone, the ridge collides with the subduction zone, at which time there will develop a complex interaction of subduction-related tectonic sedimentary, and spreading-related tectonic igneous activity. The left-over ridge may either subduct or ride upward across the trench onto arc trench gap and arc terranes as a hot ophiolite slice. These two mechanisms are shown in figure 2 B and C.\nTwo examples of this interaction of a ridge colliding into a trench are well documented. The first one is the progressive diminution of the Farallon plate off California. Ophiolite obduction by the above proposed mechanism would not be expected as the two plates share a dextral transform boundary. However, the major collision of the Kula/Pacific plate with the Alaskan/Aleutian resulted in the initiation of subduction of the Pacific plate beneath Alaska, with no sign of either obduction or indeed any major manifestation of a ridge being “swallowed”.\n\nDewey and Bird suggested that a common form of ophiolite obduction is related to the closure of rear-arc marginal basins and that, during such closure by subduction, slices of oceanic crust and mantle may be expelled onto adjacent continental forelands and emplaced as ophiolite sheets. In the high heat-flow region of a volcanic arc and rear-arc basin the lithosphere is particularly thin. This thin lithosphere may preferentially fail along gently dipping thrust surface if a compressional stress is applied to the region. Under these circumstances a thin sheet of lithosphere may become detached and begin to ride over adjacent lithosphere to finally become emplaced as a thin ophiolite sheet on the adjacent continental foreland.\nThis mechanism is a form of plate convergence where a thin, hot layer of oceanic lithosphere is obducted over cooler and thicker lithosphere.\n\nAs an ocean is progressively trapped in between two colliding continental lithospheres, the rising wedges of oceanic crust and mantle rise are caught in the jaws of the continent/continent vise and detach and begin to move up the advancing continental rise. Continued convergence may lead to the overthrusting of the arc-trench gap and eventually overthrusting of the metamorphic plutonic and volcanic rocks of the volcanic arc.\n\nFollowing total subduction of an oceanic tract, continuing convergence may lead to a further sequence of intra-continental mechanisms of crustal shortening. \nThis mechanism is thought to be responsible for the various ocean basins of the Mediterranean region. The Alpine belt is believed to register a complex history of plate interactions during the general convergence of the Eurasian plate and African plates.\n\nThere are many examples of oceanic crustal rocks and deeper mantle rocks that have been obducted and exposed at the surface worldwide. New Caledonia is one example of recent obduction. The Klamath Mountains of northern California contain several obducted oceanic slabs. Obducted fragments also are found in Oman, the Troodos Mountains of Cyprus, Newfoundland, New Zealand, the Alps of Europe, the Shetland islands of Unst and Fetlar, and the Appalachians of eastern North America.\n"}
{"id": "34836294", "url": "https://en.wikipedia.org/wiki?curid=34836294", "title": "Paradise Lust", "text": "Paradise Lust\n\nParadise Lust: Searching for the Garden of Eden is a 2011 book by Brook Wilensky-Lanford that discusses efforts to locate the Garden of Eden.\n\nWilensky-Lanford writes that more people began to search for the garden to reassert the truth of the Bible after the advent of Darwinism. The book focuses on 20th-century individuals who have sought to locate the garden. Wilensky-Lanford profiles several individuals who have discussed the location of the garden, including William Fairfield Warren and the author(s) of \"The Urantia Book\". \"Paradise Lust\" also discusses the work of archaeologist Juris Zarins.\n\nAssociated Press writer Carl Hartman applauded the book as \"witty and exhaustively researched\", though he notes that the title could confuse readers. (Wilensky-Lanford chose the book's title as a reference to \"Paradise Lost\" by John Milton, not to indicate sexual content.) Writing in \"The New York Times\", Andrea Wulf praised the book as an \"enjoyable parade of oddities\" that is an \"appealing mix of serious research and tongue-in-cheek humor\", but noted that it occasionally felt like a repetitive list of bizarre characters.\n\n"}
{"id": "8642593", "url": "https://en.wikipedia.org/wiki?curid=8642593", "title": "Pinch analysis", "text": "Pinch analysis\n\nPinch analysis is a methodology for minimising energy consumption of chemical processes by calculating thermodynamically feasible \"energy targets\" (or minimum energy consumption) and achieving them by optimising heat recovery systems, energy supply methods and process operating conditions. It is also known as \"process integration\", \"heat integration\", \"energy integration\" or \"pinch technology\".\n\nThe process data is represented as a set of energy flows, or streams, as a function of heat load (kW) against temperature (°C). These data are combined for all the streams in the plant to give \"composite curves\", one for all \"hot streams\" (releasing heat) and one for all \"cold streams\" (requiring heat). The point of closest approach between the hot and cold composite curves is the \"pinch point\" (or just \"pinch\") with a hot stream pinch temperature and a cold stream pinch temperature. This is where the design is most constrained. Hence, by finding this point and starting the design there, the energy targets can be achieved using heat exchangers to recover heat between hot and cold streams in two separate systems, one for temperatures above pinch temperatures and one for temperatures below pinch temperatures. In practice, during the pinch analysis of an existing design, often cross-pinch exchanges of heat are found between a hot stream with its temperature above the pinch and a cold stream below the pinch. Removal of those exchangers by alternative matching makes the process reach its \"energy target\".\n\nIn 1971, Ed Hohmann stated in his PhD that 'one can\ncompute the least amount of hot and cold utilities required for a process\nwithout knowing the heat exchanger network that could accomplish it. One\nalso can estimate the heat exchange area required'.\n\nIn late 1977, Ph.D. student Bodo Linnhoff under the supervision of Dr John Flower at the University of Leeds showed the existence in many processes of a heat integration bottleneck, ‘the pinch’, which laid the basis for the technique, known today as pinch-analysis. At that time he had joined Imperial Chemical Industries (ICI) where he led practical applications and further method development.\n\nBodo Linnhoff developed the 'Problem Table', an algorithm for calculating the energy targets and worked out the basis for a calculation of the surface area required, known as ‘the spaghetti network’. These algorithms enabled practical application of the technique.\n\nIn 1982 he joined University of Manchester Institute of Technology (UMIST, present day University of Manchester) to continue the work. In 1983 he set up a consultation firm known as Linnhoff March International later acquired by KBC Energy Services.\n\nMany refinements have been developed since and used in a wide range of industries, including extension to heat and power systems and\nnon-process situations. Both detailed and simplified (spreadsheet) programs are now available to calculate the energy targets. See Pinch Analysis Software below.\n\nIn recent years, Pinch analysis has been extended beyond energy applications. It now includes:\n\n\nClassical pinch-analysis primarily calculates the energy costs for the heating and cooling utility. At the pinch point, where the hot and cold streams are the most constrained, large heat exchangers are required to transfer heat between the hot and cold streams. Large heat exchangers entail high investment costs. In order to reduce capital cost, in practice a minimum temperature difference (Δ T) at the pinch point is demanded, e.g., 10 °F. It is possible to estimate the heat exchanger area and capital cost, and hence the optimal Δ T minimum value. However, the cost curve is quite flat and the optimum may be affected by \"topology traps\". The pinch method is not always appropriate for simple networks or where severe operating constraints exist. Kemp (2006) discusses these aspects in detail.\n\nThe problem of integrating heat between hot and cold streams, and finding the optimal network, in particular in terms of costs, may today be solved with numerical algorithms. The network can be formulated as a so-called mixed integer non-linear programming (MINLP) problem and solved with an appropriate numerical solver. Nevertheless, large-scale MINLP problems can still be hard to solve for today’s numerical algorithms. Alternatively, some attempts were made to formulate the MINLP problems to mixed integer linear problems, where then possible networks are screened and optimized. For simple networks of a few streams and heat exchangers, hand design methods with simple targeting software are often adequate, and aid the engineer in understanding the process.\n\n\n\n"}
{"id": "22472780", "url": "https://en.wikipedia.org/wiki?curid=22472780", "title": "Quantum chromodynamics binding energy", "text": "Quantum chromodynamics binding energy\n\nQuantum chromodynamics binding energy (QCD binding energy), gluon binding energy or chromodynamic binding energy is the energy binding quarks together into hadrons. It is the energy of the field of the strong force, which is mediated by gluons. QCD binding energy contributes most of the hadron's mass.\n\nMost of the mass of hadrons is actually QCD binding energy, through mass-energy equivalence. This phenomenon is related to chiral symmetry breaking. In the case of nucleons – protons and neutrons – QCD binding energy forms about 99% of the nucleon's mass. That is if assuming that the kinetic energy of the hadron's constituents, moving at near the speed of light, which contributes greatly to the hadron mass, is part of QCD binding energy. For protons, the sum of the rest masses of the three valence quarks (two up quarks and one down quark) is approximately 9.4 MeV/c, while the proton's total mass is about 938.3 MeV/c. For neutrons, the sum of the rest masses of the three valence quarks (two down quarks and one up quark) is approximately 11.9 MeV/c, while the neutron's total mass is about 939.6 MeV/c. Considering that nearly all of the atom's mass is concentrated in the nucleons, this means that about 99% of the mass of everyday matter (baryonic matter) is, in fact, chromodynamic binding energy.\n\nWhile gluons are massless, they still possess energy – chromodynamic binding energy. In this way, they are similar to photons, which are also massless particles carrying energy – photon energy. The amount of energy per single gluon, or \"gluon energy\", cannot be calculated. Unlike photon energy, which is quantifiable, described by the Planck-Einstein relation and depends on a single variable (the photon's frequency), no formula exists for the quantity of energy carried by each gluon. While the effects of a single photon can be observed, single gluons have not been observed outside of a hadron. Due to the mathematical complexity of quantum chromodynamics and the somewhat chaotic structure of hadrons, which are composed of gluons, valence quarks, sea quarks and other virtual particles, it is not even measurable how many gluons exist at a given moment inside a hadron. Additionally, not all of the QCD binding energy is gluon energy, but rather, some of it comes from the kinetic energy of the hadron's constituents. Therefore, only the total QCD binding energy per hadron can be stated. However, in the future, studies into quark-gluon plasma might be able to overcome this.\n\n"}
{"id": "13858535", "url": "https://en.wikipedia.org/wiki?curid=13858535", "title": "Rana Niejta", "text": "Rana Niejta\n\nRana Niejta and Rana Niejte are Ume Sami names on a goddess in Sami mythology. In Northern Sami she is called Rana Neida and Rana Neide (names in other Sami languages are Rana Nieda, Ruona Neida, Radien-neide and Blende).\n\nRana Niejta is the goddess for spring and fertility. The literal translation of the name Rana is «the green» or «the green, fertile fields». The name Rana Niejta can freely be translated as «the daughter of earth». According to Sami mythology, she made the mountains turned southwards green, so that hungry reindeer had enough food.\n\nThe Finnish linguist Otto Donner described in his translation of Sámi poems into German and Finnish in 1876 how Sala Niejta \"daughter of the Sun\", Rana Niejta and Saivo Niejta \"daughter of the underworld\" often were mentioned together in sami poetry, and sometimes were confused with each other by outsiders without personal knowledge of Sámi mythology:\n\nHowever, older sources from 1700 clearly shows that they are three different goddesses. Sala Niejta had the power to end the snow and the cold, while Rana Niejta made it possible for trees and herbs to grow and flourish anew every year. Rana Niejta thus represents the recreation of the spring.\n\nThe Samis considered the Sun as Sala Niejta and Rana Niejta were two different goddesses, which, together with \nSome also consider her name as the origin of the name of the municipality of Rana in Norway.\n\nIn 1971, a bronze statue depicting Rana-Niejta was raised in the park beneath the shopping centre LA Meyer in Mo i Rana. The statue was made by the artist Arne Durban, and financed by \"Den Norske Bank\" (DNB, «The Norwegian Bank») in 1970 in connection with its 25-years anniversary. It was delivered to Rana municipality on November 19, 1970. In 2003, a similar statue was moved from DNB to \"Nordlandsbanken\" («Bank of Nordland») in Rana after the process of amalgamating the two banks.\n\n"}
{"id": "3328574", "url": "https://en.wikipedia.org/wiki?curid=3328574", "title": "RapidEye", "text": "RapidEye\n\nRapidEye AG was a German geospatial information provider focused on assisting in management decision-making through services based on their own Earth observation imagery. The company operated a five-satellite constellation producing 5 meter resolution imagery that was designed and implemented by MacDonald Dettwiler (MDA) of Richmond, Canada.\n\nToday, RapidEye refers to the constellation of 5 earth observation satellites owned and operated by Planet Labs.\n\n1996: The RapidEye business concept was designed by Kayser-Threde GmbH, based on a call for ideas from the DLR (German Aerospace Agency), on how to commercialize remote sensing in Germany.\n\n1998: RapidEye was established as an independent company in Munich with seed financing from a few private investors and Vereinigte Hagelversicherung, a German agricultural insurance provider.\n\nIn 2004, funding was secured for the RapidEye satellite constellation and ground segment with the help of the European Union, the State of Brandenburg (Germany), a banking consortium consisting of Commerzbank, EDC (Export Development Canada) and KfW Banking Group.\nThrough a contract with the CCC (Canadian Commercial Corporation), MacDonald Dettwiler (MDA) was awarded the contract as the prime contractor to build RapidEye's satellite system.\nOriginally located in Munich, the company relocated 60 km southwest of Berlin to Brandenburg an der Havel in 2004.\n\n2008: RapidEye earned certification in April from TÜV Nord. On August 29, 2008, a Dnepr rocket (a refurbished ICBM missile), was successfully launched from Baikonur in Kazakhstan carrying RapidEye's constellation of five Earth observation satellites designed and implemented by MacDonald Dettwiler (MDA) of Richmond, Canada.\n\n2009: After the satellites completed their MPAR phase (consisting of testing and calibration) they became commercially operational in February 2009.\n\n2011: RapidEye files for bankruptcy protection on 30 May.\n\n2011: RapidEye Blackbridge Ltd. of Lethbridge, Alberta, Canada acquired RapidEye AG on 29 August.\n\nOn December 18, 2012 the company announced that it has successfully relocated the company headquarters to Berlin, Germany.\n\nOn November 6, 2013 RapidEye officially changed its name to BlackBridge.\n\n2014: Blackbridge Ltd. announced a new constellation called RapidEye+ \n\n2015 : Planet Labs acquired RapidEye.\n\nFive Identical Satellites: Built by Surrey Satellite Technology Ltd. (SSTL) of Guildford, subcontracted by MacDonald Dettwiler (MDA), each satellite is based on an evolution of the flight-proven SSTL-100 bus. Each satellite measures less than one cubic meter and weighs 150 kg (bus + payload).\n\nEach of RapidEye's five satellites contain identical sensors, are equally calibrated and travel on the same orbital plane (at an altitude of 630 km). Together, the 5 satellites are capable of collecting over 4 million km² of 5 m resolution, 5-band color imagery every day.\n\nSensors: The Jena-Optronik multi-spectral imager, the Jena Spaceborne Scanner JSS 56, is a pushbroom sensor carried on each satellite. Each sensor is capable of collecting image data in five distinct bands of the electromagnetic spectrum: Blue (440-510 nm), Green (520-590 nm), Red (630-690 nm), Red-Edge (690-730 nm) and Near-Infrared (760-880 nm). The nominal resolution on the ground is 6.5 meters, corresponding to NIIRS 2.\n\nRapidEye's satellites are the first commercial satellites to include the Red-Edge band, which is sensitive to changes in chlorophyll content. Studies show that this band can assist in monitoring vegetation health, improve species separation and help in measuring protein and nitrogen content in biomass.\n\n\n\nImagery from the RapidEye constellation can provide geospatial information to the following industries:\n\nAgriculture – The RapidEye constellation is capable of field based, regional or global scale agricultural monitoring on a frequent revisit cycle. The information derived from the imagery can assist farmers in precision farming operations, agricultural insurers in damage assessment and risk management, or governments in food security and environmental compliance monitoring.\n\nForestry – Satellite-based information is increasingly being used by governments and commercial operators to assess forest status, evaluate management strategies, measure the environmental and economical sustainability of forest operations and monitor illegal logging and deforestation.\n\nSecurity & Emergency - Fast turnaround of imagery showing current ground conditions following a natural or man-made disaster is essential for crisis management authorities in assessing the situation and helping to better coordinate rescue teams.\n\nEnvironment – Satellite imagery can provide valuable information to governmental agencies or industries, that monitor the environmental impact of human activities.\n\nSpatial Solutions – RapidEye satellite imagery is used as background imagery for a variety of purposes including mapping, navigation, flight simulation, gaming and as an integral component in geospecific 3D modeling.\n\nEnergy & Infrastructure - The RapidEye constellation can monitor pipeline and transmission corridors and identify problems on the ground such as vegetation encroachment, nearby buildings, development of roads or leaks. It can provide land cover and land use classification data to telecommunication firms to assist in planning their antenna network.\n\n"}
{"id": "17371523", "url": "https://en.wikipedia.org/wiki?curid=17371523", "title": "Rivera Transform Fault", "text": "Rivera Transform Fault\n\nThe Rivera Transform Fault, also referred to as the Rivera Fracture Zone, is a right lateral-moving (dextral) transform fault which lies along the seafloor of the Pacific Ocean off the west coast of Mexico just south of the mouth of the Gulf of California. It runs between two segments of the East Pacific Rise, forming the southwest boundary of the small Rivera Plate. The fault is broken into two segments, bisected by a short rifting zone.\n"}
{"id": "2990123", "url": "https://en.wikipedia.org/wiki?curid=2990123", "title": "Serravallian", "text": "Serravallian\n\nThe Serravallian is in the geologic timescale an age or a stage in the middle Miocene epoch/series, that spans the time between 13.65 ± 0.05 Ma and 11.608 ± 0.005 Ma (million years ago). The Serravallian follows the Langhian and is followed by the Tortonian.\n\nIt overlaps with the middle of the Astaracian European Land Mammal Mega Zone, the upper Barstovian and lower Clarendonian North American Land Mammal Ages and the Laventan and lower Mayoan South American Land Mammal Ages. It is also coeval with the Sarmatian and upper Badenian stages of the Paratethys time scale of Central and eastern Europe.\n\nThe Serravallian stage was introduced in stratigraphy by the Italian geologist Lorenzo Pareto in 1865. It was named after the town of Serravalle Scrivia in northern Italy.\n\nThe base of the Serravallian is at the first occurrence of fossils of the nanoplankton species \"Sphenolithus heteromorphus\" and is located in the magnetic chronozone C5ABr. The official Global Boundary Stratotype Section and Point (GSSP) for the Serravallian is in the 'Ras il-Pellegrin' section, located at the 'Ras il-Pellegrin' headland in the vicinity of 'Fomm ir-Rih' Bay , SW Malta.The base of the Serravallian is represented in the field as the formation boundary between the Globigerina Limestone formation and the Blue Clay formation . The base of the Serravallian is related to the Mi3b oxygen isotope excursion marking the onset of the Middle Miocene Cooling step. \n\nThe top of the Serravallian (the base of the Tortonian stage) is at the last common appearance of calcareous nannoplanktons \"Discoaster kugleri\" and planktonic foram \"Globigerinoides subquadratus\". It is also associated with the short normal-polarized magnetic chronozone C5r.2n.\n\n\n"}
{"id": "39766788", "url": "https://en.wikipedia.org/wiki?curid=39766788", "title": "The Poverty of Philosophy", "text": "The Poverty of Philosophy\n\nThe Poverty of Philosophy ( \"Misère de la philosophie\") is a book by Karl Marx published in Paris and Brussels in 1847, where he lived in exile from 1843 until 1849. It was originally written in French as an answer to the economic and philosophical arguments of French anarchist Pierre-Joseph Proudhon set forth in his 1846 book \"The System of Economic Contradictions, or The Philosophy of Poverty.\"\n\nPierre-Joseph Proudhon (1809-1865) was a French anarchist theoretician who wrote extensively on the relationship between the individual and the state. Proudhon believed in an orderly society but argued that the state represented an illegitimate concentration of official violence which effectively undercut any effort to build a just society. Proudhon rejected all political action as a form of class collaboration but argued instead that the working class could achieve its salvation through economic action alone; abstention from politics was advocated with a view to the ultimate eradication of the existing state and its political apparatus.\n\nProudhon believed that the stateless future was not preordained by iron laws of history, but was rather to be the conscious creation of a population which had been morally awakened. This necessary morality, based upon honesty, decency, self-respect, and individual responsibility, was believed to be an inherent part of the working class—something to be developed and emphasized.\n\nBy way of contrast, industrialists, businessmen, and their servitors were held to be incapable of developing this morality due to the nature of their day-to-day economic and political activity. The act of labor itself was believed to be socially ennobling, whereas the act of economic exploitation backed by political force was held to be inherently corrupting. Therefore, Proudhon emphatically declared for a strict separatism between the working class and all others.\n\nKarl Marx left Germany following the repression of the newspaper he edited, the Rheinische Zeitung, by the government of Prussia early in 1843. He landed in Paris, where he lived from October 1843 until December 1845. It was there that he first met Proudhon, who was already a well known radical writer, with four books to his credit. Despite an appeal being made as a prospective French collaborator, Proudhon declined to participate in the ill-fated \"Deutsch-französische Jahrbücher\" (German-French Yearbook) project with which Marx was intimately associated.\n\nAlthough the personal contact between the two was limited, Marx read Proudhon's writings at this time, discussions of which may be found in his work of the period, including the book written against Bruno Bauer, \"The Holy Family\" (1845), and the unpublished \"Economic and Philosophic Manuscripts of 1844.\" In the published book Marx lent critical support to some of the ideas of Proudhon against competing ideas of Bauer.\n\nMarx was particularly attracted to the comprehensive nature of Proudhon's writings up to 1845 and the latter's willingness to make larger connections from smaller observations. In his book \"What Is Property?\" Proudhon emphasized the social relationships emerging from private property, and the tendency of economic development to produce a propertyless proletariat in ever increasing numbers—ideas which Marx found compelling. Marx's praise of Proudhon was not limitless, however, as he felt Proudhon did not fully grasp the way in which wages and money, for example, were themselves forms of private property.\n\nMarx was forced to exit Paris by the French government in 1845, with Brussels, Belgium his next destination. Despite his departure from France, he continued to see Proudhon as a potential political collaborator, asking him in 1846 to participate in a new international correspondence committee patterned after the London-based Workers' Educational Association, designed to propagate socialist ideas among the working class of continental Europe. Proudhon responded cautiously to Marx's appeal. Perhaps partially in consequence, Marx and his friend and political associate turned their organizing efforts to an established political body, the League of the Just.\n\nMarx read Proudhon's book late in 1846 and responded strongly and negatively, authoring a lengthy letter to his Russian correspondent P.V. Annenkov on December 28, 1846 with a detailed exposition of his views that became the core of his 1847 book. He began working on a book-length formal reply the following January, completing the work in the spring and going to press in April 1847.\n\nThe book, formally titled \"The Poverty of Philosophy: Answer to the\" Philosophy of Poverty \" by M. Proudhon,\" saw print in Brussels and Belgium early in July 1847. The book was written in the French language to strike its target most closely and for the cutting pun of a title to be rendered most unmistakably. The book was regarded by the political circle around Marx organized as the Communist League as a key part of their contemporary program, delineating the views of the League from those espoused by Proudhon and his followers.\n\nSomewhat surprisingly, following its initial release in 1847, \"The Poverty of Philosophy\" was never republished in full prior to Marx's death in 1883. The first German edition of the book was first published in 1885; a Russian language translation by the Emancipation of Labor group ( Освобождение труда) was released in 1886. A corrected Second French Edition materialized in 1896, initiated by Friedrich Engels and completed after his death by Marx's daughter, Laura Lafargue.\n\nThe first English language edition of \"The Poverty of Philosophy\" was unveiled in London in 1900 by the pioneer Marxist publisher Twentieth Century Press. The translation for this edition was made by British socialist Harry Quelch. Quelch's version was reprised in the United States for the first time in 1910 by Charles H. Kerr & Co., a socialist publishing house based in Chicago.\n\nThe tone of Marx's polemic against Proudhon is set from the outset, with a witty cut in lieu of a foreword:\n\"M. Proudhon has the misfortune of being particularly misunderstood in Europe. In France, he has the right to be a bad economist, because he is reputed to be a good German philosopher. In Germany, he has the right to be a bad philosopher, because he is reputed to be one of the ablest of French economists. Being both a German and an economist at the same time, we desire to protest against this double error... —\"Karl Marx,\" Brussels, June 15, 1847.\"\n\nAlthough prominently featuring the word \"philosophy\" in its title, \"The Poverty of Philosophy\" is essentially a book dealing with the subject of economics—first English-language translator Harry Quelch noted that the work contained \"the groundwork of the theories so fully elaborated in \"Capital\", apart from its exhaustive analysis of the capitalist system of production and distribution\" as well as law of value To argue the method to apply the dialectics to political economy, he cites the Science of Logic of Hegel. And Marx rejects idea of Proudhon on consumption tax and denial of strike action. And the end of the book, he cites the words of George Sand that \"Combat or Death: bloody struggle or extinction. It is thus that the question is inexorably put.\". Further he cites the theory of John Gray. Indeed, the book has been called by one Soviet scholar, \"one of the first works of mature Marxism.\"\n\nIn 1956 economist Joan Robinson proclaimed in a review of a new British edition of \"The Poverty of Philosophy\" that from the standpoint of modern economics Marx's polemic with Proudhon was \"a dead horse\" of only \"highly specialised interest.\" She wrote:\n\"The entertainment value...is not great. There is no wit in \"The Poverty of Philosophy\" apart from its title; Proudhon's ideas were confused enough to begin with, and Marx's presentation of them makes them totally unseizable, so that there is little sport to be got out of following the argument. All the same for anyone interested in 'What Marx Really Meant' some passages in this book are very valuable. In some ways they bear the same relation to \"Capital\" that Marshall's \"Pure Theory\" does to his \"Principles\". Ideas that are clear in the early and short version were later elaborated into obscurity.\"\n\nAlthough a widely recognized and periodically reissued title, \"The Poverty of Philosophy\" is not regarded as one of the fundamental works of Marxist doctrine, exemplified by its omission from the two volume \"Karl Marx: Selected Works\" published simultaneously in several countries in the 1930s under the auspices of the Marx-Engels-Lenin Institute of Moscow.\n\nA new translation of the work appeared in conjunction with the publication of Volume 6 of the joint Soviet-British-American publication of \"Marx-Engels Collected Works\" in 1975.\n\n"}
{"id": "31161", "url": "https://en.wikipedia.org/wiki?curid=31161", "title": "Tsunami", "text": "Tsunami\n\nA tsunami (from , \"harbour wave\";\nEnglish pronunciation: or ) sometimes incorrectly referred to as a tidal wave, also known as a seismic sea wave, is a series of waves in a water body caused by the displacement of a large volume of water, generally in an ocean or a large lake. Earthquakes, volcanic eruptions and other underwater explosions (including detonations of underwater nuclear devices), landslides, glacier calvings, meteorite impacts and other disturbances above or below water all have the potential to generate a tsunami. Unlike normal ocean waves, which are generated by wind, or tides, which are generated by the gravitational pull of the Moon and the Sun, a tsunami is generated by the displacement of water. \nTsunami waves do not resemble normal undersea currents or sea waves because their wavelength is far longer. Rather than appearing as a breaking wave, a tsunami may instead initially resemble a rapidly rising tide. For this reason, it is often referred to as a \"tidal wave\", although this usage is not favoured by the scientific community because it might give the false impression of a causal relationship between tides and tsunamis. Tsunamis generally consist of a series of waves, with periods ranging from minutes to hours, arriving in a so-called \"internal wave train\". Wave heights of tens of metres can be generated by large events. Although the impact of tsunamis is limited to coastal areas, their destructive power can be enormous, and they can affect entire ocean basins. The 2004 Indian Ocean tsunami was among the deadliest natural disasters in human history, with at least 230,000 people killed or missing in 14 countries bordering the Indian Ocean.\n\nThe Ancient Greek historian Thucydides suggested in his 5th century BC \"History of the Peloponnesian War\" that tsunamis were related to submarine earthquakes, but the understanding of tsunamis remained slim until the 20th century and much remains unknown. Major areas of current research include determining why some large earthquakes do not generate tsunamis while other smaller ones do; accurately forecasting the passage of tsunamis across the oceans; and forecasting how tsunami waves interact with shorelines.\n\nThe term \"tsunami\" is a borrowing from the Japanese \"tsunami\" , meaning \"harbour wave\". For the plural, one can either follow ordinary English practice and add an \"s\", or use an invariable plural as in the Japanese. Some English speakers alter the word's initial to an by dropping the \"t\", since English does not natively permit /ts/ at the beginning of words, though the original Japanese pronunciation is .\n\nTsunamis are sometimes referred to as tidal waves. This once-popular term derives from the most common appearance of a tsunami, which is that of an extraordinarily high tidal bore. Tsunamis and tides both produce waves of water that move inland, but in the case of a tsunami, the inland movement of water may be much greater, giving the impression of an incredibly high and forceful tide. In recent years, the term \"tidal wave\" has fallen out of favour, especially in the scientific community, because the causes of tsunamis have nothing to do with those of tides, which are produced by the gravitational pull of the moon and sun rather than the displacement of water. Although the meanings of \"tidal\" include \"resembling\" or \"having the form or character of\" the tides, use of the term \"tidal wave\" is discouraged by geologists and oceanographers.\n\nThe term seismic sea wave also is used to refer to the phenomenon, because the waves most often are generated by seismic activity such as earthquakes. Prior to the rise of the use of the term \"tsunami\" in English, scientists generally encouraged the use of the term \"seismic sea wave\" rather than \"tidal wave\". However, like \"tsunami\", \"seismic sea wave\" is not a completely accurate term, as forces other than earthquakes – including underwater landslides, volcanic eruptions, underwater explosions, land or ice slumping into the ocean, meteorite impacts, and the weather when the atmospheric pressure changes very rapidly – can generate such waves by displacing water.\n\nWhile Japan may have the longest recorded history of tsunamis, the sheer destruction caused by the 2004 Indian Ocean earthquake and tsunami event mark it as the most devastating of its kind in modern times, killing around 230,000 people. The Sumatran region is also accustomed to tsunamis, with earthquakes of varying magnitudes regularly occurring off the coast of the island.\n\nTsunamis are an often underestimated hazard in the Mediterranean Sea and parts of Europe. Of historical and current (with regard to risk assumptions) importance are the 1755 Lisbon earthquake and tsunami (which was caused by the Azores–Gibraltar Transform Fault), the 1783 Calabrian earthquakes, each causing several tens of thousands of deaths and the 1908 Messina earthquake and tsunami. The tsunami claimed more than 123,000 lives in Sicily and Calabria and is among the most deadly natural disasters in modern Europe. The Storegga Slide in the Norwegian Sea and some examples of tsunamis affecting the British Isles refer to landslide and meteotsunamis predominantly and less to earthquake-induced waves.\n\nAs early as 426 BC the Greek historian Thucydides inquired in his book \"History of the Peloponnesian War\" about the causes of tsunami, and was the first to argue that ocean earthquakes must be the cause.\n\nThe cause, in my opinion, of this phenomenon must be sought in the earthquake. At the point where its shock has been the most violent the sea is driven back, and suddenly recoiling with redoubled force, causes the inundation. Without an earthquake I do not see how such an accident could happen.\n\nThe Roman historian Ammianus Marcellinus (\"Res Gestae\" 26.10.15–19) described the typical sequence of a tsunami, including an incipient earthquake, the sudden retreat of the sea and a following gigantic wave, after the 365 AD tsunami devastated Alexandria.\n\nThe principal generation mechanism (or cause) of a tsunami is the displacement of a substantial volume of water or perturbation of the sea. This displacement of water is usually attributed to either earthquakes, landslides, volcanic eruptions, glacier calvings or more rarely by meteorites and nuclear tests. The waves formed in this way are then sustained by gravity.\n\nTsunami can be generated when the sea floor abruptly deforms and vertically displaces the overlying water. Tectonic earthquakes are a particular kind of earthquake that are associated with the Earth's crustal deformation; when these earthquakes occur beneath the sea, the water above the deformed area is displaced from its equilibrium position. More specifically, a tsunami can be generated when thrust faults associated with convergent or destructive plate boundaries move abruptly, resulting in water displacement, owing to the vertical component of movement involved. Movement on normal (extensional) faults can also cause displacement of the seabed, but only the largest of such events (typically related to flexure in the outer trench swell) cause enough displacement to give rise to a significant tsunami, such as the 1977 Sumba and 1933 Sanriku events.\n\nTsunamis have a small amplitude (wave height) offshore, and a very long wavelength (often hundreds of kilometres long, whereas normal ocean waves have a wavelength of only 30 or 40 metres), which is why they generally pass unnoticed at sea, forming only a slight swell usually about above the normal sea surface. They grow in height when they reach shallower water, in a wave shoaling process described below. A tsunami can occur in any tidal state and even at low tide can still inundate coastal areas.\n\nOn April 1, 1946, the 8.6 Aleutian Islands earthquake occurred with a maximum Mercalli intensity of VI (\"Strong\"). It generated a tsunami which inundated Hilo on the island of Hawaii with a surge. Between 165 and 173 were killed. The area where the earthquake occurred is where the Pacific Ocean floor is subducting (or being pushed downwards) under Alaska.\n\nExamples of tsunami originating at locations away from convergent boundaries include Storegga about 8,000 years ago, Grand Banks 1929, Papua New Guinea 1998 (Tappin, 2001). The Grand Banks and Papua New Guinea tsunamis came from earthquakes which destabilised sediments, causing them to flow into the ocean and generate a tsunami. They dissipated before travelling transoceanic distances.\n\nThe cause of the Storegga sediment failure is unknown. Possibilities include an overloading of the sediments, an earthquake or a release of gas hydrates (methane etc.).\n\nThe 1960 Valdivia earthquake (\"M\" 9.5), 1964 Alaska earthquake (\"M\" 9.2), 2004 Indian Ocean earthquake (\"M\" 9.2), and 2011 Tōhoku earthquake (\"M\"9.0) are recent examples of powerful megathrust earthquakes that generated tsunamis (known as teletsunamis) that can cross entire oceans. Smaller (\"M\" 4.2) earthquakes in Japan can trigger tsunamis (called local and regional tsunamis) that can devastate stretches of coastline, but can do so in only a few minutes at a time.\n\nIn the 1950s, it was discovered that larger tsunamis than had previously been believed possible could be caused by giant submarine landslides. These rapidly displace large water volumes, as energy transfers to the water at a rate faster than the water can absorb. Their existence was confirmed in 1958, when a giant landslide in Lituya Bay, Alaska, caused the highest wave ever recorded, which had a height of 524 metres (over 1700 feet). The wave did not travel far, as it struck land almost immediately. Two people fishing in the bay were killed, but another boat managed to ride the wave.\n\nAnother landslide-tsunami event occurred in 1963 when a massive landslide from Monte Toc entered the Vajont Dam in Italy. The resulting wave surged over the 262 m (860 ft) high dam by 250 metres (820 ft) and destroyed several towns. Around 2,000 people died. Scientists named these waves megatsunamis.\n\nSome geologists claim that large landslides from volcanic islands, e.g. Cumbre Vieja on La Palma in the Canary Islands, may be able to generate megatsunamis that can cross oceans, but this is disputed by many others.\nIn general, landslides generate displacements mainly in the shallower parts of the coastline, and there is conjecture about the nature of large landslides that enter the water. This has been shown to subsequently affect water in enclosed bays and lakes, but a landslide large enough to cause a transoceanic tsunami has not occurred within recorded history. Susceptible locations are believed to be the Big Island of Hawaii, Fogo in the Cape Verde Islands, La Reunion in the Indian Ocean, and Cumbre Vieja on the island of La Palma in the Canary Islands; along with other volcanic ocean islands. This is because large masses of relatively unconsolidated volcanic material occurs on the flanks and in some cases detachment planes are believed to be developing. However, there is growing controversy about how dangerous these slopes actually are.\n\nSome meteorological conditions, especially rapid changes in barometric pressure, as seen with the passing of a front, can displace bodies of water enough to cause trains of waves with wavelengths comparable to seismic tsunamis, but usually with lower energies. These are essentially dynamically equivalent to seismic tsunamis, the only differences being that meteotsunamis lack the transoceanic reach of significant seismic tsunamis and that the force that displaces the water is sustained over some length of time such that meteotsunamis can't be modelled as having been caused instantaneously. In spite of their lower energies, on shorelines where they can be amplified by resonance, they are sometimes powerful enough to cause localised damage and potential for loss of life. They have been documented in many places, including the Great Lakes, the Aegean Sea, the English Channel, and the Balearic Islands, where they are common enough to have a local name, \"rissaga\". In Sicily they are called \"marubbio\" and in Nagasaki Bay, they are called \"abiki\". Some examples of destructive meteotsunamis include 31 March 1979 at Nagasaki and 15 June 2006 at Menorca, the latter causing damage in the tens of millions of euros.\n\nMeteotsunamis should not be confused with storm surges, which are local increases in sea level associated with the low barometric pressure of passing tropical cyclones, nor should they be confused with setup, the temporary local raising of sea level caused by strong on-shore winds. Storm surges and setup are also dangerous causes of coastal flooding in severe weather but their dynamics are completely unrelated to tsunami waves. They are unable to propagate beyond their sources, as waves do.\n\nThere have been studies of the potential of the induction of and at least one actual attempt to create tsunami waves as a tectonic weapon.\n\nIn World War II, the New Zealand Military Forces initiated Project Seal, which attempted to create small tsunamis with explosives in the area of today's Shakespear Regional Park; the attempt failed.\n\nThere has been considerable speculation on the possibility of using nuclear weapons to cause tsunamis near an enemy coastline. Even during World War II consideration of the idea using conventional explosives was explored. Nuclear testing in the Pacific Proving Ground by the United States seemed to generate poor results. \"Operation Crossroads\" fired two bombs, one in the air and one underwater, above and below the shallow () waters of the Bikini Atoll lagoon. Fired about from the nearest island, the waves there were no higher than upon reaching the shoreline. Other underwater tests, mainly \"Hardtack I/Wahoo\" (deep water) and \"Hardtack I/Umbrella\" (shallow water) confirmed the results. Analysis of the effects of shallow and deep underwater explosions indicate that the energy of the explosions doesn't easily generate the kind of deep, all-ocean waveforms which are tsunamis; most of the energy creates steam, causes vertical fountains above the water, and creates compressional waveforms. Tsunamis are hallmarked by permanent large vertical displacements of very large volumes of water which do not occur in explosions.\n\nTsunamis cause damage by two mechanisms: the smashing force of a wall of water travelling at high speed, and the destructive power of a large volume of water draining off the land and carrying a large amount of debris with it, even with waves that do not appear to be large.\n\nWhile everyday wind waves have a wavelength (from crest to crest) of about and a height of roughly , a tsunami in the deep ocean has a much larger wavelength of up to . Such a wave travels at well over , but owing to the enormous wavelength the wave oscillation at any given point takes 20 or 30 minutes to complete a cycle and has an amplitude of only about . This makes tsunamis difficult to detect over deep water, where ships are unable to feel their passage.\n\nThe velocity of a tsunami can be calculated by obtaining the square root of the depth of the water in metres multiplied by the acceleration due to gravity (approximated to 10 m/s). For example, if the Pacific Ocean is considered to have a depth of 5000 metres, the velocity of a tsunami would be the square root of √(5000 × 10) = √50000 = ~224 metres per second (735 feet per second), which equates to a speed of ~806 kilometres per hour or about 500 miles per hour. This is the formula used for calculating the velocity of shallow-water waves. Even the deep ocean is shallow in this sense because a tsunami wave is so long (horizontally from crest to crest) by comparison.\n\nThe reason for the Japanese name \"harbour wave\" is that sometimes a village's fishermen would sail out, and encounter no unusual waves while out at sea fishing, and come back to land to find their village devastated by a huge wave.\n\nAs the tsunami approaches the coast and the waters become shallow, wave shoaling compresses the wave and its speed decreases below . Its wavelength diminishes to less than and its amplitude grows enormously – in accord with Green's law. Since the wave still has the same very long period, the tsunami may take minutes to reach full height. Except for the very largest tsunamis, the approaching wave does not break, but rather appears like a fast-moving tidal bore. Open bays and coastlines adjacent to very deep water may shape the tsunami further into a step-like wave with a steep-breaking front.\n\nWhen the tsunami's wave peak reaches the shore, the resulting temporary rise in sea level is termed \"run up\". Run up is measured in metres above a reference sea level. A large tsunami may feature multiple waves arriving over a period of hours, with significant time between the wave crests. The first wave to reach the shore may not have the highest run-up.\n\nAbout 80% of tsunamis occur in the Pacific Ocean, but they are possible wherever there are large bodies of water, including lakes. They are caused by earthquakes, landslides, volcanic explosions, glacier calvings, and bolides.\n\nAll waves have a positive and negative peak; that is, a ridge and a trough. In the case of a propagating wave like a tsunami, either may be the first to arrive. If the first part to arrive at the shore is the ridge, a massive breaking wave or sudden flooding will be the first effect noticed on land. However, if the first part to arrive is a trough, a drawback will occur as the shoreline recedes dramatically, exposing normally submerged areas. The drawback can exceed hundreds of metres, and people unaware of the danger sometimes remain near the shore to satisfy their curiosity or to collect fish from the exposed seabed.\n\nA typical wave period for a damaging tsunami is about twelve minutes. Thus, the sea recedes in the drawback phase, with areas well below sea level exposed after three minutes. For the next six minutes, the wave trough builds into a ridge which may flood the coast, and destruction ensues. During the next six minutes, the wave changes from a ridge to a trough, and the flood waters recede in a second drawback. Victims and debris may be swept into the ocean. The process repeats with succeeding waves.\n\nAs with earthquakes, several attempts have been made to set up scales of tsunami intensity or magnitude to allow comparison between different events.\n\nThe first scales used routinely to measure the intensity of tsunami were the \"Sieberg-Ambraseys scale\", used in the Mediterranean Sea and the \"Imamura-Iida intensity scale\", used in the Pacific Ocean. The latter scale was modified by Soloviev, who calculated the Tsunami intensity \"I\" according to the formula\n\nwhere formula_2 is the average wave height along the nearest coast. This scale, known as the \"Soloviev-Imamura tsunami intensity scale\", is used in the global tsunami catalogues compiled by the NGDC/NOAA and the Novosibirsk Tsunami Laboratory as the main parameter for the size of the tsunami.\n\nIn 2013, following the intensively studied tsunamis in 2004 and 2011, a new 12 point scale was proposed, the Integrated Tsunami Intensity Scale (ITIS-2012), intended to match as closely as possible to the modified ESI2007 and EMS earthquake intensity scales.\n\nThe first scale that genuinely calculated a magnitude for a tsunami, rather than an intensity at a particular location was the ML scale proposed by Murty & Loomis based on the potential energy. Difficulties in calculating the potential energy of the tsunami mean that this scale is rarely used. Abe introduced the \"tsunami magnitude scale formula_3\", calculated from,\n\nwhere \"h\" is the maximum tsunami-wave amplitude (in m) measured by a tide gauge at a distance \"R\" from the epicentre, \"a\", \"b\" and \"D\" are constants used to make the M scale match as closely as possible with the moment magnitude scale.\n\nThere are different term being used to describe different characteristic of tsunami in term of their height, and each of them are used to refer to different characteristic of a tsunami.\n\n\nDrawbacks can serve as a brief warning. People who observe drawback (many survivors report an accompanying sucking sound), can survive only if they immediately run for high ground or seek the upper floors of nearby buildings. In 2004, ten-year-old Tilly Smith of Surrey, England, was on Maikhao beach in Phuket, Thailand with her parents and sister, and having learned about tsunamis recently in school, told her family that a tsunami might be imminent. Her parents warned others minutes before the wave arrived, saving dozens of lives. She credited her geography teacher, Andrew Kearney.\n\nIn the 2004 Indian Ocean tsunami drawback was not reported on the African coast or any other east-facing coasts that it reached. This was because the wave moved downwards on the eastern side of the fault line and upwards on the western side. The western pulse hit coastal Africa and other western areas.\n\nA tsunami cannot be precisely predicted, even if the magnitude and location of an earthquake is known. Geologists, oceanographers, and seismologists analyse each earthquake and based on many factors may or may not issue a tsunami warning. However, there are some warning signs of an impending tsunami, and automated systems can provide warnings immediately after an earthquake in time to save lives. One of the most successful systems uses bottom pressure sensors, attached to buoys, which constantly monitor the pressure of the overlying water column.\n\nRegions with a high tsunami risk typically use tsunami warning systems to warn the population before the wave reaches land. On the west coast of the United States, which is prone to Pacific Ocean tsunami, warning signs indicate evacuation routes. In Japan, the community is well-educated about earthquakes and tsunamis, and along the Japanese shorelines the tsunami warning signs are reminders of the natural hazards together with a network of warning sirens, typically at the top of the cliff of surroundings hills.\n\nThe Pacific Tsunami Warning System is based in Honolulu, Hawaii. It monitors Pacific Ocean seismic activity. A sufficiently large earthquake magnitude and other information triggers a tsunami warning. While the subduction zones around the Pacific are seismically active, not all earthquakes generate a tsunami. Computers assist in analysing the tsunami risk of every earthquake that occurs in the Pacific Ocean and the adjoining land masses.\n\nAs a direct result of the Indian Ocean tsunami, a re-appraisal of the tsunami threat for all coastal areas is being undertaken by national governments and the United Nations Disaster Mitigation Committee. A tsunami warning system is being installed in the Indian Ocean.\n\nComputer models can predict tsunami arrival, usually within minutes of the arrival time. Bottom pressure sensors can relay information in real time. Based on these pressure readings and other seismic information and the seafloor's shape (bathymetry) and coastal topography, the models estimate the amplitude and surge height of the approaching tsunami. All Pacific Rim countries collaborate in the Tsunami Warning System and most regularly practise evacuation and other procedures. In Japan, such preparation is mandatory for government, local authorities, emergency services and the population.\n\nSome zoologists hypothesise that some animal species have an ability to sense subsonic Rayleigh waves from an earthquake or a tsunami. If correct, monitoring their behaviour could provide advance warning of earthquakes, tsunami etc. However, the evidence is controversial and is not widely accepted. There are unsubstantiated claims about the Lisbon quake that some animals escaped to higher ground, while many other animals in the same areas drowned. The phenomenon was also noted by media sources in Sri Lanka in the 2004 Indian Ocean earthquake. It is possible that certain animals (e.g., elephants) may have heard the sounds of the tsunami as it approached the coast. The elephants' reaction was to move away from the approaching noise. By contrast, some humans went to the shore to investigate and many drowned as a result.\n\nAlong the United States west coast, in addition to sirens, warnings are sent on television and radio via the National Weather Service, using the Emergency Alert System.\n\nKunihiko Shimazaki (University of Tokyo), a leading member of the Earthquake Research Committee at The Headquarters for Earthquake Research Promotion in Japan, has mentioned an idea for instituting a system of public education regarding the probability of tsunami risk; such a system was announced by Shimazaki at the Japan National Press Club in May 2011. The forecast would include a detection for environmental risk, including proposed tsunami height, danger areas prone to tsunamis, and overall occurrence probability. The forecast would integrate the scientific knowledge of recent interdisciplinarity with information gathered from the aftermath of the 2011 Tōhoku earthquake and tsunami. Per the announcement, a plan was due to be put in place by 2014; however, reliable forecasting of earthquake and tsunami probability is still unavailable. Shimazaki acknowledged that, given the current literature on the topic, tsunami probability warnings are just as, if not more, difficult to predict than earthquake risk probability.\n\nIn some tsunami-prone countries, earthquake engineering measures have been taken to reduce the damage caused onshore.\n\nJapan, where tsunami science and response measures first began following a disaster in 1896, has produced ever-more elaborate countermeasures and response plans. The country has built many tsunami walls of up to high to protect populated coastal areas. Other localities have built floodgates of up to high and channels to redirect the water from an incoming tsunami. However, their effectiveness has been questioned, as tsunami often overtop the barriers.\n\nThe Fukushima Daiichi nuclear disaster was directly triggered by the 2011 Tōhoku earthquake and tsunami, when waves exceeded the height of the plant's sea wall. Iwate Prefecture, which is an area at high risk from tsunami, had tsunami barriers walls (Taro sea wall) totalling long at coastal towns. The 2011 tsunami toppled more than 50% of the walls and caused catastrophic damage.\n\nThe which struck Okushiri Island of Hokkaidō within two to five minutes of the earthquake on July 12, 1993, created waves as much as tall—as high as a 10-storey building. The port town of Aonae was completely surrounded by a tsunami wall, but the waves washed right over the wall and destroyed all the wood-framed structures in the area. The wall may have succeeded in slowing down and moderating the height of the tsunami, but it did not prevent major destruction and loss of life.\n\n\n\n"}
{"id": "11657097", "url": "https://en.wikipedia.org/wiki?curid=11657097", "title": "WiTricity", "text": "WiTricity\n\nWiTricity is an American engineering company that manufactures devices for wireless energy transfer using resonant energy transfer based on oscillating magnetic fields.\n\nThe term WiTricity was used for a project that took place at MIT, led by Marin Soljačić in 2006. The MIT researchers successfully demonstrated the ability to power a 60 watt light bulb wirelessly, using two 5-turn copper coils of 60 cm (24 in) diameter, that were 2 m (7 ft) away, at roughly 45% efficiency. The coils were designed to resonate together at 9.9 MHz (wavelength ≈ 30 m) and were oriented along the same axis. One was connected inductively to a power source, and the other one to a bulb. The setup powered the bulb on, even when the direct line of sight was blocked using a wooden panel. Researchers were able to power a 60 watt light bulb at roughly 90% efficiency at a distance of 3 feet. The research project was spun off into a private company, also called WiTricity.\n\nThe emerging technology was demonstrated in July 2009 by CEO Eric Giler at the TED Global Conference held in Oxford. There he refers to the original idea, first applied by the physicist Nikola Tesla between his coils, and shows a WiTricity power unit powering a television as well as three different cell phones, the initial problem that inspired Soljacic to get involved with the project.\n\nAutomobile manufacturer Toyota made an investment in WiTricity in April 2011.\n\nIn September 2012, the company announced it would make a $1000 demonstration kit available to interested parties, to promote development of commercial applications.\n\nCEO Alex Gruzen was hired in 2014, and decided to take WiTricity out of the competition for powering consumer electronics, and focus on wireless power for vehicles. The company nonetheless demonstrated wireless power for a Dell laptop at the January, 2017 Consumer Electronics Show, which became commercially available in 2017. The company has reportedly collaborated with car makers Audi, BMW, Chrysler, Jaguar, Nissan, and Toyota. In 2017, having raised $68 million to date and facing competition from the wireless vehicle standard Halo (developed by Qualcomm), the company reduced its workforce from 80 to 55, and closed an office in Austin, Texas.\n\n\n"}
{"id": "5934618", "url": "https://en.wikipedia.org/wiki?curid=5934618", "title": "World Population Day", "text": "World Population Day\n\nWorld Population day is an annual event, observed on July 11 every year, which seeks to raise awareness of global population issues. The event was established by the Governing Council of the United Nations Development Programme in 1989. It was inspired by the public interest in Five Billion Day on July 11, 1987, the approximate date on which the world's population reached five billion people. World Population Day aims to increase people's awareness on various population issues such as the importance of family planning, gender equality, poverty, maternal health and human rights.\n\nThe day was suggested by Dr KC Zachariah in which population reaches Five Billion when he worked as Sr Demographer at World Bank.\n\nWhile press interest and general awareness in the global population surges only at the increments of whole billions of people, the world population increases annually by 100 million approximately every 14 months. The world population reached 7,400,000,000 on February 6, 2016; the world population had reached 7,500,000,000 at around 16:21 on April 24, 2017.\n\n\n"}
