{"id": "10855624", "url": "https://en.wikipedia.org/wiki?curid=10855624", "title": "Amihan (mythology)", "text": "Amihan (mythology)\n\nAmihan is a genderless deity that is depicted as a bird in the Philippine mythology. According to the Tagalog folklore, Amihan is the first creature to inhabit the universe, along with the gods called Bathala and Aman Sinaya. In the legend Amihan is described as a bird who saves the first human beings, Malakas and Maganda from a bamboo plant. Amihan is also a word used to describe monsoon weather which occurs early in the year in the Philippines.\n"}
{"id": "27295752", "url": "https://en.wikipedia.org/wiki?curid=27295752", "title": "Andrew Lack", "text": "Andrew Lack\n\nDr Andrew John Lack (born 1953) is an English biologist and author, specializing in botany and based at Oxford Brookes University.\n\nAndrew Lack is the son of the ornithologist David Lack (1910–1973). He was educated at the Dragon School, Oxford and Bryanston School, Dorset. He studied for an undergraduate degree in botany at Aberdeen University and obtained his doctorate, also in botany, from the University of Cambridge.\n\nLack was a lecturer at Swansea University for seven years. In 1987, he became a lecturer in biology at Oxford Brookes University where he contributed to modules taught on the Environmental Biology degree, along with contemporaries such as Denis Owen.\n\nAndrew Lack's research is in the area of plant reproductive ecology and genetics, especially pollination, tropical rain forest ecology, and the history and philosophy of the interaction of humans with the environment.\n\nIn 2008, Lack published the book \"Redbreast: The Robin in Life and Literature\", a literary collection based on the robin. This was an updated version of a book published by his father, David Lack.\n\nAndrew Lack is married, has four children, and lives in Oxford. He leads the Isis Chamber Orchestra.\n\nLack has written the following books:\n\n\nHe has contributed to:\n\n\n"}
{"id": "29593616", "url": "https://en.wikipedia.org/wiki?curid=29593616", "title": "Arctic front", "text": "Arctic front\n\nThe Arctic front is the semipermanent, semi-continuous weather front between the cold arctic air mass and the warmer air of the polar cell. It can also be defined as the southern boundary of the Arctic air mass. Mesoscale cyclones known as polar lows can form along the arctic front in the wake of extratropical cyclones. Arctic air masses in their wake are shallow with a deep layer of stable air above the shallow cold cool.\n\nArctic Fronts form in the Arctic region, and move southwards in southerly flows. When they reach Northern Europe, they have usually travelled over an open sea, and convective cloudiness has developed. The appearance of an Arctic Cold Fronts is then, essentially, that of a shallow Cold Front.\n\nArctic Cold Fronts are usually so far north that Meteosat images alone are inadequate to recognize them. Also, the following conceptual models may look like Arctic Cold Fronts: polar Cold Front, Polar Low and Comma. The final check is best made using a loop of AVHRR images with the help of numerical model parameter fields.\n\nArctic Cold Fronts can be classified into two types:\nThese fronts resemble polar cold fronts, but are usually not so extensive. The frontal cloudiness becomes more convective with time.\nThese fronts form over the ice/sea boundary and move southwards with the basic flow. There is only an isolated Cold Front. Often this type is so shallow and weak that it can not be detected in Meteosat water vapour images.\n\n"}
{"id": "3769515", "url": "https://en.wikipedia.org/wiki?curid=3769515", "title": "Audra State Park", "text": "Audra State Park\n\nAudra State Park is a West Virginia state park located on in southwestern Barbour County. It was established around the remnants of an early 19th-century gristmill and the tiny community of Audra. A gristmill spillway is still visible in the river. \n\nThe park is a hilly, secondary forest area bisected by the Middle Fork River. The deep pools, large, flat rocks, and riverside beach have provided generations of campers, local teens and college students a place to swim or work on their tans. Audra State Park is the site of Alum Cave, which is accessible by a boardwalk built along this overhanging sandstone ledge. \n\nThe park serves as the put-in point for a 6.6 mile kayak run along about 2.8 miles the Middle Fork River and about 3.8 miles of the Tygart Valley River to the confluence of the latter with the Buckhannon River.\n\n\nAccessibility for the disabled was assessed by West Virginia University. The assessment found the campground, picnic area, and park offices to be accessible. The main swimming hole (just below the site of the former gristmill), with wet, slippery rocks and unpaved approaches is not considered accessible.\n\n"}
{"id": "9581618", "url": "https://en.wikipedia.org/wiki?curid=9581618", "title": "Bahia interior forests", "text": "Bahia interior forests\n\nThe Bahia interior forests is an ecoregion of eastern Brazil. It is part of the larger Atlantic forests biome complex, and lies between the Bahia coastal forests and the dry shrublands and savannas of Brazil's interior.\n\nThe Bahia interior forests cover an area of , extending across portions of Bahia, Espirito Santo, Minas Gerais, Rio de Janeiro, and Sergipe states. The Bahia interior forests lie inland from the Bahia coastal forests, which extend approximately inland from the coast. The Bahia interior forests extend north to the São Francisco River, where they lie much closer to the coast, and are bounded on the west by the dry Caatinga shrublands. Moving south, the forests extend further inland to the Rio Paraíba do Sul, Rio Preto, and Rio Grande, which form the boundary with the Paraná-Paraíba interior forests to the southwest.\n\nAtlantic forest in Minas Gerais, interior Bahia and southern Espírito Santo, according to IBGE, consists of a semi-deciduous or deciduous forest. In this ecoregion is found a highly threatened spicies, the \"Brazilian rosewood\" \"(Dalbergia nigra)\".\n\nThis ecoregion is poorly known. Recently, a new primate species was described, the Coimbra Filho's titi, and other primate, the Northern muriqui is endemic of Bahia interior forests ecoregion.\n\nBahia interior forest is one of the most modified ecoregions in Atlantic forest region. Most forests remnants has less than 10 km², and even these are currently under strong pressure from anthropogenic activities, as fires, illegal deforestation and predatory hunting. Less than 2 percent of Bahia interior forests are protected as conservation units. The largest forest remnant of this ecoregion is the Rio Doce State Park, with 359 km² of area.\n"}
{"id": "37194531", "url": "https://en.wikipedia.org/wiki?curid=37194531", "title": "Ben Carlin", "text": "Ben Carlin\n\nFrederick Benjamin \"Ben\" Carlin (27 July 1912 – 7 March 1981) was an Australian adventurer who was the first and only person to circumnavigate the world in an amphibious vehicle. Born in Northam, Western Australia, Carlin attended Guildford Grammar School in Perth, and later studied mining engineering at the Kalgoorlie School of Mines. After qualifying as an engineer, he worked on the Goldfields before in 1939 emigrating to China to work in a British coal mine. In the Second World War, Carlin was posted to the Indian Army Corps of Engineers, serving in India, Italy, and throughout the Middle East. After his discharge from service in 1946, he emigrated to the United States with his American wife, Elinore (née Arone).\n\nSparked by an idea he had had whilst in the military, Carlin proposed that the couple honeymoon by crossing the Atlantic Ocean in a modified Ford GPA (an amphibious version of the Ford GPW Jeep), which they named the \"Half-Safe\". Beginning their trip in Montreal, Quebec, Canada, the Carlins finally completed the transatlantic crossing in 1951, after unsuccessful attempts. From there, they travelled to Europe, temporarily settling in Birmingham to raise more money. They resumed their journey in 1954, travelling overland through the Middle East before arriving in Calcutta. After a short fundraising trip to Australia, Carlin's wife left to return to the United States. He resumed the journey with new partners, travelling through South-East Asia and the Far East to the northern tip of Japan, and then to Alaska. After an extended tour through the United States and Canada, he and \"Half-Safe\" finally returned to Montreal, having travelled over by sea and by land during a ten-year journey. Following Carlin's death in 1981, \"Half-Safe\" was acquired by Guildford Grammar, his old school, where it remains on display.\n\nFrederick Benjamin Carlin was born on 27 July 1912 in Northam, Western Australia, a small town in the state's Wheatbelt. His mother, the former Charlotte Amelia Bramwell, died when he was four, and he was raised by his father, Frederick Cecil Carlin, who was an electrical engineer employed with the Western Australian Government Railways. At the age of ten, Carlin was sent to board at Guildford Grammar School in Perth. Leaving school in 1929, he enrolled at the School of Mines in Kalgoorlie, where he studied mining engineering. Once he had qualified as an engineer, he worked for a period of time in the surrounding Goldfields region. However, in 1939, he moved to Peking, China, to work for a British coal mining company.\n\nUpon the outbreak of the Second World War, Carlin enlisted in the Indian Army. Before leaving for India, he married Gertrude Plath, a German citizen who had been living in China with her aunt and uncle. The couple wed on 20 April 1940, at Tientsin, although they separated before the end of the war. Having originally enlisted at Shanghai, Carlin was later posted to the Madras Sappers in the Indian Army Corps of Engineers. In August 1941, he was promoted to the position of second lieutenant, as part of a number of \"emergency commissions\" made at the start of the conflict. During the war, Carlin served in India, Iraq, Persia, Palestine, Syria, and Italy, and by the conflict's end had been promoted to the rank of major. Towards the end of the war, he met an American Red Cross nurse, Elinore Arone, who was originally from Boston. On his discharge from service in 1946, the couple emigrated to Maryland, where they eventually married, in June 1948.\n\nThroughout the war, the Allies had made use of a number of different varieties of amphibious vehicle. One of the more commonly used was the Ford GPA, a modified version of the Ford GPW Jeep (also known as a \"Seep\"). In India towards the end of the war, Carlin had noticed a GPA in an army vehicle lot. To the mockery of his fellow engineers, he suggested that the vehicle could be used to take him around the world, supposedly remarking: \"with a bit of titivation, you could go around the world in one of those things\". This idea remained with Carlin after his marriage, and he proposed to his wife that the couple honeymoon by crossing the Atlantic Ocean in a modified GPA. After a considerable amount of trouble, the Carlins finally managed to purchase a 1942 Ford GPA (serial number 1239) from a government auction in Washington, D.C., for US$901 ($9500 in 2018 dollars). The vehicle had originally been manufactured at Ford's plant in River Rouge, Michigan, one of 12,778 built during the war. He originally tried to convince Ford to sponsor his proposed trip, but the company refused, believing the craft would not make the journey. The vehicle required a number of modifications to make it seaworthy, including the addition of a more boat-like bow, a rudder, a larger cabin, and two extra fuel tanks – one at the bow and one under the \"belly\" of the craft, at the stern. Inside the cabin, a bunk was installed, and the dash was modified to include aircraft instruments, as well as a two-way radio (including a 19-set transmitter and receiver). In total, the vessel's length was extended by three feet to , and the fuel capacity to 200 gallons (760 L) from the original 12 gallons (45 L). The construction of the under-belly fuel tank allowed it to be jettisoned when empty, reducing further its full weight of three tons (6,720 lb or 3,048 kg). The vessel was christened \"Half-Safe\", after the slogan of Arrid, a deodorant brand – \"Don't be half-safe – use Arrid to be sure\".\n\nThe couple began testing their craft in 1947, and experienced problems with carbon monoxide removal, with the vessel's enclosed structure potentially increasing the risks of carbon monoxide poisoning. The Carlins chose Montreal, Quebec, Canada, as the official starting point of their circumnavigation attempt. They set out from the city in late 1947 for New York City, where they were to launch \"Half-Safe\" for the first time, with the intention of crossing the Atlantic via the Azores. A trial run was made in early January 1948, watched by \"crowds of sceptical waterside workers\". The couple's first attempt to complete the transatlantic crossing occurred on 16 June 1948, launching from New York Harbor. Cheered on by \"100 amazed wharf labourers\", they were first washed up-river by a strong tide, but then made their way out into the Atlantic at a speed of five knots. The Carlins failed to maintain radio contact, prompting a search by the United States Coast Guard. The craft was eventually landed five days after its departure, south of New York City near the Shark River inlet in New Jersey. The couple had experienced problems with the steering gear and rudder, which made the vessel unable to steer at sea unless the wheel was constantly manned. With \"Half-Safe\" sailed back to New York, the Carlins commenced their journey for a second time on 3 July, but were once again forced back to shore a few days later, this time after nearly being asphyxiated due to a cracked exhaust pipe.\n\nA third attempt was made in late July, but was again not successful due to the mechanical troubles and heavy seasickness the Carlins experienced. The Carlins set out for a fourth time in early August, and progressed further, being sighted several days after their launch by an American destroyer almost off of New York. However, the couple soon lost radio contact, prompting Pan-American Airways to direct their crews to search for their craft. \"Half-Safe\" and the Carlins were finally rescued approximately off New York by the oil tanker \"New Jersey\", bound for Halifax, Nova Scotia. Seven days into the voyage, a propeller bearing had welded itself fast due to lack of lubrication, leaving the vessel to drift aimlessly for a further ten days without means of steering it or navigating. According to a message Carlin radioed from the tanker to his friends in New York, the couple \"drifted and fished\", enjoying a \"pleasant life, cheaper than Atlantic City\". At the time of the couple's rescue, he considered abandoning the entire voyage, but was convinced to continue by the tanker's Norwegian captain, who greeted Carlin with the words: \"Hell, you're not going to leave that god-damned Jeep lying around?!\"\n\nThe Carlins' fourth failed attempt in two months led them to abandon the project for a period of time in order to raise more money. With the \"New Jersey\" arriving in Halifax two weeks after their rescue, Carlin took up a position with a local marine salvage firm, while his wife returned to her family in Boston, and worked in a law office. One final attempt was considered in November 1948, but postponed due to the approaching winter weather, with \"Half-Safe\" stored in a Halifax garage. In mid 1949, the couple began to ready \"Half-Safe\" for a further attempt at the crossing. Testing in late August revealed a burnt-out clutch, which was repaired, and Carlin recognised the need for much larger amounts of fuel. To achieve this extra capacity, two fuel tanks were tied behind \"Half-Safe\", painted bright yellow to aid visibility from the air. Further alterations were also made to the craft's superstructure, and extra stabilising rudders were added. The Carlins launched again in early September 1949. When the vessel was off shore, both of the auxiliary fuel tanks were lost, necessitating return to Halifax. Carlin almost decided to abandon the journey and liquidate \"Half-Safe\", but was convinced by his wife to continue.\n\nOver the following six months, the Carlins again made modifications to their vessel, with the most important being a large, purpose-built tank that was to be towed behind the craft. This increased the total fuel capacity of \"Half-Safe\" to 735 gallons (3,337 L), with the vessel also carrying 30 gallons (136 L) of water, eight gallons (36 L) of oil, and six weeks' worth of provisions. The couple left Halifax on 19 July 1950, and, after a 32-day voyage, arrived on Flores, the most westerly island of the Azores. Their landing was well-received, with \"LIFE\" featuring the crossing in a multiple-page article later that year, which also featured many of the Carlins' photographs. However, the journey had not occurred without mishap – Carlin was forced to remove the cylinder head several times in order to clean the carbon from the valves and replace the head gasket, and the couple lost radio contact halfway through the voyage, leading to fears they had been lost at sea. From Flores, the couple progressed to Horta on the island of Faial, a distance of . They then travelled to Madeira, having obtained surplus fuel from a passing Portuguese cruiser midway through the trip. Although originally expected to head directly to Lisbon, Portugal, from Madeira, the couple instead chose to head for Morocco via the Canary Islands, coming ashore at Cap Juby in the Spanish territory of Rio de Oro on 23 February 1951.\n\nFrom Cap Juby, the Carlins drove north through the coastal regions of Morocco to Europe. The hot daytime temperatures, which reportedly reached within the vehicle's cabin, necessitated that \"Half-Safe\" be driven exclusively at night. The vehicle reached Casablanca, French Morocco, on 16 March 1951, and the British territory of Gibraltar in mid April, after it was sailed across the Straits of Gibraltar. From there, the Carlins drove through a number of European countries, where they engaged in sight-seeing, before finally sailing across the English Channel and concluding the first part of their journey in Birmingham, where they arrived on 1 January 1952.\n\nTired, weary, and lacking in money, the Carlins decided to remain in England to rest and recuperate. Throughout the journey from Nova Scotia to the Azores, both Carlin and his wife had suffered from severe hallucinations, including one instance where he had jerked awake to find himself 60° off course. Another important objective of their time in Britain was to repair \"Half-Safe\", which had sustained large amounts of damage during the crossing, not least from Hurricane Charlie, which battered the vessel whilst it was amongst the islands of Macaronesia. The repairs to the craft were accomplished with the help of RAF Group Captain Malcolm Bunting, who had served alongside Carlin in India. To raise money for the continuation of the journey, \"Half-Safe\" was exhibited in department stores throughout Europe. During this time, Carlin also completed \"Half Safe: Across the Atlantic by Jeep\", a book chronicling the first half of their journey, which sold 32,000 copies and was translated into five languages. The book was generally well received, with a reviewer in \"The Montreal Gazette\" describing Carlin as \"an adventurer of the old school – full of the explorer's instinct, and with a dry wit that makes his story an odd mixture of high-adventure and real understatement\".\n\nThe Carlins set out again in early 1955, arriving in France on 22 April 1955. The vehicle continued through Switzerland, northern Italy, and Yugoslavia, where in May 1955, it was reported that \"Half-Safe\" had had its first flat tire, whilst travelling through Belgrade. The Carlins then continued through Greece and Turkey, sailing across the Bosphorus to Asia Minor, before progressing through Syria, Jordan, Iraq, Iran, and Pakistan to Calcutta, India. Carlin later noted: \"the 2000 miles across the Atlantic from Nova Scotia to the Azores were in many ways much less worrying than a similar distance covered on murderous roads in Persia\". At Calcutta, the Carlins decided to transport \"Half-Safe\" to Australia via steamer. At the start of his voyage, Carlin had said he would not travel to Australia or New Zealand, because petrol was \"too dear\" there. However, a lack of funding meant the side trip was necessary. The trip also allowed Carlin to meet with his family, who still lived in Perth – his brother, Tom Carlin, had become a captain in the Royal Australian Navy, and was actively involved in nuclear weapons testing on the Montebello Islands in 1952, as part of Operation Hurricane.\n\n\"Half-Safe\"<nowiki>'</nowiki>s Australian tour began in late October 1955 in Perth, where Carlin grew up, and included a tour of his old school, Guildford Grammar. The Carlins then went to Adelaide, and subsequently progressed to Melbourne, Sydney, and Brisbane. \"Half-Safe\" was returned to Calcutta on a steamship in January 1956. However, Elinore, Carlin's wife, left the trip in Australia, having finally tired of the long travel and the constant seasickness she was experiencing. Carlin continued his journey alone, with the first leg consisting of a sea voyage from Calcutta to Akyab, Burma, across the Bay of Bengal. At Akyab, he was joined by Barry Hanley, another Australian. The two met on Burma's coast in late February 1956, and from there crossed the Arakan Yoma mountain ranges to the Irrawaddy River, where the vehicle was bogged down in mud for two days. After extricating \"Half-Safe\" from the mire, the pair progressed to Rangoon, arriving on 11 March. From Burma, \"Half-Safe\" was driven overland to Bangkok, Thailand, and from there to Saigon, on the coast of Indochina. From there, Carlin and Hanley set out to sail from Indochina to Japan, passing through several ports and islands in the South China Sea. Upon his arrival in Hong Kong in early May 1956, Carlin was \"mobbed by autograph-seeking girls\", having been delayed on his voyage by engine trouble and headwinds in the South China Sea. He arrived in Kaohsiung, Taiwan, in early June, and from there travelled to Keelung on the northern tip of Taiwan, and Okinawa, part of the American-administered Ryukyu Islands. Carlin and Hanley drove ashore at Kagoshima Prefecture at the southern tip of Japan in July 1956, and from there drove overland to Tokyo. Hanley returned to Australia at this stage, while Carlin rested in Japan, again performing much-needed repairs. An American journalist for \"The Japan Times\", Boyé Lafayette de Mente (originally of Phoenix, Arizona), offered to accompany Carlin on the journey from Japan to Alaska, departing in early 1957 for the first stage of the trip from Tokyo to Wakkanai, Hokkaidō. The pair left Tokyo on 1 May 1957 to great fanfare, cheered off from the Mainichi and Yomiuri Newspaper buildings. The craft sprang a leak while crossing the Tsugaru Strait, separating the southern island of Honshu from Hokkaidō, and collided with submerged rocks near the port of Muroran. They finally reached Wakkanai on 12 June 1957, despite what de Mente later described as Carlin's aggression and \"irascible character\" during the trip.\n\nCarlin's aim was to travel directly from Wakkanai to Shemya, a small island in the Near Islands group of the Semichi Islands chain, part of the Aleutian Islands running southwest of the Alaskan mainland. The craft was carrying enough fuel to last for approximately 21 days, but did not make contact within this time, causing the US Coast Guard's search and rescue station to be notified. \"Half-Safe\" finally landed on Shemya on 8 July, with the pair having made an unexpected detour to visit the town of Petropavlovsk on the Kamchatka Peninsula, at the time part of the Russian SFSR. From Shemya, Carlin and de Mente sailed to Adak Island, a distance of , then a further to Cold Bay, and thence along the Aleutian island chain to the mainland town of Homer, arriving in late August. Carlin and de Mente then drove \"Half-Safe\" overland to Anchorage, where de Mente flew home to Phoenix. He would go on to write \"Once a Fool: From Tokyo to Alaska by Amphibious Jeep\", a detailed account of his experiences with Carlin and \"Half-Safe\", as well as becoming a prolific author on topics relating to Mesoamerica and East Asia, publishing over 100 books. Carlin subsequently drove solo to Seattle, Washington, arriving in early November 1957. Whilst travelling the Alaska Highway in British Columbia, he encountered the collapsed Peace River Suspension Bridge. While other motorists queued for a nearby ferry, Carlin simply drove \"Half-Safe\" into the river and across to the other side. Continuing on to San Francisco, California, where he met his wife for the first time in two years, Carlin then continued onwards through the United States and north to Canada. He arrived in Toronto, Ontario, on 10 May 1958, and three days later arrived in Montreal, where he finally completed his ten-year journey. He and \"Half-Safe\" had travelled by sea and by land over ten years, passing through 38 countries and over two oceans, with the entire trip costing him around $35,000.\n\nAfter the conclusion of the trip, \"Half-Safe\" remained in the United States, where it was occasionally exhibited by Carlin's friend George Calimer, who was a co-owner of the vehicle. Carlin remained in the country for a period, appearing on the lecture circuit, before returning to Perth, where he took up residence in Cottesloe. Having divorced his second wife Elinore by December 1955, Carlin wed for a third time on 1 June 1963 in the United States, marrying Cynthia Henderson. Although the couple's marriage was short-lived, the union produced one daughter, Deirdre Scott Carlin, who was born in March 1964. Carlin died in Perth in March 1981, of a heart attack, and was cremated at Karrakatta Cemetery. His second wife, Elinore, who completed the first half of his journey alongside him, died in 1996 in New York City. Carlin left his share in \"Half-Safe\" to his old school, Guildford Grammar, as well as a sizeable endowment for the purposes of funding a scholarship. He had previously offered the craft to the Western Australian Maritime Museum, which declined the offer due to a lack of exhibition space. The Guildford Grammar School Foundation subsequently purchased the other share in the vehicle, transferring it to the school's campus in Guildford, Western Australia. The school also posthumously published \"The Other Half of Half-Safe\", which detailed the second portion of Carlin's journey. In 1999, the craft was transported by truck across Australia to Corowa, New South Wales, where it featured in an annual celebration on the Murray River, along with 16 other amphibious vehicles from the Second World War. \"Half-Safe\" is currently exhibited in a specially-made glass enclosure at Guildford Grammar's main campus. Money from Carlin's estate was used to found the Charlotte Carlin Scholarship (named for his mother), awarded for \"the proficiency of the English language with the avoidance of clichés\". Guinness World Records recognises Carlin as having completed the \"first and only circumnavigation by an amphibious vehicle\".\n\n"}
{"id": "44255367", "url": "https://en.wikipedia.org/wiki?curid=44255367", "title": "Biofuel in Turkey", "text": "Biofuel in Turkey\n\nThere is a high biogas potential in Turkey.\nMore than eighty five million tons of animal waste produced annually could produce over 1.8 million tons of oil equivalent (toe) and with plant waste included the potential raises to over 5.3 million tons of oil equivalent (toe). However, only 85 biogas facilities with 36 plants are currently in operation.\n\n80 MW of landfill power is in operation while 78 MW is under construction.\n\nA biodiesel plant is planned.\n\nSugar beets are the main source of bioethanol production in Turkey, followed by corn and wheat.\n\n"}
{"id": "43064767", "url": "https://en.wikipedia.org/wiki?curid=43064767", "title": "C/2013 V5", "text": "C/2013 V5\n\nC/2013 V5 (Oukaimeden) is a retrograde Oort cloud comet discovered on 12 November 2013 by Oukaimeden Observatory at an apparent magnitude of 19.4 using a reflecting telescope.\n\nFrom 5 May 2014 until 18 July 2014 it had an elongation less than 30 degrees from the Sun. By late August 2014 it had brighten to apparent magnitude 8 making it a small telescope and high-end binoculars target for experienced observers. It crossed the celestial equator on 30 August 2014 becoming a southern hemisphere object. On 16 September 2014 the comet passed from Earth. The comet peaked around magnitude 6.2 in mid-September 2014 but only had an elongation of about 35 degrees from the Sun. On 20 September 2014 the comet was visible in STEREO HI-1B. The comet came to perihelion (closest approach to the Sun) on 28 September 2014 at a distance of from the Sun.\n\nC/2013 V5 is dynamically new. It came from the Oort cloud with a loosely bound chaotic orbit that was easily perturbed by galactic tides and passing stars. Before entering the planetary region (epoch 1950), C/2013 V5 had an orbital period of several million years. After leaving the planetary region (epoch 2050), it will have an orbital period of about 6000 years.\n\n"}
{"id": "5531030", "url": "https://en.wikipedia.org/wiki?curid=5531030", "title": "Charles Bowden", "text": "Charles Bowden\n\nCharles Clyde Bowden (July 20, 1945 – August 30, 2014) was an American non-fiction author, journalist and essayist based in Las Cruces, New Mexico.\n\nHe attended the University of Arizona and then the University of Wisconsin, where he obtained his master's degree in American intellectual history; while there he walked out as he was defending his dissertation for his doctorate, annoyed by the questions asked him by the review committee. He was a writer for the \"Tucson Citizen\" and often wrote about the American Southwest. He was a contributing editor of \"GQ\" and \"Mother Jones\" magazine, and wrote for other periodicals including \"Harper's Magazine\", \"The New York Times Book Review\", \"Esquire\", \"High Country News\", and \"Aperture\".\n\nBowden was the winner of the 1996 Lannan Literary Award for Nonfiction, and a 2010 award from United States Artists. He grew up in Chicago but lived most of his life in Tucson, Arizona. He was known for his writings on the situation at the US–Mexico border and wrote often about the effects of the War on Drugs on the lives of the people in that region.\n\nHe died in Las Cruces, New Mexico, on August 30, 2014, after a brief illness. He was survived by his son and two siblings.\n\n\n\n"}
{"id": "23663251", "url": "https://en.wikipedia.org/wiki?curid=23663251", "title": "Dewbow", "text": "Dewbow\n\nA dewbow is an optical effect, similar to a rainbow, where dewdrops instead of rain droplets reflect and disperse sunlight.\n\nDewbows can be seen on fields covered with dew, when the sun shines. Dew forms outdoors in the early morning after a clear night, when the surface temperature drops below the dew point. It forms most easily on surfaces that are isolated from conducted heat from deep ground, such as grass, leaves, and spider webs. Dew bows will be clearest on fields littered with cobwebs, as may occur in autumn. \n\nA \"rainbow\" is perceived as a circle in the sky; and its contributing light rays form a cone. In contrast, a \"dewbow\" is perceived as the intersection of that cone and the ground. If the ground is flat and horizontal, and the sun is low in the sky, the dew bow is a hyperbola. Theoretically, when the sun is high, the intersection might be another conic section, like a parabola or an ellipse. However, dew usually evaporates before the sun is high. Nonetheless, an elliptical dew bow was captured on camera, when at night the full moon, high in the sky, illuminated a field loaded with dew.\n\n"}
{"id": "1413965", "url": "https://en.wikipedia.org/wiki?curid=1413965", "title": "Energy transformation", "text": "Energy transformation\n\nEnergy transformation, also termed as energy conversion, is the process of changing energy from one of its forms into another. In physics, energy is a quantity that provides the capacity to perform many works—think of lifting or warming an object. In addition to being convertible, energy is transferable to a different location or object, but it cannot be created or destroyed.\n\nEnergy in many of its forms may be used in natural processes, or to provide some service to society such as heating, refrigeration, lighting or performing mechanical work to operate machines. For example, in order to heat your home, your furnace can burn fuel, whose chemical potential energy is thus converted into thermal energy, which is then transferred to your home's air in order to raise its temperature.\n\nIn another example, an internal combustion engine burns gasoline to create pressure that pushes the pistons, thus performing work in order to accelerate your vehicle, ultimately converting the fuel's chemical energy to your vehicle's additional kinetic energy corresponding to its increase in speed.\n\nConversions to thermal energy (thus raising the temperature) from other forms of energy, may occur with essentially 100% efficiency (many types %, such as when potential energy is converted to kinetic energy as an object falls in vacuum, or when an object orbits nearer or farther from another object, in space.\n\nThough, conversion of thermal energy to other forms, thus reducing the temperature of a system, has strict limitations, often keeping its efficiency much less than 100% (even when energy is not allowed to escape from the system). This is because thermal energy has already been partly spread out among many available states of a collection of microscopic particles constituting the system, which can have enormous numbers of possible combinations of momentum and position (these combinations are said to form a phase space). In such circumstances, a measure called entropy, or evening-out of energy distributions, dictates that future states of an isolated system must be of at least equal evenness in energy distribution. In other words, there is no way to \"concentrate\" energy without spreading out energy somewhere else.\n\nThermal energy in equilibrium at a given temperature already represents the maximal evening-out of energy between all possible states. Such energy is sometimes considered \"degraded energy,\" because it is not entirely convertible a \"useful\" form, i.e. one that can do more than just affect temperature. The second law of thermodynamics is a way of stating that, for this reason, thermal energy in a system may be converted to other kinds of energy with efficiencies approaching 100%, only if the entropy (even-ness or disorder) of the universe is increased by other means, to compensate for the decrease in entropy associated with the disappearance of the thermal energy and its entropy content. Otherwise, only a part of thermal energy may be converted to other kinds of energy (and thus, useful work), since the remainder of the heat must be reserved to be transferred to a thermal reservoir at a lower temperature, in such a way that the increase in Entropy for this process more than compensates for the entropy decrease associated with transformation of the rest of the heat into other types of energy... \nExamples\n\nIn order to make energy transformation more efficient, it is desirable to avoid thermal conversion. For example, the efficiency of nuclear energy reactors, where the kinetic energy of the nuclei is first converted to thermal energy and then to electric energy, lies around 35%. By direct conversion of kinetic energy to electric energy, i.e. by eliminating the intermediate thermal energy transformation, the efficiency of the energy transformation process can be dramatically improved.\n\nEnergy transformations in the universe over time are (generally) characterized by various kinds of energy which have been available since the Big Bang, later being \"released\" (that is, transformed to more active types of energy such as kinetic or radiant energy), when a triggering mechanism is available to do it.\n\nRelease of energy from gravitational potential: A direct transformation of energy occurs when hydrogen produced in the Big Bang collects into structures such as planets, in a process during which part of the gravitational potential is to be converted directly into heat. In Jupiter, Saturn, and Neptune, for example, such heat from continued collapse of the planets' large gas atmospheres continues to drive most of the planets' weather systems, with atmospheric bands, winds, and powerful storms which are only partly powered by sunlight, however, on Uranus, little of this process occurs.\n\nOn Earth, a significant portion of the heat output from the interior of the planet, estimated at a third to half of the total, is caused by the slow collapse of planetary materials to a smaller size, with the output of gravitationally driven heat.\n\nRelease of energy from radioactive potential: Familiar examples of other such processes transforming energy from the Big Bang include nuclear decay, which releases energy that was originally \"stored\" in heavy isotopes, such as uranium and thorium. This energy was stored at the time of the nucleosynthesis of these elements, a process which ultimately uses the gravitational potential energy released from the gravitational collapse of Type II supernovae, to store energy in the creation of these heavy elements before they were incorporated into the Solar System and the Earth. Such energy locked into uranium is triggered for sudden-release in nuclear fission bombs, and similar stored energies in atomic nuclei are released spontaneously, during most types of radioactive decay. In such processes, heat from decay of these atoms of radioisotope in the core of the Earth is transformed immediately to heat. This heat in turn may lift mountains, via plate tectonics and orogenesis. This slow lifting of terrain thus represents a kind of gravitational potential energy storage of the heat energy. The stored potential energy may be released to active kinetic energy in landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a kind of mechanical potential energy which has been produced ultimately from the same radioactive heat sources.\n\nThus, according to present understanding, familiar events such as landslides and earthquakes release energy which has been stored as potential energy in the Earth's gravitational field, or elastic strain (mechanical potential energy) in rocks. Prior to this, the energy represented by these events had been stored in heavy atoms (or in the gravitational potential of the Earth). The energy stored in heat atoms had been stored as potential ever since the time that gravitational potentials transforming energy in the collapse of long-destroyed stars (supernovae) created these atoms, and in doing so, stored the energy within.\n\nRelease of energy from hydrogen fusion potential: In a similar chain of transformations beginning at the dawn of the universe, nuclear fusion of hydrogen in the Sun releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This resulted in hydrogen representing a store of potential energy which can be released by nuclear fusion. Such a fusion process is triggered by heat and pressure generated from the gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight. Such sunlight may again be stored as gravitational potential energy after it strikes the Earth, as (for example) snow-avalanches, or when water evaporates from oceans and is deposited high above sea level (where, after being released at a hydroelectric dam, it can be used to drive turbine/generators to produce electricity). Sunlight also drives many weather phenomena on Earth. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, give up some of their thermal energy suddenly to power a few days of violent air movement. Sunlight is also captured by green plants as \"chemical potential energy\", when carbon dioxide and water are converted into a combustible combination of carbohydrates, lipids, and oxygen. Release of this energy as heat and light may be triggered suddenly by a spark, in a forest fire; or it may be available more slowly for animal or human metabolism, when these molecules are ingested, and catabolism is triggered by enzyme action.\n\nThrough all of these transformation chains, potential energy stored at the time of the Big Bang is later released by intermediate events, sometimes being stored in a number of different ways for long periods of time between releases, as more active energy. All of these events involve the conversion of one kind of energy into others, including heat.\n\nFor instance, a coal-fired power plant involves these energy transformations:\nIn such a system, the first and fourth step are highly efficient, but the second and third steps are less efficient. The most efficient gas-fired electrical power stations can achieve 50% conversion efficiency. Oil- and coal-fired stations achieve less.\n\nIn a conventional automobile, these energy transformations are involved:\n\nThere are many different machines and transducers that convert one energy form into another. A short list of examples follows:\n\n"}
{"id": "43234", "url": "https://en.wikipedia.org/wiki?curid=43234", "title": "Green flash", "text": "Green flash\n\nGreen flashes and green rays are optical phenomena that sometimes occur just after sunset or right before sunrise. When the conditions are right, a distinct green spot is briefly visible above the upper rim of the Sun's disk; the green appearance usually lasts for no more than a second or two. Rarely, the green flash can resemble a green ray shooting up from the sunset (or sunrise) point.\n\nGreen flashes occur because the Earth's atmosphere can cause the light from the sun to separate out into different colors. Green flashes are a group of similar phenomena which stem from slightly different causes, and therefore some types of green flashes are more common than others.\n\nGreen flashes may be observed from any altitude. They usually are seen at an unobstructed horizon, such as over the ocean, but are possible over cloud tops and mountain tops as well. They may occur at any latitude, although at the equator the flash rarely lasts longer than a second.\n\nA green flash also may be observed in association with the Moon and bright planets at the horizon, including Venus and Jupiter. With an unrestricted view of the horizon, green flashes are regularly seen by airline pilots, particularly when flying westwards as the sunset is slowed. If the atmosphere is layered the green flash may appear as a series of flashes.\n\nWhile observing at the Vatican Observatory in 1960, D.K.J. O'Connell produced the first color photographs of a green flash at sunset.\n\nGreen flashes are enhanced by Mirage of astronomical objects mirage, which increases refraction. A green flash is more likely to be seen in stable, clear air, when more of the light from the setting sun reaches the observer without being scattered. One might expect to see a blue flash, since blue light is refracted most of all, and the blue component of the sun's light is therefore the very last to disappear below the horizon, but the blue is preferentially scattered out of the line of sight, and the remaining light ends up appearing green. \n\nWith slight magnification, a green rim on the top of the solar disk may be seen on most clear-day sunsets, although the flash or ray effects require a stronger layering of the atmosphere and a mirage, which serves to magnify the green from a fraction of a second to a couple of seconds.\n\nThe \"green flash\" description relates to a group of optical phenomena, some of which are listed below:\n\nThe majority of flashes observed are inferior-mirage or mock-mirage effects, with the others constituting only 1% of reports. Some types not listed in the table above, such as the cloud-top flash (seen as the sun sinks into a coastal fog, or at distant cumulus clouds), are not understood.\n\nRarely, the amount of blue light is sufficient to be visible as a \"blue flash\". An explanation for the blue flash has not yet been identified.\n\nAs an astronomical object sets or rises in relation to the horizon, the light it emits travels through Earth's atmosphere, which works as a prism separating the light into different colors. The color of the upper rim of an astronomical object could go from green to blue to violet depending on the decrease in concentration of pollutants, as they spread throughout an increasing volume of atmosphere. The lower rim of an astronomical object is always red.<br>A green rim is very thin and is difficult or impossible to see with the naked eye. In usual conditions, a green rim of an astronomical object gets fainter when an astronomical object is very low above the horizon because of atmospheric reddening, but sometimes the conditions are right to see a green rim just above the horizon. The following quote describes what was probably the longest observation of a green rim, which at times could have been a green flash. It was seen on and off for 35 minutes by members of the Richard Evelyn Byrd party from the Antarctic Little America exploration base in 1934:\n\nFor the explorers to have seen a green rim on and off for 35 minutes there must have been some mirage effect present.\n\nA green rim is present at every sunset but it is too thin to be seen with the naked eye. Often a green rim changes to a green flash and back again during the same sunset. The best time to observe a green rim is about 10 minutes before sunset. That is too early to use any magnification like binoculars or a telescope to look directly at the Sun without potential harm to the eyes. (Of course, a magnified image might be projected onto a sheet of paper for safe viewing.) As the sun gets closer to the horizon, the green rim becomes fainter due to atmospheric reddening. According to the above, it is probably correct to conclude that although a green rim is present during every sunset, a green flash is rarer because of the required mirage.\n\nJules Verne's 1882 novel \"The Green Ray\" helped to popularize the green flash phenomenon. A 1986 film also called \"The Green Ray\" uses the green flash and Verne's book as a plot device. Additionally, the green flash has inspired or been mentioned in:\n\n\n\n\n"}
{"id": "48653964", "url": "https://en.wikipedia.org/wiki?curid=48653964", "title": "Ground heat exchanger", "text": "Ground heat exchanger\n\nGround heat exchangers (GHEs), which are also called geothermal heat exchangers, have emerged as a promising and globally accepted way of exploiting shallow geothermal energy, for example ground-coupled heat pumps, ground heat storage. A GHE is essentially a pipe (e.g., U-, W-, or helical-shaped) in a vertical borehole or a foundation pile of a building, in which a circulating heat-carrying fluid absorbs (or discharges) heat from (or to) the ground.\nGHEs can have various configurations. This article discusses two kinds of closed loop GHEs, i.e., borehole and foundation pile GHEs. The borehole type is the most common. It consists of one or two U-shaped pipes that are inserted into a vertical borehole and connected to a heat pump or a heating system to form a closed loop. A U-shaped channel usually comprises two small-diameter high-density polyethylene (HDPE) tubes thermally fused to form a U-shaped bend at the bottom. The space between the wall of the borehole and the U-shaped tubes is usually grouted completely with grouting material or, in some cases, partially filled with groundwater. The depth of the hole (generally from 30 m to 200 m) depends strongly on local geological conditions and available drilling equipment.\nIn a foundation pile GHE (or energy pile), the heat transfer tubes are inside the steel frame of a foundation pile. There are various possible shapes. Foundation piles are usually much shallower than boreholes and have a greater radius. Since energy piles generally require less land area, this technology is evoking increasing interest in the ground-source heat pumps community.\n\nA huge challenge in predicting the thermal response of a GHE is the diversity of the time and space scales involved.Four space scales and eight time scales are involved in the heat transfer of GHEs. The first space scale having practical importance is the diameter of the borehole (~ 0.1 m) and the associated time is on the order of 1 hr, during which the effect of the heat capacity of the backfilling material is significant. The second important space dimension is the half distance between two adjacent boreholes, which is on the order of several meters. The corresponding time is on the order of a month, during which the thermal interaction between adjacent boreholes is important. The largest space scale can be tens of meters or more, such as the half length of a borehole and the horizontal scale of a GHE cluster. The time scale involved is as long as the lifetime of a GHE (decades).\n\nThe short-term hourly temperature response of the ground is vital for analyzing the energy of ground-source heat pump systems and for their optimum control and operation. By contrast, the long-term response determines the overall feasibility of a system from the standpoint of life cycle. Addressing the complete spectrum of time scales require vast computational resources.\n\nThe main questions that engineers may ask in the early stages of designing a GHE are (a) what the heat transfer rate of a GHE as a function of time is, given a particular temperature difference between the circulating fluid and the ground, and (b) what the temperature difference as a function of time is, given a required heat exchange rate. In the language of heat transfer, the two questions can probably be expressed as\nformula_1\n\nwhere \"T\" is the average temperature of the circulating fluid, \"T\" is the effective, undisturbed temperature of the ground, \"q\" is the heat transfer rate of the GHE per unit time per unit length (W/m), and \"R\" is the total thermal resistance (mK/W).\"R\"(\"t\") is often an unknown variable that needs to be determined by heat transfer analysis. Despite \"R\"(\"t\") being a function of time, analytical models exclusively decompose it into a time-independent part and a time-dependent part to simplify the analysis.\n\nVarious models for the time-independent and time-dependent R can be found in the references.\n\n"}
{"id": "4860689", "url": "https://en.wikipedia.org/wiki?curid=4860689", "title": "Hesperus Mountain (Colorado)", "text": "Hesperus Mountain (Colorado)\n\nHesperus Mountain is the highest summit of the La Plata Mountains range of the Rocky Mountains of North America. The prominent thirteener is located in San Juan National Forest, northeast by east (bearing 59°) of the Town of Mancos in Montezuma County, Colorado, United States. The summit of Hesperus Mountain is the highest point in Montezuma County.\n\nThough not of particularly high elevation for the region, Hesperus Mountain is visually quite prominent, as it is near the southern edge of the San Juan Mountains and rises over above the area.\n\nHesperus is notable as the Navajo People's Sacred Mountain of the North, \"\", which marks the northern boundary of the Dinetah, their traditional homeland. It is associated with the color black, and is said to be impregnated with jet. When First Man created the mountain as a replica of mountains in the Fourth World, he fastened it to the ground with a rainbow and covered it in darkness.\n\nThe San Juan Mountains have been the traditional homeland of the Ute People. http://www.dargnet.org\nhttp://uintahbasintah.org/maps/ubsw.jpg\n\nAlong with Ute the La Plata Mountain Range has also been the early homeland of the Navajo People who had settled on and near this mountain and the La Plata Mountain Range.\n\n"}
{"id": "30872597", "url": "https://en.wikipedia.org/wiki?curid=30872597", "title": "Hypoxia (environmental)", "text": "Hypoxia (environmental)\n\nHypoxia refers to low oxygen conditions. Normally, 20.9% of the gas in the atmosphere is oxygen. The partial pressure of oxygen in the atmosphere is 20.9% of the total barometric pressure. In water however, oxygen levels are much lower, approximately 1%, and fluctuate locally depending on the presence of photosynthetic organisms and relative distance to the surface (if there is more oxygen in the air, it will diffuse across the partial pressure gradient).\n\nAtmospheric hypoxia occurs naturally at high altitudes. Total atmospheric pressure decreases as altitude increases, causing a lower partial pressure of oxygen which is defined as hypobaric hypoxia. Oxygen remains at 20.9% of the total gas mixture, differing from hypoxic hypoxia, where the percentage of oxygen in the air (or blood) is decreased. This is common, for example, in the sealed burrows of some subterranean animals, such as blesmols. Atmospheric hypoxia is also the basis of altitude training which is a standard part of training for elite athletes. Several companies mimic hypoxia using normobaric artificial atmosphere.\n\nOxygen depletion is a phenomenon that occurs in aquatic environments as dissolved oxygen (DO; molecular oxygen dissolved in the water) becomes reduced in concentration to a point where it becomes detrimental to aquatic organisms living in the system. Dissolved oxygen is typically expressed as a percentage of the oxygen that would dissolve in the water at the prevailing temperature and salinity (both of which affect the solubility of oxygen in water; see oxygen saturation and underwater). An aquatic system lacking dissolved oxygen (0% saturation) is termed anaerobic, reducing, or anoxic; a system with low concentration—in the range between 1 and 30% saturation—is called hypoxic or dysoxic. Most fish cannot live below 30% saturation. Hypoxia leads to impaired reproduction of remaining fish via endocrine disruption. A \"healthy\" aquatic environment should seldom experience less than 80%. The exaerobic zone is found at the boundary of anoxic and hypoxic zones.\n\nHypoxia can occur throughout the water column and also at high altitudes as well as near sediments on the bottom. It usually extends throughout 20-50% of the water column, but depending on the water depth and location of pycnoclines (rapid changes in water density with depth). It can occur in 10-80% of the water column. For example, in a 10-meter water column, it can reach up to 2 meters below the surface. In a 20-meter water column, it can extend up to 8 meters below the surface.\n\nOxygen depletion can result from a number of natural factors, but is most often a concern as a consequence of pollution and eutrophication in which plant nutrients enter a river, lake, or ocean, and phytoplankton blooms are encouraged. While phytoplankton, through photosynthesis, will raise DO saturation during daylight hours, the dense population of a bloom reduces DO saturation during the night by respiration. When phytoplankton cells die, they sink towards the bottom and are decomposed by bacteria, a process that further reduces DO in the water column. If oxygen depletion progresses to hypoxia, fish kills can occur and invertebrates like worms and clams on the bottom may be killed as well.\nHypoxia may also occur in the absence of pollutants. In estuaries, for example, because freshwater flowing from a river into the sea is less dense than salt water, stratification in the water column can result. Vertical mixing between the water bodies is therefore reduced, restricting the supply of oxygen from the surface waters to the more saline bottom waters. The oxygen concentration in the bottom layer may then become low enough for hypoxia to occur. Areas particularly prone to this include shallow waters of semi-enclosed water bodies such as the Waddenzee or the Gulf of Mexico, where land run-off is substantial. In these areas a so-called \"dead zone\" can be created. Low dissolved oxygen conditions are often seasonal, as is the case in Hood Canal and areas of Puget Sound, in Washington State. The World Resources Institute has identified 375 hypoxic coastal zones around the world, concentrated in coastal areas in Western Europe, the Eastern and Southern coasts of the US, and East Asia, particularly in Japan.\n\nScientists have determined that high concentrations of minerals dumped into bodies of water causes significant growth of phytoplankton blooms. As these blooms are broken down by bacteria, such as \"Phanerochaete chrysosprium\", oxygen is depleted by the enzymes of these organisms.\n\nPhytoplankton are mostly made up of lignin and cellulose, which are broken down by enzymes present in organisms such as \"P. chrysosprium\", known as white-rot\".\" However, the breakdown of cellulose does not deplete oxygen concentration in water, whereas breakdown of lignin does. This breakdown of lignin includes an oxidative mechanism, and requires the presence of dissolved oxygen to take place by enzymes like ligninperoxidase. Other fungi such as brown-rot, soft-rot, and blue stain fungi also are necessary in lignin transformation. As this oxidation takes place, CO is formed in its place\n\nLigninperoxidase (LiP) serves as the most import enzyme because it is best at breaking down lignin in these organisms. LiP disrupts C-C bonds and C-O bonds within Lignin’s three-dimensional structure, causing it to break down. LiP consists of ten alpha helices, two Ca structural ions, as well as a heme group called a tetrapyrrol ring. Oxygen serves an important role in the catalytic cycle of LiP to form a double bond on the Fe ion in the tetrapyrrol ring. Without the presence of diatomic oxygen in the water, this breakdown cannot take place because Ferrin-LiP will not be reduced into Oxyferroheme. Oxygen gas is used to reduce Ferrin-LiP into Oxyferroheme-LiP. Oxyferroheme and veratric alcohol combine to create oxygen radical and Ferri-LiP, which can now be used to degrade lignin. Oxygen radicals cannot be used in the environment, and are harmful in high presence in the environment.\n\nOnce Ferri-LiP is present in the ligninperoxidase, it can be used to break down lignin molecules by removing one phenylpropane group at a time through either the LRET mechanism or the mediator mechanism. The LRET mechanism (long range electron transfer mechanism) transfers an electron from the tetrapyrrol ring onto a molecule of phenylpropane in a lignin. This electron moves onto a C-C or C-O bond to break one phenylpropane molecule from the lignin, breaking it down by removing one phenylpropane at a time.\n\nIn the mediator mechanism, LiP enzyme is activated by the addition of hydrogen peroxide to make LiP radical, and a mediator such as veratric alcohol is added and activated creating veratric alcohol radical. Veratric alcohol radical transfers one electron to activate the phenylpropane on lignin, and the electron dismantles a C-C or C-O bond to release one phenylpropane from the lignin. As the size of a lignin molecule increases, the more difficult it is to break these C-C or C-O bonds. Three types of phenyl propane rings include coniferyl alcohol, sinapyl alcohol, and-coumaryl alcohol.\n\nLiP has a very low MolDock score, meaning there is little energy required to form this enzyme and stabilize it to carry out reactions. LiP has a MolDock score of -156.03 kcal/mol. This is energetically favorable due to its negative free energy requirements, and therefore this reaction catalyzed by LiP is likely to take place spontaneously. Breakdown of propanol and phenols occur naturally in the environment because they are both water soluble.\n\nThe breakdown of phytoplankton in the environment depends on the presence of oxygen, and once oxygen is no longer in the bodies of water, ligninperoxidases cannot continue to break down the lignin. When oxygen is not present in the water, the breakdown of phytoplankton changes from 10.7 days to a total of 160 days for this to take place.\n\nThe rate of phytoplankton breakdown can be represented using this equation:\n\nformula_1\n\nIn this equation, G(t) is the amount of particulate organic carbon (POC) overall at a given time, t. G(0) is the concentration of POC before breakdown takes place. k is a rate constant in year-1, and t is time in years. For most POC of phytoplankton, the k is around 12.8 years-1, or about 28 days for nearly 96% of carbon to be broken down in these systems. Whereas for anoxic systems, POC breakdown takes 125 days, over four times longer. It takes approximately 1 mg of Oxygen to break down 1 mg of POC in the environment, and therefore, hypoxia takes place quickly as oxygen is used up quickly to digest POC. About 9% of POC in phytoplankton can be broken down in a single day at 18 °C, therefore it takes about eleven days to completely break down a full phytoplankton.\n\nAfter POC is broken down, this particulate matter can be turned into other dissolved organic carbon, such as carbon dioxide, bicarbonate ions, and carbonate. As much as 30% of phytoplankton can be broken down into dissolved organic carbon. When this particulate organic carbon interacts with 350 nm ultraviolet light, dissolved organic carbon is formed, removing even more oxygen from the environment in the forms of carbon dioxide, bicarbonate ions, and carbonate. Dissolved inorganic carbon is made at a rate of 2.3-6.5 mg/(m^3)day.\n\nAs phytoplankton breakdown, free phosphorus and nitrogen become available in the environment, which also fosters hypoxic conditions. As the breakdown of these phytoplankton takes place, the more phosphorus turns into phosphates, and nitrogens turn into nitrates. This depletes the oxygen even more so in the environment, further creating hypoxic zones in higher quantities. As more minerals such as phosphorus and nitrogen are displaced into these aquatic systems, the growth of phytoplankton greatly increases, and after their death, hypoxic zones are formed.\n\nTo combat hypoxia, it is essential to reduce the amount of land-derived nutrients reaching rivers in runoff. This can be done by improving sewage treatment and by reducing the amount of fertilizers leaching into the rivers. Alternately, this can be done by restoring natural environments along a river; marshes are particularly effective in reducing the amount of phosphorus and nitrogen (nutrients) in water. Other natural habitat-based solutions include restoration of shellfish populations, such as oysters. Oyster reefs remove nitrogen from the water column and filter out suspended solids, subsequently reducing the likelihood or extent of harmful algal blooms or anoxic conditions. Foundational work toward the idea of improving marine water quality through shellfish cultivation was conducted by Odd Lindahl et al., using mussels in Sweden.\nTechnological solutions are also possible, such as that used in the redeveloped Salford Docks area of the Manchester Ship Canal in England, where years of runoff from sewers and roads had accumulated in the slow running waters. In 2001 a compressed air injection system was introduced, which raised the oxygen levels in the water by up to 300%. The resulting improvement in water quality led to an increase in the number of invertebrate species, such as freshwater shrimp, to more than 30. Spawning and growth rates of fish species such as roach and perch also increased to such an extent that they are now amongst the highest in England.\n\nIn a very short time the oxygen saturation can drop to zero when offshore blowing winds drive surface water out and anoxic depth water rises up. At the same time a decline in temperature and a rise in salinity is observed (from the longterm ecological observatory in the seas at Kiel Fjord, Germany). New approaches of long-term monitoring of oxygen regime in the ocean observe online the behavior of fish and zooplankton, which changes drastically under reduced oxygen saturations (ecoSCOPE) and already at very low levels of water pollution.\n\n\n\n"}
{"id": "35280316", "url": "https://en.wikipedia.org/wiki?curid=35280316", "title": "John J. Rowlands", "text": "John J. Rowlands\n\nJohn James Rowlands (19 June 1892 – 16 November 1972) was a journalist, writer, and outdoorsman noted for his works about nature and wood lore.\n\nHe was born in Aberdeen, North Carolina, the son of John Rowlands, and Catharine Stewart Stevenson. He attended Staunton Military Academy, Fishburne Military School, and Meisterschaft College in Toronto. His father, manager of the Tarbell Lumber Company, moved the family to Canada to supervise a lumber camp. From 1910 until 1916 Rowlands worked as a prospector and surveyor in the Cobalt and Porcupine Mining regions in Northern Ontario.\n\nIn Autumn 1911, Rowlands had finished a prospecting assignment and took a job testing the performance of a military gig through 100 miles of rough country. He hired a guide named Chief Tibeash (c. 1841 – 9 September 1917), a Cree Indian trapper. After the completion of the journey, he stayed with Tibeash for a month at his cabin near Larger Lake, and they became close friends. Over the next five years he periodically visited Tibeash, who taught Rowlands the Cree way of living in the north country. The relationship culminated with Tibeash offering to adopt Rowlands, but he had already decided to return to the states to pursue a journalism career. The news of Tibeash's death came to Rowlands in a letter from a friend in Northern Ontario.\n\nIn 1916 he left Canada to join the staff of \"The Springfield Union\". From there he went to the United Press in New York, eventually becoming the manager of the New England bureau in Boston. He gained some small notoriety as being the first person to bring the news of President Warren G. Harding's death to Vice President Calvin Coolidge in 1923.\n\nIn 1923 he went to the \"National Sportsman\" magazine. In 1925 Massachusetts Institute of Technology created the MIT News Service to provide \"dignified publicity\" about the school, naming Rowlands as its first director responsible for writing and distributing news releases. In 1955 he was made an honorary member of the Association of Alumni and Alumnae of MIT. He retired in 1957 and built a house on the coast in Cohasset, Massachusetts. The life change instigated a period of reflection, resulting in a series of essays that were published in book form titled \"Spindrift\" (1960). \nHe died in Boston.\n\nThroughout his life, Rowlands contributed articles and stories about outdoors woodcraft and his experiences to such magazines as the \"Atlantic Monthly\" and \"Boys' Life\". He wrote two books, and he is most noted for his first book, \"Cache Lake Country: Life in the North Woods\", a fictionalized account of his experiences with Chief Tibeash in the lake country of the North Ontario woods, originally written between 1945 and 1947 as a series of letters available by subscription for $1 a month. Rowlands and his friend and MIT colleague, the illustrator and photographer Henry B. Kane, who illustrated both of Rowlands' books, would take periodic trips to Northern Canada, and Rowlands added Kane as a character in the book.\n\nThe book was published in 1947 by W. W. Norton & Company and in England by Adam and Charles Black the following year. Norton reissued in 1953 in a slightly smaller format as the Wilderness Edition, with a two-page foreword by Rowlands, and in paperback in 1978. Lyons & Burford reissued the book in 1990 with an introduction by Verlyn Klinkenborg, and in 1998 it was again reissued by Countryman Press, an imprint of Norton, with subsequent printings. It won the 1999 National Outdoor Book Award (NOBA) in the Outdoor Classic Category.\n"}
{"id": "23029816", "url": "https://en.wikipedia.org/wiki?curid=23029816", "title": "Kabaw Valley", "text": "Kabaw Valley\n\nThe Kabaw Valley is a highland valley in northern Burma (Myanmar), western Sagaing division. The valley is the home of a number of ethnic minorities including the Meitei (Kathe and Paona), the Zo, the Mizo, the Kadu and the Kanan.\n\nKabaw valley, historically, was the border region between Awa ( in present Burma ) and the Manipur Kingdom ( Earlier known as Kangleipak or Meitrabak). King Khomba (1432–1467) of Kangleipak was the conqueror of <nowiki>Tamu</nowiki>, a border town in kabow valley, now in Myanmar. King Kiyamba (1467–1508), son of King Khomba, was known as the \"Conqueror of Kabaw Valley\", as he along with his friend, Chaopha Khe Khomba, the king of Pong (Shan Kingdom) of present Myanmar, conquered Kyang, a Shan kingdom in the Kabow Valley of present Myanmar. \n\nIt first came under the Burmese rule in 1560 when Toungoo Dynasty invaded the border valley. Many Shan people fled into Manipur, unable to defend themselves from the Burmese and the Chinese invaders. King Khagemba (1597–1652) of Kangleipak, known as the \"Conqueror of the Chinese\" (\"khagi\": China, \"Ngamba\": conqueror), consolidated and expanded his father's kingdom of Meitrabak, later successfully defending it from foreign invaders such as the Muslims, the Kachari and the Awas. \n\nEverything was recorded in the meitei sacred book \"The Puyas\" known as the Cheitharol Kumbaba, or the royal chronicle of Manipur, started recording from 33 AD. But after the reign of King Khagemba, the Cheitharol Kumbaba was reformed by adding months in the events recorded, making the dates more accurate. \n\nThe reign of King Charairongba (1697–1709) became the transition period from traditional Meitei culture to a Hinduised Meitei society. There were continual trade contacts and social relationships between Manipur and Burma. In 1702, the Toongoo dynasty of Awa (Burma) sent emissaries asking for the hand of a Meitei Princess. Charirongba gave his daughter, Chakpa Makhao Ngambi, in marriage to the then Burmese King who constructed several laishangs/ temples for Meitei deities such as Panthoibi, Sanamahi, today converted into Buddhist temples. \n\nKing Pamheiba (1709-1748), the successor of Charairongba, rose to prominence as a fierce military conqueror. His reign can be divided into three phases. The first phase (1710–17) focused on internal consolidation of the hill tribes. Phase two (1728–33) involved war against the Burmese kingdom of Awa. And, the third and final phase (1745–48) saw a war against Tripura, now in northeast India. As a result, Pamheiba extended his kingdom from the Kabow Valley in the east as far as Nongnang (Cachar) and Takhel (Tripura) in the west. Starting in 1724, he began frequent raids of Upper Burma until 1749.\n\nThe Konbaung Dynasty recovered the Kabaw valley from Manipur in 1756. In 1758, the Burmese king Alaungpaya invaded Manipur. In 1759, King Maramba aka Gourashyam (1953-1958), gave up the throne in favour of his brother Chingthang Khomba aka Bhagayachandra who restored normalcy in the kingdom and tried to regain the lost glory of Manipur. In 1764, the new Burmese king Hsinbyushin invaded Manipur again through the Kabaw Valley. The Meitei forces were defeated at Tamu and the king fled to the Ahom kingdom in Assam. He regained the throne of Kangleipak in 1768 with help of the then Ahom king Rajeshwar and went on to rule for more than 30 years, signing a treaty with the British East India Company in 1762. Manipur remained a rebellion-prone tributary, prompting the Burmese to send expeditions in 1764–1765, 1768–1770, and 1775–1782. Manipur became a Burmese territory again in 1814, and was taken back in 1819 after a rebellion. There were a number of wars during this era between the Manipuris, the Burmese and the British. \n\nWith the help from the Burmese kingdom of Awa, Marjit invaded Manipur in 1813 and defeated his brother King Chaurajit (1803-1813). He then ascended the throne in 1813 and ruled for six years (1813–1819). The new king of Awa, Bagyidaw, invited King Marjit of Manipur to attend his coronation ceremony and to pay homage to him. King Marjit refused to attend the coronation, which offended the Burmese king, who then sent a large force under the command of General Maha Bandula to humble Marjit. Marjit was defeated and fled to Cachar. Meitrabak was then brought under the brutal rule of Awa for the seven years between 1819 and 1826, which is known as Chahi Taret Kuntakpa (7 years devastation )in the history of Meitrabak. The flight of King Marjit from Meitrabak and the conquest by Awa in 1819 marks the end of the mediaeval period in the history of Manipur. \n\nIn the early nineteenth century, after being dislodged from Meitrabak, Manipur princes made Cachar a springboard for the reconquest of the territory. In 1819, three Manipuri princes occupied Cachar Kingdom and drove King Govinda Chandra out to Sylhet in present Bangladesh. The kingdom of Cachar, divided between Govinda Chandra and Chaurajit in 1818, was repartitioned after the flight of Govind Chandra among the three Meitrabak princes. King Chaurajit ruled the eastern portion of Cachar bordering Meitrabak from Sonai. King Gambhir Singh was given the land west of Tillain hill and his headquarters was at Gumrah. King Marjit Singh ruled Hailakandi from Jhapirbond. King Gambhir Singh (1826–1834) with the 500 strong Meetei Levy and with the help from the British East India Company, succeeded in expelling the Burmese of Awa from Meitrabak beyond the Ningthi Turel (Chindwin River). He ruled the country from Langthabal and died on 9 January 1834, to be succeeded by his infant son Chandrakirti / Ningthem Pishak (1834–1844).\n\nAfter the First Anglo-Burmese War (1824–1826), Burma ceded Manipur to the British but the exact border remained in dispute. The British claimed the entire Kabaw valley. However, in 1830, the British, with the assistance of Henry Burney, agreed that Kabaw valley was not part of historical Manipur, and redrew the border in favor of the Burmese. Nonetheless, some in Manipur still claim that the Kabaw Valley belongs in Manipur. The treaty of yadanbo made sure that the Burmese King must pay Kabaw valley compensation tax to the Manipuri King.\n\nManipur was merged in the Indian union in 1949, during the reign of the last king, Bodhachandra, just two year after getting independence from the British rule for 57 years (1891-1947). In 1952, India first Prime Minister Jawaharlal Nehru completely gifted the Kabaw valley to the Burmese government as a token of peace. In 1950, a social leader of Manipur, Hijam Irabot visited Burma and negotiated with the Burmese army political fraction, coming with an agreement to stop the Burmese tax to Manipur government and let Manipur have Kabaw valley. But, the compensation tax is no longer paid and the valley is under Myanmar territory now.\n\nAt the north end of the valley, lies the Manipuri town of Humine, with the first Burmese town being Zedi. The region is mixedly inhabited by the Meeteis, Nepalis, kukis/ chins, kados, kanans,etc.\n\nMoreh is the border town in the Manipuri / Indian side while Tamu is in Myanmar.Both are being referred to as the twin border towns of trade in the region.\n\n"}
{"id": "16474288", "url": "https://en.wikipedia.org/wiki?curid=16474288", "title": "Keystone (limestone)", "text": "Keystone (limestone)\n\nKeystone is a type of limestone, or coral rag, quarried in the Florida Keys, in particular from Windley Key fossil quarry, which is now a State Park of Florida. The limestone is Pleistocene in age, and the rock primarily consists of scleractinian coral, such as Elkhorn coral and Brain coral.\n\nThe Hurricane Monument, commemorating victims of the Labor Day Hurricane of 1935, and located at mile marker 82 on U.S. Route 1 near Islamorada, is constructed of keystone, as is the David W. Dyer Federal Building and United States Courthouse.\n\n"}
{"id": "51026775", "url": "https://en.wikipedia.org/wiki?curid=51026775", "title": "Kitsat-3", "text": "Kitsat-3\n\nKitsat-3 was a South Korean remote sensing minisatellite which carried MEIS (Multispectral Earth Imaging System) and SENSE (Space ENvironment Scientific Experiment) instruments to Low Earth orbit. Launched on 26 May 1999 by Indian space agency ISRO, on orbit the satellite was renamed to Uribyol 3. Manufactured by KAIST Satellite Technology Research Center (SaTReC), Kitsat-3 was developed with experience from Kitsat-1 and Kitsat-2 (no heritage to the Kitsat-1 and Kitsat-2 bus) and was the first independently designed South Korean satellite.\n\nKitsat-3 was launched in the PSLV-C2 mission by 26 May 1999 by Indian space agency ISRO at 06:22 UTC from Sriharikota Launching Range in India. The launch was the first commercial launch by ISRO of its expendable launch system (PSLV) and $1.0 million (equivalent to $ million in ) was charged by the Indian agency for launching and injecting the satellite in the Low Earth orbit.\n\n\n"}
{"id": "78469", "url": "https://en.wikipedia.org/wiki?curid=78469", "title": "La Niña", "text": "La Niña\n\nLa Niña (, ) is a coupled ocean-atmosphere phenomenon that is the counterpart of El Niño as part of the broader El Niño–Southern Oscillation climate pattern. The name La Niña originates from Spanish, meaning \"the little girl\", analogous to El Niño meaning \"the little boy\". It has also in the past been called \"anti-El Niño\", and El Viejo (meaning \"the old man\"). During a period of La Niña, the sea surface temperature across the equatorial Eastern Central Pacific Ocean will be lower than normal by 3 to 5 °C. In the United States, an \"appearance\" of La Niña persists for at least five months. It has extensive effects on the weather in North America, even affecting the Atlantic and Pacific hurricane seasons.\n\nLa Niña is the positive phase of the El Niño–Southern Oscillation and is associated with cooler-than-average sea surface temperatures in the central and eastern tropical Pacific Ocean. However, each country and island nation has a different threshold for what constitutes a La Niña event, which is tailored to their specific interests. For example, the Australian Bureau of Meteorology looks at the trade winds, SOI, weather models and sea surface temperatures in the Niño 3 and 3.4 regions before declaring that a La Niña event has started. However, the Japan Meteorological Agency declares that a La Niña event has started when the average five-month sea surface temperature deviation for the NINO.3 region is more than cooler for 6 consecutive months or longer.\n\nA timeline of all La Niña episodes between 1900 and 2018.\nThere was a relatively strong La Niña episode during 1988–1989. La Niña also formed in late 1983, in 1995, and a protracted La Niña event that lasted from mid-1998 through early 2001. This was followed by a neutral period between 2001 and 2002. The La Niña which developed in mid-2007, and lasted until almost 2009, was a moderate one. The strength of La Niña made the 2008 Atlantic hurricane season one of the five most active since 1944; sixteen named storms had winds of at least , eight of which became or greater hurricanes.\n\nA new La Niña episode developed quite quickly in the eastern and central tropical Pacific in mid-2010, and lasted until early 2011. It intensified again in mid-2011 and lasted until early 2012. This La Niña, combined with record-high ocean temperatures in the north-eastern Indian Ocean, was a large factor in the 2010–2011 Queensland floods, and the quartet of recent heavy snowstorms in North America starting with the December 2010 North American blizzard. The same La Niña event was also a likely cause of a series of tornadoes of above-average severity that struck the Midwestern and Southern United States in the spring of 2011, and drought conditions in the South Central states including Texas, Oklahoma and Arkansas. Meanwhile, a series of major storms caused extensive flooding in California in December 2010, with seven consecutive days of non-stop rainfall, leading to one of the wettest Decembers in over 120 years of records. This is in contrast to the drier-than-normal conditions typically associated with La Niña in California, especially in the south.\n\nIn 2011, on a global scale, La Niña events helped keep the average global temperature below recent trends. As a result, 2011 tied with 1997 for the eleventh-warmest year on record. It was the second-coolest year of the 21st century to date, and tied with the second-warmest year of the 20th century. A relatively strong phase of La Niña opened the year, dissipated in the spring before re-emerging in October and lasted through the end of the year. When compared to previous La Niña years, the 2011 global surface temperature was the warmest observed. The 2011 globally-averaged precipitation over land was the second-wettest year on record, behind 2010. Precipitation varied greatly across the globe. This La Niña contributed to severe drought in East Africa and to Australia's third-wettest year in its 112-year period of records.\n\nLa Niñas occurred in 1904, 1908, 1910, 1916, 1924, 1928, 1938, 1949–51, 1954–56, 1964, 1970–72, 1973–76, 1983–85, 1988–89, 1995–96, 1998–2001, 2007–08, 2008–09, 2010–12, 2016–17 and 2017-18.\n\nLa Niña impacts the global climate and disrupts normal weather patterns, which as a result can lead to intense storms in some places and droughts in others.<ref name=\"NIWA El Niño/La Niña\"></ref>\n\nObservations of La Niña events since 1950, show that impacts associated with La Niña events depend on what season it is. However, while certain events and impacts are expected to occur during events, it is not certain or guaranteed that they will occur.\n\nLa Niña results in wetter-than-normal conditions in Southern Africa from December to February, and drier-than-normal conditions over equatorial East Africa over the same period.\n\nDuring La Niña years, the formation of tropical cyclones, along with the subtropical ridge position, shifts westward across the western Pacific Ocean, which increases the landfall threat to China. In March 2008, La Niña caused a drop in sea surface temperatures over Southeast Asia by 2 °C. It also caused heavy rains over Malaysia, the Philippines, and Indonesia.\n\nLa Niña causes mostly the opposite effects of El Niño, above-average precipitation across the northern Midwest, the northern Rockies, Northern California, and the Pacific Northwest's southern and eastern regions. Meanwhile, precipitation in the southwestern and southeastern states, as well as Southern California, is below average. This also allows for the development of many stronger-than-average hurricanes in the Atlantic and fewer in the Pacific.\n\nThe synoptic condition for Tehuantepecer winds is associated with high-pressure system forming in Sierra Madre of Mexico in the wake of an advancing cold front, which causes winds to accelerate through the Isthmus of Tehuantepec. Tehuantepecers primarily occur during the cold season months for the region in the wake of cold fronts, between October and February, with a summer maximum in July caused by the westward extension of the Azores-Bermuda high pressure system. Wind magnitude is weaker during La Niña years than El Niño years, due to the less frequent cold frontal incursions during La Niña winters, with its effects can last from a few hours to six days. Between 1942 and 1957, La Niña had an impact that caused isotope changes in the plants of Baja California.\n\nIn Canada, La Niña will, in general, cause a cooler, snowier winter, such as the near-record-breaking amounts of snow recorded in La Niña winter of 2007/2008 in Eastern Canada.\n\nDuring a time of La Niña, drought plagues the coastal regions of Peru and Chile. From December to February, northern Brazil is wetter than normal. La Niña causes higher than normal rainfall in the central Andes, which in turn causes catastrophic flooding on the Llanos de Mojos of Beni Department, Bolivia. Such flooding is documented from 1853, 1865, 1872, 1873, 1886, 1895, 1896, 1907, 1921, 1928, 1929 and 1931.\n\nThe traditional La Niña, also called Eastern Pacific (EP) La Niña, involves temperature anomalies in the Eastern Pacific. However, in the last two decades, nontraditional La Niña were observed, in which the usual place of the temperature anomaly (Niño 1 and 2) is not affected, but an anomaly arises in the central Pacific (Niño 3.4). The phenomenon is called Central Pacific (CP) La Niña, \"dateline\" La Niña (because the anomaly arises near the dateline), or La Niña \"Modoki\" (Modoki is Japanese for \"similar, but different\"). There are flavors of ENSO additional to EP and CP types and some scientists argue that ENSO exists as a continuum often with hybrid types.\n\nThe effects of the CP La Niña are different from those of the traditional EP La Niña—e.g., the recently discovered La Niña leads to a rainfall increase over northwestern Australia and northern Murray-Darling basin, rather than over the east as in a conventional La Niña. Also, La Niña Modoki increases the frequency of cyclonic storms over Bay of Bengal, but decreases the occurrence of severe storms in the Indian Ocean overall, with the Arabian Sea becoming severely non-conductive to tropical cyclone formation.\n\nThe recent discovery of ENSO Modoki has some scientists believing it to be linked to global warming. However, comprehensive satellite data go back only to 1979. Generally, there is no scientific consensus on how/if climate change may affect ENSO.\n\nThere is also a scientific debate on the very existence of this \"new\" ENSO. A number of studies dispute the reality of this statistical distinction or its increasing occurrence, or both, either arguing the reliable record is too short to detect such a distinction, finding no distinction or trend using other statistical approaches, or that other types should be distinguished, such as standard and extreme ENSO.\n\nRecent years when La Niña Modoki events occurred include 1973–74, 1975–76, 1983–84, 1988–89, 1998–99, 2000–01, 2008–09, 2010–11 and 2016–17.\n\n\n"}
{"id": "19324173", "url": "https://en.wikipedia.org/wiki?curid=19324173", "title": "List of Nature Conservation Act endangered flora of Queensland", "text": "List of Nature Conservation Act endangered flora of Queensland\n\nThis is a list of the flora of Queensland listed as \"Endangered\" under the Nature Conservation Act 1992.\n\n\n"}
{"id": "57977603", "url": "https://en.wikipedia.org/wiki?curid=57977603", "title": "List of Prunus species", "text": "List of Prunus species\n\nThe following species in the genus \"Prunus\" are recognised by \"The Plant List\":\n\nThe following additional species are accepted by the Integrated Taxonomic Information System (ITIS), although they might be considered synonyms by other sources:\n\nThe following additional species are accepted by the Germplasm Resources Information Network (GRIN), although they might be considered synonyms by other sources, or be erroneous accessions:\n\n\nThe following additional species are listed by Tropicos; they are almost certainly synonyms of the species above:\n\nThe following additional species are accepted by the Global Biodiversity Information Facility (GBIF):\n\n\n\nThese are described from fossils. Some may have been synonymized with other fossil \"Prunus\" species, other fossil genera, or even living species at some point after their description.\n\n"}
{"id": "7105652", "url": "https://en.wikipedia.org/wiki?curid=7105652", "title": "List of Salticidae species (D–F)", "text": "List of Salticidae species (D–F)\n\nList of Salticidae species D–F includes all described species with a scientific name starting from D to F of the spider family Salticidae as of December 16, 2016.\n\n\"Damoetas\" \n\n\"Darwinneon\" \n\n\"Dasycyptus\" \n\n\"Dendryphantes\" \n\n\"Depreissia\" \n\n\"Descanso\" \n\n\"Dexippus\" \n\n\"Diolenius\" \n\n\"Diplocanthopoda\" \n\n\"Dolichoneon\" \n\n\"Donaldius\" \n\n\"Drizztius\" \n\n\"Druzia\" \n\n\"Eburneana\" \n\n\"Echeclus\" \n\n\"Echinussa\" \n\n\"Ecuadattus\" \n\n\"Edilemma\" \n\n\"Edwardsya\" \n\n\"Efate\" \n\n\"Emathis\" \n\n\"Empanda\" \n\n\"Encolpius\" \n\n\"Encymachus\" \n\n\"Enoplomischus\" \n\n\"Epeus\" \n\n\"Epidelaxia\" \n\n\"Epocilla\" \n\n\"Erasinus\" \n\n\"Ergane\" \n\n\"Erica\" \n\n\"Eris\" \n\n\"Euophrys\" \n\n\"Eupoa\" \n\n\"Euryattus\" \n\n\"Eustiromastix\" \n\n\"Evarcha\" \n\n\"Featheroides\" \n\n\"Festucula\" \n\n\"Flacillula\" \n\n\"Fluda\" \n\n\"Foliabitus\" \n\n\"Frespera\" \n\n\"Frewena\" \n\n\"Freya\" \n\n\"Frigga\" \n\n\"Fritzia\" \n\n\"Fuentes\" \n\n\"Furculattus\" \n\n"}
{"id": "9020628", "url": "https://en.wikipedia.org/wiki?curid=9020628", "title": "List of citrus diseases", "text": "List of citrus diseases\n\nThe following is a list of diseases in citrus plants.\n\n"}
{"id": "48372863", "url": "https://en.wikipedia.org/wiki?curid=48372863", "title": "List of earthquakes in Afghanistan", "text": "List of earthquakes in Afghanistan\n\nThis is a list of earthquakes in Afghanistan.\n\nAfghanistan is situated near the southern extent of the Eurasian Plate.\n\nSources\n"}
{"id": "9132780", "url": "https://en.wikipedia.org/wiki?curid=9132780", "title": "List of foliage plant diseases (Bromeliaceae)", "text": "List of foliage plant diseases (Bromeliaceae)\n\nThis is a list of diseases of foliage plants belonging to the family Bromeliaceae.\n\n"}
{"id": "22906287", "url": "https://en.wikipedia.org/wiki?curid=22906287", "title": "List of mountain passes of Limpopo", "text": "List of mountain passes of Limpopo\n\nThis is a list of publicly accessible, motorable passes in the Limpopo Province, South Africa.\nSee Mountain Passes of South Africa\n"}
{"id": "58527654", "url": "https://en.wikipedia.org/wiki?curid=58527654", "title": "List of pipeline accidents in the United States in 2018", "text": "List of pipeline accidents in the United States in 2018\n\nThe following is a list of pipeline accidents in the United States in 2018. It is one of several lists of U.S. pipeline accidents. See also list of natural gas and oil production accidents in the United States.\n\nThis is not a complete list of all pipeline accidents. For natural gas alone, the Pipeline and Hazardous Materials Safety Administration (PHMSA), a United States Department of Transportation agency, has collected data on more than 3,200 accidents deemed serious or significant since 1987.\n\nA \"significant incident\" results in any of the following consequences:\n\nPHMSA and the National Transportation Safety Board (NTSB) post incident data and results of investigations into accidents involving pipelines that carry a variety of products, including natural gas, oil, diesel fuel, gasoline, kerosene, jet fuel, carbon dioxide, and other substances. Occasionally pipelines are repurposed to carry different products.\n\n"}
{"id": "22464958", "url": "https://en.wikipedia.org/wiki?curid=22464958", "title": "List of rivers of Burundi", "text": "List of rivers of Burundi\n\nThis is a list of rivers in Burundi. This list is arranged by drainage basin, with respective tributaries indented under each larger stream's name.\n\n\n\n"}
{"id": "36721003", "url": "https://en.wikipedia.org/wiki?curid=36721003", "title": "List of rivers of Mauritania", "text": "List of rivers of Mauritania\n\nThis is a list of rivers in Mauritania. This list is arranged by drainage basin, with respective tributaries indented under each larger stream's name.\n\n\n"}
{"id": "44659110", "url": "https://en.wikipedia.org/wiki?curid=44659110", "title": "List of sperm whale strandings", "text": "List of sperm whale strandings\n\nStrandings of sperm whales have occurred across much of their global range. About 60 per cent of the world's recorded sperm whale strandings occur in three regions - Tasmania, New Zealand and the North Sea. 132 strandings of sperm whales were recorded around the coast of the United Kingdom (mostly in Scotland) between 1990 and 2011. The list below is in reverse chronological order and is not exhaustive.\n"}
{"id": "146106", "url": "https://en.wikipedia.org/wiki?curid=146106", "title": "List of waterways", "text": "List of waterways\n\nThis is a list of waterways, defined as navigable rivers, canals, estuaries, lakes, or firths. In practice, and depending on the language, the term \"waterway\" covers maritime or inland transport routes, as suggested by \"way\". Wherever a free-flowing river cannot bear load-carrying vessels, the correct term is \"watercourse\", with no connotation of use for transportation of cargo. To be of practical use, the list distinguishes international maritime waterways (including ship canals), international inland waterways, then inland waterways, including canals and large lakes. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "17967625", "url": "https://en.wikipedia.org/wiki?curid=17967625", "title": "Mineral industry of Azerbaijan", "text": "Mineral industry of Azerbaijan\n\nAs of 2005, Azerbaijan produced a range of metals and industrial minerals, including aluminum, lead, iron, and zinc.\n\nAzerbaijan's importance as a world mineral producer, however, was based on its petroleum extracting industry. The country has been a significant oil producer for more than a century, but recent focus has been on developing offshore resources in the Caspian Sea. Production from the country’s Soviet-era fields are in decline, but since independence, foreign direct investment in offshore fields had revitalized the oil sector through the development of large-scale new projects and the refurbishment of older ones. In 2005, Azerbaijan had signed more than 20 major agreements to develop oilfields with approximately 30 companies from 15 countries.\n\nOil extraction and refining accounted for more than 75% of the value of industrial production. The oil extraction and refining sectors and the metallurgy and metal fabrication sectors employed more than 60,000 people in 2005. The country was becoming a major producer of oil, producing far more than it consumed, but its natural gas production in 2005 was still significantly below its consumption. The country was increasing its steel products production at the Baku Steel company, a privately owned company that produced steel products from steel scrap.\n\nIn 2005, production increased for practically all mineral commodities. Crude petroleum production increased by more than 43% compared with that of 2004. The country was developing its steel industry, although it is still on a small scale.\n\nFuels accounted for 76% of the value of exports in 2005. The country’s major export was crude petroleum, almost all of which was sold on world markets rather than supplied to other CIS countries. Other mineral exports included petroleum refinery products and alumina. The country imported a variety of mineral commodities, including natural gas.\n\nAzerbaijan’s major mineral wealth is its oil and gas reserves. Offshore hydrocarbon structures in the Caspian Sea accounted for most of the country’s oil and gas production. Azerbaijan’s proven crude oil reserves were estimated to range from 7 billion to 13 billion barrels (Gbbl) [or from about 950 million metric tons (Mt) to 1.8 billion metric tons (Gt)] based on various industry journals and Government sources. The State Oil Company of the Azerbaijan Republic (SOCAR) has estimated that proven reserves are 17.5 Gbbl (about 2.4 Gt) using the Soviet reserve classification system. This evaluation was not based on market economy criteria and may include resources that are not economically viable. Estimates of natural gas reserves also vary. According to the Oil & Gas Journal, Azerbaijan has proven natural gas reserves of roughly 30 trillion cubic feet (about 850 billion cubic meters, and BP p.l.c. estimates that the country has 48 trillion cubic feet (about 1.4 trillion cubic meters) of proven gas reserves.\n\nAlthough some effort has been made to promote balanced mineral development of all the country’s mineral resources, the country’s economic development has depended primarily on the development of its large offshore oil and gas resources. These resources are expected to be the country’s chief source of revenue for the coming decades.\n\nIn 2004, Azerbaijan exported approximately of oil. Exports are expected to more than double to in 2006 and to reach as high as by 2008.\n\nAzerbaijan was a net natural gas importer in 2005. The country is expected to become a significant gas exporter following the development of the Shah Deniz natural gas deposit, which is considered to be one of the world’s largest natural gas field discoveries of the past 20 years. According to BP (the project operator), Shah Deniz has potential recoverable reserves of about 15 trillion cubic feet (about 424 billion cubic meters) of natural gas and —about 82 Mt] of condensate. Other industry and trade sources have estimated that the field contains as much as of gas. The field is being developed by the Shah Deniz consortium, whose members include BP, LukAgip, National Iranian Oil Company (NICO) International, SOCAR, Statoil ASA of Norway, TotalFinaElf, and Türkiye Petrolleri Anonim Ortaklig (TPAO) of Turkey.\n\nIn the first phase of the Shah Deniz field’s development, production of natural gas for export was expected to begin in late 2006. In the second phase, according to BP, the Shah Deniz project could produce an additional per year of natural gas by as early as 2015.\n\nAlthough Azerbaijan lacks any infrastructure for the export of natural gas, efforts were underway to secure export routes and customers for gas deliveries beginning in 2006. The main conduit for Azerbaijan’s natural gas exports would be the South Caucasus Pipeline, also known as Baku-Tbilisi-Erzurum, which would run parallel to the Baku-T’bilisi-Ceyhan oil pipeline for most of its route before connecting to the Turkish gas pipeline network near the town of Horasan in Turkey. Pipeline construction began in late 2004 and was scheduled to be completed during the first quarter of 2007. The pipeline was expected to carry per year initially; this volume could be increased later to up to per year with the future addition of compression stations.\n\nWith the new pipeline infrastructure in place, Shah Deniz would be capable of producing approximately per year of natural gas by 2009. Supplies of natural gas from Shah Deniz and associated gas from the Azeri Chirag Gunashli (AGC) and the Bakhar-2 projects are expected to make Azerbaijan self-sufficient in natural gas and to result in significant export revenues.\n"}
{"id": "44730631", "url": "https://en.wikipedia.org/wiki?curid=44730631", "title": "Mixedwood stand", "text": "Mixedwood stand\n\nA mixedwood stand is a forest type in which 26% to 75% of the canopy is made up of softwood trees.\n\nUncertainties of the definition, extent, and potential of mixedwood types necessitate the placement of some mensurational bounds on the subject of mixedwood management, especially the distribution and component sub-types, age classes, advance growth, productivity, and rotation ages. A major ecological factor in mixedwood management is the spruce budworm; another is the problem of providing for sufficient white spruce regeneration.\n\nThe white spruce–aspen mixedwood associations of the Prairie Provinces have a variety of compositions ranging from pure aspen to pure white spruce, to mixtures of both. Balsam poplar, white birch, black spruce, balsam fir, and pines may also occur. Silvicultural treatments have generally been aimed at promoting white spruce, primarily through plantation establishment and management. The type of stand of a given association is as much a product of successional stage and stand history as it is of site type. Depending on seed source and seedbed conditions, recruitment of white spruce may begin relatively soon after disturbance or may be spread over many decades.\n\nManagement of mixedwoods in the Prairie Provinces in the 1990s usually used clearcutting. When aspen is the main species to be regenerated, little treatment is applied to the site, but slash piles, compaction of soil, and damage to aspen root systems are minimized as much as is feasible in order to encourage suckering. In the coniferous harvest, aspen that is not harvested is usually left standing to reduce suckering, as well as for the benefit of wildlife. Regeneration of white spruce is more difficult. In general, plantation techniques are used, with mechanical site preparation following clearcutting. Depending on site conditions and availability of equipment, disk trenching, double disking, blading, ripper, or Marttiini plowing, Bracke spot scarification, high-speed mixing, or spot mounding are used. Plantings of white spruce have come to favour the use of large container or transplant stock. In the early years after clearcutting, site preparation and planting, shade-intolerant vegetation, such as aspen, \"Calamagrostis canadensis\", and green alder compete strongly with the young outplants, frequently causing death.\n"}
{"id": "4117298", "url": "https://en.wikipedia.org/wiki?curid=4117298", "title": "Odisha semi-evergreen forests", "text": "Odisha semi-evergreen forests\n\nThe Odisha semi-evergreen forests are a tropical moist broadleaf forest ecoregion of eastern India. The ecoregion covers an area of on the coastal plain of Odisha state, bounded on the north and west by the Eastern Highlands moist deciduous forests and on the south and west by the Bay of Bengal.\n\nThe ecoregion has been extensively cleared for agriculture use and urbanization. Several of Odisha's largest cities, including Bhubaneswar, Cuttack, Puri, Chhatrapur, Kendrapara, and Bhadrak, lie within the ecoregion. According to the WWF, 96% of the ecoregion's area has been cleared, and only 4% remains in the original semi-evergreen rain forest. Much of the remaining forest has been degraded by grazing and fuelwood harvesting.\n\nAbout 5% of the ecoregion's area (1100 km²) is within three protected areas.\n\n\nA study done by Reddy, Jha, & Dadhwal in this area is being used to shape environmental policies in India to protect biodiversity. Through monitoring long term forest resource changes show a loss in overall species and ecosystem services that can be measured in physical data. The results of this study show a connection between deforestation and fragmentation, and loss of important biodiversity in the ecoregion.\n\n"}
{"id": "59042714", "url": "https://en.wikipedia.org/wiki?curid=59042714", "title": "Philyra (Oceanid)", "text": "Philyra (Oceanid)\n\nIn Greek mythology, Philyra or Phillyra (: , \"linden-tree\") was one of the Oceanids, daughters of Oceanus and Tethys. \n\nChiron was her son by Cronus, who chased her and consorted with her in the shape of a stallion, hence the half-human, half-equine shape of their offspring; this was said to have taken place on Mount Pelion. When she gave birth to her son, she was so disgusted by how he looked that she abandoned him at birth, and implored the gods to transform her into anything other than anthropomorphic as she could not bear the shame of having had such a monstrous child; the gods changed her into a linden tree. \n\nYet in some versions Philyra and Chariclo, the wife of Chiron, nursed the young Achilles; Chiron's dwelling on Pelion where his disciples were reared was known as \"Philyra's cave\". Chiron was often referred to by the matronymic Philyrides or the like. Two other sons of Cronus and Philyra may have been Dolops and Aphrus, the ancestor and eponym of the Aphroi, i.e. the native Africans.\n"}
{"id": "57837450", "url": "https://en.wikipedia.org/wiki?curid=57837450", "title": "Point counting (geology)", "text": "Point counting (geology)\n\nIn geology, point counting is a method to determine the proportion of an area that is covered by some objects of interest. In most cases the area is a thin section or a polished slab. The objects of interest vary between subdisciplines and can for example be quartz or feldspar grains in sedimentology, any type of mineral in petrology or different taxonomic groups in paleontology.\n\nThe basic method is to cover the area by a grid of points. Then for each of these points, the underlying object is identified. Then the estimate for the proportion of the area covered by the type of object is given as\n\nwhere\n\nThere exist many variations of this procedure that can for example vary in grid geometry.\n\n\n"}
{"id": "43835810", "url": "https://en.wikipedia.org/wiki?curid=43835810", "title": "Quick condition", "text": "Quick condition\n\nThe quick condition of soil is the condition when the upward water pressure gradient and water flow reduce the effective stress, i.e., cohesiveness of the soil. Sandy soils may lose their shear strength, and the soil may behave as a fluid‌. Cohesive soils may produce cracks with water seepage.\n\n"}
{"id": "41172105", "url": "https://en.wikipedia.org/wiki?curid=41172105", "title": "Reformed baptismal theology", "text": "Reformed baptismal theology\n\nIn Reformed theology, baptism is a sacrament signifying the baptized person's union with Christ, or becoming part of Christ and being treated as if they had done everything Christ had. Sacraments, along with preaching of God's word, are means of grace through which God offers Christ to people. Sacraments are believed to have their effect through the Holy Spirit, but these effects are only believed to be beneficial to those who have faith in Christ.\n\nIn Reformed theology, baptism is the sacrament of initiation into the visible church, or body of people who publicly claim faith in Christ. Baptism also signifies regeneration and remission of sin. Reformed Christians believe that the children of those who express faith in Christ should be baptized. Because baptism is believed to be beneficial only to those who have faith in Christ, infants are baptized on the basis of the promise of faith which will come to fruition later in life.\n\nChristian baptismal theology prior to the Reformation taught that sacraments, including baptism, are means or instruments through which God communicates grace to people. The sacrament was considered valid regardless of who administered it. Not everyone who received a sacrament, however, received the grace signified by the sacrament. Some medieval theologians spoke of an obstacle of mortal sin which blocks the grace of the sacrament, while others insisted that the recipient be positively open and responding in faith to the sacrament in order to receive any benefit. Baptism was believed to be used by the Holy Spirit to transform the believer, and offered the benefits of remission of sins, regeneration, and the indwelling of the Holy Spirit. The sacrament of penance was believed to be necessary for forgiveness for sins committed after baptism.\n\nDuring the Reformation, Martin Luther rejected many of the Catholic Church's seven sacraments, but retained baptism and the Lord's Supper. He saw many practices of the medieval church as abuses of power intended to require work in order to merit forgiveness for sin after baptism rather than faith alone. Luther attached the promise of salvation to baptism, and taught that life after baptism should be spent in recollection of it and the dying to sin it signified.\n\nHuldrych Zwingli, the earliest theologian considered part of the Reformed tradition, was vigorously opposed to worship practices he believed to be based on tradition rather than the Bible. Nevertheless, he disagreed with Anabaptists, who refused to baptize their children on scriptural grounds. Through his arguments with Anabaptists, Zwingli arrived at the position that baptism was a sign of the covenant between God and his people, but that it did not convey grace to the baptized. He saw baptism as essentially identical to the circumcision of Israelites in the Old Testament in this respect, and used this idea in polemics against Anabaptists. Zwingli's emphasis on baptism as a pledge or oath was to prove unique in the Reformed tradition. Heinrich Bullinger, Zwingli's successor, continued the teaching of the continuity of God's covenants and circumcision with baptism. Bullinger also emphasized that baptism indicates duties to the baptized in response to God's grace.\n\nJohn Calvin was influenced by Martin Luther's idea of baptism as God's promises to the baptized person attached to the outward sign of washing with water. Calvin maintained Zwingli's idea of baptism as a public pledge, but insisted that it was secondary to baptism's meaning as a sign of God's promise to forgive sin. He maintained that sacraments were effective instruments in bringing about the promises they represent, however he also maintained that the promises could be refused by the baptized, and would have no effect in that case. Calvin carefully distinguished between the outward sign of the washing of water with the promises that baptism signifies while maintaining that they were inseparable. Calvin's baptismal theology is very similar to that of Luther. It differs in the way Calvin subordinated sacraments to the preaching of the word of God. While Luther placed preaching and sacraments on the same level, Calvin saw sacraments as confirmation which is added to the preaching of the word of God.\nFrom the end of the sixteenth century through the eighteenth century, a period known as Reformed orthodoxy, Reformed baptismal theology further developed the covenantal meaning of baptism. Theologians more carefully defined the sacramental union of baptism, or the relationship between the outward washing with that which it signifies. In the high orthodox period (middle to late seventeenth century), theologians such as Hermann Witsius expanded the covenantal meaning of baptism using analogies such as Noah's Ark and the crossing of the Red Sea, which carried the theological themes of the resurrection and eternal life. This period also saw the emergence of Reformed Baptists. Reformed Baptist theologians had much in common with the Reformed, but saw baptism as a sign of the baptized's fellowship with Christ rather than a sign and seal of the covenant of grace, and as a result did not baptize their children.\n\nFriedrich Schleiermacher, an influential nineteenth-century Reformed theologian, saw baptism as the way the church receives new members and taught that faith is a precondition for baptism. He was ambivalent about the practice of infant baptism, teaching that it was not an essential institution, but could be continued as long as the church was faithful in bringing children to confirmation. Schleiermacher also saw baptism as primarily individual rather than initiating one into a covenant community, and rejected the idea that baptism should be connected with Old Testament circumcision.\n\nScottish nineteenth-century Reformed theologian William Cunningham also sought to articulate a distinctively Reformed theology of baptism in the modern world. Cunningham preferred the writings of Zwingli on the sacraments, writing that Calvin and later Reformed orthodox theologians overly elevated the value of the sacraments. He argued that the efficacy of baptism only applies to adults expressing faith in the act of baptism.\n\nIn the twentieth century, Karl Barth, an influential Swiss Reformed theologian, argued that baptism should not be administered to infants because it represented a completed association with Christ which could only be accepted or rejected by adults. Further, Barth in his later years rejected the idea that baptism was actually used by God to accomplish anything, or could even properly be called a sacrament. Instead, he taught that water baptism is a human act of obedience. His views have been called \"neo-Zwinglian\" for this reason, and he himself identified Zwingli's views on sacraments as the believer's oath as his own. He continued to accept the validity of infant baptisms, and did not believe those baptized as infants should be rebaptized. \n\nLater Reformed theologians reacted against Barth's views on baptism by appealing to Calvin, the idea that baptism is a promise rather than an accomplished reality, and the idea of baptism as a replacement of circumcision. Scottish Reformed theologian T.F. Torrance emphasized the idea that baptism is God's word establishing the church, and that the individual's response comes after rather than before God's act in baptism. German Reformed liberation theologian Jürgen Moltmann, on the other hand, saw infant baptism as inappropriately associated with the national church. He saw baptism as properly a free response God's call to discipleship. Reformed churches have generally maintained the practice of infant baptism despite these critiques.\n\nIn Reformed theology, sacraments are held to be, along with the word of God preached, the means of grace. In the sacraments, God graciously condescends to use common material objects to communicate divine promises to people. The grace promised consists not only in benefits which God bestows on people, but Christ's person himself, to whom God unites the believer. Sacraments confirm or ratify the promises communicated in preaching. Both preaching and the sacraments are not merely symbolic and representative of the reality to which they refer, but actually create the reality of saving grace. The sacraments are made efficacious by the Holy Spirit in actually bringing into effect the promises signified in the sacraments. This efficacy is only beneficial, however, for those who have faith. The sacrament remains efficacious regardless of the recipient's response. Its effect is negative, resulting in judgement, for the faithless; while it confers Christ and his benefits for the faithful.\n\nReformed theologians believe sacraments to be instituted in the context of covenants between God and people. They believe that when God makes covenants, he provides physical signs associated with the covenant. Old Testament covenant signs include the rainbow which appeared following a covenant made with Noah. Circumcision is believed to be a sign of God's covenant with Abraham and his descendants. Such signs entail blessings and sanctions on those with whom God covenants. In the New Testament period there are two such signs or sacraments: baptism and the Lord's Supper.\n\nIn Reformed sacramental theology, the sign (in the case of baptism the external washing with water) may be described in terms of the thing signified (regeneration, remission of sin, etc.), because of the close connection between them. For example, baptism may be said to save, and baptism is often called the \"laver of regeneration\". However, there is also a distinction between the sign and thing signified. The sign is seen as a pledge and seal of the inward washing of regeneration and purification. The sacramental union between the sign and thing signified means that the use or purpose of the visible action of the sacrament is changed even as its substance remains the same.\n\nThe Reformed tradition holds that baptism is primarily God's promise or offer of grace to the baptized. Baptism is said to signify union with Christ in his death, burial, and resurrection. The baptized is made one with Christ's person, meaning God the Father treats them the same as he treats Christ. Baptism also unites the baptized with Christ's history, meaning that the person can be said to have died, been buried, and raised again just as Christ was. The baptized person's identity in Christ is based on Christ's action in baptism rather than the person's action. This union also unites Christians to one another. Through the words of institution used in baptism, Christians are also united to each of the members of the trinity.\nIn the Reformed tradition, baptism's function as a rite of initiation into the church is secondary to its function as a sign of God's promise of grace. Reformed theologians distinguish between the visible church, which consists of those who publicly claim to have faith in Christ as well as their children; and the invisible church, which consists of those who actually have faith and have been regenerated. Baptism is believed to make one a member of the visible, rather than the invisible church. It is believed to be impossible to know who is a member of the invisible church. As members of the visible church, baptized Christians are believed to have obligations to live in love and service to Christ and his people. The fulfillment of these obligations is referred to as the \"improvement\" of one's baptism.\n\nReformed Christians see baptism as a replacement of circumcision in the Old Testament. Baptism does everything for New Testament Christians that circumcision did for Jews in the Old Testament. Circumcision is seen as a ritual where God's judgement passes over the person circumcised, only to cut off a part of the flesh, sparing the rest of the person. The \"cutting off\" of Christ in death is seen as a perfection of circumcision, and in baptism similarly the entire body is subjected to judgement and death in order to be raised again in new life.\n\nReformed Christians believe baptism to be a sign of regeneration, or the making of one into a new creature, based on the connection found in the New Testament between regeneration and washing with water. Baptism also represents forgiveness or remission of sin by the sprinkling of the blood of Christ, similarly to the sprinkling of blood of sacrificial animals. Baptism is held by almost the entire Reformed tradition to effect regeneration, even in infants who are incapable of faith, by effecting faith which would come to fruition later. However, Reformed theologians do not teach that baptism is necessarily bound to the forgiveness of sins. Not everyone who participates in the outward rite of baptism can be said to have had their sins forgiven. Rather, it is necessary that the baptized person participate spiritually by faith in order to receive this benefit.\n\nWith some notable exceptions, Reformed Christians baptize infants who are born to believing parents. Reformed Christians do so on the basis of the continuity from the old covenant between God and Israel and the new covenant with the church, since infants were circumcised under the old covenant. They also see God's saving purpose in the new covenant as having to do with families as well as individuals. Because Reformed Christians believe baptism must be embraced by faith to have any benefit, they recognize that faith may come later in life rather than preceding baptism. Infants may also be said to possess a seed of faith which will come to fruition later, or baptism may be administered based on a promise of faith offered by their sponsors (usually their parents) which will be kept at a later age.\n\nReformed Christians believe that immersion is not necessary for baptism to be properly performed, but that pouring or sprinkling are acceptable. Sprinkling is said to symbolize the sprinkling of the blood of Christ for the removal of the guilt of sin. Only ordained ministers are permitted to administer baptism in Reformed churches, contrary to the allowance for emergency baptism by midwives in Roman Catholic churches, though baptisms performed by non-ministers are generally considered valid. Reformed churches, while rejecting the baptismal ceremonies of the Roman Catholic church (such as the use of chrism, salt, and insufflation), accept the validity of baptisms performed with them on the basis that the substance of baptism remains. They do not rebaptize someone who has been baptized using these ceremonies because baptism is never to be repeated.\n\n"}
{"id": "44421636", "url": "https://en.wikipedia.org/wiki?curid=44421636", "title": "Relocation of Marine Corps Air Station Futenma", "text": "Relocation of Marine Corps Air Station Futenma\n\nOver the last five decades there have been various plans for the relocation of Marine Corps Air Station Futenma, a United States Marine Corps base located within the urban area of Ginowan City (pop. 93,661) in Okinawa, Japan.\n\nLocal opposition within Okinawa regarding the facility has so far hindered efforts to begin construction. , the Japanese government had agreed to halt construction activities temporarily while talks with Okinawan officials continued. Still, US sources insisted nothing about their approach had changed.\n\nIn October 2015, despite strong opposition in Okinawa, the Japanese central government began work to build the base in the Henoko Bay, in Nago. The issue has been taken to court by both parties in November 2015 and December 2015. After a tentative court-mediated settlement in March 2016, the national government sued Okinawa governor Takeshi Onaga in July, and obtained a High Court ruling in September determining that it was illegal for Onaga to revoke his predecessor's permission for landfill work at the new site. The Supreme Court of Japan indicated in December that it would let this judgment stand, opening a door for the relocation work to proceed.\n\nOkinawa prefecture constitutes 0.6% of Japan's land surface, yet as of 2006, 75% of all USFJ bases were located on Okinawa, and U.S. military bases occupied 18% of the main island.\n\nThere is local opposition in Okinawa to the construction of a new base; more than 76 per cent of the population having expressed their opposition to a relocation in Henoko.\n\nIn November 2014 Takeshi Onaga, who had run for election on an anti-base platform, was elected Governor of Okinawa. His predecessor and main opponent in the gubernatorial race, Hirokazu Nakaima, had previously opposed the relocation plans himself too; but 11 months before the 2014 election, Nakaima approved a landfill permit allowing the relocation plans to progress, two days after Tokyo earmarked 348 billion yen for Okinawa's economic development.\n\nOne of Japan's most popular filmmakers, Hayao Miyazaki, publicly spoke out in July 2015 against the facility when he argued that most Okinawans are against it.\n\nIn July 15, 2015's daily press briefing at the White House, US Navy Admiral John Kirby said in regards to opposition: \"Construction of the facility is the meaningful result of many years of sustained work between the United States and Japan, and our understanding is that construction’s going to continue. This is something we’ve talked at length about with the Government of Japan. Certainly I’ve seen the reports and understand some of the angst by people in Okinawa, but nothing’s changed about our approach or our policies with respect to that facility. We have, through many different fora, consistently talked about the importance of this relocation and the degrees to which it helps strengthen our alliance with Japan.\"\n\nDeclassified reports indicate the plan to build new runways at Heonko Bay was secretly formulated in the 1960s during the U.S. Military Occupation and Administration of the Islands. Building an expanded base at Henoko has been called the \"only solution\" to resolving the issues at Futenma. The U.S. Military had originally proposed constructing \"an offshore landfill facility with two 3,000-meter runways, a large military port and an integrated ammunition bunker capable of storing nuclear weapons.\" \n\nA separate 260-page report revealed the master plan for U.S. Navy facilities of the base expansion that was submitted by an American company under contract to the Navy in 1966.\n\nThe report states that the U.S. government “should continue to emphasize to the government of Japan that Japan’s security is in large part dependent on the maintenance of a substantial U.S. military posture.”\n\nThe base expansion plan was abandoned over local friction and criticism over the seizure of civilian-owned land and a drawdown of the War in Vietnam.\n\nIn December 1996, as part of the Defense Policy Review Initiative (DPRI), the Japanese and U.S. governments decided that the Futenma base should be relocated to an off-shore location in the Oura Bay of Henoko (\"Ourawan\" in Japanese; often called \"Henoko Bay\"), in Nago, a relatively less populated area of the northern part of the island, 'in order to reduce military impact to the populated communities of southern Okinawa'.\n\nThis was and remains a controversial decision, since the projected site involved construction on a coral reef and seagrass beds inhabited by the dugong, an endangered marine mammal protected under Japanese law and U.S. law. The environmental impact extends beyond the coral reef and seagrass beds, with there expected to be waste dumping, the disruption of fisheries, and an overall decrease in biological diversity. In October 2015, \"The Japan Times\" mentioned that 'two members of a governmental panel monitoring the environmental impact of the Futenma base relocation within Okinawa Prefecture (had) admitted to accepting donations from contractors involved.'\n\nIn a non-binding referendum conducted in December 1997, the majority of Nago residents voted against the Henoko relocation plan. However, a few days later on December 24, Nago Mayor Tetsuya Higa ignored the referendum results and accepted the relocation plan, resigned, and moved to Tokyo. The next year Tateo Kishimoto was elected mayor of Nago and tried to find compromises regarding the relocation. So did his successor Yoshikazu Shimabukuro, at a time when the Prefecture Governor, Masahide Ota, was opposed to the Henoko relocation. The next mayor too, Susumu Inamine, was opposed to it and he was elected twice with a high margin on an anti-base agenda.\n\nThe Henoko Bay plan was reactivated in 2013 by the U.S. and Japanese governments after other projects were abandoned (\"see below\") despite the continued research on the detrimental environmental effects of the base construction.\n\nThe Japanese central government began work on October 29, 2015 to build the base in the Henoko coastal area of Nago, to replace the Futenma Air Station, despite strong opposition among Okinawans and political and legal action initiated by Governor Takeshi Onaga, who insisted the relocation was 'extremely unjust'.\n\nThe opposition to the relocation has received notable support outside of Okinawa, including those of animation film maker Hayao Miyazaki, who will help 'a fund set up to oppose the relocation', of Nobel Prize winner Kenzaburo Oe and of musician Ryuichi Sakamoto. The latter, whose October 2015 single is a charity work in favor of the Henoko Fund, is \"a critic of the national security legislation enacted (in September 2015) (and) said the issue of the heavy U.S. military presence on Okinawa and the contentious security laws share the same root.\"\n\nGreenpeace too gathered signatures of people from 164 countries, in a call for the relocation to be stopped and the coral reef and dugong habitat preserved.\n\nIn November 2015, the \"Asahi Shimbun\" called Japanese Government agenda on the matter an 'obsession'.\n\nIn December 2015, a group of 70 American personalities, including the filmmaker Oliver Stone, criticized the U.S. Ambassador to Japan, Caroline Kennedy, for the support she expressed to the contentious U.S.-Japan relocation plan.\n\nIn June 2016, massive protests took place after the rape and murder of an Okinawan woman by an American base staff member: 'The incidents seem certain to complicate efforts to relocate a Marine air base at Okinawa, to a less densely populated part of the island. Onaga and a majority of Okinawa residents want the base moved off the island.', commmented USA Today.\n\nOn 26 October 2005, the governments of the United States and Japan agreed to move the relocation site for Futenma from the reef area off Henoko to the interior and coastal portions of the existing Marine base at Camp Schwab, just a few hundred meters away from the previously-planned offshore facility. One of the cited reasons for the change was to reduce the engineering challenge associated with building a runway on reefs in deep water: experts estimate that rather than the 15-plus years required to construct a new airbase at the previous reef location, the Camp Schwab plan will enable Futenma to be relocated sooner. These plans were also accelerated when a CH-53D Sea Stallion transport helicopter experienced mechanical issues and of Okinawa International University in August 2004: all three crew members were injured but there were not civilian injuries.\nThe mayor of Nago, which hosts Camp Schwab, formally agreed to accept the relocation when he signed an agreement with Defense Minister Nukaga on 8 April 2006. Mayor Shimabukuro was later joined by all five of the major mayors of northern Okinawa. Although some all-Okinawa public opinion polls indicated that majority of Okinawans wish the based moved out of the prefecture entirely, all 12 elected mayors of northern Okinawa publicly accepted the new relocation plan, exposing a range of conflicting opinions among Okinawans: those who maintain that military facilities and associated public works infrastructure benefit the island's economy, environmentalists, and those who either object or are critical to the U.S. military presence on ideological grounds or on rooted sentiments.\n\nThe relocation plans again gained national attention in 2009 when the Democratic Party of Japan included a promise to move Futenma off the island in its manifesto. After winning the election, Prime Minister Yukio Hatoyama found the promise hard to honor and resigned after only eight months in office when it was confirmed that the base would not move off Okinawa. At one point in 2009, Osaka Prefecture governor Toru Hashimoto even publicly proposed moving the base's functions to Osaka's Kansai International Airport (which is on an artificial island), remarking that \"the burden [of bases on Okinawa] should be spread more evenly throughout Japan.\"\n\nSusumu Inamine, the mayor of Nago city elected on 24 January 2010, and reelected again on 19 January 2013, is against the Henoko relocation plan and argued for the relocation of Futenma outside of Okinawa. The local assembly of Nago voted against the relocation plan, and the prefectural assembly of Okinawa also formally asked the prime minister to move the base out of the prefecture. On 17 May 2010, the anniversary of the reversion of Okinawa to Japan, an estimated 17,000 Okinawans encircled the base in protest. This was the fifth time such an action took place.\n\nIn 2011, the chairman and ranking member of the United States Senate Committee on Armed Services called for an alternative plan where Futenma aircraft would move to Kadena Air Base while the current aircraft at Kadena would move to Andersen Air Force Base. However, US and Japan governments remained with the relocation plan as previously agreed and the fate of Futenma remained unresolved through early 2012, with the U.S. insisting that the Marine Corps' aviation elements be kept on the island while the Okinawa Prefectural government and Nago City government would like the base moved off the island. The US alleged that the aviation elements should be in close proximity to the ground and logistics elements of the Marine Air Ground Task Force, and the Japanese government of the time maintained the plan to keep the replacement airbase within Okinawa.\n\nThe US and Japan delinked the relocation of Futenma from plans to decrease the number of Marines stationed on Okinawa under a troop redeployment agreement in April 2012. Under the terms of the new U.S.-Japan agreement, 5,000 U.S. Marines were to be relocated to Guam and 4,000 U.S. Marines to other Pacific locations such as Hawaii or Australia, while some 10,000 Marines would remain on Okinawa. No timetable for the Marines redeployment was announced, but the Washington Post reported that U.S. Marines would leave Futenma as soon as suitable facilities on Guam and elsewhere would be ready. The relocation move was expected to cost 8.6 billion US Dollars and included a $3.1 billion cash commitment from Japan for the move to Guam as well as for developing joint training ranges on Guam and on Tinian and Pagan in the Commonwealth of the Northern Mariana Islands.\n\nDuring this period, the US began to deploy Bell Boeing V-22 Osprey tilt rotor aircraft to Futenma in 2012, allowing the Marines (and the MV-22B Osprey aircraft) from Okinawa to train all along the length of Japan and around the entire Asia-Pacific region, with the Osprey's greatly increased speed, lift capabilities and range.\n\nIn April 2013, the United States and Japan released an \"Okinawa Consolidation Plan,\" which detailed more general positions of the 1996 DPRI and 2006 SACO plans, specifying 2,500 acres of land to be returned Japan. This included returning the entirety of MCAS Futenma by \"Japanese Fiscal Year 2022 or later\" once the \"replacement facilities in Okinawa are provided.\" As part of the original DPRI plan, Futenma's KC-130J 'Super Hercules' refueling transport squadron moved to MCAS Iwakuni on mainland Japan in July 2014. The plan also included, as in previous plans, moving Marine Corps airfield facilities to Camp Schwab at Henoko. The proposed location within Camp Schwab is insulated from potential protesters, unlike the previous proposed location in Henoko Bay where local civilians were able to enter the survey area.\n\nIn December 2013, Okinawa Governor Hirokazu Nakaima approved a landfill proposal by the Japanese government to permit construction of new military facilities in Henoko, a move praised by the US. The decision came two days after Tokyo earmarked 348 billion yen for Okinawa's economic development and despite earlier campaign promises by Nakaima to move the base outside of the prefecture all together. Over 2,000 citizens responded immediately with a protest in front of the prefectural administration building, with around 1,000 forcing their way into the building to stage a sit-in. The head of the Nago municipal assembly responded that \"what the governor has done is unforgivable. Residents who are opposed will surely resort to the use of force, such as blocking roads to stop this from happening.\" The Okinawa prefectural assembly adopted a resolution by a 24–21 vote calling for Nakaima's resignation, stating that he broke an election promise by agreeing to the move.\n\nSusumu Inamine, Mayor of Nago, where the new facility is to be built, opposed the plan, while Mayor Atsushi Sakima, of Ginowan where the current facility is located, supported the plan. Nago held a mayoral election in January 2014, in which Inamine's main rival, former Vice Mayor Bunshin Suematsu, supported the plan as \"a significant step toward reducing the dangers posed by Futenma.\" Inamine won the election and subsequently vowed to block any landfill plans in the city, but the national government said it would continue with the plan and that the authority to approve the plan rested at the time with the governor of Okinawa.\n\nTakeshi Onaga, running on an anti-base platform, won the November 2014 gubernatorial elections in Okinawa promising to veto any landfill work needed for the new base to be built. In March 2015, Onaga ordered a suspension of work on the new base, and in August 2015 the Japanese government agreed to halt construction activities temporarily while talks with Okinawan officials continued.\n\nIn November 2015, George Washington University professor Mike Mochizuki explained that \"an option of setting up a helicopter base at Marine Corps Camp Schwab in Nago could be considered instead of the current plan to build runways in the camp that would extend offshore\" \"The option was included in a 1996 report by the Special Action Committee on Okinawa between the two countries.\", noted the \"Japan Times\".\n\n\"Japanese officials in the ruling and opposition parties had in the past suggested Kyushu and Hokkaido as alternatives to Henoko.\" In November 2015 a group of 'traditionally anti-base activist' citizens from Kansai called for Futenma’s replacement airstrip to be built in Osaka, in \"hope to lighten Okinawa’s base-hosting burden and prevent an escalation of violence.\"\n\n"}
{"id": "27760875", "url": "https://en.wikipedia.org/wiki?curid=27760875", "title": "Solana Valley", "text": "Solana Valley\n\nSolana Valley (Spanish language \"Valle de la Solana\"; Aragonese language \"Val d'a Solana\") is a valley in the Pyrenees. It is located in Aragon, Spain. River Ara cuts across the valley from east to west and its average altitude is 850 m.\n\nThere were many villages in Solana Valley. The inhabitants left the place between 1960 and 1970 owing to the pressure induced by ICONA, the Spanish National Institute for Forestal recovery that had bought the land surrounding the villages. There were other factors as well, such as the abandonment of traditional agricultural practices like sheep and goat rearing, as well as the lifestyle changes that swept over rural Spain after General Franco's \"Plan de Estabilización\" that pulled the local youth towards the cities and the coast.\n\nMost of Solana Valley's territory depends administratively from Fiscal, Sobrarbe comarca, Huesca Province.\n\nIn Solana Valley there are numerous village churches and smaller religious buildings worth visiting, such as the \"Iglesia de la Asunción\" and the exconjuratory in Burgasé, the \"Iglesia de Santa María\" in Muro de Solana, Santiago Church in Villamana and Saint Peter's Church in Gere. Many of the churches are in ruins.\n\nThe villages in the valley lie abandoned and the houses have fallen into disrepair and ruin:\n\n\n"}
{"id": "50365786", "url": "https://en.wikipedia.org/wiki?curid=50365786", "title": "Sources of electrical energy", "text": "Sources of electrical energy\n\nThis article provides information on the following six methods of producing electricity.\n\nFriction is the least methods which you provide of the six methods of producing energy. If a cloth rubs against an object, the object will display an effect called friction electricity. The object becomes charged due to the rubbing process, and now possesses an electrical charge. There are two main types of electrical charge: positive and negative. Each type of charge attracts the opposite type and repels the same type. This can be stated in the following way: Like charges repel and unlike charges attract. Static electricity has several applications. Its main application is in Van de Graaff generators, used to produce high voltages in order to test the dialectric strength of insulating materials. Other uses are in electrostatic painting and sandpaper manufacturing. The course grains acquire a negative charge as they move across the negative plate. As unlike charges attract, the positive plate attracts the course grains and their impact velocity enables them to be embedded into the adhesive.\n\nIn 1821 Thomas Seebeck discovered that the junction between two metals generates a voltage that is a function of temperature. If a closed circuit consists of conductors of two different metals, and if one junction of the two metals is at a higher temperature than the other, an electromotive force is created in a specific polarity. An example of this is in the case of copper and iron, the electrons first flow along the iron from the hot junction to the cold one. The electrons cross from the iron to the copper at the hot junction, and from the copper to the iron at the cold junction. This property of electromotive force production is known as the Seebeck effect. This effect is utilized in the most widely employed method of thermometry.\n\nThe sun's rays can be used to produce electrical energy. The direct user of sunlight is the solar cell or photovoltaic cell, which converts sunlight directly into electrical energy without the incorporation of a mechanical device. This technology is simpler than the fossil-fuel-driven systems of producing electrical energy. A solar cell is formed by a light-sensitive p-n junction semiconductor, which when exposed to sunlight is excited to conduction by the photons in light. When light, in the form of photons, hits the cell and strikes an atom, photo-ionisation creates electron-hole pairs. The electrostatic field causes separation of these pairs, establishing an electromotive force in the process. The electric field sends the electron to the p-type material, and the hole to the n-type material. If an external current path is provided, electrical energy will be available to do work. The electron flow provides the current, and the cell's electric field creates the voltage. With both current and voltage the silicon cell has power. The greater the amount of light falling on the cell's surface, the greater is the probability of photons releasing electrons, and hence more electric energy is produced.\n\nWhen a zinc electrode and copper electrode are placed in a dilute solution of sulfuric acid, the two metals react to each other's presence within the electrolyte and develop a potential difference of about 1 volt between them. When a conducting path joins the electrodes externally, the zinc electrode dissolves slowly into the acid electrolyte, The zinc molecule goes into the electrolyte in the form of positive ions while its electrons are left on the electrode. The copper electrode on the other hand does not dissolve in the electrolyte. Instead it gives up its electrons to the positively charged ions of hydrogen in the electrolyte, turning them into molecules of hydrogen gas that bubble up around the electrode. The zinc ion combines with the sulfate ion to form zinc sulfate, and this salt falls to the bottom of the cell. The effect of all this is that the dissolving zinc electrode becomes negatively charged, the copper electrode is left with a positive charge and electrons from the zinc pass through the external circuit to the copper electrode.\n\nThe molecules of some crystals and ceramics are permanently polarised: some parts of the molecule are positively charged, while other parts are negatively charged. These materials produce an electric charge when the material changes dimension as a result of an imposed external force. The charge produced is referred to as piezoelectricity. Many crystalline materials such as the natural crystals of quartz and rochelle salted together with manufactured polycrystalline ceramics such as lead titanate zirconate and barium titanate exhibit piezoelectric effects. Piezoelectric materials are used as buzzers inside pagers, ultrasonic cleaners and mobile phones, and in gas igniters. In addition, these piezoelectric sensors are able to convert pressure, force, vibration or shock into electrical energy. Being capable only of measuring active events, they are also used in flow meters, accelerometers and level detectors, as well as motor vehicles to sense changes in the transmission, fuel injection and coolant pressure. When a voltage or an applied electric field stresses a piezo element electrically, its dimensions change. This phenomenon is known as electrostriction, or the reverse piezoelectric effect. This effect enables the element to act as a translating device called an actuator. Piezoelectric materials are used in power actuators, converting electrical energy into mechanical energy, and in acoustic transducers, converting electric fields into sound waves.\n\nThe most useful and widely employed application of magnetism is in the production of electrical energy. The mechanical power needed to assist in this production is provided by a number of different sources. These sources are called prime movers, and include diesel, petrol and natural gas engines. Coal, oil, natural gas, biomass and nuclear energy are energy sources that are used to heat water to produce super-heated steam. Non-mechanical prime movers include water, steam, wind, wave motion and tidal current. These non-mechanical prime movers engage a turbine that is coupled to a generator. Generators that employ the principle of electro-magnetic induction carry out the final conversion of these energy sources. In order to do this, three necessary conditions must exist before a voltage is created by magnetism: movement, conductors and a magnetic field.\n\nIn accordance with these conditions, when a conductor or conductors move through a magnetic field to cut the lines of force, electrons are enabled to enter the conduction band thereby inducing an electric pressure for the production of alternating current in an external circuit. This may be referred to as an elementary alternator, consisting of a single wire loop called an armature with each end being attached to slip-rings and arranged so as to revolve midway between the magnetic poles. Two copper-graphite brushes connect with the external circuit on the slip-rings in order to collect the alternating current, generated in the conductor when the alternator is in operation. Another machine used for converting mechanical energy into electrical energy by means of electromagnetic induction is called a dynamo or direct current generator.\n\nThe key difference between an alternator and a generator is that the alternator delivers AC (alternating current) to the external circuit, while the generator delivers DC (direct current). In both machines alternating current is induced in the armature, but the type of current delivered to the external circuit depends on the way in which the induced current is collected. In an alternator, the current is collected brushes bearing against slip-rings; in a generator, a form of rotating switch called the commutator is placed between the armature and the external circuit. The commutator is designed to reverse the connections with the external circuit at the instant of each reversal of induced current in the armature, producing rectified current or direct current. This rectified current is not pure like the current of a voltaic cell but is instead a pulsating current that is constant in direction and varying in intensity.\n"}
{"id": "266344", "url": "https://en.wikipedia.org/wiki?curid=266344", "title": "Space debris", "text": "Space debris\n\nInitially, the term space debris referred to the natural debris found in the solar system: asteroids, comets, and meteoroids. However, with the 1979 beginning of the NASA Orbital Debris Program, the term also refers to the debris (alt. space waste or space garbage) from the mass of defunct, artificially created objects in space, especially Earth orbit. These include old satellites and spent rocket stages, as well as the fragments from their disintegration and collisions. \n\nAs of December 2016, five satellite collisions have generated space debris. Space debris is also known as \"orbital debris\", \"space junk\", \"space waste\", \"space trash\", \"space litter\" or \"space garbage\".\n, the United States Strategic Command tracked a total of 17,852 artificial objects in orbit above the Earth, including 1,419 operational satellites. However, these are just objects large enough to be tracked. , more than 170 million bits of debris smaller than , about 670,000 pieces of debris 1–10 cm, and around 29,000 larger pieces were estimated to be in orbit around the earth. Collisions with debris have become a hazard to spacecraft; they cause damage akin to sandblasting, especially to solar panels and optics like telescopes or star trackers that cannot be covered with a ballistic Whipple shield (unless it is transparent).\n\nBelow Earth-altitude, pieces of debris are denser than meteoroids; most are dust from solid rocket motors, surface erosion debris like paint flakes, and frozen coolant from RORSAT (nuclear-powered satellites). \nFor comparison, the International Space Station orbits in the range, and the 2009 satellite collision and 2007 antisat test occurred at altitude. The ISS has Whipple shielding; however, known debris with a collision chance over 1/10,000 are avoided by maneuvering the station.\n\nThe Kessler syndrome, a runaway chain reaction of collisions exponentially increasing the amount of debris, has been hypothesized to ensue beyond a critical density. This could affect useful polar-orbiting bands, increases the cost of protection for spacecraft missions and could destroy live satellites. Whether Kessler syndrome is already underway has been debated. The measurement, mitigation, and potential removal of debris are conducted by some participants in the space industry.\n\nThere are estimated to be over 51 million pieces of debris smaller than as of July 2013. There are approximately 670,000 pieces from one to ten cm. The current count of large debris (defined as 10 cm across or larger) is 29,000. The technical measurement cutoff is c. . Over 98 percent of the 1,900 tons of debris in low Earth orbit (as of 2002) was accounted for by about 1,500 objects, each over . Total mass is mostly constant despite addition of many smaller objects, since they reenter the atmosphere sooner. Using a 2008 figure of 8,500 known items, it is estimated at .\n\nIn LEO there are few \"universal orbits\" which keep spacecraft in particular rings (in contrast to GEO, a single widely used orbit). The closest are sun-synchronous orbits that keep a constant angle between the Sun and the orbital plane; they are polar, meaning they cross over the polar regions. LEO satellites orbit in many planes, up to 15 times a day, causing frequent approaches between objects (the density of objects is much higher in LEO).\n\nOrbits are further changed by perturbations (which in LEO include unevenness of the Earth's gravitational field), and collisions can occur from any direction. For these reasons, the Kessler syndrome applies mostly to the LEO region; impacts occur at up to 16 km/s (twice the orbital speed) if head-on – the 2009 satellite collision occurred at 11.7 km/s, creating much spall in the critical size range. These can cross other orbits and lead to a cascade effect. A large-enough collision (e.g. between a space station and a defunct satellite) could make low Earth orbit impassable.\n\nManned missions are mostly at and below, where air drag helps clear zones of fragments. Atmospheric expansion as a result of space weather raises the critical altitude by increasing drag; in the 90s, it was a factor in reduced debris density. Another was fewer launches by Russia; the USSR made most of their launches in the 1970s and 1980s.\n\nAt higher altitudes, where air drag is less significant, orbital decay takes longer. Slight atmospheric drag, lunar perturbations, Earth's gravity perturbations, solar wind and solar radiation pressure can gradually bring debris down to lower altitudes (where it decays), but at very high altitudes this may take millennia. Although high-altitude orbits are less commonly used than LEO and the onset of the problem is slower, the numbers progress toward the critical threshold more quickly.\n\nMany communications satellites are in geostationary orbits (GEO), clustering over specific targets and sharing the same orbital path. Although velocities are low between GEO objects, when a satellite becomes derelict (such as Telstar 401) it assumes a geosynchronous orbit; its orbital inclination increases about .8° and its speed increases about per year. Impact velocity peaks at about . Orbital perturbations cause longitude drift of the inoperable spacecraft and precession of the orbital plane. Close approaches (within 50 meters) are estimated at one per year. The collision debris pose less short-term risk than from an LEO collision, but the satellite would likely become inoperable. Large objects, such as solar-power satellites, are especially vulnerable to collisions.\n\nAlthough the ITU now requires proof a satellite can be moved out of its orbital slot at the end of its lifespan, studies suggest this is insufficient. Since GEO orbit is too distant to accurately measure objects under , the nature of the problem is not well known. Satellites could be moved to empty spots in GEO, requiring less maneuvring and making it easier to predict future motion. Satellites or boosters in other orbits, especially stranded in geostationary transfer orbit, are an additional concern due to their typically high crossing velocity.\n\nDespite efforts to reduce risk, spacecraft collisions have occurred. The European Space Agency telecom satellite Olympus-1 was struck by a meteoroid on 11 August 1993 and eventually moved to a graveyard orbit. On 29 March 2006, the Russian Express-AM11 communications satellite was struck by an unknown object and rendered inoperable; its engineers had enough contact time with the satellite to send it into a graveyard orbit.\n\nIn 1958, the United States launched Vanguard I into a medium Earth orbit (MEO). , it, and the upper stage of its launch rocket, are the oldest surviving man-made space objects still in orbit. In a catalog of known launches until July 2009, the Union of Concerned Scientists listed 902 operational satellites from a known population of 19,000 large objects and about 30,000 objects launched.\n\nAn example of additional dead satellite debris are the remains of the 1970s/80s Soviet RORSAT naval surveillance satellite program. The satellite's BES-5 nuclear reactor were cooled with a coolant loop of sodium-potassium alloy, creating a potential problem when the satellite reached end of life. While many satellites were nominally boosted into medium-altitude graveyard orbits, not all were. Even satellites which had been properly moved to a higher orbit had an eight-percent probability of puncture and coolant release over a 50-year period. The coolant freezes into droplets of solid sodium-potassium alloy, forming additional debris.\n\nThese events continue to occur. For example, in February 2015, the USAF Defense Meteorological Satellite Program Flight 13 (DMSP-F13) exploded on orbit, creating at least 149 debris objects, which were expected to remain in orbit for decades.\n\nAccording to Edward Tufte's book \"Envisioning Information\", space debris includes a glove lost by astronaut Ed White on the first American space-walk (EVA); a camera lost by Michael Collins near Gemini 10; a thermal blanket lost during STS-88; garbage bags jettisoned by Soviet cosmonauts during Mir's 15-year life, a wrench and a toothbrush. Sunita Williams of STS-116 lost a camera during an EVA. During an STS-120 EVA to reinforce a torn solar panel, a pair of pliers was lost, and in an STS-126 EVA, Heidemarie Stefanyshyn-Piper lost a briefcase-sized tool bag.\n\nIn characterizing the problem of space debris, it was learned that much debris was due to rocket upper stages (e.g. the Inertial Upper Stage) which end up in orbit, and break up due to decomposition of unvented unburned fuel. However, a major known impact event involved an (intact) Ariane booster. Although NASA and the United States Air Force now require upper-stage passivation, other launchers do not.\nLower stages, like the Space Shuttle's solid rocket boosters or Apollo program's Saturn IB launch vehicles, do not reach orbit.\n\nOn 11 March 2000 a Chinese Long March 4 CBERS-1 upper stage exploded in orbit, creating a debris cloud.\nA Russian Briz-M booster stage exploded in orbit over South Australia on 19 February 2007. Launched on 28 February 2006 carrying an Arabsat-4A communications satellite, it malfunctioned before it could use up its propellant. Although the explosion was captured on film by astronomers, due to the orbit path the debris cloud has been difficult to measure with radar. By 21 February 2007, over 1,000 fragments were identified. A 14 February 2007 breakup was recorded by Celestrak. Eight breakups occurred in 2006, the most since 1993. Another Briz-M broke up on 16 October 2012 after a failed 6 August Proton-M launch. The amount and size of the debris was unknown. A Long March 7 rocket booster created a fireball visible from portions of Utah, Nevada, Colorado, Idaho and California on the evening of 27 July 2016; its disintegration was widely reported on social media.\n\nA past debris source was the testing of anti-satellite weapons (ASATs) by the U.S. and Soviet Union during the 1960s and 1970s. North American Aerospace Defense Command (NORAD) files only contained data for Soviet tests, and debris from U.S. tests were only identified later. By the time the debris problem was understood, widespread ASAT testing had ended; the U.S. Program 437 was shut down in 1975.\n\nThe U.S. restarted their ASAT programs in the 1980s with the Vought ASM-135 ASAT. A 1985 test destroyed a satellite orbiting at , creating thousands of debris larger than . Due to the altitude, atmospheric drag decayed the orbit of most debris within a decade. A \"de facto\" moratorium followed the test.\n\nChina's government was condemned for the military implications and the amount of debris from the 2007 anti-satellite missile test, the largest single space debris incident in history (creating over 2,300 pieces golf-ball size or larger, over 35,000 or larger, and one million pieces or larger). The target satellite orbited between and , the portion of near-Earth space most densely populated with satellites. Since atmospheric drag is low at that altitude the debris is slow to return to Earth, and in June 2007 NASA's Terra environmental spacecraft maneuvered to avoid impact from the debris.\n\nOn 20 February 2008, the U.S. launched an SM-3 missile from the USS \"Lake Erie\" to destroy a defective U.S. spy satellite thought to be carrying of toxic hydrazine propellant. The event occurred at about , and the resulting debris has a perigee of or lower. The missile was aimed to minimize the amount of debris, which (according to Pentagon Strategic Command chief Kevin Chilton) had decayed by early 2009.\n\nThe vulnerability of satellites to debris and the possibility of attacking LEO satellites to create debris clouds, has triggered speculation that it is possible for countries unable to make a precision attack. An attack on a satellite of 10 tonnes or more would heavily damage the LEO environment.\n\nSpace junk is a threat to active satellites and spaceships. The Earth's orbit may even become impassable as the risk of collision grows too high.\n\nAlthough spacecraft are protected by Whipple shields, solar panels, which are exposed to the Sun, wear from low-mass impacts. These produce a cloud of plasma which is an electrical risk to the panels.\n\nSatellites are believed to have been destroyed by micrometeorites and orbital debris (MMOD). The earliest suspected loss was of Kosmos 1275, which disappeared on 24 July 1981 (a month after launch). Kosmos contained no volatile propellant, therefore, there appeared to be nothing internal to the satellite which could have caused the destructive explosion which took place. However the case has not been proven and another hypothesis forwarded is that the battery exploded. Tracking showed it broke up, into 300 new objects.\n\nMany impacts have been confirmed since. Olympus-1 was struck by a meteoroid on 11 August 1993, and left adrift. On 24 July 1996, the French microsatellite Cerise was hit by fragments of an Ariane-1 H-10 upper-stage booster which exploded in November 1986. On 29 March 2006, the Russian Ekspress AM11 communications satellite was struck by an unknown object and rendered inoperable; its engineers had sufficient time in contact with the spacecraft to send it to a parking orbit out of GEO. On October 13, 2009, Terra suffered a single battery cell failure anomaly and a battery heater control anomaly which were likely the result of an MMOD strike. On March 12, 2010, Aura lost power from one-half of one of its 11 solar panels and this was also attributed to an MMOD strike. On May 22, 2013 GOES-13 was hit by an MMOD which caused it to lose track of the stars that it uses to maintain attitude. It took nearly a month for the spacecraft to return to operation.\n\nThe first major satellite collision occurred on 10 February 2009 at 16:56 UTC. The deactivated Kosmos 2251 and the operational Iridium 33 collided, over northern Siberia. The relative speed of impact was about , or about . Both satellites were destroyed, with accurate estimates of the number of debris unavailable. On 22 January 2013 BLITS (a Russian laser-ranging satellite) was struck by debris suspected to be from the 2007 Chinese anti-satellite missile test, changing its orbit and spin rate.\n\nSatellites frequently have to perform Collision Avoidance Maneuvers and managers have to monitor debris as part of maneuver planning. For example, in January 2017, the European Space Agency planned to alter orbit of one of its $319 million Swarm mission spacecrafts, based on data from the US Joint Space Operations Center, to end the risk of collision from Cosmos-375, an old Russian satellite. Cosmos-375, which was destroyed by Soviet operators when its mission was complete, had previously threatened to impact the International Space Station in 2011.\n\nFrom the early Space Shuttle missions, NASA used NORAD to monitor the Shuttle's orbital path for debris. In the 1980s, this used much of its capacity. The first collision-avoidance maneuver occurred during STS-48 in September 1991, a seven-second thruster burn to avoid debris from Kosmos 955. Similar maneuvers followed on missions 53, 72 and 82.\n\nOne of the first events to publicize the debris problem occurred on \"Challenger\"'s second flight, STS-7. A fleck of paint struck its front window, creating a pit over wide. On STS-59 in 1994, \"Endeavour\"'s front window was pitted about half its depth. Minor debris impacts increased from 1998.\n\nWindow chipping and minor damage to thermal protection system tiles (TPS) was already common by the 1990s. The Shuttle was later flown tail-first to take the debris load mostly on the engines and rear cargo bay (not used in orbit or during descent, and less critical for post-launch operation). When flying to the ISS, the two connected spacecraft were flipped around so the better-armored station shielded the orbiter.\nNASA's study concluded that debris accounted for half of the overall risk to the Shuttle. Executive-level decision to proceed was required if catastrophic impact was likelier than 1 in 200. On a normal (low-orbit) mission to the ISS the risk was c. 1 in 300, but STS-125 (the Hubble repair mission) at was initially calculated at a 1-in-185 risk (due to the 2009 satellite collision). A re-analysis with better debris numbers reduced the estimated risk to 1 in 221, and the mission went ahead.\n\nDebris incidents continued on later Shuttle missions. During STS-115 in 2006 a fragment of circuit board bored a small hole through the radiator panels in \"Atlantis\"' cargo bay. On STS-118 in 2007 debris blew a bullet-like hole through \"Endeavour\"s radiator panel.\n\nImpact wear was notable on Mir, the Soviet space station, since it remained in space for long periods with its original module panels.\n\nAlthough the ISS uses Whipple shielding to protect itself from minor debris, portions (notably its solar panels) cannot be protected easily. In 1989, the ISS panels were predicted to degrade c. 0.23% in four years, and they were overdesigned by 1%. A maneuver is performed if \"there is a greater than one-in-10,000 chance of a debris strike\". , there have been sixteen maneuvers in the fifteen years the ISS had been in orbit.\n\nThe crew sheltered in the Soyuz on three occasions due to late debris-proximity warnings. In addition to the sixteen firings and three Soyuz-capsule shelter orders, one attempted maneuver failed (due to not having the several days' warning necessary to upload the manoeuvre timeline to the station's computer). A March 2009 close call involved debris believed to be a piece of the Kosmos 1275 satellite. In 2013, the ISS did not maneuver to avoid debris, after a record four debris maneuvers the previous year.\n\nAlthough most manned space activity takes place at altitudes below , a Kessler syndrome cascade in that region would rain down into lower altitudes and the decay time scale is such that \"the resulting [low Earth orbit] debris environment is likely to be too hostile for future space use\".\n\nIn a Kessler syndrome, satellite lifetimes would be measured in years or months. New satellites could be launched through the debris field into higher orbits or placed in lower orbits (where decay removes the debris), but the utility of the region between is the reason for its amount of debris.\n\nAlthough most debris burns up in the atmosphere, larger objects can reach the ground intact. According to NASA, an average of one cataloged piece of debris has fallen back to Earth each day for the past 50 years. Despite their size, there has been no significant property damage from the debris.\n\nIn 1969 five sailors on a Japanese ship were injured by space debris. In 1997 an Oklahoma woman, Lottie Williams, was injured when she was hit in the shoulder by a piece of blackened, woven metallic material confirmed as part of the propellant tank of a Delta II rocket which launched a U.S. Air Force satellite the year before.\n\nThe original re-entry plan for Skylab called for the station to remain in space for eight to ten years after its final mission in February 1974. High solar activity expanded the upper atmosphere, resulting in higher-than-expected drag and bringing its orbit closer to Earth than planned. On 11 July 1979 Skylab re-entered the Earth's atmosphere and disintegrated, raining debris along a path over the southern Indian Ocean and Western Australia.\n\nOn 12 January 2001, a Star 48 Payload Assist Module (PAM-D) rocket upper stage re-entered the atmosphere after a \"catastrophic orbital decay\", crashing in the Saudi Arabian desert. It was identified as the upper-stage rocket for NAVSTAR 32, a GPS satellite launched in 1993.\n\nIn the 2003 \"Columbia\" disaster, large parts of the spacecraft reached the ground and entire equipment systems remained intact. More than 83,000 pieces, along with the remains of the six astronauts, were recovered in an area from three to 10 miles around Hemphill in Sabine County, TX. More pieces were found in a line from west Texas to east Louisiana, with the westernmost piece found in Littlefield, TX and the easternmost found southwest of Mora, LA. Although there is significant evidence that debris fell in Nevada, Utah, and New Mexico, debris was only found in Texas, Arkansas and Louisiana. In a rare case of property damage, a foot-long metal bracket smashed through the roof of a dentist office. NASA warned the public to avoid contact with the debris because of the possible presence of hazardous chemicals. 15 years after the failure, people were still sending in pieces with the last,as of February 1, 2018, found in the spring of 2017.\n\nOn 27 March 2007, airborne debris from a Russian spy satellite was seen by the pilot of a LAN Airlines Airbus A340 carrying 270 passengers whilst flying over the Pacific Ocean between Santiago and Auckland. The debris was within of the aircraft.\n\nRadar and optical detectors such as lidar are the main tools for tracking space debris. Although objects under have reduced orbital stability, debris as small as 1 cm can be tracked, however determining orbits to allow re-acquisition is difficult. Most debris remain unobserved. The NASA Orbital Debris Observatory tracked space debris with a liquid mirror transit telescope. FM Radio waves can detect debris, after reflecting off them onto a receiver. Optical tracking may be a useful early-warning system on spacecraft.\n\nThe U.S. Strategic Command keeps a catalog of known orbital objects, using ground-based radar and telescopes, and a space-based telescope (originally to distinguish from hostile missiles). The 2009 edition listed about 19,000 objects. Other data come from the ESA Space Debris Telescope, TIRA, the Goldstone, Haystack, and EISCAT radars and the Cobra Dane phased array radar, to be used in debris-environment models like the ESA Meteoroid and Space Debris Terrestrial Environment Reference (MASTER).\n\nReturned space hardware is a valuable source of information on the directional distribution and composition of the (sub-millimetre) debris flux. The LDEF satellite deployed by mission STS-41-C \"Challenger\" and retrieved by STS-32 \"Columbia\" spent 68 months in orbit to gather debris data. The EURECA satellite, deployed by STS-46 \"Atlantis\" in 1992 and retrieved by STS-57 \"Endeavour\" in 1993, was also used for debris study.\n\nThe solar arrays of Hubble were returned by missions STS-61 \"Endeavour\" and STS-109 \"Columbia\", and the impact craters studied by the ESA to validate its models. Materials returned from Mir were also studied, notably the Mir Environmental Effects Payload (which also tested materials intended for the ISS).\n\nA debris cloud resulting from a single event is studied with scatter plots known as Gabbard diagrams, where the perigee and apogee of fragments are plotted with respect to their orbital period. Gabbard diagrams of the early debris cloud prior to the effects of perturbations, if the data were available, are reconstructed. They often include data on newly observed, as yet uncatalogued fragments. Gabbard diagrams can provide important insights into the features of the fragmentation, the direction and point of impact.\n\nAn average of about one tracked object per day has been dropping out of orbit for the past 50 years, averaging almost three objects per day at solar maximum (due to the heating and expansion of the Earth's atmosphere), but one about every three days at solar minimum, usually 5½ yr later. In addition to natural atmospheric effects, corporations, academics and government agencies have proposed plans and technology to deal with space debris, but , most of these are theoretical, and there is no extant business plan for debris reduction.\n\nA number of scholars have also observed that institutional factors—political, legal, economic and cultural \"rules of the game\"—are the greatest impediment to the cleanup of near-Earth space. There is no commercial incentive, since costs aren't assigned to polluters, but a number of suggestions have been made. However, effects to date are limited. In the US, governmental bodies have been accused of backsliding on previous commitments to limit debris growth, \"let alone tackling the more complex issues of removing orbital debris.\"\n\nUpper stage passivation (e.g. of Delta boosters) by releasing residual propellants reduces debris from orbital explosions; however not all boosters implement this. Although there is no international treaty minimizing space debris, the United Nations Committee on the Peaceful Uses of Outer Space (COPUOS) published voluntary guidelines in 2007. As of 2008, the committee is discussing international \"rules of the road\" to prevent collisions between satellites.\nBy 2013, various legal regimes existed, typically instantiated in the launch licenses that are required for a launch in all spacefaring nations.\n\nThe U.S. has a set of standard practices for civilian (NASA) and military (DoD and USAF) orbital-debris mitigation, as has the European Space Agency. In 2007, the ISO began preparing an international standard for space-debris mitigation. Germany and France have posted bonds to safeguard property from debris damage.\n\nWhen originally proposed in 2015, the OneWeb constellation, initially planned to have ~700 satellites anticipated on orbit after 2018, would only state that they would re-enter the atmosphere within 25 years of retirement.\nBy October 2017, both OneWeb—and also SpaceX, with their large Starlink constellation—had filed documents with the US FCC with more aggressive space debris mitigation plans. Both companies committed to a deorbit plan for post-mission satellites which will explicitly move the satellites into orbits where they will reenter the Earth's atmosphere within approximately one year following end-of-life.\n\nWith a \"one-up, one-down\" launch-license policy for Earth orbits, launchers would rendezvous with, capture and de-orbit a derelict satellite from approximately the same orbital plane. Another possibility is the robotic refueling of satellites. Experiments have been flown by NASA, and SpaceX is developing large-scale on-orbit propellant transfer technology and tanker spacecraft.\n\nAnother approach to debris mitigation is to explicitly design the mission architecture to always leave the rocket second-stage in an elliptical geocentric orbit with a low-perigee, thus ensuring rapid orbital decay and avoiding long-term orbital debris from spent rocket bodies. Such missions require the use of a small kick stage to circularize the orbit, but the kick stage itself may be designed with the excess-propellant capability to be able to self-deorbit.\n\nAlthough the ITU requires geostationary satellites to move to a graveyard orbit at the end of their lives, the selected orbital areas do not sufficiently protect GEO lanes from debris. Rocket stages (or satellites) with enough propellant may make a direct, controlled de-orbit, or if this would require too much propellant, a satellite may be brought to an orbit where atmospheric drag would cause it to eventually de-orbit. This was done with the French Spot-1 satellite, reducing its atmospheric re-entry time from a projected 200 years to about 15 by lowering its altitude from to about .\n\nPassive methods of increasing the orbital decay rate of spacecraft debris have been proposed. Instead of rockets, an electrodynamic tether could be attached to a spacecraft at launch; at the end of its lifetime, the tether would be rolled out to slow the spacecraft. Other proposals include a booster stage with a sail-like attachment and a large, thin, inflatable balloon envelope.\n\nA consensus of speakers at a meeting in Brussels on 30 October 2012 organized by the Secure World Foundation (a U.S. think tank) and the French International Relations Institute reported that removal of the largest debris would be required to prevent the risk to spacecraft becoming unacceptable in the foreseeable future (without any addition to the inventory of dead spacecraft in LEO). Removal costs and legal questions about ownership and the authority to remove defunct satellites have stymied national or international action. Current space law retains ownership of all satellites with their original operators, even debris or spacecraft which are defunct or threaten active missions.\n\nA well-studied solution uses a remotely controlled vehicle to rendezvous with, capture and return debris to a central station.\nOne such system is Space Infrastructure Servicing, a commercially developed refueling depot and service spacecraft for communications satellites in geosynchronous orbit originally scheduled for a 2015 launch. The SIS would be able to \"push dead satellites into graveyard orbits.\" The Advanced Common Evolved Stage family of upper stages is being designed with a high leftover-propellant margin (for derelict capture and de-orbit) and in-space refueling capability for the high delta-v required to de-orbit heavy objects from geosynchronous orbit. A tug-like satellite to drag debris to a safe altitude for it to burn up in the atmosphere has been researched. When debris is identified the satellite creates a difference in potential between the debris and itself, then using its thrusters to move itself and the debris to a safer orbit.\n\nA variation of this approach is for the remotely controlled vehicle to rendezvous with debris, capture it temporarily to attach a smaller de-orbit satellite and drag the debris with a tether to the desired location. The \"mothership\" would then tow the debris-smallsat combination for atmospheric entry or move it to a graveyard orbit. One such system is the proposed Busek ORbital DEbris Remover (ORDER), which would carry over 40 SUL (satellite on umbilical line) de-orbit satellites and propellant sufficient for their removal.\nOn 7 January 2010 Star, Inc. reported that it received a contract from the Space and Naval Warfare Systems Command for a feasibility study of the ElectroDynamic Debris Eliminator (EDDE) propellantless spacecraft for space-debris removal.\nIn February 2012 the Swiss Space Center at École Polytechnique Fédérale de Lausanne announced the Clean Space One project, a nanosatellite demonstration project for matching orbit with a defunct Swiss nanosatellite, capturing it and de-orbiting together. The mission has seen several evolutions to reach a pac-man inspired capture model.\n\nThe laser broom uses a ground-based laser to ablate the front of the debris, producing a rocket-like thrust which slows the object. With continued application, the debris would fall enough to be influenced by atmospheric drag. During the late 1990s, the U.S. Air Force's Project Orion was a laser-broom design. Although a test-bed device was scheduled to launch on a Space Shuttle in 2003, international agreements banning powerful laser testing in orbit limited its use to measurements. The Space Shuttle \"Columbia\" disaster postponed the project and according to Nicholas Johnson, chief scientist and program manager for NASA's Orbital Debris Program Office, \"There are lots of little gotchas in the Orion final report. There's a reason why it's been sitting on the shelf for more than a decade.\"\n\nThe momentum of the laser-beam photons could directly impart a thrust on the debris sufficient to move small debris into new orbits out of the way of working satellites. NASA research in 2011 indicates that firing a laser beam at a piece of space junk could impart an impulse of per second, and keeping the laser on the debris for a few hours per day could alter its course by per day. One drawback is the potential for material degradation; the energy may break up the debris, adding to the problem. A similar proposal places the laser on a satellite in Sun-synchronous orbit, using a pulsed beam to push satellites into lower orbits to accelerate their reentry. A proposal to replace the laser with an Ion Beam Shepherd has been made, and other proposals use a foamy ball of aerogel or a spray of water,\ninflatable balloons,\nelectrodynamic tethers,\nboom electroadhesion,\nand dedicated anti-satellite weapons.\n\nOn 28 February 2014, Japan's Japan Aerospace Exploration Agency (JAXA) launched a test \"space net\" satellite. The launch was an operational test only. In December 2016 the country sent a space junk collector via Kounotori 6 to the ISS by which JAXA scientists experiment to pull junk out of orbit using a tether. The system failed to extend a 700-meter tether from a space station resupply vehicle that was returning to Earth. On 6 February the mission was declared a failure and leading researcher Koichi Inoue told reporters that they \"believe the tether did not get released\".\n\nSince 2012, the European Space Agency has designed a mission to remove large space debris from orbit. The mission, e.Deorbit, is scheduled for launch during 2023 with an objective to remove debris heavier than from LEO. Several capture techniques are being studied, including a net, a harpoon and a combination robot arm and clamping mechanism.\n\nHolger Krag of the European Space Agency states that as of 2017 there is no binding international regulatory framework with no progress occurring at the respective UN body in Vienna.\n\nIn 1946 during the Giacobinid meteor shower, Helmut Landsberg collected several small magnetic particles that were apparently associated with the shower. Fred Whipple was intrigued by this and wrote a paper that demonstrated that particles of this size were too small to maintain their velocity when they encountered the upper atmosphere. Instead, they quickly decelerated and then fell to Earth unmelted. In order to classify these sorts of objects, he coined the term \"micro-meteorite\".\n\nWhipple, in collaboration with Fletcher Watson of the Harvard Observatory, led an effort to build an observatory to directly measure the velocity of the meteors that could be seen. At the time the source of the micro-meteorites was not known. Direct measurements at the new observatory were used to locate the source of the meteors, demonstrating that the bulk of material was left over from comet tails, and that none of it could be shown to have an extra-solar origin. Today it is understood that meteoroids of all sorts are leftover material from the formation of the Solar System, consisting of particles from the interplanetary dust cloud or other objects made up from this material, like comets.\n\nThe early studies were based on optical measurements only. In 1957, Hans Pettersson conducted one of the first direct measurements of the fall of space dust on the Earth, estimating it to be 14,300,000 tons per year. This suggested that the meteoroid flux in space was much higher than the number based on telescope observations. Such a high flux presented a very serious risk to missions deeper in space, specifically the high-orbiting Apollo capsules. To determine whether the direct measurement was accurate, a number of additional studies followed, including the Pegasus satellite program. These showed that the rate of meteors passing into the atmosphere, or flux, was in line with the optical measurements, at around 10,000 to 20,000 tons per year.\n\nWhipple's work pre-dated the space race and it proved useful when space exploration started only a few years later. His studies had demonstrated that the chance of being hit by a meteoroid large enough to destroy a spacecraft was extremely remote. However, a spacecraft would be almost constantly struck by micrometeorites, about the size of dust grains.\n\nWhipple had already developed a solution to this problem in 1946. Originally known as a \"meteor bumper\" and now termed the Whipple shield, this consists of a thin foil film held a short distance away from the spacecraft's body. When a micrometeoroid strikes the foil, it vaporizes into a plasma that quickly spreads. By the time this plasma crosses the gap between the shield and the spacecraft, it is so diffused that it is unable to penetrate the structural material below. The shield allows a spacecraft body to be built to just the thickness needed for structural integrity, while the foil adds little additional weight. Such a spacecraft is lighter than one with panels designed to stop the meteoroids directly.\n\nFor spacecraft that spend the majority of their time in orbit, some variety of the Whipple shield has been almost universal for decades. Later research showed that ceramic fibre woven shields offer better protection to hypervelocity (~7 km/s) particles than aluminium shields of equal weight. Another modern design uses multi-layer flexible fabric, as in NASA's design for its never-flown TransHab expandable space habitation module,\nand the Bigelow Expandable Activity Module, which was launched in April 2016 and attached to the ISS for two years of orbital testing.\n\nTo avoid artificial space debris, many—but not all—research satellites are launched on elliptical orbits with perigees inside Earth's atmosphere so they will destroy themselves. Willy Ley predicted in 1960 that \"In time, a number of such accidentally too-lucky shots will accumulate in space and will have to be removed when the era of manned space flight arrives\". After the launch of Sputnik 1 in 1957, the North American Aerospace Defense Command (NORAD) began compiling a database (the Space Object Catalog) of all known rocket launches and objects reaching orbit: satellites, protective shields and upper- and lower-stage booster rockets. NASA published modified versions of the database in two-line element set, and during the early 1980s the CelesTrak bulletin board system re-published them.\nThe trackers who fed the database were aware of other objects in orbit, many of which were the result of in-orbit explosions. Some were deliberately caused during 1960s anti-satellite weapon (ASAT) testing, and others were the result of rocket stages blowing up in orbit as leftover propellant expanded and ruptured their tanks. To improve tracking, NORAD employee John Gabbard kept a separate database. Studying the explosions, Gabbard developed a technique for predicting the orbital paths of their products, and Gabbard diagrams (or plots) are now widely used. These studies were used to improve the modelling of orbital evolution and decay.\n\nWhen the NORAD database became publicly available during the 1970s, NASA scientist Donald J. Kessler applied the technique developed for the asteroid-belt study to the database of known objects. In 1978 Kessler and Burton Cour-Palais co-authored \"Collision Frequency of Artificial Satellites: The Creation of a Debris Belt\", demonstrating that the process controlling asteroid evolution would cause a similar collision process in LEO in decades rather than billions of years. They concluded that by about 2000, space debris would outpace micrometeoroids as the primary ablative risk to orbiting spacecraft.\n\nAt the time, it was widely thought that drag from the upper atmosphere would de-orbit debris faster than it was created. However, Gabbard was aware that the number and type of objects in space were under-represented in the NORAD data and was familiar with its behaviour. In an interview shortly after the publication of Kessler's paper, Gabbard coined the term \"Kessler syndrome\" to refer to the accumulation of debris; it became widely used after its appearance in a 1982 \"Popular Science\" article, which won the Aviation-Space Writers Association 1982 National Journalism Award.\n\nThe lack of hard data about space debris prompted a series of studies to better characterize the LEO environment. In October 1979, NASA provided Kessler with funding for further studies. Several approaches were used by these studies.\n\nOptical telescopes or short-wavelength radar was used to measure the number and size of space objects, and these measurements demonstrated that the published population count was at least 50% too low. Before this, it was believed that the NORAD database accounted for the majority of large objects in orbit. Some objects (typically, U.S. military spacecraft) were found to be omitted from the NORAD list, and others were not included because they were considered unimportant. The list could not easily account for objects under in size—in particular, debris from exploding rocket stages and several 1960s anti-satellite tests.\n\nReturned spacecraft were microscopically examined for small impacts, and sections of Skylab and the Apollo Command/Service Module which were recovered were found to be pitted. Each study indicated that the debris flux was higher than expected and debris was the primary source of collisions in space. LEO already demonstrated the Kessler syndrome.\n\nIn 1978 Kessler found that 42 percent of cataloged debris was the result of 19 events, primarily explosions of spent rocket stages (especially U.S. Delta rockets). He discovered this by first identifying those launches that were described having a large number of objects associated with a payload, then researching the literature to determine the rockets used in the launch. In 1979, this finding resulted in establishment of the NASA Orbital Debris Program after a briefing to NASA senior management, overturning the previously held belief that most unknown debris was from old ASAT tests, but from US upper stage rocket explosions and could be easily managed by depleting the unused fuel following the payload injection the upper stage Delta rocket. Beginning in 1986, when it was discovered that other international agencies were possibly experiencing the same type of problem, NASA expanded its program to include international agencies, the first being the European Space Agency. A number of other Delta components in orbit (Delta was a workhorse of the U.S. space program) had not yet exploded.\n\nDuring the 1980s, the U.S. Air Force conducted an experimental program to determine what would happen if debris collided with satellites or other debris. The study demonstrated that the process differed from micrometeoroid collisions, with large chunks of debris created which would become collision threats.\n\nIn 1991, Kessler published \"Collisional cascading: The limits of population growth in low Earth orbit\" with the best data then available. Citing the USAF conclusions about creation of debris, he wrote that although almost all debris objects (such as paint flecks) were lightweight, most of its mass was in debris about or heavier. This mass could destroy a spacecraft on impact, creating more debris in the critical-mass area. According to the National Academy of Sciences:\n\nA 1-kg object impacting at 10 km/s, for example, is probably capable of catastrophically breaking up a 1,000-kg spacecraft if it strikes a high-density element in the spacecraft. In such a breakup, numerous fragments larger than 1 kg would be created.\n\nKessler's analysis divided the problem into three parts. With a low-enough density, the addition of debris by impacts is slower than their decay rate and the problem is not significant. Beyond that is a critical density, where additional debris leads to additional collisions. At densities beyond this critical mass production exceeds decay, leading to a cascading chain reaction reducing the orbiting population to small objects (several cm in size) and increasing the hazard of space activity. This chain reaction is known as the Kessler syndrome.\n\nIn an early 2009 historical overview, Kessler summed up the situation:\n\nAggressive space activities without adequate safeguards could significantly shorten the time between collisions and produce an intolerable hazard to future spacecraft. Some of the most environmentally dangerous activities in space include large constellations such as those initially proposed by the Strategic Defense Initiative in the mid-1980s, large structures such as those considered in the late-1970s for building solar power stations in Earth orbit, and anti-satellite warfare using systems tested by the USSR, the U.S., and China over the past 30 years. Such aggressive activities could set up a situation where a single satellite failure could lead to cascading failures of many satellites in a period much shorter than years.\n\nDuring the 1980s, NASA and other U.S. groups attempted to limit the growth of debris. One effective solution was implemented by McDonnell Douglas on the Delta booster, by having the booster move away from its payload and vent any propellant remaining in its tanks. This eliminated the pressure buildup in the tanks which caused them to explode in the past. Other countries were slower to adopt this measure and, due especially to a number of launches by the Soviet Union, the problem grew throughout the decade.\n\nA new battery of studies followed as NASA, NORAD and others attempted to better understand the orbital environment, with each adjusting the number of pieces of debris in the critical-mass zone upward. Although in 1981 (when Schefter's article was published) the number of objects was estimated at 5,000, new detectors in the Ground-based Electro-Optical Deep Space Surveillance system found new objects. By the late 1990s, it was thought that most of the 28,000 launched objects had already decayed and about 8,500 remained in orbit. By 2005 this was adjusted upward to 13,000 objects, and a 2006 study increased the number to 19,000 as a result of an ASAT test and a satellite collision. In 2011, NASA said that 22,000 objects were being tracked.\n\nThe growth in the number of objects as a result of the late-1990s studies sparked debate in the space community on the nature of the problem and the earlier dire warnings. According to Kessler's 1991 derivation and 2001 updates, the LEO environment in the altitude range should be cascading. However, only one major incident has occurred: the 2009 satellite collision between Iridium 33 and Cosmos 2251. The lack of obvious short-term cascading has led to speculation that the original estimates overstated the problem. According to Kessler a cascade would not be obvious until it was well advanced, which might take years.\n\nA 2006 NASA model suggested that if no new launches took place the environment would retain the then-known population until about 2055, when it would increase on its own. Richard Crowther of Britain's Defence Evaluation and Research Agency said in 2002 that he believed the cascade would begin about 2015. The National Academy of Sciences, summarizing the professional view, noted widespread agreement that two bands of LEO space—900 to and —were already past critical density.\n\nIn the 2009 European Air and Space Conference, University of Southampton researcher Hugh Lewis predicted that the threat from space debris would rise 50 percent in the next decade and quadruple in the next 50 years. , more than 13,000 close calls were tracked weekly.\n\nA 2011 report by the U.S. National Research Council warned NASA that the amount of orbiting space debris was at a critical level. According to some computer models, the amount of space debris \"has reached a tipping point, with enough currently in orbit to continually collide and create even more debris, raising the risk of spacecraft failures\". The report called for international regulations limiting debris and research of disposal methods.\n\nThe plot of episode 4 (\"Conflict\") of Gerry Anderson's 1970 TV series \"UFO\" includes routine missions for the disposal of spent satellites by bombing.\n\n\"Salvage 1\" (1979 TV series) deals humorously with a scrap dealer who establish a space junk salvage company.\n\n\"Planetes\" is a manga (1999-2004) and anime series (2003-2004) that gives focus on a team which is responsible for the collection and disposal of space debris. The DVDs for the TV series include interviews with NASA's Orbital Debris Program Office.\n\nIn 2009, Rhett & Link wrote a song called \"Space Junk\" and made an accompanying music video for the TV series \"Brink\". The lyrics refer to two men tasked to clean up debris such as satellites and expended rockets.\n\n\"Gravity\" is a 2013 survival film, directed by Alfonso Cuaron, about a disaster on a space mission caused by Kessler syndrome.\n\n\n\n"}
{"id": "53700866", "url": "https://en.wikipedia.org/wiki?curid=53700866", "title": "State Environmental Quality Review Act", "text": "State Environmental Quality Review Act\n\nA State Environmental Quality Review Act (SEQRA) is a stipulation enacted by the state of New York that all local and state government agencies must uniformly reflect the environmental impacts when considering taking social and/or economic factors into action.\n\nIn 1975, the state of New York passed the State Environmental Quality Review Act to better establish a process when looking to add new developments on a site. From 1976 to 2005 there have been alterations to the Changes or Applications and Amendments categories.\n\nThis applies to any group that is deciding to approve a funded sponsored action through private or public financials. These groups include the following; \nAny project or action classified under Type I has to follow SEQRA requirements. A Type I action is any class of actions that unavoidably is going to have significant impacts on the environment.\n\nThere is no one agency that has the power to enforce SEQRA. The formation of the legislation enables it to be self-enforcing. The agencies responsible for an action that falls under SEQRA requirements must under its own power meet these regulations. The regulations that are issued are provided through the Department of Environmental Conservation.\n\nIf the project is listed under the statewide and agency SEQRA regulations is listen under the Type II list then it is determined not to have a large impact on the surrounding environment. Type II actions are classified as the project not having any significant impacts on the surrounding environment, or actions that have been exempted from SEQRA reviews.\n\nWhen going forward to satisfying the SEQRA requirements there is an 11 step process that you need to follow.\n\nStep 1 Is the action being taken subject to SEQRA. If yes then it needs to be classified as a type II Action or Type I Action.\n\nStep 2 The correct environmental assessment form needs to be completed and reviewed.\n\nStep 3 A coordinated review is set up by all agencies involved in Type 1 Actions.\n\nStep 4 This is the step where the agency that is taking the lead will make its determination on the significance.\n\nStep 5 The preparation of the draft EIS is stared by the lead agency or the applicant can.\n\nStep 6 The lead agency that received the draft EIS has 45 days to review and see if it is the draft is adequate for public review.\n\nStep 7 The publishing notice that the EIS has been accepted for the public review.\n\nStep 8 After the notice of complete of the EIS a public comment period then begins.\n\nStep 9 A debate on weather a public hearing should be held.\n\nStep 10 This is where the lead agency is held accountable for checking the precision on the final EIS statement. This should be finalized 45 days after the final hearings or 60 days after the filing of the draft EIS.\n\nStep 11 The final step is involves each agency writing their own SEQRA findings statement for that project. This has to be completed after the final EIS statement and before the final decision the agency makes. Findings certify that the project has met requirements of Part 617.\n\nThese are specific geographical areas that local agencies can deem Critical Environmental Areas (CEA). To designate an area to this stand it mus have one of more of the following characteristics ;\n"}
{"id": "31652273", "url": "https://en.wikipedia.org/wiki?curid=31652273", "title": "Syzygy (astronomy)", "text": "Syzygy (astronomy)\n\nIn astronomy, a syzygy (; from the Ancient Greek ) is a (roughly) straight-line configuration of three or more celestial bodies in a gravitational system.\n\nThe word is often used in reference to the Sun, Earth, and either the Moon or a planet, where the latter is in conjunction or opposition. Solar and lunar eclipses occur at times of syzygy, as do transits and occultations. The term is\noften applied when the Sun and Moon are in conjunction (new moon) or opposition (full moon).\n\nThe word \"syzygy\" is often used to describe interesting configurations of astronomical objects in general. For example, one such case occurred on March 21, 1894, around 23:00 GMT, when Mercury transited the Sun as would have been seen from Venus, and Mercury and Venus both simultaneously transited the Sun as seen from Saturn. It is also used to describe situations when all the planets are on the same side of the Sun although they are \"not necessarily in a straight line\", such as on March 10, 1982.\n\nOn June 3, 2014, the \"Curiosity\" rover on Mars observed the planet Mercury transiting the Sun, marking the first time a planetary transit has been observed from a celestial body besides Earth.\n\nSyzygy sometimes results in an occultation, transit, or eclipse.\n\n\nTransits and occultations of the Sun by Earth's Moon are called solar eclipses regardless of whether the Sun is completely or partially covered. By extension, transits of the Sun by a satellite of a planet may also be called eclipses, as with the transits of Phobos and Deimos shown on NASA's JPL photojournal, as may the passage of a satellite into the planet's shadow, as with this eclipse of Phobos. The term \"eclipse\" is also used more generally for bodies passing in front of one another. For example, a NASA Astronomy Picture of the Day refers to the Moon eclipsing and occulting Saturn interchangeably.\n\nAs electromagnetic rays are somewhat bent by gravitation, when they pass by a heavy mass they are bent. One says the mass acts as a gravitational lens. If the light source, the diffracting mass and the observer stand in a line, one sees an Einstein ring.\n\nSyzygy causes the bimonthly phenomena of spring and neap tides. At the new and full moon, the Sun and Moon are in syzygy. Their tidal forces act to reinforce each other, and the ocean both rises higher and falls lower than the average. Conversely, at the first and third quarter, the Sun and Moon are at right angles, their tidal forces counteract each other, and the tidal range is smaller than average. Tidal variation can also be measured in the earth's crust, and this may affect the frequency of earthquakes.\n"}
{"id": "1511686", "url": "https://en.wikipedia.org/wiki?curid=1511686", "title": "Sânziană", "text": "Sânziană\n\nSânziană is the Romanian name for gentle fairies who play an important part in local folklore, also used to designate the \"Galium verum\" or \"Cruciata laevipes\" flowers. Under the plural form Sânziene, the word designates an annual festival in the fairies' honor. Etymologically, the name comes from the Latin \"Sancta Diana\", the Roman goddess of the hunt and moon, also celebrated in Roman Dacia (ancient Romania). Diana was known to be the virgin goddess and looked after virgins and women. She was one of the three maiden goddesses, Diana, Minerva and Vesta, who swore never to marry.\n\nPeople in the western Carpathian Mountains celebrate the \"Sânziene\" holiday annually, on June 24. This is similar to the Swedish Midsummer holiday, and is believed to be a pagan celebration of the summer solstice in June. According to the official position of the Romanian Orthodox Church, the customs actually relate to the celebration of Saint John the Baptist's Nativity, which also happens on June 24.\n\nThe folk practices of \"Sânziene\" imply that the most beautiful maidens in the village dress in white and spend all day searching for and picking flowers, of which one MUST be \"Galium verum\" (Lady's bedstraw or Yellow bedstraw) which in Romanian is also named \"Sânziànă\". Using the flowers they picked during the day, the girls braid floral crowns which they wear upon returning to the village at nightfall. There they meet with their beloved and they dance around a bonfire. The crowns are thrown over the houses, and whenever the crown falls, it is said that someone will die in that house; if the crown stays on the roof of the house, then good harvest and wealth will be bestowed upon the owners. As with other bonfire celebrations, jumping over the embers after the bonfire is not raging anymore is done to purify the person and also to bring health.\n\nAnother folk belief is that during the \"Sânziene\" Eve night, the heavens open up, making it the strongest night for magic spells, especially for the love spells. Also it is said that the plants harvested during this night will have tremendous magical powers.\n\nIt is not a good thing though to be a male and walk at night during Sanziene Eve night, as that is the time when the fairies dance in the air, blessing the crops and bestowing health on people - they do not like to be seen by males, and whomever sees them will be maimed, or the fairies will take their hearing/speech or make them mad.\n\nIn some areas of the Carpathians, the villagers then light a big wheel of hay from the ceremonial bonfire and push it down a hill. This has been interpreted as a symbol for the setting sun (from the solstice to come and until the midwinter solstice, the days will be getting shorter).\n\nThe consequences of heavens opening on \"Sânziene\" are connected by some to paranormal events reported during that period of each year. According to popular beliefs, strange things, both positive and negative, may happen to a person wandering alone on \"Sânziene\" night. Strange ethereal activities are believed to happen especially in places such as the Băneasa forest (near the capital of Bucharest) or the Baciu forest (near the city of Cluj-Napoca).\n\nMircea Eliade's novel, \"Noaptea de Sânziene\" (translated as \"The Forbidden Forest\"), includes references to the folk belief about skies opening at night, as well as to paranormal events happening in the Băneasa Forest.\n\nIn the form \"Sânziana\" (\"the sânziană\"), the word has also come to be used as a female name. It is notably used as such in Vasile Alecsandri's comedy \"Sânziana şi Pepelea\" (later an opera by George Stephănescu).\n\n\nhttp://www2.macleans.ca/2011/06/28/week-in-pictures-june-20th-26th-2011/gypsy-fortune-tellers-and-maidens-perform-a-ritual-during-sanziene-night-on-a-lake-shore-on-the-outskirts-of-bucharest/\n\nhttp://www.romania-insider.com/sanzienedragaica-celebration-in-romania/3003/\n\nhttp://terradacicaaeterna.blogspot.com/2012/02/sanziene-or-summer-solstice.html\n\n\n\n"}
{"id": "95501", "url": "https://en.wikipedia.org/wiki?curid=95501", "title": "Tāwhaki", "text": "Tāwhaki\n\nIn Māori mythology, Tāwhaki is a semi-supernatural being associated with lightning and thunder.\n\nThe genealogy of Tāwhaki varies somewhat in different accounts. In general, Tāwhaki is a grandson of Whaitiri, a cannibalistic goddess who marries the mortal Kaitangata (man-eater), thinking that he shares her taste for human flesh. Disappointed at finding that this is not so, she leaves him after their sons Hemā and Punga are born and returns to heaven. Hemā is the father of Tāwhaki and Karihi. Tāwhaki grows up to be handsome, the envy of his cousins, who beat him up and leave him for dead. He is nursed back to health by his wife, who feeds the fire that warms him with a whole log of wood. In memory of this incident, their child is named Wahieroa (Long-piece-of-firewood) (Biggs 1966:450). In some versions Tawhaki is the father of Arahuta. She was the cause of a quarrel between her parents, and her mother Tangotango took her to heaven, where they were afterwards joined by Tāwhaki.\n\nHemā, while looking for a gift for his son, trespasses into the land of the Ponaturi, who are evil beings. They capture him and Urutonga, blinding Hemā in the process. While journeying to rescue his parents, Tāwhaki meets and marries Hinepiripiri, to whom is born their son, Wahieroa. Tāwhaki and his brother Karihi rescue their enslaved mother, who tells them that light is fatal to the Ponaturi. Eventually, with the help of their mother, they trick the Ponaturi, who have returned to their house to sleep. Tāwhaki and his brother hide, after having blocked up all the chinks of the house so that no light can enter. When the Ponaturi begin to think that the night is very long, Urutonga reassures them that there is still a long time until dawn comes. They then set fire to the house, and open the door. The Ponaturi are killed by the fire and the exposure to the sunlight. The only survivors are Tonga-Hiti and Kanae.\n\nTāwhaki and his young brother set off to climb up to the sky. At the foot of the ascent they find their grandmother, Whaitiri, now blind, who sits continually counting the tubers of sweet potato or taro that are her only food. Whaitiri is the guardian of the vines that form the pathway into the sky. The brothers tease her by snatching them away, one by one, and upsetting her count. Eventually, they reveal themselves to her and restore her sight. In return, she gives them advice about how best to make the climb into the sky. Karihi tries first, but makes the error of climbing up the \"aka taepa\", or hanging vine. He is blown violently around by the winds of heaven, and falls to his death. Tāwhaki climbs by the \"aka matua\", or parent vine, recites the right incantations, and reaches the highest of the 10 heavens. There he learns many spells from Tama-i-waho, and marries a woman named Hāpai, or as others say, Tangotango or Maikuku-makaka. They have a son, and according to some versions of the story it is this child who is named Wahieroa (Biggs 1966:450).\n\nIn a country like New Zealand, each tribe has a different version (or series of related versions) of a story like Tāwhaki; actually, the stories told by each storyteller within a tribe would be different, and the same storyteller would tell a slightly different tale each time it was told. To illustrate this variation in a small way, and to demonstrate that there is no one correct way to tell the story of Tāwhaki, two versions from different tribal groups are presented below.\n\nIn an 1850 version of Tāwhaki by Hohepa Paraone of the Arawa tribe of Rotorua (Paraone 1850:345-352, White 1887:115-119 (English), 100-105 (Māori), Tāwhaki is a mortal man who is visited each night by Hāpai, a woman from the heavens. When Hāpai becomes pregnant, she tells Tāwhaki that if their child is female, he is to wash her. After their daughter Puanga is born, Tāwhaki washes her, but expresses disgust at the smell. Offended, Hāpai takes the child, climbs onto the roof of the house, and disappears into the sky.\n\nAfter some months, Tāwhaki decides to go and find Hāpai and Puanga. He sets off with his two slaves. He warns the slaves not to look at the fortress of Tongameha as they pass by. One of the slaves looks, and Tongameha gouges out his eyes. Tāwhaki and the remaining slave go on, and meet Matakerepō, an old blind woman, guarding the vines (or ropes) that lead up into the heavens. Matakerepō is an ancestress of Tāwhaki's. As Matakerepō counts out her ten taro tubers, Tāwhaki removes them one by one.\n\nMatakerepō, aware that someone is deceiving her, begins to sniff the air, and her stomach distends, ready to swallow the stranger. She sniffs towards the south, and towards all the winds. When she sniffs towards the west she catches Tāwhaki's scent and calls out 'Are you come with the wind that blows on my skin?' Tāwhaki grunts, and Matakerepō says, 'Oh, it is my grandson Tāwhaki.' Her stomach begins to shrink. Had he not been from the west wind, she would have swallowed him.\n\nMatakerepō asks Tāwhaki where he is going. He replies that he is searching for his wife and daughter; his wife is a daughter of Whatitiri-matakamataka (or Whaitiri) and has returned to the heavens. Matakerepō shows him the pathway, advising him to set off in the morning. Tāwhaki's slave prepares a meal. Tāwhaki takes some cooked food and rubs it on the eyes of the old woman. Matakerepō is instantly cured of her blindness. In the morning, Tāwhaki presents his slave to Matakerepō, who chants a spell to help him as climbs. When he reaches the heavens, Tāwhaki disguises himself as an old slave and assists his brothers-in-law to build a canoe. Each night, the brothers-in-law return to their village, where Tāwhaki's wife and daughter are living. Pretending to be unable to keep up, Tāwhaki lets the brothers-in-law go on ahead, and returns to work on the canoe, arriving at the village much later. The next morning, Tāwhaki and the brothers-in-law return; seeing the canoe, the brothers-in-law are surprised by all the work that has been done. Each evening, Tāwhaki sits in the special seat of Hāpai, despite the protests of the villagers. These deeds of Tāwhaki bring him to Hāpai's attention, and she asks him who he is. Tāwhaki resumes his true appearance and is recognised by his wife. He performs rituals of dedication over their daughter.\n\nIn a legend committed to manuscript by Mohi Ruatapu of Ngāti Porou in 1971 (Reedy 1993:25-33, 126-134), Tāwhaki is a descendant of Māui. Whaitiri, a granddaughter of Māui, marries Kaitangata and has Hemā. Hemā marries Rawhita-i-te-rangi, and has Tāwhaki and his younger brother Karihi. Tāwhaki and Karihi set off to find their grandmother Whaitiri. They come to a village where a \"kawa\" (open ceremony) is being performed for Hine-te-kawa's house. They hide in the walls of the house and listen to the incantations. As the ceremony ends, Tāwhaki and Karihi leap out and kill all the people except Hine-te-kawa, who sleeps with Tāwhaki that night. She shows them the pathway they must take into the sky; it has pegs as footholds. Karihi makes several attempts at the climb, but falls to his death on the second attempt. Tāwhaki takes Karihi's eyes and makes the climb. He comes upon Whaitiri, his blind grandmother, counting out twelve taro for her grandchildren, who are away at the village of Tama-i-waho. Tāwhaki removes the taro tubers one by one, until Whaitiri realises that it must be her grandson who she had foretold would come to find her. Tāwhaki places Karihi's eyes into her eyes, and her sight is restored. Tāwhaki busies himself tidying his grandmother's village, and washes and cares for her. Tāwhaki catches marries Maikuku, one of Whaitiri's granddaughters; the other granddaughters escape to Tama-i-waho's village, up in the second sky. When they look down and see Tāwhaki and Maikuku making love outdoors, they are offended and come down and take Maikuku away into the sky. Tāwhaki, desperate to find his wife, who is pregnant, tries to ascend on a kite, but the evil Tama-i-waho sends a hākuai, a mythical bird, to attack the kite, causing Tāwhaki to fall. Tāwhaki then turns himself into a harrier hawk, and takes off. Using his adze Te Rakuraku-o-te-rangi, Tama-i-waho cuts off one of the wings of the hawk, and Tāwhaki falls to his death. After Tāwhaki's death, Maikuku bears him a son, named Wahiroa.\n\nSome versions of the Māori story of Tāwhaki contain episodes where the hero causes a flood to destroy the village of his two jealous brothers-in-law. He directs his own people to relocate their village to the top of the mountain Hikurangi.\nA comment in Grey's \"Polynesian Mythology\" may have given the Māori something they did not have before — as A.W Reed put it, \"In \"Polynesian Mythology\" Grey said that when Tāwhaki's ancestors released the floods of heaven, the earth was overwhelmed and all human beings perished — thus providing the Māori with his own version of the universal flood\" (Reed 1963:165, in a footnote). Christian influence has led to the appearance of genealogies where Tawhaki's grandfather Hema is reinterpreted as Shem, son of Noah of the biblical deluge.\n\n\n"}
{"id": "19244712", "url": "https://en.wikipedia.org/wiki?curid=19244712", "title": "World Development Report", "text": "World Development Report\n\nThe World Development Report (WDR) is an annual report published since 1978 by the International Bank for Reconstruction and Development (IBRD) or World Bank. Each WDR provides in-depth analysis of a specific aspect of economic development. Past reports have considered such topics as agriculture, youth, equity, public services delivery, the role of the state, transition economies, labour, infrastructure, health, the environment, risk management, and poverty. The reports are the Bank's best-known contribution to thinking about development.\n\nThe World Development Report 2019 studies the impact of technology on the nature of work. It is the most-downloaded World Development Report, with more than a million downloads, half of which before its official publication. The study was led by Simeon Djankov and Federica Saliola.\n\n\"The World Development Report 2014 Risk and Opportunity: Managing Risk for Development\" looked at risk management from a development perspective. It argued that managing risks such as job loss, crime, disease, disaster, social unrest, and financial and macroeconomic turbulence responsibly can save lives, avert damages, prevent development setbacks, and unleash opportunities. The report proposed a conceptual framework for thinking about risk and resilience, identified obstacles to better risk management, and recommended numerous avenues for better risk management that can be pursued by individuals, families, communities, enterprises, governments, and the international community.\n\n\"The World Development Report 2011: Conflict, Security, and Development\" looked at conflict as a challenge to economic development. It analyzed the nature, causes and development consequences of modern violence and highlight lessons learned from efforts to prevent or recover from violence.\nThe goal of this WDR was considered to promote new ways of preventing or addressing violent conflict. By drawing on insight and experiences from a host of past and present situations, the report identified promising national and regional initiatives as well as directions for change in international responses, and discuss how lessons can be applied in situations of vulnerability to violent conflict.\nThe World Development Report is published by the World Bank.\n\nThe WDR 2010, on the theme \"Development and Climate Change\", explored how public policy can change to better help people cope with new or worsened risks, how land and water management must adapt to better protect a threatened natural environment while feeding an expanding and more prosperous population, and how energy systems will need to be transformed. The report was seen as a call for action, both for developing countries who are striving to ensure policies are adapted to the realities and dangers of a hotter planet, and for high-income countries who need to undertake ambitious mitigation while supporting developing countries’ efforts.\n\nThe WDR 2009 focused on the theme \"Reshaping Economic Geography\". Rising densities of human settlements, migration and transport to reduce distances to market, and specialization and trade facilitated by fewer international divisions are central to economic development. The transformations along these three dimensions—density, distance, and division—are most noticeable in North America, Western Europe, and Japan, but countries in Asia and Eastern Europe are changing in ways similar in scope and speed.\n\nThe report concludes that these spatial transformations are essential, and should be encouraged. The conclusion is not without controversy. Slum-dwellers now number a billion, but the rush to cities continues. Globalization is believed to benefit many, but not the billion people living in lagging areas of developing nations. High poverty and mortality persist among the world's \"bottom billion\", while others grow wealthier and live longer lives. Concern for these three billion often comes with the prescription that growth must be made spatially balanced. The WDR has a different message: economic growth is seldom balanced, and efforts to spread it out prematurely will jeopardize progress.\n\nThe WDR 2008 addressed \"Agriculture for Development\", calling for greater investment in agriculture in developing countries. The report warned that the sector must be placed at the center of the development agenda if the goals of halving extreme poverty and hunger by 2015 are to be realized.\n\nWhile 75 percent of the world's poor live in rural areas in developing countries, a mere 4 percent of official development assistance goes to agriculture. In Sub-Saharan Africa, a region heavily reliant on agriculture for overall growth, public spending for farming is also only 4 percent of total government spending and the sector is still taxed at relatively high levels. For the poorest people, GDP growth originating in agriculture is about four times more effective in raising incomes of extremely poor people than GDP growth originating outside the sector.\n\n“A dynamic ‘agriculture for development’ agenda can benefit the estimated 900 million rural people in the Developing world who live on less than $1 a day, most of whom are engaged in agriculture,” said Robert B. Zoellick, World Bank Group President. “We need to give agriculture more prominence across the board. At the global level, countries must deliver on vital reforms such as cutting distorting subsidies and opening markets, while civil society groups, especially farmer organizations, need more say in setting the agricultural agenda.”\n\nAccording to the report, agriculture can offer pathways out of poverty if efforts are made to increase productivity in the staple foods sector; connect smallholders to rapidly expanding high-value horticulture, poultry, aquaculture, as well as dairy markets; and generate jobs in the rural nonfarm economy.\n\nThe World Development Report began as a series of annual publications in the year 1978 with its first report titled \"Prospects for Growth and Alleviation of Poverty.\" Since then, it has focused each year on a particular theme that is central to development and the reports present a detailed study of the relevant sectors, applications and toolkits developed. The reports and their titles are as follows:\n\n\n\n"}
{"id": "54242474", "url": "https://en.wikipedia.org/wiki?curid=54242474", "title": "İncirliin Cave", "text": "İncirliin Cave\n\nİnicrliin Cave () is a show cave located in Muğla Province, southwestern Turkey.\n\nİncirliin Cave is situated in Gökçeler Canyon in Milas district of Muğla Province, Turkey. It is the most significant one and the only show cave in a group of nearly 30 caves in the canyon area. It is on the northern hillside of Mount Manastır overlooking the canyon. The cave is long, however only about of it is open to tourism. It is a horizontal lying spring cave. Its forming was affected by a distinctive fault in a karst formation. The cave has a wide entrance. It is wide and has a clearance of . It features ponds, giant stalactites and stalagmites. There are many rooms separated from the main gallery by stalactites. The rooms are mostly connected with each other by high passages. The \"Gösteri Salonu\" (literally \"Show Room\") in the middle of the cave is elevated below the entrance level. The \"Damlataş Galerisi\" (\"Dripstone Gallery\") at the end of the show cave, which was formed on the fault, is situated higher than the entrance level. \n\nIn terms of hydrogeology, the cave is in a vadose zone. It remains totally dry but becomes wet by dripping water from the cave ceiling during the rainy period. Generally, the stalactites and stalagmites in the entrance, the \"Yarasa Galerisi\" (\"Bat Gallery\"), the \"Havuzlu Salon\" (\"Pond's Room\") and the \"Gösteri Salonu\" are partially fossilized, while the formation of the stalactites, stalagmites, columns and draperies in the \"Damlataş Galerisi\" (\"Dripstone Gallery\") are still continueing.\n\nA great number of earthenware pieces, which are dated back to the prehistoric era and antiquity, were found in the ground at the entrance and inside the cave. By December 2016, archaeological excavations were started by the Muğla University in the section of the cave, which is not open to the pıblic, Human and animal bones, stone tools and terracotta pieces were discovered. These finds show that the cave was inhabited in the ancient times already 8,000 years ago in 6000 BC. İncirliin Cave was registered as a first-grade archaeological site and first-grade nature reserve on February 27, 2008. A walking path was established on a length of nearly in the cave. The cave was fitted in 2013 with lighting that does not harm geological formations. In April 2016, a -long part of the cave was opened to the public as a show cave.\n"}
