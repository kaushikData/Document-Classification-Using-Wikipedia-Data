{"id": "364478", "url": "https://en.wikipedia.org/wiki?curid=364478", "title": "Absorption spectroscopy", "text": "Absorption spectroscopy\n\nAbsorption spectroscopy refers to spectroscopic techniques that measure the absorption of radiation, as a function of frequency or wavelength, due to its interaction with a sample. The sample absorbs energy, i.e., photons, from the radiating field. The intensity of the absorption varies as a function of frequency, and this variation is the absorption spectrum. Absorption spectroscopy is performed across the electromagnetic spectrum.\n\nAbsorption spectroscopy is employed as an analytical chemistry tool to determine the presence of a particular substance in a sample and, in many cases, to quantify the amount of the substance present. Infrared and ultraviolet-visible spectroscopy are particularly common in analytical applications. Absorption spectroscopy is also employed in studies of molecular and atomic physics, astronomical spectroscopy and remote sensing.\n\nThere are a wide range of experimental approaches for measuring absorption spectra. The most common arrangement is to direct a generated beam of radiation at a sample and detect the intensity of the radiation that passes through it. The transmitted energy can be used to calculate the absorption. The source, sample arrangement and detection technique vary significantly depending on the frequency range and the purpose of the experiment.\n\nA material's absorption spectrum is the fraction of incident radiation absorbed by the material over a range of frequencies. The absorption spectrum is primarily determined by the atomic and molecular composition of the material. Radiation is more likely to be absorbed at frequencies that match the energy difference between two quantum mechanical states of the molecules. The absorption that occurs due to a transition between two states is referred to as an absorption line and a spectrum is typically composed of many lines.\n\nThe frequencies where absorption lines occur, as well as their relative intensities, primarily depend on the electronic and molecular structure of the sample. The frequencies will also depend on the interactions between molecules in the sample, the crystal structure in solids, and on several environmental factors (e.g., temperature, pressure, electromagnetic field). The lines will also have a width and shape that are primarily determined by the spectral density or the density of states of the system.\n\nAbsorption lines are typically classified by the nature of the quantum mechanical change induced in the molecule or atom. Rotational lines, for instance, occur when the rotational state of a molecule is changed. Rotational lines are typically found in the microwave spectral region. Vibrational lines correspond to changes in the vibrational state of the molecule and are typically found in the infrared region. Electronic lines correspond to a change in the electronic state of an atom or molecule and are typically found in the visible and ultraviolet region. X-ray absorptions are associated with the excitation of inner shell electrons in atoms. These changes can also be combined (e.g. rotation-vibration transitions), leading to new absorption lines at the combined energy of the two changes.\n\nThe energy associated with the quantum mechanical change primarily determines the frequency of the absorption line but the frequency can be shifted by several types of interactions. Electric and magnetic fields can cause a shift. Interactions with neighboring molecules can cause shifts. For instance, absorption lines of the gas phase molecule can shift significantly when that molecule is in a liquid or solid phase and interacting more strongly with neighboring molecules.\n\nThe width and shape of absorption lines are determined by the instrument used for the observation, the material absorbing the radiation and the physical environment of that material. It is common for lines to have the shape of a Gaussian or Lorentzian distribution. It is also common for a line to be described solely by its intensity and width instead of the entire shape being characterized.\n\nThe integrated intensity—obtained by integrating the area under the absorption line—is proportional to the amount of the absorbing substance present. The intensity is also related to the temperature of the substance and the quantum mechanical interaction between the radiation and the absorber. This interaction is quantified by the transition moment and depends on the particular lower state the transition starts from, and the upper state it is connected to.\n\nThe width of absorption lines may be determined by the spectrometer used to record it. A spectrometer has an inherent limit on how narrow a line it can resolve and so the observed width may be at this limit. If the width is larger than the resolution limit, then it is primarily determined by the environment of the absorber. A liquid or solid absorber, in which neighboring molecules strongly interact with one another, tends to have broader absorption lines than a gas. Increasing the temperature or pressure of the absorbing material will also tend to increase the line width. It is also common for several neighboring transitions to be close enough to one another that their lines overlap and the resulting overall line is therefore broader yet.\n\nAbsorption and transmission spectra represent equivalent information and one can be calculated from the other through a mathematical transformation. A transmission spectrum will have its maximum intensities at wavelengths where the absorption is weakest because more light is transmitted through the sample. An absorption spectrum will have its maximum intensities at wavelengths where the absorption is strongest.\n\nEmission is a process by which a substance releases energy in the form of electromagnetic radiation. Emission can occur at any frequency at which absorption can occur, and this allows the absorption lines to be determined from an emission spectrum. The emission spectrum will typically have a quite different intensity pattern from the absorption spectrum, though, so the two are not equivalent. The absorption spectrum can be calculated from the emission spectrum using appropriate theoretical models and additional information about the quantum mechanical states of the substance. \n\nThe scattering and reflection spectra of a material are influenced by both its index of refraction and its absorption spectrum. In an optical context, the absorption spectrum is typically quantified by the extinction coefficient, and the extinction and index coefficients are quantitatively related through the Kramers-Kronig relation. Therefore, the absorption spectrum can be derived from a scattering or reflection spectrum. This typically requires simplifying assumptions or models, and so the derived absorption spectrum is an approximation.\n\nAbsorption spectroscopy is useful in chemical analysis because of its specificity and its quantitative nature. The specificity of absorption spectra allows compounds to be distinguished from one another in a mixture, making absorption spectroscopy useful in wide variety of applications. For instance, Infrared gas analyzers can be used to identify the presence of pollutants in the air, distinguishing the pollutant from nitrogen, oxygen, water and other expected constituents.\n\nThe specificity also allows unknown samples to be identified by comparing a measured spectrum with a library of reference spectra. In many cases, it is possible to determine qualitative information about a sample even if it is not in a library. Infrared spectra, for instance, have characteristics absorption bands that indicate if carbon-hydrogen or carbon-oxygen bonds are present.\n\nAn absorption spectrum can be quantitatively related to the amount of material present using the Beer-Lambert law. Determining the absolute concentration of a compound requires knowledge of the compound's absorption coefficient. The absorption coefficient for some compounds is available from reference sources, and it can also be determined by measuring the spectrum of a calibration standard with a known concentration of the target.\n\nOne of the unique advantages of spectroscopy as an analytical technique is that measurements can be made without bringing the instrument and sample into contact. Radiation that travels between a sample and an instrument will contain the spectral information, so the measurement can be made remotely. Remote spectral sensing is valuable in many situations. For example, measurements can be made in toxic or hazardous environments without placing an operator or instrument at risk. Also, sample material does not have to be brought into contact with the instrument—preventing possible cross contamination.\n\nRemote spectral measurements present several challenges compared to laboratory measurements. The space in between the sample of interest and the instrument may also have spectral absorptions. These absorptions can mask or confound the absorption spectrum of the sample. These background interferences may also vary over time. The source of radiation in remote measurements is often an environmental source, such as sunlight or the thermal radiation from a warm object, and this makes it necessary to distinguish spectral absorption from changes in the source spectrum.\n\nTo simplify these challenges, Differential optical absorption spectroscopy has gained some popularity, as it focusses on differential absorption features and omits broad-band absorption such as aerosol extinction and extinction due to rayleigh scattering. This method is applied to ground-based, air-borne and satellite based measurements. Some ground-based methods provide the possibility to retrieve tropospheric and stratospheric trace gas profiles.\n\nAstronomical spectroscopy is a particularly significant type of remote spectral sensing. In this case, the objects and samples of interest are so distant from earth that electromagnetic radiation is the only means available to measure them. Astronomical spectra contain both absorption and emission spectral information. Absorption spectroscopy has been particularly important for understanding interstellar clouds and determining that some of them contain molecules. Absorption spectroscopy is also employed in the study of extrasolar planets. Detection of extrasolar planets by the transit method also measures their absorption spectrum and allows for the determination of the planet's atmospheric composition, temperature, pressure, and scale height, and hence allows also for the determination of the planet's mass.\n\nTheoretical models, principally quantum mechanical models, allow for the absorption spectra of atoms and molecules to be related to other physical properties such as electronic structure, atomic or molecular mass, and molecular geometry. Therefore, measurements of the absorption spectrum are used to determine these other properties. Microwave spectroscopy, for example, allows for the determination of bond lengths and angles with high precision.\n\nIn addition, spectral measurements can be used to determine the accuracy of theoretical predictions. For example, the Lamb shift measured in the hydrogen atomic absorption spectrum was not expected to exist at the time it was measured. Its discovery spurred and guided the development of quantum electrodynamics, and measurements of the Lamb shift are now used to determine the fine-structure constant.\n\nThe most straightforward approach to absorption spectroscopy is to generate radiation with a source, measure a reference spectrum of that radiation with a detector and then re-measure the sample spectrum after placing the material of interest in between the source and detector. The two measured spectra can then be combined to determine the material's absorption spectrum. The sample spectrum alone is not sufficient to determine the absorption spectrum because it will be affected by the experimental conditions—the spectrum of the source, the absorption spectra of other materials in between the source and detector and the wavelength dependent characteristics of the detector. The reference spectrum will be affected in the same way, though, by these experimental conditions and therefore the combination yields the absorption spectrum of the material alone.\n\nA wide variety of radiation sources are employed in order to cover the electromagnetic spectrum. For spectroscopy, it is generally desirable for a source to cover a broad swath of wavelengths in order to measure a broad region of the absorption spectrum. Some sources inherently emit a broad spectrum. Examples of these include globars or other black body sources in the infrared, mercury lamps in the visible and ultraviolet and x-ray tubes. One recently developed, novel source of broad spectrum radiation is synchrotron radiation which covers all of these spectral regions. Other radiation sources generate a narrow spectrum but the emission wavelength can be tuned to cover a spectral range. Examples of these include klystrons in the microwave region and lasers across the infrared, visible and ultraviolet region (though not all lasers have tunable wavelengths).\n\nThe detector employed to measure the radiation power will also depend on the wavelength range of interest. Most detectors are sensitive to a fairly broad spectral range and the sensor selected will often depend more on the sensitivity and noise requirements of a given measurement. Examples of detectors common in spectroscopy include heterodyne receivers in the microwave, bolometers in the millimeter-wave and infrared, mercury cadmium telluride and other cooled semiconductor detectors in the infrared, and photodiodes and photomultiplier tubes in the visible and ultraviolet.\n\nIf both the source and the detector cover a broad spectral region, then it is also necessary to introduce a means of resolving the wavelength of the radiation in order to determine the spectrum. Often a spectrograph is used to spatially separate the wavelengths of radiation so that the power at each wavelength can be measured independently. It is also common to employ interferometry to determine the spectrum—Fourier transform infrared spectroscopy is a widely used implementation of this technique.\n\nTwo other issues that must be considered in setting up an absorption spectroscopy experiment include the optics used to direct the radiation and the means of holding or containing the sample material (called a cuvette or cell). For most UV, visible, and NIR measurements the use of precision quartz cuvettes are necessary. In both cases, it is important to select materials that have relatively little absorption of their own in the wavelength range of interest. The absorption of other materials could interfere with or mask the absorption from the sample. For instance, in several wavelength ranges it is necessary to measure the sample under vacuum or in a rare gas environment because gases in the atmosphere have interfering absorption features.\n\n\n"}
{"id": "37517661", "url": "https://en.wikipedia.org/wiki?curid=37517661", "title": "Animals Are Like That", "text": "Animals Are Like That\n\nAnimals Are Like That! was Frank Buck’s sixth book, which continued his stories of capturing exotic animals.\nIf you should find yourself with a monkey or ape on your hands and no knowledge of what to do with it, Buck tells co-author Carol Weld, just treat it like a child. And the elephant, like a man in the tropics, needs a sheltered siesta in mid-afternoon because he is susceptible to sunstroke. Monkeys pick up human ways and copy them. But you should never, never trust a tiger, any more than you should trust a crocodile.\n\n\"Buck describes the animals in their native haunts, the capture of some of them, their characteristics, and their reactions in captivity...filled with adventure and odd bits of animal lore.\" Booklist 36:170 Jan 1, 1940<br>\n\"The vast legion of Frank Buck's followers will find \"Animals Are Like That\" thoroughly\nenjoyable and instructive reading. When the author doesn't know the answer to some more intangible animal trait he frankly admits his deficiency; but this happens infrequently. Mr. Buck has selected a large number of excellent illustrations...\"\nSpringfield Republican p10 Nov 29, 1939<br>\n\"A fascinating study of animal traits.\" The Montreal Gazette - Dec 9, 1939\n"}
{"id": "357657", "url": "https://en.wikipedia.org/wiki?curid=357657", "title": "Bloch wave", "text": "Bloch wave\n\nA Bloch wave (also called Bloch state or Bloch function or Bloch wavefunction), named after Swiss physicist Felix Bloch, is a type of wavefunction for a particle in a periodically-repeating environment, most commonly an electron in a crystal. A wavefunction ψ is a Bloch wave if it has the form:\n\nwhere r is position, ψ is the Bloch wave, \"u\" is a periodic function with the same periodicity as the crystal, k is a vector of real numbers called the crystal wave vector, \"e\" is Euler's number, and \"i\" is the imaginary unit. In other words, if we multiply a plane wave by a periodic function, we get a Bloch wave.\n\nBloch waves are important because of Bloch's theorem, which states that the energy eigenstates for an electron in a crystal can be written as Bloch waves. (More precisely, it states that the electron wave functions in a crystal have a basis consisting entirely of Bloch wave energy eigenstates.) This fact underlies the concept of electronic band structures.\n\nThese Bloch wave energy eigenstates are written with subscripts as ψ, where \"n\" is a discrete index, called the \"band index\", which is present because there are many different Bloch waves with the same k (each has a different periodic component \"u\"). Within a band (i.e., for fixed \"n\"), ψ varies continuously with k, as does its energy. Also, for any reciprocal lattice vector K, ψ = ψ. Therefore, all distinct Bloch waves occur for k-values within the first Brillouin zone of the reciprocal lattice.\n\nThe most common example of Bloch's theorem is describing electrons in a crystal. However, a Bloch-wave description applies more generally to any wave-like phenomenon in a periodic medium. For example, a periodic dielectric in electromagnetism leads to photonic crystals, and a periodic acoustic medium leads to phononic crystals. It is generally treated in the various forms of the dynamical theory of diffraction.\n\nSuppose an electron is in a Bloch state\nwhere \"u\" is periodic with the same periodicity as the crystal lattice. The actual quantum state of the electron is entirely determined by ψ, not k or \"u\" directly. This is important because k and \"u\" are \"not\" unique. Specifically, if ψ can be written as above using k, it can \"also\" be written using (k + K), where K is any reciprocal lattice vector (see figure at right). Therefore, wave vectors that differ by a reciprocal lattice vector are equivalent, in the sense that they characterize the same set of Bloch states.\n\nThe first Brillouin zone is a restricted set of values of k with the property that no two of them are equivalent, yet every possible k is equivalent to one (and only one) vector in the first Brillouin zone. Therefore, if we restrict k to the first Brillouin zone, then every Bloch state has a unique k. Therefore, the first Brillouin zone is often used to depict all of the Bloch states without redundancy, for example in a band structure, and it is used for the same reason in many calculations.\n\nWhen k is multiplied by the reduced Planck's constant, it equals the electron's crystal momentum. Related to this, the group velocity of an electron can be calculated based on how the energy of a Bloch state varies with k; for more details see crystal momentum.\n\nFor a detailed example in which the consequences of Bloch's theorem are worked out in a specific situation, see the article: Particle in a one-dimensional lattice (periodic potential).\n\nNext, we prove Bloch's theorem:\n\nThe defining property of a crystal is translational symmetry, which means that if the crystal is shifted an appropriate amount, it winds up with all its atoms in the same places. (A finite-size crystal cannot have perfect translational symmetry, but it is a useful approximation.)\n\nA three-dimensional crystal has three \"primitive lattice vectors\" a, a, a. If the crystal is shifted by any of these three vectors, or a combination of them of the form\nwhere \"n\" are three integers, then the atoms end up in the same set of locations as they started.\n\nAnother helpful ingredient in the proof is the \"reciprocal lattice vectors\". These are three vectors b, b, b (with units of inverse length), with the property that a · b = 2π, but a · b = 0 when \"i\" ≠ \"j\". (For the formula for b, see reciprocal lattice vector.)\n\nLet formula_6 denote a translation operator that shifts every wave function by the amount (as above, \"n\" are integers). The following fact is helpful for the proof of Bloch's theorem:\n\nProof: Assume that we have a wavefunction \"ψ\" which is an eigenstate of all the translation operators. As a special case of this, \nfor \"j\" = 1, 2, 3, where \"C\" are three numbers (the eigenvalues) which do not depend on r. It is helpful to write the numbers \"C\" in a different form, by choosing three numbers \"θ\", \"θ\", \"θ\" with :\nAgain, the \"θ\" are three numbers which do not depend on r. Define , where b are the reciprocal lattice vectors (see above). Finally, define \n\nThen\n\nThis proves that \"u\" has the periodicity of the lattice. Since \"ψ\"(r) = \"e\"\"u\"(r), that proves that the state is a Bloch wave.\n\nFinally, we are ready for the main proof of Bloch's theorem.\n\nAs above, let formula_6 denote a \"translation operator\" that shifts every wave function by the amount , where \"n\" are integers. Because the crystal has translational symmetry, this operator commutes with the Hamiltonian operator. Moreover, every such translation operator commutes with every other. Therefore, there is a simultaneous eigenbasis of the Hamiltonian operator and every possible formula_6 operator. This basis is what we are looking for. The wavefunctions in this basis are energy eigenstates (because they are eigenstates of the Hamiltonian), and they are also Bloch waves (because they are eigenstates of the translation operators; see Lemma above).\n\nThe concept of the Bloch state was developed by Felix Bloch in 1928, to describe the conduction of electrons in crystalline solids. The same underlying mathematics, however, was also discovered independently several times: by George William Hill (1877), Gaston Floquet (1883), and Alexander Lyapunov (1892). As a result, a variety of nomenclatures are common: applied to ordinary differential equations, it is called Floquet theory (or occasionally the \"Lyapunov–Floquet theorem\"). The general form of a one-dimensional periodic potential equation is Hill's equation:\n\nwhere \"f(t)\" is a periodic potential. Specific periodic one-dimensional equations include the Kronig–Penney model and Mathieu's equation.\n\nMathematically Bloch's theorem is interpreted in terms of unitary characters of a lattice group, and is applied to spectral geometry.\n\n"}
{"id": "162621", "url": "https://en.wikipedia.org/wiki?curid=162621", "title": "Braided river", "text": "Braided river\n\nA braided river, or braided channel, consists of a network of river channels separated by small, and often temporary, islands called braid bars or, in British usage, \"aits\" or \"eyots\". Braided streams occur in rivers with low slope and/or large sediment load. Braided channels are also typical of environments that dramatically decrease channel depth, and consequently channel velocity, such as river deltas, alluvial fans, and peneplains.\n\nBraided rivers, as distinct from meandering rivers, occur when a threshold level of sediment load or slope is reached while a steep gradient is also maintained. Geologically speaking, an increase in sediment load over time will increase the slope of the river, so these two conditions may be considered synonymous; and, consequently, a variation of slope can model a variation in sediment load. A threshold slope was experimentally determined to be 0.016 (ft/ft) for a stream with poorly sorted coarse sand. Any slope over this threshold created a braided stream, while any slope under the threshold created a meandering stream or—for very low slopes—a straight channel. So the main controlling factor on river development is the amount of sediment that the river carries; once a given system crosses a threshold value for sediment load, it will convert from a meandering system to a braided system. Also important to channel development is the proportion of suspended load sediment to bed load. An increase in suspended sediment allowed for the deposition of fine erosion-resistant material on the inside of a curve, which accentuated the curve and in some instances, caused a river to shift from a braided to a meandering profile.\nThe channels and braid bars are usually highly mobile, with the river layout often changing significantly during flood events. Channels move sideways via differential velocity: On the outside of a curve, deeper, swift water picks up sediment (usually gravel or larger stones), which is re-deposited in slow-moving water on the inside of a bend.\n\nThe braided channels may flow within an area defined by relatively stable banks or may occupy an entire valley floor. The Rakaia River in Canterbury, New Zealand has cut a channel 100 metres wide into the surrounding plains; this river transports sediment to a lagoon located on the river-coast interface.\n\nConditions associated with braided channel formation include:\n\nHowever, the critical factor that determines whether a stream will meander or braid is bank erodibility. A stream with cohesive banks that are resistant to erosion will form narrow, deep, meandering channels, whereas a stream with highly erodible banks will form wide, shallow channels, sustaining helical flow and resulting in the formation of braided channels.\n\nExtensive braided river systems are found in Alaska, Canada, New Zealand's South Island, and the Himalayas, which all contain young, rapidly eroding mountains.\n\n\nNotable braided rivers in Europe:\n\nAnastomosing rivers or streams are similar to braided rivers in that they consist of multiple interweaving channels. However, anastomosing rivers typically consist of a network of low-gradient, narrow, deep channels with stable banks, in contrast to braided rivers, which form on steeper gradients and display less bank stability.\n\n"}
{"id": "6772172", "url": "https://en.wikipedia.org/wiki?curid=6772172", "title": "Christmas and holiday season", "text": "Christmas and holiday season\n\nThe Christmas season, also called the festive season, or the holiday season (mainly in the U.S. and Canada; often simply called the holidays), is an annually recurring period recognized in many Western and Western-influenced countries that is generally considered to run from late November to early January. It is defined as incorporating at least Christmas, and usually New Year, and sometimes various other holidays and festivals. It also is associated with a period of shopping which comprises a peak season for the retail sector (the \"Christmas (or holiday) shopping season\"), and a period of sales at the end of the season (the \"January sales\"). Christmas window displays and Christmas tree lighting ceremonies when trees decorated with ornaments and light bulbs are illuminated, are traditions in many areas.\n\nIn the denominations of Western Christianity, the term \"Christmas season\" is considered synonymous with Christmastide, a term associated with Yuletide, which runs from December 25 (Christmas Day) to January 5 (Epiphany Eve), popularly known as the 12 Days of Christmas. However, as the economic impact involving the anticipatory lead-up to Christmas Day grew in America and Europe into the 19th and 20th centuries, the term \"Christmas season\" began to become synonymous instead with the traditional Christian Advent season, the period observed in Western Christianity from the fourth Sunday before Christmas Day until Christmas Day itself. The term \"Advent calendar\" survives in secular Western parlance as a term referring to a countdown to Christmas Day from the beginning of December.\n\nBeginning in the mid-20th century, as the Christian-associated Christmas holiday became increasingly secularized and central to American economics and culture while religio-multicultural sensitivity rose, generic references to the season that omitted the word \"Christmas\" became more common in the corporate and public sphere of the United States, which has caused a semantics controversy that continues to the present. By the late 20th century, the Jewish holiday of Hanukkah and the new African American cultural holiday of Kwanzaa began to be considered in the U.S. as being part of the \"holiday season\", a term that as of 2013 has become equally or more prevalent than \"Christmas season\" in U.S. sources to refer to the end-of-the-year festive period. \"Holiday season\" has also spread in varying degrees to Canada; however, in the United Kingdom and Ireland, the phrase \"holiday season\" is not widely synonymous with the Christmas–New Year period, and is often instead associated with summer holidays.\n\nSaturnalia was an ancient Roman festival in honor of the deity Saturn, held on December 17 of the Julian calendar and later expanded with festivities through December 23. The holiday was celebrated with a sacrifice at the Temple of Saturn, in the Roman Forum, and a public banquet, followed by private gift-giving, continual partying, and a carnival atmosphere that overturned Roman social norms: gambling was permitted, and masters provided table service for their slaves. The poet Catullus called it \"the best of days.\"\n\nThe earliest source stating December 25 as the date of birth of Jesus was Hippolytus of Rome (170–236), written very early in the 3rd century, based on the assumption that the conception of Jesus took place at the Spring equinox which he placed on March 25, and then added nine months. There is historical evidence that by the middle of the 4th century the Christian churches of the East celebrated the birth and Baptism of Jesus on the same day, on January 6 while those in the West celebrated a Nativity feast on December 25 (perhaps influenced by the Winter solstice); and that by the last quarter of the 4th century, the calendars of both churches included both feasts. The earliest suggestions of a fast of Baptism of Jesus on January 6 during the 2nd century comes from Clement of Alexandria, but there is no further mention of such a feast until 361 when Emperor Julian attended a feast on January 6 in the year 361.\n\nIn the Christian tradition the Christmas season is a period \"beginning\" on Christmas Day (December 25). In some churches (e.g. the Anglican Communion) the season continues until the day before the Epiphany, which is celebrated either on January 6 or on the Sunday between January 2 and 8. In other churches (e.g. the Roman Catholic Church) it continues until the feast of the Baptism of the Lord, which falls on the Sunday following the Epiphany, or on the Monday following the Epiphany if the Epiphany is moved to January 7 or 8. If the Epiphany is kept on January 6, the Church of England's use of the term \"Christmas season\" corresponds to the Twelve Days of Christmas, and ends on Twelfth Night.\n\nThis short Christmas season is preceded by Advent, which begins on the fourth Sunday before Christmas Day: the majority of the secularized Christmas and holiday season falls during Advent. The Anglican Communion and some Protestant churches follow the Christmas season with an Epiphany season which lasts until Shrove Tuesday which is also known as Mardi Gras or 'Fat Tuesday'. Other European cultures have their own carnival festivities between new year and Lent.\n\nAccording to Yanovski et al., in the United States the holiday season \"is generally considered to begin with the day after Thanksgiving and end after New Year's Day\". According to Axelrad, the season in the United States encompasses at least Christmas and New Year's Day, and also includes Saint Nicholas Day. The U.S. Fire Administration defines the \"Winter Holiday Season\" as the period from December 1 to January 7. According to Chen et al., in China the Christmas and holiday season \"is generally considered to begin with the winter solstice and end after the Lantern Festival\". Some stores and shopping malls advertise their Christmas merchandise beginning after Halloween or even in late October, alongside Halloween items. In the UK and Ireland, Christmas food generally appears on supermarket shelves as early as September or even August, while the Christmas shopping season itself starts from mid November when the high street Christmas lights are switched on.\n\nThe precise definition of feasts and festival days that are encompassed by the Christmas and holiday season has become controversial in the United States over recent decades. While in other countries the only holidays included in the \"season\" are Christmas Eve, Christmas Day, St. Stephen's Day/Boxing Day, New Year's Eve, New Year's Day and Epiphany, in recent times, this definition in the U.S. has begun to expand to include Yule, Hanukkah, Kwanzaa, Thanksgiving, Black Friday and Cyber Monday. The expansion of the holiday season in the U.S. to encompass Thanksgiving is believed to have begun in the 1920s, when major department stores Macy's and Gimbels launched dueling Thanksgiving Day parades to promote Christmas sales. Due to the phenomenon of Christmas creep and the informal inclusion of Thanksgiving, the Christmas and holiday season has begun to extend earlier into the year, overlapping Veterans/Remembrance/Armistice Day, Halloween and Guy Fawkes Night.\n\nThe exchange of gifts is central to the Christmas and holiday season, and the season thus also incorporates a \"holiday shopping season\". This comprises a peak time for the retail sector at the start of the holiday season (the \"Christmas shopping season\") and a period of sales at the end of the season, the \"January sales\".\n\nAlthough once dedicated mostly to white sales and clearance sales, the January sales now comprise both winter close-out sales and sales comprising the redemption of gift cards given as presents. Young-Bean Song, director of analytics at the Atlas Institute in Seattle, states that it is a \"myth that the holiday shopping season starts with Thanksgiving and ends with Christmas. January is a key part of the holiday season.\" stating that for the U.S. e-commerce sector January sales volumes matched December sales volumes in the 2004/2005 Christmas and holiday season.\n\nMany people find this time particularly stressful. As a remedy, and as a return to what they perceive as the root of Christmas, some practice alternative giving.\n\nIn the United States, the holiday season is a particularly important time for retail shopping, with shoppers spending more than $600 billion during the 2013 holiday season, averaging about $767 per person. During the 2014 holiday shopping season, retail sales in the United States increased to a total of over $616 billion, and in 2015, retail sales in the United States increased to a total of over $630 billion, up from 2014's $616 billion. The average US holiday shopper spent on average $805. More than half of it was spent on family shopping.\n\nIt is traditionally considered to commence on the day after American Thanksgiving, a Friday colloquially known as either Black Friday or Green Friday. This is widely reputed to be the busiest shopping day of the entire calendar year. However, in 2004 the VISA credit card organization reported that over the previous several years VISA credit card spending had in fact been 8 to 19 percent higher on the last Saturday before Christmas Day (i.e., Super Saturday) than on Black Friday. A survey conducted in 2005 by GfK NOP discovered that \"Americans aren't as drawn to Black Friday as many retailers may think\", with only 17% of those polled saying that they will begin holiday shopping immediately after Thanksgiving, 13% saying that they plan to finish their shopping before November 24 and 10% waiting until the very last day before performing their holiday gift shopping.\nAccording to a survey by the Canadian Toy Association, peak sales in the toy industry occur in the Christmas and holiday season, but this peak has been occurring later and later in the season every year.\n\nIn 2005, the kick-off to the Christmas and holiday season for online shopping, the first Monday after US Thanksgiving, was named Cyber Monday. Although it was a peak, that was not the busiest on-line shopping day of that year. The busiest on-line shopping days were December 12 and 13, almost two weeks later; the second Monday in December has since become known as Green Monday. Another notable day is Free Shipping Day, a promotional day that serves as the last day in which a person can order a good online and have it arrive via standard shipping (the price of which the sender pays) prior to Christmas Eve; this day is usually on or near December 16. Four of the largest 11 on-line shopping days in 2005 were December 11 to 16, with an increase of 12% over 2004 figures. In 2011, Cyber Monday was slightly busier than Green Monday and Free Shipping Day, although all three days registered sales of over US$1 billion, and all three days registered gains ranging from 14% to 22% over the previous year. Analysts had predicted the peak on December 12, noting that Mondays are the most popular days for on-line shopping during the holiday shopping season, in contrast to the middle of the week during the rest of the year. They attribute this to people \"shopping in stores and malls on the weekends, and [...] extending that shopping experience when they get into work on Monday\" by \"looking for deals, [...] comparison shopping and [...] finding items that were out of stock in the stores\".\n\nIn 2006, the average US household was expected to spend about $1,700 on Christmas and holiday spendings. Retail strategists such as ICSC Research observed in 2005 that 15% of holiday expenditures were in the form of gift certificates, a percentage that was rising. So they recommended that retailers manage their inventories for the entire holiday shopping season, with a leaner inventory at the start and new winter merchandise for the January sales.\n\nMichael P. Niemira, chief economist and director of research for the Shopping Center Council, states that he expects gift certificate usage to be between US$30billion and US$40billion in the 2006/2007 holiday shopping season. On the basis of the growing popularity of gift certificates, he states that \"To get a true picture of holiday sales, one may consider measuring October, November, December and January sales combined as opposed to just November and December sales.\", because with \"a hefty amount of that spending not hitting the books until January, extending the length of the season makes sense\".\n\nAccording to the Deloitte 2007 Holiday Survey, for the fourth straight year, gift cards are expected to be the top gift purchase in 2007, with more than two-thirds (69 percent) of consumers surveyed planning to buy them, compared with 66 percent in 2006. In addition, holiday shoppers are planning to buy even more cards this year: an average of 5.5 cards, compared with the 4.6 cards they planned to buy last year. One in six consumers (16 percent) plan to buy 10 or more cards, compared with 11 percent last year. Consumers are also spending more in total on gift cards and more per card: $36.25 per card on average compared with $30.22 last year. Gift cards continue to grow in acceptance: Almost four in 10 consumers surveyed (39 percent) would rather get a gift card than merchandise, an increase from last year’s 35 percent. Also, resistance to giving gift cards continues to decline: 19 percent say they don’t like to give gift cards because they’re too impersonal (down from 22 percent last year). Consumers said that the cards are popular gifts for adults, teens and children alike, and almost half (46 percent) intend to buy them for immediate family; however, they are hesitant to buy them for spouses or significant others, with only 14 percent saying they plan to buy them for those recipients.\n\nSome stores in Canada hold Boxing Week sales (before the end of the year) for income tax purposes.\n\nWhat has become known as \"Christmas creep\" refers to a merchandising phenomenon in which merchants and retailers exploit the commercialized status of Christmas by moving up the start of the holiday shopping season. The term was first used in the mid-1980s, and is associated with a desire of merchants to take advantage of particularly heavy Christmas-related shopping well before Black Friday in the United States and before Halloween in Canada.\n\nThe term is not used in the UK and Ireland, where retailers call Christmas the \"golden quarter\", that is, the three months of October through December is the quarter of the year in which the retail industry hopes to make the most profit. It can apply for other holidays as well, notably Valentine's Day, Easter and Mother's Day.\n\nIn the Republic of Ireland and the United Kingdom, the Christmas shopping season starts from mid-November, around the time when high street Christmas lights are turned on. In the UK in 2010, up to £8 billion was expected to be spent online at Christmas, approximately a quarter of total retail festive sales. Retailers in the UK call Christmas the \"golden quarter\", that is, the three months of October to December is the quarter of the year in which the retail industry hopes to make the most money. In Ireland, around early December or late November each year, The Late Late Toy Show is broadcast on Irish television, which features all the popular toys throughout the year being demonstrated and showcased before the holiday season and shopping sprees commence.\n\nThe Netherlands and Belgium have a double holiday. The first one, the arrival of the Bishop Saint Nicholas and Black Peter, starts about mid November, with presents being given on December 5 or 6. This is a separate holiday from Christmas, Bishop Saint Nick (Sinterklaas) and Santa Claus (Kerstman) being different people. Netherlands and Belgium often do not start the Christmas season until December 6 or 7, i.e. after Sinterklaas has finished.\n\nIn France, the January sales are restricted by legislation to no more than four weeks in Paris, and no more than six weeks for the rest of the country, usually beginning on the first Wednesday in January, and are one of only two periods of the year when retailers are permitted to hold sales.\n\nIn Italy, the January sales begin on the first weekend in January, and last for at least six weeks.\n\nIn Croatia and Bosnia (predominantly Sarajevo) the sales periods are regulated by the Consumer Protection Act. The January sales period starts on December 27 and can last up to 60 days.\n\nIn Germany, the \"Winterschlussverkauf\" (winter sale before the season ends) was one of two official sales periods (the other being the \"Sommerschlussverkauf\", the summer sales). It begins on the last Monday in January and lasts for 12 days, selling left-over goods from the holiday shopping season, as well as the winter collections. However, unofficially, goods are sold at reduced prices by many stores throughout the whole of January. By the time the sales officially begin the only goods left on sale are low-quality ones, often specially manufactured for the sales. Since a legislative reform to the corresponding law in 2004, season sales are now allowed over the whole year and are no longer restricted to season-related goods. However, voluntary sales still called \"Winterschlussverkauf\" take place further on in most stores at the same time every year.\n\nIn Sweden, where the week of the first Advent Sunday marks the official start of the Christmas and holiday season, continuing with Saint Lucy's Day on December 13, followed up by Christmas before the \"Mellandagsrea\" (between days sell off) traditionally begins on December 27 (nowadays often December 26 or even December 25) and lasts during the rest of the Christmas holiday. It is similar to Black Friday, but lasts longer. They last 34–35 days. Black Friday itself has also gained publicity in Sweden since the early-2010s. The Swedish Christmas and holiday season continues over Epiphany, and finally ends on St. Knut's Day when the children have a Knut's party.\n\nIn Bosnia (Republika Srpska), Montenegro and Serbia, holiday sales starts in the middle of December and last for at least one month.\n\nHong Kong, China has a lot of seasonal activities and traditions to offer around Christmas time. December 25 and 26 are Public Holidays that makes most shops open for shopping. Locals and tourists love to watch the 30-meter Swarovski Christmas tree in the Central as well as the Christmas light displays on buildings on Victoria Harbour. A huge party in Hong Kong called Winterfest is celebrated every year which involves malls, shops, theme parks and other attractions.\n\nThe Philippines has the longest Christmas season, reportedly. As early as September up until January 9, which is the feast of the Black Nazarene (the season ends on the Feast of the Lord's Baptism on the 2nd Sunday of January or the Monday after Epiphany if the 2nd Sunday is marked as such), Carolers can be typically heard going door to door serenading fellow Filipinos in exchange of money. All over the entire country, parols (star shaped lanterns) are hung everywhere and lights are lit. Simbang Gabi or dawn masses start December 16 and run for nine days up until Christmas Eve.\n\nSouth Korea's population are 30% Christian and Christmas is a Public Holiday. According to the \"Washington Post\", \"Koreans prefer cash Christmas gifts over more creative presents.\"\n\nSingapore widely celebrates Christmas which is a Public Holiday in this country. For six weeks, mid-November to early January, the stretch of Orchard Road glitters with lights from decorated trees and building facades of malls and hotels.\n\nA selection of goodwill greetings are often used around the world to address strangers, family, colleagues or friends during the season. Some greetings are more prevalent than others, depending on culture and location. Traditionally, the predominant greetings of the season have been \"Merry Christmas\", \"Happy Christmas\", and \"Happy New Year\". In the mid-to-late 20th century in the United States, more generic greetings such as \"Happy Holidays\" and \"Season's Greetings\" began to rise in cultural prominence, and this would later spread to other Western countries including Canada, Australia and to a lesser extent some European countries. A 2012 poll by Rasmussen Reports indicated that 68% of Americans prefer the use of \"Merry Christmas\", while 23% preferred \"Happy Holidays\". A similarly-timed Canadian poll conducted by Ipsos-Reid indicated that 72% of Canadians preferred \"Merry Christmas\".\n\nThe greetings and farewells \"Merry Christmas\" and \"Happy Christmas\" are traditionally used in English-speaking countries, starting a few weeks before Christmas (December 25) each year.\n\nVariations are:\nThese greetings and their equivalents in other languages are popular not only in countries with large Christian populations but also in the largely non-Christian nations of China and Japan, where Christmas is celebrated primarily due to cultural influences of predominantly Christian countries. They have somewhat decreased in popularity in the United States and Canada in recent decades, but polls in 2005 indicated that they remained more popular than \"Happy Holidays\" or other alternatives.\n\n\"Merry,\" derived from the Old English \"myrige\", originally meant merely \"pleasant, agreeable\" rather than joyous or jolly (as in the phrase \"merry month of May\").\nChristmas has been celebrated since the 4th century AD, the first known usage of any Christmas greeting dates was in 1534. \"Merry Christmas and a Happy New Year\" (thus incorporating two greetings) was in an informal letter written by an English admiral in 1699. The same phrase is contained in the title of the English carol \"We Wish You a Merry Christmas,\" and also appears in the first commercial Christmas card, produced by Henry Cole in England in 1843.\n\nAlso in 1843, Charles Dickens' \"A Christmas Carol\" was published, during the mid Victorian revival of the holiday. The word Merry was then beginning to take on its current meaning of \"jovial, cheerful, jolly and outgoing\". \"Merry Christmas\" in this new context figured prominently in \"A Christmas Carol\". The cynical Ebenezer Scrooge rudely deflects the friendly greeting: \"If I could work my will … every idiot who goes about with 'Merry Christmas' on his lips should be boiled with his own pudding.\" After the visit from the Ghosts of Christmas effects his transformation, Scrooge exclaims; \"I am as merry as a school-boy. A merry Christmas to everybody!\" and heartily exchanges the wish to all he meets. The instant popularity of \"A Christmas Carol\", the Victorian era Christmas traditions it typifies, and the term's new meaning appearing in the book popularized the phrase \"Merry Christmas\".\n\nThe alternative \"Happy Christmas\" gained usage in the late 19th century, and in the UK and Ireland is a common spoken greeting, along with \"Merry Christmas\". One reason may be the Victorian middle class influence in attempting to separate wholesome celebration of the Christmas season from public insobriety and associated asocial behaviour, at a time when \"merry\" also meant \"intoxicated\" – Queen Elizabeth II is said to prefer \"Happy Christmas\" for this reason. In her annual Christmas messages to the Commonwealth, Queen Elizabeth has used \"happy Christmas\" far more often than \"merry Christmas\".\n\nIn the American poet Clement Moore's \"A Visit from St. Nicholas\" (1823), the final line, originally written as \"Happy Christmas to all, and to all a good night\", has been changed in many later editions to \"Merry Christmas to all\", perhaps indicating the relative popularity of the phrases in the US.\n\nIn the United States, \"Happy Holidays\" (along with the similarly generalized \"Season's Greetings\") has become a common holiday greeting in the public sphere of department stores, public schools and greeting cards. Its use is generally confined to the period between United States Thanksgiving and New Year's Day. The phrase \"Happy Holidays\" has been used as a Christmas greeting in the United States for more than 100 years.\n\nThe increasing usage of \"Happy Holidays\" has been the subject of some controversy in the United States. Advocates claim that \"Happy Holidays\" is an inclusive greeting that is not intended as an attack on Christianity or other religions, but is rather a response to what they say is the reality of a growing non-Christian population.\n\nCritics of \"Happy Holidays\" generally claim it is a secular neologism. The greeting may be deemed materialistic, consumerist, atheistic, indifferentist, agnostic, politically correct and/or anti-Christianity. Critics of the phrase have associated it with a larger cultural clash termed the \"War on Christmas\".\n\n\"Season's Greetings\" is a greeting more commonly used as a motto on winter season greeting cards, and in commercial advertisements, than as a spoken phrase. In addition to \"Merry Christmas\", Victorian Christmas cards bore a variety of salutations, including \"Compliments of the Season\" and \"Christmas Greetings.\" By the late 19th century, \"With the Season's Greetings\" or simply \"The Season's Greetings\" began appearing. By the 1920s it had been shortened to \"Season's Greetings\", and has been a greeting card fixture ever since. Several White House Christmas cards, including U.S. President Dwight D. Eisenhower's 1955 card, have featured the phrase.\n\nVarious studies have been performed on the effects of the Christmas and holiday season, which encompasses several feast days, on health. They have concluded that the health changes that occur during the Christmas and holiday season are not reversed during the rest of the year and have a long-term cumulative effect over a person's life, and that the risks of several medical problems increase during the Christmas and holiday season.\n\nYanovski et al. investigated the assertion that the average American gains weight over the season. They found that average weight gain over the Christmas and holiday season is around . They also found that this weight gain is not reversed over the rest of the year, and concluded that this \"probably contributes to the increase in body weight that frequently occurs during adulthood\" (cf Lent).\n\nChan et al. investigated the increases in A1C and fasting plasma glucose in type 2 diabetic patients, to see whether these increases were steady throughout the year or varied seasonally. They concluded that the winter holidays did influence the glycemic control of the patients, with the largest increases being during that period, increases that \"might not be reversed during the summer and autumn months\".\n\nThe Christmas and holiday season, according to a survey by the ADA, is the second most popular reason, after birthdays, for sharing food in the workplace. The British Columbia Safety Council states that if proper food safety procedures are not followed, food set out for sharing in the workplace can serve as a breeding ground for bacteria, and recommends that perishable foods (for which it gives pizza, cold cuts, dips, salads, and sandwiches as examples) should not sit out for more than 2 hours.\n\nA survey conducted in 2005 found shopping caused headaches in nearly a quarter of people and sleeplessness in 11 percent.\n\nPhillips et al. investigated whether some or all of the spike in cardiac mortality that occurs during December and January could be ascribed to the Christmas/New Year's holidays rather than to climatic factors. They concluded that the Christmas and holiday season is \"a risk factor for cardiac and noncardiac mortality\", stating that there are \"multiple explanations for this association, including the possibility that holiday-induced delays in seeking treatment play a role in producing the twin holiday spikes\".\n\nThe Asthma Society of Canada states that the Christmas and holiday season increases exposure to irritants because people spend 90% of their time indoors, and that seasonal decorations in the home introduce additional, further, irritants beyond the ones that exist all year around. It recommends that asthmatics avoid scented candles, for example, recommending either that candles not be lit or that soy or beeswax candles be employed.\n\nAccording to the Stanford Recycling Center Americans throw away 25% more trash during the Christmas and holiday season than at other times of the year.\n\nBecause of the cold weather in the Northern Hemisphere, the Christmas and holiday season (as well as the second half of winter) is a time of increased use of fuel for domestic heating. This has prompted concerns in the United Kingdom about the possibility of a shortage in the domestic gas supply. However, in the event of an exceptionally long cold season, it is industrial users, signed on to interruptible supply contracts, who would find themselves without gas supply.\n\nThe U.S. Fire Administration states that the Christmas and holiday season is \"a time of elevated risk for winter heating fires\" and that the fact that many people celebrate the different holidays during the Christmas and holiday season by decorating their homes with seasonal garlands, electric lights, candles, and banners, has the potential to change the profile of fire incidence and cause. The Government of Alberta Ministry of Municipal Affairs states that candle-related fires rise by 140% during the Christmas and holiday season, with most fires involving human error and most deaths and injuries resulting from the failure to extinguish candles before going to bed. It states that consumers don't expect candle holders to tip over or to catch fire, assuming that they are safe, but that in fact candle holders can do this.\n\nBecause of increased alcohol consumption at festivities and poorer road conditions during the winter months, alcohol-related road traffic accidents increase over the Christmas and holiday season.\n\nIn the United States, the Establishment Clause of the First Amendment to the Constitution of the United States has had significant legal impact upon the activities of governments and of state-funded public schools during and relating to the Christmas and holiday season, and has been the source of controversy.\n\nPublic schools are subject to what the Anti-Defamation League terms the \"December Dilemma\", namely the task of \"acknowledging the various religious and secular holiday traditions celebrated during that time of year\" whilst restricting observances of the various religious festivals to what is constitutionally permissible. The ADL and many school district authorities have published guidelines for schools and for teachers. For example: The directive on maintaining religious neutrality in public schools over the Christmas and holiday season, given to public school administrators in the District of Columbia by the Superintendent, contains several points on what may and may not be taught in the D.C. school district, the themes of parties and concerts, the uses of religious symbols, the locations of school events and classes and prayer.\n\nIn 2002, for the Christmas and holiday season, Moscow mayor Yuriy Luzhkov ordered all stores, restaurants, cafés and markets to display seasonal decorations and lights in their windows and interiors from December 1 onwards. Banks, post offices and public institutions were to do the same from December 15, with violators liable for fines of up to 200 rubles. Every business was ordered to have illuminated windows during the hours of 16:30 until 01:00. This caused a mixed reaction, with people objecting to being forced to put up decorations.\n\n\n\n"}
{"id": "51755560", "url": "https://en.wikipedia.org/wiki?curid=51755560", "title": "Cold-energy battery", "text": "Cold-energy battery\n\nA cold-energy battery utilizes the properties of an advanced phase-change material (PCM) to maintain temperature as battery thermal management. As with a standard electrical battery, a cold energy battery stores energy and releases depending on the energy demand on it. It can then be recharged by placing in a temperature environment conducive to the phase change properties of the PCM.\n\n"}
{"id": "1582312", "url": "https://en.wikipedia.org/wiki?curid=1582312", "title": "Core countries", "text": "Core countries\n\nIn world systems theory, the core countries are the industrialized capitalist countries on which periphery countries and semi-periphery countries depend. Core countries control and benefit from the global market. They are usually recognized as wealthy nations with a wide variety of resources and are in a favorable location compared to other states. They have strong state institutions, a powerful military and powerful global political alliances.\n\nCore countries do not always stay core permanently. Throughout history, core nations have been changing and new ones have been added to the core list. The most influential countries in the past have been what would be considered core. These were the Asian, Indian and Middle Eastern empires in the ages up to the 16th century, prominently India and China were the richest regions in the world until the 15th century, when the European powers took the lead, although the major Asian powers such as China were still very influential in the region. Europe remained ahead of the pack until the 20th century, when the two World Wars turned disastrous for the European economies. It is then that the victorious United States and Soviet Union, up to late 1980s, became the two hegemons, creating a bipolar world order.\nThe heart of civilisation consists of Western Europe, North America, Australasia and Japan. The population of the core is by far the wealthiest and best educated on the planet.\n\nCore countries control and profit the most from the world system, and thus they are the \"core\" of the world system. These countries possess the ability to exercise control over other countries or groups of countries with several kinds of power such as military, economic, and political power.\n\nThe United States, Canada, the countries of the European Union, Australia, South Korea and Japan are examples of present core countries that have the most power in the world economic system. Core countries tend to have both strong state machinery and a developed national culture.\n\nBefore the 13th century, many empires were considered to be \"core\" nations, such as the Persian, Indian, and Roman empires, the Muslim Caliphates, the Chinese and Egyptian dynasties, the various Mesopotamian kingdoms, and so on.\n\nIn Asia, the Chinese Empire was considered the middle kingdom and controlled the region. The two empires communicated and traded through the Silk Route, which takes its name from the extensive trade of Chinese silk.\n\nIndia until the 13th century, often referred to as Greater India, extended its religious, cultural, and trading influence on vast Asian regions from Iran and Afghanistan to Malaysia, Indonesia and Cambodia. With Buddhism and Hinduism, two of the most followed religions in Asia and the World as a whole, having originated there, India's cultural impact spread throughout Asia. A notable example is China, where Buddhism became the prominent religion. Sanskrit was a prominent scholarly language in all the southeastern kingdoms until the 10th century C.E.. Angkor Vat of Cambodia, the largest temple complex in the world, was originally a Hindu temple and later transformed into a Buddhist monastery.\n\nPax Mongolica is a particularly important period which started in 1206 and ended, according to contradicting sources, between late 14th and early 15th centuries. The trade during this period took on a truly multi-continental dimension, efficient and safe trade routes were established, and many of the modern rules of trade were emerging. The Mongol Empire was the largest contiguous empire in the history of the world. It stretched from as far east as China all the way to Europe, taking up large parts of Central Asia, Middle East, and India.\nMany trade routes went through the Mongol Empire territory, even though they were not the easiest ones to travel, due to the rough Asian terrain. Yet, they attracted many merchants, because these routes were relatively cheap and safe to travel. The Mongols controlled their territories through military force and taxation. In many regions of the Mongol territory, Mongol rule is remembered as brutal and destructive. Yet, some argue that many economic and cultural improvements were made during the Mongol Empire's rule.\n\nThe Ottoman Empire, which emerged in 1299, quickly became a power to be reckoned with. By 1450, the Ottoman Empire took up the connecting territory between the Black and Mediterranean seas. Despite lasting three times longer than the Mongol Empire, the Ottoman Empire never came to be anywhere near as expansive.\n\nPrior to the 16th century, feudalism took over Western European society and pushed Western Europe on a road to capitalist development. Population and commerce grew rapidly within the feudal system during the years of 1150–1300. Through the years 1300–1450, an economic downfall came about. The feudalism growth had come to an end. According to Wallerstein, \"the feudal crisis was most likely brought on by the involvement of the three following factors below:\n\nThe feudal crisis lead to the development of the world economic system. The world economic system came about during the late 15th and early 16th centuries. The most dominant of Northwestern Europe were England, France, and the Netherlands (see map of Western Europe on the right). These countries took on the definition of a core country. They developed a strong central government, bureaucracies, and grew their military power. These countries were then able to control the international commerce and create a profit for themselves. All of western Europe attempted bureaucratization, homogenization of the local population, development of a stronger military, and involvement of the country in a vast number of different economic activities. After these attempts to gain the \"core\" status, north-western European states locked in their positions as core states by 1640. England dominated the pack, as Spain and Italy fell to semi-peripheral status.\n\nOne factor that helped the core countries dominate over the other countries is long-distance trade with the Americas and the East. This trade produced profits of 200–300%. In order to enter this trade market, countries needed a great amount of capital and state help. The smaller countries could not make this happen, and this widened the gap between the \"core\" and \"semi-periphery\" countries. These core positions held strong up and throughout the 18th century, even as the core regions started to produce a mixture of agricultural and industrial goods. At the beginning of 1700, manufacture of goods in industrial productions started to take off. Industrial production soon took over the agricultural production up to the year 1900.\n\nAs nations continued to grow technologically, especially through printing journals and newspapers, communication was more widespread. Thus, the global society was united through this force. In order to assure a good life for their citizens, countries needed to rely on trade and on technological advancements, which ultimately determined how well in the world a country stood.\n\nKeeping in mind the interactions of nations in this period, John W. Cell notes in his essay entitled \"Europe and the World in an Expanding World Economy, 1700—1850\", that war and trade were somewhat dependent on each other. Nations had to defend their ships while also establishing territories elsewhere to ensure successful trade for themselves. By the middle of the 17th century, the \"foundations of the modern world system had been laid.\"\n\nAt the beginning of the 18th century, Europe had not yet dominated in the world economy on account of the fact that its military did not match that of Asia or of the Middle East. However, through organizing its economics and improving technology in industry, European countries took the lead as the most powerful nations in the late 18th century and remained in this position until late in the 20th century.\n\nIn the 18th century, Asia was making and distributing goods that were valued by other areas, namely cotton, silk and tea. Europe on the other hand, was not producing products of interest to the other parts of the world. Hence, although Europe was wealthy, this dynamic shows that there may be a reversal of power because it was consistently expanding money, yet hardly bringing in currency. America's crops were not initially appealing to Europeans. Tobacco's demand had to be advertised, and eventually Europe became interested in this particular plant. In time, there was rather regular trans-Atlantic trade between the Americas and Europe for such crops as tobacco, cotton, and also goods available in South America.\n\nThe 18th century was profoundly marked by the slave trade. Slavery was present in civilizations on all continents throughout post-hunter-gatherer history. The importation of slaves from the Old World started on continental North America in August 1619 as a form of indentured servitude, and continued in the next centuries. Slavery also occurred in Africa previous to Europeans capitalizing on selling slaves. Africans were sometimes hired to collect others off the coast, and bring them back to European ships. Because of this trade, the dependent nations remained dependent as their populations were suffering from the slave trade.\n\nThis trade of humans was incredibly profitable for the Europeans, perpetuating their success and \"rule\" of the seas. Immediately following the early 19th century, the southern U.S. population consisted of 37.5% slaves.\n\nAt the beginning of the 19th century, Europe still dominated as the core region of the world. France attempted to obtain European hegemony under the rule of Napoleon Bonaparte.\n\nIn 1871, Germany became united and established themselves as the leading industrial nation on the European mainland. Their desire to dominate the mainland helped them to become a core nation. After the First World War, Europe was decimated, and the position for new core nations was opening up. This culminated with the defeat of Nazi Germany in the Second World War, when Britain was forced to sacrifice its hegemony, allowing the United States and the Soviet Union to become world superpowers and major cores. The USSR lost its core status following its collapse in 1991.\nThe following are core according to Chase-Dunn, Kawano, Brewer (2000).\n\nAnd this is the core listing according to Babones (2005), who notes that this list is composed of countries that \"have been consistently classified into a single one of the three zones [core, semi-periphery or periphery] of the world economy over the entire 28-year study period\".\n\nThe World Systems Theory argues that a nation's future is decided by their stance in the global economy. A global capitalistic market demands the needs for wealthy (core) states and poor (periphery) states. Core states benefit from the hierarchical structure of international trade and labor. World systems theory follows the logic that international wars or multinational financial disputes can be explained as attempts to change a location within the global market for a specific state or groups of states; these changes can have the objective to gain more control over the global market (to become a core country), while causing another nation to lose control over the world market. As the two groups grew apart in power, world systems theorists to established another group, the semi-periphery, to act as the middle group.\n\nSemi-periphery countries usually surround the core countries both in a physical and fundamental sense. The semi-periphery countries act as the middle men between the core and the periphery countries - by giving the wealthy countries what they receive from the poor countries. The periphery countries are the poorer countries usually specializing in farming and have access natural resources - which the core countries use to profit from.\n\nIn order for a country to remain a core or to become a core, possible investors must be kept in mind when nation's policies are planned. Core countries change with time due to many different factors including changes in geographic favoritism and regional affluence. Alterations in financing plans by companies will also play a part as they change to react to the continuously evolving world market.\n\nIn order for a country to be considered a core country nominee, the country must possess an independent, stable government and potential for growth in the global market and advances in technology. Although these three factors will not completely decide where a company chooses to invest – they do play extremely large roles in such decisions. A main key to becoming or remaining a core is determined by the country's government policies to encourage funding from outside.\n\nThe main function of the core countries is to command and financially benefit from the world system better than the rest of the world. Core countries could also be viewed as the capitalist class while the periphery countries could be viewed as a disordered working class. In a capitalism-driven market, core countries exchange goods with the poor nations at an unequal rate greatly in favor of the core countries.\n\nThe periphery countries’ purpose is to provide agricultural and natural resources along with the lower division of labor for larger corporations of semi-periphery and core countries. As a result of the lower priced division of labor and natural resources available, the core nations’ companies buy these products for a relatively low cost and then sell them for much higher. The periphery countries only receive low amounts of money for what they sell and must pay higher prices for anything they buy from outside their own region. Because of this continuous order, periphery countries can never earn enough to cover the costs of their imports while setting aside money to invest in better technologies. Core countries support this pattern by giving loans to the poor regions for specific investments in a raw material or type of agriculture, rather than help such regions establish themselves and balance out the world market.\n\nA disadvantage to core nations is to remain a member of the core grouping, the government must retain or create new policies that encourage investments to keep in their country and not relocate. This can make it difficult for governments to change national standards that may sacrifice high profits.\n\nAn example of a change that capitalism does not favor is the abolition of slavery. During the early industrialization and growth of America, exports produced by slaves played a huge role in making businesses the most profit. Such movements to abolish slavery and spread equality caused an internal war within the United States.\n\n"}
{"id": "12685721", "url": "https://en.wikipedia.org/wiki?curid=12685721", "title": "Displacement receiver", "text": "Displacement receiver\n\nA displacement receiver is a device that responds to or is sensitive to directed distance (displacement).\n\nExamples of displacement receivers include carbon microphones, strain gauges, and pressure sensors or force sensors, which, to within an appropriate scale factor, respond to distance.\n\nIn music, certain music keyboards can be considered displacement receivers in the sense that they respond to displacement, rather than velocity (as is more commonly the case).\n\nExamples of displacement-responding sensors include the mechanical action of tracker organs, as well as the force-sensing resistors found in music keyboards that had polyphonic aftertouch capability. Polyphonic aftertouch is no longer a feature of presently manufactured keyboards, but certain older models such as the Roland A50 featured a pressure sensing resistor, similar in principle-of-operation to a carbon microphone, in each key.\n"}
{"id": "5180948", "url": "https://en.wikipedia.org/wiki?curid=5180948", "title": "Emmert's law", "text": "Emmert's law\n\nEmmert's law states that objects that generate retinal images of the same size will look different in physical size (linear size) if they appear to be located at different distances. Specifically, the \"perceived linear size\" of an object increases as its \"perceived\" distance from the observer increases. This makes intuitive sense: an object of constant size will project progressively smaller retinal images as its distance from the observer increases. Similarly, if the retinal images of two \"different\" objects at different distances are the same, the physical size of the object that is farther away must be larger than the one that is closer.\n\nEmil Emmert (1844–1911) first described the law in 1881. He noted that an afterimage appeared to increase in size when projected to a greater distance. It is unclear whether he intended this to mean physical distance or perceived distance, but most authors assume the latter.\n\nThe effect of viewing distance on perceived size can be observed by first obtaining an afterimage, which can be achieved by viewing a bright light for a short time, or staring at a figure for a longer time. It appears to grow in size when projected to a further distance. However, the increase in perceived size is much less than would be predicted by geometry, which casts some doubt on the geometrical interpretation given above. \n\nEmmert's law is closely related to size constancy, and has been used to investigate the moon illusion (the apparent enlargement of the moon or sun near the horizon compared with higher in the sky). A recent neuroimaging study that examined brain activation when participants viewed afterimages on surfaces placed at different distances found evidence supporting Emmert's Law and thus size constancy played out in primary visual cortex (V1); i.e. the larger the perceived size of the afterimage, the larger the retinotopic activation in V1.\n\n"}
{"id": "23325935", "url": "https://en.wikipedia.org/wiki?curid=23325935", "title": "Energy in Burkina Faso", "text": "Energy in Burkina Faso\n\nEnergy in Burkina Faso is a growing industry with tremendous potential.\n\nAll petroleum products are imported since the country has no known crude oil reserves or refining capacity . Imports and consumption of petroleum in 2002 amounted to 8,870 barrels per day. As for natural gas, Burkina Faso is known to have no natural gas production, consumption, or reserves.\n\nElectricity accounts for all energy production. Total installed electrical capacity in 2001 was 121 MW. Production rose from 42 GWh in 1973 to 280 GWh in 2001, of which 73.6% was thermal and 26.4% hydroelectric. Consumption of electricity was 0.26 billion kWh in 2001. Construction of a 15 MW hydroelectric facility at Kompienga was finished in 1989. In 1999, with a grant from the government of Denmark, Burkina Faso built a new power station, completing it in just five months to meet the country's emergency energy needs. Production and distribution of electricity and water are controlled by the state-owned Société Nationale d'électricité du Burkina Faso (SONABEL), established in Ouagadougou in 1968.\n\nAs of 2008, it is estimated 7% of Burkina Faso have access to electricity.\n"}
{"id": "9696", "url": "https://en.wikipedia.org/wiki?curid=9696", "title": "Erosion", "text": "Erosion\n\nIn earth science, erosion is the action of surface processes (such as water flow or wind) that removes soil, rock, or dissolved material from one location on the Earth's crust, and then transports it to another location (not to be confused with weathering which involves no movement). This natural process is caused by the dynamic activity of erosive agents, that is, water, ice (glaciers), snow, air (wind), plants, animals, and humans. In accordance with these agents, erosion is sometimes divided into water erosion, glacial erosion, snow erosion, wind (aeolic) erosion, zoogenic erosion, and anthropogenic erosion.The particulate breakdown of rock or soil into clastic sediment is referred to as \"physical\" or \"mechanical\" erosion; this contrasts with \"chemical\" erosion, where soil or rock material is removed from an area by its dissolving into a solvent (typically water), followed by the flow away of that solution. Eroded sediment or solutes may be transported just a few millimetres, or for thousands of kilometres.\n\nNatural rates of erosion are controlled by the action of geological weathering geomorphic drivers, such as rainfall; bedrock wear in rivers; coastal erosion by the sea and waves; glacial plucking, abrasion, and scour; areal flooding; wind abrasion; groundwater processes; and mass movement processes in steep landscapes like landslides and debris flows. The rates at which such processes act control how fast a surface is eroded. Typically, physical erosion proceeds fastest on steeply sloping surfaces, and rates may also be sensitive to some climatically-controlled properties including amounts of water supplied (e.g., by rain), storminess, wind speed, wave fetch, or atmospheric temperature (especially for some ice-related processes). Feedbacks are also possible between rates of erosion and the amount of eroded material that is already carried by, for example, a river or glacier. Processes of erosion that produce sediment or solutes from a place contrast with those of deposition, which control the arrival and emplacement of material at a new location.\n\nWhile erosion is a natural process, human activities have increased by 10-40 times the rate at which erosion is occurring globally. At well-known agriculture sites such as the Appalachian Mountains, intensive farming practices have caused erosion up to 100x the speed of the natural rate of erosion in the region. Excessive (or accelerated) erosion causes both \"on-site\" and \"off-site\" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, the eventual end result is desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems worldwide.\n\nIntensive agriculture, deforestation, roads, anthropogenic climate change and urban sprawl are amongst the most significant human activities in regard to their effect on stimulating erosion. However, there are many prevention and remediation practices that can curtail or limit erosion of vulnerable soils.\n\nRainfall, and the surface runoff which may result from rainfall, produces four main types of soil erosion: \"splash erosion\", \"sheet erosion\", \"rill erosion\", and \"gully erosion\". Splash erosion is generally seen as the first and least severe stage in the soil erosion process, which is followed by sheet erosion, then rill erosion and finally gully erosion (the most severe of the four).\n\nIn \"splash erosion\", the impact of a falling raindrop creates a small crater in the soil, ejecting soil particles. The distance these soil particles travel can be as much as 0.6 m (two feet) vertically and 1.5 m (five feet) horizontally on level ground.\n\nIf the soil is saturated, or if the rainfall rate is greater than the rate at which water can infiltrate into the soil, surface runoff occurs. If the runoff has sufficient flow energy, it will transport loosened soil particles (sediment) down the slope. \"Sheet erosion\" is the transport of loosened soil particles by overland flow.\n\n\"Rill erosion\" refers to the development of small, ephemeral concentrated flow paths which function as both sediment source and sediment delivery systems for erosion on hillslopes. Generally, where water erosion rates on disturbed upland areas are greatest, rills are active. Flow depths in rills are typically of the order of a few centimetres (about an inch) or less and along-channel slopes may be quite steep. This means that rills exhibit hydraulic physics very different from water flowing through the deeper, wider channels of streams and rivers.\n\"Gully erosion\" occurs when runoff water accumulates and rapidly flows in narrow channels during or immediately after heavy rains or melting snow, removing soil to a considerable depth.\n\n\"Valley\" or \"stream erosion\" occurs with continued water flow along a linear feature. The erosion is both downward, deepening the valley, and headward, extending the valley into the hillside, creating head cuts and steep banks. In the earliest stage of stream erosion, the erosive activity is dominantly vertical, the valleys have a typical V cross-section and the stream gradient is relatively steep. When some base level is reached, the erosive activity switches to lateral erosion, which widens the valley floor and creates a narrow floodplain. The stream gradient becomes nearly flat, and lateral deposition of sediments becomes important as the stream meanders across the valley floor. In all stages of stream erosion, by far the most erosion occurs during times of flood when more and faster-moving water is available to carry a larger sediment load. In such processes, it is not the water alone that erodes: suspended abrasive particles, pebbles, and boulders can also act erosively as they traverse a surface, in a process known as \"traction\".\n\n\"Bank erosion\" is the wearing away of the banks of a stream or river. This is distinguished from changes on the bed of the watercourse, which is referred to as \"scour\". Erosion and changes in the form of river banks may be measured by inserting metal rods into the bank and marking the position of the bank surface along the rods at different times.\n\n\"Thermal erosion\" is the result of melting and weakening permafrost due to moving water. It can occur both along rivers and at the coast. Rapid river channel migration observed in the Lena River of Siberia is due to thermal erosion, as these portions of the banks are composed of permafrost-cemented non-cohesive materials. Much of this erosion occurs as the weakened banks fail in large slumps. Thermal erosion also affects the Arctic coast, where wave action and near-shore temperatures combine to undercut permafrost bluffs along the shoreline and cause them to fail. Annual erosion rates along a segment of the Beaufort Sea shoreline averaged per year from 1955 to 2002.\n\nMost river erosion happens nearer to the mouth of a river. On a river bend, the longest least sharp side has slower moving water. Here deposits build up. On the narrowest sharpest side of the bend, there is faster moving water so this side tends to erode away mostly.\n\nShoreline erosion, which occurs on both exposed and sheltered coasts, primarily occurs through the action of currents and waves but sea level (tidal) change can also play a role.\n\n\"Hydraulic action\" takes place when the air in a joint is suddenly compressed by a wave closing the entrance of the joint. This then cracks it. \"Wave pounding\" is when the sheer energy of the wave hitting the cliff or rock breaks pieces off. \"Abrasion\" or \"corrasion\" is caused by waves launching sea load at the cliff. It is the most effective and rapid form of shoreline erosion (not to be confused with \"corrosion\"). \"Corrosion\" is the dissolving of rock by carbonic acid in sea water. Limestone cliffs are particularly vulnerable to this kind of erosion. \"Attrition\" is where particles/sea load carried by the waves are worn down as they hit each other and the cliffs. This then makes the material easier to wash away. The material ends up as shingle and sand. Another significant source of erosion, particularly on carbonate coastlines, is boring, scraping and grinding of organisms, a process termed \"bioerosion\".\n\nSediment is transported along the coast in the direction of the prevailing current (longshore drift). When the upcurrent amount of sediment is less than the amount being carried away, erosion occurs. When the upcurrent amount of sediment is greater, sand or gravel banks will tend to form as a result of deposition. These banks may slowly migrate along the coast in the direction of the longshore drift, alternately protecting and exposing parts of the coastline. Where there is a bend in the coastline, quite often a buildup of eroded material occurs forming a long narrow bank (a spit). Armoured beaches and submerged offshore sandbanks may also protect parts of a coastline from erosion. Over the years, as the shoals gradually shift, the erosion may be redirected to attack different parts of the shore.\n\nChemical erosion is the loss of matter in a landscape in the form of solutes. Chemical erosion is usually calculated from the solutes found in streams. Anders Rapp pioneered the study of chemical erosion in his work about Kärkevagge published in 1960.\n\nGlaciers erode predominantly by three different processes: abrasion/scouring, plucking, and ice thrusting. In an abrasion process, debris in the basal ice scrapes along the bed, polishing and gouging the underlying rocks, similar to sandpaper on wood. Scientists have shown that, in addition to the role of temperature played in valley-deepening, other glaciological processes, such as erosion also control cross-valley variations. In a homogeneous bedrock erosion pattern, curved channel cross-section beneath the ice is created. Though the glacier continues to incise vertically, the shape of the channel beneath the ice eventually remain constant, reaching a U-shaped parabolic steady-state shape as we now see in glaciated valleys. Scientists also provide a numerical estimate of the time required for the ultimate formation of a steady-shaped U-shaped valley - approximately 100,000 years. In a weak bedrock (containing material more erodible than the surrounding rocks) erosion pattern, on the contrary, the amount of over deepening is limited because ice velocities and erosion rates are reduced.\n\nGlaciers can also cause pieces of bedrock to crack off in the process of plucking. In ice thrusting, the glacier freezes to its bed, then as it surges forward, it moves large sheets of frozen sediment at the base along with the glacier. This method produced some of the many thousands of lake basins that dot the edge of the Canadian Shield. Differences in the height of mountain ranges are not only being the result tectonic forces, such as rock uplift, but also local climate variations. Scientists use global analysis of topography to show that glacial erosion controls the maximum height of mountains, as the relief between mountain peaks and the snow line are generally confined to altitudes less than 1500 m. The erosion caused by glaciers worldwide erodes mountains so effectively that the term \"glacial buzzsaw\" has become widely used, which describes the limiting effect of glaciers on the height of mountain ranges. As mountains grow higher, they generally allow for more glacial activity (especially in the accumulation zone above the glacial equilibrium line altitude), which causes increased rates of erosion of the mountain, decreasing mass faster than isostatic rebound can add to the mountain. This provides a good example of a negative feedback loop. Ongoing research is showing that while glaciers tend to decrease mountain size, in some areas, glaciers can actually reduce the rate of erosion, acting as a \"glacial armor\". Ice can not only erode mountains but also protect them from erosion. Depending on glacier regime, even steep alpine lands can be preserved through time with the help of ice. Scientists have proved this theory by sampling eight summits of northwestern Svalbard using Be10 and Al26, showing that northwestern Svalbard transformed from a glacier-erosion state under relatively mild glacial maxima temperature, to a glacier-armor state occupied by cold-based, protective ice during much colder glacial maxima temperatures as the Quaternary ice age progressed.\n\nThese processes, combined with erosion and transport by the water network beneath the glacier, leave behind glacial landforms such as moraines, drumlins, ground moraine (till), kames, kame deltas, moulins, and glacial erratics in their wake, typically at the terminus or during glacier retreat.\n\nThe best-developed glacial valley morphology appears to be restricted to landscapes with low rock uplift rates (less than or equal to 2 mm per year) and high relief, leading to long-turnover times. Where rock uplift rates exceed 2 mm per year, glacial valley morphology has generally been significantly modified in postglacial time. Interplay of glacial erosion and tectonic forcing governs the morphologic impact of glaciations on active orogens, by both influencing their height, and by altering the patterns of erosion during subsequent glacial periods via a link between rock uplift and valley cross-sectional shape.\n\nAt extremely high flows, kolks, or vortices are formed by large volumes of rapidly rushing water. Kolks cause extreme local erosion, plucking bedrock and creating pothole-type geographical features called Rock-cut basins. Examples can be seen in the flood regions result from glacial Lake Missoula, which created the channeled scablands in the Columbia Basin region of eastern Washington.\n\nWind erosion is a major geomorphological force, especially in arid and semi-arid regions. It is also a major source of land degradation, evaporation, desertification, harmful airborne dust, and crop damage—especially after being increased far above natural rates by human activities such as deforestation, urbanization, and agriculture.\n\nWind erosion is of two primary varieties: \"deflation\", where the wind picks up and carries away loose particles; and \"abrasion\", where surfaces are worn down as they are struck by airborne particles carried by wind. Deflation is divided into three categories: (1) \"surface creep\", where larger, heavier particles slide or roll along the ground; (2) \"saltation\", where particles are lifted a short height into the air, and bounce and saltate across the surface of the soil; and (3) \"suspension\", where very small and light particles are lifted into the air by the wind, and are often carried for long distances. Saltation is responsible for the majority (50-70%) of wind erosion, followed by suspension (30-40%), and then surface creep (5-25%).\n\nWind erosion is much more severe in arid areas and during times of drought. For example, in the Great Plains, it is estimated that soil loss due to wind erosion can be as much as 6100 times greater in drought years than in wet years.\n\n\"Mass movement\" is the downward and outward movement of rock and sediments on a sloped surface, mainly due to the force of gravity.\n\nMass movement is an important part of the erosional process and is often the first stage in the breakdown and transport of weathered materials in mountainous areas. It moves material from higher elevations to lower elevations where other eroding agents such as streams and glaciers can then pick up the material and move it to even lower elevations. Mass-movement processes are always occurring continuously on all slopes; some mass-movement processes act very slowly; others occur very suddenly, often with disastrous results. Any perceptible down-slope movement of rock or sediment is often referred to in general terms as a landslide. However, landslides can be classified in a much more detailed way that reflects the mechanisms responsible for the movement and the velocity at which the movement occurs. One of the visible topographical manifestations of a very slow form of such activity is a scree slope.\n\n\"Slumping\" happens on steep hillsides, occurring along distinct fracture zones, often within materials like clay that, once released, may move quite rapidly downhill. They will often show a spoon-shaped isostatic depression, in which the material has begun to slide downhill. In some cases, the slump is caused by water beneath the slope weakening it. In many cases it is simply the result of poor engineering along highways where it is a regular occurrence.\n\n\"Surface creep\" is the slow movement of soil and rock debris by gravity which is usually not perceptible except through extended observation. However, the term can also describe the rolling of dislodged soil particles in diameter by wind along the soil surface.\n\nThe amount and intensity of precipitation is the main climatic factor governing soil erosion by water. The relationship is particularly strong if heavy rainfall occurs at times when, or in locations where, the soil's surface is not well protected by vegetation. This might be during periods when agricultural activities leave the soil bare, or in semi-arid regions where vegetation is naturally sparse. Wind erosion requires strong winds, particularly during times of drought when vegetation is sparse and soil is dry (and so is more erodible). Other climatic factors such as average temperature and temperature range may also affect erosion, via their effects on vegetation and soil properties. In general, given similar vegetation and ecosystems, areas with more precipitation (especially high-intensity rainfall), more wind, or more storms are expected to have more erosion.\n\nIn some areas of the world (e.g. the mid-western USA), rainfall intensity is the primary determinant of erosivity (for a definition of \"erosivity\" check,) with higher intensity rainfall generally resulting in more soil erosion by water. The size and velocity of rain drops is also an important factor. Larger and higher-velocity rain drops have greater kinetic energy, and thus their impact will displace soil particles by larger distances than smaller, slower-moving rain drops.\n\nIn other regions of the world (e.g. western Europe), runoff and erosion result from relatively low intensities of stratiform rainfall falling onto the previously saturated soil. In such situations, rainfall amount rather than intensity is the main factor determining the severity of soil erosion by water.\n\nIn Taiwan, where typhoon frequency increased significantly in the 21st century, a strong link has been drawn between the increase in storm frequency with an increase in sediment load in rivers and reservoirs, highlighting the impacts climate change can have on erosion.\n\nVegetation acts as an interface between the atmosphere and the soil. It increases the permeability of the soil to rainwater, thus decreasing runoff. It shelters the soil from winds, which results in decreased wind erosion, as well as advantageous changes in microclimate. The roots of the plants bind the soil together, and interweave with other roots, forming a more solid mass that is less susceptible to both water and wind erosion. The removal of vegetation increases the rate of surface erosion.\n\nThe topography of the land determines the velocity at which surface runoff will flow, which in turn determines the erosivity of the runoff. Longer, steeper slopes (especially those without adequate vegetative cover) are more susceptible to very high rates of erosion during heavy rains than shorter, less steep slopes. Steeper terrain is also more prone to mudslides, landslides, and other forms of gravitational erosion processes.\n\nTectonic processes control rates and distributions of erosion at the Earth's surface. If the tectonic action causes part of the Earth's surface (e.g., a mountain range) to be raised or lowered relative to surrounding areas, this must necessarily change the gradient of the land surface. Because erosion rates are almost always sensitive to the local slope (see above), this will change the rates of erosion in the uplifted area. Active tectonics also brings fresh, unweathered rock towards the surface, where it is exposed to the action of erosion.\n\nHowever, erosion can also affect tectonic processes. The removal by erosion of large amounts of rock from a particular region, and its deposition elsewhere, can result in a lightening of the load on the lower crust and mantle. Because tectonic processes are driven by gradients in the stress field developed in the crust, this unloading can in turn cause tectonic or isostatic uplift in the region. In some cases, it has been hypothesised that these twin feedbacks can act to localize and enhance zones of very rapid exhumation of deep crustal rocks beneath places on the Earth's surface with extremely high erosion rates, for example, beneath the extremely steep terrain of Nanga Parbat in the western Himalayas. Such a place has been called a \"tectonic aneurysm\".\n\nHuman land development, in forms including agricultural and urban development, is considered a significant factor in erosion and sediment transport. In Taiwan, increases in sediment load in the northern, central, and southern regions of the island can be tracked with the timeline of development for each region throughout the 20th century.\n\nMountain ranges are known to take many millions of years to erode to the degree they effectively cease to exist. Scholars Pitman and Golovchenko estimate that it takes probably more than 450 million years to erode a mountain mass similar to the Himalaya into an almost-flat peneplain if there are no major sea-level changes. Erosion of mountains massifs can create a pattern of equally high summits called summit accordance. It has been argued that extension during post-orogenic collapse is a more effective mechanism of lowering the height of orogenic mountains than erosion.\n\nExamples of heavily eroded mountain ranges include the Timanides of Northern Russia. Erosion of this orogen has produced sediments that are now found in the East European Platform, including the Cambrian Sablya Formation near Lake Ladoga. Studies of these sediments indicate that it is likely that the erosion of the orogen began in the Cambrian and then intensified in the Ordovician.\n\nIf the rate of erosion is higher than the rate of soil formation the soils are being destroyed by erosion. Where soil is not destroyed by erosion, erosion can in some cases prevent the formation of soil features that form slowly. Inceptisols are common soils that form in areas of fast erosion.\n\nWhile erosion of soils is a natural process, human activities have increased by 10-40 times the rate at which erosion is occurring globally. Excessive (or accelerated) erosion causes both \"on-site\" and \"off-site\" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, the eventual end result is desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems.\n\n\n"}
{"id": "39776215", "url": "https://en.wikipedia.org/wiki?curid=39776215", "title": "Exhaust heat recovery system", "text": "Exhaust heat recovery system\n\nIn transportation, an exhaust heat recovery system turns thermal losses in the exhaust pipe into energy. This technology seems to be more and more of interest by car and heavy-duty vehicle manufacturers as an efficient way to save fuel and reduce vehicles’ CO emissions.\nThis technology can be used either on a hybrid vehicle or a conventional one: it produces either electric energy for batteries or mechanical energy reintroduced on the crankshaft.\n\nEven if current engines consume less fuel than they used to, the thermal efficiency of an internal combustion engine has not really increased since its creation. The peak efficiency reached by a 4-cycle Otto cycle engine is around 35%, which means that 65% of the energy contained in the fuel is lost as heat. High speed Diesel cycle engines fare better with around 45% peak efficiency, but are still far from their Carnot efficiency, and hence 55% of the fuel energy content is lost.\n\nThe 2016 Chevrolet Malibu Hybrid car features an Exhaust gas Heat Recovery (EGHR) system to accelerate coolant heat up time. This gives faster heat up of the engine coolant which in turn heats up the engine faster. Less fuel is used giving reduced emissions. This will also quicken cabin heating warm up for passenger comfort and window defrosting. For hybrid applications it also can warm the battery pack. The cooling system is connected to a heat exchanger placed in the exhaust gas transferring the thermal energy from the exhaust gas to the cooling system. When the engine is warmed up the exhaust gas is diverted to a by-pass pipe.\n\nRankine cycle systems vaporize pressurised water using a steam generator located in the exhaust pipe. As a result of the heating by exhaust gases, the fluid is turned into steam. The steam then drives the expander of the Rankine engine, either a turbine or pistons. This expander can be directly tied to the crankshaft of the thermal engine or linked to an alternator to generate electricity.\n\nResearchers at Loughborough University and the University of Sussex, both in the UK, also have concluded that using waste heat from light-duty vehicle engines in a steam power cycle could deliver fuel economy advantages of between 6.3% and 31.7%, depending upon drive cycle, and that high efficiencies can be achieved at practical operating pressures.\n\nThermoelectric generator are another option to recover heat from the exhaust pipe to reduce vehicles fuel consumption.\n\nElectric Turbo Compounding (ETC) is a technology solution to the challenge of improving energy efficiency for the stationary power generation industry.\n\nFossil fuel based power generation is predicted to continue for decades, especially in developing economies. This is against the global need to reduce carbon emissions, of which, a high percentage is produced by the power sector worldwide.\n\nETC works by making gas and diesel-powered gensets (Electric Generators) work more effectively and cleaner, by recovering waste energy from the exhaust to improve power density and fuel efficiency.\n\n\n\nFacing the new American, European, Japanese or Chinese regulation, more and more stringent concerning CO2 emissions, exhaust heat recovery sounds like one of the most efficient ways to recover a free energy, since heat is generated in many ways by the engine. Numerous companies develop system based upon a Rankine Cycle:\n\nThe German company has been one of the first major to study exhaust heat recovery with a Rankine system called Turbosteamer.\n\nHonda also develops a module based on a Rankine Cycle to improve overall efficiency of hybrid vehicles, by recovering the heat of the engine and turning it into electricity for the battery pack.\nIn the US highway cycle, the Rankine cycle system regenerated three times as much energy as the vehicle’s regenerative braking system.\n\nA French company, Exoès is specialized in designing and manufacturing exhaust heat recovery systems based on Rankine Cycles. The system EVE, Energy Via Exhaust, leads to fuel savings from 5 up to 15%.\n\nBarber-Nichols Inc. develops Rankine technologies for vehicles.\n\nThe German consortium unites the majority of internal combustion engine manufacturers across the world. Two task forces are currently studying exhaust heat recovery systems on passenger cars.\n\nRenault Trucks: As a part of the All For Fuel Eco Initiative, Renault Trucks studies a Rankine system for long distance vehicles that could lead to 10% fuel savings. The goal is to produce enough energy to feed the components and electronic auxiliaries with electricity and reduce the fuel consumption by reducing the load on the alternator.\n\nDouble Arrow Engineering's WildFire Heat Recovery System (WFHRS) is underdevelopment and utilizes wasted heat from both coolant and exhaust. This system mechanically adds power back to the drive-line, utilizing a Rankine engine as the energy conversion method. The WFHRS is designed for a verity of different applications, both fixed and variable RPM, aftermarket and OEM applications, but generally geared toward larger equipment such as large on-highway trucks, diesel generators, large buses and motor-homes, marine vessels, medium duty trucks, etc. \n\nIFPEN, Enogia and Alstom are developing a system called Trenergy dedicated to improve train fuel efficiency.\n\nFuel efficiency, reduction of CO2 emissions, reliability and costs are necessary parts of Formula 1 manufacturers’ strategies.\nAutomobile sport competitions is a good place to try and assess technologies that, once reliable, are adapted to private cars. As much as kinetic energy recovery system, Formula 1 constructors have produced one of the first exhaust heat recovery systems. Nowadays these devices are essential parts of embedded technologies on F1. Besides, heat recovery will be mandatory for the first time in 2014’s F1 Championship. Manufacturers, like Renault (ERS-H), test their systems, which also drives the turbo to improve its reactivity –and the torque at low regime- after braking.\n"}
{"id": "2454447", "url": "https://en.wikipedia.org/wiki?curid=2454447", "title": "Fata Morgana (mirage)", "text": "Fata Morgana (mirage)\n\nA () is a complex form of superior mirage that is seen in a narrow band right above the horizon. It is an Italian term named after the Arthurian sorceress Morgan le Fay, from a belief that these mirages, often seen in the Strait of Messina, were fairy castles in the air or false land created by her witchcraft to lure sailors to their deaths. Although the term Fata Morgana sometimes is applied to other more common kinds of mirages, true Fata Morgana is different from both an ordinary superior mirage and an inferior mirage.\n\nFata Morgana mirages significantly distort the object or objects on which they are based, often such that the object is completely unrecognizable. A Fata Morgana may be seen on land or at sea, in polar regions, or in deserts. It may involve almost any kind of distant object, including boats, islands, and the coastline.\n\nOften, a Fata Morgana changes rapidly. The mirage comprises several inverted (upside down) and erect (right side up) images that are stacked on top of one another. Fata Morgana mirages also show alternating compressed and stretched zones.\n\nThe optical phenomenon occurs because rays of light are bent when they pass through air layers of different temperatures in a steep thermal inversion where an atmospheric duct has formed. (A thermal inversion is an atmospheric condition where warmer air exists in a well-defined layer above a layer of significantly cooler air. This temperature inversion is the opposite of what is normally the case; air is usually warmer close to the surface, and cooler higher up.)\n\nIn calm weather, a layer of significantly warmer air may rest over colder dense air, forming an atmospheric duct that acts like a refracting lens, producing a series of both inverted and erect images. A Fata Morgana requires a duct to be present; thermal inversion alone is not enough to produce this kind of mirage. While a thermal inversion often takes place without there being an atmospheric duct, an atmospheric duct cannot exist without there first being a thermal inversion.\n\nA Fata Morgana is most commonly seen in polar regions, especially over large sheets of ice that have a uniform low temperature. It may, however, be observed in almost any area. In polar regions the Fata Morgana phenomenon is observed on relatively cold days. In deserts, over oceans, and over lakes, however, a Fata Morgana may be observed on hot days.\n\nTo generate the Fata Morgana phenomenon, the thermal inversion has to be strong enough that the curvature of the light rays within the inversion layer is stronger than the curvature of the Earth. Under these conditions, the rays bend and create arcs. An observer needs to be within or below an atmospheric duct in order to be able to see a Fata Morgana.\n\nA Fata Morgana may be observed from any altitude within the Earth's atmosphere, from sea level up to mountaintops, and even including the view from airplanes.\nA Fata Morgana may be described as a very complex superior mirage with more than three distorted erect and inverted images. Because of the constantly changing conditions of the atmosphere, a Fata Morgana may change in various ways within just a few seconds of time, including changing to become a straightforward superior mirage.\n\nThe sequential image here shows sixteen photographic frames of a mirage of the Farallon Islands as seen from San Francisco; the images were all taken on the same day.\n\nIn the first fourteen frames, elements of the Fata Morgana mirage display alternations of compressed and stretched zones. The last two frames were photographed a few hours later, around sunset time. At that point in time, the air was cooler while the ocean was probably a little bit warmer, which caused the thermal inversion to be not as extreme as it was few hours before. A mirage was still present at that point, but it was not so complex as a few hours before sunset: the mirage was no longer a Fata Morgana, but instead had become a simple superior mirage.\n\nFata Morgana mirages are visible to the naked eye, but in order to be able to see the detail within them, it is best to view them through binoculars, a telescope, or as is the case in the images here, through a telephoto lens.\n\nGabriel Gruber (1740–1805) and (1744–1806), who observed Fata Morgana above Lake Cerknica, were the first to study it in a laboratory setting.\n\n\"La Fata Morgana\" (\"The Fairy Morgana\") is the name of Morgan le Fay in Italian. Morgan le Fay, also known as Morgane, Morgain, Morgana, and other variants, was described as a powerful sorceress and antagonist of King Arthur and Queen Guinevere in the Arthurian legend.\n\nAs her name indicates, the figure of Morgan appears to have been originally a fairy (Fata, Le Fay) rather than a human woman. The early works featuring Morgan do not elaborate on her nature, other than describing her role as that of a fairy or magician. Later, she was described as a woman, King Arthur's half-sister, and an enchantress.\n\nAfter King Arthur's final battle at Camlann, Morgan le Fay takes her half-brother Arthur to Avalon. In medieval times, suggestions for the location of Avalon included the other side of the Earth at the antipodes, Sicily, and other locations in the Mediterranean.\n\nLegends claimed that sirens in the waters around Sicily lured the unwary to their death. Morgan le Fay is associated not only with Etna, but also with sirens. In a medieval French Arthurian Romance, \"Floriant et Florete\", she is called \"mistress of the fairies of the salt sea\" (\"La mestresse [des] fées de la mer salée\".) Ever since that time, Fata Morgana has been associated with Sicily. \n\nWalter Charleton, in his 1654 treatise \"Physiologia Epicuro-Gassendo-Charltoniana\", devotes several pages to the description of the Morgana of Rhegium, in the Strait of Messina (Book III, Chap. II, Sect. II). He records that a similar phenomenon was reported in Africa by Diodorus Siculus, a Greek historian writing in the first century BC, and that the Rhegium Fata Morgana was described by Damascius, a Greek Philosopher of the sixth century AD. In addition, Charleton tells us that Athanasius Kircher described the Rhegium mirage in his book of travels.\n\nAn early mention of the term \"Fata Morgana\" in English, in 1818, referred to such a mirage noticed in the Strait of Messina, between Calabria and Sicily.\n\nThe Flying Dutchman, according to folklore, is a ghost ship that can never go home, and is doomed to sail the oceans forever. The Flying Dutchman is usually spotted from afar, sometimes seen to be glowing with ghostly light. One of the possible explanations of the origin of the Flying Dutchman legend is a Fata Morgana mirage seen at sea.\n\nA Fata Morgana superior mirage of a ship can take many different forms. Even when the boat in the mirage does not seem to be suspended in the air, it still looks ghostly, and unusual, and what is even more important, it is ever-changing in its appearance. Sometimes a Fata Morgana causes a ship to appear to float inside the waves, at other times an inverted ship appears to sail above its real companion.\n\nIn fact, with a Fata Morgana it can be hard to say which individual segment of the mirage is real and which is not real: when a real ship is out of sight because it is below the horizon line, a Fata Morgana can cause the image of it to be elevated, and then everything which is seen by the observer is a mirage. On the other hand, if the real ship is still above the horizon, the image of it can be duplicated many times and elaborately distorted by a Fata Morgana.\n\nIn the 19th and early 20th centuries, Fata Morgana mirages may have played a role in a number of unrelated \"discoveries\" of arctic and antarctic land masses which were later shown not to exist. Icebergs frozen into the pack ice, or the uneven surface of the ice itself, may have contributed to the illusion of distant land features.\n\nYakov Sannikov and Matvei Gedenschtrom claimed to have seen a land mass north of Kotelny Island during their 1809–1810 cartographic expedition to the New Siberian Islands. Sannikov reported this sighting of a \"new land\" in 1811, and the supposed island was named after him. Three-quarters of a century later, in 1886, Baron Eduard Toll, a Baltic German explorer in Russian service, reported observing Sannikov Land during another expedition to the New Siberian Islands. In 1900, he would lead still another expedition to the region, which had among its objectives the location and exploration of Sannikov Land. The expedition was unsuccessful in this respect. Toll and three others were lost after they departed their ship, which was stuck in ice for the winter, and embarked on a risky expedition by dog sled. In 1937, the Soviet icebreaker \"Sadko\" also tried and failed to find Sannikov Land. Some historians and geographers have theorised that the land mass that Sannikov and Toll saw was actually Fata Morganas of Bennett Island.\n\nIn 1818, Sir John Ross led an expedition to discover the long-sought-after Northwest Passage. When he reached Lancaster Sound in Canada, he sighted, in the distance, a land mass with mountains, directly ahead in the ship's course. He named the mountain range the Croker Mountains, after First Secretary to the Admiralty John Wilson Croker, and ordered the ship to turn around and return to England. Several of his officers protested, including First Mate William Edward Parry and Edward Sabine, but they could not dissuade him. The account of Ross's voyage, published a year later, brought to light this disagreement, and the ensuing controversy over the existence of the Croker Mountains ruined Ross's reputation. The year after Ross's expedition, in 1819, Parry was given command of his own Arctic expedition, and proved Ross wrong by continuing west beyond where Ross had turned back, and sailing through the supposed location of the Croker Mountains. The mountain range that had caused Ross to abandon his mission had been a mirage. \n\nRoss made two errors. First, he refused to listen to the counsel of his officers, who must have been more familiar with mirages than he was. Second, his attempt to honour Croker by naming a mountain range after him backfired when the mountains turned out to be non-existent. Ross could not obtain ships, or funds, from the government for his subsequent expeditions, and was forced to rely on private backers instead.\n\nBenjamin Morrell reported that, in March 1823, while on a voyage to the Antarctic and southern Pacific Ocean, he had explored what he thought was the east coast of New South Greenland. The west coast of New South Greenland had been explored two years earlier by Robert Johnson, who had given the land its name. This name was not adopted, however, and the area, which is the northern part of the Antarctic Peninsula, is now known as Graham Land. Morrell's reported position was actually far to the east of Graham Land. Searches for the land that Morrell claimed to have explored would continue into the early 20th century before New South Greenland's existence was conclusively disproven. Why Morrell reported exploring a non-existent land is unclear, but one possibility is that he mistook a Fata Morgana for actual land. \n\nRobert Peary claimed to have seen, while on a 1906 Arctic expedition, a land mass in the distance. He said that it was north-west from the highest point of Cape Thomas Hubbard, which is situated in what is now the northern Canadian territory of Nunavut, and he estimated it to be 130 miles away, at about 83 degrees N, longitude 100 degrees W. He named it Crocker Land, after George Crocker of the Peary Arctic Club.\n\nAs Peary's diary contradicts his public claim that he had sighted land, it is now believed that Crocker Land was a fraudulent invention of Peary, created in an unsuccessful attempt to secure further funding from Crocker.\n\nIn 1913, unaware that Crocker Land was merely an invention, Donald Baxter MacMillan organised the Crocker Land Expedition, which set out to reach and explore the supposed land mass. On 21 April the members of the expedition did, in fact, see what appeared to be a huge island on the north-western horizon. As MacMillan later said, \"Hills, valleys, snow-capped peaks extending through at least one hundred and twenty degrees of the horizon.”\n\nPiugaattoq, a member of the expedition and an Inuit hunter with 20 years of experience of the area, explained that it was just an illusion. He called it \"poo-jok\", which means 'mist'. However, MacMillan insisted that they press on, even though it was late in the season and the sea ice was breaking up. For five days they went on, following the mirage. Finally, on 27 April, after they had covered some of dangerous sea ice, MacMillan was forced to admit that Piugaattoq was right—the land that they had sighted was in fact a mirage (probably a Fata Morgana). \n\nLater MacMillan wrote:\n\nThe expedition collected interesting samples, but is still considered to be a failure and a very expensive mistake. The final cost was $100,000 ().\n\nLake Ontario is said to be famous for mirages, with opposite shorelines becoming clearly visible during the events.\n\nIn July 1866, mirages of boats and islands were seen from Kingston, Ontario.\nHere the described mirages of vessels \"could only be seen with the aid of a telescope\". It is often the case when observing a Fata Morgana that one needs to use a telescope or binoculars to really make out the mirage. The \"cloud\" that the article mentions a few times probably refers to a duct.\n\nOn 25 August 1894, \"Scientific American\" described a \"remarkable mirage\" seen by the citizens of Buffalo, New York.\nThis description might refer to looming due to inversion rather than to an actual mirage.\n\nFrom McMurdo Station in Antarctica, Fata Morganas are often seen during the Antarctic spring and summer, across McMurdo Sound. An Antarctic Fata Morgana, seen from a C-47 transport flight, was recounted:\n\nFata Morgana mirages may continue to trick some observers and are still sometimes mistaken for otherworldly objects such as UFOs.\nA Fata Morgana can display an object that is located below the astronomical horizon as an apparent object hovering in the sky. A Fata Morgana can also magnify such an object vertically and make it look absolutely unrecognizable.\n\nSome UFOs which are seen on radar may also be due to Fata Morgana mirages. Official UFO investigations in France indicate:<ref name=\"Official UFO Investigations in France: the GEPAN/SEPRA Project\"> Electromagnetic-Wave Ducting By V. R. Eshleman</ref> \nFata Morgana mirages could explain the mysterious Australian Min Min light phenomenon.\nFata Morgana Land, a phantom island in the Arctic reported first in 1907. After unfruitful search it was deemed to be Tobias Island.\n\nA Fata Morgana is usually associated with something mysterious, something that never could be approached.\n\nIn the lines, \"the weary traveller sees / In desert or prairie vast, / Blue lakes, overhung with trees / That a pleasant shadow cast\", because of the mention of blue lakes, it is clear that the author is actually describing not a Fata Morgana, but rather a common inferior or desert mirage. The 1886 drawing shown here of a \"Fata Morgana\" in a desert might have been an imaginative illustration for the poem, but in reality no mirage ever looks like this. Andy Young writes, \"They're always confined to a narrow strip of sky—less than a finger's width at arm's length—at the horizon.\"\n\nThe 18th-century poet Christoph Martin Wieland wrote about \"Fata Morgana's castles in the air\". The idea of castles in the air was probably so irresistible that many languages still use the phrase Fata Morgana to describe a mirage.\n\nIn the book \"Thunder Below!\" about the submarine USS \"Barb\", the crew sees a Fata Morgana (called an \"arctic mirage\" in the book) of four ships trapped in the ice. As they try to approach the ships the mirage vanishes.\n\nThe Fata Morgana is briefly mentioned in the HP Lovecraft horror novel \"At the Mountains of Madness\", in which the narrator states: \"On many occasions the curious atmospheric effects enchanted me vastly; these including a strikingly vivid mirage—the first I had ever seen—in which distant bergs became the battlements of unimaginable cosmic castles.\"\n\n"}
{"id": "5943699", "url": "https://en.wikipedia.org/wiki?curid=5943699", "title": "Genesis I", "text": "Genesis I\n\nGenesis I is an experimental space habitat designed and built by the private American firm Bigelow Aerospace and launched in 2006. It was the first module to be sent into orbit by the company, and is testing various systems, materials and techniques related to determining the viability of long-term inflatable space structures. Such structures, including this module and others built by Bigelow Aerospace, are based on the NASA TransHab design, which provides increased interior volume at a reduced launch diameter and potentially reduced mass compared to traditional rigid structures.\n\nThe on-board systems transmitted data for 2.5 years. The spacecraft remains in orbit, which allows researchers to continue testing the long-term viability of expandable space structures.\n\n\"Genesis I\" was launched on 12 July 2006 at 14:53:30 UTC aboard an ISC Kosmotras Dnepr rocket, launched from Dombarovskiy missile base near Yasniy, Russia. Spacecraft control was transferred to Bigelow Aerospace at 15:08 UTC after a successful orbital insertion. Designed as a one-third scale model of the full size \"BA 330\", when in orbit the main body of the craft measures long and in diameter, with an interior habitable volume of . As part of the expandable design, however, the module launched with a diameter of only , inflating to its full size after entering orbit. The expansion process took approximately ten minutes.\n\n\"Genesis I\" suffered a major radiation event in December 2006 as a result of a \"solar storm\". Mission controllers were able to restart the system in time, though the situation was described as being \"one fault away from the spacecraft being dead.\" Despite this, no lasting damage appears to have occurred and the spacecraft was operating in \"excellent shape\" .\n\nThe spacecraft completed its 10,000th orbit on 8 May 2008, some 660 days after launch. By that time, \"Genesis I\" had traveled more than 430 million kilometers (270 million miles), the equivalent of going to the Moon and back 1,154 times, and had taken more than 14,000 images, including images of all seven continents. Its electrical equipment had been continuously powered since it first became operational.\n\nAlthough the design life of the spacecraft avionics was only six months, the avionics systems worked flawlessly for \"over two and a half years\" before failure. The data received after the first six months was a re-verification of the validation test suite that was accomplished during the design life period.\n\nIn February 2011, Bigelow reported that the vehicle had \"performed flawlessly in terms of pressure maintenance and thermal control-environmental containment.\"\n\nThe orbital life was originally estimated to be 12 years, with a gradually decaying orbit resulting in re-entry into Earth's atmosphere and burn-up expected. Its operations lasted approximately 2.5 years, significantly longer than its expected 6-month mission duration. , the vehicle remains in orbit.\n\n\"Genesis I\" is outfitted with eight GaAs solar panel arrays, four on each end of the craft, which produce one kilowatt total power and maintain a 26 volt battery charge. It carries thirteen cameras, seven externally to monitor the physical condition of the spacecraft, such as the outer shell and solar arrays, and six internally to photograph the various objects and experiments. Internal systems established an atmospheric pressure of and use passive thermal control to keep temperatures at an average of , with observed limits of approximately and . \"Genesis I\" uses a single gas tank for its inflation system, and guidance/stabilization control is performed using a network of torque rods, sun sensors, GPS and a magnetometer.\n\nAside from the various systems and monitoring equipment, \"Genesis I\" is orbiting with a wide variety of cargo. Bigelow employees contributed numerous photographs, toys, cards and other items, which can be seen in still images floating around the cabin. Bigelow also placed a life sciences experiment on board, which contains four Madagascar hissing cockroaches (\"Gromphadorhina portentosa\") and approximately 20 so-called Mexican jumping beans, which are seeds containing the live larva of the moth \"Cydia deshaisiana\". In addition, the company allowed NASA to include a prototype for the GeneSat series of nanosatellites. This device, called GeneBox, tested the systems and procedures that will be used on future GeneSat missions. While GeneBox carries no living organisms, future flights will use sensors and optics to measure how weightlessness affects genes and the genetic activity of cells and microscopic life.\n\n\n"}
{"id": "50210206", "url": "https://en.wikipedia.org/wiki?curid=50210206", "title": "Gewässerkennzahl", "text": "Gewässerkennzahl\n\nThe Gewässerkennzahl (GKZ, rarely GWK or GEWKZ) or \"waterbody index number/waterbody number\" is an identifier with which all watercourses in Germany are numbered, together with their catchments and precipitation areas. It is also referred to as a Gebietskennzahl or \"basin number\". A Gewässerkennzahl may have up to 13 figures (theoretically even 19). Basins normally are only defined up to seven figures. For a more detailed subdivision, the Gewässerkennzahl may be enlarged by ten more figures. Only that enlarged version is called \"Fließgewässerkennziffer.\" The Gewässerkennzahlen are defined by the environment offices of the states.\n\nIn order to have comparable values and usable data across the state of Germany, the Federal and State Water Authorities agreed in December 1970 to create a unified system for hydrological work on certain important rivers and their above-ground catchment areas and to issue them with index numbers. Linked to that was the establishment of the size and boundaries of their catchment areas.\n\nEvery waterbody (streams, rivers, canals and ditches, but also lakes and even some bays) and its catchment area was given a waterbody number in such a way that it could be clearly identified. The waterbody numbers are built in hierarchical fashion so that, based on the number, the next river system of the waterbody can be deduced.\n\nAt first the course of water has to be defined from source to mouth. Then the four major tributaries (or 'affluents') are identified. They are marked by even figures in downstream sequence, \"-2, -4, -6, -8\". This way, the (main) course is divided into five sections, which are marked by odd figures, \"-1, -3, -5, -7, -9\". A number with an even end-digit is the number of a whole watercourse, while a number with an odd end-digit is the number of a section. Lowest sections are always given a nine, even if not all figures between one and nine have been used. In the next step of numbering, each section defined by the first step is dealt in the same way, selecting four major tributaries and marking five sections.\n\nLakes are integrated as a part of the watercourse formed by their main tributary and their outlet.\n\nFor coastal regions, the scheme of numbering was altered in different ways by different states:\n\nSome waterbodies indexed under this classification system have un-indexed headstreams or lateral tributaries in the form of very small streams or ditches. If such an unclassified waterbody is relevant for the water management of the region, it may be given a number by within the local classification system of the regional Wasser- und Bodenverband (association for water and ground management).\n\nThe numbers for a watercourse and its catchment area are thus identical. If a river has subsidiary watercourses, an additional figure is allocated to its index number for each further branch. So in theory even a rivulet could be allocated its own catchment. In practice, catchment numbering for water sources below the level of streams are not used.\n\nCatchment areas are thus distinguished by a number with up to a maximum of seven digits. Watercourse index numbers, by contrast, may have up to 13 digits in order to be able to classify all their tributaries and headstreams; although in practice only 10 digits are used.\n\nThe first digit of the number indicates which major river basin the waterbody belongs to, as follows:\n\nThe second and subsequent digits of the index number represent further subdivisions of the river and its catchment area.\n\nThe Heusiepen stream in Remscheid has waterbody number 27366462. This can be decoded as follows:\n\nListed below are all the rivers with up to a three-figure index number, and some rivers with four-figure numbers above a length of 50 km.\n\nHere some three-figure numbers are not listed.\n\n\n\n"}
{"id": "4380836", "url": "https://en.wikipedia.org/wiki?curid=4380836", "title": "Glycon", "text": "Glycon\n\nGlycon ( \"Glýkon\", : \"Glýkonos\"), also spelled Glykon, was an ancient snake god. Having a large and influential cult within the Roman Empire in the 2nd century; Glycon had been mentioned earlier by Horace. However contemporary satirist Lucian provides the primary literary reference to the deity. Lucian claimed Glycon was created in the mid-2nd century by the Greek prophet Alexander of Abonoteichos. Lucian was ill-disposed toward the cult, calling Alexander a false prophet and accusing the whole enterprise of being a hoax: Glycon himself was supposedly a hand puppet.\n\nThe cult possibly originated in Macedonia, where similar snake cults had existed for centuries. The Macedonians believed snakes had magical powers relating to fertility and had a rich mythology on this subject, for example the story of Olympias's impregnation by Zeus disguised as a serpent. In 20 BC Glycon was referred to by the Roman poet Horace, in his Epistle 1 to Maecenas in his First Book of Epistles; \"... you despair of the muscles of the invincible Glycon...\").\n\nAt least initially, the cult did not worship an abstraction or a spirit of a snake but an actual, physical serpent that was said to embody the god. According to the cult's mythology, the snake appeared after Alexander had foretold the coming of a new incarnation of Asclepius. When the people gathered in the marketplace of Abonutichus at noon, when the incarnation was supposed to occur, Alexander produced a goose egg and sliced it open, revealing the god within. Within a week it grew to the size of a man with the features of a man on its face, including long blond hair. At this point the figure resembling this description was apparently a puppet that appeared in the temple. In some references Glycon was a trained snake with a puppet head.\n\nAs with previous Macedonian snake cults, the focus of worship at the temple was on fertility. Barren women would bring offerings to Glycon in hopes of becoming pregnant. According to Lucian, Alexander had less magical ways of causing pregnancy among his flock as well.\n\nBy 160, the worship of Glycon had undoubtedly spread beyond the Aegean. An inscription from Antioch of that date records a slogan, \"Glycon protect us from the plague-cloud\" that is consistent with the description we have from Lucian. Also in that year the governor of Asia, Publius Mummius Sisenna Rutilianus, declared himself protector of Glycon's oracle. The governor later married Alexander's daughter. According to Lucian, another Roman governor, of Cappadocia, was led by Glycon's oracle to his death in Armenia, and even the Emperor himself was not immune to the cult: Marcus Aurelius sought prophesies from Alexander and his snake god.\n\nMeanwhile, Abonoteichos, a small fishing village before the arrival of the cult, became an important town and accepted another name, Ionopolis. It is uncertain what role the popularity of Glycon played in the rise of the city. \n\nIn short order Glycon worship was found throughout the vast area between the Danube and Euphrates. Beginning late in the reign of Antoninus Pius and continuing into the 3rd century, official Roman coins were struck in honor of Glycon, attesting his popularity. While the cult gradually lost followers after the death of its leader in c.170, it survived for at least a hundred years thereafter, with Alexander being incorporated into its mythology as a grandson of Asclepius. Some evidence indicates the cult survived into the 4th century.\n\nResidual superstitions originating with Glycon were reported by some researchers to continue even into modern times. A Turkish friend of Dutch scholar Jona Lendering mentioned that a common belief in a magical snake persisted near İnebolu (the current name for the ancient city of Ionopolis).\n\nFollowing his \"coming out\" as a magician in 1993, the English comic book writer and occultist Alan Moore has declared himself a devotee of Glycon. At the same time, he acknowledges that Glycon was almost certainly a hoax.\n\nOne single marble statue of Glycon snake was found in excavations done under the site of the former Pallas railway station in Constanța, Romania. The statue is 0.66 metres high and the snake dimension is 4.76 metres.\nThe Romanians commemorated this unique sculpture on a postage stamp in 1974, and on a bank note of 10.000 lei in 1994.\n\n\n\n"}
{"id": "11730273", "url": "https://en.wikipedia.org/wiki?curid=11730273", "title": "Graves (system)", "text": "Graves (system)\n\nGRAVES () is a French radar-based space surveillance system, akin to the American Air Force Space Surveillance System. Using radar measurements, the French Air Force is able to spot satellites orbiting the Earth and determine their orbit. The GRAVES system took 15 years to develop, and became operational in November, 2005. GRAVES is also a contributing system to the European Space Agency's Space Situational Awareness Programme (SSA).\n\nGRAVES is a bistatic radar system using Doppler and directional information to derive the orbits of the detected satellites. Its operating frequency is 143.050 MHz, with the transmitter being located on a decommissioned airfield near Broye-lès-Pesmes at and the receiver at a former missile site near Revest du Bion on the Plateau d'Albion at . Data processing and generation of satellite orbital elements is performed at the Balard Air Complex in Paris, .\n\n\n"}
{"id": "34220486", "url": "https://en.wikipedia.org/wiki?curid=34220486", "title": "IEC 62325", "text": "IEC 62325\n\nIEC 62325 is a set of standards related to deregulated energy market communications, based on the Common Information Model. IEC 62325 is a part of the International Electrotechnical Commission's (IEC) Technical Committee 57 (TC57) reference architecture for electric power systems, and is the responsibility of Working Group 16 (WG16).\n\nIEC 62325 consists of the following parts, detailed in separate IEC 62325 standard documents:\n\n\n"}
{"id": "9623824", "url": "https://en.wikipedia.org/wiki?curid=9623824", "title": "Ian Lowe", "text": "Ian Lowe\n\nIan Lowe (born 1942) is Emeritus Professor of Science, Technology and Society and former Head of the School of Science at Griffith University, as well as an adjunct professor at Sunshine Coast University and Flinders University. In 1996 he was chair-person of the advisory council producing the first national report on the state of Australia's environment. He is a patron of Sustainable Population Australia. One of his principal interests is the way policy decisions influence use of science and technology, especially in the fields of energy and environment.\n\nLowe was made an Officer of the Order of Australia in 2001 for services to science, technology, and the environment. In 2002 he was awarded a Centenary Medal for contributions to environmental science and won the Eureka Prize for promotion of science. His contributions have also been recognised by the Prime Minister's Environment Award for Outstanding Individual Achievement, the Queensland Premier's Millennium Award for Excellence in Science and the University of NSW Alumni Award for achievement in science. Lowe was named Humanist of the Year in 1988. He was President of the Australian Conservation Foundation from 2004 to April 2014. In 2009 the International Academy of Sciences, Health and Ecology awarded him the Konrad Lorenz Gold Medal.\n\nLowe was a member of the Australian Radiation Health and Safety Advisory Council from 2002 to 2014 and a former member or chair of many other bodies advising all three levels of government in Australia. \n\nLowe has authored or co-authored 10 books, 10 Open University books, more than 50 book chapters and over 500 other publications. He wrote for 13 years a regular column for New Scientist and also writes for several other publications, as well as contributing frequently to electronic media programs. Books by Ian Lowe include \"A Big Fix\", \"Reaction Time\", \"Living in the Hothouse\", \"Why vs Why: Nuclear Power\", \"A Voice of Reason: Reflections on Australia\", \"Bigger or Better? Australia's Population Debate\" and \"The Lucky Country? Reinventing Australia\".\n\nIn April 2015 Lowe was appointed to the Expert Advisory Committee for the Nuclear Fuel Cycle Royal Commission in South Australia.\n\nIan Lowe sees the nuclear power option for electricity generation as being risky and unworkable. He says nuclear power installations peaked last century and in the past 20 years, retirements, cancellations and deferments have outnumbered new reactor construction. Lowe says nuclear power is too expensive, with insurmountable problems associated with waste disposal and weapons proliferation. It is also not a fast enough response to address climate change. Lowe advocates for renewable energy which he claims is \"quicker, less expensive and less dangerous than nuclear\".\n\n\n\n"}
{"id": "7895949", "url": "https://en.wikipedia.org/wiki?curid=7895949", "title": "Immobilization (soil science)", "text": "Immobilization (soil science)\n\nImmobilization in soil science is the conversion of inorganic compounds to organic compounds by micro-organisms or plants, by which it is prevented from being accessible to plants. Immobilization is the opposite of mineralization.\n\nWhether nitrogen is mineralized or immobilized depends on the C/N ratio of the plant residues. In general plant residues entering the soil have too little nitrogen for the soil microbial population to convert all of the carbon into their cells. If the C:N ratio of the decomposing plant material is above about 30:1 the soil microbial population may take nitrogen in mineral form (e.g. nitrate). This mineral nitrogen is said to be immobilized. This may cause nitrogen deficiency in plants growing in the soil.\n\nAs carbon dioxide is released via decomposition the C:N ratio of the organic matter decreases, and the microbial demand for mineral nitrogen is decreased. When the C:N ratio falls below about 25:1 further decomposition results in simultaneous mineralization of nitrogen which is in excess to that required by the microbial population.\n\nWhen decomposition is virtually complete soil mineral nitrogen will be higher than it was initially due to mineralization of the plant residue nitrogen.\n\n"}
{"id": "67554", "url": "https://en.wikipedia.org/wiki?curid=67554", "title": "Invasive species", "text": "Invasive species\n\nAn invasive species is a species that is not native to a specific location (an introduced species), and that has a tendency to spread to a degree believed to cause damage to the environment, human economy or human health. The criteria for invasive species has been controversial, as widely divergent perceptions exist among researchers as well as concerns with the subjectivity of the term \"invasive\". Several alternate usages of the term have been proposed. The term as most often used applies to introduced species (also called \"non-indigenous\" or \"non-native\") that adversely affect the habitats and bioregions they invade economically, environmentally, or ecologically. Such invasive species may be either plants or animals and may disrupt by dominating a region, wilderness areas, particular habitats, or wildland–urban interface land from loss of natural controls (such as predators or herbivores). This includes non-native invasive plant species labeled as exotic pest plants and invasive exotics growing in native plant communities. It has been used in this sense by government organizations as well as conservation groups such as the International Union for Conservation of Nature (IUCN) and the California Native Plant Society. The European Union defines \"Invasive Alien Species\" as those that are, firstly, outside their natural distribution area, and secondly, threaten biological diversity.\n\nThe term is also used by land managers, botanists, researchers, horticulturalists, conservationists, and the public for noxious weeds. The kudzu vine (\"Pueraria lobata\"), Andean pampas grass (\"Cortaderia jubata\"), and yellow starthistle (\"Centaurea solstitialis\") are examples. An alternate usage broadens the term to include indigenous or \"native\" species along with \"non-native\" species, that have colonized natural areas (p. 136). Deer are an example, considered to be overpopulating their native zones and adjacent suburban gardens, by some in the Northeastern and Pacific Coast regions of the United States. Sometimes the term is used to describe a non-native or introduced species that has become widespread (p. 136). However, not every introduced species has adverse effects on the environment. A nonadverse example is the common goldfish (\"Carassius auratus\"), which is found throughout the United States, but rarely achieves high densities (p. 136). Notable examples of invasive species include European rabbits, grey squirrels, domestic cats, carp and ferrets.\n\nDispersal and subsequent proliferation of species is not solely an anthropogenic phenomenon. There are many mechanisms by which species from all Kingdoms have been able to travel across continents in short periods of time such as via floating rafts, or on wind currents. Charles Darwin performed many experiments to better understand long distance seed dispersal, and was able to germinate seeds from insect frass, faeces of waterfowl, dirt clods on the feet of birds, all of which may have traveled significant distances under their own power, or be blown off course by thousands of miles.\n\nInvasion of long-established ecosystems by organisms from distant bio-regions is a natural phenomenon, which has likely been accelerated via hominid-assisted migration although this has not been adequately directly measured.\n\nThe definition of \"native\" is controversial in that there is no way to precisely determine nativity. For example, the ancestors of Equus ferus (modern horses) evolved in North America and radiated to Eurasia before becoming locally extinct. Upon returning to North America in 1493 during their hominid-assisted migration, it is debatable as to whether they were native or exotic to the continent of their evolutionary ancestors.\n\nScientists include species and ecosystem factors among the mechanisms that, when combined, establish invasiveness in a newly introduced species.\n\nWhile all species compete to survive, invasive species appear to have specific traits or specific combinations of traits that allow them to outcompete native species. In some cases, the competition is about rates of growth and reproduction. In other cases, species interact with each other more directly.\n\nResearchers disagree about the usefulness of traits as invasiveness markers. One study found that of a list of invasive and noninvasive species, 86% of the invasive species could be identified from the traits alone. Another study found invasive species tended to have only a small subset of the presumed traits and that many similar traits were found in noninvasive species, requiring other explanations. Common invasive species traits include the following:\n\nTypically, an introduced species must survive at low population densities before it becomes invasive in a new location. At low population densities, it can be difficult for the introduced species to reproduce and maintain itself in a new location, so a species might reach a location multiple times before it becomes established. Repeated patterns of human movement, such as ships sailing to and from ports or cars driving up and down highways offer repeated opportunities for establishment (also known as a high propagule pressure).\n\nAn introduced species might become invasive if it can outcompete native species for resources such as nutrients, light, physical space, water, or food. If these species evolved under great competition or predation, then the new environment may host fewer able competitors, allowing the invader to proliferate quickly. Ecosystems in which are being used to their fullest capacity by native species can be modeled as zero-sum systems in which any gain for the invader is a loss for the native. However, such unilateral competitive superiority (and extinction of native species with increased populations of the invader) is not the rule. Invasive species often coexist with native species for an extended time, and gradually, the superior competitive ability of an invasive species becomes apparent as its population grows larger and denser and it adapts to its new location.\n\nAn invasive species might be able to use resources that were previously unavailable to native species, such as deep water sources accessed by a long taproot, or an ability to live on previously uninhabited soil types. For example, barbed goatgrass (\"Aegilops triuncialis\") was introduced to California on serpentine soils, which have low water-retention, low nutrient levels, a high magnesium/calcium ratio, and possible heavy metal toxicity. Plant populations on these soils tend to show low density, but goatgrass can form dense stands on these soils and crowd out native species that have adapted poorly to serpentine soils.\n\nInvasive species might alter their environment by releasing chemical compounds, modifying abiotic factors, or affecting the behaviour of herbivores, creating a positive or negative impact on other species. Some species, like \"Kalanchoe daigremontana\", produce allelopathic compounds, that might have an inhibitory effect on competing species, and influence some soil processes like carbon and nitrogen mineralization. Other species like \"Stapelia gigantea\" facilitates the recruitment of seedlings of other species in arid environments by providing appropriate microclimatic conditions and preventing herbivory in early stages of development.\n\nOther examples are \"Centaurea solstitialis\" (yellow starthistle) and \"Centaurea diffusa\" (diffuse knapweed). These Eastern European noxious weeds have spread through the western and West Coast states. Experiments show that 8-hydroxyquinoline, a chemical produced at the root of \"C. diffusa\", has a negative effect only on plants that have not co-evolved with it. Such co-evolved native plants have also evolved defenses. \"C. diffusa\" and \"C. solstitialis\" do not appear in their native habitats to be overwhelmingly successful competitors. Success or lack of success in one habitat does not necessarily imply success in others. Conversely, examining habitats in which a species is less successful can reveal novel weapons to defeat invasiveness.\n\nChanges in fire regimens are another form of facilitation. \"Bromus tectorum\", originally from Eurasia, is highly fire-adapted. It not only spreads rapidly after burning but also increases the frequency and intensity (heat) of fires by providing large amounts of dry detritus during the fire season in western North America. In areas where it is widespread, it has altered the local fire regimen so much that native plants cannot survive the frequent fires, allowing \"B. tectorum\" to further extend and maintain dominance in its introduced range.\n\nFacilitation also occurs where one species physically modifies a habitat in ways that are advantageous to other species. For example, zebra mussels increase habitat complexity on lake floors, providing crevices in which invertebrates live. This increase in complexity, together with the nutrition provided by the waste products of mussel filter-feeding, increases the density and diversity of benthic invertebrate communities.\n\nIn ecosystems, the amount of available resources and the extent to which those resources are used by organisms determines the effects of additional species on the ecosystem. In stable ecosystems, equilibrium exists in the use of available resources. These mechanisms describe a situation in which the ecosystem has suffered a disturbance, which changes the fundamental nature of the ecosystem.\n\nWhen changes such as a forest fire occur, normal succession favors native grasses and forbs. An introduced species that can spread faster than natives can use resources that would have been available to native species, squeezing them out. Nitrogen and phosphorus are often the limiting factors in these situations.\n\nEvery species occupies a \"niche\" in its native ecosystem; some species fill large and varied roles, while others are highly specialized. Some invading species fill niches that are not used by native species, and they also can create new niches. An example of this type can be found within the \"Lampropholis delicata\" species of skink.\n\nEcosystem changes can alter species' distributions. For example, edge effects describe what happens when part of an ecosystem is disturbed as when land is cleared for agriculture. The boundary between remaining undisturbed habitat and the newly cleared land itself forms a distinct habitat, creating new winners and losers and possibly hosting species that would not thrive outside the boundary habitat.\n\nOne interesting finding in studies of invasive species has shown that introduced populations have great potential for rapid adaptation and this is used to explain how so many introduced species are able to establish and become invasive in new environments. When bottlenecks and founder effects cause a great decrease in the population size and may constrict genetic variation, the individuals begin to show additive variance as opposed to epistatic variance. This conversion can actually lead to increased variance in the founding populations which then allows for rapid adaptive evolution. Following invasion events, selection may initially act on the capacity to disperse as well as physiological tolerance to the new stressors in the environment. Adaptation then proceeds to respond to the selective pressures of the new environment. These responses would most likely be due to temperature and climate change, or the presence of native species whether it be predator or prey. Adaptations include changes in morphology, physiology, phenology, and plasticity.\n\nRapid adaptive evolution in these species leads to offspring that have higher fitness and are better suited for their environment. Intraspecific phenotypic plasticity, pre-adaptation and post-introduction evolution are all major factors in adaptive evolution. Plasticity in populations allows room for changes to better suit the individual in its environment. This is key in adaptive evolution because the main goal is how to best be suited to the ecosystem that the species has been introduced. The ability to accomplish this as quickly as possible will lead to a population with a very high fitness. Pre-adaptations and evolution after the initial introduction also play a role in the success of the introduced species. If the species has adapted to a similar ecosystem or contains traits that happen to be well suited to the area that it is introduced, it is more likely to fare better in the new environment. This, in addition to evolution that takes place after introduction, all determine if the species will be able to become established in the new ecosystem and if it will reproduce and thrive.\n\nIn 1958, Charles S. Elton claimed that ecosystems with higher species diversity were less subject to invasive species because of fewer available niches. Other ecologists later pointed to highly diverse, but heavily invaded ecosystems and argued that ecosystems with high species diversity were more susceptible to invasion.\n\nThis debate hinged on the spatial scale at which invasion studies were performed, and the issue of how diversity affects susceptibility remained unresolved as of 2011. Small-scale studies tended to show a negative relationship between diversity and invasion, while large-scale studies tended to show the reverse. The latter result may be a side-effect of invasives' ability to capitalize on increased resource availability and weaker species interactions that are more common when larger samples are considered.\nInvasion was more likely in ecosystems that were similar to the one in which the potential invader evolved. Island ecosystems may be more prone to invasion because their species faced few strong competitors and predators, or because their distance from colonizing species populations makes them more likely to have \"open\" niches. An example of this phenomenon was the decimation of native bird populations on Guam by the invasive brown tree snake. Conversely, invaded ecosystems may lack the natural competitors and predators that check invasives' growth in their native ecosystems.\n\nInvaded ecosystems may have experienced disturbance, typically human-induced. Such a disturbance may give invasive species a chance to establish themselves with less competition from natives less able to adapt to a disturbed ecosystem.\n\nNon-native species have many \"vectors\", including biogenic vectors, but most invasions are associated with human activity. Natural range extensions are common in many species, but the rate and magnitude of human-mediated extensions in these species tend to be much larger than natural extensions, and humans typically carry specimens greater distances than natural forces.\n\nAn early human vector occurred when prehistoric humans introduced the Pacific rat (\"Rattus exulans\") to Polynesia.\nVectors include plants or seeds imported for horticulture. The pet trade moves animals across borders, where they can escape and become invasive. Organisms stow away on transport vehicles.\n\nThe arrival of invasive propagules to a new site is a function of the site's invasibility.\n\nSpecies have also been introduced intentionally. For example, to feel more \"at home,\" American colonists formed \"Acclimation Societies\" that repeatedly imported birds that were native to Europe to North America and other distant lands. In 2008, U.S. postal workers in Pennsylvania noticed noises coming from inside a box from Taiwan; the box contained more than two dozen live beetles. Agricultural Research Service entomologists identified them as rhinoceros beetle, hercules beetle, and king stag beetle. Because these species were not native to the U.S., they could have threatened native ecosystems. To prevent exotic species from becoming a problem in the U.S., special handling and permits are required when living materials are shipped from foreign countries. USDA programs such as Smuggling Interdiction and Trade Compliance (SITC) attempt to prevent exotic species outbreaks in America.\n\nMany invasive species, once they are dominant in the area, are essential to the ecosystem of that area. If they are removed from the location it could be harmful to that area.\n\nEconomics plays a major role in exotic species introduction. High demand for the valuable Chinese mitten crab is one explanation for the possible intentional release of the species in foreign waters.\n\nThe development of maritime trade has rapidly affected the way marine organisms are transported within the ocean. Two ways marine organisms are transported to new environments are hull fouling and ballast water transport. In fact, Molnar et al. 2008 documented the pathways of hundreds of marine invasive species and found that shipping was the dominant mechanism for the transfer of invasive species. \n\nMany marine organisms have the capacity to attach themselves to vessel hulls. Therefore, these organisms are easily transported from one body of water to another and are a significant risk factor for a biological invasion event. Unfortunately, controlling for vessel hull fouling is voluntary and there are no regulations currently in place to manage hull fouling. However, California and New Zealand have announced more stringent control for vessel hull fouling within their respective jurisdictions.\n\nThe other main vector for the transport of non-native aquatic species is ballast water. Ballast water taken up at sea and released in port by transoceanic vessels is the largest vector for non-native aquatic species invasions. In fact, it is estimated that 10,000 different species, many of which are non-indigenous, are transported via ballast water each day. Many of these species are considered harmful and can negatively impact their new environment. For example, freshwater zebra mussels, native to the Black, Caspian and Azov seas, most likely reached the Great Lakes via ballast water from a transoceanic vessel. Zebra mussels outcompete other native organisms for oxygen and food, such as algae. Although the zebra mussel invasion was first noted in 1988, and a mitigation plan was successfully implemented shortly thereafter, the plan had a serious flaw or loophole, whereby ships loaded with cargo when they reached the Seaway were not tested because their ballast water tanks were empty. However, even in an empty ballast tank, there remains a puddle of water filled with organisms that could be released at the next port (when the tank is filled with water after unloading the cargo, the ship takes on ballast water which mixes with the puddles and then everything including the living organisms in the puddles is discharged at the next port). Current regulations for the Great Lakes rely on ‘salinity shock’ to kill freshwater organisms left in ballast tanks.\n\nEven though ballast water regulations are in place to protect against potentially invasive species, there exists a loophole for organisms in the 10-50 micron size class. For organisms between 10 and 50 microns, such as certain types of phytoplankton, current regulations allow less than 10 cells per milliliter be present in discharge from treatment systems. The discharge gets released when a ship takes on cargo at a port so the discharged water is not necessarily the same as the receiving body of water. Since many species of phytoplankton are less than 10 microns in size and reproduce asexually, only one cell released into the environment could exponentially grow into many thousands of cells over a short amount of time. This loophole could have detrimental effects to the environment. For example, some species in the genus \"Pseudo-nitzschia\" are smaller than 10 microns in width and contain domoic acid, a neurotoxin. If toxic \"Pseudo-nitzschia\" spp. are alive in ballast discharge and get released into their “new environment” they could cause domoic acid poisoning in shellfish, marine mammals and birds. Fortunately, human deaths related to domoic acid poisoning have been prevented because of stringent monitoring programs that arose after a domoic acid outbreak in Canada in 1987. Ballast water regulations need to be more rigorous to prevent future ramifications associated with the potential release of toxic and invasive phytoplankton.\n\nAnother important factor to consider about marine invasive species is the role of environmental changes associated with climate change, such as an increase in ocean temperature. There have been multiple studies suggesting an increase in ocean temperature will cause range shifts in organisms, which could have detrimental effects on the environment as new species interactions emerge. For example, Hua and Hwang proposed that organisms in a ballast tank of a ship traveling from the temperature zone through tropical waters can experience temperature fluctuations as much as 20 °C. To further examine the effects of temperature on organisms transported on hulls or in ballast water, Lenz et al. (2018) carried out study where they conducted a double heat stress experiment. Their results suggest that heat challenges organisms face during transport may enhance the stress tolerance of species in their non-native range by selecting for genetically adapted genotypes that will survive a second applied heat stress, such as increased ocean temperature in the founder population. Due to the complexity of climate change induced variations, it is difficult to predict the nature of temperature-based success of non-native species \"in-situ\". Since some studies have suggested increased temperature tolerance of “hijackers” on ships’ hulls or in ballast water, it is necessary to develop more comprehensive fouling and ballast water management plans in an effort to prevent against future possible invasions as environmental conditions continue to change around the world.\n\nInvasive species often exploit disturbances to an ecosystem (wildfires, roads, foot trails) to colonize an area. Large wildfires can sterilize soils, while adding a variety of nutrients. In the resulting free-for-all, formerly entrenched species lose their advantage, leaving more room for invasives. In such circumstances plants that can regenerate from their roots have an advantage. Non-natives with this ability can benefit from a low intensity fire burns that removes surface vegetation, leaving natives that rely on seeds for propagation to find their niches occupied when their seeds finally sprout.\n\nWildfires often occur in remote areas, needing fire suppression crews to travel through pristine forest to reach the site. The crews can bring invasive seeds with them. If any of these stowaway seeds become established, a thriving colony of invasives can erupt in as few as six weeks, after which controlling the outbreak can need years of continued attention to prevent further spread. Also, disturbing the soil surface, such as cutting firebreaks, destroys native cover, exposes soil, and can accelerate invasions. In suburban and wildland-urban interface areas, the vegetation clearance and brush removal ordinances of municipalities for defensible space can result in excessive removal of native shrubs and perennials that exposes the soil to more light and less competition for invasive plant species.\n\nFire suppression vehicles are often major culprits in such outbreaks, as the vehicles are often driven on back roads overgrown with invasive plant species. The undercarriage of the vehicle becomes a prime vessel of transport. In response, on large fires, washing stations \"decontaminate\" vehicles before engaging in suppression activities. Large wildfires attract firefighters from remote places, further increasing the potential for seed transport.\n\nLand clearing and human habitation put significant pressure on local species. Disturbed habitats are prone to invasions that can have adverse effects on local ecosystems, changing ecosystem functions. A species of wetland plant known as aeae in Hawaii (the indigenous \"Bacopa monnieri\") is regarded as a pest species in artificially manipulated water bird refuges because it quickly covers shallow mudflats established for endangered Hawaiian stilt (\"Himantopus mexicanus knudseni\"), making these undesirable feeding areas for the birds.\n\nMultiple successive introductions of different non-native species can have interactive effects; the introduction of a second non-native species can enable the first invasive species to flourish. Examples of this are the introductions of the amethyst gem clam (\"Gemma gemma\") and the European green crab (\"Carcinus maenas\"). The gem clam was introduced into California's Bodega Harbor from the East Coast of the United States a century ago. It had been found in small quantities in the harbor but had never displaced the native clam species (\"Nutricola\" spp.). In the mid-1990s, the introduction of the European green crab, found to prey preferentially on the native clams, resulted in a decline of the native clams and an increase of the introduced clam populations.\n\nIn the Waterberg region of South Africa, cattle grazing over the past six centuries has allowed invasive scrub and small trees to displace much of the original grassland, resulting in a massive reduction in forage for native bovids and other grazers. Since the 1970s, large scale efforts have been underway to reduce invasive species; partial success has led to re-establishment of many species that had dwindled or left the region. Examples of these species are giraffe, blue wildebeest, impala, kudu and white rhino.\n\nInvasive species can change the functions of ecosystems. For example, invasive plants can alter the fire regime (cheatgrass, \"Bromus tectorum\"), nutrient cycling (smooth cordgrass \"Spartina alterniflora\"), and hydrology (\"Tamarix\") in native ecosystems. Invasive species that are closely related to rare native species have the potential to hybridize with the native species. Harmful effects of hybridization have led to a decline and even extinction of native species. For example, hybridization with introduced cordgrass, \"Spartina alterniflora\", threatens the existence of California cordgrass (\"Spartina foliosa\") in San Francisco Bay. Invasive species cause competition for native species and because of this 400 of the 958 endangered species under the Endangered Species Act are at risk.\n\nPrimary geomorphological effects of invasive plants are bioconstruction and bioprotection. For example, Kudzu Pueraria montana, a vine native to Asia was widely introduced in the southeastern USA in the early 20th century to control soil erosion. While primary effects of invasive animals are bioturbation, bioerosion, and bioconstruction. For example, invasion of Chinese mitten crab Eriocheir sinensis have resulted in higher bioturbation and bioerosion rates.\n\nSome invaders cause negative benefits towards the economy of the local area. For example, in the Great Lakes Region the sea lamprey is an invasive species that acts as a predator. In its original habitat, the sea lamprey used co-evolution to act as a parasite without killing the host organism. However, in the Great Lakes Region, this co-evolutionary link is non existent, so the sea lamprey acts as a predator, and can consume up to 40 pounds of fish in its 12-18 month feeding period. Sea lampreys prey on all types of large fish such as lake trout and salmon. The sea lampreys' destructive effects towards large fish negatively affects the fishing industry and has helped collapse the population of some economy dependent species.\n\nSome invasions offer potential commercial benefits. For instance, silver carp and common carp can be harvested for human food and exported to markets already familiar with the product, or processed into pet foods, or mink feed. Water hyacinth can be turned into fuel by methane digesters, and other invasive plants can also be harvested and utilized as a source of bioenergy.\n\nAlthough most people focus on the negative effects of invasive and non-native species, they can actually be harmless or even beneficial in some cases. Ecosystems thrive because of biodiversity and some need non-native species in order to succeed. There are four major ways that non-natives can be very beneficial for an ecosystem. The first is that they can provide a suitable habitat or food source for other organisms. In areas where a native has become extinct or reached a point that it cannot be restored, non-native species can fill their role. A good example of this is the Tamarisk, a non-native woody plant, and the Southwestern Willow Flycatcher, an endangered bird. 75% of Southwestern Willow Flycatcher were found to nest in these plants and their success was the same as the flycatchers that had nested in native plants. The removal of Tamarisk would be detrimental to Southwestern Willow Flycatcher as their native nesting sites are unable to be restored. The second way that non-native species can be beneficial is that they act as catalysts for restoration. This is because the presence of non-native species increases the heterogeneity and biodiversity in an ecosystem. This increase in heterogeneity can create microclimates in sparse and eroded ecosystems, which then promotes the growth and reestablishment of native species. Another benefit of non-native species is that they can act as a substitute for an existing ecosystem engineer. In many cases, non-native species can be introduced to fill a niche that had previously been occupied by a native species. Many non-native species have similar characteristics and functions and can keep an ecosystem functioning properly without collapse. An example of this is the Aldabra giant tortoises, which were introduced on several small islands and have successfully taken over the roles of herbivore and seed disperser. The last benefit of non-native species is that they provided ecosystem services. There are many examples of this. The major one being pollinators. The American Honey bee was introduced in the rainforest to pollinate fragmented landscapes that native species cannot. Also, non-native species can function as biocontrol agents to limit the effects of invasive species. Such as the use of non-native species to control agricultural pests.\n\nNon-native species can have other benefits. Asian oysters, for example, filter water pollutants better than native oysters. They also grow faster and withstand disease better than natives. Biologists are currently considering releasing this mollusk in the Chesapeake Bay to help restore oyster stocks and remove pollution. A recent study by the Johns Hopkins School of Public Health found the Asian oyster could significantly benefit the bay's deteriorating water quality. Additionally, some species have invaded an area so long ago that they have found their own beneficial niche in the environment, a term referred to as naturalisation. For example, \"L. leucozonium\", shown by population genetic analysis to be an invasive species in North America, has become an important pollinator of caneberry as well as cucurbit, apple trees, and blueberry bushes.\n\n\"See also \"\n\nInvasive species are flora and fauna whose introduction into a habitat disrupts the native eco-system. In response, Invasivorism is a movement that explores the idea of eating invasive species in order to control, reduce, or eliminate their populations. Chefs from around the world have begun seeking out and using invasive species as alternative ingredients. Miya's of New Haven, Connecticut created the first invasive species menu in the world. Skeptics point out that once a foreign species has entrenched itself in a new place—such as the Indo-Pacific lionfish that has now virtually taken over the waters of the Western Atlantic, Caribbean and Gulf of Mexico—eradication is almost impossible. Critics argue that encouraging consumption might have the unintended effect of spreading harmful species even more widely.\n\nProponents of invasivorism argue that humans have the ability to eat away any species that it has an appetite for, pointing to the many animals which humans have been able to hunt to extinction—such as the Dodo bird, the Caribbean monk seal, and the passenger pigeon. Proponents of invasivorism also point to the success that Jamaica has had in significantly decreasing the population of lionfish by encouraging the consumption of the fish.\n\nEconomic costs from invasive species can be separated into direct costs through production loss in agriculture and forestry, and management costs. Estimated damage and control cost of invasive species in the U.S. alone amount to more than $138 billion annually. Economic losses can also occur through loss of recreational and tourism revenues. When economic costs of invasions are calculated as production loss and management costs, they are low because they do not consider environmental damage; if monetary values were assigned to the extinction of species, loss in biodiversity, and loss of ecosystem services, costs from impacts of invasive species would drastically increase. The following examples from different sectors of the economy demonstrate the impact of biological invasions.\n\nIt is often argued that the key to reducing the costs of invasive species damage and management is early detection and rapid response, meaning that incurring an initial cost of searching for and finding an invasive species and quickly controlling it, while the population is small, is less expensive that managing the invasive population when it is widespread and already causing damage. However, an intense search for the invader is only important to reduce costs in cases where the invasive species is (1) not frequently reintroduced into the managed area and (2) cost effective to search for and find.\n\nWeeds reduce yield in agriculture, though they may provide essential nutrients. Some deep-rooted weeds can \"mine\" nutrients (see dynamic accumulator) from the subsoil and deposit them on the topsoil, while others provide habitat for beneficial insects or provide foods for pest species. Many weed species are accidental introductions that accompany seeds and imported plant material. Many introduced weeds in pastures compete with native forage plants, threaten young cattle (e.g., leafy spurge, \"Euphorbia esula\") or are unpalatable because of thorns and spines (e.g., yellow starthistle). Forage loss from invasive weeds on pastures amounts to nearly US$1 billion in the U.S. alone. A decline in pollinator services and loss of fruit production has been caused by honey bees infected by the invasive varroa mite. Introduced rats (\"Rattus rattus\" and \"R. norvegicus\") have become serious pests on farms, destroying stored grains.\n\nInvasive plant pathogens and insect vectors for plant diseases can also suppress agricultural yields and nursery stock. Citrus greening is a bacterial disease vectored by the invasive Asian citrus psyllid (ACP). Because of the impacts of this disease on citrus crops, citrus is under quarantine and highly regulated in areas where ACP has been found.\n\nAquaculture is a very common vector of species introductions – mainly of species with economic potential (e.g., \"Oreochromis niloticus\").\n\nThe unintentional introduction of forest pest species and plant pathogens can change forest ecology and damage the timber industry. Overall, forest ecosystems in the U.S. are widely invaded by exotic pests, plants, and pathogens.\n\nThe Asian long-horned beetle (\"Anoplophora glabripennis\") was first introduced into the U.S. in 1996, and was expected to infect and damage millions of acres of hardwood trees. As of 2005 thirty million dollars had been spent in attempts to eradicate this pest and protect millions of trees in the affected regions. The woolly adelgid has inflicted damage on old-growth spruce, fir and hemlock forests and damages the Christmas tree industry. And the chestnut blight fungus (\"Cryphonectria parasitica\") and Dutch elm disease (\"Ophiostoma novo-ulmi\") are two plant pathogens with serious impacts on these two species, and forest health. Garlic mustard, \"Alliaria petiolata\", is one of the most problematic invasive plant species in eastern North American forests. The characteristics of garlic mustard are slightly different from those of the surrounding native plants, which results in a highly successful species that is altering the composition and function of the native communities it invades. When garlic mustard invades the understory of a forest, it affects the growth rate of tree seedlings, which is likely to alter forest regeneration of impact forest composition in the future.\n\nInvasive species can impact outdoor recreation, such as fishing, hunting, hiking, wildlife viewing, and water-based activities. They can damage a wide array of environmental services that are important to recreation, including, but not limited to, water quality and quantity, plant and animal diversity, and species abundance. Eiswerth states, \"very little research has been performed to estimate the corresponding economic losses at spatial scales such as regions, states, and watersheds\". Eurasian watermilfoil (\"Myriophyllum spicatum\") in parts of the US, fill lakes with plants complicating fishing and boating. The very loud call of the introduced common coqui depresses real estate values in affected neighborhoods of Hawaii.\n\nEncroachment of humans into previously remote ecosystems has exposed exotic diseases such as HIV to the wider population. Introduced birds (e.g. pigeons), rodents and insects (e.g. mosquito, flea, louse and tsetse fly pests) can serve as vectors and reservoirs of human afflictions. The introduced Chinese mitten crabs are carriers of Asian lung fluke. Throughout recorded history, epidemics of human diseases, such as malaria, yellow fever, typhus, and bubonic plague, spread via these vectors. A recent example of an introduced disease is the spread of the West Nile virus, which killed humans, birds, mammals, and reptiles. Waterborne disease agents, such as cholera bacteria (\"Vibrio cholerae\"), and causative agents of harmful algal blooms are often transported via ballast water. Invasive species and accompanying control efforts can have long term public health implications. For instance, pesticides applied to treat a particular pest species could pollute soil and surface water.\n\nBiotic invasion is considered one of the five top drivers for global biodiversity loss and is increasing because of tourism and globalization. This may be particularly true in inadequately regulated fresh water systems, though quarantines and ballast water rules have improved the situation.\n\nInvasive species may drive local native species to extinction via competitive exclusion, niche displacement, or hybridisation with related native species. Therefore, besides their economic ramifications, alien invasions may result in extensive changes in the structure, composition and global distribution of the biota of sites of introduction, leading ultimately to the homogenisation of the world's fauna and flora and the loss of biodiversity. Nevertheless, it is difficult to unequivocally attribute extinctions to a species invasion, and the few scientific studies that have done so have been with animal taxa. Concern over the impacts of invasive species on biodiversity must therefore consider the actual evidence (either ecological or economic), in relation to the potential risk.\n\nNative species can be threatened with extinction through the process of \"genetic pollution\". Genetic pollution is unintentional hybridization and introgression, which leads to homogenization or replacement of local genotypes as a result of either a numerical or fitness advantage of the introduced species. Genetic pollution occurs either through introduction or through habitat modification, where previously isolated species are brought into contact with the new genotypes. Invading species have been shown to adapt to their new environments in a remarkably short amount of time. The population size of invading species may remain small for a number of years and then experience an explosion in population, a phenomenon known as \"the lag effect\".\n\nHybrids resulting from invasive species interbreeding with native species can incorporate their genotypes into the gene pool over time through introgression. Similarly, in some instances a small invading population can threaten much larger native populations. For example, \"Spartina alterniflora\" was introduced in the San Francisco Bay and hybridized with native \"Spartina foliosa.\" The higher pollen count and male fitness of the invading species resulted in introgression that threatened the native populations due to lower pollen counts and lower viability of the native species. Reduction in fitness is not always apparent from morphological observations alone. Some degree of gene flow is normal, and preserves constellations of genes and genotypes. An example of this is the interbreeding of migrating coyotes with the red wolf, in areas of eastern North Carolina where the red wolf was reintroduced. The end result was a decrease in stable breeding pairs of red wolf, which may further complicate the social stability of packs and reintroduction efforts.\n\nHistory is rife with the spread of exotic diseases, such as the introduction of smallpox into the indigenous peoples of the Americas by the Spanish, where it obliterated entire populations of indigenous civilizations before they were ever even seen by Europeans.\n\nProblematic exotic disease introductions in the past century or so include the chestnut blight which has almost eliminated the American chestnut tree from its forest habitat. Responses to increase the population of the American chestnut include creating blight resistant trees that can be reintroduced. This displays both the positive and negative aspects of introduced species.\n\nAnother example is the Dutch elm disease, which has severely reduced the American elm trees in forests and cities.\n\nDiseases may also be vectored by invasive insects such as the Asian citrus psyllid and the bacterial disease citrus greening.\n\nBut in recent years some argue that some introduced species may have a positive ecological impact on an environment.\n\nWhile the study of invasive species can be done within many subfields of biology, the majority of research on invasive organisms has been within the field of ecology and geography where the issue of biological invasions is especially important. Much of the study of invasive species has been influenced by Charles Elton's 1958 book \"The Ecology of Invasion by Animals and Plants\" which drew upon the limited amount of research done within disparate fields to create a generalized picture of biological invasions. Studies on invasive species remained sparse until the 1990s when research in the field experienced a large amount of growth which continues to this day. This research, which has largely consisted of field observational studies, has disproportionately been concerned with terrestrial plants. The rapid growth of the field has driven a need to standardize the language used to describe invasive species and events. Despite this, little standard terminology exists within the study of invasive species which itself lacks any official designation but is commonly referred to as \"Invasion ecology\" or more generally \"Invasion biology\". This lack of standard terminology is a significant problem, and has largely arisen due to the interdisciplinary nature of the field which borrows terms from numerous disciplines such as agriculture, zoology, and pathology, as well as due to studies on invasive species being commonly performed in isolation of one another.\n\nIn an attempt to avoid the ambiguous, subjective, and pejorative vocabulary that so often accompanies discussion of invasive species even in scientific papers, Colautti and MacIsaac proposed a new nomenclature system based on biogeography rather than on taxa.\n\nBy discarding taxonomy, human health, and economic factors, this model focused only on ecological factors. The model evaluated individual populations rather than entire species. It classified each population based on its success in that environment. This model applied equally to indigenous and to introduced species, and did not automatically categorize successful introductions as harmful.\nPerhaps the best place to study problems associated with introduced species is on islands. Depending upon the isolation (how far an island is located from continental biotas), native island biological communities may be poorly adapted to the threat posed by exotic introductions. Often this can mean that no natural predator of an introduced species is present, and the non-native spreads uncontrollably into open or occupied niche.\n\nAn additional problem is that birds native to small islands may have become flightless because of the absence of predators prior to introductions and cannot readily escape the danger brought to them by introduced predators. The tendency of rails in particular to evolve flightless forms on islands making them vulnerable has led to the disproportionate number of extinctions in that family.\n\nThe field of island restoration has developed as a field of conservation biology and ecological restoration, a large part of which deals with the eradication of invasive species.\n\nIn New Zealand the largest commercial crop is \"Pinus radiata\", the native Californian Monterey pine tree, which grows as well in New Zealand as in California. However, the pine forests are also occupied by deer from North America and Europe. They are exotic species and have thrived in the New Zealand environment. The pines are seen as beneficial while the deer are regarded as serious pests.\n\nCommon gorse, originally a hedge plant in Britain, was introduced to New Zealand for the same purpose. Like the Monterey pine, it has shown a favour to its new climate. It is, however, regarded as a noxious plant that threatens to obliterate native plants in much of the country and is hence routinely eradicated, though it can also provide a nursery environment for native plants to reestablish themselves.\n\nRabbits, introduced as a food source by sailors in the 1800s, have become a severe nuisance to farmers, notably in the South Island. The myxomatosis virus was illegally imported and illegally released, but it had little lasting effect upon the rabbit population other than to make it more resistant to the virus.\n\nCats, brought later by Europeans, have had a devastating effect upon the native birdlife, particularly as many New Zealand birds are flightless. Feral cats and dogs which were originally brought as pets are also known to kill large numbers of birds. A recent (2006) study in the South Island has shown that even domestic cats with a ready supply of food from their owners may kill hundreds of birds in a year, including natives.\n\nSparrows, which were brought to control insects upon the introduced grain crops, have displaced native birds as have rainbow lorikeets and cockatoos (both from Australia) which fly free around areas west of Auckland City such as the Waitakere Ranges.\n\nIn much of New Zealand, the Australian black swan has effectively eliminated the existence of the previously introduced mute swan.\n\nTwo notable varieties of spiders have also been introduced: the white tail spider and the redback spider. Both may have arrived inside shipments of fruit. Until then, the only spider (and the only venomous animal) dangerous to humans was the native katipo, which is very similar to the redback and interbreed with the more aggressive Australian variety.\n\nIn 2018, the South Georgia Island was declared free of invasive rodents after a multi-year extermination effort.\n\nThis article incorporates CC-BY-3.0 text from the reference\n\n\n"}
{"id": "1592806", "url": "https://en.wikipedia.org/wiki?curid=1592806", "title": "Ion beam", "text": "Ion beam\n\nAn ion beam is a type of charged particle beam consisting of ions. Ion beams have many uses in electronics manufacturing (principally ion implantation) and other industries. A variety of ion beam sources exists, some derived from the mercury vapor thrusters developed by NASA in the 1960s. The most common ion beams are of singly-charged ions.\n\nIon current density is typically measured in mA/cm^2, and ion energy in eV. The use of eV is convenient for converting between voltage and energy, especially when dealing with singly-charged ion beams, as well as converting between energy and temperature (1 eV = 11600 K).\n\nMost commercial applications use two popular types of ion source, gridded and gridless, which differ in current and power characteristics and the ability to control ion trajectories. In both cases electrons are needed to generate an ion beam. The most common electron emitters are hot filament and hollow cathode.\n\nIn a gridded ion source, DC or RF discharge are used to generate ions, which are then accelerated and decimated using grids and apertures. Here, the DC discharge current or the RF discharge power are used to control the beam current. \n\nThe ion current density formula_1 that can be accelerated using a gridded ion source is limited by the space charge effect, which is described by Child's law: \n\nformula_2, \n\nwhere formula_3 is the voltage between the grids, formula_4 is the distance between the grids, and formula_5 is the ion mass. \n\nThe grids are placed as closely as possible to increase the current density, typically formula_6. The ions used have a significant impact on the maximum ion beam current, since formula_7. Everything else being equal, the maximum ion beam current with krypton is only 69% the maximum ion current of an argon beam, and with xenon the ratio drops to 55%.\n\nIn a gridless ion source, ions are generated by a flow of electrons (no grids). The most common gridless ion source is the end-Hall ion source. Here, the discharge current and the gas flow are used to control the beam current.\n\nOne type of ion beam source is the duoplasmatron. Ion beams can be used for sputtering or ion beam etching and for ion beam analysis.\n\nIon beam application, etching, or sputtering, is a technique conceptually similar to sandblasting, but using individual atoms in an ion beam to ablate a target. Reactive ion etching is an important extension that uses chemical reactivity to enhance the physical sputtering effect.\n\nIn a typical use in semiconductor manufacturing, a mask can selectively expose a layer of photoresist on a substrate made of a semiconductor material such as a silicon dioxide or gallium arsenide wafer. The wafer is developed, and for a positive photoresist, the exposed portions are removed in a chemical process. The result is a pattern left on the surface areas of the wafer that had been masked from exposure. The wafer is then placed in a vacuum chamber, and exposed to the ion beam. The impact of the ions erodes the target, abrading away the areas not covered by the photoresist.\n\nFocused ion beam (FIB) instruments have numerous applications for characterization of thin-film devices. Using a focused, high-brightness ion beam in a scanned raster pattern, material is removed (sputtered) in precise rectilinear patterns revealing a two-dimensional, or stratigraphic profile of a solid material. The most common application is to verify the integrity of the gate oxide layer in a CMOS transistor. A single excavation site exposes a cross section for analysis using a scanning electron microscope. Dual excavations on either side of a thin lamella bridge are utilized for preparing transmission electron microscope samples.\n\nAnother common use of FIB instruments is for design verification and/or failure analysis of semiconductor devices. Design verification combines selective material removal with gas-assisted material deposition of conductive, dielectric, or insulating materials. Engineering prototype devices may be modified using the ion beam in combination with gas-assisted material deposition in order to rewire an integrated circuit's conductive pathways. The techniques are effectively used to verify the correlation between the CAD design and the actual functional prototype circuit, thereby avoiding the creation of a new mask for the purpose of testing design changes.\n\nMaterials science use sputtering for extending surface analytical techniques such as secondary ion mass spectrometry or electron spectroscopy (XPS, AES) so that they can depth profile them.\n\nIn radiobiology a broad or focused ion beam is used to study mechanisms of inter- and intra- cellular communication, signal transduction and DNA damage and repair.\n\nIon beams are also used in particle therapy, most often in the treatment of cancer.\n\nIon beams produced by ion and plasma thrusters on board a spacecraft can be used to transmit a force to a nearby object (e.g. another spacecraft, an asteroid, etc.) that is irradiated by the beam. This innovative propulsion technique named Ion Beam Shepherd has been shown to be effective in the area of active space debris removal as well as asteroid deflection.\n\nHigh-energy ion beams produced by particle accelerators are used in atomic physics, nuclear physics and particle physics.\n\nThe use of ion beams as a particle beam weapon is theoretically possible, but has not been demonstrated. Electron beam weapons have been tested by the U.S. Navy in the early 20th century, but the hose instability effect prevents these from being accurate at a distance of over approximately 30 inches. See particle beam weapon for more information on this type of weapon.\n\n\n"}
{"id": "16871072", "url": "https://en.wikipedia.org/wiki?curid=16871072", "title": "Ionogram", "text": "Ionogram\n\nAn ionogram is a display of the data produced by an ionosonde. It is a graph of the virtual height of the ionosphere plotted against frequency. Ionograms are often converted into electron density profiles. Data from ionograms may be used to measure changes in the Earth's ionosphere due to space weather events.\n\n\n"}
{"id": "1965987", "url": "https://en.wikipedia.org/wiki?curid=1965987", "title": "Isotropic radiation", "text": "Isotropic radiation\n\nIsotropic radiation is radiation that has the same intensity regardless of the direction of measurement, such as would be found in a thermal cavity. The radiation may be electromagnetic, sound or may be composed of elementary particles.\n"}
{"id": "170789", "url": "https://en.wikipedia.org/wiki?curid=170789", "title": "List of Acer species", "text": "List of Acer species\n\nThere are over 160 species in the genus \"Acer\". Species with evergreen foliage are tagged #. Species and sections that are extinct are tagged with †.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3062873", "url": "https://en.wikipedia.org/wiki?curid=3062873", "title": "List of Lepidoptera that feed on beeches", "text": "List of Lepidoptera that feed on beeches\n\nBeeches, \"Fagus\" species, are used as food plants by the larvae of a number of Lepidoptera species including:\n\n\n"}
{"id": "55235621", "url": "https://en.wikipedia.org/wiki?curid=55235621", "title": "List of Ramsar sites in Albania", "text": "List of Ramsar sites in Albania\n\nThis is a list of wetlands in Albania which are designated by the Ramsar Convention as sites of international importance. Currently, Albania has 4 sites designated as Wetlands of International Importance, with a total surface area of . \n\n\n \n"}
{"id": "6146924", "url": "https://en.wikipedia.org/wiki?curid=6146924", "title": "List of Sites of Special Scientific Interest in Moray and Nairn", "text": "List of Sites of Special Scientific Interest in Moray and Nairn\n\nThe following is a list of Sites of Special Scientific Interest in the Moray and Nairn Area of Search. For other areas, see List of SSSIs by Area of Search.\n\n"}
{"id": "34923024", "url": "https://en.wikipedia.org/wiki?curid=34923024", "title": "List of animals referred to as white-lipped", "text": "List of animals referred to as white-lipped\n\nThe descriptive term white-lipped is part of the common name of a number of different animal species:\n\n"}
{"id": "27691659", "url": "https://en.wikipedia.org/wiki?curid=27691659", "title": "List of botanical gardens in Pakistan", "text": "List of botanical gardens in Pakistan\n\nA botanical garden is a place where plants, especially ferns, conifers and flowering plants, are grown and displayed for the purposes of research and education. This distinguishes them from parks and pleasure gardens where plants, usually with showy flowers, are grown for public amenity only. Botanical gardens that specialize in trees are sometimes referred to as arboretums. They are occasionally associated with universities, zoos.\n\n\n\n\n"}
{"id": "29928541", "url": "https://en.wikipedia.org/wiki?curid=29928541", "title": "List of coniferous plants of Montana", "text": "List of coniferous plants of Montana\n\nThere are at least 20 species of Gymnosperms or Coniferous plants in Montana. \n\nThe conifers, division Pinophyta, also known as division Coniferophyta or Coniferae, are one of 13 or 14 division level taxa within the Kingdom Plantae. Pinophytes are gymnosperms. They are cone-bearing seed plants with vascular tissue; all extant conifers are woody plants, the great majority being trees with just a few being shrubs. Typical examples of conifers include cedars, Douglas-firs, cypresses, firs, junipers, kauris, larches, pines, hemlocks, redwoods, spruces, and yews. The division contains approximately eight families, 68 genera, and 630 living species.\n\nThe Ponderosa Pine, a conifer, is the Montana State Tree.\n\nOrder: Pinales, Family: Cupressaceae\n\nOrder: Pinales, Family: Pinaceae\n\nOrder: Pinales, Family: Taxaceae\n\n\n"}
{"id": "15572892", "url": "https://en.wikipedia.org/wiki?curid=15572892", "title": "List of ecoregions in Gabon", "text": "List of ecoregions in Gabon\n\nThe following is a list of ecoregions in the Gabon, according to the Worldwide Fund for Nature (WWF).\n\n\"by major habitat type\"\n\n\n\n\n\"by bioregion\"\n\n\n\n"}
{"id": "9019508", "url": "https://en.wikipedia.org/wiki?curid=9019508", "title": "List of hop diseases", "text": "List of hop diseases\n\nThis article is a list of diseases of hops (\"Humulus lupulus\").\n\n"}
{"id": "16815656", "url": "https://en.wikipedia.org/wiki?curid=16815656", "title": "List of mountains in Croatia", "text": "List of mountains in Croatia\n\nThis is a list of mountains () in Croatia.\n\nThe highest mountains in Croatia belong to the Dinarides range that is sometimes also called Dinaric Alps, of which Dinara is the highest mountain in Croatia. Together with the easternmost parts of the Alps, these mountains span most of the country, and their orogenic activity started in the Paleozoic with the Variscan orogeny and continued in the Mesozoic and Cenozoic with the Alpine orogeny.\n\nThe mountains in the northeastern part of the country, in the Pannonian plain, are considerably older than the rest as their orogeny happened in the Paleozoic.\n\nMountains in the list are ordered by height.\n\n\n"}
{"id": "52878953", "url": "https://en.wikipedia.org/wiki?curid=52878953", "title": "List of protected areas of Aarhus Municipality", "text": "List of protected areas of Aarhus Municipality\n\nThis list of protected areas in Aarhus Municipality lists protected areas in Aarhus Municipality, Denmark.\n\nThree protections in the municipality are shared with adjacent Skanderborg Municipality. Most of the older protections are grounded in attempts at protecting scenic landscape values or securing public access, while more recent protections are mostly based in protecting biodiversity and threatened habitats.\n"}
{"id": "201289", "url": "https://en.wikipedia.org/wiki?curid=201289", "title": "List of trees of Denmark", "text": "List of trees of Denmark\n\nList of Hardy Trees cultivated in Denmark by genera\n\n\n"}
{"id": "35655100", "url": "https://en.wikipedia.org/wiki?curid=35655100", "title": "List of types of formally designated forests", "text": "List of types of formally designated forests\n\nThis is a list of types of formally designated forests, as used in various places around the world. It is organized in three sublists: by forest ownership, protection status, and designated use.\n\n\n\n\n\n\n\n\n"}
{"id": "27721731", "url": "https://en.wikipedia.org/wiki?curid=27721731", "title": "Nain Province", "text": "Nain Province\n\nIn Labrador, Canada, the North Atlantic Craton is known as the Nain Province. The Nain geologic province was intruded by the Nain Plutonic Suite which divides the province into the northern Saglek block and the southern Hopedale block.\n\nThe North Atlantic Craton is exposed in parts of the coast of Labrador, parts of central Greenland, the Scourian Complex of northwestern Scotland and is unexposed in northern Norway. The North Atlantic Craton fragmented 2450 to 2000 million years ago. When North America and Europe rejoined, the North Atlantic Craton was triangular shaped with each side ; this unit was separated when the Labrador Sea formed 61 to 40 million years ago. The crust of the North Atlantic Craton varies between thick and its rocks are 85% granitoid gneisses. The Nain Province was intruded by the 1350- to 1290-million-year-old Nain Plutonic Suite; composite anorthosite-granitic intrusions which divide the Nain Province into the northern Saglek Block and the southern Hopedale Block.\n\nIn Labrador the North Atlantic Craton is known as the Nain Province or Nain Craton. The Nain Province is more than long and wide. The gneisses of the Nain Province were last deformed and metamorphosed when two blocks docked together 2500 million years ago with a collisional boundary extending to the north and to the south of Nain, Labrador, Canada. These two blocks appear to represent two distinct Archean cratonic nuclei, each with its own mineral depositional history. \nMajor granitic intrusions – the Wheeler Mountain, Halbach, Alliger, Sheet Hill, Loon Island, Red Island, and Satok Island intrusions – form a north-trending linear chain which have a southerly decrease in age – 2135-million-year-old Wheeler Mountain granite in the north to the 2025-million-year-old Satok Island monzonite in the south. The Nain Province was then intruded by the 1350- to 1290-million-year-old Nain Plutonic Suite; composite anorthosite-granitic intrusions which divide the Nain Province into the northern Saglek block and the southern Hopedale block. The Torngat orogen developed during the oblique convergence of the Superior and Nain Provinces 900 million years ago. \nThe crystalline crust in the Nain Province is thick; it thins to thick in the shelf area of the Labrador margin, where it is covered with up to of sediments.\n\nThe 3800- to 3300-million-year-old Saglek block is long and wide; it has a north-northwesterly trend from Nain, Labrador, extending nearly to the northern tip of Labrador. This block is a high-grade gneiss terrane; it has no greenstone belts. Within the gneiss are variably-sized enclaves ranging from anorthosite to ultramafic. There are also three small anorthositic, ultramafic meta-igneous complexes in the gneiss near Okak Bay.\n\nThe northward–trending Handy fault separates the Saglek block into two metamorphic parts. The gneiss complex on the western side of the Handy fault has rocks that crystallized under granulite facies conditions; this western block is more deeply exposed than the eastern one. On the eastern side amphibolite facies rocks are exposed in the northern part; they transition to granulite facies to the south. The total crustal thickness is north of the fault and south of the fault.\n\nThe 3100- to 2800-million-year-old Hopedale block is long and wide. Hopedale, Labrador, is at the eastern midpoint. This block contains the 3100-million-year-old Hunt River and 3000-million-year-old Florence Lake greenstone belts, and the Weekes amphibolite which represents remnants of the older Hunt River greenstone belt.\n"}
{"id": "4200598", "url": "https://en.wikipedia.org/wiki?curid=4200598", "title": "Ontong Java Plateau", "text": "Ontong Java Plateau\n\nThe Ontong Java Plateau (OJP) is a huge oceanic plateau located in the south-west Pacific Ocean, north of the Solomon Islands.\nThe OJP was emplaced 120 Ma with a much smaller volcanic event 90 Ma. Two other south-west Pacific plateaus, Manihiki and Hikurangi, now separated from the OJP by Cretaceous ocean basins, are of similar age and composition and probably formed as a single plateau and a contiguous large igneous province together with the OJP.\nWhen emplaced this Ontong Java-Manihiki-Hikurangi plateau covered 1% of Earth's surface and represented a volume of of basaltic magma.\nThis \"Ontong Java event\", first proposed in 1991, represents the largest volcanic event of the past 200 million years, with a magma emplacement rate estimated at up to /year over three million years, several times larger than the Deccan Traps.\nThe smooth surface of the OJP is punctuated by seamounts such as the Ontong Java Atoll, the largest atoll in the world.\n\nThe OJP covers , roughly the size of Alaska. It reaches up to below sea level but has an average depth closer to . It is bounded by Lyra Basin to the north-west, East Mariana Basin to the north, Nauru Basin to the north-east, and the Ellice Basin to the south-east. The OJP has collided with the Solomon Islands island arc and now lies on the inactive Vitiaz Trench and the Pacific-Australian plate boundary.\n\nThe high plateau, with a crustal thickness estimated to at least but probably closer to , has a volume of more than . The maximum extent of the event can, however, be much larger since lavas in several surrounding basins are closely related to the OJP event and probably represent dike swarms associated with the emplacement of the OJP.\n\nOJP formed quickly over a mantle plume head, most likely the then newly formed Louisville hotspot, followed by limited volcanism for at least 30 million years. The extant seamounts of the Louisville Ridge started to form 70 Ma and have a different isotopic composition, and therefore a shift in intensity and magma supply in the plume must have occurred before that.\n\nThe early, short-duration eruptions of OJP coincide with the global Early Aptian oceanic anoxic event (known as OAE1a or the Selli Event, 125.0–124.6 Ma) that lead to the deposition of black shales during the interval 124–122 Ma. Additionally, isotopic records of seawater in sediments have been associated with the 90 Ma OJP submarine eruptions.\n\nAbout 80% of the OJP is being subducted beneath the Solomon Islands. Only the uppermost 7 km of the crust is preserved on the Australian Plate.\nThis collision has lifted some of the OJP between above sea level. The construction of Pliocene stratovolcanoes in the western end of the convergence zone has resulted in the New Georgia Islands () and Bougainville Island (). Shortening, uplift, and erosion of the northern Melanesian arc and the Malaita accretionary prism at deep levels has produced Guadacanal (), Makira (), and Malaita ().\n\n\n"}
{"id": "5561995", "url": "https://en.wikipedia.org/wiki?curid=5561995", "title": "Ottoman–German alliance", "text": "Ottoman–German alliance\n\nThe Ottoman–German Alliance was an alliance between the German Empire and the Ottoman Empire that was ratified on August 2, 1914, shortly following the outbreak of World War I. The alliance was created as part of a joint-cooperative effort that would strengthen and modernize the failing Ottoman military, as well as provide Germany safe passage into neighboring British colonies.\n\nOn the eve of the First World War, the Ottoman Empire was in ruinous shape. As a result of successive wars fought in this period, territories were lost, the economy was in shambles and people were demoralized and tired. What the Empire needed was time to recover and to carry out reforms; however, there was no time, because the world was sliding into war and the Ottoman Empire was highly unlikely to manage to remain outside the coming conflict. Since staying neutral and focusing on recovery did not appear to be possible, the Empire had to ally with one or the other camp, because, after the Italo-Turkish War and Balkan Wars, it was completely out of resources. There were not adequate quantities of weaponry and machinery left; and neither did the Empire have the financial means to purchase new ones. The only option for the Sublime Porte was to establish an alliance with a European power; and at first it did not really matter which one that would be. As Talat Paşa, the Minister of Interior, wrote in his memoirs: “Turkey needed to join one of the country groups so that it could organize its domestic administration, strengthen and maintain its commerce and industry, expand its railroads, in short to survive and to preserve its existence.”\n\nMost European powers were not interested in joining an alliance with the ailing Ottoman Empire. Already at the beginning of the Turco-Italian War in Northern Africa, the Grand Vizier Sait Halim Paşa had expressed the government’s desire, and the Turkish ambassadors were asked to find out whether the European capitals would be interested. Only Russia seemed to have an interest – however, under conditions that would have amounted a Russian protectorate on the Ottoman lands. It was impossible to reconcile an alliance with the French: as France’s main ally was Russia, the long-time enemy of the Ottoman Empire since the War of 1828. Great Britain declined an Ottoman request.\n\nThe Ottoman Sultan Mehmed V specifically wanted the Empire to remain a non-belligerent nation. However pressure from some of Mehmed’s senior advisors led the Empire to align with the Central Powers. Whilst Great Britain was unenthusiastic about aligning with the Ottoman Empire, Germany was enthusiastic.\n\nGermany needed the Ottoman Empire on its side. The Orient Express had run directly to Constantinople since 1889, and prior to the First World War the Sultan had consented to a plan to extend it through Anatolia to Baghdad under German auspices. This would strengthen the Ottoman Empire's link with industrialized Europe, while also giving Germany easier access to its African colonies and to trade markets in India. To keep the Ottoman Empire from joining the Triple Entente, Germany encouraged Romania and Bulgaria to enter the Central Powers.\n\nA secret treaty was concluded between the Ottoman Empire and the German Empire on August 2, 1914. The Ottoman Empire was to enter the war on the side of the Central Powers one day after the German Empire declared war on Russia. The alliance was ratified on 2 August by many high-ranking Ottoman officials, including Grand Vizier Said Halim Pasha, the Minister of War Enver Pasha, the Interior Minister Talat Pasha, and Head of Parliament Halil Bey.\n\nHowever, there was no signature from the House of Osman as the Sultan Mehmed V did not sign it. According to the Constitution, the Sultan was the Commander-in-Chief of the Army, and this made the legitimacy of the Alliance questionable. This meant that the army was not able to fight on behalf of the Sultan. The Sultan himself had wanted the Empire to remain neutral. He did not wish to command a war himself and as such left the Cabinet to do much of his bidding. The third member of the cabinet of the Three Pashas Djemal Pasha also did not sign the treaty as he had tried to form an alliance with France. Not all parts of the Ottoman government accepted the Alliance.\n\nAustria-Hungary adhered to the Ottoman–German treaty on 5 August. The Ottoman Empire did not enter the war until the Ottoman Navy bombarded Russian ports on the 29 October 1914.\n\n"}
{"id": "44915179", "url": "https://en.wikipedia.org/wiki?curid=44915179", "title": "Psi Draconis", "text": "Psi Draconis\n\nThe Bayer designation Psi Draconis (ψ Dra / ψ Draconis) is shared by two star systems, in the constellation Draco:\n"}
{"id": "46655162", "url": "https://en.wikipedia.org/wiki?curid=46655162", "title": "Rapa das Bestas of Sabucedo", "text": "Rapa das Bestas of Sabucedo\n\n\"A rapa das bestas\" is the name given to the annual \"curro\" (roundup) of wild horses celebrated the first friday, Saturday, Sunday, and Monday of July in Sabucedo, Pontevedra, Spain.\n\nAcross more than 200 km² of hillside currently more than six-hundred horses roam freely in fourteen droves, referred to in Galician as \"bestas\" (mares) and \"garañones\" (stallions). The festival involves bringing the horses down from the hillside, gathering them into an enclosure, cutting their manes and tails, and tagging them, nowadays with a microchip. The \"curro\" in Sabucedo is the most renowned of all and is set apart from the rest by unique characteristics, the most important of which is that neither ropes, sticks, nor other such instruments are used to subdue the animals.\nThe \"aloitadores\", those responsible for restraining the horses whilst the \"rapa\" takes place, use only their body strength and raw skill to complete the job. Another interesting feature of the \"rapa\" is the \"Bajada\"– the process of rounding up the horses and leading them into Sabucedo – a part of the celebration joined by hundreds of local residents and visitors from further afield. Another element of the tradition is the celebration of a poignant mass, held very early on the Saturday morning, before going up the hill. During the mass, the congregation pray to San Lorenzo, the patron saint of Sabucedo, to keep those participating from any harm.\n\nAccording to the scholar Manuel Cabada, the \"rapa\" is a rite of passage from childhood to adolescence for those who seize a foal for the first time, guided and assisted by the older generation. \nThe town of A Estrada is twinned with Almonte, located in the province of Huelva, due to a similar celebration that takes place called \"Saca de las Yeguas\".\n\nRecords show that the tradition of the \"bajada\", the subsequent \"rapa\" and the marking of the young foals dates back to the beginning of the 18th century. Nevertheless, it is believed that the tradition is actually much older as scholars such as Manuel Cabada have mentioned in their writings. In fact it could even be Pre-Roman, given that various petroglyphs have been found in the area in which men are depicted on horseback. In 1963, the festival was declared of National Touristic Interest, and in 2007 was awarded the status of International Touristic Interest, one of only four in Galicia to hold this prestigious title.\n\n"}
{"id": "16733975", "url": "https://en.wikipedia.org/wiki?curid=16733975", "title": "Rodrigues Triple Junction", "text": "Rodrigues Triple Junction\n\nThe Rodrigues Triple Junction (RTJ), also known as the Central Indian [Ocean] Triple Junction (CITJ) is a geologic triple junction in the southern Indian Ocean where three tectonic plates meet: the African Plate, the Indo-Australian Plate, and the Antarctic Plate. The triple junction is named for the island of Rodrigues which lies north-west of it.\n\nThe RTJ was first recognized in 1971, then described as a stable R-R-R (ridge-ridge-ridge) triple junction based on coarse ship data.\n\nThe boundaries of the three plates which meet at the Rodrigues Triple Junction are all oceanic spreading centers, making it an R-R-R type triple junction. They are: the Central Indian Ridge (CIR, between the African and Indo-Australian plates) with a spreading rate of 50 mm/yr; the Southwest Indian Ridge (SWIR, between the African and Antarctic plates) 16 mm/yr; and the Southeast Indian Ridge (SEIR, between the Indo-Australian and Antarctic plates) 60 mm/yr.\n\nThe SEIR has the highest spreading rates at the RTJ, and, while now considered an intermediate spreading centre, it was a fast spreading ridge between anomalies 31 and 22, with a rate of 110 km/myr at anomaly 28. The spreading rate is similar in the CIR but slower and the ridge has a more complex geometry. The SWIR has ultra-slow spreading rates, a rough topography, and great number of large offset fracture zones.\n\nAll three boundaries are themselves intersected by diffuse boundaries: the CIR is intersected by the Indian–Capricorn boundary; the CEIR by the Capricorn–Australian boundary; and the SWIR by the Nubian–Somalian boundary. For example, the East African Rift divides Africa into the Nubian and Somalian plates. These plates converge in the southern part of the rift valley (2 mm/yr) but diverge in the northern part (6 mm/yr) and a very slight difference in spreading rates across the central part of the ultra-slow SWIR indicates there is a vague triple junction somewhere south of Madagascar.\n\nThe RTJ was born when the Seychelles microcontinent drifted off the Indian Plate at 64 Ma and the Carlsberg Ridge opened. Since then the RTJ has moved eastward from south of Madagascar (modern coordinates) to its current location.\n\nSince 65 Ma the RTJ has been migrating north-east at a decreasing rate: originally the velocity was 10 cm/yr, at 43 Ma 2.6 cm/yr, and since 41 Ma around 3.6–3.8 cm/yr. The stability in migration rate around 41 Ma coincide with the bend in the Hawaiian–Emperor seamount chain — hinting at a global reorganisation of tectonic plates at this time.\n\nOriginally considered a stable RRR (ridge-ridge-ridge) triple junction, the RTJ is now believed to be an unstable RRF (ridge-ridge-fault) triple junction in which the axis of the CIR is offset eastward by 14 km/myr because of differences in spreading rates between the CEIR and CIR. This is a configuration similar to that of the Galapagos Triple Junction in the east Pacific.\nEach time the RTJ offset eastward a new segment is added to CIR. resulting in a constant length for the CEIR while CIR constantly lengthens. Spreading rates in the SWIR, in contrast, is intermittent and very slow, but the extension of the plates in the SEIR and CIR causes constant lengthening of the SWIR near the RTJ.\n\n"}
{"id": "3090379", "url": "https://en.wikipedia.org/wiki?curid=3090379", "title": "Rubble", "text": "Rubble\n\nRubble is broken stone, of irregular size, shape and texture; undressed especially as a filling-in. Rubble naturally found in the soil is known also as 'brash' (compare cornbrash). Where present, it becomes more noticeable when the land is ploughed or worked.\n\n\"Rubble-work\" is a name applied to several types of masonry. One kind, where the stones are loosely thrown together in a wall between boards and grouted with mortar almost like concrete, is called in Italian \"muraglia di getto\" and in French \"bocage\". In Pakistan, walls made of rubble and concrete, cast in a formwork, are called 'situ', which probably derives from Sanskrit (similar to the Latin 'in situ' meaning 'made on the spot').\n\nWork executed with more or less large stones put together without any attempt at courses is called rubble walling. Where similar work is laid in courses, it is known as coursed rubble. Dry-stone walling is somewhat similar work done without the use of mortar. It is bound together by the fit of the stones and the regular placement of stones which extend through the thickness of the wall. A rubble wall built with mortar will be stronger if assembled in this way.\n\nRubble walls () are found all over the island of Malta. Similar walls are also frequently found in Sicily and the Arab countries. The various shapes and sizes of the stones used to build these walls look like stones that were found in the area lying on the ground or in the soil. It is most probable that the practice of building these walls around the field was inspired by the Arabs during their rule in Malta, as in Sicily who were also ruled by the Arabs around the same period. The Maltese farmer found that the technique of these walls was very useful especially during an era where resources were limited. Rubble walls are used to serve as borders between the property of one farm from the other. A great advantage that rubble walls offered is that when heavy rain falls, their structure would allow excessive water to pass through and therefore, excess water will not ruin the products. Soil erosion is minimised as the wall structure allows the water to pass through but it traps the soil and prevents it from being carried away from the field. One can see many rubble walls on the side of the hills and in valleys where the land slopes down and consequently the soil is in greater danger of being carried away.\n\n\n"}
{"id": "27293590", "url": "https://en.wikipedia.org/wiki?curid=27293590", "title": "The SAS Survival Handbook", "text": "The SAS Survival Handbook\n\nThe SAS Survival Handbook is a survival guide by British author and professional soldier, John Wiseman, first published by Williams Collins in 1986. Second, revised edition came out in 2009. A digital app for smartphones based on the book is also available. The book spans over 11 sections, and an introduction and postscript, detailing how to survive in dangerous surroundings.\n\nWith this book, John Wiseman seeks to provide the reader with the knowledge to survive any wilderness survival or disaster situation. It details basic survival skills, like how to build a fire, to more complex and situation-specific skills, like how to take shelter while indoors during an earthquake. \n\nA third, expanded version of the book was published in 2014. A section on \"Urban Survival\" was added for this edition. \n\nThe book is a popular choice among survivalists and preppers. \n\n\n\n"}
{"id": "2060273", "url": "https://en.wikipedia.org/wiki?curid=2060273", "title": "Threatened fauna of Australia", "text": "Threatened fauna of Australia\n\nThreatened fauna of Australia are those species and subspecies of birds, fish, frogs, insects, mammals, molluscs, crustaceans and reptiles to be found in Australia that are in danger of becoming extinct. This list is the list proclaimed under the Australian federal Environment Protection and Biodiversity Conservation Act 1999 (EPBC Act). The classifications are based on those used by the World Conservation Union (IUCN), however IUCN and Australian rankings do differ.\nOne fish is listed as extinct in the wild.\n\nFive mammals, six birds, two reptiles, three fish and five other species are listed as critically endangered.\n\n\n\n\n\n\nThirty-four mammals, thirty-eight birds, eleven reptiles, eighteen frogs, sixteen fishes and eleven other species are listed as endangered.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFour fish and one mammal are conservation dependent.\n\n\n\n\"Environment Protection and Biodiversity Conservation Act 1999\" (Cth) and Regulations set up a framework for protection of the Australian environment, including its biodiversity and its natural and culturally significant places. \n\nThreatened species in Australia are protected (or affected by) by four main types of legislation:\n\n\n"}
{"id": "143410", "url": "https://en.wikipedia.org/wiki?curid=143410", "title": "Umbra, penumbra and antumbra", "text": "Umbra, penumbra and antumbra\n\nThe umbra, penumbra and antumbra are three distinct parts of a shadow, created by any light source after impinging on an opaque object. Assuming no diffraction, for a point source only the umbra is cast.\n\nThese names are most often used for the shadows cast by celestial bodies, though they are sometimes used to describe levels of darkness, such as in sunspots.\n\nThe umbra (Latin for \"shadow\") is the innermost and darkest part of a shadow, where the light source is completely blocked by the occluding body. An observer in the umbra experiences a total eclipse. The umbra of a round body occluding a round light source forms a right circular cone; to a viewer at the cone's apex, the two bodies are equal in apparent size. The distance from the Moon to the apex of its umbra is roughly equal to that between the Moon and Earth (). Since Earth's diameter is 3.70 times the Moon's, its umbra extends correspondingly farther: roughly .\n\nThe penumbra (from the Latin \"paene\" \"almost, nearly\") is the region in which only a portion of the light source is obscured by the occluding body. An observer in the penumbra experiences a partial eclipse.\nAn alternative definition is that the penumbra is the region where \"some or all\" of the light source is obscured (i.e., the umbra is a subset of the penumbra). For example, NASA's Navigation and Ancillary Information Facility defines that a body in the umbra is also within the penumbra.\n\nThe antumbra (from Latin \"ante\", \"before\") is the region from which the occluding body appears entirely within the disc of the light source. An observer in this region experiences an annular eclipse, in which a bright ring is visible around the eclipsing body. If the observer moves closer to the light source, the apparent size of the occluding body increases until it causes a full umbra.\n\n"}
{"id": "8547338", "url": "https://en.wikipedia.org/wiki?curid=8547338", "title": "VENUS", "text": "VENUS\n\nVENUS - (Victoria Experimental Network Under the Sea) is one of two principal cabled sea floor observatories operated by Ocean Networks Canada at the University of Victoria, British Columbia, Canada. \n\nThe VENUS cabled ocean observatory is designed to provide new ways of studying the ocean. Since its launch in 2006, it has enabled scientists to run and monitor various ocean experiments out of the convenience of their desktops. The aim of VENUS is to study coastal oceans in two sites near Victoria and Vancouver, British Columbia. The first site of the VENUS seafloor network, operational since February 2006, is located in Saanich Inlet at 100m. The second site is located in the deeper waters of the Strait of Georgia and links instrument arrays deployed at depths varying from 100 to 300 meters. \n\nVENUS uses Internet, telecommunication technology, and a network of about 50 kilometers of fiber optic cables at a maximum depth of 300 meters to create a permanent link to cameras and other monitoring instruments on the seafloor. The VENUS observatory has scores of sensors that measure such parameters as temperature, salinity, and pressure of the water 24 hours a day. The seafloor instruments provide oceanographers, marine biologists, and geologists with real-time ocean data. \"The VENUS observatory represents a step change for the world of marine science and oceanography, which will help improve the way marine scientists observe ocean life in the future,\" said Dr. Phil Hart, Director of Engineering at Global Marine. Ship-based ocean research methods provide a snapshot view only, whereas the VENUS observatory can be like a continuous film, which will allow more reliable long term observation.\n\nThe data, including images and audio, are processed and made available to researchers and the public through the VENUS website. The goal of the project is to not only provide valuable information to advance research, but also to allow everyone from graduate school students to curious parents to log on and view the ocean up close. \n\nThe facility is funded by the federal and provincial governments of Canada, as well as private industry. VENUS is designed to provide continuous observations for 20–25 years.\n\n\n"}
{"id": "15503003", "url": "https://en.wikipedia.org/wiki?curid=15503003", "title": "Western Hemisphere Shorebird Reserve Network", "text": "Western Hemisphere Shorebird Reserve Network\n\nThe Western Hemisphere Shorebird Reserve Network (WHSRN) is a conservation strategy targeting shorebirds in the Americas launched in 1985. Its aim is to protect the nesting, breeding and staging habitats of migratory shorebirds. The first site to be classified was Delaware Bay, which was dedicated in May 1986 as a site of Hemispheric Importance.\n\nSites in the Western Hemisphere Shorebird Reserve Network may also be classified as Important Bird Areas, Ramsar wetlands of international importance, or both.\n\nThere are three possible classifications for sites in the network. Landscapes are always classified as being of Hemispheric Importance.\n\n\n\n"}
{"id": "13859485", "url": "https://en.wikipedia.org/wiki?curid=13859485", "title": "Western Himalayan alpine shrub and meadows", "text": "Western Himalayan alpine shrub and meadows\n\nThe Western Himalayan alpine shrub and meadows is an montane grasslands and shrublands ecoregion of Nepal, India, and Tibet, which lies between the tree line and snow line in the western portion of the Himalaya Range.\n\nThe Western Himalayan alpine shrub and meadows covers an area of , extending from the Kali Gandaki Gorge in central Nepal westwards across Uttarakhand and eastern Himachal Pradesh states of India to the gorge of the Sutlej River. The alpine shrub and meadows lie between approximately elevation. \n\nThe Eastern Himalayan alpine shrub and meadows lie east of the Kali Gandaki gorge, while the Northwestern Himalayan alpine shrub and meadows lies west of the Sutlej. Below lie the Western Himalayan subalpine conifer forests. Permanent ice and snow lies above . To the north, the Western Himalayan alpine shrub and meadows transition to the drier Central Tibetan Plateau alpine steppe of central Tibet. The Karakoram-West Tibetan Plateau alpine steppe lies to the southwest.\n\nAlpine shrublands, dominated by rhododendrons, predominate at lower elevations close to the treeline.\n\nAbove the shrublands are alpine meadows, known as bugyals or bughiyals, which support a variety of herbaceous plants, including species of \"Anaphalis, Cyananthus, Jurinea, Morina, Potentilla, Gentiana, Delphinium, Meconopsis, Pedicularis, Anemone, Aster, Polygonum, Primula\", and \"Saussurea\". In the spring and summer, the alpine meadows are covered with brightly colored flowers.\n\nOn the upper slopes, low plants of genera \"Saxifraga, Allium, Corydalis, Eriophyton, Stellaria, Soroseris\", and \"Cremanthodium\" grow among the boulders and scree.\n\nAn alpine steppe of \"Caragana pygma, C. gerardiana, Lonicera spinosa, Juniperus squamata, Juniperus indica, Ephedra gerardiana, Hippophae tibetana, Myricaria rosea, Lonicera spinulosa\", and \"Berberis\" can be found in drier parts of the ecoregion.\n\nLarge mammals include the snow leopard (\"Uncia uncia\"), bharal or Himalayan blue sheep (\"Pseudois nayaur\"), Himalayan tahr (\"Hemitragus jemlahicus\"), Himalayan musk deer (\"Moschus chrysogaster\"), and mainland serow (\"Capricornis sumatraensis\"). Smaller mammals include weasels and pikas.\n\nSeveral protected areas lie within or partly within the ecoregion, including:\n\n\n"}
