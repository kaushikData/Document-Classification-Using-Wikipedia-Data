{"id": "44811946", "url": "https://en.wikipedia.org/wiki?curid=44811946", "title": "12BV7", "text": "12BV7\n\nThe 12BV7, 12BY7, 12BY7A, and equivalents were a class of medium-low gain, pentode vacuum tube amplifiers using the Noval socket configuration. Although originally marketed as pentode tubes for use in early television receivers, they found additional uses in audio and radiotelephone equipment. The series shares the EIA 9BF pinout with a number of other miniature pentode tubes of the era.\n\nThe most successful tube in this series, 12BY7A was introduced by General Electric in June 1955 as a demodulated video signal amplifier for television receivers. Its design specifications called for linear gain along a wide bandwidth (approximately 4 MHz) with low transconductance (13 Millimhos (Millisiemens)) and high sensitivity. This combination of sensitivity, bandwidth and price lead to its popularity in audio amplification systems during the tube era.\n\nLike other vacuum tubes of US and Japanese manufacture, the RETMA tube designation system was used to designate identical tubes across different manufacturers. Any variations from the original electrical design specifications required a change to the tube designation code. As a result, a number of cross-reference resources exist. In some cases, multiple tube designation numbers were marked on the tube itself.\n\n12BY7 was an immediate successor to the 12BV7 and provided the same amplification values, but had slightly higher screen dissipation and voltage ratings. The tube also exhibited slightly lower transconductance ratings (11 mS vs the original specification of 13 mS).\n\nThe most popular variant from the original 12BV7 was the 12BY7A. In this case, the A suffix is used to indicate a backwards-compatible revision to the original specification. Specifically, the heater filament had been redesigned to further protect it from the potentially damaging voltage spikes which were known to occur when the tube heater circuits were wired in series rather than parallel. All of the other design specifications, including warmup time, were identical to the 12BY7.\n\nThe 12DQ7 was the final backwards compatible update to the 12BV7. It offered higher maximum screen and plate voltages of 330VAC. The transconductance value was further reduced from 11 mS to 10.5 mS.\n\nThe 7733 is listed as a premium version of the 12BY7A variant suitable for industrial or instrument service.\n\nThis is the European Mullard–Philips tube designation number for the 12BY7A variant. The code breakdown is as follows:\n\nAlthough intended for video signal pre-amplification, the relatively high Mu to bandwidth ratio of the 12BY7 and 12BY7A variants lead to their adoption in audio amplification equipment during the Hi-Fi era. There is some dispute in the audio community as to whether the 12DQ7 and 12BV7 variants are acceptable substitutes when discussing the psychoacoustics of various amplifiers.\n\nThe tube series' wide-bandwidth characteristics lead a number of manufacturers to utilize later variants, such as the 12BY7A as a transmit exciter and/or receive preamplifier in the RF stages of their radios. This RF design remained in use throughout the 1970s and early 1980s even as the other stages were replaced with Solid State components. Equipment using mixed tube & solid-state technologies came to be known as \"Hybrid\" or \"Hybrid Solid State\".\n\nTrio (later Kenwood) - TS-520, TS-820, TS-530, TS-830, R-820\nR.L. Drake Company - TR4\nYaesu Musen (later Yaesu) - FT-101, FT-200 (Also resold as the Henry Tempo One)\nSide-Band Engineers - SBE-34\n\nThe Tektronix 555 Modular Oscilloscope utilized a total of six 12BY7 and 12BY7A tubes. Four 12BY7s were specified for the main chassis as vertical amplifiers for the CRT beams (V1014, V1024, V2014, V2024), and one 12BY7A each in the Type 21 and Type 22 time-base modules (V145)\n"}
{"id": "13480983", "url": "https://en.wikipedia.org/wiki?curid=13480983", "title": "ATP Rankings", "text": "ATP Rankings\n\nThe ATP Rankings are the objective merit-based method used by the Association of Tennis Professionals (ATP) for determining the qualification for entry as well as the seeding of players in all singles and doubles tournaments. The first rankings for singles were published on 23 August 1973 while the doubles players were ranked for the first time on 1 March 1976. Ranking points are awarded according to the stage of tournament reached, and the prestige of the tournament, with the four Grand Slams awarding the most points. The rankings are updated every Monday, and points are dropped 52 weeks after being awarded (with the exception of the ATP Finals, from which points are dropped on the Monday following the last ATP World Tour event of the following year.\n\nThe ATP began as the men's trade union in 1972, through the combined efforts of Jack Kramer, Cliff Drysdale, and Donald Dell, and rose to prominence when 81 of its members boycotted the 1973 Wimbledon Championships. Just two months later, in August, the ATP introduced its ranking system intended to objectify tournament entry criteria, which up to that point was controlled by national federations and tournament directors.\n\nThe ATP's new ranking system was quickly adopted by men's tennis. While virtually all ATP members were in favor of objectifying event participation, the system's first No. 1, Ilie Năstase, lamented that \"everyone had a number hanging over them,\" fostering a more competitive and less collegial atmosphere among the players.\n\nThe original ATP ranking criteria, which persisted through the 1980s, was based on averaging each player's results, though the details were revised a number of times. Starting in 1990, in conjunction with the expansion of ATP purview as the new men's tour operator, the ranking criteria was replaced with a 'best of' system modeled after competitive downhill skiing. This 'best of' system originally used 14 events but expanded to 18 in 2000.\n\nA player's ATP Ranking is based on the total points he accrued in the following 19 tournaments (18 if he did not qualify for the ATP Finals):\nThe requirement to play in four ATP World Tour 500 events does not apply to a player who was outside the top 30 in the previous year-end ranking; however, no more than four of his results from 500 level events may be counted. For a better result within the same tour type to be transposed one has to wait for the expiry of the first worse result from previous year. It only expires at the drop date of that tournament and only if the player reached a worse result or has not entered the current year.\n\nRanking points gained in a tournament are dropped 52 weeks later, with the exception of the ATP Finals, from which points are dropped on the Monday following the last ATP World Tour event of the following year.\n\nThe Monte-Carlo Masters 1000 became optional in 2009, but if a player chooses to participate in it, its result is counted and his fourth-best result in an ATP 500 event is ignored (his three best ATP 500 results remain). From 2009 until 2015, if a player did not play enough ATP 500 events and did not have an ATP 250 or Challenger appearance with a better result, the Davis Cup was counted in the 500's table. The World Team Cup was also included before its cancellation in 2012.\n\nFor the Davis Cup, from 2009 until 2015, points were distributed for the World Group countries. Instead of having an exact drop date they were gradually updated at each phase of the competition, comparing the player's results with his results from the previous year. E.g. if a player played two matches in a semifinal but plays one the next year only that one missing match will be extracted from his points).\n\nA player who is out of competition for 30 or more days, due to a verified injury, will not receive any penalty. The ATP Finals will count as an additional 19th tournament in the ranking of its eight qualifiers at season's end.\n\nFor every Grand Slam tournament or mandatory ATP World Tour Masters 1000 tournament for which a player is not in the main draw, and was not (and, in the case of a Grand Slam tournament, would not have been, had he and all other players entered) a main draw direct acceptance on the original acceptance list, and never became a main draw direct acceptance, the number of his results from all other eligible tournaments in the ranking period that count for his ranking is increased by one.\n\nOnce a player is accepted in the main draw of a Grand Slam tournament or ATP World Tour Masters 1000 tournament, his result in this tournament counts for his ranking, regardless of whether he participates. A player's withdrawal from an ATP World Tour 500 event, regardless of whether the withdrawal was on time, results in a zero point included as one of his best of four results. Further non-consecutive withdrawals results in a zero point allocation replacing the next best positive result for each additional withdrawal.\n\nPlayers with multiple consecutive withdrawals who are out of competition for 30 days or longer because of injury are not subject to a ranking penalty as long as verified and approved medical forms are provided; or, a player will not have the ranking penalty imposed if he completes the Promotional Activities requirement as specified under \"Repeal of Withdrawal Fines and/or Penalties\" or if the on-site withdrawal procedures apply. Players may also appeal withdrawal penalties to a Tribunal who will determine whether the penalties are affirmed or set aside.\n\nBetween 2000 and 2012, ranking points were awarded based on results in the Summer Olympics. This was changed before the 2016 Olympics where no ranking points were awarded.\n\nWith these rules, a player playing and winning the mandatory 4 Grand Slams and 8 ATP Masters 1000 events, a further 5 ATP 500 events and the Monte-Carlo Masters 1000 can amass a total of 19,500 points before the ATP Finals and end the calendar year with a maximum of 21,000 points. Novak Djokovic's haul of 16,585 points in the 2015 season is the best in history.\n\nSince the introduction of the ATP rankings the method used to calculate a player's ranking points has changed several times.\n\n\nIn addition qualifiers and main draw entry players will then also receive the points in brackets for the rounds they reached.\n\nStarting in 2016, points were no longer awarded for Davis Cup ties, nor for the tennis tournament at the Summer Olympics.\n\nThe following is a list of players who have achieved the number one position in singles since the inception of the rankings in 1973:\n\"Last update: 3 December 2018\"\n\nNotes<br>\nIn 2009 a new point system was introduced where points were roughly doubled.\n\nThe following is a list of players who were ranked world No.5 or higher but not No.1 in the period since the 1973 introduction of the ATP computer rankings:\n\n\n"}
{"id": "32622165", "url": "https://en.wikipedia.org/wiki?curid=32622165", "title": "Ambiguity resolution", "text": "Ambiguity resolution\n\nAmbiguity resolution is used to find the value of a measurement that requires modulo sampling.\n\nThis is required for pulse-Doppler radar signal processing.\n\nSome types of measurements introduce an unavoidable modulo operation in the measurement process. This happens with all radar systems.\n\nRadar aliasing happens when:\n\nPulse Doppler sonar uses similar principles to measure position and velocity involving liquids.\n\nRadar systems operating at a PRF below about 3 kHz pulse rate produce true range, but produce ambiguous target speed. Radar systems operating at a PRF above 30 kHz produce true target speed, but produce ambiguous target range.\n\nMedium PRF systems produce both ambiguous range measurement and ambiguous radial speed measurement using PRF from 3 kHz to 30 kHz.\n\nAmbiguity resolution finds true range and true speed by using ambiguous range and ambiguous speed measurements with multiple PRF.\n\nDoppler systems involve velocity measurements similar to the kind of measurements made using a strobe light.\n\nFor example, a strobe light can be used as a tachometer to measure rotational velocity for rotating machinery. Strobe light measurements can be inaccurate because the light may be flashing 2 or 3 times faster than shaft rotation speed. The user can only produce an accurate measurement by increasing the pulse rate starting near zero until pulses are fast enough to make the rotating object appear stationary.\n\nRadar and sonar systems use the same phenomenon to detect target speed.\n\nThe ambiguity region is shown graphically in this image. The x axis is range (left-right). The y axis is radial speed. The z axis is amplitude (up-down). The shape of the rectangles changes when the PRF changes.\nThe unambiguous zone is in the lower left corner. All of the other blocks have ambiguous range or ambiguous radial velocity.\n\nPulse Doppler radar relies on medium pulse repetition frequency (PRF) from about 3 kHz to 30 kHz. Each transmit pulse is separated by between 5 km and 50 km of distance.\n\nThe received signals from multiple PRF are compared using the range ambiguity resolution process.\n\nEach range sample is converted from time domain I/Q samples into frequency domain. Older systems use individual filters for frequency filtering. Newer systems use digital sampling and a Fast Fourier transform or Discrete Fourier transform instead of physical filters. Each filter converts time samples into a frequency spectrum. Each spectrum frequency corresponds with a different speed. These samples are thresholded to obtain ambiguous range for several different PRF.\n\nThe received signals are also compared using the frequency ambiguity resolution process.\n\nA blind velocity occurs when Doppler frequency falls close to the PRF. This folds the return signal into the same filter as stationary clutter reflections. Rapidly alternating different PRF while scanning eliminates blind frequencies.\n"}
{"id": "5481051", "url": "https://en.wikipedia.org/wiki?curid=5481051", "title": "Association for Women Geoscientists", "text": "Association for Women Geoscientists\n\nThe Association for Women Geoscientists is a professional organization which promotes the professional development of its members, provides geoscience outreach to girls, and encourages women to become geoscientists. Membership is open to all who support AWG's goals. Members include professional women and men from industry, government, museums and academia, students from a cross-section of colleges and universities, retirees, and others interested in supporting the society's goals.\n\nAWG was founded in San Francisco in 1977. The original purpose of the society was to provide encouragement to women in the geosciences, a career choice where they were largely underrepresented at the time. Today, the purpose remains the same, though some advances have been made, as AWG membership approaches 1200 students and scientists, reflecting the increasing participation of women in the geosciences. AWG is a 501(c)(6) mutual benefit corporation with local chapters in many cities and at-Large members throughout the U.S. and around the world.\n\n\nThe society provides and sponsors several programs that strive to achieve the goals of the society:\n\n"}
{"id": "27579073", "url": "https://en.wikipedia.org/wiki?curid=27579073", "title": "Association for the Conservation of Energy", "text": "Association for the Conservation of Energy\n\nThe Association for the Conservation of Energy is a British organisation that promotes energy conservation. It represents the energy conservation industry and does collective research for the industry.\nThe Association for the Conservation of Energy was formed in 1981 and Andrew Warren has been the Director since its formation. It is based in the east of the London Borough of Islington.\n\nThe Association for the Conservation of Energy has two divisions:\n\nMembers include:\n\n\n"}
{"id": "1347243", "url": "https://en.wikipedia.org/wiki?curid=1347243", "title": "At-Tur", "text": "At-Tur\n\nSūrat aṭ-Ṭūr (, \"The Mount\") is the 52nd sura of the Qur'an with 49 ayat. The surah that opens with the oath of the Divine One swearing by the Mount of Sinai, where the Torah was revealed to Moses. It takes its name from \"the mount\" (\"ṭūr\") mentioned in Ayah#1. The surah which addresses many of the arguments put to the Prophet by the disbelievers of Mecca (ayah#29 ff.). The bliss that will be enjoyed by the believers is contrasted to the torments of Hell, and the Prophet is urged to bide his time, to continue to deliver his message, and to wait with confidence for God’s judgement. God swears by, among other things, Mount Sinai, that the Day of Judgement is inevitable.\n"}
{"id": "8355389", "url": "https://en.wikipedia.org/wiki?curid=8355389", "title": "Baku Initiative", "text": "Baku Initiative\n\nThe Baku Initiative is an international initiative of the European Union. It is a policy dialogue on energy and transport cooperation between the European Union, Turkey, and the former Soviet republics, undertaken as part of the INOGATE energy and TRACECA transport programmes.\n\nThe Baku Initiative is originating from the European Neighbourhood Policy launched in 2004. On 13 November 2004, the First Ministerial Conference on Energy Cooperation between the EU and the littoral states of the Black Sea, Caspian Sea and their neighbours was held in Baku. Conclusions of this conference became known as the Baku Initiative. At the same time, a Transport Ministerial conference was held, resulting in a formal announcement on 14 November, supporting the framework of the EU TRACECA programme. A second Ministerial Conference following up the Energy Initiative was held in Astana, Kazakhstan on 30 November 2006. A second Transport Ministerial Conference was held in Sofia, Bulgaria on 2–3 May 2006.\n\nThe Initiative aims to enhance integration of the energy markets of participating countries with the EU energy market so as to create transparent energy markets, capable of attracting investment as well as enhancing security of energy supply. Some authors describe this aim as European funding and investment for infrastructure development in return for a guarantee of supplies to European markets.\n\nThe objectives of the initiative are harmonisation of legal and technical standards so as to create a functioning integrated energy market in accordance with EU and international legal and regulatory frameworks; increasing the safety and security of energy supplies by extending and modernising existing infrastructure; substituting old and inefficient power generation infrastructures with environmentally friendly power generation infrastructures; developing new infrastructures and implementing a modern monitoring system of their operation; improvement of energy supply and demand management through the integration of efficient and sustainable energy systems; and promoting the financing of commercially and environmentally viable energy projects of common interest. A road map to achieve these objectives was adopted at the Astana Ministerial Conference. The road map lists following priorities:\n\nThese activities were financed through the European Bank for Reconstruction and Development and the European Investment Bank.\n\nAccording to the EU Transport Directorate, 'The Baku Initiative aims to give an impulse to Trans-European transport cooperation on the basis of the mutual interest for the progressive integration of their respective transport networks and markets in accordance with EU and international legal and regulatory frameworks. It provides a supportive framework for TRACECA to foster the reflection on the cooperation between the EU-Black Sea/Caspian littoral States and their Neighbours, and to ensure the consistency with the EU priorities in the context of its Neighbourhood Policy.\n\nFollowing the conclusions reached at the EU-Caspian region Transport Ministerial Conference on 14 November 2004 in Baku, 4 expert working groups have been created (aviation, security in all modes of transport, road and rail transport, transport infrastructure).'\n\nFollowing the Sofia meeting in 2006, a fifth working group was added, dealing with maritime transport.\n\nThe partner countries of the transport and energy aspects and issues of the Baku Initiative are listed below. Aside from Turkey, the majority of the members are the former republics of the Soviet Union:\n\nThe European Union follows the progress of the Baku Initiative through the European Commission (Directorate General for Transport & Energy; Directorate General for External Relations, and EuropeAid Cooperation Office). The INOGATE Technical Secretariat (which is located in Kiev, with a regional office in Tbilisi covering the Caucasus) co-ordinates the energy aspects on behalf of the Commission and the TRACECA Secretariat, (which is located in Baku with a regional office in Odessa) performs the same function for the transport aspects.\n\nSome experts, e.g. Frank Umbach of Centre for European Security Strategies, have criticised the Baku Initiative and other policies towards the Caspian region for concentrating too much on the technical cooperation instead of seeking a more strategic long-term cooperation.\n\n\n"}
{"id": "2833233", "url": "https://en.wikipedia.org/wiki?curid=2833233", "title": "Blue Knob State Park", "text": "Blue Knob State Park\n\nBlue Knob State Park is a Pennsylvania state park in Kimmel, Lincoln, and Pavia townships in Bedford County, Pennsylvania, in the United States. The average annual snowfall at the park is about . The park is named for Blue Knob, the second highest mountain in Pennsylvania at . It is the location of Blue Knob All Seasons Resort, the ski slope in Pennsylvania with the highest elevation. Blue Knob State Park is just off Interstate 99 on Pennsylvania Route 869 west of Pavia.\n\nThe earliest settlers to the Blue Knob area were of German descent. They cleared and farmed the land soon after the American Revolution. They also built several distilleries, a lumber mill and gristmill.\n\nThe logging boom that swept over most of the mountains and forests of Pennsylvania drastically altered the landscape surrounding Blue Knob State Park. The old-growth forests of hemlock were clear cut. The timber was hauled away on trains that climbed the steep hillsides. A railroad that followed Bobs Creek used six switchbacks to ascend the mountain. Another railroad used five switchbacks to climb the hills near Wallacks Branch. These railroad grades are still used today to gain access to State Gamelands. The train tracks have since been removed and replaced with hiking trails.\n\nThe lumber industry abandoned the lands once all the salable timber had been harvested. They left behind a wasteland of dried out tree tops that were ignited by passing steam locomotives. The land was scarred by immense wild fires. The wildlife that had once thrived in the area was also gone due to over-hunting and deforestation.\n\nThe efforts of the National Park Service are largely responsible for the reforestation of Blue Knob State Park. Blue Knob National Recreation Demonstration Area was opened by the park service in 1935. The park was built by the men of the Works Projects Administration and the young men of the Civilian Conservation Corps with the cooperation of Pennsylvania Governor Gifford Pinchot. The WPA and CCC were established by President Franklin D. Roosevelt during the Great Depression to provide work for the unemployed. Ownership of the park was transferred to the Commonwealth of Pennsylvania on September 26, 1945 and Blue Knob State Park was officially opened. \n\nThe bedrock in the valleys of the park consists of the Upper Devonian Catskill Formation, consisting of sequences of sandstone, siltstone, and shale. The mountains in the park are capped by the Mississippian Burgoon Sandstone, which is underlain by the transitional Devonian-Mississippian Rockwell Formation, consisting of crossbedded argillacious sandstone with some shale beds.\n\nBlue Knob All Seasons Resort is on Blue Knob the second highest mountain in Pennsylvania. The resort was opened on the site of a former military base. The resort includes 36 trails on slopes for skiing, snow boarding and tubing, a golf course, trails for mountain biking and cross-country skiing. It is open year-round. The lodge provides year-round accommodations with tennis courts and a swimming pool.\n\nThere is a swimming pool at the park that is separate from the pool at the resort. It opens Memorial Day weekend and closes Labor Day weekend. The hours of operation are 11:00 am until 7:00 pm. Lifeguards are provided.\n\nThere are three picnic areas at Blue Knob State Park with over 200 picnic tables. Mowery Hollow and Burnt House picnic areas are open year-round. Willow Springs picnic area opens the weekend before Memorial Day and closes the day after Thanksgiving.\n\nBlue Knob State Park has a campground with 45 sites, 25 of which have connections to an electrical supply. 43 sites will accommodate tents or campers. Two of the sites are walk-in only. The campground has running water, a sanitary dump station, modern restrooms and a playground.\n\nA group of cabins, built and used by the CCC, is available for rent by large groups. The cabin area has a large dining hall and kitchen area and a showerhouse.\n\nHunting is permitted on about of Blue Knob State Park. The most common game species are turkey, squirrels and white-tailed deer. The hunting of groundhogs is prohibited. Hunters are expected to follow the rules and regulations of the Pennsylvania Game Commission. The park is next to Pennsylvania State Game Land 26. There are parking lots and trails at Blue Knob State Park for those interested parking at the state park and hiking into the gamelands.\n\nBlue Knob contains a vast network of hiking trails that range from easy walks to difficult and challenging day hikes. The total network of trails is approximately 18 miles in length. Most of these trails are multiple use for hiking, cross country skiing, mountain biking, horseback riding and snowmobiling. Below is a brief description of each trail that can be found on the mountain.\n\nMountain View Trail\n\nThis trail is 5 miles in length and one of the more difficult on the mountain. It is marked with a double red blaze and the trailhead can be found on the Tower Road just below the summit. The Mountain View Trail begins at about the 3,000 ft. contour and begins by looping around a gentle grade on the upper portion of the mountain's east shoulder. This part of the mountain is marked by stunted and wind deformed trees, mainly scrub oak and striped maple. Also large slabs of the conglomerate rocks that form this mountain may be seen strewn about on these upper slopes. This trail passes two lookouts, the Pavia Overlook and the Queen Overlook before descending into the Beaverdam Creek drainage and the lowest portion of this trail at the 2,000 ft. contour. The trail then traverses the east face of the mountain to the Willow Springs picnic area before it begins its steep ascent on the west face of the mountain and back to the trailhead.\n\nThree Springs Trail\n\nThis trail is 2 miles in length and follows an old roadbed. The trail is wide and good for snowmobiles and horseback riding. This trail can be accessed from the Mountain View Trail at about the 3,050 ft. contour and generally runs downslope before it bisects the east face, and ends at the 2,500 ft. contour where it junctions once again with the Mountain View Trail. Along its length you can see how the trail got its name by the number of springs that are used for supplying water to the villages below the mountain.\n\nRock N' Ridge Trail\n\nThis trail begins at the 1,550 ft. contour just above the gated entrance to the park headquarters. It is 2.8 miles in length and marked by an inverted blue \"T\". The trail is located on the west side of the mountain and begins by following a ridge that abuts the main dome of the mountain. On this trail you may see mountain laurel which is the Pennsylvania State Flower. When the mountain laurel blooms in June it makes for a very scenic hike. The trail eventually junctions into the Sawmill trail at the 2,400 ft. contour, before this however, the trail has a turnoff which will descend down the Pavia Run drainage and end at the Mowry Hollow Picnic Area.\n\nSawmill Trail\n\nThe Sawmill Trail crosses the west face of the mountain and is 3 miles in length marked by yellow blazes. This is another wide trail that follows an old roadbed and is conducive to snowmobiles and mountain biking. The trailheads are located at either end of the trail off the Knob Road or on State Route 403 on Ickes Hill. If you begin on Ickes Hill, you will begin ascending the southwest buttress of the mountain to the Willow Springs Picnic Area at the 2,250 ft. contour. From there you will navigate shortly on the Mountain View Trail before you again pick up the Sawmill Trail. The trail moves across the hollows of the mountain at approximately the 2,400 ft. contour before it ends at that north end of Chappell Field and the trail head on the Knob Road. This hike takes you through rich hardwoods and passes over mountain seeps which drain from the upper slopes of the mountain, it is one of the easier hikes in the park.\n\nHomestead Trail\n\nThis trail is a small loop at 1.8 miles in length and marked by orange blazes. The Homestead Trail may be gained by access off the Whysong Road or by a connector trail off the Sawmill Trail. The hike is on the lower portions of the mountain and only gains to the 2,100 ft. contour. The trail is easy and wide open and as its name suggests, marks the site of an old settlers house site. Hiking along this pathway affords good opportunities for viewing wildlife.\n\nChappell's Field Trail\n\nThe Chappell's Field Trail is accessible at points on the Knob Road and campground areas. The trail is located on one of the main ridges that are found on the west side of the mountain. On the top of this ridge, which is over 2,400 ft., Chapell's Field holds one of the best views in the park as it looks up at the main summit of Blue Knob and down on the valley below. The trail encircles the top of this ridge and is 2.5 miles in length, a loop marked by inverted orange \"V\" blazes.\n\nCrist Ridge Trail\n\nThe 1.9 mile orange blazed trail connects to the Chappell's Field Trail at the 2,250 ft. contour and winds its way down the ridge ending on the Knob Road. This trail had large areas of blowdowns on it following the wind events in September 2004. Since then the trail has been cleared and is a good trail for mountain biking and cross country skiing. In the winter with the foliage down, views of Blue Knob Mountain can be seen through the trees.\n\nLost Turkey Trail\n\nThis is the longest and most difficult trail at 26 miles long. The trail begins on 3,034 foot Herman Point and is marked by red blazes. The trail crosses over both public and private lands as it eventually ends in neighboring Somerset County. To begin this hike you must proceed up the Tower Road and pass by the gated road which leads to Herman Point and the transmitter towers on its summit. Just behind the fenced in towers, you can see the trail which proceeds down the steep face of the mountain into the Rhodes Run drainage. From here the trail follows Ciana Run before crossing Hogback ridge, then beginning its steep ascent up Forks Ridge and the Allegheny Front beyond. Once on top of the Allegheny Plateau it winds its way through high elevation forests and mountain bogs. Proper footwear is recommended for this hike as it is steep in some areas and stream crossings are required along its length.\n\nConnector Trails\n\nThere are several connector trails that make up the remaining mileage on Blue Knob's trails system. They are double blue blazed markings and vary in length and difficulty.\n\nBobs Creek is stocked with trout by the Pennsylvania Fish and Boat Commission in co-operation with the Pavia Sportsmen Club Inc. There is also a population of native brook trout in Bobs Creek and its tributaries.\n\nThe following state parks are within of Blue Knob State Park:\n\n"}
{"id": "1809553", "url": "https://en.wikipedia.org/wiki?curid=1809553", "title": "Blue Spring State Park", "text": "Blue Spring State Park\n\nBlue Spring State Park is a state park located west of Orange City, Florida in the United States. The park is a popular tourist destination; available activities include canoeing, SCUBA diving, kayaking, fishing, camping, hiking, wildlife watching, and swimming. The spring is the largest on the St. Johns River and with a relatively warm temperature of , the spring attracts many Florida manatees during the winter months. of water flow out of Blue Spring into the St. Johns River every day.\n\nThe spring was visited by botanist John Bartram in 1766.\n\nThe spring and surrounding land was acquired by the Weismore family in the mid-19th century and a large plantation-style home built upon a shell mound on the property. The area seemed to be excellent for cultivation of citrus fruit, and a small railway was built linking Orange City to the dock at Blue Spring. Ultimately, the Florida East Coast Railway was constructed not far from the present-day park. A killing freeze occurred in the 1890s, wiping out area citrus groves and driving the industry south. The Thursbys switched to the tourist trade, taking advantage of the beautiful spring and excellent fishing and hunting opportunities along the St. Johns River.\n\nThe park was acquired by the Florida Department of Environmental Protection in 1972 to kick-start its manatee protection program.\n\nBlue Spring State Park has a lot to offer its visitors including, but not limited to, fifty-one campsites with water and electricity hookups, and six cabins which are available for those who wish to stay at the park. The crystal clear spring runs a few miles long where swimming and tubing are very popular on hot summer days but are not allowed during manatee season. Qualified Scuba divers can descend into the spring cave in season as well. Picnicking is a popular pastime, with multiple pavilions available for groups and scattered picnic tables around the entire park. The park also features volleyball courts and a playground, as well as, canoeing, kayaking, and fishing. The old Thursby plantation house is being maintained and has historical displays that visitors can explore. Various wildlife besides manatees can be seen as well including alligators, bears, racoons, and various species of birds. Hontoon Island State Park is a short paddle down the St. Johns River. Hours of operation, fees, and rental information can be found here: https://www.floridastateparks.org/park/Blue-Spring\n\n\n"}
{"id": "37818808", "url": "https://en.wikipedia.org/wiki?curid=37818808", "title": "Centrist Marxism", "text": "Centrist Marxism\n\nCentrism has a specific meaning within the Marxist movement, referring to a position between revolution and reformism. For instance, the Independent Social Democratic Party of Germany (USPD) and Independent Labour Party (ILP) were both seen as centrist because they oscillated between advocating reaching a socialist economy through reforms and advocating revolution. The parties that belonged to the \"so-called\" Two-and-a-half and Three-and-a-half Internationals, who could not choose between the reformism of the social democrat Second International and the revolutionary politics of the Communist Third International, were also exemplary of centrism in this sense. They included the Spanish Workers' Party of Marxist Unification (POUM), the ILP and Poale Zion. \n\nFor Trotskyists and other revolutionary Marxists, the term \"centrist\" in this sense has a pejorative association. They often describe centrism in this sense as opportunistic since it argues for a revolution at some point in the future, but urges reformist practices in the meantime. Libertarian socialists and anarchists also tend to view any reformism as political opportunism because they view reformism as being incapable of effecting structural changes to social organization.\nThe term \"centrism\" also denotes positions held by some of the Bolsheviks during the 1920s. In this context, \"centrism\" refers to a position between the Right Opposition, which supported the New Economic Policy and friendly relations with capitalist countries; and the Left Opposition, which supported an immediate transition to a socialist economy and world revolution. By the end of the 1920s, the two opposing factions had been defeated by Joseph Stalin, who eventually gained enough support from members of both factions through the application of various ideas formulated by the factions' various leaders, notably Leon Trotsky and Nikolai Bukharin.\n\n\"Two Articles on Centrism\" by Leon Trotsky\n\n"}
{"id": "1127361", "url": "https://en.wikipedia.org/wiki?curid=1127361", "title": "Chamaecyparis pisifera", "text": "Chamaecyparis pisifera\n\nChamaecyparis pisifera (Sawara cypress or Sawara ) is a species of false cypress, native to central and southern Japan, on the islands of Honshū and Kyūshū.\n\nIt is a slow-growing coniferous tree growing to 35–50 m tall with a trunk up to 2 m in diameter. The bark is red-brown, vertically fissured and with a stringy texture. The foliage is arranged in flat sprays; adult leaves are scale-like, 1.5–2 mm long, with pointed tips (unlike the blunt tips of the leaves of the related \"Chamaecyparis obtusa\" (hinoki cypress), green above, green below with a white stomatal band at the base of each scale-leaf; they are arranged in opposite decussate pairs on the shoots. The juvenile leaves, found on young seedlings, are needle-like, 4–8 mm long, soft and glaucous bluish-green. The cones are globose, 4–8 mm diameter, with 6–10 scales arranged in opposite pairs, maturing in autumn about 7–8 months after pollination.\n\nThe Latin specific epithet \"pisifera\", “pea-bearing”, refers to the small round green cones.\n\nA related cypress found on Taiwan, \"Chamaecyparis formosensis\" (Formosan cypress), differs in longer ovoid cones 6–10 mm long with 10–16 scales. The extinct Eocene species \"Chamaecyparis eureka\", known from fossils found on Axel Heiberg Island in Canada, is noted to be very similar to \"C. pisifera\".\n\nIt is grown for its timber in Japan, where it is used as a material for building palaces, temples, shrines and baths, and making coffins, though less valued than the timber of \"C. obtusa\". The wood is lemon-scented and light-colored with a rich, straight grain, and is rot resistant.\n\nIt is also a popular ornamental tree in parks and gardens, both in Japan and elsewhere in temperate climates including western Europe and parts of North America. A large number of cultivars have been selected for garden planting, including dwarf forms, forms with yellow or blue-green leaves, and forms retaining the juvenile needle-like foliage; particularly popular juvenile foliage cultivars include 'Plumosa', 'Squarrosa' and 'Boulevard'.\n\nIn cultivation in the UK the following have gained the Royal Horticultural Society’s Award of Garden Merit (confirmed 2017): \n\n"}
{"id": "1639843", "url": "https://en.wikipedia.org/wiki?curid=1639843", "title": "Charles K. Johnson", "text": "Charles K. Johnson\n\nCharles Kenneth Johnson (July 24, 1924 – March 19, 2001) was, from 1972 until his death, the president of the International Flat Earth Research Society, which he and his wife ran from their home in California. He claimed that the Apollo moon landings, and space exploration in general, were faked to lead people away from the biblical truth that the world was flat.\n\nOriginally an airplane mechanic in San Francisco, Johnson took over the Society from Samuel Shenton on the latter's death in 1972, from his ranch, near Edwards Air Force Base.\n\nIn his obituary, Tim Bullamore wrote, \"Although the world at large was slow to accept his work, Johnson remained cheerful and unruffled. He enjoyed smoking a cigar while watching the sun set over the flat desert. He was regularly interviewed by curious journalists and was often invited to speak about his subject. He received large quantities of mail, not all of it ridiculing his work, and on one occasion he starred in an ice-cream advertisement.\" \n\n"}
{"id": "1664148", "url": "https://en.wikipedia.org/wiki?curid=1664148", "title": "Chhath", "text": "Chhath\n\nChhath is an ancient Hindu Vedic festival historically native to the Indian subcontinent, more specifically, the Indian states of Bihar, Jharkhand, and Uttar Pradesh as well as the Madhesh region of Nepal. The Chhath Puja is dedicated to the Sun and his sister in order to thank them for bestowing the bounties of life on earth and to request the granting of certain wishes. Chhath does not involve any idol worship. This festival is observed by Nepalese and Indian people, along with their diaspora.\n\nThe rituals of the festival are rigorous and are observed over a period of four days. They include holy bathing, fasting and abstaining from drinking water (Vratta), standing in water for long periods of time, and offering prasad (prayer offerings) and arghya to the setting and rising sun. The main worshipers, called \"Parvaitin\" (from Sanskrit \"parv\", meaning 'occasion' or 'festival'), are usually women. However, a large number of men also observe this festival as Chhath is not a gender-specific festival. Some devotees also perform a prostration march as they head for the river banks.\nEnvironmentalists claim that Chhath is the most eco-friendly Hindu festival. Although the festival is observed most elaborately in Madhesh (southern) region of Nepal and Indian states of Bihar, Jharkhand and UP, it is also more prevalent in areas where migrants from those areas have a presence. It is celebrated in all Northern regions and major Northern urban centers in India. The festival is celebrated in the regions including but not exclusive to the northeast region of India, Madhya Pradesh, Bihar, Uttarkhand, Uttar Pradesh, Odisha, Chhattisgarh, Jharkhand, Rajasthan, Mauritius, Fiji, South Africa, Trinidad and Tobago, Guyana, Suriname, Jamaica, other parts of the Caribbean, United States, United Kingdom, Republic of Ireland, Australia, New Zealand, Malaysia, Macau, Japan, and Indonesia.\n\nChhath puja is performed on \"Kartika Shukla Shashthi\", which is the sixth day of the month of Kartika in the Vikram Samvat. This falls typically in the month of October or November in the Gregorian English Calendar. It is also celebrated in the month of Chaitra.\n\nChhath puja is on the 13th(evening ) & 14th(sunrise) of November 2018. The four-day festival will start from 11 November and will end on 14 November.\n\nIt is also celebrated in the summer (March–April), on Chaitra Shashthi, some days after Holi; this event is called \"Chaiti Chhath\". Chhath is an arduous observance, requiring the worshipers to fast without a sip of water for around 36 hours continuously.\n\nThe word \"chhath\" means \"sixth\" in Nepali, Maithili and Bhojpuri languages and the festival is celebrated on the sixth day of the month Kārtika of the Hindu luni-solar Bikram Sambat calendar. The word is a Prakrit derivation from the Sanskrit \"ṣaṣṭhi\", meaning \"sixth\".It is the longest and most important festival after navratri.\n\nIt is believed that the ritual of Chhath puja may date back to the ancient Vedic texts, as the Rigveda contains hymns worshiping the Sun god and describes similar rituals. The rituals also find reference in the Sanskrit epic poem \"Mahābhārata\" in which Draupadi is depicted as observing similar rites.\n\nIn the poem, Draupadi and the Pandavas, rulers of Indraprastha (modern Delhi), performed the Chhath ritual on the advice of noble sage Dhaumya. Through her worship of the Sun God, Draupadi was not only able to solve her immediate problems, but also helped the Pandavas later regain their lost kingdom.\n\nIts yogic history dates back to the Vedic times. The rishis of yore used this method to remain without any external intake of food as they were able to obtain energy directly from the sun's rays. This was done through the Chhath method. Another history behind celebrating the Chhath puja is the story of Lord Rama. It is considered that Lord Rama of Ayodhya and Sita of Mithila had kept fast and offer puja to the Lord Sun in the month of Kartika in Shukla Paksh during their coronation after returning to the Ayodhya after 14 years of exile.\n\nThe Goddess who is worshipped during the famous Chhath Puja is known as Chhathi Maiya. Chhathi Maiya is the manas daughter of brahma and also known as devsena and Shasthi devi in vedas.She is the form of Parvati,Sister of lord Sun and wife of Mahadev.During Chhath she come from kailash in form of Chhathi maiya and Dinanath receives her.In mithilanchal region she is also worshipped as name of \"RANABE MAI \".\n\nThis is the only festival which signifies both the rising and setting sun.\n\nThe most unique feature about the Chhath Puja is the main idea behind it which is different from the traditional concept of \"Murti Pujan \"(Idol Worshipping) unlike most of the festivals of the Hindu religion { But Murti Pujan is to worshipping the Cool Air mean not to get deceased from air and water, from may years it was linked with fortune and ethical stories }. Some people simply believe that, The sun is necessary for the life of possibly every creature on the earth and this festival is a way to pay tribute to it irrespective of caste, creed, gender and social stigmas.\n\nThe rituals of the festival are rigorous and are observed over a period of four days. They include holy bathing, fasting and abstaining from drinking water (Vratta), standing in water for long periods of time, and offering prasad (prayer offerings) and arghya to the setting and rising sun,they did not wear stitched cloth,man wear dhoti and women wear cotton saree without any stitches. Some devotees also perform a prostration march as they head for the river banks.\nThe very first day of chhath starts exactly 4 days from Diwali and last for 4 more days. This day the people who observe fast take bath at a river or pond and prepare lunch (consisting of rice, dal mixed with pumpkin, made in pure ghee).\n\nThe second day (5th day from Diwali) is known as kharna or kheer-roti or kheer-puri. In which the kheer( A Indian recipe where rice is prepared with sweetened milk instead of water) and chapati ( called roti in many Indian provinces). The people observe fast for the full day without taking even water and eat this kheer-roti as dinner after offering it to the rising moon and Goddess Ganga. This is the only time when they eat or drink anything from the starting of the day until the last day of chhath.\n\nThe third day is the main festival day (exactly 6th day from Diwali) of chhath. The devotees maintain 'nirjal vrat(vrata)' ( Fast without even taking a drop of water ) on the third day. It mainly consist of going on river bank and offering 'argha' ( offering of fruits and sweets in winnow ) and surya namaskar to the setting sun followed by the next day (exactly 7th day from Diwali) event of offering argha and surya namaskar to the rising sun on the fourth or last day of chhath. The fast then comes to an end after offering argha to rising sun. In this way, nearly 42 hours of strict penance comes to an end.\n\nThe main worshipers, called \"Parvaitin\" pray for the well-being of their family, and for the prosperity of their offsprings. The starting of the chhath is known as \"chhath uthana\" and stopping is known as \"chhath baithana\". Once a family member starts performing Chhath Puja, it is their compulsory duty to perform it every year and to pass it on to the following generations. The festival is skipped only if there happens to be a death of a person or birth of a child in the family that year. If the person stops performing the ritual on any particular year, it stops permanently and one cannot resume it again. Hence, once started, it cannot be stopped and once stopped, it cannot be restarted.\n\nThe prasad offerings include sweets, Kheer, Thekua, rice laddu(made of rice grit) and fruits (mainly sugarcane, sweet lime and banana) offered in small bamboo soop winnows. The food is strictly vegetarian and is cooked without salt, onions or garlic. Emphasis is put on maintaining the purity of the food. It is said that the festival and the rules must be followed strictly as it is said that it brings more adverse effects than the gain that the puja provides if any of the smallest rule is broken. It is the festival in which providing the helping hand of the person doing the puja is also considered as a good omen. it is the only festival in which the Setting Sun is worshipped.\n"}
{"id": "36060804", "url": "https://en.wikipedia.org/wiki?curid=36060804", "title": "FIH World Rankings", "text": "FIH World Rankings\n\nThe FIH World Ranking is a ranking system for men's and women's national teams in field hockey. The teams of the member nations of International Hockey Federation (FIH), field hockey's world governing body, are ranked based on their game results. The rankings were introduced in October 2003.\n\nThe rankings were introduced to overcome the criticism of fixing when drawing the pools for each tournament. It also determines the quotas for tournaments such as the Olympic Games and also the World Cup.\n\nAll of the FIH-recognised, including qualifying and continental tournaments for last four years are included in ranking points calculation. However, the past results will be deducted by the percentage set by the FIH as shown by the tabulated below.\n\nFIH had set the total allocated points for continental tournament. However, a different percentage was set to differ the standard of regional field hockey. Currently, only Europe had full 100% points allocation for all classification while the others had only several finishers with full points allocation. Africa is the sole continent with neither men's or women's tournament had full points allocation.\n\n"}
{"id": "9464291", "url": "https://en.wikipedia.org/wiki?curid=9464291", "title": "Ferranti valve", "text": "Ferranti valve\n\nThe Ferranti valve is a type of vacuum tube developed by Messers. Ferranti Ltd., in measuring the charge-to-mass ratio of an electron. It consists of an anode and two co-axial guard rings. A cathode, as a thin wire of tungsten filament, runs through this arrangement. When heated to a particular temperature using an HT electricity supply, electrons are emitted.\n\n"}
{"id": "52920162", "url": "https://en.wikipedia.org/wiki?curid=52920162", "title": "Geyik Alanı Grove", "text": "Geyik Alanı Grove\n\nGeyik Alanı Grove () is a pine grove in Eskişehir Province, western Turkey. \"Geyik Alanı\" means \"Deer Field\". The area is a registered natural monument of the country.\n\nGeyik Alanı Grove features 200–400 years old trees of Scots pine, which are high. The trees are at straight and well-rounded stand. The grove covers an area of . The area was registered a natural monument on November 3, 2000.\n"}
{"id": "30933019", "url": "https://en.wikipedia.org/wiki?curid=30933019", "title": "Indianocéanisme", "text": "Indianocéanisme\n\nIndianocéanisme is a humanist ideology from the southwest Indian Ocean region. The term was coined by the Mauritian Camille de Rauville during the founding conference of the International Historical Association of the Indian Ocean in 1960 in Tananarive. The ideology grows out of the observation that literature throughout the Indian Ocean is characterized by the preferential use of French along with some specific features such as the use of the myth of Lemuria and the region's Hindu heritage. Indianocéanisme was long inspired by Algerianism.\n\n"}
{"id": "50311265", "url": "https://en.wikipedia.org/wiki?curid=50311265", "title": "Ionic liquids in carbon capture", "text": "Ionic liquids in carbon capture\n\nThe use of ionic liquids in carbon capture is a potential application of ionic liquids as absorbents for use in carbon capture and sequestration. Ionic liquids, which are salts that exist as liquids near room temperature, are polar, nonvolatile materials that have been considered for many applications. The urgency of climate change has spurred research into their use in energy-related applications such as carbon capture and storage.\n\nAmines are the most prevalent absorbent in postcombustion carbon capture technology today. In particular, monoethanolamine (MEA) has been used in industrial scales in postcombustion carbon capture, as well as in other CO separations, such as \"sweetening\" of natural gas. However, amines are corrosive, degrade over time, and require large industrial facilities. Ionic liquids on the other hand, have low vapor pressures . This property results from their strong Coulombic attractive force. Vapor pressure remains low through the substance's thermal decomposition point (typically >300 °C). In principle, this low vapor pressure simplifies their use and makes them \"green\" alternatives. Additionally, it reduces risk of contamination of the CO gas stream and of leakage into the environment.\n\nThe solubility of CO in ionic liquids is governed primarily by the anion, less so by the cation. The hexafluorophosphate (PF) and tetrafluoroborate (BF) anions have been shown to be especially amenable to CO capture.\n\nIonic liquids have been considered as solvents in a variety of liquid-liquid extraction processes, but never commercialized. Beside that, ionic liquids have replaced the conventional volatile solvents in industry such as absorption of gases or extractive distillation. Additionally, ionic liquids are used as co-solutes for the generation of aqueous biphasic systems, or purification of biomolecules.\n\nA typical CO absorption process consists of a feed gas, an absorption column, a stripper column, and output streams of CO-rich gas to be sequestered, and CO-poor gas to be released to the atmosphere. Ionic liquids could follow a similar process to amine gas treating, where the CO is regenerated in the stripper using higher temperature. However, ionic liquids can also be stripped using pressure swings or inert gases, reducing the process energy requirement. A current issue with ionic liquids for carbon capture is that they have a lower working capacity than amines. Task-specific ionic liquids that employ chemisorption and physisorption are being developed in an attempt to increase the working capacity. 1-butyl-3-propylamineimidazolium tetrafluoroborate is one example of a TSIL.\n\nIn carbon capture an effective absorbent is one which demonstrates a high selectivity, meaning that CO will preferentially dissolve in the absorbent compared to other gaseous components. In post-combustion carbon capture the most salient separation is CO from N, whereas in pre-combustion separation CO is primarily separated from H. Other components and impurities may be present in the flue gas, such as hydrocarbons, SO, or HS. Before selecting the appropriate solvent to use for carbon capture it is critical to ensure that at the given process conditions and flue gas composition CO maintains a much higher solubility in the solvent than the other species in the flue gas and thus has a high selectivity.\n\nThe selectivity of CO in ionic liquids has been widely studied by researchers. Generally, polar molecules and molecules with an electric quadrupole moment are highly soluble in liquid ionic substances. It has been found that at high process temperatures the solubility of CO decreases, while the solubility of other species, such as CH and H, may increase with increasing temperature, thereby reducing the effectiveness of the solvent. However, the solubility of N in ionic liquids is relatively low and does not increase with increasing temperature so the use of ionic liquids in post-combustion carbon capture may be appropriate due to the consistently high CO/N selectivity. The presence of common flue gas impurities such as HS severely inhibits CO solubility in ionic liquids and should be carefully considered by engineers when choosing an appropriate solvent for a particular flue gas.\n\nA primary concern with the use of ionic liquids for carbon capture is their high viscosity compared with that of commercial solvents. Ionic liquids which employ chemisorption depend on a chemical reaction between solute and solvent for CO separation. The rate of this reaction is dependent on the diffusivity of CO in the solvent and is thus inversely proportional to viscosity. The self diffusivity of CO in ionic liquids are generally to the order of 10 m/s, approximately an order of magnitude less than similarly performing commercial solvents used on CO capture. The viscosity of an ionic liquid can vary significantly according to the type of anion and cation, the alkyl chain length, and the amount of water or other impurities in the solvent. Because these solvents can be “designed” and these properties chosen, developing ionic liquids with lowered viscosities is a current topic of research. Supported ionic liquid phases (SILPs) are one proposed solution to this problem.\n\nAs required for all separation techniques, ionic liquids exhibit selectivity towards one or more of the phases of a mixture. 1-Butyl-3-methylimidazolium hexafluorophosphate (BMIM-PF) is a room-temperature ionic liquid that was identified early on as a viable substitute for volatile organic solvents in liquid-liquid separations. Other [PF]- and [BF]- containing ionic liquids have been studied for their CO absorption properties, as well as 1-ethyl-3-methylimidazolium (EMIM) and unconventional cations like trihexyl(tetradecyl) phosphonium ([P]). Selection of different anion and cation combinations in ionic liquids affects their selectivity and physical properties. Additionally, the organic cations in ionic liquids can be \"tuned\" by changing chain lengths or by substituting radicals. Finally, ionic liquids can be mixed with other ionic liquids, water, or amines to achieve different properties in terms of absorption capacity and heat of absorption. This tunability has led some to call ionic liquids \"designer solvents.\" 1-butyl-3-propylamineimidazolium tetrafluoroborate was specifically developed for CO capture; it is designed to employ chemisorption to absorb CO and maintain efficiency under repeated absorption/regeneration cycles. Other ionic liquids have been simulated or experimentally tested for potential use as CO absorbents.\n\nCurrently, CO capture uses mostly amine-based absorption technologies, which are energy intensive and solvent intensive. Volatile organic compounds alone in chemical processes represent a multibillion-dollar industry. Therefore, ionic liquids offer an alternative that prove attractive should their other deficiencies be addressed.\n\nDuring the capture process, the anion and cation play a crucial role in the dissolution of CO. Spectroscopic results suggest a favorable interaction between the anion and CO, wherein CO molecules preferentially attach to the anion. Furthermore, intermolecular forces, such as hydrogen bonds, van der Waals bonds, and electrostatic attraction, contributes to the solubility of CO in ionic liquids. This makes ionic liquids promising candidates for CO capture because the solubility of CO can be modeled accurately by the regular solubility theory (RST), which reduces operational costs in developing more sophisticated model to monitor the capture process.\n\n"}
{"id": "30753733", "url": "https://en.wikipedia.org/wiki?curid=30753733", "title": "Kedr", "text": "Kedr\n\nKedr ( meaning \"Siberian pine\"; Yuri Gagarin's callsign during the Vostok 1 mission) also known as ARISSat 1 and RadioSkaf-2, was an amateur radio minisatellite operated by RKK Energia as part of the Amateur Radio on the International Space Station and RadioSkaf programmes. A follow-up to the SuitSat spacecraft, Kedr was launched to commemorate the fiftieth anniversary of the Vostok 1 mission.\n\nKedr transmitted 25 greetings in 15 different languages. It also transmitted photos of the Earth, telemetry and scientific data., voice, telemetry and slow-scan television data on a frequency of 145.950 MHz. The satellite was also intended for use in educational programmes. Kedr was a satellite measuring by by . It carried solar cells to generate power, and was expected to operate for six months.\n\nFor launch, Kedr was stored aboard the Progress M-09M spacecraft, which was launched to resupply the International Space Station. Progress M-09M was launched atop a Soyuz-U carrier rocket flying from Site 1/5 at the Baikonur Cosmodrome at 01:31:39 UTC on 28 January 2011. It docked with the International Space Station at 02:39 UTC on 30 January.\n\nKedr was deployed from the ISS by Sergey Volkov during an extra-vehicular activity on 3 August 2011 and re-entered Earth's atmosphere on 4 January 2012, having spent 154 days in orbit.\n\n\"KEDR\" was also used as the suffix for several Russian amateur radio Call signs (for example, RS0KEDR) that were active in 2014 around the 80th anniversary of Gagarin's birth.\n"}
{"id": "29273685", "url": "https://en.wikipedia.org/wiki?curid=29273685", "title": "Kisarawi", "text": "Kisarawi\n\nKisarawe is a Tanzanian district that is the larger settlement of the Pugu Hills, southwest of Dar es Salaam. In the Kisarawe district there is an 8200-hectres cultivation of \"Jathropa\" shrubs that are processed to produce biodiesel.\n\nIt is one of the districts of the Pwani (Coast) region and also one of the earliest districts of Tanzania. It is bordered by Mkuranga District to the east, Dar es Salaam region to the north east, Kibaha district to the north, Rufiji district to the South and Morogoro region to the west.\nAs of January, 2018 the population of Kisarawe district was 108,398 according to the Kisarawe District council website. The district is divided into seventeen (17) wards. \nThough Kisarawe has not enjoyed the economic prosperity as the neighbouring Dar es Salaam and other surrounding districts, it is strategically located with both TAZARA and Central railway lines passing through the district. It is also a few kilometres from JK Nyerere International Airport in Dar es Salaam.\nThe Pugu Forest Reserve, an important nature reserve around the Dar es Salaam area is located in the district. Also Kisarawe is one of the major cultivators of cassava in Tanzania.\n"}
{"id": "38825288", "url": "https://en.wikipedia.org/wiki?curid=38825288", "title": "Leo Ferrari", "text": "Leo Ferrari\n\nLeo Charles Ferrari (December 8, 1927 – October 7, 2010) was a St. Thomas University philosophy professor, noted Saint Augustine scholar, and founding member of the parody organization Flat Earth Society of Canada.\n\nLeo Ferrari was a founding member and head of the satirical Flat Earth Society of Canada, later renamed the Flat Earth Society (FES).\n\nIn Ferrari's writings in support of the FES and the Flat Earth, he attributed everything from gender to racial inequality on the globularist and the Spherical Earth model. Ferrari even claimed to have nearly fallen off \"the Edge\" of the Earth at Brimstone Head on Fogo Island.\n\nFerrari was a key figure in the 1990 flat earth \"documentary\", \"In Search of the Edge\". In the accompanying study guide, Ferrari is outed as a \"globularist,\" someone who believes the earth is spherical. The intent of the film was to promote critical thinking about media by \"[attempting] to prove in convincing fashion, something everyone knew to be false.\"\n\n\n\n\n\n"}
{"id": "14222028", "url": "https://en.wikipedia.org/wiki?curid=14222028", "title": "List of Category 4 Atlantic hurricanes", "text": "List of Category 4 Atlantic hurricanes\n\nCategory 4 hurricanes are tropical cyclones that reach Category 4 intensity on the Saffir–Simpson Hurricane Scale. Category 4 hurricanes that later attained Category 5 strength are not included in this list. The Atlantic basin includes the open waters of the Atlantic Ocean, the Caribbean Sea and the Gulf of Mexico. Category 4 is the second-highest hurricane classification category on the Saffir–Simpson Hurricane Scale, and storms that are of this intensity maintain maximum sustained winds of 113–136 knots (130–156 mph, 209–251 km/h). Based on the Atlantic hurricane database, 94 hurricanes have attained Category 4 hurricane status since 1851, the start of modern meteorological record keeping. Category 4 storms are considered extreme hurricanes. Hurricane Ike, which was a Category 4 storm, brought on a 24 ft storm surge, the third greatest storm surge ever recorded (after Hurricane Katrina and Hurricane Camille, respectively).\n\nCategory 4 hurricanes have maximum sustained winds of 113–136 knots (130–156 mph, 209–251 km/h). \"Sustained winds\" refers to the average wind speed observed over one minute at a height of 10 meters (33 ft) above ground. Gust can be 30% higher than the sustained winds. Mobile homes and other buildings without fixed structures can be completely destroyed, and the lower floors of sturdier structures usually sustain major damage. In addition to the winds, the cyclones generally produce a storm surge of 13–18 feet (4–5.5 m) above normal, potentially causing major beach erosion. Heavy, irreparable damage and/or near complete destruction of gas station canopies and other wide span overhang type structures are also very common, and mobile and manufactured homes are often completely destroyed. Low-level terrain may be flooded well inland, as well. In addition, Category 4 hurricanes are very often Cape Verde type hurricanes. Cape Verde hurricanes are usually the strongest, and their track sometimes points them towards the United States, or other land.\n\nThe number of Category 4 and 5 hurricanes appears to have nearly doubled in occurrence in from 1970 to 2004. It is likely that the increase in Atlantic tropical storm and hurricane frequency is primarily due to improved monitoring.\n\nDue to growing population in major coastal cities, many areas have become more vulnerable to strong hurricanes, especially categories 4 and 5.\n\nAll of the storms listed in this analysis are listed in chronological order, but they also list the minimum central pressure and maximum sustained winds. Each of these meteorological readings are taken using a specific meteorological instrument. For modern storms, the minimum pressure measurements are taken by Reconnaissance Aircraft using dropsondes, or by determining it from satellite imagery using the Dvorak technique. For older storms, pressures are often incomplete, typically being provided by ship-reports or land-observations. None of these methods can provide constant pressure measurements; thus it is possible the only measurement occurred when the cyclone was at a lesser strength. Sustained winds are taken using an Anemometer at 10 meters (33 ft) above the ground.\n\nA total of 95 hurricanes in the Atlantic Ocean Basin, including the Gulf of Mexico and the Caribbean, have reached Category 4 status as their peak intensity. (Note that Category 4 storms that intensified later to Category 5 status are not included in this analysis.)\nMost Category 4 hurricanes occur during September, with 51 storms occurring in that month. This coincides with the average peak of the Atlantic hurricane season, which occurs on September 10. Most Category 4 hurricanes develop in the warm waters of the Gulf of Mexico and the Caribbean Sea. Several Category 4 hurricanes are Cape Verde-type hurricanes. \nThere have been no Category 4 hurricanes to form in either May or December, or in any other month outside the traditional bounds of the Atlantic hurricane season.\n\nAll data listed is provided by the NHC best track, unless otherwise noted. \nAlso, some pressure readings for the older storms may have been taken at a time other than the storm's peak intensity. Thus, some pressure readings might not be the minimum pressure.\n\nSome pressure readings are unavailable due to scarce information.\n\nIn the years between 1851 and 1900, thirteen Category 4 storms are known to have occurred in the Atlantic Ocean. These numbers are limited by the observation techniques used prior to the use of satellite imagery in the 1960s.\n\nBetween 1901 and 1950, 29 Category 4 hurricanes formed in the Atlantic Basin.\n\nIn the years between 1951 and 1975, there were 23 Category 4 hurricanes in the Atlantic Ocean.\n\nIn the years between 1976 and 2000, 24 Category 4 hurricanes formed in the basin:\n\nIn the years between 2001 and the present time, 24 Category 4 hurricanes formed within the confines of the Atlantic Ocean. A dagger () denotes that the storm temporarily weakened below Category 4 intensity during the specified period of time.\n\nThe following hurricanes made landfall at some location at any strength. Due to inaccuracies in data, tropical depression landfalls are not included. Several of these storms weakened slightly after attaining Category 4 status as they approached land; this is usually a result of dry air, shallower water due to shelving, cooler waters, or interaction with land.\n"}
{"id": "6069234", "url": "https://en.wikipedia.org/wiki?curid=6069234", "title": "List of SSSIs in Clwyd", "text": "List of SSSIs in Clwyd\n\nDue to subsequent local government reorganisation in the UK since 1972, many counties and districts have been divided, merged or renamed. Using the AOS system alone would make it difficult to search for individual SSSI citations via the Countryside Council for Wales (CCW) database without knowing 1972 region divisions. As a result, the CCW groups Welsh SSSIs using the subdivisions of Wales formed in April 1996 by the Local Government (Wales) Act 1994, resulting in 22 principal areas.\n\nClwyd AOS lies within the counties of Conwy, Denbighshire, Flintshire, and Wrexham.\n\nFor SSSIs elsewhere in the UK, see List of SSSIs by Area of Search.\n\n"}
{"id": "6231633", "url": "https://en.wikipedia.org/wiki?curid=6231633", "title": "List of Sites of Special Scientific Interest in Clydesdale and South East Glasgow", "text": "List of Sites of Special Scientific Interest in Clydesdale and South East Glasgow\n\nThe following is a list of Sites of Special Scientific Interest in the Clydesdale and South East Glasgow Area of Search. For other areas, see List of SSSIs by Area of Search.\n\n"}
{"id": "39271562", "url": "https://en.wikipedia.org/wiki?curid=39271562", "title": "List of fjords, channels, sounds and straits of Chile", "text": "List of fjords, channels, sounds and straits of Chile\n\nThe information regarding fjords, channels, sound and straits of Chile on this page is compiled from the data supplied by the National Geospatial-Intelligence Agency, Country Files (GNS).\n\nThis list contains only:\n\nThis list doesn't include Chilean claims in the Antarctica.\n\nNGA lists 1447 names for 838 features with generics like \"Fiordo\", \"Seno\", \"Canal\", \"Paso\", \"Bahía\", \"Brazo\", \"Estrecho\", \"Ensenada\", \"Estero\". This compilation moved repeated UFIs to the last column of the first name given by NGA.\n\nNGA gives following definition of the features in Feature Designation Code:\n\nAlthough some features are called \"Bahía\", the designation code \"BAY\" was not selected.\n\nFor more information about the feature search in GeoNames Search, using the Unique Feature Identifier (UFI) in the \"Advanced Search\" Form.\n\n\n"}
{"id": "57160968", "url": "https://en.wikipedia.org/wiki?curid=57160968", "title": "List of fossil primates of South America", "text": "List of fossil primates of South America\n\nVarious fossil primates have been found in South America and adjacent regions such as Panama and the Caribbean. Presently, 78 species of New World monkeys have been registered in South America. Around the middle of the Cenozoic, approximately 34 million years ago, two types of mammals appeared for the first time in South America: rodents and primates. Both of these groups had already been inhabiting other continents for millions of years and they simply arrived in South America rather than originated there. Analyses of evolutionary relationships have shown that their closest relatives were living in Africa at the time. Therefore, the most likely explanation is that they somehow crossed the Atlantic Ocean, which was less wide than today, landed in South America, and founded new populations of rodents and primates.\n\nThe first South American primates gave rise to an impressive evolutionary radiation: more than 120 species in five families. These primates are known as platyrrhine (flat-nosed) primates and are closely related to Old World apes and monkeys (catarrhine primates). Platyrrhines include some of the most popular and acrobatic monkeys such as spider monkeys (\"Ateles\") and capuchins (\"Cebus\"), both of which have grasping (prehensile) tails that can be used as a fifth limb. Platyrrhines also include a wide variety of colorful tamarins and marmosets (family Callitrichidae). The platyrrhine primate fossil record is relatively sparse, quite unlike that of caviomorph rodents.\n\nThe presently oldest New World monkey is \"Perupithecus ucayaliensis\" from Amazonian Peru, described in 2015. A 2017 study of the fossils estimated the body mass for the various fossil primate species.\n\n\"Note:\" some authors, among others Fossilworks, consider \"Killikaike\" synonymous with \"Homunculus\" and \"Szalatavus\" with \"Branisella\", while other researchers consider the genera as different.<br>The Panamanian and Caribbean fossil primates have been included for completeness.\n\n\n\n\n"}
{"id": "36105344", "url": "https://en.wikipedia.org/wiki?curid=36105344", "title": "List of shipwrecks in the Pacific Ocean", "text": "List of shipwrecks in the Pacific Ocean\n\nThis is a list of shipwrecks located in the Pacific Ocean.\n\nMap of New Zealand wrecks to 1936\n\n20th century New Zealand wrecks\n"}
{"id": "1832701", "url": "https://en.wikipedia.org/wiki?curid=1832701", "title": "List of tundra ecoregions", "text": "List of tundra ecoregions\n\nA list of tundra ecoregions from the World Wide Fund for Nature (WWF) includes:\n\n"}
{"id": "15763623", "url": "https://en.wikipedia.org/wiki?curid=15763623", "title": "List of volcanoes by elevation", "text": "List of volcanoes by elevation\n\nA list (incomplete) of volcanoes on Earth arranged by elevation in metres above sea level.\n\nA list (incomplete) of volcanoes on Earth arranged by elevation in meters from its base on the ocean floor.\n\n"}
{"id": "26750386", "url": "https://en.wikipedia.org/wiki?curid=26750386", "title": "Master of Resource Management", "text": "Master of Resource Management\n\nThe Master of Resource Management (MRM) degree is a graduate degree program in the School of Resource and Environmental Management at Simon Fraser University in Burnaby, British Columbia, Canada. and the university centre of the Westfjords, Iceland. This program is designed for both recent graduates and individuals with experience in the private or public sector in dealing with natural resources and the environment. The program seeks students from a range of disciplines including biology, engineering, chemistry, forestry, geology, business, economics, geography, planning and social sciences. The program is recognized as an accredited sustainable planning program by the Canadian Institute of Planners and the Association for the Advancement of Sustainability in Higher Education.\n\nThe M.R.M. degree requires completion of six required courses (social science in natural resource management, ecology, ecological economics, earth systems, research methods), six elective courses, a field workshop, and a research project.\n\nThe aim is to increase familiarity and competence in understanding the dynamics of natural resources, the strategies and techniques of natural resource and environmental planning and management, and the biological, physical, social, economic and institutional implications of resource decisions. Students also become familiar with various quantitative methods of analysis and aids to decision making. In the field of natural resources, in particular, it is important that an academic degree provide a foundation for problem-solving as well as creative and critical thinking rather than focus primarily on subject matter such as fisheries, economics, or forestry.\n\nGraduate student research projects required to complete the degree evaluate the effectiveness of existing natural resource management policies and, where appropriate, present alternatives. Students apply a range of approaches including cost-benefit analysis, simulation modeling, legal and institutional assessment frameworks, and social surveys to address critical and emerging natural resource management issues on local, national, and international scales.\n\n"}
{"id": "145197", "url": "https://en.wikipedia.org/wiki?curid=145197", "title": "Metallic hydrogen", "text": "Metallic hydrogen\n\nMetallic hydrogen is a phase of hydrogen in which it behaves like an electrical conductor. This phase was predicted in 1935 on theoretical grounds by Eugene Wigner and Hillard Bell Huntington.\n\nAt high pressure and temperatures, metallic hydrogen can exist as a liquid rather than a solid, and researchers think it is present in large quantities in the hot and gravitationally compressed interiors of Jupiter, Saturn, and in some exoplanets.\n\nThough often placed at the top of the alkali metal column in the periodic table, hydrogen does not, under ordinary conditions, exhibit the properties of an alkali metal. Instead, it forms diatomic molecules, analogous to halogens and non-metals in the second row of the periodic table, such as nitrogen and oxygen. Diatomic hydrogen is a gas that, at atmospheric pressure, liquefies and solidifies only at very low temperature (20 degrees and 14 degrees above absolute zero, respectively). Eugene Wigner and Hillard Bell Huntington predicted that under an immense pressure of around hydrogen would display metallic properties: instead of discrete molecules (which consist of two electrons bound between two protons), a bulk phase would form with a solid lattice of protons and the electrons delocalized throughout. Since then, producing metallic hydrogen in the laboratory has been described as \"...the holy grail of high-pressure physics.\"\n\nThe initial prediction about the amount of pressure needed was eventually shown to be too low. Since the first work by Wigner and Huntington, the more modern theoretical calculations point towards higher but nonetheless potentially accessible metallization pressures of around .\n\nHelium-4 is a liquid at normal pressure near absolute zero, a consequence of its high zero-point energy (ZPE). The ZPE of protons in a dense state is also high, and a decline in the ordering energy (relative to the ZPE) is expected at high pressures. Arguments have been advanced by Neil Ashcroft and others that there is a melting point maximum in compressed hydrogen, but also that there might be a range of densities, at pressures around 400 GPa, where hydrogen would be a liquid metal, even at low temperatures.\n\nGeng predicted that the ZPE of protons indeed lowers the melting temperature of hydrogen to a minimum of at pressures of , within this flat region there might have an elemental mesophase intermediate between the liquid and solid state, which could metastably be stabilized down to low temperature and enter a supersolid state.\n\nIn 1968, Neil Ashcroft suggested that metallic hydrogen might be a superconductor, up to room temperature (), far higher than any other known candidate material. This hypothesis is based on an expected strong coupling between conduction electrons and lattice vibrations.\n\nPresently known \"super\" states of matter are superconductors, superfluid liquids and gases, and supersolids. Egor Babaev predicted that if hydrogen and deuterium have liquid metallic states, they might have quantum ordered states that cannot be classified as superconducting or superfluid in the usual sense. Instead, they might represent two possible novel types of quantum fluids: \"superconducting superfluids\" and \"metallic superfluids\". Such fluids were predicted to have highly unusual reactions to external magnetic fields and rotations, which might provide a means for experimental verification of Babaev's predictions. It has also been suggested that, under the influence of a magnetic field, hydrogen might exhibit phase transitions from superconductivity to superfluidity and vice versa.\n\nIn 2009, Zurek \"et al.\" predicted that the alloy would be a stable metal at only one quarter of the pressure required to metallize hydrogen, and that similar effects should hold for alloys of type LiH and possibly \"other alkali high-hydride systems\", i.e. alloys of type XH where X is an alkali metal.\n\nIn March 1996, a group of scientists at Lawrence Livermore National Laboratory reported that they had serendipitously produced the first identifiably metallic hydrogen for about a microsecond at temperatures of thousands of kelvins, pressures of over , and densities of approximately . The team did not expect to produce metallic hydrogen, as it was not using solid hydrogen, thought to be necessary, and was working at temperatures above those specified by metallization theory. Previous studies in which solid hydrogen was compressed inside diamond anvils to pressures of up to , did not confirm detectable metallization. The team had sought simply to measure the less extreme electrical conductivity changes they expected. The researchers used a 1960s-era light-gas gun, originally employed in guided missile studies, to shoot an impactor plate into a sealed container containing a half-millimeter thick sample of liquid hydrogen. The liquid hydrogen was in contact with wires leading to a device measuring electrical resistance. The scientists found that, as pressure rose to , the electronic energy band gap, a measure of electrical resistance, fell to almost zero. The band-gap of hydrogen in its uncompressed state is about , making it an insulator but, as the pressure increases significantly, the band-gap gradually fell to . Because the thermal energy of the fluid (the temperature became about due to compression of the sample) was above , the hydrogen might be considered metallic.\n\nMany experiments are continuing in the production of metallic hydrogen in laboratory conditions at static compression and low temperature. Arthur Ruoff and Chandrabhas Narayana from Cornell University in 1998, and later Paul Loubeyre and René LeToullec from Commissariat à l'Énergie Atomique, France in 2002, have shown that at pressures close to those at the center of the Earth () and temperatures of , hydrogen is still not a true alkali metal, because of the non-zero band gap. The quest to see metallic hydrogen in laboratory at low temperature and static compression continues. Studies are also ongoing on deuterium. Shahriar Badiei and Leif Holmlid from the University of Gothenburg have shown in 2004 that condensed metallic states made of excited hydrogen atoms (Rydberg matter) are effective promoters to metallic hydrogen.\n\nThe theoretically predicted maximum of the melting curve (the prerequisite for the liquid metallic hydrogen) was discovered by Shanti Deemyad and Isaac F. Silvera by using pulsed laser heating. Hydrogen-rich molecular silane () was claimed to be metallized and become superconducting by M.I. Eremets \"et al.\". This claim is disputed, and their results have not been repeated.\n\nIn 2011 Eremets and Troyan reported observing the liquid metallic state of hydrogen and deuterium at static pressures of . This claim was questioned by other researchers in 2012.\n\nIn 2015, scientists at the Z Pulsed Power Facility announced the creation of metallic deuterium using dense liquid deuterium, an electrical insulator-to-conductor transition associated with an increase in optical reflectivity.\n\nOn 5 October 2016, Ranga Dias and Isaac F. Silvera of Harvard University released claims of experimental evidence that solid metallic hydrogen had been synthesised in the laboratory at a pressure of around using a diamond anvil cell. This manuscript was available in October 2016, and a revised version was subsequently published in the journal \"Science\" in January 2017.\n\nIn the preprint version of the paper, Dias and Silvera write:\n\nSilvera stated that they did not repeat their experiment, since more tests could damage or destroy their existing sample, but assured the scientific community that more tests are coming. He also stated that the pressure would eventually be released, in order to find out whether the sample was metastable (i.e., whether it would persist in its metallic state even after the pressure was released).\n\nShortly after the claim was published in \"Science\", \"Nature\" news division published an article stating that some other physicists regarded the result with skepticism. Recently, prominent members of the high pressure research community have criticised the claimed results, questioning the claimed pressures or the presence of metallic hydrogen at the pressures claimed.\n\nIn February 2017, it was reported that the sample of claimed metallic hydrogen was lost, after the diamond anvils it was contained between broke.\n\nIn August 2017, Silvera and Dias issued an erratum to the \"Science\" article, regarding corrected reflectance values due to variations between the optical density of stressed natural diamonds and the synthetic diamonds used in their pre-compression diamond anvil cell.\n\nIn August 2018, scientists announced new observations regarding the rapid transformation of fluid deuterium from an insulating to a metallic form below 2000 K. Remarkable agreement is found between the experimental data and the predictions based on Quantum Monte Carlo simulations, which is expected to be the most accurate method to date. This may help researchers better understand giant gas planets, such as Jupiter, Saturn and related exoplanets, since such planets are thought to contain a lot of liquid metallic hydrogen, which may be responsible for their observed powerful magnetic fields.\n\n"}
{"id": "17070227", "url": "https://en.wikipedia.org/wiki?curid=17070227", "title": "Nankai Trough", "text": "Nankai Trough\n\nThe Nankai Trough is a submarine trough located south of the Nankaidō region of Japan's island of Honshū, extending approximately 900 km offshore. The underlying fault, the \"Nankai megathrust,\" is the source of the devastating Nankai megathrust earthquakes, while the trough itself is potentially a major source of hydrocarbon fuel, in the form of methane clathrate.\n\nIn plate tectonics, the Nankai Trough marks a subduction zone that is caused by subduction of the Philippine Sea Plate beneath Japan, part of the Eurasian plate (Kanda et al., 2004). This plate boundary would be an oceanic trench except for a high flux of sediments that fills the trench. Within the Nankai Trough there is a large amount of deformed trench sediments (Ike, 2004), making one of Earth's best examples of accretionary prism. Furthermore, seismic reflection studies have revealed the presence of basement highs that are interpreted as seamounts that are covered in sediments (Ike, 2004). The northern part of the trough is known as the Suruga Trough, while to the east is the Sagami Trough. The Nankai trough runs roughly parallel to the Japan Median Tectonic Line.\n\nConventional geologic estimates of plate movement velocities are difficult in the Nankai Trough because there are no spreading ridges that bound the tectonic plate. This area was not in the original NUVEL models (DeMets et al., 1990). However, a more recent study that included the Philippine Sea plate was based on data from the NUVEL-1A model (Zang et al., 2002). This study estimates that subduction in the Nankai Trough is about 43 mm/yr. REVEL-based calculations indicate that there is no accumulation of strain at the trench. The rates of movement have been calculated to be in a range of 3.0 ± 1.8 mm/yr to 11.1 ± 1.7 mm/yr (Sella et al., 2002). As mentioned previously, the NUVEL-1A plate motion model does not include the Philippine Sea plate. This is because the mathematics of this model only used twelve plates, and the Philippine Sea and Eurasian convergent margin were not included. However, using the Eurasia to North America plate motion, the estimated rate was 2–4 mm/yr (DeMets et al., 1990). This is not in agreement with the REVEL model, seemingly indicating that the NUVEL-1A model may need further revision.\n\nThe deposits are primarily trench-wedge turbidites (Spinelli et al., 2007). There are indications of an increase in the retention of porosity within the rock. Typically porosity reduces with increasing depth. However, there is an anomalous preservation of porosity at depth at drill site 1173. This has been attributed to post-depositional opal cementation that is preserving the porosity (Spinelli et al., 2007).\nThe detrital clays, primarily smectite, display variation over time and location in the Nankai Trough as well as the Shikoku basin. At depth there is an increase in the smectite clay content in the sediments, inferring that there has been a change in the deposition source rock (Steurer et al., 2003). Furthermore, there is a geothermal alteration of the smectite, converting it to illite clay (Steurer et al., 2003).\n\nThe Nankai Trough is actively deforming and marks a region of seismic activity. Deformation is concentrated in the outermost imbricate zone, with a significant amount of \"out of sequence\" thrusting occurring landward. Based on the work of Operto et al., 2006, several areas of intense tectonic activity in the Nankai Trough were identified using full waveform tomography. The upper portion of the upper accretionary prism and the underlying backstop are currently undergoing a great deal of compressional pressure. Several thrust faults were identified by Operto et al., 2006, of which the thrust faults closest to the subduction zone are active. Furthermore, Pisani et al., 2006, identified protothrusts and decollement surfaces along the Nankai Trough. Recently there has been an increase in interest in the release of water from illite clays in subducting sediments. The conversion of smectite to illite (illitizatation) in subduction zones is likely driven by the higher temperature found in the subduction zone as opposed to non-subducting sediments (Saffer et al., 2005). IODP Expedition 370 will seek to find the temperature limit of the deepest life on Earth by drilling in the Nankai Trough, where heat flow is particularly high near its boundary with the subducting young, hot Philippine Sea tectonic plate. At the targeted site, the geothermal gradient is about four times steeper than elsewhere in the Pacific Ocean. Reaching temperatures of approximately 130 °C in other areas would require collecting cores from approximately 4 kilometers below the seafloor, rather than 1.2 kilometers as planned.\n\nThe Nankai Trough is the near-surface extension of a zone of active seismicity that dips beneath SW Japan. The rupture zone has been subdivided into five areas with respect to seismic modelling (Mitsui et al., 2004). These five subdivisions show interesting differences in earthquake behavior: frequency of earthquakes varying on a 90 to 150-year cycle (Mitsui, et al., 2004; Tanioka et al., 2004), similar slip occurrences along the fault segments, the order of subdivision faulting, and finally, different failure features. Hydrologic observatories were placed in boreholes drilled in 2000 (IODP sites 808 and 1173) in an attempt to quantify changes in pore-fluid pressure that are a result of the oncoming Philippine Sea plate (Davis et al., 2006). Site 808 is located in the front section of the main thrust fault, while site 1173 is located approximately 11 km from the frontal thrust zone (Hitoshi et al., 2006). Other interesting results of the pressure measurements were the pressure changes that resulted from sediment deformation near boreholes and the effect of very low earthquake swarms at the time of pressure changes (Davis et al., 2006). The working hypothesis is that pressure changes indicate a change in the elastic strain within the formation (Davis et al., 2006).\n\nA seaward change in the pressure as measured by the borehole instruments likely indicates a relaxation of the sediments from the previous major thrust earthquake. Furthermore, the short period seismicity appears to have some degree of dependency on bathymetric highs such as seamounts. This was concluded by Kanda et al., 2004, through inversion analysis of seismic data.\nHistorically, the most recent large-scale earthquake to occur in the Nankai Trough was in 1944 off the Kii Peninsula. Using recent ocean bottom seismograph studies, it has been determined that most of the seismicity occurs near the trough axis (Obana et al., 2006). Along the western area of the Nankai Trough, seismicity appears to be related to irregularities in crustal structure such as fractures generated from the subducted seafloor, including backarc basin crust of the Shikoku Basin, as well as due to serpentization of uppermost mantle beneath the overriding plate (Obana et al., 2006). Recent large scale earthquakes resulting from subduction along the Nankai Trough have occurred in areas of large scale increases in the dip angle of the subducting plate (Hori et al., 2004).\n\nThe trough is potentially a major source of hydrocarbon fuel, in the form of methane clathrate. However, there is no commercial exploitation.\n\nAt depth in the ocean bottoms, in some cases water can form an ice-like solid structure that has methane trapped in its crystalline lattice, forming gas hydrates. The source of water for the formation of gas hydrates frequently comes from the dewatering of a subducting slab as well as the overriding plate (Muramatsu et al., 2006). Gas hydrates nearest the trough appear to be sourced mainly from dewatering associated with subduction, while with increasing distance from the trough the sourcing is more a result of lateral movement of methane enriched waters (Muramatsu et al., 2006). This was determined by drilling a series of boreholes and measuring the concentration, as well as radiometric age determination of the halogen elements iodine, bromine, and chlorine (Tomaru et al., 2007). The age determination of the iodine indicated multiple methane sources.\n\nIt has been estimated that convergent margins may contain up to two-thirds of the total gas hydrate volume on the earth (Kastner, 2001). The Nankai Trough has been described as containing a large amount of gas hydrates and is one of the best studied sites of gas hydrate formations (Collett, 2002; Saito et al., 2007). The information concerning the gas hydrates in the Nankai Trough was initially published in 2000 by the Japan National Oil Corporations. The data in the news release came from a series of boreholes what were started in the late 1990s. In this area the main sedimentological controls for the accumulation of gas hydrates are the sand-rich areas of the trough (Collett, 2002). Well coring indicates the presence of at least three gas hydrate zones. Krason, 1994, estimated that there are 0.42 to 4.2×10 cubic meters of methane within the gas hydrates. Seismically, the high bottom simulating reflectors are considered indicative of gas hydrates (Colwell et al., 2004). Methane-rich horizons have been identified as areas of higher attenuation of sonic frequencies (10 to 20 kHz) and only slight attenuation of seismic frequencies (30 to 110 Hz) (Matsushima, 2006).\n\n\n"}
{"id": "89343", "url": "https://en.wikipedia.org/wiki?curid=89343", "title": "Nemesis", "text": "Nemesis\n\nIn ancient Greek religion, Nemesis (; Ancient Greek: Νέμεσις), also called Rhamnousia or Rhamnusia (\"the goddess of Rhamnous\"), is the goddess who enacts retribution against those who succumb to hubris (arrogance before the gods). Another name is Adrasteia or Adrestia, meaning \"the inescapable\".\n\nThe name \"Nemesis\" is related to the Greek word νέμειν \"némein\", meaning \"to give what is due\", from Proto-Indo-European \"nem-\" \"distribute\".\nDivine retribution is a major theme in the Hellenic world view, providing the unifying theme of the tragedies of Sophocles and many other literary works. Hesiod states: \"Also deadly Nyx bore Nemesis an affliction to mortals subject to death\" (\"Theogony\", 223, though perhaps an interpolated line). Nemesis appears in a still more concrete form in a fragment of the epic \"Cypria\".\n\nShe is implacable justice: that of Zeus in the Olympian scheme of things, although it is clear she existed prior to him, as her images look similar to several other goddesses, such as Cybele, Rhea, Demeter, and Artemis.\n\nAs the \"Goddess of Rhamnous\", Nemesis was honoured and placated in an archaic sanctuary in the isolated district of Rhamnous, in northeastern Attica. There she was a daughter of Oceanus, the primaeval river-ocean that encircles the world. Pausanias noted her iconic statue there. It included a crown of stags and little Nikes and was made by Pheidias after the Battle of Marathon (490 BC), crafted from a block of Parian marble brought by the overconfident Persians, who had intended to make a memorial stele after their expected victory. Her cult may have originated at Smyrna.\n\nShe is portrayed as a winged goddess wielding a whip or a dagger.\n\nThe poet Mesomedes wrote a hymn to Nemesis in the early second century AD, where he addressed her:\nNemesis, winged balancer of life, dark-faced goddess, daughter of Justice\nand mentioned her \"adamantine bridles\" that restrain \"the frivolous insolences of mortals\".\n\nIn early times the representations of Nemesis resembled Aphrodite, who sometimes bears the epithet Nemesis.\n\nLater, as the maiden goddess of proportion and the avenger of crime, she has as attributes a measuring rod (tally stick), a bridle, scales, a sword, and a scourge, and she rides in a chariot drawn by griffins.\n\nThe word \"Nemesis\" originally meant the distributor of fortune, neither good nor bad, simply in due proportion to each according to what was deserved. Later, \"nemesis\" came to suggest the resentment caused by any disturbance of this right proportion, the sense of justice that could not allow it to pass unpunished.\n\nO. Gruppe (1906) and others connect the name with \"to feel just resentment\". From the fourth century onward, Nemesis, as the just balancer of Fortune's chance, could be associated with Tyche.\n\nIn the Greek tragedies Nemesis appears chiefly as the avenger of crime and the punisher of hubris, and as such is akin to Atë and the Erinyes. She was sometimes called \"Adrasteia\", probably meaning \"one from whom there is no escape\"; her epithet \"Erinys\" (\"implacable\") is specially applied to Demeter and the Phrygian mother goddess, Cybele.\n\nNemesis has been described as the daughter of Oceanus or Zeus, but according to Hyginus she was a child of Erebus and Nyx. She has also been described, by Hesiod, as the daughter of Nyx alone. In the Theogony, Nemesis is the sister of the Moirai (the Fates), the Keres (Black Fates), the Oneiroi (Dreams), Eris (Discord) and Apate (Deception)\n\nIn some metaphysical mythology, Nemesis produced the egg from which hatched two sets of twins: Helen of Troy and Clytemnestra, and the Dioscuri, Castor and Pollux. While many myths indicate Zeus and Leda to be the parents of Helen of Troy, the author of the compilation of myth called \"Bibliotheke\" notes the possibility of Nemesis being the mother of Helen. Nemesis, to avoid Zeus, turns into a goose, but he turns into a swan and mates with her. Nemesis in her bird form lays an egg that is discovered in the marshes by a shepherd, who passes the egg to Leda. It is in this way that Leda comes to be the mother of Helen of Troy, as she kept the egg in a chest until it hatched.\nRich-haired Nemesis gave birth to her [Helene (Helen)] when she had been joined in love with Zeus the king of the gods by harsh violence. For Nemesis tried to escape him and liked not to lie in love with her father Zeus the son of Kronos (Cronus); for shame and indignation vexed her heart: therefore she fled him over the land and fruitless dark sea. But Zeus ever pursued and longed in his heart to catch her. Now she took the form of a fish and sped over the waves of the loud-roaring sea, and now over Okeanos' (Oceanus') stream and the furthest bounds of Earth, and now she sped over the furrowed land, always turning into such dread creatures as the dry land nurtures, that she might escape him.\nNemesis, as she fled from Zeus' embrace, took the form of a goose; whereupon Zeus as a swan had intercourse with her. From this union, she laid an egg, which some herdsman found among the trees and handed over to Lede (Leda). She kept it in a box, and when Helene was hatched after the proper length of time, she reared her as her own.\nI will now go on to describe what is figures on the pedestal of the statue [of Nemesis at Rhamnos], having made this preface for the sake of clearness. The Greeks say that Nemesis was the mother of Helene (Helen), while Leda suckled and nursed her. The father of Helene the Greeks like everybody else hold to be not Tyndareos (Tyndareus) but Zeus. Having heard this legend [the sculptor] Pheidias has represented Helene as being led to Nemesis by Leda, and he has represented Tyndareos and his children.\nConstellation Swan (Cygnus). When Jupiter [Zeus], moved by desire, had begun to love Nemesis, and couldn't persuade her to lie with him, he relieved his passion by the following plan. He bade Venus Aphrodite, in the form of an eagle, pursue him; he, changed to a swan as if in flight from the eagle, took refuge with Nemesis and lighted in her lap. Nemesis did not thrust him away, but holding him in her arms, fell into a deep sleep. While she slept, Jupiter [Zeus] embraced her and then flew away. Because he was seen by men flying high in the sky, they said he was put in the stars. To make this really true, Jupiter put the swan flying and the eagle pursuing in the sky. But Nemesis, as if wedded to the tribe of birds, when her months were ended, bore an egg. Mercurius (Mercury) Hermes took it away and carried it to Sparta and threw it in Leda's lap. From it sprang Helen, who excelled all other girls in beauty.\n\nOne source of the myth says that Nemesis was the mother of the Telchines, whom others say were children of Pontus and Gaea or Thalassa.\nThe four famous Telkhines (Telchines), Aktaios (Actaeus), Megalesios (Megalesius), Ormenos (Ormenus) and Lykos (Lycus), whom Bakkhylides (Bacchylides) calls the children of Nemesis and Tartaros.[N.B. Tartaros is the spirit of the great pit beneath the earth.]\n\nAlthough a respected goddess, Nemesis brought much sorrow to mortals such as Echo and Narcissus. Narcissus was a very beautiful and arrogant hunter from the territory of Thespiae and Boeotia, who disdained the ones who loved him. Nemesis lured him to a pool where he saw his own reflection in the water and fell in love with it, not realizing it was only an image. He was unable to leave the beauty of his reflection and he eventually died. Nemesis believed that no one should ever have too much goodness in their lives, and she had always cursed those who were blessed with countless gifts.\n\nA festival called Nemeseia (by some identified with the Genesia) was held at Athens. Its object was to avert the nemesis of the dead, who were supposed to have the power of punishing the living, if their cult had been in any way neglected (Sophocles, \"Electra,\" 792; E. Rohde, \"Psyche,\" 1907, i. 236, note I).\n\nAt Smyrna there were two manifestations of Nemesis, more akin to Aphrodite than to Artemis. The reason for this duality is hard to explain. It is suggested that they represent two aspects of the goddess, the kindly and the implacable, or the goddesses of the old city and the new city refounded by Alexander. The martyrology \"Acts of Pionius\", set in the \"Decian persecution\" of AD 250–51, mentions a lapsed Smyrnan Christian who was attending to the sacrifices at the altar of the temple of these Nemeses.\n\nNemesis was one of several tutelary deities of the drill-ground (as \"Nemesis campestris\"). Modern scholarship offers little support for the once-prevalent notion that arena personnel such as gladiators, \"venatores\" and \"bestiarii\" were personally or professionally dedicated to her cult. Rather, she seems to have represented a kind of \"Imperial Fortuna\" who dispensed Imperial retribution on the one hand, and Imperially subsidised gifts on the other; both were functions of the popular gladiatorial Ludi held in Roman arenas. She is shown on a few examples of Imperial coinage as \"Nemesis-Pax\", mainly under Claudius and Hadrian. In the third century AD, there is evidence of the belief in an all-powerful \"Nemesis-Fortuna\". She was worshipped by a society called Hadrian's freedmen.\n\nAmmianus Marcellinus includes her in a digression on Justice following his description of the death of Gallus Caesar.\n\n\n"}
{"id": "3550569", "url": "https://en.wikipedia.org/wiki?curid=3550569", "title": "Noise control", "text": "Noise control\n\nNoise control or noise mitigation is a set of strategies to reduce noise pollution or to reduce the impact of that noise, whether outdoors or indoors.\n\nThe main areas of noise mitigation or abatement are: transportation noise control, architectural design, urban planning through zoning codes, and occupational noise control. Roadway noise and aircraft noise are the most pervasive sources of environmental noise. Social activities may generate noise levels that consistently affect the health of populations residing in or occupying areas, both indoor and outdoor, near entertainment venues that feature amplified sounds and music that present significant challenges for effective noise mitigation strategies.\n\nMultiple techniques have been developed to address interior sound levels, many of which are encouraged by local building codes; in the best case of project designs, planners are encouraged to work with design engineers to examine trade-offs of roadway design and architectural design. These techniques include design of exterior walls, party walls, and floor and ceiling assemblies; moreover, there are a host of specialized means for damping reverberation from special-purpose rooms such as auditoria, concert halls, entertainment and social venues, dining areas, audio recording rooms, and meeting rooms.\n\nMany of these techniques rely upon materials science applications of constructing sound baffles or using sound-absorbing liners for interior spaces. Industrial noise control is a subset of interior architectural control of noise, with emphasis on specific methods of sound isolation from industrial machinery and for protection of workers at their task stations.\n\nSound masking is the active addition of noise to reduce the annoyance of certain sounds; the opposite of soundproofing.\n\nOrganizations each have their own standards, recommendations, and directives for what levels of noise workers are permitted to be around before noise controls must be put into place.\n\nOSHA's requirements state that when workers are exposed to noise levels above 90 A-weighted decibels (dBA) in 8-hour time-weighted averages (TWA), administrative controls and/or new engineering controls must be implemented in the workplace. OSHA also requires that impulse noises and impact noises must be controlled to prevent these noises reaching past 140 dB peak sound pressure levels (SPL).\n\nMSHA requires that administrative and/ or engineering controls must be implemented in the workplace when miners are exposed to levels above 90 dBA TWA. If noise levels exceed 115 dBA, miners are required to wear hearing protection. MSHA, therefore, requires that noise levels be reduced below 115 dB TWA. Measuring noise levels for noise control decision making must integrate all noises from 90dBA to 140 dBA. \n\nThe FRA recommends that worker exposure to noise should be reduced when their noise exposure exceeds 90 dBA 8-hour TWA. Noise measurements must integrate all noises, including intermittent, continuous, impact, and impulse noises between 80 dBA to 140 dBA.\n\nThe DoD suggests that noise levels be controlled primarily through engineering controls. The DoD requires that all steady-state noises be reduced to levels below 85 dBA and that impulse noises be reduced below 140 dB peak SPL. Time Weighted Average exposures are not considered for the DoD's requirements.\n\nThe European Parliament and Council directive require noise levels to be reduced or eliminated using administrative and engineering controls. This directive requires lower exposure action levels of 80 dBA for 8 hours with 135 dB peak SPL, along with upper exposure action levels of 85 dBA for 8 hours with 137 peak dBSPL. Exposure limits are 87 dBA for 8 hours with peak levels of 140 peak dBSPL.\n\nAn effective model for noise control is the source, path, and receiver model by Bolt and Ingard. Hazardous noise can be controlled by reducing the noise output at its source, minimizing the noise as it travels along a path to the listener, and providing equipment to the listener or receiver to attenuate the noise.\n\nA variety of measures aim to reduce hazardous noise at its source. Programs such as Buy Quiet and the National Institute for Occupational Safety and Health (NIOSH) Prevention through design promote research and design of quiet equipment and renovation and replacement of older hazardous equipment with modern technologies. Physical materials, such as foam to absorb sound and walls to provide a sound barrier, modify existing systems to decrease hazardous noise at the source.\n\nThe principle of noise reduction through pathway modifications applies to the alteration of direct and indirect pathways for noise. Noise that travels across reflective surfaces such as smooth floors can be hazardous. Pathway alterations include sound dampening enclosures for loud equipment and isolation chambers from which workers can remotely control equipment while removed from noise. These methods prevent sound from traveling along a path to the worker or other listener.\n\nIn the industrial or commercial setting, workers must comply with the appropriate Hearing conservation program. Administrative controls such as the restriction of personnel in noisy areas prevent unnecessary noise exposure. Personal protective equipment such as foam ear plugs or ear muffs to attenuate sound provide a last line of defense for the listener.\n\n\nSource control in roadway noise has provided little reduction in vehicle noise, except for the development of the hybrid vehicle; nevertheless, hybrid use will need to attain a market share of roughly fifty percent to have a major impact on noise source reduction of city streets. Highway noise is today less affected by motor type, since the effects in higher speed are aerodynamic and tire noise related. Other contributions to reduction of noise at the source are: improved tire tread designs for trucks in the 1970s, better shielding of diesel stacks in the 1980s, and local vehicle regulation of unmuffled vehicles.\n\nThe most fertile areas for roadway noise mitigation are in urban planning decisions, roadway design, noise barrier design, speed control, surface pavement selection and truck restrictions. Speed control is effective since the lowest sound emissions arise from vehicles moving smoothly at 30 to 60 kilometres per hour. Above that range, sound emissions double with each five miles per hour of speed. At the lowest speeds, braking and (engine) acceleration noise dominates.\n\nSelection of road surface pavement can make a difference of a factor of two in sound levels, for the speed regime above 30 kilometres per hour. Quieter pavements are porous with a negative surface texture and use medium to small aggregates; the loudest pavements have a transversely grooved surface, and/or a positive surface texture and use larger aggregates. Surface friction and roadway safety are important considerations as well for pavement decisions.\n\nWhen designing new urban freeways or arterials, there are numerous design decisions regarding alignment and roadway geometrics. Use of a computer model to calculate sound levels has become standard practice since the early 1970s. In this way exposure of sensitive receptors to elevated sound levels can be minimized. An analogous process exists for urban mass transit systems and other rail transportation decisions. Early examples of urban rail systems designed using this technology were: Boston MBTA line expansions (1970s), San Francisco BART system expansion (1981), Houston METRORail system (1982), and the MAX Light Rail system in Portland, Oregon (1983).\n\nNoise barriers can be applicable for existing or planned surface transportation projects. They are probably the single most effective weapon in retrofitting an existing roadway, and commonly can reduce adjacent land use sound levels by up to ten decibels. A computer model is required to design the barrier since terrain, micrometeorology and other locale specific factors make the endeavor a very complex undertaking. For example, a roadway in cut or strong prevailing winds can produce a setting where atmospheric sound propagation is unfavorable to any noise barrier.\n\nAs in the case of roadway noise, little progress has been made in quelling aircraft noise at the source, other than elimination of loud engine designs from the 1960s and earlier. Because of its velocity and volume, jet turbine engine exhaust noise defies reduction by any simple means.\n\nThe most promising forms of aircraft noise abatement are through land planning, flight operations restrictions and residential soundproofing. Flight restrictions can take the form of preferred runway use, departure flight path and slope, and time-of-day restrictions. These tactics are sometimes controversial since they can impact aircraft safety, flying convenience and airline economics.\n\nIn 1979, the US Congress authorized the FAA to devise technology and programs to attempt to insulate homes near airports. While this obviously does not aid the exterior environment, the program has been effective for residential and school interiors. Some of the first airports at which the technology was applied were San Francisco International Airport, Seattle-Tacoma International Airport, John Wayne International Airport and San Jose International Airport in California.\n\nThe underlying technology is a computer model which simulates the propagation of aircraft noise and its penetration into buildings. Variations in aircraft types, flight patterns and local meteorology can be analyzed along with benefits of alternative building retrofit strategies such as roof upgrading, window glazing improvement, fireplace baffling, caulking construction seams and other measures. The computer model allows cost effectiveness evaluations of a host of alternative strategies.\n\nIn Canada, Transport Canada prepares noise exposure forecasts (NEF) for each airport, using a computer model similar to that used in the US. Residential land development is discouraged within high impact areas identified by the forecast.\n\nIn 1998, the flight paths in all of Scandinavia were changed as the new Oslo-Gardermoen Airport was opened. These new paths were straighter, reducing fuel use, and disturbing fewer people, however, vociferous protests came from people near the new paths who had not been disturbed before, and they took legal action (NIMBY effect).\n\nArchitectural acoustics noise control practices include: interior sound reverberation reduction, inter-room noise transfer mitigation and exterior building skin augmentation.\n\nIn the case of construction of new (or remodeled) apartments, condominiums, hospitals, and hotels, many states and cities have stringent building codes with requirements of acoustical analysis, in order to protect building occupants. With regard to exterior noise, the codes usually require measurement of the exterior acoustic environment in order to determine the performance standard required for exterior building skin design. The architect can work with the acoustical scientist to arrive at the best cost-effective means of creating a quiet interior (normally 45 dBA). The most important elements of design of the building skin are usually: glazing (glass thickness, double pane design etc.), perforated metal (used internally or externally), roof material, caulking standards, chimney baffles, exterior door design, mail slots, attic ventilation ports, and mounting of through-the-wall air conditioners.\n\nRegarding sound generated inside the building, there are two principal types of transmission. Firstly, airborne sound travels through walls or floor and ceiling assemblies and can emanate from either human activities in adjacent living spaces or from mechanical noise within the building systems. Human activities might include voice, noise from amplified sound systems, or animal noise. Mechanical systems are elevator systems, boilers, refrigeration or air conditioning systems, generators and trash compactors. Aerodynamic sources include fans, pneumatics, and combustion. Noise control for aerodynamic sources include quiet air nozzles, pneumatic silencers and quiet fan technology. Since many mechanical sounds are inherently loud, the principal design element is to require the wall or ceiling assembly to meet certain performance standards, (typically Sound transmission class of 50), which allows considerable attenuation of the sound level reaching occupants.\n\nThe second type of interior sound is called Impact Insulation Class (IIC) transmission. This effect arises not from airborne transmission, but rather from transmission of sound through the building itself. The most common perception of IIC noise is from footfall of occupants in living spaces above. Low frequency noise is transferred easily through the ground and buildings. This type of noise is more difficult to abate, but consideration must be given to isolating the floor assembly above or hanging the lower ceiling on resilient channel.\n\nBoth of the transmission effects noted above may emanate either from building occupants or from building mechanical systems such as elevators, plumbing systems or heating, ventilating and air conditioning units. In some cases it is merely necessary to specify the best available quieting technology in selecting such building hardware. In other cases shock mounting of systems to control vibration may be in order. In the case of plumbing systems there are specific protocols developed, especially for water supply lines, to create isolation clamping of pipes within building walls. In the case of central air systems, it is important to baffle any ducts that could transmit sound between different building areas.\n\nDesigning special-purpose rooms has more exotic challenges, since these rooms may have requirements for unusual features such as concert performance, sound studio recording, lecture halls. In these cases reverberation and reflection must be analyzed in order to not only quiet the rooms, but to prevent echo effects from occurring. In these situations special sound baffles and sound absorptive lining materials may be specified to dampen unwanted effects.\n\nAcoustical wall and ceiling panels can be constructed of many different materials and finishes. The ideal acoustical panels are those without a face or finish material that interferes with the acoustical infill or substrate. Fabric covered panels are one way to maximize the acoustical absorption. The finish material is used to cover over the acoustical substrate. Mineral fiber board, or Micore, is a commonly used acoustical substrate. Finish materials often consist of fabric, wood or metal. Fabric can be wrapped around substrates to create what is referred to as a \"pre-fabricated panel\" if laid onto a wall, and require no modifications. Such fabrics are generally acoustically 'transparent, meaning that they do not impede a sound wave.\n\nPrefabricated panels are limited to the size of the subas \"on-site acoustical wall panels\" This is constructed by \"framing\" the perimeter track into shape, infilling the acoustical substrate and then stretching and tucking the fabric into the perimeter frame system. On-site wall panels can be constructed to work around door frames, baseboard, or any other intrusion. Large panels (generally greater than 50 feet) can be created on walls and ceilings with this method.\n\nDouble-glazed and thicker windows can also prevent sound transmission from the outdoors.\n\nIndustrial noise is traditionally associated with manufacturing settings where industrial machinery produces intense sound levels, often upwards of 85 decibels. While this circumstance is the most dramatic, there are many other work environments where sound levels may lie in the range of 70 to 75 decibels, entirely composed of office equipment, music, public address systems, and even exterior noise intrusion. Either type of environment may result in noise health effects if the sound intensity and exposure time is too great.\n\nIn the case of industrial equipment, the most common techniques for noise protection of workers consist of shock mounting source equipment, creation of acrylic glass or other solid barriers, and provision of ear protection equipment. In certain cases the machinery itself can be re-designed to operate in a manner less prone to produce grating, grinding, frictional, or other motions that induce sound emissions. In recent years, Buy Quiet programs and initiatives have arisen in an effort to combat occupational noise exposures. These programs promote the purchase of quieter tools and equipment and encourage manufacturers to design quieter equipment.\n\nIn the case of more conventional office environments, the techniques in architectural acoustics discussed above may apply. Other solutions may involve researching the quietest models of office equipment, particularly printers and photocopy machines. Impact printers and other equipment were often fitted with \"acoustic hoods\", enclosures to reduce emitted noise. One source of annoying, if not loud, sound level emissions are lighting fixtures (notably older fluorescent globes). These fixtures can be retrofitted or analyzed to see whether over-illumination is present, a common office environment issue. If over-illumination is occurring, de-lamping or reduced light bank usage may apply. Photographers can quieten noisy still cameras on a film set using sound blimps.\n\nReductions in cost of technology have allowed noise control technology to be used not only in performance facilities and recording studios, but also in noise-sensitive small businesses such as restaurants. Acoustically absorbent materials such as fiberglass duct liner, wood fiber panels and recycled denim jeans serve as artwork-bearing canvasses in environments in which aesthetics are important.\n\nUsing a combination of sound absorption materials, arrays of microphones and speakers, and a digital processor, a restaurant operator can use a tablet computer to selectively control noise levels at different places in the restaurant: the microphone arrays pick up sound and send it to the digital processor, which controls the speakers to output sound signals on command.\n\nCommunities may use zoning codes to isolate noisy urban activities from areas that should be protected from such unhealthy exposures and to establish noise standards in areas that may not be conducive to such isolation strategies. Because low-income neighborhoods are often at greater risk of noise pollution, the establishment of such zoning codes is often an environmental justice issue. Mixed use areas present especially difficult conflicts that require special attention to the need to protect people from the harmful effects of noise pollution. Noise is generally one consideration in an environmental impact statement, if applicable (such as transportation system construction).\n\n\nGeneral:\n\n"}
{"id": "305748", "url": "https://en.wikipedia.org/wiki?curid=305748", "title": "Nomina Anatomica Veterinaria", "text": "Nomina Anatomica Veterinaria\n\nThe Nomina Anatomica Veterinaria (often abbreviated as NAV) is a text prepared by the International Committee on Veterinary Gross Anatomical Nomenclature. It is used as the standard reference for anatomical (zootomical) terminology in the field of Veterinary Science.\n\nThe text is continually under revision. The 5th edition is available free of charge from the World Association of Veterinary Anatomists (WAVA) as a PDF file, with last revision in 2017. The 6th edition has not been printed commercially. The 4th edition, published in 1994, was the last commercially printed edition.\n\n"}
{"id": "46899448", "url": "https://en.wikipedia.org/wiki?curid=46899448", "title": "Oil content meter", "text": "Oil content meter\n\nAn oil content meter (OCM) is an integral part of all oily water separator (OWS) systems. Oil content meters are also sometimes referred to as oil content monitors, bilge alarms, or bilge monitors.\n\nThe OCM continuously monitors how much oil is in the water that is pumped out the discharge line of the OWS system. The OCM will not allow the oil concentration of the exiting water to be above the Marpol standard of 15 ppm. This standard was first adopted in 1977 with Resolution A.393(X) which was published by IMO. These standards were updated various but the most current resolution is MEPC 107(49). The oil content meter will sound an alarm if the liquid leaving the system has an unsatisfactory amount of oil in the mixture. If it is still above that standard, then the bilge water will be reentered into the system until it meets the required criteria. The OCM uses light beams to determine how oily the water in the system is. The system will then gauge the oil concentration based on a light intensity meter. Modern oil content meters also have a data logging system that can store oil concentration measurements for more than 18 months.\n\nIf the OCM determines that there is far too much of a type of oil, the OCM may be fouled and needs to be flushed out. Running clean water through the OCM sensor cell is one way it can be cleaned. Also scrubbing the sensor area with a bottle brush is another effective method. The new MEPC 107(49) regulations have set out stringent actions that require the OCM to be tamper proof and also the OCM needs to have an alarm that sounds whenever the OCM is being cleaned. When the alarm goes off, the OCM functionality will be checked by crew members.\n\nAn OCM is a small part of what is called the oil discharge monitoring and control system. The first part is the oil content meter. The second is a flow meter which measures the flow rate of the water at the discharge pipe. Third, is a computing unit which calculates how much oil has actually been discharged along with the day and time of the discharge. And lastly is the overboard valve control system which is essentially just a valve that can stop the discharge from flowing out at the appropriate time.\n\nOil content meters measure how effective the oily water separators on a ship are functioning. If the OCM computes that the oily discharge is above the 15 ppm standard, the oily water separator needs to be checked by the crew.\n\nThere are three types of oil that the oil content meter needs to check for and they are fuel oil, diesel, and emulsions.\n\n"}
{"id": "28951294", "url": "https://en.wikipedia.org/wiki?curid=28951294", "title": "Oliver G. Pike", "text": "Oliver G. Pike\n\nOliver Gregory Pike, FZS, FRPS. (usually credited as Oliver G. Pike; 1 October 1877 – 17 October 1963) was a British naturalist, wildlife photographer, author and early nature documentary pioneer, specialising in the study of bird life. \"His claim to significance,\" according to Bryony Dixon of BFI Screenonline, \"lies in the groundbreaking techniques he developed to capture animals in their natural habitats and in the fact that he passed this knowledge on.\"\n\nPike studied at Enfield Grammar School until 1893, where he became friends with local commercial photographer and ornithologist Reginald Badham Lodge, who specialised in bird photography. Pike accompanied Lodge while he worked, taking his first photograph of a wild flower at the age of 13, in the autumn of 1890. In 1895 the two invented a bird-activated trip-wire releases, which effectively allowed birds to take their own pictures. Pike developed a profound knowledge of photographic techniques and went on to publish a series of 25 handbooks on ornithological photography and cinematography, starting with \"In Birdland with Field Glass and Camera\" (1900). He also developed his own stills camera, marketed as \"The Birdland Camera\" by Sanders & Crowhurst of Shaftesbury Avenue, London, and later a cine-camera for wildlife photography that was camouflaged so as not to frighten off the subjects.\nPike's first film, \"In Birdland\", which premiered at the Palace Theatre, London in August 1907, was the first British wildlife film to be screened to a fee paying audience. Together with cinematographer Harold Armytage Sanders, Pike took great physical risks hanging from ropes over coastal cliffs to capture unprecedented footage of Britain's seabirds, including kittiwakes, gannets, cormorants and puffins. The film proved hugely popular in its 6-week run with over 100 additional prints were made for screenings across the UK. All copies are now however believed lost or destroyed. He made two more films along a similar theme, \"St Kilda, Its People and Birds\" (1908) and \"Cliff Climbing – The Egg Harvest of Flamborough Head\" (1908), before becoming director of photography for Pathé Frères from 1910 to 1920, where he made \"Glimpses of Bird Life\" (1910), noted for its use of positioning which was \"years ahead of their time\" and \"helped to establish British wildlife photographers as leaders in this field.\"\n\nIn 1921, Pike went to work for old friend Harry Bruce Wolfe at British Instructional Films on the single-reel series \"Secrets of Nature\" series. His inaugural film for the series was \"The Cuckoo's Secret\" (1922), commissioned by Edgar Chance, which changed public perception of how common cuckoos reproduce by providing the first proof that they lay their eggs directly in the nests of the species they parasitise rather than laying them on the ground and carrying them to the nest. Over the course of the next 11 years, Smith blended \"nature photography with painstaking laboratory work,\" on the series, \"providing an atmospheric account of British wildlife,\" which filmmaker, historian and critic Paul Rotha described in 1930 as \"the sheet anchor of the British film industry.\" He later went on to work for Gaumont-British Instructional Films on the similar \"Secrets of Life\" series, where he made the controversial \"A Family of Great Tits\" (1934), highlighting the brutality of nature with footage from a specially constructed nesting box. Working until 1947, he made over 50 films many of which showed animal behaviour that had never before been recorded.\n\nPike, represented by the Thomas's Lecture Agency of Strand, London, was a popular speaker on wildlife subjects and lectured all over the United Kingdom. He was opposed to the egg collecting, shooting and other blood sports. He joined the Royal Photographic Society in 1907 and gained his Fellowship the same year. He was made an Honorary Fellow in 1957. He exhibited and lectured extensively at the Society. Some 300 prints, negatives and lantern-slides of his work, which were acquired from the London Natural History Society in 1974, are preserved in the RPS Collection at the National Media Museum in Bradford, along with one of his early cameras. He also donated several of his films to the BFI National Archive. He died in Leighton Buzzard in 1963.\n\nA local blue plaque for Oliver Pike, co-sponsored by Southgate District Civic Trust and Enfield Grammar School was unveiled on 16 November 2014 by his grandsons Jonathan and Richard Dollimore at 96 Green Dragon Lane, Winchmore Hill, his family home from 1882 to 1914. \n\n\n\n\n\"The Cuckoo's Secret\" is available on the BFI DVD \"Secrets of Nature\", released in 2010.\n\n"}
{"id": "40156355", "url": "https://en.wikipedia.org/wiki?curid=40156355", "title": "One Less Nuclear Power Plant", "text": "One Less Nuclear Power Plant\n\nOne Less Nuclear Power Plant is the flagship energy policy launched in April 2012 by Seoul, the capital city of the Republic of Korea, in its broad effort to respond to climate change and energy crisis in the aftermath of the Fukushima nuclear accident and the nationwide rolling blackout in 2011.\n\nThe main target of the One Less Nuclear Power plant was to cut energy consumption by 2 million TOE, which is equivalent to the capacity of one nuclear power plant, mainly by directly engaging citizens in energy-saving and renewable energy generation. This target was exceeded in June 2014, six months ahead of schedule, as Seoul reduced the city’s energy consumption by 2.04 million TOE.\n\nThe Seoul Metropolitan Government announced the launch of the second phase of the One Less Nuclear Power Plant, Seoul Sustainable Energy Action Plan, in August 2014.\n\nWith “Energy Generation, Energy Efficiency, and Energy-Saving,” at its core, the One Less Nuclear Power Plant took a multi-faceted approach, consisting of 71 specific projects in 6 policy categories, which can be re-categorized in 10 key action plans. The six policy categories include expanding renewable energy generation, improving building energy efficiency, promoting eco-friendly transportation system, generating green jobs, building a low energy-consuming city and creating a low energy-consuming civic culture.\n\nThe One Less Nuclear Power Plant presented set an example for local energy policies as it reached its target through unique means like Seoul Feed-in Tariff (FIT), and improved rent conditions for photovoltaic power generation. The significance of the One Less Nuclear Power Plant lies in the fact that it is a civic-participatory governance policy, under which citizens took the lead in policy development and implementation.\n\nThe energy-saving programs achieved the greatest cut in energy consumption at some 910,000 TOE, while energy efficiency and generation projects pushed down the total energy consumption by 870,000 TOE and 260,000 TOE respectively.\n\nAs a result, Seoul’s consumption of energy including electricity, city gas, and oil turned downward. In 2013, when tangible outcomes of the Ones Less Nuclear Power Plant started to surface, Seoul’s electricity consumption decreased by 1.4%, whereas the nationwide consumption jumped by 1.76%.\n\nUnder the One Less Nuclear Power Plant, the Seoul Metropolitan Government attracted of about 400 billion won in private capital to generate electricity from clean renewable sources that could be supplied to 300,000 households. 63.5 billion won out of the total private investment was used to establish 3,756 photovoltaic power generation systems with the combined capacity of 69 MW.\n\nSeoul implemented Building Retrofit Program (BRP) on 20,000 buildings by offering loans with ultra-low interest rates of 1.75% and adopting a first-invest-return-later approach. Moreover, 6.79 million energy-efficient LED bulbs were introduced by Seoul. In particular, Seoul replaced 430,000 conventional bulbs in all 243 subway stations in the city with LED ones with the full financial support by the Korea Finance Corporation.\n\nThe Eco-Mileage program, which incentivizes citizens’ energy-saving actions, saw its membership increase to 1.7 million, prompting energy-saving behaviors both at households and businesses. The Eco-Mileage program won the 2013 UN Public Service Award in the category of “Fostering participation in public policy decision making through innovative mechanisms.”\n\nThe brand identity (BI) of One Less Nuclear Power Plant was designed to reflect the vision of Healing city, Healing earth. The BI was a winning project from a civic competition, which was later retouched by Mr. Dong-min Ahn, the President of Intergram Graphics, local marketing design firm.\n\nThe slogans above were developed by citizens through a contest.\n\nDongeuri the Sunlight Angel is the mascot of One Less Nuclear Power Plant, symbolizing the face of Seoul citizens who both save and generate energy. Dongueri was designed and donated by Mr. Ho-seop Yoon, Honorary Professor of Kookmin University.\n\n"}
{"id": "20045399", "url": "https://en.wikipedia.org/wiki?curid=20045399", "title": "Oslo Dumping Convention", "text": "Oslo Dumping Convention\n\nThe Convention for the Prevention of Marine Pollution by Dumping from Ships and Aircraft also called the Oslo Convention was an international agreement designed to control the dumping of harmful substances from ships and aircraft into the sea. It was adopted on February 15, 1972 in Oslo, Norway and came into force on April 7, 1974. Original signatories were Denmark, France, Iceland, Norway, Portugal, Spain, and Sweden. Later members included the United Kingdom (1975), the Netherlands (1975), Germany (1977), Finland (1979), Ireland (1982), and Belgium (1985). \n\nThe area covered by the treaty included the Atlantic and Arctic Oceans north of latitude 36°N, east of longitude 42°W and west of longitude 51°E, excluding the Baltic and Mediterranean Seas\n\nThe Convention prohibited the dumping of halocarbons and organosilicon (with some exceptions), mercury and mercury compounds, cadmium and cadmium compounds, non-biodegradable plastics and other persistent materials, as well as \"substances which have been agreed between the Contracting Parties as likely to be carcinogenic under the conditions of disposal.\" It also restricted and required a permit for the dumping of arsenic, lead, copper, zinc and their compounds, as well as cyanides, and fluorides, pesticides, containers, \"tar-like substances\", scrap metal, and \"other bulky wastes.\"\n\nIt also defined the considerations to be made in the issuance of dumping permits by each signatory state and required them to enforce the agreement within their territorial sea and make efforts to prevent dumping of materials outside the agreement's defined borders. \n\nThe convention was amended once, in December, 1981, which amendment came into force in February, 1982. The Oslo Convention was replaced by the Convention for the Protection of the Marine Environment of the North-East Atlantic or \"OSPAR Convention\" when it came into force on March 25, 1998. \n\n"}
{"id": "38381054", "url": "https://en.wikipedia.org/wiki?curid=38381054", "title": "PSR B0943+10", "text": "PSR B0943+10\n\nPSR B0943+10 is a pulsar 2,000 light years from Earth in the direction of the constellation of Leo.\n\nThe pulsar is estimated to be 5 million years old, which is relatively old for a pulsar. It has a rotational period of 1.1 seconds and emits both radio waves and X-rays. \nOngoing research at the University of Vermont discovered that the pulsar was found to flip on a roughly a few hours timescale between a radio bright mode with highly organized pulsations and a quieter mode with rather chaotic temporal structure.\n\nMoreover, the observations of the pulsar performed simultaneously with the European Space Agency's XMM-Newton X-ray observatory and ground-based radio telescopes revealed that it exhibits variations in its X-ray emission that mimic in reverse the changes seen in radio waves—the pulsar has a weaker non-pulsing X-ray luminosity during the radio bright mode and is actually brighter during the radio quite mode emitting distinct X-ray pulses. Such changes can only be explained if the pulsar's magnetosphere (which may extend up to 52,000 km from the surface) quickly switches between two extreme states. The change happens on a few seconds timescale, far faster than most pulsars. Despite being one of the first pulsars discovered the mechanism for its unusual behavior is unknown.\n\nA research group from Peking University in Beijing, China published a paper suggesting that the pulsar may actually be a low-mass quark star.\n\nOn May of 2014 two gas giants extrasolar planets was found orbiting PSR B0943+10 \n"}
{"id": "15470157", "url": "https://en.wikipedia.org/wiki?curid=15470157", "title": "Polar Research Institute of China", "text": "Polar Research Institute of China\n\nThe Polar Research Institute of China () (PRIC) is the main Chinese research institute for the study of the Earth's polar regions. It is based in Shanghai, China.\n\nThe Institute manages four polar research stations (three in Antarctica and one in the Arctic), as well as the icebreaking research vessel \"Xuě Lóng\".\n"}
{"id": "16636448", "url": "https://en.wikipedia.org/wiki?curid=16636448", "title": "Poor fen", "text": "Poor fen\n\nA poor fen (also known as transitional bog, transitional mire or sedge mire) is a natural wetland habitat, consisting of dense low growth of small sedges and other plants. It develops on wet ground where the water is fairly acidic and has very few plant nutrients.\n\nPoor fen is intermediate between the taller vegetation of fen, which occurs where the water is much less acidic, and the short, mossy vegetation of bog, which is even more acidic.\n\nPoor fen is found where the ground is permanently wet with nutrient-poor water which is somewhat acidic. For example it occurs as the vegetation of flushes (marshy springs on slopes), in places where neutral water enters more acidic bogs, in wet acidic grassland, and sometimes in the flatter parts of flood-meadows where much of the water is ombrotrophic (derived directly from rainfall). It sometimes forms a floating mat over water or very wet peat, making a mobile surface known as quaking bog.\n\nPoor fen is usually grazed by wild animals or livestock, which prevent ecological succession into wet woodland.\n\nIn north-western Europe, characteristic plant species of poor fen communities include common sedge (\"Carex nigra\"), carnation sedge (\"Carex panicea\"), star sedge (\"Carex echinata\"), white beak-sedge (\"Rhynchospora alba\") and many other small sedges, as well as other plants such as jointed rush (\"Juncus articulatus\"), marsh cinquefoil (\"Potentilla palustris\"), bog-bean (\"Menyanthes trifoliata\"), bog pimpernel (\"Anagallis tenella\"), lesser skullcap (\"Scutellaria minor\") and marsh valerian (\"Valeriana dioica\"). \"Sphagnum\" mosses also occur, but are not dominant as they would be in bog vegetation. There may also be some grasses, but these are usually inconspicuous amongst the sedges and rushes.\n\n"}
{"id": "51250772", "url": "https://en.wikipedia.org/wiki?curid=51250772", "title": "Self-adhesive plastic sheet", "text": "Self-adhesive plastic sheet\n\nSelf-adhesive plastic sheet, known in the United Kingdom as sticky-backed plastic, is wide plastic sheet or film with an adhesive layer on one side, used as a surface coating for decorative purposes. It is typically smooth and shiny, but can also come in textured varieties, in which case it can sometimes be used as a cheap alternative to veneer. The plastic is often PVC. The sheeting is typically sold with a removable paper release liner to prevent it from adhering prematurely.\n\nSelf-adhesive vinyl sheet was introduced to the UK market in the 1960s under the brand name Fablon. It was extensively used in DIY at the time, and notably featured in children's DIY projects on the British TV show \"Blue Peter\", but always under the generic name \"sticky-backed plastic.\"\n\nSmooth self-adhesive plastic sheet is typically used to cover the studio floor for shiny-floor shows, thus giving them their name.\n\n"}
{"id": "84927", "url": "https://en.wikipedia.org/wiki?curid=84927", "title": "Silvanus (mythology)", "text": "Silvanus (mythology)\n\nSilvanus (; meaning \"of the woods\" in Latin) was a Roman tutelary deity of woods and fields. As protector of the forest (\"sylvestris deus\"), he especially presided over plantations and delighted in trees growing wild. He is also described as a god watching over the fields and husbandmen, protecting in particular the boundaries of fields. The similarly named Etruscan deity Selvans may be a borrowing of Silvanus, or not even related in origin.\n\nSilvanus is described as the divinity protecting the flocks of cattle, warding off wolves, and promoting their fertility. Dolabella, a rural engineer of whom only a few pages are known, states that Silvanus was the first to set up stones to mark the limits of fields, and that every estate had three \"Silvani:\"\nHence \"Silvani\" were often referred to in the plural.\n\nLike other gods of woods and flocks, Silvanus is described as fond of music; the syrinx was sacred to him, and he is mentioned along with the Pans and Nymphs. Later speculators even identified Silvanus with Pan, Faunus, Inuus and Aegipan. He must have been associated with the Italian Mars, for Cato refers to him as \"Mars Silvanus\". In the provinces outside of Italy, Silvanus was identified with numerous native gods:\n\nThe sacrifices offered to Silvanus consisted of grapes, ears of grain, milk, meat, wine and pigs. In Cato's \"De Agricultura\" an offering to \"Mars Silvanus\" is described, to ensure the health of cattle; it is stated there that his connection with agriculture referred to only the labour performed by men, and that females were excluded from his worship. (Compare Bona Dea for a Roman deity from whose worship men were excluded.) Virgil relates that in the very earliest times the Tyrrhenian Pelasgians had dedicated a grove and a festival to Silvanus.\n\nIn works of Latin poetry and art, Silvanus always appears as an old man, but as cheerful and in love with Pomona. Virgil represents him as carrying the trunk of a cypress (), about which the following myth is told. Silvanus – or Apollo according to other versions – was in love with Cyparissus, and once by accident killed a pet hind belonging to Cyparissus. The latter died of grief, and was metamorphosed into a cypress.\n\nIn Edmund Spenser's epic poem \"The Faerie Queene\" (1590–96), Silvanus appears in Canto VI of Book I. His 'wyld woodgods' (Stanza 9) save the lost and frightened Lady Una from being molested by \"Sans loy\" and take her to him. They treat her as a Queen because of her great beauty. Spenser writes in Stanza 14:\n\n"}
{"id": "5642519", "url": "https://en.wikipedia.org/wiki?curid=5642519", "title": "Soil zoology", "text": "Soil zoology\n\nSoil zoology is the study of animals living fully or partially in the soil (soil fauna). The term was apparently first used for a conference of soil zoologists presenting their research at the University of Nottingham, UK, in 1955.\n\n\n\n"}
{"id": "47050281", "url": "https://en.wikipedia.org/wiki?curid=47050281", "title": "Tamanowas Rock", "text": "Tamanowas Rock\n\nTamanowas Rock (also spelled Tamanous), also called Chimacum Rock, is a high rock with caves and crevices that lies in a forest adjacent to Anderson Lake State Park, near Port Townsend, Washington. It is a sacred site to the Coast Salish peoples of the Pacific Northwest and a pilgrimage site. The rock was listed on the National Register of Historic Places in 2015.\n\nTamanowas Rock is said to have first been used 10,000 years ago by the Chimakum (or Chemacum) people (who no longer exist), leading to its alternate name \"Chimacum Rock\", whose name is also found in other local geographic features. In accordance with legend, it may have been used as a refuge from the tsunami caused by the 1700 Cascadia earthquake, and earlier as a lookout for hunting now-extinct mastodon. \"Tamanowas\" means \"spirit power\" in the Klallam language.\n\nThe site is either a registered archaeological site, or nominated to become one with the Washington State Department of Archaeology.\n\nIn 2013, the rock was purchased with of surrounding land by the Jamestown S'Klallam Tribe for preservation, at the end of a series of loans and purchases by organizations including Washington State Parks, Bullitt Foundation and Jefferson Land Trust, that started in 2009. The land was added to an existing 22-acre purchase by the tribe. Prior to this, it was a rock climbing site, a practice which was ended when the S'Klallam Tribe took ownership.\n\nIn 2014, the rock was desecrated with graffiti, gaining national and international attention.\n\nThe mineral composition is Eocene subaerial adakitic lava and lava breccia. Dikes of similar composition exist in the Blue Hills near Bremerton 60 km away, both thought to be created by subduction of the Kula-Farallon Ridge beneath North America. They may be related by being part of a magmatic arc , they may be two isolated volcanic centers, or they may have been created at a single center and displaced along a fault (see Puget Sound faults).\n\n"}
{"id": "449531", "url": "https://en.wikipedia.org/wiki?curid=449531", "title": "The Blue Marble", "text": "The Blue Marble\n\nThe Blue Marble is an image of planet Earth taken on December 7, 1972, by the crew of the Apollo 17 spacecraft at a distance of about from the surface. It is one of the most reproduced images in human history.\n\nThe image has the official NASA designation AS17-148-22727 and shows the Earth from the point of view of the Apollo crew travelling towards the moon. The translunar coast photograph extends from the Mediterranean Sea to Antarctica. This was the first time the Apollo trajectory made it possible to photograph the south polar ice cap, despite the Southern Hemisphere being heavily covered in clouds. In addition to the Arabian Peninsula and Madagascar, almost the entire coastline of Africa is clearly visible. The Asian mainland is on the horizon.\n\nThe name has also been applied by NASA to a 2012 series of image data sets covering the entire globe at relatively high resolution, created by carefully sifting through satellite-captured sequences taken over time, to eliminate as much cloud cover as possible from the collated set of images.\n\nThe photograph, taken by astronauts on December 7, 1972, at 05:39 a.m. EST (10:39 UTC), is one of the most widely distributed photographic images in existence. The image is one of the few to show an almost fully illuminated Earth as the astronauts had the Sun behind them when they took the image. To the astronauts, the slightly gibbous Earth had the appearance and size of a glass marble, hence the name. It has been mostly shown with Antarctica at the bottom, although the actual view the astronauts had was with Antarctica on top.\n\nThe photograph was taken about 5 hours and 6 minutes after launch of the Apollo 17 mission, and about 1 hour 54 minutes after the spacecraft left its parking orbit around Earth, to begin its trajectory to the Moon. The time of Apollo 17's launch, 12:33 a.m. EST, meant that Africa was in daylight during the early hours of the spacecraft's flight. With the December solstice approaching, Antarctica was also illuminated.\n\nThe 1972 Tamil Nadu cyclone can be seen in the top right of the image. This storm had brought flooding and high winds to the Indian state of Tamil Nadu on December 5, two days before the photograph was taken.\n\nThe photograph's official NASA designation is AS17-148-22727. NASA photograph AS17-148-22726, taken just before and nearly identical to 22727, is also used as a full-Earth image.\n\nThe photographer used a 70-millimeter Hasselblad camera with an 80-millimeter Zeiss lens. NASA credits the image to the entire Apollo 17 crewEugene Cernan, Ronald Evans and Jack Schmittall of whom took photographs during the mission with the on-board Hasselblad, although evidence examined after the mission suggests that Jack Schmitt was the photographer. \n\nAll Apollo flights were heavily scheduled down to the minute. At the time this photo was taken, none of the astronauts was scheduled to do so. Thus this photo was taken quickly in a stolen moment. The astronaut who took the picture was weightless, and the continents were hard to see, and he took the photo quickly, which explains why he held the camera upside down compared to the north up orientation of all maps. If every photo on this roll of film is printed, and all of the photos on the roll of film are oriented the same way, then when viewed in sequence, to put feet down and heads up, this photo will have the south pole up, breaking the map convention.\n\nApollo 17 was the last manned lunar mission. No human since has been far enough from Earth to photograph a whole-Earth image such as \"The Blue Marble\", but whole-Earth images have been taken by many unmanned spacecraft missions.\n\n\"The Blue Marble\" was not the first clear image taken of an illuminated face of Earth, since similar shots from the ATS-3 satellite had already been made as early as 1967. The Apollo 17 image, however, released during a surge in environmental activism during the 1970s, became a symbol of the environmental movement, as a depiction of Earth's frailty, vulnerability, and isolation amid the vast expanse of space. NASA archivist Mike Gentry has speculated that \"The Blue Marble\" is among the most widely distributed images in human history.\n\nSubsequent similar images of Earth (including composites at much higher resolution) have also been termed \"Blue Marble\" images, and the phrase \"blue marble\" (as well as the picture itself) is frequently used, as in the Earth flag by environmental activist organizations or companies attempting to promote an environmentally conscious image. There has also been a children's television program called \"Big Blue Marble\". Poet-diplomat Abhay K has penned an Earth Anthem inspired by the blue marble which contains \"all the peoples and the nations of the world, one for all, all for one, united we unfurl the blue marble flag\".\n\nIn 2002, NASA released an extensive set of satellite-captured imagery, including prepared images suitable for direct human viewing, as well as complete sets suitable for use in preparing further works. At the time, 1 km/pixel was the most detailed imagery available for free, and permitted for reuse without a need for extensive preparatory work to eliminate cloud cover and conceal missing data, or to parse specialized data formats. The data also included a similarly manually assembled cloud-cover and night-lights image sets, at lower resolutions.\n\nA subsequent release was made in 2005, named \"Blue Marble Next Generation\". This series of photo mosaics was produced with the aid of automated image-sifting upon images from NASA's Earth Observatory, which enabled the inclusion of a complete, cloud-free globe for each month from January to December 2004, at even higher resolution (500 m/pixel). The original release of a single-image set covering the entire globe could not reflect the extent of seasonal snow-and-vegetative cover across both hemispheres, but this newer release closely modeled the changes of the seasons.\n\nA number of interactive viewers for these data have also been released, among them a music visualization for the PS3 that is based on the texture data.\n\nOn January 25, 2012, NASA released a composite image of the western hemisphere of Earth entitled \"Blue Marble 2012\". The picture logged over 3.1 million views on the Flickr image hosting website within the first week of release. On February 2, 2012, NASA released a companion to this new \"Blue Marble\", showing a composite image of the eastern hemisphere from data obtained on January 23, 2012.\n\nThe picture is composed of data obtained by the Visible/Infrared Imager Radiometer Suite (VIIRS) instrument on board the Suomi NPP satellite on January 4, 2012. The data was obtained from six orbits of the Earth by the Suomi NPP over an eight-hour period. The image was created using a near-sided perspective projection with the viewing point placed 2100 km above 20° North by 100° West. This projection results in a very wide-angle presentation such as one might get with a fish-eye lens, and it does not include the whole hemisphere.\n\nOn December 5, 2012, NASA released a nighttime view of Earth called \"Black Marble\" during an annual meeting of Earth scientists held by the American Geophysical Union in San Francisco. The images display all the human and natural matter that glows and can be detected from space. The data was acquired by the Suomi NPP satellite in April and October 2012 and then mapped over existing \"Blue Marble\" imagery of Earth to provide a realistic view of the planet. The Suomi NPP satellite completed 312 orbits and gathered 2.5 terabytes of data to get a clear shot of every parcel of the Earth’s land surface. Named for satellite meteorology pioneer Verner Suomi, the satellite flies over any given point on Earth’s surface twice each day and flies above the surface in a polar orbit.\n\nThe nighttime views were obtained with the new satellite's \"day-night band\" of the Visible Infrared Imaging Radiometer Suite (VIIRS), which detects light in a range of wavelengths from green to near-infrared, and uses filtering techniques to observe dim signals such as city lights, gas flares, auroras, wildfires, and reflected moonlight. Auroras, fires, and other stray light have been removed in the case of the \"Black Marble\" images to emphasize the city lights. The images have been used to study the spatial distribution of economic activity, to select sites for astronomical observatories, and to monitor human activities around protected areas.\n\nOn July 21, 2015, NASA released a new \"Blue Marble\" photograph taken by a U.S. Deep Space Climate Observatory (DSCOVR), a solar weather and Earth observation satellite which was launched in February 2015 and will provide a near-continuous view of the entire sunlit-side of the Earth. The image was taken on July 6, 2015. The photograph, of the Western Hemisphere, is centered over Central America. The Western United States, Mexico and the Caribbean are visible, but much of South America is hidden beneath cloud cover. Greenland can be seen at the upper edge of the image.\n\nThe EPIC science team plans to upload 13 new color images per day on their website. The color balance has been adjusted to approximate an image that could be seen with the average human eye. In addition to images, scientific information will be uploaded as it becomes available after in-flight calibration is complete. The science information will be ozone and aerosol amounts, cloud reflectivity, cloud height, and vegetation information. The EPIC instrument views the Earth from sunrise in the west to sunset in the east 12 to 13 times per day as the Earth rotates at 15 degrees of longitude per hour. Clearly visible are storms forming over the Atlantic and Pacific Oceans, major slowly moving \"cloud rivers\", dust aerosol plumes from Africa, the sun's reflection in the oceans, ship exhaust tracks in the clouds, rivers and lakes, and the variegated land surface patterns especially in the African deserts. The spatial resolution of the color images is about 10 km, and the resolution of the science products will be about 20 km. Once every three months, lunar images are obtained that are the same as those viewed from Earth during our full Moon. On occasion, the other side of the Moon will appear in the Earth images as the Moon crosses in front of the Earth.\n\n\n\n\n"}
{"id": "13630730", "url": "https://en.wikipedia.org/wiki?curid=13630730", "title": "Tidewater glacier cycle", "text": "Tidewater glacier cycle\n\nThe tidewater glacier cycle is the typically centuries-long behavior of tidewater glaciers that consists of recurring periods of advance alternating with rapid retreat and punctuated by periods of stability. During portions of its cycle, a tidewater glacier is relatively insensitive to climate change.\n\nWhile climate is the main factor affecting the behavior of all glaciers, additional factors affect calving (iceberg-producing) tidewater glaciers. These glaciers terminate abruptly at the ocean interface, with large pieces of the glacier fracturing and separating, or calving, from the ice front as icebergs.\n\nClimate change causes a shift in the equilibrium line altitude (ELA) of a glacier. This is the imaginary line on a glacier, above which snow accumulates faster than it ablates, and below which, the reverse is the case. This altitude shift, in turn, prompts a retreat or advance of the terminus toward a new steady-state position. However, this change in terminus behavior for calving glaciers is also a function of resulting changes in fjord geometry, and calving rate at the glacier terminus as it changes position.\n\nCalving glaciers are different from land terminating glaciers in the variation in velocity along their length. Land terminating glacier velocities decline as the terminus is approached. Calving glaciers accelerate at the terminus. A declining velocity near the terminus slows the glacier response to climate. An accelerating velocity at the front enhances the speed of the glaciers response to climate or glacier dynamic changes. This is observed in Svalbard, Patagonia and Alaska. A calving glacier requires more accumulation area than a land terminating glacier to offset this higher loss from calving.\n\nThe calving rate is largely controlled by the depth of the water and the glacier velocity at the calving front. The process of calving provides an imbalance in forces at the front of the glaciers, that raises velocity. The depth of the water at the glacier front is a simple measure that allows estimation of calving rate, but is the amount of flotation of the glacier at the front that is the specific physical characteristic that is important.\n\nWater depth at the glacier terminus is the key variable in predicting calving of a tidewater glacier. Debris flux and sediment recycling at the glacier grounding-line, particularly rapid in the temperate glaciers of Alaska, can alter this depth, acting as a second-order control on terminus fluctuations. This effect contributes to the insensitivity of a glacier to climate when its terminus is either retreating or advancing in deep water.\n\nAustin Post was one of the first to propose that water depth at the calving margin strongly affects the rate of iceberg calving. Glaciers that terminate on a morainal shoal are generally stable, but once a glacier retreats into water that deepens as the ice front recedes, calving rate increases rapidly and results in drastic retreat of the terminus. Using data collected from 13 Alaskan tidewater calving glaciers, Brown et al. (1982) derived the following relationship between calving speed and water depth: formula_1, where formula_2 is the mean calving speed (m⋅a), formula_3 is a calving coefficient (27.1±2 a), formula_4 is the mean water depth at glacier front (m) and formula_5 is a constant (0 m⋅a). Pelto and Warren (1991) found a similar calving relationship with tidewater glaciers observed over longer time periods, with slightly reduced calving rate to the mainly summer rates noted by Brown et al. (1982).\n\nCalving is an important form of ablation for glaciers that terminate in freshwater, also. Funk and Röthlisberger determined a relationship between calving speed and water depth based on analysis of six glaciers that calve into lakes. They found that the same basic calving relationship developed for tidewater calving glaciers was true for freshwater calving glaciers, only the calving coefficients lead to calving rates 10% of that for tidewater glaciers.\n\nObservations of Alaskan tidewater calving glaciers prompted Austin Post to describe the tidewater calving glacier advance/retreat cycle: (1) advancing, (2) stable-extended, (3) drastically retreating, or (4) stable-retracted. The following is a detailed review of the tidewater glacier cycle derived by Post, with numerous cited examples, the cycle is based on observations of temperate tidewater glaciers in Alaska, not outlet glaciers from large ice sheets or polar glaciers.\n\nThe \"accumulation area ratio\" of a glacier, AAR, is the percentage of a glacier that is a snow-covered accumulation zone at the end of the summer melt season. This percentage for large Alaskan glaciers is between 60 and 70 for non-calving glaciers, 70-80 for moderately calving glaciers and up to 90 for very high calving rate glaciers. By using accumulation area ratio (AAR) data for Alaskan tidewater calving glaciers, Pelto (1987) and Viens (1995) produced models showing that climate acts as a first-order control on the advance/retreat cycle of calving glaciers during most of the advance retreat cycle, but there are climate insensitive periods as well. Pelto (1987) examined the terminus behavior of 90 Alaskan glaciers and found that the terminus behavior of all 90 were correctly predicted based on the AAR and calving rate.\n\nIf we begin at the stable retracted position at the end of a tidewater glacier cycle the glacier will have a moderate calving rate and a high AAR, above 70. The glacier will build a terminus shoal of sediment further reducing the calving rate. This will improve the glacier mass balance and the glacier can begin to advance due to this change or an increase in ice flux to the terminus due to increasing snowfall or reduced snow melt. As the advance proceeds the terminus shoal will be pushed in front of the glacier and continue to build, keeping the calving rate low. In the case of the most glaciers such as the Taku Glacier the glacier will eventually build a terminus shoal that is above water and calving will essentially cease. This will eliminate this loss of ice from the glacier and the glacier can continue to advance. Taku Glacier and Hubbard Glacier have been in this phase of the cycle. Taku Glacier which has been advancing for 120 years no longer calves. Hubbard Glacier still has a calving front. The glacier will then expand until the AAR is between 60 and 70 and equilibrium of the non-calving glacier is achieved. The glacier is not very sensitive to climate during the advance as its AAR is quite high, when the terminus shoal is limiting calving.\n\nAt the maximum extended position the glacier is once again sensitive to changing climate. Brady Glacier and Baird Glacier are examples of glaciers currently at this point. Brady Glacier has been thinning during the last two decades due to the higher equilibrium line altitudes accompanying warmer conditions in the region, and its secondary termini have begun to retreat. A glacier can remain at this position for sometime, a century at least in the case of Brady Glacier. Usually substantial thinning occurs before retreat from the shoal commences. This allowed the prediction in 1980, by the United States Geological Survey (USGS), of the retreat of the Columbia Glacier from its terminus shoal. The glacier had remained on this shoal throughout the entire 20th century. The USGS was monitoring the glacier due to its proximity to Valdez, Alaska, the port for crude oil export from the Alaskan Pipeline. At some point a decline in mass balance will trigger a retreat from the shoal into deeper water at which point calving will ensue. Based on the recent thinning it is suggested that Brady Glacier is poised to begin retreat.\n\nThe calving rate will increase as the glacier retreats from the shoal into the deeper fjord just cleared by the glacier during advance. The water depth initially increases as the glacier retreats from the shoal, causing every more rapid glacier flow, calving and retreat. A glacier is comparatively insensitive to climate during this calving retreat. However, in the case of San Rafael Glacier, Chile, a switch from retreat (1945–1990) to advance (1990–1997) was noted. Current examples of this retreat are Columbia Glacier and Guyot Glacier. The most famous recent example of this is the large retreat of Glacier Bay and Icy Bay glaciers in Alaska that occurred rapidly via this process.\nMuir Glacier retreated 33 km from 1886 to 1968 featuring extensive calving the entire time. It reversed its retreat briefly 1890—1892. In 1968, Muir Glacier was still 27 km long, less than half of its length in 1886. The retreat continued an additional 6.5 km by 2001. Today, the glacier is near the head of its fjord and with minimal calving the glacier may be stable at this retracted position.\n\nThe best current example is illustrated by the United States Geological Survey study of Columbia Glacier. They noted that the average calving rate from Columbia Glacier increased from 3 km⋅a in the second half of 1983 to 4 km⋅a during the first nine months of 1984. This rate was four times greater than that measured at the end of 1977 and increased again in 1985. The glacier flow, i.e., the movement of the ice toward the sea, also increased, it was inadequate to keep pace with the break-up and expulsion of icebergs. The increase in speed instead seemed to just feed the ever faster conveyor to the terminus for iceberg production. This prompted the USGS to predict that the glacier would retreat 32 km before stabilizing. By 2006, it has retreated 16 km. The water remains deep and the calving rate and glacier velocity very high, indicating retreat will continue. At this point, just like having a balloon payment in an adjustable rate mortgage, the glacier has to pay a whole new portion of its balance via icebergs. The glacier accelerates as flow is enhanced by the calving process; this increases the export of icebergs from the glacier. Large calving retreats are initiated by warming conditions causing ice thinning. The resulting retreat to a new equilibrium conditions can be far more extensive than will be regained during the next advance stage. A good example of this is Muir Glacier.\n\nNext to Glacier Bay, Icy Bay has had the most extensive retreat. At the beginning of the 20th century, the coastline was nearly straight and the bay non-existent. The entrance of the bay was filled by a tidewater glacier face that calved icebergs directly into the Gulf of Alaska. A century later glacier retreat has opened a multi-armed bay more than 30 miles long. The tidewater glacier has divided into three independent glaciers, Yahtse, Tsaa and Guyot Glacier. Other examples of glaciers currently in the retreat phase are South Sawyer and Sawyer Glaciers in Alaska, retreating 2.1 and 2.3 km respectively from 1961 to 2005.\n\nIn Patagonia an example of a rapidly retreating glacier is the Jorge Montt Glacier which drains into Baja Jorge Montt in the Pacific Ocean. The glacier’s ice thinning, at low elevations, from 1975 to 2000 reached 18 m⋅a at the lowest elevations. The glacier calving front experienced a major retreat of 8.5 km in those 25 years as a result of rapid thinning .\n\nAt some point the glacier reaches a pinning point where calving is reduced due to a fjord narrowing or shoaling and the glacier’s AAR is near 100. This is occurring with LeConte Glacier and Yathse Glacier. Le Conte Glacier currently has an AAR of 90, is at a retracted position and seems likely to be set to advance after building a terminus shoal. The drop in calving rate allows the glacier to reestablish equilibrium.\n\nThe Taku Glacier provides a good example of this cycle. It was at its maximum extent near 1750. At this point it had closed off Taku Inlet. Subsequently, calving retreat commenced. By the time John Muir saw the glacier in 1890, it was near its minimum extent, at a location where the fjord narrowed, with deep water in front. About 1900, its AAR of 90 led to the Taku Glacier onset of advance, at the same time that the remaining Juneau Icefield glaciers continued receding. This advance continued at a rate of 88 m⋅a, advancing 5.3 km from the 1900 minimum until 1948, all the while building and then riding up on a substantial outwash plain beneath its calving face. After 1948, the now non-calving Taku Glacier, possessed an AAR only slightly reduced (86 and 63). This drove 1.5 km of further advance at a reduced rate of 37 m⋅a. In 1990, the Taku Glacier’s AAR was 82 high enough, to prompt Pelto and Miller to conclude that the Taku Glacier would continue to advance for the remaining decade of the 20th century. From 1986 to 2005, the equilibrium line altitude on the glacier rose without a significant terminus shift causing the AAR to decline to about 72. Pelto and Miller concluded that the current reduction in rate of advance is since 1970 is attributable to the laterally expanding terminal lobe as opposed to declining mass balance and that the primary force behind the Taku Glacier’s advance since about 1900 is due to positive mass balance. The recent lack of positive mass balance will eventually slow the retreat if it persists.\n\nThe size of tidewater glaciers is such that the tidewater glacier cycle is several hundred years in length. A tidewater glacier is not sensitive to climate during the advancing and drastically retreating phases of its cycle. In the same region, disparate terminus responses are observed amongst tidewater calving glaciers, but not land terminating glaciers. This is exemplified by the 17 major glaciers of the Juneau Icefield, 5 have retreated more than 500 m since 1948, 11 more than 1000 m, and one glacier the Taku has advanced. This difference highlights the unique impacts on terminus behavior of the tidewater glacier cycle, which has caused the Taku Glacier to be insensitive to climate change in the last 60 years.\nConcurrently, in both Patagonia and Alaska, there are tidewater glaciers that have advanced for a considerable period, tidewater glaciers undergoing rapid retreat and stable tidewater glaciers.\n\n"}
{"id": "47719656", "url": "https://en.wikipedia.org/wiki?curid=47719656", "title": "WUE", "text": "WUE\n\nWUE, or Water Usage Effectiveness, is a sustainability metric created by The Green Grid in 2011 to attempt to measure the amount of water used by datacenters to cool their IT assets.\nTo calculate simple WUE, a data center manager divides the annual site water usage in liters by the IT equipment energy usage in kilowatt hours (Kwh). Water usage includes water used for cooling, regulating humidity and producing electricity on-site. More complex WUE calculations are available from The Green Grid website.\n"}
