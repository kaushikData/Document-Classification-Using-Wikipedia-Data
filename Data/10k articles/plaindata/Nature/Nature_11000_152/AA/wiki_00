{"id": "1575209", "url": "https://en.wikipedia.org/wiki?curid=1575209", "title": "Accelerant", "text": "Accelerant\n\nAccelerants are substances that can bond, mix or disturb another substance and cause an increase in the speed of a natural, or artificial chemical process. Accelerants play a major role in chemistry—most chemical reactions can be hastened with an accelerant. Accelerants alter a chemical bond, speed up a chemical process, or bring organisms back to homeostasis. Accelerants are not necessarily catalysts as they may be consumed by the process.\n\nIn fire protection, the term accelerant is used very broadly to include any substance or mixture that \"accelerates\" the development of fire to commit arson. Chemists would distinguish an accelerant from a fuel; the terms are not, in the truest sense of chemical science, interchangeable. Some fire investigators use the term \"accelerant\" to mean any substance that initiates and promotes a fire without differentiating between an accelerant and a fuel. To a chemical engineer, \"gasoline\" is not at all considered an \"accelerant;\" it is more accurately considered a \"fuel.\"\n\nA fire is a self-sustaining, exothermic oxidation reaction that emits heat and light. When a fire is accelerated with a true accelerant like oxygen bearing liquids and gases (like ) it can produce more heat, consume the actual fuels more quickly, and increase the spread of the fire. Fires involving liquid accelerants, like gasoline, burn more quickly, but at the same temperature as fires involving ordinary fuels.\n\nIndicators of an incendiary fire or arson can lead fire investigators to look for the presence of fuel traces in fire debris. Burning compounds and liquids can leave behind evidence of their presence and use. Fuels present in areas they aren't typically found in can indicate an incendiary fire or arson. Investigators often use special dogs known as \"accelerant detection canines\" trained to smell ignitable liquids. Well-trained dogs can pinpoint areas for the investigator to collect samples. Fire debris submitted to forensic laboratories employ sensitive analytical instruments with GC-MS capabilities for forensic chemical analysis.\n\nMany so-called accelerants are hydrocarbon-based fuels, sometimes more realistically referred to as petroleum distillates: gasoline, diesel fuel, kerosene, turpentine, butane, and various other flammable solvents. These accelerants are also known as ignitable liquids. Ignitable liquids can leave behind irregular patterns on the surface of a floor. These irregular burn patterns can indicate the presence of an ignitable liquid in a fire and can indicate the point of origin of the fire. Note, however, that irregular patterns may be found in fires involving no accelerant. This is particularly true in cases of full room involvement.\n\nThe properties of some ignitable liquids make them dangerous fuels. Many ignitable liquids have high vapor pressures, low flash points and a relatively wide range between their upper and lower explosive limit. This allows ignitable liquids to ignite easily, and when mixed in a proper air-fuel ratio, readily explode. Many arsonists who use generous amounts of gasoline have been seriously burned or killed igniting their fire.\n\nCommon household items and objects can accelerate a fire. Wicker and foam have high surface to mass ratios and favorable chemical compositions and thus burn easily and readily. Arsonists sometimes use large amounts of available combustible material rather than ignitable liquids in attempts to try to avoid detection. Using large fuel loads can increase the rate of fire growth as well as spread the fire over a larger area, thus increasing the amount of fire damage. Inappropriate amounts and types of fuel in a particular area can indicate arson. Whether available combustible materials constitute an accelerant depends on the intent of the person responsible for their use.\n\nThe use of accelerators and activators lowers the activation energy of vulcanization reaction to 80-125kJ/mole from 210kJ/mole which is necessary if we use sulfur alone. Accelerators and activators break sulfur chains. Accelerated sulfur vulcanization systems require only 5-15 sulfur atoms per cross-link as compared to 40-45 S atoms/crosslink for a non-accelerated sulfur vulcanization.\nThere are many accelerators available for the vulcanization of rubber. That is because there is a wide range of rubber articles on the market with a wide variety of properties. For instance in a car tire alone there can be already up to eight different rubber compounds, each with specific properties. For instance the tread in a typical passenger car tire consists of a mixture of SBR (styrene-butadiene rubber) and BR (butadiene rubber). This rubber should have high abrasion resistance and high grip on both dry and wet roads. The side wall of the tire should have a high flexibility, meaning that it should resist many flexings during the running of the tire without cracking. It consists normally of a mixture of natural rubber and butadiene rubber. Inside the tire there is a rubber compound with as major function the adhesion between rubber and the steel cord of the belt. It typically consists of natural rubber with a very high sulfur level (up to 8 phr), to get a relatively stiff rubber, with sulfur promoting the adhesion with the steel cord. The basis of the tire is formed by the carcass, normally a mixture of NR (natural rubber), SBR and BR. It should have a very good adhesion to the polyester cord, used as reinforcement.\nAnd the inner side of the tire is formed by the inner liner, normally consisting of halogenated butyl rubber (IIR)\nFor all these compounds with their different properties different accelerators and mixtures of accelerators have to be used to obtain the required properties.\nA vulcanization accelerator is typically used in combination with sulfur as the cross-linker, and with zinc oxide and stearic acid as activators. Other additives can be added too, but for the cross-linking reaction, those mentioned above are the most important.\nThe various types of rubber used in the various tire compounds all have different vulcanization characteristics, like speed of cure (cure is the crosslinking reaction) and extent of cure (the number of cross-links). A typical passenger car tire is vulcanized for 10 minutes at 170 degrees C. Many accelerators and various mixtures thereof are typically used to ensure the vulcanization of all the component compounds have completed during the 10 minute process.\n\nThere are two major classes of vulcanization accelerators, primary accelerators and secondary accelerators or ultra accelerators.\n\nOf the primary accelerators the major group used in tire manufacture is formed by sulfenamides. These are produced by an oxidative coupling reaction of mercapto-benzthiazole (otherwise called mercaptobenzothiazole) (MBT) with a primary amine like cyclohexylamine or tert-Butylamine.\nSecondary amines like dicyclohexylamine can be used also but result in much slower accelerators. Such a slow accelerator is required in the steel cord adhesion compound mentioned above, because for optimal adhesion a slow cure is required.\nAnother important group of primary accelerators is formed by the thiazoles. The two main products are mercaptobenzthiazole (MBT) and mercaptobenzthiazole disulfide (MBTS), a product formed by oxidative coupling of two MBT molecules. The thiazoles are used for the vulcanization of thick articles, and as basic accelerator in EPDM compounds (ethylene-propylene-diene rubbers), in combination with mixtures of ultra-accelerators.\n\nIn the vulcanization of neoprene or polychloroprene rubber (CR rubber) the choice of accelerator is governed by different rules to other diene rubbers. Most conventionally used accelerators are problematic when CR rubbers are cured and the most important accelerator has been found to be ethylene thiourea (ETU) which, although being an excellent and proven accelerator for polychloroprene, has been classified as reprotoxic. The European rubber industry has started a research project SafeRubber to develop a safer alternative to the use of ETU.\n\nOf the secondary or ultra-accelerators the main categories are the thiurams and the dithiocarbamates. In vulcanization of tire compounds they are used as small addition to sulfenamides to boost the speed and state of cure.\nThey have a very fast vulcanization speed and therefore, next to boosters in tire compounds they are used as main accelerator in EPDM compounds and in latex compounds. EPDM compounds have much less cure sites than natural rubber or SBR, and therefore need a rapid vulcanization system to have sufficient cure speed. Latex is cured at relatively low temperature (100- 120 °C)and therefore need an inherently rapid accelerator.\nThe major thiurams used are TMTD (tetramethylthiuram disulfide) and TETD(tetraethylthiuram disulfide), They are produced by the reaction between dimethylamine or diethylamine and carbon disulfide. The major dithiocarbamates are the zinc salts ZDEC (zinc diethyldithiocarbamate) and ZDBC (zinc dibutyldithiocarbamate).\n\nCement accelerators are available as admixtures for the use in concrete, mortar, rendering and screeds. The addition of an accelerator speeds the setting time and thus cure time starts earlier. This allows concrete to be placed in winter with reduced risk of frost damage. Concrete is damaged if it does not reach a strength of before freezing. Typical chemicals used for acceleration today are calcium nitrate (Ca(NO)), calcium formate (Ca(HCOO)) and sodium nitrate (NaNO).\n\n\n"}
{"id": "19421320", "url": "https://en.wikipedia.org/wiki?curid=19421320", "title": "Ancient and Primeval Beech Forests of the Carpathians and Other Regions of Europe", "text": "Ancient and Primeval Beech Forests of the Carpathians and Other Regions of Europe\n\nAncient and Primeval Beech Forests of the Carpathians and Other Regions of Europe is a transnational composite nature UNESCO World Heritage site, encompassing forests in 12 European countries.\n\nThe Primeval Beech Forests of the Carpathians include ten separate massifs located along the long axis from the Rakhiv mountains and Chornohora ridge in Ukraine over the Poloniny Ridge (Slovakia) to the Vihorlat Mountains in Slovakia. The Ancient Beech Forests of Germany include five locations, cover 4,391 hectares and were added in 2011.\n\nThe Carpathian site covers a total area of , out of which only are part of the actual preserved area, while the rest is considered a \"buffer zone\". Primeval Beech Forests of the Carpathians cover areas of Zakarpattia and Prešov Regions. Over 70% of the site is located in Ukraine. The area includes two national parks, and some habitat controlled areas, mostly in Slovakia. Both national parks, along with a neighboring area in Poland, compose a separate biosphere reserve, the East Carpathian Biosphere Reserve. Besides Havešová, Rožok, and Stužica (all of them located in Bukovské vrchy), there is a fourth component situated in Slovakia, named Kyjovský prales of Vihorlat. Ukrainian locations include Chornohora, Kuziy-Trybushany, Maramarosh, Stuzhytsia–Uzhok, Svydovets, and Uholka–Shyrikyi Luh. Only a few of the ten components are accessible to visitors. Stužica is the only one of three locations in Bukovské vrchy (Slovakia) with available hiking trails. In 2017, UNESCO extended the site, adding forests in Albania, Austria, Belgium, Bulgaria, Croatia, Italy, Romania, Slovenia, and Spain.\n\nThe last intact virgin forest in the temperate latitudes of Europe is to be found in the Carpathians. Trees can live to a hundred years old in these forests, providing an important habitat for organisms such as mushrooms, moss, lichen, insects, rare birds (e.g. capercaillie and black grouse) and mammals (e.g. bats, brown bear, wolf and lynx). Large parts of the forest in the Romanian part of the Carpathians have been lost due to deforestation. The pressure on timber as a resource may increase due to international demand and European companies may start large-scale felling in neighbouring Ukraine. Currently unprotected areas of virgin forest can be permanently preserved in the Ukrainian Carpathians by expanding and reinforcing conservation areas. In the Ukrainian Carpathians there are nine national parks and two biosphere reserves. There is a general ban on tree felling in coniferous forest areas above 1,100 metres. If park administrations are shown to work, management of larger, previously unprotected areas of virgin forest to preserve them on a permanent basis, may occur. There are roughly 100,000 additional hectares of forest which could be integrated into the existing conservation areas.\n\nMost of the Slovak components of the World Heritage site are situated in the Poloniny National Park in the easternmost and also the least populated part of the country. The National Park was created on 1 October 1997 with a protected area of 298.05 km² and a buffer zone of 109.73 km².\n\nOn 28 February 2018, several more forests in Serbia, Montenegro and Switzerland were placed on the World Heritage Tentative list as a proposal for the expansion of the Ancient and Primeval Beech Forests of the Carpathians and Other Regions of Europe site. Forests included on the Tentative list are:\n\n\n\n\n"}
{"id": "1151773", "url": "https://en.wikipedia.org/wiki?curid=1151773", "title": "Atra-Hasis", "text": "Atra-Hasis\n\nAtra-Hasis (\"exceedingly wise\") is the protagonist of an 18th-century BC Akkadian epic recorded in various versions on clay tablets. The \"Atra-Hasis\" tablets include both a creation myth and a flood account, which is one of three surviving Babylonian deluge stories. The name \"Atra-Hasis\" also appears on one of the Sumerian king lists as king of Shuruppak in the times before a flood.\n\nThe oldest known copy of the epic tradition concerning Atrahasis can be dated by colophon (scribal identification) to the reign of Hammurabi’s great-grandson, Ammi-Saduqa (1646–1626 BC), but various Old Babylonian fragments exist; it continued to be copied into the first millennium BC. The Atrahasis story also exists in a later fragmentary Assyrian version, having been first rediscovered in the library of Ashurbanipal, but, because of the fragmentary condition of the tablets and ambiguous words, translations had been uncertain. Its fragments were assembled and translated first by George Smith as \"The Chaldean Account of Genesis\"; the name of its hero was corrected to \"Atra-Hasis\" by Heinrich Zimmern in 1899.\n\nIn 1965 Wilfred G. Lambert and A. R. Millard published many additional texts belonging to the epic, including an Old Babylonian copy (written around 1650 BC) which is our most complete surviving recension of the tale. These new texts greatly increased knowledge of the epic and were the basis for Lambert and Millard’s first English translation of the Atrahasis epic in something approaching entirety. A further fragment has been recovered in Ugarit. Walter Burkert traces the model drawn from Atrahasis to a corresponding passage, the division by lots of the air, underworld and sea among Zeus, Hades and Poseidon in the \"Iliad\", in which “a resetting through which the foreign framework still shows”.\n\nIn its most complete surviving version, the Atrahasis epic is written on three tablets in Akkadian, the language of ancient Babylon.\n\nTablet I contains a creation myth about the Sumerian gods Anu, Enlil, and Enki, gods of sky, wind, and water, “when gods were in the ways of men” according to its \"incipit\". Following the Cleromancy (casting of lots), sky is ruled by Anu, earth by Enlil, and the freshwater sea by Enki. Enlil assigned junior divines to do farm labor and maintain the rivers and canals, but after forty years the lesser gods or dingirs rebelled and refused to do strenuous labor. Instead of punishing the rebels, Enki, who is also the kind, wise counselor of the gods, suggested that humans be created to do the work. The mother goddess Mami is assigned the task of creating humans by shaping clay figurines mixed with the flesh and blood of the slain god Geshtu-E, “a god who had intelligence” (his name means “ear” or “wisdom”). All the gods in turn spit upon the clay. After 10 months, a specially-made womb breaks open and humans are born. Tablet I continues with legends about overpopulation and plagues. Atrahasis is mentioned at the end of Tablet I.\n\nTablet II begins with more overpopulation of humans and the god Enlil sending first famine and drought at formulaic intervals of 1200 years to reduce the population. In this epic Enlil is depicted as a cruel, capricious god while Enki is depicted as a kind, helpful god, perhaps because priests of Enki were writing and copying the story. Tablet II is mostly damaged, but ends with Enlil's decision to destroy humankind with a flood and Enki bound by an oath to keep the plan secret.\n\nTablet III of the Atrahasis Epic contains the flood story. This is the part that was adapted in tablet XI of the Epic of Gilgamesh. Tablet III of Atrahasis tells how the god Enki warns the hero Atrahasis (“Extremely Wise”) of Shuruppak, speaking through a reed wall (suggestive of an oracle) to dismantle his house (perhaps to provide a construction site) and build a boat to escape the flood planned by the god Enlil to destroy humankind. The boat is to have a roof “like Apsu” (a subterranean, fresh water realm presided over by the god Enki), upper and lower decks, and to be sealed with bitumen. Atrahasis boards the boat with his family and animals and seals the door. The storm and flood begin. Even the gods are afraid. In tablet III iv, lines 7-9 the words \"river\" and \"riverbank\" are used, which probably mean the Euphrates River, because Atrahasis is listed in WB-62 as a ruler of Shuruppak which was on the Euphrates River.\n\nAfter seven days the flood ends and Atrahasis offers sacrifices to the gods. Enlil is furious with Enki for violating his oath. But Enki denies violating his oath and argues: “I made sure life was preserved.” Enki and Enlil agree on other means for controlling the human population.\n\nA few general histories can be attributed to the Mesopotamian Atrahasis by ancient sources; these should generally be considered mythology but they do give an insight into the possible origins of the character. The Epic of Gilgamesh labels Atrahasis as the son of Ubara-Tutu, king of Shuruppak, on tablet XI, ‘Gilgamesh spoke to Utnapishtim (Atrahasis), the Faraway… O man of Shuruppak, son of Ubara-Tutu’. The Instructions of Shuruppak instead label Atrahasis (under the name Ziusudra) as the son of the eponymous Shuruppak, who himself is labelled as the son of Ubara-Tutu. At this point we are left with two possible fathers: Ubara-Tutu or Shuruppak. Many available tablets comprising The Sumerian King Lists support The Epic of Gilgamesh by omitting Shuruppak as a ruler of Shuruppak. These lists imply an immediate flood after or during the rule of Ubara-Tutu. These lists also make no mention of Atrahasis under any name. However WB-62 lists a different and rather interesting chronology – here Atrahasis is listed as a ruler of Shuruppak and gudug priest, preceded by his father Shuruppak who is in turn preceded by his father Ubara-Tutu. WB-62 would therefore lend support to The Instructions of Shuruppak and is peculiar in that it mentions both Shuruppak and Atrahasis. In any event it seems that Atrahasis was of royal blood; whether he himself ruled and in what way this would affect the chronology is debatable.\n\nThe Epic of Atrahasis provides additional information on the flood and flood hero that is omitted in Gilgamesh XI and other versions of the Ancient Near East flood story. According to Atrahasis III ii.40–47 the flood hero was at a banquet when the storm and flood began: “He invited his people…to a banquet… He sent his family on board. They ate and they drank. But he (Atrahasis) was in and out. He could not sit, could not crouch, for his heart was broken and he was vomiting gall.”\n\nThe flood story in the standard edition of the Epic of Gilgamesh, Chapter XI may have been paraphrased or copied verbatim from a non-extant, intermediate version of the Epic of Atrahasis. But editorial changes were made, some of which had long-term consequences. The sentence quoted above from Atrahasis III iv, lines 6–7: “Like dragonflies they have filled the river.” was changed in Gilgamesh XI line 123 to: “Like the spawn of fishes, they fill the sea.” However, see comments above.\n\nOther editorial changes were made to the Atrahasis text. In the Epic of Gilgamesh, anthropomorphic descriptions of the gods are weakened. For example, Atrahasis OB III, 30–31 “The Anunnaki (the senior gods) [were sitt]ing in thirst and hunger.” was changed in Gilgamesh XI, 113 to “The gods feared the deluge.” Sentences in Atrahasis III iv were omitted in Gilgamesh, e.g. “She was surfeited with grief and thirsted for beer” and “From hunger they were suffering cramp.”\n\n\n"}
{"id": "24757107", "url": "https://en.wikipedia.org/wiki?curid=24757107", "title": "Birds of Western Australia", "text": "Birds of Western Australia\n\nThe Birds of Western Australia is a book first published in 1948 by Patersons Press Ltd in Perth, Western Australia. Its full title originally was A Handbook of the Birds of Western Australia (with the exception of the Kimberley Division), though with the publication of the 5th edition only the shorter form was used. It was authored by Dominic Serventy and Hubert Whittell. It was issued in octavo format (228 x 148 mm) and contains 372 pages bound in blue buckram with a dustjacket illustrated with a painting of Australian pelicans by Harley Webster. It contains a coloured frontispiece of paintings of the heads of \"Meliphaga\" honeyeaters, with numerous black-and-white drawings and maps scattered through the text. The second edition (1951) contained colour plates by Olive Seymour.\n\nThe book covered birds recorded within the Australian state of Western Australia except, as the full title of the first edition indicates, the tropical Kimberley region of its north. It was the first Australian regional ornithological handbook. In the Introduction the authors state:\n”The need for some such Handbook as this one was impressed on the authors by their own early experiences in Western Australian ornithology. Perhaps, however, they flatter themselves unduly for presenting to the bird-loving public a book which they like to feel is one of the type they wished had been available to them when beginning the study of local birds.”\n\nWith regard to the layout of the book, they say:\n”The first two sections deal with the history of Western Australian ornithology and a discussion of the bird geography of the State. Though complete in themselves both are supplementary to the third section, the detailed treatment of the species of birds occurring in our area.”\nThe success of the book was such that, for many years, it was the principal source of information on the birds of the state. Further editions appeared in 1951, 1962, 1967 and 1976, the fifth and final one being published by the University of Western Australia Press, with the length having increased by then to some 490 pages. It was described later in the preface to the state’s next ornithological handbook as:\n”…a landmark in Australian ornithology. Its high standard and concise presentation provided a stimulus for a great deal of ornithological research in this State.”\n\n"}
{"id": "57862836", "url": "https://en.wikipedia.org/wiki?curid=57862836", "title": "Borda (legendary creature)", "text": "Borda (legendary creature)\n\nThe Borda is a legendary creature that belongs to the culture of the Emilia-Romagna and other areas of the Po Valley in Italy.\n\nIt is a sort of witch that appears, blindfolded and horrible, both at night and on foggy days and kills anyone who has the misfortune to meet her. It is a personification of the fear related to swamps and marshlands, and to ponds and canals, invoked by adults to scare children and keep them away from such potentially dangerous places.\n\nThe Borda, known by this name especially in Modenese, is also known as 'Bourda' in Bolognese, 'Bùrda'in Ferrarese, 'Bûrda' or 'Burdâna' in Emelian. The masculine form takes the name of 'Bordón' in Parma, 'Bordö' or 'Bordoeu' in Milan (meaning Ogre), 'Bordò' in Bormiese (with a generally derogatory connotation). In Milanese, as well as in the dialects cremasco and bormiese, the word 'borda' means fog. In bergamese the name has the meaning fog as well as that of paper mask .\n\nSome scholars of local folklore trace the etymology of the term Borda to the root \"bor-\" which can be traced back to Borvo, of celtic mythology, who presided over thermal and spring waters, and would be found, in a vast area united by an ancient celtic presence, in toponyms and terms related to the water element. Examples being: the river Bormida, spa resorts such as Bormio, Bourbon-Lancy, Bourbon-l'Archambault, words in French such as \"brouillard\" and \"brume\" (meaning fog) or \"bourbe\" (slime).\n\nItalian\n\n<br>\n<br>\n<br>\n<br>\n<br>\n\nEmilian-Romagnol\n\n<br>\n<br>\n<br>\n<br>\n<br>\n\nEnglish\n\n\"<br>\n\"<br>\n\"<br>\n\"<br>\n\"<br>\n\nSome lullabies in Romagnole are dedicated to the Borda, which kills children who are not good and do not want to sleep by strangling them with a lasso or a rope. Some scholars point out that this peculiar way of killing can be traced back to the human sacrifices practiced in ancient Germanic cults and would be known by the discovery, in some Danish and British peat bogs, of bodies of people suffocated with a rope tied around their neck and then drowned, such as the Tollund Man .\n\nThe legend of Borda is central to the novel \"Mal'aria\" by Eraldo Baldini, from which the \"Mal'aria ()\" TV miniseries was created.\n\n\n\n \n"}
{"id": "22155407", "url": "https://en.wikipedia.org/wiki?curid=22155407", "title": "Cape Stolbchaty", "text": "Cape Stolbchaty\n\nCape Stolbchaty is the cape at east shore of Kunashir Island, and place in the state of Sakhalin, Russia is famous for its columnar basalt formations, which are strikingly similar to the Giant's Causeway in County Antrim in Northern Ireland.\n\n\n"}
{"id": "31218363", "url": "https://en.wikipedia.org/wiki?curid=31218363", "title": "Dion-Olympos", "text": "Dion-Olympos\n\nDion-Olympos (, \"Díon-Ólympos\") is a municipality in the Pieria regional unit, Central Macedonia, Greece. The seat of the municipality is the town Litochoro. The municipality has an area of 495.314 km.\n\nThe municipality Dion-Olympos was formed at the 2011 local government reform by the merger of the following 3 former municipalities, that became municipal units:\n"}
{"id": "1641211", "url": "https://en.wikipedia.org/wiki?curid=1641211", "title": "Earth Prime", "text": "Earth Prime\n\nEarth Prime (or Earth-Prime) is a term sometimes used in works of speculative fiction, most notably in DC Comics, involving parallel universes or a multiverse, and refers either to the universe containing \"our\" Earth, or to a parallel world with a bare minimum of divergence points from Earth as we know it — often the absence or near-absence of metahumans, or with their existence confined to fictional narratives like comics. The \"Earth Prime\" of a given fictional setting may or may not have an intrinsic value to or vital connection to the other Earths it exists alongside (although it appears to be the case that such Prime Earths — and sometimes the 'central universes' in which those Prime Earths exist as well — are portrayed in fiction to be vital to the existence of the other Earths).\n\nIn the DC Multiverse, Earth-Prime is the true Earth from which all the other worlds within the multiverse originate, the actual reality where the readers live, DC Comics operates as a publisher, and all superheroes are fictional. However, Earth Prime became an alternate reality in its first appearance in \"The Flash\" #179 (May, 1968), when the Flash accidentally travels there from Earth-One by being pushed by a creature called \"The Nok\". The Flash, stranded, contacts DC Comics editor Julius Schwartz, who helps him construct a cosmic treadmill to return to Earth-One. Eventually it was stated that the writers of DC Comics of Earth Prime subconsciously base their stories on the adventures of the heroes on Earth-One and Earth-Two.\n\nIn \"The Flash\" #228 (July/Aug 1974), Earth Prime's Cary Bates travels to Earth-One, where he discovers that the stories he writes are not only based on events on Earth-One, but can actually influence these events as well. This power turns for the worse in \"Justice League of America\" #123 (October 1975), when Bates is accidentally transported to Earth-Two. The interdimensional trip temporarily turns Bates into a supervillain, and he quickly kills the Justice Society of America. Luckily fellow DC writer Elliot S. Maggin, with the help of the Justice League and the Spectre, is able to restore matters on both Earths in \"Justice League of America\" #124 (November 1975).\n\nThe first superhero is Ultraa, introduced in \"Justice League of America\" #153. Like Superman, Ultraa was the sole survivor of a destroyed alien world, rocketed to Earth-Prime as a baby. After his first encounter with the Justice League, Ultraa decided Earth-Prime was not ready for superheroes and relocated to Earth-One. Post-Crisis, when there was no longer an Earth-Prime or greater multiverse, Ultraa was retconned into being from the planet Almerac, homeworld of Maxima.\n\nThe second superhero (later villain) is Superboy-Prime, the true Superman from which all the other Supermen originate. He first appeared in \"DC Comics Presents\" #87 (Nov. 1985). This Superboy's powers first manifested around the time of the passage of Halley's Comet in 1985. Just after manifesting his powers, Superboy-Prime met Earth-One's Superman. Very soon thereafter Earth-Prime was destroyed in Crisis on Infinite Earths #10. Superboy-Prime escaped his universe's destruction, and later joined Earth-Two's Superman, Earth-Two's Lois Lane-Kent, and Earth-Three's Alexander Luthor in a \"paradise dimension\".\n\nSuperboy Prime possesses powers far exceeding those of the modern \"New-Earth\" Superman (Kal-El).\n\nIn issue #6 of the \"Infinite Crisis\" mini-series, a now anti-heroic Superboy-Prime convinced Alexander Luthor that Earth-Prime was the ideal world and urged him to draw his inspiration for making a new Earth from Earth-Prime. Luthor began searching through the myriad Earths for Earth-Prime and, in a metatextual nod to Earth Prime's original status as the keystone Earth, looks directly at the readers and reaches out towards them to grab our reality.\n\nIn 2004, DC revisited the Earth-Prime concept in the miniseries \"\". Writer Kurt Busiek states in the introduction to the collected volume of the series that the original appearance of Superboy-Prime was the inspiration for his graphic novel.\n\nIn 2008 the Final Crisis tie in series \"Legion of Three Worlds\", makes various references to Earth-Prime, while Superboy-Prime is still looking to make his \"Perfect Earth\". He starts by rebuilding the Legion of Super-Villains to fight Superman and the three versions of the Legion of Super-Heroes. During the battle, the 2004 team's Element Lad created Kryptonite that unexpectedly affected Superboy-Prime. The Kryptonite of New Earth had no effect on Superman (Kal-L) and Prime during \"Infinite Crisis.\"\n\nAt the end of the mini series, it's revealed that Earth-Prime has been reborn and Superboy-Prime was returned there. It was also revealed that the Threeboot Legion are from Earth-Prime's future. The current status of Superboy-Prime after the events of Flashpoint remains unclear, but he has not reappeared since 2011. The character may have been obliterated by the continuity change and shifts within the multiverse that occurred after that core DC event.\n\nIn September 2011, The New 52 rebooted DC's continuity. In this new timeline, Earth-33 is introduced in Grant Morrison's \"The Multiversity\" series, as the additional designation for Earth-Prime. This Earth continues the tradition of having minimal superhero activity – in this case, the minds of Earth-33's comic book readers have empowered a superhero named Ultra Comics. Ultra is the only metahuman on that world, fighting the encroachment of the \"Gentry\" (the series' lead villains) by confining their presence on 'our' world to the pages of an 'entrapment' comic book built around the title character.\n\nIn the fictional Marvel Universe, the 'Earth Prime' of that setting is designated by extradimensional cartographers as Earth-1218, where real-life readers buy Marvel Comics. On some occasions, various characters of the Marvel Universe, looking for their version of God, encounter 'real world' figures such as Jack Kirby and Stan Lee. Yet other characters (such as She-Hulk and Deadpool) are capable of breaking the fourth wall, addressing the readers directly. Still others, such as the Earth's Watcher, Uatu, is possessed of the ability to see \"all\" alternate Earths in the Marvel Universe setting at will, including the real one in which he and all other beings are nothing more than fictional characters (in some early issues of \"What If?\", the Watcher actually addressed the reader by showing him which issues of which \"comics\" the past exploits of a given character could be found in). Having a similar name, \"Prime Earth\" is the new designation of \"Earth-616\".\n\nEarth Prime, as used in the television show \"Sliders\", is the name of the alternate Earth where the four original sliders (Quinn Mallory, Wade Welles, Rembrandt Brown, and Maximillian Arturo) started their journey. This Earth was the same as ours until 1997 or 1998, when the Kromaggs slid onto Earth Prime and conquered it.\n\nMuch of the action in the last few books of Stephen King's \"Dark Tower\" series takes place in \"the keystone world\", essentially the Earth Prime concept under a different name, complete with appearances by King himself as a character.\n\nThough not using the term \"Earth Prime\", Roger Zelazny's \"The Chronicles of Amber\" fantasy series features a similar concept. In the Amber stories, Amber is the only true world; all others, including our Earth, are but \"shadows\" of the tension between it and Chaos.\n\nIn the Teenage Mutant Ninja Turtles made-for-TV film, \"Turtles Forever\", Ch'rell (or 2003 series's version of The Shredder), took the technodrome from his 1987 series counterpart and Krang and upgraded it with Utrom technology. He later decided to destroy Turtle-Prime to destroy the multiverse. He was stopped by the three teams of turtles from the Prime, 1987, and 2003 universes. Although the true \"Earth Prime\" of the movie would be that inhabited by Kevin Eastman and Peter Laird in the closing shot, shown putting the finishing touches on the first issue of the Teenage Mutant Ninja Turtles comic book.\n\n"}
{"id": "10081897", "url": "https://en.wikipedia.org/wiki?curid=10081897", "title": "Effects of tropical cyclones", "text": "Effects of tropical cyclones\n\nThe main effects of tropical cyclones include heavy rain, strong wind, large storm surges near landfall, and tornadoes. The destruction from a tropical cyclone, such as a hurricane or tropical storm, depends mainly on its intensity, its size, and its location. Tropical cyclones act to remove forest canopy as well as change the landscape near coastal areas, by moving and reshaping sand dunes and causing extensive erosion along the coast. Even well inland, heavy rainfall can lead to mudslides and landslides in mountainous areas. Their effects can be sensed over time by studying the concentration of the Oxygen-18 isotope within caves within the vicinity of cyclones' paths.\n\nAfter the cyclone has passed, devastation often continues. Fallen trees can block roads and delay rescues, with medical supplies, or slow the repairs to electrical lines, telephone towers or water pipes, which could put other lives at risk for days or months. Standing water can cause the spread of disease, and transportation or communication infrastructure may have been destroyed, hampering clean-up and rescue efforts. Nearly two million people have died globally due to tropical cyclones. Despite their devastating effects, tropical cyclones are also beneficial, by potentially bringing rain to dry areas and moving heat from the tropics poleward. Out at sea, ships take advantage of their known characteristics by navigating through their weaker, western half.\n\nPST hazards. PST is an acronym standing for Primary, Secondary and Tertiary. A primary hazard involves destructive winds, debris and storm surge. Secondary hazards include flooding and fires. Tertiary hazards include spikes in prices of food and other necessities, as well as long term hazards like water-borne diseases.\n\nA mature tropical cyclone can release heat at a rate upwards of 6x10 watts. Tropical cyclones on the open sea cause large waves, heavy rain, and high winds, disrupting international shipping and, at times, causing shipwrecks. Generally, after its passage, a tropical cyclone stirs up ocean water, lowering sea surface temperatures behind it. This cool wake can cause the region to be less favorable for a subsequent tropical cyclone. On rare occasions, tropical cyclones may actually do the opposite. 2005's Hurricane Dennis blew warm water behind it, contributing to the unprecedented intensity of Hurricane Emily, which followed it closely. Hurricanes help to maintain the global heat balance by moving warm, moist tropical air to the mid-latitudes and polar regions and also by influencing ocean heat transport. Were it not for the movement of heat poleward (through other means as well as hurricanes), the tropical regions would be unbearably hot.\n\nShipwrecks are common with the passage of strong tropical cyclones. Such shipwrecks can change the course of history, as well as influence art and literature. A hurricane led to a victory of the Spanish over the French for control of Fort Caroline, and ultimately the Atlantic coast of North America, in 1565. The \"Sea Venture\" was wrecked near Bermuda in 1609 which led to the colonization of Bermuda and provided the inspiration for Shakespeare's \"The Tempest\".\n\nMariners have a way to safely navigate around tropical cyclones. They split tropical cyclones in two, based on their direction of motion, and maneuver to avoid the right segment of the cyclone in the Northern Hemisphere (the left segment in the Southern Hemisphere). Sailors term the right side the dangerous semicircle since the heaviest rain and strongest winds and seas were located in this half of the storm, as the cyclone's translation speed and its rotational wind are additive. The other half of the tropical cyclone is called the navigable semicircle since weather conditions are lessened (subtractive) in this portion of the storm (but are still potentially quite hazardous). The rules of thumb for ship travel when a tropical cyclone is in their vicinity are to avoid them if at all possible and do not cross their forecast path (crossing the T). Those traveling through the dangerous semicircle are advised to keep to the true wind on the starboard bow and make as much headway as possible. Ships moving through the navigable semicircle are advised to keep the true wind on the starboard quarter while making as much headway as possible.\n\nThe most significant effects of a tropical cyclone occur when they cross coastlines, making landfall then it destroys ships and lives.\n\nStrong winds can damage or destroy vehicles, buildings, bridges, trees, personal property and other outside objects, turning loose debris into deadly flying projectiles. In the United States, major hurricanes comprise just 21% of all land-falling tropical cyclones, but account for 83% of all damage. Tropical cyclones often knock out power to tens or hundreds of thousands of people, preventing vital communication and hampering rescue efforts. Tropical cyclones often destroy key bridges, overpasses, and roads, complicating efforts to transport food, clean water, and medicine to the areas that need it. Furthermore, the damage caused by tropical cyclones to buildings and dwellings can result in economic damage to a region, and to a diaspora of the population of the region.\n\nThe storm surge, or the increase in sea level due to the cyclone, is typically the worst effect from landfalling tropical cyclones, historically resulting in 90% of tropical cyclone deaths. The relatively quick surge in sea level can move miles/kilometers inland, flooding homes and cutting off escape routes. The storm surges and winds of hurricanes may be destructive to human-made structures, but they also stir up the waters of coastal estuaries, which are typically important fish-breeding locales.\n\nThe thunderstorm activity in a tropical cyclone produces intense rainfall, potentially resulting in flooding, mudslides, and landslides. Inland areas are particularly vulnerable to freshwater flooding, due to residents not preparing adequately. Heavy inland rainfall eventually flows into coastal estuaries, damaging marine life in coastal estuaries. The wet environment in the aftermath of a tropical cyclone, combined with the destruction of sanitation facilities and a warm tropical climate, can induce epidemics of disease which claim lives long after the storm passes. Infections of cuts and bruises can be greatly amplified by wading in sewage-polluted water. Large areas of standing water caused by flooding also contribute to mosquito-borne illnesses. Furthermore, crowded evacuees in shelters increase the risk of disease propagation.\nAlthough cyclones take an enormous toll in lives and personal property, they may be important factors in the precipitation regimes of places they affect and bring much-needed precipitation to otherwise dry regions. Hurricanes in the eastern north Pacific often supply moisture to the Southwestern United States and parts of Mexico. Japan receives over half of its rainfall from typhoons. Hurricane Camille (1969) averted drought conditions and ended water deficits along much of its path, though it also killed 259 people and caused $9.14 billion (2005 USD) in damage.\n\nOn the other hand, the occurrence of tropical cyclones can cause tremendous variability in rainfall over the areas they affect: indeed cyclones are the primary cause of the most extreme rainfall variability in the world, as observed in places such as Onslow and Port Hedland in subtropical Australia where the annual rainfall can range from practically nothing with no cyclones to over if cyclones are abundant.\n\nThe broad rotation of a land-falling tropical cyclone often spawns tornadoes, particularly in their right front quadrant. While these tornadoes are normally not as strong as their non-tropical counterparts, heavy damage or loss of life can still occur. Tornadoes can also be spawned\nas a result of eyewall mesovortices, which persist until landfall.\n\nDuring the last two centuries, tropical cyclones have been responsible for the deaths of about 1.9 million people worldwide. It is estimated that 10,000 people per year perish due to tropical cyclones. The deadliest tropical cyclone was the 1970 Bhola cyclone, which had a death toll of anywhere from 300,000 to 500,000 lives.\n\nBefore Hurricane Katrina, which combined storm-tide flooding with levee-breach (dam) flooding from Lake Ponchartrain, the average death rate for tropical cyclones in the United States had been decreasing. The main cause of storm-related fatalities had been shifting away from storm surge and towards freshwater (rain) flooding. However, the median death rate per storm had increased through 1979, with a lull during the 1980–1995 period. This was due to greater numbers of people moving to the coastal margins and into harm's way. Despite advances in warning strategies and reduction in track forecast error, this increase in fatalities is expected to continue for as long as people migrate towards the shore.\n\nWhile tropical cyclones may well seriously damage settlement, total destruction encourages rebuilding. For example, the destruction wrought by Hurricane Camille on the Gulf coast spurred redevelopment, greatly increasing local property values. Research indicates that the typical hurricane strike raises real house prices by a few percent for a number of years, with a maximum effect of between 3 percent to 4 percent three years after occurrence. However, disaster response officials point out that redevelopment encourages more people to live in clearly dangerous areas subject to future deadly storms. Hurricane Katrina is the most obvious example, as it devastated the region that had been revitalized after Hurricane Camille. Many former residents and businesses do relocate to inland areas away from the threat of future hurricanes as well.\n\nIn isolated areas with small populations, tropical cyclones may cause enough casualties to contribute to the founder's effect as survivors repopulate their place. For example, around 1775, a typhoon hit Pingelap Atoll, and in combination with a subsequent famine, reduced the island's population to a low level. Several generations after the disaster, as many as 10% of Pingelapese have a genetic form of color-blindness called achromatopsia. This is due to one of the survivors of the depopulation brought on by the typhoon having a mutated gene, which the population bottleneck caused to be at a higher-than-usual level in succeeding generations.\n\nTropical cyclones reshape the geology near the coast by eroding sand from the beach as well as offshore, rearranging coral, and changing dune configuration onshore. Their rain water gets absorbed into stalagmites within caves, creating a record of past tropical cyclone impacts.\n\nWaves and storm surges accompanying tropical cyclones erode undersea sands, erode shell deposits, break off corals from near shore reefs in their paths, and carry all this detritus landwards in a rolling wave of material that is deposited onshore, above highest astronomical tide as a ridge of sand, shell and coral. For example, each severe tropical cyclone (i.e. Category 4–5 on the Saffir-Simpson scale) crossing northeast Australia's tropical coastline since the last significant change in sea levels (about 5,000 years ago) has 'emplaced' such ridges within the coastal landscape forming, in some places, series of ridges and a geomorphological record of highest magnitude cyclones hitting the coast over 3,000–5,000 years.\n\nEyewitness accounts verify ridges of this kind are formed by severe tropical cyclones and two clear examples cited are the long, wide, high coral shingle ridge deposited on Funafuti Atoll (Central South Pacific) by Cyclone Bebe in October 1972, and the large coral shingle ridge deposited on Jaluit Atoll (Marshall Islands) by Typhoon Ophelia in January 1958. In tropical northeast Australia, an intense tropical cyclone hit in March 1918 (crossing over the town of Innisfail), at which time there were eyewitness accounts of a to high ridge of pumice being deposited by that cyclone's surge as it crossed the coast.).\n\nWhen tropical cyclones cross land, thin layers of calcium carbonate of 'light' composition (i.e. unusual isotopic ratio of Oxygen-18 and Oxygen-16) are deposited onto stalagmites in limestone caves up to from the cyclone's path.\n\nAs the cloud tops of tropical cyclones are high and cold, and their air is humid – their rainwater is 'lighter'. In other words, the rainfall contains significantly higher quantities of unevaporated Oxygen-18 than other tropical rainfall. The isotopically lighter rainwater soaks into the ground, percolates down into caves, and, within a couple of weeks, Oxygen-18 transfers from the water into calcium carbonate, before being deposited in thin layers or 'rings' within stalagmites. A succession of such events created within stalagmites maintain a record of cyclones tracking within a radius of caves going back centuries, millennia, or even millions of years.\n\nAt Actun Tunichil Muknal cave in central Belize, researchers drilling stalagmites with a computer- controlled dental drill accurately identified and verified evidence of isotopically light rainfall for 11 tropical cyclones occurring over a 23-year period (1978–2001).\n\nAt the Chillagoe limestone caves in northeast Australia ( inland from Cairns) researchers identified and matched evidence of isotopically light rainfall with 100 years of cyclone records, and from this have created a record of tropical cyclones from 2004 back to 1200 A.D. (an 800-year record).\n\nSevere tropical cyclones defoliate tropical forest canopy trees, remove vines and epiphytes from the trees, break tree crown stems, and cause tree falls. The degree of damage they do along their paths, at a landscape level (i.e. > ), can be catastrophic yet variable and patchy. Trees will break at , regardless of size and type. Stripping trees and scattering forest debris also provides fuel for wildfires, such as a blaze that lasted three months in 1989 and burned of forest that had been stripped by Hurricane Gilbert.\n\n\nAssessments of cyclone damage done to tropical rainforest landscapes in northeast Australia, have produced the following typology for describing and 'mapping' the variable impacts they have along their paths, as follows:\n\n\n"}
{"id": "52400224", "url": "https://en.wikipedia.org/wiki?curid=52400224", "title": "Eisengarn", "text": "Eisengarn\n\nEisengarn, meaning \"iron yarn\" in English, is a light-reflecting, strong, waxed-cotton thread. It was invented and manufactured in Germany in the mid-19th century, but is now most well known for its use in cloth woven for the tubular-steel chairs designed by Marcel Breuer while he was a teacher at the Bauhaus design school.\n\nThe yarn is also known as Glanzgarn ('gloss' or 'glazed' yarn). \n\nDespite the name, there is no iron in \"eisengarn\". The name refers to its strength and metallic shine. It is made by soaking cotton threads in a starch and paraffin wax solution. The threads are dried and then stretched and polished by steel rollers and brushes. The end result of the process is a lustrous, tear-resistant yarn which is extremely hardwearing.\n\nThe \"eisengarn\" manufacturing process was invented in the mid-19th century in a factory in Barmen, now part of the city of Wuppertal, east of the river Rhine. \n\nIt was used as a sewing thread and for making lace, shoe laces, hat strings, ribbons, lining materials and in the cable industry.\n\nThe manufacture of the yarn gave a considerable boost to the textile industry of Barmen and the surrounding region. By 1875, the Wuppertal company Barthels & Feldhoff employed more than 300 people in eisengarn production.\n\nIn 1927 the weaver and textile designer Margaretha Reichardt (1907–1984), then a student at the Bauhaus design school, experimented and improved the quality of the thread and developed cloth and strapping material made from \"eisengarn\" for use on Marcel Breuer's tubular steel chairs, such as the Wassily Chair. \n\nLight-weight tubular steel seating was also used in aircraft seating in the 1930s and Reichardt's improved version of \"eisengarn\" was used as a covering for the seats.\n\nA more prosaic use for the strong eisengarn thread was, and still is, for making colourful string shopping bags, which were popular in the former East Germany, and are now an Ostalgie item. When the bag is not in use, the nature of the eisengarn yarn enables it to be compressed so that it takes up very little space.\n\n"}
{"id": "23642688", "url": "https://en.wikipedia.org/wiki?curid=23642688", "title": "Energy in Gabon", "text": "Energy in Gabon\n\nEnergy in Gabon is an industry with plenty of potential.\n\nGabon, a former OPEC member (1975–1994) that rejoined in 2016, is the sixth-largest oil producer in sub-Saharan Africa, and has the region's fifth-largest oil reserves. Oil prospecting began in 1931. Deposits were found on the coast or off shore in the vicinity of Libreville, northwestern Gabon and Port-Gentil, along the coast and in the southwestern part of the country. Larger deposits were found in the south. Oil from the northwest is channeled by pipeline to Cape Lopez, where there are loading facilities for export. \nAdditional deposits were found on Mandji Island in 1962. The Rabi Kounga oil field, operated by Shell Gabon, is Gabon's largest oil field. In 1997, it produced a peak of . As of November 2004, it was producing .\n\nThe first national oil company was the Société Nationale Petrolière Gabonaise but it was disbanded in 1987. The government of Gabon controls all petroleum and mineral rights within the state. In 2011 a presidential decree created the Gabon Oil Company (GOC). This new entity works in partnership with international companies operating in Gabon and operates two fields: Obangue and Remboue.\n\nAlthough Gabon's proven petroleum reserves rose from in 1996 to in 2004, the government is concerned about long-term depletion of resources. Total production of crude oil fell from a peak of day to an estimated in 2003. Gabon's production goes primarily to Argentina, Brazil, France, the United States, and, more recently, Taiwan. Net oil exports in 2003 are estimated at 289,680 barrels per day.\n\nAs of January 2004, reserves of natural gas reserves estimated at , by the Oil & Gas Journal. Production and consumption of natural gas in 2002 were estimated at , each. Gross output stood at in 2002, of which was flared or vented off, and was reinjected.\n\nIn 2002 there were hydroelectric stations at the Kinguélé and Tchimbélé dams on the Mbei River and at the Petite Poubara Dam, near Makokou on the Ogooué. Production and distribution of electricity are maintained by the Energy and Water Company of Gabon (SEEG), which was formed in 1963 and incorporates a number of smaller private and quasi-public entities. In 2002, electric power output totalled an estimated 1.16 TWh, with capacity estimated as of January 2002 at 406 MW. Consumption of electricity was 1.275 TWh in 2002. Natural gas is the principal fuel for the thermal plants. Hydropower accounts for 11% of Gabon's electric power consumption in 2013.\n"}
{"id": "24224338", "url": "https://en.wikipedia.org/wiki?curid=24224338", "title": "Expocode", "text": "Expocode\n\nEXPOCODE, or the \"expedition code\", is a unique alphanumeric identifier defined by the National Oceanographic Data Center (NODC) of the US. The code defines a standard nomenclature for cruise labels of research vessels and intends to avoid confusion in oceanographic data management.\n\nThe code was used by international projects (WOCE, CarboOcean) and is considered a de facto standard in the international hydrographic community beginning with the Climate Variability Program (CLIVAR) and the EU-Project Eurofleets.\n\nThe format of an expocode for an oceanographic cruise is defined in the format NODCYYYYMMDD where:\n\nExample for a cruise of the US research vessel \"Nathaniel B. Palmer\", starting on 2011-02-19: 320620110219 (Code of US = 32, code of Palmer = 06, date when cruise starts 2011-02-19)\n\n"}
{"id": "27195467", "url": "https://en.wikipedia.org/wiki?curid=27195467", "title": "Facultative parasite", "text": "Facultative parasite\n\nA facultative parasite is an organism that may resort to parasitic activity, but does not absolutely rely on any host for completion of its life cycle.\n\nExamples of facultative parasitism occur among many species of fungi, such as family members of the genus \"Armillaria\". \"Armillaria\" species do parasitise living trees, but if the tree dies, whether as a consequence of the fungal infection or not, the fungus continues to eat the wood without further need for parasitic activity; some species even can ingest dead wood without any parasitic activity at all. As such, although they also are important ecological agents in the process of nutrient recycling by microbial decomposition, the fungi become pests in their role as destructive agents of wood rot.\n\nSimilarly, green plants in genera such as \"Rhinanthus\" and Colpoon can grow independently of any host, but they also act opportunistically as facultative root parasites of neighboring green plants.\n\nAmong animals, facultatively kleptoparasitic species generally can survive by hunting or scavenging for themselves, but it often is more profitable for them to rob food from other animals kleptoparasitically, whether their hosts are of the same species or not. Such behavior occurs in lions and hyaenas for example, and also among insects such as \"Jackal flies\" in the family Milichiidae.\n\nMore intimately, normally free-living microbes may opportunistically live as facultative parasites in other organisms.\n\nAn example of this in humans is Naegleria fowleri. As a rule this amoeboid species is a free-living predator on microbes, but occasionally it successfully infects humans as a facultative internal parasite.\n\n"}
{"id": "55763499", "url": "https://en.wikipedia.org/wiki?curid=55763499", "title": "Fire and carbon cycling in boreal forests", "text": "Fire and carbon cycling in boreal forests\n\nTerrestrial ecosystems found in the boreal (or taiga) regions of North America and Eurasia cover less than 17% of the earth's land surface, yet contain more than 30% of all carbon present in the terrestrial biome. In terms of carbon storage, the boreal region consists of three ecosystems: boreal forest, peatland, and tundra. Vast areas of the globe and are contributing greatly to atmospheric carbon release due to increased temperature and fire hazard. High northern latitudes will experience the most significant increase in warming on the planet as a result of increased atmospheric greenhouse gases thus placing in jeopardy the carbon sink in these areas. In addition to the release of carbon through the melting of permafrost, high intensity wildfires will become more common and thus contribute to the release of stored carbon. This means that the boreal forest and its fire regime is becoming an increasingly more significant factor in determining the global carbon budget. \n\nBoreal forests are also important economic factors in Russia and Canada specifically, and the uncertainty of fire patterns in the future as a result of climate change is a major consideration in forest management plans. A decrease in allowed timber harvest could be a solution to long term uncertainty of fire cycles. \n\nAlthough temperate and tropical forests in total cover twice as much land as boreal forest, boreal forest contains 20% more carbon than the other two combined. Boreal forests are susceptible to global warming because the ice/snow albedo feedback is significantly influenced by surface temperature, so fire induced changes in surface albedo and infrared emissivity are more significant than in the tropics . \n\nBoreal forest fires contribute greatly to greenhouse gas presence in the atmosphere. Large boreal fires produce enough energy to produce convective smoke columns that can break into the troposphere and occasionally penetrate across the tropopause. In addition, the cold temperature in boreal regions result in low levels of water vapor. This low level of water vapor combined with low solar radiation results in very low photochemical production of the OH radical, which is a chemical that controls the atmospheric lifetime of most tropospheric gases. Therefore, the greenhouse gas emission in boreal forest fires will have prolonged lifetimes over the forest. \n\nThe fire regimes of boreal forest in Canada and in Russia are distinct. In Russia, the climate is drier and the majority of fires are human caused. This means that there are more frequent fires of lower intensity than in Canada and that most carbon output as a result of fire is in Russia. Forestry practices in Russia involve the use of heavy machinery and large-scale clear-cuts, leading to the alteration of fuel complexes. This practice is reportedly causing areas to degrade into grass steppes, rather that regenerate as new forest. This may result in the shorting of fire return intervals. Industrial practices in Russia also create additional fire hazards (severe damages in the Russian Federation affect about 9 million ha). Radioactive contamination on an area of about 7 million ha creates a fire hazard because fire can redistribute radionuclides.\n\nThe majority of boreal forest fires in Canada are started by lighting. Subsequently, there are fewer fires on average in Canada but a much higher frequency of high intensity crown fire than Russia with a crown fire rate of 57% in Canada as opposed to 6% in Russia. Natural fire rotation across Canadian and Alaskan boreal forests is one to several centuries. \n\nFire indirectly plays a role in the exchange of carbon between terrestrial surface and the atmosphere by regulating soil and moisture regimes, including plant succession, photosynthesis, and soil microbial processes. Soil in boreal regions is a significant global carbon sink; boreal forest soil holds 200 Gt of carbon while boreal peatlands hold 400 Gt of carbon. Northernmost permafrost regions contain 10,355 ± 150 Pg of soil organic carbon (SOC) in the top 0-3 m and 21% of this carbon is in the soil organic layer (SOL) pool found in the top 30 cm of the ground layer. \n\nThe depth of the organic soil layer is one of the controls on permafrost, leading to a generalization of two domains in boreal forest: thick soil layer and thin soil layer. Thick organic soil insulates the subsoil from warmer summer temperatures and allows for permafrost to develop. Although permafrost keeps ground moist during winter, during summer months upper organic soil horizons will become dessicated. As average temperatures increase, Permafrost is melting at a faster rate and, correspondingly, the length of the fire season is increasing. When the fire-free interval (FFI) is decreased, the loss of the SOL may result in a domain change to a thin soil layer, leading to less carbon storage in the soil, greater fire vulnerability, and decreased permafrost. In black spruce forests, decreased FFI can ruin successional trajectories by opening the door for deciduous trees and shrubs to invade, which also further increases fire vulnerability.\n\nData regarding carbon storage in the permafrost region as well as fire activity in boreal forests is sparse, which is a significant barrier in determining an accurate carbon budget. An expert assessment indicates that the permafrost region will become a net carbon source by 2100.\n\nA 5 - 10 degree C rise in forest floor temperature after a fire will significantly increase the rate of decomposition for years after the fire occurs, which temporarily turns the soil into a net carbon source (not sink) locally. \n\nFire enhances the biogenic emissions of NO and N20 from soil. \n\n"}
{"id": "16334304", "url": "https://en.wikipedia.org/wiki?curid=16334304", "title": "Homoclinal ridge", "text": "Homoclinal ridge\n\nA homoclinal ridge or strike ridge is a hill or ridge with a moderate, generally between 10° to 30°, sloping backslope. Its backslope is a \"dip slope,\" that conforms with the dip of a resistant stratum or strata, called \"caprock.\" On the other side of the other slope, which is its frontslope, of a homoclinal ridge is a steeper or even cliff-like frontslope (escarpment) that is formed by the outcrop of the caprock. The escarpment cuts through the dipping strata that comprises the homoclinal ridge.\n\nHomoclinal ridges are the expression of regional outcrops of moderately dipping strata, typically sedimentary strata, that consist of alternating beds of hard, well-lithified strata, i.e. sandstone and limestone and weak or loosely cemented strata, i.e. shale, mudstone, and marl. The surface of hard, erosion-resistant rock strata forms the caprock of the backslope (dip-slope) of the homoclinal ridges from which erosion has preferentially stripped any weaker strata. The opposite slope, its frontslope, that forms the front of a homoclinal ridge consists of an escarpment that cuts across the bedding of the strata comprising it. Because of the moderately dipping nature of the strata that forms a homoclinal ridge, a significant shift in horizontal location will take place the landscape is lowered by erosion. Because the slope of a homoclinal ridge dips in the same direction as the sedimentary strata underlying it, the dip angle of this bedding (Ө) can be calculated by v/h= tan(Ө) where v is equal to the vertical distance and h is equal to the horizontal distance perpendicular to the strike of the beds.\n\nCuestas, homoclinal ridges, and hogbacks comprise a sequence of landforms that form a gradational continuum. These landform differ only on the steepness of their backslopes and relative differences in the inclination of their backslopes and frontslopes. These differences depends upon whether the dip of the strata from which they have been eroded are either nearly vertical, moderately dipping, or gently dipping. In general, homoclinal ridges, or strike ridges, are associated with strata that dip between 10° and 30°. The symmetrical ridges that characterize hogbacks develop where the strata dip very steeply at 40° or more. Because they are gradational in nature, the exact angle of the backslope used to define these landforms is arbitrary and can vary in the scientific literature.\n"}
{"id": "1129026", "url": "https://en.wikipedia.org/wiki?curid=1129026", "title": "Hyperon", "text": "Hyperon\n\nIn particle physics, a hyperon is any baryon containing one or more strange quarks, but no charm, bottom, or top quark. This form of matter may exist in a stable form within the core of some neutron stars.\n\nBeing baryons, all hyperons are fermions. That is, they have half-integer spin and obey Fermi–Dirac statistics. Hyperons all interact via the strong nuclear force, making them types of hadron. They are composed of three light quarks, at least one of which is a strange quark, which makes them strange baryons. Hyperons decay weakly with non-conserved parity.\n\nNotes:\nIt takes multiple flavor-changing weak decays for it to decay into a proton or neutron. Murray Gell-Mann's and Yuval Ne'eman's SU(3) model (sometimes called the Eightfold Way) predicted this hyperon's existence, mass and that it will only undergo weak decay processes. Experimental evidence for its existence was discovered in 1964 at Brookhaven National Laboratory. Further examples of its formation and observation using particle accelerators confirmed the SU(3) model.\n\nThe first research into hyperons happened in the 1950s, and spurred physicists on to the creation of an organized classification of particles. Today, research in this area is carried out on data taken at many facilities around the world, including CERN, Fermilab, SLAC, JLAB, Brookhaven National Laboratory, KEK, and others. Physics topics include searches for CP violation, measurements of spin, studies of excited states (commonly referred to as \"spectroscopy\"), and hunts for exotic states such as pentaquarks and dibaryons.\n\n"}
{"id": "32582607", "url": "https://en.wikipedia.org/wiki?curid=32582607", "title": "ISO 50001", "text": "ISO 50001\n\nISO 50001 \"Energy management systems – Requirements with guidance for use\" is a specification created by the International Organization for Standardization (ISO) for an energy management system. The standard specifies the requirements for establishing, implementing, maintaining and improving an energy management system, whose purpose is to enable an organization to follow a systematic approach in achieving continual improvement of energy performance, including energy efficiency, energy security, energy use and consumption. The standard aims to help organizations continually reduce their energy use, and therefore their energy costs and their greenhouse gas emissions.\n\nISO 50001 was originally released by ISO in June 2011 and is suitable for any organization, whatever its size, sector or geographical location. The second edition, ISO 50001:2018 was released in August of 2018.\n\nThe system is modelled after the ISO 9001 Quality Management System and the ISO 14001 Environmental Management System (EMS). Eccleston describes the procedural details of the ISO Energy Management System (EnMS) and compares its procedures with those of the ISO 14001 EMS.\n\nA significant feature in ISO 50001 is the requirement to \"... improve the EnMS and the resulting energy performance\" (clause 4.2.1 c). The other standards mentioned here (ISO 9001 and ISO 14001) both require improvement to the effectiveness of the Management System but not to the quality of the product/service (ISO 9001) or to environmental performance (ISO 14001). It is anticipated that by implementing ISO 9001 and 14001 together an organization would improve quality and environmental performance, but the standards do not currently specify this as a requirement.\n\nISO 50001, therefore, has made a major leap forward in 'raising the bar' by requiring an organization to demonstrate that they have improved their energy performance. There are no quantitative targets specified – an organization chooses its own then creates an action plan to reach the targets. With this structured approach, an organization is more likely to see some tangible financial benefits.\n\nThe main objective of the standard is to improve energy-related performance and energy efficiency continuously and to identify energy reduction opportunities. This systematic approach will help organizations to establish systems and processes.\n\nConsistent energy management helps organizations to realize untapped energy efficiency potential. They will benefit from cost savings and make a significant contribution to environmental and climate protection, for example by the permanent reduction of CO2 emissions.\nThe standard should alert employees and in particular the management level to the immediate and long-term energy management gains that can be made. The organization can discover potential savings and competitive advantages. Furthermore, a huge image boost for the organization can be created.\n\nOrganizations of all types and sizes increasingly want to reduce the amount of energy they consume. This is driven by the need or desire to:\n\nIn tandem, governments increasingly want to reduce the Greenhouse Gas Emissions of their citizens and industries, and are imposing legislative mechanisms to compel carbon reduction more and more frequently.\n\nIn response, a range of energy management standards, specifications and regulations were developed in Australia, China, Denmark, France, Germany, Ireland, Japan, Republic of Korea, Netherlands, Singapore, Sweden, Taiwan, Thailand, New Zealand and the USA.\n\nSubsequently, the European Committee for Standardization (CEN) developed EN 16001:2009 \"Energy management systems. Requirements with guidance for use\" as a first international energy management standard. This was published in July 2009 and withdrawn in April 2012 as it had been superseded by ISO 50001.\n\nThe United Nations Industrial Development Organization (UNIDO) recognized that industry around the world needed to mount an effective response to climate change. It also noted a proliferation of national energy management standards that were emerging as a response to market demand for help with energy efficiency. \nIn April 2007, a UNIDO stakeholders meeting decided to ask ISO to develop an international energy management standard.\n\nISO for its part had identified energy management as one of its top five areas for the development of International Standards and, in 2008, created a project committee, ISO/PC 242, \"Energy management\", to carry out the work.\n\nISO/PC 242 was led by ISO members for the United States (ANSI) and Brazil (ABNT). In addition, its leadership included the ISO members for China (SAC) and the United Kingdom (BSI Group) to ensure that developed and developing economies participated together in the project committee.\n\nExperts from the national standards bodies of 44 ISO member countries participated and another 14 countries sent observers. Development organizations including UNIDO and the World Energy Council (WEC) were also involved.\n\nISO 50001 also drew on existing national and regional energy management codes and standards, including ones developed in China, Denmark, Ireland, Japan, Republic of Korea, Netherlands, Sweden, Thailand, the USA and the European Union.\n\nISO 50001:2011 \"Energy management systems – Requirements with guidance for use\" was published on June 17, 2011.\n\nISO published a revised version of ISO 50001 in 2018. The revision reflects a desire to promote adoption of the standard among small and medium sized enterprises. It also incorporates ISO's \"high level structure\" for use where organizations wish to integrate a number of management system standards together.\n\nThe structure of ISO 50001 is designed according to other ISO management system standards, in particular ISO 9001 (Quality Management Systems) and ISO 14001 (Environmental Management Systems). Since all three management systems standards are based on the PDCA cycle, and now share the same high level structure, ISO 50001 can be integrated easily to these systems.\n\nThere are ten major components to ISO 50001:2018:\n\n\nISO 50001 provides a framework of requirements that help organizations to:\n\n\nISO 50001 focuses on a continual improvement process to achieve the objectives related to the environmental performance of an organization (enterprise, service provider, administration, etc.). The process follows a plan – do – check – act approach (Plan-Do-Check-Act, PDCA):\n\n\nThe overall responsibility for the installed energy management system must be located with the top management. An energy officer and an energy team should be appointed. Furthermore, the organization has to formulate the energy policy in form of a written statement which contains the intent and direction of energy policy. Energy policy must be communicated within the organization. The energy team is the connection between management and employees. In this phase the organization has to identify the significant energy uses and prioritize the opportunities for energy performance improvement.\n\n\nThe stated objectives and processes are now introduced and implemented. Resources are made available and responsibilities determined. Make sure that employees and other participants are aware of and capable of carrying out their energy management responsibilities. The realization of the energy management system starts.\n\n\nAn energy management system requires a process for compliance and valuation of energy-related regulations. Internal audit can help to verify that the energy management system is functioning properly and generating the planned results. The processes are monitored with regard to legal and other requirements (customer requirements, internal policies) as well as to the objectives of the energy management of the organization. The results are documented and reported to top management.\n\n\nThe top management prepares a written valuation based on the internal audit. This document is called the management review. The results will be evaluated on their performance level. If necessary, corrective or preventive actions can be initiated. Energy-relevant processes are optimized and new strategic goals are derived.\n\nCertification proves that the energy management system meets the requirements of ISO 50001. This gives customers, stakeholders, employees and management more confidence that the organization is saving energy. It also helps to ensure that the energy management system is working throughout the organization.\n\nAnother advantage of a certification is its emphasis on continual improvement. The organization will continue to get better at managing its energy. Additional cost savings can be generated over several years. Furthermore, certifying an organization shows your public commitment to energy management.\n\nUKAS, the certification bodies' accreditation scheme in UK, accredits certification bodies to carry out certification of business energy management systems to ISO 50001. In July 2018 there were 15 UK bodies with the necessary accreditation to carry out independent audits and issue Energy Management Systems Certification to ISO 50001.\n\nISO reported that the standard was warmly received by the market when it was first published. To the end of January 2012, around 100 organizations in 26 countries had already achieved certification to ISO 50001. ISO also listed several users who had reported significant early cost savings and benefits.\n\nIn China, Delta Electronics, a provider of power and thermal management solutions, reported reducing power consumption by 10.51 million kWh as compared to the same period in 2010. This is equivalent to a reduction of 10.2 thousand tons of carbon emissions and a saving of CNY 8 million ($1.2m).\n\nIn India, the Dahanu Thermal Power Station in Maharashtra expected to accrue annual savings of about INR 96.4 million ($1.7m) from raised energy efficiency and management.\n\nIn Austria, the municipality of Bad Eisenkappel, with 2,400 inhabitants, expected its consumption of energy to be reduced by nearly 25 per cent, with the main savings achieved by updating the waste water plant and reducing energy consumption by 86 000 kWh, equivalent to €16,000 ($20.7k).\n\nBSI Group published a case study showing that Sheffield Hallam University in the UK reduced its carbon emissions by 11 per cent once it was certified to ISO 50001. This yielded annual savings of over £100,000 ($160.7k). \nIn December 2013, the UK Department of Energy and Climate Change became the first Central Government department to achieve certification against the requirements of ISO 50001, leading by example with the belief that structured energy management will lead to substantial energy reductions and thus mitigate the effects of climate change.\n\nISO has stated that it believes in due course the standard could influence up to 60 per cent of the world’s energy use.\n\nISO 50001 is data driven and focuses on energy performance improvement, while ISO 14001 provides a more qualitative look at all significant environmental impacts of an organization. Both standards can be implemented individually or they can be integrated with each other, or with any other ISO management system standards, such as ISO 9001. \nIf energy is an organization’s most significant environmental impact, ISO 50001 might be more appropriate than ISO 14001. Many organizations will manage energy successfully via ISO 14001, but especially in organizations where energy is a significant cost, ISO 50001 provides a more specific framework that enables organizations to apply a sharper focus to energy efficiency.\n\n\n"}
{"id": "3120985", "url": "https://en.wikipedia.org/wiki?curid=3120985", "title": "Ignacio Maria de Álava y Sáenz de Navarrete", "text": "Ignacio Maria de Álava y Sáenz de Navarrete\n\nIgnacio María de Álava y Sáenz de Navarrete (24 October 1750 – 26 May 1817) was a Spanish naval officer, present at the Battle of Trafalgar.\n\nÁlava joined the Spanish navy in 1766. In his early years, he was involved in fighting the pirates of the North African coast (whom the Spanish navy had been fighting for a long time). In 1781, he commanded the corvette \"San Luis\", which took part in the Spanish blockade of Gibraltar during the American Revolutionary War. He took part in an attack on the floating batteries of Gibraltar, and was involved in the Battle of Cape Spartel on 20 October 1782. Shortly after, he was promoted to \"capitán de navío\" (naval captain), and was transferred to the frigate \"Sabina\".\n\nFrom 1787 to 1790, he was flag captain in the fleet of Admiral Don Juan de Lángara. In 1790, commanding the \"San Francisco de Paula\", he brought relief to the city of Oran, which was besieged by Algerian pirates. In 1792 he was promoted to \"brigadier\" (Commodore), and given command of a squadron in Lángara's fleet. In 1793 and 1794, Álava took part in the campaigns in the Golfe du Lion, part of the French Revolutionary Wars. In 1795, Álava, who had been promoted to \"jefe de esquadra\" (rear admiral) the previous year, was given command of a naval squadron that sailed around the world in order to undertake several missions in the Spanish colonies, for example reorganizing the naval forces in the Philippines. While in the East Indies, he witnessed the British raid on Manila of 1798 and led the combined squadron at the inconclusive Macau Incident of 1799. He would not return to Cadiz until 1803. By then he was a \"teniente general\" (vice admiral).\n\nOn 15 February 1805, Álava was appointed second-in-command of the Spanish fleet in Cadiz, under Admiral Gravina. When Gravina joined the French Mediterranean fleet under Villeneuve for its voyage to the Caribbean, Álava remained as commander of the ships in Cadiz. On 20 August 1805 Gravina and Villeneuve returned, and Cadiz was blockaded by a British fleet under Vice-Admiral Horatio Nelson. On 19 October, the combined French and Spanish fleet left Cadiz, with Álava on board of his flagship, the 112-gun \"Santa Ana\". On 21 October, they met the British fleet and the Battle of Trafalgar ensued.\n\nAlava was severely wounded in the battle, and the \"Santa Ana\" was captured by the British. However, two days later, a squadron jointly under the command of Commodore Cosmao-Kerjulien and Spanish Commodore Enrique MacDonell succeeded in recapturing her and getting her back to Cadiz. After Gravina died of the wounds he had received in the battle, Álava became the commander of the remaining ships in Cadiz. In May 1808, Álava defected to Sevilla, where a junta had formed to oppose the French. After Cadiz had been recaptured by the Spanish, Álava once again became commander of the naval squadron based there. In 1810, Álava became Commander-in-Chief in the Caribbean, based in Havana. He returned to Cadiz in 1813, as its governor. In 1814 he became a member of the Supreme Council of the Spanish Admiralty, and on 24 February 1817 he became Admiral of the Spanish Fleet. He died after only three months in this position.\n\n"}
{"id": "57880", "url": "https://en.wikipedia.org/wiki?curid=57880", "title": "In vitro fertilisation", "text": "In vitro fertilisation\n\nIn vitro fertilisation (IVF) is a process of fertilisation where an egg is combined with sperm outside the body, in vitro (\"in glass\"). The process involves monitoring and stimulating a woman's ovulatory process, removing an ovum or ova (egg or eggs) from the woman's ovaries and letting sperm fertilise them in a liquid in a laboratory. After the fertilised egg (zygote) undergoes embryo culture for 2–6 days, it is implanted in the same or another woman's uterus, with the intention of establishing a successful pregnancy.\n\nIVF is a type of assisted reproductive technology used for infertility treatment and gestational surrogacy. A fertilised egg may be implanted into a surrogate's uterus, and the resulting child is genetically unrelated to the surrogate. Some countries banned or otherwise regulate the availability of IVF treatment, giving rise to fertility tourism. Restrictions on the availability of IVF include costs and age, in order for a woman to carry a healthy pregnancy to term. IVF is generally not used until less invasive or expensive options have failed or been determined unlikely to work.\n\nIn 1978 Louise Brown was the first child successfully born after her mother received IVF treatment. Brown was born as a result of natural-cycle IVF, where no stimulation was made. The procedure took place at Dr Kershaw's Cottage Hospital (now Dr Kershaw's Hospice) in Royton, Oldham, England. Robert G. Edwards was awarded the Nobel Prize in Physiology or Medicine in 2010. The physiologist co-developed the treatment together with Patrick Steptoe and embryologist Jean Purdy but the latter two were not eligible for consideration as they had died and the Nobel Prize is not awarded posthumously.\n\nWith egg donation and IVF, women who are past their reproductive years, have infertile male partners, have idiopathic female-fertility issues, or have reached menopause, can still become pregnant. Adriana Iliescu held the record as the oldest woman to give birth using IVF and donated egg, when she gave birth in 2004 at the age of 66, a record passed in 2006. After the IVF treatment, some couples get pregnant without any fertility treatments. In 2012 it was estimated that five million children had been born worldwide using IVF and other assisted reproduction techniques. \n\nThe term \"In Vitro Fertilization\" is derived from the Latin words \"In Vitro\" and the English word \"Fertilization\". In vitro fertilization is the scientific practice of fusing the male and female gametesto form a zygote. Therefore, the term refers to the medical practice of fusing the male sperm and female ova in a controlled environment such as a petri dish, test tube or a laboratory beaker. However, advances in technology have made it easier to use the petri dishes.\n\nThe Latin term is relevant to the concept of fertilization as it was initially used to denote biological experiments in which physical tissues were cultivated outside the living organisms which they were extracted from. Hence, the In Vitro Fertilization (IVF) concept involves the performing of ovum and sperm fusion outside the female body.\n\nIn Vivo Fertilization is the antonym of the term as it is performed by introducing a sperm cell directly to the egg in the uterus.\n\nIn a broader sense, the IVF is a form of Assisted Reproductive Technology (ART) for individuals grappling with infertility. The first step is to extract the ova from the ovaries which are done using the transvaginal oocyte retrieval method. On the male perspective, semen is extracted in three ways. Firstly, there is the ejaculation through self-stimulation that is effortless for most men. This can be done at home under hygiene conditions. The semen is then deposited directly to a sterilized container. Secondly, there is the Testicular Sperm Extraction method (TESA). This is for men whose semen contain extreme low spermatozoa. Lastly, there is sperm donation method. The semen is usually obtained on the same day as the harvesting of ova.\n\nThe IVF biological procedure is more than just the collection of sperms and ova. The first process is to stimulate the ovaries to release the eggs to the follicles. This process is however not necessary in selected cases as the woman can be in the ideal period. In this case, minimal stimulation is undertaken. Secondly, the embryologist assesses the status of the egg. This practice is followed by incubation to keep the egg alive. Meanwhile, the semen is sorted to retrieve healthy sperms. Thirdly, the IVF process entails controlling of the environment in which the specimens are kept to encourage growth, development, and maturity.\n\nThe IVF procedure also involves the scientific process of embryo culture. In this stage, the sperm is introduced to the egg and fertilization occurs in the culture dish. The duration can range from two to five days. Lastly, the embryo is implanted into the uterus.\n\nThe IVF administration is painless and no sedatives are required. The ultimate success of the ART is dependent on the good quality of sperm and ova, medical condition of donors, and the health status of both the male and female patients.\n\nIVF may be used to overcome female infertility when it is due to problems with the fallopian tubes, making in vivo fertilisation difficult. It can also assist in male infertility, in those cases where there is a defect in sperm quality; in such situations intracytoplasmic sperm injection (ICSI) may be used, where a sperm cell is injected directly into the egg cell. This is used when sperm has difficulty penetrating the egg. In these cases the partner's or a donor's sperm may be used. ICSI is also used when sperm numbers are very low. When indicated, the use of ICSI has been found to increase the success rates of IVF.\n\nAccording to UK's guidelines, IVF treatment is appropriate in cases of unexplained infertility for women who have not conceived after 2 years of regular unprotected sexual intercourse.\n\nIVF success rates are the percentage of all IVF procedures that result in a favourable outcome. Depending on the type of calculation used, this outcome may represent the number of confirmed pregnancies, called the pregnancy rate, or the number of live births, called the live birth rate. The success rate depends on variable factors such as maternal age, cause of infertility, embryo status, reproductive history, and lifestyle factors.\n\nMaternal age: Younger candidates of IVF are more likely to get pregnant. Women older than 41 are more likely to get pregnant with a donor egg.\n\nReproductive history: Women who have been previously pregnant are in many cases more successful with IVF treatments than those who have never been pregnant.\n\nDue to advances in reproductive technology, IVF success rates are substantially higher today than they were just a few years ago.\n\nThe live birth rate is the percentage of all IVF cycles that lead to a live birth. This rate does not include miscarriage or stillbirth; multiple-order births, such as twins and triplets, are counted as one pregnancy. A 2012 summary compiled by the Society for Reproductive Medicine which reports the average IVF success rates in the United States per age group using non-donor eggs compiled the following data:\n\nIn 2006, Canadian clinics reported a live birth rate of 27%. Birth rates in younger patients were slightly higher, with a success rate of 35.3% for those 21 and younger, the youngest group evaluated. Success rates for older patients were also lower and decrease with age, with 37-year-olds at 27.4% and no live births for those older than 48, the oldest group evaluated. Some clinics exceeded these rates, but it is impossible to determine if that is due to superior technique or patient selection, because it is possible to artificially increase success rates by refusing to accept the most difficult patients or by steering them into oocyte donation cycles (which are compiled separately). Further, pregnancy rates can be increased by the placement of several embryos at the risk of increasing the chance for multiples.\n\nThe live birth rates using donor eggs are also given by the SART and include all age groups using either fresh or thawed eggs.\n\nBecause not each IVF cycle that is started will lead to oocyte retrieval or embryo transfer, reports of live birth rates need to specify the denominator, namely IVF cycles started, IVF retrievals, or embryo transfers. The Society for Assisted Reproductive Technology (SART) summarised 2008-9 success rates for US clinics for fresh embryo cycles that did not involve donor eggs and gave live birth rates by the age of the prospective mother, with a peak at 41.3% per cycle started and 47.3% per embryo transfer for patients under 35 years of age.\n\nIVF attempts in multiple cycles result in increased cumulative live birth rates. Depending on the demographic group, one study reported 45% to 53% for three attempts, and 51% to 71% to 80% for six attempts.\n\nPregnancy rate may be defined in various ways. In the United States, the pregnancy rate used by the Society for Assisted Reproductive Technology and the Centers for Disease Control (and appearing in the table in the Success Rates section above) are based on fetal heart motion observed in ultrasound examinations.\n\nThe 2009 summary compiled by the Society for Reproductive Medicine included the following data for the United States:\n\nIn 2006, Canadian clinics reported an average pregnancy rate of 35%. A French study estimated that 66% of patients starting IVF treatment finally succeed in having a child (40% during the IVF treatment at the centre and 26% after IVF discontinuation). Achievement of having a child after IVF discontinuation was mainly due to adoption (46%) or spontaneous pregnancy (42%).\n\nThe main potential factors that influence pregnancy (and live birth) rates in IVF have been suggested to be maternal age, duration of infertility or subfertility, bFSH and number of oocytes, all reflecting ovarian function. Optimal woman's age is 23–39 years at time of treatment.\nBiomarkers that affect the pregnancy chances of IVF include:\n\nOther determinants of outcome of IVF include:\n\nAspirin is sometimes prescribed to women for the purpose of increasing the chances of conception by IVF, but there was no evidence to show that it is safe and effective.\n\nA 2013 review and metaanalysis of randomised controlled trials of acupuncture as an adjuvant therapy in IVF found no overall benefit, and concluded that an apparent benefit detected in a subset of published trials where the control group (those not using acupuncture) experienced a lower than average rate of pregnancy requires further study, due to the possibility of publication bias and other factors.\n\nA Cochrane review came to the result that endometrial injury performed in the month prior to ovarian induction appeared to increase both the live birth rate and clinical pregnancy rate in IVF compared with no endometrial injury. There was no evidence of a difference between the groups in miscarriage, multiple pregnancy or bleeding rates. Evidence suggested that endometrial injury on the day of oocyte retrieval was associated with a lower live birth or ongoing pregnancy rate.\n\nFor women, intake of antioxidants (such as N-acetyl-cysteine, melatonin, vitamin A, vitamin C, vitamin E, folic acid, myo-inositol, zinc or selenium) has not been associated with a significantly increased live birth rate or clinical pregnancy rate in IVF according to Cochrane reviews. The review found that oral antioxidants given to men in couples with male factor or unexplained subfertility may improve live birth rates, but more evidence is needed.\n\nA Cochrane review in 2015 came to the result that there is no evidence identified regarding the effect of pre-conception lifestyle advice on the chance of a live birth outcome.\n\nThe major complication of IVF is the risk of multiple births. This is directly related to the practice of transferring multiple embryos at embryo transfer. Multiple births are related to increased risk of pregnancy loss, obstetrical complications, prematurity, and neonatal morbidity with the potential for long term damage. Strict limits on the number of embryos that may be transferred have been enacted in some countries (e.g. Britain, Belgium) to reduce the risk of high-order multiples (triplets or more), but are not universally followed or accepted. Spontaneous splitting of embryos in the womb after transfer can occur, but this is rare and would lead to identical twins. A double blind, randomised study followed IVF pregnancies that resulted in 73 infants (33 boys and 40 girls) and reported that 8.7% of singleton infants and 54.2% of twins had a birth weight of < .\n\nRecent evidence also suggest that singleton offspring after IVF is at higher risk for lower birth weight for unknown reasons.\n\nCertain kinds of IVF, in particular ICSI (first applied in 1991) and blastocyst transfer (first applied in 1984) have been shown to lead to distortions in the sex ratio at birth. ICSI leads to slightly more female births (51.3% female) while blastocyst transfer leads to significantly more boys (56.1% male) being born. Standard IVF done at the second or third day leads to a normal sex ratio.\n\nEpigenetic modifications caused by extended culture leading to the death of more female embryos has been theorised as the reason why blastocyst transfer leads to a higher male sex ratio, however adding retinoic acid to the culture can bring this ratio back to normal.\n\nBy sperm washing, the risk that a chronic disease in the male providing the sperm would infect the female or offspring can be brought to negligible levels.\n\nIn males with hepatitis B, The Practice Committee of the American Society for Reproductive Medicine advises that sperm washing is not necessary in IVF to prevent transmission, unless the female partner has not been effectively vaccinated. In females with hepatitis B, the risk of vertical transmission during IVF is no different from the risk in spontaneous conception. However, there is not enough evidence to say that ICSI procedures are safe in females with hepatitis B in regard to vertical transmission to the offspring.\n\nRegarding potential spread of HIV/AIDS, Japan's government prohibited the use of IVF procedures for couples in which both partners are infected with HIV. Despite the fact that the ethics committees previously allowed the Ogikubo, Tokyo Hospital, located in Tokyo, to use IVF for couples with HIV, the Ministry of Health, Labour and Welfare of Japan decided to block the practice. Hideji Hanabusa, the vice president of the Ogikubo Hospital, states that together with his colleagues, he managed to develop a method through which scientists are able to remove HIV from sperm.\n\nA risk of ovarian stimulation is the development of ovarian hyperstimulation syndrome, particularly if hCG is used for inducing final oocyte maturation. This results in swollen, painful ovaries. It occurs in 30% of patients. Mild cases can be treated with over the counter medications and cases can be resolved in the absence of pregnancy. In moderate cases, ovaries swell and fluid accumulated in the abdominal cavities and may have symptoms of heartburn, gas, nausea or loss of appetite. In severe cases patients have sudden excess abdominal pain, nausea, vomiting and will result in hospitalisation.\n\nDuring egg retrieval, there exists a small chance of bleeding, infection, and damage to surrounding structures like bowel and bladder (transvaginal ultrasound aspiration) as well as difficulty in breathing, chest infection, allergic reactions to medication, or nerve damage (laproscopy).\n\nEctopic pregnancy may also occur if a fertilised egg develops outside the uterus, usually in the fallopian tubes and requires immediate destruction of the fetus.\n\nIVF does not seem to be associated with an elevated risk of cervical cancer, nor with ovarian cancer or endometrial cancer when neutralising the confounder of infertility itself. Nor does it seem to impart any increased risk for breast cancer.\n\nRegardless of pregnancy result, IVF treatment is usually stressful for patients. Neuroticism and the use of escapist coping strategies are associated with a higher degree of distress, while the presence social support has a relieving effect. A negative pregnancy test after IVF is associated with an increased risk for depression in women, but not with any increased risk of developing anxiety disorders. Pregnancy test results do not seem to be a risk factor for depression or anxiety among men.\n\nA review in 2013 came to the result that infants resulting from IVF (with or without ICSI) have a relative risk of birth defects of 1.32 (95% confidence interval 1.24–1.42) compared to naturally conceived infants. In 2008, an analysis of the data of the National Birth Defects Study in the US found that certain birth defects were significantly more common in infants conceived through IVF, notably septal heart defects, cleft lip with or without cleft palate, esophageal atresia, and anorectal atresia; the mechanism of causality is unclear. However, in a population-wide cohort study of 308,974 births (with 6163 using assisted reproductive technology and following children from birth to age five) researchers found: \"The increased risk of birth defects associated with IVF was no longer significant after adjustment for parental factors.\" Parental factors included known independent risks for birth defects such as maternal age, smoking status, etc. Multivariate correction did not remove the significance of the association of birth defects and ICSI (corrected odds ratio 1.57), although the authors speculate that underlying male infertility factors (which would be associated with the use of ICSI) may contribute to this observation and were not able to correct for these confounders. The authors also found that a history of infertility elevated risk itself in the absence of any treatment (odds ratio 1.29), consistent with a Danish national registry study and \"...implicates patient factors in this increased risk.\" The authors of the Danish national registry study speculate: \"...our results suggest that the reported increased prevalence of congenital malformations seen in singletons born after assisted reproductive technology is partly due to the underlying infertility or its determinants.\"\n\nIf the underlying infertility is related to abnormalities in spermatogenesis, it is plausible, but too early to examine that male offspring are at higher risk for sperm abnormalities.\n\nIVF does not seem to confer any risks regarding cognitive development, school performance, social functioning, and behaviour. Also, IVF infants are known to be as securely attached to their parents as those who were naturally conceived, and IVF adolescents are as well-adjusted as those who have been naturally conceived.\n\nLimited long-term follow-up data suggest that IVF may be associated with an increased incidence of hypertension, impaired fasting glucose, increase in total body fat composition, advancement of bone age, subclinical thyroid disorder, early adulthood clinical depression and binge drinking in the offspring. It is not known, however, whether these potential associations are caused by the IVF procedure in itself, by adverse obstetric outcomes associated with IVF, by the genetic origin of the children or by yet unknown IVF-associated causes. Increases in embryo manipulation during IVF result in more deviant fetal growth curves, but birth weight does not seem to be a reliable marker of fetal stress.\n\nIVF, including ICSI, is associated with an increased risk of imprinting disorders (including Prader-Willi syndrome and Angelman syndrome), with an odds ratio of 3.7 (95% confidence interval 1.4 to 9.7).\n\nAn IVF-associated incidence of cerebral palsy and neurodevelopmental delay are believed to be related to the confounders of prematurity and low birthweight. Similarly, an IVF-associated incidence of autism and attention-deficit disorder are believed to be related to confounders of maternal and obstetric factors.\n\nOverall, IVF does not cause an increased risk of childhood cancer. Studies have shown a decrease in the risk of certain cancers and an increased risks of certain others including retinoblastoma hepatoblastoma and rhabdomyosarcoma.\n\nTheoretically, IVF could be performed by collecting the contents from a woman's fallopian tubes or uterus after natural ovulation, mixing it with sperm, and reinserting the fertilised ova into the uterus. However, without additional techniques, the chances of pregnancy would be extremely small. The additional techniques that are routinely used in IVF include ovarian hyperstimulation to generate multiple eggs, ultrasound-guided transvaginal oocyte retrieval directly from the ovaries, co-incubation of eggs and sperm, as well as culture and selection of resultant embryos before embryo transfer into a uterus.\n\nOvarian hyperstimulation is the stimulation to induce development of multiple follicles of the ovaries. It should start with response prediction by e.g. age, antral follicle count and level of anti-Müllerian hormone. The resulting prediction of e.g. poor or hyper-response to ovarian hyperstimulation determines the protocol and dosage for ovarian hyperstimulation.\n\nOvarian hyperstimulation also includes suppression of spontaneous ovulation, for which two main methods are available: Using a (usually longer) GnRH agonist protocol or a (usually shorter) GnRH antagonist protocol. In a standard long GnRH agonist protocol the day when hyperstimulation treatment is started and the expected day of later oocyte retrieval can be chosen to conform to personal choice, while in a GnRH antagonist protocol it must be adapted to the spontaneous onset of the previous menstruation. On the other hand, the GnRH antagonist protocol has a lower risk of ovarian hyperstimulation syndrome (OHSS), which is a life-threatening complication.\n\nFor the ovarian hyperstimulation in itself, injectable gonadotropins (usually FSH analogues) are generally used under close monitoring. Such monitoring frequently checks the estradiol level and, by means of gynecologic ultrasonography, follicular growth. Typically approximately 10 days of injections will be necessary.\n\nThere are several methods termed \"natural cycle IVF\":\n\nIVF using no drugs for ovarian hyperstimulation was the method for the conception of Louise Brown. This method can be successfully used when women want to avoid taking ovarian stimulating drugs with its associated side-effects. HFEA has estimated the live birth rate to be approximately 1.3% per IVF cycle using no hyperstimulation drugs for women aged between 40–42.\n\nMild IVF is a method where a small dose of ovarian stimulating drugs are used for a short duration during a woman's natural cycle aimed at producing 2–7 eggs and creating healthy embryos. This method appears to be an advance in the field to reduce complications and side-effects for women and it is aimed at quality, and not quantity of eggs and embryos. One study comparing a mild treatment (mild ovarian stimulation with GnRH antagonist co-treatment combined with single embryo transfer) to a standard treatment (stimulation with a GnRH agonist long-protocol and transfer of two embryos) came to the result that the proportions of cumulative pregnancies that resulted in term live birth after 1 year were 43.4% with mild treatment and 44.7% with standard treatment. Mild IVF can be cheaper than conventional IVF and with a significantly reduced risk of multiple gestation and OHSS.\n\nWhen the ovarian follicles have reached a certain degree of development, induction of final oocyte maturation is performed, generally by an injection of human chorionic gonadotropin (hCG). Commonly, this is known as the \"trigger shot.\" hCG acts as an analogue of luteinising hormone, and ovulation would occur between 38 and 40 hours after a single HCG injection, but the egg retrieval is performed at a time usually between 34 and 36 hours after hCG injection, that is, just prior to when the follicles would rupture. This avails for scheduling the egg retrieval procedure at a time where the eggs are fully mature. HCG injection confers a risk of ovarian hyperstimulation syndrome. Using a GnRH agonist instead of hCG eliminates most of the risk of ovarian hyperstimulation syndrome, but with a reduced delivery rate if the embryos are transferred fresh. For this reason, many centers will freeze all oocytes or embryos following agonist trigger.\n\nThe eggs are retrieved from the patient using a transvaginal technique called transvaginal oocyte retrieval, involving an ultrasound-guided needle piercing the vaginal wall to reach the ovaries. Through this needle follicles can be aspirated, and the follicular fluid is passed to an embryologist to identify ova. It is common to remove between ten and thirty eggs. The retrieval procedure usually takes between 20 and 40 minutes, depending on the number of mature follicles, and is usually done under conscious sedation or general anaesthesia.\n\nIn the laboratory, the identified eggs are stripped of surrounding cells and prepared for fertilisation. An oocyte selection may be performed prior to fertilisation to select eggs with optimal chances of successful pregnancy. In the meantime, semen is prepared for fertilisation by removing inactive cells and seminal fluid in a process called sperm washing. If semen is being provided by a sperm donor, it will usually have been prepared for treatment before being frozen and quarantined, and it will be thawed ready for use.\n\nThe sperm and the egg are incubated together at a ratio of about 75,000:1 in a culture media in order for the actual fertilisation to take place. A review in 2013 came to the result that a duration of this co-incubation of about 1 to 4 hours results in significantly higher pregnancy rates than 16 to 24 hours. In most cases, the egg will be fertilised during co-incubation and will show two pronuclei. In certain situations, such as low sperm count or motility, a single sperm may be injected directly into the egg using intracytoplasmic sperm injection (ICSI). The fertilised egg is passed to a special growth medium and left for about 48 hours until the egg consists of six to eight cells.\n\nIn gamete intrafallopian transfer, eggs are removed from the woman and placed in one of the fallopian tubes, along with the man's sperm. This allows fertilisation to take place inside the woman's body. Therefore, this variation is actually an in vivo fertilisation, not in vitro.\n\nThe main durations of embryo culture are until cleavage stage (day two to four after co-incubation) or the blastocyst stage (day five or six after co-incubation). Embryo culture until the blastocyst stage confers a significant increase in live birth rate per embryo transfer, but also confers a decreased number of embryos available for transfer and embryo cryopreservation, so the cumulative clinical pregnancy rates are increased with cleavage stage transfer. Transfer day two instead of day three after fertilisation has no differences in live birth rate. There are significantly higher odds of preterm birth (odds ratio 1.3) and congenital anomalies (odds ratio 1.3) among births having from embryos cultured until the blastocyst stage compared with cleavage stage.\n\nLaboratories have developed grading methods to judge ovocyte and embryo quality. In order to optimise pregnancy rates, there is significant evidence that a morphological scoring system is the best strategy for the selection of embryos. Since 2009 where the first time-lapse microscopy system for IVF was approved for clinical use, morphokinetic scoring systems has shown to improve to pregnancy rates further. However, when all different types of time-lapse embryo imaging devices, with or without morphokinetic scoring systems, are compared against conventional embryo assessment for IVF, there is insufficient evidence of a difference in live-birth, pregnancy, stillbirth or miscarriage to choose between them.\n\nThe number to be transferred depends on the number available, the age of the woman and other health and diagnostic factors. In countries such as Canada, the UK, Australia and New Zealand, a maximum of two embryos are transferred except in unusual circumstances. In the UK and according to HFEA regulations, a woman over 40 may have up to three embryos transferred, whereas in the US, there is no legal limit on the number of embryos which may be transferred, although medical associations have provided practice guidelines. Most clinics and country regulatory bodies seek to minimise the risk of multiple pregnancy, as it is not uncommon for multiple embryos to implant if multiple embryos are transferred. Embryos are transferred to the patient's uterus through a thin, plastic catheter, which goes through her vagina and cervix. Several embryos may be passed into the uterus to improve chances of implantation and pregnancy.\n\nLuteal support is the administration of medication, generally progesterone, progestins, hCG, or GnRH agonists, and often accompanied by estradiol, to increase the success rate of implantation and early embryogenesis, thereby complementing and/or supporting the function of the corpus luteum. A Cochrane review found that hCG or progesterone given during the luteal phase may be associated with higher rates of live birth or ongoing pregnancy, but that the evidence is not conclusive. Co-treatment with GnRH agonists appears to improve outcomes, by a live birth rate RD of +16% (95% confidence interval +10 to +22%).\n\nOn the other hand, growth hormone or aspirin as adjunctive medication in IVF have no evidence of overall benefit.\n\nThere are various expansions or additional techniques that can be applied in IVF, which are usually not necessary for the IVF procedure itself, but would be virtually impossible or technically difficult to perform without concomitantly performing methods of IVF.\n\nPreimplantation genetic screening (PGS) or preimplantation genetic diagnosis (PGD) has been suggested to be able to be used in IVF to select an embryo that appears to have the greatest chances for successful pregnancy. However, a systematic review and meta-analysis of existing randomised controlled trials came to the result that there is no evidence of a beneficial effect of PGS with cleavage-stage biopsy as measured by live birth rate. On the contrary, for women of advanced maternal age, PGS with cleavage-stage biopsy significantly lowers the live birth rate. Technical drawbacks, such as the invasiveness of the biopsy, and non-representative samples because of mosaicism are the major underlying factors for inefficacy of PGS.\n\nStill, as an expansion of IVF, patients who can benefit from PGS/PGD include:\n\nPGS screens for numeral chromosomal abnormalities while PGD diagnosis the specific molecular defect of the inherited disease. In both PGS and PGD, individual cells from a pre-embryo, or preferably trophectoderm cells biopsied from a blastocyst, are analysed during the IVF process. Before the transfer of a pre-embryo back to a woman's uterus, one or two cells are removed from the pre-embryos (8-cell stage), or preferably from a blastocyst. These cells are then evaluated for normality. Typically within one to two days, following completion of the evaluation, only the normal pre-embryos are transferred back to the woman's uterus. Alternatively, a blastocyst can be cryopreserved via vitrification and transferred at a later date to the uterus. In addition, PGS can significantly reduce the risk of multiple pregnancies because fewer embryos, ideally just one, are needed for implantation.\n\nCryopreservation can be performed as oocyte cryopreservation before fertilisation, or as embryo cryopreservation after fertilisation.\n\nThe Rand Consulting Group has estimated there to be 400,000 frozen embryos in the United States in 2006. The advantage is that patients who fail to conceive may become pregnant using such embryos without having to go through a full IVF cycle. Or, if pregnancy occurred, they could return later for another pregnancy. Spare oocytes or embryos resulting from fertility treatments may be used for oocyte donation or embryo donation to another woman or couple, and embryos may be created, frozen and stored specifically for transfer and donation by using donor eggs and sperm. Also, oocyte cryopreservation can be used for women who are likely to lose their ovarian reserve due to undergoing chemotherapy.\n\nBy 2017, many centers have adopted embryo cryopreservation as their primary IVF therapy, and perform few or no fresh embryo transfers. The two main reasons for this have been better endometrial receptivity when embryos are transferred in cycles without exposure to ovarian stimulation and also the ability to store the embryos while awaiting the results of pre-implantation genetic testing.\n\nThe outcome from using cryopreserved embryos has uniformly been positive with no increase in birth defects or development abnormalities.\n\n\nThere may be leftover embryos or eggs from IVF procedures if the woman for whom they were originally created has successfully carried one or more pregnancies to term. With the woman's or couple's permission, these may be donated to help other women or couples as a means of third party reproduction.\n\nIn embryo donation, these extra embryos are given to other couples or women for transfer with the goal of producing a successful pregnancy. The resulting child is considered the child of the woman who carries it and gives birth, and not the child of the donor, the same as occurs with egg donation or sperm donation.\n\nTypically, genetic parents donate the eggs to a fertility clinic or where they are preserved by oocyte cryopreservation or embryo cryopreservation until a carrier is found for them. Typically the process of matching the embryo(s) with the prospective parents is conducted by the agency itself, at which time the clinic transfers ownership of the embryos to the prospective parents.\n\nIn the United States, women seeking to be an embryo recipient undergo infectious disease screening required by the U.S. Food and Drug Administration (FDA), and reproductive tests to determine the best placement location and cycle timing before the actual Embryo Transfer occurs. The amount of screening the embryo has already undergone is largely dependent on the genetic parents' own IVF clinic and process. The embryo recipient may elect to have her own embryologist conduct further testing.\n\nAlternatives to donating unused embryos are destroying them (or having them implanted at a time where pregnancy is very unlikely), keeping them frozen indefinitely, or donating them for use in research (which results in their unviability). Individual moral views on disposing leftover embryos may depend on personal views on the beginning of human personhood and definition and/or value of potential future persons and on the value that is given to fundamental research questions. Some people believe donation of leftover embryos for research is a good alternative to discarding the embryos when patients receive proper, honest and clear information about the research project, the procedures and the scientific values.\n\nThe first successful birth of a child after IVF treatment, Louise Brown, occurred in 1978. Louise Brown was born as a result of natural cycle IVF where no stimulation was made. The procedure took place at Dr Kershaw's Cottage Hospital (now Dr Kershaw's Hospice) in Royton, Oldham, England. Robert G. Edwards was awarded the Nobel Prize in Physiology or Medicine in 2010, the physiologist who co-developed the treatment together with Patrick Steptoe and embryologist Jean Purdy; Steptoe and Purdy were not eligible for consideration as the Nobel Prize is not awarded posthumously.\n\nThe second successful birth of a test tube baby occurred in India just 67 days after Louise Brown was born. The girl, named Durga conceived in vitro using a method developed independently by Dr. Subhash Mukhopadhyay, a physician and researcher from Kolkata, India.\n\nWith egg donation and IVF, women who are past their reproductive years, have infertile male partners, have idiopathic female-fertility issues, or have reached menopause can still become pregnant. Adriana Iliescu held the record as the oldest woman to give birth using IVF and donated egg, when she gave birth in 2004 at the age of 66, a record passed in 2006. After the IVF treatment some couples are able to get pregnant without any fertility treatments. In 2012 it was estimated that five million children had been born worldwide using IVF and other assisted reproduction techniques. \n\nIn some cases, laboratory mix-ups (misidentified gametes, transfer of wrong embryos) have occurred, leading to legal action against the IVF provider and complex paternity suits. An example is the case of a woman in California who received the embryo of another couple and was notified of this mistake after the birth of her son. This has led to many authorities and individual clinics implementing procedures to minimise the risk of such mix-ups. The HFEA, for example, requires clinics to use a double witnessing system, the identity of specimens is checked by two people at each point at which specimens are transferred. Alternatively, technological solutions are gaining favour, to reduce the manpower cost of manual double witnessing, and to further reduce risks with uniquely numbered RFID tags which can be identified by readers connected to a computer. The computer tracks specimens throughout the process and alerts the embryologist if non-matching specimens are identified. Although the use of RFID tracking has expanded in the US, it is still not widely adopted. However, In other cases there has been not mix-up of embryos or gametes, but the intentional use of embryos of another couple or gamete donor, without informed consent of parents, both: receptors or donors. Some of these cases are taking a legal and judicial course.\n\nAnother concern is that people will screen in or out for particular traits, using preimplantation genetic diagnosis (PGD) or preimplantation genetic screening. For example, a deaf British couple, Tom and Paula Lichy, have petitioned to create a deaf baby using IVF. Some medical ethicists have been very critical of this approach. Jacob M. Appel wrote that \"intentionally culling out blind or deaf embryos might prevent considerable future suffering, while a policy that allowed deaf or blind parents to select \"for\" such traits intentionally would be far more troublesome.\"\n\nThis concept of decisively altering genes has coined the concept of the Designer Baby. Currently, PGD can alter some physical and health attributes, and projections for the future power of PGD in its ability to create the ideal human has raised many ethical issues. Projections for societal repercussions include changing the realm of athletics, creating human weapons, and exchanging autonomy over one's life course for predesignation. Also, with a limited view of the future, it is difficult to alter a human's genetic makeup without knowing full repercussions. For example, through gene therapy, a lab was able to make rats lose weight, but the long-term effects of the gene manipulation lead to worry of toxin production and too much weight loss. To prevent some of these issues from arising, scientists work towards stabilising the entire process to make it safer before applying a higher degree of gene modification to the human embryos in IVF.\n\nMany people do not oppose the IVF practice itself (i.e. the creating of a pregnancy through \"artificial\" ways) but are highly critical of the current state of the present day industry. Such individuals argue that the industry has now become a multibillion-dollar industry, which is widely unregulated and prone to serious abuses in the desire of practitioners to obtain profit. For instance, in 2008, a California physician transferred 12 embryos to a woman who gave birth to octuplets (see Suleman octuplets). This has made international news, and had led to accusations that many doctors are willing to seriously endanger the health and even life of women in order to gain money. Robert Winston, professor of fertility studies at Imperial College London, had called the industry \"corrupt\" and \"greedy\" saying that \"One of the major problems facing us in healthcare is that IVF has become a massive commercial industry,\" and that \"What has happened, of course, is that money is corrupting this whole technology\", and accused authorities of failing to protect couples from exploitation \"The regulatory authority has done a consistently bad job. It's not prevented the exploitation of women, it's not put out very good information to couples, it's not limited the number of unscientific treatments people have access to\". The IVF industry can thus be seen as an example of what social scientists are describing as an increasing trend towards a market-driven construction of health, medicine and the human body.\n\nAs the science progresses, the industry is further driven by money in that researchers and innovators enter into the fight over patents and intellectual property rights. The Copyright Clause in the US Constitution protects innovator's rights to their respective work in attempts to promote scientific progress. Essentially, this lawful protection gives incentive to the innovators by providing them a temporary monopoly over their respective work. In the IVF industry, already incredibly expensive for patients, patents risk even higher prices for the patients to receive the procedure as they have to also cover the costs of protected works. For example, company 23andMe has patented a process used to calculate probability of gene inheritance. While this innovation could help many, the company retains sole right to administer it and thus does not have economic competition. Lack of economic competition leads to higher prices of products.\n\nThe industry has been accused of making unscientific claims, and distorting facts relating to infertility, in particular through widely exaggerated claims about how common infertility is in society, in an attempt to get as many couples as possible and as soon as possible to try treatments (rather than trying to conceive naturally for a longer time). This risks removing infertility from its social context and reducing the experience to a simple biological malfunction, which not only \"can\" be treated through bio-medical procedures, but \"should\" be treated by them. Indeed, there are serious concerns about the overuse of treatments, for instance Dr Sami David, a fertility specialist and one of the pioneers of the early days of the IVF treatments, has expressed disappointment over the current state of the industry, and said many procedures are unnecessary; he said: \"It's being the first choice of treatment rather than the last choice. When it was first opening up in late 1970s, early 80s, it was meant to be the last resort. Now it's a first resort. I think that's an injustice to women. I also think it can harm women in the long run.\" IVF thus raises ethical issues concerning the abuse of bio-medical facts to 'sell' corrective procedures and treatments for conditions that deviate from a constructed ideal of the 'healthy' or 'normal' body i.e., fertile females and males with reproductive systems capable of co-producing offspring.\n\nAlthough menopause is a natural barrier to further conception, IVF has allowed women to be pregnant in their fifties and sixties. Women whose uteruses have been appropriately prepared receive embryos that originated from an egg of an egg donor. Therefore, although these women do not have a genetic link with the child, they have a physical link through pregnancy and childbirth. In many cases the genetic father of the child is the woman's partner. Even after menopause the uterus is fully capable of carrying out a pregnancy.\n\nA 2009 statement from the ASRM found no persuasive evidence that children are harmed or disadvantaged solely by being raised by single parents, unmarried parents, or homosexual parents. It did not support restricting access to assisted reproductive technologies on the basis of a prospective parent's marital status or sexual orientation.\n\nEthical concerns include reproductive rights, the welfare of offspring, nondiscrimination against unmarried individuals, homosexual, and professional autonomy.\n\nA recent controversy in California focused on the question of whether physicians opposed to same-sex relationships should be required to perform IVF for a lesbian couple. Guadalupe T. Benitez, a lesbian medical assistant from San Diego, sued doctors Christine Brody and Douglas Fenton of the North Coast Women's Care Medical Group after Brody told her that she had \"religious-based objections to treating her and homosexuals in general to help them conceive children by artificial insemination,\" and Fenton refused to authorise a refill of her prescription for the fertility drug Clomid on the same grounds. The California Medical Association had initially sided with Brody and Fenton, but the case, North Coast Women's Care Medical Group v. Superior Court, was decided unanimously by the California State Supreme Court in favour of Benitez on 19 August 2008.\n\nIVF is increasingly being used to allow lesbian and other LGBT couples to share in the reproductive process through a technique called reciprocal IVF. The eggs of one partner are used to create embryos which the other partner carries through pregnancy.\n\nNadya Suleman came to international attention after having twelve embryos implanted, eight of which survived, resulting in eight newborns being added to her existing six-child family. The Medical Board of California sought to have fertility doctor Michael Kamrava, who treated Suleman, stripped of his licence. State officials allege that performing Suleman's procedure is evidence of unreasonable judgment, substandard care, and a lack of concern for the eight children she would conceive and the six she was already struggling to raise. On 1 June 2011 the Medical Board issued a ruling that Kamrava's medical licence be revoked effective 1 July 2011.\n\nSome children conceived by IVF using anonymous donors report being troubled over not knowing about their donor parent as well any genetic relatives they may have and their family history.\n\nAlana Stewart, who was conceived using donor sperm, began an online forum for donor children called AnonymousUS in 2010. The forum welcomes the viewpoints of anyone involved in the IVF process. Olivia Pratten, a donor-conceived Canadian, sued the province of British Columbia for access to records on her donor father's identity in 2008. \"I'm not a treatment, I'm a person, and those records belong to me,\" Pratten said. In May 2012, a court ruled in Pratten's favour, agreeing that the laws at the time discriminated against donor children and making anonymous sperm and egg donation in British Columbia illegal.\n\nIn the U.K., Sweden, Norway, Germany, Italy, New Zealand, and some Australian states, donors are not paid and cannot be anonymous.\n\nIn 2000, a website called Donor Sibling Registry was created to help biological children with a common donor connect with each other.\n\nIn 2012, a documentary called \"Anonymous Father's Day\" was released that focuses on donor-conceived children.\n\nDuring the selection and transfer phases, many embryos may be discarded in favour of others. This selection may be based on criteria such as genetic disorders or the sex. One of the earliest cases of special gene selection through IVF was the case of the Collins family in the 1990s, who selected the sex of their child. The ethic issues remain unresolved as no consensus exists in science, religion, and philosophy on when a human embryo should be recognised as a person. For those who believe that this is at the moment of conception, IVF becomes a moral question when multiple eggs are fertilised, begin development, and only a few are chosen for implantation. \n\nIf IVF were to involve the fertilisation of only a single egg, or at least only the number that will be implanted, then this would not be an issue. However, this has the chance of increasing costs dramatically as only a few eggs can be attempted at a time. As a result, the couple must decide what to do with these extra embryos. Depending on their view of the embryo's humanity or the chance the couple will want to try to have another child, the couple has multiple options for dealing with these extra embryos. Couples can choose to keep them frozen, donate them to other infertile couples, thaw them, or donate them to medical research. Keeping them frozen costs money, donating them does not ensure they will survive, thawing them renders them immediately unviable, and medical research results in their termination. In the realm of medical research, the couple is not necessarily told what the embryos will be used for, and as a result, some can be used in stem cell research, a field perceived to have ethical issues.\n\nThe Catholic Church opposes all kinds of assisted reproductive technology and artificial contraception, on the grounds that they separate the procreative goal of marital sex from the goal of uniting married couples.\nThe Catholic Church permits the use of a small number of reproductive technologies and contraceptive methods like natural family planning, which involves charting ovulation times, and allows other forms of reproductive technologies that allow conception to take place from normative sexual intercourse, such as a fertility lubricant. Pope Benedict XVI had publicly re-emphasised the Catholic Church's opposition to in vitro fertilisation, saying that it replaces love between a husband and wife.\n\nThe Catechism of the Catholic Church, in accordance with the Catholic understanding of natural law, teaches that reproduction has an \"inseparable connection\" to the sexual union of married couples. In addition, the church opposes IVF because it might result in the disposal of embryos; in Catholicism, an embryo is viewed as an individual with a soul that must be treated as a person. The Catholic Church maintains that it is not objectively evil to be infertile, and advocates adoption as an option for such couples who still wish to have children.\n\nHindus welcome IVF as gift for those who are unable to bear children and have declared doctors related to IVF to be conducting punya as there are several characters who were claimed to be born without intercourse, mainly Karna and five Pandavas.\n\nRegarding the response to IVF of Islam, the conclusions of Gad El-Hak Ali Gad El-Hak's ART fatwa include that:\n\nWithin the Orthodox Jewish community the concept is debated as there is little precedent in traditional Jewish legal textual sources. Regarding laws of sexuality, religious challenges include masturbation (which may be regarded as \"seed wasting\"), laws related to sexual activity and menstruation (niddah) and the specific laws regarding intercourse. An additional major issue is that of establishing paternity and lineage. For a baby conceived naturally, the father's identity is determined by a legal presumption (chazakah) of legitimacy: \"rov bi'ot achar ha'baal\" - a woman's sexual relations are assumed to be with her husband. Regarding an IVF child, this assumption does not exist and as such Rabbi Eliezer Waldenberg (among others) requires an outside supervisor to positively identify the father. Reform Judaism has generally approved IVF.\n\nMany people of sub-Saharan Africa choose to foster their children to infertile women. IVF enables these infertile women to have their own children, which imposes new ideals to a culture in which fostering children is seen as both natural and culturally important. Many infertile women are able to earn more respect in their society by taking care of the children of other mothers, and this may be lost if they choose to use IVF instead. As IVF is seen as unnatural, it may even hinder their societal position as opposed to making them equal with fertile women. It is also economically advantageous for infertile women to raise foster children as it gives these children greater ability to access resources that are important for their development and also aids the development of their society at large. If IVF becomes more popular without the birth rate decreasing, there could be more large family homes with fewer options to send their newborn children. This could result in an increase of orphaned children and/or a decrease in resources for the children of large families. This would ultimately stifle the children's and the community's growth.\n\nStudies have indicated that IVF mothers show greater emotional involvement with their child, and they enjoy motherhood more than mothers by natural conception. Similarly, studies have indicated that IVF fathers express more warmth and emotional involvement than fathers by adoption and natural conception and enjoy fatherhood more. Some IVF parents become overly involved with their children.\n\nResearch has shown that men largely view themselves as 'passive' contributors since they have 'less physical involvement' in IVF treatment. Despite this, many men feel distressed after seeing the toll of hormonal injections and ongoing physical intervention on their female partner.\nFertility was found to be a significant factor in a man's perception of his masculinity, driving many to keep the treatment a secret. In cases where the men did share that he and his partner were undergoing IVF, they reported to have been teased, mainly by other men, although some viewed this as an affirmation of support and friendship. For others, this led to feeling socially isolated. In comparison with women, men showed less deterioration in mental health in the years following a failed treatment. However many men did feel guilt, disappointment and inadequacy, stating that they were simply trying to provide an 'emotional rock' for their partners.\n\nHigh costs keep IVF out of reach for many developing countries, but research by the Genk Institute for Fertility Technology, in Belgium, claim to have found a much lower cost methodology (about 90% reduction) with similar efficacy, which may be suitable for some fertility treatment.\nMoreover, the laws of many countries permit IVF for only single women, lesbian couples, and persons participating in surrogacy arrangements. Using PGD gives members of these select demographic groups disproportionate access to a means of creating a child possessing characteristics that they consider \"ideal,\" raising issues of equal opportunity for both the parents'/parent's and the child's generation. Many fertile couples now demand equal access to embryonic screening so that their child can be just as healthy as one created through IVF. Mass use of PGD, especially as a means of population control or in the presence of legal measures related to population or demographic control, can lead to intentional or unintentional demographic effects such as the skewed live-birth sex ratios seen in communist China following implementation of its one-child policy.\n\nIn the United States, overall availability of IVF in 2005 was 2.5 IVF physicians per 100,000 population, and utilisation was 236 IVF cycles per 100,000. 126 procedures are performed per million people per year. Utilisation highly increases with availability and IVF insurance coverage, and to a significant extent also with percentage of single persons and median income. In the US, an average cycle, from egg retrieval to embryo implantation, costs $12,400, and insurance companies that do cover treatment, even partially, usually cap the number of cycles they pay for.\n\nThe cost of IVF rather reflects the costliness of the underlying healthcare system than the regulatory or funding environment, and ranges, on average for a standard IVF cycle and in 2006 United States dollars, between $12,500 in the United States to $4,000 in Japan. In Ireland, IVF costs around €4,000, with fertility drugs, if required, costing up to €3,000. The cost per live birth is highest in the United States ($41,000) and United Kingdom ($40,000) and lowest in Scandinavia and Japan (both around $24,500).\n\nMany fertility clinics in the United States limit the upper age at which women are eligible for IVF to 50 or 55 years. These cut-offs make it difficult for women older than fifty-five to utilise the procedure.\n\nIn Australia, the average age of women undergoing ART treatment is 35.5 years among those using their own eggs (one in four being 40 or older) and 40.5 years among those using donated eggs. while IVF is available in Australia, Australians are unable to choose their baby's gender using ivf.\n\nErnestine Gwet Bell supervised the first Cameroonian child born through IVF in 1998.\n\nIsrael has the highest rate of IVF in the world, with 1657 procedures performed per million people per year. The second highest rate is in Iceland, with 899 procedures per million people per year. Israel provides unlimited free IVF procedures for its citizens for up to two children per woman under 45 years of age. In other countries the coverage of such procedures is limited if it exists at all. The Israeli Health Ministry says it spends roughly $3450 per procedure.\n\nAvailability of IVF in England is determined by Clinical commissioning groups. The National Institute for Health and Care Excellence (NICE) recommends up to 3 cycles of treatment for women under 40 and one cycle for some women aged between 40 and 42, but financial pressure has eroded compliance with this recommendation. CCGs in Essex, Bedfordshire and Somerset have reduced funding to one cycle, or none, and it is expected that reductions will become more widespread. Funding may be available in \"exceptional circumstances\" – for example if a male partner has a transmittable infection or one partner is affected by cancer treatment. According to the campaign group Fertility Fairness at the end of 2014 every CCG in England was funding at least one cycle of IVF\". Prices paid by the NHS in England varied between under £3,000 to more than £6,000 in 2014/5. In February 2013, the cost of implementing the NICE guidelines for IVF along with other treatments for infertility was projected to be £236,000 per year per 100,000 members of the population.\n\nIVF increasingly appears on NHS treatments blacklists. In August 2017 five of the 208 CCGs had stopped funding IVF completely and others were considering doing so. By October 2017 only 25 CCGs were delivering the three recommended NHS IVF cycles to eligible women under 40. Policies could fall foul of discrimination laws if they treat same sex couples differently from heterosexual ones.\n\nThe Human Fertilisation and Embryology Authority said in September 2018 that parents who are limited to one cycle of IVF, or have to fund it themselves, are more likely choose to implant multiple embryos in the hope it increases the chances of pregnancy. This significantly increases the chance of multiple births and the associated poor outcomes, which would increase NHS costs. The president of the Royal College of Obstetricians and Gynaecologists said that funding 3 cycles was \"the most important factor in maintaining low rates of multiple pregnancies and reduce(s) associated complications\".\n\nThe penetration of the IVF market in India is quite low at present with only 2,800 cycles/million infertile women in the reproductive age group (20–44 years) as compared to China which has 6,500 cycles. The key challenges are lack of awareness, affordability and accessibility. India in 2018 becomes the destination for Fertility Tourism because of most affordable IVF treatment cost. IVF treatment cost in India varies from $2000 to $4000 (roughly between 150000/- INR to 250000/- INR including all aspects of IVF treatment with medicines which is almost 5 times lower than IVF Cost in Western part of the world.\n\nGovernment agencies in China passed bans on the use of IVF in 2003 by unmarried women or by couples with certain infectious diseases.\n\nSunni Muslim nations generally allow IVF between married couples when conducted with their own respective sperm and eggs, but not with donor eggs from other couples. But Iran, which is Shi'a Muslim, has a more complex scheme. Iran bans sperm donation but allows donation of both fertilised and unfertilised eggs. Fertilised eggs are donated from married couples to other married couples, while unfertilised eggs are donated in the context of mut'ah or temporary marriage to the father.\n\nBy 2012 Costa Rica was the only country in the world with a complete ban on IVF technology, it having been ruled unconstitutional by the nation's Supreme Court because it \"violated life.\" Costa Rica had been the only country in the western hemisphere that forbade IVF. A law project sent reluctantly by the government of President Laura Chinchilla was rejected by parliament. President Chinchilla has not publicly stated her position on the question of IVF. However, given the massive influence of the Catholic Church in her government any change in the status quo seems very unlikely. In spite of Costa Rican government and strong religious opposition, the IVF ban has been struck down by the Inter-American Court of Human Rights in a decision of 20 December 2012. The court said that a long-standing Costa Rican guarantee of protection for every human embryo violated the reproductive freedom of infertile couples because it prohibited them from using IVF, which often involves the disposal of embryos not implanted in a patient's uterus. On 10 September 2015, President Luis Guillermo Solís signed a decree legalising in-vitro fertilisation. The decree was added to the country's official gazette on 11 September. Opponents of the practice have since filed a lawsuit before the country's Constitutional Court.\n\nAll major restrictions on single but infertile women using IVF were lifted in Australia in 2002 after a final appeal to the Australian High Court was rejected on procedural grounds in the Leesa Meldrum case. A Victorian federal court had ruled in 2000 that the existing ban on all single women and lesbians using IVF constituted sex discrimination. Victoria's government announced changes to its IVF law in 2007 eliminating remaining restrictions on fertile single women and lesbians, leaving South Australia as the only state maintaining them.\n\nFederal regulations in the United States include screening requirements and restrictions on donations, but generally do not affect sexually intimate partners. However, doctors may be required to \"provide\" treatments due to nondiscrimination laws, as for example in California. The US state of Tennessee proposed a bill in 2009 that would have defined donor IVF as adoption. During the same session another bill proposed barring adoption from any unmarried and cohabitating couple, and activist groups stated that passing the first bill would effectively stop unmarried people from using IVF. Neither of these bills passed.\n\n\n\n"}
{"id": "1429237", "url": "https://en.wikipedia.org/wiki?curid=1429237", "title": "Induced gravity", "text": "Induced gravity\n\nInduced gravity (or emergent gravity) is an idea in quantum gravity that space-time curvature and its dynamics emerge as a mean field approximation of underlying microscopic degrees of freedom, similar to the fluid mechanics approximation of Bose–Einstein condensates. The concept was originally proposed by Andrei Sakharov in 1967.\n\nSakharov observed that many condensed matter systems give rise to emergent phenomena that are analogous to general relativity. For example, crystal defects can look like curvature and torsion in an Einstein–Cartan spacetime. This allows one to create a theory of gravity with torsion from a world crystal model of spacetime in which the lattice spacing is of the order of a Planck length.\nSakharov's idea was to start with an arbitrary background pseudo-Riemannian manifold (in modern treatments, possibly with torsion) and introduce quantum fields (matter) on it but not introduce any gravitational dynamics explicitly. This gives rise to an effective action which to one-loop order contains the Einstein–Hilbert action with a cosmological constant. In other words, general relativity arises as an emergent property of matter fields and is not put in by hand. On the other hand, such models typically predict huge cosmological constants.\n\nSome argue that the particular models proposed by Sakharov and others have been proven impossible by the Weinberg–Witten theorem. However, models with emergent gravity are possible as long as other things, such as spacetime dimensions, emerge together with gravity. Developments in AdS/CFT correspondence after 1997 suggest that the microphysical degrees of freedom in induced gravity might be radically different. The bulk space-time arises as an emergent phenomenon of the quantum degrees of freedom that are entangled and live in the boundary of the space-time. According to some prominent researchers in emergent gravity (such as Mark Van Raamsdonk) spacetime is built up of quantum entanglement. This implies that quantum entanglement is the fundamental property that gives rise to spacetime. In 1995, Jacobson showed that the Einstein field equations can be derived from the first law of thermodynamics applied at local Rindler horizons. Thanu Padmanabhan and Erik Verlinde explore links between gravity and entropy. The Einstein equation for gravity can emerge from the entanglement first law.\n\n\n"}
{"id": "15624663", "url": "https://en.wikipedia.org/wiki?curid=15624663", "title": "International Cable Protection Committee", "text": "International Cable Protection Committee\n\nThe International Cable Protection Committee was formed in 1958 and its primary goal is to promote the safeguarding of international submarine cables against man-made and natural hazards. The organisation provides a forum for the exchange of technical, legal and environmental information about submarine cables and, with more than 155 members from over 60 nations, including cable operators, owners, manufacturers, industry service providers, as well as governments, it is the world’s premier submarine cable organization.\n\nNearly 100% of the world's intercontinental electronic communications traffic is carried by the undersea cable infrastructure. Likewise, submarine power cables underpin the global expansion of offshore renewable energy generation. As such, the impact of failures of these critical telecommunications and power cables can be devastating to social and economic stability. This is why submarine cables are classified as \"critical infrastructure\" that is to be protected from physical damage due to manmade or natural causes.\n\nThe prime activities of the International Cable Protection Committee (ICPC) are related to promoting the awareness of submarine cables, both telecom and power, as critical infrastructure that must be protected, particularly to other seabed users, governments, and the public by establishing internationally agreed upon standards for cable installation, protection, and maintenance. The ICPC actively monitors the evolution of international treaties and national legislation and help to ensure that submarine cable interests are fully understood and protected by all relevant stakeholders. ICPC supports peer-reviewed research into the interactions of cables with the ocean environment to provide an evidence-based foundation for those interactions.\n\nThe Cable Damage Committee was established on May 22, 1958. The name of the committee was later changed to the International Cable Protection Committee (ICPC) in 1967 to better reflect that intended aims of the organisation and its membership. The original organisation was for the \"Main Committee\", as it was originally known, to formulate the policies, which a small Sub-Committee of members, voted in at each Main Committee meeting. Adopted policies were then organised and subsequently implemented. In addition, the Sub-Committee ran the internal administration of the organisation through the secretary.\n\nIn the early years, the Sub-Committee would meet frequently, organising many aspects, such as Cable Warning Charts, which were later devolved down to the organisation of individual members. Most of the detailed notes from these early meetings have disappeared prior to 1975, but they always produced a formal report to the Main Committee. The frequency of the meetings prevents their listing prior to the formation of the Executive Committee in 1977.\n\nThe title \"Plenary\" for the Main Committee first appeared in 1972, but would not appear to have been a firm change, but rather a title that evolved gradually during the 1970s. By contrast, the title \"Executive\" for the Sub-Committee was a firm decision of the 1977 Plenary meeting.\n\nThe offices of chairman and vice chairman have been held by the member administration rather than the individual person. This enables a reorganization of staff to take place within an administration, without effecting the committee's organisation. Before 1976 there was no vice chairman, and if the administration holding the chair was unable to attend, as occurred twice, then a chairman had to be nominated at the start of the meeting. After 1976 the absence of the chairman was more smoothly covered, as occurred in 1979 and 1991.\n\nThe secretary was initially provided by Cable & Wireless, and subsequently changed to the British Post Office in 1960, although for a number of years after that, the official address remained with Cable & Wireless. The secretariat remained with BPO/British Telecom International continuously until 1990, when an independent secretary was engaged. This was followed later by appointment of an International Cable Legal Advisor (1999) and Marine Environmental Advisor (2003).\n\nPresently, governance is exercised by the ICPC Limited, which operates through a 17-member executive committee elected by the ICPC membership. ICPC membership has expanded and since 2011, national governments have been allowed to join as a government member in its own right. Government members include the Australia, Malta, New Zealand, Singapore, and the United Kingdom. Since February 2013, Associate membership has been made available to any person or group that shares the goals of the ICPC.\n\nAs of March 2017, the ICPC has more than 155 Members from over 60 countries. The membership includes cable owners, operators and manufacturers as well as survey companies, research groups, industry service providers and national governments, and it is the world’s premier submarine cable organisation.\n\nNumerous changes and associated challenges that affect submarine cables are actively studied and addressed by the ICPC membership through the development of industry recommendations. These recommendations contain the combined knowledge of the ICPC membership such that submarine cables are best protected thus ensuring the utmost in reliability of this critical undersea infrastructure. Some of the changes that are actively monitored by the ICPC are summarized below.\n\n\nThe ICPC develops and maintains a suite of industry standards targeted at the various lifespan stages of undersea cables, from conception to retirement. These standards are available to organisations involved with these various stages through ICPC membership.\n\n\nThe ICPC provides educational materials for the benefit of those who need to be informed about submarine cables and their role as critical infrastructure. These materials are intended to promote the awareness of the strategic, socio-economic, and social benefits of submarine cables, especially to government agencies, the fishing industry, other seabed users and the public. Relevant information is also provided to prospective new submarine cable owners to encourage the adoption of minimum industry standards for the benefit of all involved with the seabed. The ICPC has also entered into memorandums of understanding with the International Seabed Authority and the Rhodes Academy to further cooperation with these two bodies. The ICPC also has a working relationship with the East-West Institute.\n\nThe ICPC provides a forum for members to interact and learn about legal, technical, and environmental developments relevant to submarine cables where areas of common interest are identified such that members can benefit from working together and each other's expertise and real-world experience. To ensure information sharing external to the ICPC, affiliations are also developed with equivalent seabed user organisations the world over. Formal relationships with appropriate international organisations are also developed with the goal of information sharing.\n\nThe ICPC engages in projects that are beneficial to the protection of submarine cable systems. For example, a global database showing fault causes and average repair times is developed and maintained. Research projects associated with the potential effects of submarine cables on the seabed environment are also performed to ensure harmony with the undersea environment.\n\nThe ICPC actively monitors the development of international treaties and national legislation to advise and support committee members when changes to laws are proposed that may affect submarine cables. Expertise to ensure ongoing compatibility and uniformity of the law with various industry requirements is also provided through ICPC membership.\n\nWorkshops are held by the ICPC with national governments and regional organisations to foster understanding of the rights and obligations that States have with respect to submarine cables under the United Nations Law of the Sea Convention (UNCLOS).\n\nThe ICPC sponsors a reference handbook based on unique collaboration of 15 industry experts, scientists, and international law scholars that address critical legal and governance issues, as it pertains to submarine cables deployed around the world.\n\nThe interaction between submarine cables and the marine environment is documented in peer-reviewed, mainstream publications. The ICPC supports such research as a means of providing evidence-based analyses to assist cable protection in naturally hazardous regions and cable operations in environmentally sensitive areas. Briefly, cable/environmental interactions can be summarized as follows.\n\nDeep Ocean (greater than 2000 meters)\n\nOver 80% of trans-oceanic telecommunication cables are located in water depths >2000m. There, the risks posed by fishing and shipping – the main causes of cable damage – are small. Accordingly, a typical cable is a 17-22mm diameter tube, the size of a domestic garden hose. It is composed of optical glass fibres, a copper power conductor and steel wires to add strength, all of which are encased in chemically inert, marine-grade polyethylene. Antifouling agents are not used. Furthermore, the amount of power in a cable is small being around 0.6 to 1 ampere, which is less than a laptop computer. Deep-ocean cables are laid on the seabed surface with minimal disturbance to the benthic environment.\n\nLaying is planned as an one-off operation in the 20-25 year life of a cable (note the operational life may extend to 30 or more years as improved signal processing has expanded the carrying capacity of some existing cables). Given their well proven design and low risk from deep ocean hazards, cables are subject to an average of 4 faults annually worldwide. However, fault numbers may spike under extreme events such as a major submarine landslide (see Natural Hazards).\n\nWhile studies of cables and their interaction with deep-ocean organisms are few, independent research from the continental shelf (0-130m average water depth) and the upper continental slope down to around 1200m, reveals little effect of modern cables on animals living on and under the seabed. No statistical differences have been observed regarding the abundance, composition and diversity of organisms living near and distant from cables. Any observed changes are usually within the natural variability of the animals studied.\n\nContinental Margin (less than 2000 meters)\n\nAptly phrased the \"urban sea\", this sector of the ocean is the focus of a wide range of human activities that include fishing, mineral exploration, shipping, dredging, renewable energy generation, scientific research as well as telecommunications. As a result, special measures are required to protect cables. This includes (i) strengthening with steel wire armour, which increases cable diameter up to ~50mm, (ii) burial beneath the seabed and positive engagement with other seabed users to share information and knowledge regarding their respective industries.\n\nNatural Hazards\n\nMost cable faults result from human activities especially ships' anchoring and commercial fishing that involves contact with the seabed, e.g. bottom trawling. Collectively, these activities account for over 65% of cable faults and occur primarily in water depths <200m. Damage resulting from natural phenomena account for around <10% of all cable faults, but this percentage can spike during a major event such as large earthquakes (>M=7.0) when multiple cables can break. On the continental shelf, waves and currents, especially those generated by storms, may abrade exposed cables and/or cause them to sway in the oscillating currents thus inducing fatigue. Those effects are minimized by cable armouring and burial beneath the seabed. Less frequent but nonetheless devastating are tsunami such as the 2011 Great Tohuku Earthquake of 2011 that severely damaged Japanese coastal infrastructure. Such earthquakes may also generate submarine landslides and turbidity currents – sediment-laden currents that travel long distances (100s to 1000s kilometres) at high speeds (up to 68 kilometres/hour). These turbulent flows break cables in water depths down to 5000m and deeper. For example, offshore Taiwan and Algeria suffered earthquakes in 2006 and 2003 that caused 22 and 29 cable breaks respectively. Turbidity currents also form under major rain storms. The discharged flood waters are so laden with mud and sand that they sink to the seabed and move downslope to form cable-damaging turbidity currents. Other natural causes of cable faults include deep-ocean currents, volcanoes and ice. While such forces may be locally significant, worldwide they are minor compared to earthquakes and storms.\n\n"}
{"id": "50855939", "url": "https://en.wikipedia.org/wiki?curid=50855939", "title": "Israeli Citizens' Fund", "text": "Israeli Citizens' Fund\n\nThe Israeli Citizens' Fund (, \"Keren LeEzraḥei Yisra'el\") is a sovereign wealth fund (SWF) in Israel. It was established in order to handle the windfall profits expected from the discovery of the Tamar and Leviathan gas fields. The fund is managed by the Bank of Israel.\n\nWithout the fund, the economy of Israel would run the risk of the so-called \"Dutch disease\". This happens when a significant increase in revenue from one sector (such as natural gas) causes the local currency (the shekel) to strengthen, which in turn would make other sectors of the economy less competitive.\n\nIn November 2010 the International Monetary Fund recommended, in its Article IV Consultation, that Israel set up a sovereign wealth fund. The OECD recommended likewise in 2011. The OECD estimates that its size by 2040 would be between 40 to 175 billion USD (that is, between 10 and 50 percent of Israel's GDP) depending on the rate of new discoveries.\n\nThe law establishing the fund was passed by Knesset in July 2014. The law states that the fund will begin operating a month after the state's tax revenues from natural gas exceeds one billion. Originally expected to happen by 2017, more recent estimates expect this threshold to be passed by 2020. The complicated nature of the windfall tax might cause companies to use intricate forms of tax avoidance.\n"}
{"id": "706216", "url": "https://en.wikipedia.org/wiki?curid=706216", "title": "Jökulhlaup", "text": "Jökulhlaup\n\nA jökulhlaup () (literally \"glacial run\") is a type of glacial outburst flood. It is an Icelandic term that has been adopted in glaciological terminology in many languages. \nIt originally referred to the well-known subglacial outburst floods from Vatnajökull, Iceland, which are triggered by geothermal heating and occasionally by a volcanic subglacial eruption, but it is now used to describe any large and abrupt release of water from a subglacial or proglacial lake/reservoir.\n\nSince jökulhlaups emerge from hydrostatically-sealed lakes with floating levels far above the threshold, their peak discharge can be much larger than that of a marginal or extra-marginal lake burst. The hydrograph of a jökulhlaup from Vatnajökull typically either climbs over a period of weeks with the largest flow near the end, or it climbs much faster during the course of some hours. These patterns are suggested to reflect channel melting, and sheet flow under the front, respectively. Similar processes on a very large scale occurred during the deglaciation of North America and Europe after the last ice age (e.g., Lake Agassiz and the English Channel), and presumably at earlier times, although the geological record is not well preserved.\n\nSubglacial meltwater generation is one key to the understanding of subglacial meltwater flow. Meltwater may be produced on the glacier surface (supraglacially), below the glacier (basally) or in both locations. Ablation (surface melting) tends to result in surface pooling. Basal melting results from geothermal heat flux out of the earth, which varies with location, as well as from friction heating which results from the ice moving over the surface below it. Analyses by Piotrowski concluded that, based on basal meltwater production rates, the annual production of subglacial water from one typical northwestern Germany catchment was 642x10 m during the last Weichselian glaciation.\n\nMeltwater may flow either above the glacier (supraglacially), below the glacier (subglacially/basally) or as groundwater in an aquifer below the glacier as a result of the hydraulic transmissivity of the subsoil under the glacier. If the rate of production exceeds the rate of loss through the aquifer, then water will collect in surface or subglacial ponds or lakes.\n\nThe signatures of supraglacial and basal water flow differ with the passage zone. Supraglacial flow is similar to stream flow in all surface environments—water flows from higher areas to lower areas under the influence of gravity. Basal flow under the glacier exhibits significant differences. In basal flow the water, either produced by melting at the base or drawn downward from the surface by gravity, collects at the base of the glacier in ponds and lakes in a pocket overlain by hundreds of metres of ice. If there is no surface drainage path, water from surface melting will flow downward and collect in crevices in the ice, while water from basal melting collects under the glacier; either source can form a subglacial lake. The hydraulic head of the water collected in a basal lake will increase as water drains through the ice until the pressure grows high enough either to force a path through the ice or to float the ice above it.\n\nIf meltwater accumulates, the discharges are episodic under continental ice sheets as well as under Alpine glaciers. The discharge results when water collects, the overlying ice is lifted, and the water moves outward in a pressurized layer or a growing under-ice lake. Areas where the ice is most easily lifted (i.e. areas with thinner overlying ice sheets) are lifted first. Hence the water may move up the terrain underlying the glacier if it moves toward areas of lower overlying ice. As water collects, additional ice is lifted until a release path is created.\n\nIf no preexisting channel is present, the water is initially released in a broad-front jökulhlaup which can have a flow front that is tens of kilometres wide, spreading out in a thin front. As the flow continues, it tends to erode the underlying materials and the overlying ice, creating a tunnel valley channel even as the reduced pressure allows most of the glacial ice to settle back to the underlying surface, sealing off the broad front release and channelizing the flow. The direction of the channel is defined primarily by the overlying ice thickness and second by the gradient of the underlying earth, and may be observed to \"run uphill\" as the pressure of the ice forces the water to areas of lower ice coverage until it emerges at a glacial face. Hence the configuration of the various tunnel valleys formed by a specific glaciation provides a general mapping of the glacier thickness when the tunnel valleys were formed, particularly if the original surface relief under the glacier was limited.\n\nThe rapid, high-volume discharge is highly erosive, as evidenced by the debris found in tunnels and at the mouth of tunnels, which tends to be coarse rocks and boulders. This erosive environment is consistent with creation of tunnels over 400 m deep and 2.5 km wide, as have been observed in the Antarctic.\n\nPiotrowski has developed a detailed analytic model of the process, which predicts a cycle as follows:\n\nWhilst jökulhlaups were originally associated with Vatnajökull, they have been reported in the literature over a broad range of locations including the present day Antarctic, and there is evidence that they also occurred in the Laurentian ice sheet and the Scandinavian ice sheet during the last ice age.\n\nIn July 1994, an ice-dammed surface lake drained via a subglacial tunnel through , in the British Columbian Coast Mountains, resulting in a jökulhlaup. The flood surge of from 100 to 300 m/second flowed 11 km through Farrow Creek to terminate in Chilko Lake, causing significant erosion. The ice dam has not reformed. Similar British Columbian jökulhlaups are summarized in the table below.\n\nAs the Laurentide Ice Sheet receded from its maximum extent from around 21,000 to 13,000 years ago, two significant meltwater rerouting events occurred in eastern North America. Though there is still much debate among geologists as to where these events occurred, they likely took place when the ice sheet receded from the Adirondack Mountains and the St. Lawrence Lowlands.\n\n\n"}
{"id": "402157", "url": "https://en.wikipedia.org/wiki?curid=402157", "title": "List of Canadian electric utilities", "text": "List of Canadian electric utilities\n\nThis is a list of the electric utilities in Canada.\n\nThis is a list of Canadian public and private electric utilities, by province.\n\n\n\n\n\n\n\n\n\nOntario’s electricity distribution system – local distribution company service areas\n\n\n"}
{"id": "46938110", "url": "https://en.wikipedia.org/wiki?curid=46938110", "title": "List of mountain peaks of Idaho", "text": "List of mountain peaks of Idaho\n\nThis article comprises three sortable tables of major mountain peaks of the U.S. State of Idaho.\n\nThe summit of a mountain or hill may be measured in three principal ways:\n\nOf the highest major summits of Idaho, ten peaks exceed elevation and 34 peaks exceed elevation.\n\nOf the most prominent summits of Idaho, three peaks are ultra-prominent summits with more than of topographic prominence and 20 peaks exceed of topographic prominence.\n\nOf the most isolated major summits of Idaho, Borah Peak exceeds of topographic isolation and three peaks exceed of topographic isolation.\n\n\n"}
{"id": "334186", "url": "https://en.wikipedia.org/wiki?curid=334186", "title": "List of mountains on the Moon", "text": "List of mountains on the Moon\n\nThis is a list of named mountains on the Moon.\n\nNote that the heights listed below are not consistent across sources. In the 1960s, the US Army Mapping Service used elevation relative to 1,737,988 meters from the center of the Moon. In the 1970s, the US Defense Mapping Agency used 1,730,000 meters. The Clementine topographic data published in the 1990s uses 1,737,400 meters.\n\nAlso note that this table is not comprehensive, and does not list the highest places on the Moon. Clementine data show a range of about 18,100 meters from lowest to highest point on the Moon. The highest point, located on the far side of the Moon, is approximately 6500 meters higher than Mons Huygens (usually listed as the tallest mountain).\n\nThese are isolated mountains or massifs.\n\n\n"}
{"id": "381665", "url": "https://en.wikipedia.org/wiki?curid=381665", "title": "List of national parks of Spain", "text": "List of national parks of Spain\n\nThere are fifteen national parks in Spain: ten in the Iberian Peninsula and four in the Canary Islands and the Balearic Islands. Twelve of the seventeen autonomous communities of Spain have national parks. Canary Islands has the most (four), followed by Andalusia, Castile-La Mancha and Castile and León (two each). There are five autonomous communities that have no national parks: Basque Country, La Rioja, Murcia, Navarre, Valencian Community.\n\nAbout 10 million people visited Spanish national parks in 2009, with Teide accounting for about 30% of all visitors. The second most visited park was Picos de Europa (18%), followed by Timanfaya (13%). The least visited parks were Cabrera Archipelago (0.60%) and Cabañeros (0.90%). With more than 2.5 million visitors in 2013, Teide was the most visited national park in Europe that year, and sixth most visited in the world.\n\nThe Sierra de las Nieves Natural Park in the province of Malaga is being elevated to National Park status.\n\n\n"}
{"id": "13482790", "url": "https://en.wikipedia.org/wiki?curid=13482790", "title": "List of psilocybin mushroom species", "text": "List of psilocybin mushroom species\n\nPsilocybin mushrooms are mushrooms which contain the hallucinogenic substances psilocybin, psilocin, baeocystin and norbaeocystin. The mushrooms are collected and grown as an entheogen and recreational drug, despite being illegal in many countries. Many psilocybin mushrooms are in the genus \"Psilocybe\", but species across several other genera contain the drugs.\n\n\n\n\n\n\n\nMost species in this genus are poisonous.\n\n\n\n\n\nA B C D E F G H I J K L M N O P Q R S T U V W X Y Z\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "9018033", "url": "https://en.wikipedia.org/wiki?curid=9018033", "title": "List of red clover diseases", "text": "List of red clover diseases\n\nThis article is a list of diseases of red clover (\"Trifolium pratense\").\n\n"}
{"id": "9125024", "url": "https://en.wikipedia.org/wiki?curid=9125024", "title": "List of rivers of Belarus", "text": "List of rivers of Belarus\n\nThis is a list of rivers in Belarus.\n\n\n"}
{"id": "31525546", "url": "https://en.wikipedia.org/wiki?curid=31525546", "title": "List of world production", "text": "List of world production\n\nThis is a list of annual world production. (Bold number is a list of countries producing commodity)\n\n\n\nTotal production is 1,868,700 tonnes in 2003.\n"}
{"id": "27573754", "url": "https://en.wikipedia.org/wiki?curid=27573754", "title": "Luzon tropical pine forests", "text": "Luzon tropical pine forests\n\nThe Luzon tropical pine forests are a tropical coniferous forest ecoregion of the Philippines in the western Pacific Ocean. These pine forests are home to a large number of the island's endemic plants and animals.\n\nLuzon is the largest island in the Philippines and lies at the north of the group of islands. These pine forests are found at elevations over 1000m in the Cordillera Central mountains in the north of the island, where they are mixed in with areas of Luzon montane rain forests especially at the northern end of the range. The Cordillera Central includes Luzon's highest peak Mount Pulag along with other high peaks such as Mount Puguis, Mount Polis and Mount Data. Pine forests are also found in the Zambales Mountains of west-central Luzon, particularly in Mount Tapulao and Mount Redondo near Subic, Zambales.\n\nRainfall is high (over 2500mm per year) but concentrated in the July/August monsoon with a long dry season from November to April.\n\nLuzon has long been isolated from other land masses so a unique flora has developed. In this ecoregion Benguet pine (\"Pinus insularis\") trees are thinly spread over the grasslands that cover the slopes. Regular fires in the dry season maintain the balance of pines and grassland and prevent other deciduous trees and shrubs from taking hold.\n\nThere are a number of mammals endemic to the Cordillera Central, mainly species of mice and rats including large squirrel-like cloud rats. Three larger mammals of the forest are the Philippine long-tailed macaque (\"Macaca fascicularis\"), Philippine warty pig (\"Sus philippensis\"), and Malayan civet (\"Viverra tangalunga\") all of which are vulnerable to forest clearance while the pig and the macaque are prey for hunters. Birds of the pine forest include the pine-nut eating common crossbill, which is found in pine forests all over the world.\n\nPine trees have been cut down for timber, firewood and turpentine production for centuries and today this is intensified as forest is cleared for agriculture and copper and gold mining projects as the population of the Philippines grows and remains impoverished in these rural areas. In the dry season it is a straightforward process to set fires for forest clearance. Protected areas include Mount Pulag, home to a number of endemic plants and birds.\n\n"}
{"id": "1770746", "url": "https://en.wikipedia.org/wiki?curid=1770746", "title": "Marine clay", "text": "Marine clay\n\nMarine clay is a type of clay found in coastal regions around the world. In the northern, deglaciated regions, it can sometimes be quick clay, which is notorious for being involved in landslides. \n\nMarine clay is a particle of soil that is dedicated to a particle size class, this is usually associated with USDA’s classification with sand at 0.05mm, silt at 0.05-.002mm and clay being less than 0.002 mm in diameter. Paired with the fact this size of particle was deposited within a marine system involving the erosion and transportation of the clay into the ocean. \n\nSoil particles become suspended when in a solution with water, with sand being affected by the force of gravity first with suspended silt and clay still floating in solution. This is also known as turbidity, in which floating soil particles create a murky brown color to a water solution. These clay particles are then transferred to the abyssal plain in which they are deposited in high percentages of clay. A soil is only considered a clay if it has above 55% total clay content. This is due to the way in which the clay reacts to things like water, heat and other chemicals. \n\nOnce the clay is deposited on the ocean floor it can change its structure through a process known as flocculation, process by which fine particulates are caused to clump together or floc. These can be either edge to edge flocculation or edge to face flocculation. Relating to individual clay particles interacting with each other. Clays can also be aggregated or shifted in their structure besides being flocculated. \n\nClay particles can self-assemble into various configurations, each with totally different properties.\n\nThis change in structure to the clay particles is due to a swap in cations with the basic structure of a clay particle. This basic structure of the clay particle is known as a silica tetrahedral or aluminum octahedral. They are the basic structure of clay particles composing of one cation, usually silica or aluminum surrounded by hydroxide anions, these particles form in sheets forming what we know as clay particles and have very specific properties to them including micro porosity which is the ability of clay to hold water against the force of gravity, shrink swell capacity and absorption capabilities. \n\nWhen clay is deposited in the ocean, the presence of excess ions in seawater causes a loose, open structure of the clay particles to form, a process known as flocculation. Once stranded and dried by ancient changing ocean levels, this open framework means that such clay is open to water infiltration. Construction in marine clays thus presents a geotechnical engineering challenge. \n\nWhere clay overlies peat, a lateral movement of the coastline is indicated and shows a rise in relative sea level\n\nSwelling of marine clay has the potential to destroy building foundations in only a few years. Due to the changes in climatic conditions on the construction site, the pavement constructed on the marine clay (as subgrade) will have less durability and requires lot of maintenance cost. Some simple precautions, however, can reduce the hazard significantly .\n\nThe swapping of this positive cation with another is what makes different types of clays including Kaolinite, montmorillonite, smectite and illite. This happens in marine clays due the fact the oceans water is high in solution with cations making it very easy to overcome the clays negative net charge and swap the clays cation with a less positive one. These marine clays can be what are known as quick clays, which are notorious for its erosive properties. A great example of these quick clays is in the pacific northwest. They are known as blue goo which is a mix of clay and mélange (greenstone, basalt, chert, shale, sandstone, schists. uplifted through the accretionary wedge). These quick clays have a very high-risk factor associated with them if they are built upon, as they are very unstable due to the fact that liquefaction happens when it becomes saturated and literally flows, causing mass wasting events to happen. Other marine clays are used all around the world for many different uses, such as ceramics, building material, including adobe. Clay layers in soils which can be used as an impermeable layer are very important for dumps or chemical spills as they have a very high absorption capacity for heavy metals. For these clays to be available for human use they must have been eroded deposited on the ocean floor and then uplifted through means of tectonic activity to bring it to land.\n\nDuring the construction of Marina Barrage in Singapore, marine clay was found at the site. Since marine clay was the cause of the Nicoll Highway collapse years previous, the construction team removed all the marine clay to ensure the stability of Marina Barrage. Later on, they found marine clay mixed with seawater even in the deeper underground.\n\nGeotechnical problems posed by marine clay can be handled by various ground improvement techniques. Marine clay can be densified by mixing it with cement or similar binding material in specific proportions. Marine clay can be stabilised using wastes of various industries like porcelain industry and tree-cutting industries. This method is usually adopted in highways where marine clay is used as a subgrade soil. \n\nEffect of pore water chemistry on the hydro-mechanical behaviour of Lianyungang soft marine clay\nDeng, Y.F. ; Yue, X.B. ; Cui, Y.J. ; Shao, G.H. ; Liu, S.Y. ; Zhang, D.W.\nApplied Clay Science, June 2014, Vol.95, pp.167-175\n\nStrength of High Water Content Marine Clay Stabilized by Low Amount of Cement\nZhang, R ; Santoso, A ; Tan, T ; Phoon, K\nJournal of Geotechnical and Geoenvironmental Engineering, April 23, 2013\n\nStructuration and Destructuration Behavior of Cement-Treated Singapore Marine Clay\nKamruzzaman, A ; Chew, S ; Lee, F\nJournal of Geotechnical Engineering, Apr. 2009, Issue 4, pp.573-589\n\nSulfidization of lacustrine glacial clay upon Holocene marine transgression (Arkona Basin, Baltic Sea)\nHolmkvist, Lars ; Kamyshny, Alexey ; Brüchert, Volker ; Ferdelman, Timothy G. ; Jørgensen, Bo Barker\nGeochimica et Cosmochimica Acta, 1 October 2014, Vol.142, pp.75-94\n\nLinear and Nonlinear Dynamic Response of Piles in Soft Marine Clay\nDezi, Francesca ; Gara, Fabrizio ; Roia, Davide\nJournal of Geotechnical and Geoenvironmental Engineering, July 29, 2016, Vol.143(1)\n"}
{"id": "229104", "url": "https://en.wikipedia.org/wiki?curid=229104", "title": "Matter wave", "text": "Matter wave\n\nMatter waves are a central part of the theory of quantum mechanics, being an example of wave–particle duality. All matter can exhibit wave-like behavior. For example, a beam of electrons can be diffracted just like a beam of light or a water wave. The concept that matter behaves like a wave was proposed by Louis de Broglie () in 1924. It is also referred to as the \"de Broglie hypothesis\". Matter waves are referred to as \"de Broglie waves\".\n\nThe \"de Broglie wavelength\" is the wavelength, , associated with a massive particle and is related to its momentum, , through the Planck constant, :\n\nWave-like behavior of matter was first experimentally demonstrated by George Paget Thomson's thin metal diffraction experiment, and independently in the Davisson–Germer experiment both using electrons, and it has also been confirmed for other elementary particles, neutral atoms and even molecules. Recently, it was also found that investigating the elementary process of diffusion gives the theoretical evidence of the relation of matter wave, regardless of the photon energy. It is thus revealed that the relation of matter wave is now not a hypothesis but an actual equation relevant to a characteristic of micro particle. The wave-like behavior of matter is crucial to the modern theory of atomic structure and particle physics.\n\nAt the end of the 19th century, light was thought to consist of waves of electromagnetic fields which propagated according to Maxwell's equations, while matter was thought to consist of localized particles (See history of wave and particle viewpoints). In 1900, this division was exposed to doubt, when, investigating the theory of black body thermal radiation, Max Planck proposed that light is emitted in discrete quanta of energy. It was thoroughly challenged in 1905. Extending Planck's investigation in several ways, including its connection with the photoelectric effect, Albert Einstein proposed that light is also propagated and absorbed in quanta. Light quanta are now called photons. These quanta would have an energy given by the Planck–Einstein relation:\nand a momentum\nwhere (lowercase Greek letter nu) and (lowercase Greek letter lambda) denote the frequency and wavelength of the light, the speed of light, and the Planck constant. In the modern convention, frequency is symbolized by \"f\" as is done in the rest of this article. Einstein’s postulate was confirmed experimentally by Robert Millikan and Arthur Compton over the next two decades.\n\nDe Broglie, in his 1924 PhD thesis, proposed that just as light has both wave-like and particle-like properties, electrons also have wave-like properties. By rearranging the momentum equation stated in the above section, we find a relationship between the wavelength, associated with an electron and its momentum, , through the Planck constant, :\n\nThe relationship is now known to hold for all types of matter: all matter exhibits properties of both particles and waves.\n\nIn 1926, Erwin Schrödinger published an equation describing how a matter wave should evolve—the matter wave analogue of Maxwell’s equations—and used it to derive the energy spectrum of hydrogen.\n\nMatter waves were first experimentally confirmed to occur in George Paget Thomson's cathode ray diffraction experiment and the Davisson-Germer experiment for electrons, and the de Broglie hypothesis has been confirmed for other elementary particles. Furthermore, neutral atoms and even molecules have been shown to be wave-like.\n\nIn 1927 at Bell Labs, Clinton Davisson and Lester Germer fired slow-moving electrons at a crystalline nickel target. The angular dependence of the diffracted electron intensity was measured, and was determined to have the same diffraction pattern as those predicted by Bragg for x-rays. At the same time George Paget Thomson at the University of Aberdeen was independently firing electrons at very thin metal foils to demonstrate the same effect. Before the acceptance of the de Broglie hypothesis, diffraction was a property that was thought to be exhibited only by waves. Therefore, the presence of any diffraction effects by matter demonstrated the wave-like nature of matter. When the de Broglie wavelength was inserted into the Bragg condition, the observed diffraction pattern was predicted, thereby experimentally confirming the de Broglie hypothesis for electrons.\n\nThis was a pivotal result in the development of quantum mechanics. Just as the photoelectric effect demonstrated the particle nature of light, the Davisson–Germer experiment showed the wave-nature of matter, and completed the theory of wave–particle duality. For physicists this idea was important because it meant that not only could any particle exhibit wave characteristics, but that one could use wave equations to describe phenomena in matter if one used the de Broglie wavelength.\n\nExperiments with Fresnel diffraction and an atomic mirror for specular reflection of neutral atoms confirm the application of the de Broglie hypothesis to atoms, i.e. the existence of atomic waves which undergo diffraction, interference and allow quantum reflection by the tails of the attractive potential. Advances in laser cooling have allowed cooling of neutral atoms down to nanokelvin temperatures. At these temperatures, the thermal de Broglie wavelengths come into the micrometre range. Using Bragg diffraction of atoms and a Ramsey interferometry technique, the de Broglie wavelength of cold sodium atoms was explicitly measured and found to be consistent with the temperature measured by a different method.\n\nThis effect has been used to demonstrate atomic holography, and it may allow the construction of an atom probe imaging system with nanometer resolution. The description of these phenomena is based on the wave properties of neutral atoms, confirming the de Broglie hypothesis.\n\nThe effect has also been used to explain the spatial version of the quantum Zeno effect, in which an otherwise unstable object may be stabilised by rapidly repeated observations.\n\nRecent experiments even confirm the relations for molecules and even macromolecules that otherwise might be supposed too large to undergo quantum mechanical effects. In 1999, a research team in Vienna demonstrated diffraction for molecules as large as fullerenes. The researchers calculated a De Broglie wavelength of the most probable C velocity as 2.5 pm.\nMore recent experiments prove the quantum nature of molecules made of 810 atoms and with a mass of 10,123 amu.\n\nStill one step further than Louis De Broglie go theories which in quantum mechanics eliminate the concept of a pointlike classical particle and explain the observed facts by means of wavepackets of matter waves alone.\n\nThe de Broglie equations relate the wavelength to the momentum , and frequency to the total energy of a particle:\n\nformula_5\n\nwhere \"h\" is the Planck constant. The equations can also be written as\n\nformula_6\n\nor \n\nformula_7\n\nwhere is the reduced Planck constant, is the wave vector, is the phase constant, and is the angular frequency.\nIn each pair, the second equation is also referred to as the Planck–Einstein relation, since it was also proposed by Planck and Einstein.\n\nUsing two formulas from special relativity, one for the relativistic momentum and one for the relativistic mass energy\n\nallows the equations to be written as\n\nwhere formula_11 denotes the particle's rest mass, formula_12 its velocity, formula_13 the Lorentz factor, and formula_14 the speed of light in a vacuum. See below for details of the derivation of the de Broglie relations. Group velocity (equal to the particle's speed) should not be confused with phase velocity (equal to the product of the particle's frequency and its wavelength). In the case of a non-dispersive medium, they happen to be equal, but otherwise they are not.\n\nAlbert Einstein first explained the wave–particle duality of light in 1905. Louis de Broglie hypothesized that any particle should also exhibit such a duality. The velocity of a particle, he concluded, should always equal the group velocity of the corresponding wave. The magnitude of the group velocity is equal to the particle's speed.\n\nBoth in relativistic and non-relativistic quantum physics, we can identify the group velocity of a particle's wave function with the particle velocity. Quantum mechanics has very accurately demonstrated this hypothesis, and the relation has been shown explicitly for particles as large as molecules.\n\nDe Broglie deduced that if the duality equations already known for light were the same for any particle, then his hypothesis would hold. This means that\n\nwhere is the total energy of the particle, is its momentum, is the reduced Planck constant. For a free non-relativistic particle it follows that\n\nwhere is the mass of the particle and its velocity.\n\nAlso in special relativity we find that\n\nwhere is the rest mass of the particle and is the speed of light in a vacuum. But (see below), using that the phase velocity is , therefore\n\nwhere is the velocity of the particle regardless of wave behavior.\n\nIn quantum mechanics, particles also behave as waves with complex phases. The phase velocity is equal to the product of the frequency multiplied by the wavelength.\n\nBy the de Broglie hypothesis, we see that\n\nUsing relativistic relations for energy and momentum, we have\n\nwhere \"E\" is the total energy of the particle (i.e. rest energy plus kinetic energy in the kinematic sense), \"p\" the momentum, formula_13 the Lorentz factor, \"c\" the speed of light, and β the speed as a fraction of \"c\". The variable \"v\" can either be taken to be the speed of the particle or the group velocity of the corresponding matter wave. Since the particle speed formula_22 for any particle that has mass (according to special relativity), the phase velocity of matter waves always exceeds \"c\", i.e.\n\nand as we can see, it approaches \"c\" when the particle speed is in the relativistic range. The superluminal phase velocity does not violate special relativity, because phase propagation carries no energy. See the article on \"Dispersion (optics)\" for details.\n\nUsing four-vectors, the De Broglie relations form a single equation:\n\nformula_24\n\nwhich is frame-independent.\n\nLikewise, the relation between group/particle velocity and phase velocity is given in frame-independent form by:\n\nformula_25\n\nwhere\n\nThe physical reality underlying de Broglie waves is a subject of ongoing debate. Some theories treat either the particle or the wave aspect as its fundamental nature, seeking to explain the other as an emergent property. Some, such as the hidden variable theory, treat the wave and the particle as distinct entities. Yet others propose some intermediate entity that is neither quite wave nor quite particle but only appears as such when we measure one or the other property. The Copenhagen interpretation states that the nature of the underlying reality is unknowable and beyond the bounds of scientific inquiry.\n\nSchrödinger's quantum mechanical waves are conceptually different from ordinary physical waves such as water or sound. Ordinary physical waves are characterized by undulating real-number 'displacements' of dimensioned physical variables at each point of ordinary physical space at each instant of time. Schrödinger's \"waves\" are characterized by the undulating value of a dimensionless complex number at each point of an abstract multi-dimensional space, for example of configuration space.\n\nAt the Fifth Solvay Conference in 1927, Max Born and Werner Heisenberg reported as follows:\n\nAt the same conference, Erwin Schrödinger reported likewise.\n\nIn 1955, Heisenberg reiterated this:\n\nIt is mentioned above that the \"displaced quantity\" of the Schrödinger wave has values that are dimensionless complex numbers. One may ask what is the physical meaning of those numbers. According to Heisenberg, rather than being of some ordinary physical quantity such as, for example, Maxwell's electric field intensity, or mass density, the Schrödinger-wave packet's \"displaced quantity\" is probability amplitude. He wrote that instead of using the term 'wave packet', it is preferable to speak of a probability packet. The probability amplitude supports calculation of probability of location or momentum of discrete particles. Heisenberg recites Duane's account of particle diffraction by probabilistic quantal translation momentum transfer, which allows, for example in Young's two-slit experiment, each diffracted particle probabilistically to pass discretely through a particular slit. Thus one does not need necessarily think of the matter wave, as it were, as 'composed of smeared matter'.\n\nThese ideas may be expressed in ordinary language as follows. In the account of ordinary physical waves, a 'point' refers to a position in ordinary physical space at an instant of time, at which there is specified a 'displacement' of some physical quantity. But in the account of quantum mechanics, a 'point' refers to a configuration of the system at an instant of time, every particle of the system being in a sense present in every 'point' of configuration space, each particle at such a 'point' being located possibly at a different position in ordinary physical space. There is no explicit definite indication that, at an instant, this particle is 'here' and that particle is 'there' in some separate 'location' in configuration space. This conceptual difference entails that, in contrast to de Broglie's pre-quantum mechanical wave description, the quantum mechanical probability packet description does not directly and explicitly express the Aristotelian idea, referred to by Newton, that causal efficacy propagates through ordinary space by contact, nor the Einsteinian idea that such propagation is no faster than light. In contrast, these ideas are so expressed in the classical wave account, through the Green's function, though it is inadequate for the observed quantal phenomena. The physical reasoning for this was first recognized by Einstein.\n\nDe Broglie's thesis started from the hypothesis, \"that to each portion of energy with a proper mass one may associate a periodic phenomenon of the frequency , such that one finds: . The frequency is to be measured, of course, in the rest frame of the energy packet. This hypothesis is the basis of our theory.\"\n\nDe Broglie followed his initial hypothesis of a periodic phenomenon, with frequency  , associated with the energy packet. He used the special theory of relativity to find, in the frame of the observer of the electron energy packet that is moving with velocity formula_12, that its frequency was apparently reduced to\n\nThen\n\nusing the same notation as above. The quantity formula_32 is the velocity of what de Broglie called the \"phase y wave\". Its wavelength is formula_33 and frequency formula_34. De Broglie reasoned that his hypothetical intrinsic particle periodic phenomenon is in phase with that phase wave. This was his basic matter wave conception. He noted, as above, that formula_35, and the phase wave does not transfer energy.\n\nWhile the concept of waves being associated with matter is correct, de Broglie did not leap directly to the final understanding of quantum mechanics with no missteps. There are conceptual problems with the approach that de Broglie took in his thesis that he was not able to resolve, despite trying a number of different fundamental hypotheses in different papers published while working on, and shortly after publishing, his thesis.\nThese difficulties were resolved by Erwin Schrödinger, who developed the wave mechanics approach, starting from a somewhat different basic hypothesis.\n\n\n\n"}
{"id": "35482347", "url": "https://en.wikipedia.org/wiki?curid=35482347", "title": "Moria (nymph)", "text": "Moria (nymph)\n\nIn Greek mythology, Moria (Ancient Greek: Μοριαw means \"sacred olive-tree\" \"moria\") as a Naiad nymph dwelling by the river Hermus. She was the sister of Tylus.\n\nMoria makes an appearance in Nonnus' \"Dionysiaca\", in an episode that is as follows. Tylus accidentally touched a serpent, which then attacked Tylus, coiled round his body and suffocated him; Tylus was not his first victim. Moria only could helplessly watch her brother die, but then Damasen, a Giant son of Gaia, arrived on the spot; Moria implored him to help and he killed the serpent, hitting it with the trunk of a tree he tore out of the ground. Then a female serpent, the slain monster's mate, appeared and used a magical herb, referred to as \"Zeus' flower\", to bring the dead serpent back to life. Moria then used the same herb to revive her brother. \n\nIt has been speculated that the myth of Moria, Tylus and Damasen may be rooted in Lydian mythology.\n\nA similar story could be compared to that of Polyidus who used an herb to resurrect Glaucus, the son of Minos.\n"}
{"id": "14625100", "url": "https://en.wikipedia.org/wiki?curid=14625100", "title": "Ottawa-Bonnechere Graben", "text": "Ottawa-Bonnechere Graben\n\nThe Ottawa-Bonnechere Graben (also known as the Ottawa Graben) is a geological structure that coincides with a wide topographic depression extending from near Montréal through Ottawa. It is part of the St. Lawrence rift system that also includes the seismically active Saguenay graben. This rift valley was formed when the Earth's crust moved downward about a kilometre between two major fault zones known as the Mattawa and Petawawa faults. The length of the graben is about .\n\nThe Ottawa-Bonnechere Graben runs from the Montreal area on the east to near Sudbury and Lake Nipissing on the west. On the east, it joins the Saint Lawrence rift system, a half-graben which extends more than 1000 km along the Saint Lawrence River valley and links the Ottawa and Saguenay Graben.\n\nThe segment of the Ottawa-Bonnechere Graben west of Ottawa was the first to be recognized as a graben. Since then, it has been traced west to Lake Nipissing, and northwestwards from the confluence of the Mattawa and Ottawa Rivers up the valley of the latter stream to Lake Timiskaming and the Montreal River valley. This latter branch is the Timiskaming Graben. At the rifts' western termini, the main faults split into divergent smaller faults. The graben has been interpreted as a Late Proterozoic to Early Paleozoic failed arm of the Iapetus Ocean, the precursor to the Atlantic Ocean. The main Ottawa-Bonnechere Graben is associated with collapse of the regional carbonate platform and formation of deep water shale basins by ~452 mya (million years ago); similar events formed the Temiskaming Graben ~449–451 mya. These grabens were reactivated during the breakup of supercontinent Pangaea some 150 mya.\n\nSince the Late Proterozoic to Early Paleozoic, erosion has removed the volcanic peaks, exposing a number of relic volcanic pipes, such as Callander Bay and the Manitou Islands in Lake Nipissing.\n\nThese features are subterranean geological structures formed by the violent, supersonic eruption of deep-origin volcanoes. Batholiths and dikes were also exposed by erosion, such as the Timber Lake, Mulock, West Arm, Powassan and Bonfield batholiths. The expressions of a thick pile of dominantly mafic, bimodal volcanics and the Tibbit Hill volcanics in the Humber Zone of the Quebec Appalachians are believed to be related to the formation of the Ottawa-Bonnechere Graben. The precise age of these volcanics is unknown but they are either early Cambrian and late Precambrian. This volcanism was probably coeval with the emplacement of the Grenville dike swarm.\n\nMinor but significant igneous activity occurred during the Mesozoic era, including kimberlite emplacement during the Jurassic period, and the development of alkalic intrusions along the Ottawa-Bonnechere Graben and elsewhere in Ontario. This second episode of alkalic volcanism occurred along the eastern part of the graben in the early Cretaceous.\n\nThe products of this event are the Monteregian Hills in Montérégie, Quebec. These are thought to have formed as a result of the North American Plate sliding westward over a long-lived center of upwelling magma called the New England hotspot, and is the eroded remnants of intrusive stocks.\n\nThese intrusive stocks have been variously interpreted as the feeder intrusions of long extinct volcanoes, which would have been active about 125 million years ago, or as intrusives that never breached the surface in volcanic activity. Of all these features, Mont Saint-Hilaire is the best known as a source of rare specimens.\nAlong the northern side of the Ottawa-Bonnechere Graben lies a dramatic escarpment that forms the southern edge of the Gatineau Hills. This escarpment, called the Eardley Escarpment, makes this part of the graben an attractive location for rock climbers and hikers, offering a beautiful view of the relatively flat fields below, which extend to the Ottawa River.\n\nOn or near a branch of the Ottawa-Bonnechere Graben lies the Brent impact crater. It is in diameter and the age is estimated about 400 million years (Early Devonian). The impact crater, which was first recognized in 1951 from aerial photographs, formed in Precambrian gneisses.\n\nThe rocks beneath the crater floor are thoroughly fragmented over a depth of about . Like the similar Pingualuit crater, the Brent crater is attributed to the high speed impact of a giant meteorite. It is calculated that the impact released energy equaling 250 megatons of TNT and occurred when this area was probably covered by a shallow sea.\n\nThe depressions formed by the graben across the rugged Canadian Shield were a spillway for the Great Lakes after the last Ice Age. Later they became a thoroughfare for exploration and trade. These depressions now contain the Ottawa River and its tributary the Mattawa, which rises at Trout Lake near Lake Nipissing. The latter is the source of the French River, which drains into Lake Huron. This water route, with few portages, connected Lake Huron and the Saint Lawrence River by a much shorter route than through the lower Great Lakes. It was the mainline of the French-Canadian voyageurs engaged in the fur trade; they took canoes on the waterways along this route from Montreal to the upper Great Lakes and the \"pays d'en haut\"—the \"upper country\" in the old Northwest. \n\nAfter the arrival of European settlers in North America, the Mattawa River was an important transportation corridor for native peoples of the region and formed part of the water route leading west to Lake Superior in the days of the fur trade. Canoes travelling north up the Ottawa turned left to enter the Mattawa, reaching Lake Nipissing by way of \"La Vase Portage\", an stretch of water and portages. In the 19th century, the river provided access to large untouched stands of white pine. The river was also used to transport logs to sawmills. While logging is still an important industry in this region, almost the full length of the river has been designated as a Canadian Heritage River, and as such, its shores are now protected from further development and logging. Today, the river and lakes are mainly used for recreation.\n\n\n"}
{"id": "29748678", "url": "https://en.wikipedia.org/wiki?curid=29748678", "title": "Plutonia (novel)", "text": "Plutonia (novel)\n\nPlutonia (\"Плутония\") is an early science-fiction novel by Russian academician Vladimir Obruchev. It was written in 1915 in Kharkov and first published in the original Russian in 1924.\n\nThe title \"Plutonia\" refers to the novel's setting in a lost land. It is an underground world having its own sun, called Pluto for the Roman god of the underworld. The terrain is marked by dramatic geographic features and inhabited by monstrous animals and primitive people. These are essentially the animal and plant life of previous geological periods in their natural surroundings. As the characters venture deeper into the underground area, they encounter more and more ancient life forms, back to dinosaurs and other Jurassic species.\n\n\n\n\nThe descriptive passages are made more credible by Obruchev's extensive scientific knowledge of geology and paleontology.\n\nBesides English, the novel has been published in other foreign languages: Spanish (1953), Finnish (1954), Ukrainian (1955), French (1955), Czech (1956), Hungarian (1956), Romanian (1956), Latvian (1957), Portuguese (1960), and Polish (1966).\n\n"}
{"id": "13407146", "url": "https://en.wikipedia.org/wiki?curid=13407146", "title": "Positive vorticity advection", "text": "Positive vorticity advection\n\nPositive vorticity advection, or PVA, is the result of more cyclonic values of vorticity advecting into lower values of vorticity. It is more generally referred to as \"Cyclonic Vorticity Advection\" (CVA). In the Northern Hemisphere this is positive, whilst in the Southern Hemisphere it is negative.\n\nVorticity in the atmosphere is created in three different ways, which are named in their resultant vorticity. These are; Coriolis vorticity, curvature vorticity, and shear vorticity. For example, at the base of a trough, there is curvature and shear vorticity. Curvature vorticity is due to the increasing cyclonic turning as an air parcel enters the trough base. The maximum counter-clockwise spin (positive vorticity in the N.H.) is at the trough base. Shear vorticity is caused by the difference in wind speed between air moving through the trough base (typically a jet or jet finger) and slower moving air on either poleward and equatorward side of the faster flow. Consider that slower air to the poleward side will be imparted counter-clockwise spin (picture faster moving air (jet) south and slower air to the north, spin is created). Thus, to the north (poleward) of the trough base an air parcel will experience positive vorticity. Likewise, to the south of the faster flow the air is spun in a clockwise direction (faster air (jet)to the north with slower air to the south, spin is created). Thus, to the south of the faster winds will be an area of negative vorticity. \n\nWhen these areas of negative and positive vorticity are moved (advected) they produce areas of negative vorticity advection (NVA) and positive vorticity advection (PVA) respectively, downstream from the trough base. The positive vorticity advection area is typically associated with divergence and upward motion. The negative vorticity advection area will be associated with convergence and downward motion.\n\nThis produces convergence because of the way the air gains cyclonic vorticity while entering the base of the trough. The opposite happens when air is exiting the base of a trough. This air has more cyclonic vorticity than the air it is entering and therefore produces CVA. CVA produces divergence as a result of how there is a loss of cyclonic vorticity. Coriolis vorticity in this situation is ignored because it acts about the same on all the air flowing through the base of the trough.\n\nThe divergence with CVA is significant because it creates forced lift in the atmosphere. This forced lift, in the presence of conditions favorable for atmospheric convection, can cause clouds or precipitation. AVA will do the opposite and lead to a stable atmosphere. In combination with a jet streak, CVA can lead to the amplification of a trough which is significant for forecasting many conditions of the atmosphere.\n\n"}
{"id": "24731", "url": "https://en.wikipedia.org/wiki?curid=24731", "title": "Positron", "text": "Positron\n\nThe positron or antielectron is the antiparticle or the antimatter counterpart of the electron. The positron has an electric charge of +1 \"e\", a spin of 1/2 (same as electron), and has the same mass as an electron. When a positron collides with an electron, annihilation occurs. If this collision occurs at low energies, it results in the production of two or more gamma ray photons (see electron–positron annihilation).\n\nPositrons can be created by positron emission radioactive decay (through weak interactions), or by pair production from a sufficiently energetic photon which is interacting with an atom in a material.\n\nIn 1928, Paul Dirac published a paper proposing that electrons can have both a positive and negative charge. This paper introduced the Dirac equation, a unification of quantum mechanics, special relativity, and the then-new concept of electron spin to explain the Zeeman effect. The paper did not explicitly predict a new particle but did allow for electrons having either positive or negative energy as solutions. Hermann Weyl then published a paper discussing the mathematical implications of the negative energy solution. The positive-energy solution explained experimental results, but Dirac was puzzled by the equally valid negative-energy solution that the mathematical model allowed. Quantum mechanics did not allow the negative energy solution to simply be ignored, as classical mechanics often did in such equations; the dual solution implied the possibility of an electron spontaneously jumping between positive and negative energy states. However, no such transition had yet been observed experimentally. He referred to the issues raised by this conflict between theory and observation as \"difficulties\" that were \"unresolved\".\n\nDirac wrote a follow-up paper in December 1929 that attempted to explain the unavoidable negative-energy solution for the relativistic electron. He argued that \"... an electron with negative energy moves in an external [electromagnetic] field as though it carries a positive charge.\" He further asserted that all of space could be regarded as a \"sea\" of negative energy states that were filled, so as to prevent electrons jumping between positive energy states (negative electric charge) and negative energy states (positive charge). The paper also explored the possibility of the proton being an island in this sea, and that it might actually be a negative-energy electron. Dirac acknowledged that the proton having a much greater mass than the electron was a problem, but expressed \"hope\" that a future theory would resolve the issue.\n\nRobert Oppenheimer argued strongly against the proton being the negative-energy electron solution to Dirac's equation. He asserted that if it were, the hydrogen atom would rapidly self-destruct. Persuaded by Oppenheimer's argument, Dirac published a paper in 1931 that predicted the existence of an as-yet-unobserved particle that he called an \"anti-electron\" that would have the same mass and the opposite charge as an electron and that would mutually annihilate upon contact with an electron.\n\nFeynman, and earlier Stueckelberg, proposed an interpretation of the positron as an electron moving backward in time, reinterpreting the negative-energy solutions of the Dirac equation. Electrons moving backward in time would have a positive electric charge. Wheeler invoked this concept to explain the identical properties shared by all electrons, suggesting that \"they are all the same electron\" with a complex, self-intersecting worldline. Yoichiro Nambu later applied it to all production and annihilation of particle-antiparticle pairs, stating that \"the eventual creation and annihilation of pairs that may occur now and then is no creation or annihilation, but only a change of direction of moving particles, from the past to the future, or from the future to the past.\" The backwards in time point of view is nowadays accepted as completely equivalent to other pictures, but it does not have anything to do with the macroscopic terms \"cause\" and \"effect\", which do not appear in a microscopic physical description.\n\nDmitri Skobeltsyn first observed the positron in 1929. While using a Wilson cloud chamber to try to detect gamma radiation in cosmic rays, Skobeltsyn detected particles that acted like electrons but curved in the opposite direction in an applied magnetic field.\n\nLikewise, in 1929 Chung-Yao Chao, a graduate student at Caltech, noticed some anomalous results that indicated particles behaving like electrons, but with a positive charge, though the results were inconclusive and the phenomenon was not pursued.\n\nCarl David Anderson discovered the positron on 2 August 1932, for which he won the Nobel Prize for Physics in 1936. Anderson did not coin the term \"positron\", but allowed it at the suggestion of the \"Physical Review\" journal editor to which he submitted his discovery paper in late 1932. The positron was the first evidence of antimatter and was discovered when Anderson allowed cosmic rays to pass through a cloud chamber and a lead plate. A magnet surrounded this apparatus, causing particles to bend in different directions based on their electric charge. The ion trail left by each positron appeared on the photographic plate with a curvature matching the mass-to-charge ratio of an electron, but in a direction that showed its charge was positive.\n\nAnderson wrote in retrospect that the positron could have been discovered earlier based on Chung-Yao Chao's work, if only it had been followed up on. Frédéric and Irène Joliot-Curie in Paris had evidence of positrons in old photographs when Anderson's results came out, but they had dismissed them as protons.\n\nThe positron had also been contemporaneously discovered by Patrick Blackett and Giuseppe Occhialini at the Cavendish Laboratory in 1932. Blackett and Occhialini had delayed publication to obtain more solid evidence, so Anderson was able to publish the discovery first.\n\nPositrons are produced naturally in β decays of naturally occurring radioactive isotopes (for example, potassium-40) and in interactions of gamma quanta (emitted by radioactive nuclei) with matter. Antineutrinos are another kind of antiparticle produced by natural radioactivity (β decay). Many different kinds of antiparticles are also produced by (and contained in) cosmic rays. Recent (as of January 2011) research by the American Astronomical Society has discovered antimatter (positrons) originating above thunderstorm clouds; positrons are produced in gamma-ray flashes created by electrons accelerated by strong electric fields in the clouds. Antiprotons have also been found to exist in the Van Allen Belts around the Earth by the PAMELA module.\n\nAntiparticles, of which the most common are positrons due to their low mass, are also produced in any environment with a sufficiently high temperature (mean particle energy greater than the pair production threshold). During the period of baryogenesis, when the universe was extremely hot and dense, matter and antimatter were continually produced and annihilated. The presence of remaining matter, and absence of detectable remaining antimatter, also called baryon asymmetry, is attributed to CP-violation: a violation of the CP-symmetry relating matter to antimatter. The exact mechanism of this violation during baryogenesis remains a mystery.\n\nPositron production from radioactive decay can be considered both artificial and natural production, as the generation of the radioisotope can be natural or artificial. Perhaps the best known naturally-occurring radioisotope which produces positrons is potassium-40, a long-lived isotope of potassium which occurs as a primordial isotope of potassium. Even though a small percent of potassium (0.0117%) it is the single most abundant radioisotope in the human body. In a human body of 70 kg mass, about 4,400 nuclei of K decay per second. The activity of natural potassium is 31 Bq/g. About 0.001% of these K decays produce about 4000 natural positrons per day in the human body. These positrons soon find an electron, undergo annihilation, and produce pairs of 511 keV gamma rays, in a process similar (but much lower intensity) to that which happens during a PET scan nuclear medicine procedure. \n\nRecent observations indicate black holes and neutron stars produce vast amounts of positron-electron plasma in astrophysical jets. Large clouds of positron-electron plasma have also been associated with neutron stars.\n\nSatellite experiments have found evidence of positrons (as well as a few antiprotons) in primary cosmic rays, amounting to less than 1% of the particles in primary cosmic rays. These do not appear to be the products of large amounts of antimatter from the Big Bang, or indeed complex antimatter in the universe (evidence for which is lacking, see below). Rather, the antimatter in cosmic rays appear to consist of only these two elementary particles, probably made in energetic processes long after the Big Bang. \n\nPreliminary results from the presently operating Alpha Magnetic Spectrometer (\"AMS-02\") on board the International Space Station show that positrons in the cosmic rays arrive with no directionality, and with energies that range from 10 to 250 GeV. In September 2014, new results with almost twice as much data were presented in a talk at CERN and published in Physical Review Letters. A new measurement of positron fraction up to 500 GeV was reported, showing that positron fraction peaks at a maximum of about 16% of total electron+positron events, around an energy of 275 ± 32 GeV. At higher energies, up to 500 GeV, the ratio of positrons to electrons begins to fall again. The absolute flux of positrons also begins to fall before 500 GeV, but peaks at energies far higher than electron energies, which peak about 10 GeV. These results on interpretation have been suggested to be due to positron production in annihilation events of massive dark matter particles.\n\nPositrons, like anti-protons, do not appear to originate from any hypothetical \"antimatter\" regions of the universe. On the contrary, there is no evidence of complex antimatter atomic nuclei, such as antihelium nuclei (i.e., anti-alpha particles), in cosmic rays. These are actively being searched for. A prototype of the \"AMS-02\" designated \"AMS-01\", was flown into space aboard the on STS-91 in June 1998. By not detecting any antihelium at all, the \"AMS-01\" established an upper limit of 1.1×10 for the antihelium to helium flux ratio.\n\nPhysicists at the Lawrence Livermore National Laboratory in California have used a short, ultra-intense laser to irradiate a millimeter-thick gold target and produce more than 100 billion positrons. Presently significant lab production of 5 MeV positron-electron beams allows investigation of multiple characteristics such as how different elements react to 5 MeV positron interactions or impacts, how energy is transferred to particles, and the shock effect of gamma-ray bursts (GRBs).\n\nCertain kinds of particle accelerator experiments involve colliding positrons and electrons at relativistic speeds. The high impact energy and the mutual annihilation of these matter/antimatter opposites create a fountain of diverse subatomic particles. Physicists study the results of these collisions to test theoretical predictions and to search for new kinds of particles.\n\nThe ALPHA experiment combines positrons with antiprotons to study properties of antihydrogen.\n\nGamma rays, emitted indirectly by a positron-emitting radionuclide (tracer), are detected in positron emission tomography (PET) scanners used in hospitals. PET scanners create detailed three-dimensional images of metabolic activity within the human body.\n\nAn experimental tool called positron annihilation spectroscopy (PAS) is used in materials research to detect variations in density, defects, displacements, or even voids, within a solid material.\n\n\n"}
{"id": "3129916", "url": "https://en.wikipedia.org/wiki?curid=3129916", "title": "Quantum defect", "text": "Quantum defect\n\nThe term quantum defect is ambiguous. Various meanings are discussed below. Characteristic is that the defect deals with the loss on the smallest energy scale of light: that of the quantum.\n\nIn laser science, the term \"quantum defect\" refers to the fact that the energy of a pump photon is generally higher than that of a \"signal photon\" (photon of the output radiation). The difference of energies goes to the heat; this heat may carry away the excess of entropy delivered with the multimode incoherent pump.\n\nThe quantum defect of a laser can be defined as part of the energy of the pumping photon, which is lost (not turned into photons at the lasing wavelength) in the gain medium at the lasing.\nAt given frequency formula_1 of pump and given frequency formula_2 of lasing, the quantum defect formula_3. Such quantum defect has dimension of energy; for the efficient operation, the temperature of the gain medium\n(measured in units of energy) should be small compared to the quantum defect.\nAt a fixed pump frequency, the higher the quantum defect, the lower is the upper bound for the power efficiency.\n\nThe quantum defect of a Rydberg atom refers to a correction applied to the equations governing Rydberg atom behavior to take into account the fact that the inner electrons do not entirely screen their associated charge in the nucleus. It is used particularly for the alkalis that contain a single electron in their outer shell.\n\nThe perfect 1/\"r\" potential in the hydrogen atom leads to an electron binding energy given by\n\nwhere \"R\" is the Rydberg constant, \"h\" is Planck's constant, \"c\" is the speed of light and \"n\" is the principal quantum number.\n\nFor multi-electron atoms in Rydberg states with a low value of the orbital angular momentum, there is a high probability of finding the excited electron near the nucleus where it can polarize or even penetrate the ion core, modifying the potential. The resulting shift of the energy levels is represented mathematically as an angular momentum dependent quantum defect, δ:\n\nThe largest shifts occur when the orbital angular momentum is equal to 0 (normally labelled 's') and these are shown in the table for the alkali metals:\n"}
{"id": "24240122", "url": "https://en.wikipedia.org/wiki?curid=24240122", "title": "Ragnar Frislid", "text": "Ragnar Frislid\n\nRagnar Frislid (29 June 1926 – 14 June 2009) was a Norwegian writer, photographer and environmentalist.\n\nHe was born in Oslo. He was a journalist in \"Dagbladet\" from 1950 to 1959. From 1965 to 1986 he edited \"Norsk Natur\", the magazine released by Norwegian Society for the Conservation of Nature. He also edited the magazines \"Jakt-Fiske-Friluftsliv\" and \"Fjell og Vidde\" as well as the yearbook of the Norwegian Trekking Association. He wrote about 30 books, and translated other books. His 1964 release \"Naturvern\" has been called the first Norwegian book about the conservation of nature.\n\nIn 1969 he wrote \"Norske dyr\" ('Animals of Norway') together with Arne Semb-Johansson. His translation \"Verdens dyr\" ('Animals of the World'), from English to Norwegian in 1984, became an issue of dispute in 1992, when the publishing house J.W. Cappelens Forlag and De norske Bokklubbene arranged for the making of a second edition. Frislid demanded a new fee of in addition to the one-off fee of NOK 319,158 received in 1984. The publishing house won the trials in the district court as well as the court of appeal, but after years of legal battle, Frislid won in the Supreme Court of Norway in 1999.\n\nFrislid also contributed to encyclopedias and radio. As a nature photographer he was a part of the Norwegian photo agency Samfoto and an honorary member of the organization Norwegian Nature Photographers. He died in June 2009.\n\n"}
{"id": "2481476", "url": "https://en.wikipedia.org/wiki?curid=2481476", "title": "Rice hulls", "text": "Rice hulls\n\nRice hulls (or rice husks) are the hard protecting coverings of grains of rice. In addition to protecting rice during the growing season, rice hulls can be put to use as building material, fertilizer, insulation material, or fuel or gasoline\n\nRice hulls are the coatings of seeds, or grains, of rice. The husk protects the seed during the growing season, since it is formed from hard materials, including opaline silica and lignin. The hull is mostly indigestible to humans.\n\nWinnowing, used to separate the rice from hulls, is to put the whole rice into a pan and throw it into the air while the wind blows. The light hulls are blown away while the heavy rice fall back into the pan. Later pestles and a simple machine called a rice pounder were developed to remove hulls. In 1885 the modern rice hulling machine was invented in Brazil. During the milling processes, the hulls are removed from the raw grain to reveal whole brown rice, which may then sometimes be milled further to remove the bran layer, resulting in white rice.\n\nCombustion of rice hulls affords rice husk ash (acronym RHA). This ash is a potential source of amorphous reactive silica, which has a variety of applications in materials science. Most of the ash is used in the production of Portland cement. When burnt completely, the ash can have a Blaine number of as much as 3,600 compared to the Blaine number of cement (between 2,800 and 3,000), meaning it is finer than cement. Silica is the basic component of sand, which is used with cement for plastering and concreting. This fine silica will provide a very compact concrete. The ash also is a very good thermal insulation material. The fineness of the ash also makes it a very good candidate for sealing fine cracks in civil structures, where it can penetrate deeper than the conventional cement sand mixture.\n\nA number of possible uses for RHA include absorbents for oils and chemicals, soil ameliorants, a source of silicon, insulation powder in steel mills, as repellents in the form of \"vinegar-tar\" release agent in the ceramics industry, as an insulation material.\nMore specialized applications include the use of this material as a catalyst support.\n\nGoodyear announced plans to use rice husk ash as a source for tire additive.\n\nRice hulls are a low-cost material from which silicon carbide \"whiskers\" can be manufactured. The SiC whiskers are then used to reinforce ceramic cutting tools, increasing their strength tenfold.\n\nIn Kerala, India, charcoal from Rice husks (\"Umikari\" in Malayalam) were universally used for over centuries in cleaning teeth, before toothpaste replaced it.\n\nRice hulls can be used in brewing beer to increase the lautering ability of a mash.\n\nRice hulls can be composted, but their high lignin content can make this a slow process. Sometimes earthworms are used to accelerate the process. Using vermicomposting techniques, hulls can be converted to fertilizer in about four months.\n\nRice hulls that are parboiled (PBH) are used as a substrate or medium for gardening, including certain hydrocultures. The hulls decay over time. Rice hulls allow drainage, and retain less water than growstones. It has been shown that rice hulls do not affect plant growth regulation.\n\nRice hulls are coated with fine-grained gunpowder and used as the main bursting charge in aerial fireworks shells.\n\nWith proper techniques, rice hulls can be burned and used to power steam engines. Some rice mills originally disposed of hulls in this way.\nUnfortunately the direct combustion of rice hulls produces large quantities of smoke. An alternative is gasification. Rice hulls are easily gasified in top-lit updraft gasifiers. The combustion of this rice hull gas produces a blue flame, and rice hull biochar makes a good soil amendment.\n\nRice hulls are used as a \"press aid\" to improve extraction efficiency of apple pressing.\n\nRice hulls are an inexpensive byproduct of human food processing, serving as a source of fiber that is considered a filler ingredient in pet foods.\n\nRice hulls are used as pillow stuffing. The pillows are loosely stuffed and considered therapeutic as they retain the shape of the head.\n\nRice hulls themselves are a class A thermal insulating material because they are difficult to burn and less likely to allow moisture to propagate mold or fungi. It is also used as roofing after mixing it with mud and water.\n\nRice hulls are also used to make particle boards and cardboard. The silica in rice husk make the particle boards less attractive to termites.\n\n\n"}
{"id": "1245661", "url": "https://en.wikipedia.org/wiki?curid=1245661", "title": "Robert Angus Smith", "text": "Robert Angus Smith\n\nBorn at Pollokshaws, Glasgow, Smith was educated at the University of Glasgow in preparation for ministry in the Church of Scotland but left before graduating. He worked as a personal tutor and, accompanying a family to Gießen in 1839, he stayed on in Germany to study chemistry supervised by Justus von Liebig, earning a PhD in 1841.\n\nOn returning to England the same year, he again considered Holy Orders but instead was attracted to Manchester to join the chemical laboratory of Lyon Playfair at the Royal Manchester Institution. Here he became involved in some of the environmental issues of the world's first industrial city (see \"History of Manchester\"). Playfair left for greener pastures in 1845 and Smith worked at making a living as an independent analytical chemist. After some initial alarming experiences, Smith refused to take on expert witness work which was a staple of consulting scientists of the day and which he saw as corrupt. Consequently, when the Alkali Inspectorate was established by the Alkali Act 1863, Smith's integrity made him the natural candidate. As Queen Victoria's Inspector of Alkali Works, he was the prototype of the scientific civil servant. He held the post until his death. He is buried in the graveyard of St Paul's Church on Kersal Moor, Salford\n\nIn 1872 Smith published the book \"Air and Rain: The Beginnings of a Chemical Climatology\", which presents his studies of the chemistry of atmospheric precipitation. These studies include the discovery, in 1852, of acid rain in northern British cities, a consequence of the burning of coal rich in sulfur. He was conferred with Honorary Membership of the Institution of Engineers and Shipbuilders in Scotland in 1884. After his death his collection of about 4,000 books was acquired by the library of Owens College, Manchester. They are now in the John Rylands University Library, the successor of the college library.\n\nSmith with his friend William Crookes, attended a séance on 21 April 1870 in London. He sent Crookes 15 letters on spiritualism between April 1869 and 1871. Smith did not choose to write widely about spiritualism as he believed it may have damaged his scientific reputation. He was a member of the Society for Psychical Research from 1882 to 1884. After he died, 89 books on the occult were discovered in his library.\n\nSmith was elected a Fellow of the Royal Society (FRS) in 1857.\n\n\n"}
{"id": "2054994", "url": "https://en.wikipedia.org/wiki?curid=2054994", "title": "Roving", "text": "Roving\n\nA roving is a long and narrow bundle of fiber. Rovings are produced during the process of making spun yarn from wool fleece, raw cotton, or other fibres. Their main use is as fibre prepared for spinning, but they may also be used for specialised kinds of knitting or other textile arts.\n\nAfter carding, the fibres lie roughly parallel in smooth bundles. These are drawn out, by hand or machine, and slightly twisted to form lengths suitable for spinning. These unspun strands of fibre are the rovings. Roving can also mean a roll of these strands, the strands in general (as a mass noun), or the process of creating them.\n\nBecause it is carded, the fibres are less parallel than top (which is combed) and are not of uniform length. Carded rovings look fluffier than combed top, which looks smooth and has a high lustre. The fibres in combed top tend to be of a fairly uniform length due to the method of preparation. Though drawing it into strips may line the fibres up a bit. Roving is not to be confused with sliver as there is twist in roving.\n\nPencil roving is a type of roving that has been drawn until it is the size of a fat pencil. It can be used by spinners with minimal drafting (withdrawing fibers from a clump). Knitters also use pencil roving, similar to Lopi style yarns, or when making a thrummed item. (Regular roving can also be used in thrummed knitting.)\n"}
{"id": "145744", "url": "https://en.wikipedia.org/wiki?curid=145744", "title": "Skagen", "text": "Skagen\n\nSkagen (, ) is Denmark's northernmost town, on the east coast of the Skagen Odde peninsula in the far north of Jutland, part of Frederikshavn Municipality in Nordjylland, north of Frederikshavn and northeast of Aalborg. The Port of Skagen is Denmark's main fishing port and it also has a thriving tourist industry, attracting 2 million people annually.\n\nOriginally the name was applied to the peninsula but it now usually refers to the town itself. The settlement began in the Middle Ages as a fishing village, renowned for its herring industry. Thanks to its seascapes, fishermen and evening light, towards the end of the 19th century it became popular with a group of Impressionist artists now known as the Skagen Painters. In 1879, the Skagen Fisherman's Association was established with the purpose of facilitating the local fishing industry through the Skagensbanen railway, which opened as a narrow-gauged railway in 1890. The modern port of Skagen opened on 20 November 1907, and with the railway connections to Frederikshavn and the rest of Denmark, tourism began to develop.\n\nIn the early 1910s, Christian X and Queen Alexandrine often visited Skagen and brought friends from other European monarchies. They built the summer residence Klitgaarden, completed in 1914. Between the 1930s and 1950s the town grew rapidly, with the population more than doubling from 4,048 in 1930 to 9,009 in 1955. Skagen reached a peak population of 14,050 in 1980, after which it gradually declined. As of 1 January 2014 it has a population of 8,198. Thanks to the artistic community which still remains in Skagen, the local arts and crafts trade remains important to the income of the town with its numerous crafts shops and galleries. Chains such as the international jeweller Skagen Designs have branches in the town, and given the abundance of fresh fish coming in at the port of Skagen, seafood forms a staple in Skagen's restaurants.\n\nSt Lawrence's Church was built just outside the village at the end of the 14th century, but after it was buried in drifting sand it was replaced by Skagen Church in 1841 designed by Christian Frederik Hansen. It was redeveloped in 1909–10 by Ulrik Plesner who also designed a number of other buildings in Skagen, including Klitgaarden and the railway station. Several landmarks in the town are closely associated with the Skagen Painters who used to frequent them, including Brøndums Hotel, Skagens Museum, Michael and Anna Ancher's House, and Drachmann's House.\n\nSkagen's first school was the \"Latinskole\", a grammar school, which was in operation from 1549 until 1739. By the end of the 19th century, three schools had been established in Skagen, and in 1921, Skagen's Skipper School was opened to train navigators for both fishing boats and merchant ships, and in 1955, the public school \"Ankermedets skole\" was opened on Skagavej. The primary gymnasium of the town, Skagen Kultur- og Fritidscenter, opened in 1972, and was later expanded with an aquatic centre and a number of smaller training facilities. Skagen's Sportscenter was completed in 1974, primary to accommodate badminton and tennis. The local football club, Skagen Idræts Klub, was founded in 1946 and reached the Jyllandsserien, one of the lower divisions in Danish football, as their best position. The Hvide Klit Golf Club is south of the town.\n\nSkagen station is the most northerly railway station in mainland Denmark and is the terminus of the Skagensbanen. Nordjyske Jernbaner operates the local train service between Skagen, Frederikshavn and Aalborg with onward national connections by DSB. From Frederikshavn, there are ferries to Gothenburg, Oslo and Læsø. Aalborg Airport is southwest of Skagen.\n\nSkagen was mentioned as far back as the first century AD by Pliny the Elder:\n\nThis is the only time the name Tastris is mentioned but Skagen itself, first documented as \"Skaffuen\" in 1284, simply means narrow promontory.\n\nThe first building in the area, dating from the 12th century, was in Højen on the west side of the peninsula. It belonged to Tronder, a shepherd who also became Skagen's first fisherman. Around 1340, Vesterby, on the east coast (to the south west of today's harbour), developed into the main village. Further to the south west, St Lawrence's Church was built at the end of the 14th century. In 1413, Erik of Pommern granted Skagen the status of market town with the result that for a time it became Vendsyssel's largest community with up to 2,000 inhabitants.\n\nIn 1549 a grammar school was opened (closing again in 1739), and in 1561 Skagen's first lighthouse was constructed. In 1568, some 350 fishing boats and merchant ships were wrecked off the coast of Skagen. In the 1590s, successive storms led not only to numerous drownings but to flooding, destroying many of the houses. In 1591, 22 died in a flood and in 1593, 14 houses were washed away. In 1595, 25 farms in the area were covered in drifting sand. As a result, new housing was built in Østerby to the north east, away from the rapidly accumulating sand.\n\nIn the 17th century, fishing suffered from a decline in herring stocks. Shortly after the beginning of the Torstensson War, the Swedish army arrived in Skagen in January 1644, plundering the town. Skagen's White Lighthouse with adjoining accommodation for the keeper was built in 1747. In 1775, accumulations of drifting sand made it difficult to access St Lawrence's Church, finally leading to its closure and partial demolition in 1795. Its remaining artefacts were sold by auction in 1810. St Lawrence's was replaced by Skagen Church, completed in 1841 and redesigned in the local style by Ulrik Plesner in 1910.\nOn a single day in 1825, 23 ships were left stranded off the coast. In 1833, Martinus Rørbye became the first artist to paint the fishermen and landscapes of Skagen, almost half a century before the arrival of the Skagen Painters. Skagen Church was inaugurated in 1841, and the first guest house in the town opened in 1844. In 1858, the grey lighthouse was inaugurated. The same year, bye-laws were established specifying building requirements including the completion of tiled roofs within five years. Skagen was struck by the cholera epidemic of 1853.\n\nHans Christian Andersen visited the town in 1859. During his stay at Brøndums Hotel, the future painter Anna Ancher, daughter of the inn-keeper, was born. In 1871, the author Holger Drachmann and the painters Fritz Thaulow and Karl Madsen arrived in Skagen, the first of the colony of artists which became known as the Skagen Painters. They were followed by Carl Locher in 1872, Michael Ancher in 1874 and Peder Severin Krøyer in 1882. \nIn 1879, the Skagen Fisherman's Association was established with the purpose of facilitating the local fishing industry through the railway. In 1890, the Skagensbanen narrow-gauge railway from Frederikshavn finally arrived in Skagen, connecting the town to the rest of Denmark. The tracks were widened in 1916 to avoid the need to transfer cargoes of fish in Frederikshavn. Many of the town's typical yellow-plastered houses with red roofs which grew up along Sankt Laurentii Vej from 1890 to 1930 were designed by Ulrik Plesner. He was also the architect behind many other buildings in the town, including the railway station, Brøndums Hotel and Skagen Museum. Skagen Missionshus was opened in 1896.\n\nIn 1904-7, the fishing harbour was built with inner and outer sections under the patronage of hydraulic engineer Palle Bruun. It was inaugurated on 20 November 1907, and later additions were made for cold storage and the fish processing industry. The distinctive warehouses next to the harbour were designed by Thorvald Bindesbøll.\n\nIn the early 1910s, Christian X and Queen Alexandrine often visited Skagen in the royal yacht \"Kongeskibet Dannebrog\". Occasionally they arrived by train and brought friends from other European monarchies and stayed at the Brøndums and Grenen hotels. They grew fond of the place, befriending many of the artists in Skagen. Christian X bought up land in the vicinity and built the summer residence Klitgaarden as a gift for his wife. Designed by Ulrik Plesner, with furniture provided by Marie Krøyer, the villa was inaugurated on 11 April 1914, with the town celebrating the royal opening with many flags. Klitgaarden was further embellished inside by local artists. It passed to Prince Knud and Princess Caroline Mathilde, and after Caroline's death in 1995, it was converted into a villa retreat for scholars in 2000. Composer Carl Nielsen also frequented Skagen in his youth, and he purchased a plot of land on Vestre Strandvej at Vesterby in 1918 with his sculptor wife Anne Marie Carl-Nielsen, using one of the two small half-timbered houses there as a residence and studio. They named it \"Finis Terrae\", meaning \"end of the world\". The Nielsen family owned the property until 1957 when they sold it to Frode Jensen, a machinery manufacturer. \n\nIn the 1930s, development of the town as a tourist attraction led to the opening of new hotels. In 1931, the residents of Skagen and their famous friends campaigned for a monument to be established on the square in the town, commemorating the fishermen and lifeboatmen of Jutland. Anne Marie Carl-Nielsen was commissioned to erect a bronze statue of a lifeboatman in garb, holding a lifeline. The monument was showcased at the Free Exhibition Hall in Copenhagen in the spring of 1931, before fundraising enabled it to be brought by sea to Skagen on 10 November 1932. In October 1938, lightning struck the Skagens Badehotel, affecting the wing with the salons and music rooms. During World War II, the hotel was taken over by the Germans, until it was demolished in 1943. Further facilities were developed in the 1950s. From the 1960s, housing estates were constructed to the north, forming a built-up area extending to Højen. Anna and Michael Ancher's house was opened as a museum (1967) and the new town hall was completed in 1969. The Skagen Festival was founded in 1971, making it the oldest music festival in the country. The primary genre is folk music. In 1977, Drachmanns House was broken into and four paintings were stolen, and then in 1980, a painting by Christian Krohg was stolen from Skagens Museum.\n\nSeveral fires and industrial incidents occurred in the 1980s. In 1981, an oil slick affected the coastline of Skagen municipality, and in 1985 a pipe bomb exploded at Ankermedet School. Skagen ice factory was affected by a chemical incident in 1989. A new shrimp factory opened in the industrial area in 1991, while the local cinema was closed in 1993. There was a major fire on the Hulsig Heath dunes in 1996.\n\nThe Skagen Painters were a group of Scandinavian artists who visited the area every summer from the late 1870s until the turn of the century. They were attracted by the scenery, the fishermen and the quality of light which encouraged them to paint \"en plein air\" following the example of the French Impressionists while sometimes adopting the Realist approach of the Barbizon School. They broke away from the rigid traditions of the Danish and Swedish art academies, preferring the modern trends they had experienced in Paris.\n\nThe group was reputed to have adopted a bohemian lifestyle. It encompassed not only painters, but also writers, and other influential people. While only a few were full-time residents of the area, they were often joined by family and friends, especially during the summer months. The group initially revolved around Michael Ancher and his wife to be Anna, the only member of the group who was a native of Skagen. P.S. Krøyer, who arrived in 1882, was perhaps the most colourful member of the group. His painting \"Hip, Hip, Hurrah!\" shows several of the artists celebrating around a table out in the garden. The painters included the Swedes Oscar Björck and Johan Krouthén, the Norwegians Christian Krohg and Eilif Peterssen, and the Danes Karl Madsen, Laurits Tuxen, Marie Triepcke Krøyer Alfvén, Carl Locher, Viggo Johansen and Thorvald Niss. The group also included the writers Holger Drachmann, Georg Brandes and Henrik Pontoppidan and the Swedish composer Hugo Alfvén. They often gathered in Brøndums Hotel whose dining room now forms part of Skagens Museum.\n\nIn 1890, the railway to Skagen not only led to the expansion of the village but also brought in considerable numbers of tourists. It was largely responsible for breaking up the regular summer meetings of the artists' colony as they could no longer find suitable accommodation and venues for their meetings. However, some of them purchased homes in Skagen: P.S. Krøyer in 1894, Laurits Tuxen in 1901, Holger Drachmann in 1903. Anna and Michael Ancher, Krøyer and Tuxen continued to paint in Skagen until well into the 20th century and were occasionally joined by their earlier friends. Other painters, sometimes referred to as the younger group of Skagen painters, continued to visit the area. They included Jørgen Aabye, Tupsy and Gad Frederik Clement, Ella Heide, Frederik Lange and Johannes Wilhjelm, some of whom settled in the area until the 1930s or even later. Skagens Museum's has a large collection of works from all the recognized artists who painted in Skagen.\n\nSkagen is Denmark's northernmost town, located north of Frederikshavn, northeast of Aalborg, and northeast of Aarhus by road. It takes its name from the peninsula which projects into the waters between the North Sea and the straits of Denmark. The oldest areas lie along the south coast. Gammel Skagen (Old Skagen), also known as Højen, is located next to \"Nordstrand\" on the western side. Vesterby and Østerby are notable for their little fishermen's cottages and narrow streets. Danish national road 40 to Frederikshavn passes through Skagen.\n\nGrenen (also known as \"the Skagen Odde peninsula\") is bordered by Ålbæk Bay (\"Ålbæk Bugt\") to the east on the Kattegat and Tannis Bay (\"Tannis Bugt\") to the west on the Skagerrak. The area is picturesque, and distinguished by its low, yellow houses with red tile roofs nestled into the beach areas.\nThe wild landscape was largely formed by a severe process of desertification in the 18th and 19th centuries.\nProblems with moving dunes and desertification were subsequently brought under control in the latter 19th and early 20th centuries by establishing large plantations of grasses, bushes and fir trees. Two significant migratory dunes remain in the area, one of which is the enormous Råbjerg Mile.\n\nSkagen is the place in Denmark where the most bird species can be experienced, a total of 367 out of 471 bird species in the country.(2017)\n\nYear round the area around Skagen, especially Grenen, is visited by hundreds of birdwatchers from all over Denmark, particularly in April–May and the beginning of June and to a lesser degree in August–November. Furthermore, the area is visited by birdwatchers from Sweden, Norway and Germany.\n\nOther well-visited locations for birdwatchers are Ellekrattet, Nordstrand (near Batterivej), Skagen Harbour, Flagbakken southwest of the town as well as horse fields and brushwood near Fyrvej, Bøjlevejen and Buttervej.\n\nEvery day all year round Skagen Bird Observatory observes the migration on Grenen from the highest sand dune located between the parking lot and Grenen: \"The World's End\".\n\nVolunteers at Skagen Bird Observatory ring thousands of small birds in the Skagen area every year with permission from the Zoological Museum in Copenhagen.\n\nBeing surrounded by the sea in three directions, Skagen has a cool oceanic climate with a lack of temperature extremes. Its maritime and moderated characteristics is shared with the rest of the country. Skagen is Denmark's sunniest town with an average of 233 hours of sunshine in the holiday month of July, higher than the 222 hours recorded for Bornholm's Østerlars.\n\nThe population of Skagen has mostly grown steadily, reaching a peak of 14,050 people in 1980, but has shown a marked decline in the 21st century. In 1672 Skagen had a population of 1,004, but by 1781 this had declined to 650. The 1801 population of 834 began to grow significantly in subsequent decades, reaching 1,052 people in 1824 and jumping to 1,632 by 1840. By 1850, however, it had dropped to 1,400, after which is again began to grow steadily. Major growth occurred in the 1870s and 1880s, with the population growing from 1,615 in 1870 to 1,954 in 1880 and 2,323 inhabitants in 1890. Several of the new inhabitants were artists, who significantly altered the ethnic composition of Skagen, as they brought their friends and families from abroad to join the colony at Skagen. Noticeable change occurred between 1901 and 1906, when the population grew from 2,438 to 2,936, and again in the late 1910s, growing from 3,212 in 1916 to 3,854 in 1921. Major growth began to take place in the 1930s and 1940s in Skagen which grew from 4,048 inhabitants in 1930 to 5,358 in 1940. Skagen's population more than doubled between 1930 and 1955 when it reached a population of 9,009. By 1960, Skagen had 10,213 inhabitants, growing to 11,253 in 1965. Following a municipal merger in 1971, the population jumped from 11,749 to 13,513. Thereafter the population grew very steadily, reaching a peak of 14,050 in 1980. There has since been a steady decline, with 13,724 people recorded in 1990, 13,298 in 1994, and 12,691 in 2000. In the 2000s, the permanent population of Skagen has shown a marked decline, falling from 12,213 in 2003 to 8,088 inhabitants in 2017.\n\nFor generations, Skagen's economy has been based on its fishing industry which continues to prosper today, facilitated by its fishing harbour, the largest in Denmark. Skagen also has the country's main herring processing facility and the world's largest fish oil factory. The town's evolving fishing industry led to considerable growth in the local population which reached some 11,500 in the 1960s. A fish auction is held at dawn in the harbour, and between May and October the harbour also attracts yachting enthusiasts.\n\nTourism has now become the town's main industry. Initially attracted by its associations with the Skagen Painters, well-to-do visitors sought to benefit from its special light, colour and its fishermen. Their interest led to new hotels, summer houses and expensive villas. The old fishing village was transformed into a miniature city with fine streets lined with boutiques. From the 1960s, it became increasingly fashionable for the upper-classes to spend their summers in Skagen.\n\nGalleries selling local art and reproductions of Skagen's most iconic paintings have spread across the town, making it one of the places in Denmark with most galleries. Thanks to the town's growing reputation, sailing enthusiasts from Norway, Sweden and Denmark are now also among its frequent visitors. The quality brand name of Skagen has spread far afield, resulting in the establishment of the successful American watch company Skagen Designs which \"set out to create a design driven company centred around the welcoming spirit of the city\". Currently a new tourist initiative \"The Top of Denmark\" targets Skagen as a year-round attraction, not just a summer resort. The harbour is also being adapted to accommodate large international cruise ships. A new 450-meter berth will be completed by 2015 while the existing 170-meter berth will be extended to 200 meters. Skagen now attracts some 2 million visitors a year to its hotels, restaurants, shops and galleries, making tourism a major source of income and employment. An annual attraction is the Skagen Festival, Denmark's oldest music festival, which is held the first weekend of July at various venues in Skagen and the harbour area. The largest campsite in the Skagen area is Grenen Camping, situated about northeast of the centre, adjacent to the beach.\n\nUntil 2007, Skagen was a municipality in its own right with a substantial local administration. With the reforms of 2007, it became part of Frederikshavn Municipality with a resulting loss in administrative jobs. The Bank of Skagen was established in 1862, and in 1865 a telegraph station was established in the town. The pharmacy opened in 1904, a hospital in 1916, and telephone services were automated in 1956. Ankermedet School was established in 1955. Recently, Skagen has seen developments in the offshore sector with an initiative to assist the Norwegian market through the establishment of Skagen Offshorepark in 2012. On the shipbuilding front, Karstensens Skibsværft continues to prosper with orders for trawlers from Norway.\n\nCurrently the harbour is being enlarged in order to accommodate larger vessels, especially cruise ships. From 2015 the enlarged harbour is expected to attract up to 40 large cruise ships per year compared to about a dozen smaller ships at present. The new harbour should provide new jobs increasing the workforce in the harbour from 2,000 today to some 2,600 on completion. Karstens Skibsværft, Danish Yacht, and the herring processing firm, Skagerrak Pelgic, are reported to be the most successful companies in Skagen but the town is also home to FF Skagen, the world's top producer of fish meal and fish oil.\n\nThanks to Skagen's reputation as an artistic community, the local arts and crafts trade is also an important source of income and employment. Artwork and handicrafts are sold in galleries such as the Galerie Skagen on Trondsvej. Sankt Laurentii Vej, one of the main streets away from the harbour area in Skagen, is a known for its glass and pottery shops; of particular note are Skagen Glasvaerksted, which produces some of \"Jutland's finest glass pieces\", and Skagen Potteri. In addition to its arts and crafts stores, the town has a wide range of shops, including jewellery, clothes and shoes, handbags, souvenirs, flowers and gardening equipment. There are also a variety of food stores with butchers, bakers, a cheese shop, fishmongers, and several restaurants and cafés. Skagen has a branch of the EuroSpar supermarket, opened in 1998. Skagen Cementstøberi A/S is a local cement firm which produces concrete, paving stones, tiles, granite and other items.\nGiven the abundance of fresh fish coming it at the port of Skagen, seafood forms a staple of cuisine in Skagen. Of particular note is the Skagen Fiske Restaurant, one of the most renowned seafood restaurants in Jutland which was established in 1907 at the side of the harbour. It serves shrimp, herring, grilled fillets of sole with lemon sauce and Norwegian lobster. Ruth's Gourmet in Ruth's Hotel on Hans Ruth Vej is also of note and has been cited to be one of the top five restaurants in Denmark outside of Copenhagen, serving French cuisine under head chef Michel Michaud. Ruths Hotel was originally built by Emma and Hans Christian Ruth in 1904 as a bath and guest house. It was purchased by J. Philip-Sørensen in 2003. The Restaurant Pakhuset, the restaurant of the Brøndums Hotel, and Jakobs Café are also popular; Jakobs Café is a music venue and bar at night. True foodies are also bound to visit the famous butcher, Slagter Munch, who is known for their sausages and for their ham: Skagen Skinken.\n\nAt the headland at Grenen, the northernmost point of Denmark, the North Sea and the Baltic Sea meet. Because of their different densities, a clear dividing line can be seen. As a result of turbulent seas, beachings and shipwrecks were common. These frequent losses combined with the town's strategic location as the gateway to the Baltic led to Skagen being the site of one of Denmark's earliest lighthouses, Vippefyr, a lever light constructed in 1627. A faithful copy has now been constructed on the site of the original.\n\nThe White Lighthouse (\"det Hvide fyr\") just north of the town is Denmark's oldest brick-built lighthouse. With a height of , it was designed by Philip de Lange and lit for the first time in 1747. In 1858, it was replaced by the Grey Lighthouse (\"det Grå fyr\") 2 km further north. Restored in 1960, the White Lighthouse now houses art exhibitions.\n\nThe old village church from the 14th century is now known as The Sand-Covered Church as only its tower can still be seen. Sand began drifting in from Råbjerg Mile around 1600, the area surrounding the church becoming affected by the desertification which destroyed the fields. In 1775, the church door had to be dug free for the congregation to be able to attend the service, and for the following 20 years, the Skageners struggled to keep the church free from sand, without being allowed to close it down. In 1795 the church was closed by royal decree and the body of the church demolished.\nA highlight of the year is the celebration of Midsummer Eve or St. John's Evening (\"Sankt Hans Aften\") on the beach with blazing bonfire and song.\n\nTowards the end of the 19th century, Skagen became the summer venue of a group of artists who were attracted by the way of life in the fishing village and by the opportunities for painting the fishermen and surrounding landscapes. Skagens Museum was founded on 20 October 1908 in the dining room at Brøndums Hotel. Among the founders were artists Michael Ancher, P.S. Krøyer and Laurits Tuxen, who were elected to form the first board of governors together with Victor Christian Klæbel, the local pharmacist, and Degn Brøndum, who was the proprietor of Brøndums Hotel and brother of Anna Ancher. In 1982, the exhibition rooms were extended with an annex designed by the Royal Surveyor, architect Jacob Blegvad. Blegvad also planned the later extension to the museum that was inaugurated in 1989. Today Skagens Museum has more than 1,900 works of art at its disposal.\n\nThe former residence of the two painters Anna and Michael Ancher dates from 1884 and was expanded with a studio designed by Ulrik Plesner in 1913. Their only child, Helga Ancher, who died in 1964, left the property to a foundation for conversion into a museum. Opened to the public in 1967, the house contains much of the original furniture, preserving the atmosphere of the artists' home. Together with the adjacent 18th-century Saxild House (\"Saxilds Gaard\"), it displays many of the Anchers' paintings as well as those of their artist friends. Saxild House hosts exhibitions and a museum café\n\nDrachmanns Hus on Hans Baghs Vej in the west of the town is a large property built in 1829. Now a museum, it is dedicated to the writer and marine painter Holger Drachmann who lived in the house from 1902 until his death in a sanatorium in Hornbæk in January 1908. Drachmann had regularly visited Skagen from 1871. Drachmann's House, first opened to the public on 4 June 1911, offers a collection not only of his own oil paintings and sketchbooks, but also of paintings from the colony's other artists including Krøyer, Tuxen and the Anchers. An annex contains a photographic exhibition about Drachmann. Every year, the house hosts a \"Drachmann evening\" in which enthusiasts gather together to hear readings, oral presentations and music related to the writer's life and works.\n\nIn central Skagen there is a teddy bear museum, \"Skagen Bamsemuseum\". The teddy bears on display belong to the private collection of the owner Jonna Thygesen. It is the only teddy bear museum in Scandinavia. Opened in 1998, the collection contains about a thousand bears of all kinds, some of historic value. The museum also has a sculptured garden, an ice café and a teddy bear shop. Special events are arranged at Easter and Christmas.\n\nThe Skagen Odde Nature Centre located close to the northern tip of the peninsula is a museum specially built to allow visitors to see, hear and understand more about the area's sand, water, wind and light. Each of the pavilions presents one of these elements in a special atmosphere. Designed by Jørn Utzon, it is the most northerly building on Skagen Odde.\n\nSkagen Town and Regional Museum (\"Skagen By- og Egnsmuseum\"), an open-air museum, was opened by the local population in 1927. In 1938 it was moved to the sand dunes of Vesterby. The museum brings together examples of fishermen's cottages and the homes of less fortunate inhabitants of Skagen in the middle of the 19th century. There is an old life-saving station, a smithy, an old Dutch windmill, pictures of ships in distress and related nautical artefacts as well as a collection of items illustrating the town's history over various periods.\n\nSkagen's first school was the \"Latinskole\", a grammar school, which was in operation from 1549 until 1739. By the end of the 19th century, three schools had been established in Skagen: one in Vesterby, another in Østerby and a third in Højen. As a result of evolving legislation, a new public primary school (\"Borgerskolen\") designed by A. Haunstrup was completed in 1901. A gymnasium was added in 1909 but in 1924 it was converted into classrooms to accommodate the growing number of pupils. A secondary school (\"Realskolen\") was opened in 1904 behind the former local authority building on Sct. Laurentii vej. The secondary school was later moved next to the primary school and in 1948 the buildings were extended. An additional two-storey wing was completed in 1969.\n\nIn 1921, Skagen's Skipper School was opened to train navigators for both fishing boats and merchant ships. It is now the only remaining skipper school in Denmark with some 100 students from the whole of Scandinavia and 15 staff. In 2012, the school moved into new premises close to the Kattegat. In 1955, the folkschool \"Ankermedets skole\" was opened on Skagavej, initially with 483 pupils and 16 classes. It has been extended several times over the years, most recently when a new wing was added in 2003. The private school \"Brovandeskolen\", a so-called free school, opened in 1977 for parents wishing to offer their children a new pedagogical approach. A primary goal is active cooperation between pupils, teachers and parents.\n\nSkagen's sports centre dates from 1974 when its large hall was completed. A smaller hall with bedrooms was built in 1999. The centre has facilities for badminton, basketball, handball, hockey and tennis in addition to its football fields. Overnight accommodation is also available. Skagen Idræts Klub, the local football club founded in 1946, plays in Jyllandsserien, one of the lower divisions in Denmark's football system. Skagen also has a badminton club and a tennis club, The Hvide Klit Golf Club is located some south of the town on the road to Ålbæk. In season, it is popular with tourists.\n\nThe Skagen Line connects Skagen with Frederikshavn Station in Frederikshavn to the south. Nordjyske Jernbaner operates a frequent train service between Skagen and Frederikshavn with onward connections by DSB to the rest of Denmark. Skagen Station, the most northerly railway station in mainland Denmark, is the principal station of the town. Skagen's first station, opened in 1890, was designed by Thomas Arboe. The current building, completed in 1919, is the work of the architect Ulrik Plesner. The western part of Skagen is also served by the Frederikshavnsvej railway halt.\n\nIn the summer, there are buses from Skagen to Blokhus via Hirtshals.\n\nFrom Frederikshavn, there are ferries to Gothenburg and Oslo. From Hirtshals, there are ferries to Stavanger, Bergen, Larvik, Faroe Islands and Langesund\n\nAalborg Airport with flights to destinations across Europe is located some southwest of Skagen. It can be reached by rail and metro.\n\nSkagen lies along Danish national road 40, also known as Frederikshavnsvej, which connects the town to Frederikshavn, via Ålbæk to the southeast. The stretch of the road between Skagen and Ålbæk was asphalted in 1932. Hirtshals on the western side of the peninsula can be reached by taking Road 597 from Ålbæk. The Bøjlevejen road is the main skirt road around the town to the north, along which lies the Skagen Odde Nature Centre. In the peak season during the summer months, Skagen can become congested with traffic. Free parking facilities are provided for short periods, and there is also a metered car park near the train station. As in other Danish cities, cycling is popular, and Skagen Cykeludlejning, to the west of the train station, and Pedersen on Kappelborgvej rent out bikes to tourists. There are a number of interesting marked cycle routes in and around Skagen. These include circuits for mountain bikes.\n\nAmong those born in Skagen are:\n\n\nAll the painters, writers and other members of the also have close associations with Skagen.\n\n\n\n\n"}
{"id": "6576473", "url": "https://en.wikipedia.org/wiki?curid=6576473", "title": "Smallest organisms", "text": "Smallest organisms\n\nThe smallest organisms found on Earth can be determined according to various aspects of organism size; including volume, mass, height, length, or genome size.\nGiven the incomplete nature of scientific knowledge, it is possible that the smallest organism is undiscovered. Furthermore, there is some debate over the definition of life, and what entities qualify as organisms; consequently the smallest known organism (microorganism) is debatable.\n\nMany biologists consider viruses to be non-living because they lack a cellular structure and cannot metabolize by themselves, requiring a host cell to replicate and synthesize new products. A minority of scientists hold that, because viruses do have genetic material and can employ the metabolism of their host, they can be considered organisms. As well, an emerging idea that is gaining traction among some virologists is the concept of the virocell, in which the actual phenotype of a virus is the infected cell, and the virus particle is simply a reproductive or dispersal stage, much like pollen or a spore.\n\nThe smallest viruses in terms of genome size are single-stranded DNA (ssDNA) viruses. Perhaps the most famous is the bacteriophage Phi-X174 with a genome size of 5386 nucleotides. However, some ssDNA viruses can be even smaller. For example, Porcine circovirus type 1 has a genome of only 1759 nucleotides and a capsid diameter of only 17 nm. As a whole, the viral family geminiviridae is only about 30 nm in length. However, the two capsids making up the virus are fused; divided, the capsids would be 15 nm in length. Other environmentally characterized ssDNA viruses such as CRESS DNA viruses as well as others can have genomes that are considerably less that 2,000 nucleotides.\n\nThe smallest RNA viruses in terms of genome size are small retroviruses such as rous sarcoma virus with genomes of 3.5 kilo base pairs (kb) and particle diameters of 80 nanometres (nm). The smallest double stranded DNA viruses are the hepadnaviruses such as Hepatitis B, at 3.2 kb and 42 nm; parvoviruses have smaller capsids, at 18-26 nm, but larger genomes, at 5 kb. It is important to consider other self replicating genetic elements, such as satelliviruses, viroids and ribozymes.\n\nThe genome of \"Nasuia deltocephalinicola\", a symbiont of the European pest leafhopper, Macrosteles quadripunctulatus consists of a circular chromosome of 112,031 base pairs.\n\n\"Nanoarchaeum equitans\"'s genome is 490,885 nucleotides long.\n\nPelagibacter ubique is one of the smallest known free-living bacterium with a length of 0.37-0.89 μm and an average cell diameter of 0.12-0.20 μm. They also have the smallest free-living bacterium genome; 1.8Mbp, 1354 protein genes, 35 RNA genes. They are one of the most common and smallest organisms in the ocean, with their total weight equaling more than all fish presently in the sea.\n\n\"Mycoplasma genitalium\", a parasitic bacterium which lives in the primate bladder, waste disposal organs, genital, and respiratory tracts, is thought to be the smallest known organism capable of independent growth and reproduction. With a size of approximately 200 to 300 nm, \"M. genitalium\" is an ultramicrobacterium, smaller than other small bacteria, including rickettsia and chlamydia. However, the vast majority of bacterial strains have not been studied, and the marine ultramicrobacteria \"Sphingomonas\" sp strain RB2256 is reported to have passed through a 220 nm ultrafilter. A complicating factor is nutrient-downsized bacteria, bacteria that become much smaller due to a lack of available nutrients.\n\"Nanoarchaeum equitans\" is a species of tiny microbe 400 nm in diameter. It was discovered in 2002 in a hydrothermal vent off the coast of Iceland by Karl Stetter. A thermophile that grows in near-boiling temperatures, \"Nanoarchaeum\" appears to be an obligatory symbiont on the archaeon \"Ignicoccus\"; it must be in contact with the host organism to survive.\n\nPrasinophyte algae of the genus \"Ostreococcus\" is the smallest free-living eukaryote. The single cell of an \"Ostreococcus\" measures only 0.8 μm across.\n\nSeveral species of Myxozoa (obligately parasitic cnidarians) never grow larger than 20 µm. One of the smallest species (\"Myxobolus shekel\") is no more than 8.5 µm when fully grown.\n\nThe shell of the nut clam \"Condylonucula maya\" grows only 0.54 mm long.\nThe smallest water snail (of all snails) is \"Ammonicera minortalis\" in North America, originally described from Cuba. It measures 0.32 to 0.46 mm.\n\nThe smallest land snail is \"Acmella nana\". Discovered in Borneo, Malaysia, and described in November 2015, it measures only 0.7 mm. The previous record was that of \"Angustopila dominikae\" from China, which was reported in September 2015. This snail measures 0.86 mm.\n\nThe smallest crustacean, and indeed the smallest arthropod, is the tantulocarid \"Stygotantulus stocki\", at a length of only .\n\nEriophyid mites measure 125 to 250 μm in length.\n\nAdult males of the parasitic wasp \"Dicopomorpha echmepterygis\" can be as small as 139 μm long, smaller than some species of protozoa (single-cell creatures); females are 40% larger.\n\n\"Megaphragma caribea\" from Guadeloupe, measuring 170 μm long, is another contender for smallest known insect in the world.\nBeetles of the tribe Nanosellini are all less than 1 mm long; the smallest confirmed specimen is of \"Scydosella musawasensis\" at 325 μm long; a few other nanosellines are reportedly smaller, in historical literature, but none of these records have been confirmed using accurate modern tools. These are among the tiniest non-parasitic insects.\n\nThe western pygmy blue (\"Brephidium exilis\") is one of the smallest butterflies in the world.\n\nThe smallest sea cucumber, and also the smallest echinoderm, is \"Psammothuria ganapati\", a synaptid that lives between sand grains on the coast of India. Its maximum length is only 4 mm.\nThe smallest sea urchin, \"Echinocyamus scaber\", has a test only 6 mm across.\n\n\"Patiriella parvivipara\" is the smallest starfish, at only 5 mm across.\n\nThe smallest vertebrates (and smallest amphibians) known are \"Paedophryne amauensis\" frogs from Papua New Guinea, which range in length from , and average . Previously, the title of smallest vertebrate was held by members of the fish genus \"Paedocypris\" of Indonesia.\n\nThe world's smallest fish based on the minimum size at maturity is \"Paedocypris progenetica\" from Indonesia, with mature females measuring as little as in standard length. This fish, a member of the carp family, has a translucent body and a head unprotected by a skeleton.\n\nMale individuals of the anglerfish species \"Photocorynus spiniceps\" have been documented to be at maturity, and thus claimed to be a smaller species. However, these survive only by sexual parasitism and the female individuals reach the significantly larger size of .\n\nThe average snout-to-vent length of several specimens of the salamander \"Thorius arboreus\" was only .\n\nFrogs include the smallest vertebrates known. The smallest known frog species is \"Paedophryne amauensis\", with a snout-vent length reported as 7.7 mm, which occurs among leaf-litter in the tropical montane forests of New Guinea. Other very small frogs include \"Brachycephalus didactylus\" from Brazil (reported as 9.6-9.8 mm), several species of \"Eleutherodactylus\" such as \"Eleutherodactylus iberia\" (around 10mm) from Cuba, Gardiner's Frog \"Sechellophryne gardineri\" from the Seychelles (up to 11 mm), several species of \"Stumpffia\" such as \"Stumpffia tridactyla\" and \"Stumpffia pygmaea\" from Madagascar, and the Rough Moss-frog \"Arthroleptella rugosa\" of South Africa (11.9 - 14.1 mm). In general these extremely small frogs occur in tropical forest and montane environments. There is relatively little data on size variation among individuals, growth from metamorphosis to adulthood or size variation among populations in these species. Additional studies and the discovery of further minute frog species are likely to change the rank order of this list.\n\nThe dwarf gecko (\"Sphaerodactylus ariasae\") and the Virgin Islands dwarf sphaero (\"S. parthenopion\"), two geckos in the genus \"Sphaerodactylus\", are the world's smallest known reptile species and smallest lizard, with a snout-vent length of . A few \"Brookesia\" chameleons from Madagascar are equally small, with a reported snout-vent length of 15–18  millimetres for male dwarf chameleons (\"B. minima\"), 14–19  millimetres for male Mount d'Ambre leaf chameleons (\"B. tuberculata\") and 15–16  millimetres for male \"B. micra\", though females are larger.\nOf the aforementioned geckos, \"S. ariasae\" was first described in 2001 by the biologists Blair Hedges and Richard Thomas. This dwarf gecko is endangered and lives in Jaragua National Park in the Dominican Republic and on Beata Island (\"Isla Beata\"), off the southern coast of Hispaniola in the Dominican Republic.\n\nThe world's smallest turtle is the speckled padloper tortoise (\"Homopus signatus\") from South Africa. The males measure , while females measure up to almost .\n\nThe smallest crocodilian is the Cuvier's dwarf caiman (\"Paleosuchus palpebrosus\") from northern and central South America. It reaches up to in length.\n\nOne of the smallest snakes known is the recently discovered Barbados threadsnake (\"Leptotyphlops carlae\"). Adults average about long, which is only about twice as long as the hatchlings.\n\nThe smallest known dinosaur (excluding modern birds) is \"Anchiornis\", a genus of feathered dinosaur that lived in what is now China during the Late Jurassic Period 160 to 155 million years ago. Adult specimens range from long, and the weight has been estimated at up to . Nevertheless, sizes of dinosaurs are commonly labelled with a level of uncertainty, as the available material often (or even usually) is incomplete.\n\nWith a mass of approximately and a length of 5 centimetres (2.0 in), the bee hummingbird (\"Mellisuga helenae\") is the world's smallest bird species and the smallest warm-blooded vertebrate. Called the \"zunzún\" in its native habitat on Cuba, it is lighter than a Canadian or U.S. penny. It is said that it is \"more apt to be mistaken for a bee than a bird\". The bee hummingbird eats half its total body mass and drinks eight times its total body mass each day. Its nest is 3 cm across.\n\nThe vulnerable Kitti's hog-nosed bat (\"Craseonycteris thonglongyai\"), also known as the bumblebee bat, from Thailand and Myanmar is the smallest mammal, at in length and in weight.\n\nThe Etruscan shrew (\"Suncus etruscus\"), is the smallest mammal by mass, weighing only about on average. The bumblebee bat has a smaller skull size. The smallest mammal that ever lived, the shrew-like \"Batodonoides vanhouteni\", weighed only .\n\nThe smallest member of the rodent order is the Baluchistan pygmy jerboa, with an average body length of only 4.4 cm (1.7 in).\n\nThe smallest member of the order Carnivora is the least weasel (\"Mustela nivalis\"), with an average body length of 114–260 mm (4.5-10.2 in). It weighs between 29.5 – 250 grams with females being lighter.\n\nThe smallest marsupial is the Long-tailed planigale from Australia. It has a body length of (including tail) and weigh on average.\n\nThe Pilbara ningaui is considered to be of similar size and weight.\n\nThe smallest member of the primate order is Madame Berthe's mouse lemur (\"Microcebus berthae\"), found in Madagascar, with an average body length of 92 mm (3.6 in).\n\nThe smallest cetacean, which is also (as of 2006) the most endangered, is the vaquita. Male vaquitas grow to an average of around 135 cm (53 in); the females are slightly longer, averaging about 141 cm (55 in) in length.\n\nDuckweeds of the genus \"Wolffia\" are the world's smallest flowering plants. Fully grown, they measure only 300 µm by 600 µm and reach a mass of just 150 µg.\n\nNanobes are thought by some scientists to be the smallest known organisms \nabout one tenth the size of the smallest known bacteria. Nanobes, tiny filamental structures first found in some rocks and sediments, were first described in 1996 by Philippa Uwins of the University of Queensland.\n\n"}
{"id": "7962469", "url": "https://en.wikipedia.org/wiki?curid=7962469", "title": "Ultra-linear", "text": "Ultra-linear\n\nUltra-linear electronic circuits are those used to couple a tetrode or pentode vacuum-tube (also called \"electron-valve\") to a load (e.g. to a loudspeaker).\n\n'Ultra-linear' is a special case of 'distributed loading'; a circuit technique patented by Alan Blumlein in 1937 (Patent No. 496,883), although the name 'distributed loading' is probably due to Mullard. In 1938 he applied for the US patent 2218902. The particular advantages of ultra-linear operation, and the name itself, were published by David Hafler and Herbert Keroes in the early 1950s through articles in the magazine \"Audio Engineering\" from the USA. The special case of 'ultra linear' operation is sometimes confused with the more general principle of distributed loading.\n\nA pentode or tetrode vacuum-tube (valve) configured as a common-cathode amplifier (where the output signal appears on the plate) may be operated as:\n\n\nThe impression of any portion of the output signal onto the screen-grid can be seen as a form of feedback, which alters the behaviour of the electron stream passing from cathode to anode.\n\nBy judicious choice of the screen-grid percentage-tap, the benefits of both triode and pentode vacuum-tubes can be realised. Over a very narrow range of percentage-tapping, distortion is found to fall to an unusually low value—sometimes less than for either triode or pentode operation—while power efficiency is only slightly reduced compared with full pentode operation. The optimum percentage-tap to achieve ultra-linear operation depends mainly on the type of valve used; a commonly seen percentage is 43% (of the number of transformer primary turns on the plate-circuit) which applies to the KT88, although many other valve types have optimum values close to this. A value of 20% was recommended for 6V6GTs. Mullard circuits such as the 5-20 also used 20% distributed loading (but did not achieve ultra-linear operation), while LEAK amplifiers used 50%.\n\nThe characteristics of the circuit which make distributed loading suitable for audio power amplifiers, when compared to a tetrode or pentode amplifier, are:\n\n\nThe distributed load circuit may be applied to either push-pull or single-ended amplifier circuits.\n\nNote that the term 'ultra linear' was expressly reserved only for the condition of optimum tapping point. As Hafler and Keroes wrote:\n\"\"Our patent claims cover the use of any primary tap in this circuit arrangement. However, we have restricted the use of the term \"Ultra Linear\" to the conditions where the dynamic plate characteristic curves are most linear\"\".\n\nThe \"QUAD II\" amplifier from QUAD uses a circuit in which the cathode has a portion of the output signal applied to it, and was referred to as \"distributed load\" by Peter Walker of QUAD. In the United States, McIntosh Laboratories used this technique extensively in their vacuum-tube power amplifiers. Audio Research Corp have also used a similar circuit.\n"}
{"id": "42181409", "url": "https://en.wikipedia.org/wiki?curid=42181409", "title": "Violette Cordery", "text": "Violette Cordery\n\nViolette Cordery, (10 January 1900 – 30 December 1983) (married name Hindmarsh) was a British racing driver and long distance record breaker.\n\nCordery was born in London to Henry Cordery and had an elder sister (Lucy)/Leslie and a younger sister Evelyn who also participated in her driving exploits.\n\nCordery was employed as a driver to captain Noel Macklin of the Royal Naval Volunteer Reserve (RNVR) at Dover. He subsequently invalided out of the Royal Artillery in 1915 and transferred to the RNVR. Macklin was married to her elder sister Lucy.\nIn 1920 she competed in the South Harting hill climb driving a Silver Hawk, manufactured by Noel Macklin. Cordery also competed in two British Motor Cycle Racing Club handicap events driving an Eric-Campbell, also manufactured by Noel Macklin. In May 1921 she won the ladies' race at the Junior Car Club meeting, averaging .\n\nIn 1925 she publicised the new Invicta car, also manufactured by Noel Macklin, by racing and breaking records. At the West Kent Motor Club meeting at Brooklands she won the half mile sprint in a 2.7 litre Invicta, and went on other victories and records.\n\nIn 1926 she set a long distance record at the Autodromo Nazionale Monza, Italy, when she co-drove a 19.6 hp Invicta for at . In July 1926 she averaged for at Autodrome de Linas-Montlhéry, Paris, and became the first woman to be awarded the Dewar Trophy by the Royal Automobile Club.\n\nIn 1927 she drove an Invicta around the world in five months, covering at an average speed of . She traveled through Europe, Africa, India, Australia, the United States, and Canada accompanied by a nurse, a mechanic, and a Royal Automobile Club observer.\n\nIn 1929, with her younger sister Evelyn, she covered of the Brooklands circuit within 30,000 minutes (approximately 20 days, 20 hours) at an average speed and earning a second Dewar Trophy from the Royal Automobile Club. By 1930 her 4.5-litre Invicta tourer had completed return journeys from London to Monte Carlo, London to John O'Groats and London to Edinburgh.\n\nCordery married the racing driver and aviator John Stuart Hindmarsh on 15 September 1931 at Stoke D'Abernon parish church. They had two daughters, of whom Susan married the racing driver Roy Salvadori. Widowed in 1938 by Hindmarsh's death while test flying a Hawker Hurricane, she retired from public life until her death on 30 December 1983 in Oxshott, Surrey. She was cremated at Randalls Park crematorium.\n\n"}
{"id": "11677633", "url": "https://en.wikipedia.org/wiki?curid=11677633", "title": "Withy", "text": "Withy\n\nA withy or withe is a strong flexible willow stem, typically used in thatching and for gardening.\n\nSeveral species and hybrid cultivars of willows (often known as osiers) are grown for withy production; typical species include \"Salix acutifolia\", \"Salix daphnoides\", \"Salix × mollissima\", \"Salix purpurea\", \"Salix triandra\", and \"Salix viminalis\".\n\nThe term is also sometimes used to describe any type of flexible rod used in rural crafts such as hazel or ash.\n\nWithies traditionally serve to mark minor tidal channels in UK harbours and estuaries. In many places they remain in use and are often marked on navigation charts. At high tide the tops of a line of withies stuck in the mud on one or both sides of a channel will show above water to indicate where the deeper water lies. Note the images of international navigation-chart symbols for withies (port and starboard).\n\nPlaces such as Wythenshawe and Withy Grove (both in Manchester) take their names from the willow woods and groves that grew there in earlier times. The Somerset Levels remain the only area in the UK growing basket willow commercially.\n\n\n"}
