{"id": "42674255", "url": "https://en.wikipedia.org/wiki?curid=42674255", "title": "2014 Ontario fireball", "text": "2014 Ontario fireball\n\nOn 4 May 2014 around 4:17pm (EDT) a daylight bolide occurred near Ontario. The meteoroid was estimated to be roughly in diameter. The air burst was estimated to be equivalent to approximately 10–20 tons of TNT. The meteor was first seen in Peterborough and traveled on a southwest-to-northeast trajectory. A meteor of this size impacts Earth about twice a week.\n\nThe meteor was large enough that it may have generated meteorites. A strewn field has not yet been located but would be downstream after dark flight. Weather radar returns suggest that the meteorite(s) may have landed near Codrington.\n\n"}
{"id": "17025000", "url": "https://en.wikipedia.org/wiki?curid=17025000", "title": "Atlantic Equatorial coastal forests", "text": "Atlantic Equatorial coastal forests\n\nThe Atlantic Equatorial coastal forests are a tropical moist broadleaf forest ecoregion of central Africa, covering hills, plains, and mountains of the Atlantic coast of Cameroon, Equatorial Guinea, Gabon, Republic of the Congo, Angola, and Democratic Republic of the Congo.\n\nThis is rich forest home to large mammals such as western gorilla, chimpanzees, forest elephants and African buffalo, as well as many small mammals, birds, amphibians, reptiles, and invertebrates. As well as chimpanzees and gorillas other primates include black colobus monkeys and mandrills.\n\nThe Atlantic Equatorial coastal forests cover an area of , extending along the Atlantic coast from low hills in the north to mountains further south and east. The forests cover Cameroon's southwest corner, mainland Equatorial Guinea (Río Muni) and the coastal plains of Gabon. A narrow strip extends southeast through Republic of the Congo and the eastern portion the Cabinda enclave of Angola to just north of the Congo River in Bas-Congo province of Democratic Republic of the Congo.\n\nThe Atlantic Equatorial coastal forests form the southernmost part of the Lower Guinean forests complex, a region of coastal moist broadleaf forests that extend north and west into southwestern Cameroon and southern Nigeria. The Atlantic Ocean lies to the west, and pockets of the Central African mangroves can be found along the brackish river mouths and estuaries along the coast. The region extends south from the Sanaga River in Cameroon down to just north of the River Congo, with a number of other large rivers running through. To the east, the coastal forests transition to the Northwestern Congolian lowland forests, part of the vast Congolian forests complex that covers the Congo Basin. The Western Congolian forest-savanna mosaic bounds the Atlantic Equatorial coastal forests to the southeast.\n\nThis is a tropical ecoregion receiving high rainfall throughout the year.\n\nAlong with the neighbouring Cross-Sanaga-Bioko Coastal Forests ecoregion the area holds about 50% of the endemic plant life of tropical West Africa. Particularly important areas for plant life include the Monts de Cristal in Gabon and the Mayombe area on the borders of the Republic of the Congo, Angola, and the Democratic Republic of the Congo.\n\nThe area contains a number of endemic forest mammals including sun-tailed monkey, long-footed shrew, lesser Angolan epauletted fruit bat, and African smoky mouse as well as the forest elephant and the gorillas, chimpanzees and other primates mentioned above. The forests are also rich in bird life. Endemic reptiles include the Apouh night frog (\"Astylosternus schioetzi\"), Perret's snout-burrower, Gabon dwarf clawed frog (\"Hymenochirus feae\"), Ogowe River frog (\"Phrynobatrachus ogoensis\"), and Andre's clawed frog.\n\nMany of the animals here, including the primates, are endangered by hunting for meat or as prizes while elephants are poached for meat and for the ivory trade. Logging is a continuing threat in Cameroon, Gabon, the Republic of Congo and particularly in Equatorial Guinea. However extensive areas of forest remain and the fauna is still especially rich in the southern parts of Equatorial Guinea and in Gabon, which has designated large areas as national parkland, including Loango National Park in this ecoregion.\n\nThis is a thinly populated region. South Region (Cameroon) is heavily forested and contains the coastal resort of Kribi and the Campo Ma'an National Park. All of mainland Equatorial Guinea (Río Muni is in this region including the port of Bata. In Gabon, as well as logging camps, the forests are inhabited by small groups of agricultural and fishing people including traditional forest dwellers such as the Bakola and Bagyeli. Gabonese towns among the coastal forests include Lambaréné, home of the Albert Schweitzer Hospital, the logging base of Ndjolé, Fougamou base for visiting the Waka National Park and Gamba, oil hub but also base for visiting Loango National Park.\n"}
{"id": "11070221", "url": "https://en.wikipedia.org/wiki?curid=11070221", "title": "Barkcamp State Park", "text": "Barkcamp State Park\n\nBarkcamp State Park is a public recreation area located in Belmont County, Ohio, United States, near the village of Belmont. The state park centers around Belmont Lake, which was once considerably smaller than its present-day predecessor. The Barkcamp Creek, the namesake for the park, once ran through the area until the dam was completed in 1963, thus reducing the outflow of water. The area once housed a logging camp where logs were stripped of bark in preparation for delivery to the mill. The Ohio Department of Natural Resources began land acquisition for the park in 1955 and developed the property into a fishing and game reserve. The park houses over 150 campsites (including equestrian facilities), miles of hiking and horseback riding trails, basketball courts, boat ramps, beach, as well as other recreational sites. The park ranger once lived on the site and the house still stands inside the park.\n\n"}
{"id": "3266881", "url": "https://en.wikipedia.org/wiki?curid=3266881", "title": "Constellation Observing System for Meteorology, Ionosphere, and Climate", "text": "Constellation Observing System for Meteorology, Ionosphere, and Climate\n\nConstellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC) is a program designed to provide advances in meteorology, ionospheric research, climatology, and space weather by using GPS satellites in conjunction with low Earth orbiting (LEO) satellites. The term \"COSMIC\" may refer to either the organization itself or the constellation of satellites (also known as FORMOSAT-3, 福爾摩沙衛星三號, in Taiwan). The constellation is a joint U.S.-Taiwanese project with major participants including the University Corporation for Atmospheric Research (UCAR), the National Science Foundation, the Naval Research Laboratory (NRL), the Air Force Research Laboratory (AFRL) on the U.S. side and the National Space Organization (NSPO) on the Taiwanese side.\n\nThe total cost of the project is US$100 million, 80% of which is being provided by NSPO, and the remainder by various U.S. agencies.\n\nAfter experiencing several delays, the launch of the COSMIC satellite constellation atop a Minotaur launch vehicle from Vandenberg AFB occurred at 01:40 GMT, on April 15, 2006, despite heavy fog. The satellites, which orbit at an altitude of 500 miles, required over a year to move into the correct positions to provide full global coverage.\n\nThe COSMIC satellites are equipped with three primary forms of instrumentation for remote sensing, including:\n\nAll 6 microsatellites were launched on a single launch vehicle and deployed into a single parking orbit after launch. The spacecraft were then deployed into separate orbital planes through the use of precession due to the oblateness of the Earth and raised to a final orbital altitude over the course of several months. Scientific data were collected during the deployment process, along with experimental validation and calibration.\n\nCurrently only four of the microsatellites remain fully functional. The FM2's power system lost 50% of its output in February 2007, while FM3's solar panel also malfunctioned since August 2007. As a result, both satellites are operating in a degraded state, capable of returning data only during specific solar angles. The FM6 went out of control in September 2007, but control was restored by November 16 of the same year.\nFM3 had severe power problem since July 6, 2010. It is declared not functional since then. FM4, FM5, and FM6 have had battery aging problem.\n\n\n\n\n"}
{"id": "28578885", "url": "https://en.wikipedia.org/wiki?curid=28578885", "title": "Dead-ice", "text": "Dead-ice\n\nDead-ice occurs when a glacier or ice sheet ceases to move and melts in situ. After the ice has melted it leaves behind a hummocky terrain produced by the deposition of glacio-fluvial sediments and ablation till as the ice melted. Such features include kettle holes. Landscape forming Veiki moraines in northern Sweden and Canada have been ascribed as the result of ablation of extensive bodies of till-covered dead-ice.\n"}
{"id": "894988", "url": "https://en.wikipedia.org/wiki?curid=894988", "title": "Donald C. Peattie", "text": "Donald C. Peattie\n\nDonald Culross Peattie (June 21, 1898 – November 16, 1964) was an American botanist, naturalist and author. He was described by Joseph Wood Krutch as \"perhaps the most widely read of all contemporary American nature writers\" during his heyday. His brother, Roderick Peattie (1891–1955), was a geographer and a noted author in his own right. Some have said that Peattie’s views on race may be considered regressive, but that expressions of these views are \"mercifully brief and hardly malicious\".\n\nPeattie was born in Chicago to the journalist Robert Peattie and the novelist Elia W. Peattie. He studied French poetry for two years at the University of Chicago and then transferred to – and graduated (1922) from — Harvard University, where he studied with the noted botanist Merritt Lyndon Fernald. After field work in the Southern and Mid-West United States, he worked as a botanist for the U.S. Department of Agriculture (1922–1924). He was then nature columnist for the \"Washington Star\" from 1924 to 1935. At some point in the late 1920s Peattie and his wife, with their four-year-old daughter and baby son, moved to Paris to \"launch the frail bark of our careers\". At two days in Paris the daughter died \"of a malady unsuspected and always fatal\". In a \"search for sunlight\" they re-settled in Vence in the south. Another son was born there.\n\nPeattie was an advocate for protecting the Indiana Dunes. He served on the Save the Dunes Council in the late 1950s, helping to bring Illinois' Senator Paul Douglas into the fight to protect the Indiana Dunes from industrial development.\n\nPeattie's nature writings are distinguished by a poetic and philosophical cast of mind and are scientifically scrupulous. His best known works are the two books (out of a planned trilogy) on North American trees, \"A Natural History of Trees of Eastern and Central North America\" (1950) and \"A Natural History of Western Trees\" (1953), with woodcut illustrations by Paul Landacre. Peattie also produced children's and travel books, altogether totaling almost forty volumes. He also published the classic, botanical treatment on the \"Flora of the Indiana Dunes\" (1930).\n\nAn example of Peattie's views that can be construed as racist is the following, from \"An Almanac for Moderns\": \"Every species of ant has its racial characteristics. This one seems to me to be the negro of ants, and not alone from the circumstance that he is all black, but because he is the commonest victim of slavery, and seems especially susceptible to a submissive estate. He is easily impressed by the superior organization or the menacing tactics of his raiders and drivers, and, as I know him, he is relatively lazy or at least disorganized, random, feckless and witless when free in the bush, while for his masters he will work faithfully.\"\n\nOn the other hand, there's a strain of at least mild anti racism often discernible in Peattie's commentary. For example, in his discussion of Linnaeus, the Swedish founding father of taxonomy, Peattie describes, in 1936, how Linnaeus grew up in a small, provincial town far from the scientific capitals of Europe: \"To the astonishment of all the wise men, he (Linnaeus) was not a product of Wittenberg, or the parks of Versailles or even of English country life, that nurse of so much delicate feeling for natural beauty. But genius so seldom grows where the highly born and the members of the eugenical societies tell us to expect it!\" (This is a slap against the American Eugenics Society, a national group formed in 1921, which was prominent in the 1930s, promoting \"racial betterment.\" During that time, the group consisted of \"mostly prominent and wealthy members who more often than not were non-scientists.\" ) \n\nFurthermore, according to Peattie's grandson, David Peattie, \"In the period following the bombing of Pearl Harbor... [Donald Culross Peattie] spoke out eloquently against the internment of Japanese Americans, and wrote letters to the editor in their defense\" . That was after he witnessed a Japanese gardener, who had been hired by the owner of a house he was renting in California, interred in the camps.\n\n\n"}
{"id": "7052986", "url": "https://en.wikipedia.org/wiki?curid=7052986", "title": "EI Niš", "text": "EI Niš\n\nEI Niš (full legal name: Holding-Korporacija Elektronska industrija a.d. Niš) or Electronics Industry Niš, is a holding company with headquarters in Niš, Serbia. It declared bankruptcy in May 2016.\n\nIt originated in 1948 from the foundation of the Institute for the Production of Radio Sets and Roentgen Machines, \"RR Niš.\" In the 1970s and 1980s it was one of the greatest Yugoslavian companies employing over 10 thousand people. However, during the 1990s most of the company business collapsed, due to lack of investing in research and sanctions the country was facing.\n\nDuring the 2000s, the company manufactured acoustic equipment, electronic tubes including cathode-ray tubes, printed plates, electronic machine elements, hydraulics, pneumatics, appliances, air-conditioners, medical equipment, roentgen machines, TV sets, radio receivers, and semiconductors. It was one of the few remaining makers of electronic vacuum tubes.\n\n\n"}
{"id": "2904575", "url": "https://en.wikipedia.org/wiki?curid=2904575", "title": "East Asian rainy season", "text": "East Asian rainy season\n\nThe East Asian rainy season, commonly called the plum rain (; , ), is caused by precipitation along a persistent stationary front known as the Mei-Yu front for nearly two months during the late spring and early summer between eastern Russia, China, Korea, and Japan. The wet season ends during the summer when the subtropical ridge becomes strong enough to push this front north of the region.\n\nAn east-west zone of disturbed weather during spring along this front stretches from the east China coast, initially across Taiwan and Okinawa, later, when it has shifted to the north, eastward into the southern peninsula of South Korea and Japan. The rainy season usually lasts from May to June in Taiwan and Okinawa, from June to July (approximately 50 days) in Russian Primorsky Krai, Japan and Korea and from July to August in Eastern China (especially the Chang Jiang and Huai River regions).\n\nThe weather front forms when the moist air over the Pacific meets the cooler continental air mass. The front and the formation of frontal depressions along it brings precipitation to Primorsky Krai, Japan, Korea, eastern China, and Taiwan. As the front moves back and forth depending on the strength of cool and warm air masses, there is often prolonged precipitation and sometimes flooding in eastern China. However, in the years that it does not rain as much as usual, a drought might result. The rainy season ends when the warm air mass associated with the subtropical ridge is strong enough to push the front north and away.\n\nThe high humidity in the air during this season encourages the formation of mold and rot not only on food but on fabrics as well.\nEnvironmentally, heavy rains encourage mudslides and flooding in all areas affected. The most rain in a one-hour period as recorded in Japan was in Nagasaki in 1982 with 153 mm. The highest overall recorded rainfall during the rainy season in Japan was in 2003, when Miyazaki Prefecture recorded rains of 8670 mm.\n\nIn Japan, the rainy season lasts from early June to mid-July for most of the country (on the main island of Honshū and the islands of Kyūshū and Shikoku), approximately June 7 to July 20 for the main Kansai and Kantō regions. It comes a month earlier to Okinawa in the south (early May through mid-June), but Hokkaidō in the north is largely unaffected. The season is occasionally called on account of this timing. The enka artist Eiichi Ōtaki produced a popular song by this name, and a WW2 Japanese naval ship was also given this name.\n\nThe rains in the middle of November - early December are sometimes called the \"Sazanka Tsuyu\", literally \"rainy season of the Camellia\" on account of the timing with the blossoming of the seasonal flower.\n\nThis period is generally avoided for tourism, but some sights are considered particularly atmospheric in the rain and fog, particularly mountain forests, notably Sacred Sites and Pilgrimage Routes in the Kii Mountain Range (including Mount Kōya). Vegetation, especially moss, is also rather lush at this time, and hence sights known for their moss, such as Saihō-ji (the moss temple) are also popular at this time of year.\n\nThe rainy season is between June and mid-July. It is caused by hot and humid high pressure forming in the Sea of Okhotsk due to the North Pacific anticyclone combining with Asiatic continental high pressure. When the two meteorological events meet they form a long \"jangmajeonseon\" (Hanja: 장마前線). Beginning in late-May, the North Pacific high pressure forces the weaker continental anticyclone south of the island of Okinawa. This fall to the south then reverses and gradually strengthens as it moves northwards back towards the Korean peninsula. On landfall, heavy monsoon rains lead to torrential downpours and flooding. By August the system has weakened as the southern systems retreat towards the Filipino archipelago.\n\nBy early autumn, the North Pacific high pressure system is pushed away as Asiatic continental cold high pressure moves southwards. This produces inclement weather although not on the scale of the summer monsoons. Korea can, however, be struck by typhoons during this period.\n\nIn some years, the rainy season's actual beginning and end are under debate. For example, in 2005, the subtropical ridge moved quickly northward in late June/early July. The weather front skipped the Chang Jiang region and there was no rainy season there. Then, the ridge retreated southward and there was significant rainfall in the region. This gave rise to the question of whether this was the summer-type rainfall pattern that is common after the first rainy season or the second rainy season. Some meteorologists even argued that the rainy period in late June was not a true rainy season.\n\n"}
{"id": "595147", "url": "https://en.wikipedia.org/wiki?curid=595147", "title": "Edward L. Beach Jr.", "text": "Edward L. Beach Jr.\n\nEdward Latimer Beach Jr. (April 20, 1918 – December 1, 2002), nicknamed \"Ned\", was a highly decorated United States Navy submarine officer and best-selling author.\n\nDuring World War II, he participated in the Battle of Midway and 12 combat patrols, earning 10 decorations for gallantry, including the Navy Cross. After the war, he served as the naval aide to the President of the United States, Dwight D. Eisenhower, and commanded the first submerged circumnavigation.\n\nBeach's best-selling novel, \"Run Silent, Run Deep\", was made into the 1958 movie by the same name. The son of Captain Edward L. Beach Sr. and Alice Fouché Beach, Beach Jr., was born in New York City and raised in Palo Alto, California.\n\nBeach was appointed to the U.S. Naval Academy in 1935 by Senator Hiram Johnson of California. Beach served as a regimental commander in his first class year. Beach was named as the midshipman who had done the most to promote naval spirit and loyalty in his regiment when he graduated second out of 576 men in his class in 1939.\n\nBeach was initially assigned to the heavy cruiser , before joining the newly recommissioned destroyer , which participated in the neutrality patrol in the Atlantic, the escort of the German passenger liner , the initial American occupation of Iceland, and convoy duty in the North Atlantic.\n\nBeach was detached from \"Lea\" in September 1941 to undergo accelerated training at the Submarine Training School at the New London Submarine Base in Connecticut. He completed training, graduating first in his class, in December 1941 shortly after the attack on Pearl Harbor.\n\nDuring World War II Beach served aboard the submarines and , and took command of just as the Pacific War was ending.\n\nBeach was assigned to the new commissioned USS \"Tirante\" (SS-420) late in 1944. He served as executive officer under Lieutenant Commander George L. Street, who was awarded the Medal of Honor for a making a daring attack in a heavily defended Japanese harbor during \"Tirante\"s first war patrol from 3 March to 26 April 1945. Beach received the Navy Cross for heroism during the same patrol and \"Tirante\" received the Presidential Unit Citation.\n\nBeach assumed command of USS \"Piper\" (SS-409) at Pearl Harbor on 25 June 1945. \"Piper\" departed on her third war patrol on 19 July and entered the Sea of Japan on 13 August. The war ended on 14 August and \"Piper\" was in Japanese waters when the formal surrender was signed on 2 September and started her return to Pearl Harbor the next day.\n\nDuring World War II, Beach earned 10 decorations for gallantry, including the Navy Cross and three unit citations, and participated in 12 war patrols that damaged or sank 45 enemy vessels.\n\nIn December 1945, Beach reported to the Department of the Navy to serve as the personal aide to Vice Admiral Louis E. Denfeld, the chief of the Bureau of Naval Personnel. In March 1947, he was attached to the Atomic Defense Section (OPNAV 36) under Rear Admiral William S. Parsons.\n\nIn May 1948, he was given command of , a GUPPY II modified submarine. \"Amberjack\" gained the nickname \"Anglejack\" because of its pioneering use of steep diving and surfacing angles, which was immortalized in the January 1950 edition of the \"National Geographic\" magazine. During war games, \"Amberjack\" photographed the opposing task force's flagship through its periscope and sent the admiral a copy inscribed with \"Regards from Ned Beach and the Amberjack.\".\nHis tour as skipper of \"Amberjack\" was abbreviated as he was called to Washington to serve as Naval Aide to General Omar Bradley, USA, the first Chairman of the Joint Chiefs of Staff, in August 1949. In that post, Beach witnessed first hand the events surrounding the Revolt of the Admirals.\n\nUpon completing his tour of duty as Bradley's aide in March 1951, Beach was named prospective commanding officer of the new , then under construction. Upon commissioning of \"Trigger II\", which was named for lost during World War II, he became commanding officer of the second submarine to be completed in the new after World War II.\n\nFrom 1953 to 1957, Beach was Naval Aide to President Dwight D. Eisenhower. As Naval Aide Beach was responsible for the management of Camp David, the White House Mess, and for the presidential yacht . Because Eisenhower had made a campaign promise to get rid of the presidential yacht, neither the efforts of Beach nor those of Mrs. Eisenhower were successful in dissuading him from that course of action. The elimination of \"Williamsburg\" proved to be a bureaucratic hassle for Beach and the Navy Department since \"Williamsburg\" was the funnel for all budgets and personnel for Camp David and the White House Mess. While working the White House, Beach volunteered to be the coordinator on the White House staff for all plans to protect the President in case of nuclear attack. Since the Secret Service in 1953 did not deem helicopter travel as safe, evacuating the President on short notice was planned by Beach via the Potomac River, several PT (patrol torpedo) boats and a high speed race down river to meet up with a waiting Navy ship. It was Beach who spearheaded the effort to get First Lady Mamie Eisenhower to christen , the world's first nuclear-powered submarine, in 1954.\n\nBeach was advanced to the rank of captain on October 1, 1956.\n\nBeach left the White House in January 1957, and assumed command of , a fleet replenishment oiler, on March 15. He completed a deployment to the U.S. Sixth Fleet, operating in the Mediterranean Sea, in December 1957.\n\nIn January 1958, he attended the Navy's training program for atomic reactors in order to qualify for his next command, , the nation's fifth nuclear-powered submarine.\n\nIn November 1959, Beach took command of USS \"Triton\", the only American nuclear-powered submarine to be equipped with two nuclear reactors. Departing New London on what was supposed to have been a \"shake-down\" cruise in February 1960, \"Triton\" began a 1960 circumnavigation of the Earth in 84 days without surfacing, covering over , an unprecedented feat. The route of \"Triton\" followed roughly that of Ferdinand Magellan in 1519-1522. The scientific and military significance of the \"Triton\" voyage was overshadowed by the U-2 Incident which broke just as USS \"Triton\" was returning.\n\nFor successfully completing its mission, \"Triton\" was awarded the Presidential Unit Citation. At a special White House ceremony, Captain Beach was presented the Legion of Merit by President Eisenhower. Beach wrote about \"Triton\"s voyage in his book \"Around the World Submerged: The Voyage of the Triton\", published in 1962.\n\nFollowing her post-shakedown availability, \"Triton\" deployed to European waters with the Second Fleet to participate in NATO exercises against British naval forces led by the aircraft carriers and under the command of Rear Admiral Sir Charles Madden. This deployment was culminated with a port visit to Bremerhaven, West Germany, the first visit by a nuclear-powered ship to a European port.\n\nAfter his tour in command of \"Triton\", Beach commanded Submarine Squadron Eight from July 1961 to August 1962. He was next a student at the National War College, where he completed a course of study in July 1963. At the same time he earned a Master of Arts degree in International Relations from George Washington University.\n\nIn May 1963, Eugene Parks Wilkinson and Beach were in competition for selection to Rear Admiral, and the board selected Wilkinson with Beach's sincere congratulations.\n\nFrom July 1963 to December 1966, Beach served in the office of the Chief of Naval Operations (OpNav) preparing annual budget reports for Congress and preparing the Secretary of the Navy (Fred Korth, Paul B. Fay, and Paul H. Nitze) and the Chief of Naval Operations (George W. Anderson Jr. and David L. McDonald) for hearings before Congressional committees.\n\nBeach retired from active duty with the rank of captain in 1966, after 27 years of service.\n\nBeach retired from active duty in the Navy in 1966, and was appointed as the Stephen B. Luce Chair of Naval Science at the Naval War College in Newport, Rhode Island — the first person to hold that position. During his tenure he was the editor of the \"Naval War College Review\".\n\nSubsequently, Beach served for seven years as staff director of the United States Senate Republican Policy Committee, and for one year as chief of staff for Senator Jeremiah Denton (R-Alabama).\n\nAfter World War II, Beach wrote extensively in his spare time following in the footsteps of his father, who was also a career naval officer and author. His first book \"Submarine!\" (1952) was a compilation of accounts of several wartime patrols made by his own as well as other submarines, which \"TIME\" magazine called \"the liveliest and most authentic account of underseas combat to come out of World War II.\"\n\nIn all, Beach published thirteen books, but is best known for his first novel, \"Run Silent, Run Deep\" (1955), which appeared on \"The New York Times Book Review\" bestseller list for several months. A movie of the same name, based loosely on the novel and starring Clark Gable and Burt Lancaster, was released by United Artists in 1958 (Beach was unhappy with the adaptation). Beach penned two sequels to \"Run Silent, Run Deep\": \"Dust on the Sea\" (1972), relating in detail a war patrol by \"Eel\" leading a wolfpack, and \"Cold is the Sea\" (1978), set in 1961 aboard a nuclear submarine.\n\nIn addition to \"Submarine!\", Beach wrote several more books on naval history, including \"The Wreck of the Memphis\" (1966); \"United States Navy: 200 Years\" (1986), a general history of the Navy; \"Scapegoats: A Defense of Kimmel and Short at Pearl Harbor\" (1995); and \"Salt and Steel: Reflections of a Submariner\" (1999). \"Keepers of the Sea\" (1983) is a pictorial record of the modern navy with photography by Fred J. Maroon. For a number of years Beach was co-editor of \"Naval Terms Dictionary\" as that standard reference work passed through several editions. His last work, completed shortly before his death, was to prepare for publication his father's manuscript of his own distinguished service in the navy. That book, \"From Annapolis to Scapa Flow: The Autobiography of Edward L. Beach, Sr\" (2003), is Captain Beach Sr.'s personal account of the navy from the age of sail to the age of steam.\n\nIn addition to his books, Beach was a prolific author of articles and book reviews for periodicals ranging from \"Blue Book Magazine\" to \"National Geographic\", and \"Naval History\" to \"American Heritage\".\n\nFiction:\nMemoirs:\nNon-fiction:\n\"Run Silent, Run Deep\" and \"The Wreck of the Memphis\" were republished in hardcover by the Naval Institute Press as part of its \"Classics of Naval Literature\" series while \"Around the World Submerged\", \"Submarine!\", \"Dust on the Sea\", and \"Cold is the Sea\" were reprinted in quality paperback editions as part of its \"Bluejacket Books\" series\n\nBeach married Ingrid Schenck, daughter of Stanford University professor Hubert G. Schenck and Inga Bergström Schenck, in Palo Alto in 1944. They had four children: Inga-Marie (1945–1948), Edward A. (b. 1948), Hugh S. (b. 1949) and Ingrid Alice (b. 1952).\n\nDuring his service in the United States Navy, Beach was awarded the Navy Cross, the Silver Star with Gold Star in lieu of a second Silver Star, the Legion of Merit, the Bronze Star with a combat Distinguished \"V\" and Gold Star in lieu of a second Bronze Star Medal with a combat Distinguished \"V\", Letter of Commendation Ribbon with Gold Star in lieu of second award and \"V\" device from the Commander in Chief of the Pacific Fleet, three Presidential Unit Citations, the Navy Unit Commendation, American Defense Service Medal with Atlantic Fleet Clasp, the American Campaign Medal, the Asiatic-Pacific Campaign Medal with three engagement stars, the World War II Victory Medal and the National Defense Service Medal with bronze service star in lieu of second award.\n\n\"The Navy Cross is presented to Edward Latimer Beach, Lieutenant Commander, United States Navy, for gallantry and intrepidity in action as Executive Officer, Navigator and Assistant Approach Officer on board the U.S.S. TIRANTE (SS-420) on the First War Patrol of that submarine during the period March 3, 1945 to April 25, 1945, in enemy controlled waters of the East China Sea. Lieutenant Commander Beach rendered valiant service to his commanding officer in penetrating mined and shoal-obstructed shallow waters in defiance of hostile shore-based radar stations and aircraft. By his excellent judgment and keen understanding of attack problems, he aided immeasurably in sending torpedoes into targets with deadly accuracy and contributed to the sinking of three Japanese cargo ships, one large transport, a hostile tanker, three patrol frigates, and one lugger, totaling 28,000 tons of shipping vital to the enemy's ability to prosecute the war. Through his experience and sound judgment he assisted in bringing his ship safely back to port. His conduct throughout was an inspiration to his officers and men and in keeping with the highest traditions of the United States Naval Service.\"\n\nBureau of Naval Personnel Information Bulletin No. 345 – December 1945\n\nGold Star to denote a second Silver Star:\n\nThe White House – May 10, 1960\n\nGold Star in lieu of second Bronze Star, with Combat\"V\":\n\n\nAuthor Tom Clancy summarized Beach's many accomplishments and contributions when he wrote:\n\nNed loved the Navy as a man might love his own family. For the Navy \"was\" his family, the junior officers he trained and the enlisted men who did so much of the hand-labor in the boats. He served with distinction approaching perfection and, like his father, would then write about the things he'd seen and done... More than once I spoke with him about the psychological aspects of combat, and every time he told me what I needed to know, always from his own rich experiences. Ned was a serious student of history -- he wrote several splendid books on this subject -- and of human nature. What he didn't know had never happened.\n\nEd Offley of \"DefenseWatch\" wrote:\n\nBeach once told an interviewer, \"What is there about the Navy? To me, it's always been a tremendous feeling that I am part of an organization that's much bigger than I am.\"\n\nThe submariner was inaccurate. It is sailors like Capt. Edward L. Beach Jr. – who died on December 1 at the age of 84 – who make institutions like the Navy bigger and greater than they otherwise would be.\n\n\n"}
{"id": "10978306", "url": "https://en.wikipedia.org/wiki?curid=10978306", "title": "Effects on the environment in Czechoslovakia from Soviet influence during the Cold War", "text": "Effects on the environment in Czechoslovakia from Soviet influence during the Cold War\n\nAfter World War II, the Soviet Union put in place five-year plans in the East European countries imitating their own five-year plans in order to recover from the war. The Soviets believed that the economic policies that helped them recover would similarly help the Eastern European counties recoup. Countries in the Eastern Bloc were instructed to build up the industries present in the Soviet Union – regardless of whether or not they had the natural resources to support those industries – or to concentrate on developing pre-existing industries which could benefit the Soviet Union. In the case of Czechoslovakia, the state was told to concentrate on heavy industry. This concentration on heavy industry depleted the country's natural resources at an extraordinarily fast rate and produced an excessive amount of pollution.\n\nThe pollution produced by heavy industry seriously degraded air quality. The air contained high concentrations of sulfur dioxide because the energy production was largely based on combustion of fuel high in sulfur. As a result, 50 percent of the forests were either dead or dying. Cases of bronchitis and asthma in children almost doubled with the increase in the use of sulfur dioxide. The water, too, was affected by the excessive pollution, both from industrial fertilizers and oil spills. The lack of water waste treatment meant that a large portion of the water was undrinkable for the population, and some of the water was so bad that it was even unusable by the industry. Conditions were worst in Northern Bohemia, which was a part of the so-called ‘triangle of death’ that also included South-East East Germany and South-West Poland, but the effects were also felt beyond the region in which the pollution originated. The Danube River carried much of the pollution to other areas of the state and other countries, and acid rain brought the pollution directly to the cities, where it could eat away at the buildings and statues.\n\nWhile pollution was increasing, records and information relating to pollution became increasingly inaccessible to the public. Students who tried to make the public aware of the problems were arrested and detained by the police. Often no records were even kept on the industrial effects on the environment. There were some people involved with non-governmental organizations that tried to correct the situation, but these groups were largely interested in acting as an adversary of the state. Under the 1960 Constitution of Czechoslovakia, the state was legally required to protect the quality of the environment as far as necessary to protect human health, but in northern Czechoslovakia, pollution reportedly shortened a person’s life by three to four years. The government even acknowledged these poor living conditions by offering a bonus to people who lived in the area for more than ten years – called burial money by the people in the area.\n\nThe government faced problems in trying to solve environmental problems because there was no central branch responsible for environmental safety and protection. Instead, there were many different branches responsible for different aspects of the environment – one for water, one for land, one for air, etc., and these different branches often had conflicting interests. Each branch would try to enforce its own environmental priorities without regard to the overall environmental picture. Furthermore, these branches were in charge not only of the environmental issues in their area, but also of the economic issues, giving each branch a set of conflicting priorities, and economic needs would generally win out. When the government imposed fines for failures to comply with pollution regulations, it would also help industry pay off the fines, leaving industry with little incentive to change policies. \n\n"}
{"id": "4605404", "url": "https://en.wikipedia.org/wiki?curid=4605404", "title": "Forest-savanna mosaic", "text": "Forest-savanna mosaic\n\nForest-savanna mosaic is a transitory ecotone between the tropical moist broadleaf forests of Equatorial Africa and the drier savannas and open woodlands to the north and south of the forest belt. The forest-savanna mosaic consists of drier forests, often gallery forest, interspersed with savannas and open grasslands.\n\nThe World Wildlife Fund recognizes several distinct forest-savanna mosaic ecoregions:\n\n"}
{"id": "840652", "url": "https://en.wikipedia.org/wiki?curid=840652", "title": "Fuller's earth", "text": "Fuller's earth\n\nFuller's earth is any clay material that has the capability to decolorize oil or other liquids without chemical treatment. Fuller's earth typically consists of palygorskite (attapulgite) or bentonite.\n\nModern uses of fuller's earth include absorbents for oil, grease, and animal waste (cat litter) and as a carrier for pesticides and fertilizers. Minor uses include filtering, clarifying, and decolorizing; active and inactive ingredient in beauty products; and as a filler in paint, plaster, adhesives, and pharmaceuticals. It also has a number of uses in the film industry and on stage.\n\nThe English name reflects the historic use of the material for cleaning or \"fulling\" wool by textile workers called \"fullers\". In past centuries, fullers kneaded fuller's earth and water into woollen cloth to absorb lanolin, oils, and other greasy impurities as part of the cloth finishing process.\nFuller's Earth is also known by the following other names: \n\nFuller's earth consists primarily of hydrous aluminum silicates (clay minerals) of varying composition. Common components are montmorillonite, kaolinite and attapulgite. Small amounts of other minerals may be present in fuller's earth deposits, including calcite, dolomite, and quartz. In some localities fuller's earth refers to calcium bentonite, which is altered volcanic ash composed mostly of montmorillonite.\n\nIn 2005, the United States was the largest producer of fuller's earth with an almost 70% world share followed at a distance by Japan and Mexico. In the United States fuller's earth is typically derived from deposits of volcanic ash of Cretaceous age and younger (glacial clays do not form fuller's earth). Fuller's earth deposits have been mined in 24 states. The first discovery of fuller’s earth in the United States was near Quincy, Florida, in 1893; previously it was imported from England. In 1939 mines near Quincy produced half the U.S. production.\n\nIn the United Kingdom, fuller's earth occurs mainly in England. It has been mined in the Lower Greensand Group and the Vale of White Horse, Oxfordshire. The Combe Hay Mine was a fuller's earth mine operating to the south of Bath, Somerset until 1979. Other sites south of Bath included Frome, Lonsdale, Englishcombe, Tucking Mill and Duncorn Hill. Although these sites had been used since Roman times, William Smith developed new methods for the identification of deposits of fuller's earth to the south of Bath. Other English sources include a mine near Redhill, Surrey (worked until 2000), and Woburn, Bedfordshire, where production ceased in 2004.\n\nHills, cliffs, and slopes that contain fuller's earth can be unstable, since this material can be thixotropic when saturated by heavy rainfall.\n\nFulling is an important step in the production of woolen garments, and can be traced back to ancient times. Cuneiform texts from Mesopotamia mention a raw material, (, : ‘gypsum, plaster’), literally “white earth”, which was delivered to fullers for the finishing of cloth. There are several Biblical references to fulling (2 Kings 18:17; Isaiah 7:3 and 36:2; Malachi 3:2; Mark 9:3), but the materials used to whiten the fabric are not specified. Pliny the Elder mentions several types of fuller’s earth ( in Latin) from a variety of locations, each with different properties and therefore different uses.\n\nThe first references to fulling mills are from Persia, and by the time of the Crusades in the late eleventh century, fulling mills were active throughout the medieval world. \n\nCalled 'Multani Mitti' ('mud from Multan') in modern-day India and Pakistan, the use of Fuller's earth across the Indian subcontinent dates back to at least 1879. While its household use and transportation by local carts in the Sindh region predates the 1800s, export by rail was first recorded in 1929 in British India.\n\nIn addition to its original use in the fulling of raw fibers, fuller's earth is now utilized in a number of industries. Most important applications make use of the minerals' natural absorbent properties in products sold as absorbents or filters.\n\n\n\n\nNotes\nFurther reading\n\n"}
{"id": "6161526", "url": "https://en.wikipedia.org/wiki?curid=6161526", "title": "Internal waters", "text": "Internal waters\n\nAccording to the United Nations Convention on the Law of the Sea, a nation's internal waters include waters on the landward side of the baseline of a nation's territorial waters, except in archipelagic states. It includes waterways such as rivers and canals, and sometimes the water within small bays. \n\nIn inland waters, sovereignty of the state is equal to that which it exercises on the mainland. The coastal state is free to make laws relating to its internal waters, regulate any use, and use any resource. In the absence of agreements to the contrary, foreign vessels have no right of passage within internal waters, and this lack of right to innocent passage is the key difference between internal waters and territorial waters. The \"archipelagic waters\" within the outermost islands of archipelagic states are treated as internal waters with the exception that innocent passage must be allowed, although the archipelagic state may designate certain sea lanes in these waters.\n\nWhen a foreign vessel is authorized to enter inland waters, it is subject to the laws of the coastal State, with one exception: the crew of the ship is subject to the law of the flag State. This extends to labor conditions as well as to crimes committed on board the ship, even if docked at a port. Offences committed in the harbor and the crimes committed there by the crew of a foreign vessel always fall in the jurisdiction of the coastal State. The coastal State can intervene in ship affairs when the master of the vessel requires intervention of the local authorities, when there is danger to the peace and security of the coastal State, or to enforce customs rules.\n\nThe claim by one state of a waterway as internal waters has led to disputes with other states. For example, Canada claims a section of the Northwest Passage as part of its internal waters, fully under Canadian jurisdiction, a claim which has been disputed by the United States and most maritime nations, which consider them to be an international strait, which means that foreign vessels have a right of transit passage. (See Canadian Internal Waters and Northwest Passage#International waters dispute.)\n\nThe International Tribunal for the Law of the Sea, which was formed in 1994, has the power to settle maritime disputes between party states, although in practice, these resolutions depend on the willingness of these states to adhere to the rulings.\n\n\n"}
{"id": "4991160", "url": "https://en.wikipedia.org/wiki?curid=4991160", "title": "International Union of Geodesy and Geophysics", "text": "International Union of Geodesy and Geophysics\n\nThe International Union of Geodesy and Geophysics (IUGG; , UGGI) is an international non-governmental organisation dedicated to the scientific study of the Earth and its space environment using geophysical and geodetic techniques.\n\nThe IUGG was established in Brussels, Belgium in 1919. Some areas within its scope are environmental preservation, reduction of the effects of natural hazards, and mineral resources.\n\nIUGG's objectives are the promotion and coordination of studies related to Earth's physical, chemical and mathematical representation. This includes geometrical shape, internal structure, gravity and magnetic fields, seismicity, volcanism, hydrologic cycle, glaciers, oceans, atmosphere, ionosphere, and magnetosphere of Earth. It also includes solar, lunar and planetary studies.\n\nThe IUGG consists of eight semi-autonomous associations: \n\nIt has also established six commissions to promote interdisciplinary problems: \nand the Union Working Group on History.\n\nList of General Assemblies, Presidents, and Secretaries-General.\n\n"}
{"id": "1450795", "url": "https://en.wikipedia.org/wiki?curid=1450795", "title": "Jet propulsion", "text": "Jet propulsion\n\nJet propulsion is the propulsion of an object in one direction, produced by ejecting a jet of fluid in the opposite direction. By Newton's third law, the moving body is propelled in the opposite direction to the jet. Reaction engines operating on the principle of jet propulsion include the jet engine used for aircraft propulsion, the pump-jet used for marine propulsion, and the rocket engine and plasma thruster used for spacecraft propulsion. Biological systems include the propulsion mechanisms of certain marine animals such as cephalopods, sea hares, arthropods, and fish.\n\nJet propulsion is produced by some reaction engines or animals when thrust is generated by a fast moving jet of fluid in accordance with Newton's laws of motion. It is most effective when the Reynolds number is high—that is, the object being propelled is relatively large and passing through a low-viscosity medium.\n\nIn biology, the most efficient jets are pulsed, rather than continuous, at least when the Reynolds number is greater than 6.\n\nSpecific impulse (usually abbreviated \"I\") is a measure of how effectively a rocket uses propellant or jet engine uses fuel. By definition, it is the total impulse (or change in momentum) delivered per unit of propellant consumed and is dimensionally equivalent to the generated thrust divided by the propellant mass flow rate or weight flow rate. If mass (kilogram, pound-mass, or slug) is used as the unit of propellant, then specific impulse has units of velocity. If weight (newton or pound-force) is used instead, then specific impulse has units of time (seconds). Multiplying flow rate by the standard gravity (\"g\") converts specific impulse from the mass basis to the weight basis.\n\nA propulsion system with a higher specific impulse uses the mass of the propellant more effectively in creating forward thrust and, in the case of a rocket, less propellant needed for a given delta-v, per the Tsiolkovsky rocket equation. In rockets, this means the engine is more effective at gaining altitude, distance, and velocity. This effectiveness is less important in jet engines that employ wings and use outside air for combustion and carry payloads that are much heavier than the propellant.\n\nSpecific impulse includes the contribution to impulse provided by external air that has been used for combustion and is exhausted with the spent propellant. Jet engines use outside air, and therefore have a much higher specific impulse than rocket engines. The specific impulse in terms of propellant mass spent has units of distance per time, which is an artificial velocity called the \"effective exhaust velocity\". This is higher than the \"actual\" exhaust velocity because the mass of the combustion air is not being accounted for. Actual and effective exhaust velocity are the same in rocket engines not utilizing air.\n\nSpecific impulse is inversely proportional to specific fuel consumption (SFC) by the relationship \"I\" = 1/(\"g\"·SFC) for SFC in kg/(N·s) and \"I\" = 3600/SFC for SFC in lb/(lbf·hr).\n\nFrom the definition of specific impulse thrust in SI units is:\n\nwhere V is the effective exhaust velocity and formula_2 is the propellant flow rate.\n\nReaction engines produce thrust by expelling solid or fluid reaction mass; jet propulsion applies only to engines which use fluid reaction mass.\n\nA jet engine is a reaction engine which uses ambient air as the working fluid, and converts it to a hot, high-pressure gas which is expanded through one or more nozzles. Two types of jet engine, the turbojet and turbofan, employ axial-flow or centrifugal compressors to raise the pressure before combustion, and turbines to drive the compression. Ramjets operate only at high flight speeds because they omit the compressors and turbines, depending instead on the dynamic pressure generated by the high speed (known as ram compression). Pulse jets also omit the compressors and turbines, but can generate static thrust and have limited maximum speed.\n\nThe rocket is capable of operating in the vacuum of space, because it is dependent on the vehicle carrying its own oxidizer instead of using the oxygen in the air, or in the case of a nuclear rocket, heats an inert propellant (such as liquid hydrogen) by forcing it through a nuclear reactor.\n\nPlasma thrusters accelerate a plasma by electromagnetic means.\n\nThe pump-jet, used for marine propulsion, uses water as the working fluid, pressurized by a ducted propeller, centrifugal pump, or a combination of the two.\n\nJet propulsion in cephalopods is produced by water being exhaled through a siphon, which typically narrows to a small opening to produce the maximum exhalent velocity. The water passes through the gills prior to exhalation, fulfilling the dual purpose of respiration and locomotion. Sea hares (gastropod molluscs) employ a similar means of jet propulsion, but without the sophisticated neurological machinery of cephalopods they navigate somewhat more clumsily.\n\nSome teleost fish have also developed jet propulsion, passing water through the gills to supplement fin-driven motion.\n\nIn some dragonfly larvae, jet propulsion is achieved by the expulsion of water from a specialised cavity through the anus. Given the small size of the organism, a great speed is achieved.\n\nScallops and cardiids, siphonophores, tunicates (such as salps), and some jellyfish also employ jet propulsion. The most efficient jet-propelled organisms are the salps, which use an order of magnitude less energy (per kilogram per metre) than squid.\n\n"}
{"id": "17797376", "url": "https://en.wikipedia.org/wiki?curid=17797376", "title": "Johannes van Walbeeck", "text": "Johannes van Walbeeck\n\nJan, Johan or Johannes van Walbeeck (1602, Amsterdam – after 1649) was a Dutch navigator and cartographer during a 1620s circumnavigation of the earth, an admiral of the Dutch West India Company, and the first governor of the Netherlands Antilles.\n\nVan Walbeeck is thought to have been born in Amsterdam in 1601 or 1602 and he might be the Jan van Walbeeck, son of the merchant Jacob van Walbeeck and of Weijntgen van Foreest (apparently the only Walbeeck family in town), who was baptized on August 15, 1602, in Amsterdam.\n\nHe studied at the University of Leiden before enlisting as navigator and cartographer on the ship \"De Amsterdam\" during the three-year circumnavigation of the world from 1623 to 1626 by the Nassau fleet (\"Nassause vloot\") led by Admiral Jacques l'Hermite and Vice Admiral Gheen Huygensz Schapenham. It is thought that the account of this voyage published by Hessel Gerritsz shortly after the expedition's return in 1626 was written and drawn by Van Walbeeck.\n\nIn 1627, Van Walbeeck continued his mathematics and physics study in Leiden, but interrupted it again to join Laurens Reael's diplomatic mission to Denmark at the end of the year. Upon his return, he enlisted in a fleet that sailed to the Dutch East Indies.\n\nIn 1629, back in the Netherlands, he changed employment from the Dutch East India Company to the Dutch West India Company (WIC). In April 1630, he arrived on the ship \"Neptunus\" in Pernambuco, after Hendrick Cornelisz Loncq had taken Olinda in February and Recife in March from the Portuguese (who between 1580 and 1640 were governed by Habsburg Spain, with which the Dutch Republic was at war). Van Walbeeck immediately was made a member of the \"Politieke Raad\" (\"Political Council\"), the highest level of government in Dutch Brazil. Already in the same year, Loncq sent him (as \"Admiral of the Brazilian coast\") and Maarten Valck to establish a Dutch base on the Chilean coast from which to explore Terra Australis. However, due to the colonial conflicts between the Dutch Republic and Portugal, the expedition did not get to its destination. Several more expeditions followed, until in 1632 Van Walbeeck was promoted to president of the Politieke Raad.\nIn 1633, Van Walbeeck and the governor of Dutch Brazil, Dierick van Waerdenburgh, left for the Dutch Republic to meet with the WIC council (\"de heren XIX\"). The WIC had lost its base in the Antilles when a Spanish fleet had destroyed its settlement on Sint Maarten in the summer of that year. The council now planned a base in Curaçao and Bonaire, Lesser Antilles under Spanish rule of Province of Venezuela, both for the salt pans (large quantities of salt were needed to preserve fish), and as a strategic location off the South American mainland. The natural harbor of St Anna Bay on Curaçao was the perfect location for this. On April 6, 1634 they assigned Van Walbeeck to the task of taking it from the Spanish, who had colonized the island since the 1520s. On 4 May 1634, he departed from Holland with four ships, carrying 180 sailors and 250 soldiers, led by the French Huguenot mercenary Pierre Le Grand who had previously served the Dutch in Brazil. The small fleet arrived at Curaçao on July 6, but through adverse currents and winds could not enter the bay. On July 29, after being joined by a fifth ship and approaching from the north west, the fleet could enter the bay and captured the island from Spain with little resistance and without loss of life on either side. Van Walbeeck wrote in his diary, as transcribed by Johannes de Laet before it was lost, that the 32 Spanish and under 500 remaining (or reintroduced) local Arawaks inhabitants just withdrew to the West end of the island after poisoning their wells and burning their villages. On August 21 the Spanish commander, Lope Lopez de Morla, signed the surrender. The Dutch deported the Spaniards and most West Indians to the Venezuelan port of Coro, keeping about seventy-five of the latter as laborers. Thus, Van Walbeeck became the first director/governor of the Netherlands Antilles. The first task was to build a fortification at the natural harbor, renamed \"Schottegat\" by the Dutch, which pentagonal structure Fort Amsterdam was finished in 1635, following standard Dutch military engineering practice. During his three years as governor, the beginnings of the town of Willemstad were built next to the fort.\n\nIn 1638, he and Le Grand were sent to Brazil, while Jacob Pietersz Tolck took over his position as governor although van Walbeeck remained political director of Curaçao for the next several years. He stayed in Brazil as a member of the Hoge Raad until 1642, after which he returned to Holland again to give advice on the forthcoming expedition under Hendrick Brouwer to establish a trading base in Chile. He went back to Brazil, being mentioned as elder of the Reformed Church there. In 1647 he left Brazil. Maybe he died in the Netherlands, as he lived in Amsterdam when his wife was buried there on 29 April 1649.\n\nLike Peter Stuyvesant, Van Walbeeck was one of the limited number of WIC employees with a university education. The company appears to have valued him at least as highly as Stuyvesant and it has been suggested that he missed being appointed director-general of the New Netherlands merely by not being in the Netherlands at the right time.\n\n\n"}
{"id": "48359943", "url": "https://en.wikipedia.org/wiki?curid=48359943", "title": "Juan de Zubileta", "text": "Juan de Zubileta\n\nJuan de Zubileta was one of the members of Ferdinand Magellan's expedition to circumnavigate the globe, which began in Seville on August 10, 1519. Zubileta was one of the eighteen men who managed to complete the expedition, reaching Sanlúcar de Barrameda on September 6, 1522 on the \"Victoria\", along with 17 other survivors.\n\n"}
{"id": "5949785", "url": "https://en.wikipedia.org/wiki?curid=5949785", "title": "Law of three stages", "text": "Law of three stages\n\nThe law of three stages is an idea developed by Auguste Comte in his work \"The Course in Positive Philosophy\". It states that society as a whole, and each particular science, develops through three mentally conceived stages: (1) the theological stage, (2) the metaphysical stage, and (3) the positive stage.\n\n(1) The Theological stage refers to explanation by personified deities. During the earlier stages, people believe that all the phenomena of nature are the creation of the divine or supernatural. Men and children failed to discover the natural causes of various phenomena and hence attributed them to a supernatural or divine power. Comte broke this stage into 3 sub-stages:\n\n(2) The Metaphysical stage is the extension of the theological stage. Metaphysical stage refers to explanation by impersonal abstract concepts. People often tried to believe that God is an abstract being. They believe that an abstract power or force guides and determines events in the world. Metaphysical thinking discards belief in a concrete God. The nature of inquiry was legal and rational in nature. For example: In Classical Hindu Indian society the principle of the transmigration of the soul, the conception of rebirth, notions of pursuant were largely governed by metaphysical uphill.\n\n(3) The Positivity stage, also known as the scientific stage, refers to scientific explanation based on observation, experiment, and comparison. Positive explanations rely upon a distinct method, the scientific method, for their justification. Today people attempt to establish cause and effect relationships. Positivism is a purely intellectual way of looking at the world; as well, it emphasizes observation and classification of data and facts. This is the highest, most evolved behavior according to Comte.\n\nComte, however, was conscious of the fact that the three stages of thinking may or do coexist in the same society or in the same mind and may not always be successive.\n\nComte proposed a hierarchy of the sciences based on historical sequence, with areas of knowledge passing through these stages in order of complexity. The simplest and most remote areas of knowledge—mechanical or physical—are the first to become scientific. These are followed by the more complex sciences, those considered closest to us.\n\nThe sciences, then, according to Comte's \"law\", developed in this order: Mathematics; Astronomy; Physics; Chemistry; Biology; Sociology. A science \"of society\" is thus the \"Queen science\" in Comte's hierarchy as it would be the most fundamentally complex. \nSince Comte saw social science as an observation of human behavior and knowledge, his definition of sociology included observing humanity’s development of science itself. Because of this, Comte presented this introspective field of study as the science above all others. Sociology would both complete the body of positive sciences by discussing humanity as the last unstudied scientific field, and would link the fields of science together in human history, showing the \"intimate interrelation of scientific and social development\".\n\nTo Comte, the law of three stages made development of sociology inevitable and necessary. Comte saw the formation of his law as an active use of sociology, but this formation was dependent on other sciences reaching the positive stage; Comte’s three-stage law would not have evidence for a positive stage without the observed progression of other sciences through these three stages. Thus, sociology and its first law of three stages would be developed after other sciences were developed out of the metaphysical stage, with the observation of these developed sciences becoming the scientific evidence used in a positive stage of sociology. This special dependence on other sciences contributed to Comte’s view of sociology being the most complex. It also provided an explanation for sociology being the last science to be developed.\n\nComte saw the results of his three-stage law and sociology as not only inevitable, but good. In Comte’s eyes, the positive stage was not only the most evolved stage, but also the stage best for mankind. Through a continuous development of positive sciences, Comte hoped that humans would perfect their knowledge of the world and make real progress to improve the welfare of humanity. He acclaimed the positive stage as the \"highest accomplishment of the human mind\" and as having \"natural superiority\" over the other, more primitive stages.\n\nOverall, Comte saw his law of three stages as the start of the scientific field of sociology as a positive science. He believed this development was the key to completing positive philosophy and would finally allow humans to study every observable aspect of the universe. For Comte, sociology’s human-centered studies would relate the fields of science to each other as progressions in human history and make positive philosophy one coherent body of knowledge. Comte presented the positive stage as the final state of all sciences, which would allow human knowledge to be perfected, leading to human progress.\n\nHistorian William Whewell wrote \"Mr. Comte's arrangement of the progress of science as successively metaphysical and positive, is contrary to history in fact, and contrary to sound philosophy in principle.\" The historian of science H. Floris Cohen has made a significant effort to draw the modern eye towards this first debate on the foundations of positivism.\n\nIn contrast, within an entry dated early October 1838 Charles Darwin wrote in one of his then private notebooks that \"M. Comte's idea of a theological state of science [is a] grand idea.\"\n\n\n"}
{"id": "3292654", "url": "https://en.wikipedia.org/wiki?curid=3292654", "title": "List of Lepidoptera that feed on Solanum", "text": "List of Lepidoptera that feed on Solanum\n\nSolanum species are used as food plants by the larvae of a number of Lepidoptera species including:\n\n\n"}
{"id": "29940042", "url": "https://en.wikipedia.org/wiki?curid=29940042", "title": "List of Ramsar sites in Honduras", "text": "List of Ramsar sites in Honduras\n\nThe list of Ramsar Sites in Honduras includes wetlands in Honduras that are considered to be of \"international importance\" under the Ramsar Convention. \nFor a full list of all Ramsar Sites worldwide, see the Ramsar list of wetlands of international importance.\n"}
{"id": "13025095", "url": "https://en.wikipedia.org/wiki?curid=13025095", "title": "List of Sapindaceae genera", "text": "List of Sapindaceae genera\n\nThis is a list of genera in the soapberry family, Sapindaceae, which includes the soapberries (\"Sapindus\"), maples (\"Acer\"), and paullinias, amongst others. As currently circumscribed, the family contains approximatively 1900 species into over 140 genera classified into 4 subfamilies.\n\nThe current circumscription of Sapindaceae encompasses the traditional Aceraceae and Hippocastanaceae as tribes in subfamily Hippocastanoideae. Although the classification at subfamilial level is fairly well-established, the circumscription at tribal and generic level remains only partially resolved, especially in the larger subfamily Sapindoideae, which has led the most recent revision to treat the majority of these genera without placing them in a tribe. Another recent study hints at even more incongruity between traditional circumscription and molecular evidence.\n\nRecent changes have included the synonymization of \"Distichostemon\" with \"Dodonaea\", and \"Neotina\" and \"Tinopsis\" with \"Tina\". Additionally, not all authors agree about the broad circumscription that ensues from placing \"Xanthoceras\" as the sister group to the three traditional families as the resulting Sapindaceae \"sensu lato\", unlike the traditional families, is difficult to characterize. As a result, the elevation of Xanthoceroideae to family level was recently proposed, which would remove from Sapindaceae those six genera currently placed in that subfamily and Hippocastanoideae.\n\nThis list follows Acevedo-Rodríguez et al. as modified by more recent research.\n"}
{"id": "9209349", "url": "https://en.wikipedia.org/wiki?curid=9209349", "title": "List of Schefflera species", "text": "List of Schefflera species\n\nThis is a list of all species of the genus \"Schefflera\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "25488165", "url": "https://en.wikipedia.org/wiki?curid=25488165", "title": "List of Superfund sites in Missouri", "text": "List of Superfund sites in Missouri\n\nThis is a list of Superfund sites in Missouri designated under the Comprehensive Environmental Response, Compensation, and Liability Act (CERCLA) environmental law. The CERCLA federal law of 1980 authorized the United States Environmental Protection Agency (EPA) to create a list of polluted locations requiring a long-term response to clean up hazardous material contaminations. These locations are known as Superfund sites, and are placed on the National Priorities List (NPL). \n\nThe NPL guides the EPA in \"determining which sites warrant further investigation\" for environmental remediation. As of May 1, 2010, there were thirty Superfund sites on the National Priorities List in Missouri. One more site has been proposed for entry on the list and five others have been cleaned up and removed from it.\n\n\n"}
{"id": "8427933", "url": "https://en.wikipedia.org/wiki?curid=8427933", "title": "List of artificial objects leaving the Solar System", "text": "List of artificial objects leaving the Solar System\n\nBelow is a list of artificial objects leaving the Solar System. All of these objects are space probes and their upper stages launched by NASA. \n\nOf the major spacecraft Voyager 1, Voyager 2, and New Horizons are still functioning and are regularly contacted by radio communication, while Pioneer 10 and Pioneer 11 are now derelict. In addition to these spacecraft, some 3rd stages and de-spin weights are leaving the solar system, assuming they continued on their trajectories. \n\nThe objects are \"leaving\" the Solar System, because they have a velocity and direction that is taking them away from the Sun, but for the distance they are from the Sun, the Sun's gravitational pull would not be predicted to pull the object back to it or into orbit around it. They are not at all immune from the gravitational pull of the Sun and are being slowed down, but they are predicted to have enough velocity to coast into interstellar space; see escape velocity.\n\n\nAlthough other probes were launched first, \"Voyager 1\" has achieved a higher speed and overtaken all others. \"Voyager 1\" overtook \"Voyager 2\" a few months after launch, on 19 December 1977. It overtook \"Pioneer 11\" in 1983, and then \"Pioneer 10\"—becoming the probe farthest from Earth—on February 17, 1998.\n\n\"Voyager 2\" is also moving faster than the probes launched earlier: having overtaken \"Pioneer 11\" by March 1988, it will overtake \"Pioneer 10\" in April 2019.\n\nDepending on how the \"Pioneer anomaly\" impacts it, \"New Horizons\" will also probably pass the \"Pioneer\" probes, but will need many years to do so. It will not overtake \"Pioneer 11\" until the 22nd Century; will not overtake \"Pioneer 10\" until the end of that century, and it will never overtake the \"Voyagers\".\n\nSource : heavens above and JPL\n\nThe escape velocity of the Sun from its surface is 618. km/sec (1381600.8 mph). The force of gravity can be predicted with Newton's law of universal gravitation for a certain distance from the Sun, and the mass of the Sun and the object in question and where G is the Gravitational constant.\n\nEvery planetary probe was placed into its escape trajectory by a multistage rocket, the last stage of which ends up on nearly the same trajectory as the probe it launched. Because these stages cannot be actively guided, their trajectories are now different from the probes they launched (the probes were guided with small thrusters that allow course changes). However, in cases where the spacecraft acquired escape velocity because of a gravity assist, the stages may not have a similar course and there is the remote possibility that they collided with something. Some objects in heliocentric orbit have been reidentified with a telescope, and so it can be confirmed that they are still there. The stages on an escape trajectory are:\n\nIn addition, two small \"yo-yo de-spin weights\" on wires were used to reduce the spin of the \"New Horizons\" probe prior to its release from the third-stage rocket. Once the spin rate was lowered, these masses and the wires were released, and so are also on an escape trajectory out of the Solar System. None of these objects are trackable (they have no power or radio antennae, spin uncontrollably, and are too small to be detected), and their exact positions are unknowable beyond their projected Solar System escape trajectories.\n\nThe third stage of \"Pioneer 11\" is thought to be in solar orbit because its encounter with Jupiter would not have resulted in escape from the Solar System. \"Pioneer 11\" gained the required velocity to escape the Solar System in its subsequent encounter with Saturn.\n\nThe only objects to date to be launched directly into a solar escape trajectory were the \"New Horizons\" spacecraft, its third stage, and the two de-spin masses. The \"New Horizons\" Centaur (second) stage is not escaping; it is in a 2.83-year heliocentric (solar) orbit.\n\nThe \"Pioneer 10\" and \"11\", and \"Voyager 1\" and \"2\" Centaur (second) stages are also in heliocentric orbits.\n\nIn order to leave the Solar System, the probe needs to reach the escape velocity. After leaving Earth, the Sun's escape velocity is 42.1 km/s. In order to reach this speed, it is highly advantageous to utilize the orbital speed of the Earth around the Sun, which is 29.78 km/s. By passing near a planet, a probe can gain extra speed.\n\nOn January 19, 2006 the New Horizons spacecraft to Pluto was launched directly into a solar-escape trajectory at from Cape Canaveral using an Atlas V version with 5 of the AJ-60A SRBs and the Common Core Booster, Centaur upper stage, and Star 48B third stage . \"New Horizons\" passed the Moon's orbit in just nine hours.\n\nPropulsive units for \"New Horizons\" which was launched directly to a solar escape velocity from Earth.\n\nSome have conjectured that some nuclear explosions may have accelerated debris to escape velocity, possible sending man-made debris out of the solar system.\n\n\n"}
{"id": "29695389", "url": "https://en.wikipedia.org/wiki?curid=29695389", "title": "List of mountain passes in Montana (M-Z)", "text": "List of mountain passes in Montana (M-Z)\n\nThere are at least 290 named mountain passes in Montana.\n\n"}
{"id": "270811", "url": "https://en.wikipedia.org/wiki?curid=270811", "title": "Lowest temperature recorded on Earth", "text": "Lowest temperature recorded on Earth\n\nThe lowest natural temperature ever directly recorded at ground level on Earth is at the Soviet Vostok Station in Antarctica on July 21, 1983 by ground measurements. \n\nOn August 10, 2010, satellite observations showed a surface temperature of at , along a ridge between Dome Argus and Dome Fuji, at elevation. The result was reported at the 46th annual meeting of the American Geophysical Union in San Francisco in December 2013; it is a provisional figure, and may be subject to revision. The value is not listed as the record lowest temperature as it was measured by remote sensing from satellite and not by ground-based thermometers, unlike the 1983 record. The temperature announced reflects that of the ice surface, while the Vostok readings measured the air above the ice, and so the two are not directly comparable. More recent work shows many locations in the high Antarctic where surface temperatures drop to approximately . Due to the very strong temperature gradient near the surface, these imply near-surface air temperature minima of approximately .\n\nOn January 21, 1838 a recording was made by the Russian merchant Neverov in Yakutsk, of . On January 15, 1885 H. Wild reported that a temperature of was noted in Verkhoyansk. A later measurement at the same place in February 1892 was reported as . Soviet researchers later announced a recording of in February 1933 at Oymyakon, about to the south-east of Verkhoyansk; this measurement was reported by Soviet texts through the 1940s as a record low, with the previous measurement from Verkhoyansk retroactively adjusted to .\n\nThe next reliable measurement was made during the 1957 season at the Amundsen–Scott South Pole Station in Antarctica, yielding on May 11 and on September 17. A subsequent measurement of , on August 24, 1960, held the record until a temperature of was measured at the Soviet Vostok Station, on the Antarctic Plateau, on July 21, 1983. This remains the record for a directly recorded temperature.\n\nIn 1904 Dutch scientist Heike Kamerlingh Onnes created a special lab in Leiden with the aim of producing liquid helium. In 1908 he managed to lower the temperature to less than −269 °C (-452.2 F, 4 K), which is less than four degrees above absolute zero. Only in this exceptionally cold state will helium liquefy, the boiling point of helium being at −268.94 °C (-452.092 F). Kamerlingh Onnes received a Nobel Prize for his achievement.\n\nOnnes' method relied upon depressurising the subject gases, causing them to cool by adiabatic cooling. This follows from the first law of thermodynamics;\n\nformula_1\n\nwhere \"U\" = internal energy, \"Q\" = heat added to the system, \"W\" = work done by the system.\n\nConsider a gas in a box of set volume. If the pressure in the box is higher than atmospheric pressure, then upon opening the box our gas will do work on the surrounding atmosphere to expand. As this expansion is adiabatic and the gas has done work\n\nformula_2\n\nformula_3\n\nformula_4\n\nNow as the internal energy has decreased, so has the temperature.\n\nAs of November 2000, nuclear spin temperatures below 100 pK were reported for an experiment at the Helsinki University of Technology Low Temperature Lab. However, this was the temperature of one particular type of motion—a quantum property called nuclear spin—not the overall average thermodynamic temperature for all possible degrees of freedom. At such low temperatures, the concept of \"temperature\" becomes multifaceted since molecular motion cannot be assumed to average out across degrees of freedom. The corresponding peak emission will be in radio waves, rather than in the familiar infrared, so it is very inefficiently absorbed by neighboring atoms, making it difficult to reach thermal equilibrium.\n\nLow Temperature Laboratory recorded a record low temperature of 100 pK, or 1.0 × 10 K in 1999.\n\nThe current apparatus for achieving low temperatures has two stages. The first utilizes a helium dilution refrigerator to get to temperatures of millikelvins, then the next stage uses adiabatic nuclear demagnetisation to reach picokelvins.\n\nExtremely low temperatures are useful for observation of quantum mechanical phases of matter such as superfluids and Bose-Einstein condensates, which would be disrupted by thermal motion.\n\n\n"}
{"id": "1729730", "url": "https://en.wikipedia.org/wiki?curid=1729730", "title": "Madrean pine-oak woodlands", "text": "Madrean pine-oak woodlands\n\nThe Madrean pine-oak woodlands is an ecoregion of the Tropical and subtropical coniferous forests biome, located in North America. They are subtropical woodlands found in the mountains of Mexico and the southwestern United States.\n\nConservation International estimates the woodlands' original area at 461,265 km². The woodlands are surrounded at lower elevations by other ecoregions, mostly tropical and subtropical deserts and xeric shrublands, forests, and grasslands. Woodland areas were isolated from one another and from the pine-oak woodlands of the Sierra Madre Occidental to the south by the warming and drying of the climate since the 1st century CE.\n\nThe Madrean pine-oak woodlands are found at higher elevations in Mexico's major mountain ranges, the Sierra Madre Occidental, the Sierra Madre Oriental, the Trans-Mexican volcanic belt, the Sierra Madre del Sur, the Sierra Madre de Oaxaca, the Peninsular Ranges of the Baja California Peninsula. \n\nThere are also approximately 27 enclaves in southern Arizona and New Mexico and in western Texas, where they are known as the \"Madrean sky islands\". The major Madrean \"sky island\" ranges in Arizona are the Dragoon Mountains, Chiricahua Mountains, Pinaleño Mountains, Santa Catalina Mountains, Rincon Mountains, Santa Rita Mountains, and Tumacacori Highlands. In New Mexico, the Sacramento Mountains and Guadalupe Mountains, which extend into Texas, as well as the Davis Mountains and Chisos Mountains, are also forested Madrean sky islands.\n\nThe pine-oak woodlands are composed of stands of oak \"(Quercus)\", pine \"(Pinus)\", douglas-fir \"(Pseudotsuga)\" and fir \"(Abies)\". The trees generally occur in mixed stands, though monospecific stands are sometimes found. \n\nThe pine-oak woodlands are home to one-quarter of Mexico's plant species, and Mexico is home to 44 of the 110 species of pine and over 135 species of oak, over 28% of the world's oak species. \n\nPlant species descended from Madro-Tertiary flora, Madrean ancestor species, are an important element of the California chaparral and woodlands ecoregion.\n\nThe World Wildlife Fund recognizes several distinct Madrean pine-oak woodlands sub−ecoregions, based on geographic distribution and species mix.\nThey include:\n\n\n"}
{"id": "33221682", "url": "https://en.wikipedia.org/wiki?curid=33221682", "title": "Martialia hyadesii", "text": "Martialia hyadesii\n\nMartialia hyadesii is a species of squid commonly known as the sevenstar flying squid.\n\n\"M. hyadesii\" occurs in epipelagic and mesopelagic waters of the Southern Ocean. Its range may be circumpolar with a Sub-Antarctic distribution\n\nThese large squid are known to prey upon deep-sea ridgeheads and other mesopelagic fish, and to be preyed upon in turn by king penguins and albatrosses.\n"}
{"id": "14980902", "url": "https://en.wikipedia.org/wiki?curid=14980902", "title": "Mediterranean Acacia-Argania dry woodlands", "text": "Mediterranean Acacia-Argania dry woodlands\n\nThe Mediterranean \"Acacia-Argania\" dry woodlands and succulent thickets is a Mediterranean forests, woodlands, and scrub ecoregion in North Africa centered mainly on Morocco but also including northwestern Western Sahara and the eastern Canary Islands. \n\nThis ecoregion occupies in Morocco, northwestern Western Sahara, and the eastern Canary Islands (Lanzarote, Fuerteventura, and associated islets). On the African mainland, it encompasses the Atlantic coastal plain, the lowlands of Al Haouz Province, the valleys of the Sous River and Draa River, and the westernmost part of the High Atlas and Anti-Atlas Mountains. \n\nIt has either a Mediterranean climate or a semi-arid climate or even an arid climate given that mean annual rainfall is below and falls as low as in the driest areas of the ecoregion. The winters are mild and frost-free and the summers relatively cool because of the moderating influence of the ocean. Temperatures average .\n\nThe Mediterranean \"Acacia-Argania\" dry woodlands and succulent thickets ecoregion is bounded on the north by the Mediterranean woodlands and forests, on the east by the North Saharan steppe and woodlands, on the south by the Atlantic coastal desert, and on the west by the Atlantic Ocean.\n\nThe chief plant communities in the ecoregion are dominated by \"Argania spinosa\" accompanied by Acacias, and the predominant lower vegetation is succulent shrubland dominated by Euphorbias. Some of the associated plant species are \"Periploca laevigata\", \"Senecio anthephorbium\", \"Launaea arborescens\", \"Warionia saharae\", \"Acacia gummifera\", \"Rhus trpartitum\", \"Withania frutescens\", \"Euphorbia officinarum\", \"Cytisus albidus\", \"Ephedra altissima\" and \"Tetraclinis articulata\".\n\nThere are a number of plants endemic to the Canary Islands part of the ecoregion, and the white-toothed shrew is the only mammal endemic there. On the mainland, a number of mammals are found in this ecoregion. These include the honey badger, European wildcat, Egyptian mongoose, Barbary ground squirrel, North African elephant shrew, Hoogstraal's gerbil, Barbary striped grass mouse and wild boar. Other, rarer mammals include caracal, African wildcat, dorcas gazelle, Cuvier's gazelle and Barbary sheep.\n"}
{"id": "36891119", "url": "https://en.wikipedia.org/wiki?curid=36891119", "title": "Nang Ta-khian", "text": "Nang Ta-khian\n\nNang Ta-khian (; \"Lady of Ta-khian\") is a female spirit of the folklore of Thailand. It manifests itself as a woman that haunts \"Hopea odorata\" trees. These are very large trees known as \"Ta-khian\" (ตะเคียน) in Thai, hence her name.\n\nThe Nang Ta-khian belong to a type of spirits or fairies related to trees and known generically in Thai folklore as \"Nang Mai\" (นางไม้; \"Lady of the Tree\"). \nLegends in the Thai oral tradition say the spirit inhabits a Ta-khian tree and sometimes appears as a beautiful young woman wearing traditional Thai attire, usually in reddish or brownish colours, contrasting with \"Nang Tani\" who is mostly represented in a green dress. \n\nNang Ta-khian is generally a sylvan spirit, for the Ta-khian is a tall, massive tree that can live for centuries, naturally found in the forest and not near inhabited areas. As it has a large trunk and a wide-spreading root system, it is normally not planted close to homesteads. Like all \"Nang Mai\", Nang Ta-khian haunts the immediate environment of her tree and she may also haunt a house having beams, stilts or pillars made from Ta-khian wood. She may hurt wicked or immoral people that come close to her abode, but righteous persons have nothing to fear from her.\n\nThe tree is almost never felled for lumber, since the spirit will be furious and follow the wood. About the only place Ta-khian is used as lumber is in a Buddhist monastery, where the merit of the monks is considered sufficient to render the spirit harmless. Traditionally trees where Ta-khian resides have lengths of colored satin cloth wrapped around their trunk. In order to protect venerable old trees from logging, Buddhist monks use to wrap lengths of satin around them and in case of having to cut the tree a special ceremony had to be performed to ask for permission. However, in present times some of these very ancient trees are felled anyway for their wood, even though it is said to be dangerous for a person to cut such a tree without the previous consent of the spirit inhabiting it.\n\nIn some parts of Thailand, Nang Ta-khian has become a popular tree deity. Miracles are attributed to her power and not only living trees, but also logs, beams or keels of wooden boats where the spirit is deemed to reside are an object of pilgrimage and have lengths of colored silk tied as an offering. In present times Nang Ta-Khian is usually propitiated in order to be lucky in the lottery.\n\nMost Nang Ta-khian shrines are quite humble, but larger temples and shrines dedicated to Nang Ta-Khian are found in locations such as Sao Hai District, Saraburi Province, and Amphawa District, Samut Songkhram Province, the shrine being part of a larger temple compound in some places.\n\nThis folk spirit is featured in the 2003 Thai film Ta-khian (\"The Haunted Tree\"), with Sorapong Chatree and 2010 movie Nang Ta-khian (\"Takien: The Haunted Tree\"). Nang Ta-khian has a role as well in the Nak animated movie.\n\n\n"}
{"id": "58990845", "url": "https://en.wikipedia.org/wiki?curid=58990845", "title": "Oceanography and Marine Biology: An Annual Review", "text": "Oceanography and Marine Biology: An Annual Review\n\nOceanography and Marine Biology: An Annual Review is an annual review of oceanography and marine biology that has been published since 1963. It was originally edited by Harold Barnes. It was originally published by Aberdeen University Press and Allen & Unwin but is now published by CRC Press, part of Taylor & Francis. The 55th volume was published in 2017.\n"}
{"id": "22858502", "url": "https://en.wikipedia.org/wiki?curid=22858502", "title": "Opposition surge", "text": "Opposition surge\n\nThe opposition surge (sometimes known as the opposition effect, opposition spike or Seeliger effect) is the brightening of a rough surface, or an object with many particles, when illuminated from directly behind the observer. The term is most widely used in astronomy, where generally it refers to the sudden noticeable increase in the brightness of a celestial body such as a planet, moon, or comet as its phase angle of observation approaches zero. It is so named because the reflected light from the Moon and Mars appear significantly brighter than predicted by simple Lambertian reflectance when at astronomical opposition. Two physical mechanisms have been proposed for this observational phenomenon: shadow hiding and coherent backscatter.\n\nThe phase angle is defined as the angle between the observer, the observed object and the source of light. In the case of the solar system, the light source is the Sun, and the observer is situated on Earth. At zero phase angle, the Sun is directly behind the observer and the object is directly ahead, fully illuminated.\n\nAs the phase angle of an object lit by the Sun decreases, the object's brightness rapidly increases. This is mainly due to the increased area lit, but is also partly due to the intrinsic brightness of the part that is sunlit. This is affected by such factors as the angle at which light reflected from the object is observed. For this reason, a full moon is more than twice as bright as the moon at first or third quarter, even though the visible area illuminated appears to be exactly twice as large.\n\nWhen the angle of reflection is close to the angle at which the light's rays hit the surface (that is, when the sun and the object are close to opposition from the viewpoint of the observer), this intrinsic brightness is usually close to its maximum. At a phase angle of zero degrees, all shadows disappear and the object is fully illuminated. When phase angles approach zero, there is a sudden increase in apparent brightness, and this sudden increase is referred to as the opposition surge.\n\nThe effect is particularly pronounced on regolith surfaces of airless bodies in the solar system. The usual major cause of the effect is that a surface's small pores and pits that would otherwise be in shadow at other incidence angles become lit up when the observer is almost in the same line as the source of illumination. The effect is usually only visible for a very small range of phase angles near zero. For bodies whose reflectance properties have been quantitatively studied, details of the opposition effect – its strength and angular extent – are described by two of the Hapke parameters. In the case of planetary rings (such as Saturn's), an opposition surge is due to the uncovering of shadows on the ring particles. This explanation was first proposed by Hugo von Seeliger in 1887.\n\nA theory for an additional effect that increases brightness during opposition is that of coherent backscatter. In the case of coherent backscatter, the reflected light is enhanced at narrow angles if the size of the scatterers in the surface of the body is comparable to the wavelength of light and the distance between scattering particles is greater than a wavelength. The increase in brightness is due to the reflected light combining coherently with the emitted light.\n\nCoherent backscatter phenomena have also been observed with radar. In particular, recent observations of Titan at 2.2 cm with Cassini have shown that a strong coherent backscatter effect is required to explain the high albedos at radar wavelengths.\n\nThe existence of the opposition surge was described in 1956 by Tom Gehrels during his study of the reflected light from an asteroid. Gehrels' later studies showed that the same effect could be shown in the moon's brightness. He coined the term \"opposition effect\" for the phenomenon, but the more intuitive \"opposition surge\" is now more widely used.\n\nSince Gehrels' early studies, an opposition surge has been noted for most airless solar system bodies. No such surge has been reported for bodies with significant atmospheres.\n\nIn the case of the Moon, B. J. Buratti \"et al.\" have suggested that its brightness increases by some 40% between a phase angle of 4° and one of 0°, and that this increase is greater for the rougher-surfaced highland areas than for the relatively smooth maria. As for the principal mechanism of the phenomenon, measurements indicate that the opposition effect exhibits only a small wavelength dependence: the surge is 3-4% larger at 0.41 μm than at 1.00 μm. This result suggests that the principal cause of the lunar opposition surge is shadow-hiding rather than coherent backscatter.\n\n\n"}
{"id": "48298600", "url": "https://en.wikipedia.org/wiki?curid=48298600", "title": "Richard Cannings (British Columbia politician)", "text": "Richard Cannings (British Columbia politician)\n\nRichard J. \"Dick\" Cannings (born March 31, 1954) is a Canadian politician, who was elected to represent the riding of South Okanagan—West Kootenay in the House of Commons of Canada in the Canadian federal election, 2015. An alumnus of Memorial University of Newfoundland and the University of British Columbia, he is a biologist and author.\n\nCannings was appointed the NDP Critic for Post-Secondary Education as well as the Deputy Critic for Natural Resources in the 42nd Canadian Parliament.\n\n!align=\"right\" colspan=3|Total Valid Votes\n!align=\"right\"|22,888\n!align=\"right\"|100%\n!align=\"right\"|\n!align=\"right\" colspan=3|Total Rejected Ballots\n!align=\"right\"|\n!align=\"right\"|\n!align=\"right\"|\n!align=\"right\" colspan=3|Turnout\n!align=\"right\"|\n!align=\"right\"|\n!align=\"right\"|\n\n"}
{"id": "6887798", "url": "https://en.wikipedia.org/wiki?curid=6887798", "title": "Sacred Oak", "text": "Sacred Oak\n\nThe Sacred Oak is a more-than-500-year-old Chinkapin Oak located in the Oley Valley, Pennsylvania. It sits in a grove of trees just off Friedensburg Road.\n\nAccording to Native-American legend, a beautiful woman, the wife of a powerful chief, became very ill. All the tribe's medicine men were called in; they \"pow-wowed\" and administered herbal medicines, to no effect. Slowly, the chief's wife became weaker and sicker. Finally, desperate for a cure, the young chief traveled to the Sacred Oak and there prayed to the Great Spirit for his wife to be saved. Amazingly, when he returned to camp, his wife was well again. Several years went by and the tribe was threatened by a hostile tribe. Once again, the chief traveled to the Sacred Oak and prayed to the Great Spirit, who gave him guidance. The chief gathered blankets and beads and journeyed the camp of the enemy. His gifts were accepted, and before he left, he smoked the pipe of peace with the chief of the other tribe. From then on, the Sacred Oak was looked upon as the shrine tree of the Delaware Indians. They went to the Sacred Oak in times of trouble to pray, and legend has it that help was always given to them. Legend says that the oak also has caused adverse effects to ones who have wronged or disrespected the oak. According to legend, the son of a high Lenape chief once urinated on the oak. Later that same day the ten-year-old disappeared into the woods of Oley never to be found.\n\nToday, the Sacred Oak still grows in a forested area just off Friedensburg Road in Oley Township. In the past, people were allowed to visit the tree, but now the land is considered private property and is off limits to visitors due to evidence and sightings of pagan worship ceremonies. This includes numerous spottings of robed individuals near the tree, ritualistic items on the surrounding rocks, and multiple animal carcasses. The land was recently sold to a new owner, who has begun raising money to help preserve the Sacred Oak. In 2007, the leader of the Lenape Nation Council, Chief Gentlemoon led two ceremonies to revitalize the tree. The tree was fertilized and deadwood was trimmed to help the tree continue to grow. The wood is being used for a variety of things, including being made into pens by a local craftsmen and Native-Americans all over the country. The Sacred Oak is currently the biggest tree in Berks County and is on the Pennsylvania Forestry Association's Champion Trees of Pennsylvania website.\nUpdate 12/3/09\nThe Sacred Oak is only open to the public twice per year. The two dates for public access are available on the Sacred Oak Facebook page or if you contact Oley Township.\n\nElders of the Lenni Lenape tribe have certified the tree has been venerated for 480+ years. The current owner, a horticulturist, places the tree's age at approximately 700 years.\n\nUPDATE 2014: New property owner again. Public access is limited to two times per year. Dates for public access are on the sacred oak facebook page or are available if you contact Oley Township. \n\n\n\n"}
{"id": "57997807", "url": "https://en.wikipedia.org/wiki?curid=57997807", "title": "South Sakhalin-Kurile mixed forests", "text": "South Sakhalin-Kurile mixed forests\n\nThe South Sakhalin-Kurile mixed forests ecoregion (WWF ID:PA0438) is split between the southwest region of Sakhalin Island, and the southern three islands of the Kurile Islands chain in the Russian Far East. The ecoregion is in the Palearctic ecozone, with a Humid Continental climate. It covers .\n\nThe Sakhalin Island side of the ecoregion faces the Sea of Japan to the west, and the Okhotsk Sea to the east. Being on the southern end of the island, plant life is denser and more varied. The Kurile Islands side of the ecoregion has high levels of biodiversity, reflecting the islands' position along the meeting of warm and cold sea currents (the Pacific Ocean and Okhotsk Sea, respectively). The resulting richness of marine life attracts large colonies of marine birds. The ecoregion in the Kurils is defined as the southern three islands: Kunashir Island, Iturup, and Shikotan. These islands were connected to the Japanese island of Hokkaido during the most recent glacial period, and unlike the northern two thirds of the Kuriles are not icebound in winter.\n\nThe region has a Humid continental, hot summer climate (Koppen classification (Dfa)). This climate is characterized by high variation in temperature, both daily and seasonally; with dry winters and cool summers. The \"hot summer\" designation indicates that at least one month per year averages above .\n\nThe area is characterized by high biodiversity because of the relatively mild climate, transition-zone placement, and island location. The flora of the southern Kuriles is closely related to that of Hokkaido, and endemism is low. A dominant floral community in the southern Kuriles is the bamboo thicket. Snow falling on the evergreen bamboo thickets in winter insulate the understory, which is relatively empty but abounding in shrews, mice and other rodents. These animals also thrive in the high-growth thickets, typified by white clover and \"Sakhalin buckwheat\" (Reynoutrua sachalinensis).\n\nAlthough plant communities are favorable to rodents, a noteworthy feature of the animal life in the southern Kuriles is the predominance of predator species, such as fox, sable, and bear, which have had to develop broader sources of food, particular marine sources on the coasts. Salmon are abundant in the streams.\n\nNotable protected areas of the Russian Federation in the ecoregion include:\nThis is an IUCN class Ia \"strict ecological reserves\" (Zapovednik).\n\n"}
{"id": "5375330", "url": "https://en.wikipedia.org/wiki?curid=5375330", "title": "Sri Lanka dry-zone dry evergreen forests", "text": "Sri Lanka dry-zone dry evergreen forests\n\nThe Sri Lanka dry-zone dry evergreen forests are a tropical dry broadleaf forest ecoregion of the island of Sri Lanka. The ecoregion covers an area of , which includes most of the island of Sri Lanka, with the exception of the islands' southwestern corner and central highlands, home to the Sri Lanka lowland rain forests and Sri Lanka montane rain forests ecoregions, respectively, and the northern Jaffna Peninsula, part of the Deccan thorn scrub forests ecoregion.\n\nThe Sri Lanka dry-zone dry evergreen forests are made up mostly of evergreen trees, which distinguish them from the deciduous trees that characterize most other tropical dry broadleaf forest ecoregions. The dry-zone dry evergreen forests most closely resemble the East Deccan dry evergreen forests of India's southeast coast.\n\n"}
{"id": "300026", "url": "https://en.wikipedia.org/wiki?curid=300026", "title": "Stream bed", "text": "Stream bed\n\nA stream bed or streambed is the channel bottom of a stream or river, the physical confine of the normal water flow. The lateral confines or channel margins are known as the stream banks or river banks, during all but flood stage. Under certain conditions a river can branch from one stream bed to multiple stream beds. A flood occurs when a stream overflows its banks and flows onto its flood plain. As a general rule, the bed is the part of the channel up to the normal water line, and the banks are that part above the normal water line. However, because water flow varies, this differentiation is subject to local interpretation. Usually, the bed is kept clear of terrestrial vegetation, whereas the banks are subjected to water flow only during unusual or perhaps infrequent high water stages and therefore might support vegetation some or much of the time.\nThe nature of any stream bed is always a function of the flow dynamics and the local geologic materials, influenced by that flow. With small streams in mesophytic regions, the nature of the stream bed is strongly responsive to conditions of precipitation runoff. Where natural conditions of either grassland or forest ameliorate peak flows, stream beds are stable, possibly rich, with organic matter and exhibit minimal scour. These streams support a rich biota. Where conditions produce unnatural levels of runoff, such as occurs below roads, the stream beds will exhibit a greater amount of scour, often down to bedrock and banks may be undercut. This process greatly increases watershed erosion and results in thinner soils, upslope from the stream bed, as the channel adjusts to the increase in flow. The stream bed is very complex in terms of erosion. Sediment is transported, eroded and deposited on the stream bed. With global warming there is a fear that the size and shape of riverbeds will change due to increased flood magnitude and frequency. However, one study has shown that the majority of sediment washed out in floods is \"near-threshold\" sediment that has been deposited during normal flow and only needs a slightly higher flow to become mobile again. This shows that the stream bed is left mostly unchanged in size and shape.\n\nBeds are usually what would be left once a stream is no longer in existence; the beds are usually well preserved even if they get buried, because the walls and canyons made by the stream usually have hard walls, usually soft sand and debris fill the bed. Dry stream beds are also subject to becoming underground water pockets (buried stream beds only) and flooding by heavy rains and water rising from the ground and may sometimes be part of the rejuvenation of the stream.\n\n"}
{"id": "1113560", "url": "https://en.wikipedia.org/wiki?curid=1113560", "title": "Tallgrass prairie", "text": "Tallgrass prairie\n\nThe tallgrass prairie is an ecosystem native to central North America. Natural and anthropogenic fire, as well as grazing by large mammals (primarily bison), were historically agents of periodic disturbance, which regulates tree encroachment, recycles nutrients to the soil, and catalyzes some seed dispersal and germination processes. Prior to widespread use of the steel plow, which enabled conversion to agricultural land use, tallgrass prairies expanded throughout the American Midwest and smaller portions of southern central Canada, from the transitional ecotones out of eastern North American forests, west to a climatic threshold based on precipitation and soils, to the southern reaches of the Flint Hills in Oklahoma, to a transition into forest in Manitoba.\n\nThey were characteristically found in the central forest-grasslands transition, the central tall grasslands, the upper Midwest forest-savanna transition, and the northern tall grasslands ecoregions. They flourished in areas with rich loess soils and moderate rainfall around 30-35 inches (700–900 mm) per year. To the east were the fire-maintained eastern savannas. In the northeast, where fire was infrequent and periodic windthrow represented the main source of disturbance, beech-maple forests dominated. In contrast, shortgrass prairie was typical in the western Great Plains, where rainfall is less frequent and soils are less fertile. Due to expansive agricultural land use, very little tallgrass prairie remains.\n\nRetreating glaciers deposited the parent material for soil in the form of till, i.e. unsorted sediment, about 10,000 years ago. Wind-dropped loess and organic matter accumulated, resulting in deep levels of topsoil. Animals such as bison, elk, deer, and rabbits added nitrogen to the soil through urine and feces. Prairie dogs, a ground squirrel-like rodent considered to be a keystone species, dug tunnels that \"aerated the soil and channeled water several feet below the surface.\"\nFor 5,000 to 8,000 years, more than of prairie grasslands were a major feature of the landscape. Between 1800 and 1930, the vast majority was destroyed. Settlers transformed what they named \"the Great American Desert\" or \"The Inland Sea\" into farmland. Major reasons for the prairie's demise were the confined grazing pattern of European cattle versus bison, the near-extermination of prairie dogs, and the plowing and cultivation of the land, which breached tallgrass root systems and interrupted reproduction. Further, extensive tile drainage has changed the soil's water content and hydrodynamics, and ongoing soil erosion results in its increasing loss.\n\nEstimates differ of how much original tallgrass prairie survives, ranging from less than 1% mostly in \"scattered remnants found in pioneer cemeteries, restoration projects, along highways and railroad rights-of-way, and on steep bluffs high above rivers\" to 4%.\n\nTallgrass prairie is capable of supporting significant biodiversity. Parts of the ecoregion among the \"top ten ecoregions for reptiles, birds, butterflies, and tree species. Tallgrass species are found in the understory layer.\" Oak (blackjack oak (\"Quercus marilandica\") and post oak (\"Q. stellata\") ) and hickory tree species occur in some areas, but generally in moderate densities. Bison (\"Bison bison\") were a dominant species.\n\nThe tallgrass prairie biome depends on prairie fires, a form of wildfire, for its survival and renewal. Tree seedlings and intrusive alien species without fire tolerance are eliminated by periodic fires. Such fires may either be set by humans (for example, Native Americans used fires to drive bison and improve hunting, travel, and visibility) or started naturally by lightning.\n\nAs its name suggests, the most obvious features of the tallgrass prairie are tall grasses, such as indiangrass (\"Sorghastrum nutans\"), big bluestem (\"Andropogon gerardi\"), little bluestem (\"Schizachyrium scoparium\"), and switchgrass (\"Panicum virgatum\"), which average between tall, with occasional stalks as high as . Prairies also include a large percentage of forbs, such as lead plant (\"Amorpha\" spp.), prairie rosinweed (\"Silphium\" spp.), gayfeathers (\"Liatris\" spp.), sunflowers (\"Helianthus\" spp.), asters (\"Aster\" and \"Symphyotrichum\" spp.), coneflowers (\"Echinacea\" spp., and \"Rudbeckia\" spp.), and many other species.\n\nTechnically, prairies have less than 5–11% tree cover. A grass-dominated plant community with 10–49% tree cover is a savanna.\n\nAfter the steel plow was invented by John Deere, this fertile soil became one of America's most important resources. Over 95% of the original tallgrass prairie is now farmland.\n\nThe tallgrass prairie survives in areas unsuited to plowing: the rocky hill country of the Flint Hills, which runs north to south through east-central Kansas; the eastern fringe of the Red River Valley (Tallgrass Aspen Parkland) in Manitoba and Minnesota; the \"Coteau des Prairies\", which extends from South Dakota through Minnesota and into Iowa; and the far north portion of Oklahoma. In Oklahoma, the tallgrass prairie has been maintained by ranchers, who saw the hat-high grass as prime grazing area for cattle.\n\nThe Tallgrass Prairie Preserve in Osage County, Oklahoma, and the somewhat smaller Tallgrass Prairie National Preserve in Kansas, attempt to maintain this ecosystem in its natural form. They have reintroduced plains bison to the vast expanses of grass. Other U.S. preserves include Midewin National Tallgrass Prairie in Illinois, Broken Kettle Preserve and Neal Smith National Wildlife Refuge in Iowa, Konza Prairie in Kansas, and Prairie State Park in Missouri. In eastern North Dakota is Sheyenne National Grassland, the only national grassland on the tallgrass prairie. Also, several small tallgrass prairie reservations are in Cook County, Illinois, including the National Natural Landmark, Gensburg-Markham Prairie.\n\nThe original extent of tallgrass prairie in Canada was the plain in the Red River Valley, southwest of Winnipeg in Manitoba (\"see\" map). While most of Manitoba's tallgrass prairie has been destroyed through cultivation and urban expansion, relatively small areas persist. One of the largest blocks of remaining tallgrass prairie in Manitoba is protected by several conservation partners in a conservation area called the Tallgrass Aspen Parkland. The Manitoba Tall Grass Prairie Preserve, which occupies small portions of the rural municipalities of Stuartburn and Franklin, forms a part of the Tallgrass Aspen Parkland. This preserve contains about of tallgrass prairie, aspen parkland, and wetlands.\n\nA small pocket of less than of tallgrass prairie remains in the southwest corner of Windsor, Ontario, protected by Ojibway Park, and Spring Garden Area of Natural Scientific Interest, along with the interconnected parks: Black Oak Heritage Park, Ojibway Prairie Provincial Nature Reserve, and the Tallgrass Prairie Heritage Park. Aside from the Provincial Nature Reserve, all are operated by the City of Windsor's Parks and Recreation.\n\nConsidered the birthplace of ecological restoration, the first tallgrass prairie restoration was the 1936 Curtis Prairie at the University of Wisconsin-Madison Arboretum. The UW Arboretum was the center of tallgrass prairie research through the first half of the 20th century, with the development of the nearby Greene Prairie, Aldo Leopold Shack and Farm and pioneering techniques like prescribed burning. The latter-half of the 20th century saw the growth of tallgrass prairie restoration beyond Wisconsin borders, with projects in Illinois such as at Knox College, and Fermi National Laboratory. These major tallgrass restoration projects marked restorations growth from isolated studies to widespread practice. Tallgrass prairie restoration efforts picked up wider public recognition in the 1980s, spurred by the publication of a book of appreciation, John Madson's \"Where the Sky Began: Land of the Tallgrass Prairie\" (1982). Nonprofit organizations throughout the former tallgrass prairie region began to reserve or restore small remnants of native prairie. For example, the Native Prairies Association of Texas was founded in 1986 to locate, restore, and protect prairies in Texas; the group currently protects about of Texas prairies.\n\nThe Midewin National Tallgrass Prairie, founded in 1996 near Elwood, Illinois, was as of 2006 the largest tallgrass prairie restoration area in the United States. In Minnesota, Glacial Ridge National Wildlife Refuge was established in 2004. The core of the refuge is a preserved tallgrass prairie remnant, and an additional are either in the process of restoration or will be soon. According to The Nature Conservancy, so far, 100 wetlands have been restored and of land have been seeded with native plant species.\n\nSeveral books have been published on tallgrass prairie restoration, including:\n\n\n"}
{"id": "7209935", "url": "https://en.wikipedia.org/wiki?curid=7209935", "title": "Trans-Caspian Oil Transport System", "text": "Trans-Caspian Oil Transport System\n\nThe Trans-Caspian Oil Transport System is a proposed project to transport oil through the Caspian Sea from Kazakhstani Caspian oilfields to Baku in Azerbaijan for the further transportation to the Mediterranean or Black Sea coast. The main options under consideration are an offshore oil pipeline from Kazakhstan to Azerbaijan, and construction of oil terminals and oil tankers fleet. A strong push for the project has been from the partners of the Kashagan oilfield project and in particular Total who has a share in both the field and the BTC pipeline. They have estimated that such a project would cost roughly US$4 billion. The project also faces opposition from Iran and Russia, both alternative avenues for Kazakhstan's oil and gas who would likely object to competing pipelines being built.\n\nIn 2005, the Government of Kazakhstan adopted plans for creation of a trans-Caspian westbound route for oil export. On 19 June 2006, President of Kazakhstan Nursultan Nazarbayev and President of Azerbaijan Ilham Aliyev signed a framework agreement on the trans-Caspian oil transport system. On 24 January 2007, partners in TengizChevroil (developer of Tengiz field) and KCO (Kashagan field developer)signed a memorandum of understanding to create a trans-Caspian oil transport system. On 2 October 2009, the national oil company of Kazakhstan Kazmunaygas and the State Oil Company of Azerbaijan Republic signed a memorandum of understanding to expand the Caspian Oil Transport System to include Azeri infrastructure and onshore pipelines from Baku to Kulevi oil terminal in Georgia. \n\nOn 6 October 2009, an agreement on the oil pipeline from Kashagan to Baku was signed by consortium of French companies during the French President Nicolas Sarkozy's visit to Kazakhstan.\n\nA long oil pipeline will run from Kashagan field or Kuryk to Baku. Work for the pipeline is still in the feasibility stage according to an official from the oil company Total.\n\nThe shuttle tankers system envisages an usage of oil tankers to transport oil from Kuryk terminal in Kazakhstan to Sangachal Terminal in Azerbaijan. The capacity of this system would be in the initial stage, rising later up to .\n\n\n"}
{"id": "4723868", "url": "https://en.wikipedia.org/wiki?curid=4723868", "title": "Tree of Life (Bahrain)", "text": "Tree of Life (Bahrain)\n\nThe Tree of Life (\"Shajarat-al-Hayat\") in Bahrain is a 9.75 meters (32 feet) high \"Prosopis cineraria\" tree that is over 400 years old. It is on a hill in a barren area of the Arabian Desert, 2 kilometers (1.2 miles) from Jebel Dukhan, the highest point in Bahrain, and 40 kilometers from Manama, the nearest city.\n\nThe tree is abundantly covered in green leaves. Due to its age and the fact that it is the only major tree growing in the area, the tree is a local tourist attraction and is visited by approximately 50,000 people every year. The yellow resin is used to make candles, aromatics and gum; the beans are processed into meal, jam, and wine.\n\nIt is not certain how the tree survives. Bahrain has little to no rain throughout the year. Its roots are 50 meters deep which may be enough to reach the water source. Others say the tree has learned to extract moisture from grains of sand. Some assert that the tree is protected by Enki, a god of water in Babylonian and Sumerian religion. Others claim that the tree is standing in what was once the Garden of Eden, and so has a more mystical source of water.\n\nIn 2009, the tree was nominated to be on the New7Wonders of Nature list, but it did not finish on the list.\n\nIn October 2010, archaeologists unearthed 500-year-old pottery and other artefacts in the vicinity of the tree. A soil and dendrochronology analysis conducted in the 1990s concluded that the tree was an \"Acacia\" planted in 1582.\n\nThe tree was mentioned in the 1991 film \"L.A. Story\", where Steve Martin calls it one of the most mystical places on earth.\n"}
{"id": "30669", "url": "https://en.wikipedia.org/wiki?curid=30669", "title": "Tunguska event", "text": "Tunguska event\n\nThe Tunguska event was a large explosion that occurred near the Stony Tunguska River in Yeniseysk Governorate (now Krasnoyarsk Krai), Russia, on the morning of 30 June 1908 (NS). The explosion over the sparsely populated Eastern Siberian Taiga flattened of forest, yet caused no known human casualties. The explosion is generally attributed to the air burst of a meteor. It is classified as an impact event, even though no impact crater has been found; the object is thought to have disintegrated at an altitude of rather than to have hit the surface of the Earth.\n\nThe Tunguska event is the largest impact event on Earth in recorded history. Studies have yielded different estimates of the meteoroid's size, on the order of , depending on whether the body was a comet or a denser asteroid.\n\nSince the 1908 event, there have been an estimated 1,000 scholarly papers (most in Russian) published on the Tunguska explosion. In 2013, a team of researchers published analysis results of micro-samples from a peat bog near the center of the affected area showing fragments that may be of meteoritic origin.\n\nEarly estimates of the energy of the air burst range from to 30 megatons of TNT (130 PJ), depending on the exact height of burst estimated when the scaling-laws from the effects of nuclear weapons are employed. However, modern supercomputer calculations that include the effect of the object's momentum find that more of the energy was focused downward than would be the case from a nuclear explosion and estimate that the airburst had an energy range from 3 to 5 megatons of TNT (13 to 21 PJ).\n\nThe 15-megaton (Mt) estimate represents an energy about 1,000 times greater than that of the atomic bomb dropped on Hiroshima, Japan—roughly equal to that of the United States' Castle Bravo (15.2 Mt) ground-based thermonuclear detonation on 1 March 1954, and about one-third that of the Soviet Union's Tsar Bomba explosion on 30 October 1961 (which, at 50 Mt, is the largest nuclear weapon ever detonated).\n\nIt is estimated that the Tunguska explosion knocked down some 80 million trees over an area of , and that the shock wave from the blast would have measured 5.0 on the Richter magnitude scale. An explosion of this magnitude would be capable of destroying a large metropolitan area, but, due to the remoteness of the location, no human fatalities were officially documented. Several reports have indicated that two people may have died in the event; however, these deaths remain unofficial.<ref name=\"SAO/NASA - ADS\"></ref> This event has helped to spark discussion of asteroid impact avoidance.\n\nOn 30 June 1908, at around 07:17 local time, Evenki natives and Russian settlers in the hills north-west of Lake Baikal observed a column of bluish light, nearly as bright as the Sun, moving across the sky. About ten minutes later, there was a flash and a sound similar to artillery fire. Eyewitnesses closer to the explosion reported that the source of the sound moved from the east to the north of them. The sounds were accompanied by a shock wave that knocked people off their feet and broke windows hundreds of kilometres away. The majority of witnesses reported only the sounds and tremors, and did not report seeing the explosion. Eyewitness accounts vary regarding the sequence and duration of the events.\n\nThe explosion registered at seismic stations across Eurasia, and air waves from the blast were detected in Germany, Denmark, Croatia, the UK, and as far away as Jakarta and Washington, D.C. It is estimated that, in some places, the resulting shock wave was equivalent to an earthquake measuring 5.0 on the Richter magnitude scale. Over the next few days night skies in Asia and Europe were aglow, with contemporaneous reports of photographs being successfully taken at midnight in both Sweden and Scotland. It has been theorized that this effect was due to light passing through high-altitude ice particles that had formed at extremely low temperatures—a phenomenon that many years later would be produced by space shuttles. In the United States, the Smithsonian Astrophysical Observatory and the Mount Wilson Observatory observed a months-long decrease in atmospheric transparency due to an increase in suspended dust particles.\n\nTestimony of S. Semenov, as recorded by Leonid Kulik's expedition in 1930:\n\nTestimony of Chuchan of Shanyagir tribe, as recorded by I. M. Suslov in 1926:\n\n\"Sibir\" newspaper, 2 July 1908:\n\n\"Siberian Life\" newspaper, 27 July 1908:\n\n\"Krasnoyaretz\" newspaper, 13 July 1908:\n\nThe first recorded expedition arrived at the scene more than a decade after the event. In 1921, the Russian mineralogist Leonid Kulik, visiting the Podkamennaya Tunguska River basin as part of a survey for the Soviet Academy of Sciences, deduced from local accounts that the explosion had been caused by a giant meteorite impact. He persuaded the Soviet government to fund an expedition to the Tunguska region, based on the prospect of meteoric iron that could be salvaged to aid Soviet industry. Kulik's party eventually undertook an expedition in 1927.\nUpon arrival, Kulik made arrangements with the local Evenki hunters to guide his party to the impact site. Reaching the explosion site was an extremely arduous task. Upon reaching an area just south of the site, the superstitious Evenki hunters would go no farther, fearing what they called the Valleymen. Kulik had to return to the nearby village, and his party was delayed for several days while they sought new guides.\n\nThe spectacle that confronted Kulik as he stood on a ridge overlooking the devastated area was overwhelming. To the explorers' surprise, they found no crater. There was instead around ground zero a zone across of trees scorched and devoid of branches, but standing upright. The trees farther away had been partly scorched and knocked down in a direction away from the centre. Much later, in the 1960s, it was established that the zone of levelled forest occupied an area of , its shape resembling a gigantic spread-eagled butterfly with a \"wingspan\" of and a \"body length\" of . Upon closer examination, Kulik located holes that he erroneously concluded were meteorite holes; he did not have the means at that time to excavate the holes.\n\nDuring the next ten years there were three more expeditions to the area. Kulik found several dozens of little \"pothole\" bogs, each some in diameter, that he thought might be meteoric craters. After a laborious exercise in draining one of these bogs (the so-called \"Suslov's crater\", in diameter), he found an old stump on the bottom, ruling out the possibility that it was a meteoric crater. In 1938, Kulik arranged for an aerial photographic survey of the area covering the central part of the levelled forest (). The negatives of these aerial photographs (1,500 negatives, each ) were burned in 1975 by order of Yevgeny Krinov, then Chairman of the Committee on Meteorites of the USSR Academy of Sciences, as part of an initiative to dispose of hazardous nitrate film. Positive prints were preserved for further study in the Russian city of Tomsk.\n\nExpeditions sent to the area in the 1950s and 1960s found microscopic silicate and magnetite spheres in siftings of the soil. Similar spheres were predicted to exist in the felled trees, although they could not be detected by contemporary means. Later expeditions did identify such spheres in the resin of the trees. Chemical analysis showed that the spheres contained high proportions of nickel relative to iron, which is also found in meteorites, leading to the conclusion they were of extraterrestrial origin. The concentration of the spheres in different regions of the soil was also found to be consistent with the expected distribution of debris from a meteoroid air burst. Later studies of the spheres found unusual ratios of numerous other metals relative to the surrounding environment, which was taken as further evidence of their extraterrestrial origin.\n\nChemical analysis of peat bogs from the area also revealed numerous anomalies considered consistent with an impact event. The isotopic signatures of stable carbon, hydrogen, and nitrogen isotopes at the layer of the bogs corresponding to 1908 were found to be inconsistent with the isotopic ratios measured in the adjacent layers, and this abnormality was not found in bogs located outside the area. The region of the bogs showing these anomalous signatures also contains an unusually high proportion of iridium, similar to the iridium layer found in the Cretaceous–Paleogene boundary. These unusual proportions are believed to result from debris from the falling body that deposited in the bogs. The nitrogen is believed to have been deposited as acid rain, a suspected fallout from the explosion.\n\nResearcher John Anfinogenov has suggested that a boulder found at the event site, known as John's stone, is a remnant of the meteorite.\n\nThe leading scientific explanation for the explosion is the air burst of an asteroid above Earth's surface.\n\nMeteoroids enter Earth's atmosphere from outer space every day, travelling at a speed of at least . The heat generated by compression of air in front of the body (ram pressure) as it travels through the atmosphere is immense and most meteoroids burn up or explode before they reach the ground. Since the second half of the 20th century, close monitoring of Earth's atmosphere has led to the discovery that such asteroid air bursts occur rather frequently. A stony asteroid of about in diameter can produce an explosion of around 20 kilotons, similar to that of the Fat Man bomb dropped on Nagasaki, and data released by the US Air Force's Defense Support Program indicate that such explosions occur high in the upper atmosphere more than once a year. Tunguska-like megaton-range events are much rarer. Eugene Shoemaker estimated that such events occur about once every 300 years.\n\nThe explosion's effect on the trees near the hypocentre of the explosion was replicated during atmospheric nuclear tests in the 1950s and 1960s, and was similar to the effects of the conventional Operation Blowdown. These effects are caused by the blast wave produced by large airburst explosions. The trees directly below the explosion are stripped as the blast wave moves vertically downward, while trees farther away are knocked over because the blast wave is travelling closer to horizontal when it reaches them.\n\nSoviet experiments performed in the mid-1960s, with model forests (made of matches on wire stakes) and small explosive charges slid downward on wires, produced butterfly-shaped blast patterns strikingly similar to the pattern found at the Tunguska site. The experiments suggested that the object had approached at an angle of roughly 30 degrees from the ground and 115 degrees from north and had exploded in mid-air.\n\nIn 1930, the British astronomer F. J. W. Whipple suggested that the Tunguska body was a small comet. A comet is composed of dust and volatiles, such as water ice and frozen gases, and could have been completely vaporised by the impact with Earth's atmosphere, leaving no obvious traces. The comet hypothesis was further supported by the glowing skies (or \"skyglows\" or \"bright nights\") observed across Europe for several evenings after the impact, possibly explained by dust and ice that had been dispersed from the comet's tail across the upper atmosphere. The cometary hypothesis gained a general acceptance amongst Soviet Tunguska investigators by the 1960s.\n\nIn 1978, Slovak astronomer Ľubor Kresák suggested that the body was a fragment of Comet Encke. This is a periodic comet with an extremely short period of 3 years that stays entirely within the orbit of Jupiter. It is also responsible for the Beta Taurids, an annual meteor shower with a maximum activity around 28–29 June. The Tunguska event coincided with the peak activity of that shower, and the approximate trajectory of the Tunguska object is consistent with what would be expected from a fragment of Comet Encke. It is now known that bodies of this kind explode at frequent intervals tens to hundreds of kilometres above the ground. Military satellites have been observing these explosions for decades.\n\nIn 1983, astronomer Zdeněk Sekanina published a paper criticising the comet hypothesis. He pointed out that a body composed of cometary material, travelling through the atmosphere along such a shallow trajectory, ought to have disintegrated, whereas the Tunguska body apparently remained intact into the lower atmosphere. Sekanina argued that the evidence pointed to a dense, rocky object, probably of asteroidal origin. This hypothesis was further boosted in 2001, when Farinella, Foschini, \"et al.\" released a study calculating the probabilities based on orbital modelling extracted from the atmospheric trajectories of the Tunguska object. They concluded with a probability of 83% that the object moved on an asteroidal path originating from the asteroid belt, rather than on a cometary one (probability of 17%).\n\nProponents of the comet hypothesis have suggested that the object was an extinct comet with a stony mantle that allowed it to penetrate the atmosphere.\n\nThe chief difficulty in the asteroid hypothesis is that a stony object should have produced a large crater where it struck the ground, but no such crater has been found. It has been hypothesised that the passage of the asteroid through the atmosphere caused pressures and temperatures to build up to a point where the asteroid abruptly disintegrated in a huge explosion. The destruction would have to have been so complete that no remnants of substantial size survived, and the material scattered into the upper atmosphere during the explosion would have caused the skyglows. Models published in 1993 suggested that the stony body would have been about across, with physical properties somewhere between an ordinary chondrite and a carbonaceous chondrite. Typical carbonaceous chondrite substance tends to be dissolved with water rather quickly unless it is frozen.\n\nChristopher Chyba and others have proposed a process whereby a stony meteorite could have exhibited the behaviour of the Tunguska impactor. Their models show that when the forces opposing a body's descent become greater than the cohesive force holding it together, it blows apart, releasing nearly all its energy at once. The result is no crater, with damage distributed over a fairly wide radius, and all of the damage resulting from the thermal energy released in the blast.\n\nThree-dimensional numerical modelling of the Tunguska impact done by Utyuzhnikov and Rudenko in 2008 supports the comet hypothesis. According to their results, the comet matter dispersed in the atmosphere, while the destruction of the forest was caused by the shock wave.\n\nDuring the 1990s, Italian researchers, coordinated by the physicist Giuseppe Longo from University of Bologna, extracted resin from the core of the trees in the area of impact to examine trapped particles that were present during the 1908 event. They found high levels of material commonly found in rocky asteroids and rarely found in comets.\n\nKelly \"et al.\" (2009) contend that the impact was caused by a comet because of the sightings of noctilucent clouds following the impact, a phenomenon caused by massive amounts of water vapor in the upper atmosphere. They compared the noctilucent cloud phenomenon to the exhaust plume from NASA's \"Endeavour\" space shuttle.\n\nIn 2010, an expedition led by Vladimir Alexeev with scientists from the Troitsk Innovation and Nuclear Research Institute (TRINITY) used ground penetrating radar to examine the Suslov crater at the Tunguska site. What they found was that the crater was created by the violent impact of a celestial body. The layers of the crater consisted of modern permafrost on top, older damaged layers underneath, and finally, deep below, fragments of the celestial body were discovered. Preliminary analysis showed that it was a huge piece of ice that shattered on impact, which seem to support the theory that a comet caused the cataclysm. In contrast, in 2013, analysis of fragments from the Tunguska site by a joint US-European team was consistent with an iron meteorite.\n\nIn June 2007, scientists from the University of Bologna identified a lake in the Tunguska region as a possible impact crater from the event. They do not dispute that the Tunguska body exploded in mid-air but believe that a ten-metre fragment survived the explosion and struck the ground. Lake Cheko is a small, bowl-shaped lake approximately north-northwest of the hypocentre. The hypothesis has been disputed by other impact crater specialists. A 1961 investigation had dismissed a modern origin of Lake Cheko, saying that the presence of metres-thick silt deposits at the lake's bed suggests an age of at least 5,000 years, but more recent research suggests that only a metre or so of the sediment layer on the lake bed is \"normal lacustrine sedimentation\", a depth consistent with an age of about 100 years. Acoustic-echo soundings of the lake floor provide support for the hypothesis that the lake was formed by the Tunguska event. The soundings revealed a conical shape for the lake bed, which is consistent with an impact crater. Magnetic readings indicate a possible metre-sized chunk of rock below the lake's deepest point that may be a fragment of the colliding body. Finally, the lake's long axis points to the hypocentre of the Tunguska explosion, about away. Work is still being done at Lake Cheko to determine its origins.\n\nThe main points of the study are that\nIn 2017, however, new research by Russian scientists points to a rejection of the theory. They used soil research to prove that the lake is 280 years old or even much older; in any case clearly older than the Tunguska events.\n\nThe scientific consensus is that the explosion was caused by the impact of a small asteroid; however, there are some dissenters. Astrophysicist Wolfgang Kundt has proposed that the Tunguska event was caused by the release and subsequent explosion of 10 million tons of natural gas from within Earth's crust. The basic idea is that natural gas leaked out of the crust and then rose to its equal-density height in the atmosphere; from there, it drifted downwind, in a sort of wick, which eventually found an ignition source such as lightning. Once the gas was ignited, the fire streaked along the wick, and then down to the source of the leak in the ground, whereupon there was the explosion.\n\nThe similar verneshot hypothesis has also been proposed as a possible cause of the Tunguska event. Other research has supported a geophysical mechanism for the event.\n\nThe Tunguska event is not the only example of a great unobserved explosion event. For example, the 1930 Curuçá River event in Brazil was an explosion of a superbolide that left no clear evidence of an impact crater. Modern developments in infrasound detection by the Comprehensive Nuclear-Test-Ban Treaty Organization and infrared DSP satellite technology have reduced the likelihood of undetected airbursts.\n\nA smaller air burst occurred over a populated area in Russia on 15 February 2013, at Chelyabinsk in the Ural district of Russia. The exploding meteoroid was an asteroid that measured about 17 to 20 metres across, with an estimated initial mass of 11,000 tonnes, and inflicted over 1,200 injuries, mainly from broken glass falling from windows shattered by its shock wave.\n\n\nNotes\nBibliography\n\n"}
{"id": "1384399", "url": "https://en.wikipedia.org/wiki?curid=1384399", "title": "USS Porpoise (1836)", "text": "USS Porpoise (1836)\n\nThe second USS \"Porpoise\" was a 224-ton \"Dolphin\" class brigantine. (In early American usage, a brigantine was referred to as a hermaphrodite brig.) The USS \"Porpoise\" was later rerigged as a brig (see illustration at right). She was based on the same plans as .\n\n\"Porpoise\" was authorized by Congress on 30 June 1834; built in 1835; and launched 31 May 1836; Lieutenant William Ramsay in command.\n\n\"Porpoise\" sailed from Boston, Massachusetts on 25 August 1836, called at various southern ports, and conducted coastal surveying operations under the direction of Lt. Charles Wilkes in the summer of 1837. In October 1837, she hunted pirates along the southern coast, and then resumed her survey work in December.\n\n\"Porpoise\", Lt. Cadwalader Ringgold in command, was then assigned to the squadron which Wilkes was to command on an extended exploratory expedition around the world. She stood out of Hampton Roads on 18 August 1838 with the United States Exploring Expedition Squadron. She assisted in the exploration and survey work of the Expedition as it confirmed the existence of the Antarctic Continent, charted vast areas of the South Pacific, circumnavigated the world, and returned to New York four years later.\n\n\"Porpoise\" underwent overhaul at New York at the end of 1842 and sailed on 8 February 1843 for the west coast of Africa to join the squadron patrolling for slavers. She returned to New York on 19 November 1844.\n\nFrom February 1845-July 1847, \"Porpoise\" cruised in the Gulf of Mexico, participating in the Naval operations against Tampico, Pánuco, and Veracruz during the War with Mexico. Upon return to Norfolk, Virginia, she remained decommissioned until 1 January 1848.\n\nDuring the next three and a half years, she hunted slavers along the west coast of Africa, touching at the U.S. in the spring of 1850. Returning to New York from this extended cruise on 19 December 1851. She again decommissioned on 3 August 1852.\n\nRecommissioned in May 1853, she was assigned to North Pacific Exploring and Surveying Expedition under Commander Cadwalader Ringgold, a veteran, like \"Porpoise\", of the Wilkes Expedition. She joined the squadron at Hampton Roads, and with it, stood out to sea on 11 June 1853. \"Porpoise\" rounded the Cape of Good Hope, and with the squadron explored and charted many Pacific islands and shoals before arriving in China in March 1854. The squadron put to sea once more to explore in the Bonins, the Ladrones, and the Marianas. \"Porpoise\" parted company with the other vessels on 21 September 1854 between Formosa and China, and was never heard from again. It is supposed that she foundered in a heavy typhoon which occurred a few days after her separation from the squadron.\n\n\n"}
{"id": "474589", "url": "https://en.wikipedia.org/wiki?curid=474589", "title": "Ultra-high-energy cosmic ray", "text": "Ultra-high-energy cosmic ray\n\nIn astroparticle physics, an ultra-high-energy cosmic ray (UHECR) is a cosmic ray particle with a kinetic energy greater than eV, far beyond both the rest mass and energies typical of other cosmic ray particles.\n\nAn extreme-energy cosmic ray (EECR) is an UHECR with energy exceeding (about 8 joule), the so-called Greisen–Zatsepin–Kuzmin limit (GZK limit). This limit should be the maximum energy of cosmic ray protons that have traveled long distances (about 160 million light years), since higher-energy protons would have lost energy over that distance due to scattering from photons in the cosmic microwave background (CMB). It follows that EECR could not be survivors from the early universe, but are cosmologically \"young\", emitted somewhere in the Local Supercluster by some unknown physical process. If an EECR is not a proton, but a nucleus with formula_1 nucleons, then the GZK limit applies to its nucleons, which carry only a fraction formula_2 of the total energy of the nucleus. For an iron nucleus, the corresponding limit would be .\n\nThese particles are extremely rare; between 2004 and 2007, the initial runs of the Pierre Auger Observatory (PAO) detected 27 events with estimated arrival energies above , i.e., about one such event every four weeks in the 3000 km area surveyed by the observatory.\n\nThere is evidence that these highest-energy cosmic rays might be iron nuclei, rather than the protons that make up most cosmic rays.\n\nThe postulated (hypothetical) sources of EECR are known as Zevatrons, named in analogy to Lawrence Berkeley National Laboratory's Bevatron and Fermilab's Tevatron, and therefore capable of accelerating particles to 1 ZeV (10 eV, zetta-electronvolt). In 2004 there was a consideration of the possibility of galactic jets acting as Zevatrons, due to diffusive acceleration of particles caused by shock waves inside the jets. In particular, models suggested that shock waves from the nearby M87 galactic jet could accelerate an iron nucleus to ZeV ranges. In 2007, PAO tentatively associated EECR with extragalactic supermassive black holes at the center of nearby galaxies called active galactic nuclei (AGN). Extremely high energies might be explained also by the Centrifugal mechanism of acceleration in the magnetospheres of AGN. Although newer results indicate that fewer than 40% of these cosmic rays seemed to be coming from the AGN, a much weaker correlation than previously reported. A more speculative suggestion by Grib and Pavlov (2007, 2008) envisages the decay of superheavy dark matter by means of the Penrose process.\n\nThe first observation of a cosmic ray particle with an energy exceeding (16 J) was made by Dr John D Linsley and Livio Scarsi at the Volcano Ranch experiment in New Mexico in 1962.\n\nCosmic ray particles with even higher energies have since been observed. Among them was the Oh-My-God particle observed by the University of Utah's Fly's Eye experiment on the evening of 15 October 1991 over Dugway Proving Ground, Utah. Its observation was a shock to astrophysicists, who estimated its energy to be approximately (50 J)—in other words, an atomic nucleus with kinetic energy equal to that of a baseball () traveling at about .\n\nThe energy of this particle is some 40 million times that of the highest energy protons that have been produced in any terrestrial particle accelerator. However, only a small fraction of this energy would be available for an interaction with a proton or neutron on Earth, with most of the energy remaining in the form of kinetic energy of the products of the interaction (see Collider#Explanation). The effective energy available for such a collision is the square root of double the product of the particle's energy and the mass energy of the proton, which for this particle gives , roughly 50 times the collision energy of the Large Hadron Collider.\n\nSince the first observation, by the University of Utah's Fly's Eye Cosmic Ray Detector, at least fifteen similar events have been recorded, confirming the phenomenon. These very high energy cosmic ray particles are very rare; the energy of most cosmic ray particles is between 10 MeV and 10 GeV.\n\n\nPierre Auger Observatory is an international cosmic ray observatory designed to detect ultra-high-energy cosmic ray particles (with energies beyond 10 eV). These high-energy particles have an estimated arrival rate of just 1 per square kilometer per century, therefore, in order to record a large number of these events, the Auger Observatory has created a detection area of 3,000 km² (the size of Rhode Island, USA) in Mendoza Province, western Argentina.\nA larger cosmic-ray detector array is also planned for the northern hemisphere as part of the Pierre Auger complex.\nThe Pierre Auger Observatory, in addition to obtaining directional information from the cluster of water tanks used to observe the cosmic-ray-shower components, also has four telescopes trained on the night sky to observe fluorescence of the nitrogen molecules as the shower particles traverse the sky, giving further directional information on the original cosmic ray particle.\n\nIn September 2017, data from 12 years of observations from PAO supported an extragalactic source (e.g. outside of Earth's galaxy) for the origin of extremely high energy cosmic rays.\n\nOne suggested source of UHECR particles is their origination from neutron stars. In young neutron stars with spin periods of <10ms, the magnetohydrodynamic (MHD) forces from the quasi-neutral fluid of superconducting protons and electrons existing in a neutron superfluid accelerate iron nuclei to UHECR velocities. The magnetic field produced by the neutron superfluid in rapidly rotating stars creates a magnetic field of 10–10 tesla, at which point the neutron star is classified as a magnetar. This magnetic field is the strongest in the observed universe and creates the relativistic MHD wind believed to accelerate iron nuclei remaining from the supernova to the necessary energy.\n\nAnother hypothesized source of UHECRs from neutron stars is during neutron star to strange star combustion. This hypothesis relies on the assumption that strange matter is the ground state of matter which has no experimental or observational data to support it. Due to the immense gravitational pressures from the neutron star, it is believed that small pockets of matter consisting of \"up\", \"down\", and \"strange\" quarks in equilibrium acting as a single hadron (as opposed to a number of baryons). This will then combust the entire star to strange matter, at which point the neutron star becomes a strange star and its magnetic field breaks down, which occurs because the protons and neutrons in the quasi-neutral fluid have become strangelets. This magnetic field breakdown releases large amplitude electromagnetic waves (LAEMWs). The LAEMWs accelerate light ion remnants from the supernova to UHECR energies.\n\nVery high energy cosmic ray electrons might be explained by the Centrifugal mechanism of acceleration in the magnetospheres of the Crab-like Pulsars.\n\nInteractions with blue-shifted cosmic microwave background radiation limit the distance that these particles can travel before losing energy; this is known as the Greisen–Zatsepin–Kuzmin limit or GZK limit.\n\nThe source of such high energy particles has been a mystery for many years. Recent results from the Pierre Auger Observatory show that ultra-high-energy cosmic ray arrival directions appear to be correlated with extragalactic supermassive black holes at the center of nearby galaxies called active galactic nuclei (AGN).\nHowever, since the angular correlation scale used is fairly large (3.1 degrees) these results do not unambiguously identify the origins of such cosmic ray particles. The AGN could merely be closely associated with the actual sources, for example in galaxies or other astrophysical objects that are clumped with matter on large scales within 100 Mpc.\n\nSome of the supermassive black holes in AGN are known to be rotating, as in the Seyfert galaxy MCG 6-30-15 with time-variability in their inner accretion disks. Black hole spin is a potentially effective agent to drive UHECR production, provided ions are suitably launched to circumvent limiting factors deep within the galactic nucleus, notably curvature radiation and inelastic scattering with radiation from the inner disk. Low-luminosity, intermittent Seyfert galaxies may meet the requirements with the formation of a linear accelerator several light years away from the nucleus, yet within their extended ion tori whose UV radiation ensures a supply of ionic contaminants. The corresponding electric fields are small, on the order of 10 V/cm, whereby the observed UHECRs are indicative for the astronomical size of the source. Improved statistics by the Pierre Auger Observatory will be instrumental in identifying the presently tentative association of UHECRs (from the Local Universe) with Seyferts and LINERs.\n\nOther possible sources of the UHECR are:\n\n\nIt is hypothesized that active galactic nuclei are capable of converting dark matter into high energy protons. Yuri Pavlov and Andrey Grib at the Alexander Friedmann Laboratory for Theoretical Physics at St. Petersburg hypothesize that dark matter particles are about 15 times heavier than protons, and that they can decay into pairs of heavier virtual particles of a type that interacts with ordinary matter. Near an active galactic nucleus, one of these particles can fall into the black hole, while the other escapes, as described by the Penrose process. Some of those particles will collide with incoming particles; these are very high energy collisions which, according to Pavlov, can form ordinary visible protons with very high energy. Pavlov then claims that evidence of such processes are ultra-high-energy cosmic ray particles. Ultra-high energy cosmic ray particles may also be produced by the decay of super-heavy dark matter \"X particles\" such as Holeums. Such very energetic decay products, carrying a fraction of the mass of the X particle, are believed to be a plausible explanation for the observed ultra-high energy cosmic rays (UHECR).\nHigh energy cosmic ray particles traversing intergalactic space suffer the GZK cutoff above 10 eV due to interactions with cosmic background radiation if the primary cosmic ray particles are protons or nuclei. The Pierre Auger Project, HiRes and Yakutsk Extensive Air Shower Array found the GZK cutoff, while Akeno-AGASA observed the events above the cutoff (11 events in the past 10 years). The result of the Akeno-AGASA experiment is smooth near the GZK cutoff energy. If one assumes that the Akeno-AGASA result is correct and consider its implication, a possible explanation for the AGASA data on GZK cutoff violation would be a shower caused by dark matter particles. A dark matter particle is not constrained by the GZK cutoff, since it interacts weakly with cosmic background radiation. Recent measurements by the Pierre Auger Project have found a correlation between the direction of high energy cosmic ray particles and the location of AGN.\n\n\n\n"}
{"id": "53947242", "url": "https://en.wikipedia.org/wiki?curid=53947242", "title": "Uzunkum Nature Park", "text": "Uzunkum Nature Park\n\nUzunkum Nature Park () is a nature park declared coastal area in Kocaeli Province, northwestern Turkey.\n\nUzunkum, literally long sandy beach, is located at Black Sea east of Cebeci village in Kandıra district of Kocaeli Province. The area was declared a nature park by the Ministry of Environment and Forest in 2014. The nature park consists of the parts, the sandy beach in the north and forested hillside. It covers an area of .\n\nThe nature park offers outdoor recreational activities like hiking, swimming, surfing and angling.\n\nThe vegetation of the nature park consists of the endangered sea daffodil (\"Pancratium maritimum\"), Syrian juniper (\"Juniperus drupacea\"), juniper, Valonia oak (\"Quercus macrolepis\"), laurel (\"Laurus nobilis\"), oak, hornbeam (\"Carpinus\"), common ash (\"Fraxinus excelsior\"), cedar (\"Cedrus\"), cypress, willow, rose hip, buxus, European cornel (\"Cornus mas\"), spurge (\"Cornus mas\"), \"Cercis\", pilewort, \"Crocus\", trefoi (\"Trifolium\"), hemp and diverse algae species.\n\nThe nature is habitat for the mammals fox, jackal, hare, beaver, badger, crested porcupine, the reptile tortoise, the bird species woodcock, quail, gull, black cormorant, francolin, partridge, common blackbird, kingfisher and owl.\n"}
{"id": "20902194", "url": "https://en.wikipedia.org/wiki?curid=20902194", "title": "Vitaly Bianki", "text": "Vitaly Bianki\n\nVitaly Valentinovich Bianki () (11 February 1894, St. Petersburg — 10 June 1959, Leningrad) — was a popular Russian children’s writer and a prolific author of books on nature.\n\nBianki's father was Valentin Lvovich Bianchi (1857-1920), an entomologist and curator at the Zoological Museum of the Russian Academy of Sciences. His three sons were at home in its halls. On a summer vacation Vitaly Bianchi went on his first forestry trip, and became a passionate outdoorsman. He graduated from the Natural Science Department of the Physical and Mathematical Faculty of Petrograd University in 1916 with a specialization in ornithology, as well as studies in art at the St. Petersburg Art Institute to assist with the drawing of plants and animals.\n\nBianchi served in the army in 1916 and joined the Socialist-Revolutionary Party in 1917. In 1917 moved to Biysk, where he was forced into the Kolchak army. He deserted and lived under a false name \"Vitaly Belyanin\" until the eventual expulsion of the Kolchak regime. His double name Bianki-Belyanin remained on his passport until the end of his life. He worked for the Commission for the Protection of Monuments of Tsarskoye Selo, and was sent in spring 1918 to Siberia and the Volga, where he worked in the summer of 1918 in Samara for the newspaper \"People\" (\"Народ\").\n\nAfter the Soviets came to power, Bianki worked in Biysk in the Department of Education at a regional museum where he served as director. He also worked as a school teacher for Comintern III. He was arrested twice in 1921, and in fear of further arrest, he moved his family in 1922 to Petrograd.\n\nBianki participated in scientific expeditions on the Volga, Altai Krai, Urals and Kazakhstan and brought back copious scientific notes, about which he wrote: \"They were lying like a dead weight on my soul. They - as at the Zoological Museum - has been meeting the many dead animals in the dry record of facts, it was a forest, animals stagnation of immobility, no birds flew and did not sing. Then again, as in childhood, painfully wanted to find a word that would revive them magically compelled to come to life.\"\n\nIn 1923, Bianki began to publish a natural calendar in the Leningrad magazine \"Sparrow\" (later \"New Robinson\"). This publication became a prototype of his later \"Forest newspapers every year\" (1927). In those years he became associated with a literary club, where writers of children's literature gathered. This included the writers Chukovsky, Zhitkov and Marshak. Soon afterward his story \"The Red Sparrow Traveling\" was published in the magazine \"Sparrow\". Bianki’s first published book for children was titled \"Whose nose is better?\" (1923). His voluminous \"Forest Newspaper for Every Year\" (1st edition, 1928) is a peculiar encyclopedia of forest life and forest inhabitants.\n\nAt the end of 1925, Bianki was arrested again on suspicion of subversive activity and sentenced to three years of exile in Uralsk. In the spring of 1928, he was released to return to Leningrad. In November 1932 was arrested again, but was released after three and a half weeks for lack of evidence. In March 1935, he was arrested as an \"active member of the armed uprising against Soviet rule\" and taken to the Aktobe region, but was released after intercession by Maxim Gorky's ex-wife, Yekaterina Peshkova. In 1941, he returned to Leningrad. Because of poor health he was not drafted to serve in the army for World War II, but was evacuated to the Urals. After the war he returned again to Leningrad.\n\nThe body of his work consists of over three hundred short stories, fairy tales, stories, and articles, which make up 120 books. One of his students and followers was Nikolai Sladkov, an author of books about nature.\n\nVitali Bianki died in Leningrad and was buried in the Bogoslovskoe Cemetery.\n\n\n"}
{"id": "73231", "url": "https://en.wikipedia.org/wiki?curid=73231", "title": "Weather forecasting", "text": "Weather forecasting\n\nWeather forecasting is the application of science and technology to predict the conditions of the atmosphere for a given location and time. People have attempted to predict the weather informally for millennia and formally since the 19th century. Weather forecasts are made by collecting quantitative data about the current state of the atmosphere at a given place and using meteorology to project how the atmosphere will change.\n\nOnce calculated by hand based mainly upon changes in barometric pressure, current weather conditions, and sky condition or cloud cover, weather forecasting now relies on computer-based models that take many atmospheric factors into account. Human input is still required to pick the best possible forecast model to base the forecast upon, which involves pattern recognition skills, teleconnections, knowledge of model performance, and knowledge of model biases. The inaccuracy of forecasting is due to the chaotic nature of the atmosphere, the massive computational power required to solve the equations that describe the atmosphere, the error involved in measuring the initial conditions, and an incomplete understanding of atmospheric processes. Hence, forecasts become less accurate as the difference between current time and the time for which the forecast is being made (the \"range\" of the forecast) increases. The use of ensembles and model consensus help narrow the error and pick the most likely outcome.\n\nThere are a variety of end uses to weather forecasts. Weather warnings are important forecasts because they are used to protect life and property. Forecasts based on temperature and precipitation are important to agriculture, and therefore to traders within commodity markets. Temperature forecasts are used by utility companies to estimate demand over coming days. On an everyday basis, people use weather forecasts to determine what to wear on a given day. Since outdoor activities are severely curtailed by heavy rain, snow and wind chill, forecasts can be used to plan activities around these events, and to plan ahead and survive them. In 2009, the US spent $5.1 billion on weather forecasting.\n\nFor millennia people have tried to forecast the weather. In 650 BC, the Babylonians predicted the weather from cloud patterns as well as astrology. In about 350 BC, Aristotle described weather patterns in \"Meteorologica\". Later, Theophrastus compiled a book on weather forecasting, called the \"Book of Signs\". Chinese weather prediction lore extends at least as far back as 300 BC, which was also around the same time ancient Indian astronomers developed weather-prediction methods. In New Testament times, Christ himself referred to deciphering and understanding local weather patterns, by saying, \"When evening comes, you say, 'It will be fair weather, for the sky is red', and in the morning, 'Today it will be stormy, for the sky is red and overcast.' You know how to interpret the appearance of the sky, but you cannot interpret the signs of the times.\"\n\nIn 904 AD, Ibn Wahshiyya's \"Nabatean Agriculture\", translated into Arabic from an earlier Aramaic work, discussed the weather forecasting of atmospheric changes and signs from the planetary astral alterations; signs of rain based on observation of the lunar phases; and weather forecasts based on the movement of winds.\n\nAncient weather forecasting methods usually relied on observed patterns of events, also termed pattern recognition. For example, it might be observed that if the sunset was particularly red, the following day often brought fair weather. This experience accumulated over the generations to produce weather lore. However, not all of these predictions prove reliable, and many of them have since been found not to stand up to rigorous statistical testing.\n\nIt was not until the invention of the electric telegraph in 1835 that the modern age of weather forecasting began. Before that, the fastest that distant weather reports could travel was around 100 miles per day (160 km/d), but was more typically 40–75 miles per day (60–120 km/day) (whether by land or by sea). By the late 1840s, the telegraph allowed reports of weather conditions from a wide area to be received almost instantaneously, allowing forecasts to be made from knowledge of weather conditions further upwind.\n\nThe two men credited with the birth of forecasting as a science were an officer of the Royal Navy Francis Beaufort and his protégé Robert FitzRoy. Both were influential men in British naval and governmental circles, and though ridiculed in the press at the time, their work gained scientific credence, was accepted by the Royal Navy, and formed the basis for all of today's weather forecasting knowledge.\n\nBeaufort developed the Wind Force Scale and Weather Notation coding, which he was to use in his journals for the remainder of his life. He also promoted the development of reliable tide tables around British shores, and with his friend William Whewell, expanded weather record-keeping at 200 British Coast guard stations.\n\nRobert FitzRoy was appointed in 1854 as chief of a new department within the Board of Trade to deal with the collection of weather data at sea as a service to mariners. This was the forerunner of the modern Meteorological Office. All ship captains were tasked with collating data on the weather and computing it, with the use of tested instruments that were loaned for this purpose.\nA storm in 1859 that caused the loss of the \"Royal Charter\" inspired FitzRoy to develop charts to allow predictions to be made, which he called \"forecasting the weather\", thus coining the term \"weather forecast\". Fifteen land stations were established to use the telegraph to transmit to him daily reports of weather at set times leading to the first gale warning service. His warning service for shipping was initiated in February 1861, with the use of telegraph communications. The first daily weather forecasts were published in \"The Times\" in 1861. In the following year a system was introduced of hoisting storm warning cones at the principal ports when a gale was expected. The \"Weather Book\" which FitzRoy published in 1863 was far in advance of the scientific opinion of the time.\n\nAs the electric telegraph network expanded, allowing for the more rapid dissemination of warnings, a national observational network was developed, which could then be used to provide synoptic analyses. Instruments to continuously record variations in meteorological parameters using photography were supplied to the observing stations from Kew Observatory – these cameras had been invented by Francis Ronalds in 1845 and his barograph had earlier been used by FitzRoy.\n\nTo convey accurate information, it soon became necessary to have a standard vocabulary describing clouds; this was achieved by means of a series of classifications first achieved by Luke Howard in 1802, and standardized in the \"International Cloud Atlas\" of 1896.\n\nIt was not until the 20th century that advances in the understanding of atmospheric physics led to the foundation of modern numerical weather prediction. In 1922, English scientist Lewis Fry Richardson published \"Weather Prediction By Numerical Process\", after finding notes and derivations he worked on as an ambulance driver in World War I. He described therein how small terms in the prognostic fluid dynamics equations governing atmospheric flow could be neglected, and a finite differencing scheme in time and space could be devised, to allow numerical prediction solutions to be found.\n\nRichardson envisioned a large auditorium of thousands of people performing the calculations and passing them to others. However, the sheer number of calculations required was too large to be completed without the use of computers, and the size of the grid and time steps led to unrealistic results in deepening systems. It was later found, through numerical analysis, that this was due to numerical instability. The first computerised weather forecast was performed by a team composed of American meteorologists Jule Charney, Philip Thompson, Larry Gates, and Norwegian meteorologist Ragnar Fjørtoft, applied mathematician John von Neumann, and ENIAC programmer Klara Dan von Neumann. Practical use of numerical weather prediction began in 1955, spurred by the development of programmable electronic computers.\n\nThe first ever daily weather forecasts were published in \"The Times\" on August 1, 1861, and the first weather maps were produced later in the same year. In 1911, the Met Office began issuing the first marine weather forecasts via radio transmission. These included gale and storm warnings for areas around Great Britain. In the United States, the first public radio forecasts were made in 1925 by Edward B. \"E.B.\" Rideout, on WEEI, the Edison Electric Illuminating station in Boston. Rideout came from the U.S. Weather Bureau, as did WBZ weather forecaster G. Harold Noyes in 1931.\n\nThe world's first televised weather forecasts, including the use of weather maps, were experimentally broadcast by the BBC in 1936. This was brought into practice in 1949 after World War II. George Cowling gave the first weather forecast while being televised in front of the map in 1954. In America, experimental television forecasts were made by James C Fidler in Cincinnati in either 1940 or 1947 on the DuMont Television Network. In the late 1970s and early 80s, John Coleman, the first weatherman on ABC-TV's Good Morning America, pioneered the use of on-screen weather satellite information and computer graphics for television forecasts. Coleman was a co-founder of The Weather Channel (TWC) in 1982. TWC is now a 24-hour cable network. Some weather channels have started broadcasting on live broadcasting programs such as YouTube and Periscope to reach more viewers.\n\nThe basic idea of numerical weather prediction is to sample the state of the fluid at a given time and use the equations of fluid dynamics and thermodynamics to estimate the state of the fluid at some time in the future. The main inputs from country-based weather services are surface observations from automated weather stations at ground level over land and from weather buoys at sea. The World Meteorological Organization acts to standardize the instrumentation, observing practices and timing of these observations worldwide. Stations either report hourly in METAR reports, or every six hours in SYNOP reports. Sites launch radiosondes, which rise through the depth of the troposphere and well into the stratosphere. Data from weather satellites are used in areas where traditional data sources are not available. Compared with similar data from radiosondes, the satellite data has the advantage of global coverage, however at a lower accuracy and resolution. Meteorological radar provide information on precipitation location and intensity, which can be used to estimate precipitation accumulations over time. Additionally, if a pulse Doppler weather radar is used then wind speed and direction can be determined.\nCommerce provides pilot reports along aircraft routes, and ship reports along shipping routes. Research flights using reconnaissance aircraft fly in and around weather systems of interest such as tropical cyclones. Reconnaissance aircraft are also flown over the open oceans during the cold season into systems that cause significant uncertainty in forecast guidance, or are expected to be of high impact 3–7 days into the future over the downstream continent.\n\nModels are \"initialized\" using this observed data. The irregularly spaced observations are processed by data assimilation and objective analysis methods, which perform quality control and obtain values at locations usable by the model's mathematical algorithms (usually an evenly spaced grid). The data are then used in the model as the starting point for a forecast. Commonly, the set of equations used to predict the known as the physics and dynamics of the atmosphere are called primitive equations. These equations are initialized from the analysis data and rates of change are determined. The rates of change predict the state of the atmosphere a short time into the future. The equations are then applied to this new atmospheric state to find new rates of change, and these new rates of change predict the atmosphere at a yet further time into the future. This \"time stepping\" procedure is continually repeated until the solution reaches the desired forecast time.\n\nThe length of the time step chosen within the model is related to the distance between the points on the computational grid, and is chosen to maintain numerical stability. Time steps for global models are on the order of tens of minutes, while time steps for regional models are between one and four minutes. The global models are run at varying times into the future. The Met Office's Unified Model is run six days into the future, the European Centre for Medium-Range Weather Forecasts model is run out to 10 days into the future, while the Global Forecast System model run by the Environmental Modeling Center is run 16 days into the future. The visual output produced by a model solution is known as a prognostic chart, or \"prog\". The raw output is often modified before being presented as the forecast. This can be in the form of statistical techniques to remove known biases in the model, or of adjustment to take into account consensus among other numerical weather forecasts. MOS or model output statistics is a technique used to interpret numerical model output and produce site-specific guidance. This guidance is presented in coded numerical form, and can be obtained for nearly all National Weather Service reporting stations in the United States. As proposed by Edward Lorenz in 1963, long range forecasts, those made at a range of two weeks or more, are impossible to definitively predict the state of the atmosphere, owing to the chaotic nature of the fluid dynamics equations involved. In numerical models, extremely small errors in initial values double roughly every five days for variables such as temperature and wind velocity.\n\nEssentially, a model is a computer program that produces meteorological information for future times at given locations and altitudes. Within any modern model is a set of equations, known as the primitive equations, used to predict the future state of the atmosphere. These equations—along with the ideal gas law—are used to evolve the density, pressure, and potential temperature scalar fields and the velocity vector field of the atmosphere through time. Additional transport equations for pollutants and other aerosols are included in some primitive-equation mesoscale models as well. The equations used are nonlinear partial differential equations, which are impossible to solve exactly through analytical methods, with the exception of a few idealized cases. Therefore, numerical methods obtain approximate solutions. Different models use different solution methods: some global models use spectral methods for the horizontal dimensions and finite difference methods for the vertical dimension, while regional models and other global models usually use finite-difference methods in all three dimensions.\n\nThe simplest method of forecasting the weather, persistence, relies upon today's conditions to forecast the conditions tomorrow. This can be a valid way of forecasting the weather when it is in a steady state, such as during the summer season in the tropics. This method of forecasting strongly depends upon the presence of a stagnant weather pattern. Therefore, when in a fluctuating weather pattern, this method of forecasting becomes inaccurate. It can be useful in both short range forecasts and long range forecasts.\n\nMeasurements of barometric pressure and the pressure tendency (the change of pressure over time) have been used in forecasting since the late 19th century. The larger the change in pressure, especially if more than , the larger the change in weather can be expected. If the pressure drop is rapid, a low pressure system is approaching, and there is a greater chance of rain. Rapid pressure rises are associated with improving weather conditions, such as clearing skies.\n\nAlong with pressure tendency, the condition of the sky is one of the more important parameters used to forecast weather in mountainous areas. Thickening of cloud cover or the invasion of a higher cloud deck is indicative of rain in the near future. High thin cirrostratus clouds can create halos around the sun or moon, which indicates an approach of a warm front and its associated rain. Morning fog portends fair conditions, as rainy conditions are preceded by wind or clouds that prevent fog formation. The approach of a line of thunderstorms could indicate the approach of a cold front. Cloud-free skies are indicative of fair weather for the near future. A bar can indicate a coming tropical cyclone. The use of sky cover in weather prediction has led to various weather lore over the centuries.\n\nThe forecasting of the weather within the next six hours is often referred to as nowcasting. In this time range it is possible to forecast smaller features such as individual showers and thunderstorms with reasonable accuracy, as well as other features too small to be resolved by a computer model. A human given the latest radar, satellite and observational data will be able to make a better analysis of the small scale features present and so will be able to make a more accurate forecast for the following few hours. However, there are now expert systems using those data and mesoscale numerical model to make better extrapolation, including evolution of those features in time.\n\nIn the past, the human forecaster was responsible for generating the entire weather forecast based upon available observations. Today, human input is generally confined to choosing a model based on various parameters, such as model biases and performance. Using a consensus of forecast models, as well as ensemble members of the various models, can help reduce forecast error. However, regardless how small the average error becomes with any individual system, large errors within any particular piece of guidance are still possible on any given model run. Humans are required to interpret the model data into weather forecasts that are understandable to the end user. Humans can use knowledge of local effects that may be too small in size to be resolved by the model to add information to the forecast. While increasing accuracy of forecast models implies that humans may no longer be needed in the forecast process at some point in the future, there is currently still a need for human intervention.\n\nThe analog technique is a complex way of making a forecast, requiring the forecaster to remember a previous weather event that is expected to be mimicked by an upcoming event. What makes it a difficult technique to use is that there is rarely a perfect analog for an event in the future. Some call this type of forecasting pattern recognition. It remains a useful method of observing rainfall over data voids such as oceans, as well as the forecasting of precipitation amounts and distribution in the future. A similar technique is used in medium range forecasting, which is known as teleconnections, when systems in other locations are used to help pin down the location of another system within the surrounding regime. An example of teleconnections are by using El Niño-Southern Oscillation (ENSO) related phenomena.\n\nMost end users of forecasts are members of the general public. Thunderstorms can create strong winds and dangerous lightning strikes that can lead to deaths, power outages, and widespread hail damage. Heavy snow or rain can bring transportation and commerce to a stand-still, as well as cause flooding in low-lying areas. Excessive heat or cold waves can sicken or kill those with inadequate utilities, and droughts can impact water usage and destroy vegetation.\n\nSeveral countries employ government agencies to provide forecasts and watches/warnings/advisories to the public in order to protect life and property and maintain commercial interests. Knowledge of what the end user needs from a weather forecast must be taken into account to present the information in a useful and understandable way. Examples include the National Oceanic and Atmospheric Administration's National Weather Service (NWS) and Environment Canada's Meteorological Service (MSC). Traditionally, newspaper, television, and radio have been the primary outlets for presenting weather forecast information to the public. In addition, some cities had weather beacons. Increasingly, the internet is being used due to the vast amount of specific information that can be found. In all cases, these outlets update their forecasts on a regular basis.\n\nA major part of modern weather forecasting is the severe weather alerts and advisories that the national weather services issue in the case that severe or hazardous weather is expected. This is done to protect life and property. Some of the most commonly known of severe weather advisories are the severe thunderstorm and tornado warning, as well as the severe thunderstorm and tornado watch. Other forms of these advisories include winter weather, high wind, flood, tropical cyclone, and fog. Severe weather advisories and alerts are broadcast through the media, including radio, using emergency systems as the Emergency Alert System, which break into regular programming.\n\nThe low temperature forecast for the current day is calculated using the lowest temperature found between 7pm that evening through 7am the following morning. So, in short, today's forecasted low is most likely tomorrow's low temperature.\n\nThere are a number of sectors with their own specific needs for weather forecasts and specialist services are provided to these users.\n\nBecause the aviation industry is especially sensitive to the weather, accurate weather forecasting is essential. Fog or exceptionally low ceilings can prevent many aircraft from landing and taking off. Turbulence and icing are also significant in-flight hazards. Thunderstorms are a problem for all aircraft because of severe turbulence due to their updrafts and outflow boundaries, icing due to the heavy precipitation, as well as large hail, strong winds, and lightning, all of which can cause severe damage to an aircraft in flight. Volcanic ash is also a significant problem for aviation, as aircraft can lose engine power within ash clouds. On a day-to-day basis airliners are routed to take advantage of the jet stream tailwind to improve fuel efficiency. Aircrews are briefed prior to takeoff on the conditions to expect en route and at their destination. Additionally, airports often change which runway is being used to take advantage of a headwind. This reduces the distance required for takeoff, and eliminates potential crosswinds.\n\nCommercial and recreational use of waterways can be limited significantly by wind direction and speed, wave periodicity and heights, tides, and precipitation. These factors can each influence the safety of marine transit. Consequently, a variety of codes have been established to efficiently transmit detailed marine weather forecasts to vessel pilots via radio, for example the MAFOR (marine forecast). Typical weather forecasts can be received at sea through the use of RTTY, Navtex and Radiofax.\n\nFarmers rely on weather forecasts to decide what work to do on any particular day. For example, drying hay is only feasible in dry weather. Prolonged periods of dryness can ruin cotton, wheat, and corn crops. While corn crops can be ruined by drought, their dried remains can be used as a cattle feed substitute in the form of silage. Frosts and freezes play havoc with crops both during the spring and fall. For example, peach trees in full bloom can have their potential peach crop decimated by a spring freeze. Orange groves can suffer significant damage during frosts and freezes, regardless of their timing.\n\nWeather forecasting of wind, precipitations and humidity is essential for preventing and controlling wildfires. Different indices, like the \"Forest fire weather index\" and the \"Haines Index\", have been developed to predict the areas more at risk to experience fire from natural or human causes. Conditions for the development of harmful insects can be predicted by forecasting the evolution of weather, too.\n\nElectricity and gas companies rely on weather forecasts to anticipate demand, which can be strongly affected by the weather. They use the quantity termed the degree day to determine how strong of a use there will be for heating (heating degree day) or cooling (cooling degree day). These quantities are based on a daily average temperature of . Cooler temperatures force heating degree days (one per degree Fahrenheit), while warmer temperatures force cooling degree days. In winter, severe cold weather can cause a surge in demand as people turn up their heating. Similarly, in summer a surge in demand can be linked with the increased use of air conditioning systems in hot weather. By anticipating a surge in demand, utility companies can purchase additional supplies of power or natural gas before the price increases, or in some circumstances, supplies are restricted through the use of brownouts and blackouts.\n\nIncreasingly, private companies pay for weather forecasts tailored to their needs so that they can increase their profits or avoid large losses. For example, supermarket chains may change the stocks on their shelves in anticipation of different consumer spending habits in different weather conditions. Weather forecasts can be used to invest in the commodity market, such as futures in oranges, corn, soybeans, and oil.\n\nRoyal Navy\n\nThe UK Royal Navy, working with the UK Met Office, has its own specialist branch of weather observers and forecasters, as part of the Hydrographic and Meteorological (HM) specialisation, who monitor and forecast operational conditions across the globe, to provide accurate and timely weather and oceanographic information to submarines, ships and Fleet Air Arm aircraft.\n\nA mobile unit in the RAF, working with the UK Met Office, forecasts the weather for regions in which British, allied servicemen and women are deployed. A group based at Camp Bastion provides forecasts for the British armed forces in Afghanistan.\n\nSimilar to the private sector, military weather forecasters present weather conditions to the war fighter community. Military weather forecasters provide pre-flight and in-flight weather briefs to pilots and provide real time resource protection services for military installations. Naval forecasters cover the waters and ship weather forecasts. The United States Navy provides a special service to both themselves and the rest of the federal government by issuing forecasts for tropical cyclones across the Pacific and Indian Oceans through their Joint Typhoon Warning Center.\n\nWithin the United States, Air Force Weather provides weather forecasting for the Air Force and the Army. Air Force forecasters cover air operations in both wartime and peacetime operations and provide Army support; United States Coast Guard marine science technicians provide ship forecasts for ice breakers and other various operations within their realm; and Marine forecasters provide support for ground- and air-based United States Marine Corps operations. All four military branches take their initial enlisted meteorology technical training at Keesler Air Force Base. Military and civilian forecasters actively cooperate in analyzing, creating and critiquing weather forecast products.\n\n\nThese are academic or governmental meteorology organizations. Most provide at least a limited forecast for their area of interest on their website.\n\n"}
{"id": "56106", "url": "https://en.wikipedia.org/wiki?curid=56106", "title": "Wildfire", "text": "Wildfire\n\nA wildfire or wildland fire is a fire in an area of combustible vegetation occurring in rural areas. Depending on the type of vegetation present, a wildfire can also be classified more specifically as a brush fire, bushfire, desert fire, forest fire, grass fire, hill fire, peat fire, vegetation fire, and veld fire.\n\nFossil charcoal indicates that wildfires began soon after the appearance of terrestrial plants 420 million years ago. Wildfire's occurrence throughout the history of terrestrial life invites conjecture that fire must have had pronounced evolutionary effects on most ecosystems' flora and fauna. Earth is an intrinsically flammable planet owing to its cover of carbon-rich vegetation, seasonally dry climates, atmospheric oxygen, and widespread lightning and volcanic ignitions.\n\nWildfires can be characterized in terms of the cause of ignition, their physical properties, the combustible material present, and the effect of weather on the fire. Wildfires can cause damage to property and human life, though naturally occurring wildfires may have beneficial effects on native vegetation, animals, and ecosystems that have evolved with fire. High-severity wildfire creates complex early seral forest habitat (also called \"snag forest habitat\"), which often has higher species richness and diversity than unburned old forest. Many plant species depend on the effects of fire for growth and reproduction. Wildfires in ecosystems where wildfire is uncommon or where non-native vegetation has encroached may have strongly negative ecological effects. Wildfire behavior and severity result from the combination of factors such as available fuels, physical setting, and weather. Analyses of historical meteorological data and national fire records in western North America show the primacy of climate in driving large regional fires via wet periods that create substantial fuels or drought and warming that extend conducive fire weather.\n\nStrategies for wildfire prevention, detection, and suppression have varied over the years. One common and inexpensive technique is controlled burning, intentionally igniting smaller fires to minimize the amount of flammable material available for a potential wildfire. Vegetation may be burned periodically to maintain high species diversity and limit the accumulation of plants and other debris that may serve as fuel. Wildland fire use is the cheapest and most ecologically appropriate policy for many forests. Fuels may also be removed by logging, but fuels treatments and thinning have no effect on severe fire behavior when under extreme weather conditions. Wildfire itself is reportedly \"the most effective treatment for reducing a fire's rate of spread, fireline intensity, flame length, and heat per unit of area\" according to Jan Van Wagtendonk, a biologist at the Yellowstone Field Station. Building codes in fire-prone areas typically require that structures be built of flame-resistant materials and a defensible space be maintained by clearing flammable materials within a prescribed distance from the structure.\n\nThree major natural causes of wildfire ignitions exist: \n\nThe most common direct human causes of wildfire ignition include arson, discarded cigarettes, power-line arcs (as detected by arc mapping), and sparks from equipment. Ignition of wildland fires via contact with hot rifle-bullet fragments is also possible under the right conditions. Wildfires can also be started in communities experiencing shifting cultivation, where land is cleared quickly and farmed until the soil loses fertility, and slash and burn clearing. Forested areas cleared by logging encourage the dominance of flammable grasses, and abandoned logging roads overgrown by vegetation may act as fire corridors. Annual grassland fires in southern Vietnam stem in part from the destruction of forested areas by US military herbicides, explosives, and mechanical land-clearing and -burning operations during the Vietnam War.\n\nThe most common cause of wildfires varies throughout the world. In Canada and northwest China, lightning operates as the major source of ignition. In other parts of the world, human involvement is a major contributor. In Africa, Central America, Fiji, Mexico, New Zealand, South America, and Southeast Asia, wildfires can be attributed to human activities such as agriculture, animal husbandry, and land-conversion burning. In China and in the Mediterranean Basin, human carelessness is a major cause of wildfires. In the United States and Australia, the source of wildfires can be traced both to lightning strikes and to human activities (such as machinery sparks, cast-away cigarette butts, or arson). Coal seam fires burn in the thousands around the world, such as those in Burning Mountain, New South Wales; Centralia, Pennsylvania; and several coal-sustained fires in China. They can also flare up unexpectedly and ignite nearby flammable material.\n\nThe spread of wildfires varies based on the flammable material present, its vertical arrangement and moisture content, and weather conditions. Fuel arrangement and density is governed in part by topography, as land shape determines factors such as available sunlight and water for plant growth. Overall, fire types can be generally characterized by their fuels as follows: \n\nWildfires occur when all of the necessary elements of a fire triangle come together in a susceptible area: an ignition source is brought into contact with a combustible material such as vegetation, that is subjected to sufficient heat and has an adequate supply of oxygen from the ambient air. A high moisture content usually prevents ignition and slows propagation, because higher temperatures are required to evaporate any water within the material and heat the material to its fire point. Dense forests usually provide more shade, resulting in lower ambient temperatures and greater humidity, and are therefore less susceptible to wildfires. Less dense material such as grasses and leaves are easier to ignite because they contain less water than denser material such as branches and trunks. Plants continuously lose water by evapotranspiration, but water loss is usually balanced by water absorbed from the soil, humidity, or rain. When this balance is not maintained, plants dry out and are therefore more flammable, often a consequence of droughts.\n\nA wildfire \"front\" is the portion sustaining continuous flaming combustion, where unburned material meets active flames, or the smoldering transition between unburned and burned material. As the front approaches, the fire heats both the surrounding air and woody material through convection and thermal radiation. First, wood is dried as water is vaporized at a temperature of . Next, the pyrolysis of wood at releases flammable gases. Finally, wood can smoulder at or, when heated sufficiently, ignite at . Even before the flames of a wildfire arrive at a particular location, heat transfer from the wildfire front warms the air to , which pre-heats and dries flammable materials, causing materials to ignite faster and allowing the fire to spread faster. High-temperature and long-duration surface wildfires may encourage flashover or \"torching\": the drying of tree canopies and their subsequent ignition from below.\n\nWildfires have a rapid \"forward rate of spread\" (FROS) when burning through dense, uninterrupted fuels. They can move as fast as in forests and in grasslands. Wildfires can advance tangential to the main front to form a \"flanking\" front, or burn in the opposite direction of the main front by \"backing\". They may also spread by \"jumping\" or \"spotting\" as winds and vertical convection columns carry \"firebrands\" (hot wood embers) and other burning materials through the air over roads, rivers, and other barriers that may otherwise act as firebreaks. Torching and fires in tree canopies encourage spotting, and dry ground fuels that surround a wildfire are especially vulnerable to ignition from firebrands. Spotting can create \"spot fires\" as hot embers and firebrands ignite fuels downwind from the fire. In Australian bushfires, spot fires are known to occur as far as from the fire front.\n\nEspecially large wildfires may affect air currents in their immediate vicinities by the stack effect: air rises as it is heated, and large wildfires create powerful updrafts that will draw in new, cooler air from surrounding areas in thermal columns. Great vertical differences in temperature and humidity encourage pyrocumulus clouds, strong winds, and fire whirls with the force of tornadoes at speeds of more than . Rapid rates of spread, prolific crowning or spotting, the presence of fire whirls, and strong convection columns signify extreme conditions.\n\nThe thermal heat from wildfire can cause significant weathering of rocks and boulders, heat can rapidly expand a boulder and thermal shock can occur, which may cause an object's structure to fail.\n\nHeat waves, droughts, cyclical climate changes such as El Niño, and regional weather patterns such as high-pressure ridges can increase the risk and alter the behavior of wildfires dramatically. Years of precipitation followed by warm periods can encourage more widespread fires and longer fire seasons. Since the mid-1980s, earlier snowmelt and associated warming has also been associated with an increase in length and severity of the wildfire season in the Western United States. Global warming may increase the intensity and frequency of droughts in many areas, creating more intense and frequent wildfires. A 2015 study indicates that the increase in fire risk in California may be attributable to human-induced climate change. A study of alluvial sediment deposits going back over 8,000 years found warmer climate periods experienced severe droughts and stand-replacing fires and concluded climate was such a powerful influence on wildfire that trying to recreate presettlement forest structure is likely impossible in a warmer future.\n\nIntensity also increases during daytime hours. Burn rates of smoldering logs are up to five times greater during the day due to lower humidity, increased temperatures, and increased wind speeds. Sunlight warms the ground during the day which creates air currents that travel uphill. At night the land cools, creating air currents that travel downhill. Wildfires are fanned by these winds and often follow the air currents over hills and through valleys. Fires in Europe occur frequently during the hours of 12:00 p.m. and 2:00 p.m. Wildfire suppression operations in the United States revolve around a 24-hour \"fire day\" that begins at 10:00 a.m. due to the predictable increase in intensity resulting from the daytime warmth.\n\nWildfire's occurrence throughout the history of terrestrial life invites conjecture that fire must have had pronounced evolutionary effects on most ecosystems' flora and fauna. Wildfires are common in climates that are sufficiently moist to allow the growth of vegetation but feature extended dry, hot periods. Such places include the vegetated areas of Australia and Southeast Asia, the veld in southern Africa, the fynbos in the Western Cape of South Africa, the forested areas of the United States and Canada, and the Mediterranean Basin.\n\nHigh-severity wildfire creates complex early seral forest habitat (also called “snag forest habitat”), which often has higher species richness and diversity than unburned old forest. Plant and animal species in most types of North American forests evolved with fire, and many of these species depend on wildfires, and particularly high-severity fires, to reproduce and grow. Fire helps to return nutrients from plant matter back to soil, the heat from fire is necessary to the germination of certain types of seeds, and the snags (dead trees) and early successional forests created by high-severity fire create habitat conditions that are beneficial to wildlife. Early successional forests created by high-severity fire support some of the highest levels of native biodiversity found in temperate conifer forests. Post-fire logging has no ecological benefits and many negative impacts; the same is often true for post-fire seeding.\n\nAlthough some ecosystems rely on naturally occurring fires to regulate growth, some ecosystems suffer from too much fire, such as the chaparral in southern California and lower-elevation deserts in the American Southwest. The increased fire frequency in these ordinarily fire-dependent areas has upset natural cycles, damaged native plant communities, and encouraged the growth of non-native weeds. Invasive species, such as \"Lygodium microphyllum\" and \"Bromus tectorum\", can grow rapidly in areas that were damaged by fires. Because they are highly flammable, they can increase the future risk of fire, creating a positive feedback loop that increases fire frequency and further alters native vegetation communities.\n\nIn the Amazon Rainforest, drought, logging, cattle ranching practices, and slash-and-burn agriculture damage fire-resistant forests and promote the growth of flammable brush, creating a cycle that encourages more burning. Fires in the rainforest threaten its collection of diverse species and produce large amounts of CO. Also, fires in the rainforest, along with drought and human involvement, could damage or destroy more than half of the Amazon rainforest by the year 2030. Wildfires generate ash, reduce the availability of organic nutrients, and cause an increase in water runoff, eroding away other nutrients and creating flash flood conditions. A 2003 wildfire in the North Yorkshire Moors burned off of heather and the underlying peat layers. Afterwards, wind erosion stripped the ash and the exposed soil, revealing archaeological remains dating back to 10,000 BC. Wildfires can also have an effect on climate change, increasing the amount of carbon released into the atmosphere and inhibiting vegetation growth, which affects overall carbon uptake by plants.\n\nIn tundra there is a natural pattern of accumulation of fuel and wildfire which varies depending on the nature of vegetation and terrain. Research in Alaska has shown fire-event return intervals, (FRIs) that typically vary from 150 to 200 years with dryer lowland areas burning more frequently than wetter upland areas.\n\nPlants in wildfire-prone ecosystems often survive through adaptations to their local fire regime. Such adaptations include physical protection against heat, increased growth after a fire event, and flammable materials that encourage fire and may eliminate competition. For example, plants of the genus \"Eucalyptus\" contain flammable oils that encourage fire and hard sclerophyll leaves to resist heat and drought, ensuring their dominance over less fire-tolerant species. Dense bark, shedding lower branches, and high water content in external structures may also protect trees from rising temperatures. Fire-resistant seeds and reserve shoots that sprout after a fire encourage species preservation, as embodied by pioneer species. Smoke, charred wood, and heat can stimulate the germination of seeds in a process called \"serotiny\". Exposure to smoke from burning plants promotes germination in other types of plants by inducing the production of the orange butenolide.\n\nGrasslands in Western Sabah, Malaysian pine forests, and Indonesian \"Casuarina\" forests are believed to have resulted from previous periods of fire. Chamise deadwood litter is low in water content and flammable, and the shrub quickly sprouts after a fire. Cape lilies lie dormant until flames brush away the covering and then blossom almost overnight. Sequoia rely on periodic fires to reduce competition, release seeds from their cones, and clear the soil and canopy for new growth. Caribbean Pine in Bahamian pineyards have adapted to and rely on low-intensity, surface fires for survival and growth. An optimum fire frequency for growth is every 3 to 10 years. Too frequent fires favor herbaceous plants, and infrequent fires favor species typical of Bahamian dry forests.\n\nMost of the Earth's weather and air pollution resides in the troposphere, the part of the atmosphere that extends from the surface of the planet to a height of about . The vertical lift of a severe thunderstorm or pyrocumulonimbus can be enhanced in the area of a large wildfire, which can propel smoke, soot, and other particulate matter as high as the lower stratosphere. Previously, prevailing scientific theory held that most particles in the stratosphere came from volcanoes, but smoke and other wildfire emissions have been detected from the lower stratosphere. Pyrocumulus clouds can reach over wildfires. Satellite observation of smoke plumes from wildfires revealed that the plumes could be traced intact for distances exceeding . Computer-aided models such as CALPUFF may help predict the size and direction of wildfire-generated smoke plumes by using atmospheric dispersion modeling.\n\nWildfires can affect local atmospheric pollution, and release carbon in the form of carbon dioxide. Wildfire emissions contain fine particulate matter which can cause cardiovascular and respiratory problems. Increased fire byproducts in the troposphere can increase ozone concentration beyond safe levels. Forest fires in Indonesia in 1997 were estimated to have released between 0.81 and 2.57 gigatonnes (0.89 and 2.83 billion short tons) of CO into the atmosphere, which is between 13%–40% of the annual global carbon dioxide emissions from burning fossil fuels. Atmospheric models suggest that these concentrations of sooty particles could increase absorption of incoming solar radiation during winter months by as much as 15%.\n\nIn the Welsh Borders, the first evidence of wildfire is rhyniophytoid plant fossils preserved as charcoal, dating to the Silurian period (about ). Smoldering surface fires started to occur sometime before the Early Devonian period . Low atmospheric oxygen during the Middle and Late Devonian was accompanied by a decrease in charcoal abundance. Additional charcoal evidence suggests that fires continued through the Carboniferous period. Later, the overall increase of atmospheric oxygen from 13% in the Late Devonian to 30-31% by the Late Permian was accompanied by a more widespread distribution of wildfires. Later, a decrease in wildfire-related charcoal deposits from the late Permian to the Triassic periods is explained by a decrease in oxygen levels.\n\nWildfires during the Paleozoic and Mesozoic periods followed patterns similar to fires that occur in modern times. Surface fires driven by dry seasons are evident in Devonian and Carboniferous progymnosperm forests. Lepidodendron forests dating to the Carboniferous period have charred peaks, evidence of crown fires. In Jurassic gymnosperm forests, there is evidence of high frequency, light surface fires. The increase of fire activity in the late Tertiary is possibly due to the increase of C-type grasses. As these grasses shifted to more mesic habitats, their high flammability increased fire frequency, promoting grasslands over woodlands. However, fire-prone habitats may have contributed to the prominence of trees such as those of the genera \"Eucalyptus\", \"Pinus\" and \"Sequoia\", which have thick bark to withstand fires and employ serotiny.\n\nThe human use of fire for agricultural and hunting purposes during the Paleolithic and Mesolithic ages altered the preexisting landscapes and fire regimes. Woodlands were gradually replaced by smaller vegetation that facilitated travel, hunting, seed-gathering and planting. In recorded human history, minor allusions to wildfires were mentioned in the Bible and by classical writers such as Homer. However, while ancient Hebrew, Greek, and Roman writers were aware of fires, they were not very interested in the uncultivated lands where wildfires occurred. Wildfires were used in battles throughout human history as early thermal weapons. From the Middle ages, accounts were written of occupational burning as well as customs and laws that governed the use of fire. In Germany, regular burning was documented in 1290 in the Odenwald and in 1344 in the Black Forest. In the 14th century Sardinia, firebreaks were used for wildfire protection. In Spain during the 1550s, sheep husbandry was discouraged in certain provinces by Philip II due to the harmful effects of fires used in transhumance. As early as the 17th century, Native Americans were observed using fire for many purposes including cultivation, signaling, and warfare. Scottish botanist David Douglas noted the native use of fire for tobacco cultivation, to encourage deer into smaller areas for hunting purposes, and to improve foraging for honey and grasshoppers. Charcoal found in sedimentary deposits off the Pacific coast of Central America suggests that more burning occurred in the 50 years before the Spanish colonization of the Americas than after the colonization. In the post-World War II Baltic region, socio-economic changes led more stringent air quality standards and bans on fires that eliminated traditional burning practices. In the mid-19th century, explorers from observed Australian Aborigines using fire for ground clearing, hunting, and regeneration of plant food in a method later named fire-stick farming. Such careful use of fire has been employed for centuries in the lands protected by Kakadu National Park to encourage biodiversity.\n\nWildfires typically occurred during periods of increased temperature and drought. An increase in fire-related debris flow in alluvial fans of northeastern Yellowstone National Park was linked to the period between AD 1050 and 1200, coinciding with the Medieval Warm Period. However, human influence caused an increase in fire frequency. Dendrochronological fire scar data and charcoal layer data in Finland suggests that, while many fires occurred during severe drought conditions, an increase in the number of fires during 850 BC and 1660 AD can be attributed to human influence. Charcoal evidence from the Americas suggested a general decrease in wildfires between 1 AD and 1750 compared to previous years. However, a period of increased fire frequency between 1750 and 1870 was suggested by charcoal data from North America and Asia, attributed to human population growth and influences such as land clearing practices. This period was followed by an overall decrease in burning in the 20th century, linked to the expansion of agriculture, increased livestock grazing, and fire prevention efforts. A meta-analysis found that 17 times more land burned annually in California before 1800 compared to recent decades (1,800,000 hectares/year compared to 102,000 hectares/year).\n\nAccording to a paper published in Science, the number of natural and human-caused fires decreased by 24.3% between 1998 and 2015. Researchers explain this a transition from nomadism to settled lifestyle and intensification of agriculture that lead to a drop in the use of fire for land clearing.\n\nIncreases of certain native tree species (i.e. conifers) in favor of others (i.e. leaf trees) also increases wildfire risk, especially if these trees are also planted in monocultures\n\nSome invasive species, moved in by humans (i.e., for the pulp and paper industry) have in some cases also increased the intensity of wildfires. Examples include species such as Eucalyptus in California and gamba grass in Australia.\n\nWildfire prevention refers to the preemptive methods aimed at reducing the risk of fires as well as lessening its severity and spread. Prevention techniques aim to manage air quality, maintain ecological balances, protect resources, and to affect future fires. North American firefighting policies permit naturally caused fires to burn to maintain their ecological role, so long as the risks of escape into high-value areas are mitigated. However, prevention policies must consider the role that humans play in wildfires, since, for example, 95% of forest fires in Europe are related to human involvement. Sources of human-caused fire may include arson, accidental ignition, or the uncontrolled use of fire in land-clearing and agriculture such as the slash-and-burn farming in Southeast Asia.\n\nIn 1937, U.S. President Franklin D. Roosevelt initiated a nationwide fire prevention campaign, highlighting the role of human carelessness in forest fires. Later posters of the program featured Uncle Sam, characters from the Disney movie \"Bambi\", and the official mascot of the U.S. Forest Service, Smokey Bear. Reducing human-caused ignitions may be the most effective means of reducing unwanted wildfire. Alteration of fuels is commonly undertaken when attempting to affect future fire risk and behavior. Wildfire prevention programs around the world may employ techniques such as \"wildland fire use\" and \"prescribed or controlled burns\". \"Wildland fire use\" refers to any fire of natural causes that is monitored but allowed to burn. \"Controlled burns\" are fires ignited by government agencies under less dangerous weather conditions.\n\nVegetation may be burned periodically to maintain high species diversity and frequent burning of surface fuels limits fuel accumulation. Wildland fire use is the cheapest and most ecologically appropriate policy for many forests. Fuels may also be removed by logging, but fuels treatments and thinning have no effect on severe fire behavior Wildfire models are often used to predict and compare the benefits of different fuel treatments on future wildfire spread, but their accuracy is low.\n\nWildfire itself is reportedly \"the most effective treatment for reducing a fire's rate of spread, fireline intensity, flame length, and heat per unit of area\" according to Jan van Wagtendonk, a biologist at the Yellowstone Field Station.\n\nBuilding codes in fire-prone areas typically require that structures be built of flame-resistant materials and a defensible space be maintained by clearing flammable materials within a prescribed distance from the structure. Communities in the Philippines also maintain fire lines wide between the forest and their village, and patrol these lines during summer months or seasons of dry weather. Continued residential development in fire-prone areas and rebuilding structures destroyed by fires has been met with criticism. The ecological benefits of fire are often overridden by the economic and safety benefits of protecting structures and human life.\n\nFast and effective detection is a key factor in wildfire fighting. Early detection efforts were focused on early response, accurate results in both daytime and nighttime, and the ability to prioritize fire danger. Fire lookout towers were used in the United States in the early 20th century and fires were reported using telephones, carrier pigeons, and heliographs. Aerial and land photography using instant cameras were used in the 1950s until infrared scanning was developed for fire detection in the 1960s. However, information analysis and delivery was often delayed by limitations in communication technology. Early satellite-derived fire analyses were hand-drawn on maps at a remote site and sent via overnight mail to the fire manager. During the Yellowstone fires of 1988, a data station was established in West Yellowstone, permitting the delivery of satellite-based fire information in approximately four hours.\n\nCurrently, public hotlines, fire lookouts in towers, and ground and aerial patrols can be used as a means of early detection of forest fires. However, accurate human observation may be limited by operator fatigue, time of day, time of year, and geographic location. Electronic systems have gained popularity in recent years as a possible resolution to human operator error. A government report on a recent trial of three automated camera fire detection systems in Australia did, however, conclude \"...detection by the camera systems was slower and less reliable than by a trained human observer\". These systems may be semi- or fully automated and employ systems based on the risk area and degree of human presence, as suggested by GIS data analyses. An integrated approach of multiple systems can be used to merge satellite data, aerial imagery, and personnel position via Global Positioning System (GPS) into a collective whole for near-realtime use by wireless Incident Command Centers.\n\nA small, high risk area that features thick vegetation, a strong human presence, or is close to a critical urban area can be monitored using a local sensor network. Detection systems may include wireless sensor networks that act as automated weather systems: detecting temperature, humidity, and smoke. These may be battery-powered, solar-powered, or \"tree-rechargeable\": able to recharge their battery systems using the small electrical currents in plant material. Larger, medium-risk areas can be monitored by scanning towers that incorporate fixed cameras and sensors to detect smoke or additional factors such as the infrared signature of carbon dioxide produced by fires. Additional capabilities such as night vision, brightness detection, and color change detection may also be incorporated into sensor arrays.\n\nSatellite and aerial monitoring through the use of planes, helicopter, or UAVs can provide a wider view and may be sufficient to monitor very large, low risk areas. These more sophisticated systems employ GPS and aircraft-mounted infrared or high-resolution visible cameras to identify and target wildfires. Satellite-mounted sensors such as Envisat's Advanced Along Track Scanning Radiometer and European Remote-Sensing Satellite's Along-Track Scanning Radiometer can measure infrared radiation emitted by fires, identifying hot spots greater than . The National Oceanic and Atmospheric Administration's Hazard Mapping System combines remote-sensing data from satellite sources such as Geostationary Operational Environmental Satellite (GOES), Moderate-Resolution Imaging Spectroradiometer (MODIS), and Advanced Very High Resolution Radiometer (AVHRR) for detection of fire and smoke plume locations. However, satellite detection is prone to offset errors, anywhere from for MODIS and AVHRR data and up to for GOES data. Satellites in geostationary orbits may become disabled, and satellites in polar orbits are often limited by their short window of observation time. Cloud cover and image resolution and may also limit the effectiveness of satellite imagery.\n\nin 2015 a new fire detection tool is in operation at the U.S. Department of Agriculture (USDA) Forest Service (USFS) which uses data from the Suomi National Polar-orbiting Partnership (NPP) satellite to detect smaller fires in more detail than previous space-based products. The high-resolution data is used with a computer model to predict how a fire will change direction based on weather and land conditions. The active fire detection product using data from Suomi NPP's Visible Infrared Imaging Radiometer Suite (VIIRS) increases the resolution of fire observations to 1,230 feet (375 meters). Previous NASA satellite data products available since the early 2000s observed fires at 3,280 foot (1 kilometer) resolution. The data is one of the intelligence tools used by the USFS and Department of Interior agencies across the United States to guide resource allocation and strategic fire management decisions. The enhanced VIIRS fire product enables detection every 12 hours or less of much smaller fires and provides more detail and consistent tracking of fire lines during long duration wildfires – capabilities critical for early warning systems and support of routine mapping of fire progression. Active fire locations are available to users within minutes from the satellite overpass through data processing facilities at the USFS Remote Sensing Applications Center, which uses technologies developed by the NASA Goddard Space Flight Center Direct Readout Laboratory in Greenbelt, Maryland. The model uses data on weather conditions and the land surrounding an active fire to predict 12–18 hours in advance whether a blaze will shift direction. The state of Colorado decided to incorporate the weather-fire model in its firefighting efforts beginning with the 2016 fire season.\n\nIn 2014, an international campaign was organized in South Africa's Kruger National Park to validate fire detection products including the new VIIRS active fire data. In advance of that campaign, the Meraka Institute of the Council for Scientific and Industrial Research in Pretoria, South Africa, an early adopter of the VIIRS 375m fire product, put it to use during several large wildfires in Kruger.\n\nThe demand for timely, high-quality fire information has increased in recent years. Wildfires in the United States burn an average of 7 million acres of land each year. For the last 10 years, the USFS and Department of Interior have spent a combined average of about $2–4 billion annually on wildfire suppression.\n\nWildfire suppression depends on the technologies available in the area in which the wildfire occurs. In less developed nations the techniques used can be as simple as throwing sand or beating the fire with sticks or palm fronds. In more advanced nations, the suppression methods vary due to increased technological capacity. Silver iodide can be used to encourage snow fall, while fire retardants and water can be dropped onto fires by unmanned aerial vehicles, planes, and helicopters. Complete fire suppression is no longer an expectation, but the majority of wildfires are often extinguished before they grow out of control. While more than 99% of the 10,000 new wildfires each year are contained, escaped wildfires under extreme weather conditions are difficult to suppress without a change in the weather. Wildfires in Canada and the US burn an average of per year.\n\nAbove all, fighting wildfires can become deadly. A wildfire's burning front may also change direction unexpectedly and jump across fire breaks. Intense heat and smoke can lead to disorientation and loss of appreciation of the direction of the fire, which can make fires particularly dangerous. For example, during the 1949 Mann Gulch fire in Montana, USA, thirteen smokejumpers died when they lost their communication links, became disoriented, and were overtaken by the fire. In the Australian February 2009 Victorian bushfires, at least 173 people died and over 2,029 homes and 3,500 structures were lost when they became engulfed by wildfire.\n\nIn California, the U.S. Forest Service spends about $200 million per year to suppress 98% of wildfires and up to $1 billion to suppress the other 2% of fires that escape initial attack and become large.\n\nWildland fire fighters face several life-threatening hazards including heat stress, fatigue, smoke and dust, as well as the risk of other injuries such as burns, cuts and scrapes, animal bites, and even rhabdomyolysis. Between 2000–2016, more than 350 wildland firefighters died on-duty.\n\nEspecially in hot weather condition, fires present the risk of heat stress, which can entail feeling heat, fatigue, weakness, vertigo, headache, or nausea. Heat stress can progress into heat strain, which entails physiological changes such as increased heart rate and core body temperature. This can lead to heat-related illnesses, such as heat rash, cramps, exhaustion or heat stroke. Various factors can contribute to the risks posed by heat stress, including strenuous work, personal risk factors such as age and fitness, dehydration, sleep deprivation, and burdensome personal protective equipment. Rest, cool water, and occasional breaks are crucial to mitigating the effects of heat stress.\n\nSmoke, ash, and debris can also pose serious respiratory hazards to wildland fire fighters. The smoke and dust from wildfires can contain gases such as carbon monoxide, sulfur dioxide and formaldehyde, as well as particulates such as ash and silica. To reduce smoke exposure, wildfire fighting crews should, whenever possible, rotate firefighters through areas of heavy smoke, avoid downwind firefighting, use equipment rather than people in holding areas, and minimize mop-up. Camps and command posts should also be located upwind of wildfires. Protective clothing and equipment can also help minimize exposure to smoke and ash.\n\nFirefighters are also at risk of cardiac events including strokes and heart attacks. Fire fighters should maintain good physical fitness. Fitness programs, medical screening and examination programs which include stress tests can minimize the risks of firefighting cardiac problems. Other injury hazards wildland fire fighters face include slips, trips and falls, burns, scrapes and cuts from tools and equipment, being struck by trees, vehicles, or other objects, plant hazards such as thorns and poison ivy, snake and animal bites, vehicle crashes, electrocution from power lines or lightning storms, and unstable building structures.\n\nFire retardants are used to slow wildfires by inhibiting combustion. They are aqueous solutions of ammonium phosphates and ammonium sulfates, as well as thickening agents. The decision to apply retardant depends on the magnitude, location and intensity of the wildfire. In certain instances, fire retardant may also be applied as a precautionary fire defense measure.\n\nTypical fire retardants contain the same agents as fertilizers. Fire retardant may also affect water quality through leaching, eutrophication, or misapplication. Fire retardant's effects on drinking water remain inconclusive. Dilution factors, including water body size, rainfall, and water flow rates lessen the concentration and potency of fire retardant. Wildfire debris (ash and sediment) clog rivers and reservoirs increasing the risk for floods and erosion that ultimately slow and/or damage water treatment systems. There is continued concern of fire retardant effects on land, water, wildlife habitats, and watershed quality, additional research is needed. However, on the positive side, fire retardant (specifically its nitrogen and phosphorus components) has been shown to have a fertilizing effect on nutrient-deprived soils and thus creates a temporary increase in vegetation.\n\nCurrent USDA procedure maintains that the aerial application of fire retardant in the United States must clear waterways by a minimum of 300 feet in order to safeguard effects of retardant runoff. Aerial uses of fire retardant are required to avoid application near waterways and endangered species (plant and animal habitats). After any incident of fire retardant misapplication, the U.S. Forest Service requires reporting and assessment impacts be made in order to determine mitigation, remediation, and/or restrictions on future retardant uses in that area.\n\nWildfire modeling is concerned with numerical simulation of wildfires in order to comprehend and predict fire behavior. Wildfire modeling aims to aid wildfire suppression, increase the safety of firefighters and the public, and minimize damage. Using computational science, wildfire modeling involves the statistical analysis of past fire events to predict spotting risks and front behavior. Various wildfire propagation models have been proposed in the past, including simple ellipses and egg- and fan-shaped models. Early attempts to determine wildfire behavior assumed terrain and vegetation uniformity. However, the exact behavior of a wildfire's front is dependent on a variety of factors, including windspeed and slope steepness. Modern growth models utilize a combination of past ellipsoidal descriptions and Huygens' Principle to simulate fire growth as a continuously expanding polygon. Extreme value theory may also be used to predict the size of large wildfires. However, large fires that exceed suppression capabilities are often regarded as statistical outliers in standard analyses, even though fire policies are more influenced by large wildfires than by small fires.\n\nWildfire risk is the chance that a wildfire will start in or reach a particular area and the potential loss of human values if it does. Risk is dependent on variable factors such as human activities, weather patterns, availability of wildfire fuels, and the availability or lack of resources to suppress a fire. Wildfires have continually been a threat to human populations. However, human induced geographical and climatic changes are exposing populations more frequently to wildfires and increasing wildfire risk. It is speculated that the increase in wildfires arises from a century of wildfire suppression coupled with the rapid expansion of human developments into fire-prone wildlands. Wildfires are naturally occurring events that aid in promoting forest health. Global warming and climate changes are causing an increase in temperatures and more droughts nationwide which contributes to an increase in wildfire risk.\n\nThe most noticeable adverse effect of wildfires is the destruction of property. However, the release of hazardous chemicals from the burning of wildland fuels also significantly impacts health in humans.\n\nWildfire smoke is composed primarily of carbon dioxide and water vapor. Other common smoke components present in lower concentrations are carbon monoxide, formaldehyde, acrolein, polyaromatic hydrocarbons, and benzene. Small particulates suspended in air which come in solid form or in liquid droplets are also present in smoke. 80 -90% of wildfire smoke, by mass, is within the fine particle size class of 2.5 micrometers in diameter or smaller.\n\nDespite carbon dioxide's high concentration in smoke, it poses a low health risk due to its low toxicity. Rather, carbon monoxide and fine particulate matter, particularly 2.5 µm in diameter and smaller, have been identified as the major health threats. Other chemicals are considered to be significant hazards but are found in concentrations that are too low to cause detectable health effects.\n\nThe degree of wildfire smoke exposure to an individual is dependent on the length, severity, duration, and proximity of the fire. People are exposed directly to smoke via the respiratory tract though inhalation of air pollutants. Indirectly, communities are exposed to wildfire debris that can contaminate soil and water supplies.\n\nThe U.S. Environmental Protection Agency (EPA) developed the Air Quality Index (AQI), a public resource that provides national air quality standard concentrations for common air pollutants. The public can use this index as a tool to determine their exposure to hazardous air pollutants based on visibility range.\n\nAfter a wildfire, hazards remain. Residents returning to their homes may be at risk from falling fire-weakened trees. Humans and pets may also be harmed by falling into ash pits.\n\nFirefighters are at the greatest risk for acute and chronic health effects resulting from wildfire smoke exposure. Due to firefighters' occupational duties, they are frequently exposed to hazardous chemicals at a close proximity for longer periods of time. A case study on the exposure of wildfire smoke among wildland firefighters shows that firefighters are exposed to significant levels of carbon monoxide and respiratory irritants above OSHA-permissible exposure limits (PEL) and ACGIH threshold limit values (TLV). 5–10% are overexposed. The study obtained exposure concentrations for one wildland firefighter over a 10-hour shift spent holding down a fireline. The firefighter was exposed to a wide range of carbon monoxide and respiratory irritant (combination of particulate matter 3.5 µm and smaller, acrolein, and formaldehype) levels. Carbon monoxide levels reached up to 160ppm and the TLV irritant index value reached a high of 10. In contrast, the OSHA PEL for carbon monoxide is 30ppm and for the TLV respiratory irritant index, the calculated threshold limit value is 1; any value above 1 exceeds exposure limits.\n\nBetween 2001 and 2012, over 200 fatalities occurred among wildland firefighters. In addition to heat and chemical hazards, firefighters are also at risk for electrocution from power lines; injuries from equipment; slips, trips, and falls; injuries from vehicle rollovers; heat-related illness; insect bites and stings; stress; and rhabdomyolysis.\n\nResidents in communities surrounding wildfires are exposed to lower concentrations of chemicals, but they are at a greater risk for indirect exposure through water or soil contamination. Exposure to residents is greatly dependent on individual susceptibility. Vulnerable persons such as children (ages 0–4), the elderly (ages 65 and older), smokers, and pregnant women are at an increased risk due to their already compromised body systems, even when the exposures are present at low chemical concentrations and for relatively short exposure periods.\n\nAdditionally, there is evidence of an increase in maternal stress, as documented by researchers M.H. O'Donnell and A.M. Behie, thus affecting birth outcomes. In Australia, studies show that male infants born with drastically higher average birth weights were born in mostly severely fire-affected areas. This is attributed to the fact that maternal signals directly affect fetal growth patterns.\n\nAsthma is one of the most common chronic disease among children in the United States affecting estimated 6.2 million children. A recent area of research on asthma risk focuses specifically on the risk of air pollution during the gestational period. Several pathophysiology processes are involved are in this. In human's considerable airway development occurs during the 2 and 3 trimester and continue until 3 years of age. It is hypothesized that exposure to these toxins during this period could have consequential effects as the epithelium of the lungs during this time could have increased permeability to toxins. Exposure to air pollution during parental and pre-natal stage could induce epigenetic changes which are responsible for the development of asthma. Recent Meta-Analyses have found significant association between PM, NO and development of asthma during childhood despite heterogeneity among studies. Furthermore, maternal exposure to chronic stressor, which are most like to be present in distressed communities, which is also a relevant co relate of childhood asthma which may further help explain the early childhood exposure to air pollution, neighborhood poverty and childhood risk. Living in distressed neighborhood is not only linked to pollutant source location and exposure but can also be associated with degree of magnitude of chronic individual stress which can in turn alter the allostatic load of the maternal immune system leading to adverse outcomes in children, including increased susceptibility to air pollution and other hazards.\n\nWildfire smoke contains particulate matter that may have adverse effects upon the human respiratory system. Evidence of the health effects of wildfire smoke should be relayed to the public so that exposure may be limited. Evidence of health effects can also be used to influence policy to promote positive health outcomes.\n\nInhalation of smoke from a wildfire can be a health hazard. Wildfire smoke is composed of combustion products i.e. carbon dioxide, carbon monoxide, water vapor, particulate matter, organic chemicals, nitrogen oxides and other compounds. The principal health concern is the inhalation of particulate matter and carbon monoxide.\n\nParticulate matter (PM) is a type of air pollution made up of particles of dust and liquid droplets. They are characterized into three categories based on the diameter of the particle: coarse PM, fine PM, and ultrafine PM. Coarse particles are between 2.5 micrometers and 10 micrometers, fine particles measure 0.1 to 2.5 micrometers, and ultrafine particle are less than 0.1 micrometer.  Each size can enter the body through inhalation, but the PM impact on the body varies by size. Coarse particles are filtered by the upper airways and these particles can accumulate and cause pulmonary inflammation. This can result in eye and sinus irritation as well as sore throat and coughing. Coarse PM is often composed of materials that are heavier and more toxic that lead to short-term effects with stronger impact.\n\nSmaller particulate moves further into the respiratory system creating issues deep into the lungs and the bloodstream. In asthma patients, PM causes inflammation but also increases oxidative stress in the epithelial cells. These particulates also cause apoptosis and autophagy in lung epithelial cells. Both processes cause the cells to be damaged and impacts the cell function. This damage impacts those with respiratory conditions such as asthma where the lung tissues and function are already compromised. The third PM type is ultra-fine PM (UFP). UFP can enter the bloodstream like PM however studies show that it works into the blood much quicker. The inflammation and epithelial damage done by UFP has also shown to be much more severe. PM is of the largest concern in regards to wildfire. This is particularly hazardous to the very young, elderly and those with chronic conditions such as asthma, chronic obstructive pulmonary disease (COPD), cystic fibrosis and cardiovascular conditions. The illnesses most commonly with exposure to fine particle from wildfire smoke are bronchitis, exacerbation of asthma or COPD, and pneumonia. Symptoms of these complications include wheezing and shortness of breath and cardiovascular symptoms include chest pain, rapid heart rate and fatigue.\n\nSmoke from wildfires can cause health problems, especially for children and those who already have respiratory problems. Several epidemiological studies have demonstrated a close association between air pollution and respiratory allergic diseases such as bronchial asthma. \n\nAn observational study of smoke exposure related to the 2007 San Diego wildfires revealed an increase both in healthcare utilization and respiratory diagnoses, especially asthma among the group sampled. Projected climate scenarios of wildfire occurrences predict significant increases in respiratory conditions among young children. Particulate Matter (PM) triggers a series of biological processes including inflammatory immune response, oxidative stress, which are associated with harmful changes in allergic respiratory diseases.\n\nAlthough some studies demonstrated no significant acute changes in lung function among people with asthma related to PM from wildfires, a possible explanation for these counterintuitive findings is the increased use of quick-relief medications, such as inhalers, in response to elevated levels of smoke among those already diagnosed with asthma. In investigating the association of medication use for obstructive lung disease and wildfire exposure, researchers found increases both in the usage of inhalers and initiation of long-term control as in oral steroids. More specifically, some people with asthma reported higher use of quick-relief medications (inhalers). After two major wildfires in California, researchers found an increase in physician prescriptions for quick-relief medications in the years following the wildfires than compared to the year before each occurrence. \n\nThere is consistent evidence between wildfire smoke and the exacerbation of asthma.\n\nCarbon monoxide (CO) is a colorless, odorless gas that can be found at the highest concentration at close proximity to a smoldering fire. For this reason, carbon monoxide inhalation is a serious threat to the health of wildfire firefighters. CO in smoke can be inhaled into the lungs where it is absorbed into the bloodstream and reduces oxygen delivery to the body's vital organs. At high concentrations, it can cause headache, weakness, dizziness, confusion, nausea, disorientation, visual impairment, coma and even death. However, even at lower concentrations, such as those found at wildfires, individuals with cardiovascular disease may experience chest pain and cardiac arrhythmia. A recent study tracking the number and cause of wildfire firefighter deaths from 1990–2006 found that 21.9% of the deaths occurred from heart attacks.\n\nAnother important and somewhat less obvious health effect of wildfires is psychiatric diseases and disorders. Both adults and children from countries ranging from the United States and Canada to Greece and Australia who were directly and indirectly affected by wildfires were found by researchers to demonstrate several different mental conditions linked to their experience with the wildfires. These include post-traumatic stress disorder (PTSD), depression, anxiety, and phobias.\n\nIn a new twist to wildfire health effects, former uranium mining sites were burned over in the summer of 2012 near North Fork, Idaho. This prompted concern from area residents and Idaho State Department of Environmental Quality officials over the potential spread of radiation in the resultant smoke, since those sites had never been completely cleaned up from radioactive remains.\n\nThe western US has seen an increase in both frequency and intensity of wildfires over the last several decades. This increase has been attributed to the arid climate of the western US and the effects of global warming. An estimated 46 million people were exposed to wildfire smoke from 2004 to 2009 in the Western United States. Evidence has demonstrated that wildfire smoke can increase levels of particulate matter in the atmosphere.\n\nThe EPA has defined acceptable concentrations of particulate matter in the air, through the National Ambient Air Quality Standards and monitoring of ambient air quality has been mandated. Due to these monitoring programs and the incidence of several large wildfires near populated areas, epidemiological studies have been conducted and demonstrate an association between human health effects and an increase in fine particulate matter due to wildfire smoke.\n\nThe EPA has defined acceptable concentrations of particulate matter in the air. The National Ambient Air Quality Standards are part of the Clean Air Act and provide mandated guidelines for pollutant levels and the monitoring of ambient air quality. In addition to these monitoring programs, the increased incidence of wildfires near populated areas have precipitated several epidemiological studies. Such studies have demonstrated an association between negative human health effects and an increase in fine particulate matter due to wildfire smoke. The size of the particulate matter is significant as smaller particulate matter (fine) is easily inhaled into the human respiratory tract. Often, small particulate matter can be inhaled into deep lung tissue causing respiratory distress, illness, or disease. \n\nAn increase in PM smoke emitted from the Hayman fire in Colorado in June 2002, was associated with an increase in respiratory symptoms in patients with COPD. Looking at the wildfires in Southern California in October 2003 in a similar manner, investigators have shown an increase in hospital admissions due to asthma symptoms while being exposed to peak concentrations of PM in smoke. Another epidemiological study found a 7.2% (95% confidence interval: 0.25%, 15%) increase in risk of respiratory related hospital admissions during smoke wave days with high wildfire-specific particulate matter 2.5 compared to matched non-smoke-wave days.\n\nChildren participating in the Children's Health Study were also found to have an increase in eye and respiratory symptoms, medication use and physician visits. Recently, it was demonstrated that mothers who were pregnant during the fires gave birth to babies with a slightly reduced average birth weight compared to those who were not exposed to wildfire during birth. Suggesting that pregnant women may also be at greater risk to adverse effects from wildfire. Worldwide it is estimated that 339,000 people die due to the effects of wildfire smoke each year.\n\nWhile the size of particulate matter is an important consideration for health effects, the chemical composition of particulate matter (PM) from wildfire smoke should also be considered. Antecedent studies have demonstrated that the chemical composition of PM from wildfire smoke can yield different estimates of human health outcomes as compared to other sources of smoke. Health outcomes for people exposed to wildfire smoke may differ from those exposed to smoke from alternative sources such as solid fuels. \n\n"}
{"id": "37276405", "url": "https://en.wikipedia.org/wiki?curid=37276405", "title": "Zeuxo (Greek mythology)", "text": "Zeuxo (Greek mythology)\n\nIn Greek mythology Zeuxo (; Ζευξώ) was an Oceanid. Her name appears in Hesiod's catalogue of Oceanid names; no other literary mention of her survives.\n\n"}
{"id": "186814", "url": "https://en.wikipedia.org/wiki?curid=186814", "title": "Zond 6", "text": "Zond 6\n\nZond 6, a formal member of the Soviet Zond program and unmanned version of Soyuz 7K-L1 manned moon-flyby spacecraft, was launched on a lunar flyby mission from a parent satellite (68-101B) in Earth parking orbit. The spacecraft, which carried scientific probes including cosmic ray and micrometeoroid detectors, photography equipment, and a biological payload, was a precursor to a manned circumlunar flight which the Soviets hoped could occur in December 1968, beating the American \"Apollo 8\". However, after orbiting the Moon Zond 6 crashed on its return to Earth due to a parachute failure.\n\nZond 6 was the official designation for Soyuz 7K-L1 s/n 12. It was supposed to photograph the Moon in colour and in black and white from 8000 km and 2600 km ranges, then return to Earth, landing at Tyuratam only 16 km from the launch pad. It had been a long and difficult road to develop the L1 guidance system, but it worked perfectly that time.\n\nZond 6 flew around the Moon on 14 November 1968, at a minimum distance of 2420 km. Photographs of the lunar near side and far side were obtained with panchromatic film. Each photo was . Some of the views allowed for stereo pictures. The photos were taken from distances of approximately 11,000 km and 3300 km. However, only one negative was recovered from the camera container.\n\nZond 6 used a relatively uncommon technique called \"skip reentry\" to shed velocity upon returning to Earth. A few hours before reentry, on 17 November 1968, a faulty O-ring rubber gasket caused the cabin to depressurise, killing all the animal test subjects aboard. Zond 6's parachutes also deployed too early and it crashed in Kazakhstan, near the designated landing area.\n\nFor propaganda reasons the Soviets claimed the flight was a success. A State Commission investigating the crash later determined that the coronal discharge effect which caused the parachute to jettison would only occur at the 25 mm capsule pressure. If the capsule had been completely depressurised to a high vacuum, the accident would not have occurred.\n\n\n\n\n\"This article was originally based on material from NASA (NSSDC) information on Zond 6\"\n"}
