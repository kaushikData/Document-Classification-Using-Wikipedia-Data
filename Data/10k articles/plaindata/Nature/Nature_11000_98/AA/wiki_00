{"id": "58017495", "url": "https://en.wikipedia.org/wiki?curid=58017495", "title": "1969 Cincinnati tornado", "text": "1969 Cincinnati tornado\n\nThe 1969 Cincinnati tornado was a powerful, devastating and deadly tornado that struck Cincinnati, Ohio on Saturday, August 9, 1969, at 5:57pm. The tornado was a F3 or F4 on the Fujita scale. (Most records show its official rating as F3, but some have as an F4 and its possible it may have caused F4 damage.)\n\nIn the late afternoon hours of Saturday, August 9, the tornado formed in the Cincinnati suburb of Wyoming, 8 miles north-northeast of downtown Cincinnati. Moving east–southeast at 40–50mph, it traveled through the city's suburban neighborhoods of Hartwell and Roselawn, and the several of its northeastern suburbs, including Reading, Arlington Heights, Golf Manor, and Madeira. It carved a path through Hamilton and Clermont counties that was 22 miles long and up to 400 yards wide. It hit the communities of Milford and Perintown before finally dissipating north of Williamsburg.\n\nAll the death were in Hamilton County, including three members of one family. In Madeira, 30 people were injured when a tent they were in at a church event collapsed on top of them. The most severe damage, all of the deaths, and the majority of injuries, occurred in the area between Hartwell and Golf Manor.\n\nDespite it being among the most significant killer tornadoes in the Cincinnati area, it is considered by some to be one of \"Cincinnati's Forgotten Tornadoes\" due to several other events in the U.S. in August 1969, including the Manson murders (which occurred early that morning) and Hurricane Camille. In addition, the area was hit by seven significant tornadoes in 1974, 1999 and 2012, including an F4 and an F5 in 1974 and an F4 in 1999.\n\n"}
{"id": "42433033", "url": "https://en.wikipedia.org/wiki?curid=42433033", "title": "Arcadian ecology", "text": "Arcadian ecology\n\nArcadian ecology is a school of thought that advocates for a harmonious relationship between humans and nature. It is named for the mountainous Arcady region of Greece. Gilbert White's seminal piece \"Natural History of Selbourne\" promotes a benign attitude towards nature and advocates for a peaceful coexistence between organisms. It was an individual realization of ancient arcadian ideas of harmonious interactions between humans and nature. The evolution of Arcadian ecological thought continuously reverts to the detailed letters and poems in this work.\n\nThe harmonious relationship described by Arcadian ecology establishes a responsibility to resist the domination of nature. Donald Worster in his book, \"Nature's Economy: A History of Ecological Ideas\", uses Imperial ecology as a counterpoint to Arcadian ecology. Imperial ecology takes a different approach, and suggests that humans should attempt to manage nature, because nature exists for man's benefit (utilitarianism). This contradiction is representative of the ecologists' struggle to explain humanity's relationship with nature while considering popular theological views of the time period. The discussion of Arcadian versus Imperial ecology would continue with prominent figures of the field such as Henry David Thoreau and Charles Darwin. The long term implications of this debate have the potential to shape nature in the future as humans struggle with ethical debates and laws for preservation.\n\nThe Arcadian standpoint has its roots in several historical and cultural traditions which have shaped the study of ecology. One of these such cultural traditions was the Renaissance, which cultivated the appreciation of landscape, wilderness, and nature. Environmental sociologist Kris van Koppen underscores this point by arguing, \"The social theories that belong to the arcadian approach are particularly orientated to the recognition, elaboration and extension of the intrinsic values of nature, as well as to the social organization of their preservation\".\n\nArcadian ecology can be understood by its contrasts with another prominent view, Imperial Ecology. Sociologists and historians define Imperial Ecology as the standpoint that nature is a force to be dominated in the quest for human convenience. It is in this difference that it can be clearly seen that the arcadian approach criticizes 'resourcism' and 'reductionism'. Therefore, sociologists and ecologists who subscribe to the notion of arcadian ecology view natural disasters like the Dust Bowl as stemming directly from conceptions of nature like imperial ecology.\n\nWithin arcadian ecological thought, there has been a recent focus on the relationship between humans and animals. This comes primarily from Keith Tomas and his work \"Man and the Natural World: Changing Attitudes in England 1500–1800\" published in 1983. This contribution began to highlight animal rights and the inhumane treatment of animals between 1500 and 1800. In a similar vein, Lynn White reflected on the shift from the biblical idea that animals were put on earth to serve man, to the realization that man must live in harmony with beast.\n\nEthical and political implications of the Arcadian Ecology viewpoint are ever popular in scholarly and media debates during the twenty-first century. The debate however, did not begin during the current time but rather has progressed over many centuries as humans attempt to grapple with their short-term and long-term environmental impact. Max Oelschlaeger remarks, \"Nearly 50 years ago Aldo Leopold identified the basic problem of conservation: learn how to live on the land without spoiling it\". It would also not even be fifteen years later when Rachel Carson wrote about Neanderthal science and its unreflective practitioners.\n\nA more reflective look at the United States' environmental practices can show in depth the struggle of a relatively new country, with substantial economic means, to come to an agreement on appropriate actions regarding nature. Historically the United States has had significant expansion and over-resourcing. The many national parks and government-protected environmental lands were in part created because there was over-framing and development. Teddy Roosevelt used his position as the United States President to set aside more than 194 million acres of park land. Karl Jacoby, an expert in environmental history, has written how the Adirondack Park in New York was created to ensure a continued water source to the New York City population and a natural environment to “recharge” from city life.\n\nNot all United States National Parks were created for reasons other than nature preservation, such as Yosemite National Park. Originally it was set aside as land to be undeveloped by those who predicted that land conservation may become important in the future. For classification purposes, those ecologists that saw a need to refuse a developmental and destructive path for Yellowstone ascribe to the arcadian ecology view. However, this originally Arcadian movement was opposed, when San Francisco need a viable water supply after a devastating earthquake. This conservation issue sparked a major debate over the Hetch Hetchy. The debate pitted major thinkers against each other including John Muir who thought there was \"no holier temple than Yosemite\" and Gifford Pinchot who was in favor of damming to provide water resources to San Francisco. The Hetch Hetchy examines the dichotomy of arcadian and imperial ecology.\n\nIn addition to National Parks, the United States has put many laws into motion regarding environmental protection including the National Environmental Policy Act (1969), the Wilderness Act (1964), and the Endangered Species Act (1973). These laws all celebrate the Arcadian harmony between nature and humans and ensure its preservation. Unfortunately, Americans, according to Max Oelschlaeger, are also, \"the world’s leading consumers: our ecological footprints tread heavily on other parts of the planet\".\n\nOne of the major problems in determining if there has been success in terms of the environment in the United States is the subjectivity that comes with this environmental issue. A look at the work by Eliot Brownlee, a professor of economic history, will suggest that the United States is an economic success story that utilized the natural resources to the best of their abilities. The view looks at nature not as a pawn, but a means to an end in production which has advanced the human race further than ever thought possible. In opposition, a prominent environmental philosopher, Joseph Petulla, wrote a different story of the landscape of Brownlee. He saw the economic success coming at a costly price of the destruction of the American land. Western civilization had encroached too far into nature and it was more reminiscent of Imperial Ecology rather than Arcadian Ecology.\n\n\n"}
{"id": "42105000", "url": "https://en.wikipedia.org/wiki?curid=42105000", "title": "Australia–East Timor spying scandal", "text": "Australia–East Timor spying scandal\n\nThe Australia–East Timor spying scandal began in 2004 when the Australian Secret Intelligence Service (ASIS) planted 200 covert listening devices in the Timor-Leste Cabinet Office at Dili, to obtain information in order to ensure Australian interests held the upper hand in negotiations with Timor-Leste over the rich oil and gas fields in the Timor Gap. Even though the Timor-Leste government was unaware of the espionage operation undertaken by Australia, negotiations were hostile. The first Prime Minister of Timor-Leste, Mari Alkatiri, bluntly accused the Howard Government of plundering the oil and gas in the Timor Sea, stating:\n\nAustralian Foreign Minister Alexander Downer ironically responded:\n\n\"Witness K\", a former senior ASIS intelligence officer who led the bugging operation, revealed in 2012 the Australian Government had accessed top-secret Cabinet discussions in Dili and exploited this during negotiations of the Timor Sea Treaty. The treaty was superseded by the signing of the Treaty on Certain Maritime Arrangements in the Timor Sea (CMATS) which restricted further sea claims by Timor-Leste until 2057. Lead negotiator for Timor-Leste, Peter Galbraith, laid-out the motives behind the espionage by ASIS:\n\nThe espionage revealation led to Timor-Leste rejecting the treaty on the Timor Sea, and referring the matter to The Hague. In March 2014, the International Court of Justice (ICJ) ordered Australia to stop spying on East Timor. The Permanent Court of Arbitration in the Hague considered claims by Timor-Leste over the territory until early 2017, when East Timor dropped the case after the Australian Government agreed to renegotiate. In 2018, the parties signed a new agreement which split the profits 80% East Timor, 20% Australia.\n\nThe identity of Witness K must be kept secret under the provisions of the \"Intelligence Services Act\" and any person in breach of this could face prosecution.\n\nIn June 2018 the Commonwealth Director of Public Prosecutions filed criminal charges against Witness K and his lawyer Bernard Collaery. A directions hearing was set down for 25 July 2018 in the ACT Magistrates Court.\n\nIn 2002, the Australian Government withdrew from the United Nations Convention on the Law of the Sea (UNCLOS) clauses which could bind Australia to a decision of the Permanent Court of Arbitration in the Hague on matters of territorial disputes. Two months later, East Timor officially gained its independence from Indonesia. In 2004, East Timor began negotiating territorial borders with Australia. In response to this, ASIS used an Australian aid project to infiltrate the Palace of Government in Dili and install listening devices in the walls of the cabinet room. This enabled ASIS to obtain top-secret information from treaty negotiators led by Prime Minister Mari Alkatiri. This provided the Australian Government with \"an advantage during treaty talks\". The installation of listening devices occurred 18 months after the 2002 Bali bombings, during a time of heightened ASIS activity in the Southeast Asia region. In 2006, Australia and East Timor signed the second CMats treaty.\n\nBefore \"Witness K\" revealed ASIS's clandestine activities, the treaty between Timor-Leste and Australia was ridiculed. Over 50 members of the US Congress sent a letter to Prime Minister John Howard calling for a \"fair\" and \"equitable\" resolution of the border dispute, noting East Timor's poverty. Signatories included Nancy Pelosi, Rahm Emanuel and Patrick J. Kennedy. Witness K made the Australian Government's spying activities public after the Inspector-General of Intelligence and Security (IGIS) recommended he do so.\n\nDavid Irvine, ASIS head (2003-2009) authorised the operation. His successor Nick Warner, ASIS head (2009-2017), assisted in an advisory role. Foreign Minister Alexander Downer, who oversaw ASIS was overseas during the operation. According to the lawyer of Witness K, former ACT Attorney-General Bernard Collaery, successive Australian Governments from both major parties have actively sought to cover-up the incident.\n\nWitness K revealed the bugging operation in 2012 after learning Foreign Minister Alexander Downer had become an adviser to Woodside Petroleum, which was benefiting from the treaty.\n\nThe Gillard Government, in response to a letter sent by East Timor's Prime Minister Xanana Gusmao requesting an explanation and a bilateral resolution to the dispute, authorised the installation of listening devices in Collaery's Canberra office. After the story became public in 2012, the Gillard Government inflamed tensions with East Timor by denying the alleged facts of the dispute and sending as a representative to Dili someone who was known by Gusmao to have been involved in the bugging. In 2015, Guamao said of Prime Minister Julia Gillard's response:\n\nThe response of the Gillard Government led to East Timor's application to have the case heard in the Permanent Court of Arbitration. According to Gusmao, Prime Minister Tony Abbott sought to assuage East Timor's concerns over the spying scandal by assuring X that \"the Chinese are listening to [Australia]\".\nIn 2015, the bugging scandal received renewed interest after the Australian Broadcasting Corporation ran a story revealing the level of concern amongst senior intelligence officials in the Australian intelligence apparatus. Foreign Minister Julie Bishop banned Witness K from using his or her passport. As Collaery has pointed out, such security assessments are usually conducted by ASIO and not, as in the case of Witness K, by ASIS. Attorney-General George Brandis, under lengthy questioning by a panel of Australian senators, admitted that new national security laws could enable prosecution of Witness K and his lawyer, Collaery. Further, Australia's Solicitor General, Justin Gleeson SC, claimed in a submission to the ICJ that Witness K and Collaery could have breached parts of the Criminal Code pertaining to espionage and could be stripped of their Australia citizenship if they are dual-nationals (as, indeed, Collaery is). Foreign Minister Julie Bishop said in April 2016 that: \"We stand by the existing treaties, which are fair and consistent with international law.\"\n\nThe Turnbull Government has recently (August 2016) indicated it will consider any decision made by the Permanent Court of Arbitration binding. Some suggest this \"softening\" is linked to the territorial dispute over the South China Sea between China and neighbouring states. The Timor-Leste government has continued to press Australia for an equidistant border between the two countries. The Australian Labor Party in 2016 suggested a new deal could be struck between Timor-Leste and Australia if it formed government.\n\nIn September 2016, The Age newspaper in Australia published an editorial claiming East Timor's attempts to resolve this matter in international courts \"is an appeal to Australians' sense of fairness.\" An article in the Global Times in China on 6 September 2016 said:\n\nOn 26 September 2016, Labor Foreign Affairs spokesperson Senator Penny Wong said, \"In light of this ruling [that the court can hear East Timor's claims], we call on the government to now settle this dispute in fair and permanent terms; it is in both our national interests to do so\". To date (March 2018), the Australian Government has not officially acknowledged the spying claims. \nDespite having approval from the Director-General of ASIO to apply for a passport, ASIS and the Turnbull Government deny Witness K right to obtain a passport citing national security. His lawyer maintains that this is \"pure retaliation\" and that Witness K remains in \"effective house arrest\" in Australia in violation of the law.\n\nThe Australian lawyer Bernard Collaery, who was representing the East Timorese government in a dispute against the Australian Government over the bugging of cabinet offices during the negotiations for a petroleum and gas treaty in 2004, alleged in 2013 that two agents from the Australian Security Intelligence Organisation (ASIO) had raided his Canberra office and seized his electronic and paper files. Three months after the election of the Abbott Government in 2013, ASIS was authorised to raid the office of Collaery and the home of Witness K, whose passport was seized. Australia's Attorney-General George Brandis has since asserted that he had authorised the ASIO raids to protect Australia's national security. The passport of Witness K was still being held as of March 2018. Collaery said of Witness K's ability to travel overseas and appear before the Hague:\n\nWitness K has since been allowed to give video evidence in the Hague trial given his inability to travel outside Australia.\n\nOn 3 March 2014, in response to an East Timorese request for the indication of provisional measures, the International Court of Justice (ICJ) ordered Australia not to interfere with communications between East Timor and its legal advisors in the arbitral proceedings and related matters. The case was officially removed from ICJ's to-do list on 12 June 2015 after Timor-Leste confirmed that Australia had handed back the goods: \"the Agent of Timor-Leste explained that, “[f]ollowing the return of the seized documents and data by Australia on 12 May 2015, Timor-Leste [has] successfully achieved the purpose of its Application to the Court, namely the return of Timor-Leste’s rightful property, and therefore implicit recognition by Australia that its actions were in violation of Timor-Leste’s sovereign rights”.\n\nIn 2013, East Timor launched a case at the Permanent Court of Arbitration in The Hague to pull out of a gas treaty that it had signed with Australia as it accuses the latter of having ASIS bug the East Timorese cabinet room in Dili in 2004.\n\nIn April 2016, East Timor began proceedings in the Permanent Court of Arbitration under UNCLOS over the sea border it shares with Australia. The Department of Foreign Affairs and Trade released a statement condemning the move, which it said was contrary to the previous treaties it had lawfully signed and implemented. East Timor believes much of the Greater Sunrise oil field falls under its territory and that it has lost $US5 billion to Australian companies as a result of the treaty it now disputes. Hearings before the court commence on 29 August 2016. The court dismissed Australia's claim that it did not have jurisdiction to hear the case on 26 September 2016.\n\n"}
{"id": "39021390", "url": "https://en.wikipedia.org/wiki?curid=39021390", "title": "Beydağları Coastal National Park", "text": "Beydağları Coastal National Park\n\nBeydağları Coastal National Park (), a.k.a. Olympos Beydagları National Park (), is a national park in Antalya Province, southern Turkey.\n\nThe national park was established on March 16, 1972 by a decret of the government. It stretches over an area of beginning in Sarısu, located southwest of Antalya and reaching out to Cape Gelidonya parallel to the Mediterranean Sea across the Kemer-Kumluca shoreline.\n\nThe ancient settlements Olympos, Phaselis and Idyros are situated within the national park, which lies between the shores of the ancient regions Pamphylia and Lycia. The tallest mountain in the park is Tahtalı Dağı. The Yanartaş burning gas field is found on the foothills of that mountain.\n\nThe national park offers place for activities such as beach and sea sports, picnic, camping, trekking, mountain climbing, paragliding etc. Visiting of the archeological sites within the national park is possible all around the year.\n\n"}
{"id": "11267683", "url": "https://en.wikipedia.org/wiki?curid=11267683", "title": "Cleaner fish", "text": "Cleaner fish\n\nCleaner fish are fish that provide a service to other species by removing dead skin and ectoparasites. Although the animal being cleaned typically is another fish, it can also involve aquatic reptiles (sea turtles and marine iguana), mammals (manatees and whales) or octopuses. The cleaning symbiosis is an example of mutualism, an ecological interaction that benefits both parties involved. However, the cleaner fish may sometimes cheat and consume mucus or tissue, thus creating a form of parasitism. A wide variety of fish including wrasse, cichlids, catfish, pipefish, and gobies display cleaning behaviors. Similar behavior is found in other groups of animals, such as cleaner shrimps.\n\nCleaner fish advertise their services with conspicuous coloration, often displaying a brilliant blue stripe that spans the length of the body. This adaptation has evolved independently in different species of cleaner fish, making it an example of convergent evolution. Other species of fish, called mimics, imitate the behavior and phenotype of cleaner fish to gain access to client fish tissue. This is another example of convergent evolution.\n\nThe best known cleaner fish are the cleaner wrasses of the genus \"Labroides\" found on coral reefs in the Indian Ocean and Pacific Ocean. These small fish maintain so-called cleaning stations where other fish, known as hosts, congregate and perform specific movements to attract the attention of the cleaner fish. Remarkably, these small cleaner fish safely clean large predatory fish that would otherwise eat small fish such as these.\n\nWhile they derive the majority of their nutrients by removing ectoparasites, cleaner fish also feed on the mucus and tissue of the client fish, as these food sources have greater nutritional value. There is however a risk of terminating the cleaning interaction if the cleaner is too aggressive, taking too much mucus and tissue. Because of this, cleaners seek a balance in feeding between ectoparasites and mucus or tissue.\n\nCleaning behaviors have been observed in a number of other fish groups. Neon gobies of the genera \"Gobiosoma\" and \"Elacatinus\" provide a cleaning service similar to the cleaner wrasses, though this time on reefs in the western Atlantic, providing a good example of convergent evolution. Unlike the cleaner wrasses, they also eat a variety of small animals as well being cleaner fish, and generally do well in aquaria. However, the Caribbean cleaning goby (\"Elacatinus evelynae\") gladly eat scales and mucus from the host when the ectoparasites it normally feeds on are scarce, making the relationship somewhat less than mutually beneficial. The symbiosis does not break down because the abundance of these parasites varies significantly seasonally and spatially, and the overall benefit to the larger fish outweighs any cheating on the part of the smaller.\n\nAn interesting example of a cleaning symbiosis has been observed between two brackish water cichlids of the genus \"Etroplus\" from South Asia. The small species \"Etroplus maculatus\" is the cleaner fish, and the much larger \"Etroplus suratensis\" is the host that receives the cleaning service.\n\nCleaning has infrequently been observed in fresh waters compared to marine waters, but at least in part this is possibly related to fewer observers (such as divers) in the former habitat compared to the latter. One of the few known examples of cleaning is juvenile striped Raphael catfish cleaning the piscivorous \"Hoplias\" cf. \"malabaricus\". In public aquariums, \"Synaptolaemus\" headstanders have been seen cleaning larger fish.\n\nMimic species have evolved body forms, patterns, and colors which imitate other species to gain a competitive advantage. One of the most studied examples of mimicry on coral reefs is the relationship between the aggressive mimic \"Plagiotremus rhinorhynchos\" (the bluestriped fangblenny) and the cleaner wrasse model \"Labroides dimidiatus\". By appearing like \"L. dimidiatus\", \"P. rhinorhynchos\" is able to approach and subsequently feed on the tissue and scales of client fish while posing as a cleaner.\n\nThe presence of the cleaner mimic, \"P. rhinorhynchos\", has a negative impact on the foraging success of the cleaner model \"L. dimidiatus\". \"P. rhinorhynchos\" feeds by eating the tissue and scales of client fish, making client fish much more cautious while at cleaning stations. More aggressive mimics have a greater negative impact on the foraging rate and success of the cleaner fish. When mimics appear in higher densities relative to cleaners, there is a significant decline in the success rate of the cleaner fish. The effects of the mimic/model ratio are susceptible to dilution, whereby an increase in client fish allows both the mimics and the models to have more access to clients, thus limiting the negative effects that mimics have on model foraging success.\n\n"}
{"id": "8293", "url": "https://en.wikipedia.org/wiki?curid=8293", "title": "Diffusion pump", "text": "Diffusion pump\n\nDiffusion pumps use a high speed jet of vapor to direct gas molecules in the pump throat down into the bottom of the pump and out the exhaust. Invented in 1915 by Wolfgang Gaede using mercury vapor, and improved by Irving Langmuir and W. Crawford, they were the first type of high vacuum pumps operating in the regime of free molecular flow, where the movement of the gas molecules can be better understood as diffusion than by conventional fluid dynamics. Gaede used the name \"diffusion pump\" since his design was based on the finding that gas cannot diffuse against the vapor stream, but will be carried with it to the exhaust. However, the principle of operation might be more precisely described as gas-jet pump, since diffusion plays a role also in other high vacuum pumps. In modern textbooks, the diffusion pump is categorized as a momentum transfer pump.\n\nThe diffusion pump is widely used in both industrial and research applications. Most modern diffusion pumps use silicone oil or polyphenyl ethers as the working fluid. Cecil Reginald Burch discovered the possibility of using silicone oil in 1928.\n\nAn oil diffusion pump is used to achieve higher vacuum (lower pressure) than is possible by use of positive displacement pumps alone. Although its use has been mainly associated within the high-vacuum range (down to 10 mbar), diffusion pumps today can produce pressures approaching 10 mbar when properly used with modern fluids and accessories. The features that make the diffusion pump attractive for high and ultra-high vacuum use are its high pumping speed for all gases and low cost per unit pumping speed when compared with other types of pump used in the same vacuum range. Diffusion pumps cannot discharge directly into the atmosphere, so a mechanical forepump is typically used to maintain an outlet pressure around 0.1 mbar.\n\nThe oil diffusion pump is operated with an oil of low vapor pressure. The high speed jet is generated by boiling the fluid and directing the vapor through a jet assembly. Note that the oil is gaseous when entering the nozzles. Within the nozzles, the flow changes from laminar to supersonic and molecular. Often, several jets are used in series to enhance the pumping action. The outside of the diffusion pump is cooled using either air flow or a water line. As the vapor jet hits the outer cooled shell of the diffusion pump, the working fluid condenses and is recovered and directed back to the boiler. The pumped gases continue flowing to the base of the pump at increased pressure, flowing out through the diffusion pump outlet, where they are compressed to ambient pressure by the secondary mechanical forepump and exhausted. \n\nUnlike turbomolecular pumps and cryopumps, diffusion pumps have no moving parts and as a result are quite durable and reliable. They can function over pressure ranges of 10 to 10 mbar. They are driven only by convection and thus have a very low energy efficiency.\n\nOne major disadvantage of diffusion pumps is the tendency to backstream oil into the vacuum chamber. This oil can contaminate surfaces inside the chamber or upon contact with hot filaments or electrical discharges may result in carbonaceous or siliceous deposits. Due to backstreaming, oil diffusion pumps are not suitable for use with highly sensitive analytical equipment or other applications which require an extremely clean vacuum environment, but mercury diffusion pumps may be in the case of ultra high vacuum chambers used for metal deposition. Often cold traps and baffles are used to minimize backstreaming, although this results in some loss of pumping ability.\n\nThe oil of a diffusion pump cannot be exposed to the atmosphere when hot. If this occurs, the oil will burn and has to be replaced.\n\n \nThe steam ejector is a popular form of diffusion pump for vacuum distillation and freeze-drying. A jet of steam entrains the vapour that must be removed from the vacuum chamber. Steam ejectors can have single or multiple stages, with and without condensers in between the stages.\n\nOne class of diffusion vacuum pumps is the multistage compressed-air driven ejector. It is very popular in applications where objects are moved around using suction cups and vacuum lines.\n\n\n"}
{"id": "14513725", "url": "https://en.wikipedia.org/wiki?curid=14513725", "title": "Ecocide", "text": "Ecocide\n\nEcocide, or ecocatastrophe\",\" is the extensive damage to, destruction of or loss of ecosystem(s) of a given territory, whether by human agency or by other, to such an extent that peaceful enjoyment by the inhabitants of that territory has been or will be severely diminished. \n\nThe term ecocide is more recently used to refer to the destructive impact of humanity on its own natural environment. As a group of complex organisms we are committing ecocide through unsustainable exploitation of the planet's resources. The geological era we are living in, known as the anthropocene, is so named because the activities of the human species are influencing the Earth's natural state in a way never seen before. The most notable example is that of the atmosphere which is being transformed through the emission of gases from fossil fuel use : carbon dioxide, methane, chlorofluorocarbons etc. The ecocide we are witnessing is a symptom of the disregard and reward for accounting for the damage being caused. U.S. environmental theorist and activist Patrick Hossay argues that the human species is committing ecocide, via industrial civilization's effects on the global environment. Much of the modern environmental movement stems from this belief as a precept.\n\nThe concept of ecocide as an international crime originated in the 1970s.\n\nIn 2010 it was proposed that the Rome Statute be amended to include the international crime of Ecocide. The proposal was submitted to the United Nations International Law Commission who are '‘'mandated to promote the progressive development of international law and its codification’. The definition proposed includes provisions for both individual and state responsibility and would be a strict liability crime(including both intent and negligence). It would create a duty of care in events of naturally occurring ecocide as well as creating criminal responsibility for human caused ecocide.\n\nTo be considered an ecocide under the proposed law, an environmental harm would need to be widespread, long lasting or severe. This is the parameter based disjunctive test, as already set out under the 1977 United Nations Convention on Environmental Modification, which specifies the terms ‘widespread’, ‘long-lasting’ or ‘severe’ as: \n\nThe word was first recorded at the Conference on War and National Responsibility in Washington 1970, where Arthur Galston proposed a new international agreement to ban ecocide. Galston was a US biologist who identified the defoliant effects of a chemical later developed into Agent Orange. Subsequently a bioethicist, he was the first in 1970 to name massive damage and destruction of ecosystems as an ecocide.\n\nIn an \"obiter dictum\" in the 1970 Barcelona Traction case judgement, the International Court of Justice identified a category of international obligations called \"erga omnes\", namely obligations owed by states to the international community as a whole, intended to protect and promote the basic values and common interests of all.\n\nIn 1972 at the United Nations Stockholm Conference on the Human Environment which adopted the Stockholm Declaration, Olof Palme, the Prime Minister of Sweden, in his opening speech, spoke explicitly of the Vietnam war as an ecocide and it was discussed in the unofficial events running parallel to the official UN Stockholm Conference on Human Environment. Others, including Indira Gandhi from India and Tang Ke, the leader of the Chinese delegation, also denounced the war in human and environmental terms. They too called for ecocide to be an international crime. A Working Group on Crimes Against the Environment was formed at the conference, and a draft Ecocide Convention was submitted into the United Nations in 1973.\n\nDai Dong, a branch of the International Fellowship of Reconciliation, sponsored a Convention on Ecocidal War which took place in Stockholm, Sweden. The Convention brought together many people including experts Richard A. Falk, expert on the international law of war crimes and Robert Jay Lifton, a psychohistorian. The Convention called for a United Nations Convention on Ecocidal Warfare, which would amongst other matters seek to define and condemn ecocide as an international crime of war. Richard A. Falk drafted an Ecocide Convention in 1973, explicitly stating at the outset to recognise \"that man has consciously and unconsciously inflicted irreparable damage to the environment in times of war and peace\".\n\nWesting's view was that the element of intent did not always apply. \"Intent may not only be impossible to establish without admission but, I believe, it is essentially irrelevant.\"\n\nIn 1978, the Draft Code of Crimes Against the Peace and Security of Mankind discussions commenced. At the same time, State responsibility and international crimes were discussed and drafted.\n\nThe ILC 1978 Yearbook's 'Draft articles on State Responsibility and International Crime' included: \"an international crime (which) may result, inter alia, from: (d) a serious breach of an international obligation of essential importance for the safeguarding and preservation of the human environment, such as those prohibiting massive pollution of the atmosphere or of the seas.\" Supporters who spoke out in favour of a crime of ecocide included Romania and the Holy See, Austria, Poland, Rwanda, Congo and Oman\n\nEcocide as a crime continued to be addressed. The Whitaker Report, commissioned by the Sub-Commission on the Promotion and Protection of Human Rights on the question of the prevention and punishment of the crime of genocide was prepared by then Special Rapporteur, Benjamin Whitaker. The report contained a passage that \"some members of the Sub-Commission have, however, proposed that the definition of genocide should be broadened to include cultural genocide or \"ethnocide\", and also \"ecocide\": adverse alterations, often irreparable, to the environment - for example through nuclear explosions, chemical weapons, serious pollution and acid rain, or destruction of the rain forest - which threaten the existence of entire populations, whether deliberately or with criminal negligence.\"\n\nDiscussion of international crimes continued in the International Law Commission in 1987, where it was proposed that \"the list of international crimes include \"ecocide\", as a reflection of the need to safeguard and preserve the environment, as well as the first use of nuclear weapons, colonialism, apartheid, economic aggression and mercenarism\".\n\nThe ILC 'Draft Code of Crimes Against the Peace and Security of Mankind' of 1991 contained 12 crimes. One of those was 'wilful damage to the environment (Article 26)'.\n\nAs of 29 March 1993, the Secretary-General had received 23 replies from Member States and one reply from a non-member State. They were: Australia, Austria, Belarus, Belgium, Brazil, Bulgaria, Costa Rica, Ecuador, Greece, Netherlands, the Nordic countries (Denmark, Finland, Iceland, Norway, Sweden), Paraguay, Poland, Senegal, Sudan, Turkey, UK, USA, Uruguay and Switzerland. Many objections were raised, for summarised commentary see the 1993 ILC Yearbook. Only\nthree countries, the Netherlands, the United Kingdom and the United States of\nAmerica, opposed the inclusion of an environmental crime. The issue of adding a high test of intent (‘wilful’) was of concern: Austria commented: \"Since perpetrators of this crime are usually acting out of a profit motive, intent should not be a condition for liability to punishment.\" Belgium and Uruguay also took the position that no element of intent was necessary for the crime of severe damage to the environment (Article 26).\n\nIn 1996, Canadian/Australian lawyer Mark Gray published his proposal for an international crime of ecocide, based on established international environmental and human rights law. He demonstrated that states, and arguably individuals and organisations, causing or permitting harm to the natural environment on a massive scale breach a duty of care owed to humanity in general. He proposed that such breaches, where deliberate, reckless or negligent, be identified as ecocide where they entail serious, and extensive or lasting, ecological damage; international consequences; and waste.\n\nMeanwhile, in the ILC, ‘wilful and severe damage to the environment’ (Article 26) had been tasked to a working-group: \"The Commission further decided that consultations would continue as regards [Article 26] …the Commission decided … to establish a working group that would meet … to examine the possibility of covering in the draft Code the issue of wilful and severe damage to the environment ... the Commission decided by a vote to refer to the Drafting Committee only the text prepared by the working group for inclusion of wilful and severe damage to the environment as a war crime.\n\nIn 1998, the final Draft Code was used as inspiration for the Rome Statute at the United Nations United Nations Diplomatic Conference of Plenipotentiaries on the Establishment of an International Criminal Court, which was held in Rome. The Rome Statute was the founding document of the International Criminal Court (ICC), to be used when a state is either unwilling or unable to bring their own prosecutions for international crimes.\n\nEcocide was not included in the Rome Statute as a separate crime, but featured in relation to a war-crime. The test for this war crime was narrower than previous proposed tests. Under the Environmental Modification Convention 1977 (ENMOD) the test for war-time environmental destruction is ‘widespread, long-term or severe’, whereas Article 8(2)(b) of the Rome Statute 1998 modified the ENMOD test with the change of one word to ‘widespread, long-term and severe.’ Article 8(2)(b) limited environmental harm to circumstances when \"Intentionally launching an attack in the knowledge that such attack will cause incidental loss of life or injury to civilians or damage to civilian objects or widespread, long-term and severe damage to the natural environment which would be clearly excessive in relation to the concrete and direct overall military advantage anticipated.\"\n\nThe proposal for the crime of Ecocide was submitted to the United Nations by a private party. In March 2010, British \"earth lawyer\" Polly Higgins submitted to the United Nations an amendment to the Rome Statute, proposing that “ecocide” be legally recognised as the fifth international Crime against peace. The Rome Statute currently acknowledges four crimes against peace: genocide; crimes against humanity; war crimes; and the crime of aggression. Each of these crimes affects human victims. While Higgins’ proposed definition of ecocide attends to inhabitants’ “peaceful enjoyment”, the victim the amendment is primarily promising to protect is not human but environmental.\n\nIn 2011, a mock Ecocide Act was drafted and then tested in the UK Supreme Court via a mock trial by the Hamilton Group.\n\nIn 2012, a concept paper on the Law of Ecocide was sent out to governments In June 2012 the idea of making ecocide a crime was presented to legislators and judges from around the world at the World Congress on Justice Governance and Law for Environmental Sustainability, held in Mangaratiba before the Rio +20 Earth Summit, the United Nations Conference on Sustainable Development. Making ecocide an international crime was voted as one of the top twenty solutions to achieving sustainable development at the World Youth Congress in Rio de Janeiro in June 2012.\n\nIn October 2012 a range of experts gathered at the international conference Environmental Crime: Current and Emerging Threats held in Rome at the UN Food and Agricultural Organization Headquarters hosted by the United Nations Interregional Crime and Justice Research Institute(UNICRI) in cooperation with United Nations Environmental Programme (UNEP) and the Ministry of the Environment (Italy). The conference recognized that environmental crime is an important new form of transnational organized crime in need a greater response. One of the outcomes was that UNEP and UNICRI head up a study into the definition of environmental crime, new environmental crime and give due consideration to the history of making ecocide an international crime once again.\n\nOn January 22, 2013, a committee of eleven citizens from nine EU countries officially launched the \"European Citizens Initiative \"End Ecocide in Europe\". The European Citizens' Initiative, or ECI, is a tool created by the Lisbon Treaty to promote participative and direct democracy. The ECI is a way for EU citizens to propose new or suggest amendments to legislation directly to the European Commission which is the institution proposing new EU laws. This initiative aimed at criminalising ecocide, the extensive damage and destruction of ecosystems, including the denial of market access for products based on ecocide to the EU and investments in activities causing ecocide. Three MEPs, Keith Taylor, Eva Joly, and Jo Leinen, publicly gave the first signatures. The initiative did not collect the 1 million signatures needed, but was discussed in the European Parliament.\n\nTen countries have codified ecocide as a crime during peacetime. Those countries follow closely the ILC Draft articles definition of \"An individual who wilfully causes or orders the causing of widespread, long-term and severe damage to the natural environment shall, on conviction thereof, be sentenced [to...].\" Although there are Laws of Ecocide in place, the effectiveness of these laws depends on a number of factors including the enforcement of the law, an independent judiciary and respect for the rule of law. Many of the countries with national laws of ecocide in place are ranked very highly for corruption and low for respect for the rule of law by Transparency International.\n\nArticle 409. Ecocide: \"Ecocide, i.e. contamination of atmosphere, land and water resources, mass destruction of flora and fauna or any other action that could have caused ecological disaster - shall be punishable by ...\"\n\nArticle 394. Ecocide: \"Mass destruction of flora or fauna, poisoning the environment, the soils or water resources, as well as implementation of other actions causing an ecological catastrophe, is punished ...\"\n\nArticle 441. Ecocide: \"Mass destruction of flora and fauna, poisoning of air or water resources, and also any other actions that may cause an environmental disaster, - shall be punishable by ...\"\n\nArt 131. Ecocide: \"Deliberate mass destruction of flora and fauna, or poisoning the air or water, or the commission of other intentional acts that could cause an ecological disaster (ecocide), - shall be punished by ...\"\n\nArt 161. Ecocide: \"Mass destruction of flora or fauna, poisoning the atmosphere, land or water resources, as well as the commission of other acts which caused or a capable of causation of an ecological catastrophe, - shall be punished by...\"\n\nArt 374. Ecocide: \"Massive destruction of the animal or plant kingdoms, contamination of the atmosphere or water resources, and also commission of other actions capable of causing an ecological catastrophe, shall be punishable ...\"\n\nArt 136. Ecocide: \"Deliberate mass destruction of flora and fauna, poisoning the atmosphere or water resources, and the commission of other acts that may cause or caused an ecological disaster shall be punished ...\"\n\nArt 358. Ecocide: \"Massive destruction of the animal or plant kingdoms, contamination of the atmosphere or water resources, and also commission of other actions capable of causing an ecological catastrophe, shall be punishable by ...\"\n\nArt 400. Ecocide: \"Mass destruction of flora and fauna, poisoning the atmosphere or water resources, as well as commitment of other actions which may cause ecological disasters is punishable ...\"\n\nArt 196. Pollution of Natural Environment: \"Pollution or damage of land, water, or atmospheric air, resulted in mass disease incidence of people, death of animals, birds, or fish, or other grave consequences – shall be punished ...\"\n\nArt 342 Crimes against mankind: \"Those who, in peace time or war time, commit acts of ... as well as other acts of genocide or acts of ecocide or destroying the natural environment, shall be sentenced ...\"\n\n\n\n"}
{"id": "4655742", "url": "https://en.wikipedia.org/wiki?curid=4655742", "title": "Economizer", "text": "Economizer\n\nEconomizers (US and Oxford spelling), or economisers (UK), are mechanical devices intended to reduce energy consumption, or to perform useful function such as preheating a fluid. The term economizer is used for other purposes as well. Boiler, power plant, heating, Refrigeration, ventilating, and air conditioning (HVAC) uses are discussed in this article. In simple terms, an economizer is a heat exchanger.\n\nRobert Stirling's innovative contribution to the design of hot air engines of 1816 was what he called the 'Economiser'. Now known as the regenerator, it stored heat from the hot portion of the engine as the air passed to the cold side, and released heat to the cooled air as it returned to the hot side. This innovation improved the efficiency of Stirling's engine enough to make it commercially successful in particular applications, and has since been a component of every air engine that is called a Stirling engine.\n\nIn boilers, economizers are heat exchange devices that heat fluids, usually water, up to but not normally beyond the boiling point of that fluid. Economizers are so named because they can make use of the enthalpy in fluid streams that are hot, but not hot enough to be used in a boiler, thereby recovering more useful enthalpy and improving the boiler's efficiency. They are a device fitted to a boiler which saves energy by using the exhaust gases from the boiler to preheat the cold water used to fill it (the \"feed water\").\n\nThe boiler room is a huge energy guzzler. It consists of thermal fluid boilers or steam boiler, with exhaust gases through a common chimney.\nAn indirect contact or direct contact condensing economizer will recover the residual heat from the combustion products. A series of dampers, an efficient control system, as well as a ventilator, allow all or part of the combustion products to pass through the economizer, depending on the demand for make-up water and/or process water. The temperature of the gases can be lowered from 200 °C to 10 °C, while preheating the process water from 8 °C to 80 °C. On average over the years, boiler combustion efficiency has risen from 80% to more than 95%. The efficiency of heat produced is directly linked to boiler efficiency. The percentage of excess air and the temperature of the combustion products are two key variables in evaluating this efficiency.\n\nThe combustion of natural gas needs a certain quantity of air in order to be complete, so the burners need a flow of excess air in order to operate. Combustion produces water steam, and the quantity depends on the amount of natural gas burned. Also, the evaluation of the dew point depends on the excess air. Natural gas has different combustion efficiency curves linked to the temperature of the gases and the excess air. For example, if the gases are chilled to 38 °C and there is 15% excess air, then the efficiency will be 94%. The condensing economizer can thus recover the sensible and latent heat in the steam condensate contained in the flue gases for the process.\nThe economizer is made of an aluminium and stainless steel alloy. The gases pass through the cylinder and the water through the finned tubes. It condenses about 11% of the water contained in the gases.\n\nThe first successful economizer design was used to increase the steam-raising efficiency of the boilers of stationary steam engines. It was patented by Edward Green in 1845, and since then has been known as \"Green's economizer\". It consisted of an array of vertical cast iron tubes connected to a tank of water above and below, between which the boiler's exhaust gases passed. This is the reverse arrangement to that usually but not always seen in the fire tubes of a boiler; there the hot gases usually pass through tubes immersed in water, whereas in an economizer the water passes through tubes surrounded by hot gases. While both are heat exchange devices, in a \"boiler\" the burning gases heat the water to produce steam to drive an engine, whether piston or turbine, whereas in an \"economizer\", some of the heat energy that would otherwise all be lost to the atmosphere is instead used to heat the water and/or air that will go into the boiler, thus saving fuel. The most successful feature of Green's design of economizer was its mechanical scraping apparatus, which was needed to keep the tubes free of deposits of soot.\n\nEconomizers were eventually fitted to virtually all stationary steam engines in the decades following Green's invention. Some preserved stationary steam engine sites still have their Green's economisers although usually they are not used. One such preserved site is the Claymills Pumping Engines Trust in Staffordshire, England, which is in the process of restoring one set of economisers and the associated steam engine which drove them. Another such example is the British Engineerium in Brighton & Hove, where the economiser associated with the boilers for Number 2 Engine is in use, complete with its associated small stationary engine. A third site is Coldharbour Mill Working Wool Museum, where the Green's economiser is in working order, complete with the drive shafts from the Pollit and Wigzell steam engine.\n\nModern-day boilers, such as those in coal-fired power stations, are still fitted with economizers which are descendants of Green's original design. In this context they are often referred to as feedwater heaters and heat the condensate from turbines before it is pumped to the boilers.\n\nEconomizers are commonly used as part of a heat recovery steam generator in a combined cycle power plant. In an HRSG, water passes through an economizer, then a boiler and then a superheater. The economizer also prevents flooding of the boiler with liquid water that is too cold to be boiled given the flow rates and design of the boiler.\n\nA common application of economizers in steam power plants is to capture the waste heat from boiler stack gases (flue gas) and transfer it to the boiler feedwater. This raises the temperature of the boiler feedwater, lowering the needed energy input, in turn reducing the firing rates needed for the rated boiler output. Economizers lower stack temperatures which may cause condensation of acidic combustion gases and serious equipment corrosion damage if care is not taken in their design and material selection.\n\nA building's HVAC (heating, ventilating, and air conditioning) system can make use of an air-side economizer to save energy in buildings by using cool outside air as a means of cooling the indoor space. When the temperature of the outside air is less than the temperature of the recirculated air, conditioning with the outside air is more energy efficient than conditioning with recirculated air. When the outside air is both sufficiently cool and sufficiently dry (depending on the climate) the amount of enthalpy in the air is acceptable and no additional conditioning of it is needed; this portion of the air-side economizer control scheme is called \"free cooling\".\n\nAir-side economizers can reduce HVAC energy costs in cold and temperate climates while also potentially improving indoor air quality, but are most often not appropriate in hot and humid climates. With the appropriate controls, economizers can be used in climates which experience various weather systems. For information on how economizers and other controls can affect energy efficiency and indoor air quality in buildings, see the US Environmental Protection Agency report, \"Energy Cost and IAQ Performance of Ventilation Systems and Controls Study.\" \n\nWhen the outside air's dry- and wet-bulb temperatures are low enough, a water-side economizer can use water cooled by a wet cooling tower or a dry cooler (also called a fluid cooler) to cool buildings without operating a chiller. They are historically known as the \"strainer cycle\", but the water-side economizer is not a true thermodynamic cycle. Also, instead of passing the cooling tower water through a strainer and then to the cooling coils, which causes fouling, more often a plate-and-frame heat exchanger is inserted between the cooling tower and chilled water loops.\n\nGood controls, and valves or dampers, as well as maintenance, are needed to ensure proper operation of the air- and water-side economizers.\n\nA common form of refrigeration economizer is a \"walk-in cooler economizer\" or \"outside air refrigeration system\". In such a system outside air that is cooler than the air inside a refrigerated space is brought into that space and the same amount of warmer inside air is ducted outside. The resulting cooling supplements or replaces the operation of a compressor-based refrigeration system. If the air inside a cooled space is only about 5 °F warmer than the outside air that replaces it (that is, the ∆T>5 °F) this cooling effect is accomplished more efficiently than the same amount of cooling resulting from a compressor based system. If the outside air is not cold enough to overcome the refrigeration load of the space the compressor system will need to also operate, or the temperature inside the space will rise.\n\nAnother use of the term occurs in industrial refrigeration, specifically vapor-compression refrigeration. Normally, the economizer concept is applied when a particular design or feature on the refrigeration cycle, allows a reduction either in the amount of energy used from the power grid; in the size of the components (basically the gas compressor’s nominal capacity) used to produce refrigeration, or both.\nFor example, for a walk-in freezer that is kept at , the main refrigeration components would include: an evaporator coil (a dense arrangement of pipes containing refrigerant and thin metal fins used to remove heat from inside the freezer), fans to blow air over the coil and around the box, an air-cooled condensing unit sited outdoors, and valves and piping. The condensing unit would include a compressor and a coil and fans to exchange heat with the ambient air.\n\nAn economizer display takes advantage of the fact that refrigeration systems have increasing efficiencies at increasing pressures and temperatures. The power the gas compressor needs is strongly correlated to both the ratio and the difference, between the discharge and the suction pressures (as well as to other features like the refrigerant’s heat capacity and the type of compressor). Low temperature systems such as freezers move less fluid in same volumes. That means the compressor’s pumping is less efficient on low temperature systems. This phenomenon is notorious when taking in account that the evaporation temperature for a walk-in freezer at may be around .\nSystems with economizers aim to produce part of the refrigeration work on high pressures, condition in which gas compressors are normally more efficient. Depending of the application, this technology either allows smaller compression capacities to be able to supply enough pressure and flow for a system that normally would require bigger compressors; increases the capacity of a system that without economizer would produce less refrigeration, or allows the system to produce the same amount of refrigeration using less power.\n\nThe economizer concept is linked to subcooling as the condensed liquid line temperature is usually higher than that on the evaporator, making it a good place to apply the notion of increasing efficiencies. Recalling the walk-in freezer example, the normal temperature of the liquid line in that system is around or even higher (it varies depending on the condensing temperature). That condition is by far less hostile to produce refrigeration, than the evaporator at .\n\nSeveral displays permit the refrigeration cycle to work as economizers, and benefit from this idea. The design of this kind of systems demands certain expertise on the matter, and the manufacture of some of the gear, particular finesse and durability. Pressure drop, electric valve controlling and oil drag, must all be attended with special caution.\n\nA system is said to be in a two staged set up if two separate gas compressors in serial display work together to produce the compression. A normal booster installation is a two staged system that receives fluid that cools down the discharge of the first compressor, before arriving to the second compressor’s input. The fluid that arrives to the interstage of both compressors comes from the liquid line and is normally controlled by expansion, pressure and solenoid valves.\n\nThe need to use two compressors when considering a booster set-up tends to increase the cost of a refrigeration system. Besides the gear’s price, two staged systems need special attention over synchronization, pressure control and lubrication. To reduce these costs, special gear has been elaborated.\n\nEconomizer screw compressors are being built by several manufacturers like Refcomp, Mycom, Bitzer and York. These machines merge both compressors of a two staged system into one screw compressor and have two inputs: the main suction and an interstage side entrance for higher pressure gas. This means there is no need to install two compressors and still benefit from the booster concept.\n\nThere are two types of economizer setups for these compressors, flash and subcooling. The latter works under the same principle as the two staged booster displays with subcooling. The flash economizer is different because it doesn’t use a heat exchanger to produce the subcooling. Instead, it has a flash chamber or tank, in which flash gas is produced to lower the temperature of the liquid before the expansion. The flash gas that is produced in this tank leaves the liquid line and goes to the economizer entrance of the screw compressor.\n\nAll previous systems produce an economizer effect by using compressors, meters, valves and heat exchangers within the refrigeration cycle. Depending on the system, in some refrigeration cycles it may be convenient to produce the economizer using an independent refrigeration mechanism. Such is the case of subcooling the liquid line by any other means that draw the heat out of the main system. For example, a heat exchanger that preheats cold water needed for another process or human use, may withdraw the heat from the liquid line, effectively subcooling the line and increasing the system’s capacity.\n\nRecently, machines exclusively designated for this purpose have been developed. In Chile, the manufacturer EcoPac Systems developed a cycle optimizer able to stabilize the temperature of the liquid line and allowing either an increase in the refrigeration capacity of the system, or a reduction of the power consumption. Such systems have the advantage of not interfering with the original design of the refrigeration system being an interesting alternative for expanding single staged systems that do not possess an economizer compressor.\n\nSubcooling may also be produced by superheating the gas leaving the evaporator and heading to the gas compressor. These systems withdraw heat from the liquid line but heat up the gas compressors suction. This is a very common solution to insure that gas reaches the compressor and liquid reaches the valve. It also allows maximum heat exchanger use as minimizes the portion of the heat exchangers used to change the temperature of the fluid, and maximizes the volume in which the refrigerant changes its phase (phenomena involving much more heat flow, the base principle of vapor-compression refrigeration).\n\nAn internal heat exchanger is simply a type of heat exchanger that uses the cold gas leaving the evaporator coil to cool the high-pressure liquid that is headed into the beginning of the evaporator coil via an expansion device. The gas is used to chill a chamber that normally has a series of pipes for the liquid running through it. The superheated gas then proceeds on to the compressor. The subcooling term refers to cooling the liquid below its boiling point. of subcooling means it is 10 °F colder than boiling at a given pressure. As it represents a difference of temperatures, the subcooling value won’t change if it is measured on the absolute scale, or the relative scale (10 °F of subcooling equals of subcooling).\n\n"}
{"id": "24177288", "url": "https://en.wikipedia.org/wiki?curid=24177288", "title": "Franklin bells", "text": "Franklin bells\n\nFranklin bells (also known as Gordon's Bells or lightning bells) are an early demonstration of electric charge designed to work with a Leyden jar. Franklin bells are only a qualitative indicator of electric charge and were used for simple demonstrations rather than research. This was the first device that converted electrical energy into mechanical energy in the form of continuous mechanical motion, in this case, the moving of a bell clapper back and forth between two oppositely charged bells.\n\nThis device is named for Benjamin Franklin, an early adopter who used it during his experimentation with electricity. It was discovered by the Scottish inventor Andrew Gordon, Professor of Natural Philosophy at the University of Erfurt, Germany . About 1742 he invented a device known as the \"electric chimes\", which was widely described in textbooks of electricity. Franklin made use of Gordon's idea by connecting one bell to his pointed lightning rod, attached to a chimney, and a second bell to the ground. One of his papers \ncontains the following description:\n\nIn September 1752, I erected an Iron Rod to draw the Lightning down into my House, in order to make some Experiments on it, with two Bells to give Notice when the Rod should be electrified.\n\nThe bells consist of a metal stand with a crossbar, from which hang three bells. The outer two bells hang from conductive metal chains, while the central bell hangs from a nonconductive thread. In the spaces between these bells hang two metal clappers, small pendulums, on nonconductive threads. A short metal chain hangs from the central bell.\n\nThe central bell's chain is put in contact with the inner surface of a Leyden jar, while the outside surface of the jar is put in contact with the metal stand. Thus, the central bell takes its charge from the inner surface of the jar, while the outer surface charges the two bells on the conductive chains. This causes the bells to have a difference in electrical potential equal to that between the inner and outer surfaces of the jar. The hanging metal clappers will be attracted to one bell, will touch it, pick up its charge, and be repelled; they will then swing across to the other bell, and do the same there. Each time the clappers touch a bell, charge is transferred between the inner and outer surfaces of the Leyden jar. When the jar is completely discharged, the bells will stop ringing.\n\n\n"}
{"id": "220825", "url": "https://en.wikipedia.org/wiki?curid=220825", "title": "Freezing rain", "text": "Freezing rain\n\nFreezing rain is the name given to rain precipitation maintained at temperatures below freezing by the ambient air mass that causes freezing on contact with surfaces. Unlike sleet, a mixture of rain and snow, ice pellets, or hail, freezing rain is made entirely of liquid droplets. The raindrops become supercooled while passing through a sub-freezing layer of air hundreds of meters above the ground, and then freeze upon impact with any surface they encounter, including the ground, trees, electrical wires, aircraft, and automobiles. The resulting ice, called glaze ice, can accumulate to a thickness of several centimeters and cover all exposed surfaces. The METAR code for freezing rain is FZRA.\n\nA storm that produces a significant thickness of glaze ice from freezing rain is often referred to as an ice storm. Although these storms are not particularly violent, freezing rain is notorious for causing travel problems on roadways, breaking tree limbs, and downing power lines from the weight of accumulating ice. Downed power lines cause power outages in affected areas while accumulated ice can also pose significant overhead hazards. It is also known for being extremely dangerous to aircraft since the ice can effectively 'remould' the shape of the airfoil and flight control surfaces. (See atmospheric icing.) \n\nFreezing rain is often associated with the approach of a warm front, when subfreezing air (temperatures at or below freezing) is trapped in the lowest levels of the atmosphere while warm air advects in aloft. This happens, for instance, when a low pressure system moves from the Mississippi River Valley toward the Appalachian Mountains and the Saint Lawrence River Valley of North America during the cold season, with a strong high pressure system sitting further east. This setup is known as cold-air damming, and is characterized by very cold and dry air at the surface within the region of high pressure. The warm air from the Gulf of Mexico is often the fuel for freezing precipitation.\n\nFreezing rain develops when falling snow encounters a layer of warm air aloft, typically around the 800 mbar (800 hPa) level, causing the snow to melt and become rain. As the rain continues to fall, it passes through a layer of subfreezing air just above the surface and cools to a temperature below freezing (). If this layer of subfreezing air is sufficiently deep, the raindrops may have time to freeze into ice pellets (sleet) before reaching the ground. However, if the subfreezing layer of air at the surface is very shallow, the rain drops falling through it will not have time to freeze and they will hit the ground as supercooled rain. When these supercooled drops make contact with the ground, power lines, tree branches, aircraft, or anything else below , a portion of the drops instantly freezes, forming a thin film of ice, hence freezing rain. The specific physical process by which this occurs is called nucleation. \n\nSurface observations by manned or automatic stations are the only direct confirmation of freezing rain. One can never \"see\" directly freezing rain, rain or snow on weather radars, Doppler or conventional. However, it is possible to estimate the area covered by freezing rain with radars indirectly.\n\nThe intensity of the radar echoes (reflectivity) is proportional to the form (water or ice) of the precipitation and its diameter. In fact, rain has much stronger reflective power than snow but its diameter is much smaller. So the reflectivity of rain coming from melted snow is only slightly higher. However, in the layer where the snow is melting, the wet flakes still have a large diameter and are coated with water so the returns to the radar is much stronger.\n\nThe presence of this brightband indicates that there is a warm layer above ground where snow melts. This could be producing rain on the ground or the possibility of freezing rain if the temperature is below freezing. This artifact can be located, like on the image at left, with a cross-section through radar data. The height and slope of the brightband will give clues to the extent of the region where melting occurs. Then it is possible to associate this clue with surface observations and numerical models prediction to produce output such as the ones seen on television weather programs that divide radar echoes into rain, mixed and snow precipitations.\n\nFreezing rain often causes major power outages by forming glaze ice. When the freezing rain or drizzle is light and not prolonged, the ice formed is thin and usually causes only minor damage (relieving trees of their dead branches, etc.). When large quantities accumulate, however, it is one of the most dangerous types of winter hazard. When the ice layer exceeds approximately , tree limbs with branches heavily coated in ice can break off under the enormous weight and fall onto power lines. Windy conditions and lightning, when present, will exacerbate the damage. Power lines coated with ice become extremely heavy, causing support poles, insulators and lines to break. The ice that forms on roadways makes vehicle travel dangerous. Unlike snow, wet ice provides almost no traction, and vehicles will slide even on gentle slopes. Because freezing rain does not hit the ground as an ice pellet (called \"sleet\") but still as a rain droplet, it conforms to the shape of the ground, or object such as a tree branch or car. This makes one thick layer of ice, often called \"glaze\". \nFreezing rain and glaze ice on a large scale is called an ice storm. Effects on plants can be severe, as they cannot support the weight of the ice. Trees may snap as they are dormant and fragile during winter weather. Pine trees are also victims of ice storms as their needles will catch the ice, but not be able to support the weight. In February 1994, a severe ice storm caused over $1 billion in damage in the Southern United States, primarily in Mississippi, Tennessee, Alabama, and Western North Carolina, especially the Appalachians. One particularly severe ice storm struck eastern Canada and northern parts of New York and New England in the North American ice storm of 1998.\n\nFreezing rain is considered to be an extreme hazard to aircraft, as it causes very rapid structural icing. Most helicopters and small airplanes lack the necessary deicing equipment to fly in freezing rain of any intensity, and heavy freezing rain can overwhelm even the most sophisticated deicing systems on large airplanes. Icing can increase an aircraft's weight but not typically enough to cause a hazard. The main danger comes from the ice changing the shape of its airfoils. \nThis will reduce lift and increase drag. All three factors increase stalling speed and reduce aircraft performance, making it very difficult to climb or even maintain level altitude.\n\nAn aircraft can most easily avoid freezing rain by moving into warmer air — under most conditions, this would require aircraft to descend, which it can usually do safely and easily even with a moderate accumulation of structural ice. However, freezing rain is accompanied by a temperature inversion aloft, meaning that aircraft actually need to \"climb\" to move into warmer air — a potentially difficult and dangerous task with even a small amount of ice accumulation.\n\nFor example, in 1994, American Eagle Flight 4184 encountered heavy air traffic and poor weather that postponed the arrival of this flight at Chicago's O'Hare International Airport, where it was to have landed en route from Indianapolis, Indiana. The ATR-72, a twin-engine turboprop carrying 68 people, entered a holding pattern southeast of O'Hare. As the plane circled, supercooled cloud droplets, freezing rain or freezing drizzle formed a ridge of ice on the upper surface of its wings, eventually causing the aircraft's autopilot to suddenly disconnect and the pilots to lose control. The ATR disintegrated on impact with a field below; all passengers and crew were killed.\n\n\n"}
{"id": "1420831", "url": "https://en.wikipedia.org/wiki?curid=1420831", "title": "Fuel gas", "text": "Fuel gas\n\nFuel gas is any one of a number of fuels that under ordinary conditions are gaseous. Many fuel gases are composed of hydrocarbons (such as methane or propane), hydrogen, carbon monoxide, or mixtures thereof. Such gases are sources of potential heat energy or light energy that can be readily transmitted and distributed through pipes from the point of origin directly to the place of consumption.\n\nFuel gas is contrasted with liquid fuels and from solid fuels, though some fuel gases are liquefied for storage or transport. While their gaseous nature has advantages, avoiding the difficulty of transporting solid fuel and the dangers of spillage inherent in liquid fuels, it also has limitation. It is possible for a fuel gas to be undetected and collect in certain areas, leading to the risk of a gas explosion. For this reason, odorizers are added to most fuel gases so that they may be detected by a distinct smell.\n\nThe most common type of fuel gas in current use is natural gas.\n\nThere are two broad classes of fuel gases, based not on their chemical composition, but their source and the way they are produced: those found naturally, and those manufactured from other materials.\n\nManufactured fuel gases are those produced through an artificial process, usually gasification, at a location known as a gasworks.\n\nManufactured fuel gases include:\n\nIn the 20th century, natural gas, composed primarily of methane, became the dominant source of fuel gas, as instead of having to be manufactured in various processes, it could be extracted from deposits in the earth. Natural gas may be combined with hydrogen to form a mixture known as HCNG.\n\nAdditional fuel gases can result as a process of refining natural gas or petroleum:\n\nFuel gases have been used in numerous applications. One of the earliest was gas lighting, which enabled the widespread adoption of streetlamps and the illumination of buildings in towns with a municipal gas supply. Fuel gas is also used in gas burners, in particular the Bunsen burner used in laboratory settings. It may also be used gas heaters, camping stoves, and even to power vehicles, they have high calorific value.\n"}
{"id": "31424530", "url": "https://en.wikipedia.org/wiki?curid=31424530", "title": "GasHole", "text": "GasHole\n\nGasHole is a documentary film about the history of oil prices and the future of alternative fuels. The film was completed in 2008, premiered and released directly to DVD in 2010. The film details the dependency of the United States on foreign supplies of oil. The documentary is directed by Scott D. Roberts and Jeremy Wagener and narrated by Peter Gallagher.\n\nThe movie begins showing video clips of speeches by presidents from Nixon to George W. Bush talking about how the United States needs to be less dependent on other countries for oil. Nixon even says that he wants to break the oil companies. Despite all this talk the U.S. is still dependent.\n\nNext the movie talks about a \"water-injected\" 1946 Buick Roadmaster that got 100 miles per gallon of gasoline. The gas was humidified and the pressure increased to get better mileage. The movie states that Shell Oil bought this idea and asked if they buried it. In 1977 the book \"Fuel Economy of the Gas Engine\" by Shell scientists states that they got 150 mpg in a 1947 Studebaker. On May 1, 1977, The \"El Paso Times\" ran a front page article with the headline \"200 Miles on 2 Gallons of Gas\". Tom Ogle, the subject of the article, was found in the desert, dead from a drug overdose, and his car disappeared. The movie does not make any effort to ascertain the veracity of the water-injected engine or other facts.\n\nAfter Hurricane Katrina, the energy committees in both the Senate and the House hold hearings about the sudden rise in gasoline prices, the first time that they have gone over $3 per gallon. One Congressman asks if the oil companies are taking advantage. One chairman of a committee decides not to swear in the CEOs of the oil companies, alleviating them of the requirement to tell the truth. Senator Gordon H. Smith, R-Ore., observes that no Gulf crude is used on the West Coast, yet gas prices spiked there as well. On November 10, 2005, the Chevron Oil Company is quoted as saying, \"If the U.S. petroleum industry doesn't reduce its refining capacity, it will never see any substantial increase in refining margins.\" Representative Nancy Pelosi, D-Cal., states in a committee hearing that Shell is closing a refinery in California that produces 2% of the gas used in the state, that it is Shell's most profitable refinery, and that Shell's claims that the refinery has no buyers, is not reliable and not making money are all not true, that Shell wants to control the supply of gas in order to increase profits.\n\nOn May 11, 2006, during the House Energy Committee meeting, Representative Anna Eshoo, D-Cal., asks why, if Exxon is not building in the U.S., are they looking for new ways to invest record profits. Joe Barton, R-Tex., the committee's chairman, answers that it is a low blow to use what ExxonMobil actually said against them. Next he is seen stating that as long as he is chairman, global warming is off the table. Since 1990 the oil companies have given $49 million to Democrats and $150 million to Republicans. Since January 2001 when George W. Bush became president until May 2007, the average U.S. price of a gallon of gas has risen from $1.47 to $3.12. One person interviewed in the movie questions whether it is a good idea to have both a president and vice president who are close to the oil industry.\n\n\n\n"}
{"id": "28784839", "url": "https://en.wikipedia.org/wiki?curid=28784839", "title": "Giant current ripples", "text": "Giant current ripples\n\nGiant current ripples are active channel topographic forms up to 20 m high, which develop within near-talweg areas of the main outflow valleys created by glacial lake outburst floods. Giant current ripple marks are morphologic and genetic macroanalogues of small current ripples formed in sandy stream sediments.\n\nThe giant current ripple marks are important depositional forms in diluvial plain and mountain scablands.\n\nThe history of the scabland studies has two distinct stages: the \"old\" one that began with the first works by J Harlen Bretz and Joseph Pardee in North America and lasted until the end of the 20th century that was crowned with the discovery of giant current ripple marks in Eurasia, and a \"new\" one. The latter is associated with heated debates concerning the genesis of the relief under study and which involved a lot of Russian geologists, geomorphologists and geographers. The discussion about the origin of the giant ripples dealt at least to a certain extent with every aspect of the diluvial theory, from the genesis of the lakes themselves, their existence duration, possibilities of their cataclysmic failures, etc. to the origin of the diluvial forms - the aspects that have been accepted by many scientists worldwide, including an increasing number of Russian scientists.\n\nJ Harlen Bretz, author of the hypothesis of the diluvial origin of the Channeled Scabland, considered mainly \"giant gravel bars\" (diluvial ramparts and terraces) among the diluvial-accumulative formations as a proof of his case along with the destructive forms of the scabland (gorges-coulees, waterfall cataracts – chains of erosional dry falls washed of loose sediments by the floods of diluvial farewell rocks).\nIt was only after J. T. Pardee's report in Seattle at the Session of the American Association for the Advancement of Science in 1940 that the expression \"giant current ripples\" was introduced in the modern meaning. J. Pardee gave brief characteristics to the forms found by him already in the early 20th century while researching the Late Pleistocene lake Missoula. J. Pardee, who was the discoverer of this lake and named it, had kept silent for over thirty years until his retirement about cataclysmic outbursts of the giant North-American ice-dammed lakes in the Pleistocene. As already mentioned, the \"official\" American geology represented by the United States Geological Survey, which strictly controlled all scientific studies, strongly objected to J H. Bretz's hypothesis in the early 20th century. J. Pardee was a member of this organization. Even the title \"Ripple marks (?) in the glacial lake Missoula\" of Pardee's report proves the great significance attached by Pardee to the relief he discovered a few decades ago as an instrument for the reconstruction of Late Quaternary diluvial palaeohydrology in North America. Thus, it is this scientist's name that we should associate with the discovery and correct genetic interpretation of the relief of giant current ripples. After Pardee's publication in 1942, giant current ripples have been found practically everywhere on the territory of the basaltic Columbia Plateau (this was the direction of the cataclysmic outbursts of Missoula and other ice-dammed lakes).\n\nA special study of the geomorphology and palaeohydrology of the American scabland was begun by Victor Baker. It was Baker who mapped all main fields of giant current ripples known today in America, and it was he who made first attempts to gain chief hydraulic characteristics of the Missoula floods according to the multiple measurements of paired parameters of diluvial dunes and their mechanical composition. Some other so far known means had certainly been used for the purpose as well since Bretz's times, in particular, the functional dependences by Schezi and Manning. However, those dependences estimated velocities and discharges of the floods at the channel line, and the data received, although imprecise, were tremendous. V. R. Baker calculated the palaeohydraulic data over the ripple fields, i.e. over the sites distanced from the channel line and (or) on wane of the floods, where the current velocities of the diluvial streams admittedly must have been less than maximum ones (all the same, they were hundreds of thousands of cubic metres per second).\n\nFor nearly sixty years the well-known ice-dammed Lake Missoula (and other well-known North-American ice-dammed lakes) and its cataclysmic outbursts was considered as a unique one in the world's scientific literature. Special tourist routes were organised at most impressive sites of \"giant vessels\", canyons-coulees, vast fields of giant current ripples and others. Here professional guides tell the tourists about hydrospheric catastrophes which took place in the ice ages in America.\n\nThe discovery of the relief of giant current ripples in the Altai and Tuva and its correct diagnostics began a new stage in the paleogeographical research of the continents, a broad international cooperation and initiated new conclusions which have cleared up a lot of questions in the Quaternary geology and Paleohydrology of Pleistocene in Eurasia.\n\nAlong with the development of the ideas about enormous dimensions and a big role of Pleistocene glacier-dammed lakes and their cataclysmic outbursts, a new branch of the scientific research which was called by the British geologist P. A. Carling \"flood deposit sedimentology\" is becoming more and more notable. In Russia in the middle 1990s the geological objects formed by the diluvial floods — floodstreams — were referred by the author to the research objects of Quaternary glaciohydrology based on the theory of the diluvial morpholithogenesis.\n\nIn Russia nobody had known anything about the regime of ice-dammed lakes until the 1980s and, of course, had not looked for any traces of their failures, either. Although some lake terraces of the basinal preglacial bodies of water in the mountains of South Siberia were mapped in the early 20th century (it was done incidentally during some geological and botanical investigations), the question of the evacuation mechanisms of these lakes did not even arise. As a matter of fact, this question was (and by someones is still) considered rhetorical: since there are strandlines on the sides of the depressions, then the lakes used to dry gradually and slowly. Moreover, in some authors' opinions, the lakes appeared in the depressions, in particular in the Altai, only once, at the most – twice. And when such lake terraces could be poorly distinguished, if any at all, in the depressions, then the question of the lakes did not arise: there were not any lakes.\n\nNevertheless, in the late 1950s G. F. Lungershausen and O. A. Rakovets were the first to give a correct interpretation to a \"mysterious\" ridge-and-pading relief in Kuray intermountain depression. These scientists were the first to correctly define the genesis of the relief in the depression and to assume, according to the orientation of the diluvial dunes, the eastern direction of the runoff of the rivers, which is opposite to the contemporary one, at some moment in the history of the Altai. The genetic diagnostics of the giant ripples in the Kuray Basin had a general character and was essentially limited to the terminologically correct definition only (in fact, the purpose of the article of the authors mentioned was different). The article explained the origin of the direction of the water torrents proper by some neotectonic reasons.\n\nThe notice made by G.F. Lungershausen and O.A. Rakovets about the diluvial origin of giant ripple marks in Kuray was denied by E.V. Deviatkin, who referred to an oral conclusion made by E.V. Shantser and wrote that the large ripple marks in Kuray Basin were results of heavy erosional processing of a huge fluvioglacial fan. M.V. Petkevich expressed a similar opinion in her candidate thesis. She believed that the ridged relief on the right bank of the Tetio River in Kuray Basin was a washed proluvial fan.\n\nEvery single diagnostic sign of the giant ripples given in the corresponding section contradict this theory, especially the cross-layered texture of the sediments in the ripple marks which correlates with their morphology and the regular asymmetry of their slopes at all the locations. The petrography composition of the coarse-fragmental material in the ripple marks witnesses also against this hypothesis, it is alien to the bed rock of the basins of the Tetio and the Aktru rivers.\n\nIn addition, G.G. Rusanov found malachite, axinite, sillimanite and cinnabar in the schlichs of the ripple marks in Kuray Basin, which are characteristic of the Kuray Ridge but not found in the schlichs of the end moraines of the Tetio River, the latter adjoining the fields of the giant ripples. Cinnabar is a heavy, fragile and quickly worn mineral. That is why, as G.G. Rusanov remarks, it cannot be carried away from its original source farther than over first hundreds of metres. Over longer distances this mineral can be transported only in suspension state. At the same time, galena, which is very characteristic of the moraines of the Tetio and the Aktru Valleys, is not found in the ripple sediments. Hence, pebble deposits adjoining the end moraines of the Tetio cannot be fluvioglacial or proluvial formations of the meltwater from the glaciers of the Aktru and the Tetio.\n\nAt that time P.A. Okishev flatly disagreed with his predecessors and contemporaries. He argued that the proofs of the erosional extension of a vast fluvioglacial fan here (in Kuray Basin) are unconvincing. In 1970 P.A. Okishev put forward the idea that the giant current ripple marks in Kuray depression are \"inversional formations\". \"The ridges presently expressed in the relief used to accumulate as channel sediments within above-glacial floods of a vast flat glacial field and projected afterwards onto the substratum\" (, p. 49).\n\nA. N. Rudoy shall point out in this quotation that 1) P.A. Okishev simply described, though superficially, the mechanism of the eskers, and 2) he emphasised the fluvial, channel origin of the ridges proceeding from their material composition and morphology.\nThis investigator developed his theory later in his book and his doctoral thesis (1984), but practically at the same time he put forward another hypothesis, a \"glacial\" one, without explaining anything or mentioning the \"inversional relief\". P.A. Okishev wrote that the giant current ripples in Kuray Basin are \"bedded, small-ridged, poly-ridged\" moraines. The \"inversional relief\" was forgotten by the author for ever and has never been mentioned again.\nThis author's unclear explanations of the essence of his second \"moraine\" hypothesis (he would have a third one as well) may be regarded in general as an attempt \"to introduce something new\" into the works by B.A. Borisov and E.A. Minina who, after many years of their geological surveys in the mountains of southern Siberia, discovered and described the relief of \"a washing board\" (the phase of the rogen moraine according to the classification by Yu. A. Lavrushin. B.A. Borisov and E.A. Minina ascribed the relief of giant current ripples of all the districts where it had been found, described and more or less studied to that relief of the ribbed moraine, the latter really exists in many ancient glacial mountainous valleys of Siberia, Middle Asia and in other mountains.\n\nThe first investigator in Russia who not only correctly defined the genesis of the giant current ripples (we shall remind that this was done first by G.F. Lungershausen and O.A. Rakovets about twenty-five years before that time) but also described their composition and reconstructed (in a complex with other flood forms) palaeoglaciohydrology of the region of the geological surveys was V.V. Butvilovsky. However, his discovery was made far from the region where nowadays \"lances are being broken\". It was in the valley of the Bashkaus River in the Easter Altai]. As a matter of fact, V.V. Butvilovsky managed to describe the whole palaeohydrologic scenario of the last glacial age based on a small district, which corresponds well to the modern ideas about glacial palaeohydrology of the dryland. He also showed that the Quaternary ice-dammed lake of Tuzhar Village discovered by him outburst into the valley of the Chulyshman River after having reached its critical level. He emphasised that in the valley of the Bashkaus River and the Chulyshman River there was only one but very powerful superflood with its maximum discharge of about 880 000 m3/s (the calculation was done according to the formula by Schezi). Later on, V.V. Butvilovsky developed his ideas and defended them in his doctoral thesis [Butvilovsky, 1993].\nWhen working in the Central and South-Eastern Altay, A. N. Rudoy studied in this years the largest in the Altay ice-dammed lakes of Chuya, Kuray and Uymon Basins (Butvilivsky was in the 1970s his student in Tomsk State University). In autumn 1983 Rudoy carried out some field research on the left bank site of the Katun River which is now known as \"the field of giant current ripples of Platovo-Podgornoje\". The result of the research was the first published work dedicated to the multiple cataclysmic outbursts of those tremendous Pleistocene ice-dammed lakes. That work was the first to give a detailed description of the structure of the relief of the giant current ripples at the foothills. Also the first attempt was made to define the palaeohydraulic characteristics of the diluvial floods according to the morphologic peculiarities of the ripples and their material composition.\nIn the early and middle 1980s special filed studies headed by the Alexei Rudoy were carried out at the discovered sites of the fields of the giant current ripples, four of which have become key ones in the course of time, i.e. they have been specially studied for many years by professionals from different countries and of different specialities. These key sites include: the location of giant current ripples of Platovo-Podgornoje; the location of diluvial dunes of the Little Yaloman – the Inia; the field of the giant current ripples in the central part of Kuray Basin and the diluvial dunes at the Basin (in Russian: urochishtshe) Kara-Kol on its western raised periphery.\n\nSome reconstruction of the regime of the last glacial age, estimates of the glacial runoff at its maxima and post-maxima, on the one hand, and the discovery of the diluvial morpholithocomplex on the other hand, enabled us already at the late 1980s to outline a common palaeoglaciohydrologic situation of the Glacial Pleistocene for those territories of the Earth where the oroclimatic condition were similar to those of the mountains of Siberia. At the same time M.G. Grosswald described and physically interpreted for the first time fields of giant current ripples not in the Altai only but also in the intermountain depressions of Tuva and in the valleys of the Upper Yenisei. Nowadays these fields are also studied by international expeditions, some works paying a special attention to the giant ripple marks on the Sayany-Tuva table-land have been already published.\n\nIn early 1990s first international expeditions which specially studied the diluvial morpholithologic complex in Asia. Their purpose was to compare main palaeohydromorphologic characteristics of mountain scablands of Central Asia which had been already developed in Russia by that time with those of the known plain diluvial associations of the Channeled Scabland territory in North America. The participants of those first expeditions were specialists from Russia (M.R. Kirianova, A.N. Rudoy), the United States (V.R. Baker), Great Britain (P.A. Carling), Germany (K. Fischer and M. Kuhle) and Switzerland (Ch. Siegenthaler).\n\nIn the second half of 1990s and at the beginning of the 21st century (until the field season of 2010) P.A. Carling carried out some more special expeditions in the Altai, their results were summed up in a cooperative work.\n\nLater, a group of German sedimentologists under the direction of Ju. Herget worked successfully in the Altai. Several big articles presented the refined data of the palaeohydraulic parameters of the diluvial floods in the river valleys of the Chuya River and Katun River.\n\nIn 1998 S.V. Parnachov defended his candidate thesis based on the analysis of some well-known sections of the diluvial terraces at the Katun River and the Chuya River, as well as on the data by P.A. Carling and conclusions of his own. The thesis paid a certain amount of attention to the key locations of the fields of giant current ripples discovered before. The investigator fulfilled, in particular, the petrographic and granulometric analyses of the clastic material of the giant ripples at the key sites. S.V. Parnachov based himself on the calculations of the jökulhlaup discharges by P.A. Carling – 750,000 m per second – and came to the conclusion that there were no fluvial catastrophes but there were several lake outbursts with the discharges not higher than those of contemporary big rivers. Instead of the diluvial sediments this author suggested a new geological formation – the \"flood alluvium\".\n\nConsequently, S.V. Parnachov distinguished the \"flooding period\" in the Altay of about 150 000 years long. The genesis of the basinal lakes, however, S.V. Parnachov admitted so far as ice-dammed one.\nTwo years later I.S. Novikov joined the investigations by S.V. Parnachov. These geologists drew a conclusion that \"the glaciers could not\" dam themselves such big lake depressions, consequently the dams were \"ice-tectonic\" ones. So, according to the authors quoted, during the \"flooding period\" that lasted for about 150 000 years there were no less than seven cataclysmic flooding occurrences associated with the outbursts of the palaeolakes. Moreover, a tectonic obstacle also played a role in the damming of the lakes during the very last degradation phases of the Würm glacier.\n\n\"New antidiluvialists\" have put forth alternate explanations to the giant current ripples theory.\n\n\nWhile the Russian science is discussing the genesis of the giant current ripples at the just briefly described scientific level, American and British geologists and planetologists have discovered such reliefs on Mars according to the data on the giant current ripples in the Altai and even calculated the hydraulic parameters of those diluvial floods.\n\nUp to the present, hundreds of locations of the fields of giant current ripples have been discovered in North America and Northern Asia. Here is a brief description of main characteristics of this relief and its sediments at the key, today most often visited, sites in the Altai and Tuva with the necessary references to the chief publications for the other territories.\n\n\nUnfortunately, no diagnostic features of the lithology of giant current ripples have been cleared up, yet, that could differentiate the latter from other genetic types of loosed sediments in sections. The presence of cross-bedded series in some layers with evidently fluvial genesis which were diagnosed by V.V. Butvilovsky as buried ripples (e.g. an exposure in a pit near the mouth of the Isha River, etc.) does not look as remarkable in the nature as it is described by the author. A. N. Rudoy used to work for a long time at this and similar exposures (e.g. by the settlement of Karlushka). Nothing, except the fact of the cross dipping of fluvial boulder pebbles, can tell the investigator that he sees some buried giant current ripples. One can nothing but assume this. And an abrupt dipping of bedded alluvial channel fractions is a very often seen phenomenon. The problem of diagnosing diluvial sediments in a buried state, i.e. without any geomorphological control, may apparently be solved not only, if at all, by studying peculiarities of the diluvial texture, but by means of the microscopic lithological studies of the sediments of giant current ripples, i.e. mineralogy of fine fractions, grain shapes, analysis of accessories, etc. Then these correctly summarised data must be compared with various phases of the contemporary mountainous alluvium at the analogous sections.\n\n\n"}
{"id": "10939879", "url": "https://en.wikipedia.org/wiki?curid=10939879", "title": "Gilavar", "text": "Gilavar\n\nGilavar is a name of the warm southern wind which blows across eastern Azerbaijan throughout the year, particularly in Baku and Shamakhi. Gilavar is one of the two main winds that dominates Baku, along with Khazri, the cold northern wind.\n"}
{"id": "7469344", "url": "https://en.wikipedia.org/wiki?curid=7469344", "title": "Hyperaccumulators table – 2 : Nickel", "text": "Hyperaccumulators table – 2 : Nickel\n\nThis list covers known nickel hyperaccumulators, accumulators or plant species tolerant to nickel.\n\nSee also:\n\nNotes\n\n\n"}
{"id": "30873922", "url": "https://en.wikipedia.org/wiki?curid=30873922", "title": "Laff-A-Lympics", "text": "Laff-A-Lympics\n\nLaff-A-Lympics is an American animated comedy television series produced by Hanna-Barbera Productions. The series premiered as part of the Saturday morning cartoon program block, \"Scooby's All-Star Laff-A-Lympics\", on ABC in 1977. The show is a spoof of the Olympics and the ABC primetime series \"Battle of the Network Stars\", which debuted one year earlier. It featured 45 Hanna-Barbera characters organized into the teams (the Scooby Doobies, the Yogi Yahooeys, and the Really Rottens) which would compete each week for gold, silver, and bronze medals. One season of 16 episodes was produced in 1977–78, and eight new episodes combined with reruns for the 1978–79 season as \"Scooby's All-Stars\". Unlike most cartoon series produced by Hanna-Barbera in the 1970s, \"Laff-A-Lympics\" did not contain a laugh track. \"Scooby’s Laff-a-Lympics\" was originally owned by Taft Broadcasting, Warner Bros. Television Distribution currently owns the series thru its two in-name-only units, Warner Bros. Family Entertainment and Turner Entertainment.\n\nThe sporting competitions in which the characters are called upon to compete is often a comical or offbeat version of Olympic sports, races, or scavenger hunts. Each segment is set in a different location around the world.\nEpisodes are presented in a format similar to an Olympic television broadcast, with an unseen announcer. Hosting duties and commentary are provided by Snagglepuss and Mildew Wolf from the \"It's the Wolf!\" segments of \"Cattanooga Cats\" (voiced by John Stephenson rather than Paul Lynde). Snagglepuss and Mildew wear animated versions of the contemporary yellow jackets of ABC Sports announcers. Other Hanna-Barbera characters such as Fred Flintstone, Barney Rubble, Jabberjaw and Peter Potamus made appearances as guest announcers and judges. Other non-competing characters include parents of contestants (interviewed by Mildew before events) and various monsters and creatures that serve as antagonists during events.\n\nThe \"good guy\" teams, consisting of the Yogi Yahooeys and the Scooby Doobies, are cooperative and loyal. The Really Rottens, however, always cheat. Typically the Really Rottens will be poised to win before making a fatal error at the last moment, allowing one of the other two teams to end up on top. Occasionally, though, the Rottens' cheating was not actually against the rules, resulting in their winning. (Overall, the Scooby team dominated, winning 14 times, against 7 victories for the Yahooies, 2 for the Rottens, and a three-way-tie in the final episode.)\n\nOnly one complete season of \"Laff-A-Lympics\" episodes was produced, with eight new episodes combined with reruns for the second season of \"Scooby's All Star Laff-A-Lympics\" (billed as \"Scooby's All-Stars\"). When it premiered in the fall of 1977, the series consisted of several segments, including \"Captain Caveman and the Teen Angels\" (which led the two-hour program and later was spun-off into its own half-hour show), \"The Scooby-Doo Show\" and \"Dynomutt\" (both of which featured a small number of newly produced segments alongside repeated segments from earlier seasons) and the \"Laff-A-Lympics\" segments themselves. The show resurfaced in 1980 as a half-hour series on its own (without the \"Captain Caveman\", \"Scooby-Doo\" and \"Dynomutt\" cartoons) simply titled \"Laff-A-Lympics\" and was later rerun on ABC in 1986. In later years it has been frequently rerun on USA Cartoon Express, Cartoon Network and Boomerang, often during the time periods when the Summer and Winter Olympics were held (until 2014).\n\nThis team drew mainly from the 1970s Hanna-Barbera cartoons, particularly the \"mystery-solving\" series derived from \"Scooby-Doo\", whose titular character served as team captain. The early production art for the series showed Jeannie from the \"Jeannie\" series and Melody, Alexander, Alexandra, and Sebastian the Cat from \"Josie and the Pussycats\" as members of the \"Scooby Doobies\" team. However, legal problems with Columbia Pictures Television, Screen Gems' successor, prevented this. Hanna-Barbera owned Babu, but Columbia controlled all rights to Jeannie's image. As a result, Babu appeared alone as a member of the \"Scooby Doobies\". Similarly, Archie Comics held the rights to the \"Josie\" characters. In the actual series, Jeannie is replaced by Hong Kong Phooey and the \"Josie\" characters were replaced by characters from \"Captain Caveman and the Teen Angels\".\n\nAmong the members of the Scooby Doobies are:\n\nThis team drew mainly from the 1950s and 1960s Hanna-Barbera cartoons and is the only team of characters made up completely of anthropomorphic animals. Grape Ape is the only post-1962 character in the line-up.\n\nAmong the members of the Yogi Yahooeys are:\n\nThis team is composed of villainous characters that frequently cheated by either giving themselves an unfair advantage in a contest or sabotaging the other teams (and usually had points deducted from their score as a result). With the exception of Mumbly and the Dalton Brothers, all of the members are original characters, many of whom are based on various characters that appeared in cartoons and comics prior to \"Laff-A-Lympics\". Originally, Muttley and Dick Dastardly were planned as the leaders of the Really Rottens; however, they could not appear as those characters were co-owned by Heatter-Quigley Productions. In their place, Hanna-Barbera used the existing character Mumbly and created the new character Dread Baron. Prior to \"Laff-A-Lympics\", on his original show, Mumbly was a heroic detective rather than a villain. Following the character's revision as the villainous team leader, he remained a villain in \"Yogi Bear and the Magical Flight of the Spruce Goose\", which is also Dread Baron's only other role. The Dalton Brothers appeared in 1950s and 1960s shorts (including the 1958 short \"Sheriff Huckleberry Hound\", which featured appearances by Dinky, Dirty, and Dastardly Dalton, as well as their other brothers Dangerous, Detestable, Desperate, and Despicable). However, they were given new character designs for the \"Laff-A-Lympics\" series. After \"Laff-A-Lympics\", Dinky reappears in \"The Good, the Bad, and Huckleberry Hound\" with brothers Stinky (who bears a resemblance to Dastardly Dalton from \"Laff-A-Lympics\"), Finky, and Pinky.\n\nAmong the members of the Really Rottens are:\n\n\n\nIn 1996, four VHS editions of the show were released in the US on the NTSC format, each containing two episodes for a running time of approximately 50 minutes:\n\nAt the same time a \"bumper special\" VHS tape was released in UK on the PAL format containing the following episodes (These UK episodes were the US episodes divided in two, with just one location per episode):\n\nWarner Home Video (via Hanna-Barbera Productions and Warner Bros. Family Entertainment) released episodes 1–4 on Region 1 DVD on January 19, 2010, as \"Scooby's All-Star Laff-A-Lympics - Volume 1\". Episodes 5–9 were on a second DVD titled \"Scooby's All-Star Laff-A-Lympics - Volume 2\", released the same day by Target and by other stores on October 19, 2010. A two-disc DVD set entitled \"Scooby-Doo! Laff-A-Lympics: Spooky Games\" was released on July 17, 2012. The set contains an all-new Scooby Doo special, \"Spooky Games\", plus 12 episodes of Laff-a-Lympics – including episodes 9–16, which complete the first season, plus 4 earlier first-season episodes which appear on Volume 1 and 2. The set also includes an UltraViolet digital copy of the 12 contained episodes. Later in the year Warner Brothers shop renamed this release \"Laff-a-Lympics: The Complete First Collection\".\n\nOn July 4, 2016, Volume 1 and Volume 2 were released separately in Region 2, as was a 'Gold Edition' with the previously released \"Spooky Games\" DVD; this Region 2 version of the \"Scooby-Doo! Laff-A-Lympics: Spooky Games\" DVD is only a separate version of the first disc from the R1 set, containing \"Spooky Games\" and four further episodes; therefore, only twelve episodes are currently available in R2, as of July 2016.\n\nRegion 4 received Volume 1 and 2 in July 2010.\n\nIn March 1978, Marvel Comics produced a comic book series based on the cartoon. Creative staff for the comic book included Mark Evanier, Carl Gafford, Scott Shaw, Jack Manning, Owen Fitzgerald and others. The series lasted 13 issues. A \"Laff-A-Lympics\" comic book was also published in Australia in 1978 by Sydney-based K.G. Murray Publishing Company. From 1980 to 1982, various \"Laff-A-Lympics\" stories were reprinted in \"Laff-A-Lympics Annual\" hardback books in the United Kingdom by Fleetway.\n\nAn updated Laff-A-Lympics called the \"Superstar Olympics\" appeared in \"Hanna-Barbera Presents\" #6 in 1996. The Superstar Olympics featured Atom Ant, Augie Doggie and Doggie Daddy, Barney Rubble, Betty Rubble, Boo Boo Bear, Chopper, Cindy Bear, Dick Dastardly, Fred Flintstone, Grape Ape, Hokey Wolf, Huckleberry Hound, Jabberjaw, Magilla Gorilla, Muttley, Peter Potamus, Pixie and Dixie and Mr. Jinks, Quick Draw McGraw, Ranger Smith, Secret Squirrel, Snagglepuss, Snooper and Blabber, Squiddly Diddly, Top Cat, Touché Turtle, Wally Gator, Wilma Flintstone, and Yogi Bear.\n\nA \"Laff-A-Lympics\" hand-held pinball game was released in 1978. The game featured Scooby-Doo, Captain Caveman and the Teen Angels, Blue Falcon, Yogi Bear, Boo-Boo Bear, Huckleberry Hound, Grape Ape, Mumbly, Dread Baron, Mr. Creepley, Dalton Brothers, Snagglepuss, and Mildew Wolf.\n\nIn 1979, Hanna-Barbera released a \"Laff-A-Lympics\" Old Maid card game that included Scooby-Doo, Shaggy Rogers, Dynomutt, Blue Falcon, Hong Kong Phooey, Yogi Bear, Boo-Boo Bear, Huckleberry Hound, Grape Ape, Quick Draw McGraw, Pixie and Dixie, Yakky Doodle, Mumbly, Dread Baron, Snagglepuss, and Mildew Wolf.\n\n\n"}
{"id": "21438242", "url": "https://en.wikipedia.org/wiki?curid=21438242", "title": "Lava", "text": "Lava\n\nLava is molten rock generated by geothermal energy and expelled through fractures in planetary crust or in an eruption, usually at temperatures from . The structures resulting from subsequent solidification and cooling are also sometimes described as \"lava\". The molten rock is formed in the interior of some planets, including Earth, and some of their satellites, though such material located below the crust is referred to by other terms.\n\nA lava flow is a moving outpouring of lava created during a non-explosive effusive eruption. When it has stopped moving, lava solidifies to form igneous rock. The term \"lava flow\" is commonly shortened to \"lava\". Although lava can be up to 100,000 times more viscous than water, lava can flow great distances before cooling and solidifying because of its thixotropic and shear thinning properties.\n\nExplosive eruptions produce a mixture of volcanic ash and other fragments called tephra, rather than lava flows. The word \"lava\" comes from Italian, and is probably derived from the Latin word \"labes\" which means a fall or slide. The first use in connection with extruded magma (molten rock below the Earth's surface) was apparently in a short account written by Francesco Serao on the eruption of Vesuvius between May 14 and June 4, 1737. Serao described \"a flow of fiery lava\" as an analogy to the flow of water and mud down the flanks of the volcano following heavy rain.\n\nThe composition of almost all lava of the Earth's crust is dominated by silicate minerals, mostly feldspars, olivine, pyroxenes, amphiboles, micas and quartz.\n\nIgneous rocks, which form lava flows when erupted, can be classified into three chemical types: \"felsic\", \"intermediate\", and \"mafic\" (four if one includes the super-heated \"ultramafic\"). These classes are primarily chemical, however, the chemistry of lava also tends to correlate with the magma temperature, its viscosity and its mode of eruption.\n\n\"Felsic\" or silicic lavas such as rhyolite and dacite typically form lava spines, lava domes or \"coulees\" (which are thick, short lava flows) and are associated with pyroclastic (fragmental) deposits. Most silicic lava flows are extremely viscous, and typically fragment as they extrude, producing blocky autobreccias. The high viscosity and strength are the result of their chemistry, which is high in silica, aluminium, potassium, sodium, and calcium, forming a polymerized liquid rich in feldspar and quartz, and thus has a higher viscosity than other magma types. Felsic magmas can erupt at temperatures as low as . Unusually hot (>950 °C; >1,740 °F) rhyolite lavas, however, may flow for distances of many tens of kilometres, such as in the Snake River Plain of the northwestern United States.\n\n\"Intermediate\" or andesitic lavas are lower in aluminium and silica, and usually somewhat richer in magnesium and iron. Intermediate lavas form andesite domes and block lavas, and may occur on steep composite volcanoes, such as in the Andes. Poorer in aluminium and silica than felsic lavas, and also commonly hotter (in the range of ), they tend to be less viscous. Greater temperatures tend to destroy polymerized bonds within the magma, promoting more fluid behaviour and also a greater tendency to form phenocrysts. Higher iron and magnesium tends to manifest as a darker groundmass, and also occasionally amphibole or pyroxene phenocrysts.\n\n\"Mafic\" or basaltic lavas are typified by their high ferromagnesian content, and generally erupt at temperatures in excess of . Basaltic magma is high in iron and magnesium, and has relatively lower aluminium and silica, which taken together reduces the degree of polymerization within the melt. Owing to the higher temperatures, viscosities can be relatively low, although still thousands of times higher than water. The low degree of polymerization and high temperature favors chemical diffusion, so it is common to see large, well-formed phenocrysts within mafic lavas. Basalt lavas tend to produce low-profile shield volcanoes or \"flood basalt fields\", because the fluidal lava flows for long distances from the vent. The thickness of a basalt lava, particularly on a low slope, may be much greater than the thickness of the moving lava flow at any one time, because basalt lavas may \"inflate\" by supply of lava beneath a solidified crust. Most basalt lavas are of \"ʻAʻā\" or \"pāhoehoe\" types, rather than block lavas. Underwater, they can form pillow lavas, which are rather similar to entrail-type pahoehoe lavas on land.\n\n\"Ultramafic\" lavas such as komatiite and highly magnesian magmas that form boninite take the composition and temperatures of eruptions to the extreme. Komatiites contain over 18% magnesium oxide, and are thought to have erupted at temperatures of . At this temperature there is no polymerization of the mineral compounds, creating a highly mobile liquid. Most if not all ultramafic lavas are no younger than the Proterozoic, with a few ultramafic magmas known from the Phanerozoic. No modern komatiite lavas are known, as the Earth's mantle has cooled too much to produce highly magnesian magmas.\n\nSome lavas of unusual composition have erupted onto the surface of the Earth. These include:\n\nThe term \"lava\" can also be used to refer to molten \"ice mixtures\" in eruptions on the icy satellites of the Solar System's gas giants. \"(See cryovolcanism).\"\n\nIn general, the composition of a lava determines its behavior more than the temperature of its eruption.\nThe viscosity of lava is important because it determines how the lava will behave. Lavas with high viscosity are rhyolite, dacite, andesite and trachyte, with cooled basaltic lava also quite viscous; those with low viscosities are freshly erupted basalt, carbonatite and occasionally andesite.\n\nHighly viscous lava shows the following behaviors:\n\nHighly viscous lavas do not usually flow as liquid, and usually form explosive fragmental ash or tephra deposits. However, a degassed viscous lava or one which erupts somewhat hotter than usual may form a lava flow.\n\nLava with low viscosity shows the following behaviors:\n\nLavas also may contain many other components, sometimes including solid crystals of various minerals, fragments of exotic rocks known as xenoliths and fragments of previously solidified lava.\n\nLava flow speeds vary based primarily on viscosity and slope. In general, lava flows slowly (0.25 mph), with maximum speeds between 6–30 mph on steep slopes. An exceptional speed of 20–60 mph was recorded following the collapse of a lava lake at Mount Nyiragongo.\n\nThe physical behavior of lava creates the physical forms of a lava flow or volcano. More fluid basaltic lava flows tend to form flat sheet-like bodies, whereas viscous rhyolite lava flows forms knobbly, blocky masses of rock.\n\nGeneral features of volcanology can be used to classify volcanic edifices and provide information on the eruptions which formed the lava flow, even if the sequence of lavas have been buried or metamorphosed.\n\nThe ideal lava flow will have a brecciated top, either as pillow lava development, autobreccia and rubble typical of \"aā\" and viscous flows, or a vesicular or frothy carapace such as scoria or pumice. The top of the lava will tend to be glassy, having been flash frozen in contact with the air or water.\n\nThe centre of a lava flow is commonly massive and crystalline, flow banded or layered, with microscopic groundmass crystals. The more viscous lava forms tend to show sheeted flow features, and blocks or breccia entrained within the sticky lava. The crystal size at the centre of a lava will in general be greater than at the margins, as the crystals have more time to grow.\n\nThe base of a lava flow may show evidence of hydrothermal activity if the lava flowed across moist or wet substrates. The lower part of the lava may have vesicles, perhaps filled with minerals (amygdules). The substrate upon which the lava has flowed may show signs of scouring, it may be broken or disturbed by the boiling of trapped water, and in the case of soil profiles, may be baked into a brick-red terracotta.\n\nDiscriminating between an intrusive sill and a lava flow in ancient rock sequences can be difficult. However, some sills do not usually have brecciated margins, and may show a weak metamorphic aureole on both the upper and lower surface, whereas a lava will only bake the substrate beneath it. However, it is often difficult in practice to identify these metamorphic phenomena because they are usually weak and restricted in size. Peperitic sills, intruded into wet sedimentary rocks, commonly do not bake upper margins and have upper and lower autobreccias, closely similar to lavas.\n\n\"Aā\" is one of three basic types of flow lava. Aā is basaltic lava characterized by a rough or rubbly surface composed of broken lava blocks called clinker. The Hawaiian word was introduced as a technical term in geology by Clarence Dutton.\n\nThe loose, broken, and sharp, spiny surface of an aā flow makes hiking difficult and slow. The clinkery surface actually covers a massive dense core, which is the most active part of the flow. As pasty lava in the core travels downslope, the clinkers are carried along at the surface. At the leading edge of an aā flow, however, these cooled fragments tumble down the steep front and are buried by the advancing flow. This produces a layer of lava fragments both at the bottom and top of an aā flow.\n\nAccretionary lava balls as large as are common on aā flows. Aā is usually of higher viscosity than pāhoehoe. Pāhoehoe can turn into aā if it becomes turbulent from meeting impediments or steep slopes.\n\nThe sharp, angled texture makes aā a strong radar reflector, and can easily be seen from an orbiting satellite (bright on Magellan pictures).\n\nAā lavas typically erupt at temperatures of .\n\nThe word is also spelled \"aa\", \"aa\", \"aa\", and \"a-aa\", and pronounced . It originates from Hawaiian where it is pronounced , meaning \"stony rough lava\", but also to \"burn\" or \"blaze\".\n\n\"Pāhoehoe\" ( or ; from Hawaiian , meaning \"smooth, unbroken lava\"), also spelled \"pahoehoe\", is basaltic lava that has a smooth, billowy, undulating, or ropy surface. These surface features are due to the movement of very fluid lava under a congealing surface crust. The Hawaiian word was introduced as a technical term in geology by Clarence Dutton.\n\nA pāhoehoe flow typically advances as a series of small lobes and toes that continually break out from a cooled crust. It also forms lava tubes where the minimal heat loss maintains low viscosity. The surface texture of pāhoehoe flows varies widely, displaying all kinds of bizarre shapes often referred to as lava sculpture. With increasing distance from the source, pāhoehoe flows may change into aā flows in response to heat loss and consequent increase in viscosity. Pahoehoe lavas typically have a temperature of .\n\nOn the Earth, most lava flows are less than long, but some pāhoehoe flows are more than long.\n\nThe rounded texture makes pāhoehoe a poor radar reflector, and is difficult to see from an orbiting satellite (dark on Magellan picture).\n\nBlock lava flows are typical of andesitic lavas from stratovolcanoes. They behave in a similar manner to ʻaʻā flows but their more viscous nature causes the surface to be covered in smooth-sided angular fragments (blocks) of solidified lava instead of clinkers. Like in ʻaʻā flows, the molten interior of the flow, which is kept insulated by the solidified blocky surface, overrides the rubble that falls off the flow front. They also move much more slowly downhill and are thicker in depth than ʻaʻā flows.\n\nLava domes and coulées are associated with felsic lava flows ranging from dacite to rhyolite. The very viscous nature of these lava cause them to not flow far from the vent, causing the lava to form a lava dome at the vent. When a dome forms on an inclined surface it can flow in short thick flows called coulées (dome flows). These flows often travel only a few kilometers from the vent.\n\n\"Pillow lava\" is the lava structure typically formed when lava emerges from an underwater volcanic vent or subglacial volcano or a lava flow enters the ocean. However, pillow lava can also form when lava is erupted beneath thick glacial ice. The viscous lava gains a solid crust on contact with the water, and this crust cracks and oozes additional large blobs or \"pillows\" as more lava emerges from the advancing flow. Since water covers the majority of Earth's surface and most volcanoes are situated near or under bodies of water, pillow lava is very common.\n\nBecause it is formed from viscous molten rock, lava flows and eruptions create distinctive formations, landforms and topographical features from the macroscopic to the microscopic.\n\nVolcanoes are the primary landforms built by repeated eruptions of lava and ash over time. They range in shape from shield volcanoes with broad, shallow slopes formed from predominantly effusive eruptions of relatively fluid basaltic lava flows, to steeply-sided stratovolcanoes (also known as composite volcanoes) made of alternating layers of ash and more viscous lava flows typical of intermediate and felsic lavas.\n\nA caldera, which is a large subsidence crater, can form in a stratovolcano, if the magma chamber is partially or wholly emptied by large explosive eruptions; the summit cone no longer supports itself and thus collapses in on itself afterwards. Such features may include volcanic crater lakes and lava domes after the event. However, calderas can also form by non-explosive means such as gradual magma subsidence. This is typical of many shield volcanoes.\n\nCinder cones and spatter cones are small-scale features formed by lava accumulation around a small vent on a volcanic edifice. Cinder cones are formed from tephra or ash and tuff which is thrown from an explosive vent. Spatter cones are formed by accumulation of molten volcanic slag and cinders ejected in a more liquid form.\n\nAnother Hawaiian English term derived from the Hawaiian language, a kīpuka denotes an elevated area such as a hill, ridge or old lava dome inside or downslope from an area of active volcanism. New lava flows will cover the surrounding land, isolating the kīpuka so that it appears as a (usually) forested island in a barren lava flow.\n\nLava domes are formed by the extrusion of viscous felsic magma. They can form prominent rounded protuberances, such as at Valles Caldera. As a volcano extrudes silicic lava, it can form an \"inflation dome\", gradually building up a large, pillow-like structure which cracks, fissures, and may release cooled chunks of rock and rubble. The top and side margins of an inflating lava dome tend to be covered in fragments of rock, breccia and ash.\n\nExamples of lava dome eruptions include the Novarupta dome, and successive lava domes of Mount St Helens.\n\nLava tubes are formed when a flow of relatively fluid lava cools on the upper surface sufficiently to form a crust. Beneath this crust, which being made of rock is an excellent insulator, the lava can continue to flow as a liquid. When this flow occurs over a prolonged period of time the lava conduit can form a tunnel-like aperture or \"lava tube\", which can conduct molten rock many kilometres from the vent without cooling appreciably. Often these lava tubes drain out once the supply of fresh lava has stopped, leaving a considerable length of open tunnel within the lava flow.\n\nLava tubes are known from the modern day eruptions of Kīlauea, and significant, extensive and open lava tubes of Tertiary age are known from North Queensland, Australia, some extending for .\n\nA lava fountain is a volcanic phenomenon in which lava is forcefully but non-explosively ejected from a crater, vent, or fissure. The highest lava fountains recorded were during the 1999 eruption of Mount Etna in Italy, which reached heights of . However, lava fountains observed during Mount Vesuvius' 1779 eruption are believed to have reached at least . Lava fountains may occur as a series of short pulses, or a continuous jet of lava. They are commonly associated with Hawaiian eruptions.\n\nRarely, a volcanic cone may fill with lava but not erupt. Lava which pools within the caldera is known as a lava lake. Lava lakes do not usually persist for long, either draining back into the magma chamber once pressure is relieved (usually by venting of gases through the caldera), or by draining via eruption of lava flows or pyroclastic explosion.\n\nThere are only a few sites in the world where permanent lakes of lava exist. These include:\n\nLava deltas form wherever sub-aerial flows of lava enter standing bodies of water. The lava cools and breaks up as it encounters the water, with the resulting fragments filling in the seabed topography such that the sub-aerial flow can move further offshore. Lava deltas are generally associated with large-scale, effusive type basaltic volcanism.\n\nLava flows are enormously destructive to property in their path. However, casualties are rare since flows are usually slow enough for people and animals to escape, though this is dependent on the viscosity of the lava. Nevertheless, injuries and deaths have occurred, either because they had their escape route cut off, because they got too close to the flow or, more rarely, if the lava flow front travels too quickly. This notably happened during the eruption of Nyiragongo in Zaire (now Democratic Republic of the Congo). On the night of 10 January 1977 a crater wall was breached and a fluid lava lake drained out in under an hour. The resulting flow sped down the steep slopes at up to , and overwhelmed several villages while residents were asleep. As a result of this disaster, the mountain was designated a Decade Volcano in 1991.\n\nDeaths attributed to volcanoes frequently have a different cause, for example volcanic ejecta, pyroclastic flow from a collapsing lava dome, lahars, poisonous gases that travel ahead of lava, or explosions caused when the flow comes into contact with water. A particularly dangerous area is called a lava bench. This very young ground will typically break-off and fall into the sea.\n\nAreas of recent lava flows continue to represent a hazard long after the lava has cooled. Where young flows have created new lands, land is more unstable and can break-off into the sea. Flows often crack deeply, forming dangerous chasms, and a fall against 'a'a lava is similar to falling against broken glass. Rugged hiking boots, long pants, and gloves are recommended when crossing lava flows.\n\nDiverting a lava flow is extremely difficult, but it can be accomplished in some circumstances, as was once partially achieved in Vestmannaeyjar, Iceland.\n\n\n\nTephra is volcanic ash, lapilli, volcanic bombs or volcanic blocks.\n\n\n"}
{"id": "10975134", "url": "https://en.wikipedia.org/wiki?curid=10975134", "title": "List of Canis species and subspecies", "text": "List of Canis species and subspecies\n\n\"Canis\", the genus of mammals commonly known as wolves, dingos, dogs, coyotes, and jackals, contains several living species, many divided into numerous subspecies, as well as numerous recently extinct and extinct prehistoric species.\n\nDomestic dogs are not usually granted taxonomic variety names below the level of either their species name, or subspecies name so they do not appear here with their popular breed names as individual entries. The New Guinea singing dog and any other varieties of subspecies appear as individual entries here when their taxonomic considerations now suggest that they are varieties of subspecies other than domestic dogs, such as of dingoes.\n\nReferences for taxonomic classification, issues, and current considerations, especially in light of DNA revelations year to year, are found in the articles on individual canids; as this article is only a list, the extensive literature and specifics of these issues for each canid are beyond the scope of reference notes here. Furthermore, articles on the species in this list's section headings, and details of their evolutionary, divergent, interbreeding, geolocational and human-culture mediated shifts contain references on which this list relies when including and positioning its entries. References to this article are thus of two sorts, those pertaining to wholesale sourcing of entries, especially those that don't yet have their own Wikipedia articles, and the far more extensive references in existing Wikipedia articles for each entry, header species, and other relevant taxon.\n\nCommon names from Kurtén and Anderson.\n\n"}
{"id": "5865364", "url": "https://en.wikipedia.org/wiki?curid=5865364", "title": "List of Clubionidae species", "text": "List of Clubionidae species\n\nThis page lists all described species of the spider family Clubionidae as of Dec. 21, 2016.\n\n\"Arabellata\" \n\n\"Carteroniella\" \n\n\"Carteronius\" \n\n\"Clubiona\" \n\n\"Clubionina\" \n\n\"Elaver\" \n\n\"Invexillata\" \n\n\"Malamatidia\" \n\n\"Matidia\" \n\n\"Nusatidia\" \n\n\"Pristidia\" \n\n\"Pteroneta\" \n\n\"Scopalio\" \n\n\"Simalio\" \n\n\"Tixcocoba\" \n\n"}
{"id": "52542996", "url": "https://en.wikipedia.org/wiki?curid=52542996", "title": "List of Crepidium species", "text": "List of Crepidium species\n\nThis is a list of the 292 accepted Species of the Genus Crepidium Blume (1825).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "57235243", "url": "https://en.wikipedia.org/wiki?curid=57235243", "title": "List of Local Nature Reserves in North Yorkshire", "text": "List of Local Nature Reserves in North Yorkshire\n\nThis is a list of Local Nature Reserves (LNR) in North Yorkshire. The list accounts for the post-1974 area of North Yorkshire, and includes the local authority areas of Middlesbrough and Redcar and Cleveland as well as the City of York. As such, it includes areas in places such as Harrogate, that prior to 1974, were in the historic county of the West Riding of Yorkshire.\n\nLocal Nature Reserves (LNRs) are designated by local authorities under the National Parks and Access to the Countryside Act 1949. The local authority must have a legal control over the site, by owning or leasing it or having an agreement with the owner. LNRs are sites which have a special local interest either biologically or geologically, and local authorities have a duty to care for them. They can apply local bye-laws to manage and protect LNRs. As of May 2018, North Yorkshire has 18 designated Local Nature Reserves.\n\n"}
{"id": "9017407", "url": "https://en.wikipedia.org/wiki?curid=9017407", "title": "List of Platanus diseases", "text": "List of Platanus diseases\n\nThis article is a list of diseases of trees in the genus Platanus (plane trees, also known in North America as sycamores).\n\n"}
{"id": "10909519", "url": "https://en.wikipedia.org/wiki?curid=10909519", "title": "List of United States energy acts", "text": "List of United States energy acts\n\nThis is a list of statutes enacted by the United States Congress pertaining to the energy industry.\n\n\n"}
{"id": "21813579", "url": "https://en.wikipedia.org/wiki?curid=21813579", "title": "List of films about nuclear issues", "text": "List of films about nuclear issues\n\nThis is a list of films about nuclear issues:\n\n\n\n"}
{"id": "6126726", "url": "https://en.wikipedia.org/wiki?curid=6126726", "title": "List of graminoids of Soldiers Delight", "text": "List of graminoids of Soldiers Delight\n\nThe Graminoids of Soldiers Delight Natural Environmental Area, located in western Baltimore County, Maryland. Graminoids, within the order of Poales, include: grasses (Poaceae), sedges (Cyperaceae), rushes (Juncaceae), and cattails (Typhaceae).\nMuch of the area of the Soldiers Delight NEA, which totals of protected land, contains a serpentine barren that contains a number of rare and endangered species of plants.\n\nThe Graminoids list was developed using the following publications, with authors' acronyms indicated:[F] Fleming et al. 1995, [M] Monteferrante 1973, [R] Reed 1984, [We] Wennerstrom 1995, and the unpublished data by [Wo] Worthley 1955-1985.\n\n\n\n\n\n\n\n\n"}
{"id": "450096", "url": "https://en.wikipedia.org/wiki?curid=450096", "title": "List of grape varieties", "text": "List of grape varieties\n\nThis list of grape varieties includes cultivated grapes, whether used for wine, or eating as a table grape, fresh or dried (raisin, currant, sultana).\n\nThe term \"grape variety\" refers to cultivars rather than actual botanical varieties according to the International Code of Nomenclature for Cultivated Plants, because they are propagated by cuttings and may have unstable reproductive properties. However, the term \"variety\" has become so entrenched in viticulture that any change of usage to the term \"cultivar\" is unlikely.\n\nWhile some of the grapes in this list are hybrids, they are hybridized within between different species within the same genus also known as interspecific hybrids. For those grapes hybridized across species, see the section on multispecies hybrid grapes below.\n\n\nMany commercial varieties commonly called \"labrusca\" are actually complex interspecies hybrids.\n\n\n\n\n\nHybrid grape varieties (see Hybrid grapes) or \"hybrids\" is, in fact, the popular term for a subset of what are properly known as \"hybrids\", specifically crossings between one species of the genus vitis and another. The scientific definition of a hybrid grape is any crossing (intra- or inter-specific) of two grape varieties. In keeping with the popular definition, however, the ones listed below are inter-specific hybrids where one parent is a European grape. Most of these are complex mixtures of three or more species and all parents are not always clearly known.\n\n\n\n\n\n"}
{"id": "47269642", "url": "https://en.wikipedia.org/wiki?curid=47269642", "title": "List of most massive exoplanets", "text": "List of most massive exoplanets\n\nThis is a list of most massive exoplanets so far discovered, arranged by decreasing Jupiter mass (). The exoplanets with mass higher than 10 are included.\n\n"}
{"id": "959386", "url": "https://en.wikipedia.org/wiki?curid=959386", "title": "List of mountains in Brazil", "text": "List of mountains in Brazil\n\n"}
{"id": "26527671", "url": "https://en.wikipedia.org/wiki?curid=26527671", "title": "List of near threatened plants", "text": "List of near threatened plants\n\nAs of September 2016, the International Union for Conservation of Nature (IUCN) lists 1851 near threatened plant species. 8.5% of all evaluated plant species are listed as near threatened. \nThe IUCN also lists 51 subspecies and 73 varieties as near threatened. No subpopulations of plants have been evaluated by the IUCN.\n\nThis is a complete list of near threatened plant species, subspecies and varieties evaluated by the IUCN.\nThere are two bryophyte species assessed as near threatened.\n\n\nThere are 25 pteridophyte species assessed as near threatened.\n\nThere are 168 species, two subspecies, and 29 varieties of gymnosperm assessed as near threatened.\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\nVarieties\nThere are 1378 species, 44 subspecies, and 41 varieties of dicotyledon assessed as near threatened.\n\nSpecies\n\nVarieties\n\nThere are 45 species and two varieties in Theales assessed as near threatened.\n\nSpecies\n\nVarieties\n\nSpecies\n\nSubspecies\nVarieties\n\nSpecies\n\nVarieties\n\nSpecies\n\nSubspecies\nVarieties\n\nThere are 52 species and two varieties in Euphorbiales assessed as near threatened.\n\nSpecies\n\nVarieties\n\nThere are 40 species, one subspecies, and one variety in the order Laurales assessed as near threatened.\n\nSpecies\n\nSubspecies\nVarieties\n\nThere are 73 species, five subspecies, and one variety in Ebenales assessed as near threatened.\n\nSpecies\n\nSubspecies\n\nVarieties\n\n\nThere are 45 species, two subspecies, and two varieties in the order Celastrales assessed as near threatened.\n\nSpecies\n\nSubspecies\nVarieties\n\n\nThere are 80 species and two varieties in the order Myrtales assessed as near threatened.\n\nSpecies\n\nVarieties\n\nSpecies\n\nVarieties\n\n\nThere are 113 species, six subspecies, and three varieties in the order Sapindales assessed as near threatened.\n\nSpecies\n\nSubspecies\nVarieties\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\nVarieties\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\n\nThere are 82 species, eight subspecies, and two varieties in the order Magnoliales assessed as near threatened.\n\nSpecies\n\nVarieties\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\n\nVarieties\n\n\nThere are 35 species, one subspecies, and two varieties in the order Apiales assessed as near threatened.\n\nSpecies\n\nVarieties\n\nSpecies\n\nSubspecies\n\nThere are 38 species, three subspecies, and four varieties in the order Rosales assessed as near threatened.\n\nSpecies\n\nVarieties\n\nSpecies\n\nSubspecies\nVarieties\n\nSpecies\n\nSubspecies\nVarieties\n\nThere are 21 species and two varieties in Primulales assessed as near threatened.\n\nSpecies\n\nVarieties\n\n\nSpecies\n\nVarieties\n\nThere are 20 species and one subspecies in the order Solanales assessed as near threatened.\n\nSpecies\n\nSubspecies\n\n\n\nThere are 48 species, one subspecies, and one variety in the order Scrophulariales assessed as near threatened.\n\nSpecies\n\nSubspecies\n\nSpecies\n\nVarieties\n\nThere are 33 species, two subspecies, and one variety in the order Lamiales assessed as near threatened.\n\nSpecies\n\nSubspecies\n\nSpecies\n\nVarieties\n\nSpecies\n\nSubspecies\nVarieties\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\n\nVarieties\nThere are 90 species in the order Caryophyllales assessed as near threatened.\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\nVarieties\n\nThere are 278 species, five subspecies, and three varieties of monocotyledon assessed as near threatened.\n\nSpecies\n\nVarieties\n\nSpecies\n\nSubspecies\n\nThere are 21 species in Arales assessed as near threatened.\n\nThere are 45 species, two subspecies, and one variety in Cyperales assessed as near threatened.\n\nSpecies\n\nSubspecies\nVarieties\n\nSpecies\n\nSubspecies\n\nSpecies\n\nSubspecies\n\n"}
{"id": "34141451", "url": "https://en.wikipedia.org/wiki?curid=34141451", "title": "Lists of cultivars", "text": "Lists of cultivars\n\nThe lists of cultivars in the table below are indexes of plant cultivars, varieties, and strains. A \"cultivar\" is a plant that is selected for desirable characteristics that can be maintained by propagation.\n\nThe plants listed may be ornamental, medicinal, and/or edible. Several of them bear edible fruit. Plants are selectively bred for phenotypic traits (such as flower colour) and other hereditary traits. When developing a new variety, a plant breeder might value such characteristics as appearance, disease resistance, and hardiness. In the cultivation of edible fruit and vegetables, nutritional value, shelf life, and crop yield are also among the potential considerations.\n\nSome of the lists use the word \"variety\" instead of \"cultivar\". In most of these lists, \"variety\" refers to a cultivar that is recognised by the International Union for the Protection of New Varieties of Plants (UPOV). A cultivar must meet certain criteria in order to be recognised by UPOV as a named variety.\n\nIn a few lists, \"variety\" means something else: a taxonomic rank below that of species (a kind of subspecies). If the species' binomial name is followed by the word \"var.\" and another name, that is a botanical variety, not a cultivar.\n\n"}
{"id": "47258758", "url": "https://en.wikipedia.org/wiki?curid=47258758", "title": "Lists of plants", "text": "Lists of plants\n\nAn index of some of the lists of plants.\n\n\n\n\n"}
{"id": "1055193", "url": "https://en.wikipedia.org/wiki?curid=1055193", "title": "Madagascar subhumid forests", "text": "Madagascar subhumid forests\n\nThe Madagascar subhumid forests are a tropical moist broadleaf forest ecoregion that covers most of the Central Highlands of the island of Madagascar. They are included in the WWF's Global 200 list of outstanding ecoregions. Most of the original habitats have been lost due to human pressure.\n\nThe Madagascar subhumid forests ecoregion extends over most of the Central Highlands, above approximately elevation on the east and above meters elevation on the west. Most of that area is now covered by secondary grasslands and agriculture, with forest reduced to fragmented patches. The ecoregion has an area of approximately . The highlands catch the wet northeast trade winds, while the areas to the south, west, and north lie in the drier rain shadow of the highlands.\n\nThe subhumid forests are bounded by the humid Madagascar lowland forests along the coastal strip to the east, by the Madagascar dry deciduous forests to the north, northwest and west, and by the sub-arid Madagascar succulent forests and Madagascar spiny thickets to the southwest and south. In four areas above elevation, the subhumid forests yield to the montane Madagascar ericoid thickets.\n\nMontagne d'Ambre near the northern tip of the island, contains a significant pocket of subhumid forest, surrounded at lower elevations by dry deciduous forest, as do Ankaratra, upland near Tsaratanana, Andringitra Massif, Ambohitantely Reserve, and the Ambohijanahary area. The subhumid forests ecoregion also includes the disjunct Analavelona and Isalo massifs to the southwest, surrounded by succulent forests at lower elevations, and wetlands such as Lake Alaotra. The Sambirano region in the northwest is a particular centre of endemism.\n\nThe original flora of ecoregion has been much altered by human use; extensive areas have been cleared for agriculture, grazing, and rice cultivation, and some exotic species such as \"Acacia\" and \"Eucalyptus\" have been introduced. Pockets of closed-canopy evergreen forest still exist, as do open-canopy woodlands, such as a type of hard-leaved forest dominated by tapia (\"Uapaca bojeri\"). Endemic species also included succulents in the genera \"Aloe\" and \"Kalanchoe\". Large areas are now covered by grassland, but the extent to which the grasslands are the result of human intervention is still subject to debate.\n\nEndemic species include a number of birds, reptiles and mammals including the Alaotra gentle lemur (\"Hapalemur alaotrensis\") and a number of shrews, tenrecs, and rodents. The subhumid forests were formerly home to the island's distinct megafauna, including giant lemurs, some of them larger than modern gorillas, the elephant birds (Aepyornithidae), and giant tortoises.\n\nMadagascar's high plateau forests have been altered by humans in most places. There has been extensive slash-and-burn activity by native peoples in the central highlands, eliminating most forest. Other impacts include land clearing for agricultura, overexploitation, and pollution.\n\nProtected areas include Marojejy National Park, Isalo National Park, and the upper slopes of Ranomafana National Park. There are some smaller forest reserves, including Ambohijanahary and Ambohitantely.\n\n"}
{"id": "41837562", "url": "https://en.wikipedia.org/wiki?curid=41837562", "title": "Ministry of Oil and Gas (Kazakhstan)", "text": "Ministry of Oil and Gas (Kazakhstan)\n\nThe Ministry of Oil and Gas is one of the governmental bodies of Kazakhstan and part of the cabinet. The ministry has the function of developing and implementing policies related to petroleum and petroleum products.\n\nThe ministry was established on 12 March 2010 and is the successor of the ministry of energy and mineral resources. \n\nUzakbai Karabalin has been the minister of oil and gas since July 2013. He replaced Sauat Mynbayev in the post. Mynbayev was the first minister of oil and gas.\n\nThe main function of the ministry is to oversee and regulate the oil and gas sector in the country which was largely carried out by the national oil company, KazMunaiGas, until the establishment of the ministry.\n"}
{"id": "43455681", "url": "https://en.wikipedia.org/wiki?curid=43455681", "title": "Mixed coniferous forest", "text": "Mixed coniferous forest\n\nMixed coniferous forest is a vegetation type dominated by a mixture of broadleaf trees and conifers. It is generally located in mountains, below the upper montane vegetation type.\n\nIn the Sierra Nevada mountain range of the western United States, the mixed coniferous forest is found at elevations of in the north, in central areas, and in the south. Characteristic conifers include Ponderosa Pine (\"Pinus ponderosa\"), Sugar Pine (\"Pinus lambertiana\"), Incense Cedar (\"Calocedrus decurrens\"), White Fir (\"Abies concolor\"), Douglas Fir (\"Pseudotsuga menziesii\"), and Giant Sequoias (\"Sequoiadendron giganteum\") in pockets. Characteristic broadleaved trees include Black Oak (\"Quercus kelloggii\"), and understory trees and shrubs, including Canyon Live Oak (\"Quercus chrysolepis\"), Dogwood (\"Cornus\" spp.), Mountain Misery (\"Chamaebatia foliolosa\"), and Manzanitas (\"Arctostaphylos\" spp.). Precipitation in areas of this vegetation type is , much of this falling as snow. Growing season is about seven months, in areas with summer high temperatures of , and winter lows of .\n\n\n"}
{"id": "144241", "url": "https://en.wikipedia.org/wiki?curid=144241", "title": "Molar mass", "text": "Molar mass\n\nIn chemistry, the molar mass \"M\" is a physical property defined as the mass of a given substance (chemical element or chemical compound) divided by the amount of substance. The base SI unit for molar mass is kg/mol. However, for historical reasons, molar masses are almost always expressed in g/mol.\n\nAs an example, the molar mass of water: \"M\"(HO) ≈ .\n\nThe molar mass of atoms of an element is given by the Standard atomic weight of the element multiplied by the molar mass constant, \"M\" = 1 × 10 kg/mol = 1 g/mol:\nMultiplying by the molar mass constant ensures that the calculation is dimensionally correct: standard relative atomic masses are dimensionless quantities (i.e., pure numbers) whereas molar masses have units (in this case, grams/mole).\n\nSome elements are usually encountered as molecules, e.g. hydrogen (H), sulfur (S), chlorine (Cl). The molar mass of molecules of these elements is the molar mass of the atoms multiplied by the number of atoms in each molecule:\n\nThe molar mass of a compound is given by the sum of the standard atomic weight (namely, the standard relative atomic mass) of the atoms which form the compound multiplied by the molar mass constant, \"M\":\n\nAn average molar mass may be defined for mixtures of compounds. This is particularly important in polymer science, where different polymer molecules may contain different numbers of monomer units (non-uniform polymers).\n\nThe average molar mass of mixtures formula_1 can be calculated from the mole fractions formula_2 of the components and their molar masses formula_3:\n\nIt can also be calculated from the mass fractions formula_5 of the components:\n\nAs an example, the average molar mass of dry air is 28.97 g/mol.\n\nMolar mass is closely related to the relative molar mass (\"M\") of a compound, to the older term formula weight (F.W.), and to the standard atomic masses of its constituent elements. However, it should be distinguished from the molecular mass (also known as molecular weight), which is the mass of \"one\" molecule (of any \"single\" isotopic composition) and is not directly related to the atomic mass, the mass of \"one\" atom (of any \"single\" isotope). The dalton, symbol Da, is also sometimes used as a unit of molar mass, especially in biochemistry, with the definition 1 Da = 1 g/mol, despite the fact that it is strictly a unit of mass (1 Da = 1 u = 1.660 538 921(73)×10 kg).\n\nGram atomic mass is another term for the mass, in grams, of one mole of atoms of that element. \"Gram atom\" is a former term for a mole.\n\nMolecular weight (M.W.) is an older term for what is now more correctly called the relative molar mass (\"M\"). This is a dimensionless quantity (i.e., a pure number, without units) equal to the molar mass divided by the molar mass constant.\n\nThe molecular mass (\"m\") is the mass of a given molecule: it is measured in atomic mass units (amu) or daltons (Da). Different molecules of the same compound may have different molecular masses because they contain different isotopes of an element. The molar mass is a measure of the average molecular mass of all the molecules in a sample, and is usually the more appropriate measure when dealing with macroscopic (weigh-able) quantities of a substance.\n\nMolecular masses are calculated from the standard atomic weights of each nuclide, while molar masses are calculated from the atomic mass of each element. The atomic mass takes into account the isotopic distribution of the element in a given sample (usually assumed to be \"normal\"). For example, water has a molar mass of 18.0153(3) g/mol, but individual water molecules have molecular masses which range between 18.010 564 6863(15) u (HO) and 22.027 7364(9) u (DO).\n\nThe distinction between molar mass and molecular mass is important because relative molecular masses can be measured directly by mass spectrometry, often to a precision of a few parts per million. This is accurate enough to directly determine the chemical formula of a molecule.\n\nThe term formula weight (F.W.) has a specific meaning when used in the context of DNA synthesis: whereas an individual phosphoramidite nucleobase to be added to a DNA polymer has protecting groups and has its \"molecular weight\" quoted including these groups, the amount of molecular weight that is ultimately added by this nucleobase to a DNA polymer is referred to as the nucleobase's \"formula weight\" (i.e., the molecular weight of this nucleobase within the DNA polymer, minus protecting groups).\n\nThe precision to which a molar mass is known depends on the precision of the atomic masses from which it was calculated. Most atomic masses are known to a precision of at least one part in ten-thousand, often much better (the atomic mass of lithium is a notable, and serious, exception). This is adequate for almost all normal uses in chemistry: it is more precise than most chemical analyses, and exceeds the purity of most laboratory reagents.\n\nThe precision of atomic masses, and hence of molar masses, is limited by the knowledge of the isotopic distribution of the element. If a more accurate value of the molar mass is required, it is necessary to determine the isotopic distribution of the sample in question, which may be different from the standard distribution used to calculate the standard atomic mass. The isotopic distributions of the different elements in a sample are not necessarily independent of one another: for example, a sample which has been distilled will be enriched in the lighter isotopes of all the elements present. This complicates the calculation of the standard uncertainty in the molar mass.\n\nA useful convention for normal laboratory work is to quote molar masses to two decimal places for all calculations. This is more accurate than is usually required, but avoids rounding errors during calculations. When the molar mass is greater than 1000 g/mol, it is rarely appropriate to use more than one decimal place. These conventions are followed in most tabulated values of molar masses.\n\nMolar masses are almost never measured directly. They may be calculated from standard atomic masses, and are often listed in chemical catalogues and on safety data sheets (SDS). Molar masses typically vary between:\n\nWhile molar masses are almost always, in practice, calculated from atomic weights, they can also be measured in certain cases. Such measurements are much less precise than modern mass spectrometric measurements of atomic weights and molecular masses, and are of mostly historical interest. All of the procedures rely on colligative properties, and any dissociation of the compound must be taken into account.\n\nThe measurement of molar mass by vapour density relies on the principle, first enunciated by Amedeo Avogadro, that equal volumes of gases under identical conditions contain equal numbers of particles. This principle is included in the ideal gas equation:\nwhere \"n\" is the amount of substance. The vapour density (ρ) is given by\nCombining these two equations gives an expression for the molar mass in terms of the vapour density for conditions of known pressure and temperature.\n\nThe freezing point of a solution is lower than that of the pure solvent, and the freezing-point depression (Δ\"T\") is directly proportional to the amount concentration for dilute solutions. When the composition is expressed as a molality, the proportionality constant is known as the cryoscopic constant (\"K\") and is characteristic for each solvent. If \"w\" represents the mass fraction of the solute in solution, and assuming no dissociation of the solute, the molar mass is given by\n\nThe boiling point of a solution of an involatile solute is higher than that of the pure solvent, and the boiling-point elevation (Δ\"T\") is directly proportional to the amount concentration for dilute solutions. When the composition is expressed as a molality, the proportionality constant is known as the ebullioscopic constant (\"K\") and is characteristic for each solvent. If \"w\" represents the mass fraction of the solute in solution, and assuming no dissociation of the solute, the molar mass is given by\n\n"}
{"id": "13455091", "url": "https://en.wikipedia.org/wiki?curid=13455091", "title": "Mount Horeb", "text": "Mount Horeb\n\nMount Horeb, Hebrew: , Greek in the Septuagint: , Latin in the Vulgate: \"\", is the mountain at which the book of Deuteronomy in the Hebrew Bible states that the Ten Commandments were given to Moses by God. It is described in two places (, ) as the \"Mountain of God\". The mountain is also called the Mountain of YHWH.\n\nIn other biblical passages, these events are described as having transpired at Mount Sinai. Although most scholars consider Sinai and Horeb to have been different names for the same place, there is a minority body of opinion that they may have been different locations.\n\nThe Protestant reformer John Calvin took the view that Sinai and Horeb were the same mountain, with the eastern side of the mountain being called Sinai and the western side being called Horeb. Abraham Ibn Ezra suggested that there was one mountain, \"only it had two tops, which bore these different names\".\n\nHoreb is thought to mean \"glowing\"/\"heat\", which seems to be a reference to the Sun, while Sinai may have derived from the name of Sin, the Sumerian deity of the Moon, and thus Sinai and Horeb would be the mountains of the moon and sun, respectively.\n\nThe name \"Horeb\" first occurs at , with the story of Moses and the burning bush. According to , the ground of the mountain was considered holy, and Moses was commanded by God to remove his shoes.\n\nThe only other use of the name in Exodus is at , where Horeb is the location where the Israelites stripped off their ornaments. This passage (i.e., Exodus 33:1–6) suggests that Horeb was the location from which the Israelites set off towards Canaan as they resumed their Exodus journey.\n\nIn Deuteronomy, \"Horeb\" is mentioned several times in the account of the wanderings of the Israelites in the wilderness: , , . Moses recalled in that God had said to the Israelites at Horeb, \"You have dwelt long enough at this mountain: turn and take your journey\", confirming the same suggestion that Horeb was the location from which they set off towards Canaan.\n\nThe account of the delivery to Moses of the Ten Commandments, and references back to it, include mentions of \"Horeb\" at , , , and . There are similar references back at and . creates the sense that the current generation to whom Moses was speaking had been present on Mount Horeb when Moses descended with the commandments, although \"the individuals who [had been] present had all perished with the exception of Moses, Joshua, and Caleb. [The] nation survived, and as it was with the nation as an organic whole that the covenant had been made. It might be with propriety said that it was made with those whom Moses addressed at this time, inasmuch as they constituted the nation.\"\n\nAt and it is stated that the Ark of the Covenant contained only the tablets delivered to Moses at Horeb. At , Elijah visits \"Horeb the mount of God\".\n\nAccording to the documentary hypothesis, the name Sinai is used in the Torah only by the Jahwist and Priestly Source, whereas Horeb is used only by the Elohist and Deuteronomist.\n\nThere are no references to \"Horeb\" in the New Testament. At , Mount Sinai is mentioned:\n\"… One covenant is from Mount Sinai and bears children who are to be slaves: This is Hagar. Now Hagar stands for Mount Sinai in Arabia and corresponds to the present city of Jerusalem, because she is in slavery with her children.\" Mount Sinai/Horeb is alluded to in .\n\nThe location of Horeb is disputed. Jewish and Christian scholars have advanced varying opinions as to its whereabouts since biblical times. Elijah is described in as traveling to Horeb, in a way which implies that its position was familiar when that was written, but there are no biblical references set any later in time.\n"}
{"id": "6801475", "url": "https://en.wikipedia.org/wiki?curid=6801475", "title": "National Pest Plant Accord", "text": "National Pest Plant Accord\n\nThe National Pest Plant Accord (NPPA) is a New Zealand agreement that identifies pest plants that are prohibited from sale and commercial propagation and distribution.\n\nThe Accord initially came into effect on 1 October 2001 between regional councils and government departments with biosecurity responsibilities, but in 2006 was revised to include the Nursery and Garden Industry Association as a member of the decision-making body. Under the Accord, regional councils undertake surveillance to ensure the pest plants are not being sold, propagated or distributed.\n\nThe Department of Conservation also lists 328 vascular plant species as environmental weeds - species that infest, are controlled on, or are damaging to land under its control.\n\nThe National Pest Plant Accord is periodically updated, which was last done in 2012:\n\n\n"}
{"id": "774575", "url": "https://en.wikipedia.org/wiki?curid=774575", "title": "Outgassing", "text": "Outgassing\n\nOutgassing (sometimes called offgassing, particularly when in reference to indoor air quality) is the release of a gas that was dissolved, trapped, frozen or absorbed in some material. Outgassing can include sublimation and evaporation (which are phase transitions of a substance into a gas), as well as desorption, seepage from cracks or internal volumes, and gaseous products of slow chemical reactions. Boiling is generally thought of as a separate phenomenon from outgassing because it consists of a phase transition of a liquid into a vapor of the same substance.\n\nOutgassing is a challenge to creating and maintaining clean high-vacuum environments. NASA and ESA maintains a list of low-outgassing materials to be used for spacecraft, as outgassing products can condense onto optical elements, thermal radiators, or solar cells and obscure them. Materials not normally considered absorbent can release enough light-weight molecules to interfere with industrial or scientific vacuum processes. Moisture, sealants, lubricants, and adhesives are the most common sources, but even metals and glasses can release gases from cracks or impurities. The rate of outgassing increases at higher temperatures because the vapor pressure and rate of chemical reaction increases. For most solid materials, the method of manufacture and preparation can reduce the level of outgassing significantly. Cleaning of surfaces, or heating of individual components or the entire assembly (a process called \"bake-out\") can drive off volatiles.\n\nNASA's Stardust spaceprobe suffered reduced image quality due to an unknown contaminant that had condensed on the CCD sensor of the navigation camera. A similar problem affected the Cassini spaceprobe's Narrow Angle Camera, but was corrected by repeatedly heating the system to 4 °C. A comprehensive characterisation of outgassing effects using mass spectrometers could be obtained for ESA's Rosetta spacecraft.\n\nNatural outgassing is commonplace in comets.\n\nOutgassing is a possible source of many tenuous atmospheres of terrestrial planets or moons. Many materials are volatile relative to the extreme vacuum of space, such as around the Moon, and may evaporate or even boil at ambient temperature. Materials on the lunar surface have completely outgassed and been ripped away by solar winds long ago, but volatile materials may remain at depth. Once released, gases almost always are less dense than the surrounding rocks and sand and seep toward the surface. The lunar atmosphere probably originates from outgassing of warm material below the surface. At the Earth's tectonic divergent boundaries where new crust is being created, helium and carbon dioxide are some of the volatiles being outgassed from mantle magma.\n\nOutgassing can be significant if it collects in a closed environment where air is stagnant or recirculated. For example, new car smell consists of outgassed chemicals released by heat in a closed automobile. Even a nearly odorless material such as wood may build up a strong smell if kept in a closed box for months. There is some concern that plasticizers and solvents released from many industrial products, especially plastics, may be harmful to human health. Long-term exposure to solvent vapors can cause chronic solvent-induced encephalopathy (CSE). Outgassing toxic gases are of great concern in the design of submarines and space stations, which must have self-contained recirculated atmospheres.\n\nThe outgassing of small pockets of air near the surface of setting concrete can lead to permanent holes in the structure (called bugholes) that may compromise its structural integrity.\n\n\n"}
{"id": "5719785", "url": "https://en.wikipedia.org/wiki?curid=5719785", "title": "Pacesetters", "text": "Pacesetters\n\nPacesetters is a project created by Facility Architects, a London-based design firm. Its aim is to harness the vibrations generated by activities within a city and generate electricity for lighting purposes. The electronics company Philips and Hull University are also taking part in the project.\n\nDARPA (Defense Advanced Research Projects Agency) of the United States pioneered research into the field of energy harvesting from vibrations, wanting to reduce the use of heavy rechargeable batteries that power communication devices carried by soldiers into battlefields. Most of the research was spent in development of \"heel-strike\" [generators], which were powered through the pumping motion of a footstep, which would be embedded within a heel of an army boot. They succeeded in achieving upwards of 3 - 6 watts of power output.\n\nThere are currently two design prototypes being considered. The first prototype is a staircase that will contain either hydraulic or piezoelectric mechanisms within the steps to absorb the kinetic energy from stairclimbers' footfalls, and then convert them into electricity. This method is believed to more efficient as more energy is expended by the commuters to ascend the staircase. The prototype is expected to be installed and tested by summer 2007.\n\nThe second design consists of a wireless system of lighting that will use tiny generators with components designed to resonate at the same frequency of surrounding vibrations. The resonance will then either move a tiny magnet relative to a coil of wire looped around it or apply pressure to a crystal inside the generator to create current. Light-emitting diodes or LEDs connected to such vibration harvesters could be used to illuminate areas where constant heavy vibration is present, such as train or metro stations, airports or highways. This system will enable lighting without any cables or wires connected to the power grid.\n\n\n"}
{"id": "2000320", "url": "https://en.wikipedia.org/wiki?curid=2000320", "title": "Rhyodacite", "text": "Rhyodacite\n\nRhyodacite is an extrusive volcanic rock intermediate in composition between dacite and rhyolite. It is the extrusive equivalent of granodiorite. Phenocrysts of sodium-rich plagioclase, sanidine, quartz, and biotite or hornblende are typically set in an aphanitic to glassy light to intermediate-colored matrix. \nRhyodacite is a high silica rock containing 20% to 60% quartz with the remaining constituents being mostly feldspar. The feldspar is a mix of alkaline feldspar and plagioclase, with plagioclase forming 35% to 65% of the mix. \nRhyodacite often exists as explosive pyroclastic volcanic deposits.\n\nRhyodacite lava flows occur, for example, in northwestern Ferry County (Washington), and at An Sgùrr on the island of Eigg in Scotland.\n"}
{"id": "1405663", "url": "https://en.wikipedia.org/wiki?curid=1405663", "title": "Sally Carrighar", "text": "Sally Carrighar\n\nSally Carrighar (1898–1985) was an American naturalist and writer. She is especially known for her series of nature books chronicling the lives of wild animals. Humans are often absent from these tales.\n\nShe attended Wellesley College for two years and would have graduated with the class of 1922, but had to leave due to sickness.\n\nCarrighar's work is based on years of observation. For example, she spent seven years observing at Beetle Rock in California and ten years in the Arctic before writing her famous books. These are seen as classics of nature writing and may be viewed as a specialized form of travel literature.\n\nShe wrote eleven books during her life, the most popular of which was her first \"One Day on Beetle Rock\" (1944). Several of her other popular titles are \"The Twilight Seas\" (1975), \"Icebound Summer\" (1953), \"One Day at Teton Marsh\" (1965), \"Home to the Wilderness\" (1973), and \"Wild Heritage\" (1965). Other books by this author include \"Wild Voice of the North: Chronicle of an Eskimo Dog\" (1959), \"Moonlight at Midday\" (1958), \"The Glass Dove: A Novel of the Underground Railroad\" (1962), \"A Husky in the House\" (1960) and \"Blue Whale\" (1975).\n"}
{"id": "2000829", "url": "https://en.wikipedia.org/wiki?curid=2000829", "title": "Sinus Amoris", "text": "Sinus Amoris\n\nSinus Amoris (Latin for \"Bay of Love\") extends northward from the northeast end of the Mare Tranquillitatis. It is located at selenographic coordinates 18.1° N, 39.1° E, and lies within a diameter of 130 km. To the north of the bay are the jumbled Montes Taurus peaks.\n\nNear the southern end of the bay where it outlets into the Mare Tranquillitatis lies the crater Theophrastus. Along the western side is the flooded crater Maraldi and Mons Maraldi. Bordering the east side of the bay are the craters Carmichael and Hill. There are some low ridges in the central part of the bay, but otherwise it is relatively featureless.\n\nAt the southern egress where the bay joins the mare lies Mons Esam, a minor rise that lies among several small lunar domes.\n\n\n"}
{"id": "42105035", "url": "https://en.wikipedia.org/wiki?curid=42105035", "title": "Soil stabilization", "text": "Soil stabilization\n\nSoil stabilization a general term for any physical, chemical, mechanical, biological or combined method of changing a natural soil to meet an engineering purpose. Improvements include increasing the weight bearing capabilities, tensile strength, and overall performance of in-situ subsoils, sands, and waste materials in order to strengthen road pavements.\n\nSome of the renewable technologies are: enzymes, surfactants, biopolymers, synthetic polymers, co-polymer based products, cross-linking styrene acrylic polymers, tree resins, ionic stabilizers, fiber reinforcement, calcium chloride, calcite, sodium chloride, magnesium chloride and more. Some of these new stabilizing techniques create hydrophobic surfaces and mass that prevent road failure from water penetration or heavy frosts by inhibiting the ingress of water into the treated layer.\n\nHowever, recent technology has increased the number of traditional additives used for soil stabilization purposes. Such non-traditional stabilizers include: Polymer based products (e.g. cross-linking water-based styrene acrylic polymers that significantly improves the load-bearing capacity and tensile strength of treated soils), Copolymer Based Products, fiber reinforcement, calcium chloride, and Sodium Chloride. \n\nSoil can also be stabilized mechanically with stabilization geosynthetics, for example, geogrids or geocells, a 3D mechanical soil stabilization technique. Stabilization is achieved via confinement of particle movement to improve the strength of the entire layer. Confinement in geogrids is by means of interlock between the aggregate and grid (and tensioned membrane), and in geocells, by cell wall confinement (hoop) stress on the aggregate. \n\nTraditionally and widely accepted types of soil stabilization techniques use products such as bitumen emulsions which can be used as a binding agents for producing a road base. However, bitumen is not environmentally friendly and becomes brittle when it dries out. Portland cement has been used as an alternative to soil stabilization. However, this can often be expensive and is not a very good \"green\" alternative. Cement fly ash, lime fly ash (separately, or with cement or lime), bitumen, tar, cement kiln dust (CKD), tree resin and ionic stabilizers are all commonly used stabilizing agents. Other stabilization techniques include using on-site materials including sub-soils, sands, mining waste and crushed construction waste to provide stable, dust free local roads for complete dust control and soil stabilization.\n\nThere are advantages and disadvantages to many of these soil stabilizers.\n\nMany of the \"green\" products have essentially the same formula as soap powders, merely lubricating and realigning the soil with no effective binding property. Many of the new approaches rely on large amounts of clay with its inherent binding properties. \nBitumen,tar emulsions, asphalt, cement, lime can be used as a binding agents for producing a road base. When using such products issues such as safety, health and the environment must be considered. \n\nThe National Society of Professional Engineers (NSPE) has explored some of the newer types of soil stabilization technology, specifically looking for \"effective and green\" alternatives. One of the examples utilizes new soil stabilization technology, a process based on cross-linking styrene acrylic polymer. Another example uses long crystals to create a closed cell formation that is impermeable to water and is frost, acid, and salt resistant.\n\nUtilizing new soil stabilization technology, a process of cross-linking within the polymeric formulation can replace traditional road/house construction methods in an environmentally friendly and effective way.\n\nThere is another soil stabilization method called the Deep Mixing method that is non-destructive and effective at improving load bearing capacity of weak or loose soil strata. This method uses a small, penny-sized injection probe and minimizes debris. This method is ideal for re-compaction and consolidation of weak soil strata, increasing and improving load bearing capacity under structures and the remediation of shallow and deep sinkhole problems. This is particular efficient when there is a need to support deficient public and private infrastructure.\n\nWater absorbing magnesium chloride (deliquescent) attributes include\nHowever, limitations include\n\nThe use of magnesium chloride on roads remains controversial. Advocates claim (1) Cleaner air, which leads to better health as fugitive dust can cause health problems in the young, elderly and people with respiratory conditions; and (2) Greater safety through improved road conditions, including increased driver visibility and decreased risks caused by loose gravel, soft spots, road roughness and flying rocks. It reduces foreign sediment in nearby surface waters (dust that settles in creeks and streams), helps prevent stunted crop growth caused by clogged pores in plants, and keeps vehicles and property cleaner. Other studies show the use of salts for road deicing or dust suppressing can contribute substantial amounts of chloride ions to runoff from surface of roads treated with the compounds. The salts MgCl2 (and CaCl2) are very soluble in water and will dissociate. The salts, when used on road surfaces, will dissolve during wet weather and be transported into the groundwater through infiltration and/or runoff into surface water bodies. Groundwater infiltration can be a problem and the chloride ion in drinking water is considered a problem when concentrations exceed 250 mg/l. It is therefore regulated by the U.S. EPA’s drinking water standards. The chloride concentration in the groundwater or surface water depends on several factors including:\nIn addition, the chloride concentration in the surface water also depends on the size or flow rate of the water body and the resulting dilution achieved. In chloride concentration studies carried out in Wisconsin during a winter deicing period, runoff from roadside drainages were analyzed. All studies indicated that the chloride concentration increased as a result of deicing activities but the levels were still below the MCL of 250 mg/L set by the EPA. Nevertheless, the long-term effect of this exposure is not known.\n\nAlthough the U.S. EPA has set the maximum chloride concentration in water for domestic use at 250 mg/l animals can tolerate higher levels. At excessively high levels, chloride is said to affect the health of animals. As stated by the National Technical Advisory Committee to the Secretary of Interior (1968), “Salinity may have a two-fold effect on wildlife; a direct one affecting the body processes of the species involved and an indirect one altering the environment making living species perpetuation difficult or impossible.” One major problem associated with the use of deicing salt as far as wildlife is concerned is that wildlife are known to have “salt craving” and therefore are attracted to salted highways which can be a traffic hazard to both the animals and motorists.\n\nRegarding the accumulation of chloride salts in roadside soils including the adverse effects on roadside plants and vegetation physiology and morphology, documentation dates back to World War II era times and consistently continues forward to present times. As far as plants and vegetation are concerned, the accumulation of salts in the soil adversely affects their physiology and morphology by: increasing the osmotic pressure of the soil solution, by altering the plant’s mineral nutrition, and by accumulating specific ions to toxic concentrations in the plants. Regarding the intentional application of excessive salts: see Salting the Earth.\n\nRoad departments and private industry may apply liquid or powdered magnesium chloride to control dust and erosion on unimproved (dirt or gravel) roads and dusty job sites such as quarries because it is relatively inexpensive to purchase and apply. Its hygroscopy makes it absorb moisture from the air, limiting the number of smaller particles (silts and clays) that become airborne. The most significant benefit of applying dust control products is the reduction in gravel road maintenance costs. However, recent research and updates indicate biological toxicity in the environment in plants as an ongoing problem. Since 2001, truckers have complained about \"Killer Chemicals\" on roads and now some states are backing away from using salt products.\n\nAlso a small percentage of owners of indoor arenas (e.g. for horse riding) may apply magnesium chloride to sand or other \"footing\" materials to control dust. Although magnesium chloride use in an equestrian (horse) arena environment is generally referred to as a dust suppressant it is technically more accurate to consider it as a water augmentation activity since its performance is based on absorbing moisture from the air and from whatever else comes in contact with it.\n\nTo control or mitigate dust, chlorides need moisture to work effectively so it works better in humid than arid climates. As the humidity increases the chloride draw moisture out of the air to keep the surface damp and as humidity decreases it diffuses and releases moisture. These naturally occurring equilibrium changes also allow chlorides to also be used as a dehydrating agent including the drying out of and curing and preservation of hides.\n\nAs a road stabilizer, magnesium chloride binds gravel and clay particles to keep them from leaving the road. The water-absorbing (hygroscopic) characteristics of magnesium chloride prevent the road from drying out, which keeps gravel on the ground. The road remains continually \"wet\" as if a water truck had just sprayed the road.\n\n"}
{"id": "28621", "url": "https://en.wikipedia.org/wiki?curid=28621", "title": "Stalinism", "text": "Stalinism\n\nStalinism is the means of governing and related policies implemented from around 1927 to 1953 by Joseph Stalin (1878–1953). Stalinist policies and ideas as developed in the Soviet Union included rapid industrialization, the theory of socialism in one country, a totalitarian state, collectivization of agriculture, a cult of personality and subordination of the interests of foreign communist parties to those of the Communist Party of the Soviet Union, deemed by Stalinism to be the leading vanguard party of communist revolution at the time.\n\nStalinism promoted the escalation of class conflict, utilizing state violence to forcibly purge society of the bourgeoisie, whom Stalinist doctrine regarded as threats to the pursuit of the communist revolution. This policy resulted in substantial political violence and persecution of such people. \"Enemies\" included not only bourgeois people, but also working-class people with counter-revolutionary sympathies.\n\nStalinist industrialization was officially designed to accelerate the development towards communism, stressing the need for such rapid industrialization on the grounds that the Soviet Union was previously economically backward in comparison with other countries and asserting that socialist society needed industry in order to face the challenges posed by internal and external enemies of communism. Rapid industrialization was accompanied by mass collectivization of agriculture and by rapid urbanization. Rapid urbanization converted many small villages into industrial cities. To accelerate the development of industrialization, Stalin imported materials, ideas, expertise and workers from Western Europe and from the United States and pragmatically set up joint-venture contracts with major American private enterprises, such as the Ford Motor Company, which under state supervision assisted in developing the basis of the industry of the Soviet economy from the late 1920s to the 1930s. After the American private enterprises had completed their tasks, Soviet state enterprises took over.\n\nThe term came into prominence during the mid-1930s when Lazar Kaganovich, a Soviet politician and associate of Stalin, reportedly declared: \"Let's replace Long Live Leninism with Long Live Stalinism!\". Stalin initially met this usage with hesitancy, dismissing it as excessively praiseful and contributing to a cult of personality.\n\nStalinism is used to describe the period during which Stalin was acting leader of the Soviet Union while serving as General Secretary of the Central Committee of the Communist Party from 1922 to his death on 5th of March 1953.\n\nWhile some historians view Stalinism as a reflection of the ideologies of Leninism and Marxism, some argue that it stands separate from the socialist ideals it stemmed from. After a political struggle that culminated in the defeat of the Bukharinists, Stalinism was free to shape policy without opposition, ushering forth an era of harsh authoritarianism that soldiered toward rapid industrialization regardless of the cost.\n\nFrom 1917 to 1924, Vladimir Lenin, Leon Trotsky and Stalin often appeared united, but they had discernible ideological differences. In his dispute with Trotsky, Stalin de-emphasized the role of workers in advanced capitalist countries (for example, he considered the American working class \"bourgeoisified\" labour aristocracy). Stalin also polemicized against Trotsky on the role of peasants as in China whereas Trotsky's position was in favor of urban insurrection over peasant-based guerrilla warfare.\n\nWhilst all other October Revolution 1917 Bolshevik leaders regarded their revolution more or less just as the beginning, they saw Russia as the leapboard on the road towards the World Wide Revolution, Stalin eventually introduced the idea of Socialism in One Country by the autumn of 1924. This did not just stand in sharp contrast to Trotsky's \"Permanent Revolution\", but in contrast also to all earlier Socialistic theses. But by time and through circumstances, the revolution did not spread outside Russia, as Lenin had assumed it soon would. Not even within the other former territories Russian Empire such as Poland, Finland, Lithuania, Latvia and Estonia had the revolution been a success. On the contrary, all these countries had returned to capitalist bourgeois rule. But still, by the autumn of 1924, Stalin's idea of socialism in Soviet Russia alone, initially was next to blasphemy in the ears of the other Politburo members- Zinoviev and Kamenev to the intellectual left, Rykov, Bukharin and Tomsky to the pragmatic right and the powerful Trotsky, who belonged to no side but his own. None of them had even thought of Stalin's concept as a potential addition to Communist ideology. Hence, Stalin's \"Socialism in One Country\" doctrine couldn't be imposed until he had become close to being the autocratic ruler of the U.S.S.R. (from around 1929, as Trotsky had been exiled, and Zinoviev and Kamenev had been thrown out of the party, Bukharin and the Right Opposition expressed their support for imposing Stalin's ideas). \n\nWhile traditional communist thought holds that the state will gradually \"wither away\" as the implementation of socialism reduces class distinction, Stalin argued that the proletarian state (as opposed to the bourgeois state) must become stronger before it can wither away. In Stalin's view, counter-revolutionary elements will try to derail the transition to full communism, and the state must be powerful enough to defeat them. For this reason, Communist regimes influenced by Stalin have been widely described as totalitarian.\n\nSheng Shicai collaborated with the Soviets, allowing Stalinist rule to be extended to the Xinjiang province in the 1930s. In 1937, Sheng conducted a purge similar to the Great Purge.\n\nStalin blamed the kulaks as the inciters of reactionary violence against the people during the implementation of agricultural collectivisation. In response, the state under Stalin's leadership initiated a violent campaign against the kulaks, which has been labeled \"classicide\".\n\nAs head of the Politburo of the Central Committee of the Communist Party of the Soviet Union, Stalin consolidated near-absolute power in the 1930s with a Great Purge of the party that claimed to expel \"opportunists\" and \"counter-revolutionary infiltrators\". Those targeted by the purge were often expelled from the party, though more severe measures ranged from banishment to the Gulag labor camps to execution after trials held by NKVD troikas.\n\nIn the 1930s, Stalin apparently became increasingly worried about the growing popularity of the Leningrad party boss Sergei Kirov. At the 1934 Party Congress where the vote for the new Central Committee was held, Kirov received only three negative votes (the fewest of any candidate) while Stalin received at least over a hundred negative votes. After the assassination of Kirov, which may have been orchestrated by Stalin, Stalin invented a detailed scheme to implicate opposition leaders in the murder, including Trotsky, Lev Kamenev and Grigory Zinoviev. The investigations and trials expanded. Stalin passed a new law on \"terrorist organizations and terrorist acts\" that were to be investigated for no more than ten days, with no prosecution, defense attorneys or appeals, followed by a sentence to be executed \"quickly\".\n\nThereafter, several trials known as the Moscow Trials were held, but the procedures were replicated throughout the country. Article 58 of the legal code, which listed prohibited anti-Soviet activities as counter-revolutionary crime, was applied in the broadest manner. Many alleged anti-Soviet pretexts were used to brand someone an \"enemy of the people\", starting the cycle of public persecution, often proceeding to interrogation, torture and deportation, if not death. The Russian word troika gained a new meaning: a quick, simplified trial by a committee of three subordinated to NKVD troika—with sentencing carried out within 24 hours. Stalin's hand-picked executioner Vasili Blokhin was entrusted with carrying out some of the high-profile executions in this period.\nMany military leaders were convicted of treason and a large-scale purge of Red Army officers followed. The repression of so many formerly high-ranking revolutionaries and party members led Leon Trotsky to claim that a \"river of blood\" separated Stalin's regime from that of Lenin. In August 1940, Trotsky was assassinated in Mexico, where he had lived in exile since January 1937—this eliminated the last of Stalin's opponents among the former Party leadership.\n\nWith the exception of Vladimir Milyutin (who died in prison in 1937) and Stalin himself, all of the members of Lenin's original cabinet who had not succumbed to death from natural causes before the purge were executed.\n\nMass operations of the NKVD also targeted \"national contingents\" (foreign ethnicities) such as Poles, ethnic Germans and Koreans. A total of 350,000 (144,000 of them Poles) were arrested and 247,157 (110,000 Poles) were executed. Many Americans who had emigrated to the Soviet Union during the worst of the Great Depression were executed and others were sent to prison camps or gulags. Concurrent with the purges, efforts were made to rewrite the history in Soviet textbooks and other propaganda materials. Notable people executed by NKVD were removed from the texts and photographs as though they never existed. Gradually, the history of revolution was transformed to a story about just two key characters: Lenin and Stalin.\n\nIn light of revelations from Soviet archives, historians now estimate that nearly 700,000 people (353,074 in 1937 and 328,612 in 1938) were executed in the course of the terror, with the great mass of victims merely \"ordinary\" Soviet citizens: workers, peasants, homemakers, teachers, priests, musicians, soldiers, pensioners, ballerinas and beggars. Many of the executed were interred in mass graves, with some of the major killing and burial sites being Bykivnia, Kurapaty and Butovo.\n\nSome Western experts believe the evidence released from the Soviet archives is understated, incomplete or unreliable. Conversely, historian Stephen G. Wheatcroft, who spent a good portion of his academic career researching the archives, contends that prior to the collapse of the Soviet Union and the opening of the archives for historical research, \"our understanding of the scale and the nature of Soviet repression has been extremely poor\" and that some specialists who wish to maintain earlier high estimates of the Stalinist death toll are \"finding it difficult to adapt to the new circumstances when the archives are open and when there are plenty of irrefutable data\" and instead \"hang on to their old Sovietological methods with round-about calculations based on odd statements from emigres and other informants who are supposed to have superior knowledge\".\n\nStalin personally signed 357 proscription lists in 1937 and 1938 that condemned to execution some 40,000 people and about 90% of these are confirmed to have been shot. At the time, while reviewing one such list he reportedly muttered to no one in particular: \"Who's going to remember all this riff-raff in ten or twenty years time? No one. Who remembers the names now of the boyars Ivan the Terrible got rid of? No one\". In addition, Stalin dispatched a contingent of NKVD operatives to Mongolia, established a Mongolian version of the NKVD troika and unleashed a bloody purge in which tens of thousands were executed as \"Japanese spies\". Mongolian ruler Khorloogiin Choibalsan closely followed Stalin's lead.\n\nDuring the 1930s and 1940s, the Soviet leadership sent NKVD squads into other countries to murder defectors and other opponents of the Soviet regime. Victims of such plots included Yevhen Konovalets, Ignace Poretsky, Rudolf Klement, Alexander Kutepov, Evgeny Miller, Leon Trotsky and the Workers' Party of Marxist Unification (POUM) leadership in Catalonia (e.g. Andrés Nin Pérez).\n\nShortly before, during and immediately after World War II, Stalin conducted a series of deportations on a huge scale that profoundly affected the ethnic map of the Soviet Union. It is estimated that between 1941 and 1949 nearly 3.3 million were deported to Siberia and the Central Asian republics. By some estimates, up to 43% of the resettled population died of diseases and malnutrition.\n\nSeparatism, resistance to Soviet rule and collaboration with the invading Germans were cited as the official reasons for the deportations. Individual circumstances of those spending time in German-occupied territories were not examined. After the brief Nazi occupation of the Caucasus, the entire population of five of the small highland peoples and the Crimean Tatars—more than a million people in total—were deported without notice or any opportunity to take their possessions.\n\nAs a result of Stalin's lack of trust in the loyalty of particular ethnicities, ethnic groups such as the Soviet Koreans, the Volga Germans, the Crimean Tatars, the Chechens and many Poles were forcibly moved out of strategic areas and relocated to places in the central Soviet Union, especially Kazakhstan in Soviet Central Asia. By some estimates, hundreds of thousands of deportees may have died en route.\n\nAccording to official Soviet estimates, more than 14 million people passed through the gulags from 1929 to 1953, with a further 7 to 8 million being deported and exiled to remote areas of the Soviet Union (including the entire nationalities in several cases). The emergent scholarly consensus is that from 1930 to 1953, around 1.5 to 1.7 million perished in the gulag system.\n\nIn February 1956, Nikita Khrushchev condemned the deportations as a violation of Leninism and reversed most of them, although it was not until 1991 that the Tatars, Meskhetians and Volga Germans were allowed to return \"en masse\" to their homelands. The deportations had a profound effect on the peoples of the Soviet Union. The memory of the deportations has played a major part in the separatist movements in the Baltic states, Tatarstan and Chechnya even today.\n\nAt the start of the 1930s, Stalin launched a wave of radical economic policies that completely overhauled the industrial and agricultural face of the Soviet Union. This came to be known as the Great Turn as Russia turned away from the near-capitalist New Economic Policy (NEP) and instead adopted a command economy. The NEP had been implemented by Lenin in order to ensure the survival of the socialist state following seven years of war (1914–1921, World War I from 1914 to 1917 and the subsequent Civil War) and had rebuilt Soviet production to its 1913 levels. However, Russia still lagged far behind the West and the NEP was felt by Stalin and the majority of the Communist Party, not only to be compromising communist ideals, but also not delivering sufficient economic performance as well as not creating the envisaged socialist society. It was therefore felt necessary to increase the pace of industrialisation in order to catch up with the West.\n\nFredric Jameson has said that \"Stalinism was [...] a success and fulfilled its historic mission, socially as well as economically\" given that it \"modernised the Soviet Union, transforming a peasant society into an industrial state with a literate population and a remarkable scientific superstructure\". Robert Conquest disputed such a conclusion and noted that \"Russia had already been fourth to fifth among industrial economies before World War I\" and that Russian industrial advances could have been achieved without collectivisation, famine or terror. According to Conquest, the industrial successes were far less than claimed and the Soviet-style industrialisation was \"an anti-innovative dead-end\". Stephen Kotkin said those who argue collectivization was necessary are \"dead wrong\". \"Collectivization only seemed necessary within the straitjacket of Communist ideology and its repudiation of capitalism. And economically, collectivization failed to deliver\", further claiming that it decreased harvests instead of increasing them.\n\nAccording to several Western historians, Stalinist agricultural policies were a key factor in causing the Soviet famine of 1932–1933, which the Ukrainian government now calls the Holodomor, recognizing it as an act of genocide. Some scholars dispute the intentionality of the famine.\n\nPierre du Bois argues that the cult was elaborately constructed to legitimize his rule. Many deliberate distortions and falsehoods were used. The Kremlin refused access to archival records that might reveal the truth and key documents were destroyed. Photographs were altered and documents were invented. People who knew Stalin were forced to provide \"official\" accounts to meet the ideological demands of the cult, especially as Stalin himself presented it in 1938 in \"Short Course on the History of the All-Union Communist Party (Bolsheviks)\", which became the official history. Historian David L. Hoffmann sums up the consensus of scholars: \n\nHowever, after Stalin's death in 1953 his successor Nikita Khrushchev repudiated his policies, condemned Stalin's cult of personality in his Secret Speech to the Twentieth Party Congress in 1956 and instituted de-Stalinisation and relative liberalisation (within the same political framework). Consequently, some of the world's communist parties who previously adhered to Stalinism abandoned it and to a greater or lesser degree adopted the positions of Khrushchev. Others, such as the Communist Party of China, instead chose to split from the Soviet Union.\nThe Socialist People's Republic of Albania took the Chinese party's side in the Sino-Soviet split and remained committed at least theoretically to Hoxhaism, its brand of Stalinism, for decades thereafter under the leadership of Enver Hoxha. Despite their initial cooperation against \"revisionism\", Hoxha denounced Mao as a revisionist, along with almost every other self-identified communist organization in the world. This had the effect of isolating Albania from the rest of the world as Hoxha was hostile to both the pro-American and pro-Soviet spheres of influence as well as the Non-Aligned Movement under the leadership of Josip Broz Tito, whom Hoxha had also denounced.\n\nThe ousting of Khrushchev in 1964 by his former party-state allies has been described as a Stalinist restoration by some, epitomised by the Brezhnev Doctrine and the apparatchik/nomenklatura \"stability of cadres\", lasting until the period of glasnost and perestroika in the late 1980s and the fall of the Soviet Union.\n\nSome historians and writers (like German Dietrich Schwanitz) draw parallels between Stalinism and the economic policy of Tsar Peter the Great, although Schwanitz in particular views Stalin as \"a monstrous reincarnation\" of him. Both men wanted Russia to leave the western European states far behind in terms of development. Both largely succeeded, turning Russia into Europe's leading power. Others compare Stalin with Ivan the Terrible because of his policies of oprichnina and restriction of the liberties of common people.\n\nStalinism has been considered by some reviewers as a \"red fascism\". Though fascist regimes were ideologically opposed to the Soviet Union, some of them positively regarded Stalinism as evolving Bolshevism into a form of fascism. Benito Mussolini positively reviewed Stalinism as having transformed Soviet Bolshevism into a Slavic fascism.\n\nIn writing \"The Mortal Danger: Misconceptions about Soviet Russia and the Threat to America\", Aleksandr Solzhenitsyn argues that the use of the term \"Stalinism\" is an excuse to hide the inevitable effects of communism as a whole on human liberties. He writes that the concept of Stalinism was developed after 1956 by Western intellectuals so as to be able to keep alive the communist ideal. However, the term \"Stalinism\" was in use as early as 1937 when Leon Trotsky wrote his pamphlet \"Stalinism and Bolshevism\".\n\nKristen R. Ghodsee, ethnographer and Professor of Russian and East European Studies at the University of Pennsylvania, posits that the triumphalist attitudes of Western powers at the end of the Cold War and in particular the fixation with linking all socialist political ideals with the excesses of Stalinism marginalized the left's response to the fusing of democracy with neoliberal ideology, which helped undermine the former. This allowed the anger and resentment that came with the ravages of neoliberalism (i.e. economic misery, unemployment, hopelessness and rising inequality throughout the former Eastern Bloc and much of the West) to be channeled into nationalist movements in the decades that followed.\n\nWriting in 2002, British journalist Seumas Milne said that the impact of the post-Cold War narrative that Stalin and Hitler were twin evils, and therefore Communism is as monstrous as Nazism, \"has been to relativise the unique crimes of Nazism, bury those of colonialism and feed the idea that any attempt at radical social change will always lead to suffering, killing and failure.\"\n\nIn modern Russia, public opinion of Stalin and the former Soviet Union has increased in recent years. According to a 2015 Levada Center poll, 34% of respondents (up from 28% in 2007) say that leading the Soviet people to victory in the World War II was such a great achievement that it outweighed his mistakes.\n\nTrotskyists argue that the Stalinist Soviet Union was not socialist (and not communist), but a bureaucratised degenerated workers' state—that is, a non-capitalist state in which exploitation is controlled by a ruling caste which although not owning the means of production and not constituting a social class in its own right, accrued benefits and privileges at the expense of the working class. Trotsky believed that the Bolshevik revolution needed to be spread all over the globe's working class, the proletarians for world revolution. However, after the failure of the revolution in Germany, Stalin reasoned that industrializing and consolidating Bolshevism in Russia would best serve the proletariat in the long run. The dispute did not end until Trotsky's assassination in his Mexican villa by the Stalinist assassin Ramón Mercader in 1940.\n\nIn the United States, Max Shachtman, at the time one of the principal Trotskyist theorists in the United States, argued that the Soviet Union had evolved from a degenerated worker's state to a new mode of production he called \"bureaucratic collectivism\": where orthodox Trotskyists considered the Soviet Union an ally gone astray, Shachtman and his followers argued for the formation of a Third Camp opposed equally to both the Soviet and capitalist blocs. By the mid-20th century, Shachtman and many of his associates identified as social democrats rather than Trotskyists and some ultimately abandoned socialism altogether. In the United Kingdom, Tony Cliff independently developed a critique of state capitalism that resembled Shachtman's in some respects, but retained a commitment to revolutionary communism.\n\nMao Zedong famously declared that Stalin was 70% good, 30% bad. Maoists criticised Stalin chiefly regarding his view that bourgeois influence within the Soviet Union was primarily a result of external forces (to the almost complete exclusion of internal forces) and his view that class contradictions ended after the basic construction of socialism. However, they praised Stalin for leading the Soviet Union and the international proletariat, defeating fascism in Germany and his anti-revisionism.\n\nStalin considered the political and economic system under his rule to be Marxism–Leninism, which he considered the only legitimate successor of Marxism and Leninism. The historiography of Stalin is diverse, with many different aspects of continuity and discontinuity between the regimes of Stalin and Lenin proposed. Totalitarian historians such as Richard Pipes tend to see Stalinism as the natural consequence of Leninism, that Stalin \"faithfully implemented Lenin's domestic and foreign policy programmes\". More nuanced versions of this general view are to be found in the works of other Western historians, such as Robert Service, who notes that \"institutionally and ideologically, Lenin laid the foundations for a Stalin [...] but the passage from Leninism to the worse terrors of Stalinism was not smooth and inevitable\". Likewise, historian and Stalin biographer Edvard Radzinsky believes that Stalin was a real follower of Lenin, exactly as he claimed himself. Another Stalin biographer, Stephen Kotkin, wrote that \"his violence was not the product of his subconscious but of the Bolshevik engagement with Marxist–Leninist ideology\". A third biographer, Dmitri Volkogonov, who wrote biographies of both Lenin and Stalin, explained that during the 1960s through 1980s a conventional patriotic Soviet de-Stalinized view of the Lenin–Stalin relationship (a Khrushchev Thaw and Mikhail Gorbachev-sympathetic type of view) was that the overly autocratic Stalin had distorted the Leninism of the wise dedushka Lenin, but Volkogonov also lamented that this view eventually dissolved for those like him who had the scales fall from their eyes in the years immediately before and after the dissolution of the Soviet Union. After researching the biographies in the Soviet archives, he came to the same conclusion that Radzinsky and Kotkin had, i.e. that Lenin had built a culture of violent autocratic totalitarianism of which Stalinism was a logical extension. He lamented that whereas Stalin had long since fallen in the estimation of many Soviet minds (the many who agreed with de-Stalinization), \"Lenin was the last bastion\" in his mind to fall and the fall was the most painful, given the secular apotheosis of Lenin that all Soviet children grew up with.\n\nProponents of continuity cite a variety of contributory factors as it is argued that it was Lenin, rather than Stalin, whose civil war measures introduced the Red Terror with its hostage taking and internment camps, that it was Lenin who developed the infamous Article 58 and who established the autocratic system within the Communist Party. They also note that Lenin put a ban on factions within the Russian Communist Party and introduced the one-party state in 1921—a move that enabled Stalin to get rid of his rivals easily after Lenin's death and cite Felix Dzerzhinsky, who during the Bolshevik struggle against opponents in the Russian Civil War exclaimed: \"We stand for organised terror—this should be frankly stated\".\n\nOpponents of this view include revisionist historians and a number of post-Cold War and otherwise dissident Soviet historians including Roy Medvedev, who argues that although \"one could list the various measures carried out by Stalin that were actually a continuation of anti-democratic trends and measures implemented under Lenin [...] in so many ways, Stalin acted, not in line with Lenin's clear instructions, but in defiance of them\". In doing so, some historians have tried to distance Stalinism from Leninism in order to undermine the totalitarian view that the negative facets of Stalin were inherent in communism from the start. Critics of this kind include anti-Stalinist communists such as Leon Trotsky, who pointed out that Lenin attempted to persuade the Communist Party to remove Stalin from his post as its General Secretary. Lenin's Testament, the document which contained this order, was suppressed after Lenin's death. In his biography of Trotsky, British historian Isaac Deutscher says that on being faced with the evidence \"only the blind and the deaf could be unaware of the contrast between Stalinism and Leninism\". A similar analysis is present in more recent works, such as those of Graeme Gill, who argues that \"[Stalinism was] not a natural flow-on of earlier developments; [it formed a] sharp break resulting from conscious decisions by leading political actors\". However, Gill notes that \"difficulties with the use of the term reflect problems with the concept of Stalinism itself. The major difficulty is a lack of agreement about what should constitute Stalinism\". Revisionist historians such as Sheila Fitzpatrick have criticised the focus upon the upper levels of society and the use of Cold War concepts, such as totalitarianism, which have obscured the reality of the system.\n\nAccording to the Socialist Party of Great Britain, \"Trotskyism and Stalinism are both branches off the same tree — Bolshevism\".\n\n\n\n\n \n"}
{"id": "459844", "url": "https://en.wikipedia.org/wiki?curid=459844", "title": "Surface acoustic wave", "text": "Surface acoustic wave\n\nA surface acoustic wave (SAW) is an acoustic wave traveling along the surface of a material exhibiting elasticity, with an amplitude that typically decays exponentially with depth into the material.\n\nSAWs were first explained in 1885 by Lord Rayleigh, who described the surface acoustic mode of propagation and predicted its properties in his classic paper. Named after their discoverer, Rayleigh waves have a longitudinal and a vertical shear component that can couple with any media in contact with the surface. This coupling strongly affects the amplitude and velocity of the wave, allowing SAW sensors to directly sense mass and mechanical properties.\n\nSAW devices use SAWs in electronic components to provide a number of different functions, including delay lines, filters, correlators and DC to DC converters.\n\nThis kind of wave is commonly used in devices called \"SAW devices\" in electronic circuits. SAW devices are used as filters, oscillators and transformers, devices that are based on the transduction of acoustic waves. The transduction from electric energy to mechanical energy (in the form of SAWs) is accomplished by the use of piezoelectric materials.\nElectronic devices employing SAWs normally use one or more interdigital transducers (IDTs) to convert acoustic waves to electrical signals and vice versa by exploiting the piezoelectric effect of certain materials (quartz, lithium niobate, lithium tantalate, lanthanum gallium silicate, etc.). These devices are fabricated by photolithography, the process used in the manufacture of silicon integrated circuits.\n\nSAW filters are now used in mobile telephones, and provide significant advantages in performance, cost, and size over other filter technologies such as quartz crystals (based on bulk waves), LC filters, and waveguide filters.\n\nMuch research has been done in the last 20 years in the area of surface acoustic wave sensors.\nSensor applications include all areas of sensing (such as chemical, optical, thermal, pressure, acceleration, torque and biological). SAW sensors have seen relatively modest commercial success to date, but are commonly commercially available for some applications such as touchscreen displays.\n\nSAW resonators are used in many of the same applications in which quartz crystals are used, because they can operate at higher frequency. They are often used in radio transmitters where tunability is not required. They are often used in applications such as garage door opener remote controls, short range radio frequency links for computer peripherals, and other devices where channelization is not required. Where a radio link might use several channels, quartz crystal oscillators are more commonly used to drive a phase locked loop. Since the resonant frequency of a SAW device is set by the mechanical properties of the crystal, it does not drift as much as a simple LC oscillator, where conditions such as capacitor performance and battery voltage will vary substantially with temperature and age.\n\nSAW filters are also often used in radio receivers, as they can have precisely determined and narrow passbands. This is helpful in applications where a single antenna must be shared between a transmitter and a receiver operating at closely spaced frequencies. SAW filters are also frequently used in television receivers, for extracting subcarriers from the signal; until the analog switchoff, the extraction of digital audio subcarriers from the intermediate frequency strip of a television receiver or video recorder was one of the main markets for SAW filters.\n\nEarly pioneer Jeffery Collins incorporated surface acoustic wave devices in a Skynet receiver he developed in the 1970s. It synchronised signals faster than existing technology.\n\nThey are also often used in digital receivers, and are well suited to superhet applications. This is because the intermediate frequency signal is always at a fixed frequency after the local oscillator has been mixed with the received signal, and so a filter with a fixed frequency and high Q provides excellent removal of unwanted or interference signals.\n\nIn these applications, SAW filters are almost always used with a phase locked loop synthesized local oscillator, or a varicap driven oscillator.\n\nIn seismology surface acoustic waves travelling along the Earth's surface play an important role, since they can be the most destructive type of seismic wave produced by earthquakes.\n\nIn recent years, attention has been drawn to using SAWs to drive microfluidic actuation and a variety of other processes. Owing to the mismatch of sound velocities in the SAW substrate and fluid, SAWs can be efficiently transferred into the fluid, creating significant inertial forces and fluid velocities. This mechanism can be exploited to drive fluid actions such as pumping, mixing, and jetting.[8] To drive these processes, there is a change of mode of the wave at the liquid-substrate interface. In the substrate, the SAW wave is a transverse wave and upon entering the droplet the wave becomes a longitudinal wave.[9] It is this longitudinal wave that creates the flow of fluid within the microfluidic droplet, allowing mixing to take place. This technique can be used as an alternative to microchannels and microvalves for manipulation of substrates, allowing for an open system. This mechanism is also able to mix microdroplets; however, it is not completely known how the waves affect the droplets/samples, the digital microfluidic chips, and related modules, such as the channels, in terms of droplet size and precision.\n\nPDMS (polydimethylsiloxane) is a material that can be used to create microchannels and microfluidic chips. It has many uses, including in experiments where living cells are to be tested or processed. If living organisms need to be kept alive, it is important to monitor and control their environment, such as heat and pH levels; however, if these elements are not regulated, the cells may die or it may result in unwanted reactions. PDMS has been found to absorb acoustic energy, causing the PDMS to heat up quickly (exceeding 2000 Kelvin/second). The use of SAW as a way to heat these PDMS devices, along with liquids inside microchannels, is now a technique that can be done in a controlled manner with the ability to manipulate the temperature to within 0.1 °C.\n\nSurface acoustic waves can be used for flow measurement. SAW relies on the propagation of a wave front, which appears similar to seismic activities. The waves are generated at the excitation centre and spread out along the surface of a solid material. An electric pulse induces them to generate SAWs that propagate like the waves of an earthquake. Interdigital transducer acts as sender and as receiver. When one is in sender mode, the two most distant ones act as receivers. The SAWs travel along the surface of the measuring tube, but a portion will couple out to the liquid. The decoupling angle depends on the liquid respectively the propagation velocity of the wave which is specific to the liquid. On the other side of the measuring tube, portions of the wave will couple into the tube and continue their way along its surface to the next interdigital transducer. Another portion will be coupled out again and travels back to the other side of the measuring tube where the effect repeats itself and the transducer on this side detects the wave. That means excitation of any one transducer here will lead to a sequence of input signals on two other transducers in the distance. Two of the transducers send their signals in the direction of flow, two in the other direction.\n\n\n"}
{"id": "1690435", "url": "https://en.wikipedia.org/wiki?curid=1690435", "title": "Tessera", "text": "Tessera\n\nA tessera (plural: tesserae, diminutive \"tessella\") is an individual tile, usually formed in the shape of a cube, used in creating a mosaic. It is also known as an abaciscus or abaculus.\n\nIn early antiquity, mosaics were formed from naturally formed colored pebbles. By roughly 200 BCE cut stone tesserae were being used in Hellenistic-Greek mosaics. For instance, a large body of surviving material from the Hellenistic period can be found in the mosaics of Delos, Greece, dating to the late 2nd century BCE. Ancient Roman decorative mosaic panels and floor mosaics were also produced during the 2nd century BC, particularly at sites such as Pompeii. Marble or limestone were cut into small cubes and arranged into representational designs and geometric patterns. \n\nLater, tesserae were made from colored glass, or clear glass backed with metal foils. The Byzantines used tesserae with gold leaf, in which case the glass pieces were flatter, with two glass pieces sandwiching the gold. This produced a golden reflection emanating from in between the tesserae as well as their front, causing a far richer and more luminous effect than even plain gold leaf would create.\n\nThese are manufactured glass tiles made to a uniform shape and size. They are made by molten glass being poured into trays and fired. An imprint of grooves is made on their underside for help with adhesion to cement when fixing. \nThese are the cheapest range of bought materials and can be glazed or unglazed. The glazed ceramic tiles have the color painted onto the top of the clay and then fired to a high temperature in a kiln. The unglazed or body glazed version has the color mixed into the wet clay so the color runs through them. They vary in size.\n\nThis is the classic mosaic material. It is opaque glass fired in large slabs in a kiln and then hand cut with a hammer and hardy chisel into small cubes. Their irregular finish makes them a wonderful reflector of light and this material is best used working straight into cement. It is produced in Venice and sold by colour and weight.\nThis tile is made with real gold and silver leaf sandwiched between two layers of glass and fired twice in the kiln to embed in the metal.\nMirror adds great depth and sparkle to a mosaic. It is cheap as offcuts from a glass cutting shop are often free. Use mirror glue as this protects the silver on the back of the mirror.\nKnown for its translucent qualities stained glass is also available in opaque form. It comes as large sheets that can be cut into smaller sections with a glasscutter. It can provide areas of larger tesserae pieces for variety and contrast.\nColours and surfaces are limitless and can add texture and contrast to mosaic work, especially in the technique known as trencadís or pique assiette.\n\n"}
{"id": "18712595", "url": "https://en.wikipedia.org/wiki?curid=18712595", "title": "Tollmien–Schlichting wave", "text": "Tollmien–Schlichting wave\n\nIn fluid dynamics, a Tollmien–Schlichting wave (often abbreviated T-S wave) is a streamwise unstable wave which arises in a bounded shear flow (such as boundary layer and channel flow). It is one of the more common methods by which a laminar bounded shear flow transitions to turbulence. The waves are initiated when some disturbance (sound, for example) interacts with leading edge roughness in a process known as receptivity. These waves are slowly amplified as they move downstream until they may eventually grow large enough that nonlinearities take over and the flow transitions to turbulence.\n\nThese waves, originally discovered by Ludwig Prandtl, were further studied by two of his former students, Walter Tollmien and Hermann Schlichting after whom the phenomenon is named.\n\nAlso, the T-S wave is defined as the most unstable eigen-mode of Orr–Sommerfeld equations (Page 64). \n\nIn order for a boundary layer to be absolutely unstable (have an inviscid instability), it must satisfy Rayleigh's criterion; namely\nformula_1\nwhere formula_2 represents the y-derivative and formula_3 is the free stream velocity profile. In other words, the velocity profile must have an inflection point to be unstable.\n\nIt is clear that in a typical boundary layer with a zero pressure gradient, the flow will be unconditionally stable; however, we know from experience this is not the case and the flow does transition. It is clear, then, that viscosity must be an important factor in the instability. It can be shown using energy methods that\n\nformula_4\n\nThe rightmost term is a viscous dissipation term and is stabilizing. The left term, however, is the Reynolds stress term and is the primary production method for instability growth. In an inviscid flow, the formula_5 and formula_6 terms are orthogonal, so the term is zero, as one would expect. However, with the addition of viscosity, the two components are no longer orthogonal and the term becomes nonzero. In this regard, viscosity is destabilizing and is the reason for the formation of T-S waves.\n\nIn a laminar boundary layer, if the initial disturbance spectrum is nearly infinitesimal and random (with no discrete frequency peaks), the initial instability will occur as two-dimensional Tollmien–Schlichting waves, travelling in the mean flow direction if compressibility is not important. However, three-dimensionality soon appears as the Tollmien–Schlichting waves rather quickly begin to show variations.\nThere are known to be many paths from Tollmien–Schlichting waves to turbulence, and many of them are explained by the non-linear theories of flow instability.\n\nA shear layer develops viscous instability and forms Tollmien–Schlichting waves which grow, while still laminar, into finite amplitude (1 to 2 percent of the freestream velocity) three-dimensional fluctuations in velocity and pressure to develop three-dimensional unstable waves and hairpin eddies. From then on, the process is more a breakdown than a growth. The longitudinally stretched vortices begin a cascading breakdown into smaller units, until the relevant frequencies and wave numbers are approaching randomness. Then in this diffusively fluctuating state, intense local changes occur at random times and locations in the shear layer near the wall. At the locally intense fluctuations, turbulent 'spots' are formed that burst forth in the form of growing and spreading spots — the result of which is a fully turbulent state downstream.\n\nTollmien (1931) and Schlichting (1929) theorized that viscosity-induced grabbing and releasing of laminae created long-crested simple harmonic (SH) oscillations (vibrations) along a smooth flat boundary, at a flow rate approaching the onset of turbulence. These T-S waves would gradually increase in amplitude until they broke up into the vortices, noise and high resistance that characterize turbulent flow. Contemporary wind tunnels failed to show T-S waves.\n\nIn 1943, Schubauer and Skramstad (S and S) created a wind tunnel that went to extremes to damp mechanical vibrations and sounds that might affect the airflow studies along a smooth flat plate. Using a vertical array of evenly spaced hot wire anemometers in the boundary layer (BL) airflow, they substantiated the existence of T-S oscillations by showing SH velocity fluctuations in the BL laminae. The T-S waves gradually increased in amplitude until a few random spikes of in-phase amplitude appeared, triggering focal vortices (turbulent spots), with noise. A further increase in flow rate resulted suddenly in many vortices, aerodynamic noise and a great increase in resistance to flow. An oscillation of a mass in a fluid creates a sound wave; SH oscillations of a mass of fluid, flowing in that same fluid along a boundary, must result in SH sound, reflected off the boundary, transversely into the fluid.\n\nS and S found foci of in-phase spiking amplitude in the T-S waves; these must create bursts of high amplitude sound, with high energy oscillation of fluid molecules transversely through the BL laminae. This has the potential to freeze laminar slip (laminar interlocking) in these spots, transferring the resistance to the boundary: this breaking at the boundary could rip out pieces of T-S long-crested waves which would tumble head-over-heels downstream in the boundary layer as the vortices of turbulent spots. With further increase in flow rate, there is an explosion into turbulence, with many random vortices and the noise of aerodynamic sound.\n\nSchubauer and Skramstad overlooked the significance of the co-generation of transverse SH sound by the T-S waves in transition and turbulence. However, John Tyndall (1867) in his transition-to-turbulence flow studies using flames, deduced that SH waves were created during transition by viscosity acting around the walls of a tube and these could be amplified by blending with similar SH sound waves (from a whistle), triggering turbulence at lower flow rates. Schubauer and Skramstad introduced SH sound into the boundary layer by creating SH fluttering vibrations of a BL ferromagnetic ribbon in their 1941 experiments, similarly triggering turbulence at lower flow rates.\n\nTyndall’s contribution towards explaining the mystery of transition to turbulence 150 years ago is beginning to gain recognition.\n"}
{"id": "47210155", "url": "https://en.wikipedia.org/wiki?curid=47210155", "title": "Tungabhadra Pushkaralu", "text": "Tungabhadra Pushkaralu\n\nTungabhadra Pushkaram is a festival of River Tungabhadra normally occurs once in 12 years. This Pushkaram is observed for a period of 12 days from the time of entry of Jupiter into \"Makara\" rasi (Capricorn).\n\n"}
{"id": "21010786", "url": "https://en.wikipedia.org/wiki?curid=21010786", "title": "Western and Central Pacific Fisheries Commission", "text": "Western and Central Pacific Fisheries Commission\n\nThe Western and Central Pacific Fisheries Commission (WCPFC) is a treaty-based organisation established to conserve and manage tuna and other highly migratory fish stocks across the western and central areas of the Pacific Ocean Its full name is Commission for the Conservation and Management of Highly Migratory Fish Stocks in the Western and Central Pacific Ocean. . It commenced operations in late 2005, and its secretariat is based in Pohnpei, in the northern Pacific state of the Federated States of Micronesia.\n\nIt was established by the International treaty \"Convention on the Conservation and Management of Highly Migratory Fish Stocks in the Western and Central Pacific Ocean\" (WCPF Convention), which entered into force on . The WCPF Convention is the second regional fisheries management agreement negotiated since the conclusion of the 1995 U.N. Fish Stocks Agreement.\n\nThe WCPF Convention was based on the 1995 UN Fish Stocks Agreement, and addressed the specific characteristics of the western and central Pacific Ocean. It established a framework for the participation of fishing entities legally binding them to its provisions. Territories and possessions can participate in the work of the Commission, which is also cooperate swith fisheries in other regions whose competence overlaps with WCPFC. Cooperation with the Inter-American Tropical Tuna Commission is of particular importance because of the overlap in respective Convention Areas and the wide range of some of the stocks (such as Bigeye tuna, and the two Albacore Tuna stocks) jointly managed by WCPFC and IATTC. The High Seas of the WCPFC Convention Area also overlaps with the South Pacific Regional Fisheries Management Organisation and the new North Pacific Fisheries Commission Convention Area. However the fish stocks managed by these RFMOs are different from those managed by WCPFC, and interactions are likely to be restricted to those involving bycatch and multipurpose vessels.\n\nThe WCPFC Secretariat maintains Register of Fishing Vessels authorized by their flag States to fish for tuna and other relevant highly migratory fish stocks in the WCPFC Convention Area, manages a Vessel Monitoring System, maintains standards for the national and subregional observer programs that make up the Regional Observer Program, and convenes meetings of the Commission. Primary scientific services are provided under contract by the Oceanic Fisheries Programme of the Secretariat of the Pacific Community, and one of the WCPFC subsidiary bodies - the Northern Committee - also obtains scientific advice from The International Scientific Committee for Tuna and Tuna-Like Species in the North Pacific Ocean (ISC).\n\nThe current Chair of the Commission is Rhea Moss-Christian was elected to the position in December 2014. She succeeds Charles Karnella of the USA. Satya Nandan from Fiji, who was also the first Secretary-General of the International Seabed Authority, was the previous Chair, and the first Chair of the WCPFC was Glenn Hurry, a former CEO of the Australian Fisheries Management Authority. The secretariat for the commission is located in Kolonia, Pohnpei, Federated States of Micronesia in a building funded by the Chinese government. The Commission held its twelfth regular session in December 2015, in Bali, Indonesia.\n\nIn December 2014 at the 11th regular session of the WCPFC in Apia, Samoa, Feleti Teo was appointed the Executive Director of the Commission. Teo previously served as Attorney General of Tuvalu, Director General of the Forum Fishery Agency, Deputy Secretary General of the Pacific Islands Forum and in 2008 he had been the acting Secretary General of the Pacific Islands Forum.\n\nDecisions of the Commission are normally made by consensus, but the WCPFC Convention also provides for a two-chambered voting mechanism, with member countries of the Pacific Islands Forum Fisheries Agency (FFA) forming one chamber.\n\nThe Commission has three formal subsidiary bodies: the Scientific Committee (SC), which usually meets in early August; the Northern Committee (NC), which usually meets in early September; and t he Technical and Compliance Committee (TCC), which usually meets in late September.\nMembership of the Commission is open to the States that participated in negotiating the 2004 Convention. The contracting parties to the Convention, by consensus, may invite States or regional economic integration organizations that wish to fish for highly migratory fish stocks in the western and central Pacific to accede to the Convention. This approach restricts access, emphasizing that the initiative to accede lies with existing parties, not with new applicants.\n\n\n\n\nThe status of stocks under the oversight of the Commission is informally summarized in the ISSF Status of Stocks Report.\n\nIn June 2015 the fisheries ministers of the countries that are parties to the Nauru Agreement met in Palikir, Pohnpei, under the chairmanship of Elisala Pita of Tuvalu, who stated that in 2015 Tuvalu has refused to sell fishing days to certain nations and fleets that have blocked Tuvaluan initiatives to develop and sustain their own fishery. Elisala Pita also said that Tuvalu was disappointed with the outcomes of recent meetings of the WCPFC as some fishing nations had tried to avoid their responsibilities and commitment to sustainable fishing.\n\n\n"}
{"id": "18365403", "url": "https://en.wikipedia.org/wiki?curid=18365403", "title": "Wildland fire emission", "text": "Wildland fire emission\n\nWildland fire and wildland fire atmospheric emissions have been a part of the global biosphere for millennia. The major wildland fire emissions include greenhouse gasses and several criteria pollutants that impact human health and welfare.:\nCompared to the preindustrial era, wildland land fire in the conterminous U.S. has been reduced 90 percent with proportional reductions in wildland fire emissions. Land use changes (agriculture and urbanization) are responsible for roughly 50 percent of this decrease, and land management decisions (land fragmentation, suppression actions, etc.) are responsible for the remainder. Anthropogenic activities (e.g., industrial production, transportation, agriculture, etc.) today have more than replaced the lost preindustrial wildland fire atmospheric emissions.\n\nThe following charts compare preindustrial wildland fire emissions with contemporary emissions.\n"}
