{"id": "16314077", "url": "https://en.wikipedia.org/wiki?curid=16314077", "title": "Airborne fraction", "text": "Airborne fraction\n\nThe airborne fraction is a scaling factor defined as the ratio of the annual increase in atmospheric to the emissions from anthropogenic sources. It represents the proportion of human emitted that remains in the atmosphere. The fraction averages about 45%, meaning that approximately half the human-emitted is absorbed by ocean and land surfaces. There is some evidence for a recent increase in airborne fraction, which would imply a faster increase in atmospheric for a given rate of human fossil-fuel burning. However, other sources suggest that the \"fraction of carbon dioxide has not increased either during the past 150 years or during the most recent five decades\". \n\nChanges in carbon sinks can affect the airborne fraction.\n"}
{"id": "5265080", "url": "https://en.wikipedia.org/wiki?curid=5265080", "title": "Angstrom exponent", "text": "Angstrom exponent\n\nÅngström exponent is the name of the exponent in the formula that is usually used to describe the dependency of the aerosol optical thickness, or aerosol extinction coefficient on wavelength.\n\nDepending on particle size distribution, the spectral dependence of the aerosol optical thickness is given approximately by\n\nwhere formula_2 is the optical thickness at wavelength formula_3, and formula_4 is the optical thickness at the reference wavelength formula_5. In principle, if the optical thickness at one wavelength and the Ångström exponent are known, the optical thickness can be computed at a different wavelength. In practice, measurements are made of the optical thickness of an aerosol layer at two different wavelengths, and the Ångström exponent is estimated from these measurements using this formula. The aerosol optical thickness can then be derived at all other wavelengths, within the range of validity of this formula.\n\nFor measurements of optical thickness formula_6 and formula_7 taken at two different wavelengths formula_8 and formula_9 respectively, the Ångström exponent is given by\n\nThe Ångström exponent is inversely related to the average size of the particles in the aerosol: the smaller the particles, the larger the exponent. Thus, Ångström exponent is a useful quantity to assess the particle size of atmospheric aerosols or clouds, and the wavelength dependence of the aerosol/cloud optical properties. For example, cloud droplet, usually with large sizes and thus very smaller Ångström exponent (nearly zero), is spectrally neutral, which means, e.g., the optical depth does not change with wavelength. This exponent is now routinely estimated by analyzing radiation measurements acquired on Earth Observation platforms, such as AErosol RObotic NETwork, or AERONET.\n\n\n\n"}
{"id": "3487972", "url": "https://en.wikipedia.org/wiki?curid=3487972", "title": "Boreal (age)", "text": "Boreal (age)\n\nIn paleoclimatology of the Holocene, the Boreal was the first of the Blytt-Sernander sequence of north European climatic phases that were originally based on the study of Danish peat bogs, named for Axel Blytt and Rutger Sernander, who first established the sequence. In peat bog sediments, the Boreal is also recognized by its characteristic pollen zone. It was preceded by the Younger Dryas, the last cold snap of the Pleistocene, and followed by the Atlantic, a warmer and moister period than our most recent climate. The Boreal, transitional between the two periods, varied a great deal, at times having within it climates like today's.\n\nSubsequent to the original Blytt-Sernander scheme, the first stage of the Boreal was divided off as a Pre-boreal transitional phase, followed by the Boreal proper. Some current schemes based on pollen zones also distinguish a pre-Boreal (pollen zone IV), an early Boreal (pollen zone V) and a late Boreal (pollen zone VIa, b, and c).\n\nOne commonly cited date for the end of the Younger Dryas and the start of the Pre-Boreal is 11,500 Before Present calibrated. The start of the period is relatively sharply defined by a rise of 7 °C in 50 years in South Greenland. The date is based fairly solidly on Greenland ice cores, which give 11,640 BP for the late Younger Dryas and 11,400 BP for the early Pre-Boreal.\nBut estimates of other dates vary by up to 1000 years, for a number of reasons. First, \"Boreal\" can identify a paleoclimate, a pollen zone or a temporally-fixed chronozone, and those three bases of definition allow quite different dates. Second, different dating methods obtain different dates. The underlying problem is that climate and pollen vary somewhat from region to region. The scientists of each region use the methods available in their region, whether lake varves, the annual layers of sediment from ancient or modern lake bottoms, ice cores or counts of tree rings (dendrochronology).\n\nStandardization has become of increasing concern to scientists everywhere. Dates from many methods continue to multiply as paleoclimatologists seek higher resolution. But it is unclear whether regional variation will allow high-resolution standardization.\nYet, there are some solid dates of the Pre-Boreal and Boreal. The Saksunarvatn tephra (an ash layer of volcanic fall-out) is dated in Greenland ice to 10,180±60 BP; in lake deposits at Krakenes in Norway, to 10,010–9,980 years BP calibrated; in northwest German lakes, to 10,090 BP calibrated. The tephra occurs in early Boreal contexts. So, it seems certain that the early Boreal (pollen zone V) includes the year 10,000 BP. Similarly, the late Boreal includes the Kilian/Vasset tephra of Swiss and southwest German lakes at 8200 BP, all calibrated. But the borders are less certain.\nStudies of bogs in northwest Russia are the basis for a division of the PreBoreal (PB) into PB-1, 10,000-9800, and PB-2, 9800–9300 BP incal. The scheme goes on to divide the Boreal (BO) into BO-1, 9300–9000, BO-2, 9000–8500, and BO-3, 8500–8000, incal. CalPal used on these dates suggests overall boundaries of 11,500 and 10,500 BP for the Pre-Boreal, and the end of the Boreal at 8900.\n\nDates given recently are usually earlier than those given more than 10 years ago. For example, Iverson (1973) and Rud (1979) give dates of 10,000–9000 BP for the PreBoreal and 9000–8000 BP for the Boreal, which are uncalibrated C-14 dates based on Scandinavian pollen stratigraphy.\n\nPresumably, more-recent dates are more accurate, as technology improves with time, often quite rapidly. Yet, pollen and climate phases also to some degree may depend on latitude, so no date can be regarded as certainly wrong. Scientists look for the overall pattern of the dates, but that technique is not 100% reliable, either.\n\nBefore the Pre-Boreal, Eurasia was locked in the chill of the Younger Dryas and was a mostly continuous tundra belt, with regions of taiga, covered with a blanket of grasses, shrubs and other low plants typical of open land. Large numbers of herbivores wandered in herds over vast distances. The blanket teemed with small, rapidly reproducing species, which supported food chains of larger predators. The largest predators and humans hunted the mammals of the open tundra.\n\nThe Pre-Boreal began with a sudden rise in temperature that abruptly changed this ecosystem. Forest replaced the open lands in Europe, and forest-dwelling animals spread from southern refugia and replaced the ice-age tundra mammals; new climax ecosystems developed. The old fauna persisted in Central Asia, but were soon hunted out, as they were not replenished by the larger areas formerly nourishing the ecosystem.\n\nThe sea brought additional isolation by rising rapidly and drowning the entire coast. Ireland was cut off early in the Boreal, suffering an impoverishment of species. It is home to only two-thirds of the species present in Britain. Britain was cut off by the end of the Boreal. Forest had closed over the former European tundra.\n\nHumans had to adapt to the encroaching forest or move east with the large mammals. Those who stayed became hunter-gatherers of the forests and fishers of the numerous bays, inlets and shallow waters around the thousands of islands that now spangled the seas of Europe. They lived richly and were encouraged to enter the pre-productive phase that we call the Mesolithic. Those who moved east hunted out the last of wild big game and turned their best efforts into learning to herd what was left. In the Americas, humans had left the Paleoindian phase and were now in the Archaic.\n\nMeanwhile humanity toward the south of the north temperate zone had already turned to food production in a number of widely separated locations and were on the brink of civilization. There is no evidence of any extensive contact with the cultures of the north during the Boreal. The producers tended to live in dense centers without any interest in moving from there except when motivated to find new lands. The gatherers ranged widely over their lands, building only temporary settlements in which to spend the winter.\n\nDuring the Pre-Boreal pollen zone IV, large quantities of tree pollen began to replace the pollen of open-land species, as the most mobile and flexible arboreal species colonized their way northward, replacing the ice-age tundra plants. Foremost among them were the birches, \"Betula pubescens\" and \"Betula pendula\", accompanied by \"Sorbus aucuparia\" and quaking aspen, \"Populus tremula\". Especially sensitive to temperature changes and moving northward almost immediately were \"Juniperus nana\" and \"J. communis\", the dwarf and shrub juniper respectively, which reached a maximum density in the Pre-Boreal, before their niches were shaded out. Pine soon followed, for which reason the resulting open woodland is often called a birch or a pine-birch forest. \nIn the yet warmer early Boreal pollen zone V, \"Corylus avellana\" (hazel) and pine expanded into the birch woodlands to such a degree that palynologists refer to the resulting ecology as the hazel-pine forest. In the late Boreal it was supplanted by the spread of a deciduous forest called the mixed-oak forest. Pine, birch and hazel were reduced in favor of \"Quercus\", \"Ulmus\", \"Tilia\" and \"Alnus\". The former tundra was now closed by a canopy of dense forest. In the marshland \"Typha latifolia\" prevailed. Less cold-tolerant species such as ivy and mistletoe were to be found in Denmark.\n\nThe new forest was populated with animals from refugia in Italy, Spain and the Balkans. Animals such as \"Emys orbicularis\" (European pond tortoise), which require warmer temperatures, were to be found in Denmark. The Eurasian golden plover came as far north as Norway.\nForest ungulates included: Cervidae \"Cervus elaphus\" (red deer), \"Capreolus capreolus\" (roe deer), \"Alces alces\" (elk), \"Sus scrofa\" (wild pig), and \"Bos primigenius\" (aurochs). Predators included: \"Canis lupus\" (wolf), \"Ursus arctos\" (brown bear), \"Lynx lynx\" (lynx), \"Felis sylvestris\" (wildcat), and herbivores \"Lepus europaeus\" (European hare).\nThe inland waters would have contained mammal species such as \"Castor fiber\" (beaver), \"Lutra lutra\" (otter) and species of fish such as \"Esox lucius\" (northern pike) and \"Siluris glanis\" (catfish).\n\nThe Preboreal-Boreal in Europe was a time of transition from the Palaeolithic cultures to the Mesolithic. Forests and drowned coastlands were places of plenty. Human settlements avoided the deep forest in favor of streams, lakes, and especially bays of the ocean.\n\nPre-Boreal settlements have been found in north-central Europe, such as at Friesack. There an unusual find of net fragments made from plant fibers suggested that fishing was an important part of life.\n\nFinds from another settlement at Vis, near the Vychegda River in Russia, offer more details of life in a settlement of the Boreal. Plant fibers were used for baskets and for hafting bone points to shafts. Fishermen crossed the waters in bark boats plied by oars, and set nets. They also made hand-held nets from wooden hoops and plant fiber.\n\nFood gathering continued in winter: skis and sledge runners have been found. Reindeer continued to be hunted and probably herded. Bows, arrows, and spears have been found. Implements were likely to be embellished by sculpting in wood or bone. Only a few motifs were used: the elk's head, the snake, and human.\n\nIn Europe, the major culture was the Maglemosian (9000–6400 BC), extending into Denmark and Russia. Localized cultures included the Nieman of Lithuania, the Kunda of Latvia and Estonia, the Azilian of France, and the Epi-Gravettian of Italy. Towards the end of the Mesolithic, local traditions began to multiply, perhaps due to influences from the south, or due to the general advance of culture.\n\nIn North America the San Dieguito Complex and Lake Mojave Complex existed in this period, located in Southern California's coastal region and Mojave Desert, and in northern Mexico's Sonoran Desert in the Yuma Desert and Baja California peninsula.\n\n\n"}
{"id": "8669136", "url": "https://en.wikipedia.org/wiki?curid=8669136", "title": "Boston Christmas Tree", "text": "Boston Christmas Tree\n\nThe Boston Christmas Tree is the City of Boston, Massachusetts' official Christmas tree. A tree has been lit each year since 1941, and since 1971 it has been given to the people of Boston by the people of Nova Scotia in thanks for their assistance after the 1917 Halifax Explosion. The tree is lit in the Boston Common throughout the Christmas season.\n\nOn December 6, 1917 at 9:04:35 am, the Halifax Explosion severely destroyed much of the city, by the largest man-made explosion up to that time. Boston authorities learned of the disaster by telegraph, and quickly organized and dispatched a relief train around 10 pm to assist survivors. A blizzard delayed the train, which finally arrived in the early morning of December 8, and immediately began distributing food, water, and medical supplies. Numerous personnel on the train were able to relieve the Nova Scotia medical staff, most of whom had worked without rest since the explosion occurred. Nova Scotian children study the explosion in school and they know \"Boston was one of the first responders, and really a lifesaver.\"\n\n<br>\nNova Scotia donated a large Christmas tree to the city of Boston in thanks and remembrance for the help Boston Red Cross and the Massachusetts Public Safety Committee provided immediately after the Halifax Explosion of 1917. Another tree was sent in 1971, and every year since. \n\nThe annual gift was started by the Lunenburg County Christmas Tree Producers Association to promote Christmas tree exports as well as acknowledge the Boston support after the explosion. The gift was taken over by the Nova Scotia Government in 1976 to continue the goodwill gesture and to promote trade and tourism. \n\nIn 2017, in honor of the 100th anniversary of the explosion, Boston Mayor Martin J. Walsh, Halifax Mayor Michael Savage, and Nova Scotia Premier Stephen McNeil unveiled a plaque on the Boston Common near the site of the tree. The tree that year was donated in honor of first responders in the two cities.\n\nJoseph Slauenwhite donated the first two trees. The tree typically comes from the southern half of the province, but in 2014 the tree came from Antigonish County, in the north and in 2016 the first tree ever from Cape Breton Island was selected. In 2018, the first tree from Cumberland County was donated.\n\nThe province also donates smaller trees to Rosie's Place and the Pine Street Inn, homeless shelters in Boston.\n\nThe Christmas Tree Extension Specialist whose responsibility it is to select a tree is \"always looking\" for trees, and keeps a list of trees for years. The scouting for the current year's tree begins in June and July.\n\nMost donors are \"honored to give up their trees... [and] most will gladly watch their towering trees fall\" since everyone knows the reason it is being sent to Boston. Owners often would not normally \"have dreamed of cutting down the big spruce Grandpa planted\" but will \"gladly part with it\" when told it is going to Boston. They \"consider it a great honor\" and say, 'Oh, my God, how can I refuse?\"' It is sometimes donated in memory of a family member who died in the explosion. The process can be political as families vie to have their tree chosen.\n\nKnowing its symbolic importance to both cities, the Nova Scotia Department of Natural Resources has specific guidelines for selecting the tree. It must be an attractive balsam fir, white spruce or red spruce, 12 to 16 meters (40 to 50 feet) tall, healthy with good color, medium to heavy density, uniform and symmetrical and easy to access. The trees do not usually come from tree farms, but from open land where they can grow tall and full.\n\nThe Nova Scotia Department of Natural Resources Christmas Tree Specialist has the responsibility for selecting the tree each year. For the specialist the \"tree can be elusive, the demands excessive, and the job requires remembering the locations of the best specimens in the province and persuading the people who own them to give them up for a pittance.\" The first Specialist was Tom Ernst, and he was followed in the 1990s by Peter Romkey. , the Christmas Tree Extension Specialist responsible for selecting the Boston tree is Ross H. Pentz, a position he has held since 2001.\n\nBefore the tree is cut, each branch is individually tied to the trunk. It takes two men a day and a half to prepare the tree to be cut down. A crane holds the tree at the top while it is cut at the base by a chainsaw.\n\nThe tree cutting ceremony has been described as \"quite the local spectacle for Nova Scotians,\" and features representatives from the province, the United States Consulate in Halifax, the Christmas Tree Council of Nova Scotia, hundreds of local school children, a town crier, Royal Canadian Mounted Police, Nova Scotia conservation officers, an Antigonish bagpiper, the Nova Scotia Mass Choir, and Santa Claus.\n\nIn 2014, students and staff in the environmental technologies program at the Nova Scotia Community College Strait Area Campus cut down that year's tree.\n\nThe tree travels over to Boston, with a stop at the Grand Parade in Halifax for a public send-off ceremony featuring a live musical performance by The Stanfields. Attendees are also invited to sign a thank you book for Boston. The tree travels by truck across Nova Scotia, then cruises on a ferry across the Bay of Fundy, continuing by truck through Maine and New Hampshire to Boston. People stand on the sides of roads and on highway overpasses to get a glimpse of the tree and to take pictures. \n\nIn 2013, the tree was led out of Halifax by a group of runners in honor of victims of the Boston Marathon bombings. Special permits are required to transport the tree through Nova Scotia, New Brunswick, and Maine.\n\nThe tree arrives in Boston under police escort. In the same way that schoolchildren see the tree off in Nova Scotia, schoolchildren from Boston are on hand to welcome it to the Boston Common.\n\nThe tree lighting takes place on the Common in late November or early December. The event attracts about 20,000 people and 200,000 watch the broadcast on WCVB. The 1998 tree required more than 3,200 man hours to decorate, as well as of wire and 17,000 multi-colored lights. The 2006 tree was covered in 8,000 bulbs.\n\nThe tree donated by Nova Scotia was placed at the Prudential Center from 1971 until 2002, when it was moved to the Boston Common because of planned development.\n\nThe tree is so important to the people of Nova Scotia that \"people have cried over it, argued about it, even penned song lyrics in its honour.\" Lands and Forestry Minister Iain Rankin called it \"one of our proudest traditions.\" A spokesman for the spokesman for the Department of Lands and Forestry said \"It never ceases to amaze me how excited people get about it every year. The whole province gets excited about the tree. It’s a big deal.\"\n\nWhile the donation of the Christmas Tree is first and foremost a gift, it is also a major marketing effort for Nova Scotia. In 2015, the total cost of the tree, transportation, ceremonies, and parties was ().\n\nThe scouting of the tree costs , and the cutting ceremony was . For all of their coverage and efforts, CTV Atlantic received . Promotion on Facebook and Instagram cost an additional . The sendoff in Halifax cost and transporting the tree cost . Merchandise was given away at events in both Massachusetts and Nova Scotia, including tuques at a cost of , flags at and lanyards at .\n\nProvincial officials, including the premier and his staff, were flown to Boston and put up in local hotels at an expense of . The MacEachern family also received in travel expenses. WCVB, the Boston ABC affiliate received () to broadcast a live one-hour tree lighting special. A television commercial promoting Nova Scotia would cost about four times as much. The ceremony itself cost (), which was paid by Nova Scotia to the City of Boston. This is less than half of the the ceremony costs.\n\nA reception at the Omni Parker House cost . It was attended by the official delegation, as well as Nova Scotian businessmen who traveled at their own expense, and Nova Scotians living in the Boston area.\n\nGiven the media coverage the province gets in return, and “When you look at the entire scope of the thing, it’s a pretty good value for the province of Nova Scotia,” according to Ed McHugh, who teaches business and marketing at Nova Scotia Community College.\n\nThe \"regional media coverage [of the tree cutting ceremony is] huge.\" Television personalities from CTV Atlantic host the tree cutting ceremony and the send off in Halifax. In addition, their contract commits them to doing weather items and \"tree related elements\" live from Boston during the evening news on both the day of the lighting and the day after. In 2015, CTV produced and aired a 30-second commercial over a period of 10 days. They also provided digital promotion and news promotions. CTV estimates that this contribution represents a benefit to the province.\n\nThe tree is also promoted on Facebook and Instagram.\n\n"}
{"id": "57444168", "url": "https://en.wikipedia.org/wiki?curid=57444168", "title": "Brussels effect", "text": "Brussels effect\n\nThe Brussels effect is the process of unilateral regulatory globalisation caused by the European Union de facto (but not necessarily de jure) externalising its laws outside its borders through market mechanisms.\n\nThe combination of market size, market importance, relatively stringent standards and regulatory capacity of the European Union can have the effect that firms trading internationally find that it is not economically, legally or technically practical to maintain lower standards in non-EU markets. Non-EU companies exporting globally can find that it is beneficial to adopt standards set in Brussels uniformly throughout their business. \n\nThe term Brussels effect was coined in 2012 by Professor Anu Bradford of Columbia Law School and named after the similar California effect that can be seen within the United States.\n\nThe California effect and the Brussels effect are a form of ‘race to the top’ where the most stringent standard has an appeal to companies operating across multiple regulatory environments as it makes global production and exports easier. The effects are the opposite of the \"Delaware effect\", a race to the bottom where jurisdictions can purposely choose to lower its regulatory requirements in an attempt to attract businesses looking for the least stringent standard. \n\nThe October 2000 $42 billion proposed acquisition of US-based Honeywell International by US-based General Electric was blocked by the EU antitrust authorities on the grounds of risking a horizontal monopoly in jet engines. The merger could not proceed because, despite the American Department of Justice having already approved the merger between these two US based entities, it was not legally possible to let the acquisition proceed in one important market, but not in another. \n\nUS-based multinational Dow Chemical announced in 2006 it would comply with the EU's Registration, Evaluation, Authorisation and Restriction of Chemicals (REACH) regulation for the production and use of chemical substances across its global operation.\n\nIn 2012 the EU included aviation into its existing Emission Trading Scheme. This means that any airline, regardless of their country of origin, has to purchase emissions permits for any flights within the European Economic Area. The cost of complying with EU aviation emission regulation puts pressure on manufacturers to design airplanes with improved efficiency and reduced emissions. As major airlines would not likely purchase airplanes specifically to fly outside the EEA, the EU’s stricter aviation standards have an impact on global airplane fleets, regardless of the jurisdiction of the airline.\n\nWith the introduction of theData Protection Directive in 1995 the EU had opted for a strict top-down approach to data privacy. Its successor, the EU's General Data Protection Regulation (GDPR), was adopted on 14 April 2016 and had a global effect . In 2017, during negotiations for a new Japan-EU trade deal, Japan set up an independent agency to handle privacy complaints to conform with the EU's new privacy regulation.\nFacebook announced in April 2018 that it would implement parts of the GDPR globally, Sonos announced in April 2018 that it would implement the GDPR globally and Microsoft announced in May 2018 that it would implement GDPR compliance for all its customers globally.\n\n"}
{"id": "846198", "url": "https://en.wikipedia.org/wiki?curid=846198", "title": "CRRES", "text": "CRRES\n\nThe Combined Release and Radiation Effects Satellite (CRRES) was launched on July 25, 1990 into a geosynchronous transfer orbit (GTO) for a nominal three-year mission to investigate fields, plasmas, and energetic particles inside the Earth's magnetosphere. As part of the CRRES program, the SPACERAD (Space Radiation Effects) project, managed by Air Force Geophysics Laboratory, investigated the radiation environment of the inner and outer radiation belts and measured radiation effects on state-of-the-art microelectronics devices.\n\nOther magnetospheric, ionospheric, and cosmic ray experiments were also included onboard CRRES and supported by NASA or the Office of Naval Research. The chemical release project was managed by NASA/MSFC and utilized the release of chemicals from onboard canisters at low altitudes near dawn and dusk perigee times and at high altitudes near local midnight. The chemical releases were monitored with optical and radar instrumentation by ground-based observers to measure the bulk properties and movement of the expanding clouds of photo-ionized plasma along field lines after the releases occurred. In order to study the magnetosphere at different local times during the mission, the satellite orbit was designed to precess with respect to the Earth-Sun line such that the local time at apogee decreased by 2.5 minutes/day from 08:00 (LT) just after launch and returned to this position in nineteen month cycles.\n\nThe CRRES spacecraft had the shape of an octagonal prism with solar arrays on the top side. The prism is 1 m high and 3 m between opposite faces. Four of the eight compartments were for the chemical canisters and the other four housed the SPACERAD and other experiments. The spacecraft body was spun at 2.2 rpm about a spin axis in the ecliptic plane and kept pointed about 12 degrees ahead of the Sun's apparent motion in celestial coordinates. Pre-launch and in-flight operations were supported by the Space Test and Transportation Program Office of the U.S. Air Force Space Division. Contact with the CRRES spacecraft was lost on October 12, 1991 and was presumed to be due to onboard battery failure.\n\nTaken From NASA.\n\n\"This article incorporates text in the public domain from the National Space .html J-Track Live view of satellites\n"}
{"id": "35568077", "url": "https://en.wikipedia.org/wiki?curid=35568077", "title": "Cataract bog", "text": "Cataract bog\n\nA cataract bog is a rare ecological community formed where a permanent stream flows over a granite outcropping. The sheeting of water keeps the edges of the rock wet without eroding the soil; in this precarious location no tree or large shrub can maintain a roothold. The result is a narrow, permanently wet, sunny habitat.\n\nWhile a cataract bog is host to plants typical of a bog, it is technically a fen. Bogs get water from the atmosphere, while fens get their water from groundwater seepage.\n\nCataract bogs inhabit a narrow, linear zone next to the stream and are partly shaded by trees and shrubs in the adjacent plant communities. Algae growing on the rocks can make the surface slippery and dangerous for those exploring a cataract bog.\n\nThe rushing water carves out small depressions where soil accumulates, forming micro-islands that play host to plants that thrive with low levels of nutrients and shallow root structures. Typical species include Sphagnum moss; carnivorous plants such as round-leaf sundew (\"Drosera rotundifolia\"), pitcher plants (\"Sarracenia purpurea\" and \"S. jonesii\"), and horned bladderwort (\"Utricularia cornuta\"); several orchid species such as common grass pink (\"Calopogon tuberosus\"), small green wood-orchid (\"Platanthera clavellata\"), rose pogonia (\"Pogonia ophioglossoides\"), and nodding ladies'-tresses (\"Spiranthes cernua\"). Other plants found in cataract bogs are limeseep grass-of-Parnassus (\"Parnassia grandifolia\"), Indian paint brush (\"Castilleja coccinea\"), stiff cowbane (\"Oxypolis rigidior\"), Appalachian bluet (\"Houstonia serpyllifolia\") and northern sundrops (\"Oenothera tetragona\").\n\nThe plant communities are fragile because of their tenuous attachment to thin soil above the rock substrate. During prolonged drought, the stream may dry up and the edges of the micro-islands curl up. Heavy rainfall can then wash away the micro-islands, so a cataract bog is in a continual state of change and renewal.\n\nCataract bogs are found only in the southern Appalachian Mountains of the United States, at elevations of between . They are restricted to the Blue Ridge Escarpment region of South Carolina and a small area of North Carolina, a region with exceptionally high rainfall.\n"}
{"id": "13885985", "url": "https://en.wikipedia.org/wiki?curid=13885985", "title": "Computron tube", "text": "Computron tube\n\nThe Computron was an electron tube designed to perform the parallel addition and multiplication of digital numbers. It was conceived by Richard L. Snyder, Jr., Jan A. Rajchman, Paul Rudnick and the digital computer group at the laboratories of the Radio Corporation of America under the direction of Vladimir Zworykin. Development began in 1941 under contract OEM-sr-591 to Division 7 of the National Defense Research Committee of the United States Office of Research and Development.\n\nThe numerical function of the Computron was to solve the equation formula_1 where A, B, C, and D are 14 bit inputs and S is a 28 bit output. This function was key to the RCA attempt to produce a non-analog computer based fire-control system for use in artillery aiming during WWII.\n\nA simple way to describe the physically complex Computron is to begin with a cathode ray tube structure in the form of a right-circular cylinder with a central vertical cathode structure. The cylinder is composed of 14 discrete planes, each plane having 14 individual radial outward projecting beams. Each of the 196 individual beams is steered by multiple deflection plates toward its two targets. Some deflection plates are connected to circuitry external to the Computron and are the data inputs. The balance of the plates are connected to internal targets and are the partial sums and products from other stages within the tube. Some of the targets are connected to circuitry outside the tube and represent the result.\n\nThe electronic function of the Computron design incorporated steered, rather than gated, multiple electron beams. Additionally, the Computron was based on the ability of a secondary electron emission target, under electron bombardment, to assume the potential of the nearest collector electrode. The Additron Tube design by Josef Kates gated electron beams of a fixed trajectory with several control grids which either passed or blocked a current. The Computron was a complex cathode ray tube while the Additron was a triode with multiple grids and targets.\n\nA subsection of the Computron was prototyped and tested and the concept validated but the building of an entire device was never attempted.\n\nA United States Patent was filed 30 July 1943 and granted 22 July 1947 for the Computron.\n\nThe Computron design was an early attempt to produce not only a vacuum tube integrated circuit for both size and reliability (lifetime) issues, but to minimize external electrical connections between active elements. The goal of integration is not merely to reduce external signal connections into and out of a package by including multiple active devices in one package, as in the Loewe 3NF tube. It is to merge the functions of the active devices for a technical synergy. A modern example would be the multiple-emitter transistor of transistor–transistor logic integrated circuits\n\nAnother modern construct anticipated by the Computron is the barrel shifter circuit which is used in many numeric computation style microprocessors.\n\nThe Computron was an idea born of the necessity of war research. It was to be a key element of the electronic digital computer which had yet to be built. But the project was begun to increase the accuracy of artillery in battle, not to advance the state of the embryonic electronic computer.\n\nIts fate was well described in a letter to Dr. Paul E. Klopsteg, Head of NDRC Division 17, dated 6 February 1943 which concludes:\n\n...As I said above, our entire Division is exceedingly reluctant to see a development which is scientifically so beautiful and so promising dropped at this point, though cold reason tells us that we cannot justify the expenditure of additional Government funds on the basis of Fire Control at this time. \nSincerely yours, \nHarold L. Hazen \nChief, Division 7 \n"}
{"id": "12040404", "url": "https://en.wikipedia.org/wiki?curid=12040404", "title": "Diurnal temperature variation", "text": "Diurnal temperature variation\n\nIn meteorology, diurnal temperature variation is the variation between a high temperature and a low temperature that occurs during the same day.\n\nTemperature lag is an important factor in diurnal temperature variation: peak daily temperature generally occurs \"after\" noon, as air keeps net absorbing heat even after noon, and similarly minimum daily temperature generally occurs substantially after midnight, indeed occurring during early morning in the hour around dawn, since heat is lost all night long. The analogous annual phenomenon is seasonal lag.\n\nAs solar energy strikes the earth’s surface each morning, a shallow layer of air directly above the ground is heated by conduction. Heat exchange between this shallow layer of warm air and the cooler air above is very inefficient. On a warm summer’s day, for example, air temperatures may vary by from just above the ground to waist height. Incoming solar radiation exceeds outgoing heat energy for many hours after noon and equilibrium is usually reached from 3–5 p.m. but this may be affected by a variety of different things such as large bodies of water, soil type and cover, wind, cloud cover/water vapor, and moisture on the ground.\n\nDiurnal temperature variations are greatest very near Earth's surface.\n\nHigh desert regions typically have the greatest diurnal-temperature variations, while low-lying humid areas typically have the least. This explains why an area like the Snake River Plain can have high temperatures of during a summer day, and then have lows of . At the same time, Washington D.C., which is much more humid, has temperature variations of only ; urban Hong Kong has a diurnal temperature range of little more than . \n\nWhile the National Park Service claimed that the world single-day record is a variation of (from to ) in Browning, Montana in 1916, the Montana Department of Environmental Quality claimed that Loma, Montana also had a variation of (from to ) in 1972.\n\nDiurnal temperature variation is of particular importance in viticulture. Wine regions situated in areas of high altitude experience the most dramatic swing in temperature variation during the course of a day. In grapes, this variation has the effect of producing high acid and high sugar content as the grapes' exposure to sunlight increases the ripening qualities while the sudden drop in temperature at night preserves the balance of natural acids in the grape.\n\n"}
{"id": "37620824", "url": "https://en.wikipedia.org/wiki?curid=37620824", "title": "Drumian", "text": "Drumian\n\nThe Drumian is a stage of the Miaolingian Series of the Cambrian. It succeeds the Wuliuan and precedes the Guzhangian. The base is defined as the first appearance of the trilobite \"Ptychagnostus atavus\" around million years ago. The top is defined as the first appearance of another trilobite \"Lejopyge laevigata\" around million years ago.\n\nThe GSSP is defined in the \"Drumian section\" () in the Drum Mountains, Millard County, Utah, United States. The stage was also named after the Drum Mountains. The section is an outcrop of the Wheeler Formation, a succession of calcareous shales. The precise base of the Drumian is a laminated limestone above the base of the Wheeler Formation.\n\n"}
{"id": "9282", "url": "https://en.wikipedia.org/wiki?curid=9282", "title": "ECHELON", "text": "ECHELON\n\nECHELON, originally a secret government code name, is a surveillance program (signals intelligence/SIGINT collection and analysis network) operated by the US with the aid of four other signatory nations to the UKUSA Security Agreement: Australia, Canada, New Zealand and the United Kingdom, also known as the Five Eyes.\n\nThe ECHELON program was created in the late 1960s to monitor the military and diplomatic communications of the Soviet Union and its Eastern Bloc allies during the Cold War, and it was formally established in 1971.\n\nBy the end of the 20th century, the system referred to as \"ECHELON\" had evolved beyond its military and diplomatic origins to also become \"…a global system for the interception of private and commercial communications\" (mass surveillance and industrial espionage).\n\nThe European Parliament's Temporary Committee on the ECHELON Interception System stated, \"It seems likely, in view of the evidence and the consistent pattern of statements from a very wide range of individuals and organisations, including American sources, that its name is in fact ECHELON, although this is a relatively minor detail\". The U.S. intelligence community uses many code names (\"see\", for example, CIA cryptonym).\n\nFormer NSA employee Margaret Newsham claims that she worked on the configuration and installation of software that makes up the ECHELON system while employed at Lockheed Martin, from 1974 to 1984 in Sunnyvale, California, in the United States, and in Menwith Hill, England, in the UK. At that time, according to Newsham, the code name ECHELON was NSA's term for the computer network itself. Lockheed called it \"P415\". The software programs were called \"SILKWORTH\" and \"SIRE\". A satellite named \"VORTEX\" intercepted communications. An image available on the internet of a fragment apparently torn from a job description shows Echelon listed along with several other code names.\n\nBritain's \"The Guardian\" newspaper summarized the capabilities of the ECHELON system as follows:\n\nIn 1972, former NSA analyst Perry Fellwock under pseudonym Winslow Peck, first blew the whistle on ECHELON to \"Ramparts\" in 1972, where he gave commentary revealing a global network of listening posts and his experiences working there. Fellwock also included revelations such as the Israeli attack on was deliberate and known by both sides, the existence of nuclear weapons in Israel in 1972, the widespread involvement of CIA and NSA personnel in drugs and human smuggling, and CIA operatives leading Nationalist Chinese (Taiwan) commandos in burning villages inside PRC borders.\n\nIn 1982, James Bamford, investigative journalist and author wrote \"The Puzzle Palace\", an in-depth look inside the workings of the NSA, then a super-secret agency, and the massive eavesdropping operation under the codename \"SHAMROCK\". The NSA has used many codenames, and SHAMROCK was the code name used for ECHELON prior to 1975.\n\nIn 1988, Margaret Newsham, a Lockheed employee under NSA contract, disclosed the ECHELON surveillance system to members of congress. Newsham told a member of the U.S. Congress that the telephone calls of Strom Thurmond, a Republican U.S. senator, were being collected by the NSA. Congressional investigators determined that \"targeting of U.S. political figures would not occur by accident, but was designed into the system from the start.\"\n\nAlso in 1988, an article titled \"Somebody's Listening\", written by investigative journalist Duncan Campbell in the \"New Statesman\", described the signals intelligence gathering activities of a program code-named \"ECHELON\". James Bamford describes the system as the software controlling the collection and distribution of civilian telecommunications traffic conveyed using communication satellites, with the collection being undertaken by ground stations located in the footprint of the downlink leg.\n\nA detailed description of ECHELON was provided by New Zealand journalist Nicky Hager in his 1996 book \"Secret Power: New Zealand's Role in the International Spy Network\". Two years later, Hager's book was cited by the European Parliament in a report titled \"An Appraisal of the Technology of Political Control\" (PE 168.184).\n\nIn March 1999, for the first time in history, the Australian government admitted that news reports about the top secret UKUSA Agreement were true. Martin Brady, the director of Australia's Defence Signals Directorate (DSD, now known as Australian Signals Directorate, or ASD) told the Australian broadcasting channel Nine Network that the DSD \"does co-operate with counterpart signals intelligence organisations overseas under the UKUSA relationship.\"\n\nIn 2000, James Woolsey, the former Director of the U.S. Central Intelligence Agency, confirmed that U.S. intelligence uses interception systems and keyword searches to monitor European businesses.\n\nLawmakers in the United States feared that the ECHELON system could be used to monitor U.S. citizens. According to \"The New York Times\", the ECHELON system has been \"shrouded in such secrecy that its very existence has been difficult to prove.\" Critics said the ECHELON system emerged from the Cold War as a \"Big Brother without a cause\".\n\nThe program's capabilities and political implications were investigated by a committee of the European Parliament during 2000 and 2001 with a report published in 2001. In July 2000, the Temporary Committee on the ECHELON Interception System was established by the European parliament to investigate the surveillance network. It was chaired by the Portuguese politician Carlos Coelho, who was in charge of supervising investigations throughout 2000 and 2001.\n\nIn May 2001, as the committee finalised its report on the ECHELON system, a delegation travelled to Washington, D.C. to attend meetings with U.S. officials from the following agencies and departments:\n\nAll meetings were cancelled by the U.S. government and the committee was forced to end its trip prematurely. According to a BBC correspondent in May 2001, \"The US Government still refuses to admit that Echelon even exists.\"\n\nIn July 2001, the Temporary Committee on the ECHELON Interception System released its final report. On 5 September 2001, the European Parliament voted to accept the committee's report.\n\nThe European Parliament stated in its report that the term ECHELON is used in a number of contexts, but that the evidence presented indicates that it was the name for a signals intelligence collection system. The report concludes that, on the basis of information presented, ECHELON was capable of interception and content inspection of telephone calls, fax, e-mail and other data traffic globally through the interception of communication bearers including satellite transmission, public switched telephone networks (which once carried most Internet traffic), and microwave links.\n\nTwo internal NSA newsletters from January 2011 and July 2012, published as part of the Snowden-revelations by the website \"The Intercept\" on 3 August 2015, for the first time confirmed that NSA used the code word ECHELON and provided some details about the scope of the program: ECHELON was part of an umbrella program code named FROSTING, which was established by the NSA in 1966 to collect and process data from communications satellites. FROSTING had two sub-programs:\n\nThe UKUSA intelligence community was assessed by the European Parliament (EP) in 2000 to include the signals intelligence agencies of each of the member states:\nThe EP report concluded that it seemed likely that ECHELON is a method of sorting captured signal traffic, rather than a comprehensive analysis tool.\n\nIn 2001, the EP report (p. 54 ff) listed the following ground stations as likely to have, or to have had, a role in intercepting transmissions from telecommunications satellites:\n\nThe following stations are listed in the EP report (p. 57 ff) as ones whose roles \"cannot be clearly established\":\n\nThe ability to intercept communications depends on the medium used, be it radio, satellite, microwave, cellular or fiber-optic. During World War II and through the 1950s, high-frequency (\"short-wave\") radio was widely used for military and diplomatic communication and could be intercepted at great distances. The rise of geostationary communications satellites in the 1960s presented new possibilities for intercepting international communications.\n\nIn 1964, plans for the establishment of the ECHELON network took off after dozens of countries agreed to establish the International Telecommunications Satellite Organisation (Intelsat), which would own and operate a global constellation of communications satellites.\n\nIn 1966, the first Intelsat satellite was launched into orbit. From 1970 to 1971, the Government Communications Headquarters (GCHQ) of Britain began to operate a secret signal station at Morwenstow, near Bude in Cornwall, England. The station intercepted satellite communications over the Atlantic and Indian Oceans. Soon afterwards, the U.S. National Security Agency (NSA) built a second signal station at Yakima, near Seattle, for the interception of satellite communications over the Pacific Ocean.\n\nIn 1981, GCHQ and the NSA started the construction of the first global wide area network (WAN). Soon after Australia, Canada, and New Zealand joined the ECHELON system. The report to the European Parliament of 2001 states: \"If UKUSA states operate listening stations in the relevant regions of the earth, in principle they can intercept all telephone, fax, and data traffic transmitted via such satellites.\"\n\nMost reports on ECHELON focus on satellite interception. Testimony before the European Parliament indicated that separate but similar UKUSA systems are in place to monitor communication through undersea cables, microwave transmissions, and other lines. The report to the European Parliament points out that interception of private communications by foreign intelligence services is not necessarily limited to the U.S. or British foreign intelligence services.\n\nThe role of satellites in point-to-point voice and data communications has largely been supplanted by fiber optics. In 2006, 99% of the world's long-distance voice and data traffic was carried over optical-fiber. The proportion of international communications accounted for by satellite links is said to have decreased substantially to an amount between 0.4% and 5% in Central Europe. Even in less-developed parts of the world, communications satellites are used largely for point-to-multipoint applications, such as video. Thus, the majority of communications can no longer be intercepted by earth stations; they can only be collected by tapping cables and intercepting line-of-sight microwave signals, which is possible only to a limited extent.\n\nBritish journalist Duncan Campbell and New Zealand journalist Nicky Hager asserted in the 1990s that the United States was exploiting ECHELON traffic for industrial espionage, rather than military and diplomatic purposes. Examples alleged by the journalists include the gear-less wind turbine technology designed by the German firm Enercon and the speech technology developed by the Belgian firm Lernout & Hauspie.\n\nIn 2001, the Temporary Committee on the ECHELON Interception System recommended to the European Parliament that citizens of member states routinely use cryptography in their communications to protect their privacy, because economic espionage with ECHELON has been conducted by the U.S. intelligence agencies.\n\nAmerican author James Bamford provides an alternative view, highlighting that legislation prohibits the use of intercepted communications for commercial purposes, although he does not elaborate on how intercepted communications are used as part of an all-source intelligence process.\n\nIn its report, the committee of the European Parliament stated categorically that the Echelon network was being used to intercept not only military communications, but also private and business ones. In its epigraph to the report, the parliamentary committee quoted Juvenal, \"\"Sed quis custodiet ipsos custodes\". (\"But who will watch the watchers\"). James Bamford, in \"The Guardian\" in May 2001, warned that if Echelon were to continue unchecked, it could become a \"cyber secret police, without courts, juries, or the right to a defence\".\n\nAlleged examples of espionage conducted by the members of the \"Five Eyes\" include:\n\n\nThe first American satellite ground station for the ECHELON collection program was built in 1971 at a military firing and training center near Yakima, Washington. The facility, which was codenamed JACKKNIFE, was an investment of ca. 21.3 million dollars and had around 90 people. Satellite traffic was intercepted by a 30-meter single dish antenna. The station became fully operational on 4 October 1974. It was connected with NSA headquarters at Fort Meade by a 75-baud secure Teletype orderwire channel.\n\nIn 1999 the Australian Senate Joint Standing Committee on Treaties was told by Professor Desmond Ball that the Pine Gap facility was used as a ground station for a satellite-based interception network. The satellites were said to be large radio dishes between 20 and 100 meters in diameter in geostationary orbits. The original purpose of the network was to monitor the telemetry from 1970s , air defence and other radars' capabilities, satellites' ground stations' transmissions and ground-based microwave communications.\n\nIn 1999, Enercon, a German company and leading manufacturer of wind energy equipment, developed a breakthrough generator for wind turbines. After applying for a US patent, it had learned that Kenetech, an American rival, had submitted an almost identical patent application shortly before. By the statement of a former NSA employee, it was later discovered that the NSA had secretly intercepted and monitored Enercon's data communications and conference calls and passed information regarding the new generator to Kenetech. As German intelligence services are forbidden from engaging in industrial or economic espionage, German companies are frequently complaining that this leaves them defenceless against industrial espionage from the United States. According to Wolfgang Hoffmann, a former manager at Bayer, German intelligence services are aware which companies are being targeted by US intelligence agencies, but refuse to inform the companies involved.\n\nThe television series \"Alias\" made recurring references to ECHELON throughout its run.\n\nThe antagonist of the anime series \"Digimon Tamers\", D-Reaper, was created by ECHELON.\n\n\"Echelon Conspiracy\", inspired by the surveillance system ECHELON, is a 2009 action thriller film directed by Greg Marcks. It tells the story of Max Peterson (Shane West), an American computer specialist who attempts to uncover a secret plot to turn the world into a global police state. After being chased down by NSA agent Raymond Burke (Martin Sheen), Peterson decides to flee to Moscow.\n\nThe video game series \"Tom Clancy's Splinter Cell\" also draws inspiration from this. The series features the protagonist, Sam Fisher, a trained operative belonging to a fictional branch of the National Security Agency called Third Echelon (later, in \"\", the unit is replaced by the Fourth Echelon).\n\nThe 2007 film \"The Bourne Ultimatum\" makes several references to ECHELON. A CIA listening station in London is alerted when ECHELON detects the keyword \"Blackbriar\" in a cell phone conversation between a journalist and his editor. Later in the film, CIA Deputy Director Pamela Landy requests an \"ECHELON package\" on the main character, Jason Bourne.\n\nIn the 2000 computer game \"Deus Ex\", the signals intelligence supercomputers Daedalus and Icarus (later Helios) are referred to as Echelon IV.\n\nThe sci-fi crime thriller, \"Person of Interest\", a television show which aired from 2011 to 2016 on the CBS network, had a data-collecting supercomputer as its central narrative.\n\nIn \"Steins;Gate\" SERN monitors if someone sends a D-mail through ECHELON.\n\n\n\n"}
{"id": "3373650", "url": "https://en.wikipedia.org/wiki?curid=3373650", "title": "Earth systems engineering and management", "text": "Earth systems engineering and management\n\nEarth systems engineering and management (ESEM) is a discipline used to analyze, design, engineer and manage complex environmental systems. It entails a wide range of subject areas including anthropology, engineering, environmental science, ethics and philosophy. At its core, ESEM looks to \"rationally design and manage coupled human-natural systems in a highly integrated and ethical fashion\" ESEM is a newly emerging area of study that has taken root at the University of Virginia, Cornell and other universities throughout the United States. Founders of Earth Systems Engineering & Management are Braden Allenby and Michael Gorman.\nIn the UK, the Centre for Earth Systems Engineering Research (CESER) at Newcastle University has a large ESEM programme, led by Professor Richard Dawson.\n\nFor centuries now, mankind has been utilizing the earth and its natural resources to advance civilization and develop technology. \"As a principle result of Industrial Revolutions and associated changes in human demographics, technology systems, cultures, and economic systems have been the evolution of an Earth in which the dynamics of major natural systems are increasingly dominated by human activity\".\n\nIn many ways, ESEM views the earth as a human artifact. \"In order to maintain continued stability of both natural and human systems, we need to develop the ability to rationally design and manage coupled human-natural systems in a highly integrated and ethical fashion- an Earth Systems Engineering and Management (ESEM) capability\". \n\nOver the past five years, the concept of Earth Systems Engineering and Management has been developed by a few individuals. One of particular note is Braden Allenby. Allenby holds that the foundation upon which ESEM is built is the notion that “the Earth, as it now exists, is a product of human design”. In fact there are no longer any natural systems left in the world, “there are no places left on Earth that don’t fall under humanity’s shadow”. “So the question is not, as some might wish, whether we should begin ESEM, because we have been doing it for a long time, albeit unintentionally.\n\nThe issue is whether we will assume the ethical responsibility to do ESEM rationally and responsibly”. Unlike the traditional engineering and management process “which assume a high degree of knowledge and certainty about the systems behavior and a defined endpoint to the process,” ESEM “will be in constant dialog with [the systems], as they – and we and our cultures – change and coevolve together into the future”. ESEM is a new concept, however there are a number of fields “such as industrial ecology, adaptive management, and systems engineering that can be relied on to enable rapid progress in developing” ESEM as a discipline.\n\nThe premise of ESEM is that science and technology can provide successful and lasting solutions to human-created problems such as environmental pollution and climate-change. This assumption has recently been challenged in \"Techno-Fix: Why Technology Won’t Save Us or the Environment\" ESEM, as all technological control and manipulation, causes unintended and inherently unavoidable negative consequences. Furthermore, due to the limitations of reductionist science, it is inherently impossible to predict all negative impacts of ESEM. Consequently, ESEM can be considered a high-risk technological fix, which attempts to address symptoms of the planetary environmental crisis rather than root causes, which are dysfunctional human behavior such as human overpopulation and overconsumption.\n\nAdaptive management is a key aspect of ESEM. Adaptive management is a way of approaching environmental management. It assumes that there is a great deal of uncertainty in environmental systems and holds that there is never a final solution to an earth systems problem. Therefore, once action has been taken, the Earth Systems Engineer will need to be in constant dialogue with the system, watching for changes and how the system evolves. This way of monitoring and managing ecosystems accepts nature's inherent uncertainty and embraces it by never concluding to one certain cure to a problem.\n\nEarth Systems engineering is essentially the use of systems analysis methods in the examination of environmental problems. When analyzing complex environmental systems, there are numerous data sets, stakeholders and variables. It is therefore appropriate to approach such problems with a systems analysis method. Essentially there are “six major phases of a properly-conducted system study”. The six phases are as follows:\n\nPart of the systems analysis process includes determining the goals of the system. The key components of goal development include the development of a Descriptive Scenario, a Normative Scenario and Transitive Scenario. Essentially, the Descriptive Scenario “describe[s] the situation as it is [and] tell[s] how it got to be that way” (Gibson, 1991). Another important part of the Descriptive Scenario is how it “point[s] out the good features and the unacceptable elements of the status quo”. Next, the Normative Scenario shows the final outcome or the way the system should operate under ideal conditions once action has been taken. For the Earth Systems approach, the “Normative Scenario” will involve the most complicated analysis. The Normative Scenario will deal with stakeholders, creating a common trading zone or location for the free exchange of ideas to come up with a solution of where a system may be restored to or just how exactly a system should be modified. Finally the Transitive scenario comes up with the actual process of changing a system from a Descriptive state to a Normative state. Often, there is not one final solution, as noted in adaptive management. Typically an iterative process ensues as variables and inputs change and the system coevolves with the analysis.\n\nWhen examining complex ecologic systems there is an inherent need for the Earth Systems Engineer to have a strong understanding of how natural processes function. A training in Environmental Science will be crucial to fully understand the possible unintended and undesired effects of a proposed earth systems design. Such fundamental topics such as the carbon cycle or the water cycle are pivotal processes that need to be understood.\n\nAt the heart of ESEM is the social, ethical and moral responsibility of the Earth Systems Engineer to stakeholders and to the natural system being engineered, to come up with an objective Transitive and Normative scenario. “ESEM is the cultural and ethical context itself”. The Earth Systems Engineer will be expected to explore the ethical implications of proposed solutions.\n\n“The perspective of environmental sustainability requires that we ask ourselves how each interaction with the natural environment will affect, and be judged by, our children in the future” ”. “There is an increasing awareness that the process of development, left to itself, can cause irreversible damage to the environment, and that the resultant net addition to wealth and human welfare may very well be negative, if not catastrophic”. With this notion in mind, there is now a new goal of sustainable environment-friendly development. Sustainable development is an important part to developing appropriate ESEM solutions to complex environmental problems.\n\nIndustrial ecology is the notion that major manufacturing and industrial processes need to shift from open loop systems to closed loop systems. This is essentially the recycling of waste to make new products. This reduces refuse and increases the effectiveness of resources. ESEM looks to minimize the impact of industrial processes on the environment, therefore the notion of recycling of industrial products is important to ESEM.\n\nThe Florida Everglades system is a prime example of a complex ecological system that underwent an ESEM analysis.\n\nThe Florida Everglades is located in southern Florida. The ecosystem is essentially a subtropical fresh water marsh composed of a variety of flora and fauna. Of particular note is the saw grass and ridge slough formations that make the Everglades unique. Over the course of the past century mankind has had a rising presence in this region. Currently, all of the eastern shore of Florida is developed and the population has increased to over 6 million residents. This increased presence over the years has resulted in the channeling and redirecting of water from its traditional path through the Everglades and into the Gulf of Mexico and Atlantic Ocean. With this there have been a variety of deleterious effects upon the Florida Everglades.\n\nBy 1993, the Everglades had been affected by numerous human developments. The water flow and quality had been affected by the construction of canals and levees, to the series of elevated highways running through the Everglades to the expansive Everglades Agricultural Area that had contaminated the Everglades with high amounts of nitrogen. The result of this reduced flow of water was dramatic. There was a 90 - 95% reduction in wading bird populations, declining fish populations and salt water intrusion into the ecosystem. If the Florida Everglades were to remain a US landmark, action needed to be taken.\n\nIt was in 1993 that the Army Corps of Engineers analyzed the system. They determined that an ideal situation would be to \"get the water right\". In doing so there would be a better flow through the Everglades and a reduced number of canals and levees sending water to tide.\n\nIt was from the development of the Normative Scenario, that the Army Corps of Engineers developed CERP, the Comprehensive Everglades Restoration Plan. In the plan they created a time line of projects to be completed, the estimated cost and the ultimate results of improving the ecosystem by having native flora and fauna prosper. They also outline the human benefits of the project. Not only will the solution be sustainable, as future generations will be able to enjoy the Everglades, but the correction of the water flow and through the creation of storage facilities will reduce the occurrence of droughts and water shortages in southern Florida.\n\n\n\n"}
{"id": "31746016", "url": "https://en.wikipedia.org/wiki?curid=31746016", "title": "Energy in Kuwait", "text": "Energy in Kuwait\n\nEnergy in Kuwait describes energy and electricity production, consumption, import and export in Kuwait. Energy policy of Kuwait will describe the politics of Kuwait related to energy more in detail. Electricity sector in Kuwait is the main article of electricity in Kuwait.\n\nKuwait was \"9. top oil producer\" 2009. Kuwait is a member of OPEC. In four years 2004-2008 the population growth of Kuwait was 11% and the energy export grew 16%. In 2008 the energy export of Kuwait 1 450 TWh was close to the one of Nigeria 1 342 kWh and Iran 1 429 kWh.\n\nPrimary energy use in 2009 in Kuwait was 351 TWh and 125 TWh per million persons.\n\nProduction increased 15% from 2004 to 2008.\n\nIn relation to population the electricity use in Kuwait in 2008 was more than double compared to Saudi Arabian, Japanese or Danish (Kuwait 45.7 TWh 2.7 million capita. Denmark 35 TWh 5.49 million capita. Japan 1031 TWh 127.7 million capita and Saudi-Arabia 187 TWh 24.7 million capita.). The carbon dioxide emissions per capita of Kuwait were 1.6 times compared to Saudi Arabian and 2.8 times compared to Japanese.(Kuwait 69.5 Mt, Saudi Arabia, Japan 1151 Mt)\n\n \nAccording to IEA 10 countries produced over 60% of the world oil production in 2009. The countries were: Russia 494 Mt (13%), Saudi Arabia 452 Mt (12%), US 320 Mt (8%), Iran 206 Mt (5%), China 194 Mt (5%), Canada 152 Mt (4%), Mexico 146 Mt (4%), Venezuela 126 Mt (3%), Kuwait 124 Mt (3%) ja United Arab Emirates 120 Mt (3%).\n"}
{"id": "22939829", "url": "https://en.wikipedia.org/wiki?curid=22939829", "title": "Energy policy of Malaysia", "text": "Energy policy of Malaysia\n\nThe energy policy of Malaysia is determined by the Malaysian Government, which address issues of energy production, distribution, and consumption. The Department of Electricity and Gas Supply acts as the regulator while other players in the energy sector include energy supply and service companies, research and development institutions and consumers. Government-linked companies Petronas and Tenaga Nasional Berhad are major players in Malaysia's energy sector.\n\nGovernmental agencies that contribute to the policy are the Ministry of Energy, Green Technology and Water, Energy Commission (Suruhanjaya Tenaga), and the Malaysia Energy Centre (Pusat Tenaga Malaysia). Among the documents that the policy is based on are the 1974 Petroleum Development Act, 1975 National Petroleum Policy, 1980 National Depletion Policy, 1990 Electricity Supply Act, 1993 Gas Supply Acts, 1994 Electricity Regulations, 1997 Gas Supply Regulation and the 2001 Energy Commission Act.\n\nThe Ministry of Energy, Green Technology and Water has identified three principal energy objectives that would be instrumental in guiding the development of its energy sector.\n\nTo ensure the provision of adequate, secure and cost-effective energy supplies through developing indigenous energy resources both non-renewable and renewable energy resources using the latest cost options and diversification of supply sources both from within and outside the country.\n\nIn pursuit of the supply objective, policy initiatives, particularly with respect to crude oil and natural gas,Malaysia have aimed at both extending the life of domestic non-renewable energy resources, as well as diversification away from oil dependence to include other forms of energy sources.\n\nTo promote the efficient utilisation of energy and discourage wasteful and non-productive patterns of energy consumption.\n\nThe policy's approach to realise this objective is to rely heavily on the energy industry and consumers to exercise efficiency in energy production, transportation, energy conversion, utilisation and consumption through the implementation of awareness programs. Demand side management initiatives by the utilities, particularly through tariff incentives, have had some impact on efficient utilisation and consumption.\n\nGovernment initiatives to encourage cogeneration are also aimed at promoting an efficient method for generating heat energy and electricity from a single energy source.\n\nTo minimise the negative impacts of energy production, transportation, conversion, utilisation and consumption on the environment.\n\nThe environment objective has seen limited policy initiatives in the past. All major energy development projects are subjected to the mandatory environmental impact assessment requirement. Environmental consequences, such as emissions, discharges and noise are subjected to the environmental quality standards like air quality and emission standards.\n\nThe Malaysian government is seeking to intensify the development of renewable energy, particularly biomass, as the 'fifth fuel' resource under the country's Fuel Diversification Policy. The policy, which was set out in 2001, had a target of renewable energy providing 5% of electricity generation by 2005, equal to between 500 and 600 megawatt (MW) of installed capacity. The policy has been reinforced by fiscal incentives, such as investment tax allowances and the Small Renewable Energy Programme (SREP), which encourages the connection of small renewable power generation plants to the national grid.\n\nThe Small Renewable Energy Program allows renewable projects with up to 10 MW of capacity to sell\ntheir electricity output to TNB, under 21-year licence agreements. Numerous applications for the\nprogram have been received, mainly involving biomass, and of these over half are for palm oil waste.\nIn 2005 there were 28 approved biomass projects involving the installation of 194 MW of grid-connected\ncapacity. There were also four approved landfill gas-based projects, with 9 MW of capacity, and 18 mini\nhydro-electric projects offering 69.9 MW of total capacity.\n\nCurrently (2016), the Sustainable Energy Development Authority (SEDA) of Malaysia is conducting a comprehensive onshore wind mapping effort. SEDA Malaysia is a statutory body formed under the Sustainable Energy Development Authority Act of 2011. One of the key roles of the SEDA is to administer and manage the implementation of the Feed-in Tariff(FiT) mechanism, including a Renewable Energy fund mandated under the Renewable Energy Act of 2011. The Renewable Energy fund was created to support the FiT scheme. The current onshore wind mapping exercise will determine whether wind energy should be included in the FiT regime \n\nTraditionally, energy production in Malaysia has been based around oil and natural gas. Malaysia currently has 13GW of electrical generation capacity. Power generation capacity connected to the Malaysian National Grid is 19,023 MW, with a maximum demand of 13,340 MW as of July 2007 according to Suruhanjaya Tenaga. Total electricity generation for 2007 is 108,539 GW·h with a total consumption of 97,113 GW·h or 3,570 kW·h per capita. The generation fuel mix is 62.6% gas, 20.9% coal, 9.5% hydro and 7% from other forms of fuel. In 2007, the country as a whole consumes 514 thousand barrels (23.6 million tonnes) of oil daily against a production of 755 thousand barrels (34.2 million tonnes) per day.\n\nHowever, Malaysia only has 33 years of natural gas reserves, and 19 years of oil reserves, whilst the demand for energy is increasing. Due to this the Malaysian government is expanding into renewable energy sources. Currently 16% of Malaysian electricity generation is hydroelectric, the remaining 84% being thermal. The oil and gas industry in Malaysia is currently dominated by state owned Petronas, and the energy sector as a whole is regulated by Suruhanjaya Tenaga, a statutory commission who governs the energy in the peninsula and Sabah, under the terms of the Electricity Commission Act of 2001.\n\nSource: Suruhanjaya Tenaga (Energy Commission) Annual Report\n\nAll figures are in megawatts\n\nSource: Suruhanjaya Tenaga Annual Report \n\nEnergy use per person is relatively high in Malaysia compared to other upper-middle-income countries such as Brazil, Turkey or China. In 2015, the transport sector consumed 23,425 kilotonnes of oil equivalent (ktoe), meaning that it was responsible for 45.2% of total energy consumed in Malaysia. It was followed by the industrial sector, which consumed 13,989 ktoe (27.0% of total energy demand); the residential and commercial sectors at 7,559 ktoe (14.6% of total energy demand); non-energy uses such as the manufacture of chemicals at 5,928 ktoe (11.4%) and agriculture accounting for the rest.. \n\nThe Malaysian Energy Commission has set up various energy efficiency programs. Local governments are also showing leadership on energy efficiency policies: Putrajaya has the aspiration of becoming a \"Green City\" by 2025, while Iskandar Malaysia has developed a \"Low-Carbon Society Blueprint\". \n\nThere are significant opportunities to improve energy efficiency in urban areas, where 73% of Malaysia's population live. and over 90% of Malaysia's economic activity is conducted. Johor Bahru, for example, could reduce its emissions by a quarter by 2025 through a range of cost-effective investments: switching from diesel to natural gas in the rubber and petrochemical industries, promoting hybrid cars, adopting more ambitious green building standards and introducing mandatory energy performance standards for appliances such as air conditioners. Suruhanjaya Tenaga (the Energy Commission) already have some of these measures in place. For example, the Electricity Regulation 1994 has introduced labelling systems and performance standards for air conditioners, refrigerators, domestic fans and televisions. There are also a range of government schemes for financing building energy retrofits, which have had various levels of effectiveness.\n\n\n"}
{"id": "28432924", "url": "https://en.wikipedia.org/wiki?curid=28432924", "title": "Engineering and Public Policy", "text": "Engineering and Public Policy\n\nEngineering and Public Policy, informally known as EPP, is an interdisciplinary academic department within the Carnegie Mellon College of Engineering. EPP combines technical analysis with social science and policy analysis, in order to address problems in which knowledge of technical details is critical to decision making. EPP is one of three departments in United States universities that pioneered academic degree programs to address the profound societal changes brought about by technology.\n\nWhat is now known as EPP began in 1971 as Engineering and Public Affairs (EP&A), an undergraduate double major program jointly developed by the College of Engineering and the School of Urban and Public Affairs (now the Heinz College). Washington University in St. Louis began offering a master's in Technology and Human Affairs in 1971, which was discontinued in 1993. In 1976, the School of Engineering at Massachusetts Institute of Technology (MIT) began offering a master's degree through its Technology and Policy Program. Of the several academic programs now offered in technology and public policy, EPP and the Engineering Systems Division in MIT's School of Engineering are the most similar.\n\nThe primary purpose of the E&PA program was to train undergraduate engineering students to work at the interface of the social and engineering sciences, through use of an interdisciplinary curriculum based equally on social analysis and engineering analysis. Students received a Bachelor of Science degree from one of the traditional engineering departments plus E&PA.\n\nPlanning for the program began in the spring of 1969, initiated by the late Everard M. Williams, head of the Department of Electrical Engineering. Early development and implementation of the undergraduate program began in 1970, led by faculty members Herbert Toor (then head of Chemical Engineering and later dean of Engineering), Robert Dunlap and Gordon Lewis. Dunlap and Gordon Lewis co-directed the program, which was announced in April 1971. The Alfred P. Sloan Foundation provided support between 1971 and 1975.\n\nIn 1976 the College of Engineering advanced the program to departmental status, and changed its name to Engineering and Public Policy. The establishment of EPP was the first new accredited engineering department at Carnegie Mellon in nearly 75 years. \nM. Granger Morgan, who was recruited in 1974 to a joint appointment with the Department of Electrical Engineering, was appointed head of the new EPP department in 1977, and was given responsibility to coordinate the development of an EPP graduate program. Morgan stepped down as department head in 2014, and continues both his research and teaching responsibilities at CMU. Douglas C. Sicker, a professor in the Department of Computer Science at the University of Colorado at Boulder, was appointed head of EPP in August 2014.\n\nThe department runs highly regarded undergraduate and graduate programs. The undergraduate level includes a double major degree program which grants a joint degree between EPP and any of the five traditional engineering departments (Chemical, Civil, Electrical and Computer, Mechanical, and Materials Science) or the School of Computer Science (SCS).\n\nEPP offers a minor in Technology and Policy (T&P) for students not in Engineering or SCS. The department also offers a 5th-year master's degree for students who complete an EPP major or T&P minor, as well as a master's program in Engineering & Technology Innovation Management (ETIM).\n\nThe graduate program in Engineering and Public Policy educates technically skilled men and women at the doctoral level to be leaders in policy-focused research in which a deep understanding of technology is relevant to decision-making. As part of the Ph.D., students take additional courses in engineering and science, quantitative methods, social sciences and policy analysis.\n\nThe department has approximately 40 faculty, including 50-50 joint appointments with all five traditional engineering departments and several social science units. Jointly appointed EPP faculty regularly involve more traditional disciplinary colleagues in research collaborations.\n\nBased on distinguished and continuing achievements, several EPP faculty have been elected to the United States National Academies, including M. Granger Morgan, National Academy of Science; Baruch Fischhoff and Lester Lave, Institute of Medicine; and Alfred Blumstein, Herbert Toor (emeritus) and Robert White (emeritus), National Academy of Engineering.\n\nEPP's faculty are widely published, frequently serve on government committees and provide expert testimony to lawmakers and regulators on an array of topics, from energy and the environment to consumer safety. In 2010, EPP professor Jon Peha was on sabbatical serving as Chief Technologist at the Federal Communications Commission. EPP professor David Farber also served as FCC Chief Technologist from January 2000 to June 2001.\n\nEPP works in four major research areas on problems that involve the interaction of technology with society:\n\n\nAcross these four focal areas, the department addresses issues in technology and organizations, and in technology and economic development, focusing in particular on India and China. EPP also develops new software tools for the support of policy analysis and research, and studies issues in engineered systems and security.\n\nEPP has spearheaded a dozen large collaborative research efforts, including the National Science Foundation's Climate and Energy Decision Making Center; Climate Decision Making Center; Carnegie Mellon Electricity Industry Center; Green Design Institute; Center for the Study & Improvement of Regulation; Center for Integrated Study of the Human Dimensions of Global Change; Integrated Environmental Control Model technology development; CCSReg Project, to develop regulation for carbon capture and sequestration (CCS); RenewElec, which addresses the problems of integrating variable and intermittent renewable generation into the electric power system; and Cylab Usable Privacy and Security Laboratory.\n\nIn June 1997, EPP opened an office in Washington, D.C. to expand interaction between EPP students and faculty and relevant policy organizations in Washington. It serves as a base of operations for EPP participation in the policymaking processes of the U.S. Congress, federal agencies, and other Washington institutions.\n\n\n"}
{"id": "46591173", "url": "https://en.wikipedia.org/wiki?curid=46591173", "title": "Ferguson Conservation Park", "text": "Ferguson Conservation Park\n\nFerguson Conservation Park, formerly Ferguson National Pleasure Resort and Ferguson Recreation Park, is a protected area in the Australian state of South Australia located within the Adelaide metropolitan area in the suburb of Stonyfell about east of the Adelaide city centre. \n\nThe conservation park consists of land in section 687 (formerly part section 289) of the cadastral unit of the Hundred of Adelaide. It is bounded by St Peter's Collegiate Girls' School to the north-west, a private residence to the east, and by the following roads – Stonyfell Road to the north-east, Marble Terrace to the south and Hallett Road to the west.\n\nThe land which is occupied by the conservation park was originally donated to the Government of South Australia on 24 June 1949 by its previous owner, Alice Effie Ferguson, with the request that it be dedicated as a national pleasure resort “for the benefit of the public in perpetuity.” The national pleasure resort was managed by the South Australian Government Tourist Bureau until 27 April 1972 when the land was re-dedicated under the \"National Parks and Wildlife Act 1972\" as the \"Ferguson Recreation Park\". The recreation park was abolished on 24 June 1976 and then re-constituted as a conservation park with the latter being dedicated on 2 June 1977 following the discovery of a procedural error. The land was part of a larger holding of which the remainder is now occupied by St Peter's Collegiate Girls' School.\n\nThe conservation park is classified as an IUCN Category III protected area. In 1980, the conservation park was listed on the former Register of the National Estate.\n\n\n"}
{"id": "39562", "url": "https://en.wikipedia.org/wiki?curid=39562", "title": "Geochemistry", "text": "Geochemistry\n\nGeochemistry is the science that uses the tools and principles of chemistry to explain the mechanisms behind major geological systems such as the Earth's crust and its oceans. The realm of geochemistry extends beyond the Earth, encompassing the entire Solar System, and has made important contributions to the understanding of a number of processes including mantle convection, the formation of planets and the origins of granite and basalt.\n\nThe term \"geochemistry\" was first used by the Swiss-German chemist Christian Friedrich Schönbein in 1838: \"a comparative geochemistry ought to be launched, before geochemistry can become geology, and before the mystery of the genesis of our planets and their inorganic matter may be revealed.\" However, for the rest of the century the more common term was \"chemical geology\", and there was little contact between geologists and chemists. \n\nGeochemistry emerged as a separate discipline after major laboratories were established, starting with the United States Geological Survey (USGS) in 1884, and began systematic surveys of the chemistry of rocks and minerals. The chief USGS chemist, Frank Wigglesworth Clarke, noted that the elements generally decrease in abundance as their atomic weights increase, and summarized the work on elemental abundance in \"The Data of Geochemistry\".\n\nThe composition of meteorites was investigated and compared to terrestrial rocks as early as 1850. In 1901, Oliver C. Farrington hypothesised that, although there were differences, the relative abundances should still be the same. This was the beginnings of the field of cosmochemistry and has contributed much of what we know about the formation of the Earth and the Solar System.\n\nIn the early 20th century, Max von Laue and William L. Bragg showed that X-ray scattering could be used to determine the structures of crystals. In the 1920s and 1930s, Victor Goldschmidt and associates at the University of Oslo applied these methods to many common minerals and formulated a set of rules for how elements are grouped. Goldschmidt published this work in the series \"Geochemische Verteilungsgesetze der Elemente\" [Geochemical Laws of the Distribution of Elements]\".\n\nSome subfields of geochemistry are:\n\nThe building blocks of materials are the chemical elements. These can be identified by their atomic number Z, which is the number of protons in the nucleus. An element can have more than one value for N, the number of neutrons in the nucleus. The sum of these is the mass number, which is roughly equal to the atomic mass. Atoms with the same atomic number but different neutron numbers are called isotopes. A given isotope is identified by a letter for the element preceded by a superscript for the mass number. For example, two common isotopes of chlorine are Cl and Cl. There are about 1700 known combinations of Z and N, of which only about 260 are stable. However, most of the unstable isotopes do not occur in nature. In geochemistry, stable isotopes are used to trace chemical pathways and reactions, while isotopes are primarily used to date samples.\n\nThe chemical behavior of an atom – its affinity for other elements and the type of bonds it forms – is determined by the arrangement of electrons in orbitals, particularly the outermost (valence) electrons. These arrangements are reflected in the position of elements in the periodic table. Based on position, the elements fall into the broad groups of alkali metals, alkaline earth metals, transition metals, semi-metals (also known as metalloids), halogens, noble gases, lanthanides and actinides.\n\nAnother useful classification scheme for geochemistry is the Goldschmidt classification, which places the elements into four main groups. \"Lithophiles\" combine easily with oxygen. These elements, which include Na, K, Si, Al, Ti, Mg and Ca, dominate in the Earth's crust, forming silicates and other oxides. \"Siderophile\" elements (Fe, Co, Ni, Pt, Re, Os) have an affinity for iron and tend to concentrate in the core. \"Chalcophile\" elements (Cu, Ag, Zn, Pb, S) form sulfides; and \"atmophile\" elements (O, N, H and noble gases) dominate the atmosphere. Within each group, some elements are refractory, remaining stable at high temperatures, while others are volatile, evaporating more easily, so heating can separate them.\n\nThe chemical composition of the Earth and other bodies is determined by two opposing processes: differentiation and mixing. In the Earth's mantle, differentiation occurs at mid-ocean ridges through partial melting, with more refractory materials remaining at the base of the lithosphere while the remainder rises to form basalt. After an oceanic plate descends into the mantle, convection eventually mixes the two parts together. Erosion differentiates granite, separating it into clay on the ocean floor, sandstone on the edge of the continent, and dissolved minerals in ocean waters. Metamorphism and anatexis (partial melting of crustal rocks) can mix these elements together again. In the ocean, biological organisms can cause chemical differentiation, while dissolution of the organisms and their wastes can mix the materials again.\n\nA major source of differentiation is fractionation, an unequal distribution of elements and isotopes. This can be the result of chemical reactions, phase changes, kinetic effects, or radioactivity.\nOn the largest scale, \"planetary differentiation\" is a physical and chemical separation of a planet into chemically distinct regions. For example, the terrestrial planets formed iron-rich cores and silicate-rich mantles and crusts. In the Earth's mantle, the primary source of chemical differentiation is partial melting, particularly near mid-ocean ridges. This can occur when the solid is heterogeneous or a solid solution, and part of the melt is separated from the solid. The process is known as \"equilibrium\" or \"batch\" melting if the solid and melt remain in equilibrium until the moment that the melt is removed, and \"fractional\" or \"Rayleigh\" melting if is removed continuously. \n\nIsotopic fractionation can have mass-dependent and mass-independent forms. Molecules with heavier isotopes have lower ground state energies and are therefore more stable. As a result, chemical reactions show a small isotope dependence, with heavier isotopes preferring species or compounds with a higher oxidation state; and in phase changes, heavier isotopes tend to concentrate in the heavier phases. Mass-dependent fractionation is largest in light elements because the difference in masses is a larger fraction of the total mass.\n\nRatios between isotopes are generally compared to a standard. For example, sulfur has four stable isotopes, of which the two most common are S and S. The ratio of their concentrations, , is reported as\nwhere is the same ratio for a standard. Because the differences are small, the ratio is multiplied by 1000 to make it parts per thousand (referred to as parts per mil). This is represented by the symbol .\n\n\"Equilibrium fractionation\" occurs between chemicals or phases that are in equilibrium with each other. In equilibrium fractionation between phases, heavier phases prefer the heavier isotopes. For two phases A and B, the effect can be represented by the factor\nIn the liquid-vapor phase transition for water, at 20 degrees Celsius is 1.0098 for O and 1.084 for H. In general, fractionation is greater at lower temperatures. At 0 °C, the factors are 1.0117 and 1.111.\n\nWhen there is not equilibrium between phases or chemical compounds, \"kinetic fractionation\" can occur. For example, at interfaces between liquid water and air, the forward reaction is enhanced if the humidity of the air is less than 100% or the water vapor is moved by a wind. Kinetic fractionation generally is enhanced compared to equilibrium fractionation, and depends on factors such as reaction rate, reaction pathway and bond energy. Since lighter isotopes generally have weaker bonds, they tend to react faster and enrich the reaction products.\n\nBiological fractionation is a form of kinetic fractionation, since reactions tend to be in one direction. Biological organisms prefer lighter isotopes because there is a lower energy cost in breaking energy bonds. In addition to the previously mentioned factors, the environment and species of the organism can have a large effect on the fractionation.\n\nThrough a variety of physical and chemical processes, chemical elements change in concentration and move around in what are called \"geochemical cycles\". An understanding of these changes requires both detailed observation and theoretical models. Each chemical compound, element or isotope has a concentration that is a function of position and time, but it is impractical to model the full variability. Instead, in an approach borrowed from chemical engineering, geochemists average the concentration over regions of the earth called \"geochemical reservoirs\". The choice of reservoir depends on the problem; for example, the ocean may be a single reservoir or be split into multiple reservoirs. In a type of model called a \"box model\", a reservoir is represented by a box with inputs and outputs.\n\nGeochemical models generally involve feedback. In the simplest case of a linear cycle, either the input or the output from a reservoir is proportional to the concentration. For example, salt is removed from the ocean by formation of evaporites, and given a constant rate of evaporation in evaporite basins, the rate of removal of salt should be proportional to its concentration. For a given component , if the input to a reservoir is a constant and the output is for some constant , then the \"mass balance\" equation is\n\nThis expresses the fact that any change in mass must be balanced by changes in the input or output. On a time scale of , the system approaches a steady state in which . The \"residence time\" is defined as\nwhere and are the input and output rates. In the above example, the steady-state input and output rates are both equal to , so .\n\nIf the input and output rates are nonlinear functions of , they may still be closely balanced over time scales much greater than the residence time; otherwise there will be large fluctuations in . In that case, the system is always close to a steady state and a lowest order expansion of the mass balance equation will lead to a linear equation like Equation (). In most systems, one or both of the input and output depend on , resulting in a feedback that tends to maintain the steady state. If an external forcing perturbs the system, it will return to the steady state on a time scale of .\n\nThe composition of the Solar System is similar to that of many other stars, and aside from small anomalies it can be assumed to have formed from a solar nebula that had a uniform composition, and the composition of the Sun's photosphere is similar to that of the rest of the Solar System. The composition of the photosphere is determined by fitting the absorption lines in its spectrum to models of the Sun's atmosphere. By far the largest two elements by fraction of total mass are hydrogen (74.9%) and helium (23.8%), with all the remaining elements contributing just 1.3%. There is a general trend of exponential decrease in abundance with increasing atomic number, although elements with even atomic number are more common than their odd-numbered neighbors (the Oddo–Harkins rule). Compared to the overall trend, lithium, boron and beryllium are depleted and iron is anomalously enriched.\n\nThe pattern of elemental abundance is mainly due to two factors. The hydrogen, helium, and some of the lithium were formed in about 20 minutes after the Big Bang, while the rest were created in the interiors of stars.\n\nMeteorites come in a variety of compositions, but chemical analysis can determine whether they were once in planetesimals that melted or differentiated. Chondrites are undifferentiated and have round mineral inclusions called chondrules. With ages of 4.56 billion years, they date to the early solar system. A particular kind, the CI chondrite, has a composition that closely matches that of the Sun's photosphere, except for depletion of some volatiles (H, He, C, N, O) and a group of elements (Li, B, Be) that are destroyed by nucleosynthesis in the Sun. Because of the latter group, CI chondrites are considered a better match for the composition of the early Solar System. Moreover, the chemical analysis of CI chondrites is more accurate than for the photosphere, so it is generally used as the source for chemical abundance, despite their rareness (only five have been recovered on Earth).\n\nThe planets of the Solar System are divided into two groups: the four inner planets are the terrestrial planets (Mercury, Venus, Earth and Mars), with relatively small sizes and rocky surfaces. The four outer planets are the giant planets, which are dominated by hydrogen and helium and have lower mean densities. These can be further subdivided into the gas giants (Jupiter and Saturn) and the ice giants (Uranus and Neptune) that have large icy cores.\n\nMost of our direct information on the composition of the giant planets is from spectroscopy. Since the 1930s, Jupiter was known to contain hydrogen, methane and ammonium. In the 1960s, interferometry greatly increased the resolution and sensitivity of spectral analysis, allowing the identification of a much greater collection of molecules including ethane, acetylene, water and carbon monoxide. However, Earth-based spectroscopy becomes increasingly difficult with more remote planets, since the reflected light of the Sun is much dimmer; and spectroscopic analysis of light from the planets can only be used to detect vibrations of molecules, which are in the infrared frequency range. This constrains the abundances of the elements H, C and N. Two other elements are detected: phosphorus in the gas phosphine (PH) and germanium in germane (GeH). \n\nThe helium atom has vibrations in the ultraviolet range, which is strongly absorbed by the atmospheres of the outer planets and Earth. Thus, despite its abundance, helium was only detected once spacecraft were sent to the outer planets, and then only indirectly through collision-induced absortion in hydrogen molecules. Further information on Jupiter was obtained from the \"Galileo\" probe when it was sent into the atmosphere in 1995; and the final mission of the Cassini probe in 2017 was to enter the atmosphere of Saturn. In the atmosphere of Jupiter, He was found to be depleted by a factor of 2 compared to solar composition and Ne by a factor of 10, a surprising result since the other noble gases and the elements C, N and S were enhanced by factors of 2 to 4 (oxygen was also depleted but this was attributed to the unusually dry region that Galileo sampled).\n\nSpectroscopic methods only penetrate the atmospheres of Jupiter and Saturn to depths where the pressure is about equal to 1 bar, approximately Earth's atmospheric pressure at sea level. The Galileo probe penetrated to 22 bars. This is a small fraction of the planet, which is expected to reach pressures of over 40 Mbar. To constrain the composition in the interior, thermodynamic models are constructed using information on temperature from infrared emission spectra and equations of state for the likely compositions. High pressure experiments predict that hydrogen will be a metallic liquid in the interior of Jupiter and Saturn, while in Uranus and Neptune it remains in the molecular state. Estimates also depend on models for the formation of the planets. Condensation of the presolar nebula would result in a gaseous planet with the same composition as the Sun, but the planets could also have formed when a solid core captured nebular gas.\n\nIn current models, the four giant planets have cores of rock and ice that are roughly the same size, but the proportion of hydrogen and helium decreases from about 300 Earth masses in Jupiter to 75 in Saturn and just a few in Uranus and Neptune. Thus, while the gas giants are primarily composed of hydrogen and helium, the ice giants are primarily composed of heavier elements (O, C, N, S), primarily in the form of water, methane and ammonia. The surfaces are cold enough for molecular hydrogen to be liquid, so much of each planet is likely a hydrogen ocean overlaying one of heavier compounds. Outside the core, Jupiter has a mantle of liquid metallic hydrogen and an atmosphere of molecular hydrogen and helium. Metallic hydrogen does not mix well with helium, and in Saturn it may form a separate layer below the metallic hydrogen.\n\nTerrestrial planets are believed to have come from the same nebular material as the giant planets, but they have lost most of the lighter elements and have different histories. Planets closer to the Sun might be expected to have a higher fraction of refractory elements, but if their later stages of formation involved collisions of large objects with orbits that sampled different parts of the Solar System, there could be little systematic dependence on position.\n\nDirect information on Mars, Venus and Mercury largely comes from spacecraft missions. Using gamma-ray spectrometers, the composition of the crust of Mars has been measured by the Mars Odyssey orbiter, the crust of Venus by some of the Venera missions to Venus, and the crust of Mercury by the \"MESSENGER\" spacecraft. Additional information on Mars comes from meteorites that have landed on Earth (the Shergottites, Nakhlites, and Chassignites, collectively known as SNC meteorites). Abundances are also constrained by the masses of the planets, while the internal distribution of elements is constrained by their moments of inertia.\n\nThe planets condensed from the solar nebula, and much of the details of their composition are determined by fractionation as they cooled. The phases that condense fall into five groups. First to condense are materials rich in refractory elements such as Ca and Al. These are followed by nickel and iron, then magnesium silicates. Below about 700 kelvins (700 K), FeS and volatile-rich metals and silicates form a fourth group, and in the fifth group FeO enter the magnesium silicates. The compositions of the planets and the Moon are \"chondritic\", meaning that within each group the ratios between elements are the same as in carbonaceous chondrites.\n\nThe estimates of planetary compositions depend on the model used. In the \"equilibrium condensation\" model, each planet was formed from a \"feeding zone\" in which the compositions of solids were determined by the temperature in that zone. Thus, Mercury formed at 1400 K, where iron remained in a pure metallic form and there was little magnesium or silicon in solid form; Venus at 900 K, so all the magnesium and silicon condensed; Earth at 600 K, so it contains FeS and silicates; and Mars at 450 K, so FeO was incorporated into magnesium silicates. The greatest problem with this theory is that volatiles would not condense, so the planets would have no atmospheres and Earth no atmosphere.\n\nIn \"chondritic mixing\" models, the compositions of chondrites are used to estimate planetary compositions. For example, one model mixes two components, one with the composition of C1 chondrites and one with just the refractory components of C1 chondrites. In another model, the abundances of the five fractionation groups are estimated using an index element for each group. For the most refractory group, uranium is used; iron for the second; the ratios of potassium and thalium to uranium for the next two; and the molar ratio FeO/(FeO+MgO) for the last. Using thermal and seismic models along with heat flow and density, Fe can be constrained to within 10 percent on Earth, Venus and Mercury. U can be constrained within about 30% on Earth, but its abundance on other planets is based on \"educated guesses\". One difficulty with this model is that there may be significant errors in its prediction of volatile abundances because some volatiles are only partially condensed.\n\nThe more common rock constituents are nearly all oxides; chlorides, sulfides and fluorides are the only important exceptions to this and their total amount in any rock is usually much less than 1%. F. W. Clarke has calculated that a little more than 47% of the Earth's crust consists of oxygen. It occurs principally in combination as oxides, of which the chief are silica, alumina, iron oxides, and various carbonates (calcium carbonate, magnesium carbonate, sodium carbonate, and potassium carbonate). The silica functions principally as an acid, forming silicates, and all the commonest minerals of igneous rocks are of this nature. From a computation based on 1672 analyses of numerous kinds of rocks Clarke arrived at the following as the average percentage composition of the Earth's crust: SiO=59.71, AlO=15.41, FeO=2.63, FeO=3.52, MgO=4.36, CaO=4.90, NaO=3.55, KO=2.80, HO=1.52, TiO=0.60, PO=0.22, (total 99.22%). All the other constituents occur only in very small quantities, usually much less than 1%.\n\nThese oxides combine in a haphazard way. For example, potash (potassium carbonate) and soda (sodium carbonate) combine to produce feldspars. In some cases they may take other forms, such as nepheline, leucite, and muscovite, but in the great majority of instances they are found as feldspar. Phosphoric acid with lime (calcium carbonate) forms apatite. Titanium dioxide with ferrous oxide gives rise to ilmenite. Part of the lime forms lime feldspar. Magnesium carbonate and iron oxides with silica crystallize as olivine or enstatite, or with alumina and lime form the complex ferro-magnesian silicates of which the pyroxenes, amphiboles, and biotites are the chief. Any excess of silica above what is required to neutralize the bases will separate out as quartz; excess of alumina crystallizes as corundum. These must be regarded only as general tendencies. It is possible, by rock analysis, to say approximately what minerals the rock contains, but there are numerous exceptions to any rule.\n\nExcept in acid or siliceous igneous rocks containing greater than 66% of silica, known as felsic rocks, quartz is not abundant in igneous rocks. In basic rocks (containing 20% of silica or less) it is rare for them to contain as much silicon, these are referred to as mafic rocks. If magnesium and iron are above average while silica is low, olivine may be expected; where silica is present in greater quantity over ferro-magnesian minerals, such as augite, hornblende, enstatite or biotite, occur rather than olivine. Unless potash is high and silica relatively low, leucite will not be present, for leucite does not occur with free quartz. Nepheline, likewise, is usually found in rocks with much soda and comparatively little silica. With high alkalis, soda-bearing pyroxenes and amphiboles may be present. The lower the percentage of silica and alkali's, the greater is the prevalence of plagioclase feldspar as contracted with soda or potash feldspar.\n\nEarth's crust is composed of 90% silicate minerals and their abundance in the Earth is as follows: plagioclase feldspar (39%), alkali feldspar (12%), quartz (12%), pyroxene (11%), amphiboles (5%), micas (5%), clay minerals (5%); the remaining silicate minerals make up another 3% of Earth's crust. Only 8% of the Earth is composed of non-silicate minerals such as carbonates, oxides, and sulfides.\n\nThe other determining factor, namely the physical conditions attending consolidation, plays on the whole a smaller part, yet is by no means negligible. Certain minerals are practically confined to deep-seated intrusive rocks, e.g., microcline, muscovite, diallage. Leucite is very rare in plutonic masses; many minerals have special peculiarities in microscopic character according to whether they crystallized in depth or near the surface, e.g., hypersthene, orthoclase, quartz. There are some curious instances of rocks having the same chemical composition, but consisting of entirely different minerals, e.g., the hornblendite of Gran, in Norway, which contains only hornblende, has the same composition as some of the camptonites of the same locality that contain feldspar and hornblende of a different variety. In this connection we may repeat what has been said above about the corrosion of porphyritic minerals in igneous rocks. In rhyolites and trachytes, early crystals of hornblende and biotite may be found in great numbers partially converted into augite and magnetite. Hornblende and biotite were stable under the pressures and other conditions below the surface, but unstable at higher levels. In the ground-mass of these rocks, augite is almost universally present. But the plutonic representatives of the same magma, granite and syenite contain biotite and hornblende far more commonly than augite.\n\nThose rocks that contain the most silica, and on crystallizing yield free quartz, form a group generally designated the \"felsic\" rocks. Those again that contain least silica and most magnesia and iron, so that quartz is absent while olivine is usually abundant, form the \"mafic\" group. The \"intermediate\" rocks include those characterized by the general absence of both quartz and olivine. An important subdivision of these contains a very high percentage of alkalis, especially soda, and consequently has minerals such as nepheline and leucite not common in other rocks. It is often separated from the others as the \"alkali\" or \"soda\" rocks, and there is a corresponding series of mafic rocks. Lastly a small sub-group rich in olivine and without feldspar has been called the \"ultramafic\" rocks. They have very low percentages of silica but much iron and magnesia.\n\nExcept these last, practically all rocks contain felspars or feldspathoid minerals. In the acid rocks the common feldspars are orthoclase, perthite, microcline, and oligoclase—all having much silica and alkalis. In the mafic rocks labradorite, anorthite and bytownite prevail, being rich in lime and poor in silica, potash and soda. Augite is the most common ferro-magnesian in mafic rocks, but biotite and hornblende are on the whole more frequent in felsic rocks.\n\nRocks that contain leucite or nepheline, either partly or a wholly replacing felspar, are not included in this table. They are essentially of intermediate or of mafic character. We might in consequence regard them as varieties of syenite, diorite, gabbro, etc., in which feldspathoid minerals occur, and indeed there are many transitions between syenites of ordinary type and nepheline — or leucite — syenite, and between gabbro or dolerite and theralite or essexite. But, as many minerals develop in these \"alkali\" rocks that are uncommon elsewhere, it is convenient in a purely formal classification like that outlined here to treat the whole assemblage as a distinct series.\n\nThis classification is based essentially on the mineralogical constitution of the igneous rocks. Any chemical distinctions between the different groups, though implied, are relegated to a subordinate position. It is admittedly artificial but it has grown up with the growth of the science and is still adopted as the basis on which more minute subdivisions are erected. The subdivisions are by no means of equal value. The syenites, for example, and the peridotites, are far less important than the granites, diorites and gabbros. Moreover, the effusive andesites do not always correspond to the plutonic diorites but partly also to the gabbros. As the different kinds of rock, regarded as aggregates of minerals, pass gradually into one another, transitional types are very common and are often so important as to receive special names. The quartz-syenites and nordmarkites may be interposed between granite and syenite, the tonalites and adamellites between granite and diorite, the monzoaites between syenite and diorite, norites and hyperites between diorite and gabbro, and so on.\n\nTrace metals readily form complexes with major ions in the ocean, including hydroxide, carbonate, and chloride and their chemical speciation changes depending on whether the environment is oxidized or reduced. Benjamin (2002) defines complexes of metals with more than one type of ligand, other than water, as mixed-ligand-complexes. In some cases, a ligand contains more than one \"donor\" atom, forming very strong complexes, also called chelates (the ligand is the chelator). One of the most common chelators is EDTA (ethylenediaminetetraacetic acid), which can replace six molecules of water and form strong bonds with metals that have a plus two charge. With stronger complexation, lower activity of the free metal ion is observed. One consequence of the lower reactivity of complexed metals compared to the same concentration of free metal is that the chelation tends to stabilize metals in the aqueous solution instead of in solids.\nConcentrations of the trace metals cadmium, copper, molybdenum, manganese, rhenium, uranium and vanadium in sediments record the redox history of the oceans. Within aquatic environments, cadmium(II) can either be in the form CdCl in oxic waters or CdS(s) in a reduced environment. Thus higher concentrations of Cd in marine sediments may indicate low redox potential conditions in the past. For copper(II), a prevalent form is CuCl(aq) within oxic environments and CuS(s) and CuS within reduced environments. The reduced seawater environment leads to two possible oxidation states of copper, Cu(I) and Cu(II). Molybdenum is present as the Mo(VI) oxidation state as MoO in oxic environments. Mo(V) and Mo(IV) are present in reduced environments in the forms MoO and MoS. Rhenium is present as the Re(VII) oxidation state as ReO within oxic conditions, but is reduced to Re(IV) which may form ReO or ReS. Uranium is in oxidation state VI in UO(CO)(aq) and is found in the reduced form UO(s). Vanadium is in several forms in oxidation state V(V); HVO and HVO. Its reduced forms can include VO, VO(OH), and V(OH). These relative dominance of these species depends on pH.\n\nIn the water column of the ocean or deep lakes, vertical profiles of dissolved trace metals are characterized as following \"conservative–type\", \"nutrient–type\", or \"scavenged–type\" distributions. Across these three distributions, trace metals have different residence times and are used to varying extents by planktonic microorganisms. Trace metals with conservative-type distributions have high concentrations relative to their biological use. One example of a trace metal with a conservative-type distribution is molybdenum. It has a residence time within the oceans of around 8 x 10 years and is generally present as the molybdate anion (MoO). Molybdenum interacts weakly with particles and displays an almost uniform vertical profile in the ocean. Relative to the abundance of molybdenum in the ocean, the amount required as a metal cofactor for enzymes in marine phytoplankton is negligible.\n\nTrace metals with nutrient-type distributions are strongly associated with the internal cycles of particulate organic matter, especially the assimilation by plankton. The lowest dissolved concentrations of these metals are at the surface of the ocean, where they are assimilated by plankton. As dissolution and decomposition occur at greater depths, concentrations of these trace metals increase. Residence times of these metals, such as zinc, are several thousand to one hundred thousand years. Finally, an example of a scavenged-type trace metal is aluminium, which has strong interactions with particles as well as a short residence time in the ocean. The residence times of scavenged-type trace metals are around 100 to 1000 years. The concentrations of these metals are highest around bottom sediments, hydrothermal vents, and rivers. For aluminium, atmospheric dust provides the greatest source of external inputs into the ocean.\n\nIron and copper show hybrid distributions in the ocean. They are influenced by recycling and intense scavenging. Iron is a limiting nutrient in vast areas of the oceans, and is found in high abundance along with manganese near hydrothermal vents. Here, many iron precipitates are found, mostly in the forms of iron sulfides and oxidized iron oxyhydroxide compounds. Concentrations of iron near hydrothermal vents can be up to one million times the concentrations found in the open ocean.\n\nUsing electrochemical techniques, it is possible to show that bioactive trace metals (zinc, cobalt, cadmium, iron and copper) are bound by organic ligands in surface seawater. These ligand complexes serve to lower the bioavailability of trace metals within the ocean. For example, copper, which may be toxic to open ocean phytoplankton and bacteria, can form organic complexes. The formation of these complexes reduces the concentrations of bioavailable inorganic complexes of copper that could be toxic to sea life at high concentrations. Unlike copper, zinc toxicity in marine phytoplankton is low and there is no advantage to increasing the organic binding of Zn. In high nutrient-low chlorophyll regions, iron is the limiting nutrient, with the dominant species being strong organic complexes of Fe(III).\n\n"}
{"id": "1366094", "url": "https://en.wikipedia.org/wiki?curid=1366094", "title": "Glenn Hauser", "text": "Glenn Hauser\n\nGlenn Hauser (born April 12, 1945 in Berkeley, California) is an internationally known American DXer and radio host from Enid, Oklahoma. He produces and presents a weekly 30-minute program, \"World Of Radio\", heard on a number of non-commercial AM and FM stations throughout the U.S. and worldwide on shortwave.\n\nHauser began his broadcasting career on Radio Canada International during the late 1970s, providing DX tips on Sunday nights, and his tips also appeared on Radio Nederland's \"DX Juke Box\" program. He wrote for \"Popular Electronics\" and \"Modern Electronics\", and published \"Review of International Broadcasting\".\n\n\"World Of Radio\" debuted in 1980 on WUOT-FM in Knoxville, Tennessee, moving to shortwave two years later. The half-hour program consists of Hauser reading news about radio around the world in a characteristic monotone. Although \"World of Radio\" focuses on shortwave news, it covers all aspects of broadcasting. Most items are contributed by listeners to the program or DX publications.\n\nHauser also produced \"Mundo Radial\", a Spanish edition of \"World of Radio\", from January 2002 to November 2007.\n\nHauser introduced \"Review of International Broadcasting\" in February 1977. The magazine published 154 issues, with columns such as \"Listener Insights on Programming,\" \"Radio Equipment Forum,\" \"DX Listening Digest,\" \"The Media Mind\" and \"Satellite Watch.\" Contributors included David Newkirk, Loren Cox and Juan Carlos Codina, and \"RIB\" also featured columns from the BBC, John Norfolk and Alan Roe. It was published monthly during the 1970s and 1980s, later decreasing to quarterly and semiannually before ceasing publication in October 1997. \"RIB\"s successor, \"DX Listening Digest\", went online in 1999.\n\nHauser is a political liberal and an agnostic, which occasionally puts him at odds with the fundamentalist-dominated American shortwave scene which carries \"World of Radio\".\n\n"}
{"id": "6134782", "url": "https://en.wikipedia.org/wiki?curid=6134782", "title": "Green Scouting", "text": "Green Scouting\n\nSince the 1980s, self-styled Green Scouts have appeared in several countries, related to the protection of the environment and in some cases linked to Greens Parties. However, specifically environmentally-minded Scouts have existed since the very earliest days of the movement.\n\nIn response to a rash of devastating fires in the late nineteenth and early twentieth centuries, the State of Michigan established a group of Boy Scouts called the \"Michigan Forest Scouts\" in 1912. A similar group, with nearly identical badges, was later established in the State of New York. The purpose of these organizations was not character building, as it was with the Boy Scouts of America, and there were no ranks or merit badges. Instead, the Forest Scouts were charged with protecting the state's forests, and as a result were considered auxiliary fire wardens. Although the BSA typically disapproved of such groups, it was not so with the Forest Scouts. In one of the BSA's annual reports, the Forest Scouts are mentioned with approval and a note is made that \"the groups are headed up by Boy Scout men and that the Forest Scouts and the Boy Scouts of America are closely affiliated.\"\n\nTenzin Gyatso, 14th Dalai Lama has had direct involvement with Green Scouting on at least two occasions, when on September 3, 1999 he was made a Patron of the Global Movement of Green Scouts in New Delhi, India.\n\nScouting organizations in Niger include the Association Nigerienne des Scouts de l'Environnement (ANSEN), founded in 2003, which seems to have UN accreditation.\n\nThe World Organization of the Scout Movement has clearly stated its firm opposition to use of the words \"Scout\" and \"Boy Scout\" by Green Scout organizations, and made their position clear to all international governmental and non-governmental organizations involved with the environment, such as the United Nations' Environment Program and the World-Wide Fund for Nature.\n\nSeveral national WOSM member organizations issue a World Conservation Award.\n\n"}
{"id": "41052779", "url": "https://en.wikipedia.org/wiki?curid=41052779", "title": "Japanese temperate rainforest", "text": "Japanese temperate rainforest\n\nThe Japanese temperate rainforest is located in the Japanese archipelago, in small patches over a wide range of islands, from Kyushu in the South to Hokkaido in the North. Due to its geographic features and climate, the Japanese temperate rainforest is very different from other temperate rainforests in the world. The islands in the Japanese archipelago comprise about 1/400 of the world’s land. The islands are located on a latitude that is normally dry; desert can be found elsewhere in the world at this latitude. However, the oceans surrounding Japan provide enough precipitation to maintain a temperate rainforest.\n\nThe Japanese temperate rainforest can be classified into three types: the warm temperate zone found in the southern islands and lower elevations in the north, the cool temperate zone found in the northern islands and higher elevations in the south, and the subalpine forest in the higher elevations of northern Honshu and Hokkaido. The distribution of the Japanese temperate rainforest is also highly dependent on altitude; you may see all of three types of temperate rainforest on the higher mountains such as Mt. Fuji or Mt. Miyanouradake.\n\nThe climate of this region is warm and wet. The mean annual temperature is 6 – 13 °C in the cool temperate zone and 13 – 23 °C in the warm temperate zone. Annual precipitation is 1,200 – 1,800 mm. Some regions have an annual precipitation of more than 2,800 mm. The precipitation pattern of cool and warm temperate zones is almost opposite: the southern warm temperate rainforest has higher precipitation in summer and less precipitation in winter, and the northern cool temperate rainforest has lower precipitation in summer and higher in winter with the snowfall. High precipitation is caused by oceanic circulation and the rain shadow effect. Summer typhoons from the tropics bring warm; moist air to the southern islands, especially on the Pacific Ocean side. Westerly from Siberian high and Tsushima Current cause heavy snowfall on the Sea of Japan side of northern Japan.\n\nThe Japanese temperate rainforest is home to about 5300 plant species, 40 percent of which are unique to Japan. The Japanese archipelago was not influenced by the glacier extension in the last ice age; therefore, it provided refugia for many species. Also, there is no dry, desert area within the islands; thus, flora moved fluently between north and south after the last ice age. In addition, the Japanese islands are isolated, reducing immigration of organisms from the Eurasian continent.\n\nThe subalpine (cold) temperate rainforests are dominated by tsuga and fir. Veitch’s fir (\"Abies veitchii\"), Maries’ fir (\"Abies mariesii\") and northern Japanese hemlock are commonly seen. Also, Japanese cypress (\"Chamaecyparis\"), \"Thujopsis\" (also called hiba) can be found there. Other than those trees, broad-leaf trees such as Japanese beech (\"Fagus crenata\") and oak are co-dominant canopy trees in this area. The understory is dominated by the bamboo \"Sasa veitchii\" in most lower elevation sites in western Hokkaido. Ferns, sedges (\"Carex\"), and shrubs are co-dominant understory species in this area.\n\nThe cool temperate rainforest is dominated by Japanese beech (\"Fagus crenata\"). Also, Marie's fir, (\"Abies mariesii\"), \"Pinus pumila\", oak (\"Quercus crispula\"), and Japanese cypress are commonly seen in the cool temperate zone. The understory is dominated by another bamboo species called Chisimazasa (\"Sasa kurilensis\"); willow and shrubs such as (\"Camellia rusticana\") are also common in this zone.\n\nThe warm temperate rainforest is dominated by Japanese cedar (\"Cryptomeria\"), Japanese stone oak (\"Lithocarpus edulis\"), and \"Castanopsis sieboldii\". \"Trochodendron\", Isu tree (\"Distylium racemosum\"), oak (\"Quercus crispula\"), and \"Machilus thunbergii\" are co-dominant trees in the warm temperate zone. The understory is dominated by another \"Sasa\" species called moso bamboo (\"Phyllostachys edulis\"), and \"Rhododendron\", and \"Rhododendron subg. Hymenanthes\". The warm temperate rainforest is home to a great diversity of lichen and mosses due to the warm temperature and high precipitation.\n\nTemperate rainforests, especially old-growth forests, provide quality habitat for many species, including natural monument animals or those on the IUCN Red List—species such as the black woodpecker, Japanese black bear, Japanese dormouse, Japanese giant salamander, Japanese serow, Japanese macaque, Japanese golden eagle, sika deer, Japanese grass lizard, and Japanese rat snake. Larger mammals, such as sika deer and Japanese macaque, are commonly seen in all of the temperate zones, but most amphibians and small mammals are unique to each zone. Some species, such as the black woodpecker, live in only old-growth forests and the ongoing loss of their habitat is a serious problem for these species.\n\nMost of the Japanese temperate rainforest has been logged and used as fuel and building materials over time. Before industrial development, people lived with the forest; they respected the forest and mountains. Mountain worship and mountain asceticism have been very common in Japan through the ages. However, industry and war have forced people to cut the forest. The natural old-growth forest has declined rapidly with economic development and the government's policies. Some areas are turned into plantation forest (secondary forest) of Japanese cedar, \"Quercus serrate\", and sawtooth oak (\"Quercus acutissime\").\n\nThese forests are known as Satoyama and were well-managed until the government changed its policies again. Takeuchi explains Satoyama as “secondary woodlands and grassland near human settlements that have traditionally used these lands as coppices and meadows for fuel, fertilizer, and fodder.” Increased importing of fossil fuel and timber changed the value of Satoyama in the 1960s. The Japanese forest industry was reduced and people lost interest in forest management and timber harvesting. The population’s aging and loss of timber jobs caused population decrease in rural area, which made it difficult to maintain the Satoyama area. Today, however, society’s attention is being pulled back to the function of Satoyama and people have started to maintain the forest again.\n\nCommon disturbances in Japanese temperate rainforests are triggered by typhoons that have a strong influence on both the forests and human populations. Typhoons cause trees to fall as well as floods and landslides. Although some trees falling is a normal part of the forest lifecycle, large numbers of trees falling all at once can alter or damage the ecosystem.\n\nOther recent concerns include damage by animals. Insect infestation and sika deer foraging have become big issues. Infestations by insects have increased rapidly since the 1980s, especially in the last decade, and have impacted the forestry industry. The sika deer's foraging has a less direct impact on the forest itself; however, it represents about 60% of all damage from animals. The deer also eat seedlings, which increases the risk of future canopy decline. Occasionally, sika deer attack orchards in search of food; this may suggest overpopulation of sika deer, possibly due to human impact on their habitat. Ongoing losses from land conversion and climate change also represent serious threats to the conservation of Japanese temperate rainforests.\n"}
{"id": "297503", "url": "https://en.wikipedia.org/wiki?curid=297503", "title": "Landlocked country", "text": "Landlocked country\n\nA landlocked state or landlocked country is a sovereign state entirely enclosed by land, or whose only coastlines lie on closed seas. There are currently 50 such countries, including five partially recognised states. Only two, Bolivia and Paraguay in South America, lie outside Afro-Eurasia (the Old World).\n\nAs a rule, being landlocked creates political and economic handicaps that access to the high seas avoids. For this reason, states large and small across history have striven to gain access to open waters, even at great expense in wealth, bloodshed, and political capital.\n\nThe economic disadvantages of being landlocked can be alleviated or aggravated depending on degree of development, language barriers, and other considerations. Some landlocked countries are quite affluent, such as Switzerland, Liechtenstein, Luxembourg, and Austria, all of which frequently employ neutrality to their political advantage. The majority, however, are classified as Landlocked Developing Countries (LLDCs). Nine of the twelve countries with the lowest Human Development Indices (HDI) are landlocked.\n\nHistorically, being landlocked has been disadvantageous to a country's development. It cuts a nation off from important sea resources such as fishing, and impedes or prevents direct access to seaborne trade, a crucial component of economic and social advance. As such, coastal regions tended to be wealthier and more heavily populated than inland ones. Paul Collier in his book \"The Bottom Billion\" argues that being landlocked in a poor geographic neighborhood is one of four major development \"traps\" by which a country can be held back. In general, he found that when a neighboring country experiences better growth, it tends to spill over into favorable development for the country itself. For landlocked countries, the effect is particularly strong, as they are limited in their trading activity with the rest of the world. He states, \"If you are coastal, you serve the world; if you are landlocked, you serve your neighbors.\" Others have argued that being landlocked may actually be a blessing as it creates a \"natural tariff barrier\" which protects the country from cheap imports. In some instances, this has led to more robust local food systems.\n\nLandlocked developing countries have significantly higher costs of international cargo transportation compared to coastal developing countries (in Asia the ratio is 3:1).\n\nCountries thus have made particular efforts to avoid being landlocked, by acquiring land that reaches the sea:\n\nCountries can make agreements on getting free transport of goods through neighbour countries:\n\nLosing access to the sea is generally a great blow to a nation, politically, militarily, and economically. The following are examples of countries becoming landlocked. \n\nThe United Nations Convention on the Law of the Sea now gives a landlocked country a right of access to and from the sea without taxation of traffic through transit states. The United Nations has a programme of action to assist landlocked developing countries, and the current responsible Undersecretary-General is Anwarul Karim Chowdhury.\n\nSome countries have a long coastline, but much of it may not be readily usable for trade and commerce. For instance, in its early history, Russia's only ports were on the Arctic Ocean and frozen shut for much of the year. The wish to gain control of a warm-water port was a major motivator of Russian expansion towards the Baltic Sea, Black Sea and Pacific Ocean. On the other hand, some landlocked countries can have access to the ocean along wide navigable rivers. For instance, Paraguay (and Bolivia to a lesser extent) have access to the ocean by the Paraguay and Parana rivers.\n\nSeveral countries have coastlines on landlocked seas, such as the Caspian and the Dead. Since these seas are in effect lakes without access to wider seaborne trade, countries such as Kazakhstan are still considered landlocked. Although the Caspian Sea is connected to the Black Sea via the man-made Volga–Don Canal, large oceangoing ships are unable to traverse it.\n\nLandlocked countries may be bordered by a single country having direct access to the high seas, two or more such countries, or be surrounded by other landlocked countries, making a country doubly landlocked.\n\nThree countries are landlocked by a single country (enclaved countries):\n\n\nSeven landlocked countries are surrounded by only two mutually bordering neighbours (semi-enclaved countries):\n\n\nTo this group could be added two \"de facto\" states with no or limited international recognition:\n\n\nA country is \"doubly landlocked\" or \"double-landlocked\" when it is surrounded entirely by one or more landlocked countries (requiring the crossing of at least two national borders to reach a coastline). There are two such countries:\n\nThere were no doubly landlocked countries from the unification of Germany in 1871 until the end of World War I. Liechtenstein bordered the Austro-Hungarian Empire, which had an Adriatic coastline, and Uzbekistan was then part of the Russian Empire, which had both ocean and sea access.\n\nWith the dissolution of Austria-Hungary in 1918 and creation of an independent, landlocked Austria, Liechtenstein became the sole doubly landlocked country until 1938. In the Nazi Anschluss that year, Austria was absorbed into the Third Reich, which possessed a border on the Baltic Sea and the North Sea. After World War II, Austria regained its independence and Liechtenstein once again became doubly landlocked. \n\nUzbekistan, which had been part of the Russian Empire and then the Soviet Union, gained its independence with the dissolution of the U.S.S.R. in 1991 and became the second doubly landlocked country.\n\nHowever, Uzbekistan's doubly landlocked status depends on the Caspian Sea's status dispute: some countries, especially Iran and Turkmenistan, claim that the Caspian Sea should be considered as a real sea (mainly because this way they would have larger oil and gas fields), which would make Uzbekistan only a simple landlocked country because its neighbours Turkmenistan and Kazakhstan have access to the Caspian Sea.\n\nThey can be grouped in \"contiguous\" groups as follows:\n\nIf Transnistria is included then Moldova and Transnistria form their own cluster, listed in parentheses in the table.\n\nIf it were not for the of coastline at Muanda, Democratic Republic of the Congo would join the two African clusters into one, making them the biggest contiguous group in the world. Also, the Central Asian and Caucasian clusters can be considered contiguous, joined by the landlocked Caspian Sea. Mongolia is almost part of this cluster too, being separated from Kazakhstan by only , across Russian or Chinese territory.\n\nThere are the following \"single\" landlocked countries (each of them borders no other landlocked country):\n\n\nIf the Caucasian countries and Kazakhstan are counted as part of Europe, then Europe has the most landlocked countries, at 20. If these transcontinental countries are included in Asia, then Africa has the most, at 16. Depending on the status of the three transcontinental countries, Asia has between 9 and 15, while South America has only 2. North America and Australia are the only continents with no landlocked countries (not including Antarctica, which has no countries).\n\n"}
{"id": "8748726", "url": "https://en.wikipedia.org/wiki?curid=8748726", "title": "List of Boletus species", "text": "List of Boletus species\n\nThe following is an incomplete list of some species of the mushroom genus \"Boletus\". The genus has a widespread distribution, and contains about 300 species. However, the genus is polyphyletic and approximately only 10 percent of the described species are actually members of the Boletus \"sensu stricto\" clade (Singer's \"Boletus\" section \"Boletus\", also known as the \"Porcini Clade\").\n\n\n\n"}
{"id": "9477700", "url": "https://en.wikipedia.org/wiki?curid=9477700", "title": "List of botanical gardens in Australia", "text": "List of botanical gardens in Australia\n\nThere are more than 140 botanical gardens in Australia, some like the Australian National Botanic Gardens have collections consisting entirely of Australian native and endemic species; most have a collection that include plants from around the world. There are botanical gardens and arboreta in all states and territories of Australia, most are administered by local governments, some are privately owned.\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "17807894", "url": "https://en.wikipedia.org/wiki?curid=17807894", "title": "List of countries by oil imports", "text": "List of countries by oil imports\n\nThis is a list of countries by oil imports based on The World Factbook and other sources. Many countries also export oil, and some export more oil than they import.\n\n"}
{"id": "40623499", "url": "https://en.wikipedia.org/wiki?curid=40623499", "title": "List of ecoregions in Panama", "text": "List of ecoregions in Panama\n\nThis is a list of ecoregions in Panama as defined by the World Wildlife Fund and the Freshwater Ecoregions of the World database.\n\n\n\n\n\n\n"}
{"id": "36558191", "url": "https://en.wikipedia.org/wiki?curid=36558191", "title": "List of endophytes", "text": "List of endophytes\n\nEndophytes are micro-organisms living within the tissue of a plant as endosymbionts, without causing symptoms of disease. Some of them are mutualistic symbionts with beneficial effects on their host, such as improved growth or resistance against disease or environmental stress, and are being used as microbial inoculants. However, pathogens and saprophytes may also be endophytic at some point of their life cycle. Endophytes are distinct from mycorrhizal fungi or rhizosphere microbes in that they live entirely within the plant. Most endophytes known are bacteria or fungi, although there are also some endophytic algae and oomycetes.\n\nThis list contains genera with endophytic species (but which may also have non-endophytic species). Species are only listed in notable cases. Where specific variants or cultivars of a species are endophytic, this is detailed on the taxon's page. The host range is \"wide\" when it does not include only a specific lineage of plants; in that case, the lineage is given.\n\n\"See also\" Rhizobia \" for the nitrogen-fixing bacteria on roots of legumes (Fabaceae).\"\n"}
{"id": "25875835", "url": "https://en.wikipedia.org/wiki?curid=25875835", "title": "List of marine aquarium invertebrate species", "text": "List of marine aquarium invertebrate species\n\nThis is a list of various species of marine invertebrates, animals without a backbone, that are commonly found in aquariums kept by hobby aquarists. Some species are intentionally collected for their desirable aesthetic characteristics. Others are kept to serve a functional role such as consuming algae in the aquarium. Some species are present only incidentally or are pest species.\n\n\n"}
{"id": "27471715", "url": "https://en.wikipedia.org/wiki?curid=27471715", "title": "List of rivers of Egypt", "text": "List of rivers of Egypt\n\nThis is a list of rivers in Egypt. \n\nThere is only one year-round river in Egypt, the Nile. It has no non-seasonal tributaries for its entire length in Egypt, though it has two further upstream, the Blue Nile and White Nile, which merge in central Sudan. \n\nIn the Nile Delta, the river splits into a number of distributaries and lesser channels. In ancient times there were seven distributaries, of which only two are extant today due to silting and flood relief schemes; from east to west, they were:\n\n\nThe Nile is intersected by a number of normally dry tributaries or wadis which traverse the Eastern Desert. The wadis drain run-off rainfall from the mountains along the Egyptian Red Sea coast, though it only rarely reaches the main trunk of the wadis to flow downstream to the Nile. The three principal wadis are:\n\n\nSinai haspe Mukattab]] (\"The Valley of Writing\") and the Wadi Feiran (associated with the biblical Rephidim).\n\n"}
{"id": "24206177", "url": "https://en.wikipedia.org/wiki?curid=24206177", "title": "List of rogue waves", "text": "List of rogue waves\n\nThis list of rogue waves compiles incidents of known and likely rogue waves – also known as \"freak waves\", \"monster waves\", \"killer waves\", and \"extreme waves\". These are relatively large and spontaneous ocean surface waves that occur in deep water, usually far out at sea, and are a threat even to capital ships and ocean liners.\n\nAnecdotal evidence from mariners' testimonies and damages inflicted on ships have long suggested rogue waves occurred; however, their scientific measurement was only positively confirmed following measurements of the \"Draupner wave\", a rogue wave at the Draupner platform, in the North Sea on 1 January 1995. During this event, minor damage was inflicted on the platform, confirming that the reading was valid.\n\nIn modern oceanography, rogue waves are defined not as the biggest possible waves at sea, but instead as extreme sized waves for a given sea state.\n\nIt should be noted that many of these encounters are only reported in the media, and are not examples of open ocean rogue waves. Often a huge wave is loosely denoted as a \"rogue wave\", when it is not. \nAlthough extremely large waves offer an explanation for the sudden, inexplicable disappearance of many ocean-going vessels. However, although this is a credible explanation for unexplained losses, the claim is contradicted by information held by Lloyd's Register. One of the very few cases where evidence suggests a freak wave incident is the 1978 loss of the freighter \"München\". \n\nIn 1991, the American fishing boat, Andrea Gail, was caught in a storm near the NE Atlantic coase of the USA. Junger reported that the storm created waves in excess of 100 ft (30 m) in height, but ocean buoy monitors recorded a peak wave height of 39 feet (12 m), and so waves of 100 ft (30 m) were deemed \"unlikely\" by Science Daily.[4] However, data from a series of weather buoys in the general vicinity of the vessel's last known location recorded peak wave action exceeding 60 ft (18 m) in height from 28 through 30 October 1991.\n\n\n\n\n"}
{"id": "9017548", "url": "https://en.wikipedia.org/wiki?curid=9017548", "title": "List of tomato diseases", "text": "List of tomato diseases\n\nThis article is a list of diseases of tomatoes (\"Solanum lycopersicum\").\n\n"}
{"id": "1852572", "url": "https://en.wikipedia.org/wiki?curid=1852572", "title": "Marangoni effect", "text": "Marangoni effect\n\nThe Marangoni effect (also called the Gibbs–Marangoni effect) is the mass transfer along an interface between two fluids due to a gradient of the surface tension. In the case of temperature dependence, this phenomenon may be called thermo-capillary convection (or Bénard–Marangoni convection).\n\nThis phenomenon was first identified in the so-called \"tears of wine\" by physicist James Thomson (Lord Kelvin's brother) in 1855. The general effect is named after Italian physicist Carlo Marangoni, who studied it for his doctoral dissertation at the University of Pavia and published his results in 1865. A complete theoretical treatment of the subject was given by J. Willard Gibbs in his work \"On the Equilibrium of Heterogeneous Substances\" (1875-8).\n\nSince a liquid with a high surface tension pulls more strongly on the surrounding liquid than one with a low surface tension, the presence of a gradient in surface tension will naturally cause the liquid to flow away from regions of low surface tension. The surface tension gradient can be caused by concentration gradient or by a temperature gradient (surface tension is a function of temperature).\n\nAs an example, wine may exhibit a visible effect called \"tears\", as shown in the photograph. The effect is a consequence of the fact that alcohol has a lower surface tension and higher volatility than water. The water/alcohol solution rises up the surface of the glass due to capillary action. Alcohol evaporates from the film leaving behind liquid with a higher surface tension (more water, less alcohol). This region with a lower concentration of alcohol (greater surface tension) pulls on the surrounding fluid more strongly than the regions with a higher alcohol concentration (lower in the glass). The result is the liquid is pulled up until its own weight exceeds the force of the effect, and the liquid drips back down the vessel's walls. This can also be easily demonstrated by spreading a thin film of water on a smooth surface and then allowing a drop of alcohol to fall on the center of the film. The liquid will rush out of the region where the drop of alcohol fell.\n\nThe Marangoni number, a dimensionless value, can be used to characterize the relative effects of surface tension and viscous forces.\n\nA very detailed mathematical treatment of this from the point of view of the Navier–Stokes equations and the equations of thermodynamics can be found in the first third of Subrahmanyan Chandrasekhar's Hydrodynamic and Hydromagnetic Stability originally published in 1961 by Oxford, and republished by Dover in 1981.\n\nUnder earth conditions, the effect of gravity causing natural convection in a system with a temperature gradient along a fluid/fluid interface is usually much stronger than the Marangoni effect. Many experiments (ESA MASER 1-3) have been conducted under microgravity conditions aboard sounding rockets to observe the Marangoni effect without the influence of gravity. Research on heat pipes performed on the International Space Station revealed that whilst heat pipes exposed to a temperature gradient on Earth cause the inner fluid to evaporate at one end and migrate along the pipe, thus drying the hot end, in space (where the effects of gravity can be ignored) the opposite happens and the hot end of the pipe is flooded with liquid. This is due to the Marangoni effect, together with capillary action. The fluid is drawn to the hot end of the tube by capillary action. But the bulk of the liquid still ends up as a droplet a short distance away from the hottest part of the tube, explained by Marangoni flow. The temperature gradients in axial and radial directions makes the fluid flow away from the hot end and the walls of the tube, towards the center axis. The liquid forms a droplet with a small contact area with the tube walls, a thin film circulating liquid between the cooler droplet and the liquid at the hot end.\n\nThe effect of the Marangoni effect on heat transfer in the presence of gas bubbles on the heating surface (e.g., in subcooled nucleate boiling) has long been ignored, but it is currently a topic of ongoing research interest because of its potential fundamental importance to the understanding of heat transfer in boiling.\n\nA familiar example is in soap films: the Marangoni effect \"stabilizes\" soap films. Another instance of the Marangoni effect appears in the behavior of convection cells, the so-called Bénard cells.\n\nOne important application of the Marangoni effect is the use for drying silicon wafers after a wet processing step during the manufacture of integrated circuits. Liquid spots left on the wafer surface can cause oxidation that damages components on the wafer. To avoid spotting, an alcohol vapor (IPA) or other organic compound in gas, vapor, or aerosol form is blown through a nozzle over the wet wafer surface (or at the meniscus formed between the cleaning liquid and wafer as the wafer is lifted from an immersion bath), and the subsequent Marangoni effect causes a surface-tension gradient in the liquid allowing gravity more easily to pull the liquid completely off the wafer surface, effectively leaving a dry wafer surface.\n\nA similar phenomenon has been creatively utilized to self-assemble nanoparticles into ordered arrays and to grow ordered nanotubes. An alcohol containing nanoparticles is spread on the substrate, followed by blowing the substrate with a humid air flow. The alcohol is evaporated under the flow. Simultaneously, water condenses and forms microdroplets on the substrate. Meanwhile, the nanoparticles in alcohol are transferred into the microdroplets and finally form numerous coffee rings on the substrate after drying.\n\nThe Marangoni effect is also important to the fields of welding, crystal growth and electron beam melting of metals.\n\n\n"}
{"id": "4467620", "url": "https://en.wikipedia.org/wiki?curid=4467620", "title": "Marebito (film)", "text": "Marebito (film)\n\nMasuoka (Shinya Tsukamoto) carries a camera everywhere he goes. He becomes obsessed with the idea of fear when he sees a frightened man shove a knife in his eye to commit suicide. Wishing to understand the fear that the man must have felt before his death, Masuoka descends into a labyrinthine underground area beneath the city, where he sees human-like creatures that walk on their hands and knees and whimper like dogs. While searching the series of tunnels and passages, Masuoka encounters a homeless inhabitant who warns him about the Deros. He then meets the ghost of Kuroki, the man who killed himself, and learns more about the underworld. After hours of searching, Masuoka discovers a mountain range with a village built by the underground dwellers. He finds a naked girl (Tomomi Miyashita) chained to a wall. He takes her back to his apartment and notices she doesn't eat, drink, or speak. \n\nThe girl, whom Masuoka dubs 'F', appears to be something other than human, and Masuoka becomes obsessed with understanding her. He sets up cameras that enable him to observe her from his cell phone when he leaves the apartment, and checks on her regularly. On a trip to the shopping mall, he sees F speaking to someone off camera, and a menacing man in black appears behind him. When he returns to the apartment, a woman in a yellow jacket is hiding in the stairway outside his door. Inside, he finds F convulsing, and unsuccessfully attempts to feed her. He discovers that twelve seconds of camera footage is missing, and receives a mysterious phone call from a pay phone call warning him that he is in serious trouble.\n\nAfter being beaten with his camera by a stranger whom he filmed, Masuoka cuts his finger on the broken lens and returns home. He discovers that F survives on blood when she licks his finger, and cuts himself to feed her further. Masuoka begins to care for her by providing animal carcasses, deciding to treat F more as a pet than a human. The woman in yellow confronts him in the street, saying the girl is his daughter Fuyumi and asking where she is. Masuoka denies having a daughter and runs away, returning to the apartment to find it has been broken into and F missing. He wanders the streets searching for F and encounters the man in black, who expresses his disappointment in Masuoka's handling of her, speaking to him telepathically in the same voice as in the phone call. When Masuoka gets back to the apartment, he finds that F has returned and sees her hands are bloody.\n\nWhen Masuoka leaves his apartment, the woman in yellow follows and demands that he speak to her. He walks to an alley without speaking, and turns his camera on. The woman says she wants to see her girl, at which point Masuoka stabs her to death. Later, he murders a young girl whom he met under the pretense of filming pornography. He drains their blood into bottles and feeds it to F. Masuoka calls the pay phone and speaks to the stranger, who agrees that Masuoka is taking better care of F now. While filming for a news crew at the scene of the second murder, Masuoka sees a woman he filmed in her apartment previously. He takes F out of the apartment, and leaves her in a karaoke room to travel on his own for a period. Sitting on a dock, Masuoka discusses his interest in fear with Kuroki.\n\nMasuoka becomes homeless and sleeps in the park where he killed the young girl. He briefly admits to himself that he murdered his wife and a stranger and treated his daughter like an animal, before seeing a pair of Deros and finding a cell phone that leads him back to his apartment to find F. His wife's ghost appears behind Masuoka in the elevator, and he enters the apartment to find F weak on the floor. She speaks to him for the first time, and he cuts his mouth at the corner to feed her. At the end of the film, F leads Masuoka back down into the underworld, and films him as it appears he has finally discovered the same fear that initially intrigued him.\n\nAt different points in the film, different explanations are given for what is happening to Masuoka. Early conversations in the film seem to suggest that the underground tunnels and F herself may be a physical manifestation of human ideas. The film repeatedly references dangerous creatures called the Dero who live underground, named after the \"detrimental robots\" in Richard Sharpe Shaver's \"A Warning to Future Man\". At a later point in the film, it is suggested that Masuoka is insane and delusional, perhaps because he has stopped taking Prozac, and that his delusions have led him to kill innocent people and treat his daughter like an animal. The end of the film offers no concrete explanation.\n\nIn their book \"Lurker in the Lobby: A Guide to the Cinema of H. P. Lovecraft\", Andrew Migliore and John Strysik write: \"\"Marebito\" is a very good film that wears its influences proudly, without suffocating in their embrace. It's neither an adaptation nor an homage, but it swells with inspiration from Lovecraft's work. It's unconventional, free from cliché, and redolent with sinister insinuations that never become clear. You know them only by their shadows.\"\n\nThe film was made on digital video between the shooting of \"\" and \"The Grudge\".\n\n\n"}
{"id": "1260534", "url": "https://en.wikipedia.org/wiki?curid=1260534", "title": "Mount Agung", "text": "Mount Agung\n\nMount Agung or Gunung Agung is a volcano in Bali, Indonesia, southeast of Mt Batur volcano, also in Bali. Gunung Agung stratovolcano is the highest point on Bali. It dominates the surrounding area, influencing the climate, especially rainfall patterns. From a distance, the mountain appears to be perfectly conical. From the peak of the mountain, it is possible to see the peak of Mt Rinjani on the nearby island of Lombok, to the east, although both mountains are frequently covered in clouds.\n\nGunung Agung is an active volcano, with a large and deep crater that occasionally emits smoke and ash. \n\nHaving begun in 2017, this volcano's latest eruption is ongoing as of 2018 .\n\nAgung erupted in 1843, as recorded in a report by Heinrich Zollinger:\n\nThe eruption of 1963 was one of the largest and most devastating eruptions in Indonesia's history.\n\nOn February 18, 1963, local residents heard loud explosions and saw clouds rising from the crater of Mount Agung. On February 24, lava began flowing down the northern slope of the mountain, eventually traveling 7 km in the next 20 days. On March 17, the volcano erupted (VEI 5), sending debris 8 to 10 km into the air and generating massive pyroclastic flows.\nThese flows devastated numerous villages, killing an estimated 1,100–1,500 people. Cold lahars caused by heavy rainfall after the eruption killed an additional 200. A second eruption on May 16 led to pyroclastic flows that killed another 200 inhabitants. Minor eruptions and flows followed and lasted almost a year.\n\nThe lava flows missed, sometimes by mere yards, the Mother Temple of Besakih. The saving of the temple is regarded by Balinese as miraculous and a signal from the gods that they wished to demonstrate their power but not destroy the monument that the Balinese had erected. \n\nAndesite was the dominant lava type with some samples mafic enough to be classified as basaltic andesite.\n\n2017\n\n\n2018\n\n\nBalinese people believe that Mt Agung is a replica of Mt Meru, the central axis of the universe. The most important temple on Bali, Pura Besakih, is located high on the slopes of Gunung Agung.\n\n\n"}
{"id": "48315099", "url": "https://en.wikipedia.org/wiki?curid=48315099", "title": "NIOSH air filtration rating", "text": "NIOSH air filtration rating\n\nNIOSH air filtration rating refers to the publications of National Institute for Occupational Safety and Health (NIOSH) of US government pertaining to respirators and masks worn to filter contaminated air, regardless of cause.\n\nThe first part of the filter's classification uses the letters N, R, or P to indicate the filter's ability to function when exposed to oils.\n\n\nThe second part lists the percentage of particles that the mask is certified to block (such as 95 or 97 percent).\n\nThe most common is N95, which is recommended by the US Centers for Disease Control and Prevention (CDC) for most cases of air contamination. These filters are designed to seal tightly around mouth and nose and are made of material certified to block 95% of particles 0.3 μm or larger in diameter, roughly the size of a single virus and include PM2.5. \n\nThey are however \"...relatively difficult to breath through...\", and their full effectiveness also depends on a good fit - NIOSH recommends that each respirator wearer receive \"...an initial fit test and annual fit tests thereafter\".\n\nPlain surgical masks are standard for staff in hospital operating rooms, and often recommended to the public as part of avoiding seasonal flu.\n\nThey do not carry a NIOSH rating. They are designed to filter out relatively large particles, such as sputum droplets and hair - but the World Health Organization, Society for Healthcare Epidemiology of America, the Infectious Diseases Society of America, the Association for Professionals in Infection Control and Epidemiology, and the American College of Occupational and Environmental Medicine all recommend these except in cases of \"high risk\".\n"}
{"id": "13844556", "url": "https://en.wikipedia.org/wiki?curid=13844556", "title": "National Agency of Petroleum, Natural Gas and Biofuels (Brazil)", "text": "National Agency of Petroleum, Natural Gas and Biofuels (Brazil)\n\nThe Brazilian National Agency of Petroleum, Natural Gas and Biofuels ( - ANP) is the federal government agency linked to the Ministry of Mines and Energy responsible for the regulation of the oil sector.\n\n\n"}
{"id": "12731840", "url": "https://en.wikipedia.org/wiki?curid=12731840", "title": "Nectar robbing", "text": "Nectar robbing\n\nNectar robbing is a foraging behavior utilized by some organisms that feed on floral nectar. \"Nectar robbers\" usually feed from holes bitten in flowers, rather than by entering through the flowers' natural openings. Often, nectar robbers avoid contact with the floral reproductive structures, and therefore do not facilitate plant reproduction via pollination. Because many species that act as pollinators also act as nectar robbers, nectar robbing is considered to be a form of exploitation of plant-pollinator mutualism.\n\nNectar robbers vary greatly in species diversity and include species of carpenter bees, bumblebees, stingless \"Trigona\" bees, solitary bees, wasps, ants, hummingbirds, passerine birds, and flowerpiercer birds. Nectar robbing mammals include a fruit bat and a squirrel which robs nectar from the ginger plant.\n\nRecords of nectar robbing in nature date back at least to 1793 when German naturalist Christian Konrad Sprengel observed bumblebees perforating flowers. Charles Darwin observed bumblebees stealing nectar from flowers in 1859.\n\nNectar robbing is specifically the behavior of consuming nectar from a perforation (robbing hole) in the floral tissue rather than from the floral opening. There are two main types of nectar robbing: primary robbing, which requires that the nectar forager perforates the floral tissues itself, and secondary robbing, which is foraging from a robbing hole created by a primary robber. The term \"floral larceny\" has been proposed to include the entire suite of foraging behaviors for floral rewards that can potentially disrupt pollination. They include \"nectar theft\" (floral visits that remove nectar from the floral opening without pollinating the flower), and \"base working\" (removing nectar from in between petals, which generally bypasses floral reproductive structures).\n\nPollination systems are mostly mutualistic, meaning that the plant benefits from the pollinator's transport of male gametes and the pollinator benefits from a reward, such as pollen or nectar. As nectar robbers receive the rewards without direct contact with the reproductive parts of the flower, their behaviour is easily assumed to be cheating. However, the effect of robbery on the plant is sometimes neutral or even positive. For example, the proboscis of \"E. elvina\" does not come in contact with the reproductive parts of the flower in \"C. ovandensis,\" but this does not lead to significant reduction in fruit-set of the plant. In another example, when 80 percent of the flowers in a study site were robbed and the robbers did not pollinate, neither the seed nor fruit set were negatively affected.\n\nThe effect of floral-nectar robbing on plant fitness depends on several issues. Firstly, nectar robbers such as carpenter bees, bumble bees and some birds can pollinate flowers. Pollination may take place when the body of the robber contacts the reproductive parts of the plant while it robs, or during pollen collection which some bees practice in concert with nectar robbing. The impact of \"Trigona\" bees (e.g. \"Trigona ferricauda\") on a plant is almost always negative, probably because their aggressive territorial behaviour effectively evicts legitimate pollinators. Nectar robbers may change the behaviour of legitimate pollinators in other ways, such as by reducing the amount of nectar available. This may force pollinators to visit more flowers in their nectar foraging. The increased number of flowers visited and longer flight distances increase pollen flow and outcrossing, which is beneficial for the plant because it lessens inbreeding depression. This requires a robber's not completely consuming all of a flower's nectar. When a robber consumes all of a flower's nectar, legitimate pollinators may avoid the flower, resulting in a negative effect on plant fitness.\n\nThe response of different species of legitimate pollinators also varies. Some species, like the bumble bees \"Bombus appositus\" or \"B. occidentalis\" and many species of nectar-feeding birds can distinguish between robbed and unrobbed plants and minimize their energy cost of foraging by avoiding heavily robbed flowers. Pollinating birds may be better at this than insects, because of their higher sensory capability. The ways that bees distinguish between robbed and unrobbed flowers have not been studied, but they have been thought to be related to the damage on petal tissue after robbery or changes in nectar quality. \"Xylocopa varipuncta\" steals nectar through a slit they make in the base of the petals. If nectar robbing severely reduces the success of legitimate pollinators they may be able to switch to other nectar sources.\n\nNectar robbing, especially by birds, can damage the reproductive parts of a flower and thus diminish the fitness of a plant. In this case, the effect of robbery on a plant is direct. A good example of an indirect effect is the change in the behaviour of a legitimate pollinator, which either increases or decreases the fitness of a plant. There are both primary and secondary nectar robbers. Secondary robbers are those (e.g. flies and bees) that take advantage of the holes made by primary robbers.\n\nThe effect of robbing is positive if the robber also pollinates or increases the pollination by the legitimate pollinator, and negative if the robber damages the reproductive parts of a plant or reduces pollination success, either by competing with the legitimate pollinator or by lessening the attractiveness of the flower. Distinguishing between a legitimate pollinator and a nectar robber can be difficult.\n\nPollination systems cause coevolution, as in the close relationships between figs and fig wasps as well as yuccas and yucca moths. If nectar robbers have an effect (direct or indirect) on a plant or pollinator fitness, they are part of the coevolution process. Where nectar robbing is detrimental to the plant, a plant species might evolve to minimize the traits that attract the robbers or develop some type of protective mechanism to hinder them. Another option is to try to neutralize negative effects of nectar robbers. Nectar robbers are adapted for more efficient nectar robbing: for instance, hummingbirds and \"Diglossa\" flowerpiercers have serrated bills that are thought to aid them in incising flower tissue for nectar robbing.\n\nNectar robbers may only get food in illegitimate ways because of the mismatch between the morphologies of their mouthparts and the floral structure; or they may rob nectar as a more energy-saving way to get nectar from flowers.\n\nIt is not completely clear how pollination mutualisms persist in the presence of cheating nectar robbers. Nevertheless, as exploitation is not always harmful for the plant, the relationship may be able to endure some cheating. Mutualism may simply confer a higher payoff than nectar robbing.\n\nEven though there has not been much research on the defences evolved in plants against nectar robbers, the adaptations have been assumed not to rise from traits used in interactions between plants and herbivores (especially florivores). Some defences may have evolved through traits originally referred to pollination. Defences against nectar robbers have been thought to include toxins and secondary compounds, escape in time or space, physical barriers and indirect defences.\n\nToxins and secondary compounds are likely to act as a defence against nectar robbing because they are often found in floral nectar or petal tissue. There is some evidence that secondary compounds in nectar only affect nectar robbers and not the pollinators. One example is a plant called \"Catalpa speciosa\" which produces nectar containing iridoid glycosides that deter nectar-thieving ants but not legitimate bee pollinators. Low sugar concentration in nectar may also deter nectar robbers without deterring pollinators because dilute nectar does not yield net energy profits for robbers.\n\nIf robbers and pollinators forage at different times of day, plants may produce nectar according to the active period of a legitimate pollinator. This is an example of a defence by escaping in time. Another way to use time in defence is to flower only for one day as a tropical shrub \"Pavonia dasypetala\" does to avoid the robbing Trigona bees. Escaping in space refers to a situation in which plant avoids being robbed by growing in a certain location like next to a plant which is more attractive to the robbers.\n\nThe last two methods of protection are physical barriers and indirect defence like symbionts. Tightly packed flowers and unfavourably sized corolla tubes, bract liquid moats and toughness of the corolla or sepal are barriers for some nectar robbers. A good example of an indirect defence is to attract symbiotic predators (like ants) by nectar or other rewards to scare away the robbers.\n\nThe term 'resistance' refers to the plant's ability to live and reproduce in spite of nectar robbers. This may happen, for example, by compensating the lost nectar by producing more. With the help of defence and resistance, mutualisms can persist even in the presence of cheaters.\n"}
{"id": "42384660", "url": "https://en.wikipedia.org/wiki?curid=42384660", "title": "Nkrumaism", "text": "Nkrumaism\n\nNkrumaism (sometimes Consciencism) is an African socialist political ideology based on the thinking and writing of Kwame Nkrumah. Nkrumah, a pan-Africanist and Marxist–Leninist served as Prime Minister of the Gold Coast (later Ghana) from 1952 until 1960 and subsequently as President of Ghana before being deposed by the National Liberation Council in 1966.\n\nNkrumaism is a pan-African socialist theory which aims to adapt Marxist–Leninist theory to the social context of the African continent. Nkrumah defined his belief system as \"the ideology of a New Africa, independent and absolutely free from imperialism, organized on a continental scale, founded upon the conception of one and united Africa, drawing its strength from modern science and technology and from the traditional African belief that the free development of each is the condition for the free development of all.\" The Convention People's Party (CPP), founded by Nkrumah in 1949, writes \"Nkrumaism simply means Self Reliance, African is capable of managing his own affairs. The values CPP stands for or the guiding principles of Nkrumaism today are those which have guided it throughout its existence. Social justice, Pan-Africanism, Self Determination, African Personality, Anti-Imperialism.\"\n\nNkrumaism is a syncretic ideology which blends different sources together while not necessarily borrowing their entire frameworks. In his work, Nkrumah blended different sources from within Africa, the canon of Western philosophy, and black intellectuals in North America and Europe, like Marcus Garvey and George Padmore. Particularly important in founding this ideology were his study and meetings with C.L.R. James, W.E.B. Dubois, and Father Divine. Aside from the Marxist–Leninist framework, this blending of ideas largely only took bits and pieces of other philosophical systems and even its use of traditional African cultural concepts were often stretched to fit into the larger theory. While a major focus of the ideology was ending colonial relationships on the African continent, many of the ideas were utopian, building from Marxist political theory.\n\nLike other African political ideologies at the time, the central focus of Nkrumaism was on decolonization across Africa. The central contention of Nkrumaism was that African countries, united with one another, needed to adopt socialist political structures which were consistent with the traditional African values of egalitarianism. In Nkrumah's idealized view, pre-colonial African societies did not have individual ownership or class structures, but instead were organized largely around the value of what Nkrumah called \"communalism.\" While colonial structures had damaged these communal, egalitarian values, they had not fully supplanted them. Nkrumism then argued that a return to these values through socialist political structures would both heal the disruption caused by colonial structures and allow further development of African societies. The pan-African aspects of Nkrumah's ideology were justified by a claim that all African societies had largely shared in the communalism prior to colonialism and that in the neocolonial structures that replaced formal colonies, only African unity would create real autonomy.\n\nIn Nkrumah's argument, four basic pillars formed the applied aspects of this theory: state ownership of the means of production, a one-party democracy, fostering a classless economic system, and pan-African unity. While embracing much of Marxist–Leninist philosophy and Soviet political structures at the time, the ideology differed in some key respects. First, while Marxism–Leninism saw revolution as the only way to replace class structures with a socialist egalitarian system, Nkrumah saw reform as the more appropriate case for Africa. He argued that Ghana, and most of the rest of Africa, had never developed the class distinctions which Karl Marx and Vladimir Lenin saw in Europe and thus reform could reestablish preexisting egalitarianism suited to a post-colonial context. Nkrumah wrote that:\nFrom the ancestral lines of communalism, the passage to socialism lies in reform, because the underlying principles are the same. But when this passage carries one through colonialism the reform is revolutionary since the passage from colonialism to genuine independence is an act of revolution. But because of the continuity of communalism with socialism, in communalistic society, socialism is not a revolutionary creed, but a restatement in contemporary idiom of the principles underlying communalism.\nHe would change this idea after the 1966 coup seeing revolution as increasingly necessary. Second, while Nkrumah believed in the materialism and economic determinism of Marxism, he argued that focusing on the economic system was only appropriate after achieving independence throughout Africa and that the political struggle was the first order in colonial and neocolonial contexts.\n\nThe ideology of Nkrumaism formed a key part of the personality cult around Nkrumah and the party-building efforts of his political party, the CPP. His arguments were widely published and these had an impact within the Gold Coast colony, independent Ghana, and other parts of Africa in the 1950s and 1960s. The CPP, founded by Nkrumah in 1949, became a vocal proponent for the teaching and application of Nkrumaism. When he became president in the 1960s, his Minister for Presidential Affairs, Tawia Adamafio, established study groups on Nkrumahism which many civil servants joined to advance their careers. At the same time, the CPP established Ghana Young Pioneers groups for school age children where Nkrumaism was taught. While the tenets were promoted through these various party efforts, applying all aspects of the ideology proved to be difficult for Nkrumah while President of the country. Because of this, some consider Nkrumaism to be \"first of all a cultural phenomenon\" in Ghana with little impact on the actual politics of the country.\n\nHenry Bretton argues that Nkrumaism was not a coherent ideology, but a vague framework supporting the cult of personality and the centralized rule of Nkrumah. He writes: \"Nkrumaism was a verbalization of the requirements of the personal political machine. Professional scribes and amateurs, along with the Ghanaian Left, were set to the task of providing the coherence and internal consistency required to give a semblance of philosophy to the chaotic assemblage of ideas and fantasies borrowed from all parts of the world and from all periods of history, frequently out of context.\"\n\nIn contrast, Yuri Smertin criticized early works by Nkrumah from a Marxist perspective for distorting scientific socialism by combining religious and traditional elements.\n\n\n\n"}
{"id": "53705309", "url": "https://en.wikipedia.org/wiki?curid=53705309", "title": "Nonlinear Processes in Geophysics", "text": "Nonlinear Processes in Geophysics\n\nNonlinear Processes in Geophysics is an open-access peer-reviewed scientific journal publishing research within Earth science.\n\nThis journal is indexed in the following databases:\n\nAccording to the \"Journal Citation Reports\", the journal has a 2015 impact factor of 1.321.\n"}
{"id": "860362", "url": "https://en.wikipedia.org/wiki?curid=860362", "title": "Nyord", "text": "Nyord\n\nNyord is a Danish island in the Baltic Sea, southeast of Zealand, just north of Møn island.\n\nNyord covers an area of approximately 5 km², although only 1.2 km² is cultivatable moraine, while the remaining 4 km² is salt-meadow which is used for summer grazing, but is flooded during the winter.\n\nThe island is reached by a narrow bridge from the larger island of Møn. The bridge was constructed in 1968 and replaced the post boat \"Røret\" which had been in service since 1902. The boat was not large enough for animals such as cattle or horses, which had to swim alongside the boat.\n\nTraditionally the island has been self-sufficient, relying upon farming, fishing and piloting. Prior to 1769 the island belonged to the crown, but at this time crown lands were sold off, and the islanders purchased their own island for 3903 rigsdaler. The waters around the island are sufficiently treacherous that islanders could gain a livelihood as pilots, and this became enshrined in law as both a right and duty of the islanders between 1721 and 1879. After 1879 pilots were employed directly by the government instead of earning individual fees. A number of pilots houses and a lookout were constructed when the government took over the service. Piloting ceased in 1966.\n\nThe village of Nyord remains similar to its original design, with traditional thatched cottages and farm houses. It has a church, museum and small harbour. There is a restaurant \"Lolles Gård\" which is both a farm and a restaurant, there also is a village shop. The marshland area crossed by the bridge from the main island has one of Denmark's most important habitats for geese, ducks and other wading birds. There is an observation tower for birdwatchers to use.\n\n\n\n"}
{"id": "9613440", "url": "https://en.wikipedia.org/wiki?curid=9613440", "title": "Petén-Veracruz moist forests", "text": "Petén-Veracruz moist forests\n\nThe Petén-Veracruz moist forests ecoregion, of the Tropical and subtropical moist broadleaf forest Biome, is found in Belize, Guatemala, and Mexico.\n\nThe Petén-Veracruz moist forests cover an area of , extending from central Veracruz state across portions of the Mexican states of Oaxaca, Tabasco, Chiapas, and Campeche, as well as northern Guatemala and most of Belize. The Petén-Veracruz moist forests mostly occupy a coastal lowland with meandering rivers, and includes the Lacandon Forest of Chiapas and the Petén Basin of Guatemala.\n\nThe ecoregion is bounded on the south by a series of mountain ranges and highlands, including the Sierra Madre de Oaxaca, Sierra Madre de Chiapas, Chiapas Plateau, and Guatemalan Highlands, where the lowland Petén-Veracruz forests yield to montane moist forests and pine-oak forests. In central Veracruz, the Veracruz dry forests separate the Petén-Veracruz moist forests from the Veracruz moist forests further north. The western portion of the ecoregion mostly extends to the Gulf of Mexico, although the montane forests of the Sierra de los Tuxtlas and the flooded forests and wetlands of the Pantanos de Centla constitute distinct ecoregions.\n\nThe eastern portion of the ecoregion is bounded on the north by the Yucatán moist forests, which extend east and west across the Yucatán Peninsula. The Petén-Veracruz moist forests extend east to the Caribbean Sea in Belize, surrounding enclaves of Belizean pine forests in the Maya Mountains and near the coast. The Belizean Coast mangroves run along the Caribbean coast.\n\nThe northern Petén-Veracruz moist forests were home to the Olmec culture, which built cities between 1200 and 400 BCE. The Classic Maya civilisation (250-900 CE) was centered in the eastern and southern portions of the ecoregion, from Tabasco and northern Chiapas across northern Guatemala to Belize.\n\nToday, modern Mayan people inhabit the eastern portion of the ecoregion, while Mixe–Zoque and Nahuatl peoples inhabit the western portion.\n\nThe ecoregion contains a number of protected areas, including the Maya Biosphere Reserve in Guatemala, and the Montes Azules Biosphere Reserve in Mexico. It is ranked Critical/Endangered by the World Wildlife Fund.\n\n\n"}
{"id": "24606095", "url": "https://en.wikipedia.org/wiki?curid=24606095", "title": "PlusEnergy", "text": "PlusEnergy\n\nPlusEnergy is a term used in building design to describe a structure that produces more energy than it uses. The term was coined in 1994 by Rolf Disch when building his private residence, the Heliotrope as the first PlusEnergy house in the world. Disch then went on to refine the concepts involved with several more projects built by his company Rolf Disch Solar Architecture in order to promote PlusEnergy for wider adoption in residential, commercial and retail spaces. Disch maintains that PlusEnergy is more than just a method of producing environmentally-friendly housing, but also an integrated ecological and architectural concept. As such, PlusEnergy is intended to be superior to low-energy or zero-energy designs such as those of Passivhaus. \n\nThe PlusEnergy approach uses a variety of techniques to produce a building that generates more energy than it consumes. A typical example is to capture heat during the day in order to reduce the need to generate heat over night. This is achieved using large North and South facing window areas to allow sunlight to penetrate the structure, reducing the need for energy use from light bulbs. Triple-paned windows (U-value = 0.7) trap this heat inside, and the addition of heavy insulation then means the structure is already warm in the evening and therefore needs less heating. In the Sun Ship, a commercial, retail and residential PlusEnergy structure, techniques such as phase changing materials in the walls and vacuum insulation are also used. This permits maximum availability of floor space without compromising efficient insulation.\n\nAn important part of the PlusEnergy approach that differentiates it from similar concepts is that the owner or tenant of a PlusEnergy building should be able to live and work comfortably in it without sacrificing lifestyle or normal living standards. For example, solar panels are made aesthetically pleasing so that they are integrated into the façade of the structure. This reflects PlusEnergy's emphasis on community planning and integration, with aspects of transportation, water management and communication also being seen as part of the design. \n\nPlusEnergy design also emphasises the importance of sustainable development on communities in general. An energy-efficient community is seen as generating positive identification and community pride. Rolf Disch says he attracts a high quality of tenant, innovative undertakings and creative work places through his designs. Ecological urban planning techniques like traffic management with wide, attractive walkways, bicycle routes and connections to public transportation are all part of the PlusEnergy ideal. At the Solar Settlement for example, tenants and owners incorporate bicycle and car-sharing, and the neighborhood has an extensive car-free zone with many public transportation connections.\n\nBuilt in 1994 as the private residence and special project of Rolf Disch in Freiburg, the Heliotrope is claimed by its designer to be the first building in the world to create more energy than it uses, being reliant on entirely renewable power, and being emissions free and CO neutral. The structure rotates to track the sun, which allows it to use a large amount of natural sunlight and warmth during the day. Several different energy generation technologies are used in the building, including a dual-axis solar photovoltaic tracking panel, a geothermal heat exchanger, a combined heat and power unit (CHP) and solar-thermal balcony railing to provide heat and warm water. These in combination with the large amounts of insulation allow the Heliotrope to produce between four and six times its energy usage depending on the time of year. The building is also fitted with a grey-water cleansing system and built-in waste composting.\n\nAfter the success of Freiburg’s Heliotrope, Hansgrohe contracted Rolf Disch Solar Architecture to design and built another Heliotrope to be used as a visitors' center and showroom in Offenburg, Germany. A third Heliotrope was then built in Hilpoltstein, Bavaria to be used as a technical dental laboratory. \n\nWith the success of the Heliotrope, Rolf Disch Solar Architecture applied their PlusEnergy concept to mass residential production in the form of a community development of 50 PlusEnergy houses. The project, called Solar Settlement, won 2002 House of the Year, 2002 Residential PV Solar Integration Award, and Germany’s Most Beautiful Housing Community, 2006. Built between 2000 and 2005 in the Vauban quarter of Freiburg, the Solar Settlement is intended as an example of Disch’s vision of a “fundamental environmental imperative”. As of 2011, the homes have had more than 8 years of full occupancy and each produced more than 5,000 Euros ($5,600) of surplus energy a year, from which the owners of the houses have benefitted.\n\nMade from Black Forest timber, the wood interior and natural lighting provide for happily lit spaces and a natural flow from room to room. The tenants at the Solar Settlement claim not to have made any compromises in their living standards, and that they have benefitted environmentally and economically.\n\nThe Sun Ship, located next to the Solar Settlement in Freiburg, uses its for retail, commercial and residential space. The Sun Ship houses a supermarket, convenience store and café on the first floor, offices and work spaces on the 2nd and 4th floors, and 9 penthouses on its roof. Notable aspects of the building are its vacuum insulated walls, ventilation with 95% heat recovery, triple paned windows, and solar-panelled façade.\n\nAs the first positive energy office building worldwide, the Sun Ship exhibits not only high energy efficiency but also a pleasant environment to work in. The office spaces are flanked on both the North and South ends entirely with windows, which captures natural sunlight and minimizes the energy wasted by artificial light. In addition to the office and retail space, two conference rooms provide space for lectures, meetings and as a showroom.\n\n\n"}
{"id": "2625520", "url": "https://en.wikipedia.org/wiki?curid=2625520", "title": "Ptaeroxylon", "text": "Ptaeroxylon\n\nPtaeroxylon obliquum is the botanical name for the sneezewood tree. It is native to Southern Africa, including South Africa, Zimbabwe, and Mozambique. It is the only species in the genus Ptaeroxylon.\n\n\"Ptaeroxylon obliquum\" is a species from the Rutaceae family which are most abundant in South Africa and Australia. The term \"ptaeroxylon\" is Greek for sneeze and wood, while \"obliquum\" denotes the oblique shape of the leaflets. The wood produces oils containing nieshoutol, which causes violent sneeze attacks by workers who are exposed to the tree. Though sneezewood is not poisonous, it has been known to cause respiratory complications. It has been linked to asthma, rhinitis and mucosal inflammation.\n\n\"Ptaeroxylon obliquum\" is a shrub or medium deciduous tree that stands up to tall.\nThe bark is whitish-grey and smooth when young, but fissured with age. Leaflets are 2.5 x 1.3 cm marked asymmetrically. They are blue-green to dark green in color and crowd near the ends of the rachis in three to seven pairs of leaflets. The flowers on the tree are white to creamy yellow and fragrant.\n\nSneezewood is very dense having a specific gravity of 1040 kg/m\n\nSneezewood is an extremely hard and durable timber wood. It often lasts longer than brass or iron when used for machine bearings.\n\nIn the past, sneezewood was used extensively for railway sleepers. It can also be used to make furniture. In Mozambique it is used to make xylophone keys.\n\nSneezewood is a very attractive wood with golden heartwood with light orange figures and is a favorite amongst woodturners.\n\nIts scarcity today is due in part of its past use as fuel for steam tugs.\nIt has been used extensively for fence and telegraph poles as well.\n\nSneezewood is used for medicinal and ritual purposes. The bark can be used to repel moths or as snuff. The resin has been used to get rid of warts and cattle ticks.\n\nThe Xhosa have traditionally made snuff from sneeze-wood to relieve headaches.\n\n"}
{"id": "206520", "url": "https://en.wikipedia.org/wiki?curid=206520", "title": "Pyroclastic flow", "text": "Pyroclastic flow\n\nA pyroclastic flow (also known as a pyroclastic density current or a pyroclastic cloud) is a fast-moving current of hot gas and volcanic matter (collectively known as tephra) that moves away from a volcano about on average but is capable of reaching speeds up to . The gases can reach temperatures of about .\n\nPyroclastic flows are a common and devastating result of certain explosive eruptions; they normally touch the ground and hurtle downhill, or spread laterally under gravity. Their speed depends upon the density of the current, the volcanic output rate, and the gradient of the slope.\n\nThe word \"pyroclast\" is derived from the Greek , meaning \"fire\", and , meaning \"broken in pieces\". A name for pyroclastic flows which glow red in the dark is nuée ardente (French, \"burning cloud\"); this was first used to describe the disastrous 1902 eruption of Mount Pelée on Martinique.\n\nPyroclastic flows that contain a much higher proportion of gas to rock are known as \"fully dilute pyroclastic density currents\" or pyroclastic surges. The lower density sometimes allows them to flow over higher topographic features or water such as ridges, hills, rivers and seas. They may also contain steam, water and rock at less than ; these are called \"cold\" compared with other flows, although the temperature is still lethally high. Cold pyroclastic surges can occur when the eruption is from a vent under a shallow lake or the sea. Fronts of some pyroclastic density currents are fully dilute; for example, during the eruption of Mount Pelée in 1902, a fully dilute current overwhelmed the city of Saint-Pierre and killed nearly 30,000 people.\n\nA pyroclastic flow is a type of gravity current; in scientific literature they are sometimes abbreviated to PDC (pyroclastic density current).\n\nThere are several mechanisms that can produce a pyroclastic flow:\n\n\nThe volumes range from a few hundred cubic meters to more than 1,000 cubic kilometres. The larger ones can travel for hundreds of kilometres, although none on that scale have occurred for several hundred thousand years. Most pyroclastic flows are around 1 to 10 cubic kilometres and travel for several kilometres. Flows usually consist of two parts: the \"basal flow\" hugs the ground and contains larger, coarse boulders and rock fragments, while an extremely hot ash plume lofts above it because of the turbulence between the flow and the overlying air, admixing and heating cold atmospheric air causing expansion and convection.\n\nThe kinetic energy of the moving cloud will flatten trees and buildings in its path. The hot gases and high speed make them particularly lethal, as they will incinerate living organisms instantaneously: \n\nTestimonial evidence from the 1883 eruption of Krakatoa, supported by experimental evidence, shows that pyroclastic flows can cross significant bodies of water. However, that might be a pyroclastic surge, not flow, because the density of a gravity current means it cannot move across the surface of water. One flow reached the Sumatran coast as much as 48 km (30 mi) away.\n\nA 2006 BBC documentary film, \"Ten Things You Didn't Know About Volcanoes\", demonstrated tests by a research team at Kiel University, Germany, of pyroclastic flows moving over water. When the reconstructed pyroclastic flow (stream of mostly hot ash with varying densities) hit the water, two things happened: the heavier material fell into the water, precipitating out from the pyroclastic flow and into the liquid; the temperature of the ash caused the water to evaporate, propelling the pyroclastic flow (now only consisting of the lighter material) along on a bed of steam at an even faster pace than before.\n\nDuring some phases of the Soufriere Hills volcano on Montserrat, pyroclastic flows were filmed about 1 km offshore. These show the water boiling as the flow passed over it. The flows eventually built a delta, which covered about 1 km.\n\nA pyroclastic flow can interact with a body of water to form a large amount of mud, which can then continue to flow downhill as a lahar. This is one of several mechanisms that can create a lahar.\n\nIn 1963, NASA astronomer Winifred Cameron proposed that the lunar equivalent of terrestrial pyroclastic flows may have formed sinuous rilles on the Moon. In a lunar volcanic eruption, a pyroclastic cloud would follow local relief, resulting in an often sinuous track. The Moon's Schröter's Valley offers one example.\n\n\n\n"}
{"id": "19029446", "url": "https://en.wikipedia.org/wiki?curid=19029446", "title": "Raised bog", "text": "Raised bog\n\nRaised bogs, also called ombrotrophic bogs (\"ombrotrophe Moore\"), are acidic, wet habitats that are poor in mineral salts and are home to flora and fauna that can cope with such extreme conditions. Raised bogs, unlike fens are exclusively fed by precipitation (ombrotrophy) and from mineral salts introduced from the air. They thus represent a special type of bog, hydrologically, ecologically and in terms of their development history, in which the growth of peat mosses over centuries or millennia plays a decisive role. They also differ in character from blanket bogs which are much thinner and occur in wetter, cloudier climatic zones.\n\nRaised bogs are very threatened by peat cutting and pollution by mineral salts from the surrounding land (due to agriculture and industry). There are hardly any raised bogs today that are still living and growing. The last great raised bog regions are found in western Siberia and Canada.\n\nThe term raised bog derives from the fact that this type of bog rises in height over time as a result of peat formation. They are like sponges of peat moss, full of water, than form a more or less dome shape in the landscape. In Germany, the term \"Hochmoor\" (\"high bog\"), strictly refers only to the classical, lens-shaped bogs of northwest Germany. The bogs are not influenced by mineral-rich groundwater or surface water, but are fed exclusively by precipitation - mainly rainwater, hence their alternative German designation of \"Regenmoor\" or \"rain-fed bog\". Thus the latter refers to all bogs that are not arched or only slightly arched, but which nevertheless are characterized by an extreme mineral salt deficiency and other resulting ecological properties.\n\nA living raised bog needs a moist, balanced climate in which to grow. The quantity of precipitation has to be greater than the water losses through discharge and evaporation. In addition, the precipitation must be evenly spread through the year.\n\nRaised bogs in Europe have been developing for about 11,000 years, since the beginning of the Holocene and after the retreat of the last ice sheet. As far as their origins are concerned, a distinction is made between lake mires or 'siltation-formed raised bogs' (\"Verlandungshochmoore\") and 'mire-formed raised bogs' (\"wurzelechte Hochmoore\"). The former emerged in a secondary process after the silting up of lakes or oxbows (see illustration on the right in the sequence). At first, fens emerged under the influence of groundwater (minerotrophy). Oxygen deficiencies and high acidity in the constantly moist substrate inhibited the decomposition of dead plant parts and led to peat formation.\n\nThus the raised bog rises very slowly above the level of the groundwater level, hence its name. As the resulting peat slowly rises above the influence of mineral salts in the groundwater, it reaches a point where the development of the raised bog begins to change in nature; that is, the bog now becomes fed solely by rainwater, which is low in salt water. By contrast, mire-formed raised bogs, are created directly on the mineral substrate of in low-salt area without having been initially formed as fens (see figure on the left in the sequence). They are formed either as a primary bog due to the erosion of previously dry mineral soils, for example due to clearing, climate change or infiltration, or as a secondary process as a result of the growth of a raised bog on neighbouring mineral soil. The formation of a typical raised bog is a very slow process, which lasts from centuries to a thousand years even in favourable, undisturbed conditions. Furthermore, there are a number of transitional and intermediate bogs, which in different ways combine characteristics of both raised bogs and fens. (see bog).\n\nThe main constituent of the peat are the rootless peat mosses, that only slowly grow in height, whilst at the same time the lower layer becomes peat as the air is excluded. Depending on the geographical location, various species of peat moss are involved in making the raised bogs. The growth rate of the peat layer is only about a millimetre per year.\nGrowing bogs can be divided into two layers. The 'acrotelm' (Greek: \"akros\" = highest; \"telma\" = bog) is the upper part and includes the vegetation layer and the bog 'floor'. Here fresh organic substances (peat formation horizon) are created by the growth and dying of plant elements. The \"catotelm\" (Greek: kato = below) is the underlying water-saturated part with less biological activity. This layer is counted as a geological subsoil due to the small earth-forming processes that are still going on and is known as the peat preservation horizon (\"Torferhaltungshorizont\"). In raised bogs, the upper peat layer is called white peat, since it consists of largely undecomposed light brown peat mosses. The lower layer is black peat, which is already well humified and has a black-brown colour with still recognizable plant remains.\n\nThe formation of raised bogs is dependent on the climate, that is to say the amount of precipitation and rate of evaporation, which in turn are decisively determined by the temperature. In addition, the relief of the terrain has an influence on the water discharge behaviour and thus the shape of a raised bog. This results in geographical limitations to the formation of raised bogs. Favourable conditions for the development of raised bogs are found mainly in North America (Canada and Alaska), Northern Europe and Western Siberia, South America, Southeast Asia and in the Amazon Basin. In these regions, bogs of all kinds and peat deposits of four million square kilometres have been formed, covering three percent of the earth's surface. In the southern hemisphere low-mineral-rich bogs are rarely formed from peat mosses. Only in the Tierra del Fuego do peat moss raised bogs exist. The most peaty countries in the tropics are found in Southeast Asia. In many cases it is not yet clear how these bogs have emerged as mosses are entirely absent here.\nCoastal bogs (\"Planregenmoore\") or Atlantic bogs, as their names suggest, tend to form close to the sea. In addition, in regions covered by blanket bog, there are also lightly convex coastal bogs with low energy surface relief in level locations. The distribution of coastal bogs in Europe extends from Ireland to the east via South Norway to Southwest Sweden and north to the Lofoten. In North America there are coastal bogs in the area of the Great Lakes (especially in Minnesota and Ontario). Coastal bogs are also fed exclusively by the rain.\n\nIn the less oceanically influenced climatic regions of North-West Europe (lower precipitation), the raised bogs take on the classical lens shape and are called plateau bogs or plateau raised bogs (\"Plateauregenmoore\"). They grow more strongly in the centre than at the margins. This results in the centre of the bog bulging, hence the name \"raised bog\". This bulging can be several metres high. As a result, the perimeter of the bog is more or less inclined, and is known as the \"rand\". The sloping bog sides of larger bogs are traversed by drainage channels or soaks (\"Rüllen\") through which the excess water is discharged.\n\nOther characteristic structures of these raised bogs are the flat, treeless raised bog core with its characteristic microrelief of shallow wet depressions or flarks (\"Schlenken\") alternating with hummocks (\"Bülten\") of drier peat moss. Larger accumulations of water in the middle of the bogs are called kolks or bog ponds (of humic acid-rich water); the wet area on the outer margins is known as a moat or \"lagg\".\n\nGenuine ombrotrophic bogs on the North German Plain are usually sharply divided into two layers: an underlying black peat layer, which is strongly decomposed, and an overlying white peat layer which is less decomposed. This difference is a result of changes in the hydrology of the bog. The white peat grew more rapidly under humid conditions than the black peat. This is attributed to a climate change with high precipitation and low evaporation around 1000 to 500 BC. As a result, the peat moss growth grew locally and the black peat/white peat boundary layer was formed, although this did not develop simultaneously in all raised bogs.\n\nRaised bogs also occur in precipitation-rich upland regions at the montane and, more rarely, alpine levels (i.e. above the tree line). As a result of the sloping terrain, they often have a characteristic, asymmetric or non-concentric appearance. Mountain or upland bogs may be topographically divided into:\nAll these bog types may occur on the margins of lowland bogs i.e. fens, or transition into them.\n\nKermi bogs (\"Kermimoore, Schildhochmoore, Strangmoore\" or \"Blankenmoore\") or kermi raised bogs have only a slightly domed shape. The surface of the bog rises steadily from the broad lagg zone. Kermis have ridge-shaped hummocks of peat moss, that are aligned with the contours of the bog. The flarks or elongated depressions are generally tub-shaped and hardly distinguishable externally from kolks. In the central area of these bogs, there are always large kolks. In northern Russia and western Sibiria, kermis frequently occur in giant complexes where the bogs have grown into one another. Kermis are also found in Finland in the central and northern boreal forest zone.\n\nString bogs or aapa fens (\"Aapamoore\" or \"Strangmoore\") are typically found on the northern fringes of the distribution area for raised bogs, in the sub-polar zone, north of the 66th latitude in the northern hemisphere. Here, raised bogs only occur as islands within wetlands supplied by mineral soil water. On level ground these islands are irregularly distributed; on hillsides they form ridges parallel to the contours and at right angles to line of slope. The ridges separate boggy hollows of mineral soil known by the Finnish word, \"rimpis\". The main distribution area for string bogs are the Scandinavian hills, central Finland, Karelia and north Sibiria. In North America, Alaska is the main location for string bogs, thanks to its cold continental climate. Frost action plays an important role in these bogs. On the ridges or hummocks, ground ice is found until early summer.\n\nPalsa bogs (\"Palsamoore\" or \"Palsenmoore\") are found on the margins of the Arctic permafrost soils (tundra). Here the ridges of the string bogs can grow into hummocks several metres high. Like string bogs, the so-called palsas frequently lie within peatlands fed by mineral soil water. Some are surrounded by water-filled, ditch-like hollows. Peat formation is limited; these bogs are peat deposits from warmer, interglacial periods and did not experience frost heaving of their inner core of ice until the climate became colder. These ice lenses increase in size from year to year as a result of freeze-thaw processes of the surrounding water. The low temperatures prevent full decomposition of the organic material.\n\nPolygonal bogs (\"Polygonmoore\") are widespread on the Arctic and sub-Arctic plains of Sibiria and North Americas and cover vast areas. They are associated with patterned peatland and ice wedges. A scanty layer of peat-forming vegetation can occur in the inner honeycomb-shaped areas of this frost pattern terrain (cryoturbation) and are fed during the short summers with sufficient moisture, because the meltwater is prevented from draining away by the raised polygonal margins. The peat layers can attain a thickness of .\nThe west Siberian raised bog area covers . The large bogs have domes in the centre up to high. They are predominantly of the kermi bog type. They represent probably the most important type of raised bog on earth. The Vasyugan Swamp in this region, is the largest bog system on earth and covers more than . It is estimated to contain over 14 billion tonnes of peat deposits.\nThe largest central European raised bog areas are the southern North Sea coastal area and the Alpine Foreland. As in North America there is a succession of raised bog types along the line of descent towards the ocean, from northwest to southeast. As a result of peat use, raised bogs have been harvested for peat and cultivated, apart from a few remnants (less than 10% of the original area). The largest contiguous raised bog in central Europe was the Bourtange Moor, which originally covered an area of about 2,300 km² including the Dutch portion, but only small sections remain. The largest remaining raised bog in northern Europe is the 76 km² Lille Vildmose. Other large raised bogs are the Teufelsmoor northeast of Bremen, the Vehnemoor (exhausted) and the Esterweger Dose (formerly about 80 km², exhausted) between Oldenburg and Papenburg. The raised bogs of the Central Uplands of the Harz, Solling, Thuringian Forest (Großer Beerberg, Schneekopf - Teufelsbad, Fichtenkopf, Saukopf), Giant Mountains, Ore Mountains, Fichtel and Rhön (Black Moor, Red Moor) are, by contract, comparatively small. In the Black Forest the Wildseemoor has been protected and, in the Vosges on \"le Tanet\", north of the Col de la Schlucht a large area has been protected. The Alpine Foreland, which was formed by ice-age glaciation, is also rich in peatland. The Wurzacher Ried (Haidgauer Regenmoorschild) is considered the largest and best preserved raised bog in central Europe. Other raised bogs and peatland areas include the Federsee, the High Fens on the Germano-Belgian border, the Ewiges Meer near Aurich and the Lengener Meer near Wiesmoor. The last Baltic raised bogs have now been exhausted. In 2003, Estonia exported 3.6 million m³ of peat for west European garden use, more than 60% of the state production. In Lithuania 60% of the usable peat area has been prepared for extraction or is already exhausted.\n\nLough Lurgeen Bog and Glenamaddy Turlough Bog contains very good examples of the Annex 1 habitats: active raised bog, turlough (both priority habitats), degraded raised bog (capable of regeneration) and vegetation of depressions (rhynchosporion). These habitats are considered to be among the best examples in Ireland due to their relatively large size and the generally low levels of disturbance. In the Natura form compiled for the site active raised bog was given a rating of A (Excellent value) which emphasises the importance of the site. Raised bog habitats are now very rare in Europe and it has recently been estimated that the Republic of Ireland contains 50% of the relatively intact oceanic raised bog systems in Europe.\n\nThe site contains the second largest area of intact raised bog surface in Ireland. The combination of raised bog, oligotrophic lake and turlough habitats is unique in Ireland and thus the entire system is very important from both a hydrological and ecological perspective.\n\nA region of peatland extends from Alaska in the west to the coast of the Atlantic in the east, and is comparable in size to that of West Siberia. A zone of domed raised bogs adjoins the zones of palsa bogs and string fens. In the direction of descent towards the ocean, blanket bogs occur east of Hudson Bay. These are superseded towards the west by plateau bogs in the area of the large lakes and, eventually, by kermi bogs.\n\n\n"}
{"id": "54124", "url": "https://en.wikipedia.org/wiki?curid=54124", "title": "Rhyolite", "text": "Rhyolite\n\nRhyolite is an igneous, volcanic rock, of felsic (silica-rich) composition (typically > 69% SiO – see the TAS classification). It may have any texture from glassy to aphanitic to porphyritic. The mineral assemblage is usually quartz, sanidine and plagioclase (in a ratio > 2:1 – see the QAPF diagram). Biotite and hornblende are common accessory minerals. It is the extrusive equivalent to granite.\n\nRhyolite can be considered as the extrusive equivalent to the plutonic granite rock, and consequently, outcrops of rhyolite may bear a resemblance to granite. Due to their high content of silica and low iron and magnesium contents, rhyolite melts are highly polymerized and form highly viscous lavas. They also occur as breccias or in volcanic plugs and dikes. Rhyolites that cool too quickly to grow crystals form a natural glass or vitrophyre, also called obsidian. Slower cooling forms microscopic crystals in the lava and results in textures such as flow foliations, spherulitic, nodular, and lithophysal structures. Some rhyolite is highly vesicular pumice. Many eruptions of rhyolite are highly explosive and the deposits may consist of fallout tephra/tuff or of ignimbrites.\n\nEruptions of rhyolite are relatively rare compared to eruptions of less felsic lavas. Only three eruptions of rhyolite have been recorded since the start of the 20th century: at the St. Andrew Strait volcano in Papua New Guinea, Novarupta volcano in Alaska, and Chaiten in southern Chile.\n\nRhyolite has been found on islands far from land, but such oceanic occurrences are rare.\n\n\n\n\n\n\n\nThe name rhyolite was introduced into geology in 1860 by the German traveler and geologist Ferdinand von Richthofen from the Greek word \"rhýax\" (\"a stream of lava\") and the rock name suffix \"-lite\".\n\nIn North American pre-historic times, rhyolite was quarried extensively in eastern Pennsylvania in the United States. Among the leading quarries was the Carbaugh Run Rhyolite Quarry Site in Adams County, where as many as fifty small quarry pits are known.\n\n\n"}
{"id": "40458273", "url": "https://en.wikipedia.org/wiki?curid=40458273", "title": "Subtropical Countercurrent", "text": "Subtropical Countercurrent\n\nThe subtropical countercurrent (STCC) is a narrow eastward ocean current in the central North Pacific Ocean (20–30°N) where the Sverdrup theory predicts a broad westward flow. It originates in the western North Pacific around 20°N, and flows eastward against the northeast trade winds and stretches northeastward to the north of Hawaii.\n\nIt is accompanied by a subsurface temperature and density front called the subtropical front, in thermal wind relation with the STCC. Furthermore, the STCC maintains a sea surface temperature front during winter and spring. During April and May when the SST front is still strong, the seasonal warming makes the region conductive to atmospheric convection, and surface wind stress curls turn weakly positive along the front on the background of negative curls that drive the subtropical gyre.\n\nOn the weather timescale, positive wind curls are related to low-pressure systems of a subsynoptic scale in space, energized by surface baroclinicity and latent heat release along the STF front. The SST front also anchors a meridional maximum in column-integrated water vapor, indicating a deep structure of the atmosphere response.\n"}
{"id": "8652125", "url": "https://en.wikipedia.org/wiki?curid=8652125", "title": "Tare weight", "text": "Tare weight\n\nTare weight , sometimes called unladen weight, is the weight of an empty vehicle or container. By subtracting it from the gross weight (laden weight), the weight of the goods carried (the net weight) may be determined. This can be useful in computing the cost of the goods carried for purposes of taxation or for tolls related to barge, rail, road, or other traffic, especially where the toll will vary with the value of the goods carried (\"e.g.\", tolls on the Erie Canal). Tare weight is often published upon the sides of railway cars and transport vehicles to facilitate the computation of the load carried. Tare weight is also used in body composition assessment when doing underwater weighing.\n\nThe word \"tare\" originates from the Middle French word “wastage in goods, deficiency, imperfection” (15th ), from Italian , from Arabic , lit. “thing deducted or rejected”, from “to reject”.\n\nTare weight is accounted for in kitchen scales, analytical (scientific) and other weighing scales which include a button that resets the zero of the scale display when an empty container is placed on the weighing platform, in order to subsequently display only the weight of the contents of the container.\n\nGross weight (the total weight) = net weight (the weight of the goods) + tare weight (the weight of the empty container).\n\n\n"}
{"id": "1986599", "url": "https://en.wikipedia.org/wiki?curid=1986599", "title": "University High School (Los Angeles)", "text": "University High School (Los Angeles)\n\nUniversity High School, commonly known as \"Uni\", is a public secondary school, built 1923-1924, and founded 1924, located in West Los Angeles, a district in Los Angeles, California, near the border with Santa Monica. University High is part of the Los Angeles Unified School District (LAUSD). The campus also holds Indian Springs Continuation High School. The school contains the Serra Springs, a sacred site of the Tongva–Gabrieleño native people and a registered California Historical Landmark.\n\nWhile under construction it was known as Sawtelle High School, but it opened as Warren G. Harding High School when completed in 1924, after 29th President Warren G. Harding (1865-1923, served 1921-1923), who had recently died. The school was renamed in 1929 after the University of California at Los Angeles (UCLA) moved its campus from East Hollywood to Westwood, and the reputation of former President Harding had declined after the infamous Teapot Dome scandal and other situations. The name \"University\" is supposed to have originated because it became a site where teachers-in-training from nearby UCLA worked as assistant teachers/interns.\n\nThe original administration building was designed by the firm Russell & Alpaugh and the construction process began in 1923. The style which was chosen recalls the Romanesque of Northern Italy and Spanish Mission style architecture. The administration building once displayed an octagonal tower and a portico, but these features were toppled in the 1933 Long Beach earthquake. An original cafeteria building was located where the current cafeteria and theater stand today. Although the gymnasium and a beautiful and widely admired auditorium were condemned following the 1971 Sylmar earthquake, the school's original main building from 1924 remains in use. The music building and gym (rebuilt in the early 1980s) have been scheduled to be taken down because they sit on a fault line and therefore against district policy. As of July 2010, the music building is gone.\n\nMusic classes have been moved to another unused room near the top of the school. The gym was still in use while, on the south end of the campus, in what was formerly a student parking lot, a new gym facility was under construction in 2010. The current football stadium, last rebuilt following the 1994 Northridge earthquake, is named in honor of Jackie Robinson (1919-1972), of Pasadena, California, the first African American professional baseball player in Major League Baseball, playing in 1947-1956 for the Brooklyn Dodgers, who also previously attended nearby UCLA, 1939-1940. \n\nUni is one of a very few pre-World War II high schools in Los Angeles whose buildings have been at least partially spared by three major earthquakes since its inception. The main building presents a very traditional and dignified appearance, with weathered brick and arched doorways, such that the campus is popular with film crews (see #Filming on campus). One-third of its class of 1942 did not graduate because of the internment of Japanese-Americans.\n\nIn fall 2007, some neighborhoods zoned to have their students to attend Hamilton High School were rezoned to University High School.\n\nIn 2009, Mitchell Landsberg of the \"Los Angeles Times\" stated that the school was \"struggling to regain its reputation as a center of excellence\". That year, as part of a grant program, the Academy of Engineering was established at the high school.\n\nFor the entire 88-year history of University High, the football/baseball field had been without stadium lights until they were installed in the Spring of 2012.\n\nLocated on Uni's campus are the Serra Springs, California Historical Landmark #522. The springs, called \"Kuruvungna\" by the native Gabrieleno Tongva people, were used as a source of natural fresh water by the Tongva people since 400 , and they continue to produce 22,000-25,000 gallons of water a day. The springs are found at two separate locations on campus. The larger is now closed off from the rest of the campus and is under the care of the Gabrielino/Tongva Springs Foundation. Prior to its being fenced off, the area surrounding the springs and pond into which its waters feed was popular among the students as a place to meet and relax. The other spring is located on the northeastern edge of the so-called Girls' Field. A third spring was located farther north, near Texas Avenue, but it ceased to flow during the 1940s when a local water company began drawing from the aquifer.\n\nThe Portolá Expedition of 1769, one of the two expeditions that led to the founding of Los Angeles, camped at the Kuruvunga village while travelling along the route that would become known as El Camino Real. The name Serra comes from Father Junípero Serra the founder of the Alta California mission chain, who is reported to have said Mass to there. In the 1800s, the spring served as the water supply for the city of Santa Monica.\n\nConstruction at the school in 1925 unearthed evidence of a Native America village, and in 1975, a grave was discovered from what archaeologists now believe to be a burial site.\n\nIn 1980, Indian Springs Continuation High School, which is housed on the part of the campus where the springs are, was opened. \n\nIn 1992, tribal descendants, community members, and teachers and students from the school founded the Gabrielino/Tongva Springs Foundation, a non-profit foundation, to fight a proposed development a block north of the springs that would have cut off the springs' underground water source. They successfully fought the proposed parking structure, and since that time, the Foundation has been active at the springs.\n\nThat same year, the newly established Foundation held the first annual Life Before Columbus Day event. The event, which takes place just before Columbus Day every year and celebrates the history of the land and of the Tongva people, has been known to draw upward of 600 people some years, including Native Americans from various tribes, local politicians, community members, and students and faculty from the school. \n\nThe event includes tours of the Kuruvunga Village site and springs, performances by dancers from the Tongva and Aztec tribe, and storytelling from the Chumash tribe. There are also hands-on activities offered by authentic Native American vendors. The foundation currently leases the site from the Los Angeles Unified School District for their monthly ceremony and guided tours.\n\nThe weekly student newspaper, the \"Wildcat\", is part of the High School National Ad Network. Print issues from the school's inception as Harding High are available in the journalism archives. More recent issues were previously archived online at the \"My High School Journalism\" site operated by the American Society of Newspaper Editors\n\nThe \"Red Tide\" was an underground campus newspaper. Its first issue appeared in November 1971. Following the suspension of two students for distributing \"Red Tide\" #2, 500-700 Uni students occupied the administration building.\n\nThe \"Red Tide\" challenged the Warrior mascot as racist. Twenty-five years later, the mascot was removed as part of the LAUSD's ban on Native American based nicknames. In 1995 LA and Bay Area \"Red Tide\" branches moved to Detroit, where they organized campaigns to free Gary Tyler and other campaigns against racism.\n\nThe school's mascot was formerly the Warrior, but was changed after the Southern California Indian Center petitioned the LAUSD to eliminate the mascots and names of all schools that had American Indian mascot and names. In 1997 the LAUSD decided to eliminate all American Indian mascots. The LAUSD decision was upheld in federal court, but the California Racial Mascots Act, a bill which would eliminate American Indian mascots and names statewide, was vetoed by California Governor Arnold Schwarzenegger twice.\n\nTowards the end of the 1997–1998 school year, students were allowed to vote on a new school mascot. Students chose the \"Wildcats\" over the \"Gators\" and \"Jaguars\". The Class of 1985 had, as a senior project and gift to the school, painted a large Warrior mascot on the south entrance to the gym building. Shortly after the mascot change, this was painted over with its feline animal replacement.\n\n\nAccording to the School Information Branch:\n\nNeighborhoods served by University High include West Los Angeles, portions of Brentwood (including Brentwood Glen), Beverly Glen, Beverly Hills Post Office (BHPO), Westwood, Bel-Air, Sawtelle, Benedict Canyon, the Wilshire Corridor, and Holmby Hills. Included in BHPO are relatively distant canyon neighborhoods adjacent to the city of Beverly Hills; since the neighborhoods are in Los Angeles, the students are not in the Beverly Hills Unified School District boundaries.\n\nLike other Westside high schools such as Westchester and Palisades, University High School enrolls a diverse mix of students from its enrollment area and various parts of the city; on top of Westside neighborhoods, Uni draws students from areas such as Koreatown and South Los Angeles. The school also enrolls many Capacity Adjustment Program students which come from areas zoned to heavily overcrowded high schools.\n\nTwo new LAUSD high schools opened in fall 2005, four more in fall 2006, and one more in fall 2007, decreasing the number of transfer students in other high schools.\n\nUnderground water from the Kuruvungna springs sustains seven mature Indian Laurel Ficus trees on the campus which line a walkway between the classroom building and one of the two teachers' parking lots. In September 2002, LAUSD Area D announced that it would remove the seven ficus trees lining the outside of the classroom building, because the roots had grown into and were pushing up the concrete in the parking lot causing a potential hazard.\n\nIn response to the removal announcement a campaign was launched to stop the removal of the trees. Notably, a student petition got 1,200 signatures (about half of the student population), and community involvement came from the city of Santa Monica and from the neighborhood councils of Brentwood and West Los Angeles.\n\nIn response to the public outcry, the LAUSD held meetings to determine what would happen to the trees. Walter Warriner, the Arborist of the city of Santa Monica proposed installing Rubbersidewalks by Rubbersidewalks, Inc., which could be easily lifted in order to prune the tree roots for maintenance. After months of negotiations, the LAUSD decided not to remove the trees and agreed to install Rubbersidewalks, making University High School the first high school in the United States to use Rubbersidewalks in order to preserve its trees. Installation for the Rubbersidewalks started on November 20, 2003, over a year after the LAUSD had originally condemned the trees.Installation of the Rubbersidewalks was covered by Huell Howser for California's Gold. The episode covering Uni High's Rubbersidewalks aired on KCET on January 28, 2004. Rubber asphalt was also used to repave the pushed up concrete in the teachers' parking lot.\n\nThe school, which has been able to maintain much of its original architecture, is one of the few Los Angeles schools with buildings constructed before World War II. Its brick facades, wide hallways, and \"unique east coast look\" make the school an attractive place to film. The administration, which allows filming during school hours, moves classes as needed and allows productions to make minor changes to the campus, has a long history of bringing in filming (and the money that goes with it) to the school.\n\nThe use of the school for filming is a controversial one. Filming often takes place during school hours, and students and teachers are moved from classrooms and walkways are blocked off as needed. The school often undergoes renovations for filming, anything from retiling and painting, to temporary removal of furniture and lockers. These disruptions are a cause for students and teacher complaints.\n\nPast articles in the \"Wildcat\" addressed not only the disruption to students, but how the money made from the constant filming is spent. Editorials have complained about the portion of the money that goes to the LAUSD, and the way the money is spent by the school.\n\nUniversity High charges the standard district fee for each day of filming (currently $2,500). A portion of the money earned goes to FilmL.A., Inc., formerly named the Entertainment Industry Development Corporation, which acts as an intermediary between the LAUSD and the entertainment industry. The name change, which followed the naming of a new president and finance chief and came as the company was preparing to relocate its headquarters and implement a revised contract with the Los Angeles City Council, helped distance the private non-profit from its \"bureaucratic and scandal-ridden image.\" \n\nIn March 2005, the LAUSD entered into a new three-year contract with the EIDC, aftering soliciting bids from other vendors. Ruben Rojas, the LAUSD's director of revenue enhancement, said that the district choose to continue working with the EIDC because of \"its proven track record and ability to deal with complex film-permitting issues.\". Indeed, during that time, FilmL.A. expanded the number of schools that had hosted on-location filming from 19 schools to more than 200 schools: coordinating 1,500 film shoots at 250 LAUSD sites. The LAUSD's filming profits for the 2003-2004 school year generated almost one million dollars, and the district is on target to for an annual film revenue increase to at least $1.5 million. \n\nThe doubling of the LAUSD's film revenue in the four years since FilmL.A. was original hired in March 2002 was a contributing factor to Burbank Unified School District's decision to hire Film L.A. in July 2006.\n\nUnder FilmL.A.'s current contract with the city, the company receives \"a 16% management fee based on the total use fee\". 75 percent of the remaining filming monies go to the individual schools that host the on-location shooting to be used at the school's discretion, and 25 percent goes to a district fund that benefits schools that do not generate film revenues of their own. \n\nUni High distributes among the departments the first $12,000 made each year from on-campus filming. The Budget Committee makes spending recommendations for any additional monies. Recent budget cuts have made filming at schools more attractive. In 2004, the number of schools volunteering to be film locations grew from 19 to 160 and the district's annual film revenue doubled to $1 million. In 2005,\nLAUSD officials revised the district's fee structure for the first time since 1992. The revision included extending a full day of shooting from 14 to 15 hours, and a daily rate increase from $1,700 to $2,500.\n\nUni has been noted in the press as being one of the more popular schools for filming, even compared to other local schools with similar structure and appearance. In a two-year period ending in 2003, 38 movies, TV shows and commercials were filmed at University High. This popularity, with both its positive and negative impacts, is credited to the Assistant Principal who is responsible for the filming on campus.\n\nIn November 2006, \"Drillbit Taylor\", starring Owen Wilson began filming at Uni. As of April 2007, the $90,000 received for this production is the most that the school has made on an individual filming contract. Uni underwent massive renovations in order to prepare for the filming of \"Drillbit Taylor\". The interior and exterior of the main building were painted, and the main building was retiled as well. The facade of the building was altered to read \"McKinley High School\", and plants and grass patches were added throughout the school. \n\nThese changes were unusual not only because the extent and timing of the changes meant that construction took place during the school year, but also because \"Drillbit Taylor\" production did not pay for the re-tiling. The district had provided money to re-tile floors throughout the LAUSD, so the re-tiling of the floors itself was not unusual or controversial. However, as the film's production needs guided the color choices for the re-tiling and the schedule for construction, many students were upset by the behavior of the movie company and the school.\n\nBelow is an incomplete list of productions that have filmed at University High:\n\n\n\n\n\nList of University High School (Los Angeles, California) alumni\n\n"}
{"id": "102024", "url": "https://en.wikipedia.org/wiki?curid=102024", "title": "Wetland", "text": "Wetland\n\nA wetland is a distinct ecosystem that is inundated by water, either permanently or seasonally, where oxygen-free processes prevail. The primary factor that distinguishes wetlands from other land forms or water bodies is the characteristic vegetation of aquatic plants, adapted to the unique hydric soil. Wetlands play a number of functions, including water purification, water storage, processing of carbon and other nutrients, stabilization of shorelines, and support of plants and animals. Wetlands are also considered the most biologically diverse of all ecosystems, serving as home to a wide range of plant and animal life. Whether any individual wetland performs these functions, and the degree to which it performs them, depends on characteristics of that wetland and the lands and waters near it. Methods for rapidly assessing these functions, wetland ecological health, and general wetland condition have been developed in many regions and have contributed to wetland conservation partly by raising public awareness of the functions and the ecosystem services some wetlands provide.\n\nWetlands occur naturally on every continent. The main wetland types are swamp, marsh, bog, and fen; sub-types include mangrove forest, carr, pocosin, floodplains, mire, vernal pool, sink, and many others. Many peatlands are wetlands. The water in wetlands is either freshwater, brackish, or saltwater.\nWetlands can be tidal (inundated by tides) or non-tidal. The largest wetlands include the Amazon River basin, the West Siberian Plain, the Pantanal in South America, and the Sundarbans in the Ganges-Brahmaputra delta.\n\nThe UN Millennium Ecosystem Assessment determined that environmental degradation is more prominent within wetland systems than any other ecosystem on Earth.\n\nConstructed wetlands are used to treat municipal and industrial wastewater as well as stormwater runoff. They may also play a role in water-sensitive urban design.\n\nA patch of land that develops pools of water after a rain storm would not necessarily be considered a \"wetland\", even though the land is wet. Wetlands have unique characteristics: they are generally distinguished from other water bodies or landforms based on their water level and on the types of plants that live within them. Specifically, wetlands are characterized as having a water table that stands at or near the land surface for a long enough period each year to support aquatic plants.\n\nA more concise definition is a community composed of hydric soil and hydrophytes.\n\nWetlands have also been described as ecotones, providing a transition between dry land and water bodies. Mitsch and Gosselink write that wetlands exist \"...at the interface between truly terrestrial ecosystems and aquatic systems, making them inherently different from each other, yet highly dependent on both.\"\n\nIn environmental decision-making, there are subsets of definitions that are agreed upon to make regulatory and policy decisions.\n\nA wetland is \"an ecosystem that arises when inundation by water produces soils dominated by anaerobic and aerobic processes, which, in turn, forces the biota, particularly rooted plants, to adapt to flooding.\" There are four main kinds of wetlands – marsh, swamp, bog and fen (bogs and fens being types of mires). Some experts also recognize wet meadows and aquatic ecosystems as additional wetland types. The largest wetlands in the world include the swamp forests of the Amazon and the peatlands of Siberia.\n\nUnder the Ramsar international wetland conservation treaty, wetlands are defined as follows:\n\nAlthough the general definition given above applies around the world, each county and region tends to have its own definition for legal purposes. In the United States, wetlands are defined as \"those areas that are inundated or saturated by surface or groundwater at a frequency and duration sufficient to support, and that under normal circumstances do support, a prevalence of vegetation typically adapted for life in saturated soil conditions. Wetlands generally include swamps, marshes, bogs and similar areas\". This definition has been used in the enforcement of the Clean Water Act. Some US states, such as Massachusetts and New York, have separate definitions that may differ from the federal government's.\n\nIn the United States Code, the term wetland is defined \"as land that (A) has a predominance of hydric soils, (B) is inundated or saturated by surface or groundwater at a frequency and duration sufficient to support a prevalence of hydrophytic vegetation typically adapted for life in saturated soil conditions and (C) under normal circumstances supports a prevalence of such vegetation.\" Related to this legal definitions, the term \"normal circumstances\" are conditions expected to occur during the wet portion of the growing season under normal climatic conditions (not unusually dry or unusually wet), and in the absence of significant disturbance. It is not uncommon for a wetland to be dry for long portions of the growing season. Wetlands can be dry during the dry season and abnormally dry periods during the wet season, but under normal environmental conditions the soils in a wetland will be saturated to the surface or inundated such that the soils become anaerobic, and those conditions will persist through the wet portion of the growing season.\n\nThe most important factor producing wetlands is flooding. The duration of flooding or prolonged soil saturation by groundwater determines whether the resulting wetland has aquatic, marsh or swamp vegetation. Other important factors include fertility, natural disturbance, competition, herbivory, burial and salinity. When peat accumulates, bogs and fens arise.\n\nWetlands vary widely due to local and regional differences in topography, hydrology, vegetation, and other factors, including human involvement.\n\nWetland hydrology is associated with the spatial and temporal dispersion, flow, and physio-chemical attributes of surface and ground water in its reservoirs. Based on hydrology, wetlands can be categorized as riverine (associated with streams), lacustrine (associated with lakes and reservoirs), and palustrine (isolated). Sources of hydrological flows into wetlands are predominantly precipitation, surface water, and groundwater. Water flows out of wetlands by evapotranspiration, surface runoff, and subsurface water outflow. Hydrodynamics (the movement of water through and from a wetland) affects hydro-periods (temporal fluctuations in water levels) by controlling the water balance and water storage within a wetland.\n\nLandscape characteristics control wetland hydrology and hydrochemistry. The O and CO concentrations of water depend on temperature and atmospheric pressure. Hydrochemistry within wetlands is determined by the pH, salinity, nutrients, conductivity, soil composition, hardness, and the sources of water. Water chemistry of wetlands varies across landscapes and climatic regions. Wetlands are generally minerotrophic with the exception of bogs.\n\nBogs receive most of their water from the atmosphere; therefore, their water usually has low mineral ionic composition. In contrast, groundwater has a higher concentration of dissolved nutrients and minerals.\n\nThe water chemistry of fens ranges from low pH and low minerals to alkaline with high accumulation of calcium and magnesium because they acquire their water from precipitation as well as ground water.\n\nSalinity has a strong influence on wetland water chemistry, particularly in wetlands along the coast. and in regions with large precipitation deficits. In non-riverine wetlands, natural salinity is regulated by interactions between ground and surface water, which may be influenced by human activity.\n\nCarbon is the major nutrient cycled within wetlands. Most nutrients, such as sulfur, phosphorus, carbon, and nitrogen are found within the soil of wetlands. Anaerobic and aerobic respiration in the soil influences the nutrient cycling of carbon, hydrogen, oxygen, and nitrogen, and the solubility of phosphorus thus contributing to the chemical variations in its water. Wetlands with low pH and saline conductivity may reflect the presence of acid sulfates and wetlands with average salinity levels can be heavily influenced by calcium or magnesium. Biogeochemical processes in wetlands are determined by soils with low redox potential. Wetland soils are identified by redoxymorphic mottles or low chroma, as determined by the Munsell Color System.\n\nThe biota of a wetland system includes its flora and fauna as described below. The most important factor affecting the biota is the duration of flooding. Other important factors include fertility and salinity. In fens, species are highly dependent on water chemistry. The chemistry of water flowing into wetlands depends on the source of water and the geological material in which it flows through as well as the nutrients discharged from organic matter in the soils and plants at higher elevations in slope wetlands. Biota may vary within a wetland due to season or recent flood regimes.\n\nThere are four main groups of hydrophytes that are found in wetland systems throughout the world.\n\nSubmerged wetland vegetation can grow in saline and fresh-water conditions. Some species have underwater flowers, while others have long stems to allow the flowers to reach the surface. Submerged species provide a food source for native fauna, habitat for invertebrates, and also possess filtration capabilities. Examples include seagrasses and eelgrass.\n\nFloating water plants or floating vegetation is usually small, like arrow arum (\"Peltandra virginica\").\n\nTrees and shrubs, where they comprise much of the cover in saturated soils, qualify those areas in most cases as swamps. The upland boundary of swamps is determined partly by water levels. This can be affected by dams Some swamps can be dominated by a single species, such as silver maple swamps around the Great Lakes. Others, like those of the Amazon basin, have large numbers of different tree species. Examples include cypress (\"Taxodium\") and mangrove.\n\nFish are more dependent on wetland ecosystems than any other type of habitat. Seventy-five percent of the United States' commercial fish and shellfish stocks depend solely on estuaries to survive. Tropical fish species need mangroves for critical hatchery and nursery grounds and the coral reef system for food.\n\nAmphibians such as frogs need both terrestrial and aquatic habitats in which to reproduce and feed. While tadpoles control algal populations, adult frogs forage on insects. Frogs are used as an indicator of ecosystem health due to their thin skin which absorbs both nutrient and toxins from the surrounding environment resulting in an above average extinction rate in unfavorable and polluted environmental conditions.\nReptiles such as alligators and crocodiles are common in wetlands of some regions. Alligators occur in fresh water along with the fresh water species of the crocodile.The Florida Everglades is the only place in the world where both crocodiles and alligators coexist. The saltwater crocodile inhabits estuaries and mangroves and can be seen in the coastline bordering the Great Barrier Reef in Australia.\nSnakes, lizards and turtles also can be seen throughout wetlands. Snapping turtles are one of the many kinds of turtles found in wetlands.\nBirds, particularly waterfowl and wading birds, use wetlands extensively\n\nMammals include numerous small and medium-sized species such as voles, bats, and platypus in addition to large herbivorous and apex species such as the beaver, coypu, swamp rabbit, Florida panther, and moose. Wetlands attract many mammals due to abundant seeds, berries, and other vegetation components, as well as abundant populations of prey such as invertebrates, small reptiles and amphibians.\n\nInsects and invertebrates total more than half of the 100,000 known animal species in wetlands. Insects and invertebrates can be submerged in the water or soil, on the surface, and in the atmosphere\n\nAlgae are diverse water plants that can vary in size, color, and shape. Algae occur naturally in habitats such as inland lakes, inter-tidal zones, and damp soil and provide a dedicated food source for many animals, including some invertebrates, fish, turtles, and frogs. There are three main groups of algae:\n\n\nWetlands are located in every climatic zone. Temperatures vary greatly depending on the location of the wetland. Many of the world's wetlands are in temperate zones, midway between the North or South Pole and the equator. In these zones, summers are warm and winters are cold, but temperatures are not extreme. In a temperate zone wetland, such as one along the Gulf of Mexico, a typical temperature might be . Wetlands in the tropics are much warmer for a larger portion of the year. Wetlands on the Arabian Peninsula can reach temperatures exceeding and would therefore be subject to rapid evaporation. In northeastern Siberia, which has a polar climate, wetland temperatures can be as low as . Peatlands insulate the permafrost in subarctic regions, thus delaying or preventing thawing of permafrost during summer, as well as inducing the formation of permafrost.\n\nThe amount of precipitation a wetland receives varies widely according to its area. Wetlands in Wales, Scotland, and western Ireland typically receive about per year. In some places in Southeast Asia, where heavy rains occur, they can receive up to . In some drier regions, wetlands exist where as little as precipitation occurs each year. \n\nTemporal variation:\n\nDepending partly on a wetland's geographic and topographic location, the functions it performs can support multiple ecosystem services, values, or benefits. United Nations Millennium Ecosystem Assessment and Ramsar Convention described wetlands as a whole to be of biosphere significance and societal importance in the following areas, for example:\n\n\nAccording to the Ramsar Convention:\n\nThe economic worth of the ecosystem services provided to society by intact, naturally functioning wetlands is frequently much greater than the perceived benefits of converting them to 'more valuable' intensive land use – particularly as the profits from unsustainable use often go to relatively few individuals or corporations, rather than being shared by society as a whole.\n\n\"Unless otherwise cited, ecosystem services information is based on the following series of references.\"\n\nTo replace these wetland ecosystem services, enormous amounts of money would need to be spent on water purification plants, dams, levees, and other hard infrastructure, and many of the services are impossible to replace.\n\n\"Major wetland type: floodplain and closed-depression wetlands\"\n\nStorage reservoirs and flood protection: The wetland system of floodplains is formed from major rivers downstream from their headwaters. \"The floodplains of major rivers act as natural storage reservoirs, enabling excess water to spread out over a wide area, which reduces its depth and speed. Wetlands close to the headwaters of streams and rivers can slow down rainwater runoff and spring snowmelt so that it doesn't run straight off the land into water courses. This can help prevent sudden, damaging floods downstream.\" Notable river systems that produce large spans of floodplain include the Nile River, the Niger river inland delta, [the Zambezi River flood plain], [the Okavango River inland delta], [the Kafue River flood plain][the Lake Bangweulu flood plain] (Africa), Mississippi River (USA), Amazon River (South America), Yangtze River (China), Danube River (Central Europe) and Murray-Darling River (Australia).\n\nHuman impact: Converting wetlands to upland through drainage and development forces adjoining or downstream water channels into narrower corridors. This accelerates watershed hydrologic response to storm events and this increases the need in some cases for alternative means of flood control. That is because the newly formed channels must manage the same amount of precipitation, causing flood peaks to be [higher or deeper] and floodwaters to travel faster.\n\nWater management engineering developments in the past century have degraded these wetlands through the construction of artificial embankments. These constructions may be classified as dykes, bunds, levees, weirs, barrages and dams but serve the single purpose of concentrating water into a select source or area. Wetland water sources that were once spread slowly over a large, shallow area are pooled into deep, concentrated locations. Loss of wetland floodplains results in more severe and damaging flooding. Catastrophic human impact in the Mississippi River floodplains was seen in death of several hundred individuals during a levee breach in New Orleans caused by Hurricane Katrina. Ecological catastrophic events from human-made embankments have been noticed along the Yangtze River floodplains since the middle of the river has become prone to more frequent and damaging flooding. Some of these events include the loss of riparian vegetation, a 30% loss of the vegetation cover throughout the river's basin, a doubling of the percentage of the land affected by soil erosion, and a reduction in reservoir capacity through siltation build-up in floodplain lakes.\n\n\"Major wetland type: marsh, swamp, and subterranean karst and cave hydrological systems\"\n\nThe surface water which is the water visibly seen in wetland systems only represents a portion of the overall water cycle which also includes atmospheric water and groundwater. Wetland systems are directly linked to groundwater and a crucial regulator of both the quantity and quality of water found below the ground. Wetland systems that are made of permeable sediments like limestone or occur in areas with highly variable and fluctuating water tables especially have a role in groundwater replenishment or water recharge. Sediments that are porous allow water to filter down through the soil and overlying rock into aquifers which are the source of 95% of the world's drinking water. Wetlands can also act as recharge areas when the surrounding water table is low and as a discharge zone when it is too high. Karst (cave) systems are a unique example of this system and are a connection of underground rivers influenced by rain and other forms of precipitation. These wetland systems are capable of regulating changes in the water table on upwards of .\n\nHuman impact: Groundwater is an important source of water for drinking and irrigation of crops. Over 1 billion people in Asia and 65% of the public water sources in Europe source 100% of their water from groundwater. Irrigation is a massive use of groundwater with 80% of the world's groundwater used for agricultural production.\n\nUnsustainable abstraction of groundwater has become a major concern. In the Commonwealth of Australia, water licensing is being implemented to control use of water in major agricultural regions. On a global scale, groundwater deficits and water scarcity is one of the most pressing concerns facing the 21st century.\n\n\"Wetland type: Mangroves, coral reefs, salt marsh\"\n\nTidal and inter-tidal wetland systems protect and stabilize coastal zones. Coral reefs provide a protective barrier to coastal shoreline. Mangroves stabilize the coastal zone from the interior and will migrate with the shoreline to remain adjacent to the boundary of the water. The main conservation benefit these systems have against storms and storm surges is the ability to reduce the speed and height of waves and floodwaters.\n\nHuman impact: The sheer number of people who live and work near the coast is expected to grow immensely over the next fifty years. From an estimated 200 million people that currently live in low-lying coastal regions, the development of urban coastal centers is projected to increase the population by fivefold within 50 years.\nThe United Kingdom has begun the concept of managed coastal realignment. This management technique provides shoreline protection through restoration of natural wetlands rather than through applied engineering. In East Asia, reclamation of coastal wetlands has resulted in widespread transformation of the coastal zone, and up to 65% of coastal wetlands have been destroyed by coastal development. One analysis using the impact of hurricanes versus storm protection provided naturally by wetlands projected the value of this service at US$33,000/hectare/year.\n\n\"Wetland types: floodplain, closed-depression wetlands, mudflat, salt marsh, mangroves\"\n\nNutrient retention: Wetlands cycle both sediments and nutrients balancing terrestrial and aquatic ecosystems. A natural function of wetland vegetation is the up-take, storage, and (for nitrate) the removal of nutrients found in runoff from the surrounding soil and water. In many wetlands, nutrients are retained until plants die or are harvested by animals or humans and taken to another location, or until microbial processes convert soluble nutrients to a gas as is the case with nitrate.\n\nSediment and heavy metal traps: Precipitation and surface runoff induces soil erosion, transporting sediment in suspension into and through waterways. These sediments move towards larger and more sizable waterways through a natural process that moves water towards oceans. All types of sediments which may be composed of clay, sand, silt, and rock can be carried into wetland systems through this process. Wetland vegetation acts as a physical barrier to slow water flow and trap sediment for short or long periods of time. Suspended sediment often contains heavy metals that are retained when wetlands trap the sediment. In some cases, certain metals are taken up through wetland plant stems, roots, and leaves. Many floating plant species, for example, can absorb and filter heavy metals. Water hyacinth (\"Eichhornia crassipes\"), duckweed (\"Lemna\") and water fern (\"Azolla\") store iron and copper commonly found in wastewater. Many fast-growing plants rooted in the soils of wetlands such as cattail (\"Typha\") and reed (\"Phragmites\") also aid in the role of heavy metal up-take. Animals such as the oyster can filter more than of water per day while grazing for food, removing nutrients, suspended sediments, and chemical contaminants in the process. On the other hand, some types of wetlands facilitate the mobilization and bioavailability of mercury (another heavy metal), which in its methyl mercury form increases the risk of bioaccumulation in fish important to animal food webs and harvested for human consumption.\n\nCapacity: The ability of wetland systems to store or remove nutrients and trap sediment and associated metals is highly efficient and effective but each system has a threshold. An overabundance of nutrient input from fertilizer run-off, sewage effluent, or non-point pollution will cause eutrophication. Upstream erosion from deforestation can overwhelm wetlands making them shrink in size and cause dramatic biodiversity loss through excessive sedimentation load. Retaining high levels of metals in sediments is problematic if the sediments become resuspended or oxygen and pH levels change at a future time. The capacity of wetland vegetation to store heavy metals depends on the particular metal, oxygen and pH status of wetland sediments and overlying water, water flow rate (detention time), wetland size, season, climate, type of plant, and other factors.\n\nHuman impact: The capacity of a wetland to store sediment, nutrients, and metals can be diminished if sediments are compacted such as by vehicles or heavy equipment, or are regularly tilled. Unnatural changes in water levels and water sources also can affect the water purification function. If water purification functions are impaired, excessive loads of nutrients enter waterways and cause eutrophication. This is of particular concern in temperate coastal systems. The main sources of coastal eutrophication are industrially made nitrogen, which is used as fertilizer in agricultural practices, as well as septic waste runoff. Nitrogen is the limiting nutrient for photosynthetic processes in saline systems, however in excess, it can lead to an overproduction of organic matter that then leads to hypoxic and anoxic zones within the water column. Without oxygen, other organisms cannot survive, including economically important finfish and shellfish species.\n\nExamples: An example of how a natural wetland is used to provide some degree of sewage treatment is the East Kolkata Wetlands in Kolkata, India. The wetlands cover , and are used to treat Kolkata's sewage. The nutrients contained in the wastewater sustain fish farms and agriculture.\n\nThe function of most natural wetland systems is not to manage wastewater. However, their high potential for the filtering and the treatment of pollutants has been recognized by environmental engineers that specialize in the area of wastewater treatment. These constructed wetland systems are highly controlled environments that intend to mimic the occurrences of soil, flora, and microorganisms in natural wetlands to aid in treating wastewater effluent. Constructed wetlands can be used to treat raw sewage, storm water, agricultural and industrial effluent. They are constructed with flow regimes, micro-biotic composition, and suitable plants in order to produce the most efficient treatment process. Other advantages of constructed wetlands are the control of retention times and hydraulic channels. The most important factors of constructed wetlands are the water flow processes combined with plant growth.\n\nConstructed wetland systems can be surface flow systems with only free-floating macrophytes, floating-leaved macrophytes, or submerged macrophytes; however, typical free water surface systems are usually constructed with emergent macrophytes. Subsurface flow-constructed wetlands with a vertical or a horizontal flow regime are also common and can be integrated into urban areas as they require relatively little space.\n\nWetland systems' rich biodiversity is becoming a focal point at International Treaty Conventions and within the World Wildlife Fund organization due to the high number of species present in wetlands, the small global geographic area of wetlands, the number of species which are endemic to wetlands, and the high productivity of wetland systems. Hundred of thousands of animal species, 20,000 of them vertebrates, are living in wetland systems. The discovery rate of fresh water fish is at 200 new species per year. The impact of maintaining biodiversity is seen at the local level through job creation, sustainability, and community productivity. A good example is the Lower Mekong basin which runs through Cambodia, Laos, and Vietnam. Supporting over 55 million people, the sustainability of the region is enhanced through wildlife tours. The U.S. state of Florida has estimated that US$1.6 billion was generated in state revenue from recreational activities associated with wildlife.\n\nBiodiverse river basins: The Amazon holds 3,000 species of freshwater fish species within the boundaries of its basin, whose function it is to disperse the seeds of trees. One of its key species, the Piramutaba catfish, \"Brachyplatystoma vaillantii\", migrates more than from its nursery grounds near the mouth of the Amazon River to its spawning grounds in Andean tributaries, above sea level, distributing plants seed along the route.\n\nProductive intertidal zones: Intertidal mudflats have a level of productivity similar to that of some wetlands even while possessing a low number of species. The abundance of invertebrates found within the mud are a food source for migratory waterfowl.\n\nCritical life-stage habitat: Mudflats, saltmarshes, mangroves, and seagrass beds have high levels of both species richness and productivity, and are home to important nursery areas for many commercial fish stocks.\n\nGenetic diversity: Populations of many species are confined geographically to only one or a few wetland systems, often due to the long period of time that the wetlands have been physically isolated from other aquatic sources. For example, the number of endemic species in Lake Baikal in Russia classifies it as a hotspot for biodiversity and one of the most biodiverse wetlands in the entire world. Evidence from a research study by Mazepova \"et al.\" suggest that the number of crustacean species endemic to Baikal Lake (over 690 species and subspecies) exceeds the number of the same groups of animals inhabiting all the fresh water bodies of Eurasia together. Its 150 species of free-living Platyhelminthes alone is analogous to the entire number in all of Eastern Siberia. The 34 species and subspecies number of Baikal sculpins is more than twice the number of the analogous fauna that inhabits Eurasia. One of the most exciting discoveries was made by A. V. Shoshin who registered about 300 species of free-living nematodes using only six near-shore sampling localities in the Southern Baikal. \"If we will take into consideration, that about 60% of the animals can be found nowhere else except Baikal, it may be assumed that the lake may be the biodiversity center of the Eurasian continent.\"\n\nHuman impact: Biodiversity loss occurs in wetland systems through land use changes, habitat destruction, pollution, exploitation of resources, and invasive species. Vulnerable, threatened, and endangered species number at 17% of waterfowl, 38% of fresh-water dependent mammals, 33% of freshwater fish, 26% of freshwater amphibians, 72% of freshwater turtles, 86% of marine turtles, 43% of crocodilians and 27% of coral reef-building species. Introduced hydrophytes in different wetland systems can have devastating results. The introduction of water hyacinth, a native plant of South America into Lake Victoria in East Africa as well as duckweed into non-native areas of Queensland, Australia, have overtaken entire wetland systems suffocating the wetlands and reducing the diversity of other plants and animals. This is largely due to their phenomenal growth rate and ability to float and grow on the surface of the water.\n\nWetland productivity is linked to the climate, wetland type, and nutrient availability. Low water and occasional drying of the wetland bottom during droughts (dry marsh phase) stimulate plant recruitment from a diverse seed bank and increase productivity by mobilizing nutrients. In contrast, high water during deluges (lake marsh phase) causes turnover in plant populations and creates greater interspersion of element cover and open water, but lowers overall productivity. During a cover cycle that ranges from open water to complete vegetation cover, annual net primary productivity may vary 20-fold. The grasses of fertile floodplains such as the Nile produce the highest yield including\nplants such as \"Arundo donax\" (giant reed), \"Cyperus papyrus\" (papyrus), \"Phragmites\" (reed) and \"Typha\" (cattail, bulrush).\n\nWetlands naturally produce an array of vegetation and other ecological products that can be harvested for personal and commercial use.\nThe most significant of these is fish which have all or part of their life-cycle occur within a wetland system. Fresh and saltwater fish are the main source of protein for one billion people and comprise 15% of an additional two billion people's diets. In addition, fish generate a fishing industry that provides 80% of the income and employment to residents in developing countries. Another food staple found in wetland systems is rice, a popular grain that is consumed at the rate of one fifth of the total global calorie count. In Bangladesh, Cambodia and Vietnam, where rice paddies are predominant on the landscape, rice consumption reach 70%. Some native wetland plants in the Caribbean and Australia are harvested sustainably for medicinal compounds; these include the red mangrove (\"Rhizophora mangle\") which possesses antibacterial, wound-healing, anti-ulcer effects, and antioxidant properties.\n\nFood converted to sweeteners and carbohydrates include the sago palm of Asia and Africa (cooking oil), the nipa palm of Asia (sugar, vinegar, alcohol, and fodder) and honey collection from mangroves. More than supplemental dietary intake, this produce sustains entire villages. Coastal Thailand villages earn the key portion of their income from sugar production while the country of Cuba relocates more than 30,000 hives each year to track the seasonal flowering of the mangrove \"Avicennia\".\n\nOther mangrove-derived products:\n\n\nHuman impact: Over-fishing is the major problem for sustainable use of wetlands. Concerns are developing over certain aspects of farm fishing, which uses natural waterways to harvest fish for human consumption and pharmaceuticals. This practice has become especially popular in Asia and the South Pacific. Its impact upon much larger waterways downstream has negatively affected many small island developing states.\n\nAquaculture is continuing to develop rapidly throughout the Asia-Pacific region specifically in China with world holdings in Asia equal to 90% of the total number of aquaculture farms and 80% of its global value. Some aquaculture has eliminated massive areas of wetland through practices seen such as in the shrimp farming industry's destruction of mangroves. Even though the damaging impact of large scale shrimp farming on the coastal ecosystem in many Asian countries has been widely recognized for quite some time now, it has proved difficult to check in absence of other employment avenues for people engaged in such occupation. Also burgeoning demand for shrimps globally has provided a large and ready market for the produce\n\nThreats to rice fields mainly stem from inappropriate water management, introduction of invasive alien species, agricultural fertilizers, pesticides, and land use changes. Industrial-scale production of palm oil threatens the biodiversity of wetland ecosystems in parts of southeast Asia, Africa, and other developing countries.\n\nOver-exploitation of wetland products can occur at the community level as is sometimes seen throughout coastal villages of Southern Thailand where each resident may obtain for themselves every consumable of the mangrove forest (fuelwood, timber, honey, resins, crab, and shellfish) which then becomes threatened through increasing population and continual harvest.\n\nSome types of wetlands can serve as fire breaks that help slow the spread of minor wildfires. Larger wetland systems can influence local precipitation patterns. Some boreal wetland systems in catchment headwaters may help extend the period of flow and maintain water temperature in connected downstream waters. Pollination services are supported by many wetlands which may provide the only suitable habitat for pollinating insects, birds, and mammals in highly developed areas. It is likely that wetlands have other functions whose benefits to society and other ecosystems have yet to be discovered.\n\nWetlands perform two important functions in relation to climate change. They have mitigation effects through their ability to sink carbon, converting a greenhouse gas (carbon dioxide) to solid plant material through the process of photosynthesis, and also through their ability to store and regulate water. Wetlands store approximately 44.6 million tonnes of carbon per year globally. In salt marshes and mangrove swamps in particular, the average carbon sequestration rate is while peatlands sequester approximately . Coastal wetlands, such as tropical mangroves and some temperate salt marshes, are known to be sinks for carbon that otherwise contributes to climate change in its gaseous forms (carbon dioxide and methane). The ability of many tidal wetlands to store carbon and minimize methane flux from tidal sediments has led to sponsorship of blue carbon initiatives that are intended to enhance those processes.\n\nHowever, depending on their characteristics, some wetlands are a significant source of methane emissions and some are also emitters of nitrous oxide which is a greenhouse gas with a global warming potential 300 times that of carbon dioxide and is the dominant ozone-depleting substance emitted in the 21st century. Excess nutrients mainly from anthropogenic sources have been shown to significantly increase the NO fluxes from wetland soils through denitrification and nitrification processes (see table below). A study in the intertidal region of a New England salt marsh showed that excess levels of nutrients might increase NO emissions rather than sequester them.\n\nData on nitrous oxide fluxes from wetlands in the southern hemisphere are lacking, as are ecosystem-based studies including the role of dominant organisms that alter sediment biogeochemistry. Aquatic invertebrates produce ecologically-relevant nitrous oxide emissions due to ingestion of denitrifying bacteria that live within the subtidal sediment and water column and thus may also be influencing nitrous oxide production within some wetlands.\n\nIn Southeast Asia, peatswamp forests and soils are being drained, burnt, mined, and overgrazed, contributing severely to climate change. As a result of peat drainage, the organic carbon that was built up over thousands of years and is normally under water is suddenly exposed to the air. It decomposes and turns into carbon dioxide (CO), which is released into the atmosphere. Peat fires cause the same process to occur and in addition create enormous clouds of smoke that cross international borders, such as happens every year in Southeast Asia. While peatlands constitute only 3% of the world's land area, their degradation produces 7% of all fossil fuel CO emissions.\n\nThrough the building of dams, Wetlands International is halting the drainage of peatlands in Southeast Asia, hoping to mitigate CO emissions. Concurrent wetland restoration techniques include reforestation with native tree species as well as the formation of community fire brigades. This sustainable approach can be seen in central Kalimantan and Sumatra, Indonesia.\n\nWetlands, the functions and services they provide as well as their flora and fauna, can be affected by several types of disturbances. The disturbances (sometimes termed stressors or alterations) can be human-associated or natural, direct or indirect, reversible or not, and isolated or cumulative. When exceeding levels or patterns normally found within wetlands of a particular class in a particular region, the predominant ones include the following\n\n\nDisturbances can be further categorized as follows:\n\n\nJust a few of the many sources of these disturbances are\n\n\nWetlands have historically been the victim of large draining efforts for real estate development, or flooding for use as recreational lakes or hydropower generation. Some of the world's most important agricultural areas are wetlands that have been converted to farmland. Since the 1970s, more focus has been put on preserving wetlands for their natural function yet by 1993 half the world's wetlands had been drained.\n\nIn order to maintain wetlands and sustain their functions, alterations and disturbances that are outside the normal range of variation should be minimized.\n\nWetlands are vital ecosystems that provide livelihoods for the millions of people who live in and around them. The Millennium Development Goals (MDGs) called for different sectors to join forces to secure wetland environments in the context of sustainable development and improving human wellbeing. A three-year project carried out by Wetlands International in partnership with the International Water Management Institute found that it is possible to conserve wetlands while improving the livelihoods of people living among them. Case studies conducted in Malawi and Zambia looked at how dambos – wet, grassy valleys or depressions where water seeps to the surface – can be farmed sustainably to improve livelihoods. Mismanaged or overused dambos often become degraded, however, using a knowledge exchange between local farmers and environmental managers, a protocol was developed using soil and water management practices. Project outcomes included a high yield of crops, development of sustainable farming techniques, and adequate water management generating enough water for use as irrigation. Before the project, there were cases where people had died from starvation due to food shortages. By the end of it, many more people had access to enough water to grow vegetables. A key achievement was that villagers had secure food supplies during long, dry months. They also benefited in other ways: nutrition was improved by growing a wider range of crops, and villagers could also invest in health and education by selling produce and saving money.\n\n\"The Convention on Wetlands of International Importance, especially as Waterfowl Habitat\", or Ramsar Convention, is an international treaty designed to address global concerns regarding wetland loss and degradation. The primary purposes of the treaty are to list wetlands of international importance and to promote their wise use, with the ultimate goal of preserving the world's wetlands. Methods include restricting access to the majority portion of wetland areas, as well as educating the public to combat the misconception that wetlands are wastelands. The Convention works closely with five International Organisation Partners. These are: Birdlife International, the IUCN, the International Water Management Institute, Wetlands International and the World Wide Fund for Nature. The partners provide technical expertise, help conduct or facilitate field studies and provide financial support. The IOPs also participate regularly as observers in all meetings of the Conference of the Parties and the Standing Committee and as full members of the Scientific and Technical Review Panel.\n\nThe value of a wetland to local communities, as well as the value of wetland systems generally to the earth and to humankind, is one of the most important valuations that can be conducted for sustainable development. This typically involves first mapping a region's wetlands, then assessing the functions and ecosystem services the wetlands provide individually and cumulatively, and evaluating that information to prioritize or rank individual wetlands or wetland types for conservation, management, restoration, or development. Over a longer period, it requires keeping inventories of known wetlands and monitoring a representative sample of the wetlands to determine changes due to both natural and human factors. Such a valuation process is used to educate decision-makers such as governments of the importance of particular wetlands within their jurisdiction.\n\nRapid assessment methods are used to score, rank, rate, or categorize various functions, ecosystem services, species, communities, levels of disturbance, and/or ecological health of a wetland or group of wetlands. This is often done to prioritize particular wetlands for conservation (avoidance) or to determine the degree to which loss or alteration of wetland functions should be compensated, such as by restoring degraded wetlands elsewhere or providing additional protections to existing wetlands. Rapid assessment methods are also applied before and after a wetland has been restored or altered, to help monitor or predict the effects of those actions on various wetland functions and the services they provide. Assessments are typically considered to be \"rapid\" when they require only a single visit to the wetland lasting less than one day, which in some cases may include interpretation of aerial imagery and GIS analyses of existing spatial data, but not detailed post-visit laboratory analyses of water or biological samples. Due to time and cost constraints, the levels of various wetland functions or other attributes are usually not measured directly but rather are estimated relative to other assessed wetlands in a region, using observation-based variables, sometimes called \"indicators\", that are hypothesized or known to predict performance of the specified functions or attributes.\n\nTo achieve consistency among persons doing the assessment, rapid methods present indicator variables as questions or checklists on standardized data forms, and most methods standardize the scoring or rating procedure that is used to combine question responses into estimates of the levels of specified functions relative to the levels estimated in other wetlands (\"calibration sites\") assessed previously in a region. Rapid assessment methods, partly because they often use dozens of indicators pertaining to conditions surrounding a wetland as well as within the wetland itself, aim to provide estimates of wetland functions and services that are more accurate and repeatable than simply describing a wetland's class type. A need for wetland assessments to be rapid arises mostly when government agencies set deadlines for decisions affecting a wetland, or when the number of wetlands needing information on their functions or condition is large.\n\nIn North America and a few other countries, standardized rapid assessment methods for wetlands have a long history, having been developed, calibrated, tested, and applied to varying degrees in several different regions and wetland types since the 1970s. However, few rapid assessment methods have been fully validated. Done correctly, validation is a very expensive endeavor that involves comparing rankings of a series of wetlands based on results from rapid assessment methods with rankings based on less rapid and considerably more costly, multi-visit, detailed measurements of levels of the same functions or other attributes in the same series of wetlands.\n\nAlthough developing a global inventory of wetlands has proven to be a large and difficult undertaking, many efforts at more local scales have been successful. Current efforts are based on available data, but both classification and spatial resolution have sometimes proven to be inadequate for regional or site-specific environmental management decision-making. It is difficult to identify small, long, and narrow wetlands within the landscape. Many of today's remote sensing satellites do not have sufficient spatial and spectral resolution to monitor wetland conditions, although multispectral IKONOS and QuickBird data may offer improved spatial resolutions once it is 4 m or higher. Majority of the pixels are just mixtures of several plant species or vegetation types and are difficult to isolate which translates into an inability to classify the vegetation that defines the wetland. Improved remote sensing information, coupled with good knowledge domain on wetlands will facilitate expanded efforts in wetland monitoring and mapping. This will also be extremely important because we expect to see major shifts in species composition due to both anthropogenic land use and natural changes in the environment caused by climate change.\n\nA wetland needs to be monitored over time to assess whether it is functioning at an ecologically sustainable level or whether it is becoming degraded. Degraded wetlands will suffer a loss in water quality, loss of sensitive species, and aberrant functioning of soil geochemical processes.\n\nMapping\n\nPractically, many natural wetlands are difficult to monitor from the ground as they are quite often are difficult to access and may require exposure to dangerous plants and animals as well as diseases borne by insects or other invertebrates..Therefore, mapping using aerial imagery is one effective tool to monitor a wetland, especially a large wetland, and can also be used to monitor the status of numerous wetlands throughout a watershed or region. Many remote sensing methods can be used to map wetlands. Remote-sensing technology permits the acquisition of timely digital data on a repetitive basis. This repeat coverage allows wetlands, as well as the adjacent land-cover and land-use types, to be monitored seasonally and/or annually. Using digital data provides a standardized data-collection procedure and an opportunity for data integration within a geographic information system. Traditionally, Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+), and the SPOT 4 and 5 satellite systems have been used for this purpose. More recently, however, multispectral IKONOS and QuickBird data, with spatial resolutions of and , respectively, have been shown to be excellent sources of data when mapping and monitoring smaller wetland habitats and vegetation communities.\n\nFor example, Detroit Lakes Wetland Management District assessed area wetlands in Michigan, USA, using remote sensing. Through using this technology, satellite images were taken over a large geographic area and extended period. In addition, using this technique was less costly and time-consuming compared to the older method using visual interpretation of aerial photographs. In comparison, most aerial photographs also require experienced interpreters to extract information based on structure and texture while the interpretation of remote sensing data only requires analysis of one characteristic (spectral).\n\nHowever, there are a number of limitations associated with this type of image acquisition. Analysis of wetlands has proved difficult because to obtain the data it is often linked to other purposes such as the analysis of land cover or land use.\n\nFurther improvements\n\nMethods to develop a classification system for specific biota of interest could assist with technological advances that will allow for identification at a very high accuracy rate. The issue of the cost and expertise involved in remote sensing technology is still a factor hindering further advancements in image acquisition and data processing. Future improvements in current wetland vegetation mapping could include the use of more recent and better geospatial data when it is available.\n\nRestoration and restoration ecologists intend to return wetlands to their natural trajectory by aiding directly with the natural processes of the ecosystem. These direct methods vary with respect to the degree of physical manipulation of the natural environment and each are associated with different levels of restoration. Restoration is needed after disturbance or perturbation of a wetland. Disturbances include exogenous factors such as flooding or drought. Other external damage may be anthropogenic disturbance caused by clear-cut harvesting of trees, oil and gas extraction, poorly defined infrastructure installation, over grazing of livestock, ill-considered recreational activities, alteration of wetlands including dredging, draining, and filling, and other negative human impacts. Disturbance puts different levels of stress on an environment depending on the type and duration of disturbance. There is no one way to restore a wetland and the level of restoration required will be based on the level of disturbance although, each method of restoration does require preparation and administration.\n\n\n\n\n\n\n\n\nThe following list is that used within Australia to classify wetland by type:\n\nOther classification systems for wetlands exist. In the US, the best known are the Cowardin classification system and the hydrogeomorphic (HGM) classification system .\n\nVariations of names for wetland systems:\n\n\n\n\n"}
