{"id": "55910792", "url": "https://en.wikipedia.org/wiki?curid=55910792", "title": "2017 Sri Lankan fuel crisis", "text": "2017 Sri Lankan fuel crisis\n\nSri Lanka, from 3 November 2017 until 11 November 2017, faced a fuel shortage when a substandard fuel shipment was rejected which caused a depletion in reservations due to the general public fearing of a prolonged duration of crisis. However, there was only a shortage of petrol not diesel or kerosene.\n\nThe Sri Lanka fuel crisis began on 3 November 2017 when rumours started spreading that a fuel shipment belonging to Lanka IOC (Indian Oil Company) was rejected. Later on the rumour was confirmed as legitimate and the reason given was that the fuel in the rejected shipment was not up to standards. Arjuna Ranatunga the Minister of Petroleum Resources Development on the next day addressed the situation to the media. However the Ministry of Petroleum Resources Development announced that there was 10,000 metric tonnes fuel in the reserves to last till 9 November 2017 but the leader of the Ceylon Petroleum Union, Asanka Ranawala said the contrary to this. Due to development of the tense situation the general public started panic buying causing the reserves to deplete faster than expected. However the crisis was brought to a stop after the ship \"Nevaska Lady\" on 11 November 2017 with 40,000 metric tonnes of fuel which was reported as being sufficient for twenty days.\n\nOther than the substandard fuel rejected being the main reason for the crisis there were several other events that worsened the crisis during this time period.\n\nMany steps were taken by the Ministry of Petroleum Resources Development to overcome the problem until any fuel shipments arrived\n\nA cabinet sub committee was appointed by the President of Sri Lanka Maithripala Sirisena in order to investigate the crisis on the 7 November 2017. According to the report submitted by the committee on 17 November 2017 the main reason for the crisis was the failure to maintain proper fuel stocks according to the average use and another reason was the failure to report the dire situation to higher authorities on time causing the whole situation to go out of hand. However, according to the officials the report is inconclusive and the sub committee has also requested recruiting technical officers to get a more detailed report.\n"}
{"id": "45108666", "url": "https://en.wikipedia.org/wiki?curid=45108666", "title": "21st-century globalization impacts on gender inequality in the United States", "text": "21st-century globalization impacts on gender inequality in the United States\n\nGlobalization’s impact on gender inequality in the 21st century in the USA and around the world has surfaced as a contentious issue. While some argue that globalization is beneficial, it is also claimed that not everyone is benefiting from globalization equally. In particular, females often do not benefit to the extent of their male counterparts. Contemporary globalizing forces such as the World Bank and the United Nations have worked to deconstruct the barriers of inequality and existing gender gaps. As a result, this article is focused on the 21st century economic transformation that has emerged through globalization as it has impacted not only global markets, but also, the overall landscape at an individual level. At the same time, there is a need to present the various struggles and existing realities of gender inequality in America’s workforce, which still finds itself on the path towards full equality.\n\nGlobalization has brought increased access to economic opportunities. Most of these opportunities have come as a result of trade openness and the spread of information and communication technologies (ICTs). This has led to an increase in women's access to economic opportunities and in some cases increased their wages relative to men's. More specifically, the World Bank claims, “trade openness and the diffusion of new information and technologies have translated into more jobs and stronger connections to markets for many women”. Increased access to information, primarily through television and the Internet, allows the general American public to learn about social mores in other places, which can change perceptions and promote the establishment of egalitarian attitudes. Instead, egalitarian attitudes are currently hindered by the existing reality of woman making up the majority of the low-wage workforce industry. More specifically, the Government Accountability Office (GAO), in a recent report shows that “in 2010, women constituted 59 percent of the low-wage workforce”.\n\nGlobalizing organizations and institutions such as the United Nations, and the World Bank have worked to promote gender equality. The task has not been easy given the need to undo many institutionalized and systemic influences on gender equality. Thus, the ability to override these forms of oppression stems from spreading awareness. Globalizing institutions have used increased awareness to shed light issues of gender inequality, particularly in the work force. For example, “The Beijing + 5 process provides an opportunity to reflect on the impact of Globalization in determining further actions and initiatives for the full implementation of the Beijing commitments”. Furthermore, the ability to promote awareness is by default facilitated because, for example, in the nonagricultural sector, the total share percentage of women employed is at 48% from a 2012 report. Thus, when the gender binaries of male and female in the U.S. constitute half of the entire workforce respectively, the females that receive unequal treatment have the ability to speak out against the cause with the understanding that a high proportion of the public backs them.\n\nPublic opinion in the USA on Globalization and its impacts on gender inequality has been shaped by denial of basic human rights in the workforce abroad. The World Bank states that “Public opinion in developed countries generally connects globalization with sweatshops where child labor is common and workers are denied the most basic rights”. Similarly, the issue of sweatshops is acute in the informal sector. For example, the arrangements such as sub-contracting and outsourcing have become an integral part of the contemporary market economy. Thus, issues of unfair pay and poor working environments are commonly interpreted as issues abroad. However, there remains high contestation against transnationals that allow these issues to happen in the first place through the act of shifting their manufacturing bases away from the U.S. and into other countries with lenient regulations and restrictions.\n\nGlobalization's impact on gender inequality has also had its fair share of benefits in the U.S. to the extent that the “demand for female workers in the export and ICT-enabled sectors has increased, and as women have filled these new jobs”. The U.S. has been on the forefront of the technological advancements around the world. As a result, the ICT industry impacts and reflects both a benefit, and a hindrance to gender inequality. This is mostly due to the reality that forces of globalization are real and their influences are felt everywhere. More specifically, the Inter-agency network on women and gender equality by the United Nations claims, “Equitable access to information and Communication technologies can be an important tool for empowering women.” ICT can empower women through increasing their activity, as well as help reduce gender inequalities by “reducing women’s and girls’ time demands, increasing their access to income-generating activities, and allowing them to benefit from technological advances”. However, it is also argued that ICT sectors have not necessarily helped women. Instead, “women are under-represented in ICT decision making structures including policy and regulatory institutions”. Thus, the workforce continues to fluctuate between becoming increasingly viewed as supportive of gender equality as well as the belief that it has promoted precisely the opposite.\n\nWhile there is a strong concentration around the role of women, they are the ones that mostly suffer from gender inequality. However, there are also masculine organizations that also promote the need to fix the issue of gender inequality. There is an existing belief that “Men and boys are thus, in several ways, gatekeepers for gender equality and should be targeted and included in efforts to promote gender equality so as to ensure men’s support and partnership”. It is only through a collective effort that gender equality can flourish. However, it should be noted that the reality of gender inequality in the U.S. is one where men also “face vulnerabilities because of gender inequality, such as experiencing stress from being regarded, and regarding themselves, as the main breadwinner”. Moreover, failing to get a job, or losing their job and the inability to earn enough money can also lead to an erosion of their self-worth as men.\n\nThere are various studies available that depict globalization as a hindrance toward gender inequality. For example, shortly before the transition into the 21st century, “recent studies such as UNCTAD’s Trade and Development Report (1997) and the UNDP’s Human Development Reports (1997 and 1999) suggest that economic growth fostered by recent liberalization policies can be accompanied by increased inequality and a decline in living standards\". However, on the other hand, positive effects may include “increased employment opportunities for women in non-traditional sectors” thus enabling them to earn and control income\" \n\nWhile the USA serves as one of the key players in the international system that is not to say that it is immune to the gender pay gaps that exist around the world. In fact, the great recession and financial crisis of 2007-2008 demonstrates the reality of these inequalities given that men and women were affected differently. Statistically, in the U.S. alone, men lost more jobs than women in the recession. But at the same time, men also experienced a steadier recovery. “One in five women are working part time because they cannot find full time work while at the start of the recession less than one in ten women were doing so”. Despite these developments, the overall unemployment rate for women is lower than men’s and they are also less likely to be among the long-term unemployed.\n\n21st century globalization and its impact on gender equality remains highly influenced by the past. The World Bank openly admitted to the influence of the past by claiming, “even among those who have benefited from higher access to economic opportunities, old patterns of employment segregation by gender can emerge”. Furthermore, the ability to undermine these old patterns is by continually raising awareness. The ability to raise awareness and counter old patterns is prominent in the U.S. and visible through globalizing organization-sponsored groups. One important group that has worked to raise awareness is known as WomenWatch, a United Nations inter-agency website on gender equality reducing women’s and girls’ time demands, increasing their access to income-generating activities, and allowing them to benefit from technological advances”. Their mission is essentially to shed light to the various ways gender equality can become a reality if everyone’s concerns converge and coalesce.\n\nGlobalization on its own cannot end gender inequality. There should be an understanding that the Globalization process as a whole offers both opportunities, as well as challenges for human development. Consequently, a collective effort implies an understanding that “the specific gender-related needs of men are overlooked, as well as the important role that men can play in achieving gender equality and empowering women”. It is precisely through understanding the dynamics of gender inequality while incorporating both males and females into the playing field that equality can ultimately be achieved.\n"}
{"id": "1035587", "url": "https://en.wikipedia.org/wiki?curid=1035587", "title": "Anahim Volcanic Belt", "text": "Anahim Volcanic Belt\n\nThe Anahim Volcanic Belt is a long volcanic belt, stretching from just north of Vancouver Island to near Quesnel, British Columbia, Canada. The Anahim Volcanic Belt has had three main magmatic episodes: 15–13 Ma, 9–6 Ma, and 3–1 Ma. The volcanoes generally become younger eastward at a rate of to a year. The Nazko Cone, which last erupted only 7,200 years ago, is the youngest Anahim volcano. These volcanoes are thought to have formed as a result of the North American Plate sliding westward over a long-lived center of upwelling magma called the Anahim hotspot. The hotspot is thought to be similar to the one feeding the Hawaiian Islands.\n\nFuture volcanism is most likely in the form of basaltic cinder cones, but eruptions of less mafic magma, typical of the eastern portions of the belt, cannot be ruled out. A series of earthquakes began October 9, 2007 in the vicinity of Nazko Cone which was related to intense subterranean volcanic activity in the area.\n\nThe volcanic belt is defined by 37 Quaternary basalt centers and three large shield volcanoes called the Rainbow Range, Ilgachuz Range and the Itcha Range. These three large volcanoes have built up dome-like piles of lava and fragmental rocks to a height of at Tsitsutl Peak in the Rainbow Range, at Far Mountain in the Ilgachuz Range, and at Mount Downton in the Itcha Range. The Rainbow Range is a low dome-like cone about diameter, with Anahim Peak an obsidian plug on its north-east flank. The Ilgachuz Range is or more in diameter, and the Itcha Range is wide and about long. All have been dissected by late Tertiary, pre-Pleistocene stream erosion.\n\nMajor volcanoes of the Anahim Volcanic Belt include:\n\n\n"}
{"id": "357308", "url": "https://en.wikipedia.org/wiki?curid=357308", "title": "Antagonistic contradiction", "text": "Antagonistic contradiction\n\nAntagonistic contradiction (Chinese language: 矛盾; Pinyin: Máo dùn) is the impossibility of compromise between different social classes. The term is most often applied in Maoist theory, which holds that differences between the two primary classes, the working class/proletariat and the bourgeoisie are so great that there is no way to bring about a reconciliation of their views. Because the groups involved have diametrically opposed concerns, their objectives are so dissimilar and contradictory that no mutually acceptable resolution can be found. Nonantagonistic contradictions may be resolved through mere debate, but antagonistic contradictions can only be resolved through struggle.\n\nThe term is usually attributed to Vladimir Lenin, although he may never have actually used the term in any of his written works.\n\nIn Maoism, the antagonistic contradiction was usually that between the peasantry and the landowning class. Mao Zedong expressed his views on the policy in his famous February 1957 speech \"On the Correct Handling of Contradictions Among the People.\"\n\n\n\n"}
{"id": "52343902", "url": "https://en.wikipedia.org/wiki?curid=52343902", "title": "Bangladesh Haor and Wetland Development Board", "text": "Bangladesh Haor and Wetland Development Board\n\nBangladesh Haor and Wetland Development Board or is a government board that is responsible for the management and regulation of Wetlands and Haors in Bangladesh and is located in Dhaka, Bangladesh.\n\nThe Government of Bangladesh passed an ordinance which formed the Haor Development Board on 22 February 1977. On 11 September 2000 it was reconstituted to form the Bangladesh Haor and Wetland Development Board by presidential order.\n"}
{"id": "25436988", "url": "https://en.wikipedia.org/wiki?curid=25436988", "title": "Barkhausen–Kurz tube", "text": "Barkhausen–Kurz tube\n\nThe Barkhausen–Kurz tube, also called the retarding-field tube, reflex triode, B–K oscillator, and Barkhausen oscillator was a high frequency vacuum tube electronic oscillator invented in 1920 by German physicists Heinrich Georg Barkhausen and Karl Kurz. It was the first oscillator that could produce radio power in the ultra-high frequency (UHF) portion of the radio spectrum, above 300 MHz. It was also the first oscillator to exploit electron transit time effects. It was used as a source of high frequency radio waves in research laboratories, and in a few UHF radio transmitters through World War 2. Its output power was low which limited its applications. However it inspired research that led to other more successful transit time tubes such as the klystron, which made the low power Barkhausen-Kurz tube obsolete.\n\nAfter the development by Lee de Forest of the triode vacuum tube in 1906, it was realized that the upper frequency at which the device could be used was limited by the spacing between internal components. Even with the smallest of spacing, the frequency limit of early triodes was in the low megahertz range. A technique called velocity modulation was theorized to overcome this limitation.\n\nIn 1920, Heinrich Barkhausen and Karl Kurz at the Technische Hochschule in Dresden, Germany used the velocity modulation theory in developing a \"retarded-field\" triode. They found it could operate at frequencies into the UHF region, the first vacuum tube to do so. Although severely limited in output power, the Barkhausen–Kurz tube was quickly adopted world-wide for UHF research. This device is also called the retarded-field and positive-grid oscillator. Versions of the Barkhausen oscillator were used in some of the first applications of microwaves, such as the first microwave relay system, a 1.7 GHz link across the English Channel in 1931, and in early radar systems used in World War 2. \n\nThe success of the Barkhausen-Kurz tube in generating power at microwave frequencies inspired research to develop similar tubes which did not have its limitations, resulting in the invention of other tubes which were known as \"reflex oscillators\". The best known result of this research was the klystron tube invented 1937 by Russell and Sigurd Varian. Sources like the klystron and magnetron replaced the B-K tube around World War 2 and it became obsolete.\n\nThe Barkhausen–Kurz tube was a triode operated with the grid (a thin mesh of wires) at a positive potential relative to both the cathode (or filament) and the anode (or plate). The negative electrons emitted from the cathode are accelerated toward the positive grid. Most pass between the grid wires and approach the anode. The low potential anode repels the electrons and they reverse direction before they hit the plate. They are then accelerated back toward the grid which is more positive than the anode plate, again pass through the grid wires, and are then repelled by the negative cathode, their direction reversing just before reaching the surface. The electrons continue oscillating back and forth through the grid until one by one they strike the grid wires.\n\nThe oscillating potential induced on the grid by the motion of the electrons excites oscillations in a tank circuit attached to the grid, usually consisting of a quarter wavelength of parallel transmission line shorted at the end, called a resonant stub. In turn the oscillating voltage on the tank circuit causes the electrons to \"bunch\" into a cloud of electrons moving back and forth through the grid in phase. \nThis oscillatory motion of the electron cloud continues, with some electrons lost to grid on each pass constituting the output current. The lost electrons are replenished by new electrons emitted by the cathode. The frequency of oscillation depends on the spacing and potentials of the electrodes, and can be changed to a limited extent by altering the electrode voltages. The space charge density is low and so unlike in a conventional triode oscillator the AC plate and grid current is small, so the output power of the B-K oscillator is low.\n\n"}
{"id": "2995449", "url": "https://en.wikipedia.org/wiki?curid=2995449", "title": "Bell jar", "text": "Bell jar\n\nA bell jar is a glass jar, similar in shape to a bell, and can be manufactured from a variety of materials (ranging from glass to different types of metals). Bell jars are often used in laboratories to form and contain a vacuum; they may also serve as display cases or transparent dust covers. It is a common science apparatus used in experiments.\n\nA vacuum bell jar is placed on a base which is vented to a hose fitting, that can be connected via a hose to a vacuum pump. A vacuum is formed by pumping the air out of the bell jar.\n\nThe lower edge of a vacuum bell jar forms a flange of heavy glass, ground smooth on the bottom for better contact. The base of the jar is equally heavy and flattened. A smear of vacuum grease is usually applied between them. As the vacuum forms inside, it creates a considerable compression force, so there is no need to clamp the seal. For this reason, a bell jar cannot be used to contain pressures \"above\" atmospheric, only below.\n\nBell jars are generally used for classroom demonstrations or by hobbyists, when only a relatively low-quality vacuum is required. Cutting-edge research done at ultra high vacuum requires a more sophisticated vacuum chamber. However, several tests may be completed in a bell jar chamber having an effective pump and low leak rate.\n\nAn example of a classroom science experiment involving a bell jar is to place a ringing alarm clock under the bell jar. As the air is pumped out of the sealed bell jar, the noise of the alarm clock fades, thus demonstrating that the propagation of sound is mediated by the air. In the absence of their medium, the sound waves cannot travel.\n\nA vacuum produces a pressure difference of one atmosphere, approximately 14 psi, over the surface of the glass. The energy contained within an implosion is defined by the pressure difference and the volume evacuated. Flask volumes can change by orders of magnitude between experiments. Whenever working with liter sized or larger flasks, chemists should consider using a safety screen or the sash of a flow hood to protect them from shards of glass, should an implosion occur. Glassware can also be wrapped with spirals of tape to catch shards, or wrapped with webbed mesh more commonly seen on scuba cylinders.\n\nGlass under vacuum becomes more sensitive to chips and scratches in its surface, as these form strain accumulation points, so older glass is best avoided if possible. Impacts to the glass and thermally induced stresses are also concerns under vacuum. Round bottom flasks more effectively spread the stress across their surfaces, and are therefore safer when working under vacuum.\n\nPurely decorative bell jars were commonly used in the Victorian period to display and serve as transparent dust covers for clocks and taxidermy. Decorative bell jars were made of thin glass, with more care being taken regarding their optical clarity, and they did not have a thickened base flange. For this reason, they are not suitable for vacuum use and would usually fail if pumped down.\n\nSimilar glass domes were used as cheese domes or garden cloches.\n\n"}
{"id": "1231522", "url": "https://en.wikipedia.org/wiki?curid=1231522", "title": "Biological immortality", "text": "Biological immortality\n\nBiological immortality (sometimes referred to \"bio-indefinite\" mortality) is a state in which the rate of mortality from senescence is stable or decreasing, thus decoupling it from chronological age. Various unicellular and multicellular species, including some vertebrates, achieve this state either throughout their existence or after living long enough. A biologically immortal living being can still die from means other than senescence, such as through injury or disease.\n\nThis definition of immortality has been challenged in the \"Handbook of the Biology of Aging\", because the increase in rate of mortality as a function of chronological age may be negligible at extremely old ages, an idea referred to as the late-life mortality plateau. The rate of mortality may cease to increase in old age, but in most cases that rate is typically very high. As a hypothetical example, there is only a 50% chance of a human surviving another year at age 110 or greater.\n\nThe term is also used by biologists to describe cells that are not subject to the Hayflick limit on how many times they can divide.\n\nBiologists chose the word \"immortal\" to designate cells that are not subject to the Hayflick limit, the point at which cells can no longer divide due to DNA damage or shortened telomeres. Prior to Leonard Hayflick's theory, Alexis Carrel hypothesized that all normal somatic cells were immortal.\n\nThe term \"immortalization\" was first applied to cancer cells that expressed the telomere-lengthening enzyme telomerase, and thereby avoided apoptosis—i.e. cell death caused by intracellular mechanisms. Among the most commonly used cell lines are HeLa and Jurkat, both of which are immortalized cancer cell lines. HeLa cells originated from a sample of cervical cancer taken from Henrietta Lacks in 1951. These cells have been and still are widely used in biological research such as creation of the polio vaccine, sex hormone steroid research, and cell metabolism. Normal stem cells and germ cells can also be said to be immortal (when humans refer to the cell line).\n\nImmortal cell lines of cancer cells can be created by induction of oncogenes or loss of tumor suppressor genes. One way to induce immortality is through viral-mediated induction of the large T‑antigen, commonly introduced through simian virus 40 (SV-40).\n\nAccording to the Animal Aging and Longevity Database, the list of organisms with negligible aging (along with estimated longevity in the wild) includes:\n\n\nIn 2018, scientists working for Calico, a company owned by Alphabet, published a paper in the journal \"eLife\" which presents possible evidence that Heterocephalus glaber (Naked mole rat) do not face increased mortality risk due to aging.\n\nMany unicellular organisms age: as time passes, they divide more slowly and ultimately die. Asymmetrically dividing bacteria and yeast also age. However, symmetrically dividing bacteria and yeast can be biologically immortal under ideal growing conditions. In these conditions, when a cell splits symmetrically to produce two daughter cells, the process of cell division can restore the cell to a youthful state. However, if the parent asymmetrically buds off a daughter only the daughter is reset to the youthful state—the parent isn't restored and will go on to age and die. In a similar manner stem cells and gametes can be regarded as \"immortal\".\n\nHydras are a genus of the Cnidaria phylum. All cnidarians can regenerate, allowing them to recover from injury and to reproduce asexually. Hydras are simple, freshwater animals possessing radial symmetry and no post-mitotic cells. All hydra cells continually divide. It has been suggested that hydras do not undergo senescence, and, as such, are biologically immortal. In a four-year study, 3 cohorts of hydra did not show an increase in mortality with age. It is possible that these animals live much longer, considering that they reach maturity in 5 to 10 days. However, this does not explain how hydras are consequently able to maintain telomere lengths.\n\n\"Turritopsis dohrnii\", or \"Turritopsis nutricula\", is a small () species of jellyfish that uses transdifferentiation to replenish cells after sexual reproduction. This cycle can repeat indefinitely, potentially rendering it biologically immortal. This organism originated in the Caribbean sea, but has now spread around the world. Similar cases include hydrozoan \"Laodicea undulata\" and scyphozoan \"Aurelia\" sp.1.\n\nResearch suggests that lobsters may not slow down, weaken, or lose fertility with age, and that older lobsters may be more fertile than younger lobsters. This does not however make them immortal in the traditional sense, as they are significantly more likely to die at a shell moult the older they get (as detailed below).\n\nTheir longevity may be due to telomerase, an enzyme that repairs long repetitive sections of DNA sequences at the ends of chromosomes, referred to as telomeres. Telomerase is expressed by most vertebrates during embryonic stages but is generally absent from adult stages of life. However, unlike vertebrates, lobsters express telomerase as adults through most tissue, which has been suggested to be related to their longevity. Contrary to popular belief, lobsters are not immortal. Lobsters grow by moulting which requires a lot of energy, and the larger the shell the more energy is required. Eventually, the lobster will die from exhaustion during a moult. Older lobsters are also known to stop moulting, which means that the shell will eventually become damaged, infected, or fall apart and they die. The European lobster has an average life span of 31 years for males and 54 years for females.\n\nPlanarian flatworms have both sexually and asexually reproducing types. Studies on genus Schmidtea mediterranea suggest these planarians appear to regenerate (i.e. heal) indefinitely, and asexual individuals have an \"apparently limitless [telomere] regenerative capacity fueled by a population of highly proliferative adult stem cells\". \"Both asexual and sexual animals display age-related decline in telomere length; however, asexual animals are able to maintain telomere lengths somatically (i.e. during reproduction by fission or when regeneration is induced by amputation), whereas sexual animals restore telomeres by extension during sexual reproduction or during embryogenesis like other sexual species. Homeostatic telomerase activity observed in both asexual and sexual animals is not sufficient to maintain telomere length, whereas the increased activity in regenerating asexuals is sufficient to renew telomere length... \"\n\nLifespan: For sexually reproducing planaria: \"the lifespan of individual planarian can be as long as 3 years, likely due to the ability of neoblasts to constantly replace aging cells\". Whereas for asexually reproducing planaria: \"individual animals in clonal lines of some planarian species replicating by fission have been maintained for over 15 years\". They do not live forever.\n\nAlthough the premise that biological aging can be halted or reversed by foreseeable technology remains controversial, research into developing possible therapeutic interventions is underway. Among the principal drivers of international collaboration in such research is the SENS Research Foundation, a non-profit organization that advocates a number of what it claims are plausible research pathways that might lead to engineered negligible senescence in humans.\n\nIn 2015, Elizabeth Parrish, CEO of BioViva, treated herself using gene therapy, with the goal of not just halting, but reversing aging. She has since reported feeling more energetic, and no obvious negative side effects have been noticed.\n\nFor several decades, researchers have also pursued various forms of suspended animation as a means by which to indefinitely extend mammalian lifespan. Some scientists have voiced support for the feasibility of the cryopreservation of humans, known as cryonics. Cryonics is predicated on the concept that some people considered clinically dead by today's medicolegal standards are not actually dead according to information-theoretic death and can, in principle, be resuscitated given sufficient technological advances. The goal of current cryonics procedures is tissue vitrification, a technique first used to reversibly cryopreserve a viable whole organ in 2005.\n\nSimilar proposals involving suspended animation include chemical brain preservation. The non-profit Brain Preservation Foundation offers a cash prize valued at over $100,000 for demonstrations of techniques that would allow for high-fidelity, long-term storage of a mammalian brain.\n\nIn 2016, scientists at the Buck Institute for Research on Aging and the Mayo Clinic employed genetic and pharmacological approaches to ablate pro-aging senescent cells, extending healthy lifespan of mice by over 25%. The startup Unity Biotechnology is further developing this strategy in human clinical trials.\n\nIn early 2017, Harvard scientists headed by biologist David Sinclair announced they have tested a metabolic precursor that increases NAD+ levels in mice and have successfully reversed the cellular aging process and can protect the DNA from future damage. \"The old mouse and young mouse cells are indistinguishable\", David was quoted. Human trials are to begin shortly in what the team expect is 6 months at Brigham and Women's Hospital, in Boston.\n\nTo achieve the more limited goal of halting the increase in mortality rate with age, a solution must be found to the fact that any intervention to remove senescent cells that creates competition among cells will increase age-related mortality from cancer.\n\nIn 2012 in Russia, and then in the United States, Israel, and the Netherlands, pro-immortality transhumanist political parties were launched. They aim to provide political support to anti-aging and radical life extension research and technologies and want to ensure the fastest possible—and at the same time, the least disruptive—societal transition to radical life extension, life without aging, and ultimately, immortality. They aim to make it possible to provide access to such technologies to the majority of people alive today.\n\nFuture advances in nanomedicine could give rise to life extension through the repair of many processes thought to be responsible for aging. K. Eric Drexler, one of the founders of nanotechnology, postulated cell repair devices, including ones operating within cells and utilizing as yet hypothetical molecular machines, in his 1986 book Engines of Creation. Raymond Kurzweil, a futurist and transhumanist, stated in his book \"The Singularity Is Near\" that he believes that advanced medical nanorobotics could completely remedy the effects of aging by 2030. According to Richard Feynman, it was his former graduate student and collaborator Albert Hibbs who originally suggested to him (circa 1959) the idea of a \"medical\" use for Feynman's theoretical micromachines (see biological machine). Hibbs suggested that certain repair machines might one day be reduced in size to the point that it would, in theory, be possible to (as Feynman put it) \"swallow the doctor\". The idea was incorporated into Feynman's 1959 essay \"There's Plenty of Room at the Bottom.\"\n\n\n"}
{"id": "5305193", "url": "https://en.wikipedia.org/wiki?curid=5305193", "title": "Brian Payton", "text": "Brian Payton\n\nBrian Payton is an American writer of fiction and nonfiction.\n\nBorn in Los Angeles County in 1966, Payton lived in California, Illinois, Texas, New Mexico, and Alaska before settling in British Columbia at the age of 16. He was educated at the Seminary of Christ the King and the University of Victoria.\n\nPayton’s first novel, \"Hail Mary Corner\" (Beach Holme), is a coming-of-age tale based on his experience living among fellow seminarians and Benedictine monks. His nonfiction writing about adventure, wildlife, and the environment has appeared in \"The New York Times\", \"The Los Angeles Times\", \"The Chicago Tribune\", \"The Boston Globe\", \"Canadian Geographic\".\n\n\"Shadow of the Bear: Travels in Vanishing Wilderness\" is a work of narrative nonfiction, which chronicles a personal search for the eight remaining bear species across continents, cultures, and memory.\n\nPayton's book \"The Ice Passage: A True Story of Ambition, Disaster, and Endurance in the Arctic Wilderness\" (Doubleday Canada), is a narrative nonfiction account of the final voyage of HMS \"Investigator\".\n\nHis latest book, a novel, \"The Wind is Not a River\" is set in Alaska during the Japanese invasion of the Aleutian Islands of Attu and Kiska. The New York Times, in a review posted on January 31, 2014, called the book \"gripping\" and \"meditative.\"\n\nPayton lives with his wife in Vancouver.\n\n\"Hail Mary Corner\" (2001)\n\n\n"}
{"id": "58607878", "url": "https://en.wikipedia.org/wiki?curid=58607878", "title": "Carbon Neutrality Coalition", "text": "Carbon Neutrality Coalition\n\nThe Carbon Neutrality Coalition (CNC) is a group of countries, cities and organisations who have committed to take concrete and ambitious action to achieve the aims of the Paris Agreement.. \n\nThe CNC was founded in 2017 by 16 countries and 32 cities. In December New Zealand Climate Change Minister James Shaw said:\n\nIn September 2018 the Coalition held its first meeting at the UN General Assembly and 4 new countries joined: the UK; Canada; Denmark and Spain.\n\nThe coalition aims to achieve benefits in 3 key areas: \n\nCoalition members agree to\n"}
{"id": "54477337", "url": "https://en.wikipedia.org/wiki?curid=54477337", "title": "Chukou Nature Center", "text": "Chukou Nature Center\n\nThe Chukou Nature Center () is a nature center in Xinfu Village, Fanlu Township, Chiayi County, Taiwan.\n\nThe site of the center was originally the sugar farm of Taiwan Sugar Corporation. It was then later turned into Chukou Nature Center. In 2004, the Chiayi Forest District Office established the Tree Bank and Forest Ecological Park at the center.\n\nThe center is the center providing trees from various rare species. It also features drift-wood storage, eco-waterways and greenhouses.\n\n"}
{"id": "86245", "url": "https://en.wikipedia.org/wiki?curid=86245", "title": "Cocidius", "text": "Cocidius\n\nIn Romano-British religion, Cocidius was a deity worshipped in northern Britain. The Romans equated him with Mars, god of war and hunting, and also with Silvanus, god of forests, groves and wild fields. Like Belatucadros, he was probably worshipped by lower-ranked Roman soldiers as well as by the Britons for whom he was probably a tribal god - a genius loci.\n\nRivet and Smith note that the name may be related to British Celtic \"cocco-\", 'red', suggesting that statues of the god might have been painted red:. the figure discovered in the 1980s in the Otterburn Training Area is known as the Red One.\n\n\"Fanocodi\" was a Roman place-name mentioned in the Ravenna \"Cosmography\" for a location close to the Solway Estuary; the name has been derived from \"Fanum Cocidii\", or temple of Cocidius, and the place identified with Bewcastle. There are dedications to Cocidius around Hadrian's Wall and Cumbria, including the forts at Birdoswald and Bewcastle. Another inscription, at Ebchester, refers to him as \"Cocidius Vernostonus\", Cocidius of the alder tree. A 2000-year-old carving of Cocidius was found in 2006 near Chesters Fort on Hadrian's Wall. This was dubbed the \"little man\" and shows a figure with its arms flung wide and legs braced firmly against the ground. Although the gender is not depicted, the shape and accessories are seemingly male, with a shield in the left hand, a sword in the right, and a scabbard hanging from the belt around his tunic. This is one of at least nine representations known in the Hadrian's Wall corridor, and a further 25 or so inscriptions dedicated to him. Most of these are along the western portion of the Wall, the most spectacular being found at Yardhope, where a figure in bas-relief brandishes spear and shield on a vertical rock-face at the entrance to a small shrine.\n"}
{"id": "14768005", "url": "https://en.wikipedia.org/wiki?curid=14768005", "title": "Conservation psychology", "text": "Conservation psychology\n\nConservation psychology is the scientific study of the reciprocal relationships between humans and the rest of nature, with a particular focus on how to encourage conservation of the natural world. Rather than a specialty area within psychology itself, it is a growing field for scientists, researchers, and practitioners of all disciplines to come together and better understand the earth and what can be done to preserve it. This network seeks to understand why humans hurt or help the environment and what can be done to change such behavior. The term \"conservation psychology\" refers to any fields of psychology that have understandable knowledge about the environment and the effects humans have on the natural world. Conservation psychologists use their abilities in \"greening\" psychology and make society ecologically sustainable. The science of conservation psychology is oriented toward environmental sustainability, which includes concerns like the conservation of resources, conservation of ecosystems, and quality of life issues for humans and other species.\n\nOne common issue is a lack of understanding of the distinction between conservation psychology and the more-established field of environmental psychology, which is the study of transactions between individuals and all their physical settings, including how people change both the built and the natural environments and how those environments change them. Environmental psychology began in the late 1960s (the first formal program with that name was established at the City University of New York in 1968), and is the term most commonly used around the world. Its definition as including human transactions with both the natural and built environments goes back to its beginnings, as exemplified in these quotes from three 1974 textbooks: \"Environmental psychology is the study of the interrelationship between behavior and the built and natural environment\" and \"...the natural environment is studied as both a problem area, with respect to environmental degradation, and as a setting for certain recreational and psychological needs\", and a third that included a chapter entitled The Natural Environment and Behavior.\n\nConservation psychology, proposed more recently in 2003 and mainly identified with a group of US academics with ties to zoos and environmental studies departments, began with a primary focus on the relations between humans and animals. Introduced in ecology, policy, and biology journals, some have suggested that it should be expanded to try to understand why humans feel the need to help or hurt the environment, along with how to promote conservation efforts.\n\nPsychologists from all fields including philosophy, biology, sociology, industrial and organizational, health, and consumer psychology, along with many other subfields like environmental education and conservation biology come together to put their knowledge to practice in educating others to work together and encourage a congruous relationship between humans and the environment around them. These psychologists work together with places such as zoos and aquariums. Zoos and aquariums may seem to only be places of recreation and fun but are actually trying hard to put positive messages out and to educate the public on the homes and needs of the animals that live there. They are trying to find ways to interact and teach the public the consequences of their day to day actions to the animals and the environment rather than simply viewing the animals. Psychologists and sociologists have been visiting workshops and think tanks at the zoos to evaluate if the animals are being viewed and shown to the best of their ability while still giving informative knowledge to the public.\n\nWhat characterizes conservation psychology research is that in addition to descriptive and theoretical analyses, studies will explore how to cause the kinds of changes that lessen the impact of human behavior on the natural environment, and that lead to more sustainable and harmonious relationships. Some of the research being done with respect to conservation is estimating exactly how much land and water resources are being used by each human at this point along with projected future growth. Also important to consider is the partitioning of land for this future growth. Additionally, conservation efforts look at the positive and negative consequences for the biodiversity of plant and animal life after humans have used the land to their advantage. In addition to creating better conceptual models, more applied research is needed to: 1) identify the most promising strategies for fostering ways of caring about nature, 2) find ways to reframe debates and strategically communicate to the existing values that people have, 3) identify the most promising strategies for shifting the societal discourse about human–nature relationships, and 4) measure the success of these applications with respect to the conservation psychology mission. The ultimate success of conservation psychology will be based on whether its research resulted in programs and applications that made a difference with respect to environmental sustainability. We need to be able to measure the effectiveness of the programs in terms of their impact on behavior formation or behavior change, using tools developed by conservation psychologists.\n\nConservation psychology research has broken down the four most important tenets of promoting positive conservation attitudes into \"the four 'I's\". These include: Information, Identity, Institutions, and Incentives. Research has been done in all four categories.\n\nStudies have shown that the way in which crises are presented is a key predictor for how people will react to them. When people hear that they personally can help to alleviate a crisis through their conservation efforts, just by simple actions with their personal energy use, they are more likely to conserve. However, if people are told that the other people around them are overusing energy, it increases selfish behavior and causes people to actually consume more.\n\nTeaching people about the benefits of conservation, including easy ways to help conserve, is an effective way to inform about and promote more environmentally friendly behavior. Additionally, research has shown that making sure people understand more about the boundaries of land they can help preserve actually improves positive attitudes towards conservation. When people know more about local regions they can help protect, they will care more. Knowing more about the regions includes knowing the extent of the biodiversity in that region, and being sure that the ecosystem will remain healthy and protected. Cost analysis is another important factor. People do not want to take risks on valuable lands, which in places like California, could be worth billions.\n\nIn general, people like to fit in and identify with their peer social groups. Studies have shown people identify more intimately with close friends and family, which is why conservation campaigns try to directly address the most people. The \"think of the children\" argument for conservation follows this logic by offering a group everyone can relate to and feel close to. Studies have also shown that this need to fit in among peer social groups can be reinforced positively or negatively: giving positive feedback on energy bills for conserving in their homes encourages people to continue lower energy use. Examples of negative reinforcement include the use of negative press against companies infamous for heavy pollution.\n\nAnother interesting line of research looks at how people identify positively or negatively with certain issues. One relevant idea is the notion of \"consistency attitudes\". Studies have shown that people tend to take a good association they have, and then use this to make positive or negative links with other, related things. For example, if someone thinks it is a good idea to protect old Pacific forests, this will positively form a link to also want to protect smaller forests and even grasslands. This same line of thinking can cause someone who supports the protection of old Pacific forests to start thinking negatively about the creation of more logging roads. Other studies on consistency attitudes have shown that, with one particular issue, people like to align their preferences with each other. This has been shown repeatedly while looking at political ideologies and racial attitudes, and studies have shown that this can also include environmental issues. Finally, other studies have shown that how people identify an ecosystem geographically can affect their concern for it. For instance, when people think of saving the rainforests, they often think of this as a global problem and support it more readily. However, lesser known but still significant local ecosystems remain ignored and unprotected.\n\nAnother approach that has been considered is the use of organized institutions and government as the leaders for promoting conservation. However, these leaders can only be effective if they are trusted. Studies from previous crises where conserving resources was extremely necessary showed that people were more likely to obey energy restrictions and follow certain leaders when they felt they could trust the people directing them. People need to understand that they are being encouraged to act a certain way out of necessity, and that they are not being misled.\n\nIncentivizing conservation through rewards and fines is another approach. Studies have shown that people who identify more with their community need less incentives to conserve than those who do not identify strongly with their surrounding community. For corporations, monetary incentives have been shown to work for companies showing some effort to make their buildings and practices more \"green\". Studies have also shown that doing something as simple as putting a water meter in homes has helped incentivize conservation by letting people track their energy consumption levels. Finally, studies have shown that when giving fines, it is better to start with very small and then raise it for repeated violations. If the fines are too high, the issue becomes too economic, and people start to mistrust the authorities enforcing the fines.\n\nConservation psychology assesses as a whole four different concepts. At the country's first Conservation Psychology conference these four things were discussed. The first is the main original topic of the field, and the other three are topics with a previous history in environmental psychology.\n\nThe first topic being discussed is the connection of humans and animals. The Multi-Institutional Research Project (MIRP) works diligently on finding ways to develop a compassionate stance towards animals in the public eye. Many different questions were assessed to find answers to questions concerning ways to help develop loving attitudes for animals and the earth. With these questions and answers, effective educational and interpretive programs were made that would help review the progress.\n\nThe second concept that was discussed at the conference concerned connections of humans and places. A new language of conservation will be supported if there are abundant opportunities for meaningful interactions with the natural world in both urban and rural settings. Unfortunately, as biodiversity is lost, every generation has fewer chances to experience nature. There were many questions asked concerning how humans in their everyday lives could be persuaded or educated well enough to make them want to join in programs or activities that help maintain biodiversity in their proximity. Local public and private organizations were asked to come together to help find ways to protect and manage local land, plants, and animals. Other discussions came to whether people on an individual or community level would voluntarily choose to become involved in maintaining and protecting their local biodiversity. These plus many other important questions were contemplated. Techniques in marketing are a key tool in helping people connect to their environment. If an identity could be connected from the environment to towns becoming more urbanized, maybe those living there would be more prone to keep it intact.\n\nThe third discussion covered the aspects of producing people who act environmentally friendly. Collectively, any activities that support sustainability, either by reducing harmful behaviors or by adopting helpful ones, can be called conservation behaviors. Achieving more sustainable relationships with nature will basically require that large numbers of people change their reproductive and consumptive behaviors. Any action, small or large, that helps the environment in any way is a good beginning to a future of generations who only practice environmentally friendly behavior. This may seem to be a far-fetched idea but with any help at all in educating those who do not know the repercussions of their actions could help achieve this. Approaches to encouraging a change in behavior were thought about carefully. Many do not want to change their way of life. A more simplistic lifestyle rather than their materialistic, current lives hurt their environment around them rather than help, but could people willingly change? To take public transportation rather than drive a car, recycling, turning off lights when they are not needed, all these things are very simple yet a nuisance to actually follow through with. Would restructuring tax-code help people to want to change their attitudes? Any concept to reach the goal of helping people act ecologically aware was discussed and approached. Some empirical evidence shows that simply \"being the change you want to see in the world\" can influence others to behave in more environmentally friendly ways as well.\n\nThe fourth and final point at the first Conservation Psychology convention was the discussion of the values people have to their environment. Understanding our relationship to the natural world well enough so that we have a language to celebrate and defend that relationship is another research area for conservation psychology. According to the biophilia hypothesis, the human species evolved in the company of other life forms, and we continue to rely physically, emotionally, and intellectually on the quality and richness of our affiliations with natural diversity. A healthy and diverse natural environment is considered an essential condition for human lives of satisfaction and fulfillment. Where did they get these values and are they ingrained to the point they cannot be changed? How can environmentally educated people convey value-based communication to a community, a nation, or even on a global level? National policy for this model is something that is desired but under such a strong political scrutiny this could be very challenging. Advocates for biodiversity and different programs came together to try to find methods of changing Americans' values concerning their environment and different methods to express and measure them.\n\nConservation biology was originally conceptualized as a crisis-oriented discipline, with the goal of providing principles and tools for preserving biodiversity. This is a branch of biology that is concerned with preserving genetic variation in plants and animals. This scientific field evolved to study the complex problems surrounding habitat destruction and species protection. The objectives of conservation biologists are to understand how humans affect biodiversity and to provide potential solutions that benefit both humans and non-human species. It is understood in this field that there are underlying fields of biology that could readily help to have a better understanding and contribute to conservation of biodiversity. Biological knowledge alone is not sufficient to solve conservation problems, and the role of the social sciences in solving these problems has become increasingly important. With the knowledge of conservation biology combined with other fields, much was thought to be gained. Psychology is defined as the scientific study of human thought, feeling, and behavior. Psychology was one of the fields that could take its concepts and apply them to conservation. It was also always understood that in the field of psychology there could be much aid to be given, the field only had to be developed. Psychology can help in providing insight into moral reasoning and moral functioning, which lie in the heart of human–nature relationships. Everyone that is now involved from the field of psychology had knowledge of ways to conceptualize the relationship of humans to their environment. Biology has always been involved in advances of conservation considering biodiversity, and the organisms in it are part of the main field of biology. Psychology has been absent from conservation for some time, but educators and scientists are realizing that with the help of both we can come to a better understanding of humans and their social interactions with their environment and everything in it.\n\n\n\n"}
{"id": "16656146", "url": "https://en.wikipedia.org/wiki?curid=16656146", "title": "Cult of Dionysus", "text": "Cult of Dionysus\n\nThe Cult of Dionysus is strongly associated with satyrs, centaurs, and sileni, and its characteristic symbols are the bull, the serpent, tigers/leopards, the ivy, and the wine. The Dionysia and Lenaia festivals in Athens were dedicated to Dionysus, as well as the Phallic processions. Initiates worshipped him in the Dionysian Mysteries, which were comparable to and linked with the Orphic Mysteries, and may have influenced Gnosticism. Orpheus was said to have invented the Mysteries of Dionysus.\n\nThe Cult of Dionysus traces back to at least Mycenaean Greece, since his name is found on Mycenean Linear B tablets as , \"di-wo-nu-so\". Dionysus is often shown riding a leopard, wearing a leopard skin, or in a chariot drawn by panthers, and may also be recognized by the thyrsus he carries. Besides the grapevine and its wild barren alter-ego, the toxic ivy plant, both sacred to him, the fig was also his symbol. The pinecone that tipped his thyrsus linked him to Cybele.\n\nIntroduced into Rome (c. 200 BC) from the Greek culture of southern Italy or by way of Greek-influenced Etruria, the bacchanalia were held in secret and attended by women only, in the grove of Simila, near the Aventine Hill, on 16 and 17 March. Subsequently, admission to the rites were extended to men and celebrations took place five times a month. The notoriety of these festivals, where many kinds of crimes and political conspiracies were supposed to be planned, led in 186 BC to a decree of the Senate—the so-called \"Senatus consultum de Bacchanalibus\", inscribed on a bronze tablet discovered in Calabria (1640), now at Vienna—by which the Bacchanalia were prohibited throughout all Italy except in certain special cases which must be approved specifically by the Senate. In spite of the severe punishment inflicted on those found in violation of this decree, the Bacchanalia were not stamped out, at any rate in the south of Italy, for a very long time.\n\nDionysus is equated with both Bacchus and Liber (also \"Liber Pater\"). Liber (\"the free one\") was a god of fertility, wine, and growth, married to Libera. His festival was the Liberalia, celebrated on 17 March, but in some myths the festival was also held on 5 March.\n\nDionysus sometimes has the epithet Acratophorus, by which he was designated as the giver of unmixed wine, and worshipped at Phigaleia in Arcadia. In Sicyon he was worshiped by the name Acroreites. As Bacchus, he carried the Latin epithet Adoneus, \"Ruler\". Aegobolus, \"goat killer\", was the name under which he was worshiped at Potniae in Boeotia. As Aesymnetes (\"ruler\" or \"lord\") he was worshipped at Aroë and Patrae in Achaea. Another epithet was Bromios, \"the thunderer\" or \"he of the loud shout\". As Dendrites, \"he of the trees\", he is a powerful fertility god. Dithyrambos is sometimes used to refer to him or to solemn songs sung to him at festivals; the name refers to his premature birth. Eleutherios (\"the liberator\") was an epithet for both Dionysus and Eros. Other forms of the god as that of fertility include the epithet in Samos and Lesbos Enorches (\"with balls\" or perhaps \"in the testicles\" in reference to Zeus' sewing the babe Dionysus into his thigh, i.e., his testicles). Even Augustine in \"City of God\" 6.9 credits Dionysus with being responsible for sexual relief, saying that he \"liberates\" men from semen during intercourse. Evius is an epithet of his used prominently in Euripides' play, \"The Bacchae\". Iacchus (Greek: ), possibly an epithet of Dionysus, is associated with the Eleusinian Mysteries; in Eleusis, he is known as a son of Zeus and Demeter. The name \"Iacchus\" may come from \"iacchus\", a hymn sung in honor of him. With the epithet Liknites (\"he of the winnowing fan\") he is a fertility god connected with the mystery religions. A winnowing fan was similar to a shovel and was used to separate the chaff from the grain. In addition, Dionysus is known as Lyaeus (\"he who unties\") as a god of relaxation and freedom from worry, and as Oeneus he is the god of the wine press.\n\nIn the Greek pantheon, Dionysus (along with Zeus) absorbs the role of Sabazios, a Phrygian deity. In the Roman pantheon, Sabazius became an alternate name for Bacchus.\n\n\n"}
{"id": "41864581", "url": "https://en.wikipedia.org/wiki?curid=41864581", "title": "Deb Vanasse", "text": "Deb Vanasse\n\nDeb Vanasse (born September 12, 1957) is an American writer of more than a dozen books, many of which are set in Alaska. Her children's books include six picture books and two young adult novels. She and young-adult novelist Gail Giles are the co-authors of \"No Returns\", Book One in a planned series, the Battleband Saga. Her books for adults include \"Cold Spell\" and a forthcoming biography of the Klondike gold rush figure Kate Carmack. She has also authored three travel guides on Alaska, one under a pseudonym, and she has edited a collection of historic photographs.\n\nVanasse was born in St. Paul, Minnesota. Her maiden name is Debra Lynn Lehmann; her brother is the writer Chris Lehmann. She lived in Ann Arbor, Michigan; Galesburg, Illinois; and Madison, Wisconsin before moving to Iowa, where she graduated from Davenport West High School. She attended Washington University in St. Louis and graduated with a Bachelor in Science from Bemidji State University in Minnesota and a Masters in the Humanities from California State University Dominguez Hills.\n\nVanasse's debut novel for young adults, \"A Distant Enemy\", was a Junior Literary Guild selection and is featured in Best Books for Young Teen Readers, Grades 7 to 10, as was her second novel \"Out of the Wilderness\". Her picture book titles include \"Under Alaska's Midnight Sun\" (illustrated by Jeremiah Tramell); \"Alaska Animal Babies\" (photographs by Gavriel Jecan); \"Totem Tale\" (illustrated by Erik Brooks); and \"Amazing Alaska\" (illustrated by Karen E. Lewis). Set in a Yup'ik village, there is also a Yup'ik language edition of \"Lucy's Dance\", illustrated by Nancy Slagle. \"Black Wolf of the Glacier\", also illustrated by Nancy Slagle, is based on the true story of Romeo, a well-known wolf that lived near Mendenhall Glacier in Juneau, Alaska. \"No Returns\", Book One of the Battleband Saga, is Vanasse’s first co-authored novel with Gail Giles. \"Cold Spell\", her first work of literary fiction for adults, is part of the University of Alaska Press Alaska Literary Series.\nVanasse and another writer, Andromeda Romano-Lax, founded the 49 Alaska Writing Center. She lives on Hiland Mountain in Eagle River, Alaska, with her husband and dog.\n\n"}
{"id": "29155096", "url": "https://en.wikipedia.org/wiki?curid=29155096", "title": "Earth Learning Idea", "text": "Earth Learning Idea\n\nEarth Learning Idea (ELI) provides free Earth-related teaching ideas, designed to be practical science and geography resources for secondary and primary teachers and teacher-trainers and trainees across the world. It is run on a voluntary basis by three teachers from the Earth Science Education Unit (ESEU).\n\nEarth Learning Idea was set up in May 2007, for the International Year of Planet Earth, with the intention of reaching as many children throughout the world as possible, particularly those who suffer from lack of resources and from lack of thought-provoking teaching. The aim is to foster a better knowledge of the natural world and how it works, encouraging the joy of knowledge about the Earth in those who may not otherwise have the opportunity to receive it.\n\nEarth Learning Ideas enhance learning by being fun to carry out and so enjoyable for pupils and teachers. All ELIs are directed at teachers to encourage maximum pupil participation. One of the main aims is to encourage interactive teaching and the development of thinking and investigational skills in pupils. It is a global effort offering unique teaching resources. All activities are free to download in pdf format and all are accompanied by ´back-up´ notes for teachers.\n\nThe activities range widely from ´Rock cycle in wax´, ´Craters on the Moon´ to ´Quakeshake´, an investigation into why some buildings survive in an earthquake and others do not. Other popular activities are ´Trapped! Why can´t oil and gas escape from their underground prison?´ and ´How to weigh a dinosaur´. ELIs are popular in schools especially when earthquakes, volcanoes or tsunamis have been in the news. A rich collection of exciting and imaginative activities covering a wide range of Earth-related topics can be found on the website.\n\nEach week an activity is posted on the ELI blog. New activities are publicised here and comments and suggestions are encouraged. The suggestions are incorporated into ´Extension´ ideas for the activities.\n\nAt the end of March 2017 more than 3,000,000 activities in PDF format have been downloaded worldwide. \n\nEarth Learning Idea activities are written on a voluntary basis and, with the exception of Norwegian, they have been translated voluntarily too. The Norwegian team received a small grant. ELI activities are now available in the following languages:-\n\n"}
{"id": "39204523", "url": "https://en.wikipedia.org/wiki?curid=39204523", "title": "Energetically modified cement", "text": "Energetically modified cement\n\nEnergetically modified cements (EMC) are a class of cementitious materials made from pozzolans (e.g. fly ash, volcanic ash, pozzolana), silica sand, blast furnace slag, or Portland cement (or blends of these ingredients).\n\nThe term \"energetically modified cement\" (abbreviated as \"EMC\" or \"EMC cement\") refers to a class of cementitious materials which have been produced using a special activation process. This process is entirely mechanical, as opposed to thermal, and is carried out by finely grinding the materials to increase binding capacity.\n\nThere are several types of energetically modified cements, depending on the raw materials used; all contain some proportion of conventional Portland cement, which may itself undergo EMC Activation, and many contain alternative (supplemental) cementitious materials. EMCs can be produced with less energy and carbon dioxide production than traditional cements.\n\nEach type of energetically modified cement has its own performance characteristics, including mechanical load. The most frequently used EMCs are made from fly ash and natural pozzolans; these are relatively abundant materials, and the performance characteristics are relatively close to those of Portland cement while providing energy and carbon dioxide savings. EMC products have been extensively tested by independent labs.\n\nThe term \"energetically modified cement\" was first used in Sweden, where the EMC Activation process was developed in 1992 by Vladimir Ronin at Luleå University of Technology (LTU). The term was introduced in a paper by Ronin et al. in 1993. The process was refined by Ronin and others, including Lennart Elfgren (now Professor Emeritus of LTU). Continuing academic work and research \"self-healing\" properties of energetically modified cements is ongoing at LTU.\n\nAt the 45th World Exhibition of Invention, Research and Innovation, held in 1996 in Brussels, Belgium, EMC Activation was awarded a Gold Medal with mention by EUREKA, the European inter-governmental (research and development) organisation.\n\nThe research work connected with EMCs has received awards from the \"Elsa ō Sven Thysells stiftelse för konstruktionsteknisk forskning\" (Elsa & Sven Thysell Foundation for Construction Engineering Research) of Sweden.\n\nThrough the use of pozzolans in concrete, porous (reactive) Portlandite can be transformed into hard and impermeable (relatively non-reactive) compounds, rather than the porous and soft relatively reactive calcium carbonate produced using ordinary cement. Many of the end products of pozzolanic chemistry exhibit a hardness greater than 7.0 on the Mohs scale.\n\nEMC Activation is a process which increases a pozzolan's chemical affinity for pozzolanic reactions. This is leads to faster and greater strength development of the resulting concrete, at higher replacement ratios, than untreated pozzolans. These highly reactive pozzolans can yield further stabilisation benefits upon the pozzolanic reaction-pathways.\n\nIn concrete (including concretes with EMCs), Portland cement combines with water to produce a stone-like material through a complex series of chemical reactions, the full mechanics of which are still not fully understood. That chemical process, called mineral hydration, forms two cementing compounds in the concrete: calcium silicate hydrate (C-S-H) and calcium hydroxide (Ca(OH)). This reaction can be noted in three ways, as follows:\n\n</chem>\n\nThe underlying hydration reaction forms two products:\n\n\nPortlandite makes up about 25% of concrete made with Portland cement without pozzolanic cementitious materials. In this type of concrete, carbon dioxide is slowly absorbed to convert the Portlandite into insoluble calcium carbonate (CaCO), in a process called carbonatation:\n\nIn mineral form, calcium carbonate can exhibit a wide range of hardness depending on how it is formed. At its softest, calcium carbonate can form in concrete as chalk (of hardness 1.0 on Mohs scale). Like Portlandite, calcium carbonate in mineral form can also be porous, permeable and with a poor resistance to acid attack, which causes it to release carbon dioxide.\n\nPozzolanic concretes, including EMCs, however, continue to consume the soft and porous Portlandite as the hydration process continues, turning it into additional hardened concrete as calcium silicate hydrate (C-S-H) rather than calcium carbonate. This results in a denser, less permeable and more durable concrete. This reaction is an acid-base reaction between Portlandite and silicic acid (HSiO) that may be represented as follows:\n\nFurther, many pozzolans contain aluminiate (Al(OH)) that will react with Portlandite and water to form:\nPozzolanic cement chemistry (along with high-aluminiate cement chemistry) is complex and per se is not constrained by the foregoing pathways. For example, strätlingite can be formed in a number of ways, including per the following equation which can add to a concrete's strength:\n\nThe role of pozzolans in a concrete's chemistry is not fully understood. For example, strätlingite is metastable, which in a high temperature and water-content environment (that can be generated during the early curing stages of concrete) may of itself yield stable calcium aluminium garnet (see first bullet point above). This can be represented per the following equation:\n\nPer the first bullet point, although the inclusion of calcium aluminium garnet per se is not problematic, if it is instead produced by foregoing pathway, then micro-cracking and strength-loss can occur in the concrete. However, adding high-reactivity pozzolans into the concrete mix prevents such a conversion reaction. In sum, whereas pozzolans provide a number of chemical pathways to form hardened materials, \"high-reactivity\" pozzolans such as blast furnace slag (GGBFS) can also stabilise certain pathways. In this context, EMCs made from fly ash have been demonstrated to produce concretes that meet the same characteristics as concretes comprising \"120 Slag\" (i.e., GGBFS) according to U.S. standard ASTM C989.\n\nPortlandite, when exposed to low temperatures, moist conditions and condensation, can react with sulphate ions to cause efflorescence; pozzolanic chemistry reduces the amount of Portlandite available, to reduce efflorescence.\n\nNatural pozzolanic reactions can cause mortars and concretes containing these materials to \"self-heal\". The EMC Activation process can at times increase the likelihood of the occurrence of these pozzolanic reactions. The same tendency been noted and studied in the various supporting structures of Hagia Sophia built for the Byzantine emperor Justinian (now, Istanbul, Turkey). There, in common with most Roman cements, mortars comprising high amounts of pozzolana were used — in order to give what was thought to be an increased resistance to the stress-effects caused by earthquakes.\n\nConcretes made from energetically modified cements can be designed to exhibit superior strength and durability or to exhibit rapid and ultra-rapid hardening. This depends upon the \"pozzolanic\" characteristics of the raw material that is employed to make it. For example, fly ash in its natural state is typically, but not always, more \"pozzolanic\" than volcanic ash.\n\nAn important consideration in choosing a concrete material is its strength-development within a specified time period, which must match or exceed a project's specifications. According to Ronin, the current upper-limit for using EMC made from natural pozzolans is 60% for practical large-scale usage.\n\nThe EMC activation of fly ash is a mechanical process, and does not involve heating or burning. Leachability tests were performed by LTU in 2001 in Sweden on behalf of a Swedish power production company.  These tests confirmed that EMC made from fly ash \"showed a low surface specific leachability\" with respect to \"all environmentally relevant metals.\"   \n\nEnergetically modified cements have been used in large infrastructure projects in the United States.> EMCs made by replacing at least 50% of the Portland cement with have yielded consistent field results in high-volume applications. This is also the case for EMC made from natural pozzolans (e.g., volcanic ash).\n\nVolcanic ash deposits from Southern California were independently tested; at 50% Portland cement replacement, the resulting concretes exceeded requirements. At 28 days, the compressive strength was 4,180 psi / 28.8 MPa (N/mm²). The 56-day strength exceeded the requirements for 4,500 psi (31.1 MPa) concrete, even taking into account the safety margin as recommended by the American Concrete Institute. The concrete made in this way was workable and sufficiently strong, exceeding the 75% standard of pozzolanic activity at both 7 days and 28 days. The surface smoothness of pozzolans in the concrete was also increased.\n\nTreating Portland cement with EMC activation will yield high-performance concretes. These HPCs will be high strength, highly durable, and exhibiting greater strength-development in contrast to HPCs made from untreated Portland cement. Concrete made from ordinary Portland cement without additives has a relatively impaired resistance to salt waters. Treating Portland cement with the EMC activation process may increase the strength development by nearly 50% and also significantly improve the durability, as measured according to generally accepted methods.\n\nEnergetically modified cements also exhibit high resistances to chloride and sulphate ion attack, together with low alkali-silica reactivities (ASR). Like all concretes comprising pozzolans, they are more durable than concretes made from Portland cement.\n\nAn early project using EMC made from fly ash was the construction of a road bridge in Karungi, Sweden, with Swedish construction firm Skanska. The Karungi road bridge has withstood Karungi's harsh subarctic climate and divergent annual and diurnal temperature ranges.\nIn the United States, energetically modified cements have been approved for usage by a number of state transportation agencies, including PennDOT, TxDOT and CalTrans.\n\nIn the United States, highway bridges and hundreds of miles of highway paving have been constructed using concretes made from EMC derived from fly ash. These projects include sections of Interstate 10. In these projects, EMC replaced at least 50% of the Portland cement in the concrete poured. This is about 2.5 times more than the typical amount of fly ash in projects where energetic modification is not used. Independent text data showed acceptable 28-day strength requirements in all projects.\n\nAnother project was the extension of the passenger terminals at the Port of Houston, Texas, where energetically modified cement's ability to yield concretes that exhibit high resistances to chloride– and sulphate–ion permeability (i.e., increased resistance to sea waters) was a factor.\n\nEMCs have been in production since 1992. As of 2010 the volume of concrete produced containing a least partially energetically modified cement was about 4,500,000 cu yd (3,440,496 m). This represents approximately 0.13% of the yearly worldwide concrete production.\n\nBackground science to EMC Activation:\n\n\nAcademic:\n\n\n"}
{"id": "14535813", "url": "https://en.wikipedia.org/wiki?curid=14535813", "title": "Energy and American Society: Thirteen Myths", "text": "Energy and American Society: Thirteen Myths\n\nEnergy and American Society: Thirteen Myths is a 2007 book about energy security and climate change, edited by Benjamin K. Sovacool and Marilyn A. Brown. The book is suitable for both technical and non-technical audiences since it is written in plain English and is \"easily digested by anyone with a rudimentary background or interest in energy economics\".\n\nThe book discusses and presents counter-arguments to thirteen propositions concerning American culture, energy, the environment, and society:\n\n\nThe book was produced with support from Oak Ridge National Laboratory and involved 24 contributing authors with a diverse range of backgrounds. Notable contributors include Amory Lovins and Joseph Romm.\n\nBenjamin K. Sovacool is a Visiting Associate Professor at Vermont Law School and founding Director of the Energy Justice Program at their Institute for Energy and Environment. He was formerly an Assistant Professor and Research Fellow at the National University of Singapore.\n\nMarilyn A. Brown is an American geographer on the faculty of the Georgia Institute of Technology. She is a member of the National Commission on Energy Policy and the Tennessee Valley Authority board. She previously worked at Oak Ridge National Laboratory, where she held several leadership positions.\n\n\"Energy and American Society: Thirteen Myths\" has been reviewed in \"Energy Policy\" and the \"Annals of the Association of American Geographers\".\n\n\n\n"}
{"id": "4968835", "url": "https://en.wikipedia.org/wiki?curid=4968835", "title": "Ethical living", "text": "Ethical living\n\nEthical living is the philosophy of making decisions for daily life which take into account ethics and moral values, particularly with regard to consumerism, sustainability, environmentalism, wildlife and animal welfare. \n\nAt present, it is largely an individual choice rather than an organized social movement. \nEthical living is an offshoot of sustainable living in which the individual initially makes a series of small lifestyle changes in order to limit their effect on the environment. Making the decision to start to live ethically can be as easy as beginning to recycle, switching off lights when leaving a room, buying local organic or fair trade produce, or eating less meat. Many people often go further by re-using/re-cycling waste water, using renewable resources in their homes such as solar panels or atmospheric water generators, or replacing driving with greener modes of transport such as biking. Many, however, believe that even more drastic lifestyle changes need to be made in order to combat climate change. For example, the impending increase in our world's population will likely exacerbate resource scarcity and increase carbon emissions. For this reason, many believe that ethical living could mean taking control of one's reproductive health and \"requires social solutions such as increasing women's empowerment in public and private life, and broadening the population movement beyond the family planning and reproductive health movements in order to raise its chances of success.\" \nAs As Maxwell T. Boykoff, an Assistant Professor in the Cooperative Institute for Research in Environmental Sciences Center for Science and Technology Policy Research at the University of Colorado, Boulder argues, \"initiatives and plans that were formerly confined to the climate-controlled quarters of high-level policy briefing rooms and scientific conference halls are increasingly prevalent around the kitchen table, bar stool, front porch and corner shop\" making ethical patterns of consumption influential on domestic and international policies. For example, there are many governments, such as The Netherlands, that strive to create a \"climate neutral society\" focused on \"trend breaks in technology, policy instruments, industrial, transport and agricultural practices, residential designs, and societal behavior\". While there are many calculators and venues with which to measure overall national and state level \"ecological footprints\", measurements for individual and community footprints are more difficult to measure. For this reason, the impacts of individual ethical living choices or \"green living\" can be inconclusive. Some researchers question the amount of carbon footprint reduction that can be achieved through \"pro-environmental\" behavior as surveys have found that \"no significant difference was found between the ecological footprints of the two groups - suggesting that individual pro-environmental attitudes and behaviour do not always reduce the environmental impacts of consumption.\" This phenomenon has led to a new proposition known as the \"behavior-impact gap (BIG) problem\" where researchers realize that there may not always be a proportional relationship between changing lifestyle habits and a decrease in one's carbon footprints. \n\nAlthough ethical living is growing in popularity, many in the environmental movement believe that the responsibility of ethical practice should also be placed on \"Big Business\". They argue that while individuals can change their daily habits, the most significant changes can and should be made by large organizations and multinational corporations. Many criticize this argument, however, as they claim large organizations and multinational corporations increase consumption and perpetuate neoliberal and capitalistic tendencies leading to a loss of focus on \"liveable wages, affordable health care, decent education, breathable air, and clean water.\" Another criticism of the ethical living movement is many individual consumption changes need to be made, however, “it will take more than a well-intentioned review of individual shopping habits to address our present ecological crisis.” \n\n"}
{"id": "48583555", "url": "https://en.wikipedia.org/wiki?curid=48583555", "title": "Hatchōbaru Geothermal Power Plant", "text": "Hatchōbaru Geothermal Power Plant\n\nThe is a large geothermal power station in Ōita Prefecture, Japan. At 112 MW, it is the largest geothermal power plant in the country. The plant comprises 3 generation units. The first unit, with a capacity of 55 MW, was activated in June 1977. A second unit started operation in June 1990, with an additional 55 MW capacity. A third binary unit rated at 2 MW is operational since April 2006.\nThe first unit was among the first double flash geothermal generation units. The second unit is very similar to the first, with some technical improvements based on the experience gained from the operation of unit 1.\n\nThe power station is located in Kokonoe town, in the Aso Kujū National Park. Another geothermal power station, the Otake plant with a capacity of 12.5 MW, is located about 2 km from Hatchobaru plant. The location in a national park, and the presence of popular tourist attractions nearby, means that the plant is subject to strict limits and controls over location of wells, discharges, noise and visual distraction from the local scenery.\n\nThe plant is located in the vicinity of Mount Kujū, an active volcano. It generates electricity from high temperature steam from the site.\nThe power plant is at an elevation of 1100 m and it is operated by remote control from the nearby Otake power plant.\nAs of December 2008, there are 30 steam wells ranging in depth from 760 m to 3000 m and generating a total of 890 tons of steam per hour. The wells are concentrated in a relatively small area of about 1 km, due to terrain constraints: the plant is in a narrow valley in the Kuju mountain range.\n\nAs in other Japanese geothermal plants, the waste brine from Hatchobaru is used to produce hot water for local communities before being reinjected.\n\n"}
{"id": "20604765", "url": "https://en.wikipedia.org/wiki?curid=20604765", "title": "History of ethanol fuel in Brazil", "text": "History of ethanol fuel in Brazil\n\nThe history of ethanol fuel in Brazil dates from the 1970s and relates to Brazil's sugarcane-based ethanol fuel program, which allowed the country to become the world's second largest producer of ethanol, and the world's largest exporter. Several important political and technological developments led Brazil to become the world leader in the sustainable use of bioethanol, and a policy model for other developing countries in the tropical zone of Latin America, the Caribbean, and Africa. Government policies and technological advances also allowed the country to achieve a landmark in ethanol consumption, when ethanol retail sales surpassed 50% market share of the gasoline-powered vehicle fleet in early 2008. This level of ethanol fuel consumption had only been reached in Brazil once before, at the peak of the \"Pró-Álcool\" Program near the end of the 1980s.\n\nSugarcane has been cultivated in Brazil since 1532. Introduced in Pernambuco that year, sugar was one of the first commodities exported to Europe by the Portuguese settlers. Ethyl alcohol or ethanol is obtained as a by-product of sugar mills producing sugar, and can be processed to produce alcoholic beverages, ethanol fuel or alcohol for industrial or antiseptic uses. The first use of sugarcane ethanol as fuel in Brazil dates back to the late twenties and early thirties of the 20th century, with the introduction of the automobile in the country. After World War I some experimenting took place in Brazil's Northeast Region, and as early as 1919, the Governor of Pernambuco mandated all official vehicles to run on ethanol. The first ethanol fuel production plant went on line in 1927, the Usina Serra Grande Alagoas (USGA), located in the Northeastern state of Alagoas, producing fuel with 75% ethanol and 25% ethyl ether. As other plants began producing ethanol fuel, two years later there were 500 cars running on this fuel in the country's Northeast Region.\n\nA decree was issued on February 20, 1931, mandating the blend of 5% hydrated ethanol to all imports of gasoline by volume. The number of distilleries producing ethanol fuel went from 1 in 1933 to 54 by 1945. Fuel-grade ethanol production increased from 100,000 liters in 1933 to 51.5 million liters in 1937, representing 7% of the country's fuel consumption. Production peaked to 77 million liters during World War II, representing 9.4% of all ethanol production in the country. Due to German submarine attacks threatening oil supplies, the mandatory blend was as high as 50 percent in 1943. After the end of the war cheap oil caused gasoline to prevail, and ethanol blends were only used sporadically, mostly to take advantage of sugar surpluses, until the 1970s, when the first oil crisis resulted in gasoline shortages and awareness on the dangers of oil dependence.\n\nAs a response to the 1973 oil crisis, the Brazilian government began promoting bioethanol as a fuel. The National Alcohol Program -\"Pró-Álcool\"- (), launched in 1975, was a nationwide program financed by the government to phase out automobile fuels derived from fossil fuels, such as gasoline, in favor of ethanol produced from sugar cane. The decision to produce ethanol from sugarcane was based on the low cost of sugar at the time, the idle capacity for distillation at the sugar plants, and the country's tradition and experience with this feedstock. Other sources of fermentable carbohydrates were also explored such as manioc and other feedstocks. The first phase of the program concentrated in production of anhydrous ethanol for blending with gasoline.\n\nAfter testing in government fleets with several prototypes developed by local subsidiaries of Fiat, Volkswagen, GM, and Ford, and compelled by the second oil crisis, the first 16 gasoline stations began supplying hydrous ethanol in May 1979 for a fleet of 2,000 neat ethanol adapted vehicles, and by July, the Fiat 147 was launched to the market, becoming the first modern commercial neat ethanol-powered car (E100) sold in the world. Brazilian carmakers modified gasoline engines to support hydrous ethanol characteristics. Changes included compression ratio, amount of fuel injected, replacement of materials subject to corrosion by ethanol, use of colder spark plugs suitable for dissipating heat due to higher flame temperatures, and an auxiliary cold-start system that injects gasoline from a small tank to aid cold starting. Six years later, approximately 75% of Brazilian passenger cars were manufactured with ethanol engines.\n\nThe Brazilian government also made mandatory the blend of ethanol fuel with gasoline, fluctuating from 1976 until 1992 between 10% and 22%. Due to this mandatory minimum gasoline blend, pure gasoline (E0) is no longer sold in the country. A federal law was passed in October 1993 establishing a mandatory blend of 22% anhydrous ethanol (E22) in the entire country. This law also authorized the Executive to set different percentages of ethanol within pre-established boundaries; since 2003 these limits were fixed at a maximum of 25% (E25) and a minimum of 20% (E20) by volume. Since then, the government has set the percentage on the ethanol blend according to the results of the sugarcane harvest and the levels of ethanol production from sugarcane, resulting in blend variations even within the same year.\n\nSince July 2007, the mandatory blend was 25% of anhydrous ethanol and 75% gasoline or E25 blend. As a result of supply shortages and high ethanol fuel prices, in 2010 the government mandated a temporary 90-day blend reduction from E25 to E20 beginning February 1, 2010. As supply shortages took place again between the 2010–2011 harvest seasons, some ethanol was imported from the US, and in April 2011 the government reduced the minimum mandatory blend to 18 percent, leaving the mandatory blend range between E18 to E25.\n\nBy mid-March 2015, the government raised the ethanol blend in regular gasoline from 25% to 27%. The blend on premium gasoline was kept at 25% upon request by ANFAVEA, the Brazilian association of automakers, because of concerns about the effects on the higher blend on cars that were built only for E25 as the maximum blend, as opposed to flex-fuel cars. The government approved the higher blend as an economic incentive for ethanol producers, due to an existing overstock of over 1 billion liters (264 million US gallons) of ethanol. The implementation of E27 is expected to allow the consumption of the overstock before the end of 2015.\nThe Brazilian government provided three important initial motivators for the ethanol industry: guaranteed purchases by the state-owned oil company Petrobras, low-interest loans for agro-industrial ethanol firms, and fixed gasoline and ethanol prices where hydrous ethanol sold for 59% of the government-set gasoline price at the pump. These incentives made ethanol production competitive.\n\nAfter reaching more than four million cars and light trucks running on pure ethanol by the late 1980s, representing 33% of the country's motor vehicle fleet, ethanol production and sales of neat ethanol cars tumbled due to several factors. First, gasoline prices fell sharply as a result of the 1980s oil glut. The inflation adjusted real 2004 dollar value of oil fell from an average of US$78.2 in 1981 to an average of US$26.8 per barrel in 1986. Also, by mid-1989, a shortage of ethanol fuel supply in the local market left thousands of vehicles in line at gas stations or out of fuel in their garages. At the time ethanol production was tightly regulated by the government, as well as pricing of both gasoline and ethanol fuel, the latter subject to fixed producer prices. As a complement, the government provided subsidies to guarantee a lower ethanol price at the pump as compared to gasoline, as consumers were promised that ethanol prices would never be higher than 65% the price of gasoline. As sugar prices sharply increased in the international market by the end of 1988 and the government did not set the sugar export quotas, production shifted heavily towards sugar production causing an ethanol supply shortage, as the real cost of ethanol was around per barrel. As ethanol production stagnated at 12 billion liters and could not keep pace with the increasing demand required by the now significant ethanol-only fleet, the Brazilian government began importing ethanol from Europe and Africa in 1991. Simultaneously, the government began reducing ethanol subsidies, thus marking the beginning of the industry's deregulation and the slow extinction of the \"Pró-Álcool\" Program.\n\nIn 1990, production of neat ethanol vehicles fell to 10.9% of the total car production as consumers lost confidence in the reliability of ethanol fuel supply, and began selling or converting their cars back to gasoline fuel. By the beginning of 1997 Fiat, Ford, and General Motors had all stopped producing ethanol powered cars, leaving only Volkswagen (who offered the Gol, Santana, Kombi and their derivatives). The manufacturers requested a reinstatement of a stable gasohol program and promised to develop products by 1999.\n\nConfidence in ethanol-powered vehicles was restored with the introduction in the Brazilian market of flexible-fuel vehicles starting in 2003. A key innovation in the Brazilian flex technology was avoiding the need for an additional dedicated sensor to monitor the ethanol-gasoline mix, which made the first American M85 flex fuel vehicles too expensive. This was accomplished through the lambda probe, used to measure the quality of combustion in conventional engines, is also required to tell the engine control unit (ECU) which blend of gasoline and alcohol is being burned. This task is accomplished automatically through software developed by Brazilian engineers, called \"Software Fuel Sensor\" (SFS), fed with data from the standard sensors already built-in the vehicle. The technology was developed by the Brazilian subsidiary of Bosch in 1994, but was further improved and commercially implemented in 2003 by the Italian subsidiary of Magneti Marelli. A similar fuel injection technology was developed by the Brazilian subsidiary of Delphi Automotive Systems, and it is called \"Multifuel.\" This technology allows the controller to regulate the amount of fuel injected and spark time, as fuel flow needs to be decreased and also self-combustion needs to be avoided when gasoline is used because ethanol engines have compression ratio around 12:1, too high for gasoline.\n\nIn March 2003, Volkswagen launched in the Brazilian market the Gol 1.6 Total Flex, the first commercial flexible fuel vehicle capable of running on any blend of gasoline and ethanol. Chevrolet followed three months later with the Corsa 1.8 Flexpower, using an engine developed by a joint-venture with Fiat called PowerTrain. That year production of full flex-fuel reached 39,853 automobiles and 9,411 light commercial vehicles. By 2008, popular manufacturers that build flexible fuel vehicles are Chevrolet, Fiat, Ford, Peugeot, Renault, Volkswagen, Honda, Mitsubishi, Toyota and Citroën. Nissan launched its first flex fuel in the Brazilian market in 2009 and Kia Motors in 2010.\nFlexible-fuel vehicles were 22% of the car sales in 2004, 73% in 2005, 87.6% in July 2008, and reached a record 94% in August 2009. The production of flex-fuel cars and light commercial vehicles reached the milestone of 10 million vehicles in March 2010, and 15.3 million units by March 2012. As of December 2011, the fleet of flex automobiles and light commercial vehicles had reached 14.8 million vehicles, representing 21% of Brazil's motor vehicle fleet and 31.8% of all registered light vehicles.\n\nThis rapid adoption of the flex technology was facilitated by the fuel distribution infrastructure already in place, as around 27,000 filling stations countrywide were available by 1997 with at least one ethanol pump, a heritage of the \"Pró-Álcool\" program, and by October 2008 have reached 35,000 fueling stations.\n\nThe flexibility of Brazilian FFVs empowered the consumers to choose the fuel depending on current market prices. The rapid adoption and commercial success of \"flex\" vehicles, as they are popularly known, together with the mandatory blend of alcohol with gasoline as E25 fuel, have increased ethanol consumption up to the point that during the first two months of 2008 ethanol consumption increased by 56% when compared to the same period in 2007, and achieving a landmark in ethanol consumption in February 2008, when ethanol retail sales surpassed the 50% market share of the gasoline-powered fleet. This level of ethanol fuel consumption had not been reached since the end of the 80s, at the peak of the \"Pró-Álcool\" Program. According to two separate research studies conducted in 2009, at the national level 65% of the flex-fuel registered vehicles regularly use ethanol fuel, and all-year-long by 93% of flex car owners in São Paulo, the main ethanol producer state where local taxes are lower, and prices at the pump are more competitive than gasoline.\n\nBetween 1979 and 2011, Brazil substituted around 22 million pure gasoline-powered vehicles with 5.7 million neat ethanol vehicles, 14.8 million flex-fuel vehicles and almost 1.5 million flex motorcycles. The number of neat ethanol vehicles still in use by 2003 was estimated between 2 and 3 million vehicles, and 1.22 million as of December 2011. There were 80 flex car and light truck models available in the market manufactured by 12 major carmakers by December 2011, and four flex-fuel motorcycle models available.\n\nThe early technology in flex fuel engines had a fuel economy with hydrated ethanol (E100) that was 25 to 35% lower than gasoline, but flex engines are now being designed with higher compression ratios, taking advantage of the higher ethanol blends and maximizing the benefits of the higher oxygen content of ethanol, resulting in lower emissions and improving fuel efficiency, allowing flex engines in 2008 models to reduce the fuel economy gap to 20 to 25% that of gasoline.\n\nUnder the auspices of the BioEthanol for Sustainable Transport (BEST) project, the first ethanol-powered (E95 or ED95) bus began operations in São Paulo city on December 2007 as a one-year trial project. The bus is a Scania model with a modified diesel engine capable of running with 95% hydrous ethanol blended with a 5% ignition improver, with a Marcopolo body. Scania adjusted the compression ratio from 18:1 to 28:1, added larger fuel injection nozzles, and altered the injection timing.\n\nDuring the trial period performance and emissions were monitored by the National Reference Center on Biomass (CENBIO - ) at the Universidade de São Paulo, and compared with similar diesel models, with special attention to carbon monoxide and particulate matter emissions. Performance is also important as previous tests have shown a reduction in fuel economy of around 60% when E95 is compared to regular diesel.\n\nIn November 2009, a second ED95 bus began operating in São Paulo city. The bus was a Swedish Scania with a Brazilian CAIO body. The second bus was scheduled to operate between Lapa and Vila Mariana, passing through Avenida Paulista, one of the main business centers of São Paulo city. The two test buses operated regularly for 3 years.\n\nIn November 2010 the municipal government of São Paulo city signed an agreement with UNICA, Cosan, Scania and \"Viação Metropolitana\"\", the local bus operator, to introduce a fleet of 50 ethanol-powered ED95 buses by May 2011. The city's government objective is to reduce the carbon footprint of the city's bus fleet of 15,000 diesel-powered buses, with a final goal that the entire bus fleet use only renewable fuels by 2018. Scania will manufacture the buses in its plant located in São Bernardo do Campo, São Paulo. These buses use the same technology and fuel as the 700 buses manufactured by Scania and already operating in Stockholm.\n\nThe first ethanol-powered buses were delivered in May 2011, and the 50 buses will start regular service in June 2011. The fleet of 50 ethanol-powered ED95 buses had a cost of R$ 20 million () and due to the higher cost of the ED95 fuel, one of the firms participating in the cooperation agreement, Raísen (a joint venture between Royal Dutch Shell and Cosan), will supply the fuel to the municipality at 70% the market price of regular diesel.\n\nThe latest innovation within the Brazilian flexible-fuel technology is the development of flex-fuel motorcycles. In 2007 Magneti Marelli presented the first motorcycle with flex technology. Delphi Automotive Systems also presented in 2007 its own injection technology for motorcycles. Besides the flexibility in the choice of fuels, a main objective of the fuel-flex motorcycles is to reduce CO emissions by 20 percent, and savings in fuel consumption in the order of 5% to 10% are expected.\nThe first flex fuel motorcycle was launched to the Brazilian market by Honda in March 2009. Produced by its local subsidiary Moto Honda da Amazônia, the CG 150 Titan Mix is sold for around US$2,700. Because the motorcycle does not have a secondary gas tank for a cold start like the Brazilian flex cars do, the fuel tank must have at least 20% of gasoline to avoid start up problems at temperatures below . The motorcycle’s panel includes a gauge to warn the driver about the actual ethanol-gasoline mix in the storage tank. During the first eight months after its market launch the CG 150 Titan Mix has sold 139,059 motorcycles, capturing a 10.6% market share, and ranking second in sales of new motorcycles in the Brazilian market in 2009.\n\nIn September 2009, Honda launched a second flexible-fuel motorcycle, the on-off road NXR 150 Bros Mix. By December 2010 both Honda flexible-fuel motorcycles had reached cumulative production of 515,726 units, representing an 18.1% market share of the Brazilian new motorcycle sales in that year. As of January 2011 there were four flex-fuel motorcycle models available in the market. During 2011 a total of 956,117 flex-fuel motorcycles were produced, raising its market share to 56.7%. Since their inception in 2009 almost 1.5 million flexible-fuel motorcycles had been produced in the country through December 2011, and the two million mark was reached in August 2012. \n\nThe Brazilian subsidiaries of Magneti Marelli, Delphi and Bosch have developed and announced the introduction in 2009 of a new flex engine generation that eliminates the need for the secondary gasoline tank by warming the ethanol fuel during starting, and allowing flex vehicles to do a normal cold start at temperatures as low as , the lowest temperature expected anywhere in the Brazilian territory. Another improvement is the reduction of fuel consumption and tailpipe emissions, between 10% to 15% as compared to flex motors sold in 2008. In March 2009 Volkswagen do Brasil launched the Polo E-Flex, the first flex fuel model without an auxiliary tank for cold start. The Flex Start system used by the Polo was developed by Bosch.\n\nSince 2009, the Brazilian ethanol industry has experienced financial stress due to the credit crunch caused by the economic crisis of 2008; poor sugarcane harvests due to unfavorable weather; high sugar prices in the world market that made more attractive to produce sugar rather than ethanol; and other domestic factors that resulted in a decline of its annual production despite a growing demand in the local market. Brazilian ethanol fuel production in 2011 was 21.1 billion liters (5.6 billion U.S. liquid gallons), down from 26.2 million liters (6.9 billion gallons) in 2010. A supply shortage took place for several months during 2010 and 2011, and prices climbed to the point that ethanol fuel was no longer attractive for owners of flex-fuel vehicles; the government reduced the minimum ethanol blend in gasoline to reduce demand and keep ethanol fuel prices from rising further; and for the first time since the 1990s, ethanol fuel was imported from the United States.\n\nAs a result of higher ethanol prices caused by the Brazilian ethanol industry crisis, combined with government subsidies set to keep gasoline price lower than the international market value, by November 2013 only 23% flex-fuel car owners were using ethanol regularly, down from 66% in 2009.\n\n\n"}
{"id": "31294660", "url": "https://en.wikipedia.org/wiki?curid=31294660", "title": "International Broadcasting Act", "text": "International Broadcasting Act\n\nSigned in law in 1994 by U.S. President Bill Clinton, this act was meant to streamline the U.S. international broadcasting and provide a cost-effective way to continue Radio Free Europe/ Radio Liberty, Voice of America, and Radio Marti. It placed control of the international broadcasting under the United States Information Agency.\n\nIn 1958, President Eisenhower in an address to the United Nations proposed monitoring radio broadcasts:\n\nI believe that this Assembly should ... consider means for monitoring the radio broadcasts directed across national frontiers in the troubled Near East area. It should then examine complaints from these nations which consider their national security jeopardized by external propaganda.\n\nIn the 1960s, President Kennedy to build an international broadcasting arm of the United States to as a way to promote foreign policy and overthrow socialism. In 1976, President Gerald Ford signed the Voice of America charter that established it as the leading branch of US international broadcasting.\n\nIn 1993, the Clinton Administration proposed cutting the budget for Radio Free Europe and Radio Liberty in order to reduce budget expenditures. However, after working with the Congress, the International Broadcasting Act was born.\n\nThis Act (Public Law 103-236) consolidated all non-military, U.S. Government international broadcast services under a Broadcasting Board of Governors (BBG) and also created the International Broadcasting Bureau (IBB). The BBG is an independent government agency created to replace the Board for International Broadcasting and consolidate Voice of America broadcasting.\n\nIn this law, the President appoints one member of the board as the Chairman of the board. The Secretary of State also serves on the board.\n\nBesides combining current radio service, this Act also created the Radio Free Asia - a network aimed at Burma, China, Cambodia, Laos, North Korea, and Vietnam.\n\nIn September 2009, the 111th Congress amended the International Broadcasting Act to allow a one year extension of the operation of Radio Free Asia.\n\nIn 2002, the Act was amended to include the Radio Free Afghanistan.\n\nIn May 1994, the President announce the continuation of Radio Free Asia after 2009 was dependent on its increased international broadcasting and ability to reach its audience.\n"}
{"id": "57786549", "url": "https://en.wikipedia.org/wiki?curid=57786549", "title": "Lensch-Cunow-Haenisch group", "text": "Lensch-Cunow-Haenisch group\n\nThe Lensch-Cunow-Haenisch group was a political faction within the Social Democratic Party of Germany founded in 1915 by anti-revisionist marxists who despite previously opposing participation in the First World War now supported it. Its name comes from the three principal protagonists: Paul Lensch, Heinrich Cunow and Konrad Haenisch. They followed the initiative of Parvus in advocating a German victory as a positive step for international social democracy. They mobilised Marxist arguments behind the war effort.\n"}
{"id": "58205225", "url": "https://en.wikipedia.org/wiki?curid=58205225", "title": "List of Habenaria species", "text": "List of Habenaria species\n\nThe following is a list of species of \"Habenaria\" recognised by the World Checklist of Selected Plant Families as at August 2018:\n\n\n"}
{"id": "29939656", "url": "https://en.wikipedia.org/wiki?curid=29939656", "title": "List of Marasmiaceae genera", "text": "List of Marasmiaceae genera\n\nThe Marasmiaceae are a family of fungi in the Agaricales order. It includes over 50 genera and some 1590 species.\n\n\n"}
{"id": "11051842", "url": "https://en.wikipedia.org/wiki?curid=11051842", "title": "List of NGC objects (6001–7000)", "text": "List of NGC objects (6001–7000)\n\nThis is a list of NGC objects 6001–7000 from the New General Catalogue (NGC). The astronomical catalogue is composed mainly of star clusters, nebulae, and galaxies. Other objects in the catalogue can be found in the other subpages of the list of NGC objects.\n\nThe constellation information in these tables is taken from \"The Complete New General Catalogue and Index Catalogue of Nebulae and Star Clusters by J. L. E. Dreyer\", which was accessed using the \"VizieR Service\". Galaxy types are identified using the \"NASA/IPAC Extragalactic Database\". The other data of these tables are from the SIMBAD Astronomical Database unless otherwise stated.\n"}
{"id": "18523774", "url": "https://en.wikipedia.org/wiki?curid=18523774", "title": "List of algal fuel producers", "text": "List of algal fuel producers\n\nThis is a list of algal fuel producers.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are diverse companies developing biofuels from algae:\n\n\n\n\n\n"}
{"id": "2165161", "url": "https://en.wikipedia.org/wiki?curid=2165161", "title": "List of busiest airports by international passenger traffic", "text": "List of busiest airports by international passenger traffic\n\nThe following is a list of the world's largest airports by international passenger traffic.\n\nAirports Council International's (January–December) preliminary figures are as follows.\n\nAirports Council International's (January–December) preliminary figures are as follows.\nAirports Council International's (January–December) figures are as follows.\n\nAirports Council International's (January–December) figures are as follows.\n\nAirports Council International's (January–December) figures are as follows.\n\nAirports Council International's (January–December) figures are as follows.\n\n\n"}
{"id": "26400783", "url": "https://en.wikipedia.org/wiki?curid=26400783", "title": "List of earthquakes in Nicaragua", "text": "List of earthquakes in Nicaragua\n\nNotable earthquakes in the history of Nicaragua include the following:\n\n"}
{"id": "1011976", "url": "https://en.wikipedia.org/wiki?curid=1011976", "title": "List of galaxy groups and clusters", "text": "List of galaxy groups and clusters\n\nThis page lists some galaxy groups and galaxy clusters.\n\nDefining the limits of galaxy clusters is imprecise as many clusters are still forming. In particular, clusters close to the Milky Way tend to be classified as galaxy clusters even when they are much smaller than more distant clusters.\n\nSome clusters exhibiting strong evidence of dark matter.\n\nThis is a list of galaxy groups and clusters that are well known by something other than an entry in a catalog or list, or a set of coordinates, or a systematic designation.\n\nThe major nearby groups and clusters are generally named after the constellation they lie in. Many groups are named after the leading galaxy in the group. This represents an ad hoc systematic naming system.\n\nThe Local Group contains the largest number of visible galaxies with the naked eye. However, its galaxies are not visually grouped together in the sky, except for the two Magellanic Clouds. The IC342/Maffei Group, the nearest galaxy group, would be visible by the naked eye if it were not obscured by the stars and dust clouds in the Milky Way's spiral arms.\n\n\n\nSometimes clusters are put forward that are not genuine clusters or superclusters. Through the researching of member positions, distances, peculiar velocities, and binding mass, former clusters are sometimes found to be the product of a chance line-of-sight superposition.\n\n"}
{"id": "38993240", "url": "https://en.wikipedia.org/wiki?curid=38993240", "title": "List of glaciers in Denali National Park and Preserve", "text": "List of glaciers in Denali National Park and Preserve\n\nThere are at least 40 named and hundreds of unnamed glaciers in Denali National Park and Preserve. \n\n"}
{"id": "34557509", "url": "https://en.wikipedia.org/wiki?curid=34557509", "title": "List of national parks of Tunisia", "text": "List of national parks of Tunisia\n\nThere are 17 national parks and larger nature reserves in Tunisia in 2013.\n\n\n"}
{"id": "21206536", "url": "https://en.wikipedia.org/wiki?curid=21206536", "title": "List of olive cultivars", "text": "List of olive cultivars\n\nThere are hundreds of cultivars of the olive (\"Olea europaea\"). As one of the oldest and more important domesticated crops raised by humans, the olive tree has diverged naturally and with the assistance of man into many varieties. Olive cultivars are first and foremost divided into their location of origin; most names for cultivars come from place names. Secondarily, olives may be preferred for olive oil production or for eating as table olives, though many cultivars are dual-purpose.\n"}
{"id": "45059310", "url": "https://en.wikipedia.org/wiki?curid=45059310", "title": "List of protected areas of Gribskov Municipality", "text": "List of protected areas of Gribskov Municipality\n\nThis list of protected areas of Gribskov Municipality lists protected areas of Gribskov Municipality, Denmark.\n"}
{"id": "36465643", "url": "https://en.wikipedia.org/wiki?curid=36465643", "title": "List of rivers of Liberia", "text": "List of rivers of Liberia\n\nThis is a list of rivers in Liberia. This list is arranged by drainage basin, with respective tributaries indented under each larger stream's name.\n\n\n\n"}
{"id": "56733844", "url": "https://en.wikipedia.org/wiki?curid=56733844", "title": "Lorenz energy cycle", "text": "Lorenz energy cycle\n\nThe Lorenz energy cycle describes the generation, conversion and dissipation of energy in the general atmospheric circulation. It is named after the meteorologist Edward N. Lorenz who worked on its mathematical formulation in the 1950s. \n\nAny atmospheric circulation system, whether it is a small-scale weather system or a large-scale zonal wind system, is maintained by the supply of kinetic energy. The development of such a system requires either a transformation of some other form of energy into kinetic energy, or the conversion of the kinetic energy of another system into that of the developing system.\nOn a global scale, the atmospheric circulation must carry energy polewards, because there is a net gain of energy in the tropics through incoming solar radiation and net loss of energy in high latitudes through thermal emission. At low latitudes, where the Hadley cell takes shape, the poleward transport of energy is done by the mean meridional circulation. At mid-latitudes in contrast, the influence of longitudinally asymmetric features, referred to as eddies, is dominant over the mean flow. For a closer examination, it is useful to split all parameters (e.g. P) into their zonal-mean (denoted by an overline, e.g. ) and their departures from the zonal mean due to orography, land-sea contrasts, weather systems and any other eddy-like features (denoted by a prime, e.g. P').\n\nThe available potential energy is the amount of potential energy in the atmosphere that can be conversed into kinetic energy. In a statically stable atmosphere, the zonal-mean available potential energy is approximated as:\n\nwhere formula_2 is the integral over the Earth's entire atmosphere, ρ is the mean density of air, N is the buoyancy frequency, a measure of static stability, Φ is the geopotential and z* denotes a log-pressure coordinate.\n\nEddy available potential energy P' is approximated as:\n\nZonal-mean kinetic energy is approximated as:\n\nwhere u and v are the zonal and meridional components of air velocity.\n\nEddy kinetic energy K' is approximated as:\n\nThe description of the Lorenz Energy Cycle is completed by a mathematical formalism for the generation of potential energy through diabatic heating, its conversion to kinetic energy through vertical motion of air and the dissipation of kinetic energy through friction. A conversion of zonal-mean energy to eddy energy and vice versa is possible where eddies interact with the mean flow and displace warm/cold air.\n"}
{"id": "2050671", "url": "https://en.wikipedia.org/wiki?curid=2050671", "title": "Managed retreat", "text": "Managed retreat\n\nIn the context of coastal erosion, managed retreat (also managed realignment) allows an area that was not previously exposed to flooding by the sea to become flooded by removing coastal protection. This process is usually in low-lying estuarine areas and almost always involves flooding of land that has at some point in the past been claimed from the sea.\n\nIn the UK, managed retreat is often a response to sea level rise exacerbated by local subsidence of the land surface due to post-glacial isostatic rebound in the north.\n\nIn the UK the main reason for implementation of Managed Realignment is generally to improve coastal stability, essentially replacing artificial ‘hard’ coastal defences with natural ‘soft’ coastal landforms (Pethick 2002). This process can be used to protect areas of land further inland rather than that near the coast by relying on natural defences to absorb or dampen the force of waves.\n\nIn addition to being used as a means of coastal defence, Managed Realignment has also been used in a number of cases to mitigate for loss of intertidal habitat.\n\nAlthough land reclamation has been an important factor for salt marsh loss in the UK in the past (Allen 1992) the majority of current salt marsh loss in the UK is believed to be due to erosion (Morris et al. 2004). This erosion may involve coastal squeeze, where protective sea walls prevent the landward migration of salt marsh in response to sea level rise when sediment supply is limited (Hulme 2005; Morris et al. 2004). Salt marshes are protected under the EU Habitats Directive as well as providing habitat for a number of species protected by the Birds Directive (see Natura 2000). Following this guidance, the UK’s biodiversity action plan aims to prevent net losses to the area of salt marsh present in 1992. It is, therefore, a legal requirement that all losses in marsh area must be compensated by replacement habitat with equivalent biological characteristics (Crooks et al. 2001). This equates to the need to restore approximately 1.4 km² of salt marsh habitat per year in the UK.\n\nFor very simple schemes there are limited direct costs, such as removing any defences already in place and remediating land contamination etc. Maintenance costs can be very high.\n\nSediment flow is also restored to its natural state, beaches can be naturally replenished due to erosion of the coast, providing protection and the balance of the coastline returns.\n\nA certain amount of land will inevitably be lost in this process while beaches are being built up resulting in settlements, farmland and other property being destroyed. Because of this, managed retreat is often not a socially acceptable plan and may invoke the need for compensation to land-owners. Intertidal sites are often a rich archaeological resource and the loss of heritage is a factor to be weighed in managed retreat projects.\n\nThere are no agreed protocols on the monitoring of MR sites (Atkinson et al. 2001) and, consequently, very few of the sites are being monitored consistently and effectively (Wolters et al. 2005c). Due to the low levels of monitoring there is little evidence on which to base future managed realignment projects. This has led to the results of Managed Realignment schemes being extremely unpredictable.\n\nManaged Retreat has carried with it controversy. A law suit in Del Mar California brought on by residents was initiated to stop the program based on worries that home values, insurance costs and restricted home expansion have been effects of the policy. Some areas included in Managed Retreat are above sea level and are recommended based primarily on estimated engineering costs and by studies financed by the California Coastal Commission itself.\n\n\"One of the biggest drawbacks of managed realignment is that the option requires land to be yielded to the sea.\" \n\nFrom a recent Stanford University analysis \"managed retreat rarely works when the benefits of retreat accrue to residents only or no one at all, or when political will is low and a societal cost-benefit ratio doesn't justify relocation -- a scenario they labelled \"hunkered down.\" \n\nIn the UK, the first managed retreat site was an area of 8,000 square metres at Northey Island in Essex flooded in 1991, followed by larger sites at Tollesbury and Orplands (1995), Freiston Shore (2001) and Abbott's Hall Farm, at Great Wigborough in the Blackwater Estuary, it is one of the largest managed retreat schemes in Europe. It covers nearly 280 hectares of land on the north side of the estuary (2002) and a number of others. The programme was started by EWT - The Essex Wildlife Trust who own Abbott's Hall Farm, they made five breaches in the original old sea wall to allow the held-back sea to flood through to create salt marshland. The marshland over time reverted to its original state before the time of being cultivated, it has become a great site for birds as for the perfect conditions and is a hot-spot breeding ground too.\n\nAt present approximately 4 km² of salt marsh have been restored by MR in the UK (Mossman et al. In prep). One of the major reasons cited for the slow pace of current salt marsh restoration in the UK (Morris et al. 2004) is the uncertainty associated with the practice (Foresight).\n\n\n\nThe following references review the UK and US experience respectively:\n\nAtkinson, P.W., Crooks, S., Grant, A. and Rehfisch, M. M., 2001. The success of creation and restoration schemes in producing intertidal habitat suitable for waterbirds. English Nature Research Report 425.\n\nAvailable online in three sections: http://www.english-nature.org.uk/pubs/publication/PDF/ENRR425_1.pdf\n"}
{"id": "12322042", "url": "https://en.wikipedia.org/wiki?curid=12322042", "title": "Oil shale economics", "text": "Oil shale economics\n\nOil shale economics deals with the economic feasibility of oil shale extraction and processing. Although usually oil shale economics is understood as shale oil extraction economics, the wider approach evaluates usage of oil shale as whole, including for the oil-shale-fired power generation and production of by-products during retorting or shale oil upgrading processes.\n\nThe economic feasibility of oil shale is highly dependent on the price of conventional oil, and the assumption that the price will remain at a certain level for some time to come. As a developing fuel source the production and processing costs for oil shale are high due to the small nature of the projects and the specialist technology involved. A full-scale project to develop oil shale would require heavy investment and could potentially leave businesses vulnerable should the oil price drop and the cost of producing the oil would exceed the price they could obtain for the oil.\n\nDue to the volatile prices and high capital costs few deposits can be exploited economically without subsidies. However, some countries, such as Estonia, Brazil, and China, operate oil-shale industries, while some others, including Australia, United States, Canada, Jordan, Israel, and Egypt, are contemplating establishing or re-establishing this industry.\n\nThe production cost of a barrel of shale oil ranges from as high as US$95 per barrel to as low US$25 per barrel, although there is no recent confirmation of the latter figure. The industry is proceeding cautiously, due to the losses incurred during the last major investment into oil shale in the early 1980s, when a subsequent collapse in the oil price left the projects uneconomical.\n\nThe various attempts to develop oil shale deposits have succeeded only when the cost of shale-oil production in a given region comes in below the price of crude oil or its other substitutes (break-even price). The United States Department of Energy estimates that the \"ex-situ\" processing would be economic at sustained average world oil prices above US$$54 per barrel and \"in-situ\" processing would be economic at prices above $35 per barrel. These estimates assume a return rate of 15%. The International Energy Agency estimates, based on the various pilot projects, that investment and operating costs would be similar to those of Canadian oil sands, that means would be economic at prices above $60 per barrel at current costs. This figure does not account carbon pricing, which will add additional cost. According to the New Policies Scenario introduced in its World Energy Outlook 2010, a price of $50 per tonne of emitted , expected by 2035, will add additional $7.50 per barrel cost of shale oil.\n\nAccording to a survey conducted by the RAND Corporation, the cost of producing a barrel of oil at a surface retorting complex in the United States (comprising a mine, retorting plant, upgrading plant, supporting utilities, and spent shale reclamation), would range between $70–95 ($440–600/m, adjusted to 2005 values). This estimate considers varying levels of kerogen quality and extraction efficiency. In order for the operation to be profitable, the price of crude oil would need to remain above these levels. The analysis also discusses the expectation that processing costs would drop after the complex was established. The hypothetical unit would see a cost reduction of 35–70% after its first were produced. Assuming an increase in output of during each year after the start of commercial production, the costs would then be expected to decline to $35–48 per barrel ($220–300/m) within 12 years. After achieving the milestone of , its costs would decline further to $30–40 per barrel ($190–250/m).\n\nIn 2005, Royal Dutch Shell announced that its \"in situ\" extraction technology could become competitive at prices over $30 per barrel ($190/m). However, Shell reported in 2007 that the cost of creating an underground freeze wall to contain groundwater contamination had significantly escalated. Anyway, as the commercial scale production by Shell is not foreseen until 2025, the real price needed to make production economic remains unclear.\n\nAt full-scale production, the production costs for one barrel of light crude oil of the Australia's Stuart plant were projected to be in the range of $11.3 to $12.4 per barrel, including capital costs and operation costs over a projected 30-year lifetime. However, the project has been suspended due to environmental concerns.\n\nThe project of a new Alberta Taciuk Processor which was planned by VKG Oil, was estimated to achieve break-even financial feasibility operating at 30% capacity, assuming a crude oil price of $21 per barrel or higher. At 50% utilization, the project was expected to be economic at a price of $18 per barrel, while at full capacity, it could be economic at a price of $13 per barrel. However, instead of Alberta Taciuk Processor VKG proceeded with a Petroter retort which production price level is not disclosed. Production costs in China have been reported to be as low as less than $25 per barrel, although there is no recent confirmation of this figure.\n\nA comparison of the proposed American oil shale industry to the Alberta oil-sands industry has been drawn (the latter enterprise generated over of oil in late 2007), stating that \"the first-generation facility is the hardest, both technically and economically\". According to the United States Department of Energy, in 1980s the costs of a \"ex-situ\" processing complex ranged from $8–12 billion at 2005 prices. It is estimated that the current capital costs are $3–10 billion at 2005 prices.\n\nThe new 100,000 tonnes shale oil per year retort built by VKG cost EEK 1.1 billion (€70.3 million); however, it is located in the existing production site and uses the existing infrastructure.\n\nThe RAND Corporation assumes that the development of processing plant in the United States will take 12 years, while to achieve the level of will take at least 20 years and \naround 30 years.\n\nIn the second half of the 20th century, oil shale production ceased in Canada, Scotland, Sweden, France, Australia, Romania, and South Africa due to the low price of oil and other competitive fuels. In the United States, during the 1973 oil crisis businesses expected oil prices to stay as high as US$70 a barrel, and invested considerable sums in the oil shale industry. World production of oil shale reached a peak of 46 million tonnes in 1980. Due to competition from cheap conventional petroleum in the 1980s, several investments became economically unfeasible. On 2 May 1982, known as \"Black Sunday\", Exxon canceled its US$5 billion Colony Shale Oil Project near Parachute, Colorado because of low oil-prices and increased expenses. Because of the losses in 1980s, companies were reluctant to make new invests in shale oil production. However, in the early 21st century, USA, Canada and Jordan were planning or had started shale oil production test projects, and Australia was considering restarting oil shale production.\n\nIn a 1972 publication by the journal \"Pétrole Informations\" (ISSN 0755-561X), shale oil production was unfavorably compared to the liquefaction of coal. The article stated that coal liquefaction was less expensive, generated more oil, and created fewer environmental impacts than oil shale extraction. It cited a conversion ratio of of oil per one ton of coal, as against per one ton of shale oil.\n\nA measure of the viability of oil shale as a fuel source is the ratio of the energy produced to the energy used converting it (Energy Returned on Energy Invested - EROEI). The value of the EROEI for oil shale is difficult to calculate for a number of reasons. Lack of reliable studies of modern oil shale processes, poor or undocumented methodology and a limited number of operational facilities are the main reasons. Due to technically more complex processes, the EROEI for oil shale is below the EROEI of about 20:1 for conventional oil extraction at the wellhead.\n\nA 1984 study estimated the EROEI of the different oil shale deposits to vary between 0.7–13.3:1. More recent studies estimates the EROEI of oil shales to be 1–2:1 or 2–16:1 – depending on if self-energy is counted as a cost or internal energy is excluded and only purchased energy is counted as input. According to the World Energy Outlook 2010, the EROEI of \"ex-situ\" processing is typically 4–5:1 while of \"in-situ\" processing it may be even as low as 2:1. Royal Dutch Shell has reported an expected EROEI about 3–4:1 on its \"in-situ\" test project.\n\nInternal energy (or self-energy) is energy released by the oil shale conversion process that is used to power that operation (e.g. obtained by combustion of conversion by-products such as oil shale gas), and therefore reducing the use of other fuels (external energy). There are different views as to if the internal energy should be added to the calculation as cost or not. One opinion is that internal energy should not be counted as an energy cost because is does not have an opportunity cost, unlike external energy used in the process. Another opinion is that internal energy is used for performing useful work and therefore should be added to the calculation. It might also be argued that internal energy should be included as energy invested because it contributes to CO emissions. However, EROEI then becomes a measure of environmental acceptability rather than economic viability.\n\nDevelopment of oil shale resources will require significant quantities of water for mine and plant operations, reclamation, supporting infrastructure, and associated economic growth. Above-ground retorting typically consumes between one and five barrels of water per barrel of produced shale oil, depending on technology. For an oil shale industry producing , this equates to of water. These numbers include water requirements for power generation for in-situ heating processes, retorting, refining, reclamation, dust control and on-site worker demands. Municipal and other water requirements related to population growth associated with industry development will require an additional per day. Hence, a oil shale industry would require of water per year, depending on location and processes used.\n\nThe largest deposit of oil shale in the United States is in the Green River basin. Though scarce, water in the western United States is treated as a commodity which can be bought and sold in a competitive market. Royal Dutch Shell has been reported to be buying groundwater rights in Colorado as it prepares to drill for oil in the shale deposits there. In the Colorado Big-Thompson project, average prices per share (/share) increased from some $2,000 in 1990 to more than $12,000 in mid-2003 (constant 2001 dollars). CBT Prices from 2001 to 2006 has had a range of $10,000 to $14,000 per share, or $14,000 to $20,000 per acre foot. At $10,000 per acre foot, capital costs for water rights to produce would range between $1.8-4.2 billion.\n\nSeveral co-pyrolysis processes to increase efficiency of oil shale retorting have been proposed or tested. In Estonia, the co-pyrolysis of kukersite with renewable fuel (wood waste), as well as with plastic and rubber wastes (tyres), has been tested. Co-pyrolysis of oil shale with high-density polyethylene (HDPE) has been tested also in Morocco and Turkey. Israel's AFSK Hom Tov co-pyrolyses oil shale with oil refinery residue (bitumen). Some tests involve co-pyrolysis of oil shale with lignite and cellulose wastes. Depending on reaction conditions, the co-pyrolysis may lead to higher conversion ratios and thus lower production costs, and in some cases solves the problem of utilization of certain wastes.\n\n"}
{"id": "2199729", "url": "https://en.wikipedia.org/wiki?curid=2199729", "title": "Orosirian", "text": "Orosirian\n\nThe Orosirian Period (; , meaning \"mountain range\") is the third geologic period in the Paleoproterozoic Era and lasted from Mya to Mya (million years ago). Instead of being based on stratigraphy, these dates are defined chronometrically.\n\nThe later half of the period was an episode of intensive orogeny on virtually all continents.\n\nTwo of the largest known impact events on Earth occurred during the Orosirian. At the very beginning of the period, 2023 Mya, a large asteroid collision created the Vredefort impact structure. The event that created the Sudbury Basin structure occurred near the end of the period, 1850 Mya.\n\nFor the time period from about 2060 to 1780 Mya, an alternative period based on stratigraphy rather than chronometry, named the Columbian, was suggested in the geological timescale review 2012 edited by Gradstein et al., but , this has not yet been officially adopted by the IUGS.\n\nThe supercontinent Columbia formed at the end of this period.\n\n"}
{"id": "37124167", "url": "https://en.wikipedia.org/wiki?curid=37124167", "title": "Palma Aquarium", "text": "Palma Aquarium\n\nPalma Aquarium is a commercial aquarium and park that first opened in 2007 in Palma, Mallorca, Spain. The aquarium is the property of Coral World International. The aquarium is from Playa de Palma beach, and includes 55 tanks which are home to over 700 different species from the Mediterranean Sea and the Indian, Atlantic and Pacific Oceans. One tank, \"Big Blue\" is deep, the deepest shark tank in Europe, and it also contains the largest collection of live coral in Europe The park was awarded \"Best Business Initiative in the Balearics 2007\", awarded by Actualidad Económica magazine, and was awarded the \"2007 Accessibility Prize\" by the Consell de Mallorca.\n\nThe aquarium organises environmentally focused activities, and takes part in protection and conservation campaigns.\n\nPalma Aquarium has more than 400,000 visitors every year, with an average of over 1000 visitors a day. 50% of its visitors are local and national, while the rest are mainly of European origin. Palma Aquarium has received several awards, including the “Best Business Initiative in Balearics 2007” award, awarded by Actualidad Económica magazine and the “2007 Accessibility Award”, awarded by the Consell de Mallorca.\n\nA visit to the aquarium is presented as if it were a journey through the world’s seas and oceans.\n\nThe first stage of the \"journey\" shows Mediterranean marine fauna and flora including starfish, lobsters and slipper lobsters, scorpion fish, wrasses, groupers, prawns and shrimps, crabs, eels, rays, seahorses, octopuses, conger eels, algae and coral. Visitors can also have direct contact with some of these animals, such as the starfish, in the Touch Pools.\n\nThere are 25 aquariums in this section showing animals from the tropical parts of the Indian Ocean, Atlantic Ocean and Pacific Ocean. These animals include the fire fish, the clown fish, the black widow tetra, the surgeon fish, the blacktip reef shark, and bright colourful coral.\n\nThe Palma Aquarium live coral includes gorgonians, mushroom, fragile saucer and honeycomb; anemones such as the Carpet, Caribbean or the Long Tentacle; and a great variety of tropical sponges. It is one of the few aquariums in Europe where all the coral decorating the tanks is real and alive, and one of the few aquariums to have its own coral reproduction program, which has resulted in the birth of new coral colonies on site.\n\nThere is a garden area which combines Mediterranean plants with tanks containing turtles, koi fish, gilthead bream and stingrays. Also available here is a cafeteria and a children’s play area with a \"pirate ship\". During the summer, the park has children’s entertainment every day of the week, featuring face-painting, water fights and shows.\n\nThe Jungle area is designed to resemble a tropical rainforest. It is the largest roof-top garden in Spain, and one of the largest in Europe. A waterfall and several vaporizers create a humid atmosphere; a suitable microclimate for the Amazonian plants that grow there.\n\nThe Big Blue is the deepest shark tank in Europe, at deep, long and wide. The tank holds of saltwater.\n\nSix sand tiger sharks, 5 sandbar sharks and over 1000 fish live inside this tank. Visitors descend to the central aquarium’s observation area via a transparent tunnel, while sharks and rays swim over their heads.\n\nThe Jellyfish tank is a cylinder-shaped aquarium containing about fifty jellyfish almost all of which belong to the Mediterranean’s common species, \"Aurelia aurita\".\n\nA number of different activities are available:\n\nThe Palma Aquarium is home to over 700 different species from the Mediterranean Sea, and the Indian, Atlantic and Pacific Oceans.\n\nThe Mediterranean Sea:\n\nTropical Seas:\nMediterranean Gardens:\n\nBig Blue:\n\nJellyfish Tank:\n\nPalma Aquarium has a series of research and investigation programs including developing coral reef reproduction and rehabilitation programs within artificially controlled environments.\n\nThe park also runs a conservation campaign for the Mediterranean Blue Fin Tuna, a species which is in danger of extinction due to overfishing. The park also includes an exhibition on this theme.\n\nThe aquarium takes part in a conservation project for \"Limonium barceloi\", a species which is autochthonous to the southern Balearics.\nPalma Aquarium sometimes takes part in rescue and rehabilitation projects for marine animals. The research objectives are set out by collaboration agreements with universities and research centres in order to carry out recovery programmes with populations in regression or in danger of extinction.\n\nThe indoor path is , and the outdoor area is . There are 55 tanks containing of sea water. There are approximately 8,000 marine specimens in approximately 700 species. The aquarium is open every day of the year. There is a gift shop, a public car park of and an event room, which is m2 in size and has a standing capacity of 350 people.\n\n"}
{"id": "51176295", "url": "https://en.wikipedia.org/wiki?curid=51176295", "title": "Prayas (Energy Group)", "text": "Prayas (Energy Group)\n\nPrayas (Energy Group) is an Indian analysis and advocacy organisation working in the area of energy policy. It is part of a non-governmental charitable trust called Prayas (long name is \"Initiatives in Health, Energy and Parenthood\") located in Pune, India. The aim of Prayas is to make energy a tool for sustainable and equitable development for all citizens, by analysis, discourse building, policy and regulatory engagements and collaboration with other civil society organisations.\n\nPrayas was founded in 1994 by three professionals - two doctors and an engineer – with the aim of using professional skills to promote public interest, including that of disadvantaged sections of the society and of the environment. Prayas has four groups working on different sectors - health, energy, resources & livelihoods, and learning & parenthood.\n\nGirish Sant, an energy systems engineer, was the founder coordinator of Prayas. After he died in 2012, Shantanu Dixit became the group coordinator. Prayas’s first activities were in the area of renewable energy and energy efficiency. It later took up studies on the socioeconomic impacts of projects such as Dabhol Power Station promoted by Enron. With the advent of reforms in the Indian electricity sector, Prayas published reports on electricity and related energy sectors.\n\nPrayas works on governance, regulation and policy related aspects of electricity and energy sectors. There are four major areas of work, namely: Electricity generation & supply, Energy efficiency, Renewable energy and Energy, resources & development. It covers many Indian states and national issues. There are also a few international initiatives, undertaken with collaboration with other organisations. These include analysis of Bujagali hydro power project in Uganda, Electricity Governance Initiative and Electricity Supply Monitoring Initiative.\n\nWork outputs of Prayas include reports, guides and regulatory or policy submissions, all of which are available on its website. Some major outputs are, Analysis of Enron-Dabhol power project, Survey of Electricity Regulatory Commissions, Primer on Electricity, Solar Roof-Top Photovoltaics (PV) in India, Activist Guide for better electricity service, Challenges before the Indian Coal Sector and Energy Requirement for decent living. Prayas's outputs include newspaper articles on topics like Solar Options for Agriculture, Energy Efficiency and Clean Cooking Challenges. There are also presentations/interviews on topics like India energy challenges, Energy policy, and Indian energy sector trends.\n\nPrayas is a member of several official committees at the Central and State levels and has been knowledge partner to Central Government institutions such as NITI Aayog. Various commentators and reviewers have noted that the work of Prayas has contributed to improving governance and policy in the energy sector.\n\n"}
{"id": "14552", "url": "https://en.wikipedia.org/wiki?curid=14552", "title": "Primary sector of the economy", "text": "Primary sector of the economy\n\nAn industry involved in the extraction and collection of natural resources, such as copper and timber, as well as by activities such as farming and fishing. A company in a primary industry can also be involved in turning natural resources into products.\nPrimary industry tends to make up a larger portion of the economy of developing countries than they do for developed countries. See also service industry, secondary industry.\nThe primary sector is concerned with the extraction of raw materials. It includes fishing, farming and mining.\n\nPrimary industry is a larger sector in developing countries; for instance, animal husbandry is more common in countries in Africa than in Japan. Mining in 19th-century South Wales provides a case study of how an economy can come to rely on one form of activity.\n\nIn developed countries the primary industry has become more technologically advanced, for instance the mechanization of farming as opposed to hand picking and planting. In more developed countries, additional capital is invested in primary means of production. As an example, in the United States' corn belt, combine harvesters pick the corn, and sprayers spray large amounts of insecticides, herbicides and fungicides, producing a higher yield than is possible using less capital-intensive techniques. These technological advances and investment allow the primary sector to require less workforce and, this way, developed countries tend to have a smaller percentage of their workforce involved in primary activities, instead having a higher percentage involved in the secondary and tertiary sectors.\n\nDeveloped countries are allowed to maintain and develop their primary industries even further due to the excess wealth. For instance, European Union agricultural subsidies provide buffers for the fluctuating inflation rates and prices of agricultural produce. This allows developed countries to be able to export their agricultural products at extraordinarily low prices. This makes them extremely competitive against those of poor or underdeveloped countries that maintain free market policies and low or non-existent tariffs to counter them. Such differences also come about due to more efficient production in developed economies, given farm machinery, better information available to farmers, and often larger scale.\n\n\n\n"}
{"id": "9021642", "url": "https://en.wikipedia.org/wiki?curid=9021642", "title": "Solar Dynamics", "text": "Solar Dynamics\n\nSolar Dynamics Barbados Ltd is one of the leading Barbados-based manufacturers of solar hot water systems in the Caribbean region. The company which has been in existence for over 33 years was established in 1972 by its current Managing Director James Husbands.\n\nThe company claims to have installed over 30,000 solar hot water systems on homes and businesses mainly across the Caribbean region.\n\nJust after Barbados' national independence from Britain, the prime minister Errol Barrow and government of Barbados gave staunch support to the solar energy sector of Barbados. This move by the government made Solar Dynamics one of the country's priorities in terms of moving the island forward.\n\n\n"}
{"id": "666667", "url": "https://en.wikipedia.org/wiki?curid=666667", "title": "South Pacific Applied Geoscience Commission", "text": "South Pacific Applied Geoscience Commission\n\nThe Pacific Islands Applied Geoscience Commission (SOPAC) was an inter-governmental regional organisation dedicated to providing services to promote sustainable development in the countries it serves. In 2010, its functions had been transferred to the Secretariat of the Pacific Community (SPC) and the Pacific Regional Environment Programme (SPREP), thus ending SOPAC as a separate entity. Today, SOPAC is a division of the SPC with its main office in Suva, Fiji.\n\nSOPAC was created by the conclusion of a 1990 multilateral treaty known as the Agreement establishing the South Pacific Applied Geoscience Commission. The treaty was concluded and signed on 10 October 1990 in Tarawa, Kiribati. It was signed by representatives of the governments of Australia, Cook Islands, Fiji, Guam, Federated States of Micronesia, Kiribati, Marshall Islands, New Zealand, Papua New Guinea, Solomon Islands, Tonga, Tuvalu, Vanuatu, and Western Samoa.\n\nSince SOPAC's foundation, American Samoa, France, French Polynesia, Nauru, New Caledonia, Niue, Northern Mariana Islands, Palau, Pitcairn Islands, Tokelau, United States, and Wallis and Futuna have accepted the Agreement and thereby joined SOPAC.\n\nSOPAC focuses on assisting SPC members in three key program areas, Ocean and Islands, Community Lifelines and Community Risk.\n\nBenefits accrue to SPC members directly through provision of basic geological knowledge and indirectly, through improvements in land and ocean use, leading to improved health through water and sanitation provision, wealth generation through the development of mineral resources, hazard and disaster management and sustainable development by taking into account the geo-environmental impacts of development.\n\nAny island member can request assistance from SOPAC which is funded by member-country contributions and supported by the following donors: Australia, Fiji, Canada, France, Ireland, Japan, New Zealand, the Office of US Foreign Disaster Assistance, Taiwan, the United Kingdom, the Commonwealth Secretariat, the European Union, and certain UN agencies.\n\n\n\n"}
{"id": "13771622", "url": "https://en.wikipedia.org/wiki?curid=13771622", "title": "Sting jet", "text": "Sting jet\n\nA sting jet is a meteorological phenomenon which has been postulated to cause some of the most damaging winds in extratropical cyclones, developing according to the Shapiro-Keyser model of oceanic cyclones.\n\nFollowing reanalysis of the Great Storm of 1987, led by Professor Keith Browning at the University of Reading, researchers identified a mesoscale flow where the most damaging winds were shown to be emanating from the evaporating tip of the hooked cloud head on the southern flank of the cyclone. This cloud, hooked like a scorpion's tail, gives the wind region its name the \"sting jet\".\n\nIt is thought that a zone of strong winds, originating from within the mid-tropospheric cloud head of an explosively deepening depression, are enhanced further as the \"jet\" descends, drying out and evaporating a clear path through snow and ice particles. The evaporative cooling leading to the air within the jet becoming denser, leading to an acceleration of the downward flow towards the tip of the cloud head when it begins to hook around the cyclone centre. Windspeeds in excess of 80 kn (150 km/h) can be associated with the sting jet.\n\nIt has since been reproduced in high-resolution runs with the mesoscale version of the Unified Model. The sting jet is distinct from the usual strong-wind region associated with the warm conveyor belt and main cold front. There are indications that conditional symmetric instability also plays a role in its formation but the importance of these processes remains to be quantified.\n\nOne North Atlantic storm, Cyclone Tilo (November 6–11, 2007) has also been analysed and found not to display a sting jet, despite displaying strong surface winds and a fractured cold front.\n\nThe sting jet mechanism has been considered less significant in Pacific Northwest windstorms which occur over the Pacific Ocean (which impact the Northwestern United States and British Columbia). Evidence of mesoscale high wind areas has not been noted in most large windstorms occurring there, along with cloud geometry associated with the phenomena being absent in satellite imagery of major Pacific Northwest storms. Although a case study of a sting jet in the region has been produced. High resolution computer models of the phenomena have also shown realistically strong winds without the need for sting jet dynamics.\n\n\n"}
{"id": "145810", "url": "https://en.wikipedia.org/wiki?curid=145810", "title": "Susan Blackmore", "text": "Susan Blackmore\n\nSusan Jane Blackmore (born 29 July 1951) is a British writer, lecturer, sceptic, broadcaster, and a Visiting Professor at the University of Plymouth. Her fields of research include memes, evolutionary theory, psychology, parapsychology, consciousness, and she is best known for her book \"The Meme Machine\". She has written or contributed to over 40 books and 60 scholarly articles and is a contributor to \"The Guardian\" newspaper.\n\nIn 1973, Susan Blackmore graduated from St Hilda's College, Oxford, with a BA (Hons) degree in psychology and physiology. She received an MSc in environmental psychology in 1974 from the University of Surrey. In 1980, she earned a PhD in parapsychology from the same university; her doctoral thesis was entitled \"Extrasensory Perception as a Cognitive Process.\" In the 1980s, Blackmore conducted psychokinesis experiments to see if her baby daughter, Emily, could influence a random number generator. The experiments were mentioned in the book to accompany the TV series \"Arthur C. Clarke's World Of Strange Powers\". Blackmore taught at the University of the West of England in Bristol until 2001. After spending time in research on parapsychology and the paranormal, her attitude towards the field moved from belief to scepticism. In 1987, Blackmore wrote that she had an out-of-body experience shortly after she began running the Oxford University Society for Psychical Research (OUSPR):\n\nWithin a few weeks I had not only learned a lot about the occult and the paranormal, but I had an experience that was to have a lasting effect on me—an out-of-body experience (OBE). It happened while I was wide awake, sitting talking to friends. It lasted about three hours and included everything from a typical \"astral projection,\" complete with silver cord and duplicate body, to free-floating flying, and finally to a mystical experience.\nIt was clear to me that the doctrine of astral projection, with its astral bodies floating about on astral planes, was intellectually unsatisfactory. But to dismiss the experience as \"just imagination\" would be impossible without being dishonest about how it had felt at the time. It had felt quite real. Everything looked clear and vivid, and I was able to think and speak quite clearly.\n\nIn a \"New Scientist\" article in 2000, she again wrote of this:\n\nIt was just over thirty years ago that I had the dramatic out-of-body experience that convinced me of the reality of psychic phenomena and launched me on a crusade to show those closed-minded scientists that consciousness could reach beyond the body and that death was not the end. Just a few years of careful experiments changed all that. I found no psychic phenomena—only wishful thinking, self-deception, experimental error and, occasionally, fraud. I became a skeptic.\n\nIn an article in \"The Observer\" on sleep paralysis Barbara Rowland wrote that Blackmore, \"carried out a large study between 1996 and 1999 of 'paranormal' experiences, most of which clearly fell within the definition of sleep paralysis.\"\n\nShe is a Fellow of the Committee for Skeptical Inquiry (formerly CSICOP) and in 1991, was awarded the CSICOP Distinguished Skeptic Award.\n\nBlackmore has done research on memes (which she wrote about in her popular book \"The Meme Machine\") and evolutionary theory. Her book \"Consciousness: An Introduction\" (2004), is a textbook that broadly covers the field of consciousness studies. She was on the editorial board for the \"Journal of Memetics\" (an electronic journal) from 1997 to 2001, and has been a consulting editor of the \"Skeptical Inquirer\" since 1998.\n\nShe acted as one of the psychologists who was featured on the British version of the television show \"Big Brother\", speaking about the psychological state of the contestants. She is a Patron of Humanists UK.\n\nBlackmore debated Christian apologist Alister McGrath in 2007, on the existence of God. In 2018 she debated Jordan Peterson on whether God is needed to make sense of life.\n\nIn 2017, Blackmore appeared at the 17th European Skeptics Congress (ESC) in Old Town Wrocław, Poland. This congress was organised by the Klub Sceptyków Polskich (Polish Skeptics Club) and Český klub skeptiků Sisyfos (Czech Skeptic’s Club). At the congress she joined Scott Lilienfeld, Zbyněk Vybíral and Tomasz Witkowski on a panel on skeptical psychology which was chaired by Michael Heap.\n\nSusan Blackmore has made contributions to the field of memetics. The term \"meme\" was coined by Richard Dawkins in his 1976 book \"The Selfish Gene\". In his foreword to Blackmore's book \"The Meme Machine\" (1999), Dawkins said, \"Any theory deserves to be given its best shot, and that is what Susan Blackmore has given the theory of the meme.\" Other treatments of memes, that cite Blackmore, can be found in the works of Robert Aunger: \"The Electric Meme\", and Jonathan Whitty: \"A Memetic Paradigm of Project Management\".\n\nBlackmore's treatment of memetics insists that memes are true evolutionary replicators, a second replicator that like genetics is subject to the Darwinian algorithm and undergoes evolutionary change. Her prediction on the central role played by imitation as the cultural replicator and the neural structures that must be unique to humans in order to facilitate them have recently been given further support by research on mirror neurons and the differences in extent of these structures between humans and the presumed closest branch of simian ancestors.\n\nAt the February 2008 TED conference, Blackmore introduced a special category of memes called \"temes\". Temes are memes which live in technological artifacts instead of the human mind.\n\nBlackmore has written critically about both the flaws and redeeming qualities of religion, having said, All kinds of infectious memes thrive in religions, in spite of being false, such as the idea of a creator god, virgin births, the subservience of women, transubstantiation, and many more. In the major religions, they are backed up by admonitions to have faith not doubt, and by untestable but ferocious rewards and punishments.\"\n\n...most religions include at least two aspects which I would be sorry to lose. First is the truths that many contain in their mystical or spiritual traditions; including insights into the nature of self, time and impermanence [...] The other is the rituals that we humans seem to need, marking such events as birth, death, and celebrations. Humanism provides a non-religious alternative and I have found the few such ceremonies I have attended to be a refreshing change from the Christian ones of my upbringing. I am also glad that these ceremonies allow for an eclectic mixture of songs, music and words. In spite of my lack of belief I still enjoy the ancient hymns of my childhood and I know others do too. We can and should build on our traditions rather than throwing out everything along with our childish beliefs.\n\nOn 16 September 2010, Blackmore wrote in \"The Guardian\" that she no longer refers to religion simply as a \"virus of the mind\", \"unless we twist the concept of a 'virus' to include something helpful and adaptive to its host as well as something harmful, it simply does not apply.\" Blackmore modified her position when she saw beneficial effects of religion, such as data correlating higher birth rates with the frequency of religious worship, and that \"religious people can be more generous, and co-operate more in games such as the Prisoner's Dilemma, and that priming with religious concepts and belief in a 'supernatural watcher' increase the effects\".\n\nBlackmore is spiritual, an atheist, a humanist, and a practitioner of Zen, although she identifies herself as \"not a Buddhist\" because she is not prepared to go along with any dogma. In regards to her personal views on consciousness, she considers herself to be an illusionist; she believes phenomenal consciousness is an \"illusion\" and \"grand delusion\". Blackmore is a patron of Humanists UK.\n\nOn 15 September 2010, Blackmore, along with 54 other public figures, signed an open letter published in \"The Guardian\", stating their opposition to Pope Benedict XVI's state visit to the UK. \n\nShe is married to the writer Adam Hart-Davis. Blackmore endured a bout of chronic fatigue syndrome in 1995.\n\n\n\n"}
{"id": "53715", "url": "https://en.wikipedia.org/wiki?curid=53715", "title": "Taos Pueblo", "text": "Taos Pueblo\n\nTaos Pueblo (or Pueblo de Taos) is an ancient pueblo belonging to a Taos-speaking (Tiwa) Native American tribe of Puebloan people. It lies about north of the modern city of Taos, New Mexico. The pueblos are considered to be one of the oldest continuously inhabited communities in the United States. This has been designated a UNESCO World Heritage Site.\n\nTaos Pueblo is a member of the Eight Northern Pueblos, whose people speak two variants of the Tanoan language. The Taos community is known for being one of the most private, secretive, and conservative pueblos. Natives will almost never speak of their religious customs to outsiders, and because their language has never been written down, much of the culture remains unknown to the rest of the world. A reservation of is attached to the pueblo, and about 4,500 people live in this area.\n\nThe pueblo was constructed in a setting backed by the Taos Mountains of the Sangre de Cristo Range. The settlement was built on either side of Rio Pueblo de Taos, also called Rio Pueblo and Red Willow Creek, a small stream that flows through the middle of the pueblo compound. Its headwaters come from the nearby mountains. \n\nTaos Pueblo's most prominent architectural feature is a multi-storied residential complex of reddish-brown adobe, built on either side of the Rio Pueblo. The Pueblo's website states it was probably built between 1000 and 1450.\n\nThe pueblo was designated a National Historic Landmark on October 9, 1960. In 1992 it was designated as a UNESCO Heritage Site. As of 2006, about 150 people live in the historic complex full-time.\n\nIn the Tanoan language of Taos (Northern Tiwa), the pueblo is referred to as \"the village\" in either \"tə̂otho\" \"in the village\" (\"tə̂o-\" \"village\" + \"-tho\" \"in\") or \"tə̂obo\" \"to/toward the village\" (\"tə̂o-\" \"village\" + \"-bo\" \"to, toward\"). The proper name of the pueblo is \"ȉałopháymųp’ȍhə́othə̀olbo\" \"at red willow canyon mouth\" (or \"ȉałopháybo\" \"at the red willows\" for short). This name is more commonly used in ceremonial contexts and is less common in everyday speech.\n\nThe name \"Taos\" in English was borrowed from Spanish \"Taos\". Spanish \"Taos\" is probably a borrowing of Taos \"tə̂o-\" \"village\" which was heard as \"tao\" to which the plural \"-s\" was added although in the modern language \"Taos\" is no longer a plural noun. The idea that the Spanish \"Taos\" is from \"tao,\" \"cross of the order of San Juan de los Caballeros\" (from Greek \"tau\"), is unlikely.\n\nMost archeologists believe that the Taos Indians, along with other Pueblo Indians, settled along the Rio Grande after migrating south from the Four Corners region. The dwellings of that region were inhabited by the Ancestral Puebloans. A long drought in the area in the late 13th century may have caused them to move to the Rio Grande, where the water supply was more dependable. However, their reason for migrating is still disputed and there is evidence that a violent struggle took place. Ultimately, archeological clues point to the idea that the Natives may have been forced to leave.\n\nThroughout its early years, Taos Pueblo was a central point of trade between the native populations along the Rio Grande and their Plains Tribes neighbors to the northeast. Taos Pueblo hosted a trade fair each fall after the agricultural harvest.\n\nThe first Spanish visitors to Taos Pueblo arrived in 1540; they were members of the Francisco Vásquez de Coronado expedition, which stopped at many of New Mexico's pueblos in search of the rumored Seven Cities of Gold. Around 1620, Spanish Jesuits oversaw construction of the first Catholic Church in the pueblo, the mission of San Geronimo de Taos. Reports from the period indicate that the native people of Taos resisted the building of the church and imposition of the Catholic religion. Throughout the 1600s, cultural tensions grew between the native populations of the Southwest and the increasing Spanish colonial presence. Taos Pueblo was no exception. By 1660, the native people killed the resident priest and destroyed the church. Several years after it was rebuilt, the Pueblo Revolt of 1680 began; the Taos destroyed the church and killed two resident priests.\n\nBy the turn of the 18th century, San Geronimo de Taos was under construction for a third time. Spanish/Taos relations within the pueblo became amicable for a brief period as both groups found a common enemy in invading Ute and Comanche tribes. Resistance to Catholicism and Spanish culture was still strong. Even so, Spanish religious ideals and agricultural practices subtly worked their way into the Taos community, largely starting during this time of increased cooperation between the two cultural groups.\n\nThe Taos revolt began before the conclusion of the Mexican–American War in 1847. A Mexican Pablo Montoya and Tomasito, a leader at Taos Pueblo, led a force of Mexicans and Taos who did not want to become a part of the United States. They killed Governor Charles Bent and others and marched on Santa Fe. The revolt was suppressed after the rebels took refuge in San Geronimo Mission Church. The American troops bombarded the church, killing or capturing the insurrectionists and destroying the physical structure. Around 1850, a new mission church was constructed near the west gate of the pueblo wall. The ruins of the original church and its 1850s replacement are both still visible inside the pueblo wall today. Father Anton Docher first served as a priest in Taos before his years in Isleta, where he became known as \"The Padre of Isleta\".\n\nIn 1924-25 the Taos Pueblo culture was studied by German psychiatrist Carl Jung, who visited the Pueblo led by Ochwiay Biano. He was very interested in indigenous societies as he believed they were more closely in touch with archetypes. \n\nThe Pueblo's of mountain land was taken by President Theodore Roosevelt and designated as the Carson National Forest early in the 20th century. It was finally returned in 1970 by the United States when President Nixon signed Public Law 91-550. An additional south of the ridge between Simpson Peak and Old Mike Peak and west of Blue Lake were transferred back to the Pueblo in 1996.\n\nBlue Lake, which the people of the Pueblo consider sacred, was included in this return of Taos land. The Pueblo notably involved non-native people in lobbying the federal government for the return of Blue Lake, as they argued that their unrestricted access to the lake and the surrounding region was necessary to ensure their religious freedom. The Pueblo's web site names the reacquisition of the sacred Blue Lake as the most important event in its history due to the spiritual belief that the Taos people originated from the lake. It is believed that their ancestors live there, and the pueblos themselves only ascend the mountain twice a year.\n\nAt the time of the Spaniards' initial contact, Hernando de Alvarado described the pueblo as having adobe houses built very close together and stacked five or six stories high. The homes became narrower as they rose, with the roofs of each level providing the floors and terraces for those above.\n\nThe buildings at Taos originally had few windows and no standard doorways. Instead, access to rooms was through square holes in the roof that the people reached by climbing long, wooden ladders. Engelmann Spruce logs (or \"vigas\") supported roofs that had layers of branches, grass, mud, and plaster covering them. The architecture and the building materials were well suited for the rigors of the environment and the needs of the people in the Taos Valley. It should be noted that prior to the arrive of Coronado, all Taos Pueblo walls were constructed using balls of adobe ( clay ) about the size of a 'soft ball', Coronado introduced the technique of the formed mud brick, this technique revolutionized adobe construction in the new world. Coronado also changed the roof structure, to use 2\" to 4\" inch aspen saplings branches installed at a right angle to the Engelmann Spruce vigas, then 2\" to 3\" inches of adobe plaster was applied, topped off with up to half a meter of loose soil ( about 18\" inches thick ) for insulation and structural strength. Thus indigenous architecture evolved.\n\nThe first Spanish-influenced architecture appeared in Taos Pueblo after Fray Francisco de Zamora came there in 1598 to establish a mission, under orders from Spanish Governor, Don Juan de Oñate.\n\nThe north-side Pueblo is said to be one of the most photographed and painted buildings in North America. It is the largest multistoried Pueblo structure still existing. It is made of adobe walls that are often several feet thick. Its primary purpose was for defense. Up to as late as 1900, access to the rooms on lower floors was by ladders on the outside to the roof, and then down an inside ladder. In case of an attack, outside ladders could easily be pulled up.\n\nThe homes in this structure usually consist of two rooms, one of which is for general living and sleeping, and the second of which is for cooking, eating, and storage. Each home is self-contained; there are no passageways between the houses. Taos Indians made little use of furniture in the past, but today they have tables, chairs, and beds. In the pueblo, electricity, running water, and indoor plumbing are prohibited.\n\nTwo spiritual practices are represented in the Pueblo: the original indigenous spiritual and religious tradition and Roman Catholicism. The majority of Taos Indians practice their still-vital, ancient indigenous religion. Most (90%) members of the Taos Pueblo community are baptized as Roman Catholics. Saint Jerome, or San Geronimo, is the patron saint of the pueblo.\n\n\n\n"}
{"id": "1965462", "url": "https://en.wikipedia.org/wiki?curid=1965462", "title": "Tropical rain belt", "text": "Tropical rain belt\n\nRainfall and the tropical climate dominate the tropical rain belt, which oscillates from the northern to the southern tropics over the course of the year, roughly following the solar equator. The tropical rain belt is an area of active rain that is positioned mostly around the tropics. According to the website Journey North, the reason the rain belt is situated near the tropics can be attributed to the fact that most of the sun’s radiation is directed toward the equator, which is located in the middle of the tropics. This solar radiation generates large amounts of heat near the equator providing tropical regions with higher temperatures than most other regions on Earth.\n\nWith all this solar radiation, the air around the tropics begins to warm up. Because hot air is less dense than cold air, the hot air rises into the upper levels of the atmosphere and as a result, cold air filters down into the lower levels of the atmosphere. The dynamics that provide the tropics with the rain belt are founded on the principle that warmer air is able to retain more moisture than colder air. When the colder air replaces the warmer air in the lower atmosphere, the abundant moisture from the tropics loses the ability to be stored in the atmosphere. As a result, the excess moisture that cannot be held by the colder air is then turned into thunderstorms and rain showers. These thunderstorms and rain showers are usually located along the equator, but they will extend out to the Tropic of Cancer, which is the 23.5 north latitude, as well as the Tropic of Capricorn, which is the 23.5 south latitude. It is largely a manifestation of the ITCZ (pronounced \"itch\"). \n\nThe tropical rain belt lies in the southern hemisphere of the Indian ocean and western Pacific ocean roughly from October to March, and during this time the northern tropics experience a dry season in which precipitation is very rare, and days are typically hot and sunny throughout. From April to September, the rain belt lies in the northern hemisphere, and a wet season occurs there, while the southern tropics experience their dry season.\n\nThe rain belt reaches roughly as far north as the Tropic of Cancer and as far south as the Tropic of Capricorn in the western Pacific ocean. Its variation in the Western Hemisphere is minimal, roughly between the equator and the 15th parallel north latitude. Near these latitudes, there is one wet season and one dry season annually. On the equator, there are two wet and two dry seasons as the rain belt passes over twice a year, one moving north and one moving south. Between the tropics and the equator, locations may experience both a short wet and a long wet season. Local geography may substantially modify these climate patterns.\n\nAs the earth warms, the rain belt is projected to move north of the current position. Recent climate change can be attributed to rising carbon dioxide concentrations in the atmosphere; caused by the burning of fossil fuels. The correlation between the concentration of carbon dioxide in the atmosphere and average global temperature is undeniably direct, meaning that as more carbon dioxide is released into the atmosphere, the temperature of the earth is expected to rise as well. Even though the earth is warming as a whole entity, the Northern Hemisphere is warming faster than the Southern because of melting Arctic sea ice. \n\nAs the Northern Hemisphere warms, a temperature gradient is established between the Northern and Southern hemispheres. The warmer temperatures in the Northern parts of the tropics foster an environment more conducive to the development of moisture. The additional moisture is met with a low level atmosphere that is cooler because the warm air has risen to the higher levels of the atmosphere. This scenario leads to increased precipitation and is a fundament behind the idea that the rain belt is moving north. The contrast in temperature is only a part of the entire process that is driving the tropical rain belt northward. Another factor that influences the tropical rain belt is ocean circulation. Ocean Overturning Circulation is a process that involves ocean circulation between the Antarctic and Arctic regions. \n\nDargan Frierson explains that in this process, the Northern Hemisphere receives more heat than the Southern because the overturning circulation brings more heat into the Northern Hemisphere as opposed to the Southern. He also states that as a result, the extra heat is transferred to the tropical regions in the Northern Hemisphere, causing warm ocean water to be situated in the northern tropics. This warm ocean water is what eventually generates rain and thunderstorms, and because there is more warm water in the northern tropics, it is obvious that the tropical rain belt is moving northward. Due to global climate change, the circulation of ocean currents and ocean temperatures might adjust in favor of pushing the belt further north into the region of oscillation.\n\nHowever, there is also the possibility that climate change will slow down ocean currents and circulation, which can change the present-day dynamic and send the rain belt to the south. Therefore, ocean circulation, ocean temperature, and the temperature of the earth are all attributing to the movement of the tropical rain belt. It is evident that the trend is northward and the belt is currently situated in the northern tropics, but the possibility of southward movement does exist. The northward movement does affect many countries and crops because the tropical rain belt is essential to food production in areas that rely on heavy precipitation.\n\nThe tropical regions will be affected most by the northward movement of the rain. The banana and coffee crops in Guatemala and Indonesia will become compromised by the loss of precipitation. In addition, the effects of a drier climate in Mexico could push the Mexican desert into southern portions of Texas, New Mexico and other areas in the southern U.S. Areas in the Middle East, Western America, and the Amazon rainforest risk the possibility of becoming drier and less humid. In contrast, the northward trend could bring more rain to areas in Asia already exposed to monsoons.\n\nAn increase of moisture in monsoon prone areas could be catastrophic as massive floods could follow the large amounts of rain added to preexisting rain from monsoons. Using geographical information, it is possible that the northward move of the rain belt is already evident because of droughts in the western US, Syria and northern China. Although the possible adversarial effects of the movement can be devastating, the northward movement of the rain belt could bring an increase of rain to areas that have been decimated by droughts, which could prove to be very beneficial.\n"}
{"id": "4041499", "url": "https://en.wikipedia.org/wiki?curid=4041499", "title": "Upper Gangetic Plains moist deciduous forests", "text": "Upper Gangetic Plains moist deciduous forests\n\nThe Upper Gangetic Plains moist deciduous forests is a tropical moist broadleaf forest ecoregion of northern India. \n\nIt lies on the alluvial plain of the Ganges and Yamuna rivers, with an area of , covering most of the state of Uttar Pradesh and adjacent portions of Uttarakhand, Haryana, Madhya Pradesh and Bihar. \n\nThe ecoregion is bounded on the north by the Himalayan subtropical pine forests, Terai-Duar savannas and grasslands and Himalayan subtropical broadleaf forests of the Himalaya foothills, to the west by the drier Northwestern thorn scrub forests and Kathiarbar-Gir dry deciduous forests, on the south by the Narmada Valley dry deciduous forests of the Malwa and Bundelkhand uplands, and on the east by the more humid Lower Gangetic plains moist deciduous forests.\n\nThe ecoregion has a tropical climate. Rainfall is highly seasonal, falling mainly during the June-to-September southwest monsoon.\n\nIn ancient times the region was mostly forested, with sal \"(Shorea robusta)\" the predominant tree. Many trees lose their leaves during the winter dry season. The ecoregion is currently densely populated, and the fertile plains have largely been converted to intensive agriculture, with only a few enclaves of forest remaining.\n\nProtected areas within the Upper Gangetic Plains moist deciduous forests ecoregion include:\n\n"}
{"id": "5656862", "url": "https://en.wikipedia.org/wiki?curid=5656862", "title": "World Rugby Rankings", "text": "World Rugby Rankings\n\nThe World Rugby Rankings (formerly the IRB Rankings) is a ranking system for men's national teams in rugby union, managed by World Rugby, the sport's governing body. The teams of World Rugby's member nations are ranked based on their game results, with the most successful teams being ranked highest. A point system is used, with points being awarded on the basis of the results of World Rugby-recognized international matches. Rankings are based on a team's performance, with more recent results and more significant matches being more heavily weighted to help reflect the current competitive state of a team. The ranking system was introduced the month before the 2003 Rugby World Cup, with the first new rankings issued on 8 September 2003.\n\nWhen the system was introduced England were the top team and maintained that position following victory in the 2003 Rugby World Cup. New Zealand took the lead from 7 June 2004. After winning the 2007 Rugby World Cup final, South Africa became the third team to achieve first place. The first two fixtures of the 2008 Tri Nations resulted in the top two teams switching places: the All Blacks regained the top spot after defeating South Africa in the Tri-Nations opener on 5 July 2008 in Wellington; a week later the Springboks returned the favour in Dunedin, scoring their first win over the All Blacks in New Zealand since 1998, reclaiming the top spot, only for the All Blacks to defeat both Australia and South Africa in August 2008 to regain the top spot by a considerable margin. South Africa regained the lead in July 2009 after beating New Zealand in Bloemfontein and kept the lead until losing to France in November of that year, allowing the All Blacks to regain the top spot.\n\nNew Zealand have been the most consistently ranked #1 team since the introduction of IRB World Rankings, having held the #1 ranking for more than 85 percent of the time during this period. South Africa and England make up the remainder.\n\nBelow is a list of the best and worst ranking positions for nations that have appeared in the Rugby World Cup:\nAll World Rugby member countries have been given a rating that is in the range of 0 to 100 with the top side achieving a rating of about 90 points. The point system is calculated using a 'Points Exchange' system, in which sides receive points from each other on the basis of the match result – whatever one side gains, the other loses. The exchanges are based on the match result, the ranking of each team, and the margin of victory, with an allowance for home advantage. As the system aims to depict current team strengths, past successes or losses will fade and be superseded by more recent results. Thus, it is thought that it will produce an accurate picture depicting the actual current strength and thus rank of the nations. The rankings are responsive to results and it is possible to climb to the top from the bottom (and vice versa) in fewer than 20 matches. As all matches are worth a net of 0 points for the two teams combined, there is no particular advantage to playing more matches. A rating stays the same until the team plays again. Although matches often result in points exchanges, 'predictable' results lead to very minor changes, and may result in no change to either side's rating.\n\nThe system ensures that it is representative of the teams' performance despite playing differing numbers of matches per annum, and the differing strength of opposition that teams have to face. The factors taken into account are as follows:\n\nFor each match played points exchanges are awarded for the following five outcomes and was developed using results of international matches from 1871 to the present day: \n\nDifferent matches have different importance to teams, and World Rugby has tried to respect this by using a weighting system, where the most significant matches are in the World Cup Finals. Points exchanges are doubled during the World Cup Finals to recognise the unique importance of this event. All other full international matches are treated the same, to be as fair as possible to countries playing a different mix of friendly and competitive matches. Matches that do not have full international status do not count.\n\nA win against a very highly ranked opponent is a considerably greater achievement than a win against a low-rated opponent, so the strength of the opposing team is a factor. Thus match results are more important than margins of victory in producing accurate rankings. This is because when a highly ranked team plays a lowly ranked team and manages to beat them by over 50 points, it does not necessarily indicate how either team will perform in the future.\n\nWhen calculating points exchanges, the home side is handicapped by treating them as though they are three rating points better than their current rating. This results in the home side gaining fewer points for winning and losing more points for losing. Because of this, ideally, any advantage that a side may have by playing in front of their home crowd is cancelled out.\n\nAll new member nations start with 30.00 points, which is provisional until they have completed ten test matches. When countries merge, the new country inherits the higher rating of the two countries but when they split e.g., the 2010 breakup of the Arabian Gulf rugby union team into separate teams representing its current member countries, the new countries will inherit a rating at a fixed level below the rating of the original country.\n\nBefore 1 December 2012 new member nations were given 40.00 points.\n\nCountries that have not played a test for two years are removed from the ranking system and the list. If they become active again, they resume their previous rating.\n\n<nowiki>***</nowiki>For a full explanation of how rankings are calculated, see the World Rugby rankings website.\n\n"}
