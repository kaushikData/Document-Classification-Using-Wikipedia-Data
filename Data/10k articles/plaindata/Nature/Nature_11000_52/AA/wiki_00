{"id": "13775535", "url": "https://en.wikipedia.org/wiki?curid=13775535", "title": "Bahia coastal forests", "text": "Bahia coastal forests\n\nThe Bahia coastal forests are a tropical moist broadleaf forest ecoregion of eastern Brazil, part of the larger Atlantic Forest region.\n\nThe Bahia coastal forests occupy a belt approximately wide along the Atlantic coast of eastern Brazil, in the states of Bahia and Espirito Santo. The Itapicuru River forms the northern boundary of the ecoregion, which extends south to near the Itapemirim River. The ecoregion is bounded on the east by the Atlantic Ocean and the enclaves of the Atlantic Coast restingas forests and Bahia mangroves. To the west, the forests transition to the drier Bahia interior forests.\n\nThe forests cover Tertiary sedimentary plateaus extending from near the seacoast westward to the lower slopes of the Serra da Mantiqueira. The prevalent soils are tropical nutrient-poor yellow-red latosol and podzols.\n\nThe ecoregion has a tropical climate with annual rainfall ranging from 1,200 to 1,800 mm, evenly distributed throughout the year. The southern portion of the ecoregion may experience a dry period from May through September.\n\nThe four-tiered Atlantic evergreen moist forests are the predominant vegetation type.\n\nEndangered mammals in the ecoregion include the maned three-toed sloth (\"Bradypus torquatus\") and golden-headed lion tamarin (\"Leontopithecus chrysomelas\").\n\nLess than 5% of the original forest cover remains intact. Protected areas in the ecoregion include Sooretama Biological Reserve and Linhares Forest Reserve.\n\n"}
{"id": "3044493", "url": "https://en.wikipedia.org/wiki?curid=3044493", "title": "Carbonate compensation depth", "text": "Carbonate compensation depth\n\nCalcite compensation depth (CCD) is the depth in the oceans below which the rate of supply of calcite (calcium carbonate) lags behind the rate of solvation, such that no calcite is preserved. Aragonite compensation depth (hence ACD) describes the same behaviour in reference to aragonitic carbonates. Aragonite is more soluble than calcite, so the aragonite compensation depth is generally shallower than the calcite compensation depth.\n\nCalcium carbonate is essentially insoluble in sea surface waters today. Shells of dead calcareous plankton sinking to deeper waters are practically unaltered until reaching the lysocline where the solubility increases dramatically. By the time the CCD is reached all calcium carbonate has dissolved according to this equation:\n\nCalcareous plankton and sediment particles can be found in the water column above the CCD. If the sea bed is above the CCD, bottom sediments can consist of calcareous sediments called calcareous ooze, which is essentially a type of limestone or chalk. If the exposed sea bed is below the CCD tiny shells of CaCO will dissolve before reaching this level, preventing deposition of carbonate sediment. As the sea floor spreads, thermal subsidence of the plate, which has the effect of increasing depth, may bring the carbonate layer below the CCD; the carbonate layer may be prevented from chemically interacting with the sea water by overlying sediments such as a layer of siliceous ooze or abyssal clay deposited on top of the carbonate layer.\n\nThe exact value of the CCD depends on the solubility of calcium carbonate which is determined by temperature, pressure and the chemical composition of the water – in particular the amount of dissolved in the water. Calcium carbonate is more soluble at lower temperatures and at higher pressures. It is also more soluble if the concentration of dissolved is higher. Adding a reactant to the above chemical equation pushes the equilibrium towards the right producing more products: Ca and HCO, and consuming more reactants and calcium carbonate according to Le Chatelier's principle.\n\nAt the present time the CCD in the Pacific Ocean is about 4200–4500 metres except beneath the equatorial upwelling zone, where the CCD is about 5000 m. In the temperate and tropical Atlantic Ocean the CCD is at approximately 5000 m. In the Indian Ocean it is intermediate between the Atlantic and the Pacific at approximately 4300 meters. The variation in the depth of the CCD largely results from the length of time since the bottom water has been exposed to the surface; this is called the \"age\" of the water mass. Thermohaline circulation determines the relative ages of the water in these basins. Because organic material, such as fecal pellets from copepods, sink from the surface waters into deeper water, deep water masses tend to accumulate dissolved carbon dioxide as they age. The oldest water masses have the highest concentrations of and therefore the shallowest CCD. The CCD is relatively shallow in high latitudes with the exception of the North Atlantic and regions of Southern Ocean where downwelling occurs. This downwelling brings young, surface water with relatively low concentrations of carbon dioxide into the deep ocean, depressing the CCD. \n\nIn the geological past the depth of the CCD has shown significant variation. In the Cretaceous through to the Eocene the CCD was much shallower globally than it is today; due to intense volcanic activity during this period atmospheric concentrations were much higher. Higher concentrations of resulted in a higher partial pressure of over the ocean. This greater pressure of atmospheric leads to increased dissolved in the ocean mixed surface layer. This effect was somewhat moderated by the deep oceans' elevated temperatures during this period. In the late Eocene the transition from a greenhouse to an icehouse Earth coincided with a deepened CCD.\n\nToday, increasing atmospheric concentration of from combustion of fossil fuels may lead to shallower CCD, with zones of downwelling first being affected. \n\nJohn Murray investigated and experimented on the dissolution of calcium carbonate and was first to identify the carbonate compensation depth in oceans.\n\n"}
{"id": "40462017", "url": "https://en.wikipedia.org/wiki?curid=40462017", "title": "Celtic broadleaf forests", "text": "Celtic broadleaf forests\n\nThe Celtic broadleaf forests are a terrestrial ecoregion native to western Great Britain and most of the island of Ireland. \nThe Celtic broadleaf forests occupy the eastern part of Ireland; the majority of Wales; the southwest of England, including Cornwall and Devon; central and northern parts England; and southern Scotland extending along the North Sea coast through most of Aberdeenshire and Moray. The forest is part of the temperate broadleaf and mixed forest biome of Western Europe.\n\nNinety percent of the Celtic forest habitat has been destroyed, generally over the last few thousand years, due to agriculture, fire-wood use and general deforestation. The outcome is an ecoregion which has not only lost most of its pristine cover, but which has been heavily degraded by fragmentation. The forests today are in a critical status, with the majority of the land having become the rolling pasture-hills typically associated with England.\n\nAnimals known to inhabit the forests are as follows;\n\nMany other species once inhabited the forest; however, due to exploitation of natural resources, deforestation and hunting, many animals have becomelocally extinct. Many of these animals were once numerous across the British isles, including the grey wolf, wild boar, lynx and European beaver.\n\nFlora include many broadleafed deciduous trees including common ash, silver birch, European aspen, common elm and various oak trees.\n\nThe climate of the forest is oceanic, leading to frequent precipitation, high precipitation days, high moisture and low sunshine levels; temperature extremes are rare. The combination of moisture and low evaporation (low sunshine amounts) leads to high dampness levels.\n\nThis ecoregion is relatively young with regard to human settlement due to glacialation (glaciation?)during the last glacial maximum, making it unsuitable for human settlement. Mesolithic peoples were certainly in evidence, circa 9000 to 8000 years ago, throughout the present day English portion of the ecoregion, as well as in the Welsh, Irish and eastern Scotland areas of the Celtic broadleaf forests.\n\nAs the Roman Empire expanded, the Roman peoples arrived, beginning \"recorded\" history within the ecoregion, with major Roman urban settlements commencing in the first century AD, although evidence shows indigenous towns such as York had existed for a millennium prior. Viking settlement in coastal areas of western Scotland, Wales and eastern Ireland was widespread from at least the ninth century AD.\n"}
{"id": "40341826", "url": "https://en.wikipedia.org/wiki?curid=40341826", "title": "Chiapas Depression dry forests", "text": "Chiapas Depression dry forests\n\nThe Chiapas Depression dry forests form one of the ecoregions that belong to the tropical and subtropical dry broadleaf forests biome, as defined by the World Wildlife Fund, in northwestern Central America. \n\nThis ecoregion is located in the central Chiapas Depression, the central depression of the eastern Sierra Madre de Chiapas, in Chiapas state of Mexico and into northwestern Guatemala. \n\nIt covers an area of around 13,900 km. It lies at an altitude of . \n\nThe Chiapas Depression dry forests ecoregion has a hot, dry climate.\n\nIts biodiversity is high, with about 980 plant species, and includes 40% of the endemic species of dry ecosystems found in Mexico. It also forms a corridor that connects two major biogeographic region, the Gulf of Mexico on the east and the Pacific in the west.\n\nThe ecoregion has been seriously threatened by cattle grazing, which is the main cause of its destruction, along with the effects of logging and the expansion of the agricultural frontier.\n\n"}
{"id": "2839514", "url": "https://en.wikipedia.org/wiki?curid=2839514", "title": "Chunfen", "text": "Chunfen\n\nThe traditional East Asian calendars divide a year into 24 solar terms.\nChūnfēn, \"Shunbun\", \"Chunbun\", or \"Xuân phân\" is the 4th solar term. It begins when the Sun reaches the celestial longitude of 0° and ends when it reaches the longitude of 15°. In the Gregorian calendar, it usually begins around 20 March and ends around 4 April (5 April East Asia time). It more often refers in particular to the day when the Sun is exactly at the celestial longitude of 0°.\n\nEach solar term can be divided into 3 pentads (候). They are: first pentad (初候), second pentad (次候) and last pentad (末候). Pentads in Chunfen include:\n\n\nA pentad as follows was referred to Japanese traditional calendar presented in a smaller, easy to use, format.\n\n"}
{"id": "49795172", "url": "https://en.wikipedia.org/wiki?curid=49795172", "title": "Congo Canyon", "text": "Congo Canyon\n\nCongo Canyon is a submarine canyon found at the end of the Congo River in Africa. It is one of the largest submarine canyons in the world.\n\nThe canyon begins inland on the continent, partway up the Congo Estuary, and starts at a depth of 21 meters. It cuts across the entire continental shelf for 85 kilometers until it reaches the shelf edge, then continues down the slope and ends 280 km from where it started. At its deepest point, the V-shaped canyon walls are 1100 meters tall, and the maximum width of the canyon is about 9 miles. At the bottom of the continental slope, it enters the Congo deep-sea fan and extends for an additional 220 km.\n\nThe turbidity currents found in Congo Canyon are the strongest measured in the world. These are essentially underwater avalanches that can propagate for hundreds of kilometers, and their strength and frequency correlate strongly with the period of highest outflow from the Congo River. Their speeds vary from about 0.7 m/s to 3.5 m/s and events can last for more than a week. These currents are the major source of erosion in the canyon and represent a significant portion of the sediment that ends up in the fan at the end of the canyon. They commonly destroy equipment laid on the bottom of the ocean and have destroyed telegraph cables and moorings.\n\nUnlike other rivers that empty into the sea, the Congo River is not building a delta because essentially all of its sediments are carried by turbidity currents via the submarine canyon to the fan. This accumulation is probably the greatest in the world for a currently active submarine system. The fan is built up by sediment gravity flows and other submarine mass movements, but also represents a very large active turbidite system. Although there exists a net up-canyon bottom current due to upwelling, these events overwhelm the normal bottom flow and ensure continued deposition.\n"}
{"id": "51894617", "url": "https://en.wikipedia.org/wiki?curid=51894617", "title": "Cromer Shoal Chalk Beds", "text": "Cromer Shoal Chalk Beds\n\nThe Cromer Shoal Chalk Beds are a chalk reef off the coast of Cromer, Norfolk in the United Kingdom, believed to be the largest chalk reef in Europe. Since January 2016, it has been designated as a Marine Conservation Zone.\n\nThe chalk beds have an area of about 320 km, starting 200m away from the coastline and extending about 10 km out into the North Sea, and stretching from west of Weybourne to Happisburgh. They are home to more than 350 marine species, including a species of purple Hymedesmia sponge first discovered there in 2011.\n"}
{"id": "43106571", "url": "https://en.wikipedia.org/wiki?curid=43106571", "title": "Cubelles power station", "text": "Cubelles power station\n\nCubelles power station (\"Central térmica de Cubellas\" / \"Central térmica de Foix\") - thermoelectric plant located in Cubelles, in Province of Barcelona, Spain.\n\n"}
{"id": "36177989", "url": "https://en.wikipedia.org/wiki?curid=36177989", "title": "Dark radiation", "text": "Dark radiation\n\nDark radiation (also dark electromagnetism) is a postulated type of radiation that mediates interactions of dark matter.\n\nBy analogy to the way photons mediate electromagnetic interactions between particles in the Standard Model (called \"baryonic matter\" in cosmology), dark radiation is proposed to mediate interactions between dark matter particles. Similar to dark matter particles, the hypothetical dark radiation does not interact with Standard Model particles.\n\nThere has been no notable evidence for the existence of such radiation, but since baryonic matter contains multiple interacting particle types, it is reasonable to suppose that dark matter does also. Moreover, it has been pointed out recently that the cosmic microwave background data seems to suggest that the number of effective neutrino degrees of freedom is more than 3.046, which is slightly more than the standard case for 3 types of neutrino. This extra degree of freedom could arise from having a non-trivial amount of dark radiation in the universe. One possible candidate for dark radiation is the sterile neutrino.\n\n"}
{"id": "3893638", "url": "https://en.wikipedia.org/wiki?curid=3893638", "title": "Dewcell", "text": "Dewcell\n\nDewcells, dewcels or dew cell are instruments used for determining the dew point. They consist of a small heating element surrounded by a solution of lithium chloride. As the LiCl absorbs moisture from the air, conduction across the heating element increases, current in it increases, and heat increases, evaporating moisture from the salt solution. At a certain temperature the amount of moisture absorbed by the salt solution equals the amount evaporated (equilibrium).\n\nInside the dewcell core a thermistor composite (or other temperature measurement device) changes electrical resistance with the temperature created by the heating. A front end processor provides a reference voltage, measures the output of the network, and calculates the dew point.\n\n"}
{"id": "23001219", "url": "https://en.wikipedia.org/wiki?curid=23001219", "title": "Diffusing-wave spectroscopy", "text": "Diffusing-wave spectroscopy\n\nDiffusing-wave spectroscopy (DWS) is an optical technique derived from dynamic light scattering (DLS) that studies the dynamics of scattered light in the limit of strong multiple scattering. It has been widely used in the past to study colloidal suspensions, emulsions, foams, gels, biological media and other forms of soft matter. If carefully calibrated, DWS allows the quantitative measurement of microscopic motion in a soft material, from which the rheological properties of the complex medium can be extracted via the microrheology approach.\n\nLaser light is sent to the sample and the outcoming transmitted or backscattered light is detected by an optoelectric sensor. The light intensity detected is the result of the interference of all the optical waves coming from the different light paths.\n\nThe signal is analysed by calculating the intensity autocorrelation function called g. \nformula_1\n\nFor the case of non-interacting particles suspended in a (complex) fluid a direct relation between g-1 and the mean squared displacement of the particles <Δr> can be established. Let's note P(s) the probability density function (PDF) of the photon path length s. The relation can be written as follows:\n\nformula_2\n\nwith formula_3 and formula_4 is the transport mean free path of scattered light.\n\nFor simple cell geometries, it is thus possible to calculate the mean squared displacement of the particles <Δr> from the measured g-1 values analytically. For example, for the backscattering geometry, an infinitely thick cell, large laser spot illumination and detection of photons coming from the center of the spot, the relationship between g-1 and <Δr> is:\n\nformula_5, γ value is around 2.\n\nFor less thick cells and in transmission, the relationship depends also on l* (the transport length).\n\nThis technique either uses a camera to detect many speckle grains (see speckle pattern) or a ground glass to create a large number of speckle realizations (Echo-DWS ). In both cases an average over a large number of statistically independent intensity values is obtained, allowing a much faster data acquisition time.\nformula_6\n\nMSDWS is particularly adapted for the study of slow dynamics and non ergodic media. Echo-DWS allows seamless integration of MSDWS in a traditional DWS-scheme with superior temporal resolution down to 12 ns. Camera based adaptive image processing allows online measurement of particle dynamics for example during drying.\n\n"}
{"id": "51506142", "url": "https://en.wikipedia.org/wiki?curid=51506142", "title": "Dodone (mythology)", "text": "Dodone (mythology)\n\nIn Greek mythology, Dodone was said to be one of the Oceanid nymphs (the daughters of the Titans Oceanus and Tethys), after whom the ancient city of Dodona was named. The 6th century AD grammarian Stephanus of Byzantium (\"s.v.\" \"Δωδὠνη\"), writes that according to Thrasyboulos (\"FHG\" II 464, a), as reported by Epaphroditus (fr. 57 Braswell–Billerbeck) in his commentary on Callimachus's \"Aetia\" (fr. 53 Pfeiffer), the ancient city Dodona was named after an Oceanid nymph named Dodone. Stephanus further notes that, according to Akestodorus, the city was instead named after Dodon, a son of Zeus and Europa, but concludes that it is more likely that the city was named after the river Dodon, as Herodian says. According to Schol. \"Iliad\" 16.233) the city was named after Dodon or Dodone the wife of Deucalion who named the city after her, and according to Eustathius, on \"Iliad\" 2.750, the city was named after Dodone, a heroine or Oceanid, or after Dodon.\n\n"}
{"id": "24721284", "url": "https://en.wikipedia.org/wiki?curid=24721284", "title": "Ergosophy", "text": "Ergosophy\n\nErgosophy is a term coined by the scientist Frederick Soddy, in the early 1920s, and refers to aspects of energy in relation to human existence and energy measurement as in (Ergs). Soddy's aim was to apply science theories and ideas and move the human understanding of work beyond the restrictions of management theory into a new theory of energy economics.\n\nFrederick Soddy first used the term in his book on work and economics: \"The Role of Money\".\n"}
{"id": "17141368", "url": "https://en.wikipedia.org/wiki?curid=17141368", "title": "Eric Worrell", "text": "Eric Worrell\n\nEric Arthur Frederic Worrell (MBE), (27 October 1924 – 13 July 1987) was an Australian naturalist, herpetologist and writer whose collection of snake venom was essential in the production of snake anti-venom in Australia.\n\nEric was born at Granville, New South Wales the son of salesman and taxidriver (Charles) Percy Frederic Worrell and his wife Rita Mary Ann Worrell (née Rochester). Eric was educated at Glenmore Road Public School in Paddington then Sydney Boys High School. By the age of 10 he was keenly interested in wildlife, keeping reptiles and other animals at home (first at Paddington then around 1938, to Cecily Street, Lilyfield). He was encouraged in his hobby by his parents and by George Cann, the \"Snake Man of La Perouse\", and latterly Keeper of Reptiles at Taronga Park Zoo.\n\nHe left school at 13 and spent several years in work gangs in regional New South Wales and Queensland, studying drawing and photography in his spare time. During the Second World War he worked as a civilian blacksmith on the installation of shore artillery in Darwin and other work at Katherine, where he had many opportunities to study the local wildlife. After the war he and his friend, the poet Roland Robinson returned to the Northern Territory in 1946, collecting specimens for zoos and museums, and writing articles on Territory wildlife for magazines such as \"Walkabout\".\n\nIn 1949, Worrell opened the Ocean Beach Aquarium at Umina Beach on the New South Wales Central Coast. It was here in 1951 that he first started supplying tiger snake venom to the Commonwealth Serum Laboratories (CSL) in Melbourne. Taipan venom followed in 1952. He later expanded his repertoire to include spiders such as the Sydney funnel-web spider and exotic snakes. In 1955 CSL provided Worrell, together with Ken Slater and Ram Chandra with some of the first doses of Taipan antivenom, in recognition of the dangers involved in their work.\n\nIn 1958, he purchased land at Wyoming, New South Wales, establishing the Australian Reptile Park, which opened in October 1959, with a large number of exotic as well as Australian animals. In 1963 he had a giant dinosaur statue erected at its entrance as a tourist drawcard, one of Australia's first \"Big Things\".\n\nIn 1985, beset with personal, health and financial problems, he tried to sell the Reptile Park, but was bailed out with financial assistance from entertainer Bobby Limb and local businessman Ed Manners.\n\nHe died of a heart attack at his home in the Reptile Park and was cremated.\n\nIn 1996, after Worrell's death, the Park was moved to Somersby.\n\nWorrell married Rene Carol Hawkins, a shop assistant, on 31 July 1948 and had three children. They divorced in 1971.\n\nHe married his secretary Robyn Beverley Innes on 16 June 1973. They divorced in 1985.\n\nAmong his friends were the naturalist Vincent Serventy, zoologist Jock Marshall, photographer Jeff Carter and artist Russell Drysdale.\n\n\nApart from numerous scientific papers and popular natural history articles in Walkabout, Wildlife, Australian Outdoors, Pix and People Magazine, books authored, coauthored or contributed to by Worrell include:\n\n"}
{"id": "27912295", "url": "https://en.wikipedia.org/wiki?curid=27912295", "title": "European Network of Transmission System Operators for Gas", "text": "European Network of Transmission System Operators for Gas\n\nThe European Network of Transmission System Operators for Gas (ENTSOG) is an association of Europe's transmission system operators (TSOs). ENTSOG was created on 1 December 2009 by 31 TSOs from 21 European countries. Creation of the ENTSOG was initiated by the adoption of the European Union third legislative package on the gas and electricity markets. It aims to promote the completion and cross-border trade for gas on the European internal market, and development of the European natural gas transmission network. According to the third energy package ENTSOG is required to develop an EU-wide ten-year gas network development plan.\n\nENTSOG now comprises 45 TSOs and 2 Associated Partners from 26 countries and 6 observing TSOs from EU affiliated countries:\n\n"}
{"id": "30969474", "url": "https://en.wikipedia.org/wiki?curid=30969474", "title": "Geopotential model", "text": "Geopotential model\n\nIn geophysics, a geopotential model is the theoretical analysis of measuring and calculating the effects of Earth's gravitational field.\n\nNewton's law of universal gravitation states that the gravitational force \"F\" acting between two point masses \"m\" and \"m\" with centre of mass separation \"r\" is given by\n\nwhere \"G\" is the gravitational constant and r̂ is the radial unit vector. For an object of continuous mass distribution, each mass element \"dm\" can be treated as a point mass, so the volume integral over the extent of the object gives:\n\nwith corresponding gravitational potential\n\nwhere ρ = ρ(\"x, y, z\") is the mass density at the volume element and of the direction from the volume element to the point mass.\n\nIn the special case of a sphere with a spherically symmetric mass density then ρ = ρ(\"s\"), i.e. density depends only on the radial distance\n\nThese integrals can be evaluated analytically. This is the shell theorem saying that in this case:\n\nwith corresponding potential\n\nwhere \"M\" = ∫ρ(\"s\")\"dxdydz\" is the total mass of the sphere.\n\nIn reality, Earth is not exactly spherical, mainly because of its rotation around the polar axis that makes its shape slightly oblate. If this shape were perfectly known together with the exact mass density ρ = ρ(\"x, y, z\"), the integrals () and () could be evaluated with numerical methods to find a more accurate model for Earth's gravitational field. However, the situation is in fact the opposite. By observing the orbits of spacecraft and the Moon, Earth's gravitational field can be determined quite accurately and the best estimate of Earth's mass is obtained by dividing the product \"GM\" as determined from the analysis of spacecraft orbit with a value for \"G\" determined to a lower relative accuracy using other physical methods.\n\nFrom the defining equations () and () it is clear (taking the partial derivatives of the integrand) that outside the body in empty space the following differential equations are valid for the field caused by the body:\n\nFunctions of the form formula_3\nwhere (\"r\", θ, φ) are the spherical coordinates which satisfy the partial differential equation () (the Laplace equation) are called spherical harmonic functions.\n\nThey take the forms:\n\nh(x,y,z) & =\\frac{1}{r^{n+1}} P^m_n(\\sin \\theta) \\sin m\\varphi \\,&\\quad 1 \\le m \\le n \\,&\\quad n=1,2,\\dots\n\nwhere spherical coordinates (\"r\", θ, φ) are used, given here in terms of cartesian (\"x, y, z\") for reference:\nalso \"P\" are the Legendre polynomials and \"P\" for 1 ≤ \"m\" ≤ \"n\" are the associated Legendre functions.\n\nThe first spherical harmonics with \"n\" = 0,1,2,3 are presented in the table below.\n\nThe model for Earth's gravitational potential is a sum\n\nwhere formula_4 and the coordinates () are relative the standard geodetic reference system extended into space with origin in the center of the reference ellipsoid and with \"z\"-axis in the direction of the polar axis.\n\nThe zonal terms refer to terms of the form:\n\nand the tesseral terms terms refer to terms of the form:\n\nThe zonal and tesseral terms for \"n\" = 1 are left out in ().\n\nThe different coefficients \"J\", \"C\", \"S\", are then given the values for which the best possible agreement between the computed and the observed spacecraft orbits is obtained.\n\nAs \"P\"(\"x\") = −\"P\"(−\"x\") non-zero coefficients \"J\" for odd \"n\" correspond to a lack of symmetry \"north–south\" relative the equatorial plane for the mass distribution of Earth. Non-zero coefficients \"C\", \"S\" correspond to a lack of rotational symmetry around the polar axis for the mass distribution of Earth, i.e. to a \"tri-axiality\" of Earth.\n\nFor large values of \"n\" the coefficients above (that are divided by \"r\" in ()) take very large values when for example kilometers and seconds are used as units. In the literature it is common to introduce some arbitrary \"reference radius\" \"R\" close to Earth's radius and to work with the dimensionless coefficients\n\nand to write the potential as\n\n\\ P_n(\\sin\\theta)</math>\n\nwhich is rotational symmetric around the z-axis is an harmonic function\n\nIf formula_11 is a solution to the differential equation\n\nwith \"m\" ≥ 1 one has the potential\n\nwhere \"a\" and \"b\" are arbitrary constants is a harmonic function that depends on φ and therefore is not rotational symmetric around the z-axis\n\nThe differential equation () is the Legendre differential equation for which the Legendre polynomials defined\nare the solutions.\n\nThe arbitrary factor 1/(2\"n\"!) is selected to make \"P\"(−1)=−1 and \"P\"(1) = 1 for odd \"n\" and \"P\"(−1) = \"P\"(1) = 1 for even \"n\".\n\nThe first six Legendre polynomials are:\n\nThe solutions to differential equation () are the associated Legendre functions\n\\ \\frac{d^m P_n}{dx^m} \\quad 1 \\le m \\le n\n\nOne therefore has that\n\n\n"}
{"id": "1977865", "url": "https://en.wikipedia.org/wiki?curid=1977865", "title": "Gravity darkening", "text": "Gravity darkening\n\nGravity darkening, also referred to as gravity brightening, is an astronomical phenomenon where a star rotates so rapidly that it has a detectably oblate spheroid shape, such as in Achernar in the constellation Eridanus.\n\nWhen a star is oblate, it has a larger radius at its equator than it does at its poles. As a result, the poles have a higher surface gravity, and thus higher temperature and brightness. Thus, the poles are \"gravity brightened\", and the equator \"gravity darkened\".\n\nThe star becomes oblate (and hence gravity darkening occurs) because the centrifugal force resulting from rotation creates additional outward pressure on the star. The centrifugal force is expressed mathematically as\n\nwhere formula_2 is mass (in this case of a small volume element of the star), formula_3 is the angular velocity, and formula_4 is the radial distance from the axis of rotation. In the case of a star, the value of formula_4 is largest at the equator and smallest at the poles. This means that equatorial regions of a star will have a greater centrifugal force when compared to the pole. The centrifugal force pushes mass away from the axis of rotation, and results in less overall pressure on the gas in the equatorial regions of the star. This will cause the gas in this region to become less dense, and cooler.\n\nVon Zeipel's theorem states that the radiation from a star is proportional to the local effective gravity, that is to the gravity reduced by any centrifugal force at that location on the star's surface. Then the effective temperature is proportional to the fourth root of the effective gravity.\n"}
{"id": "39979931", "url": "https://en.wikipedia.org/wiki?curid=39979931", "title": "Harela", "text": "Harela\n\nHarela is a Hindu festival celebrated basically in the Kumaon region of Uttarakhand state of India. It is celebrated thrice in year, the first two are during both the Navratis, Chaitra Navrati in the month of Chaitra and Sharad Navratri in the month of Ashwin. This is followed by \"Bhaitauli\" or \"Bhitauli\" wherein gifts are given to girls of the family. The Shravan Harela is celebrated as the first day (Kark Sankranti) of Hindu calendar month of Sravan (late July). It is also symbol for the onset of rainy season (Monsoon) as Harela literally means \"Day of Green\". Agriculture-based communities in the region consider it highly auspicious, as it marks the beginning on sowing cycle. They pray for the good harvest and prosperity. harela on 16 July 2018\n\nThe Belief behind the festival is that it is celebrated as the wedding of Lord Shiva and Goddess Parvati, with probable origins in Neo-lithic fertility festivals. The people make the clay statues of Lord Shiva and goddess Parvati known as \"Dikare\" or \"Dikars\" and worship them. Harela symbolizes for the new harvest of the rainy season\n\nThe celebration falls on the first day of Sravan. Ten days before the due date, seven or five types of seeds are sown in the buckets by the head of the family. Water is sprinkled over them. After the due time before the actual celebration, mock wedding is done by small hoes . After that people also worship the statues of lord shiva and Goddess Parvati. The yellow leaves of the new harvest are cut and put on the ears . This is the symbol for the rainy season and new harvest.People also eat the seeds of new harvest after heating them.People meet their relatives and enjoy the festival.\nSome people also sow the seeds of new plants in the earth and put together their hands for saving the environment.\n\nHarela has a great significance in Kumaon. This symbolizes for the new harvest and rainy season. It has become common practice to attribute a slogan of \"Save The Environment\" to Harela. Schools in the Kumaun area often encourage their students to plant trees, either at home, in the school or with the support of local officials.\n\n\n"}
{"id": "1692209", "url": "https://en.wikipedia.org/wiki?curid=1692209", "title": "Hegemone", "text": "Hegemone\n\nHegemone (Ἡγεμόνη) was a Greek goddess of plants, specifically making them bloom and bear fruit.\nAccording to Pausanias, Hegemone was a name given by the Athenians to one of the Graces. Auxo represented the spring, and Hegemone autumn.\n"}
{"id": "20202584", "url": "https://en.wikipedia.org/wiki?curid=20202584", "title": "Holistic community", "text": "Holistic community\n\nA holistic community (also referred to as closed or unitary) is an ecosystem where the species within the community are interdependent on each other for keeping balance and stability of the system. These communities are described as working like a superorganism, meaning that every species plays an important part in the overall well being of the ecosystem in which the community resides; much like the organelles within a cell, or even the cells making up one organism. Holistic communities have diffused boundaries, and an independent species range. Co-evolution is likely to be found in communities structured after this model, as a result of the interdependence and high rates of interaction found among the different populations. It is said that species compositions of communities change sharply at environmental edges (known as ecotones).\n\nThe ideas of a holistic community were introduced by plant ecologist Frederic Clements in 1916. These notions were countered by Henry Gleason in 1917, when he proposed the individualistic/open community concept (in applications to plants). Neither of these ecological concepts have been found to exist in entirety, both are theories which can be applied to communities. For example, a community's composition can be better explained by holism than individualism, or vice versa. This ecological concept is based on the broader concept of holism, which describes the functionality of any system as having many individual parts, all of which are extremely important to the system's viability.\n\n\"A community has been viewed as a superorganism with an integrity analogous to that of cells in an organism. This is the holistic or unitary view of a community, and one championed by Clements (1916). He regarded the community to be a highly integrated unit that operated very much within itself with little interaction with surrounding communities - a closed community.\"\n\n\n"}
{"id": "10485844", "url": "https://en.wikipedia.org/wiki?curid=10485844", "title": "Important ecological areas", "text": "Important ecological areas\n\nImportant ecological areas (IEAs) are habitat areas which, either by themselves or in a network, contribute significantly to an ecosystem’s productivity, biodiversity, and resilience. Appropriate management of key ecological features delineates the management boundaries of an IEA. The identification and protection of IEAs is an element of an ecosystem-based management approach.\n\nImportant ecological areas may have varying levels of management of extractive activities, from monitoring up to and including marine reserve. IEAs have management measures tailored to the ecological features within the area with consideration of socioeconomic factors. Whereas marine reserves generally have a fixed management policy of no extraction or ‘no-take’. Nonetheless, a marine reserve may be the appropriate management policy for an IEA.\n\nThe identification and management of IEAs is a form of ocean zoning. In the event that there are a series of linked IEAs within a large marine ecosystem, a collective action to manage the network, such as a marine sanctuary or national monument, may be warranted.\n\nExamples are tropical rainforests, oceans, forests, etc.\n"}
{"id": "11782509", "url": "https://en.wikipedia.org/wiki?curid=11782509", "title": "Isostatic depression", "text": "Isostatic depression\n\nIsostatic depression is the sinking of large parts of the Earth's crust into the asthenosphere. The sinking is caused by a heavy weight placed on the Earth's surface. Often this is caused by the heavy weight of glacial ice due to continental glaciation. This is a process in which permanent ice places pressure on the Earth's crust, thereby depressing it with its weight. After continental glaciation has receded, it is common for isostatic rebound to occur.\n\n"}
{"id": "2497628", "url": "https://en.wikipedia.org/wiki?curid=2497628", "title": "Konohanasakuya-hime", "text": "Konohanasakuya-hime\n\nKonohanasakuya-hime or Konohananosakuya-hime (木花開耶姫, 木花咲耶姫 or 木花開耶姫; lit. \"\"[cherry] tree blossom blooming princess\" (her name also appears in a shorter form as \"Sakuya-hime\"\")), in Japanese mythology, is the blossom-princess and symbol of delicate earthly life. She is the daughter of the mountain god Ohoyamatsumi. She is often considered an avatar of Japanese life, especially since her symbol is the \"sakura\" (cherry blossom). Konohanasakuya-hime is also the goddess of Mount Fuji and all volcanoes. \n\nSakuya-hime is the wife of the god Ninigi. She met him on the seashore and they fell in love; Ninigi asked Oho-Yama, the father of Sakuya-hime for her hand in marriage. Oho-Yama proposed his older daughter, Iwa-Naga-hime, instead, but Ninigi had his heart set on Sakuya-hime. Oho-Yama reluctantly agreed and Ninigi and Ko-no-hana married. Because Ninigi refused Iwa-Naga, the rock-princess, human lives are said to be short and fleeting, like the sakura blossoms, instead of enduring and long lasting, like stones. \n\nSakuya-hime became pregnant in just one night, causing suspicion in Ninigi. He wondered if this was the child of another kami. Sakuya-hime was enraged at Ninigi's accusation and entered a doorless hut, which she then set fire to, declaring that the child would not be hurt if it were truly the offspring of Ninigi. Inside the hut, Ko-no-hana had three sons, Hoderi, Hosuseri and Hoori.\n\nShrines have been built on Mount Fuji for Sakuya-hime. It is believed that she will keep Mount Fuji from erupting, but shrines to her at Kirishima have been repeatedly destroyed by volcanic eruptions. She is also known for having torn up the Yatsugatake Mountains, because it was higher than Fuji-san.\n\n\n"}
{"id": "2927242", "url": "https://en.wikipedia.org/wiki?curid=2927242", "title": "List of Lepidoptera that feed on alders", "text": "List of Lepidoptera that feed on alders\n\nAlders (\"Alnus\" species) are used as food plants by the larvae of a number of Lepidoptera species:\n\nSpecies which feed exclusively on \"Alnus\":\n\nSpecies which feed on \"Alnus\" among other plants:\n\n"}
{"id": "58787895", "url": "https://en.wikipedia.org/wiki?curid=58787895", "title": "List of Nuttall mountains in England and Wales", "text": "List of Nuttall mountains in England and Wales\n\nThis is a list of Nuttall mountains in England and Wales by height. Nuttalls are defined as peaks above in height, the general requirement to be called a \"mountain\" in the British Isles, and with a prominence above ; a mix of imperial and metric thresholds.\n\nThe Nuttall classification was suggested by Anne and John Nuttall in their 1990 two–volume book, \"The Mountains of England and Wales\". The list was updated with subsequent revised editions by the Nuttalls. Because of the prominence threshold of only , the list is subject to ongoing revisions. In response, Alan Dawson introduced the Hewitts, with a higher prominence threshold of . This was the prominence threshold that the UIAA set down in 1994 for an \"independent\" peak. In 2010, Dawson replaced his Hewitts with the fully \"metric\" Simms, consisting of a height threshold of , and a prominence threshold of . However, both the Nuttall and Hewitt classifications have become popular with peak baggers, and both remain in use, and their respective authors maintain up to date lists, as does the \"Database of British and Irish Hills.\"\n\nThe table below of 257 English Nuttals at October 2018, include:\n\nThe table below of 189 Welsh Nuttals at October 2018, include:\n\nData is from the \"Database of British and Irish Hills\" (\"DoBIH\") in October 2018, and are peaks DoBIH marks as English (\"E\" and \"ES\"), and Nuttalls (\"N\"). John and Anne Nuttall update the list of Nuttalls from time to time, and the DoBIH also updates their measurements as more surveys are recorded, so these tables should not be amended or updated unless the entire DoBIH data is re-downloaded again.\n\nThis list is from the \"Database of British and Irish Hills\" (\"DoBIH\") in October 2018, and are peaks the DoBIH marks as being Welsh, and Nuttalls (\"N\"). John and Anne Nuttall update the list of Nuttalls from time to time, and the DoBIH also updates their measurements as more surveys are recorded, so these tables should not be amended or updated unless the entire DoBIH data is re-downloaded again.\n\n\nThe DoBIH uses the following codes for the various classifications of mountains and hills in the British Isles, which many of the above peaks also fall into:\n<br>\n\nsuffixes:<br>\n= twin\n\n\n"}
{"id": "6070356", "url": "https://en.wikipedia.org/wiki?curid=6070356", "title": "List of SSSIs in Montgomery", "text": "List of SSSIs in Montgomery\n\nDue to subsequent local government reorganisation in the UK since 1972, many counties and districts have been divided, merged or renamed. Using the AOS system alone would make it difficult to search for individual SSSI citations via the Countryside Council for Wales (CCW) database without knowing 1972 region divisions. As a result, the CCW groups Welsh SSSIs using the subdivisions of Wales formed in April 1996 by the Local Government (Wales) Act 1994, resulting in 22 principal areas.\n\nMontgomery AOS lies within the county of Powys.\n\nFor SSSIs elsewhere in the UK, see List of SSSIs by Area of Search.\n\n"}
{"id": "6183587", "url": "https://en.wikipedia.org/wiki?curid=6183587", "title": "List of Sites of Special Scientific Interest in South East Sutherland", "text": "List of Sites of Special Scientific Interest in South East Sutherland\n\nThe following is a list of Sites of Special Scientific Interest in the South East Sutherland Area of Search. For North West Sutherland see List of SSSIs in North West Sutherland. For SSSIs elsewhere in Scotland, see List of SSSIs by Area of Search.\n\n"}
{"id": "21305480", "url": "https://en.wikipedia.org/wiki?curid=21305480", "title": "List of glaciers in South America", "text": "List of glaciers in South America\n\nGlaciers in South America develop exclusively on the Andes and are subject to the Andes various climatic regimes namely the Tropical Andes, Dry Andes and the Wet Andes. Apart from this there is a wide range of altitudes on which glaciers develop from 5000 m in the Altiplano mountains and volcanoes to reaching sealevel as tidewater glaciers from San Rafael Lagoon (45° S) and southwards. South America hosts two large ice fields, the Northern and Southern Patagonian Ice Fields, of which the second is the largest contiguous body of glaciers in extrapolar regions. By surface about 80% of South America's glaciers lie in Chile.\n\n\n\n\n\n\n\n\n"}
{"id": "30687979", "url": "https://en.wikipedia.org/wiki?curid=30687979", "title": "List of mountains in the Philippines", "text": "List of mountains in the Philippines\n\nThe following is a \"'partial list of mountains in the Philippines\". Several of these are volcanoes, formed by subducting tectonic plates surrounding the archipelago.\n\nThis list contains most of the highest mountains in the country. It is limited to mountain peaks with, if known, an elevation of at least above sea level, and may include those considered as hills. The distinction between a hill and a mountain in terms of elevation is unclear and largely subjective, but a hill is universally considered to be less tall and less steep than a mountain.\n\n\n"}
{"id": "443695", "url": "https://en.wikipedia.org/wiki?curid=443695", "title": "List of mountains of the United States", "text": "List of mountains of the United States\n\nThis list includes significant mountain peaks and high points located in the United States arranged alphabetically by state, district, or territory. The highest peak or point in each state is noted in bold.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe following list includes links to and for topographic summits of the United States with identical names. The United States Board on Geographic Names is the official authority for all United States geographic names. The United States Geological Survey Geographic Names Information System provides Internet access to these geographic names.\n\n\n"}
{"id": "2114539", "url": "https://en.wikipedia.org/wiki?curid=2114539", "title": "List of oil refineries", "text": "List of oil refineries\n\nThis is a list of oil refineries. The \"Oil & Gas Journal\" also publishes a worldwide list of refineries annually in a country-by-country tabulation that includes for each refinery: location, crude oil daily processing capacity, and the size of each process unit in the refinery. For some countries, the refinery list is further categorized state-by-state. The list appears in one of their December issues. It is about 45 pages in length, and updated each year with additions, deletions, name changes, capacity changes and other refinements.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis section is incomplete and needs work\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefineries with capacity more than \n\nEurope\n\n\nAsia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n, there are 137 operating oil refineries in the United States per the U.S. Energy Information Administration (EIA).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew South Wales\n\nVictoria\n\nQueensland\n\nSouth Australia\n\nWestern Australia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "31646013", "url": "https://en.wikipedia.org/wiki?curid=31646013", "title": "List of stars in Argo Navis", "text": "List of stars in Argo Navis\n\n\n"}
{"id": "3402101", "url": "https://en.wikipedia.org/wiki?curid=3402101", "title": "List of tree species by shade tolerance", "text": "List of tree species by shade tolerance\n\nA list of tree species, grouped generally by biogeographic realm and specifically by bioregions, and shade tolerance. Shade-tolerant species are species that are able to thrive in the shade, and in the presence of natural competition by other plants. Shade-intolerant species require full sunlight and little or no competition. Intermediate shade-tolerant trees fall somewhere in between the two.\nShade tolerant\n\nIntermediate shade tolerant\n\nShade intolerant\n\nShade tolerant\n\nIntermediate shade tolerant\n\nShade intolerant\n\nShade tolerant\n\nIntermediate shade tolerant\n\nShade intolerant\n\n"}
{"id": "55700453", "url": "https://en.wikipedia.org/wiki?curid=55700453", "title": "National Energy Guarantee", "text": "National Energy Guarantee\n\nNational Energy Guarantee (NEG) was an energy policy proposed by the Turnbull government in late 2017 to deal with rising energy prices in Australia and lack of clarity for energy companies to invest in energy infrastructure. The policy specifically targets energy companies in the National Electricity Market and large energy users to have a reliability obligation as well as emissions reduction obligations.\n\nTurnbull's successor Scott Morrison announced in September 2018 to focus on cheap Electricity prices; Australia would (also without NEG) make efforts to lower Carbon dioxide emissions. \n\nIn the years leading up to the proposed NEG, energy policy in Australia included the Rudd government's proposed Carbon Pollution Reduction Scheme, the introduction and repeal of the Gillard government's Clean Energy Act 2011, the Abbott government's Emissions Reduction Fund, and proposals for an Emissions Intensity Scheme (EIS) and a Clean Energy Target (CET) among others. Throughout this time, energy prices in energy resource rich Australia continued to rise. In October 2017 the Turnbull government announced a new proposal, the National Energy Guarantee, intended to \"lower electricity prices, make the system more reliable, encourage the right investment and reduce emissions\". Subsidies and incentives for renewable energy will be scrapped under the plan. The Labor opposition argues the plan will destroy the renewables sector, but the government argues renewables can be competitive without subsidies, and expects Australia will still meet its Paris Agreement obligations under the plan. The Climate Council called the NEG \"a woefully inadequate response\" to climate change.\n\nThe government via the COAG Energy Council meeting on 14 July 2017 established the Energy Security Board to coordinate the implementation of the Finkel Review authored by Australian's Chief Scientist Alan Finkel. The government decided not to adopt the Clean Energy Target as recommended by the Finkel Review after coming pressure from the conservative elements of the Liberal Party as well as vocal climate sceptics. \n\nThe NEG will need the support of the Australian states signed up to it to activate the scheme. The reason is the states need to pass legislation to change the functioning of the national electricity market. Government critics of emission reduction targets are advocating for a \"hockey-stick\" target, where the most reduction occurs in the years just before 2030.\n\nThe reliability obligation means that energy companies need to provide a mix of energy generation sources that can be fired up on demand to meet peak loads or emergency demand.\n\nThis dictates energy companies need to have in their mix of energy production from low emission sources like gas fired power stations, wind, solar, batteries or hydropower or even coal fired stations.\n\nThe government indicated if these regulatory obligations are not met after a period of time, the government can take action such as deregistering non complying energy providers. The reliability guarantee is going to be setup by the Australian Energy Market Commission (AEMC) and Australian Energy Market Operator (AEMO).\n\nThe emissions guarantee will be established by the Commonwealth and overseen by the Australian Energy Regulator (AER).\n\nIn 2017, Federal Energy Minister Josh Frydenberg asked the Energy Security Board to undertake further modelling to determine the NEG's impact on the national electricity market. The minister also forecast in the best scenario, the NEG can deliver price reduction of 6 percent of power bills. It is equivalent to a average $115 annual savings from 2020 to 2030. As of July 2018, the underlying assumptions behind the Energy Security Board's modelling has not been made public.\n\n"}
{"id": "20587039", "url": "https://en.wikipedia.org/wiki?curid=20587039", "title": "Non-volcanic passive margins", "text": "Non-volcanic passive margins\n\nNon-volcanic passive margins (NVPM) constitute one end member of the transitional crustal types that lie beneath passive continental margins; the other end member being volcanic passive margins (VPM). Transitional crust welds continental crust to oceanic crust along the lines of continental break-up. Both VPM and NVPM form during rifting, when a continent rifts to form a new ocean basin. NVPM are different from VPM because of a lack of volcanism. Instead of intrusive magmatic structures, the transitional crust is composed of stretched continental crust and exhumed upper mantle. NVPM are typically submerged and buried beneath thick sediments, so they must be studied using geophysical techniques or drilling. NVPM have diagnostic seismic, gravity, and magnetic characteristics that can be used to distinguish them from VPM and for demarcating the transition between continental and oceanic crust.\n\nNVPM are the result of rifting when a continent breaks up to form an ocean, producing transitional crust without volcanism. Extension causes a number of events to occur. First is lithospheric thinning, which allows asthenospherc upwelling; heating further erodes the lithosphere, furthering the thinning process. The extensional forces also cause listric faults and continentward dipping reflectors that help identify NVPM and distinguish them from VPM, characterized by seaward-dipping seismic reflectors. The main difference between NVPM and VPM is that in the latter case, the mantle is hot enough to melt and produce voluminous basalts, whereas in the former case the mantle doesn't melt and there is little or no volcanism. Instead, extension simply pulls the crust away, exposing or \"unroofing\" the mantle, exposing serpentinized peridotite. The mantle doesn't melt because it is cold or upwells slowly, so there are no igneous rocks like there are in VPM. The basalts and granites are replaced with serpentinized peridotite, accompanied by unique serpentothermal and hydrothermal activity. Increasing density of the lithosphere as it cools and sediment accumulation causes subsidence.\n\nSeismic reflection lines across passive margins show many structural features common to both VPM and NVPM, such as faulting and crustal thinning, with the primary contra-indicator for volcanism being the presence of continent-ward dipping reflectors.\n\nNVPM also display distinct p-wave velocity structures that differentiate them from VPM. Typical NVPM exhibit a high velocity, high gradient lower crust (6.4-7.7 km/s) overlain by a thin, low velocity (4–5 km/s) upper crustal layer. The high velocity shallow layer is usually interpreted as the serpentinized peridotite associated with NVPM. In some cases, an extremely thick igneous underplating of a VPM will display similar P-wave velocity (7.2-7.8 km/s, but with a lower gradient). For this reason, velocity structure alone cannot be used to determine the nature of a margin.\n\nGravity data provides information about the subsurface density distribution. The most important gravity feature associated with any continent-ocean transition, including NVPM, is the free-air edge effect anomaly, which consists of a gravity high and a gravity low associated with the contrast between the thick continental and thin oceanic crust. There are also subsurface variations in density that cause significant variations across the continent-ocean transition. The crust, as well as the entire lithosphere, is thinned due to mechanical extension. The Moho marks a large density contrast between crust and mantle, typically at least 0.35 g/cm3. The highest amplitudes of the gravity anomaly occur seaward of the continent-ocean transition. High-density upper mantle material is elevated relative to the more landward crustal root. The oceanic crust density is then further enhanced with gabbros and basalts and additionally contributes to the regional gravity trend.\n\nWhere the thickness of the crust and lithosphere varies, equilibrium must be reached. Isostatic compensation and gravity anomalies result from balance between mass excess of the extra mantle beneath the thinned lithosphere and the overlying low-density crust. Positive gravity anomalies result from the relatively low flexural strength of the lithosphere during the beginning of rifting. As the passive margin matures, the crust and uppermost mantle become colder and stronger, so that the compensating deflection in the base of the lithosphere is broader than the actual rift. Higher flexural strength results in a broadening of the gravity anomaly with time.\n\nThe magnetic signature of a passive continental margin is influenced by the volume of material with a high magnetic susceptibility and the depth of the material below the surface. Large amplitude magnetic anomalies are associated with high magnetic susceptibility (~0.06 emu) igneous rocks of VPM. In contrast, NVPM exhibit only small amplitude anomalies associated with the edge effect at the boundary between the exhumed mantle (~0.003 emu) at the transition zone, and the true oceanic crust basalt (~0.05 emu). This anomaly can be used to locate the boundary between transitional crust and oceanic crust. The absence of large amplitude anomalies is a very strong indication that a margin is non-volcanic.\n\nPassive rifting, unlike active rifting, occurs principally by extensional tectonic forces as opposed to magmatic forces originating from convection cells or mantle plumes. Isostatic forces allow mantle material to rise under the thinning lithosphere. Subsidence and sedimentation occur during both the initial rifting stage and the post rifting stages. Only after initial rifting does any mantle melting occur. Continued extension of the lithosphere will eventually lead to decompression melting of the mantle and the formation of a mid-ocean ridge. This process results in the creation of an ocean basin, and possibly conjugate NVPM .\n\nThere are several models for forming NVPM. Passive rifting can follow McKenzie’s pure shear model, Wernicke’s simple shear model, or a composite model combining features of both, as observed at the Galicia bank NVPM.\n\nPure shear describes “homogeneous flattening” of rocks without rotations, while maintaining a constant volume. If a cube undergoes pure shearing, the result will be a rectangular prism with sides parallel to those of the initial cube. McKenzie’s model predicts symmetric structures on either side of the rift zone composed of rotated fault blocks bounded by normal faults .\n\nIn contrast to pure shear, simple shear describes constant volume strain with rotations. If a cube undergoes simple shearing, the result will be a parallelogram with sides that increase in length and are no longer parallel to the sides of the original cube. The top and bottom of the cube will neither stretch nor shorten. In a simple shear model, a basin is stretched asymmetrically by a large scale detachment fault extending from the upper crust to the lower lithosphere and even asthenosphere .\n\nDuring the Late Jurassic-Early Cretaceous, tectonic extensional forces created a shallow angle east-dipping detachment fault. This fault cut from what is now the Flemish Cap margin in Nova Scotia, eastern Canada to the Galicia margin, which is located west of the Iberian Peninsula. This fault penetrated the upper portion of the continental crust and merged into the transition between brittle upper and plastic lower crust. In time, displacement along this detachment fault decreased to zero at a point under the Galicia margin. East of this detachment fault, the structure of the Galicia NVPM is entirely pure shear resulting in rotated fault blocks, normal faults, and continent-ward dipping seismic reflectors. Simple shear is only evident in the western edge of the Galicia margin and the upper crust of the Flemish Cap margin where the crust is brittle. Below this brittle crust, the ductile crust follows McKenzie’s pure shear model. Mantle material composed of peridotites is serpentinized by circulating seawater after it rises close enough to the upper crust due to its low density and isostatic forces. After sufficient thinning of the lithosphere, this serpentinized material is emplaced at the continent-ocean transition. This is why the transitional crust of NVPM are made of serpentinized peridotite instead of magmatic structures seen in VPM. Since the emplacement of the peridotite, oceanic crust has been forming at the Mid-Atlantic Ridge and driving the two NVPM apart. The simple shear detachment became a deactivated detachment fault once this rifting process began the formation of new oceanic crust. This process explains the structures seen at the Galicia margin today.\n\n"}
{"id": "4607613", "url": "https://en.wikipedia.org/wiki?curid=4607613", "title": "Oceanic plateau", "text": "Oceanic plateau\n\nAn oceanic or submarine plateau is a large, relatively flat elevation that is higher than the surrounding relief with one or more relatively steep sides.\n\nThere are 184 oceanic plateaus covering an area of , or about 5.11% of the oceans. The South Pacific region around Australia and New Zealand contains the greatest number of oceanic plateaus (see map).\n\nOceanic plateaus produced by large igneous provinces are often associated with hotspots, mantle plumes, and volcanic islands — such as Iceland, Hawaii, Cape Verde, and Kerguelen. The three largest plateaus, the Caribbean, Ontong Java, and Mid-Pacific Mountains, are located on thermal swells. Other oceanic plateaus, however, are made of rifted continental crust, for example Falkland Plateau, Lord Howe Rise, and parts of Kerguelen, Seychelles, and Arctic ridges.\nPlateaus formed by large igneous provinces were formed by the equivalent of continental flood basalts such as the Deccan Traps in India and the Snake River Plain in the United States.\n\nIn contrast to continental flood basalts, most igneous oceanic plateaus erupt through young and thin () mafic or ultra-mafic crust and are therefore uncontaminated by felsic crust and representative for their mantle sources.\nThese plateaus often rise above the surrounding ocean floor and are more buoyant than oceanic crust. They therefore tend to withstand subduction, more-so when thick and when reaching subduction zones shortly after their formations. As a consequence, they tend to \"dock\" to continental margins and be preserved as accreted terranes. Such terranes are often better preserved than the exposed parts of continental flood basalts and are therefore a better record of large-scale volcanic eruptions throughout Earth's history. This \"docking\" also means that oceanic plateaus are important contributors to the growth of continental crust. Their formations often had a dramatic impact on global climate, such as the most recent plateaus formed, the three, large, Cretaceous oceanic plateaus in the Pacific and Indian Ocean: Ontong Java, Kerguelen, and Caribbean.\n\nGeologists believe that igneous oceanic plateaus may well represent a stage in the development of continental crust as they are generally less dense than oceanic crust while still being denser than normal continental crust.\n\nDensity differences in crustal material largely arise from different ratios of various elements, especially silicon. Continental crust has the highest amount of silicon (such rock is called felsic). Oceanic crust has a smaller amount of silicon (mafic rock). Igneous oceanic plateaus have a ratio intermediate between continental and oceanic crust, although they are more mafic than felsic.\n\nHowever, when a plate carrying oceanic crust subducts under a plate carrying an igneous oceanic plateau, the volcanism which erupts on the plateau as the oceanic crust heats up on its descent into the mantle erupts material which is more felsic than the material which makes up the plateau. This represents a step toward creating crust which is increasingly continental in character, being less dense and more buoyant. If an igneous oceanic plateau is subducted underneath another one, or under existing continental crust, the eruptions produced thereby produce material that is yet more felsic, and so on through geologic time.\n\n\n\n\n\n"}
{"id": "8798555", "url": "https://en.wikipedia.org/wiki?curid=8798555", "title": "Peaches of Immortality", "text": "Peaches of Immortality\n\nIn Chinese mythology, Peaches of Immortality ( or ) are consumed by the immortals due to their mystic virtue of conferring longevity on all who eat them. Peaches symbolizing immortality (or the wish for a long and healthy life) are a common symbol in Chinese art, appearing in depictions or descriptions in a number of fables, paintings, and other forms of art, often in association with thematically similar iconography, such as certain deities or immortals or other symbols of longevity, such as deer or cranes.\n\nThe Jade Emperor and his wife Xi Wangmu (Queen Mother of the West) ensured the deities' everlasting existence by feasting them with the peaches of immortality. The immortals residing in the palace of Xi Wangmu were said to celebrate an extravagant banquet called the \"Feast of Peaches\" (, or ), celebrated on earth in honor (birthday) of Xi Wangmu on the 3rd day of the 3rd moon month. The immortals wait six thousand years before gathering for this magnificent feast; the peach tree put forth leaves once every thousand years and it required another three thousand years for the fruit to ripen. Statues depicting Xi Wangmu's attendants often held three peaches. And the Eight Immortals crossing the seas to attend the banquet is a popular subject in paintings.\n\nBoth the \"\" and \"\" wrote about an imaginary meeting between the Emperor Wu of Han and the Queen Mother of the West offering the Peach to him.\n\nIt is a major item featured within the popular fantasy novel \"Journey to the West\". The first time in which these immortal peaches were seen had been within heaven when Sun Wukong had been stationed as the Protector of the Peaches. As the Protector, Sun quickly realized the legendary effects of the immortal peaches if they were to be consumed – over 3,000 years of life after the consumption of a single peach – and acted quickly as to consume one. However, he ended up running into many fragments of trouble such as a certain queen that was planning on holding a peach banquet for many members of Heaven. He manages to make himself very small and hide within a sacred peach. Later on within the series, he would have another chance to eat an immortal fruit – in which would be his second time. A certain tree was stationed behind a monastery run by a Taoist master and his disciples- in which the master had been gone. The tree bore 30 of the legendary Man-fruit (fruits that looked just like a new born, complete with sense organs) once every 10,000 years. The man-fruits would grant 360 years of life to one who merely smelled them and 47,000 years of life to one who consumed them. After this point within the novel, these Immortal Peaches would never be seen again.\n\nMembers of the Eight Immortals and the Old Man of the South Pole (a longevity deity) are sometimes depicted carrying a Peach of Immortality.\n\nBecause of the stories and the peach's association with long-life, peach is a common decoration (the fruit or an image thereof) on traditional birthday cakes and pastries in China.\n\nAnother peach-related folktale from East Asia is the Momotarō.\n\n"}
{"id": "545051", "url": "https://en.wikipedia.org/wiki?curid=545051", "title": "Prospero (satellite)", "text": "Prospero (satellite)\n\nThe Prospero satellite, also known as the X-3, was launched by the United Kingdom in 1971. It was designed to undertake a series of experiments to study the effects of space environment on communications satellites and remained operational until 1973, after which it was contacted annually for over 25 years. Although Prospero was the first British satellite to have been launched successfully by a British rocket, the first British satellite placed in orbit was Ariel 1, launched in April 1962 on a U.S. rocket.\n\nProspero has the COSPAR (NSSC ID) designation 1971-093A and the US Space Command satellite catalogue number 05580.\n\nProspero was built by the Royal Aircraft Establishment in Farnborough. Initially called Puck, it was designed to conduct experiments to test the technologies necessary for communication satellites, such as solar cells, telemetry and power systems. It also carried a micrometeoroid detector, to measure the presence of very small particles. When the Ministry of Defence cancelled the Black Arrow programme, the development team decided to continue with the project, but renamed the satellite Prospero when it was announced it would be the last launch attempt using a British rocket. An earlier Black Arrow launch, carrying the Orba X-2 satellite, had failed to achieve orbit after a premature second-stage shut down.\n\nProspero was launched at 04:09 GMT on 28 October 1971, from Launch Area 5B (LA-5B) at Woomera, South Australia, on a Black Arrow rocket, making Britain the sixth nation to place a satellite into orbit using a domestically developed carrier rocket. The Black Arrow's final stage Waxwing rocket also entered orbit, \"rather too enthusiastically\", as it continued to thrust after separation and collided with Prospero, detaching one of the satellite's four radio antenna.\n\nA tape recorder is on board, which failed on 24 May 1973 after 730 plays.\n\nAs was noted in an episode of the BBC television series \"Coast\", radio transmissions from Prospero could still be heard on 137.560 MHz in 2004, though the signals used in the episode would actually come from an Orbcomm satellite, rather than Prospero itself (as the later Orbcomm used the same 137.560 MHz frequency since Prospero was considered no longer active). Prospero had officially been deactivated in 1996, when the UK's Defence Research Establishment decommissioned their satellite tracking station at Lasham, Hampshire, but the satellite had been turned on in past years on its anniversary. It is in a low Earth orbit, and is not expected to decay until about 2070, almost 100 years after its launch.\n\nIn September 2011 a team at University College London's Mullard Space Science Laboratory announced plans to re-establish communications with Prospero, in time for the satellite's 40th anniversary. As of September 2012, not much progress had been made in establishing contact with the satellite due to time constraints.\n\n\nNotes\nBibliography\n\n"}
{"id": "46800736", "url": "https://en.wikipedia.org/wiki?curid=46800736", "title": "Renewable energy in the Cook Islands", "text": "Renewable energy in the Cook Islands\n\nThe Cook Islands is a Large Ocean State with an Exclusive Economic Zone spanning approximately 2 million km2. It extends from latitude 8° to 23° South, longitude 156° to 167° West. The nation is divided into a northern group of six islands and a southern group of nine islands. Three are uninhabited (Suwarrow, Manuae and Takutea). Rarotonga is the most populated island with about 85% of the national population; the outer islands are remote and sparsely populated.\n\nElectrical power has been provided by generators on each island, but diesel fuel is sourced from Auckland and requires long sea voyages, especially to the northern atolls. Faced with global climate change driven largely by human activities, shipping fuel such long distances no longer seems viable. carbon footprint. The outer islands conserved fuel by turning the power off overnight (11 pm to 6 am), but because Taio shipping is rare they occasionally still ran out of fuel. Rarotonga and Manihiki had 24-hour power.\n\nNew Zealand Government decided to assist Cook Islands by providing solar power in the northern atolls. The AID programme \"Uira Natura ko Tokerau\" (NZ$20 million) was provided by the Ministry of Foreign Affairs & Trade Construction of the solar arrays was by PowerSmart Solar of New Zealand \n\nThe first solar site was at Rakahanga, which was completed in September 2014. Pukapuka and Nassau were next, going online at Christmas 2014. Construction began at Tongareva on 23 February 2015 and just 10 weeks later both villages Omoka and Te Tautua were running on solar power. Manihiki was progressed at the same time. In June 2015 all of the northern atolls were fully solar powered. In addition the requirement to send ships north during the \"cyclone season\" (November to April) is now reduced.\n\nThe solar arrays photovoltaic produce 800 volts DC, which is inverted to 230 volts AC and fed to the grid. Power can be inverted again to 48 volts DC to trickle charge the batteries. The system is completed with a small diesel generator that starts automatically.\n\nConstruction of solar arrays in the Southern Cook Islands is out for tender, and should be funded by the Asian Development Bank; it is expected that Cook Islands will be entirely solar powered by 2020\n"}
{"id": "962035", "url": "https://en.wikipedia.org/wiki?curid=962035", "title": "Seismic refraction", "text": "Seismic refraction\n\nSeismic refraction is a geophysical principle (see refraction) governed by Snell's Law. Used in the fields of engineering geology, geotechnical engineering and exploration geophysics, seismic refraction traverses (seismic lines) are performed using a seismograph(s) and/or geophone(s), in an array and an energy source. The seismic refraction method utilizes the refraction of seismic waves on geologic layers and rock/soil units in order to characterize the subsurface geologic conditions and geologic structure.\n\nThe methods depend on the fact that seismic waves have differing velocities in different types of soil (or rock): in addition, the waves are refracted when they cross the boundary between different types (or conditions) of soil or rock. The methods enable the general soil types and the approximate depth to strata boundaries, or to bedrock, to be determined.\n\nP-wave refraction evaluates the compression wave generated by the seismic source located at a known distance from the array. The wave is generated by vertically striking a striker plate with a sledgehammer, shooting a seismic shotgun into the ground, or detonating an explosive charge in the ground. Since the compression wave is the fastest of the seismic waves, it is sometimes referred to as the primary wave and is usually more-readily identifiable within the seismic recording as compared to the other seismic waves.\n\nS-wave refraction evaluates the shear wave generated by the seismic source located at a known distance from the array. The wave is generated by horizontally striking an object on the ground surface to induce the shear wave. Since the shear wave is the second fastest wave, it is sometimes referred to as the secondary wave. When compared to the compression wave, the shear wave is approximately one-half (but may vary significantly from this estimate) the velocity depending on the medium.\n\ni - critical angle\nV - velocity of the first layer\nV - velocity of the second layer\nh - thickness of the first layer\nT0 - intercept\n\n\n\n"}
{"id": "29538735", "url": "https://en.wikipedia.org/wiki?curid=29538735", "title": "Student Switch Off", "text": "Student Switch Off\n\nThe Student Switch Off is a campaign that aims to encourage students to save energy when living in University halls of residence. It is run by the National Union of Students. \n\nThe campaign currently runs at 35 universities across the UK and 10 Universities across Europe. In the academic year 2016/17, 26,000+ students pledged their support for energy-saving in their halls of residence.\n\nThe scheme concentrates on behavioural change and social marketing to bring about carbon reduction.\n\nIn May 2012 the campaign won an Ashden Award (described as the Oscars of the energy-saving world) and in March 2011 won the 'Best Energy Saving Idea' award at the inaugural People and Environment Achievement Awards.\n\nThe campaign was set up by Dr Neil Jennings as a pilot project at the University of East Anglia in 2006. In the pilot year the campaign helped to reduce energy usage by an average of over 10% in halls of residence – saving around 90 tonnes of and over £19,000 in energy expenditure. Neil Jennings received significant support in developing the campaign from the Ben & Jerry's Climate Change College, and secured sponsorship of the campaign from E.ON, Odeon, The Independent and First.\n\nThe campaign expanded to 7 Universities in 2007/08 and 11 in 2008/09 until in 2009 the Student Switch Off partnered with the National Union of Students (United Kingdom) as part of the Defra funded Degrees Cooler project, increasing the numbers of Universities hosting the campaign by 22. Other partners included People & Planet, London Sustainability Exchange, Green Impact and Student Force for Sustainability.\n\nIn 2009, the Student Switch Off was chosen by Carbon Leapfrog as one of the projects it would support with pro-bono legal and accountancy support. \n\nIn 2012 ownership of the campaign was transferred to the National Union of Students and in 2014 the campaign received funding from the EU to expand into four more European countries - Cyprus, Greece, Lithuania and Sweden.\n\nIn 2017 the campaign received additional funding from the EU to expand to Bulgaria, Ireland and Romania and to develop advice materials for students living in the private rented sector to reduce their exposure to fuel poverty.\n\nN.B. The aggregate CO2 and £ saving is variable between years even with a similar % reduction because of changing prices of energy, changing carbon emissions per kWh of electricity and changing number of months included in the analysis at different Universities.\n\nThe Student Switch Off has picked up the following awards since its inception in 2006:\n\nMay 2012: Ashden Awards Winner \n\nMarch 2011: Climate Week Awards. Finalist in Best Campaign category \n\nMarch 2011: People and Environment Achievement Awards. Winner, Best Energy Saving Idea\n\nJune 2010: National eWell-Being Awards. Highly commended, Energy efficiency category\n\nNov 2008: The Green Awards. Highly commended, Best Green Campaigner\n"}
{"id": "6787317", "url": "https://en.wikipedia.org/wiki?curid=6787317", "title": "Talalay process", "text": "Talalay process\n\nThe Talalay process is a method of producing molded pieces of latex foam rubber. A liquid latex rubber base is introduced to a closed mold and is then vacuumed of air. The mold is then frozen to stabilize the cell structure. Carbon dioxide gas is introduced and the mold is heated to cure the rubber. Leon, Joseph and Anselm Talalay developed the \"Talalay\" process at various commercial entities. B.F. Goodrich in Shelton, Connecticut, Dunlopillo in Pannal, Harrogate, UK, and Vita Talalay in Maastricht, Netherlands, made this process commercially practical in the late 1940s. The first Talalay production plants were built in England, Canada and the United States.\n\nThe Talalay process is an elaborate process that yields very controlled densities and product \"feel\". The formulation uses many of the same base components as the Dunlop formulation, but without gellation reagents. The result is marketed as a healthier alternative to petroleum-based foams since petroleum-based foams give off volatile organic compounds as they age. In the marketing of products such as beds that include \"natural\" latex foams created with the Talalay process, these products are sometimes characterised as 'organic' or as completely natural however there are different methods of producing Talalay that alter how natural the formula finishes. One compound called Styrene Butadyne Runner is a form of synthetic latex used by Talalay Global And is mixed with the latex from the hevea tree to form the final Talalay product. Vita Talalay in the Netherlands still produces a Talalay product that is free of Styrene Butadyne and uses the latex from the hevea tree and the entire base.\n\nThe process utilizes a closed mold with pre-vacuum, followed by freezing to maintain uniform bubble geometry. Carbon dioxide (CO) is flooded through the frozen, open foam matrix to form carbonic acid (CO+HO→ HCO). Much like the addition of sodium fluorosilicate (NaSiF) in the Dunlop process, the carbonic acid lowers the pH, thereby causing gellation. In the next process step, vulcanization locks the foam into a uniform bubble distribution.\n\nAfter the foamer aeration step, the compound is distributed into an opened mold in a precise volume and pattern. The Talalay type mold is designed to be closed and sealed with pressure provided by press hydraulics. After closing the mold, a vacuum is applied to the interior, thereby causing the air matrix bubbles to \"inflate\" and fill out the mold form.\n\nWhile being supported by the vacuum, the mold and foam mass temperature is reduced to −20 °F (−28 °C) and frozen in place. Because the resultant foam matrix is open, carbon dioxide can be pushed through the structure, thereby forming carbonic acid that moves the pH from above 10 to 7. The reduction in alkalinity triggers the foam to gel in place and hold its shape.\n\nThe mold temperature can then be incrementally raised to the vulcanization temperature of 230 °F (115 °C) for a measured amount of time. At this point, the foam form can be de-molded and sent to a washing step. Typical molding cycles are 60 minutes. After washing, the foam form is introduced into the vulcanizer stage to complete the cross-linking process. The final step is the drying process where residual moisture is driven off.\n"}
{"id": "1559907", "url": "https://en.wikipedia.org/wiki?curid=1559907", "title": "The Hype about Hydrogen", "text": "The Hype about Hydrogen\n\nThe Hype about Hydrogen: Fact and Fiction in the Race to Save the Climate is a book by Joseph J. Romm, published in 2004 by Island Press and updated in 2005. The book has been translated into German as \"Der Wasserstoff-Boom\". Romm is an expert on clean energy, advanced vehicles, energy security, and greenhouse gas mitigation.\n\nOver 200 publications, including \"Scientific American\", \"Forbes\" magazine and \"The New York Times\", have cited this book.\nThe book was named one of the best science and technology books of 2004 by Library Journal.\n\nThe thrust of the book is that hydrogen is not economically feasible to use for transportation, nor will its use reduce global warming, because of the cost and greenhouse gases generated during production, the low energy content per volume and weight of the container, the cost of the fuel cells, and the cost of the infrastructure. The author argues that a major effort to introduce hydrogen cars before 2030 would actually undermine efforts to reduce emissions of heat-trapping greenhouse gases such as carbon dioxide.\n\"The Hype about Hydrogen\" contends that global warming and U.S. reliance on foreign fuel imports cannot be solved by the hypothetical hydrogen economy that has been advanced as a possible solution to these problems, and that \"neither government policy nor business investment should be based on the belief that hydrogen cars will have meaningful commercial success in the near or medium term.\"\n\nThe book explains how fuel cells work and compares different types. It then reviews the difficulties in marketing fuel cells for applications other than transportation and argues that these are in fact easier and more likely to happen sooner than transportation applications.\n\nThe history of hydrogen and its methods of production are then described. The book claims that the most common and cost-effective method of hydrogen production is from natural gas, which emits large amounts of CO (a greenhouse gas), since it would require too much electric power to produce hydrogen using the electrolysis method. The monetary costs of hydrogen fueling infrastructure for the U.S. are then estimated at half a trillion U.S. dollars, and the book describes additional energy and environment costs to liquefy and compress hydrogen for use in fueling stations.\n\nThe book goes on to discuss the hypothetical evolution of the cost of vehicles with fuel cells and with hydrogen-powered internal combustion engines, as well as possible adoption strategies. It then reviews the issue of the greenhouse effect and offers four reasons why hydrogen would not be useful in reducing greenhouse gas emissions: \n\nThe book then describes pilot projects in Iceland and California.\n\nIn its conclusion, the book states that hydrogen will not be widely available as a transportation fuel for a long time, and describes other strategies, including energy conservation techniques, to combat global warming.\n\n\"The Hype about Hydrogen\" was named one of the best science and technology books of 2004 by Library Journal. The New York Review of Books stated that the book gives \"the most direct answers\" to the question on the promise of a near-term hydrogen economy, calling Romm \"a hydrogen realist\". The environmental community newsletter TerraGreen agrees with Romm in the claim that \"the car of the near future is the hybrid vehicle\", and cites the book's good reception by Toyota's advanced technologies group. The San Diego Union Tribune's 2004 review noted that Romm's \"clear logic\" reaches conclusions similar to an authoritative study issued by the National Academy of Sciences.\n\nThree UC Davis scientists who also reviewed the book agreed on its basic premises, but claimed that Romm had made selective use of sources, for example, citing the highest cost estimates, adopting extremely high estimates of efficiency for advanced gasoline vehicles, and giving weight to controversial non-peer-reviewed studies. \nRomm and Prof. Andrew A. Frank co-authored an article, \"Hybrid Vehicles Gain Traction\", published in the April 2006 issue of Scientific American, in which they argue that hybrid cars that can be plugged into the electric grid (Plug-in hybrid electric vehicles), rather than hydrogen fuel cell vehicles, will soon become standard in the automobile industry.\n\n\n"}
{"id": "203085", "url": "https://en.wikipedia.org/wiki?curid=203085", "title": "Tropical and subtropical grasslands, savannas, and shrublands", "text": "Tropical and subtropical grasslands, savannas, and shrublands\n\nTropical and subtropical grasslands, savannas, and shrublands are terrestrial biomes dominated by grass and/or shrubs located in semi-arid to semi-humid climate regions of subtropical and tropical latitudes.\n\nGrassland is dominated by grass and other herbaceous plants. Savanna is grassland with scattered trees. Shrubland is dominated by woody or herbaceous shrubs.\n\nRainfall in tropical and subtropical grassland, savanna, and shrubland is between 500 and 1300 millimeters (20 to 50 inches) a year, and can be highly seasonal, with the entire year's rainfall sometimes occurring within a couple of weeks.\n\nTropical and subtropical grasslands, savannas, and shrublands occur on all continents but Antarctica. They are widespread in Africa, and are also found all throughout South Asia, the northern parts of South America and Australia, and the southern United States.\n\nAfrican savannas occur between forest or woodland regions and grassland regions. The climate varies, with an average temperature of 27 °C with peaks of 30 °C in April and October, and between 300 and 1500 mm of rain per year. Flora includes:\n\n"}
{"id": "39794191", "url": "https://en.wikipedia.org/wiki?curid=39794191", "title": "Valid Time Event Code", "text": "Valid Time Event Code\n\nValid Time Event Code (VTEC) is a code used by the National Weather Service, a part of National Oceanic and Atmospheric Administration (NOAA) of the United States government, to identify products / events.\n"}
{"id": "7817474", "url": "https://en.wikipedia.org/wiki?curid=7817474", "title": "Vapor–liquid equilibrium", "text": "Vapor–liquid equilibrium\n\nIn thermodynamics and chemical engineering, the vapor–liquid equilibrium (VLE) describes the distribution of a chemical species between the vapor phase and a liquid phase.\n\nThe concentration of a vapor in contact with its liquid, especially at equilibrium, is often expressed in terms of vapor pressure, which will be a partial pressure (a part of the total gas pressure) if any other gas(es) are present with the vapor. The equilibrium vapor pressure of a liquid is in general strongly dependent on temperature. At vapor–liquid equilibrium, a liquid with individual components in certain concentrations will have an equilibrium vapor in which the concentrations or partial pressures of the vapor components have certain values depending on all of the liquid component concentrations and the temperature. The converse is also true: if a vapor with components at certain concentrations or partial pressures is in vapor–liquid equilibrium with its liquid, then the component concentrations in the liquid will be determined dependent on the vapor concentrations and on the temperature. The equilibrium concentration of each component in the liquid phase is often different from its concentration (or vapor pressure) in the vapor phase, but there is a relationship. The VLE concentration data can be determined experimentally, or computed or approximated with the help of theories such as Raoult's law, Dalton's law, and Henry's law.\n\nSuch vapor–liquid equilibrium information is useful in designing columns for distillation, especially fractional distillation, which is a particular specialty of chemical engineers. Distillation is a process used to separate or partially separate components in a mixture by boiling (vaporization) followed by condensation. Distillation takes advantage of differences in concentrations of components in the liquid and vapor phases.\n\nIn mixtures containing two or more components, the concentrations of each component are often expressed as mole fractions. The mole fraction of a given component of a mixture in a particular phase (either the vapor or the liquid phase) is the number of moles of that component in that phase divided by the total number of moles of all components in that phase.\n\nBinary mixtures are those having two components. Three-component mixtures are called ternary mixtures. There can be VLE data for mixtures with even more components, but such data is often hard to show graphically. VLE data is a function of the total pressure, such as 1 atm or whatever pressure the process is conducted at.\n\nWhen a temperature is reached such that the sum of the equilibrium vapor pressures of the liquid components becomes equal to the total pressure of the system (it is otherwise smaller), then vapor bubbles generated from the liquid begin to displace the gas that was maintaining the overall pressure, and the mixture is said to boil. This temperature is called the \"boiling point\" of the liquid mixture at the given pressure. (It is assumed that the total pressure is held steady by adjusting the total volume of the system to accommodate the specific volume changes that accompany boiling.) The boiling point at an overall pressure of 1 atm is called the \"normal boiling point\" of the liquid mixture.\n\nThe field of thermodynamics describes when vapor–liquid equilibrium is possible, and its properties. Much of the analysis depends on whether the vapor and liquid consist of a single component, or if they are mixtures.\n\nIf the liquid and vapor are pure, in that they consist of only one molecular component and no impurities, then the equilibrium state between the two phases is described by the following equations:\n\nwhere formula_4 and formula_5 are the pressures within the liquid and vapor, formula_6 and formula_7 are the temperatures within the liquid and vapor, and formula_8 and formula_9 are the molar Gibbs free energies (units of energy per amount of substance) within the liquid and vapor, respectively. In other words, the temperature, pressure and molar Gibbs free energy are the same between the two phases when they are at equilibrium.\n\nAn equivalent, more common way to express the vapor–liquid equilibrium condition in a pure system is by using the concept of fugacity. Under this view, equilibrium is described by the following equation:\n\nwhere formula_11 and formula_12 are the fugacities of the liquid and vapor, respectively, at the system temperature and pressure . \"Chemical Engineering Thermodynamics\", p. 218.</ref> and it is often convenient to use the quantity formula_13, the dimensionless \"fugacity coefficient\", which is 1 for an ideal gas.\n\nIn a multicomponent system, where the vapor and liquid consist of more than one type of compounds, describing the equilibrium state is more complicated. For all components in the system, the equilibrium state between the two phases is described by the following equations:\n\nwhere and are the temperature and pressure for each phase, and formula_17 and formula_18 are the partial molar Gibbs free energy also called chemical potential (units of energy per amount of substance) within the liquid and vapor, respectively, for each phase. The partial molar Gibbs free energy is defined by:\n\nwhere is the (extensive) Gibbs free energy, and is the amount of substance of component .\n\nBinary mixture VLE data at a certain overall pressure, such as 1 atm, showing mole fraction vapor and liquid concentrations when boiling at various temperatures can be shown as a two-dimensional graph called a boiling-point diagram. The mole fraction of component 1 in the mixture can be represented by the symbol . The mole fraction of component 2, represented by , is related to in a binary mixture as follows:\n\nIn multi-component mixtures in general with n components, this becomes: \n\nThe preceding equilibrium equations are typically applied for each phase (liquid or vapor) individually, but the result can be plotted in a single diagram. In a binary boiling-point diagram, temperature () is graphed vs. . At any given temperature where both phases are present, vapor with a certain mole fraction is in equilibrium with liquid with a certain mole fraction. The two mole fractions often differ. These vapor and liquid mole fractions are represented by two points on the same horizontal isotherm (constant ) line. When an entire range of temperatures vs. vapor and liquid mole fractions is graphed, two (usually curved) lines result. The lower one, representing the mole fraction of the boiling liquid at various temperatures, is called the \"bubble point curve\". The upper one, representing the mole fraction of the vapor at various temperatures, is called the \"dew point curve\".\n\nThese two curves necessarily meet where the mixture becomes purely one component, namely where (and , pure component 2) or (and , pure component 1). The temperatures at those two points correspond to the boiling points of each of the two pure components.\n\nFor certain pairs of substances, the two curves also coincide at some point strictly between and . When they meet, they meet tangently; the dew-point temperature always lies above the boiling-point temperature for a given composition when they are not equal. The meeting point is called an azeotrope for that particular pair of substances. It is characterized by an azeotrope temperature and an azeotropic composition, often expressed as a mole fraction. There can be maximum-boiling azeotropes, where the azeotrope temperature is at a maximum in the boiling curves, or minimum-boiling azeotropes, where the azeotrope temperature is at a minimum in the boiling curves.\n\nIf one wants to represent a VLE data for a three-component mixture as a boiling point \"diagram\", a three-dimensional graph can be used. Two of the dimensions would be used to represent the composition mole fractions, and the third dimension would be the temperature. Using two dimensions, the composition can be represented as an equilateral triangle in which each corner represents one of the pure components. The edges of the triangle represent a mixture of the two components at each end of the edge. Any point inside the triangle represents the composition of a mixture of all three components. The mole fraction of each component would correspond to where a point lies along a line starting at that component's corner and perpendicular to the opposite edge. The bubble point and dew point data would become curved surfaces inside a triangular prism, which connect the three boiling points on the vertical temperature \"axes\". Each face of this triangular prism would represent a two-dimensional boiling-point diagram for the corresponding binary mixture. Due to their three-dimensional complexity, such boiling-point diagrams are rarely seen. Alternatively, the three-dimensional curved surfaces can be represented on a two-dimensional graph by the use of curved isotherm lines at graduated intervals, similar to iso-altitude lines on a map. Two sets of such isotherm lines are needed on such a two-dimensional graph: one set for the bubble point surface and another set for the dew point surface.\n\nThe tendency of a given chemical species to partition itself\npreferentially between liquid and vapor phases is the Henry's law constant. There can be VLE data for mixtures of four or more components, but such a boiling-point diagram is hard to show in either tabular or graphical form. For such multi-component mixtures, as well as binary \nmixtures, the vapor–liquid equilibrium data are represented in terms of values (vapor–liquid distribution ratios) defined by\n\nwhere and are the mole fractions of component  in the phases and respectively.\n\nFor Raoult's law \nFor modified Raoult's law\n\nwhere formula_23 is the activity coefficient, is the partial pressure and is the pressure\n\nThe values of the ratio are correlated empirically or theoretically in terms of temperature, pressure and phase compositions in the form of equations, tables or graph such as the DePriester charts (Shown on the right).\n\nFor binary mixtures, the ratio of the values for the two components is called the relative volatility denoted by \n\nwhich is a measure of the relative ease or difficulty of separating the two components. Large-scale industrial distillation is rarely undertaken if the relative volatility is less than 1.05 with the volatile component being and the less volatile component being .\n\nFor each component in a binary mixture, one could make a vapor–liquid equilibrium diagram. Such a diagram would graph liquid mole fraction on a horizontal axis and vapor mole fraction on a vertical axis. In such VLE diagrams, liquid mole fractions for components 1 and 2 can be represented as and respectively, and vapor mole fractions of the corresponding components are commonly represented as and . Similarly for binary mixtures in these VLE diagrams: \n\nSuch VLE diagrams are square with a diagonal line running from the () corner to the () corner for reference.\n\nThese types of VLE diagrams are used in the McCabe–Thiele method to determine the number of equilibrium stages (or theoretical plates) needed to distill a given composition binary feed mixture into one distillate fraction and one bottoms fraction. Corrections can also be made to take into account the incomplete efficiency of each tray in a distillation column when compared to a theoretical plate.\n\nAt boiling and higher temperatures the sum of the individual component partial pressures becomes equal to the overall pressure, which can symbolized as \"P\".\n\nUnder such conditions, Dalton's law would be in effect as follows: \n\nThen for each component in the vapor phase: \n\nwhere \"P\" = partial pressure of component 1, \"P\" = partial pressure of component 2, etc.\n\nRaoult's law is approximately valid for mixtures of components between which there is very little interaction other than the effect of dilution by the other components. Examples of such mixtures includes mixtures of alkanes, which are non-polar, relatively inert compounds in many ways, so there is little attraction or repulsion between the molecules. Raoult's law states that for components 1, 2, etc. in a mixture:\n\nwhere \"P\", P, etc. are the vapor pressures of components 1, 2, etc. when they are pure, and \"x\", \"x\", etc. are mole fractions of the corresponding component in the liquid.\n\nRecall from the first section that vapor pressures of liquids are very dependent on temperature. Thus the \"P\" pure vapor pressures for each component are a function of temperature (\"T\"): For example, commonly for a pure liquid component, the Clausius–Clapeyron relation may be used to approximate how the vapor pressure varies as a function of temperature. This makes each of the partial pressures dependent on temperature also regardless of whether Raoult's law applies or not. When Raoult's law is valid these expressions become:\n\nAt boiling temperatures if Raoult's law applies, the total pressure becomes:\n\nAt a given \"P\" such as 1 atm and a given liquid composition, \"T\" can be solved for to give the liquid mixture's boiling point or bubble point, although the solution for \"T\" may not be mathematically analytical (i.e., may require a numerical solution or approximation). For a binary mixture at a given \"P\", the bubble point \"T\" can become a function of \"x\" (or \"x\") and this function can be shown on a two-dimensional graph like a binary boiling point diagram.\n\nAt boiling temperatures if Raoult's law applies, a number of the preceding equations in this section can be combined to give the following expressions for vapor mole fractions as a function of liquid mole fractions and temperature: \n\nOnce the bubble point \"T\"'s as a function of liquid composition in terms of mole fractions have been determined, these values can be inserted into the above equations to obtain corresponding vapor compositions in terms of mole fractions. When this is finished over a complete range of liquid mole fractions and their corresponding temperatures, one effectively obtains a temperature  \"T\" function of vapor composition mole fractions. This function effectively acts as the dew point \"T\" function of vapor composition.\n\nIn the case of a binary mixture, \"x\" = 1 − \"x\" and the above equations can be expressed as: \n\nFor many kinds of mixtures, particularly where there is interaction between components beyond simply the effects of dilution, Raoult's law does not work well for determining the shapes of the curves in the boiling point or VLE diagrams. Even in such mixtures, there are usually still differences in the vapor and liquid equilibrium concentrations at most points, and distillation is often still useful for separating components at least partially. For such mixtures, empirical data is typically used in determining such boiling point and VLE diagrams. Chemical engineers have done a significant amount of research trying to develop equations for correlating and/or predicting VLE data for various kinds of mixtures which do not obey Raoult's law well.\n\n\n"}
{"id": "7934659", "url": "https://en.wikipedia.org/wiki?curid=7934659", "title": "Void ratio", "text": "Void ratio\n\nThe void ratio of a mixture is the ratio of the volume of voids to volume of solids.\n\nIt is a dimensionless quantity in materials science, and is closely related to porosity as follows:\n\nand\n\nwhere formula_3 is void ratio, formula_4 is porosity, \"V\" is the volume of void-space (such as fluids), \"V\" is the volume of solids, and \"V\" is the total or bulk volume. This figure is relevant in composites, in mining (particular with regard to the properties of tailings), and in soil science. In geotechnical engineering, it is considered as one of the state variables of soils and represented by the symbol e.\n\nNote that in geotechnical engineering, the symbol formula_4 usually represents the angle of shearing resistance, a shear strength (soil) parameter. Because of this, the equation is usually rewritten using formula_6 for porosity:\n\nand\n\nwhere formula_3 is void ratio, formula_6 is porosity, \"V\" is the volume of void-space (air and water), \"V\" is the volume of solids, and \"V\" is the total or bulk volume.\n\n\n"}
{"id": "9715434", "url": "https://en.wikipedia.org/wiki?curid=9715434", "title": "Wave farm", "text": "Wave farm\n\nA wave farm – or wave power farm or wave energy park – is a collection of machines in the same location and used for the generation of wave power electricity. Wave farms can be either offshore or nearshore, with the former the most promising for the production of large quantities of electricity for the grid. The first wave farm was constructed in Portugal, the Aguçadoura Wave Farm, consisting of three Pelamis machines. The world's largest is planned for Scotland.\n\nFunding for a wave farm in Scotland was announced on February 20, 2007 by the Scottish Executive, at a cost of over £4 million, as part of a £13 million funding packages for marine power in Scotland. The farm will be the world's largest with a capacity of 3MW generated by four Pelamis machines. See also: Renewable energy in Scotland.\n\nOcean Power Technologies (OPT), based in Pennington, New Jersey is involved in the development of a wave farm off Cromarty Firth. The PB150 PowerBuoy was successfully deployed at sea in 2011 by a team including Scotland-based Global Maritime Scotland Ltd, Port Services (Invergordon) Ltd and OPT, with the support of the Cromarty Firth Port Authority.\n\nThe £10 million Saltire prize challenge will be awarded to the first to be able to generate 100 GWh from wave power over a continuous two-year period by 2017 (about 5.7 MW average).\n\nFunding for a wave farm known as Wave hub off the north coast of Cornwall, England was approved in June 2007. The Wave hub operates as an extension cable allowing developers to install and operate wave energy generating devices while keeping down connection costs. Four device operators have expressed an interest in using the site which will initially allow up to 20MW of wave energy capacity.\n\nOcean Power Technologies (OPT), based in Pennington, New Jersey is involved in Wave Hub. Located in Cornwall, England, OPT aims to develop its PowerBuoy technology, an innovative renewable energy project, and expects to create the UK's first offshore facility for the demonstration and proving of arrays of wave energy generation devices.\n\nA 2017 study estimates that commercial wave farms are not close to being feasible.\n\nWave power in the United States is under development in several locations off the east & west coasts as well as Hawaii. It has moved beyond the research phase and major installations are planned to come on-line within the next few years. Its use to-date has been for situations where other forms of energy production are not economically viable and as such, the power output is currently modest.\n\nAccording to the president of trade association Ocean Renewable Energy Coalition, “The total potential off the coast of the United States is 252 million megawatt hours a year.” Despite the absence of current implementation of major projects, there has been significant investment on the part of public utility companies and federal funds for the implementation and economic viability of two new wave power energy centers as of September 30, 2008.\n\nOn December 18, 2007 the Pacific Gas & Electric Company, the largest national utility company, announced a commercial agreement to purchase power generated by wave energy. This decision was made in part to be competitive in the public electrical energy market in the state of California under stringent renewable energy restrictions. Currently, California state law requires that publicly owned utilities are required to generate 20% of their electricity from renewable energy sources such as wind, solar and wave power by 2010. After the General Election on November 4, 2008 this law may be subject to change to an even more stringent law, which states that publicly owned utilities would be required to increase their proportion of electricity from renewable resources to 20% by 2010, 40% by 2020 and 50% by 2025.\n\nFederally, under the Marine Renewable Energy Research and Development Act of 2007 the United States has committed $200 million in federal funds toward wave energy technology to be allocated from 2008 through 2012. The United States Department of Energy (DOE) is currently responsible for the allocation of $50 million per fiscal year for research, development, demonstration and commercial application of ocean energy. In 2008, the first year of federal allocation toward wave energy, there are a total of fourteen recipients. The most notable recipients of this year include Oregon State University and the University of Hawaii. Oregon State University in partnership with the University of Washington, will implement the development of the Northwest National Marine Renewable Energy Center for wave and tidal energy. The second recipient, University of Hawaii will develop and implement the National Renewable Marine Energy Center in Hawaii.\n\nThe Grays Harbor Ocean Energy Company of Seattle has applied to the Federal Energy Regulatory Commission for permits to harness energy from waves off the coastline of California, Hawaii, Massachusetts, New Jersey, New York and Rhode Island. The $28 billion project would be the largest renewable energy project in the nation.\n\nIn 2012, Ocean Power Technologies (O.P.T.), based in Pennington, New Jersey is involved in the following wave projects in the US:\n\nThe Mutriku Breakwater Wave Plant is the world´s first breakwater wave plant with a multiple turbine arrangement. It is located in the Mutriku´s dike and has been producing electrical energy since July 2011. The plant has a capacity of 296 kW from 16 turbines and 16 OWCs. During the winter 2015, the plant supplied its first GWh to the grid. This up-and-running power plant is available as a test site where different researchers can test their WOC based generators.\n\nThe Aguçadoura Wave Farm was the world's first commercial-scale wave farm. It was located offshore near Póvoa de Varzim north of Oporto in Portugal. The farm used three Pelamis wave energy converters to convert the motion of the ocean surface waves into electricity, totalling to 2.25MW in total installed capacity. The farm first generated electricity into the Portuguese grid in July 2008 and was officially opened on September 23, 2008, by the Portuguese Minister of Economy. The wave farm was shut down two months after the official opening in November 2008 due to technical problems with the machines.\n\nThe company 40South Energy has its offshore test site in Castiglioncello, Italy, and plans to upgrade the site to a commercial Wave Energy Park by connecting it with an electrical cable to shore. In the meantime, the owners of an offshore aquaculture installation in Lavagna, Italy, are in the process of converting their concession from fish farming to fish farming plus electricity production. The technology used in this Wave Energy Park will come from 40South Energy.\n\nIn 2013, Ocean RusEnergy company, based in Yekaterinburg, demonstrated a line of wave energy generators, ranging from 160W to 1MW(planned). Their modular design allows to assemble a wave power farm having a desired capacity. Unlike other wave power projects it targets small-scale and private electricity generation.\n\n\n"}
