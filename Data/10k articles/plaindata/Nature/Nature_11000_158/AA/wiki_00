{"id": "10473048", "url": "https://en.wikipedia.org/wiki?curid=10473048", "title": "Alcinoe", "text": "Alcinoe\n\nAlcinoe (; Ancient Greek: Ἀλκινόη \"Alkinóē\") is the name that is attributed to three women in Greek mythology:\n\n"}
{"id": "5704371", "url": "https://en.wikipedia.org/wiki?curid=5704371", "title": "Animals in the Bible", "text": "Animals in the Bible\n\nThe Bible names over 120 species of animals by current interpretive standards. The more a particular animal abounded in the Holy Land, the more frequent allusions to it may be found.\n\nA closer examination of the way in which references to animals are introduced, the frequency of allusions to certain species, and the date of the documents in which they are found gives a fair idea of the conditions of the area at different stages of its history. The species, for instance, called in Hebrew 're'em', was very probably the aurochs, or wild ox and totally disappeared about the time of the Babylonian captivity. The wild ass, the lion and a few others long ago became extinct in Palestine. Other species alluded to in the Bible are now extremely scarce.\n\nThe Bible mentions animals from varying regions of the Middle East. The ostrich, for instance, a denizen of the torrid regions, and the camel, of the waterless districts around Palestine, are mentioned side by side with the roebuck and deer of the woody summits of Lebanon. This variety, greater probably in Palestine than in any other country in the same latitude, is attributed to the great extremes of elevation and temperature in this small area. Palestinian fauna is not as rich today as it was during the Biblical times. The land is barren today but was well wooded when the Bible was written, especially on the hills east of the Jordan River.\n\nRecent excavations in the Timna Valley discovered what may be the earliest camel bones found in Israel or even outside the Arabian peninsula, dating to around 930 BCE. This is seen as evidence that the stories of Abraham, Joseph, Jacob and Esau were written after this time.\n\nAlthough no regular classification is to be sought for in the Bible, animal creation is there practically divided into four classes, often called kinds, according to the four different modes of locomotion. Among the animals, some walk, others fly, many are essentially swimmers and several crawl on the ground. This classification, more empiric than logical, would not by any means satisfy a modern scientist. It must be known, however, if we wish fairly to understand the language of the Scriptures on the matters connected therewith. The first class, the beasts, in the Biblical parlance, includes all large, walking animals, with the exception of the amphibia, such small animals as moles, mice and the like, and humans as they were not classified as animals.\n\nBeasts are divided into cattle, or domesticated (behemoth in the strict sense), and beasts of the field, i.e. wild animals. The fowls, which constitute the second class, include not only the birds, but also \"all things that fly\", even if they \"go upon four feet\", as the different kinds of locusts. Of the many \"living beings that swim in the water\" no particular species is mentioned; the \"great whales\" are set apart in that class, while the rest are divided according to whether they have, or have not, fins and scales (Leviticus 11:9, 10).\n\nThe reptiles, or \"creeping things\", form the fourth class. References to this class are relatively few. However, it should be noticed that the \"creeping things\" include not only the reptiles properly so called, but also all short-legged animals or insects which seem to crawl rather than to walk, such as moles, lizards, etc. From a religious viewpoint, all these animals are divided into two classes, clean and unclean, according to whether they can, or cannot, be eaten.\n\n\n"}
{"id": "432719", "url": "https://en.wikipedia.org/wiki?curid=432719", "title": "Anticrepuscular rays", "text": "Anticrepuscular rays\n\nAnticrepuscular rays, or antisolar rays, are atmospheric optical phenomena similar to crepuscular rays, but appear opposite of the Sun in the sky. Anticrepuscular rays are nearly parallel, but appear to converge toward the antisolar point due to linear perspective. Anticrepuscular rays are most frequently visible around sunrise or sunset.\n\nAppearing to radiate from the Sun, crepuscular rays usually look much brighter than anticrepuscular rays. This is because the atmospheric light scattering making the crepuscular rays visible occurs at low angles to the horizon (see Mie theory).\n\nAlthough anticrepuscular rays appear to converge toward the antisolar point, the convergence is actually an optical illusion. The rays are in fact almost parallel, and their apparent convergence is toward a vanishing point, which is an infinite distance away from the viewer.\n\n"}
{"id": "14515203", "url": "https://en.wikipedia.org/wiki?curid=14515203", "title": "Asrai", "text": "Asrai\n\nIn English folklore the asrai is a type of aquatic fairy that lives in seas and lakes and is similar to the mermaid and nixie. They are sometimes described as timid and shy, standing between two and four feet tall, or may be depicted as tall and lithe.\n\nTales from Cheshire and Shropshire tell of a fisherman who captured an asrai and put it in his boat. It seemed to plead for its freedom in an unknown language, and when the fisherman bound it the touch of its cold wet hands burned his skin like fire, leaving a permanent mark. He covered the asrai with wet weeds, and it continued to protest, its voice getting fainter and fainter. By the time the fisherman reached the shore the asrai had melted away leaving nothing but a puddle of water in the boat for it will perish if directly exposed too long to the sun. Their inability to survive daylight is similar to that of trolls from Scandinavian folklore.\n\nOther tales describe the asrai as having green hair and a fishtail instead of legs or may instead have webbed feet. They live for hundreds of years and will come up to the surface of the water once each century to bathe in the moonlight which they use to help them grow. If the asrai (usually depicted as female) sees a man she will attempt to lure him with promises of gold and jewels into the deepest part of the lake to drown or simply to trick him. However, she cannot tolerate human coarseness and vulgarity, and this will be enough to frighten her away.\n\nThe etymology of the word asrai is unknown. \"Ashray\" is sometimes given as a spelling variant.\n\nTheir oldest known appearance in print was the poem \"The Asrai\" by Robert Williams Buchanan, first published in April 1872, and followed by a sequel, \"A Changeling: A Legend of the Moonlight.\" Buchanan described them as nature-loving spirits who could not bear sunlight.\n\nThe second known mention of the asrai, and the first to explicitly describe them as beings from folklore, was Ruth Tongue's account in \"Forgotten Folk-Tales of the English Counties\" (1970). Tongue was an influential folklorist, but her accuracy has been called into question. She claimed to have grown up in Somerset, where she gathered most of her research, but this claim was later disproven. In \"A Dictionary of English Folklore,\" Jacqueline Simpson and Stephen Roud state that \"in \"Forgotten Folktales\" she gives only the vaguest hints as to where, when, and from whom she had obtained the stories; any notes she may have made at the time were lost in moves and fires.\"\n"}
{"id": "655266", "url": "https://en.wikipedia.org/wiki?curid=655266", "title": "Bottom crawler", "text": "Bottom crawler\n\nA bottom crawler is an underwater exploration and recovery vehicle. It is designed to sink to the bottom of a body of water, where it moves about using traction against the bottom with wheels or tracks. It is usually tethered to a surface ship by cables providing power, control, video, and lifting capabilities, but this is not essential.\n\nSuch devices have been proposed for use in recovering deep seabed minerals, such as manganese nodules.\n\nThese also have been considered since the late 1960s for use in offshore oil exploration and production in extremely deep water, but practical devices have used other technologies from the sea surface, such as moored barges and tension leg platforms.\n"}
{"id": "53036914", "url": "https://en.wikipedia.org/wiki?curid=53036914", "title": "Caleta Chonos Formation", "text": "Caleta Chonos Formation\n\nCaleta Chonos Formation () is a geological formation of Oligocene age located around Chacao Channel in southern Chile. The formation overlies Bahía Mansa Metamorphic Complex and is overlain by the Ancud Volcanic Complex. It crops out in northwestern Chiloé Island in the isthmus of Lacuy Peninsula. \n"}
{"id": "51487006", "url": "https://en.wikipedia.org/wiki?curid=51487006", "title": "Chemistry of wetland dredging", "text": "Chemistry of wetland dredging\n\nWetland chemistry is largely affected by dredging, which can be done for a variety of purposes. Wetlands are areas within floodplains with both terrestrial and aquatic characteristics, including marshes, swamps, bogs, and others. It has been estimated that they occupy around 2.8x10 km, about 2.2% of the earth’s surface, but other estimates are even higher. It has also been estimated to have a worth of $14.9 trillion and are responsible for 75% of commercial and 90% of recreational harvest of fish and shellfish in the United States. Wetlands also hold an important role in water purification, storm protection, industry, travel, research, education, and tourism. Being heavily used and traveled through, dredging is common and leads to continuation of long-term damage of the ecosystem and land loss, and ultimately a loss in industry, homes, and protection.\n\nWetlands undergo different chemical reactions depending on a variety of parameters, including salinity and pH. Redox reactions have a major effect on wetland ecosystems, as they depend heavily on salinity, pH, oxygen availability, and others. Common redox reactions in wetland include carbon, nitrogen, and sulfur transformations. Fluctuations in water flow and flooding can change the abundance of the oxidized or reduced species depending on the environment. Increased flooding and water flow can also change the availability of nutrients to local species. The further the wetlands change from their original states, the more difficult rebuilding land becomes. The types of mitigation efforts also change depending on the chemistry, so an understanding of the change is required for effective mitigation.\n\nWetlands are areas of land submerged in water near both terrestrial and aquatic systems. They are highly diverse and are classified by the United States Fish and Wildlife Service into five categories: “The term wetland includes a variety of areas that fall into one of five categories: (1) areas with hydrophytes and hydric soils, such as those commonly known as marshes, swamps, and bogs; (2) areas without hydrophytes but with hydric soils - for example, flats where drastic fluctuation in water level, wave action, turbidity, or high concentration of salts may prevent the growth of hydrophytes; (3) areas with hydrophytes but nonhydric soils, such as margins of impoundments or excavations where hydrophytes have become established but hydric soils have not yet developed; (4) areas without soils but with hydrophytes such as the seaweed-covered portion of rocky shores; and (5) wetlands without soil and without hydrophytes, such as gravel beaches or rocky shores without vegetation”.\n\nWetlands can also be classified based on salinity, a type of classification often referenced in research where salinity is a major factor. These classifications are often referred to in parts per thousand (ppt) and include freshwater (0-2 ppt), intermediate (2-10 ppt), brackish (10-20 ppt), and saltwater (20+ ppt).\n\nWetlands are sources of extreme biodiversity and ecological benefit. They contain a multitude of species of plants and animals, including 79 species classified as rare, threatened, or endangered. An estimate by the U.S. Fish and Wildlife Service indicates that wetlands provide for, directly and indirectly, up to 43% of federally threatened or endangered species. Wetlands are the leading producer of oysters, 50% of the shrimp crop, 75% of the alligator harvest, 27% of the oil and gas, and the largest port complex in the United States. The world’s wetlands have an estimated worth of $14.9 trillion.\n\nWetlands also provide for disaster protection, including surge protection from hurricanes, as they and barrier islands help to break down the power of a storm before it reaches mainland. They also provide flood relief, as they are able to hold about three-acre feet (one million gallons) of water. This holding of water allows for rejuvenation of ecosystems, as new sediment is able to settle. Flooding also affects factors such as root penetration, soil temperature, conductivity, and bulk density.\n\nWetlands are highly effective at removing pollutants and excess nutrients due to the slow water flow and absorption by the plant systems. This has been shown to be effective in the removal of nitrogen and phosphorus, the major nutrients involved in “dead zones”. They are also major sinks for heavy metals and sulfur.\nDredging is the removal of sediment, plant species, and debris from an aquatic area. Industry, travel, and recreation throughout wetlands often requires the dredging of canals, especially by oil industry to get out to their offshore drills through coastal wetlands. Canals widen after being dredged because of the increased water flow and loss of plant life, both attributing to increased erosion. It is estimated that there are 4,572 miles of canals south of the Intracoastal Waterway, not including Lake Ponchartrain and Lake Maurepas, and that canals alone attribute to 6.53 square miles of land loss per year in the United States. The permits required to dredge these canals include stipulations of refilling, but these are not often enforced. John M. Barry, along with a group of private lawyers and coastal experts, filed a lawsuit in 2013 against 97 corporations who had violated their permits in Louisiana’s coastal wetlands in response to this. It is referred to as “the most ambitious environmental lawsuit ever” by the New York Times and has been met with political resistance.\n\nWetlands are dynamic systems that undergo a variety of chemical reactions depending greatly on the specific physicochemical properties of the area, such as temperature, pressure, dissolved organic matter, pH, salinity, and dissolved gases (CO and O). The qualities that have the largest effect are salinity and pH. An increase in flooding (a result of dredging) increases the salinity of wetlands, as it allows saltwater to intrude, neutralizes the pH, and provides more anaerobic soil conditions. The conditions then effect the nutrient availability and redox reactions.\n\nRedox reactions are highly influential in wetland soil chemistry through transformations including those of carbon, sulfur, nitrogen. The abundance of oxygen changes the abundance of oxidized or reduced states of each compound. Areas of higher oxygen availability (aerobic) tend towards oxidized states and areas of low oxygen availability (anaerobic) tend towards reduced states. The abundance of each type results in a different ecosystem, as the plants and animals of the wetlands require specific conditions for their growth. Common wetland redox reactions include:2NO +10e +12H → N +6HOSO +8e +9H → HS +4HOCO +8e +8H → CH + 2HOMnO +2e +4H → Mn + 2HOFe(OH) +e +3H → Fe + 3HODredging allows for an increased flow of water through wetlands, causing anaerobic soil conditions. This change in wetland type results in a change in redox state for each reaction undergone and thus changes the plant species available to grow in those areas. The redox potential (Eh) can help to show the relationship of the redox reactions through the Nernst equation:Eh=E-(RT/nF)ln([Reductants]/[Oxidants][H]) This equation allows for the calculation of the extent of reaction between two redox systems and can be used, for example, to decide whether a particular reaction will go to completion or not.\n\nAn example of a change in these circumstances affecting the wetland system is in the transformation of pyrite (FeS) through the reduction of SO (found in seawater).Fe(OH) + e + H → Fe(OH) + HOSO + 6e + 8H → S + 4HOS + 2e + 2H → HSFe(OH) + HS → FeS + 2HOFeS + S → FeS (pyrite)The drainage of the resulted pyrite then results in oxidation to ferric hydroxide and sulfuric acid, causing extreme acidity (pH < 2).\n\nIncreased flooding also allows for saltwater intrusion, changing the salinity levels and killing off species of plants that normally grew and changing available nutrient, chemical, and oxygen levels as well. An increase in salinity leads to higher sulfate concentrations and higher sulfide emissions, and higher toxicity. It also results in a reduction of sulfur availability to plant species as it precipitates with trace metals such as zinc and copper. An example of this is Ferrous sulfide (FeS), which gives wetland soils their black color and is the source of sulfur commonly found in coal deposits.\n\nFlooding also results in pH neutralization of generally acidic (with exceptions) wetlands. Acidic wetlands inhibit denitrification, thus flooding allows denitrification to occur, resulting in a loss of gaseous nitrogen forms to the atmosphere. The reaction is shown below:5CHO +24NO +24H → 30CO +12N +42HOAnaerobic soil conditions brought on by flooding allows for precipitation of phosphates with ferric iron and aluminum (acidic soils) or calcium and magnesium (basic soils) resulting in phosphorus being unavailable for uptake in plant species.\n\nAs the environment is altered through physical means (dredging), the occurring reactions change resulting in a decrease of the availability of nutrients and chemical species to plant species and the ecosystem. This then further changes the physical environment as these species are no longer able to survive. The loss of species then results in further changes to the chemical environment, as they are no longer present to remove excess nutrients. This also changes the physical environment further as the lack of survival of plant species results in open land and increased erosion. The change of the chemical environment also affects the mitigation techniques to be applied for rebuilding of wetlands as the survival of plant species that could potentially be planted depends on the chemical environment, and changes must be monitored for effective mitigation to take place.\n"}
{"id": "12850901", "url": "https://en.wikipedia.org/wiki?curid=12850901", "title": "Climate risk", "text": "Climate risk\n\nClimate risk means a risk resulting from climate change and affecting natural and human systems and regions.\n\nIn the course of increasing global temperature and extreme weather phenomena\nthe Intergovernmental Panel on Climate Change (IPCC) has been founded by the United Nations Environment Programme (UNEP) and the World Meteorological Organization (WMO) for a better understanding of climate change and meeting concerns of these observations. Its main aim is evaluating climate risks and exploring strategies for the prevention of these risks.\n\nAs per current projections of IPCC the following future effects have to be expected:\n\nWhile affecting all economic sectors, the effect on single continents will differ. Beside these direct physical climate risks there are also indirect derived ones:\n\nDirect risks of climate change are expected especially for branches, which strongly depend on natural resources like agriculture, fishing, forestry, health care, real estate and tourism. For example, storms and flooding damage buildings and infrastructure, whereas hot summers with less precipitation cause crop failure.\nThe governmental endeavours to reduce climate costs have direct effects on economy. For example, the targets regarding emissions within the Kyoto-Protocol shall be realised by implementing emissions trading. By this instrument the value of emissions can be quantified monetarily, approximating the value of avoiding hazardous substances. This value shall be internalized by companies and considered in investment decisions. By considering emission costs the prices for i.e. energy and transport can increase and therefore change consumer demand. The insecurity of legislation leads to indefinite adjournation of projects and investments.\n\nSimilar to the tobacco industry, industries producing excessive greenhouse gases are exposed to the risk of an increasing number of lawsuits, if damages can be traced back to emissions, i.e. for floodings, crop failure, etc.\n\nIf companies do not take measures to reduce climate risks they are competitively disadvantaged. This might lead to increasing production costs caused by obsolete technologies and therefore to decreasing profits.\n\nProduction shortfalls can result from direct or indirect climate risks. I.e. hurricanes damaging oil production facilities can lead to a scarcity of oil and increasing prices. Also the price for energy will rise, because heatwaves cause water scarcity and therefore the supply for cooling water of power plants becomes short.\n\nCompanies who are publicly criticized for their environmental policy or high emission rates, might lose customers, because of negative reputation. This risk is currently subordinate.\n\nBesides climate risks also opportunities can derive from climate change for some branches and innovative companies, i.e. for the automobile and renewable energy sectors. Especially energy-intensive sectors can reduce energy costs by using more efficient technologies, which necessarily have to be developed in near future.\n\n\n\n"}
{"id": "20455314", "url": "https://en.wikipedia.org/wiki?curid=20455314", "title": "Coherent electromagnetic radio tomography", "text": "Coherent electromagnetic radio tomography\n\nThe Coherent Electromagnetic Radio Tomography (CERTO) is a radio beacon which measures ionospheric parameters in coordination with ground receivers. CERTO provides global ionospheric maps to aid prediction of radio wave scattering. CERTO was developed by the Naval Research Lab and is one of the 4 experiment packages aboard the PicoSAT satellite. CERTO provides near–real-time measurements of the ionosphere. CERTO was used for the Equatorial Vortex Experiment in 2013.\n\n\n"}
{"id": "23017057", "url": "https://en.wikipedia.org/wiki?curid=23017057", "title": "Conny van Rietschoten", "text": "Conny van Rietschoten\n\nCornelis \"Conny\" van Rietschoten (23 March 1926 – 17 December 2013) was a Dutch yacht skipper who was the only skipper to win the Whitbread Round the World Race twice.\n\nBorn in Rotterdam, van Rietschoten was unknown as a sailor even in his own waters before competing in the 1977–78 Whitbread Round the World Race. At 45, the industrialist had retired from active business and was looking for a fresh challenge. He had read reports about the first Whitbread Race, saw it as the opportunity of a lifetime – and grabbed it with both hands. A circumnavigation was something his Father, Jan Jacob, had always wanted to do but never found the time. The younger Van Rietschoten had in fact been sailing since he was three, and had continued until tuberculosis interrupted both his sailing and business career in the early 1960s. He spent a year convalescing in a Swiss sanatorium, and then threw all his energies into developing the family electrical engineering business, Van Rietschoten & Houwens.\nWhat set Van Rietschoten ahead of the established sailing names like Sir Robin Knox-Johnston and Éric Tabarly was a professional business approach to his campaigns. His eight-year tenure at the top of the sport spelled the end of amateur gung-ho ocean racing entries. He may well have continued to see himself as an amateur, but he set levels of professionalism within the sport that were not repeated until Peter Blake also won every leg with his \"Steinlager 2\" in the 1989–90 Whitbread Round the World Race.\n\nVan Rietschoten was first to undertake extensive trials and crew training before the race, and invested in research to improve crew clothing, rigs and weather forecasting techniques.\n\nFor his first Whitbread yacht, Conny van Rietschoten turned to American designers Sparkman & Stephens to design a more modern version of the Swan 65 production yacht \"Sayula II\", which had won the first Whitbread race in 1973/74. The new \"Flyer\", built in aluminium by Jachtwerf W. Huisman, was also a ketch, but with a longer waterline and more sail area.\n\nAfter winning the transatlantic race, the \"Flyer\" crew found their greatest rival to be another Swan 65, the sloop rigged British yacht \"King's Legend\", with Nick Ratcliffe as the skipper and American Skip Novak as the navigator. 1,000 miles from Cape Town, the two crews found themselves within sight of each other, before \"Flyer\" pulled ahead to win the first leg of the race from Portsmouth by 2 hours 4 minutes.\nOn the second leg to Auckland, New Zealand, \"King's Legend\" stole the upper hand, and soon had a 360mile lead over \"Flyer\" as the Whitbread fleet raced across the Southern Ocean, but then suffered a leak, which slowed her progress. At the finish, Conny van Rietschoten’s crew had cut \"King's Legend’s\" lead back to within 1 hour 15 minutes.\n\nThe third leg around Cape Horn to Rio de Janeiro proved something of an anti-climax as far as the race was concerned, for Kings Legend suffered a broach and water wiped out her radio. Without weather forecasts, Novak and his crew were at a distinct disadvantage and fell almost 60 hours behind \"Flyer\".\n\nOn the final leg back to Portsmouth, Van Rietschoten and his crew had only to shadow Kings Legend home which they did, finishing 2 hours behind the British yacht, to win the Whitbread Race on handicap. \"Flyer\" was recently refitted by the original manufacturer\n\nThe 1981/82 Whitbread Race saw Conny van Rietschoten’s maxi sloop \"Flyer II\" designed by German Frers matched against Peter Blake’s 68 ft Bruce Farr designed \"Ceramco New Zealand\". \"Ceramco New Zealand\" was dismasted during the first leg to give \"Flyer II\" a run-away victory on this first stage of the race to Cape Town, but thereafter, the two yachts raced neck-and-neck around the rest of the world.\n\nIt was at the height of this competition when Conny van Rietschoten showed the steely side of his character. He suffered a heart attack when their yacht was deep into the Southern Ocean, en route to Auckland, New Zealand. Van Rietschoten swore his crew to secrecy, and would not even allow the \"Flyer II\" doctor Julian Fuller to call a cardiologist aboard their rival yacht Ceramco for advice. “The nearest port was 10 days away and the critical period is always the first 24–36 hours,” he recalled later. “Ceramco was already breathing down our necks. If they had known that I had a health problem, they would have pushed their boat even harder. When you die at sea, you are buried over the side. Perhaps those Ceramco boys might then have spotted me drifting by. And that I was determined would be the only thing they would see or hear from \"Flyer II\" on the matter!”\n\n\"Flyer II\" pulled out a 9 hour lead by Auckland, but \"Ceramco New Zealand\" won the leg on handicap. The race from there to Cape Horn was one of constantly swapping places. Half way across the Pacific, they were within sight of each other, and also rounded Cape Horn together. \"Flyer II\" got to Mar del Plata first to take line honours, but the \"Ceramco New Zealand\" crew were rewarded with 2nd on handicap.\n\nConny van Rietschoten and his crew finished first again back at Portsmouth, followed by \"Ceramco New Zealand\" to take line honours for the Race, and with the rest of the fleet becalmed near the Azores, took handicap honours too – the first crew to win both line and handicap honours in the history of the Race. Van Rietschoten and his crew also set two world records: The fastest Noon to Noon run of 327 miles, and the fastest circumnavigation of 120 days\n\nIn 1948 Conny van Rietschoten and his friend Morin Scott sailed their Dragon class yacht \"Gerda\" from Cowes England across the North Sea to Arendal to compete in that year's Dragon Gold Cup world championship. They did not win, but Crown Prince Olaf of Norway proclaimed the two sailors the best at the regatta for sailing by far the furthest distance.\n\nSince the 1980s the Conny van Rietschoten Trophy has been awarded each year as the best Dutch sailor.\n\nOn 17 December 2013, Conny van Rietschoten died in Portugal.\n\n"}
{"id": "480356", "url": "https://en.wikipedia.org/wiki?curid=480356", "title": "Cryogenian", "text": "Cryogenian\n\nThe Cryogenian (, from Greek κρύος \"(krýos)\", meaning \"cold\" and γένεσις \"(génesis)\", meaning \"birth\") is a geologic period that lasted from . It forms the second geologic period of the Neoproterozoic Era, preceded by the Tonian Period and followed by the Ediacaran.\n\nThe Sturtian and Marinoan glaciations occurred during the Cryogenian period, which are the greatest ice ages known to have occurred on Earth. These events are the subject of much scientific controversy. The main debate contests whether these glaciations covered the entire planet (the so-called \"Snowball Earth\") or a band of open sea survived near the equator (termed \"slushball Earth\").\n\nThe Cryogenian period was ratified in 1990 by the International Commission on Stratigraphy. In contrast to most other time periods, the beginning of the Cryogenian is not linked to a globally observable and documented event. Instead, the base of the period is defined by a fixed rock age, that was originally set at 850 million years, but changed in 2015 to 720 million years.\n\nThis is problematic because estimates of rock ages are variable and are subject to laboratory error. For instance, the time scale of the Cambrian Period is not reckoned by rock younger than a given age ( million years), but by the appearance of the worldwide \"Treptichnus pedum\" diagnostic trace fossil assemblages. This means that rocks can be recognized as Cambrian when examined in the field and do not require extensive testing to be performed in a lab to find a date.\n\nCurrently, there is no consensus on what global event is a suitable candidate to mark the start of the Cryogenian Period, but a global glaciation would be a likely candidate.\n\nThe name of the geologic period refers to the very cold global climate of the Cryogenian.\n\nCharacteristic glacial deposits indicate that Earth suffered the most severe ice ages in its history during this period (Sturtian and Marinoan). According to Eyles and Young, \"Late Proterozoic glaciogenic deposits are known from all the continents. They provide evidence of the most widespread and long-ranging glaciation on Earth.\" Several glacial periods are evident, interspersed with periods of relatively warm climate, with glaciers reaching sea level in low paleolatitudes.\n\nGlaciers extended and contracted in a series of rhythmic pulses, possibly reaching as far as the equator.\n\nThe Cryogenian is generally considered to be divisible into at least two major worldwide glaciations. The Sturtian glaciation persisted from 720 to 660 million years ago, and the Marinoan glaciation which ended approximately 635 Ma, at the end of the Cryogenian. The deposits of glacial tillite also occur in places that were at low latitudes during the Cryogenian, a phenomenon which led to the hypothesis of deeply frozen planetary oceans called \"Snowball Earth\".\n\nBefore the start of the Cryogenian, around 750 Ma, the cratons that made up the supercontinent Rodinia started to rift apart. The superocean Mirovia began to close while the superocean Panthalassa began to form. The cratons (possibly) later assembled into another supercontinent called Pannotia, in the Ediacaran.\n\nEyles and Young state, \"Most Neoproterozoic glacial deposits accumulated as glacially influenced marine strata along rifted continental margins or interiors.\" Worldwide deposition of dolomite might have reduced atmospheric carbon dioxide. The break up along the margins of Laurentia at about 750 Ma occurs at about the same time as the deposition of the Rapitan Group in North America, contemporaneously with the Sturtian in Australia. A similar period of rifting at about 650 Ma occurred with the deposition of the Ice Brook Formation in North America, contemporaneously with the Marinoan in Australia. The Sturtian and Marinoan are local divisions within the Adelaide Rift Complex.\n\nFossils of testate amoeba (or Arcellinida) first appear during the Cryogenian period. During the Cryogenian period, the oldest known fossils of sponges (and therefore animals) make an appearance.\nThe issue of whether or not biology was impacted by this event has not been settled, for example Porter (2000) suggests that new groups of life evolved during this period, including the red algae and green algae, stramenopiles, ciliates, dinoflagellates, and testate amoeba.\n\n\n"}
{"id": "7443276", "url": "https://en.wikipedia.org/wiki?curid=7443276", "title": "Dead water", "text": "Dead water\n\nDead water is the nautical term for a phenomenon which can occur when a layer of fresh or brackish water rests on top of denser salt water, without the two layers mixing. A ship powered by direct thrust under the waterline (such as a propeller), traveling in such conditions may be hard to maneuver or can even slow down almost to a standstill. Much of the energy from the ship's propeller only results in waves and turbulence between the two layers of water, leaving a ship capable of traveling at perhaps as little as 20% of its normal speed. \n\nThe phenomenon was first described by Fridtjof Nansen, the Norwegian Arctic explorer.\nNansen wrote the following from his ship \"Fram\" in August 1893 in the Nordenskiöld Archipelago near the Taymyr Peninsula:\n\nThis phenomenon is observable where glacier runoff flows into salt water without much mixing, such as in fjords.\n\n"}
{"id": "54253236", "url": "https://en.wikipedia.org/wiki?curid=54253236", "title": "Drue Leyton", "text": "Drue Leyton\n\nDrue Leyton (12 July 1903 - 8 February 1997) was an American actress and member of the French resistance. She was born Dorothy Elizabeth Blackman in Somers, Wisconsin. She became an actress after a failed mariage and notably acted in Green Grow the Lilacs on Broadway and several Charlie Chan films. In 1937 Leyton moved to Paris with her future husband a Franco-American actor who died in Syria in 1941 fighting with the Free French forces.\n\nLeyton broadcast for the Voice of America whilst acting in Paris in 1938 and her criticisms of the Nazi regime during these broadcasts earned her a promise of execution announced by Berlin radio. She was arrested by the Nazis when France became occupied by the German military but managed to escape from her prison camp with the help of French doctors by feigning cancer. She returned to her home in Barbizon in 1942 and joined the resistance movement helping 42 downed allied airmen escape to freedom and hid others in her home until the war ended. During this period she was known as Dorothy Tartière which was the real name of her husband. She wrote about this period in a book \"The House Near Paris.\"\n\n"}
{"id": "1062188", "url": "https://en.wikipedia.org/wiki?curid=1062188", "title": "Eagle River (Alaska)", "text": "Eagle River (Alaska)\n\nEagle River may refer to the following streams in the U.S. State of Alaska:\n\n\n"}
{"id": "113530", "url": "https://en.wikipedia.org/wiki?curid=113530", "title": "Fen", "text": "Fen\n\nA fen is one of the main types of wetland, the others being grassy marshes, forested swamps, and peaty bogs. Along with bogs, fens are a kind of mire. Fens are minerotrophic peatlands, usually fed by mineral-rich surface water or groundwater. They are characterised by their distinct water chemistry, which is pH neutral or alkaline, with relatively high dissolved mineral levels but few other plant nutrients. They are usually dominated by grasses and sedges, and typically have brown mosses in general including \"Scorpidium\" or \"Drepanocladus\". Fens frequently have a high diversity of other plant species including carnivorous plants such as \"Pinguicula\". They may also occur along large lakes and rivers where seasonal changes in water level maintain wet soils with few woody plants. The distribution of individual species of fen plants is often closely connected to water regimes and nutrient concentrations.\n\nFens have a characteristic set of plant species, which sometimes provide the best indicators of environmental conditions. For example, fen indicator species in New York State include \"Carex flava\", \"Cladium mariscoides\", \"Potentilla fruticosa\", \"Pogonia ophioglossoides\" and \"Parnassia glauca\".\n\nFens are distinguished from bogs, which are acidic, low in minerals, and usually dominated by sedges and shrubs, along with abundant mosses in the genus \"Sphagnum\". Bogs also tend to exist on dome-shaped landmasses where they receive almost all of their usually-abundant moisture from rainfall, whereas fens appear on slopes, flats, or depressions and are fed by surface and underground water in addition to rain.\n\nFens have been damaged in the past by land drainage, and also by peat cutting. Some are now being carefully restored with modern management methods. The principal challenges are to restore natural water flow regimes, to maintain the quality of water, and to prevent invasion by woody plants.\n\n\"Carr\" is the northern European equivalent of the wooded swamp of the southeastern United States, also known in the United Kingdom as wet woodland. It is a fen overgrown with generally small trees of species such as willow (\"Salix spp.\") or alder (\"Alnus\" spp.). In general, fens may change in composition as peat accumulates. A list of species found in a fen can therefore cover a range of species from those remaining from the earlier stage in the successional development to the pioneers of the succeeding stage.\n\nWhere streams of base-rich water run through bog, these are often lined by strips of fen, separating \"islands\" of rain-fed bog.\n\nTemporary flooding by beavers can have negative effects on fens.\n\nShakespeare used the term \"fen-sucked\" to describe the fog (literally: rising from marshes) in \"King Lear\", when Lear says \"Infect her beauty, You fen-sucked fogs drawn by the powerful sun, To fall and blister.\"\n"}
{"id": "58476264", "url": "https://en.wikipedia.org/wiki?curid=58476264", "title": "Fisheries-induced evolution", "text": "Fisheries-induced evolution\n\nFisheries-induced evolution (FIE) is the microevolution of an exploited aquatic organism's population, brought on through the artificial selection for biological traits by fishing practices. Fishing, of any severity or effort, will impose an additional layer of mortality to the natural population equilibrium and will be selective to certain genetic traits within that organism's gene pool. This removal of selected traits fundamentally changes the population gene frequency, resulting in the artificially induced microevolution by the proxy of the survival of untargeted fish and their propagation of heritable biological characteristics. This artificial selection often counters natural life-history pattern for many species, such as causing early sexual maturation, diminished sizes for matured fish, and reduced fecundity in the form of smaller egg size, lower sperm counts and viability during reproductive events. These effects can have prolonged effects on the adaptability or fitness of the species to their environmental factors. \n\nFisheries-induced evolution differ to the norm Darwinian evolution model by the direct human factor. For FIE, fishing enforces a greater selection pressure for traits, often through sheer effort and catch numbers, which can disparage natural selection pressures such as predator-prey interactions and environmental influences. \n\nFishing practices that permanently remove animals from their population (i.e. not catch and release) drive direct fisheries-induced evolution by removing the genetic materials of those animals from the population. Individuals that are untargeted, through the selection bias of fishing gears and/or legislation, are allowed to reproduce and proliferate their genetic materials. As fishing pressures persist, traits belonging to non-selected organisms are preserved through survival and become more dominant in frequency within the gene pool. Additionally, fishing on a targeted species incur knock-on effects to those around it by its disturbance of their natural interactions. In these situations, specific traits of the untargeted species may be favourable under the diminutive presence, or absence, of the targeted species, and therefore indirectly selected for. \n\nThe direct selection for biological traits through fishery practices is the result of fishery management regulations, and gear restrictions and selectivities. The most obvious artificial selection for traits through management legislation can be observed in the imposed regulations on size, sex, seasonality, and locations. \n\nCatch size regulations vary with specificity to the targeted species and is often used to prevent exploitation during a specific part of the life cycle for the organism. Such regulations arose in response to the effects of FIE observed by the fisheries of Atlantic Cod (\"Gadus morhua\"). Prior to the fishing technological revolution that has lead to the species moratorium, the exploitation of Atlantic Cod have been selective towards larger-sized fish since the 1500s. Catch data for the species have quantitatively shown that this selectivity for larger fish for over 500 years have shifted the life-history patterns, resulting in earlier sexual maturation and smaller sizes at said maturation. \n\nSexual selectivity by a fishery works on the theoretical foundation that the preservation of females allows their reproductive input to offset the fishing mortality. Fisheries of species with low fecundity such as mud crabs (\"Scylla serrata\") and blue swimmer crabs (\"Portunus armatus\") often adopt this method and only allow the harvesting of males. The direct selection for traits, with respect to sex selectivity, occurs when specific characteristics or behaviours increase the susceptibility of the organisms for harvest. For example, corking wrasses (\"Symphodus melops\") are harvested as a biological control for sea lice within farmed salmon facilities of the northern hemisphere. Male fish dominate these wild fisheries in both catch per unit effort and weight owing to their strong nesting behaviour and territorial nature, which differentiate them from females and sneaker males. Persistent fishing pressures over the years have reduced maturation age and size for these nesting males, in addition to increasing the density of sneaker males to the detriment of the localised population. \n\nIndirect fishery-induced evolution occurs when a species with some level of ecological significance is targeted by a fishery, and their diminished presence within the ecology causes a flow on effect to other untargeted species. Keystone or umbrella species provide many ecological services to the environment which they belong to, ranging from the provision of habitat and food, to the control of biodiversity by preventing any one organism from dominating. Removal or reduction of these organisms often cause significant changes to the behaviours and physiology of the organisms which were once controlled. \n\nNon-migratory reef sharks (\"Carcharhinus melanopterus, C. amblyrhynchos,\" and \"Triaenodon obesus\") play the vital role in weeding out sick and ill-adapted individuals from within a population, in addition to controlling the abundance of larger size fish. Thus, these sharks are an ever-present mortality factor for many reef organisms. Fisheries targeting these apex predators inherently allow for the proliferation of medium-sized predatory fishes (e.g. barracudas, juvenile groupers, trevallies, snappers) at the expense of the cohabiting smaller species. When this happen, the FIE responses observed from smaller species have been consistent with their increasing egg production and shifted life-history for early sexual maturation.\n\nAnother example of FIE that is instigated indirectly can be seen in the ornamental or aquarium trade industry. In particular, corals and anemones are highly prized ornamental commodities and are often harvested at unsustainable rates for profit within the Malay archipelago. Removal of anemones at rates higher than their resettlement into the reefs, as observed in the Philippines, is known to have caused drastic reduction in the localised population of clownfish or anemonefish (\"Amphiprion sp.\"). Evolutionarily, anemone fish observed on reefs that were subjected to intense and prolonged anemone fishing were significantly smaller, even for mature adult pairs, than those found living with an anemone. This size reduction is attributed to their need to hide in small coral crevices in the absence of a host.\n\nOutside of observational data collected from active fisheries, the evidence for fisheries-induced evolution, or its symptoms, may be discerned through both commercial and recreational anecdotes. These stories often articulate the diminishing catch, reduction in their weight and length records, in addition to the mandatory increase to fishing efforts over time to attain similar fishing quotas to their historical references. However, experimental data was needed to clarify two fundamental questions regarding FIE, so that the aforementioned ramifications of smaller sizes and early maturation may not be attributed to non-anthropogenic factors such as population flux. The two evidentiary questions: a) Is fishing pressure capable of changing the gene frequency of a population to cause microevolution within such a short time frame? b) How can non-selective fishing gears (gill nets and trawlers) be selective for certain traits? \n\nThe implementation of aquaculture experimental designs afford the possibility of isolating different biological traits and observing their impacts and heredity within a population. \n\nA study by Solberg et al. (2013) demonstrated that with sufficient fishing pressure and selectivity, a substantial change to a population genotype may be achieved without the geological time-frame often associated with evolution. In this study, Atlantic salmon (\"Salmo salar\") were subjected to a modified 'common garden' design, and the researchers isolated stress as an abiotic independent variable to the growth rates of salmon. By selecting for fish with a lower biological response to stress, a domesticated population was created within 10 generations of breeding, which exhibited a threefold increase in growth rate over its wild counterpart. Thus, the difference between the absence of larger fish, which can be misattributed to overfishing, and FIE lies in the inherited biological characteristics that were untargeted by fishing. \n\nFishing techniques such as gill nets and trawling are often associated with a lack of selectivity within the environment which they are operated. It is difficult to establish whether selectivity can occur under these practices, when fishing data suggest that an entire localised population may be caught or up to 80% of the effort to go to bycatches and not the targeted species. An experiment by Biro and Post (2008) shows that despite being mechanically unselective of gill nets, behavioural variation in certain fish species can indeed affect the likelihood of them being caught and therefore be a function for selectivity. Using a ‘selection experiment in the field’ model, two genotypes of rainbow trouts (\"Oncorhynchus mykiss\") were transplanted into identical artificial lake habitats and subjected to matching gill net fishing pressures. The net in question were designed to capture all size variability within the simulated populations. Trouts exhibiting the genotypes for faster growth rates and therefore a more active lifestyle were found to have a 60% increase chance to be caught in comparison to those characterised by the more sedentary genotype. Therefore, for 'non-selective' fishing methods, the selecting factor rests not on the gear itself but on the inherent behavioural variations within the population.\n\nFisheries-induced evolution is a function of the fishing-induced genetic drift, and to some extent represent the reduction of genetic diversity within the targeted population. For many exploited population, this reduction in genetic diversity has been predicted to reduce their adaptability to both environmental variability and ecological competitiveness. Indeed, the commonly observed fisheries-induced adaptation of younger and smaller size at sexual maturation counter specific life-history characteristics that would enable interspecies competition for resources. A biological model by Kindsvater and Palkovacs (2017) shows that FIE Atlantic cod, due to their smaller sizes, actually belong to a lower trophic level irrespective of their original position prior to the species moratorium. Furthermore, the FIE effect of reducing egg counts and their viability have weakened the number of recruitments back into the population after spawning, thereby reducing the localised population density. However, at the reduced population abundance and smaller sizes, the increase in \"per capita\" resource has been stipulated to counteract the effects of competitions between different species by reducing intraspecific interactions, which can allow for maximal density-dependent growth to happen. This also means that for harvesting to be sustainable, yearly or seasonal assessment of viable reproductive stocks and their recruitment rates must be performed to account for the compromised fecundity and recovery statuses. \n\nThere is limited data on the interactions between FIE affected species and their robustness to environmental fluctuations. For many species, the additional mortality rate and the frequency of harvesting exerted by the fisheries make it difficult to elucidate how environmental factors such as temperatures, salinity and currents can be beneficial or detrimental for stocks, since their effects on deaths or recruitment gains are diminutive in comparison. However, with the rapidly evolving climates stemming from the anthropogenic inputs, an understanding of how FIE affects the adaptability of these aquatic population will be necessary, not only for future stock assessments, but also sustainable harvesting. \n"}
{"id": "28996847", "url": "https://en.wikipedia.org/wiki?curid=28996847", "title": "Geophysical fluid dynamics", "text": "Geophysical fluid dynamics\n\nGeophysical fluid dynamics, in its broadest meaning, refers to the fluid dynamics of naturally occurring flows, such as lava flows, oceans, and planetary atmospheres, on Earth and other planets.\n\nTwo physical features that are common to many of the phenomena studied in geophysical fluid dynamics are rotation of the fluid due to the planetary rotation and stratification (layering). The applications of geophysical fluid dynamics do not generally include the circulation of the mantle, which is the subject of geodynamics, or fluid phenomena in the magnetosphere.\n\nTo describe the flow of geophysical fluids, equations are needed for conservation of momentum (or Newton's second law) and conservation of energy. The former leads to the Navier–Stokes equations. Further approximations are generally made. First, the fluid is assumed to be incompressible. Remarkably, this works well even for a highly compressible fluid like air as long as sound and shock waves can be ignored. Second, the fluid is assumed to be a Newtonian fluid, meaning that there is a linear relation between the shear stress and the strain , for example\nwhere is the viscosity. Under these assumptions the Navier-Stokes equations are\nThe left hand side represents the acceleration that a small parcel of fluid would experience in a reference frame that moved with the parcel (a Lagrangian frame of reference). In a stationary (Eulerian) frame of reference, this acceleration is divided into the local rate of change of velocity and advection, a measure of the rate of flow in or out of a small region.\n\nThe equation for energy conservation is essentially an equation for heat flow. If heat is transported by conduction, the heat flow is governed by a diffusion equation. If there are also buoyancy effects, for example hot air rising, then natural convection, also known as free convection, can occur. Convection in the Earth's outer core drives the geodynamo that is the source of the Earth's magnetic field. In the ocean, convection can be \"thermal\" (driven by heat), \"haline\" (where the buoyancy is due to differences in salinity), or \"thermohaline\", a combination of the two.\n\nFluid that is less dense than its surroundings tends to rise until it has the same density as its surroundings. If there is not much energy input to the system, it will tend to become stratified. On a large scale, Earth's atmosphere is divided into a series of layers. Going upwards from the ground, these are the troposphere, stratosphere, mesosphere, thermosphere, and exosphere.\n\nThe density of air is mainly determined by temperature and water vapor content, the density of sea water by temperature and salinity, and the density of lake water by temperature. Where stratification occurs, there may be thin layers in which temperature or some other property changes more rapidly with height or depth than the surrounding fluid. Depending on the main sources of buoyancy, this layer may be called a pycnocline (density), thermocline (temperature), halocline (salinity), or chemocline (chemistry, including oxygenation).\n\nThe same buoyancy that gives rise to stratification also drives gravity waves. If the gravity waves occur within the fluid, they are called internal waves.\n\nIn modeling buoyancy-driven flows, the Navier-Stokes equations are modified using the Boussinesq approximation. This ignores variations in density except where they are multiplied by the gravitational acceleration .\n\nIf the pressure depends only on density and vice versa, the fluid dynamics are called barotropic. In the atmosphere, this corresponds to a lack of fronts, as in the tropics. If there are fronts, the flow is baroclinic, and instabilities such as cyclones can occur.\n\n\n\n\n\n\n\n"}
{"id": "54155790", "url": "https://en.wikipedia.org/wiki?curid=54155790", "title": "Georgina King", "text": "Georgina King\n\nGeorgina King (1845-1932), was an Australian amateur geologist and anthropologist.\n\nGeorgina King was born on 6 June 1845 in Fremantle, Western Australia, to George King, a Church of England clergyman from Ireland, and his wife Jane Mathewson. Her brother Kelso King would also bring acclaim to the family. In 1847, her family moved to Sydney. King's father, a fellow of St Paul's College, oversaw her education and encouraged her to read widely including books on evolution and natural history. Her family doctor, George Bennett, a keen naturalist, recommended texts on geology to her. Discouraged by her father and Bennett from marrying, King looked after a nephew and niece at Springwood from the 1870s until 1881, and then travelled to Britain and Europe.\n\nAfter returning to Australia, King was active in the Women's Literary Society, which was founded in 1889, along with friend Rose Scott. King was an original member of the Women's Club. In 1888, King attended the inaugural meeting of the Australasian Association for the Advancement of Science (AAAS). She met many distinguished scientists through this meeting and later corresponded with R. L. Jack, who had done extensive geological surveys of Queensland and (Sir) Frederick McCoy of Victoria. Recalling the geological history she had been taught in her youth, and inspired by the work of McCoy and others, King proposed a 'Tertiary Period Catastrophism' theory to the wider scientific community. When her paper on this theory was rejected by the Royal Society of New South Wales in 1892, King sent them to be published in newspapers like the Sydney Morning Herald. Similarly she sent her papers to the University of Sydney and other scientists to consider. Her controversial ideas and claims to theories posed by other scientists, led to further ridicule.\n\nKing published papers on anthropological subjects after 1900. She used some of her father's work on Aborigines to expand her ideas, and continued to elaborate on her geological theory of evolution. She was elected a fellow of the Royal Anthropological Society of Australasia, and published within its journal, Science of Man. From 1913 King corresponded with and financially supported, Daisy Bates, another woman who felt frustrated by the scientific establishment.\n\nKing volunteered with the Red Cross during World War I. She made dolls for patients of the Royal Alexandra Hospital for Children and was a prolific letter writer to the daily newspapers.\n\nKing died on 7 June 1932 at Darling Point, Sydney, and was cremated.\n\nKing donated many specimens of natural science to the Australian Museum and Technological Museum of Sydney. Her papers are held by the State Library of New South Wales.\n\n"}
{"id": "2009412", "url": "https://en.wikipedia.org/wiki?curid=2009412", "title": "Geosmin", "text": "Geosmin\n\nGeosmin is an organic compound with a distinct earthy flavor and aroma produced by certain bacteria, and is responsible for the earthy taste of beets and a contributor to the strong scent (petrichor) that occurs in the air when rain falls after a dry spell of weather or when soil is disturbed. In chemical terms, it is a bicyclic alcohol with formula , a derivative of decalin. Its name is derived from the Greek \"earth\" and \"smell\".\n\nGeosmin is produced by the gram-positive bacteria \"Streptomyces\" and various cyanobacteria, and released when these microorganisms die. Communities whose water supplies depend on surface water can periodically experience episodes of unpleasant-tasting water when a sharp drop in the population of these bacteria releases geosmin into the local water supply. Under acidic conditions, geosmin decomposes into odorless substances.\n\nIn 2006, the biosynthesis of geosmin by a bifunctional \"Streptomyces coelicolor\" enzyme was unveiled. A single enzyme, geosmin synthase, converts farnesyl diphosphate to geosmin in a two-step reaction.\n\n\"Streptomyces coelicolor\" is the model representative of a group of soil-dwelling bacteria with a complex lifecycle involving mycelial growth and spore formation. Besides the production of volatile geosmin, it also produces many other complex molecules of pharmacological interest; its genome sequence is available at the Sanger Institute.\n\nThe human nose is extremely sensitive to geosmin and is able to detect it at concentrations as low as 5 parts per trillion.\n\nGeosmin is responsible for the muddy smell in many commercially important freshwater fish such as carp and catfish. Geosmin combines with 2-methylisoborneol, which concentrates in the fatty skin and dark muscle tissues. Geosmin breaks down in acid conditions; hence, vinegar and other acidic ingredients are used in fish recipes to help reduce the muddy flavor.\n\n\n"}
{"id": "27021924", "url": "https://en.wikipedia.org/wiki?curid=27021924", "title": "GovEnergy", "text": "GovEnergy\n\nThe GovEnergy Workshop and Trade Show is an annual training event in the United States for federal facility energy professionals. The event is also attended by private industry professionals who help to monitor and control energy use in federal facilities.\n\nGovEnergy is sponsored by seven federal agencies; the U.S. Department of Energy's (DOE) Federal Energy Management Program (FEMP), the U.S. General Services Administration (GSA), the U.S. Department of Veterans Affairs (VA), the U.S. Department of Defense (DOD), the U.S. Department of Homeland Security (DHS), the U.S. Environmental Protection Agency (EPA), and the U.S. Department of Agriculture (USDA). The federal government is the largest consumer of energy nationwide. As a result, the federal government has an obligation to \"lead by example\" by maintaining energy efficient facilities. Federal legislation such as the Energy Policy Act of 2005, Executive Order 13423, and EISA 2007. detail the requirements for reducing building energy costs, increasing energy efficiency, using renewable energy, and water conservation.\n\nThe event originated in 1997, under the name 'Energy'. The name was changed to GovEnergy in 2007. GovEnergy is held in a different city every year. Previous locations have included Lake Buena Vista, Florida, Rochester, New York, Long Beach, California, Chicago, Illinois, New Orleans, Louisiana, Phoenix, Arizona, Providence, Rhode Island, and Dallas, Texas.\n\nThe training sessions are organized by a series of themed categories, commonly known as \"tracks\". Previous tracks have included building operations & maintenance (O&M), contracting, energy security, project financing, greenhouse gases, legislation, energy management controls systems (EMCS), renewable energy, specialty buildings, sustainbility, technology, and water efficiency. The majority of the tracks feature nine sessions, and are held over the course of two and a half days. The tracks and individual sessions have been designed to meet the needs of \"federal facility managers, federal energy coordinators, and federal procurement officials.”. The sessions are taught by professionals representing both the public and private sectors. GovEnergy also features a mid-size trade show and a series of educational tours.\n\n"}
{"id": "1770354", "url": "https://en.wikipedia.org/wiki?curid=1770354", "title": "Greenland ice core project", "text": "Greenland ice core project\n\nThe Greenland Ice Core Project (GRIP) was a multinational European research project, organized through the European Science Foundation. Funding came from 8 nations (Belgium, Denmark, France, Germany, Iceland, Italy, Switzerland, and United Kingdom), and from the European Union.\n\nThe project ran from 1989 to 1995, with drilling seasons from 1990 to 1992. GRIP successfully drilled a 3029-metre ice core to the bed of the Greenland ice sheet at Summit, Central Greenland from 1989 to 1992 at .\n\nStudies of isotopes and various atmospheric constituents in the core have revealed a detailed record of climatic variations reaching more than 100,000 years back in time. The results indicate that Holocene climate has been remarkably stable and have confirmed the occurrence of rapid climatic variation during the last ice age (the Wisconsin). Delta-O-18 variations observed in the core part believed to date from the Eemian Stage have not been confirmed by other records including the NGRIP core and are now believed not to represent climate events: the interglacial climate of Eemian Stage appears to have been as stable as the Holocene.\n\n\nThe GRIP logistics were managed by what is now called Centre for Ice and Climate at the Niels Bohr Institute, University of Copenhagen, Denmark. This research centre maintains a web page about ice core research:\nOther links:\n"}
{"id": "52113015", "url": "https://en.wikipedia.org/wiki?curid=52113015", "title": "Güney Waterfall", "text": "Güney Waterfall\n\nGüney Waterfall () is a waterfall in Denizli Province, western Turkey. It is a registered natural monument of the country.\n\nThe waterfall is located in the Cindere village of the Güney district of Denizli Province. It is distant from Denizli and from Güney. The road to the waterfall is paved with cobblestones. \n\nThe waterfall is fed by waters of a spring dropping from a height of , which joins the Büyük Menderes River. The carbonated water dissolved limestone formation rocks and formed travertines on the waterfall base. A cave situated under the waterfall contains a pond.\n\nIt is a popular visitor attraction. Around 20,000 local and foreign tourists visit the site annually.\n\nUsed as a local recreational area since the 1960s, the waterfall and its surroundings, which cover an area of , was registered in 1994 as a natural monument by the Nature Reserve and Nature Parks Administration of the Ministry of Forest and Water Management.\n\nIn the summer of 2007, the waterfall faced the risk of disappearance due to drought in the region. To overcome the threat, water was brought by pipeline over a distance of . The -high rock wall of the waterfall collapsed following a landslide, which occurred in the afternoon of May 13, 2013. As a result of the rockfall, the waterfall almost disappeared. One person at the site sustained light injuries. In April 2014 workers diverted the stream and reestablished the waterfall about to the side of the waterfall's initial location. Facilities were added to the site for outdoor recreation. The waterfall area was also illuminated to accommodate nighttime visitors.\n"}
{"id": "10069054", "url": "https://en.wikipedia.org/wiki?curid=10069054", "title": "Helig ap Glanawg", "text": "Helig ap Glanawg\n\nHelig ap Glanawg (standard modern Welsh orthography: Helig ap Glannog) is a legendary figure described in various accounts dating to at least as early as the 13th century as a 6th-century prince who lived in North Wales.\n\nPost-medieval tradition says that the river Conwy once reached the sea by the Great Orme, Llandudno, and to the west lay the great cantref of Gwaelod which stretched all the way to Puffin Island, off Anglesey. Helig ap Glanawg was said to have lived here when his land was inundated by the sea, which formed the Lavan Sands which lie between the Great Orme's Head and the Menai Strait off the north coast of Gwynedd. The legend states the remains of Llys Helig, said to be his palace but in fact the remnants of a glacial moraine, can be seen at exceptionally low tides, this being near the Conwy channel, about a mile or so off the coast at Penmaenmawr. The earliest known use of the name Llys Helig for this rock formation is the Halliwell Manuscript, published in 1859, which is believed to date to around the beginning of the 17th century, eleven centuries later.\nAfter the disaster both Helig and his numerous sons are said to have embraced a religious life. These sons, according to various sources, were -\n\nRachel Bromwich discusses what she refers to as the folk-tale of Cantre'r Gwaelod, another alleged sunken kingdom but in Cardiganshire. As with Llys Helig, there are tales of remains being seen of the sunken kingdom. Bromwich believes that the two stories influenced each other, and that \"The widespread parallels to this inundation theme would suggest that the two stories are in fact one in origin, and were localized separately in Cardiganshire and in the Conway estuary, around two traditional figures of the sixth century. She also notes that the Halliwell Manuscript gives Helig the title \"Lord of Cantre'r Gwaelod\". In the book \"New Directions In Celtic Studies\" Antone Minard wrote that \"The Welsh legends of Cantre'r Gwaelod and Llys Helig (Helig's Court) contain the same details of audible bells beneath the waves and ruins which are visible at the equinoctial tides, which are the anchors of credulity in the story\".\n\n"}
{"id": "59611", "url": "https://en.wikipedia.org/wiki?curid=59611", "title": "Ionization", "text": "Ionization\n\nIonization or ionisation, is the process by which an atom or a molecule acquires a negative or positive charge by gaining or losing electrons to form ions, often in conjunction with other chemical changes. Ionization can result from the loss of an electron after collisions with subatomic particles, collisions with other atoms, molecules and ions, or through the interaction with electromagnetic radiation. Heterolytic bond cleavage and heterolytic substitution reactions can result in the formation of ion pairs. Ionization can occur through radioactive decay by the internal conversion process, in which an excited nucleus transfers its energy to one of the inner-shell electrons causing it to be ejected.\n\nEveryday examples of gas ionization are such as within a fluorescent lamp or other electrical discharge lamps. It is also used in radiation detectors such as the Geiger-Müller counter or the ionization chamber. The ionization process is widely used in a variety of equipment in fundamental science (e.g., mass spectrometry) and in industry (e.g., radiation therapy).\n\nNegatively charged ions are produced when a free electron collides with an atom and is subsequently trapped inside the electric potential barrier, releasing any excess energy. The process is known as electron capture ionization.\n\nPositively charged ions are produced by transferring an amount of energy to a bound electron in a collision with charged particles (e.g. ions, electrons or positrons) or with photons. The threshold amount of the required energy is known as ionization potential. The study of such collisions is of fundamental importance with regard to the few-body problem (see article on few-body systems), which is one of the major unsolved problems in physics. Kinematically complete experiments, i.e. experiments in which the complete momentum vector of all collision fragments (the scattered projectile, the recoiling target-ion, and the ejected electron) are determined, have contributed to major advances in the theoretical understanding of the few-body problem in recent years.\n\nAdiabatic ionization is a form of ionization in which an electron is removed from or added to an atom or molecule in its lowest energy state to form an ion in its lowest energy state.\n\nThe Townsend discharge is a good example of the creation of positive ions and free electrons due to ion impact. It is a cascade reaction involving electrons in a region with a sufficiently high electric field in a gaseous medium that can be ionized, such as air. Following an original ionization event, due to such as ionizing radiation, the positive ion drifts towards the cathode, while the free electron drifts towards the anode of the device. If the electric field is strong enough, the free electron gains sufficient energy to liberate a further electron when it next collides with another molecule. The two free electrons then travel towards the anode and gain sufficient energy from the electric field to cause impact ionization when the next collisions occur; and so on. This is effectively a chain reaction of electron generation, and is dependent on the free electrons gaining sufficient energy between collisions to sustain the avalanche.\n\nIonization efficiency is the ratio of the number of ions formed to the number of electrons or photons used.\n\nThe trend in the ionization energy of atoms is often used to demonstrate the periodic behavior of atoms with respect to the atomic number, as summarized by ordering atoms in Mendeleev's table. This is a valuable tool for establishing and understanding the ordering of electrons in atomic orbitals without going into the details of wave functions or the ionization process. An example is presented in figure 1. The periodic abrupt decrease in ionization potential after rare gas atoms, for instance, indicates the emergence of a new shell in alkali metals. In addition, the local maximums in the ionization energy plot, moving from left to right in a row, are indicative of s, p, d, and f sub-shells.\n\nClassical physics and the Bohr model of the atom can qualitatively explain photoionization and collision-mediated ionization. In these cases, during the ionization process, the energy of the electron exceeds the energy difference of the potential barrier it is trying to pass. The semi-classical description, however, cannot describe tunnel ionization since the process involves the passage of electron through a classically forbidden potential barrier.\n\nThe interaction of atoms and molecules with sufficiently strong laser pulses leads to the ionization to singly or multiply charged ions. The ionization rate, i.e. the ionization probability in unit time, can only be calculated using quantum mechanics. In general, the analytic solutions are not available, and the approximations required for manageable numerical calculations do not provide accurate enough results. However, when the laser intensity is sufficiently high, the detailed structure of the atom or molecule can be ignored and analytic solution for the ionization rate is possible.\n\nTunnel ionization is ionization due to quantum tunneling. In classical ionization, an electron must have enough energy to make it over the potential barrier, but quantum tunneling allows the electron simply to go through the potential barrier instead of going all the way over it because of the wave nature of the electron. The probability of an electron's tunneling through the barrier drops off exponentially with the width of the potential barrier. Therefore, an electron with a higher energy can make it further up the potential barrier, leaving a much thinner barrier to tunnel through and, thus, a greater chance to do so. In practice, tunnel ionization is observable when the atom or molecule is interacting with near-infrared strong laser pulses. This process can be understood as a process by which a bounded electron, through the absorption of more than one photon from the laser field, is ionized. This picture is generally known as multiphoton ionization (MPI).\n\nKeldysh modeled the MPI process as a transition of the electron from the ground state of the atom to the Volkov states. In this model the perturbation of the ground state by the laser field is neglected and the details of atomic structure in determining the ionization probability are not taken into account. The major difficulty with Keldysh's model was its neglect of the effects of Coulomb interaction on the final state of the electron. As it is observed from figure, the Coulomb field is not very small in magnitude compared to the potential of the laser at larger distances from the nucleus. This is in contrast to the approximation made by neglecting the potential of the laser at regions near the nucleus. Perelomov et al. included the Coulomb interaction at larger internuclear distances. Their model (which we call PPT model) was derived for short range potential and includes the effect of the long range Coulomb interaction through the first order correction in the quasi-classical action. Larochelle et al. have compared the theoretically predicted ion versus intensity curves of rare gas atoms interacting with a Ti:Sapphire laser with experimental measurement. They have shown that the total ionization rate predicted by the PPT model fit very well the experimental ion yields for all rare gases in the intermediate regime of Keldysh parameter.\n\nThe rate of MPI on atom with an ionization potential formula_1 in a linearly polarized laser with frequency formula_2 is given by\n\nwhere \nThe coefficients formula_8, formula_9 and formula_10 are given by\n\nThe coefficient formula_12 is given by\n\nThe full cycle time-average of that potential which is \n\nwill be the even function of formula_15 and therefore having the maximum at formula_16 while for that initial condition the solution will be formula_17 in the K-H and it will be therefore identical to the free electron solution in the laboratory frame. The electron velocity on the other hand is phase shifted both to the field strength and to the electron position: \n\nTherefore considering the wavelet pulses and defining the ionization as the full escape from the line segment of the length 2r (or from the spherical region in three dimensions) the full ionization happens in the classical model after the time formula_19 or no ionization at all depending if the harmonic field wavelet is cut at the zero minimum or the maximum velocity.\n\nA substance may dissociate without necessarily producing ions. As an example, the molecules of table sugar dissociate in water (sugar is dissolved) but exist as intact neutral entities. Another subtle event is the dissociation of sodium chloride (table salt) into sodium and chlorine ions. Although it may seem as a case of ionization, in reality the ions already exist within the crystal lattice. When salt is dissociated, its constituent ions are simply surrounded by water molecules and their effects are visible (e.g. the solution becomes electrolytic). However, no transfer or displacement of electrons occurs. Actually, the chemical synthesis of salt involves ionization. This is a chemical reaction.\n\n"}
{"id": "1995965", "url": "https://en.wikipedia.org/wiki?curid=1995965", "title": "Lisbon Oceanarium", "text": "Lisbon Oceanarium\n\nThe Lisbon Oceanarium (, ) is an oceanarium in Lisbon, Portugal. It is located in the \"Parque das Nações\", which was the exhibition grounds for the Expo '98. It is the largest indoor aquarium in Europe.\n\nThe Lisbon Oceanarium’s conceptual design, architecture, and exhibit design was led by Peter Chermayeff of Peter Chermayeff LLC while at Cambridge Seven Associates. It is said to resemble an aircraft carrier, and is built on a pier in an artificial lagoon. Chermayeff is also the designer of the Osaka Oceanarium, one of the world's largest aquariums, and many other aquariums around the world.\n\nThe Lisbon Oceanarium has a large collection of marine species — penguins, seagulls and other birds; sea otters (mammals); sharks, rays, chimaeras, seahorses and other bony fish; crustaceans; starfish, sea urchins and other echinoderms; sea anemones, corals and other cnidaria; octopuses, cuttlefish, sea snails and other mollusks; amphibians; jellyfish; marine plants and terrestrial plants and other marine organisms totaling about 16,000 individuals of 450 species.\n\nThe main exhibit is a , tank with four large acrylic windows on its sides, and smaller focus windows strategically located around it to make sure it is a constant component throughout the exhibit space. It is deep, which allows pelagic swimmers to swim above the bottom dwellers, and provides the illusion of the open ocean. About 100 species from around the world are kept in this tank, including sharks, rays, barracudas, groupers, and moray eels. One of the main attractions is a large sunfish.\nFour tanks around the large central tank house four different habitats with their native flora and fauna: the North Atlantic rocky coast, the Antarctic coastal line, the Temperate Pacific kelp forests, and the Tropical Indian coral reefs. These tanks are separated from the central tank only by large sheets of acrylic to provide the illusion of a single large tank. Throughout the first floor there are an additional 25 thematic aquariums with each of the habitats' own characteristics.\n\nThe Lisbon Oceanarium is one of the few aquariums in the world to house a sunfish, because of their unique and demanding requirements for care. Other interesting species include two large spider crabs and two sea otters named Eusébio after the soccer player and Amália, named after the fado singer Amália Rodrigues.\n\n"}
{"id": "4410602", "url": "https://en.wikipedia.org/wiki?curid=4410602", "title": "List of Lepidoptera that feed on Chenopodium", "text": "List of Lepidoptera that feed on Chenopodium\n\nGoosefoots (\"Chenopodium\" spp.) are used as food plants by the larvae of a large number of Lepidoptera species:\n\nSpecies which feed exclusively on goosefoots\n\nColeophoridae\n\nSpecies which feed on goosefoots and other plants\n\nColeophoridae\nCrambidae\nGelechiidae\nGeometridae\nNoctuidae\n\n"}
{"id": "44660647", "url": "https://en.wikipedia.org/wiki?curid=44660647", "title": "List of Potyvirus species", "text": "List of Potyvirus species\n\nThe List of Potyvirus species, as of the 2013 release of the ICTV database, contains 146 virus species within the genus. The type species is the \"Potato virus Y\".\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\nBack to top\n\n\nBack to top\n\n\nBack to top\n\nA number of viruses that have not been fully characterised may also belong in this genus:\n\n\"Asystasia gangetica mottle potyvirus\"<br>\n\"Celery latent potyvirus\"<br>\n\"Datura mosaic potyvirus\"<br>\n\"Endive necrotic mosaic potyvirus\"<br>\n\"Kalanchoe mosaic potyvirus\"<br>\n\"Konjak mosaic potyvirus\"<br>\n\"Nasturtium mosaic potyvirus\"<br>\n\"Patchouli mottle potyvirus\"<br>\n\"Shallot yellow stripe potyvirus\"<br>\n\"Sweet potato vein mosaic potyvirus\"<br>\n\"Welsh onion yellow stripe potyvirus\"\n"}
{"id": "5868212", "url": "https://en.wikipedia.org/wiki?curid=5868212", "title": "List of Sites of Special Scientific Interest in Avon", "text": "List of Sites of Special Scientific Interest in Avon\n\n<onlyinclude> This is a list of the Sites of Special Scientific Interest (SSSIs) in the former county of Avon, England, United Kingdom. In England the body responsible for designating SSSIs is Natural England, which chooses a site because of its fauna, flora, geological or physiographical features. Although the county of Avon no longer exists, Natural England still uses its former borders to mark one of its Areas of Search. As of 2006, there are 86 sites designated in this Area of Search, of which 38 have been designated due to their biological interest, 39 due to their geological interest, and 9 for both.\n</includeonly></onlyinclude>\n"}
{"id": "44914", "url": "https://en.wikipedia.org/wiki?curid=44914", "title": "List of national parks of India", "text": "List of national parks of India\n\nNational parks in India are IUCN category II protected areas. India's first national park was established in 1936 as Hailey National Park, now known as Jim Corbett National Park, Uttarakhand. By 1970, India only had five national parks. In 1972, India enacted the Wildlife Protection Act and Project Tiger to safeguard the habitats of conservation reliant species.\n\nFurther federal legislation strengthening protection for wildlife was introduced in the 1980s. As of July 2018, there were 104 national parks encompassing an area of , comprising 1.23% of India's total surface area.\n\nAccording to the Indian Ministry of Environment & Forests, a national park is \"[a]n area, whether within a sanctuary or not, [that] can be notified by the state government to be constituted as a National Park, by reason of its ecological, faunal, floral, geomorphological, or zoological association or importance, needed to for the purpose of protecting & propagating or developing wildlife therein or its environment. No human activity is permitted inside the national park except for the ones permitted by the Chief Wildlife Warden of the state under the conditions given in CHAPTER IV, WPA 1972\".\n\n<mapframe latitude=\"21\" longitude=\"78\" zoom=\"4\" width=\"500\" height=\"500\" text=\"National parks in India\" align=\"center\">\nSELECT ?id ?idLabel ?wikilink \nWHERE\n\n</mapframe>\n\nList of national parks in India:\n\n"}
{"id": "51335092", "url": "https://en.wikipedia.org/wiki?curid=51335092", "title": "List of pollution-related diseases", "text": "List of pollution-related diseases\n\nDiseases caused by pollution lead to the deaths of about 8.4 million people each year. \"However, pollution receives a fraction of the interest from the global community. This is in part because pollution causes so many diseases that it is often difficult to draw a straight line between cause and effect.\n\nThere are many different types of pollution-related diseases, including those caused by air pollution, contaminated soil, water pollution and lacking water, sanitation and hygiene (WASH).Air pollution can be reduced.\n\nEnvironmental diseases are a direct result from the environment. This includes diseases caused by substance abuse, exposure to toxic chemicals, and physical factors in the environment, like UV radiation from the sun, as well as genetic predisposition. Meanwhile, pollution-related diseases are attributed to exposure to toxins in the air, water, and soil. Therefore, all pollution-related disease are environmental diseases, but not all environmental diseases are pollution-related diseases.\n\nAccording to the World Health Organization (WHO), air pollution is linked to 7 million premature deaths. Here is a breakdown by the diseases air pollution causes:\n\n\n\nAccording to the Centers for Disease Control and Prevention (CDC): \"Waterborne diseases are caused by pathogenic microbes that can be directly spread through contaminated water. Most waterborne diseases cause diarrheal illness [Note: not all diseases listed below cause diarrhea]. Eighty-eight percent of diarrhea cases worldwide are linked to unsafe water, inadequate sanitation or insufficient hygiene. These cases result in 1.5 million deaths each year, mostly in young children. The usual cause of death is dehydration. Most cases of diarrheal illness and death occur in developing countries because of unsafe water, poor sanitation, and insufficient hygiene. Other waterborne diseases do not cause diarrhea; instead these diseases can cause malnutrition, skin infections, and organ damage.\n\n\n\n\nSources of lead poisoning/pollution include mining, smelting, manufacturing and recycling activities.\n\n\nArsenic is a naturally occurring element and can be found in food, water, or air. There are also industrial sources of arsenic, including mining and smelting. \"People are exposed to elevated levels of inorganic arsenic through drinking contaminated water, using contaminated water in food preparation and irrigation of food crops, industrial processes, eating contaminated food and smoking tobacco. Long-term exposure to inorganic arsenic... can lead to chronic arsenic poisoning. Skin lesions and skin cancer are the most characteristic effects.\" \n\n"}
{"id": "2020111", "url": "https://en.wikipedia.org/wiki?curid=2020111", "title": "List of rivers of Trinidad and Tobago", "text": "List of rivers of Trinidad and Tobago\n\nThis is a list of rivers of Trinidad and Tobago, arranged by coast, with respective tributaries indented under each larger stream's name.\n\nOn the north coast, rivers empty into the Caribbean Sea\n\nOn the east coast, rivers empty into the Atlantic Ocean\n\nOn the south coast, rivers empty into the Columbus Channel\n\nOn the west coast, rivers empty into the Gulf of Paria\n\nOn the north coast, river empty into the Caribbean Sea\n\nOn the south coast, rivers empty into the Atlantic Ocean\n\n"}
{"id": "26270372", "url": "https://en.wikipedia.org/wiki?curid=26270372", "title": "Lists of nuclear disasters and radioactive incidents", "text": "Lists of nuclear disasters and radioactive incidents\n\nThese are lists of nuclear disasters and radioactive incidents.\n\n\n\n"}
{"id": "98325", "url": "https://en.wikipedia.org/wiki?curid=98325", "title": "Lists of trees", "text": "Lists of trees\n\nA listing of lists of trees.\n\n\n\n\n\n\n"}
{"id": "13785655", "url": "https://en.wikipedia.org/wiki?curid=13785655", "title": "Magnetic anomaly", "text": "Magnetic anomaly\n\nIn geophysics, a magnetic anomaly is a local variation in the Earth's magnetic field resulting from variations in the chemistry or magnetism of the rocks. Mapping of variation over an area is valuable in detecting structures obscured by overlying material. The magnetic variation in successive bands of ocean floor parallel with mid-ocean ridges is important evidence supporting the theory of seafloor spreading, central to plate tectonics.\n\nMagnetic anomalies are generally a small fraction of the magnetic field. The total field ranges from 25,000 to 65,000 nanoteslas (nT). To measure anomalies, magnetometers need a sensitivity of 10 nT or less. There are three main types of magnetometer used to measure magnetic anomalies:\n\n\nIn ground-based surveys, measurements are made at a series of stations, typically 15 to 60 m apart. Usually a proton precession magnetometer is used and it is often mounted on a pole. Raising the magnetometer reduces the influence of small ferrous objects that were discarded by humans. To further reduce unwanted signals, they do not carry objects such as keys, knives or compasses. In addition, objects such as motor vehicles, railway lines, and barbed wire fences are avoided. If some such contaminant is overlooked, it often shows up as a sharp spike in the anomaly, so such features are treated with suspicion. The main application for ground-based surveys is detailed search for minerals.\n\nAirborne magnetic surveys are often used in oil surveys to provide preliminary information for seismic surveys. In some countries such as Canada, government agencies have made systematic surveys of large areas. The survey generally involves making a series of parallel runs at a constant height and intervals of anywhere from a hundred meters to several kilometers. These are crossed by occasional tie lines, perpendicular to the main survey, to check for errors. The plane is a source of magnetism, so sensors are either mounted on a boom (as in the figure) or towed behind on a cable. Aeromagnetic surveys have a lower spatial resolution of ground surveys, but this can be an advantage for a regional survey of deeper rocks.\n\nIn shipborne surveys, a magnetometer is towed a few hundred meters behind a ship in a device called a \"fish\". The sensor is kept at a constant depth of about 15 m. Otherwise, the procedure is similar to that used in aeromagnetic surveys.\n\nThe Sputnik 3 spacecraft in 1958 was the first to carry a magnetometer. In the fall of 1979, Magsat was launched and jointly operated by NASA and USGS until the spring of 1980. It had a caesium vapor scalar magnetometer and a fluxgate vector magnetometer. CHAMP, a German satellite, made precise gravity and magnetic measurements from 2001 to 2010. A Danish satellite, Ørsted, was launched in 1999 and is still in operation, while the Swarm mission of the European Space Agency involves a \"constellation\" of three satellites that were launched in November, 2013.\n\nThere are two main corrections that are needed for magnetic measurements. The first is remove short-term variations in the field from external sources. There are \"diurnal variations\" that have a period of 24 hours and magnitudes of up to 30 nT, probably from the action of the solar wind on the ionosphere. In addition, magnetic storms can have peak magnitudes of 1000 nT and can last for several days. Their contribution can be measured by returning to a base station repeatedly or by having another magnetometer that periodically measures the field at a fixed location.\n\nThe anomaly is the local contribution to the magnetic field, so the main geomagnetic field must be subtracted from it. Usually the International Geomagnetic Reference Field is used for this purpose. This is a large-scale, time-averaged mathematical model of the Earth's field based on measurements from satellites, magnetic observatories and other surveys.\n\nSome corrections that are needed for gravity anomalies are less important for magnetic anomalies. For example, the vertical gradient of the magnetic field is 0.03 nT/m or less, so an elevation correction is generally not needed.\n\nThe magnetization in the surveyed rock is a vector sum of induced and remanent magnetization:\nThe induced magnetization of many minerals is the product of the ambient magnetic field and their magnetic susceptibility :\nSome susceptibilities are given in the table.\n\nMinerals that are diamagnetic or paramagnetic only have an induced magnetization. Ferromagnetic minerals such as magnetite also can carry a remanent magnetization or remanence. This remanence can last for millions of years, so it may be in a completely different direction from the present Earth's field. If a remanence is present, it is difficult to separate from the induced magnetization unless samples of the rock are measured. The ratio of the magnitudes, , is called the Koenigsberger ratio.\n\nMagnetic surveys over the oceans have revealed a characteristic pattern of anomalies around mid-ocean ridges. They involve a series of positive and negative anomalies in the intensity of the magnetic field, forming stripes running parallel to each ridge. They are often symmetric about the axis of the ridge. The stripes are generally tens of kilometers wide, and the anomalies are a few hundred nanoteslas. The source of these anomalies is primarily permanent magnetization carried by titanomagnetite minerals in basalt and gabbros. They are magnetized when ocean crust is formed at the ridge. As magma rises to the surface and cools, the rock acquires a thermoremanent magnetization in the direction of the field. Then the rock is carried away from the ridge by the motions of the tectonic plates. Every few hundred thousand years, the direction of the magnetic field reverses. Thus, the pattern of stripes is a global phenomenon and can be used to calculate the velocity of seafloor spreading.\n\nIn the \"Space Odyssey\" series by Arthur C. Clarke, a series of monoliths are left by extraterrestrials for humans to find them. One near the crater Tycho is found by its unnaturally powerful magnetic field and named \"Tycho Magnetic Anomaly 1\" (TMA-1). One orbiting Jupiter is named TMA-2, and one in the Olduvai Gorge is found in 2513 and retroactively named TMA-0 because it was first encountered by primitive humans.\n\n\n"}
{"id": "50799410", "url": "https://en.wikipedia.org/wiki?curid=50799410", "title": "Mihrabat Nature Park", "text": "Mihrabat Nature Park\n\nMihrabat Nature Park () is a nature park located on the Asian part in Beykoz district of Istanbul Province, Turkey. \n\nSituated southeast of Kanlıca neighborhood of Beykoz next to the Bosphorus, it covers an area of . It was established in 2011.\n\nThe nature park offers outdoor recreational activities such as hiking, cycling and picnicing for visitors on daily basis. There are open-air basketball courts and football field. Access to the nature park is at Mihrabat Cad. 50. Admission is charged for visitors and vehicles. An open-air restaurant and a snack bar serve the visitors. Use of the nature park for events like weddings, music concerts and meetings is also permitted.\n\nThe nature park is the habitat for diverse species of plant with deciduous trees in the majority. Present deciduous vegetation include common hornbeam (\"Carpinus betulus\"), sweet chestnut (\"Castanea sativa\"), oriental plane (\"Platanus orientalis\"), silver linden (\"Tilia argentea\"), kermes oak (\"Quercus coccifera\"), Irish oak (\"Quercus petraea\"), Norway maple (\"Acer platanoides\"), Balkan maple (\"Acer trautvetteri\"), crepe flower (\"Lagerstroemia indica\"), Mediterranean hackberry (\"Celtis australis\"), cigartree (\"Catalpa bignonioides\"), Judas tree \"Cercis siliquastrum\", common ash (\"Fraxinus excelsior\"), silver wattle (\"Acacia dealbata\"), cherry plum (\"Prunus cerasifera\") and southern magnolia (\"Magnolia grandiflora\").\n\nPresent conifer trees are stone pine (\"Pinus pinea\"), Himalayan cedar (\"Cedrus deodara\") and Syrian juniper (\"Juniperus drupacea\").\n\nFoliage plants are Mediterranean cypress (Cupressus sempervirens\"), giant cedar (Thuja plicata\"), oriental cedar (\"Thuja orientalis\"), (Lebanon cedar (\"Cedrus libani\") and Greek juniper (\"Juniperus excelsa\").\n\nShrubs in the park are goat willow (\"Salix caprea\"), bay laurel (\"Laurus nobilis\"), Chinese photinia (\"Photinia serratifolia\"), laurestine (\"Viburnum tinus\"), strawberry tree (\"Arbutus unedo\"), English dogwood (\"Philadelphus coronarius\"), European holly \n(\"Ilex aquifolium\"), salt cedar (\"Tamarix\"), weaver's broom (\"Spartium junceum\"), scarlet firethorn (\"Pyracantha coccinea\"), blackberry (\"Rubus\"), Australian laurel (\"Pittosporum tobira\"), butcher's broom (\"Ruscus aculeatus\"), tree heath (\"Erica arborea\"), Japanese privet (\"Ligustrum japonicum\"), green olive tree (\"Phillyrea latifolia\"), dog-rose (\"Rosa canina\") and common medlar (\"Mespilus germanica\").\n\nEuropean ivy (\"Hedera helix\") is found in the nature as creeper plant. On the hillsides, flowering plants such as stonecrops (\"Sedum hispanicum\") and \n(\"Sedum spurium\"), oleander (\"Nerium oleander\"), rosemary (\"Rosmarinus officinalis\") and nandina (\"Nandina domestica \")).\n\nObserved bird species in the nature park are sparrow, dunnock, common raven, woodpecker and European goldfinch. Other animals found in the park are hare, squirrel, tortoise, lixard.\n"}
{"id": "292200", "url": "https://en.wikipedia.org/wiki?curid=292200", "title": "Missing fundamental", "text": "Missing fundamental\n\nA harmonic sound is said to have a missing fundamental, suppressed fundamental, or phantom fundamental when its overtones suggest a fundamental frequency but the sound lacks a component at the fundamental frequency itself.\nThe brain perceives the pitch of a tone not only by its fundamental frequency, but also by the periodicity implied by the relationship between the higher harmonics; we may perceive the same pitch (perhaps with a different timbre) even if the fundamental frequency is missing from a tone.\n\nFor example, when a note (that is not a pure tone) has a pitch of 100 Hz, it will consist of frequency components that are integer multiples of that value (e.g. 100, 200, 300, 400, 500... Hz). However, smaller loudspeakers may not produce low frequencies, and so in our example, the 100 Hz component may be missing. Nevertheless, a pitch corresponding to the fundamental may still be heard.\n\nA low pitch (also known as the pitch of the missing fundamental or virtual pitch) can sometimes be heard when there is no apparent source or component of that frequency. This perception is due to the brain interpreting repetition patterns that are present.\n\nIt was once thought that this effect was because the missing fundamental was replaced by distortions introduced by the physics of the ear. However, experiments subsequently showed that when a noise was added that would have masked these distortions had they been present, listeners still heard a pitch corresponding to the missing fundamental, as reported by J. C. R. Licklider in 1954. It is now widely accepted that the brain processes the information present in the overtones to calculate the fundamental frequency. The precise way in which it does so is still a matter of debate, but the processing seems to be based on an autocorrelation involving the timing of neural impulses in the auditory nerve. However, it has long been noted that any neural mechanisms which may accomplish a delay (a necessary operation of a true autocorrelation) have not been found. At least one model shows a temporal delay to be unnecessary to produce an autocorrelation model of pitch perception, appealing to phase shifts between cochlear filters; however, earlier work has shown that certain sounds with a prominent peak in their autocorrelation function do not elicit a corresponding pitch percept, and that certain sounds without a peak in their autocorrelation function nevertheless elicit a pitch. Autocorrelation can thus be considered, at best, an incomplete model.\n\nThe pitch of the missing fundamental, usually at the greatest common divisor of the frequencies present, is not, however, always perceived. Research conducted at Heidelberg University shows that, under narrow stimulus conditions with a small number of harmonics, the general population can be divided into those who perceive missing fundamentals, and those who primarily hear the overtones instead. This was done by asking subjects to judge the direction of motion (up or down) of two complexes in succession. The authors used structural MRI and MEG to show that the preference for missing fundamental hearing correlated with left-hemisphere lateralization of pitch perception, where the preference for spectral hearing correlated with right-hemisphere lateralization, and those who exhibited the latter preference tended to be musicians.\n\nOn-line sound examples comparing pure and complex tones and complexes with missing fundamentals can be found here.\n\nTimpani (kettle drums) produce inharmonic overtones, but are constructed and tuned to produce near-harmonic overtones to an implied missing fundamental. Hit in the usual way (half to three-quarters the distance from the center to the rim), the fundamental note of a timpani is very weak in relation to its second through fifth \"harmonic\" overtones. A timpani might be tuned to produce sound most strongly at 200, 302, 398, and 488 Hz, for instance, implying a missing fundamental at 100 Hz (though the actual dampened fundamental is 170 Hz).\n\nA violin's lowest air and body resonances generally fall between 250 Hz and 300 Hz. The fundamental frequency of the open G3 string is below 200 Hz in modern tunings as well as most historical tunings, so the lowest notes of a violin have an attenuated fundamental, although listeners seldom notice this.\n\nThe fundamental frequency is not normally heard on acoustic guitars, classical guitars and other stringed instruments with one end of the strings anchored on a soundboard bridge which has a low profile, holding the strings close to the soundboard surface. In these cases, the lateral string vibration has no discernable effect on the bridge; instead, the bridge is excited by changes in string tension, which are twice the lateral wave frequency. On these instruments, listeners hear the first harmonic as the lowest note. Electric guitars are not like this; the fundamental frequency of each string is heard because the lateral string movement excites the electric pickups underneath the vibrating string.\n\nMost common telephones cannot reproduce sounds lower than 300 Hz, but a male voice has a fundamental frequency approximately 150 Hz. Because of the missing fundamental effect, the fundamental frequencies of male voices are still perceived as their pitches over the telephone.\n\nThe missing fundamental phenomenon is used electronically by some pro audio manufacturers to allow sound systems to seem to produce notes that are lower in pitch than they are capable of reproducing. In a hardware effects unit or a software plugin, a crossover filter is set at a low frequency above which the sound system is capable of safely reproducing tones. Musical signal content above the high-pass part of the crossover filter is sent to the main output which is amplified by the sound system. Low frequency content below the low-pass part of the crossover filter is sent to a circuit where harmonics are synthesized above the low notes. The newly created harmonics are mixed back into the main output to create a perception of the filtered-out low notes. Using a device with this synthetic process can reduce complaints from low frequency noise carrying through walls and it can be employed to reduce low frequency content in loud music that might otherwise vibrate and damage breakable valuables.\n\nSome pipe organs makes use of this phenomenon as a resultant tone, which allows relatively smaller bass pipes to produce very low-pitched sounds.\n\nThis very concept of \"missing fundamental\" being reproduced based on the overtones in the tone has been used to create the illusion of bass in sound systems that are not capable of such bass. In mid-1999, Meir Shashoua of Tel Aviv, co-founder of Waves Audio, patented an algorithm to create the sense of the missing fundamental by synthesizing higher harmonics. Waves Audio released the MaxxBass plug-in to allow computer users to apply the synthesized harmonics to their audio files. Later, Waves Audio produced small subwoofers that relied on the missing fundamental concept to give the illusion of low bass. Both products processed certain overtones selectively to help small loudspeakers, ones which could not reproduce low-frequency components, to sound as if they were capable of low bass. Both products included a high-pass filter which greatly attenuated all the low frequency tones that were expected to be beyond the capabilities of the target sound system. One example of a popular song that was recorded with MaxxBass processing is \"Lady Marmalade\", the 2001 Grammy award-winning version sung by Christina Aguilera, Lil' Kim, Mýa, and Pink, produced by Missy Elliott.\n\nOther software and hardware companies have developed their own versions of missing fundamental-based bass augmentation products. The poor bass reproduction of earbuds has been identified as a possible target for such processing. Many computer sound systems are not capable of low bass, and songs offered to consumers via computer have been identified as ones that may benefit from augmented bass harmonics processing.\n\n\n"}
{"id": "47577212", "url": "https://en.wikipedia.org/wiki?curid=47577212", "title": "National Centers for Environmental Information", "text": "National Centers for Environmental Information\n\nThe United States National Centers for Environmental Information (NCEI), headquartered in Asheville, North Carolina, is the world's largest active archive of environmental data. In 2015 it was established from the merger of the National Climatic Data Center (NCDC), the National Geophysical Data Center (NGDC) and the National Oceanographic Data Center (NODC). The current director is Mary Wohlgemuth.\n\nThe establishment of NCEI was rooted in the dramatic increase in the demand for environmental data and information in the years preceding 2015. In order to meet the demand, the three existing data centers are merged in accordance with the Consolidated and Further Continuing Appropriations Act, 2015, Public Law 113-235:\n\nNCEI was launched on April 22, 2015. The transition is expected to finish beyond 2020, while at the meantime none of the existing products and services will be affected by the merger. Existing URLs, links and domain names for the data centers will remain accessible, even though a plan will be developed to consolidate the domains, also any change will be advertised and appropriate redirects will be created.\n\nNCEI hosts and provides access to over 20 petabytes of comprehensive atmospheric, coastal, oceanic, and geophysical digital data e.g. ocean depth information, sun surface data, million-year-old sediment records and near real-time satellite images.\n\nNCEI funds six regional climate centers in the United States, designed to provide enhanced services to sectors within their covered regions. The individual climate centers develop their own tools and services to assist partners and decision makers. The six regional climate centers are:\n\n\n"}
{"id": "65254", "url": "https://en.wikipedia.org/wiki?curid=65254", "title": "Ossë", "text": "Ossë\n\nOssë (; from the Valarin Ošošai, Oššai) is a fictional character in the works of J. R. R. Tolkien. He is introduced in \"The Silmarillion\" as an angelic being known as a Maia, associated with Ulmo, one of the Valar (analogous to archangels).\n\nA spirit of the sea in the service of Ulmo, Ossë guarded the waters around Middle-earth. He was married to Uinen, and he was a friend of Círdan the Shipwright. During the Years of the Trees, he briefly entered into the service of Melkor and began causing wanton storms which made traveling by sea particularly unsafe. He was persuaded to stop by his spouse Uinen, upon the prayer of the Vala Aulë, but Ossë's taste for storms did not quite disappear.\n\nOssë was a friend of the Sindar, and was valued as high as the Valar by them.\nThis relationship started before the coming of the Sindar to Valinor, while they dwelled on shores of Middle-earth, waiting for their leader. It was against Ossë's will that they ever went to Valinor.\n\nIn older versions of \"The Silmarillion\", Ossë was a Vala in his own right, and often opposed a Maia of Ulmo.\n"}
{"id": "20559667", "url": "https://en.wikipedia.org/wiki?curid=20559667", "title": "Photoacoustic Doppler effect", "text": "Photoacoustic Doppler effect\n\nThe photoacoustic Doppler effect, as its name implies, is one specific kind of Doppler effect, which occurs when an intensely modulated light wave induces a photoacoustic wave on moving particles with a specific frequency. The observed frequency shift is a good indicator of the velocity of the illuminated moving particles. A potential biomedical application is measuring blood flow.\n\nSpecifically, when an intensity modulated light wave is exerted on a localized medium, the resulting heat can induce an alternating and localized pressure change. This periodic pressure change generates an acoustic wave with a specific frequency. Among various factors that determine this frequency, the velocity of the heated area and thus the moving particles in this area can induce a frequency shift proportional to the relative motion. Thus, from the perspective of an observer, the observed frequency shift can be used to derive the velocity of illuminated moving particles.\n\nTo be simple, consider a clear medium firstly. The medium contains small optical absorbers moving with velocity vector formula_1. The absorbers are irradiated by a laser with intensity modulated at frequency formula_2. \nThus, the intensity of the laser could be described by:\n\nformula_3\n\nWhen formula_1 is zero, an acoustic wave with the same frequency formula_2 as the light intensity wave is induced. Otherwise, there is a frequency shift in the induced acoustic wave. The magnitude of the frequency shift depends on the relative velocity formula_1, the angle formula_7 between the velocity and the photon density wave propagation direction, and the angle formula_8 between the velocity and the ultrasonic wave propagation direction. \nThe frequency shift is given by:\n\nformula_9\n\nWhere formula_10 is the speed of light in the medium and formula_11 is the speed of sound. The first term on the right side of the expression represents the frequency shift in the photon density wave observed by the absorber acting as a moving receiver. The second term represents the frequency shift in the photoacoustic wave due to the motion of the absorbers observed by the ultrasonic transducer.\n\nIn practice, since formula_12 and formula_13, only the second term is detectable. Therefore, the above equation reduces to:\n\nformula_14\n\nIn this approximation, the frequency shift is not affected by the direction of the optical radiation. It is only affected by the magnitude of velocity and the angle between the velocity and the acoustic wave propagation direction.\n\nThis equation also holds for a scattering medium. In this case, the photon density wave becomes diffusive due to light scattering. Although the diffusive photon density wave has a slower phase velocity than the speed of light, its wavelength is still much longer than the acoustic wave.\n\nIn the first demonstration of the Photoacoustic Doppler effect, a continuous wave diode laser was used in a photoacoustic microscopy setup with an ultrasonic transducer as the detector. The sample was a solution of absorbing particles moving through a tube. The tube was in a water bath containing scattering particles\n\nFigure 2 shows a relationship between average flow velocity and the experimental photoacoustic Doppler frequency shift. In a scattering medium, such as the experimental phantom, fewer photons reach the absorbers than in an optically clear medium. This affects the signal intensity but not the magnitude of the frequency shift. Another demonstrated feature of this technique is that it is capable of measuring flow direction relative to the detector based on the sign of the frequency shift. The reported minimum detected flow rate is 0.027 mm/s in the scattering medium.\n\nOne promising application is the non-invasive measurement of flow. This is related to an important problem in medicine: the measurement of blood flow through arteries, capillaries, and veins. Measuring blood velocity in capillaries is an important component to clinically determining how much oxygen is delivered to tissues and is potentially important to the diagnosis of a variety of diseases including diabetes and cancer.However, a particular difficulty of measuring flow velocity in capillaries is caused by the low blood flow rate and micrometre-scale diameter. Photoacoustic Doppler effect based imaging is a promising method for blood flow measurement in capillaries.\n\nBased on either ultrasound or light there are several techniques currently being used to measure blood velocity in a clinical setting or other types of flow velocities.\n\nThe Doppler ultrasound technique uses Doppler frequency shifts in ultrasound wave. This technique is currently used in biomedicine to measure blood flow in arteries and veins. It is limited to high flow rates (formula_15cm/s) generally found in large vessels due to the high background ultrasound signal from biological tissue.\n\nLaser Doppler Flowmetry utilizes light instead of ultrasound to detect flow velocity. The much shorter optical wavelength means this technology is able to detect low flow velocities out of the range of Doppler ultrasound. But this technique is limited by high background noise and low signal due to multiple scattering. Laser Doppler flowmetry can measure only the averaged blood speed within 1mm without information about flow direction.\n\nDoppler Optical coherence tomography is an optical flow measurement technique that improves on the spatial resolution of laser Doppler flowmetry by rejecting multiple scattering light with coherent gating. This technique is able to detect flow velocity as low as formula_16m/s with the spatial resolution of formula_17mformula_18. The detection depth is usually limited by the high optical scattering coefficient of biological tissue to formula_19mm.\n\nPhotoacoustic Doppler effect can be used to measure the blood flow velocity with the advantages of Photoacoustic imaging. Photoacoustic imaging combines the spatial resolution of ultrasound imaging with the contrast of optical absorption in deep biological tissue. Ultrasound has good spatial resolution in deep biological tissue since ultrasonic scattering is much weaker than optical scattering, but it is insensitive to biochemical properties. Conversely, optical imaging is able to achieve high contrast in biological tissue via high sensitivity to small molecular optical absorbers, such as hemoglobin found in red blood cells, but its spatial resolution is compromised by the strong scattering of light in biological tissue. By combining the optical imaging with ultrasound, it is possible to achieve both high contrast and spatial resolution.\n\nThe photoacoustic Doppler flowmetry could use the power of photoacoustics to measure flow velocities that are usually inaccessible to pure light-based or ultrasound techniques. The high spatial resolution could make it possible to pinpoint only a few absorbing particles localized to a single capillary. High contrast from the strong optical absorbers make it possible to clearly resolve the signal from the absorbers over the background.\n\n"}
{"id": "43349971", "url": "https://en.wikipedia.org/wiki?curid=43349971", "title": "Proletariat", "text": "Proletariat\n\nThe proletariat ( from Latin \"producing offspring\") is the class of wage-earners in an economic society whose only possession of significant material value is their labour-power (how much work they can do). A member of such a class is a proletarian.\n\nIn Marxist theory, a dictatorship of the proletariat is for the proletariat, of the proletariat, and by the proletariat. On the Marxist view, this will endow the proletarian with the power to abolish the conditions that make a person a proletarian and, thus, build communism.\n\nThe constituted a social class of Roman citizens owning little or no property. The origin of the name is presumably linked with the census, which Roman authorities conducted every five years to produce a register of citizens and their property from which their military duties and voting privileges could be determined. For citizens with property valued 11,000 or less, which was below the lowest census for military service, their children— (from Latin , \"offspring\")—were listed instead of their property; hence, the name , \"the one who produces offspring\". The only contribution of a to the Roman society was seen in his ability to raise children, the future Roman citizens who can colonize new territories conquered by the Roman Republic and later by the Roman Empire. The citizens who had no property of significance were called because they were \"persons registered not as to their property...but simply as to their existence as living individuals, primarily as heads () of a family.\"\n\nAlthough included in one of the five support of the (English: Centuriate Assembly), were largely deprived of their voting rights due to their low social status caused by their lack of \"even the minimum property required for the lowest class\" and a class-based hierarchy of the . The late Roman historians, such as Livy, not without some uncertainty, understood the to be one of three forms of popular assembly of early Rome composed of , the voting units whose members represented a class of citizens according to the value of their property. This assembly, which usually met on the to discuss public policy issues, was also used as a means of designating military duties demanded of Roman citizens. One of reconstructions of the features 18 of cavalry, and 170 of infantry divided into five classes by wealth, plus 5 of support personnel called . The top infantry class assembled with full arms and armor; the next two classes brought arms and armor, but less and lesser; the fourth class only spears; the fifth slings. In voting, the cavalry and top infantry class were enough to decide an issue; as voting started at the top, an issue might be decided before the lower classes voted. In the last centuries of the Roman Republic (509–44 BC), the became impotent as a political body, which further eroded already minuscule political power the might have had in the Roman society.\n\nFollowing a series of wars the Roman Republic engaged since the closing of the Second Punic War (218–201 BC), such as the Jugurthine War and conflicts in Macedonia and Asia, the significant reduction in the number of Roman family farmers had resulted in the shortage of people whose property qualified them to perform the citizenry's military duty to Rome. As a result of the Marian reforms initiated in 107 BC by the Roman general Gaius Marius (157–86), the became the backbone of the Roman army.\n\nKarl Marx, who studied Roman law at the Friedrich Wilhelm University of Berlin, used the term \"proletariat\" in his socio-political theory of Marxism to describe a working class unadulterated by private property and capable of a revolutionary action to topple capitalism in order to create classless society. Marx most likely encountered the term while studying the works of the liberal economist and historian , who was the first to apply it to the working class created under capitalism, and whose writings were frequently cited by Marx.\n\nIn Marxist theory, the proletariat is the social class that does not have ownership of the means of production and whose only means of subsistence is to sell their labor power for a wage or salary. Proletarians are wage-workers, while some refer to those who receive salaries as the \"salariat\". For Marx, however, wage labor may involve getting a salary rather than a wage \"per se\". Marxism sees the proletariat and bourgeoisie (capitalist class) as occupying conflicting positions, since workers automatically wish their wages to be as high as possible, while owners and their proxies wish for wages (costs) to be as low as possible.\nIn Marxist theory, the borders between the proletariat and some layers of the petite bourgeoisie, who rely primarily but not exclusively on self-employment at an income no different from an ordinary wage or below it – and the lumpenproletariat, who are not in legal employment – are not necessarily well defined. Intermediate positions are possible, where some wage-labor for an employer combines with self-employment. Marx makes a clear distinction between proletariat as salaried workers, which he sees as a progressive class, and Lumpenproletariat, \"rag-proletariat\", the poorest and outcasts of the society, such as beggars, tricksters, entertainers, buskers, criminals and prostitutes, which he considers a retrograde class. Socialist parties have often struggled over the question of whether they should seek to organize and represent all the lower classes, or just the wage-earning proletariat.\n\nAccording to Marxism, capitalism is a system based on the exploitation of the proletariat by the bourgeoisie. This exploitation takes place as follows: the workers, who own no means of production of their own, must use the means of production that are property of others in order to produce, and consequently earn, their living. Instead of hiring those means of production, they themselves get hired by capitalists and work for them, producing goods or services. These goods or services become the property of the capitalist, who sells them at the market.\n\nOne part of the wealth produced is used to pay the workers' wages (variable costs), another part to renew the means of production (constant costs) while the third part, surplus value is split between the capitalist's private takings (profit), and the money used to pay rents, taxes, interests, etc. Surplus value is the difference between the wealth that the proletariat produces through its work, and the wealth it consumes to survive and to provide labor to the capitalist companies. A part of the surplus value is used to renew or increase the means of production, either in quantity or quality (i.e., it is turned into capital), and is called capitalized surplus value. What remains is consumed by the capitalist class.\n\nThe commodities that proletarians produce and capitalists sell are valued for the amount of labor embodied in them. The same goes for the workers' labor power itself: it is valued, not for the amount of wealth it produces, but for the amount of labor necessary to produce and reproduce it. Thus the capitalists earn wealth from the labor of their employees, not as a function of their personal contribution to the productive process, which may even be null, but as a function of the juridical relation of property to the means of production. Marxists argue that new wealth is created through labor applied to natural resources.\n\nMarx argued that the proletariat would displace the capitalist system with the dictatorship of the proletariat, abolishing the social relationships underpinning the class system and then developing into a communist society in which \"the free development of each is the condition for the free development of all\".\n\nProle drift, short for proletarian drift, is the tendency in advanced industrialized societies for everything inexorably to become proletarianized, or to become commonplace and commodified. This trend is attributed to mass production, mass selling, mass communication and mass education. Examples include best-seller lists, films and music that must appeal to the masses, and shopping malls.\n\n"}
{"id": "52784231", "url": "https://en.wikipedia.org/wiki?curid=52784231", "title": "Q Carinae", "text": "Q Carinae\n\nThe Bayer designations q Carinae and Q Carinae are distinct.\n\n"}
{"id": "1599733", "url": "https://en.wikipedia.org/wiki?curid=1599733", "title": "Radiation implosion", "text": "Radiation implosion\n\nRadiation implosion is the compression of a target by the use of high levels of electromagnetic radiation. The major use for this technology is in fusion bombs and inertial confinement fusion research.\n\nRadiation implosion was first developed by Klaus Fuchs and John von Neumann in the United States, as part of their work on the original \"Classical Super\" hydrogen bomb design. Their work resulted in a secret patent filed in 1946, and later given to the USSR by Fuchs as part of his nuclear espionage. However, their scheme was not the same as used in the final hydrogen bomb design, and neither the American nor the Soviet programs were able to make use of it directly in developing the hydrogen bomb (its value would become apparent only after the fact). A modified version of the Fuchs-von Neumann scheme was incorporated into the \"George\" shot of Operation Greenhouse.\n\nIn 1951, Stanislaw Ulam had the idea to use hydrodynamic shock of a fission weapon to compress more fissionable material to incredible densities in order to make megaton-range, two-stage fission bombs. He then realized that this approach might be useful for starting a thermonuclear reaction. He presented the idea to Edward Teller, who realized that radiation compression would be both faster and more efficient than mechanical shock. This combination of ideas, along with a fission \"sparkplug\" embedded inside of the fusion fuel, became what is known as the Teller–Ulam design for the hydrogen bomb.\n\nMost of the energy released by a fission bomb is in the form of x-rays. The spectrum is approximately that of a black body at a temperature of 50,000,000 kelvins (a little more than three times the temperature of the Sun's core). The amplitude can be modeled as a trapezoidal pulse with a one microsecond rise time, one microsecond plateau, and one microsecond fall time. For a 30 kiloton fission bomb, the total x-ray output would be 100 terajoules.\n\nIn a Teller-Ulam bomb, the object to be imploded is called the \"secondary\". It contains fusion material, such as lithium deuteride, and its outer layers are a material which is opaque to x-rays, such as lead or uranium-238.\n\nIn order to get the x-rays from the surface of the primary, the fission bomb, to the surface of the secondary, a system of \"x-ray reflectors\" is used.\n\nThe reflector is typically a cylinder made of a material such as uranium. The primary is located at one end of the cylinder and the secondary is located at the other end. The interior of the cylinder is commonly filled with a foam which is mostly transparent to x-rays, such as polystyrene. \n\nThe term reflector is misleading, since it gives the reader an idea that the device works like a mirror. Some of the x-rays are diffused or scattered, but the majority of the energy transport happens by a two-step process: the x-ray reflector is heated to a high temperature by the flux from the primary, and then it emits x-rays which travel to the secondary. Various classified methods are used to improve the performance of the reflection process.\n\nSome Chinese documents show that Chinese scientists used a different method to achieve radiation implosion. According to these documents, an X-ray lens, not a reflector, was used to transfer the energy from primary to secondary during the making of the first Chinese H-bomb.\n\nThe term \"radiation implosion\" suggests that the secondary is crushed by radiation pressure, and calculations show that while this pressure is very large, the pressure of the materials vaporized by the radiation is much larger. The outer layers of the secondary become so hot that they vaporize and fly off the surface at high speeds. The recoil from this surface layer ejection produces pressures which are an order of magnitude stronger than the simple radiation pressure. The so-called radiation implosion in thermonuclear weapons is therefore thought to be a radiation-powered ablation-drive implosion.\n\nThere has been much interest in the use of large lasers to ignite small amounts of fusion material. This process is known as inertial confinement fusion (ICF). As part of that research, much information on radiation implosion technology has been declassified.\n\nWhen using optical lasers, there is a distinction made between \"direct drive\" and \"indirect drive\" systems. In a direct drive system, the laser beam(s) are directed onto the target, and the rise time of the laser system determines what kind of compression profile will be achieved.\n\nIn an indirect drive system, the target is surrounded by a shell (called a Hohlraum) of some intermediate-Z material, such as selenium. The laser heats this shell to a temperature such that it emits x-rays, and these x-rays are then transported onto the fusion target. Indirect drive has various advantages, including better control over the spectrum of the radiation, smaller system size (the secondary radiation typically has a wavelength 100 times smaller than the driver laser), and more precise control over the compression profile.\n\n"}
{"id": "3423142", "url": "https://en.wikipedia.org/wiki?curid=3423142", "title": "Russia–Ukraine gas disputes", "text": "Russia–Ukraine gas disputes\n\nThe Russia–Ukraine gas disputes refer to a number of disputes between Ukrainian oil and gas company Naftohaz Ukrayiny and Russian gas supplier Gazprom over natural gas supplies, prices, and debts. These disputes have grown beyond simple business disputes into transnational political issues—involving political leaders from several countries—that threaten natural gas supplies in numerous European countries dependent on natural gas imports from Russian suppliers, which are transported through Ukraine. Russia provides approximately a quarter of the natural gas consumed in the European Union; approximately 80% of those exports travel through pipelines across Ukrainian soil prior to arriving in the EU.\n\nA serious dispute began in March 2005 over the price of natural gas supplied and the cost of transit. During this conflict, Russia claimed Ukraine was not paying for gas, but diverting that which was intended to be exported to the EU from the pipelines. Ukrainian officials at first denied the accusation, but later Naftogaz admitted that natural gas intended for other European countries was retained and used for domestic needs. The dispute reached a high point on 1 January 2006, when Russia cut off all gas supplies passing through Ukrainian territory. On 4 January 2006, a preliminary agreement between Russia and Ukraine was achieved, and the supply was restored. The situation calmed until October 2007 when new disputes began over Ukrainian gas debts. This led to reduction of gas supplies in March 2008. During the last months of 2008, relations once again became tense when Ukraine and Russia could not agree on the debts owed by Ukraine.\n\nIn January 2009, this disagreement resulted in supply disruptions in many European nations, with eighteen European countries reporting major drops in or complete cut-offs of their gas supplies transported through Ukraine from Russia. In September 2009 officials from both countries stated they felt the situation was under control and that there would be no more conflicts over the topic, at least until the Ukrainian 2010 presidential elections. However, in October 2009, another disagreement arose about the amount of gas Ukraine would import from Russia in 2010. Ukraine intended to import less gas in 2010 as a result of reduced industry needs because of its economic recession; however, Gazprom insisted that Ukraine fulfill its contractual obligations and purchase the previously agreed upon quantities of gas.\n\nOn 8 June 2010, a Stockholm court of arbitration ruled Naftohaz of Ukraine must return of gas to RosUkrEnergo, a Swiss-based company in which Gazprom controls a 50% stake. Russia accused Ukrainian side of diverting gas from pipelines passing through Ukraine in 2009. Several high-ranking Ukrainian officials stated the return \"would not be quick\".\n\nRussia plans to completely abandon gas supplies to Europe through Ukraine after 2018. Gazprom has already substantially reduced the volumes of gas it transits across Ukraine, and expressed its intention of reducing the level further by means of transit diversification pipelines (Nord Stream, Turkish Stream, etc).\n\nAfter the dissolution of the Soviet Union, oil import prices to Ukraine reached world market levels in 1993. However, gas import prices and transit fees remained below European levels for Russian exports to Europe through pipelines in Ukraine; these were set in bilateral negotiations. At the same time Ukraine remained the main transit corridor for Russia's gas export. In 2004–2005, 80% of Russian gas exports to the European Union were made through Ukrainian territory. Two-thirds of Gazprom's revenue comes from the sale of gas that crosses Ukraine.\n\nUkraine's own annual gas consumption in 2004–2005 was around , of which around were produced domestically, were bought from Turkmenistan, and were received from Russia in exchange for transport of Russian natural gas. The remaining were purchased from Russia. The gas trading system differed substantially from the gas sale to the European Union and caused problems in the form of large-scale deliveries of relatively cheap Russian gas causing an increase of energy-intensive industries and supporting Ukraine's status as one of the world's least energy-efficient countries and largest gas importers, the accumulation of Ukrainian debts and non-payment of same, unsanctioned diversion of gas and alleged theft from the transit system, and Russian pressure on Ukraine to hand over infrastructure in return for relief of debts accumulated over natural gas transactions.\n\nGas trading was conducted under a framework of bilateral intergovernmental agreements which provided for sales, transit volumes, gas prices, gas storage, and other issues such as the establishment of production joint ventures. Commercial agreements were negotiated between the relevant companies within the guidelines and dictates of that framework and supplemented by annual agreements specifying exact prices and volumes for the following year. Gas sales prices and transit tariffs were determined in relationship to each other. Commercial agreements and trade relations have been non-transparent and trade has been conducted via intermediaries such as Itera, EuralTransGaz, and RosUkrEnergo. RosUkrEnergo's involvement in the Russian-Ukrainian gas trade has been controversial. There are allegations that the company is controlled by Semion Mogilevich and its beneficiaries include strategically placed officials in the Russian and Ukrainian gas industries and governmental structures related to the energy sector. Russian Prime Minister Vladimir Putin has made accusations that RosUkrEnergo is owned by a business ally of Ukraine's ex-president, Viktor Yushchenko. The Ukrainian investigation into RosUkrEnergo, during Yulia Tymoshenko's first term as Prime Minister, was closed after she was fired by Yushchenko in September 2005.\n\nAccording to a contract between Gazprom and Naftogaz signed on 21 June 2002, payment for the transfer of Russian natural gas through the Ukrainian pipeline system had been made in exchange for no more than 15% of the gas pumped through Ukrainian territory to be taken in lieu of cash. This contract was supposed to be valid until the end of 2013. On 9 August 2004, the two companies signed an addendum to the contract, according to which the amount of gas given as a payment was calculated based on a tariff of US$1.09 for the transportation of 1,000 cubic meters of natural gas over a distance of ; the addendum further stated the price of the natural gas supplied to Ukraine was to be $50 per 1,000 cubic meters (approximately $1.40 per million Btu). This price was constant notwithstanding the gas prices in the European markets. According to the addendum the price was not subject to change until the end of 2009. Gazprom argued that this addendum was only applicable provided that the two countries sign an annual intergovernmental protocol that has higher legal status for specifying the terms of gas transit. According to Gazprom, the addendum becomes void as the annual protocol had not been signed for 2006 under the required terms. Russia claimed that Gazprom's subsidies to the Ukrainian economy amounted to billions of dollars.\n\nAccording to the agreement of 2006, RosUkrEnergo was to receive no more than 20 percent of the total delivered gas, which in 2007 was of .\n\nInitial disputes concerning gas debts and non-payment appeared immediately after the collapse of the Soviet Union. As a result of disputes over non-payments by Ukraine, Russia suspended natural gas exports several times between 1992 and 1994. This led to the illicit diversion of Russian natural gas exports from transit pipelines by Ukrainian companies and institutions in September 1993 and November 1994. The diversion of gas was acknowledged by Ukraine, while accusations of other diversions were disputed. In September 1993, at a summit conference in Massandra, Crimea, Russian President Boris Yeltsin offered to Ukrainian President Leonid Kravchuk to forgive Ukrainian debts in return for control of the Black Sea Fleet and Ukraine's nuclear arsenal. After a strong negative reaction from politicians in Kiev, the idea was abandoned. An intergovernmental agreement was drafted on gas issues, including a clause stating Ukraine would permit Gazprom to participate in the privatization of Ukrainian enterprises in gas and other sectors. In March 1994, a Ukrainian deputy prime minister agreed with Russia that Gazprom could acquire a 51% stake in the pipeline system. In early 1995, Russia and Ukraine agreed to create a joint company, Gaztransit, to operate Ukraine's natural gas transit infrastructure in exchange for the cancellation of a substantial portion of Ukraine's debts to Russia. These agreements were never implemented, and in November 1995, the Verkhovna Rada, Ukraine's parliament, adopted a law prohibiting the privatization of oil and gas assets.\n\nIn 1998, Gazprom and Naftohaz made a contract under which Gazprom would pay for the transit of volumes of gas, which established a link between gas prices and transit tariffs, but this contract did not resolve the issue of already incurred gas debts. In 1998, Gazprom alleged that Ukraine had illegally diverted gas meant for export to other European countries and suspended exports of oil and electricity to Ukraine in 1999. Gazprom also claimed that Ukraine's gas debt had reached $2.8 billion. In 2001, Deputy Prime Minister Oleh Dubyna acknowledged that in 2000 alone of Russian natural gas had been diverted from export pipelines. The debt issue was settled on 4 October 2001, by the signing of an intergovernmental agreement on Additional Measures Regarding the Provision of Transit of Russian Natural Gas on the Territory of Ukraine (the 2001 Transit Agreement).\n\nIn 2005, negotiations over gas prices for 2006 started. Gazprom insisted on a new price of $160 per 1,000 cubic meters. The Government of Ukraine agreed, with the stipulation that price increases were to be gradual, in return for increased gas transit fees and changing the method of payment for transit from payment in kind to cash. In May 2005, it was revealed that of gas which Gazprom had deposited in Ukrainian storage reservoirs during the previous winter had not been made available to the company. It remained unclear if the gas was missing, had disappeared due to technical problems, or had been stolen. This issue was resolved in July 2005 by agreement between Gazprom, Naftohaz and RosUkrEnergo, according to which Naftohaz received of gas as partial settlement of the Russian gas transit over 2005 services and was sold by Gazprom to RosUkrEnergo who has to receive it from Naftohaz. However, the negotiations between Gazprom and Naftohaz over gas prices and a new gas supply agreement failed. On 1 January 2006, Gazprom started reducing the pressure in the pipelines from Russia to Ukraine.\n\nAlthough Russia cut off supplies only to Ukraine, a number of European countries saw a drop in their supplies as well. The European Commissioner for Energy Andris Piebalgs and several affected member states warned that blocking of gas deliveries was unacceptable. Pascal Lamy, director general of the World Trade Organization, expressed the opinion that all Post-Soviet states should pay market prices for their energy needs in order to improve the efficiency of their economies.\n\nThe supply was restored on 4 January 2006, after the preliminary agreement between Ukraine and Gazprom was settled. The five-year contract was signed, although with prices set for only six months. According to the contract, the gas was sold not directly to Naftohaz, but to the intermediary Russian-Swiss company RosUkrEnergo. The price of natural gas sold by Gazprom to RosUkrEnergo rose to $230 per 1,000 cubic metres, which, after mixing it in a proportion of one-third Russian gas to two-thirds cheaper supplies from Central Asia, was resold to Ukraine at a price of $95 per 1,000 cubic metres. The parties also agreed to raise the tariff for transit from US$1.09 to US$1.60 per 1,000 cubic meters per 100 km; this applied not only to the transit of Russian gas to Europe, but also Turkmen gas through Russia to Ukraine. On 11 January 2006, Presidents Vladimir Putin and Viktor Yushchenko confirmed that the conflict had been concluded.\n\nOne possible reason for this conflict is the more pro-NATO and European Union-style approach of the new \"orange\" government of Ukraine. Russia disagreed, stating they did not want to subsidize former Soviet republics.\n\nOn 2 October 2007, Gazprom threatened to cut off gas supplies to Ukraine because of unpaid debt of $1.3 billion. This dispute appeared to be settled on 8 October 2007. On 5 January 2008, Gazprom warned Ukraine that it would reduce its gas supplies on 11 January if $1.5 billion in gas debts were not paid. Presidents Putin and Yushchenko announced on 12 February 2008, an agreement on the gas issue. Ukraine would begin paying off its debts for natural gas consumed in November–December 2007 and the price of $179.5 would be preserved in 2008. The presidents also decided to replace RosUkrEnergo and UkrGazEnergo with two new intermediaries, creating them as joint ventures of Gazprom and Naftogaz.\n\nAt the end of February 2008, Gazprom threatened to reduce the supply of natural gas to Ukraine beginning on 3 March 2008, unless the pre-payment for 2008 was paid. The Ukrainian government said it paid for the natural gas which was consumed in 2007, but refused to pay the bill for 2008. A Gazprom spokesman claimed that the bill for of gas deliveries to Ukraine valued around $600 million remained unpaid. Ukraine disagreed as that debt accumulated in recent months when Russia used its own gas to make up for a shortfall in less expensive Central Asian gas. On 3 March, Gazprom cut its shipments to Ukraine by 25% and an additional 25% the next day, claiming that the $1.5 billion debt still was not paid, although Ukrainian officials stated it had indeed been paid. Gas supplies were restored on 5 March after Gazprom CEO Alexei Miller and Naftohaz CEO Oleh Dubyna agreed during negotiations by phone on a settlement. On 6 March, the Ukrainian cabinet refused to execute the gas agreements made by presidents Yushchenko and Putin. The Ukrainian cabinet did not want to pay in advance for 2008, and it opposed the creation of a Naftohaz–Gazprom venture that would sell gas in Ukraine. Prime Minister Yulia Tymoshenko stated that Ukraine did not need any additional joint ventures, and as of 1 March 2008, UkrGazEnergo is no longer operating in Ukraine's domestic gas market.\n\nThe gas crisis of 2009 began with a failure to reach an agreement on gas prices and supplies for 2009. Ukraine owed a debt of $2.4 billion to Gazprom for gas already consumed, and Gazprom requested payment before the commencement of a new supply contract. In December 2008, despite Ukraine's repayment of more than $1 billion of its debt, Gazprom maintained its position, intending to cut the supply of natural gas to Ukraine on 1 January 2009, if Ukraine did not fully repay the remainder of $1.67 billion debt in natural gas supplies and an additional $450 million in fines levied by Gazprom. On 30 December, Naftohaz paid $1.522 billion, of the outstanding debt, but the two parties were not able to agree on the price for 2009. Ukraine proposed a price of $201, and later increased their proposed price to $235, while Gazprom demanded $250 per 1,000 cubic meters. Negotiations between Gazprom and Naftohaz were interrupted on 31 December.\n\nOn 1 January 2009, exports to Ukraine of 90 million cubic meters of natural gas per day were halted completely at 10:00 MSK. Exports intended for transhipment to the EU continued at a volume of 300 million cubic meters per day. President Yushchenko requested that the European Union become involved in the settlement of this dispute in a letter to the President of the European Commission Jose Manuel Barroso. A Ukrainian delegation including Fuel and Energy Minister Yuriy Prodan, Deputy Foreign Minister Konstantin Yeliseyev, the President's Representative for Energy Issues Bohdan Sokolovsky, and Deputy Head of Naftohaz Vadym Chuprun visited the Czech Republic as the first stop on a tour of a number EU member states to hold consultations on the gas crisis.\n\nOn 2 January 2009, Hungary, Romania, and Poland reported that pressure in their pipelines had dropped. Bulgaria also reported that their natural gas supply was dropping, affecting the shipment of natural gas to Turkey, Greece, and Macedonia. Furthermore, the United Kingdom Government announced that it was preparing to enter its gas reserves after gas pressure had dropped from the continent. On 4 January 2009, both RosUkrEnergo and Gazprom filed lawsuits against Ukraine and Naftohaz respectively with the Stockholm Tribunal of the Arbitration Institute. Ukraine also filed lawsuits with the tribunal. According to Naftohaz, RosUkrEnergo owes the company $40 million for services in transportation of natural gas. On 5 January 2009, Kiev's economic court banned Naftohaz from transshipping Russian natural gas in 2009 at the price of $1.60 per 1,600 cubic meters per 100 kilometers. The court declared contracts made by Naftohaz for the transit of natural gas through Ukraine void because the contracts were signed by Naftohaz without authorization from the Cabinet of Ministers of Ukraine. On 30 March 2010, the Stockholm tribunal ordered Naftohaz to pay RosUkrEnergo around $200 million as a penalty for various breaches of supply, transit, and storage contracts. On 8 June 2010, the tribunal ordered Naftohaz to return of natural gas to RosUkrEnergo. The tribunal further ordered that RosUkrEnergo would receive from Naftohaz a further of natural gas in lieu of RosUkrEnergo's damages for breach of contract.\n\nOn 5 January 2009 Russian Prime Minister Vladimir Putin instructed Gazprom CEO Alexei Miller to reduce natural gas exports to Europe via transshipment through Ukraine by quantities equivalent to the amounts of gas which Ukraine had allegedly diverted from the pipelines since deliveries ended on 1 January 2009. On 7 January, all Russian natural gas exports via Ukraine were halted amid accusations between the two parties. Several countries reported a major fall in supplies of Russian gas starting on 7 January; Bulgaria, Moldova, and Slovakia were among the most affected by these supply drops.\n\nTalks between Naftohaz and Gazprom resumed overnight on 8 January 2009. Ukraine agreed to guarantee the unfettered transport of natural gas on the condition that Gazprom would guarantee and supply technical gas for Ukraine's gas transit system to function; this was denied by Russia. The supplies to Europe were not restored although the European Union, Ukraine, and Russia agreed to the deployment of an international monitoring group to the gas metering stations between Russia and Ukraine. Naftohaz blocked the transit of gas, blaming a lack of pressure in the pipeline system and saying the design of the Soviet-built pipeline meant it could not ship gas entering through the Sudzha metering station governing gas leaving through the Orlivka metering station without cutting off the Donetsk region, Luhansk region, and portions of the Dnipropetrovsk region of Ukraine. Naftohaz suggested a technically more feasible alternative through the Valuyki and Pisarevka metering stations but was refused.\n\nOn 17 January 2009, Russia held an international gas conference in Moscow. The EU was represented by the Presidency, the Czech Minister of Industry and Trade Martin Říman, and the EU Energy Commissioner Andris Piebalgs, so that the European Union could speak with one voice. Ukraine was represented by the Prime Minister Yulia Tymoshenko. The conference did not achieve any solution to the crisis, and the negotiations continued bilaterally between Prime Ministers Putin and Tymoshenko. Early on 18 January 2009, after five hours of talks, Putin and Tymoshenko reached a deal to restore gas supplies to Europe and Ukraine. Both parties agreed that Ukraine would start paying European prices for its natural gas, less a 20% discount for 2009, and that Ukraine would pay the full European market price starting in 2010. In return for the discounts for 2009, Ukraine agreed to keep its transit fee for Russian gas unchanged in 2009. The two sides also agreed not to use intermediaries. On 19 January 2009, Gazprom CEO Alexei Miller and the head of Naftohaz Oleh Dubyna signed an agreement on natural gas supply to Ukraine for the period of 2009–2019. Gas supplies restarted on 20 January 2009, and were fully restored on 21 January.\n\nAccording to the EU Commission and Presidency, the Russia–Ukraine gas disputes caused irreparable and irreversible damage to customers' confidence in Russia and Ukraine, causing Russia and Ukraine to no longer be regarded as reliable partners. According to reports, due to the gas crisis Gazprom lost more than $1.1 billion in revenue for the unsupplied gas. Ukraine also incurred losses as a result of the temporary closure of its steel and chemical industries due to the lack of gas. Ukraine also lost $100 million of potential revenue in transit fees from natural gas.\n\nThere were also accusations of illegal diversion of natural gas by Ukraine; however, these accusations were not confirmed. The issue of technical gas used to fuel compressor stations and to maintain gas pressure in the pipeline network remained unclear. Some sources asserted that the responsibility for providing the technical gas falls to Ukraine, while others say that this is the responsibility of Gazprom.\n\nThere were several theories as to alleged political motives behind the gas disputes, including Russia exerting pressure on Ukrainian politicians or attempting to subvert EU and NATO expansions to include Ukraine. Others suggested that Ukraine's actions were being orchestrated by the United States. Both sides tried to win sympathy for their arguments fighting a PR war.\n\nIn August 2009, it was agreed that loans worth $1.7 billion would be given to Ukraine to help it provide stable supplies of Russian gas to Europe by the International Monetary Fund, the World Bank, and the European Bank for Reconstruction and Development, in return for reforms in Ukraine's gas sector.\n\nOn 28 December 2009, the Slovakian government announced that Russia warned it would stop oil supplies to Slovakia, Hungary, and the Czech Republic over a transit price dispute with Ukraine. However, the next day, Ukraine's Naftohaz issued a statement confirming that Russia agreed to a 30% increase in the transit fees through Ukraine. The alleged rise in the tariff would be from $7.8 to $9.50 (or €6.6) per tonne of oil going through Ukraine in 2010. Additionally, unlike previous payments, new payments would be made in Euros as this was one of Ukraine's demands. Russia and Ukraine also agreed on the volume of oil to be transported through Ukraine. The overall amount of oil to be transported to Slovakia, Czech Republic, and Hungary through Ukraine in 2010 will be 15 million tonnes—a decrease from 17.1 million tonnes in 2008.\n\nAfter meeting her Russian counterpart Putin, Ukrainian Prime Minister Tymoshenko declared on 3 September 2009, \"Both sides, Russia and Ukraine, have agreed that at Christmas, there won't be [any halt in gas supplies], as usually happens when there are crises in the gas sector. Everything will be quite calm on the basis of the current agreements\". Tymoshenko also said that the Ukrainian and Russian premiers had agreed that sanctions would not be imposed on Ukraine for the country buying less gas than expected and that the price of Russian gas transit across Ukraine may grow 65% till 70% in 2010. A week before Gazprom had said it expected gas transit fees via Ukraine to rise by up to 59% in 2010.\n\nOn 8 October 2009 Tymoshenko announced that Ukrainian 2010 natural gas imports will be significantly less than in previous years \"because we have less need for natural gas\". Because of its economic recession the industries require far less gas. In response to Tymoshenko Gazprom Chief Executive Alexey Miller stated that Ukraine should stick to the January (2009) contract for 2010.\n\nOn 16 November 2009 Commissioner for Energy at the European Commission Andris Piebalgs stated that Russia and the European Union do not expect another gas conflict with Ukraine. According to him there were no gas price negotiations or questions other than that of gas payments.\n\nOn 20 November 2009, the gas deal of 18 January 2009, was altered after a meeting between Tymoshenko and Putin in Yalta; meaning Ukraine would not be fined for buying less gas then the old contract stipulated, this was done in view of the 2008–2009 Ukrainian financial crisis. On 24 November 2009 Gazprom and Naftohaz signed these supplements to the contract of 19 January 2009 on the purchase and sale of natural gas; according to the supplements, the annual contracted amount of gas to be supplied to Ukraine in 2010 has been set at , instead of the contracted earlier. The documents signed by the sides also stipulated that there will be no fines related to the amount of gas consumed by Naftohaz in 2009. Over the first ten months of 2009 Naftohaz has purchased of gas with the contracted volume being .\n\nOn 15 December 2009, Russian Energy Minister Sergei Shmatko stated he expects no problems with Ukraine over gas supplies at New Year.\n\nUkrainian Prime Minister Mykola Azarov and Energy Minister Yuriy Boyko were in Moscow late March 2010 to negotiate lower gas prices; neither clearly explained what Ukraine was prepared to offer in return. Following these talks Russian Prime Minister Vladimir Putin stated that Russia was prepared to discuss the revision of the price for natural gas it sells to Ukraine.\n\nOn 21 April 2010, Russian President Dmitry Medvedev and Ukrainian President Viktor Yanukovych signed an agreement in which Russia agreed to a 30 percent drop in the price of natural gas sold to Ukraine. Russia agreed to this in exchange for permission to extend Russia's lease of a major naval base in the Ukrainian Black Sea port of Sevastopol for an additional 25 years with an additional five-year renewal option (to 2042-47). As of June 2010 Ukraine pays Gazprom around $234/mcm (thousand cubic meter).\n\nThis agreement was subject to approval by both the Russian and Ukrainian parliaments. They did ratify the agreement on 27 April 2010. The Ukrainian parliament ratified it after several eggs were thrown towards the speaker, Volodymyr Lytvyn, by deputies and other incidents. Opposition members in Ukraine and Russia expressed doubts the agreement would be fulfilled by the Ukrainian side.\n\nYanukovych has defended the agreement as a tool to help stabilise the state budget. Opposition members in Ukraine described the agreement as a sell out of national interests.\n\nIn February 2014, Ukraine's state-owned oil and gas company Naftogaz sued Chornomornaftogaz for delayed debt payments of 11.614 billion UAH (almost €1 billion) in the Economic Court of the Autonomous Republic of Crimea.\n\nIn March 2014, Republic of Crimea authorities announced that they would nationalize the company. Republic of Crimea deputy prime minister Rustam Temirgaliev said that Russia's Gazprom would be its new owner. A group of Gazprom representatives, including its head of business development, has been working at the Chornomornaftogaz head office since mid-March 2014. On April 1, Russia's energy minister Alexander Novak said that Gazprom would finance an undersea gas pipeline to Crimea.\n\nOn 11 April 2014 the U.S. Treasury's Office of Foreign Assets Control (OFAC) announced that it had added Chornomornaftagaz to the Specially Designated Nationals and Blocked Persons List as part of the third round of U.S. sanctions. Reuters quoted an anonymous U.S. official who explained that the United States wanted to make it impossible for Gazprom to \"have dealings with Chornomorneftegaz\", and if that were to happen, Gazprom itself could face sanctions.\n\nThe European Union followed suit on May 13, 2014, the first time its sanctions list has included a company (in addition to Chornomorneftegaz, a Crimean oil supplier called Feodosia was also included).\n\nIn an attempt at energy independence, Naftogaz signed a pipeline access deal with Slovakia's Eustream on April 28, 2014. Eustream and its Ukrainian counterpart Ukrtransgaz, owned by Naftogaz, agreed to allow Ukraine to use a never used (but aging, at 20 years old) pipeline on Slovakia's eastern border with Uzhhorod in western Ukraine. The deal would provide Ukraine with 3 billion cubic meters of natural gas beginning in autumn of 2014 with the aim of increasing that amount to 10 billion cubic meters in 2015.\n\nOn 1 April 2014 Gazprom cancelled Ukraine's natural gas discount as agreed in the 17 December 2013 Ukrainian–Russian action plan because its debt to the company had risen to $1.7 billion since 2013. Later that month the price “automatically” jumped to $485 per 1,000 cubic meters because the Russian government annulled an export-duty exemption for Gazprom in place since the 2010 Kharkiv Pact (this agreement was denounced by Russia on 31 March 2014). On 16 June 2014 Gazprom stated that Ukraine's debt to the company was $4.5 billion. On 30 May 2014 Ukraine paid $786 million to Gazprom.\n\nAfter intermediary (that had started in May 2014) trilateral talks between EU Energy Commissioner Günther Oettinger, Ukraine and Russia failed on 15 June 2014 the latter halted (after a deadline of 10 a.m. Moscow time passed without it receiving payment) its natural gas supplies to Ukraine the next day. Unilaterally Gazprom decided that Ukraine had to pay upfront for its natural gas. The company assured that its supplies to other European countries would continue. Ukraine vowed to \"provide reliable supply of gas to consumers in Ukraine and we will provide reliable transit to the European Union”. At the time about 15 percent of European Union's demand depended on Russian natural gas piped through Ukraine.\n\nAfter trilateral months of talks between the European Union, Ukraine and Russia a deal was reached on 30 October 2014 in which Ukraine agreed to pay (in advance) $378 per 1,000 cubic metres to the end of 2014, and $365 in the first quarter (ending on 31 March) of 2015. Of its debts to Gazprom Ukraine agreed to pay of $1.45bn immediately, and $1.65bn by the end of 2014. It was agreed that the European Union will be acting as guarantor for Ukraine's gas purchases from Russia and would help to meet outstanding debts (using funds from existing accords with the European Union and IMF). The total package was worth $4.6bn. According to European Union officials the deal secured that there would be no natural gas supply disruptions in other European countries.\n\nOn 25 November 2015 Gazprom halted its exports of Russian natural gas to Ukraine. According to the Ukrainian government they had stopped buying from Gazprom because Ukraine could buy natural gas cheaper from other suppliers. According to Gazprom it had halted deliveries because Ukraine had not paid them for the next delivery. Since then, Ukraine has been able to fulfil its gas supply needs solely from European Union states. In 2018 the Arbitration Institute of the Stockholm Chamber of Commerce ordered that Ukraine's Naftogaz should import 5 billion cubic meters of gas annually from Russia, as required under its 2009 contract with Russia’s Gazprom.\n\nPolitical pressure from Russia to Ukraine led to the emergence of a public campaign to boycott Russian goods in Ukraine during the gas conflict of 2005–2006. Active actions in the campaign also continued in early 2009—during the gas war of 2008–2009.\n\n\n"}
{"id": "17966625", "url": "https://en.wikipedia.org/wiki?curid=17966625", "title": "Spring soup", "text": "Spring soup\n\nSpring soup is a soup made with ingredients that are only in season for a short period during spring. Although asparagus largely characterizes spring soup, spring soup may include just about any spring vegetable added to a broth, chowder, or bisque. Spring soup is popular largely because it includes fresh ingredients not seen for a while by the consumer.\n\nWhere winter soups are hearty to \"warm and fortify\", spring soups aim to celebrate \"new skies and freshness\" by being \"delicate and light, pretty and promising.\" Spring soups need lighter, brighter tastes and textures than their winter counterparts. A reason for this is that spring soups \"capture the essence of the season in a clean-tasting, refreshing broth that showcases the pure flavors\" of its ingredients.\n\nIngredients used in spring soup include a purée of pea, asparagus, rapini, and fennel, with asparagus being considered the quintessential spring vegetable to largely characterize spring soup. Spring soups typically show a subtle green color to reflect spring.\n\nIn 1828, \"The British Almanac\" provided housekeepers' information to add spring soup to a July menu. In 1896, the Holland Society of New York published a spring soup recipe that included amontillado, olives, almonds, chicken, and radishes. In 1898, spring soup was defined as a soup having a stock with any spring vegetables added that have first been parboiled in water, with the soup often colored with caramel.\n\n\n\n"}
{"id": "11162590", "url": "https://en.wikipedia.org/wiki?curid=11162590", "title": "Subnivean climate", "text": "Subnivean climate\n\nSubnivean climate (From Latin for \"under\" (\"sub-\") and \"of snow\" (\"niveus\") and English -an. This is the environment of many hibernal animals, as it provides insulation and protection from predators. The subnivean climate is formed by three different types of snow metamorphosis: destructive metamorphosis, which begins when snow falls; constructive metamorphosis, the movement of water vapor to the surface of the snowpack; and melt metamorphosis, the melting/sublimation of snow to water vapor and its refreezing in the snowpack. These three types of metamorphosis transform individual snowflakes into ice crystals and create spaces under the snow where small animals can move.\n\nSubnivean fauna includes small mammals such as mice, voles, shrews, and lemmings that must rely on winter snow cover for survival. These mammals move under the snow for protection from heat loss and some predators. In winter regions that do not have permafrost, the subnivean zone maintains a temperature of close to 32°F (0°C) regardless of the temperature above the snow cover, once the snow cover has reached a depth of six inches (15 cm) or more. The sinuous tunnels left by these small mammals can be seen from above when the snow melts to the final inch or so.\n\nSome winter predators, such as foxes and large owls, can hear their prey through the snow and pounce from above. Ermine (stoats) can enter and hunt below the snowpack. Snowmobiles and ATVs can collapse the subnivean space. Skis and snow shoes are less likely to collapse subnivean space if the snowpack is deep enough.\n\nLarger animals also use subnivean space. In the Arctic, ringed seals have closed spaces under the snow and above openings in the ice. In addition to resting and sleeping there, the female seals give birth to their pups on the ice. Female polar bears also den in snow caves to give birth to their young. Both types of dens are protected from exterior temperatures. Formation of these large spaces is from the animals' activity, not ground heat.\n\nDeconstructive metamorphosis begins as the snow makes its way to the ground, often melting, refreezing, and settling. Water molecules become reordered, causing the snowflakes to become more spherical in appearance. These melting snowflakes fuse with others around them, becoming larger until all are uniform in size. While the snow is on the ground, the melting and joining of snow flakes reduces the height of snowpack by shrinking air spaces, causing the density and mechanical strength of the snowpack to increase. Freshly fallen snow with a density of 0.1 g/cm has very good insulating properties; however as time goes on, due to destructive metamorphism, the insulating property of the snowpack decreases, because the air spaces between snowflakes disappear. Snow that has been on the ground for a long period of time has an average density of 0.40 g/cm and conducts heat well; however, once a base of 50 cm of snow with a density around 0.3 g/cm has accumulated, temperatures under the snow remain relatively constant because the greater depth of snow compensates for its density. Destructive metamorphosis is a function of time, location, and weather. It occurs at a faster rate with higher temperatures, in the presence of water, under larger temperature gradients (e.g., warm days followed by cold nights), at lower elevations, and on slopes that receive large amounts of solar radiation. As time goes on, snow settles, compacting air spaces, a process expedited by the packing force of the wind.\n\nCompaction of snow reduces the penetration of long- and short-wave radiation by reflecting more radiation off the snow. This limitation of light transmission through the snowpack decreases light availability under the snow. Only 3% of light can penetrate to a depth of 20 cm of snow when the density is 0.21 g/cm. At a depth of 40 cm, less than 0.2% of light is transmitted from the snow surface to ground below. This decrease in light transmission occurs up to the point at which critical compaction is reached. This occurs because the surface area of the ice crystal decreases and it causes less refraction and scattering of light. Once densities reach 0.5 g/cm, total surface area is reduced, which in turn reduces internal refraction and allows light to penetrate deeper into the snowpack.\n\nConstructive metamorphosis is caused by the upward movement of water vapor within the snowpack. Warmer temperatures are found closer to the ground because it receives heat from the core of the earth. Snow has a low thermal conductivity, so this heat is retained, creating a temperature gradient between the air underneath the snowpack and the air above it. Warmer air holds more water vapor. Through the process of sublimation, the newly formed water vapor travels vertically by way of diffusion from a higher concentration (next to the ground) to a lower concentration (near the snowpack surface) by traveling through the air spaces between ice crystals. When the water vapor reaches the top of the snowpack, it is subjected to much colder air, causing it to condense and refreeze, forming ice crystals at the top of the snowpack that can be seen as the layer of crust on top of the snow.\n\nMelt metamorphism is the deterioration of snow by melting. Melting can be stimulated by warmer ambient temperatures, rain, and fog. As snow melts, water is formed and the force of gravity pulls these molecules downward. En route to the ground, they refreeze, thickening in the middle stratum. During this refreezing process, energy is released in the form of latent heat. As more water comes down from the surface, it creates more heat and brings the entire snowpack column to near equal temperature. The firnification of the snow strengthens the snowpack, due to the bonding of grains of snow. Snow around trees and under canopies melts faster due to the reradiation of long-wave radiation. As snow gets older, particles of impurities (pine needles, soil, and leaves, for example) accrue within the snow. These darkened objects absorb more short-wave radiation, causing them to rise in temperature, also reflecting more long-wave radiation.\n"}
{"id": "47734301", "url": "https://en.wikipedia.org/wiki?curid=47734301", "title": "Termination (geomorphology)", "text": "Termination (geomorphology)\n\nTermination, as used by Quaternary geologists, oceanographers, and paleoclimatologists is the period of time during a glacial cycle when there is a relatively rapid transition from full glacial climates to full interglacial climates. For the Quaternary period, terminations are numbered using Roman numerals from the most recent termination as “I” and with increasing value, e.g. “II”, “III”, and so forth, into the past. Termination I, also known as the Last Glacial Termination, is the end of Marine isotope stage 2; Termination II is the end of Marine Isotope Stage 6; Termination III is the end of Marine Isotope Stage 8; Termination IV is the end of Marine Isotope Stage 10, and so forth.\n\nDuring the Quaternary, global climate experienced a recurring pattern of ice-sheet growth and decay. The length of Late Quaternary cycles varied between 80,000 and 120,000 years, with an average recurrence interval of about 100,000 years. The typical Late Quaternary glacial cycle was asymmetric having a long cooling interval that was characterized by an oscillating buildup of ice sheets to maximum volume. The long cooling interval was then followed by a relatively short warming period. During this warming period, called a \"termination,\" huge Northern hemisphere ice sheets melted away; sea level rose about ; and interglacial climate emerged across the planet in a few thousand years. In case of the termination of the last glacial cycle, the retreat of continental ice sheets in the Northern hemisphere began about 20,000 calendar years ago. By about 7,000 calendar years ago, a small ice cap on Baffin Island was all that was left of the great Laurentide Ice Sheet that had once covered northern North America. In Antarctica, the last termination began about 18,000 years ago and interglacial climate was attained close to 11,000 years ago.\n"}
{"id": "46615027", "url": "https://en.wikipedia.org/wiki?curid=46615027", "title": "The Diamond Troupe", "text": "The Diamond Troupe\n\nThe Diamond Troupe was the concert party of the 29th Division, a First World War infantry division within the British Army. Also known as the \"Incomparable Division\", the 29th was formed in 1915 by combining units that had previously been acting as garrisons about the British Empire. The division fought throughout the Gallipoli Campaign and, from 1916 to the end of the war, on the Western Front in France.\n\nConcert parties were an integral element of the war effort; and by 1917, virtually every division had at least one. They mirrored the Pierrot troupes of music halls and seaside resorts, offering soldiers a respite from war, reminding them of home, and providing a neutral outlet to air grievances about \"food, conditions, and sergeants\". \n\nThe Diamond Troupe was one of a small number of concert parties to achieve considerable notoriety, both on the battlefield and at home. Its success was due to a combination of factors, not the least of which were the fame of the Division itself and the exceptional performances of many troupe members, especially by what historian Larry J Collins described as \"the show-stopper\": the female impersonator. The troupe's music director, Robert James Stannard, wrote in his diary that \"…the biggest hits were [Alec] Hill with his fine singing, Queenie [the troupe’s female impersonator], who deceived a great many of the audience and Larry Nicol, the trick cyclist…\"\n\nJason Wilson, in his history of the well-known Canadian concert party, the Dumbbells, singled out the Diamond Troupe as being one of the \"notable concert parties of the British Expedition Forces\" – an assessment presaged in the 1919 edition of \"The Stage\", where the Diamond Troupe, along with the Australian troupe, Anzac Coves, were praised for having earned their applause \"… by legitimate artistic means, and not on account of the increased wartime popularity of khaki or blue\".\n\nThe Diamond Troupe was formed in April 1917 in Arras, France where the 29th Division’s headquarters and various details were billeted. There, amidst ruins and the sound of distant shelling, the first voice trials took place. Out of 60 candidates drawn from every unit in the Division, eight were initially selected. Most if not all troupe members had had some previous experience in the performing arts; and all had served either in the trenches or within striking distance of enemy guns. One member, Pte. Neville Giordano (1892–1958) from Cambridge, had been part of the Division's historic landing on the Gallipoli Peninsula on 25 April 1915.\n\nThe name “Diamond Troupe” was inspired by the 29th Division’s logo, a red half-diamond, and by the tactical superiority of the diamond formation in a military advance.\n\nMaintaining a full cast was a persistent challenge for all concert troupes, given the movement of battalions and the ever-increasing casualty list. While there is no evidence of fatalities among members of the Diamond Troupe, contemporary photographs and published cast lists do suggest some variation in the group’s composition. The following table includes all individuals (musicians and stage performers) ever reported as troupe members:\nSupporting the stage performers were several \"stage hands\" whose responsibilities extended from lighting to costumes and carpentry. They included L/Cpl. Frank R. Williams (Scenic Artist), Privates J. Price, F. Ball and J. McKinnon (Electricians), Dr. Evans (Carpenter), Pte. W. Brinsley (Costumes), Pte. J. Ross (Engineer) and Pte. Wilson (Assistant). \n\nFinally, no account of the Diamond Troupe would be complete without acknowledging its commanding officer, Lt. Col. Ernest Trevor Langebear Wright, DSO (1880–1965). A veteran of the Gallipoli landing, Wright assumed command of the troupe in August 1917, following the departure of its former commander, Major John Graham Gillam (1884–1965). Wright was an exceptional leader who possessed authority, organizational skills and the respect of those who served under him. It was he who organized the troupe’s singular performance in London in January 1918, foregoing his home leave to supervise the event.\n\nWhile no complete listing exists of all the Diamond Troupe's performances, certainly the most comprehensive can be found in Capt. Stair Gillon’s \"The Story of the 29th Division. A record of gallant deeds\". His account, along with documentation now housed in public and private collections, reveals a busy schedule performed right across the Western Front—from Boulogne in the west, to Cambrai in the east. \n\nLike their counterparts in other divisions, the Diamond Troupe was supported financially by the 29th Division. As a result, the revenues from admission fees typically went to charities such as the Division’s Benevolent Fund, which supported the families of soldiers and non-commissioned officers either killed in action or disabled. At most public performances, such as those held in 1918 in Saint-Omer, audiences had their choice of open or reserved seats, with officers paying double the amount paid by other ranks.\nThe troupe’s most publicized performance took place during the week of 21–26 January 1918 at London's Royal Court Theatre. Entitled \"A Show from the Trenches\", the troupe showcased their efforts to \"alleviate the lot of the men in the trenches\" while also raising money for the Benevolent Fund. Accounts of the shows, both matinee and evening, were widely reported in the press, particularly the matinee of Thursday the 24th, which was attended by the Queen Mother Alexandra and her daughter, Princess Victoria. An amusing personal account of the event is contained in Stannard’s diary. In it, he reported that the Queen \"… sat in a box just opposite me … and although she sent a message after the show saying how greatly she had enjoyed it all she didn't appear to be enjoying herself a bit\".\n\nIn the end, the show was a great success, having netted the Benevolent Fund a profit of £750. Audiences included the rich and famous, including what one newspaper described as \"parties of stars”—renowned stage actresses, celebrities, and the wives of senior politicians and officers—who volunteered their time to sell programmes. According to the Daily Mail, many talent scouts were also to be seen. The theatre manager even asked the troupe to extend their contract by another week and the Ministry of Munitions requested that they be allowed to tour various munition centers. In both cases the War Office refused, arguing that the troupe was needed back with the division.\n\nThe London performances were representative of the troupe’s broader repertoire—an eclectic mixture of acrobatics, music and monologues, very much in line with the vaudeville performances of the time. The Royal Court Theatre programme highlighted a number of duets between the female impersonator, \"Queenie\" (played by William Threlfall), and troupe members Arthur Sykes, Alec Hill, and Jock McKinley. The program also included a trick cycling act by Larry Nicol; solo musical performances by Scottish comedian Frank Pollard; and several theatrical sketches and monologues by Neville Giordano.\n\nMuch of the troupe's musical repertoire included well-known, contemporary compositions such as W.T. Wrighton’s \"Sing me an English Song\", Philip Braham’s \"We’ll have a Little Cottage\" (1917), Weatherly and Wood’s \"Roses of Picardy\" (1916), Thomas J. Hewitt’s \"Alone in Love’s Garden\" (1912), and Davy Burnaby and Gitz Rice's \"A Conscientious Objector\" (1917). \n\nThe repertoire also included original productions—designed, written and in some cases composed for the troupe itself. The troupe’s first commanding officer, Major John Graham Gillam, excelled at producing operatic scenes, many of which (such as \"Faust\") Hill and Sykes would routinely play to great acclaim. Another key contributor to the troupe’s repertoire was officer Lancelot Cayley Shadwell, ASC, (1882–1963) who Gillon described as a “lyrical bard … [able to] supply the light, topical, frivolous comic matter, so dear to the average Briton”. Typical of this genre were two songs, \"In these Hard Times\" and \"365 Days\". Shadwell also set to music by Robert James Stannard, the \"Harlequin and Columbine\" scene, which Gillon described as “… probably the most finished production of the troupe”.\n\nIn 1917, Lancelot Cayley Shadwell wrote the lyrics to what would become the Divisional anthem, the \"Song of the 29th Division\". It is sung to music by Wilfred Ernest Sanderson (1878–1935) a composer, organist and, in all likelihood, associate of the troupe's music director, Robert Stannard. During the war, performances of the \"Song of the 29th Division\" were sung exclusively by baritone Alec [Alexander] Hill.\n\nThe wartime journalist and author, Sir Philip Armand Hamilton Gibbs, described the stirring effect the song had on those in the Division. There was, he said, “… a hush when the song was sung, for it brought back to some of the men who heard it the days of the battle in the Dardanelles and in the fields of the Somme or the quagmire of Flanders where the ghosts of brave comrades were.”\n\nThough all but forgotten today, the \"Song of the 29th Division\" was once a recognized tune, often performed at events honoring those who had served with the Division. In 1943, for example, the song was played at the funeral of Col. Robert Quentin Craufurd who served with the Royal Scots Fusiliers on the Western Front from 1914 to 1919.\nLyrics to the Song of the 29th Division\n\n<poem>\nFrom the Border vales and the Northern dales,\nFrom the rolling wave-beat coast,\nFrom South to North the lads stream forth,\nOh! we are the Army's boast!\nAnd where there's a bitter fight to wage\nOn a field all rent and gory,\nThe whole world knows there the Red Sign goes,\nWell famed in Britain's story.\n\n\"Oh, this is the Song of the Twenty-Ninth\"\n\"In the East and the West you'll find it;\"\n\"There's never a fight where the Red Sign goes\"\n\"But it leaves its mark behind it.\"\n</poem>\n<poem>\nIn desert sands of alien lands\nSleep our bravest and our best;\nThere's a Turkish hill where the flowers wave still\nO'er the graves where our dear lads rest.\nAnd wherever the red war trail's agleam,\nAnd the battle thunders waken,\nThere's a tale to be told of a soul of gold\nWho trod Death's path unshaken.\n\n\"Oh, this is the Song of the Twenty-Ninth\n\"In the East and the West you'll find it;\"\n\"There's never a fight where the Red Sign goes\"\n\"But it leaves its mark behind it.\"\n</poem>\n<poem>\nWith a roll of drum the Divisions come\nHot foot to the battle's blast;\nWhen the good Red Sign swings into the line\nOh! There they'll fight to the last!\nAnd the souls of those from the East and West,\nWell famed in Britain's story,\nMarch at our head with silent tread\nTo Honour and to Glory.\n\n\"Oh, this is the Song of the Twenty-Ninth,\"\n\"On every field you'll find it;\"\n\"For wherever the Red Triangle went\"\n\"It left its mark behind it.\"\n\nLancelot Cayley Shadwell (1882–1963)</poem>\n\nAfter the Armistice, the 29th Division was one of several divisions chosen to march into Germany to occupy the Rhine bridgehead. In January 1919, soldiers with more than two years of foreign service were given permission to take leave and apply for demobilization at their regimental depots. In his diary, Stannard noted that he and nine other members of the troupe were among the first to do so. They were soon followed by the others, although one or two, such as Queenie, remained in Germany to be absorbed into the few remaining concert troupes. By March, however, demobilization was in full swing and most units of the 29th were down to just a few officers.\n\nThe Diamond Troupe was typical of many concert parties in that its members, even before the war, had been active in the performing arts as singers, actors, or musicians. Not surprisingly, after returning to civilian life, many chose to pursue their artistic vocations—some full-time, some as an adjunct to more stable day jobs.\n\nThe troupe’s musical director, Robert J. Stannard, who as a boy attended Westminster Abbey Choir School and sang at the 1902 coronation of King Edward VII, returned to Uxbridge and his career as an organist. In 1940, he moved to Frome in Somerset where he was appointed organist and choir master for St John's Church and head of music at the Frome Grammar School for Boys and Girls.\n\nIn July 1919 William Threlfall (Queenie) returned to Liverpool where he found work as a pianist with various dance bands. He played in gigs as far afield as the Isle of Man and Saarbrucken with groups such as the Estrella Quartette, Sam Lawson’s “Elite” Orchestra, and Jack Briggs and his Band. In 1926, Threlfall went to sea as a band musician—a career that would see him sail on many of the great White Star and Cunard transatlantic liners, from the RMS Baltic to the RMS Mauretania to eventually the RMS Aquitania. Ship manifests show him almost constantly at sea, with stops in Liverpool, Glasgow, Southampton, Boston, New York, Havana, and occasionally the Mediterranean. In 1938, ill health saw Threlfall return to Southampton. After a few months, he returned briefly to sea; but ultimately ceased travelling in February 1939. In 1940, at age 44, he died suddenly of a gastric ulcer.\n\nAlec [Alexander] Hill, who performed in operas and operettas before the war, returned in 1919 to his home in Bolton, Lancashire. While his workdays were spent behind a desk, he sang professionally at weekends and evenings, well into the 1950s. With the support of his pianist wife, Margaret Eliza (née) Urmson, he continued performing Faust at the 1927 Blackpool Musical Festival, the 1934 Gounod's Grand Opera at Victoria Hall, Bolton and at Queen's Hall, Wigan in 1953. He performed at the Rothesay Pavilion in Bute, the Haddon Hall Hydro, Buxton, the Odeon in Llandudno and numerous other venues across Britain.\n\nGlasgow-born Larry [Lawrence] Nicol adopted the stage name, Larry Kemble, and embarked on an active stage career as a comedic cyclist. In 1919, he married into a well-known theatrical family, the Loydalls, and for the next 30 years, performed at the Bristol Hippodrome, London Coliseum (for the 1928 Royal Variety Performance), Glasgow’s Alhambra and Empire Theatres, and the Stoll Theatre, Kingsway, among others. In 1940, Nicol was filmed in London, doing tricks on a very tall unicycle. See the full video on British Pathe.\n\nNeville Giordano, the troupe’s only member to have participated in the initial Gallipoli landing, returned to acting under a stage name, Neville Gordon. In February 1920, the Cambridge Daily News praised his role as Lord Fancourt Babberley in \"Charley’s Aunt\"; and spoke highly of his recent successes in Stanley Houghton's (1881–1913) \"Hindle Wakes\" and \"The Younger Generation\". By 1920, he was also filling engagements with the F.R. Benson Shakespearian Company.\n\nFinally, Yorkshire-born Arthur Sykes returned to his home in Carlisle, Cumbria, where, for the next 40 years, he held the post of principal tenor at Carlisle Cathedral. During World War II, he, along with Kathleen Ferrier, Ena Mitchel and Albert Bettany formed a quartet that played to hospitals and camps across Scotland, the Midlands and North East. At Sykes' funeral in 1961, the Dean of Carlisle Cathedral praised him as “… a man who used an outstanding voice to the end of his life for the glory of God and to the service of his fellow men….”\n\nGiven the Diamond Troupe’s reputation and success, it is all too easy to forget that as a performing unit, they existed for less than two years: from their first show under a “fine canvas theatre” in Proven in August/September 1917 to their last performance as victors in Wermelskirchen, Germany in December 1918. And then, as Gillon wrote, “the Diamond Troupe thus stole silently away…” It is not known how often troupe members kept in touch with one another after the war nor to what extent they were called upon to join in activities associated with the 29th Division. \n\nIn 1921, the Division Association spearheaded an effort to keep servicemen in touch with their regimental associations. Their approach called for sending out small cards every month, each containing a calendar and a poem relating to the history of the Division. In February 1921, the card included Lancelot Cayley Shadwell’s lyrics to the \"Song of the 29th Division\". It is not known how long this practice was maintained.\n\nOn 25 April 1929—the fourteenth anniversary of the Gallipoli landing—the 29th Division Association held its twenty-first annual dinner at London’s Café Royal. There, Hill, Stannard, Palmer and Holmes were reunited to perform the \"Song of the 29th Division\". A newspaper report at the time described the event as a:\n\n... remarkable gathering of distinguished sailors and soldiers… [whose most] inspiring moment came when Mr. Alec Hill sang the song of the 29th Division. He used to sing it out there in the war days, and [it] … has never, perhaps, been cherished by so many war leaders. Earl Jellicoe, Admiral Sir Roger Keyes, General Sir Ian Hamilton, and General Sir Aylmer Hunter Weston, among others at the top table, sang it with the infectious enthusiasm of youth.\n\n"}
{"id": "2465250", "url": "https://en.wikipedia.org/wiki?curid=2465250", "title": "Thermal energy storage", "text": "Thermal energy storage\n\nThermal energy storage (TES) is achieved with widely differing technologies. Depending on the specific technology, it allows excess thermal energy to be stored and used hours, days, or months later, at scales ranging from individual process, building, multiuser-building, district, town, or region. Usage examples are the balancing of energy demand between daytime and nighttime, storing summer heat for winter heating, or winter cold for summer air conditioning (Seasonal thermal energy storage). Storage media include water or ice-slush tanks, masses of native earth or bedrock accessed with heat exchangers by means of boreholes, deep aquifers contained between impermeable strata; shallow, lined pits filled with gravel and water and insulated at the top, as well as eutectic solutions and phase-change materials.\n\nOther sources of thermal energy for storage include heat or cold produced with heat pumps from off-peak, lower cost electric power, a practice called peak shaving; heat from combined heat and power (CHP) power plants; heat produced by renewable electrical energy that exceeds grid demand and waste heat from industrial processes. Heat storage, both seasonal and short term, is considered an important means for cheaply balancing high shares of variable renewable electricity production and integration of electricity and heating sectors in energy systems almost or completely fed by renewable energy.\n\nMost practical active solar heating systems provide storage from a few hours to a day's worth of energy collected. However, there are a growing number of facilities that use seasonal thermal energy storage (STES), enabling solar energy to be stored in summer for space heating use during winter. The Drake Landing Solar Community in Alberta, Canada, has now achieved a year-round 97% solar heating fraction, a world record made possible only by incorporating STES.\n\nThe use of both latent heat and sensible heat are also possible with high temperature solar thermal input. Various eutectic mixtures of metals, such as Aluminium and Silicon (AlSi12) offer a high melting point suited to efficient steam generation, while high alumina cement-based materials offer good thermal storage capabilities.\n\nSensible heat of molten salt is also used for storing solar energy at a high temperature. Molten salts can be employed as a thermal energy storage method to retain thermal energy. Presently, this is a commercially used technology to store the heat collected by concentrated solar power (e.g., from a solar tower or solar trough). The heat can later be converted into superheated steam to power conventional steam turbines and generate electricity in bad weather or at night. It was demonstrated in the Solar Two project from 1995-1999. Estimates in 2006 predicted an annual efficiency of 99%, a reference to the energy retained by storing heat before turning it into electricity, versus converting heat directly into electricity. Various eutectic mixtures of different salts are used (e.g., sodium nitrate, potassium nitrate and calcium nitrate). Experience with such systems exists in non-solar applications in the chemical and metals industries as a heat-transport fluid.\n\nThe salt melts at . It is kept liquid at in an insulated \"cold\" storage tank. The liquid salt is pumped through panels in a solar collector where the focused sun heats it to . It is then sent to a hot storage tank. With proper insulation of the tank the thermal energy can be usefully stored for up to a week. When electricity is needed, the hot molten-salt is pumped to a conventional steam-generator to produce superheated steam for driving a conventional turbine/generator set as used in any coal or oil or nuclear power plant. A 100-megawatt turbine would need a tank of about tall and in diameter to drive it for four hours by this design.\n\nSingle tank with divider plate to hold both cold and hot molten salt, is under development. It is more economical by achieving 100% more heat storage per unit volume over the dual tanks system as the molten-salt storage tank is costly due to its complicated construction. Phase Change Material (PCMs) are also used in molten-salt energy storage.\n\nSeveral parabolic trough power plants in Spain\nand solar power tower developer SolarReserve use this thermal energy storage concept. The Solana Generating Station in the U.S. can store 6 hours worth of generating capacity in molten salt. During the summer of 2013 the Gemasolar Thermosolar solar power-tower/molten-salt plant in Spain achieved a first by continuously producing electricity 24 hours per day for 36 days.\n\nA steam accumulator consists of an insulated steel pressure tank containing hot water and steam under pressure. As a heat storage device, it is used to mediate heat production by a variable or steady source from a variable demand for heat. Steam accumulators may take on a significance for energy storage in solar thermal energy projects.\nLarge stores are widely used in Scandinavia to store heat for several days, to decouple heat and power production and to help meet peak demands. Interseasonal storage in caverns has been investigated and appears to be economical.\n\nWater has one of the highest thermal capacities Heat capacity - 4.2 J/(cm·K) whereas concrete has about one third of that. On the other hand, concrete can be heated to much higher temperatures – 1200 °C by e.g. electrical heating and therefore has a much higher overall volumetric capacity. Thus in the example below, an insulated cube of about 2.8 m would appear to provide sufficient storage for a single house to meet 50% of heating demand. This could, in principle, be used to store surplus wind or PV heat due to the ability of electrical heating to reach high temperatures. At the neighborhood level, the Wiggenhausen-Süd solar development at Friedrichshafen has received international attention. This features a 12,000 m (420,000 cu ft) reinforced concrete thermal store linked to 4,300 m² (46,000 sq ft) of solar collectors, which will supply the 570 houses with around 50% of their heating and hot water. Siemens builds a 36 MWh thermal storage near Hamburg with 600 °C basalt and 1.5 MW electric output. A similar system is scheduled for Sorø, Denmark, with 41-58% of the stored 18 MWh heat returned for the town's district heating, and 30-41% returned as electricity.\n\nMiscibility gap alloys rely on the phase change of a metallic material (see: latent heat) to store thermal energy.\n\nRather than pumping the liquid metal between tanks as in a molten-salt system, the metal is encapsulated in another metallic material that it cannot alloy with (immiscible). Depending on the two materials selected (the phase changing material and the encapsulating material) storage densities can be between 0.2 and 2 MJ/L.\n\nA working fluid, typically water or steam, is used to transfer the heat into and out of the MGA. Thermal conductivity of MGAs is often higher (up to 400 W/m K) than competing technologies which means quicker \"charge\" and \"discharge\" of the thermal storage is possible. The technology has not yet been implemented on a large scale.\n\nStorage heaters are commonplace in European homes with time-of-use metering (traditionally using cheaper electricity at night time). They consist of high-density ceramic bricks or feolite blocks heated to a high temperature with electricity, and may or may not have good insulation and controls to release heat over a number of hours.\n\nSeveral applications are being developed where ice is produced during off-peak periods and used for cooling at later time. For example, air conditioning can be provided more economically by using low-cost electricity at night to freeze water into ice, then using the cooling capacity of ice in the afternoon to reduce the electricity needed to handle air conditioning demands. Thermal energy storage using ice makes use of the large heat of fusion of water. Historically, ice was transported from mountains to cities for use as a coolant. One metric ton of water (= one cubic meter) can store 334 million joules (MJ) or 317,000 BTUs (93kWh). A relatively small storage facility can hold enough ice to cool a large building for a day or a week.\n\nIn addition to using ice in direct cooling applications, it is also being used in heat pump based heating systems. In these applications the phase change energy provides a very significant layer of thermal capacity that is near the bottom range of temperature that water source heat pumps can operate in. This allows the system to ride out the heaviest heating load conditions and extends the timeframe by which the source energy elements can contribute heat back into the system.\n\nThis uses liquification of air or nitrogen as an energy store.\n\nA pilot cryogenic energy system that uses liquid air as the energy store, and low-grade waste heat to drive the thermal re-expansion of the air, has been operating at a power station in Slough, UK since 2010.\n\nSolid or molten silicon offers much higher storage temperatures than salts with consequent greater capacity and efficiency. It is being researched as a possible more energy efficient storage technology. Silicon is able to store more than 1MWh of energy per cubic metre at 1400 °C.\n\nIn pumped-heat electricity storage (PHES), a reversible heat-pump system is used to store energy as a temperature difference between two heat stores.\n\nOne system which was being developed by the now bankrupt UK company Isentropic operates as follows. It comprises two insulated containers filled with crushed rock or gravel; a hot vessel storing thermal energy at high temperature and high pressure, and a cold vessel storing thermal energy at low temperature and low pressure. The vessels are connected at top and bottom by pipes and the whole system is filled with the inert gas argon.\n\nDuring the charging cycle the system uses off-peak electricity to work as a heat pump. Argon at ambient temperature and pressure from the top of the cold store is compressed adiabatically to a pressure of 12 bar, heating it to around . The compressed gas is transferred to the top of the hot vessel where it percolates down through the gravel, transferring its heat to the rock and cooling to ambient temperature. The cooled, but still pressurized, gas emerging at the bottom of the vessel is then expanded (again adiabatically) back down to 1 bar, which lowers its temperature to -150 °C. The cold gas is then passed up through the cold vessel where it cools the rock while being warmed back to its initial condition.\n\nThe energy is recovered as electricity by reversing the cycle. The hot gas from the hot vessel is expanded to drive a generator and then supplied to the cold store. The cooled gas retrieved from the bottom of the cold store is compressed which heats the gas to ambient temperature. The gas is then transferred to the bottom of the hot vessel to be reheated.\n\nThe compression and expansion processes are provided by a specially designed reciprocating machine using sliding valves. Surplus heat generated by inefficiencies in the process is shed to the environment through heat exchangers during the discharging cycle.\n\nThe developer claims that a round trip efficiency of 72-80% is achievable. This compares to >80% achievable with pumped hydro energy storage.\n\nAnother proposed system uses turbomachinery and is capable of operating at much higher power levels. Use of Phase Change Material (PCMs) as heat storage material would enhance the performance further.\n\nOne example of an experimental storage system based on chemical reaction energy is the salt hydrate technology. The system uses the reaction energy created when salts are hydrated or dehydrated. It works by storing heat in a container containing 50% sodium hydroxide (NaOH) solution. Heat (e.g. from using a solar collector) is stored by evaporating the water in an endothermic reaction. When water is added again, heat is released in an exothermic reaction at 50 °C (120 °F). Current systems operate at 60% efficiency. The system is especially advantageous for seasonal thermal energy storage, because the dried salt can be stored at room temperature for prolonged times, without energy loss. The containers with the dehydrated salt can even be transported to a different location. The system has a higher energy density than heat stored in water and the capacity of the system can be designed to store energy from a few months to years.\n\nIn 2013 the Dutch technology developer TNO presented the results of the MERITS project to store heat in a salt container. The heat, which can be derived from a solar collector on a rooftop, expels the water contained in the salt. When the water is added again, the heat is released, with almost no energy losses. A container with a few cubic meters of salt could store enough of this thermochemical energy to heat a house throughout the winter. In a temperate climate like that of the Netherlands, an average low-energy household requires about 6.7 GJ/winter. To store this energy in water (at a temperature difference of 70 °C), 23 m insulated water storage would be needed, exceeding the storage abilities of most households. Using salt hydrate technology with a storage density of about 1 GJ/m, 4–8 m could be sufficient.\n\nAs of 2016, researchers in several countries are conducting experiments to determine the best type of salt, or salt mixture. Low pressure within the container seems favourable for the energy transport. Especially promising are organic salts, so called ionic liquids. Compared to lithium halide based sorbents they are less problematic in terms of limited global resources, and compared to most other halides and sodium hydroxide (NaOH) they are less corrosive and not negatively affected by CO contaminations.\n\nStoring energy in molecular bonds is being investigated. Energy densities equivalent to lithium-ion batteries have been achieved.\n\n\n"}
{"id": "5833630", "url": "https://en.wikipedia.org/wiki?curid=5833630", "title": "Transport Phenomena (book)", "text": "Transport Phenomena (book)\n\nTransport Phenomena is the first textbook about transport phenomena. It is specifically designed for chemical engineering students. The first edition was published in 1960, two years after having been preliminarily published under the title \"Notes on Transport Phenomena\" based on mimeographed notes prepared for a chemical engineering course taught at the University of Wisconsin–Madison during the academic year 1957-1958. The second edition was published in August 2001. A \"revised\" second edition was published in 2007. This text is often known simply as \"BSL\" after its authors' initials.\n\nAs the chemical engineering profession developed in the first half of the 20th century, the concept of \"unit operations\" arose as being needed in the education of undergraduate chemical engineers. The theories of mass, momentum and energy transfer were being taught at that time only to the extent necessary for a narrow range of applications. As chemical engineers began moving into a number of new areas, problem definitions and solutions required a deeper knowledge of the fundamentals of transport phenomena than those provided in the textbooks then available on unit operations.\n\nIn the 1950s, R. Byron Bird, Warren E. Stewart and Edwin N. Lightfoot stepped forward to develop an undergraduate course at the University of Wisconsin–Madison to integrate the teaching of fluid flow, heat transfer, and diffusion. From this beginning, they prepared their landmark textbook \"Transport Phenomena\".\n\nThe book is divided into three basic sections, named Momentum Transport, Energy Transport and Mass Transport:\n\n\n\"Transport Phenomena\" contains many instances of hidden messages and other word play.\nFor example, the first letters of each sentence of the Preface spell out \"This book is dedicated to O. A. Hougen.\" while in the revised second edition, the first letters of each paragraph spell out \"Welcome\". The first letters of each paragraph in the Postface spell out \"On Wisconsin\". In the first printing, in Fig. 9.L (p. 305) \"Bird\" is typeset safely outside the furnace wall.\n\nAccording to many chemical engineering professors, the first edition is much better than the second edition. There are many reasons in this regard; The second edition has been revised many times despite the fact that there are still many defects and typographical errors in many parts of the book. On account of revision to defects of the revised second edition book, the authors published \"Notes for the 2nd revised edition of TRANSPORT PHENOMENA\" on 9 Aug 2011.\n\n\n"}
