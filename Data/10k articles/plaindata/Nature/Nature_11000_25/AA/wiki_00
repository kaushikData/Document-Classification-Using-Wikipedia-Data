{"id": "11850386", "url": "https://en.wikipedia.org/wiki?curid=11850386", "title": "Acoustical oceanography", "text": "Acoustical oceanography\n\nAcoustical oceanography is the use of underwater sound to study the sea, its boundaries and its contents.\n\nThe earliest efforts at bathymetry, or study of the contours of the ocean's floor, were made by the ancient Greeks in the Mediterranean. They made a depth sounding by lowering a rope with a stone tied to the end over the side of a ship, until it hit bottom. The process was very time consuming, and not always accurate.\n\nInterest in developing echo ranging systems began in earnest following the sinking of the RMS Titanic in 1912. By sending a sound wave ahead of a ship, the theory went, a return echo bouncing off the submerged portion of an iceberg should give early warning of collisions. By directing the same type of beam downwards, the depth to the bottom of the ocean could be calculated.\n\nThe first practical deep-ocean echo sounder was invented by Harvey C. Hayes, a U.S. Navy physicist. For the first time, it was possible to create a quasi-continuous profile of the ocean floor along the course of a ship. The first such profile was made by Hayes on board the U.S.S. Stewart, a Navy destroyer that sailed from Newport to Gibraltar between June 22 and 29, 1922. During that week, 900 deep-ocean soundings were made.\n\nUsing a refined echo sounder, the German survey ship Meteor made several passes across the South Atlantic from the equator to Antarctica between 1925 and 1927, taking soundings every 5 to 20 miles. Their work created the first detailed map of the Mid-Atlantic Ridge. It showed that the Ridge was a rugged mountain range, and not the smooth plateau that some scientists had envisioned. Since that time, both naval and research vessels have operated echo sounders almost continuously while at sea.\nImportant contributions to acoustical oceanography have been made by:\n\nThe earliest and most widespread use of sound and sonar technology to study the properties of the sea is the use of an rainbow echo sounder to measure water depth. Sounders were the devices used that mapped the many miles of the Santa Barbara Harbor ocean floor until 1993.\n\nFathometers measure the depth of the waters. It works by electronically sending sounds from ships, therefore also receiving the sound waves that bounces back from the bottom of the ocean. A paper chart moves through the fathometer and is calibrated to record the depth.\n\nAs technology advances, the development of high resolution sonars in the second half of the 20th century made it possible to not just detect underwater objects but to classify them and even image them. Electronic sensors are now attached to ROVs since nowadays, ships or robot submarines have Remotely Operated Vehicles (ROVs). There are cameras attached to these devices giving out accurate images. The oceanographers are able to get a clear and precise quality of pictures. The 'pictures' can also be sent from sonars by having sound reflected off ocean surroundings. Oftentimes sound waves reflect off animals, giving information which can be documented into deeper animal behaviour studies.\n\nSee Clay and Medwin.\n\nSee Clay and Medwin.\n\nApplications of acoustical oceanography include:\n\nThe study of marine life, from microplankton to the blue whale, uses bioacoustics.\n\n"}
{"id": "821914", "url": "https://en.wikipedia.org/wiki?curid=821914", "title": "Alcide d'Orbigny", "text": "Alcide d'Orbigny\n\nAlcide Charles Victor Marie Dessalines d'Orbigny (6 September 1802 – 30 June 1857) was a French naturalist who made major contributions in many areas, including zoology (including malacology), palaeontology, geology, archaeology and anthropology.\n\nD'Orbigny was born in Couëron (Loire-Atlantique), the son of a ship's physician and amateur naturalist. The family moved to La Rochelle in 1820, where his interest in natural history was developed while studying the marine fauna and especially the microscopic creatures that he named \"foraminiferans\".\n\nIn Paris he became a disciple of the geologist Pierre Louis Antoine Cordier (1777–1861) and Georges Cuvier. All his life, he would follow the theory of Cuvier and stay opposed to Lamarckism.\n\nD'Orbigny travelled on a mission for the Paris Museum, in South America between 1826 and 1833. He visited Brazil, Argentina, Paraguay, Chile, Bolivia, Peru, Ecuador and Colombia and returned to France with an enormous collection of more than 10,000 natural history specimens. He described part of his findings in \"La Relation du Voyage dans l'Amérique Méridionale pendant les annés 1826 à 1833\" (Paris, 1824–47, in 90 fascicles). The other specimens were described by zoologists at the museum.\n\nHis contemporary, Charles Darwin, arrived in South America in 1832, and on hearing that he had been preceded, grumbled that D'Orbigny had probably collected \"the cream of all the good things\". Darwin later called D'Orbigny's Voyage a \"most important work\". They went on to correspond, with D'Orbigny describing some of Darwin's specimens.\n\nHe was awarded the Gold Medal of the Société de Géographie of Paris in 1834. The South American Paleocene pantodont \"Alcidedorbignya\" was named in his honour.\n\nIn 1840, d'Orbigny started the methodical description of French fossils and published \"La Paléontologie Française\" (8 vols). In 1849 he published a closely related \"Prodrome de Paléontologie Stratigraphique\", intended as a \"Preface to Stratigraphic Palaeontology\", in which he described almost 18,000 species, and with biostratigraphical comparisons erected geological stages, the definitions of which rest on their stratotypes.\n\nIn 1853 he became professor of palaeontology at the Paris Muséum National d'Histoire Naturelle, publishing his \"Cours élémentaire\" that related paleontology to zoology, as a science independent of the uses made of it in stratigraphy. The chair of paleontology was created especially in his honor. The d'Orbigny collection is housed in the \"Salle d'Orbigny\" and is often visited by experts.\n\nHe described the geological timescales and defined numerous geological strata, still used today as chronostratigraphic reference such as Toarcian, Callovian, Oxfordian, Kimmeridgian, Aptian, Albian and Cenomanian. He died in the small town of Pierrefitte-sur-Seine, near Paris.\n\nD'Orbigny a disciple of Georges Cuvier was a notable advocate of catastrophism. \n\nHe recognized twenty-seven catastrophes in the fossil record. This became known as the \"doctrine of successive creations\". He attempted to reconcile the fossil record with the Genesis creation narrative. Both uniformitarian geologists and theologians rejected his idea of successive creations. \n\nPalaeontologist Carroll Lane Fenton has noted that his idea of twenty-seven world-wide creations was \"absurd\", even for creationists. L. Sprague de Camp has written that \"Alcide d'Orbigny, carried the idea to absurdity. Dragging in the supernatural, d'Orbigny argued that, on twenty-seven separate occasions, God had wiped out all life on earth and started over with a whole new creation.\"\n\nSeveral zoological and botanical taxa were named in his honor, including the following genera and species.\n\nIn the above list, a taxon author or binomial authority in parentheses indicates that the species was originally described in a genus other than the genus to which the species is currently assigned.\n\nLa Gazette des Français du Paraguay, Alcide d'Orbigny – Voyageur Naturaliste pour le Muséum d'Histoire Naturelle dans le Cone Sud – Alcide d'Orbigny – Viajero Naturalista para el Museo Nacional de Historia Natural de Francia en el Cono Sur – Bilingue Français Espagnol – numéro 7, année 1, Asuncion Paraguay.\n\n\n"}
{"id": "6109333", "url": "https://en.wikipedia.org/wiki?curid=6109333", "title": "Andreev reflection", "text": "Andreev reflection\n\nAndreev reflection (AR), named after the Russian physicist Alexander F. Andreev, is a type of particle scattering which\noccurs at interfaces between a superconductor (S) and a normal state material (N). It is a charge-transfer process by which normal current in N is converted to supercurrent in S. Each Andreev reflection transfers a charge \"2e\" across the interface, avoiding the forbidden single-particle transmission within the superconducting energy gap.\n\nThe process involves an electron (hole) incident on the interface from the normal state material at energies less than the superconducting energy gap. The incident electron (hole) forms a Cooper pair in the superconductor with the retroreflection of a hole (electron) of opposite spin and velocity but equal momentum to the incident electron (hole), as seen in the figure. The barrier transparency is assumed to be high, with no oxide or tunnel layer which reduces instances of normal electron-electron or hole-hole scattering at the interface. Since the pair consists of an up and down spin electron, a second electron (hole) of opposite spin to the incident electron (hole) from the normal state forms the pair in the superconductor, and hence the retroreflected hole (electron). Through time-reversal symmetry, the process with an incident electron will also work with an incident hole (and retroreflected electron).\n\nThe process is highly spin-dependent – if only one spin band is occupied by the conduction electrons in the normal-state material (\"i.e.\" it is fully spin-polarized), Andreev reflection will be inhibited due to inability to form a pair in the superconductor and impossibility of single-particle transmission. In a ferromagnet or material where spin-polarization exists or may be induced by a magnetic field, the strength of the Andreev reflection (and hence conductance of the junction) is a function of the spin-polarization in the normal state.\n\nThe spin-dependence of AR gives rise to the Point Contact Andreev Reflection (or PCAR) technique, whereby a narrow superconducting tip (often niobium, antimony or lead) is placed into contact with a normal material at temperatures below the critical temperature of the tip. By applying a voltage to the tip, and measuring differential conductance between it and the sample, the spin polarization of the normal metal at that point (and magnetic field) may be determined. This is of use in such tasks as measurement of spin-polarized currents or characterizing spin polarization of material layers or bulk samples, and the effects of magnetic fields on such properties.\n\nIn an AR process, the phase difference between the electron and hole is −π/2 plus the phase of the superconducting order parameter.\n\nCrossed Andreev reflection, or CAR, also known as non-local Andreev reflection occurs when two spatially separated normal state material electrodes form two separate junctions with a superconductor, with the junction separation of the order of the BCS superconducting coherence length of the material in question. In such a device, retroreflection of the hole from an Andreev reflection process, resulting from an incident electron at energies less than the superconducting gap at one lead, occurs in the second spatially separated normal lead with the same charge transfer as in a normal AR process to a Cooper pair in the superconductor. For CAR to occur, electrons of opposite spin must exist at each normal electrode (so as to form the pair in the superconductor). If the normal material is a ferromagnet this may be guaranteed by creating opposite spin polarization via the application of a magnetic field to normal electrodes of differing coercivity.\n\nCAR occurs in competition with elastic cotunelling or EC, the quantum mechanical tunneling of electrons between the normal leads via an intermediate state in the superconductor. This process conserves electron spin. As such, a detectable CAR potential at one electrode on the application of current to the other may be masked by the competing EC process, making clear detection difficult. In addition, normal Andreev reflection may occur at either interface, in conjunction with other normal electron scattering processes from the normal/superconductor interface.\n\nThe process is of interest in the formation of solid-state quantum entanglement, via the formation of a spatially separated entangled electron-hole (Andreev) pair, with applications in spintronics and quantum computing.\n\n\n"}
{"id": "32662418", "url": "https://en.wikipedia.org/wiki?curid=32662418", "title": "Anomalous diffraction theory", "text": "Anomalous diffraction theory\n\nAnomalous diffraction theory (also van de Hulst approximation, eikonal approximation, high energy approximation, soft particle approximation) is an approximation developed by Dutch astronomer van de Hulst describing light scattering for optically soft spheres.\n\nThe anomalous diffraction approximation for extinction efficiency is valid for optically soft particles and large size parameter, x = 2π\"a\"/λ:\n\nwhere formula_2 in this derivation since the refractive index is assumed to be real, and thus there is no absorption (formula_3). formula_4 is the efficiency factor of extinction, which is defined as the ratio of the extinction cross section and geometrical cross section π\"a\". \"p\" = 4π\"a\"(\"n\" – 1)/λ has a physical meaning of the phase delay of the wave passing through the center of the sphere; a is the sphere radius, \"n\" is the ratio of refractive indices inside and outside of the sphere, and λ the wavelength of the light.\n\nThis set of equations was first described by van de Hulst. There are extensions to more complicated geometries of scattering targets.\n\nThe anomalous diffraction approximation offers a very approximate but computationally fast technique to calculate light scattering by particles. The absolute value of the refractive index has to be close to 1, and the size parameter should be large. However, semi-empirical extensions to small size parameters and larger refractive indices are possible. The main advantage of the ADT is that one can (a) calculate, in closed form, extinction, scattering, and absorption efficiencies for many typical size distributions; (b) find solution to the inverse problem of predicting size distribution from light scattering experiments (several wavelengths); (c) for parameterization purposes of single scattering (inherent) optical properties in radiative transfer codes.\n\nAnother limiting approximation for optically soft particles is Rayleigh scattering, which is valid for small size parameters.\n"}
{"id": "2655975", "url": "https://en.wikipedia.org/wiki?curid=2655975", "title": "Asessippi Provincial Park", "text": "Asessippi Provincial Park\n\nAsessippi Provincial Park was designated a provincial park by the Government of Manitoba on April 9, 1964. It is located in the Rural Municipality of Riding Mountain West, near Inglis, Manitoba, Canada about 100 km west of Dauphin. The Park is 23.2 km (9 sq mi). The park is considered to be a Class III protected area under the IUCN protected area management categories.\n\nThe focal point is the Lake of the Prairies also known as Shellmouth Reservoir. The lake has one of the largest walleye fisheries in Manitoba. The Park includes a large campground with over 100 mostly serviced sites.\n\nAsessippi Ski Resort is in the area.\n\n\n"}
{"id": "1238181", "url": "https://en.wikipedia.org/wiki?curid=1238181", "title": "Blueschist", "text": "Blueschist\n\nBlueschist (), also called glaucophane schist, is a metavolcanic rock that forms by the metamorphism of basalt and rocks with similar composition at high pressures and low temperatures (200 to ~500 degrees Celsius), approximately corresponding to a depth of 15 to 30 kilometers. \nThe blue color of the rock comes from the presence of the predominant minerals glaucophane and lawsonite.\n\nBlueschists are typically found within orogenic belts as terranes of lithology in faulted contact with greenschist or rarely eclogite facies rocks.\n\nBlueschist, as a rock type, is defined by the presence of the minerals glaucophane + ( lawsonite or epidote ) +/- jadeite +/- albite or chlorite +/- garnet +/- muscovite in a rock of roughly basaltic composition.<br>\nBlueschist often has a lepidoblastic, nematoblastic or schistose rock microstructure defined primarily by chlorite, phengitic white mica, glaucophane, and other minerals with an elongate or platy shape. \n\nGrain size is rarely coarse, as mineral growth is retarded by the swiftness of the rock's metamorphic trajectory and perhaps more importantly, the low temperatures of metamorphism and in many cases the anhydrous state of the basalts. However, porphyritic varieties do occur. Blueschists may appear blue, black, gray, or blue-green in outcrop.\n\nBlueschist facies is determined by the particular temperature and pressure conditions required to metamorphose basalt to form blueschist. Felsic rocks and pelitic sediments which are subjected to blueschist facies conditions will form different mineral assemblages than metamorphosed basalt. Thereby, these rocks do not appear blue overall in color.\n\nBlueschist mineralogy varies by rock composition, but the classic equilibrium assemblages of blueschist facies are:\n\n\nBlueschist facies generally is considered to form under pressures of >0.6 GPa, equivalent to depth of burial in excess of 15–18 km, and at temperatures of between 200 and 500 °C. This is a 'low temperature, high pressure' prograde metamorphic path and is also known as the \"Franciscan facies series\", after the west coast of the United States where these rocks are exposed. Well-exposed blueschists also occur in Greece, Turkey, Japan, New Zealand and New Caledonia.\n\nContinued subduction of blueschist facies oceanic crust will produce eclogite facies assemblages in metamorphosed basalt (garnet + omphacitic clinopyroxene). Rocks which have been subjected to blueschist conditions during a prograde trajectory will gain heat by conduction with hotter lower crustal rocks if they remain at the 15–18 km depth. Blueschist which heats up to greater than 500 °C via this fashion will enter greenschist or eclogite facies temperature-pressure conditions, and the mineral assemblages will metamorphose to reflect the new facies conditions. \n\nThus in order for blueschist facies assemblages to be seen at the Earth's surface, the rock must be exhumed swiftly enough to prevent total thermal equilibration of the rocks which are under blueschist facies conditions with the typical geothermal gradient. \n\nBlueschists and other high-pressure subduction zone rocks are thought to be exhumed rapidly by flow and/or faulting in accretionary wedges or the upper parts of subducted crust, or may return to the Earth's surface in part owing to buoyancy if the metabasaltic rocks are associated with low-density continental crust (marble, metapelite, and other rocks of continental margins).\n\nIt has been held that the absence of blueschist dating to before the Neoproterozoic Era indicates that currently exhumed rocks never reached blueschist facies at subduction zones before 1,000 million years ago. This assertion is arguably wrong because the earliest oceanic crust would have contained more magnesium than today's crust and, therefore, would have formed greenschist-like rocks at blueschist facies.\n\nIn 1962, Edgar Bailey of the U.S. Geological Survey introduced the concept of \"blueschist\" into the subject of metamorphic geology. His carefully constructed definition established the pressure and temperature conditions which produce this type of metamorphism.\n\n\nBlueschist facies - Rock Library Glossary, Imperial College London\n"}
{"id": "631358", "url": "https://en.wikipedia.org/wiki?curid=631358", "title": "Carolina Beach State Park", "text": "Carolina Beach State Park\n\nCarolina Beach State Park is a North Carolina state park in New Hanover County, North Carolina. It covers on Pleasure Island. The state owns of the park in fee simple, and the remainder of park land is leased from the Department of the Army. The park is located along the Cape Fear River and Snow's Cut (part of the Intracoastal Waterway).\n\nPocosin wetlands, a type of wetland that supports rare carnivorous plant species, are found in the park. Carnivorous plants found at this park include Venus flytraps, pitcher plants, butterworts and bladderworts.\n\nThe park features six miles of hiking trails. Other amenities include a marina, campsites, picnic area, and a visitor's center featuring natural history exhibits.\n"}
{"id": "10234870", "url": "https://en.wikipedia.org/wiki?curid=10234870", "title": "Ceto (Oceanid)", "text": "Ceto (Oceanid)\n\nin Nonnus's \"Dionysiaca\", Ceto is called a \"Naiad daughter of Oceanos\" and thus one of the Oceanids. She bore Helios a daughter, Astris.\n\n"}
{"id": "8064915", "url": "https://en.wikipedia.org/wiki?curid=8064915", "title": "Crimean Submediterranean forest complex", "text": "Crimean Submediterranean forest complex\n\nThe Crimean Submediterranean forest complex ecoregion, in the temperate mixed forest biome of Ukraine and Russia.\n\nThe ecoregion consists of two coastal enclaves on northern coast of the Black Sea; one occupies the central coast of Crimea, extending into the Crimean Mountains, the other occupies the Black Sea coast of Krasnodar Kray, extending eastward along the northwest flank of the Caucasus.\n\nThe ecoregion's climate and vegetation resemble that of the Mediterranean Basin, with a hot dry summer and a mild, rainy winter. \n\nAt elevations below 400 meters, woodlands and maquis shrublands predominate with: \n\nBetween 400 and 800 meters are forests predominate with:\n\nFrom 800 to 1300 meters elevation forests predominate with: \n\nThe warm summers and mild winters of the region make it a popular resort destination. Cities and towns in the ecoregion include Yalta, Alupka, Alushta, Sevastopol, and Novorossiysk.\n\n"}
{"id": "2046576", "url": "https://en.wikipedia.org/wiki?curid=2046576", "title": "De Magnete", "text": "De Magnete\n\nDe Magnete, Magneticisque Corporibus, et de Magno Magnete Tellure (\"On the Magnet and Magnetic Bodies, and on That Great Magnet the Earth\") is a scientific work published in 1600 by the English physician and scientist William Gilbert and his partner Aaron Dowling. A highly influential and successful book, it exerted an immediate influence on many contemporary writers, including Francis Godwin and Mark Ridley.\n\nIn his work, Gilbert described many of his experiments with his model Earth called the \"terrella\". (Previously, it was thought that Polaris or a large magnetic island at the North Pole attracted the compass). Gilbert also made the claim that gravity was due to the same force and he believed that this held the Moon in orbit around the Earth. While incorrect by modern standards, this claim was still far closer to the truth than the ancient Aristotelian theory, which held that the heavenly bodies consist of a special fifth element which naturally moves in circles, while the earthly elements naturally move downward. Johannes Kepler accepted Gilbert's theory and used it as a working basis for his famous laws of planetary motion.\n\nIn \"De Magnete\", Gilbert also studied static electricity produced by amber. Amber is called \"elektron\" in Greek, and \"electrum\" in Latin, so Gilbert decided to refer to the phenomenon by the adjective \"electricus\", giving rise to the modern terms \"electric\" and \"electricity\".\n\n\"De Magnete\" was influential because of the inherent interest of its subject matter, but also for the rigorous way in which Gilbert described his experiments and his rejection of ancient theories of magnetism. Gilbert nevertheless acknowledged his debt to Peter of Maricourt and incorporated this 13th-century scientist's experiments on magnetism into his own treatise. Although Gilbert's thinking was influenced by the mysticism of his time he is regarded as a pioneer of experimental science.\n\n\"De Magnete\" consists of six books.\n\nHistorical survey of magnetism and theory of Earth's magnetism. The loadstone in antiquity from Plato onwards and the gradual identification of iron ores. The south pole of a loadstone points to the north pole of the earth and vice versa as the terrestrial globe is magnetic.\n\n Distinction between electricity and magnetism. An amber stick when rubbed affects a rotating needle made of any type of metal (a versorium) and attracts paper, leaves and even water. But electricity is different from heat and to magnetism which only attracts iron-bearing materials (he calls it coition). He shows the effects of cutting a spherical loadstone (which he calls a \"terrella\") through the poles and equator and the direction of attraction at different points. Magnets act at a distance but the force has no permanent presence and is not hindered like light. Materials including gold, silver and diamonds are not affected by magnets, nor can one produce perpetual motion.\n\n The earth's normal magnetism. He proposes (incorrectly) that the angle of the ecliptic and precession of the equinoxes are caused by magnetism. A loadstone cut out of rock and floated in water returns to the same direction. Iron heated to white heat and cooled lying along a meridian also acquires magnetism. But stroking with other materials fails—he proved this with an experiment with 75 diamonds in front of witnesses. The best way to magnetize a compass (magnetized versorium).\n\nDeclination. The compass does not always point to true north. There is considerable variation. Using the terella he shows that variations in the height of the surface can lead to differences but insists that variation is a global issue. In the midst of the ocean or continent there is no variation. He shows how to measure variation and the sources of common errors.\n\n Magnetic dip. The angle of inclination (dip) of a compass to the horizon differs according to latitude. He shows how to construct a dip instrument. At the equator it is level and increases towards the poles as he has shown earlier with his terrella.\n\nTerrestrial rotation. Heraclides and others held that the earth rotates from west to east and this is supported by Copernicus (the \"restorer of astronomy\"), but Aristotle said otherwise. \"If the rotations of the earth seems headlong and not to be permitted by nature because of its rapidity, then worse than insane, both as regards itself and the whole universe is the motion of the primum mobile.\" He rejects the idea of a sphere of the fixed stars for which no proof has been offered and leaves aside the question of other movements of the earth but \"infers not with mere probability, but with certainty the diurnal revolution of the earth.\" He states that \"the cause of the diurnal motion are to be found in the magnetic energy and the alliance of bodies\" but offers no further guidance. The inclination of the earth's pole to the ecliptic produces the seasons. He explains the Precession of the equinoxes as the movement of the earth's axis.\n\nIn Chapter III, Gilbert argues in favor of the Copernican System. He posits that due to the inordinate distance of the celestial spheres, if in fact the spheres exist at all, it is an absurd idea that they would rotate every 24 hours, as opposed to the rotation of the relatively tiny sphere of the Earth. He states, \"How far away from the earth are those remotest of stars: they are beyond the reach of eye, or man's devices, or man's thought. What an absurdity is this motion (of spheres)\". He also argues for the extreme variability of the distance to the various heavenly bodies and states that situated \"in thinnest aether, or in the most subtle fifth essence, or in vacuity – how shall the stars keep their places in the mighty swirl of these enormous spheres composed of a substance of which no one knows aught?\".\n\n\n"}
{"id": "1083128", "url": "https://en.wikipedia.org/wiki?curid=1083128", "title": "Dzungaria", "text": "Dzungaria\n\nDzungaria (; also spelled Zungaria, Dzungharia or Zungharia, Dzhungaria or Zhungaria, or Djungaria or Jungaria) is a geographical region in northwest China corresponding to the northern half of Xinjiang, also known as Beijiang (). Bounded by the Tian Shan mountain range to the south and the Altai Mountains to the north, it covers approximately , extending into western Mongolia and eastern Kazakhstan. Formerly the term could cover a wider area, conterminous with the Dzungar Khanate, a state led by the Oirats in the 18th century which was based in the area.\n\nAlthough geographically, historically, and ethnically distinct from the Turkic-speaking Tarim Basin area, the Qing dynasty and subsequent Chinese governments integrated both areas into one province, Xinjiang. As the center of Xinjiang's heavy industry, generator of most of Xinjiang's GDP, as well as containing its political capital Ürümqi (\"beautiful pasture\" in Oirat), northern Xinjiang continues to attract intraprovincial and interprovincial migration to its cities. In comparison to southern Xinjiang (\"Nanjiang\", or the Tarim Basin), Dzungaria is relatively well integrated with the rest of China by rail and trade links.\n\nThe name Dzungaria or Zungharia is a corruption of the Mongolian term \"Zűn Gar\" or \"Jüün Gar\" depending on the dialect of Mongolian used. \"Zűn\"/\"Jüün\" means \"left\" and \"Gar\" means \"hand\". The name originates from the notion that the Western Mongols are on the left-hand side when the Mongol Empire began its division into East and West Mongols. After this fragmentation, the western Mongolian nation was called \"Zuun Gar\".\n\nXinjiang consists of two main geographically, historically, and ethnically distinct regions, Dzungaria north of the Tianshan Mountains and the Tarim Basin south of the Tianshan Mountains, before Qing China unified them into one political entity called Xinjiang province in 1884. At the time of the Qing conquest in 1759, Dzungaria was inhabited by steppe dwelling, nomadic Tibetan Buddhist Dzungar people, while the Tarim Basin was inhabited by sedentary, oasis dwelling, Turkic speaking Muslim farmers, now known as the Uyghur people.\n\nThe Qing dynasty was well aware of the differences between the former Buddhist Mongol area to the north of the Tianshan and Turkic Muslim south of the Tianshan, and ruled them in separate administrative units at first. However, Qing people began to think of both areas as part of one distinct region called Xinjiang . The very concept of Xinjiang as one distinct geographic identity was created by the Qing and it was originally not the native inhabitants who viewed it that way, but rather it was the Chinese who held that point of view. During the Qing rule, no sense of \"regional identity\" was held by ordinary Xinjiang people; rather, Xinjiang's distinct identity was given to the region by the Qing, since it had distinct geography, history and culture, while at the same time it was created by the Chinese, multicultural, settled by Han and Hui, and separated from Central Asia for over a century and a half.\n\nIn the late 19th century, it was still being proposed by some people that two separate parts be created out of Xinjiang, the area north of the Tianshan and the area south of the Tianshan, while it was being argued over whether to turn Xinjiang into a province.\n\nThe core of Dzungaria is the triangular Dzungarian Basin, also known as Jungar Basin, or in Chinese as , with its central Gurbantünggüt Desert.\nIt is bounded by the Tian Shan to the south, the Altai Mountains to the northeast and the Tarbagatai Mountains to the northwest. The three corners are relatively open. The northern corner is the valley of the upper Irtysh River. The western corner is the Dzungarian Gate, a historically important gateway between Dzungaria and the Kazakh Steppe; presently, a highway and a railway (opened in 1990) run through it, connecting China with Kazakhstan. The eastern corner of the basin leads to Gansu and the rest of China. In the south, an easy pass leads from Ürümqi to the Turfan Depression. In the southwest, the tall Borohoro Mountains branch of the Tian Shan separates the basin from the upper Ili River.\n\nThe basin is similar to the larger Tarim Basin on the southern side of the Tian Shan Range. Only a gap in the mountains to the north allows moist air masses to provide the basin lands with enough moisture to remain semi-desert rather than becoming a true desert like most of the Tarim Basin and allows a thin layer of vegetation to grow. This is enough to sustain populations of wild camels, jerboas, and other wild species.\n\nThe Dzungarian Basin is a structural basin with thick sequences of Paleozoic-Pleistocene rocks with large estimated oil reserves. The Gurbantunggut Desert, China’s second largest, is in the center of the basin.\n\nThe Dzungarian basin does not have a single catchment center. The northernmost section of Dzungaria is part of the basin of the Irtysh River, which ultimately drains into the Arctic Ocean. The rest of the region is split into a number of endorheic basins. In particular, south of the Irtysh, the Ulungur River ends up in the (presently) endorheic Lake Ulungur. The Southwestern part of the Dzungarian basin drains into the \nAibi Lake. In the west-central part of the region, streams flow into (or toward) a group of endorheic lakes that include Lake Manas and Lake Ailik. During the region's geological past, a much larger lake (the \"Old Manas Lake\") was located in the area of today's Manas Lake; it was fed not only by the streams that presently flow toward it but also by the Irtysh and Ulungur, which too were flowing toward the Old Manas Lake at the time.\n\nThe cold climate of nearby Siberia influences the climate of the Dzungarian Basin, making the temperature colder—as low as —and providing more precipitation, ranging from , compared to the warmer, drier basins to the south. Runoff from the surrounding mountains into the basin supplies several lakes. The ecologically rich habitats traditionally included meadows, marshlands, and rivers. However, most of the land is now used for agriculture.\n\nIt is a largely steppe and semi-desert basin surrounded by high mountains: the Tian Shan (ancient Mount Imeon) in the south and the Altai in the north. Geologically it is an extension of the Paleozoic Kazakhstan Block and was once part of an independent continent before the Altai mountains formed in the late Paleozoic. It does not contain the abundant minerals of Kazakhstan and may have been a pre-existing continental block before the Kazakhstan Block was formed.\n\nÜrümqi, Yining and Karamai are the main cities; other smaller oasis towns dot the piedmont areas.\n\nDzungaria and its derivatives are used to name a number of pre-historic animals hailing from the rocky outcrops located in the Dzungar Basin:\n\nA recent notable find, in February 2006, is the oldest tyrannosaur fossil unearthed by a team of scientists from George Washington University who were conducting a study in the Dzungarian Basin. The species, named \"Guanlong\", lived 160 million years ago, more than 90 million years before the famed \"Tyrannosaurus rex\".\n\nDzungaria is home to a semi-desert steppe ecoregion known as the Dzungarian Basin semi-desert. The vegetation consists mostly of low scrub of \"Anabasis brevifolia\". Taller shrublands of saxaul bush \"(Haloxylon ammodendron)\" and \"Ephedra przewalskii\" can be found near the margins of the basin. Streams descending from the Tian Shan and Altai ranges support stands of poplar \"(Populus diversifolia)\" together with \"Nitraria roborovsky, N. sibirica, Achnatherum splendens,\" tamarisk \"(Tamarix sibirimosissima)\", and willow \"(Salix ledebouriana)\".\n\nThe northeastern portion of the Dzungarian Basin semi-desert lies within Great Gobi National Park, and is home to herds of Onagers \"(Equus hemionus)\", goitered gazelles \"(Gazella subgutturosa)\" and Wild Bactrian camels \"(Camelus ferus)\".\n\nThe basin was one of the last habitats of Przewalski's horse \"(Equus przewalskii)\", also known as Dzungarian horse, which was once extinct in the wild, though it has since been reintroduced in areas of Mongolia and China.\n\nThe first people to inhabit the region were Indo-European-speaking peoples such as the Tocharians in prehistory and the Jushi Kingdom in the first millennium BC. \n\nBefore the 21st century, all or part of the region has been ruled or controlled by the Xiongnu Empire, Han dynasty, Xianbei state, Rouran Khaganate, Turkic Khaganate, Tang Dynasty, Uyghur Khaganate, Liao dynasty, Kara-Khitan Khanate, Mongol Empire, Yuan Dynasty, Chagatai Khanate, Moghulistan, Qara Del, Northern Yuan, Four Oirat, Dzungar Khanate, Qing Dynasty, the Republic of China and, since 1950, the People's Republic of China.\n\nOne of the earliest mentions of the Dzungaria region occurs when the Han dynasty dispatched an explorer to investigate lands to the west, using the northernmost Silk Road trackway of about in length, which connected the ancient Chinese capital of Xi'an to the west over the Wushao Ling Pass to Wuwei and emerged in Kashgar.\n\nIstämi of the Göktürks received the lands of Dzungaria as an inheritance after the death of his father in the latter half of the sixth century AD.\n\nDzungaria is named after a Mongolian kingdom which existed in Central Asia during the seventeenth and eighteenth centuries. It derived its name from the Dzungars, who were so called because they formed the left wing (\"züün\", left; \"gar\", hand) of the Mongolian army, self-named Oirats. Dzungar power reached its height in the second half of the 17th century, when Galdan Boshugtu Khan repeatedly intervened in the affairs of the Kazakhs to the west, but it was completely destroyed by the Kazakhs about 1757–1759. It has played an important part in the history of Mongolia and the great migrations of Mongolian stems westward. Its widest limit included Kashgar, Yarkand, Khotan, the whole region of the Tian Shan, and the greater proportion of that part of Central Asia which extends from 35° to 50° N and from 72° to 97° E.\n\nAfter 1761, its territory fell mostly to the Qing dynasty during the campaign against the Dzungars (Xinjiang and north-western Mongolia) and partly to Russian Turkestan (the earlier Kazakh state provinces of Zhetysu and Irtysh river).\n\nAfter the Dzungar genocide, the Qing subsequently began to repopulate the area with Han and Hui people from China Proper.\n\nThe population in the 21st century consists of Kazakhs, Kyrgyz, Mongols, Uyghurs and Han Chinese. Since 1953, northern Xinjiang has attracted skilled workers from all over China—who have mostly been Han Chinese—to work on water conservation and industrial projects, especially the Karamay oil fields. Intraprovincial migration has mostly been directed towards Dzungaria also, with immigrants from the poor Uyghur areas of southern Xinjiang flooding to the provincial capital of Ürümqi to find work.\n\nAs a political or geographical term \"Dzungaria\" has practically disappeared from the map; but the range of mountains stretching north-east along the southern frontier of the Zhetysu, as the district to the southeast of Lake Balkhash preserves the name of Dzungarian Alatau. It also gave name to Djungarian hamsters.\n\nA traveller going west from China must go either north of the Tian Shan mountains through Dzungaria or south of the mountains through the Tarim Basin. Trade usually took the south side and migrations the north. This is most likely because the Tarim leads to the Ferghana Valley and Iran, while Dzungaria leads only to the open steppe. The difficulty with south side was the high mountains between the Tarim and Ferghana. There is also another reason. The Taklamakan is too dry to support much grass, and therefore nomads when they are not robbing caravans. Its inhabitants live mostly in oases formed where rivers run out of the mountains into the desert. These are inhabited by peasants who are unwarlike and merchants who have an interest in keeping trade running smoothly. Dzungaria has a fair amount of grass, few towns to base soldiers in and no significant mountain barriers to the west. Therefore, trade went south and migrations north. Today most trade is north of the mountains (Dzungarian Gate and Khorgas in the Ili valley) to avoid the mountains west of the Tarim and because Russia is currently more developed.\n\nWheat, barley, oats, and sugar beets are grown, and cattle, sheep, and horses are raised. The fields are irrigated with melted snow from the permanently white-capped mountains.\n\nDzungaria has deposits of coal, iron, and gold, as well as large oil fields.\n\n"}
{"id": "16515095", "url": "https://en.wikipedia.org/wiki?curid=16515095", "title": "EF86", "text": "EF86\n\nThe EF86 is a high transconductance sharp cutoff pentode vacuum tube with Noval (B9A) base for audio-frequency applications.\n\nIt was introduced in the late 1950s and was produced by Philips, Mullard, Telefunken, Valvo, and GEC among others. It is very similar electrically to the octal base EF37A and the Rimlock base EF40. Unlike many pentodes it was designed specifically for audio applications, low noise and low microphony being claimed advantages, although a rubber-mounted vibration-resistant base was still recommended. It has much higher stage gain than any triode, which makes it susceptible to microphony. The EF86 was used in many preamplifier designs during the last decades of vacuum tube hi-fi development. An industrial variant of the tube is known as 6267. In the former Soviet Union a variant was also produced as type 6Zh32P (Russian: 6Ж32П.) EF86s were being produced in Russia in two versions under the Electro-Harmonix brand and in the Slovak Republic as JJ Electronic (formerly Tesla).\n\n6.3 Volt, 200 mA indirectly-heated A.F. miniature pentode with Noval (B9A) base with an EIA 9CQ (or 9BJ) basing diagram.\n\nSpecial precautions have been taken in the design to reduce:\n\nThe EF86 is much less noisy than other pentodes, but slightly noisier than some triodes at about 2 µV equivalent input noise to 10 kHz. Although used in circuits such as tape recorder input stages and instrument amplifiers, microphony can be a problem, even when mounted in a vibration-reducing valve holder.\n\n\nSpecial quality:\n\nDifferent heater requirements:\n\nThe rarely used EF83 is a remote-cutoff pentode otherwise similar to the EF86; the remote cutoff (variable mu) makes it suitable for applications such as automatic gain control (agc) in tape recorders.\n\n"}
{"id": "598536", "url": "https://en.wikipedia.org/wiki?curid=598536", "title": "Einstein ring", "text": "Einstein ring\n\nIn observational astronomy an Einstein ring, also known as an Einstein–Chwolson ring or Chwolson ring, is the deformation of the light from a source (such as a galaxy or star) into a ring through gravitational lensing of the source's light by an object with an extremely large mass (such as another galaxy or a black hole). This occurs when the source, lens, and observer are all aligned—a syzygy. The first complete Einstein ring, designated B1938+666, was discovered by collaboration between astronomers at the University of Manchester and NASA's Hubble Space Telescope in 1998.\n\nGravitational lensing is predicted by Albert Einstein's theory of general relativity. Instead of light from a source traveling in a straight line (in three dimensions), it is bent by the presence of a massive body, which distorts spacetime. An Einstein Ring is a special case of gravitational lensing, caused by the exact alignment of the source, lens, and observer. This results in a symmetry around the lens, causing a ring-like structure.\nThe size of an Einstein ring is given by the Einstein radius. In radians, it is\n\nwhere\n\nNote that, over cosmological distances formula_8 in general.\n\nThe bending of light by a gravitational body was predicted by Albert Einstein in 1912, a few years before the publication of general relativity in 1916 (Renn et al. 1997). The ring effect was first mentioned in the academic literature by Orest Khvolson in a short article in 1924, in which he mentioned the “halo effect” of gravitation when the source, lens, and observer are in near-perfect alignment. Einstein remarked upon this effect in 1936 in a paper prompted by a letter by a Czech engineer, R W Mandl , but stated\n(In this statement, β is the Einstein Radius currently denoted by formula_9 as in the expression above.) However, Einstein was only considering the chance of observing Einstein rings produced by stars, which is low – the chance of observing those produced by larger lenses such as galaxies or black holes is higher since the angular size of an Einstein ring increases with the mass of the lens.\n\nThere have apparently not been any observations of a star forming an Einstein ring with another star, but there is a 45% chance of this happening in early May, 2028 when Alpha Centauri A passes between us and a distant red star.\n\nHundreds of gravitational lenses are currently known. About half a dozen of them are partial Einstein rings with diameters up to an arcsecond, although as either the mass distribution of the lenses is not perfectly axially symmetrical, or the source, lens, and observer are not perfectly aligned, we have yet to see a perfect Einstein ring. Most rings have been discovered in the radio range. The degree of completeness needed for an image seen through a gravitational lens to qualify as an Einstein ring is yet to be defined.\n\nThe first Einstein ring was discovered by Hewitt et al. (1988), who observed the radio source MG1131+0456 using the Very Large Array. This observation saw a quasar lensed by a nearer galaxy into two separate but very similar images of the same object, the images stretched round the lens into an almost complete ring. These dual images are another possible effect of the source, lens, and observer not being perfectly aligned.\n\nThe first complete Einstein ring to be discovered was B1938+666, which was found by King et al. (1998) via optical follow-up with the Hubble Space Telescope of a gravitational lens imaged with MERLIN. The galaxy causing the lens at B1938+666 is an ancient elliptical galaxy, and the image we see through the lens is a dark dwarf satellite galaxy, which we would otherwise not be able to see with current technology.\nIn 2005, the combined power of the Sloan Digital Sky Survey (SDSS) with the Hubble Space Telescope was used in the Sloan Lens ACS (SLACS) Survey to find 19 new gravitational lenses, 8 of which showed Einstein rings, these are the 8 shown in the adjacent image. As of 2009 this survey has found 85 confirmed gravitational lenses, there is not yet a number for how many show Einstein rings. This survey is responsible for most of the recent discoveries of Einstein rings in the optical range, following are some examples which were found:\n\n\nAnother example is the radio/X-Ray Einstein ring around PKS 1830-211, which is unusually strong in radio. It was discovered in X-Ray by Varsha Gupta et al. at the Chandra X-Ray observatory It is also notable for being the first case of a quasar being lensed by an almost face-on spiral galaxy.\n\nThere is also a radio ring around galaxy MG1654+1346, the image in the ring is that of a quasar radio lobe, discovered in 1989 by G.Langston et al.\n\nUsing the Hubble Space Telescope, a double ring has been found by Raphael Gavazzi of the STScI and Tommaso Treu of the University of California, Santa Barbara. This arises from the light from three galaxies at distances of 3, 6, and 11 billion light years. Such rings help in understanding the distribution of dark matter, dark energy, the nature of distant galaxies, and the curvature of the universe. The odds of finding such a double ring are 1 in 10,000. Sampling 50 suitable double rings would provide astronomers with a more accurate measurement of the dark matter content of the universe and the equation of state of the dark energy to within 10 percent precision.\n\nTo the right is a simulation depicting a zoom on a Schwarzschild black hole in the plane of the Milky Way between us and the centre of the galaxy. The first Einstein ring is to the most distorted region of the picture and shows the galactic disc. The zoom then reveals a series of 4 extra rings, increasingly thinner and closer to the black hole shadow. They are multiple images of the galactic disk. The first and third correspond to points which are behind the black hole (from the observer's position) and correspond here to the bright yellow region of the galactic disc (close to the galactic center), whereas the second and fourth correspond to images of objects which are behind the observer, which appear bluer since the corresponding part of the galactic disc is thinner and hence dimmer here.\n\n\n"}
{"id": "1520238", "url": "https://en.wikipedia.org/wiki?curid=1520238", "title": "Embodied energy", "text": "Embodied energy\n\nEmbodied energy is the sum of all the energy required to produce any goods or services, considered as if that energy was incorporated or 'embodied' in the product itself. The concept can be useful in determining the effectiveness of energy-producing or energy-saving devices, or the \"real\" replacement cost of a building, and, because energy-inputs usually entail greenhouse gas emissions, in deciding whether a product contributes to or mitigates global warming. One fundamental purpose for measuring this quantity is to compare the amount of energy produced or saved by the product in question to the amount of energy consumed in producing it.\n\nEmbodied energy is an accounting method which aims to find the sum total of the energy necessary for an entire product life-cycle. Determining what constitutes this life-cycle includes assessing the relevance and extent of energy into raw material extraction, transport, manufacture, assembly, installation, disassembly, deconstruction and/or decomposition as well as human and secondary resources.\n\nThe history of constructing a system of accounts which records the energy flows through an environment can be traced back to the origins of accounting itself. As a distinct method, it is often associated with the Physiocrat's \"substance\" theory of value, and later the agricultural energetics of Sergei Podolinsky, a Ukrainian physician, and the ecological energetics of Vladmir Stanchinsky.\n\nThe main methods of embodied energy accounting as they are used today grew out of Wassily Leontief's input-output model and are called \"Input-Output Embodied Energy analysis\". Leontief's input-output model was in turn an adaptation of the neo-classical theory of general equilibrium with application to \"the empirical study of the quantitative interdependence between interrelated economic activities\". According to Tennenbaum Leontief's Input-Output method was adapted to embodied energy analysis by Hannon to describe ecosystem energy flows. Hannon's adaptation tabulated the total direct and indirect energy requirements (the \"energy intensity\") for each output made by the system. The total amount of energies, direct and indirect, for the entire amount of production was called the \"embodied energy\".\n\nEmbodied energy analysis is interested in what energy goes to supporting a consumer, and so all energy depreciation is assigned to the final demand of consumer. Different methodologies use different scales of data to calculate energy embodied in products and services of nature and human civilization. International consensus on the appropriateness of data scales and methodologies is pending. This difficulty can give a wide range in embodied energy values for any given material. In the absence of a comprehensive global embodied energy public dynamic database, embodied energy calculations may omit important data on, for example, the rural road/highway construction and maintenance needed to move a product, human marketing, advertising, catering services, non-human services and the like. Such omissions can be a source of significant methodological error in embodied energy estimations. Without an estimation and declaration of the embodied energy error, it is difficult to calibrate the , and so the value of any given material, process or service to environmental and human economic processes.\n\nThe SBTool, UK Code for Sustainable Homes and USA LEED are methods in which the embodied energy of a product or material is rated, along with other factors, to assess a building's environmental impact. Embodied energy is a concept for which scientists have not yet agreed absolute universal values because there are many variables to take into account, but most agree that products can be compared to each other to see which has more and which has less embodied energy. Comparative lists (for an example, see the University of Bath \"Embodied Energy & Carbon Material Inventory\") contain average absolute values, and explain the factors which have been taken into account when compiling the lists.\n\nTypical embodied energy units used are MJ/kg (megajoules of energy needed to make a kilogram of product), t (tonnes of carbon dioxide created by the energy needed to make a kilogram of product). Converting MJ to t is not straightforward because different types of energy (oil, wind, solar, nuclear and so on) emit different amounts of carbon dioxide, so the actual amount of carbon dioxide emitted when a product is made will be dependent on the type of energy used in the manufacturing process. For example, the Australian Government gives a global average of 0.098 t = 1 GJ. This is the same as 1 MJ = 0.098 kg = 98 g or 1 kg = 10.204 MJ.\n\nIn the 2000s drought conditions in Australia have generated interest in the application of embodied energy analysis methods to water. This has led to use of the concept of embodied water.\n\nSelected data from the Inventory of Carbon and Energy ('ICE') prepared by the University of Bath (UK) \n\nTheoretically, embodied energy stands for the energy used to extract materials from mines, to manufacture vehicles, assemble, transport, maintain, transform them and to transport energy, and ultimately to recycle these vehicles. Besides, the energy needed to build and maintain transport networks, whether road or rail, should be taken into account as well. The process to be implemented is so complex that no one dares to put forward a figure.\n\nAccording to the , in the field of transportation, \"it is striking to note that we consume more embodied energy in our transportation expenditures than direct energy [...]. Put in other words, we consume less energy to move around in our personal vehicles than we consume the energy we need to produce, sell and transport the cars, trains or buses we use \".\n\nJean-Marc Jancovici advocates a carbon footprint analysis of any transportation infrastructure project, prior to its construction.\n\nAccording to Volkswagen, the embodied energy contents of a Golf A3 with a petrol engine amounts to 18 000 kWh (i.e. 12% of 545 GJ as shown in the report). A Golf A4 (equipped with a turbocharged direct injection) will show an embodied energy amounting to 22 000 kWh (i.e. 15% of 545 GJ as shown in the report). According to the French energy and environment agency ADEME a motor car has an embodied energy contents of 20 800 kWh whereas an electric vehicle shows an embodied energy contents amounting to 34 700 kWh.\n\nAs regards energy itself, the factor energy returned on energy invested (EROEI) of fuel can be estimated at 8, which means that to some amount of useful energy provided by fuel should be added 1/7 of that amount in embodied energy of the fuel. In other words, the fuel consumption should be augmented by 14% due to the fuel EROEI.\n\nWe have to work here with figures, which prove still more difficult to obtain. In the case of road construction, the embodied energy would amount to 1/18 of the fuel consumption (i.e. 6%).\n\nTreloar, \"et al.\" have estimated the embodied energy in an average automobile in Australia as 0.27 terajoules (i.e. 75 000 kWh) as one component in an overall analysis of the energy involved in road transportation.\n\nAlthough most of the focus for improving energy efficiency in buildings has been on their operational emissions, it is estimated that about 30% of all energy consumed throughout the lifetime of a building can be in its embodied energy (this percentage varies based on factors such as age of building, climate, and materials). In the past, this percentage was much lower, but as much focus has been placed on reducing operational emissions (such as efficiency improvements in heating and cooling systems), the embodied energy contribution has come much more into play. Examples of embodied energy include: the energy used to extract raw resources, process materials, assemble product components, transport between each step, construction, maintenance and repair, deconstruction and disposal. As such, it is important to employ a whole-life carbon accounting framework in analyzing the carbon emissions in buildings.\n\nEROEI provides a basis for evaluating the embodied energy due to energy.\n\nFinal energy has to be multiplied by formula_1 in order to get the embodied energy.\n\nGiven an EROEI amounting to eight e.g., an eighth of the final energy corresponds to the embodied energy.\n\nNot only that, for really obtaining overall embodied energy, embodied energy due to the construction and maintenance of power plants should be taken into account, too. Here, figures are badly needed.\nIn the BP \"Statistical Review of World Energy June 2018\", toe are converted into kWh \"on the basis of thermal equivalence assuming 38% conversion efficiency in a modern thermal power station\".\n\nIn France, by convention, the ratio between primary energy and final energy in electricity amounts to 2.58, corresponding to an efficiency of 0.3875 or 38.8%.\n\nIn Germany, on the contrary, because of the swift development of the renewable energies, the ratio between primary energy and final energy in electricity amounts to only 1.8, corresponding to an efficiency of 55.5%.\n\nAccording to association négaWatt, embodied energy related to digital services amounted to 3.5 TWh/a for networks and 10.0 TWh/a for data centres (half for the servers per se, i. e. 5 TWh/a, and the other half for the buildings in which they are housed, i. e. 5 TWh/a), figures valid in France, in 2015. The organization is optimistic about the evolution of the energy consumption in the digital field, underlining the technical progress being made.\n\n\n"}
{"id": "23391633", "url": "https://en.wikipedia.org/wiki?curid=23391633", "title": "Energy in Cameroon", "text": "Energy in Cameroon\n\nEnergy in Cameroon is a growing industry with tremendous potential, especially with the hydroelectric industry. With a total installed capacity of 1,292 MW, the mix of energy production of Cameroon consists of 57% of hydraulic power source, 21% of thermal springs in the gas, 10% of heat source to light fuel oil and 13% of heat source to heavy fuel oil.\n\nCameroon began off shore oil production in 1977. Annual production has gradually fallen since 1985, and the decline is expected to continue as existing reserves are depleted. Output amounted to in 2001, down from in 1999. However, Cameroon is sub-Saharan Africa's sixth-largest crude oil producer, with output in 2003 at , and estimated reserves at as of January 1, 2004, according to the Energy Information Administration (EIA). Field development and production began in the Kribi-Campo basin in the mid-1990s, and the Ebome field came online in 1996. As of 2002, the major operators were ExxonMobil, Royal Dutch Shell, and Total S.A. The oil sector is managed by the national oil company \"Société Nationale des Hydrocarbures\".\n\nWork was under way on development of the Doba basin oil fields and construction of a pipeline between Cameroon and Chad, with the aid of a US$93 million loan from the World Bank. Production was expected to have begun in early 2004. In October 2002, Cameroon and Nigeria, both of whom claimed the potentially oil-rich Bakassi Peninsula, received a ruling on the dispute from the International Court of Justice, which granted the peninsula to Cameroon. Cameroon's petroleum consumption in 2001 was .\n\nThe country reportedly has large reserves of liquid petroleum gas, which are largely untapped. According to the EIA, Cameroon's natural gas reserves stood at as of January 1, 2004, with no known production in 2002. In cooperation with GDF Suez, \"Société Nationale des Hydrocarbures\" is planning to build a liquefied natural gas plant.\n\nHydroelectric resources remain the most readily exploitable form of energy in Cameroon, which, together with the Democratic Republic of Congo, is considered to have the greatest hydroelectric potential in Africa. Electrical energy is produced primarily by two hydroelectric stations on the Sanaga River. Nearly 60% of the power from these stations goes to the aluminum smelter at Edéa. Cameroon's electrical capacity was 810 MW in 2002, for which output for that year was 3.249 TWh, of which about 90% was from hydropower and the remainder from fossil fuels. Consumption amounted to 3.022 TWh in 2002. In the 1980s, hydroelectric capacity was expanded by an additional complex on the Sanaga River (Song-Loulou) and a 72 MW generator (built with Chinese aid) on the Bénoué River. However, despite Cameroon's impressive waterpower resources, the national electricity grid runs principally from Douala to Yaoundé and from Douala to Bafoussam. Most other areas are served by diesel-generated electricity or have no electricity at all. Cameroon's National Energy Plan attempts to prepare for a diminishing petroleum output. Hydro-Québec of Canada conducted a feasibility study of the Nachtigal Power Station, which could provide 280 MW of hydroelectric power on the Sananga River north of Yaoundé. In 1998, Hydro-Québec was awarded a contract to upgrade the Song Loulou Hydroelectric Power Station.\n\n\n"}
{"id": "1706565", "url": "https://en.wikipedia.org/wiki?curid=1706565", "title": "Energy intensity", "text": "Energy intensity\n\nEnergy intensity is a measure of the energy inefficiency of an economy. It is calculated as units of energy per unit of GDP.\n\n\nHigh energy intensity means high industrial output as portion of GDP. Countries with low energy intensity signifies labor intensive economy. \n\nMany factors influence an economy's overall energy intensity. It may reflect requirements for general standards of living and weather conditions in an economy. It is not atypical for particularly cold or hot climates to require greater energy consumption in homes and workplaces for heating (furnaces, or electric heaters) or cooling (air conditioning, fans, refrigeration). A country with an advanced standard of living is more likely to have a wider prevalence of such consumer goods and thereby be impacted in its energy intensity than one with a lower standard of living.\n\nEnergy efficiency of appliances and buildings (through use of building materials and methods, such as insulation), fuel economy of vehicles, vehicular distances travelled (frequency of travel or larger geographical distances), better methods and patterns of transportation, capacities and utility of mass transit, energy rationing or conservation efforts, 'off-grid' energy sources, and stochastic economic shocks such as disruptions of energy due to natural disasters, wars, massive power outages, unexpected new sources, efficient uses of energy or energy subsidies may all impact overall energy intensity of a nation.\n\nThus, a nation that is highly economically productive, with mild and temperate weather, demographic patterns of work places close to home, and uses fuel efficient vehicles, supports carpools, mass transportation or walks or rides bicycles, will have a far lower energy intensity than a nation that is economically unproductive, with extreme weather conditions requiring heating or cooling, long commutes, and extensive use of generally poor fuel economy vehicles. Paradoxically, some activities that may seem to promote high energy intensities, such as long commutes, could in fact result in lower energy intensities by causing a disproportionate increase in GDP output.\n\nFigures of energy consumption used in statistics are energy sources marketed through major energy industries. Therefore, some small scale but frequent consumption of energy source like firewood, charcoal peat, water wheel, wind mill are not in its count.\nIn countries, which does not have such developed energy industries or people with highly self energy efficient life style, report smaller energy consumption figures.\n\n\nVarious nations have significantly higher or lower energy intensities.\n\n\nOf course, these numbers were produced with a mix of 2003 and 2004 figures, many of which are estimates. Actual mathematical models should use precise data of appropriate matching periods of study.\n\nSeveral countries, like Sweden, Norway, France, and Canada, have made the transition to operating on low-carbon utilities. Norway and Canada have made the switch to hydro power; France relies on nuclear power. Since these countries have made the shift, they produce about a fifth of the carbon emissions in comparison to 13 other countries, like some including USA, Japan, and Italy.\n\nAn inverse way of looking at the issue would be an 'economic energy efficiency,' or economic rate of return on its consumption of energy: how many economic units of GDP are produced by the consumption of units of energy.\n\n\nIt is not directly causal that a high GDP per capita must have lower economic energy efficiencies. See the accompanying chart for examples based on the top 40 national economies.\n\nEnergy intensity can be used as a comparative measure between countries; whereas the change in energy consumption required to raise GDP in a specific country over time is described as its energy elasticity.\n\n\nEnergy intensity is a measure of energy efficiency of nation's GDP.\n\n"}
{"id": "39871498", "url": "https://en.wikipedia.org/wiki?curid=39871498", "title": "Force chain", "text": "Force chain\n\nIn the study of the physics of granular materials, a force chain consists of a set of particles within a compressed granular material that are held together and jammed into place by a network of mutual compressive forces.\n\nBetween these chains are regions of low stress whose grains are shielded for the effects of the grains above by vaulting and arching. A set of interconnected force chains is known as a force network.\n\nForce networks are an emergent phenomenon that are created by the complex interaction of the individual grains of material and the patterns of pressure applied within the material. Force chains can be shown to have fractal properties.\n\nForce chains have been investigated both experimentally, through the construction of specially instrumented physical models, and through computer simulation.\n\n"}
{"id": "42137540", "url": "https://en.wikipedia.org/wiki?curid=42137540", "title": "Fuchskaute", "text": "Fuchskaute\n\nThe Fuchskaute is an extinct volcano and, at , the highest mountain of the Westerwald and the county of Westerwaldkreis in the German state of Rhineland-Palatinate.\n\nThe name \"Fuchskaute\" (\"foxhole\") refers to a place where the fox (\"Fuchs\") had its den (\"Kaute\").\n\nThe Fuchskaute rises in the High Westerwald, a plateau of the Westerwald which, in turn, is part of the Rhenish Massif. It is about half way between Bad Marienberg in the west and Breitscheid in the east and lies in the parish of Willingen. The state boundary with Hesse runs along its eastern slopes and that with North Rhine-Westphalia lies a few kilometres to the north. Just under 3 km north-northeast is the tripoint of the states of Hesse, North Rhine-Westphalia and Rhineland-Palatinate. Several streams rise on its flanks, including the Nister (\"Große Nister\").\n\nThere used to be an observation tower on the Fuchskaute from where views of the Westerwald and other local countryside could be enjoyed.\n\nAmateur radio services operate two transmission towers on the south top of the Fuchskaute.\n\n"}
{"id": "20072066", "url": "https://en.wikipedia.org/wiki?curid=20072066", "title": "Hal Roth", "text": "Hal Roth\n\nHal Roth ( – ) was an American sailor and author. In 1971 he was awarded the Blue Water Medal of the Cruising Club of America. He died of lung cancer.\n\nHal Roth was born in Cleveland, Ohio, in 1927. He was an aviator during World War II and the Korean War. During the course of his lifetime, Roth was also an author, sailor, mountaineer, and photographer. He graduated from the University of California, Berkeley with a degree in Journalism, and became a free-lance writer and photographer.\n\nIn 1959, Roth met Margaret Hale-White from Oxford, England who was visiting a friend in San Francisco, California. Margaret was born in Bombay, India and was the daughter of an English engineer. According to Roth, she worked in Paris for six and a half years as a dual language secretary for the North Atlantic Treaty Organization (NATO). They married in 1960.\n\nRoth studied photography with Edward Weston and Ansel Adams. He was a member of the American Society of Magazine Photographers and worked from a base in Sausalito, California, producing imagery of life in the surrounding area of California during the late 1950s and into the late 1960s. Roth's free-lance works of note include magazine titles such as Colliers, Fortune, The Saturday Evening Post, and The New York Times. Themes of his work include: California landscapes and wildlife, San Francisco (including Fisherman's Wharf), Winter Olympics, Dr. Suess, and Native American wildland firefighters of the Southwest.\n\nHal was also engaged in photographic study of human life as represented by his \"Time and Place\" album and his Chinatown exhibit. In 1964, the San Francisco Museum of Art exhibited 40 of Roth's black and white photographic images titled \"The Faces of Chinatown.\" Roth's first published book, \"Pathway in the Sky\" (1965) displays his passion for the John Muir Trail and the Sierra Mountains. The associated images of the John Muir Trail also reflect people enjoying the trail and document its use in the early 1960s.\n\nEven though neither was a sailor, their friends shared a love of sailing and introduced them to the sport in 1962. The couple chartered a boat in the West Indies where they learned a great deal from the captain. Later, they chartered another boat in Greece, then took sailing lessons in Scotland. After purchasing a home in Sausalito in 1964, they took a trip (1966) north along the west coast and purchased a fiberglass Spencer 35, built in Vancouver, British Columbia and designed by John Brandlmayr in Seattle, Washington. They named her \"Whisper\", and sailed her home to California. The Roths began sailing on their own in 1966 and completed several voyages in \"Whisper\". Destinations included Japan, Aleutian Islands, Alaska, Canadian islands, Ecuador, Peru, Chile, Cape Horn, Argentina, Uruguay, Brazil, Mediterranean, and Canary Islands.\n\nThe success of his first book, about the John Muir Trail in the Sierra Nevada Mountains, prompted him and his wife to try the precarious worlds of adventuring and writing. They quit their jobs, and began a 19-month voyage around the Pacific in a sloop. Their vast journey culminated in the publication of his first sailing book, \"Two on a Big Ocean.\" He and his wife, Margaret, subsequently made a life of sailing and writing about it, including sailing around South America and a circumnavigation via Panama, the Torres Strait, and Suez.\n\nIn 1978, they relocated to Maine.\n\nThe couple sold \"Whisper\" and purchased the \"American Flag\" (later renamed \"Sebago\") and Roth then sailed solo in the Brin's or British Oxygen Company (BOC) Challenge Race of 1986-7. He completed the race 4th in his class of 14, taking 171 days. \"Chasing the Long Rainbow\" (1990) is his account of this BOC race. In 1990, he tried the race again in the same Santa Cruz 50 now named \"Sebago\" (his sponsor), but due to capsizing, the voyage took 211 days. \"Chasing the Wind\" (1994) is his account of the second race. In 1992, they sold \"Sebago\", purchased a Pretorien 35, named her \"Whisper\", and the couple spent two years together tracing Odysseus' voyage through the Mediterranean. \"We Followed Odysseus\", \"How to Sail Around the World\", and \"Handling Storms at Sea\" represent books that he wrote based on the couple's final unique voyages.\n\nRoth published hundreds of articles in his lifetime. Although, his book publications appear to be his dominate body of work and document the couple's voyages and growing knowledge of sailing. The 1972 account of their first circumnavigation of the Pacific Basin (1967-8) resulted in the publication \"Two on a Big Ocean\". The Blue Water Medal of the Cruising Club of America was awarded to the Hal Roth, and Margaret was noted as the sole crew, for this voyage. \"After 50,000 Miles\" (1977) describes technical aspects of sailing. The 1978 book \"Two against Cape Horn\" describes their journey from California to Maine via Cape Horn. \"Always a Distant Anchorage\" (1988) describes their four-year (1981–1985) circumnavigation west through the Panama Canal, Torres Strait, the Red Sea, and the Suez Canal.\n\nRoth recorded reminisces and continued to draft manuscripts throughout his life. His last two works, \"The Paradise Book\" and \"Graf Spee\" were completed but never published. He worked on these manuscripts during his later years and during his two and half year battle with lung cancer. He died October 18, 2008, while living in Maryland with his wife, Margaret, who survives him.\n\nIn 1971 Roth was awarded the Blue Water Medal of the Cruising Club of America in recognition of a cruise of around the Pacific Basin, with his wife as crew aboard their sloop, \"Whisper\".\n\n"}
{"id": "1101515", "url": "https://en.wikipedia.org/wiki?curid=1101515", "title": "Hercynite", "text": "Hercynite\n\nHercynite is a spinel mineral with the formula FeAlO.\n\nIt occurs in high-grade metamorphosed iron rich argillaceous sediments as well as in mafic and ultramafic igneous rocks. Due to its hardness it also is found in placers.\n\nIt was first described in 1847 and its name originates from the Latin name for the Harz, Silva Hercynia, where the species was first found.\n\nHercynite is a spinel of regular symmetry and normal cation distribution, but some disorder occurs in its structure. It consists of ferrous (Fe) ions and aluminium ions (Al), however some ferric ions (Fe) may be located in the structure of hercynite.\n"}
{"id": "40367657", "url": "https://en.wikipedia.org/wiki?curid=40367657", "title": "Hisaki (satellite)", "text": "Hisaki (satellite)\n\nHisaki, also known as the Spectroscopic Planet Observatory for Recognition of Interaction of Atmosphere (SPRINT-A) is a Japanese ultraviolet astronomy satellite operated by the Japan Aerospace Exploration Agency (JAXA). The first mission of the Small Scientific Satellite programme, it was launched in September 2013 on the maiden flight of the Epsilon rocket.\n\nHisaki remains operational as of 2017, and is performing joint observations with \"Juno\" orbiter.\n\nHisaki was named after a cape used by local fishermen to pray for safe travels in the eastern part of Kimotsuki, Kagoshima near the Uchinoura Space Center, but has the additional meaning of \"beyond the Sun\". An old name for the mission was EXCEED (Extreme Ultraviolet Spectroscope for Exospheric Dynamics).\n\nHisaki carries an extreme ultraviolet spectrometer which will be used to study the composition of\nthe atmospheres and the behavior of the magnetospheres of the planets of the Solar System. Designed for a one-year mission, Hisaki will be operated in a low Earth orbit with a perigee of , an apogee of , 31 degrees of inclination and a period of 106 minutes.\n\nAn Epsilon was used to launch Hisaki. Making its first flight, the four-stage Epsilon rocket flew from the Mu rocket launch complex at the Uchinoura Space Centre. The launch occurred at 05:00 UTC on 14 September 2013, following a scrubbed launch attempt on 27 August 2013. Following its successful insertion into orbit and deployment of its solar arrays, the satellite was renamed \"Hisaki\", having been designated SPRINT-A until that point.\n"}
{"id": "4319474", "url": "https://en.wikipedia.org/wiki?curid=4319474", "title": "International Year of Planet Earth", "text": "International Year of Planet Earth\n\nThe United Nations General Assembly declared 2008 as the International Year of Planet Earth to increase awareness of the importance of Earth sciences for the advancement of sustainable development. UNESCO was designated as the lead agency. The Year's activities spanned the three years 2006-2009.\n\nThe Year aimed to raise $20 million from industry and governments, of which half was to be spent on co-funding research, and half on \"outreach\" activities. It was intended to be the biggest ever international effort to promote the Earth sciences.\n\nApart from researchers, who were expected to benefit under the Year's Science Programme, the principal target groups for the Year's broader messages were:\n\n\nThe research themes of the year, set out in ten science prospectuses, were chosen for their societal relevance, multidisciplinary nature, and outreach potential. The Year had twelve founding partners, 23 associate partners, and was backed politically by 97 countries representing 87% of the world’s population. The Year was promoted politically at UNESCO and at the United Nations in New York by the People’s Republic of Tanzania.\n\nThe Year encouraged contributions from researchers within ten separate themes. The outreach programme worked in a similar way, receiving bids for support from individuals and organisations worldwide.\n\nThe Year's Project Leader was former IUGS President Professor Eduardo F J de Mulder. The Year's Science Committee was chaired by Professor Edward Derbyshire (Royal Holloway) and its Outreach Committee by Dr Ted Nield (Geological Society of London).\n\nThe International Year of Planet Earth project was initiated jointly by the International Union of Geological Sciences (IUGS) and the United Nations Educational Scientific and Cultural Organisation (UNESCO). The UN press release reads: \"By a draft on the International Year of Planet Earth, 2008, which the Committee approved without a vote on 11 November, the Assembly would declare 2008 the International Year of Planet Earth. It would also designate the United Nations Educational, Scientific and Cultural Organization (UNESCO) to organize activities to be undertaken during the Year, in collaboration with UNEP and other relevant United Nations bodies, the International Union of Geological Sciences and other Earth sciences societies and groups throughout the world. Also by that draft, the Assembly would encourage Member States, the United Nations system and other actors to use the Year to increase awareness of the importance of Earth sciences in achieving sustainable development and promoting local, national, regional and international action.\"\n\nThe project was backed by the following founding partners: \n\n\nThe Year was also supported by 23 Associate Partners, including all major international geoscientific and other relevant organisations:\n\nThe Year's stated objective was to:\n\nReduce risks for society caused by natural and human-induced hazards, reduce health problems by improving understanding of the medical aspects of Earth science, discover new natural resources and make them available in a sustainable manner, build safer structures and expand urban areas, utilizing natural subsurface conditions, determine the non-human factor in climatic change, enhance understanding of the occurrence of natural resources so as to contribute to efforts to reduce political tension, detect deep and poorly accessible groundwater resources, improve understanding of the evolution of life, increase interest in the Earth sciences in society at large, encourage more young people to study Earth science in university.\n\nResearch themes for the Year included: \n\n\nAs part of the IYPE legacy, 80 National and Regional IYPE Committees were set up to bring together key figures from various organisations into a single campaign dedicated to raising awareness of the Earth sciences among decision makers and the public.\n\nThe Young Earth-Science Initiative (YES) was also created, providing a platform for young professionals in the Earth sciences. Initiated by two Italian geoscientists, David Govoni and Luca Micucci, it started in 2007 and grew rapidly at the Global Launch Event of the IYPE in Paris in 2008, during which many young geoscientists were invited to participate. From there, the YES Initiative expanded, eventually adopting a formal structure, a network of supporting organisations (including IYPE) and an invitation by the Chinese government to host the first International YES Conference in October 2009 in Beijing. \n\nAn international collaborative project known as OneGeology was launched, aiming to bring together geological data from all nations into a digital database and thus transform them into a single computer language, providing free access to the online digital geological world map in the scale of 1:1 million. That initiative, spearheaded by Ian Jackson of the British Geological Survey, came under the IYPE banner in 2007.\n\n\n"}
{"id": "44647542", "url": "https://en.wikipedia.org/wiki?curid=44647542", "title": "Iron Sky: The Coming Race", "text": "Iron Sky: The Coming Race\n\nIron Sky: The Coming Race is a Finnish-German comic science fiction action film directed by Timo Vuorensola. It is the long-awaited sequel to Vuorensola's 2012 film \"Iron Sky\". The film was crowdfunded through Indiegogo. Release was originally announced for 14 February 2018, but had been postponed to 22 August 2018 in Finland followed by the rest of the world soon after, if not the same time. However, according to reports in the Finnish press the release date of 22 August 2018 has been cancelled. It was later announced that the film is scheduled to be released on 16 January 2019 as the Fan World Premiere in Helsinki, Finland. A major inspiration of the content (and the title) is the Vril conspiracy theory.\n\nOver 20 years after the nuclear war that had been triggered by the invasion of the Moon Nazis, Earth has become an inhospitable place. The last survivors have rallied together on the former Nazi moon base, with many refugees from Earth among them. Over the years a large human colony has formed, with its own fascist government and religions, including the Jobists, a cult that formed around the teachings of Steve Jobs and their leader (Tom Green).\n\nBut the aging base is deteriorating and due to the damage the moon received in the nuclear war, its time is running out. Obi Washington (Lara Rossi), the daughter of Renate Richter (Julia Dietze) and James Washington, finds out that there may be other survivors hidden in an underground city at the center of the earth with the means to save the base and decides to travel to earth to seek help.\n\nBut the survivors, she and a ragtag band of explorers find at the center of the earth are not even human—they stumble upon a prehuman world of dinosaurs ruled by the Vril, a race of reptilians led by Adolf Hitler in his true reptilian form among other former human rulers, all of whom were Reptilians under their human skins all along.\n\n\nOn 20 May 2012, Tero Kaukomaa, producer of the first film, announced that there were plans for a prequel and a sequel but refused to disclose details. In May 2013, Vuorensola announced that \"Iron Sky\" will have a sequel titled \"Iron Sky The Coming Race\". He also mentioned that unlike the first film, this installment will be completely funded by fans via Indiegogo, with an estimated budget of US$15 million. A promo video was shot for the 2014 Cannes Film Festival and the final draft of the script is scheduled to be published by the end of 2014. Filming is expected to begin in 2015. In July 2013, Vuorensola revealed Croatia as one of the proposed shooting locations. In February 2014, Dalan Musson signed in to write the screenplay. The Finnish Film Foundation and Medienboard Berlin-Brandenburg have come on board to finance the US$13 million project. On 5 November 2014, Energia Productions launched another crowdfunding campaign to raise US$500,000 before 20 December. At the closing of the campaign on 5 January, contributors pledged a grand total of US$560,949.\n\nOn 22 November 2014, Lloyd Kaufman of Troma Entertainment confirmed having a cameo role in the film.\n\nOn 18 September 2015, Vuorensola announced that filming will commence at AED Studios in Belgium.\n\nIn October 2016, Timo Vuorensola launched a new crowdfunding campaign to fund special effects for out-of-budget scenes that were in danger of being left out from the final cut of the movie. The scenes included the deaths of reptilian Margaret Thatcher and Pope Urban II.\n\nOn 6 November 2014, the official \"Iron Sky\" YouTube channel published the film's first teaser trailer. On 1 December, two more teasers were released, the first featuring Kari Ketonen as Vladimir Putin and the second featuring Jukka Hilden as Jesus Christ.\n\nThe film is due to be released on 16 January 2019 in Finland.\n\nLike its predecessor, the movie refers to several motifs of post-war Esoteric Nazism, such as the Hollow Earth theory. The movie's title is most likely a reference to Edward Bulwer-Lytton's novel \"The Coming Race\" (1871) that is commonly regarded as the origin of the so-called Vril myth. The film teaser features the Vril symbol that was designed by the Tempelhofgesellschaft in the 1990s.\n\nIn the summer of 2017 a number of original \"Iron Sky\" VFX artists filed a suit in Finland against Iron Sky Universe Oy and Blind Spot Pictures Oy. \"The plaintiffs claim their creative contribution to the Iron Sky franchise is such that they should also be considered as joint copyright holders of the original movie.\" In May 2018, the Finnish market court dismissed the case, finding that the artists have no copyright claim to \"Iron Sky\" nor its sequel. The court awarded copyright to the artists only in the case of a Japanese ship design used in the film, but ruled that the copyright had legally transferred to Blind Spot Pictures.\n\n"}
{"id": "12804696", "url": "https://en.wikipedia.org/wiki?curid=12804696", "title": "Jaramillo reversal", "text": "Jaramillo reversal\n\nThe Jaramillo reversal was a reversal and excursion of the Earth's magnetic field that occurred approximately one million years ago. In the geological time scale it was a \"short-term\" positive reversal in the then-dominant Matuyama reversed magnetic chronozone; its beginning is widely dated to 990,000 years before the present (BP), and its end to 950,000 BP (though an alternative date of 1.07 million years ago to 990,000 is also found in the scientific literature).\n\nThe causes and mechanisms of short-term reversals and excursions like the Jaramillo, as well as the major field reversals like the Brunhes–Matuyama reversal, are subjects of study and dispute among researchers. One theory associates the Jaramillo with the Bosumtwi impact event, as evidenced by a tektite strewnfield in the Ivory Coast, though this hypothesis has been claimed as \"highly speculative\" and \"refuted\".\n\n"}
{"id": "28818398", "url": "https://en.wikipedia.org/wiki?curid=28818398", "title": "Jet Propulsion Laboratory Science Division", "text": "Jet Propulsion Laboratory Science Division\n\nThe Jet Propulsion Laboratory (JPL) Science Division investigates physical and chemical processes on the Earth, in the Solar System, and throughout the universe. Explorations of space and terrestrial processes lead to understanding of the universe. Methods for accomplishing scientific work pertaining to the nature of the Earth, the Solar System, the galaxy, etc., are addressed in the JPL Science Division. Techniques in both physical and life sciences are utilized.\n\nResearch areas include studying the nature of the Martian surface, the causes and mitigation of ozone depletion and global warming in Earth's atmosphere, the search for life in and the nature and evolution of the universe. These are significant issues related to NASA's mission.\n\nTheoretical and experimental studies are conducted which lead to new missions. They are engaged in the development of new instrumentation and in the analysis of data, publishing new scientific knowledge, and in the communication of that knowledge to the general public.\n\nNot all science at the Jet Propulsion Laboratory is contained within the Science Division. Approximately 30% of JPL scientists are embedded in other divisions.\n\nJPL's charter is to conduct robotic space missions for NASA, to explore planetary systems, understand the origin and evolution of the universe and make critical measurements to understand the Earth, which leads to its protection. This is accomplished by developing multidisciplinary capabilities in engineering, science and technology. Research in space science, as well as advancing technologies, produces the ability to implement missions for NASA.\n\nThe division's science, technology and engineering research covers many areas of planetary, astrophysics and Earth science, both as basic research leading to new observations and mission concepts, as well as research based on the data acquired by JPL flight projects. Technology research covers areas ranging from robotic systems, a range of in-situ and remote sensing instruments, deep space communications and navigation, information systems, precision flying and planetary protection and survivability.\n"}
{"id": "1833615", "url": "https://en.wikipedia.org/wiki?curid=1833615", "title": "Kalpa Sūtra", "text": "Kalpa Sūtra\n\nThe Kalpa Sūtra () is a Jain text containing the biographies of the Jain Tirthankaras, notably Parshvanatha and Mahavira. Traditionally ascribed to Bhadrabahu, which would place it in the 4th century BCE., it was probably put to writing only after 980 or 993 years after the \"Nirvana\"(\"Moksha\") of Mahavira. \n\nWithin the six sections of the Jain literary corpus belonging to the Svetambara school, it is classed as one of the Cheda Sūtras. This Sutra contains detailed life histories and, from the mid-15th century, was frequently illustrated with miniature painting. The oldest surviving copies are written on paper in western India in the 14th century.\n\nKalpasutra is ascribed to Bhadrabahu, traditionally said to have composed it some 150 years after the \"Nirvāṇa\" (death) of Mahavira. It was compiled probably during the reign of Dhruvasena, 980 or 993 years after the \"Nirvana\" of Mahavira.\n\nThe book is read and illustrated in an eight-day-long festival of Paryushan by Jain monks for general people. Only Monks can read this scriptures as in Jainism, this book has very high spiritual values.\n\n\n\n"}
{"id": "1083982", "url": "https://en.wikipedia.org/wiki?curid=1083982", "title": "Laser Doppler velocimetry", "text": "Laser Doppler velocimetry\n\nLaser Doppler velocimetry (LDV), also known as laser Doppler anemometry (LDA), is the technique of using the Doppler shift in a laser beam to measure the velocity in transparent or semi-transparent fluid flows, or the linear or vibratory motion of opaque, reflecting, surfaces. The measurement with LDA is absolute, linear with velocity and requires no pre-calibration.\nWith the development of the helium–neon laser (He-Ne) at the Bell Telephone Laboratories in 1962, the optics community had available a source of continuous wave electromagnetic radiation highly concentrated at a wavelength of 632.8 nanometers (nm), in the red portion of the visible spectrum. It was soon shown fluid flow measurement could be made from the Doppler effect on a He-Ne beam scattered by very small polystyrene spheres entrained in the fluid.\n\nAt the Research Laboratories of Brown Engineering Company (later Teledyne Brown Engineering), this phenomenon was used in developing the first laser Doppler flowmeter using heterodyne signal processing.\n\nThe instrument was soon called the laser Doppler velocimeter (LDV) and the technique laser Doppler velocimetry, also abbreviated LDV. Another application name is laser Doppler anemometry (LDA). Early LDV applications ranged from measuring and mapping the exhaust from rocket engines with speeds up to 1000 m/s to determining flow in a near-surface blood artery. A variety of similar instruments were developed for solid-surface monitoring, with applications ranging from measuring product speeds in production lines of paper and steel mills, to measuring vibration frequency and amplitude of surfaces.\n\nDoppler velocimeters work on the priniciple of Optical heterodyne detection.\n\nIn its simplest and most presently used form, LDV crosses two beams of collimated, monochromatic, and coherent laser light in the flow of the fluid being measured. The two beams are usually obtained by splitting a single beam, thus ensuring coherence between the two. Lasers with wavelengths in the visible spectrum (390–750 nm) are commonly used; these are typically He-Ne, Argon ion, or laser diode, allowing the beam path to be observed. A transmitting optics focuses the beams to intersect at their waists (the focal point of a laser beam), where they interfere and generate a set of straight fringes. As particles (either naturally occurring or induced) entrained in the fluid pass through the fringes, they reflect light that is then collected by a receiving optics and focused on a photodetector (typically an avalanche photodiode).\n\nThe reflected light fluctuates in intensity, the frequency of which is equivalent to the Doppler shift between the incident and scattered light, and is thus proportional to the component of particle velocity which lies in the plane of two laser beams. If the sensor is aligned to the flow such that the fringes are perpendicular to the flow direction, the electrical signal from the photodetector will then be proportional to the full particle velocity. By combining three devices (e.g.; He-Ne, Argon ion, and laser diode) with different wavelengths, all three flow velocity components can be simultaneously measured.\n\nAnother form of LDV, particularly used in early device developments, has a completely different approach akin to an interferometer. The sensor also splits the laser beam into two parts; one (the measurement beam) is focused into the flow and the second (the reference beam) passes outside the flow. A receiving optics provides a path that intersects the measurement beam, forming a small volume. Particles passing through this volume will scatter light from the measurement beam with a Doppler shift; a portion of this light is collected by the receiving optics and transferred to the photodetector. The reference beam is also sent to the photodetector where optical heterodyne detection produces an electrical signal proportional to the Doppler shift, by which the particle velocity component perpendicular to the plane of the beams can be determined.\n\nSimilar arrangements using optical heterodyning are also used in laser Doppler sensors for measuring the linear velocity of solids and for measuring vibrations of surfaces; the latter sensor is usually called a laser Doppler vibrometer, also abbreviated LDV.\n\nIn the decades since the LDV was first introduced, there has been a wide variety of laser Doppler sensors developed and applied.\n\nLaser Doppler velocimetry is often chosen over other forms of flow measurement because the equipment can be outside of the flow being measured and therefore has no effect on the flow. Some typical applications include the following:\nOne disadvantage has been that LDV sensors are range-dependent; they have to be calibrated minutely and the distances where they measure has to be precisely defined. This distance restriction has recently been at least partially overcome with a new sensor that is range independent.\n\nLaser Doppler velocimetry can be useful in automation, which includes the flow examples above. It can also be used to measure the speed of solid objects, like conveyor belts. This can be useful in situations where attaching a rotary encoder (or a different mechanical speed measurement device) to the conveyor belt is impossible or impractical.\n\nLaser Doppler velocimetry is used in hemodynamics research as a technique to partially quantify blood flow in human tissues such as skin. Within the clinical environment, the technology is often referred to as laser Doppler flowmetry (LDF). The beam from a low-power laser (usually a laser diode) penetrates the skin sufficiently to be scattered with a Doppler shift by the red blood cells and return to be concentrated on a detector. These measurements are useful to monitor the effect of exercise, drug treatments, environmental, or physical manipulations on targeted micro-sized vascular areas.\n\nThe laser Doppler vibrometer is being used in clinical otology for the measurement of tympanic membrane (eardrum), malleus (hammer), and prosthesis head displacement in response to sound inputs of 80- to 100-dB sound-pressure level. It also has potential use in the operating room to perform measurements of prosthesis and stapes (stirrup) displacement.\n\nThe Autonomous Landing Hazard Avoidance Technology used in NASA's Project Morpheus lunar lander to automatically find a safe landing place contains a lidar Doppler velocimeter that measures the vehicle's altitude and velocity. The AGM-129 ACM cruise missile uses laser doppler velocimeter for precise terminal guidance.\n\n\n"}
{"id": "2445900", "url": "https://en.wikipedia.org/wiki?curid=2445900", "title": "List of Michigan state forests", "text": "List of Michigan state forests\n\nThe following is a list of state forests in the U.S. state of Michigan. The Michigan Department of Natural Resources manages the largest state forest system in the nation (3.9 million acres (16,000 km²)), administered by the Forest Resources Division. \n\nIn literature describing recreational uses of state forest lands, six state forests are identified. However, state forest lands are administered by fifteen DNR Forest Management Units (FMU). There is no state forest land in the southern portion of the Lower Peninsula. \n\n\n\n\n"}
{"id": "11097691", "url": "https://en.wikipedia.org/wiki?curid=11097691", "title": "List of NGC objects (3001–4000)", "text": "List of NGC objects (3001–4000)\n\nThis is a list of NGC objects 3001–4000 from the New General Catalogue (NGC). The astronomical catalogue is composed mainly of star clusters, nebulae, and galaxies. Other objects in the catalogue can be found in the other subpages of the list of NGC objects.\n\nThe constellation information in these tables is taken from \"The Complete New General Catalogue and Index Catalogue of Nebulae and Star Clusters by J. L. E. Dreyer\", which was accessed using the \"VizieR Service\". Galaxy types are identified using the \"NASA/IPAC Extragalactic Database\". The other data of these tables are from the SIMBAD Astronomical Database unless otherwise stated.\n"}
{"id": "5870851", "url": "https://en.wikipedia.org/wiki?curid=5870851", "title": "List of Sites of Special Scientific Interest in Northumberland", "text": "List of Sites of Special Scientific Interest in Northumberland\n\nThis is a list of Sites of Special Scientific Interest (SSSIs) in Northumberland, England.\n\nEnglish Nature, the designating body for SSSIs in England, uses the 1974-1996 county system, and this list follows the same approach. Some sites one may expect to find here could therefore be in the County Durham or Tyne and Wear lists.\n\nFor other counties, see List of SSSIs by Area of Search.\n"}
{"id": "44308948", "url": "https://en.wikipedia.org/wiki?curid=44308948", "title": "List of rare breed livestock charities", "text": "List of rare breed livestock charities\n\nRare breed livestock consists of breeds of domesticated animal, generally developed for use in agriculture, which are considered by one or more national charity as being endangered or threatened. A number of societies exist worldwide to preserve these animals.\n\n\n\n\n\n\n"}
{"id": "35629344", "url": "https://en.wikipedia.org/wiki?curid=35629344", "title": "List of rivers of the Gambia", "text": "List of rivers of the Gambia\n\nThis is a list of rivers in the Gambia. This list is arranged by drainage basin, with respective tributaries indented under each larger stream's name.\n\n\n"}
{"id": "8591668", "url": "https://en.wikipedia.org/wiki?curid=8591668", "title": "List of stars in Eridanus", "text": "List of stars in Eridanus\n\nThis is the list of notable stars in the constellation Eridanus, sorted by decreasing brightness.\n\n\n"}
{"id": "49674777", "url": "https://en.wikipedia.org/wiki?curid=49674777", "title": "List of the major 4000-meter summits of California", "text": "List of the major 4000-meter summits of California\n\nThe following sortable table comprises the 16 mountain peaks of the U.S. State of California with at least of topographic elevation and at least of topographic prominence.\n\nTopographic elevation is the vertical distance above the reference geoid, a mathematical model of the Earth's sea level as an equipotential gravitational surface. The topographic prominence of a summit is the elevation difference between that summit and the highest or key col to a higher summit. The topographic isolation of a summit is the minimum great-circle distance to a point of equal elevation.\n\nThis article defines a significant summit as a summit with at least of topographic prominence, and a major summit as a summit with at least of topographic prominence. An ultra-prominent summit is a summit with at least of topographic prominence. There are 126 ultra-prominent summits in the United States.\n\nAll elevations include an adjustment from the National Geodetic Vertical Datum of 1929 (NGVD 29) to the North American Vertical Datum of 1988 (NAVD 88). For further information, please see this United States National Geodetic Survey note.\n\nIf an elevation or prominence is calculated as a range of values, the arithmetic mean is shown.\n\n\n"}
{"id": "662229", "url": "https://en.wikipedia.org/wiki?curid=662229", "title": "MOST (satellite)", "text": "MOST (satellite)\n\nThe Microvariability and Oscillations of STars telescope, better known simply as MOST, is Canada's first space telescope. Up until nearly 10 years after its launch it was also the smallest space telescope in orbit (for which its creators nicknamed it the \"Humble Space Telescope\", in reference to one of the largest, the Hubble). MOST is the first spacecraft dedicated to the study of asteroseismology, subsequently followed by the now-completed COROT and Kepler missions. It was also the first Canadian science satellite launched since ISIS II, 32 years previously.\n\nAs its name suggests, its primary mission is to monitor variations in star light, which it does by observing a single target for a long period of time (up to 60 days). Typically, larger space telescopes cannot afford to remain focused on a single target for so long due to the demand for their resources.\n\nAt 53 kg (117 pounds) x wide and tall and deep, it is the size and weight of a small chest or an extra-large suitcase filled with electronics. This places it in the microsatellite category.\n\nMOST was developed as a joint effort of the Canadian Space Agency, Dynacon Enterprises Limited (now Microsatellite Systems Canada Inc), the Space Flight Laboratory (SFL) at the University of Toronto Institute for Aerospace Studies, and the University of British Columbia. Led by Principal Investigator Jaymie Matthews, the MOST science team's plan is to use observations from MOST to use asteroseismology to help date the age of the universe, and to search for visible-light signatures from extrasolar planets.\n\nMOST features an instrument comprising a visible-light dual-CCD camera, fed by a 15-cm aperture Maksutov telescope. One CCD gathers science images, while the other provides images used by star-tracking software that, along with a set of four reaction wheels (computer-controlled motorized flywheels that are similar to gyroscopes) maintain pointing with an error of less than 1 arc-second, better pointing by far than any other microsatellite to date.\n\nThe design of the rest of MOST was inspired by and based on microsatellite bus designs pioneered by AMSAT, and first brought to commercial viability by the microsatellite company SSTL (based at the University of Surrey in the UK); during the early stages of MOST development, the core group of AMSAT microsatellite satellite designers advised and mentored the MOST satellite design team, via a know-how transfer arrangement with UTIAS. This approach to satellite design is notable for making use of commercial-grade electronics, along with a \"small team,\" \"early prototyping\" engineering development approach rather different from that used in most other space-engineering programs, to achieve relatively very low costs: MOST's life-cycle cost (design, build, launch and operate) is less than $10 million in Canadian funds (about 7 million Euros or 6 million USD, at exchange rates at time of launch).\n\nDevelopment of the satellite was managed by the Canadian Space Agency's Space Science Branch, and was funded under its Small Payloads Program; its operations are currently (as of 2012) managed by the CSA's Space Exploration Branch. It is operated by SFL (where the primary MOST ground station is located) jointly with Microsat Systems Canada Inc. (since the sale of Dynacon's space division to MSCI in 2008). As of ten years after launch, despite failures of two of its components (one of the four reaction wheels and one of the two CCD driver boards), the satellite is still operating well, as a result of both on-going on-board software upgrades as well as built-in hardware redundancy, allowing improvements to performance and to reconfigure around failed hardware units.\n\nIn 2008, the MOST Satellite Project Team won the Canadian Aeronautics and Space Institute's Alouette Award, which recognizes outstanding contributions to advancement in Canadian space technology, applications, science or engineering.\n\nOn 30 April 2014, the Canadian Space Agency announced that funding to continue operating MOST would be withdrawn as of 9 September 2014, apparently as a result of funding cuts to the Canadian Space Agency's budget by the Harper government, despite the fact that the satellite continues to be fully operational and capable of making on-going science observations. P.I. Jaymie Matthews responded by saying that \"he will consider all options to keep the satellite in orbit, and that includes a direct appeal to the public.\"\n\nIn October 2014, the MOST Satellite was acquired by Microsatellite Systems Canada Inc. (MSCI), who has operated the satellite since launch in 2003. MSCI engineers have monitored the satellite's health over the years and have performed numerous upgrades to the software. MSCI has commenced commercial operation of the satellite and offers a variety of potential uses including continuing the original MOST mission in partnership with Dr. Matthews, but also other planetary studies, attitude control system algorithm R&D, and Earth observation. MSCI is also the prime contractor for the NEOSSat spacecraft.\n\nThe MOST team has reported a number of discoveries. In 2004 they reported that the star Procyon does not oscillate to the extent that had been expected, although this has been disputed.\nIn 2006 observations revealed a previously unknown class of variable stars, the \"slowly pulsating B supergiants\" (\"SPBsg\").\nIn 2011, MOST detected transits by exoplanet 55 Cancri e of its primary star, based on two weeks of nearly continuous photometric monitoring, confirming an earlier detection of this planet, and allowing investigations into the planet's composition.\nFurther reports of discoveries are listed on the MOST science page at the University of British Columbia.\n\n\n\n"}
{"id": "7896131", "url": "https://en.wikipedia.org/wiki?curid=7896131", "title": "Mineralization (soil science)", "text": "Mineralization (soil science)\n\nMineralization in soil science is the decomposition, i. e. oxidation, of the chemical compounds in organic matter, by which the nutrients in those compounds are released in soluble inorganic forms that may be available to plants. \nMineralization is the opposite of immobilization.\n\nMineralization increases the bioavailability of the nutrients that were in the decomposing organic compounds, most notably, because of their quantities, nitrogen, phosphorus, and sulphur. Whether the decomposition of an organic compound will result in mineralization or immobilization is dependent on its concentration proportionate to that of the carbon in the organic matter. If the concentration of a specific element exceeds the needs of the decomposer for biosynthesis or storage then it will mineralize.\n\nWhether nitrogen mineralizes or immobilizes depends on the carbon-to-nitrogen ratio (C:N ratio) of the decomposing organic matter. In general organic matter contacting soil has too little nitrogen to support the biosynthetic needs of the decomposing soil microbial population. If the C:N ratio of the decomposing organic matter is above circa 30:1 then the decomposing microbes may absorb nitrogen in mineral form as, e. g., ammonium or nitrates. This mineral nitrogen is said to be immobilized. This may reduce the concentration of inorganic nitrogen in the soil and thus the nitrogen available to plants.\n\nAs carbon dioxide is released during the generation of energy in decomposition, a process denominated \"catabolism\", the C:N ratio of the organic matter decreases. When the C:N ratio is less than circa 25:1, further decomposition causes mineralization by the simultaneous release of inorganic nitrogen as ammonium. When the decomposition of organic matter is complete, the mineralized nitrogen therefrom adds to that already present in the soil, and therefore increases the total mineral nitrogen in the soil.\n\n"}
{"id": "28501590", "url": "https://en.wikipedia.org/wiki?curid=28501590", "title": "Muskwa-Slave Lake forests", "text": "Muskwa-Slave Lake forests\n\nThe Muskwa-Slave Lake forests is a taiga ecoregion in Canada.\n\nThis ecoregion is located in northwestern Alberta, northeastern British Columbia and a large portion of the southwestern Northwest Territories around the Mackenzie River valley and the Great Slave Lake for which the ecoregion is named. Specific areas include the boreal forest to the east of the MacKenzie (between Mackenzie and Franklin Mountains; the land along the Horn River west to the Mackenzie; the Liard River basin; and the Caribou Mountains in north-central Alberta. \n\nThe landscape consists of wide, flat plains and lowlands broken by low mountains and plateaus, such as the Caribou Mountains. Almost half of the area is covered in wetlands and bogs such as Zama Lake in Alberta. The ecoregion is in the zone of discontinuous permafrost and has a subarctic climate, with summer temperatures averaging around , and winter temperatures averaging from to . Annual average temperatures are between and . Precipitation is moderately low, averaging between and .\n\nVegetation consists mainly of dense forests of trembling aspen (\"Populus tremuloides\"), white spruce (\"Picea glauca\") and balsam fir (\"Abies balsamea\"), with smaller populations of balsam poplar (\"Populus balsamifera\"), black spruce (\"Picea mariana\") and birch.\n\nThis ecoregion is rich in wildlife including large herds (numbering in the thousands) of Migratory Woodland Caribou (\"Rangifer tarandus caribou\") and other large mammals such as moose (\"Alces alces\"), Wood Bison (\"Bison bison athabascae\") (Wood Buffalo National Park is in this region), elk (\"Cervus canadensis\") and mule deer (\"Odocoileus hemonius\") along with smaller animals such as snowshoe hare (\"Lepus americanus\"). The predators that feed on all this wildlife include Canada Lynx (\"Lynx canadensis\"), grizzly bear (\"Ursos arctos horriblus\"), American black bear (\"Ursus americanus\") and gray wolf (\"Canis lupus\"). Birds include the waterfowl of the many wetlands along with prairie birds such as grouse.\n\nThis ecoregion is well preserved, with an estimated 75% intact. Protected areas include western parts of Wood Buffalo National Park in Northern Alberta the south-central Northwest Territories, and Maxhamish Lake Provincial Park and Protected Area in northeastern British Columbia. Logging is the greatest threat to the region's ecological integrity along with potential for mining, the effect of the Mackenzie Highway and oil pipelines.\n"}
{"id": "26576301", "url": "https://en.wikipedia.org/wiki?curid=26576301", "title": "National Institute of Aerospace", "text": "National Institute of Aerospace\n\nThe National Institute of Aerospace (NIA) is a non-profit research and graduate education institute headquartered in Hampton, Virginia, near NASA's Langley Research Center. NIA's mission is to conduct leading-edge aerospace and atmospheric research, develop new technologies for the nation and help inspire the next generation of scientists and engineers.\n\nNIA was formed in 2002 by a consortium of research universities to ensure a national capability to support NASA's mission by expanding collaboration with academia and leveraging expertise inside and outside NASA. NIA performs research in a broad range of disciplines including space exploration, systems engineering, nanoscale materials science, flight systems, aerodynamics, air traffic management, aviation safety, planetary and space science, and global climate change.\n\nNIA is headed by Dr. Douglas O. Stanley, who was named interim to the post of president and executive director in July 2012. He succeeded Dr. Robert Lindberg, who became the first President and Executive Director in October 2003.\n\nAffiliates\n\nAbout 50 full-time researchers are working on projects at NIA.\n\nNIA conducts a broad range of scientific and engineering research sponsored by NASA, other government agencies and the aerospace industry. This work is performed by resident scientists and engineers, faculty, students and consultants in principle areas of investigation to include space exploration, systems engineering, materials science, flight systems, aerodynamics, air traffic management, aviation safety, planetary and space science, and global climate change.\n\nResearch programs, led by faculty in residence at NIA, serve as the core of the Institute’s academic research program. Through NIA’s University Research Program, faculty and students at NIA member universities collaborate with NASA research leaders in fundamental investigations in aerospace, mechanical, electrical, and systems engineering; materials science; applied mathematics, meteorology and other related fields.\n\nNIA also collaborate with other research institutions worldwide, including universities, government laboratories, industry and other non-profit institutes to accomplish its research objectives. NIA conducts applied research with and for the aerospace industry. Through NIA, industrial partners can gain access to LaRC personnel, facilities and intellectual property.\n\nResearch projects include:\n\n\nNIA's graduate program offers M.S. and Ph.D. degrees in the fields of aerospace engineering, mechanical engineering, engineering mechanics, engineering physics, materials science and engineering, electrical engineering, ocean engineering and systems engineering. Degrees are issued through its university partners: Georgia Tech, Hampton University, North Carolina A&T State University, North Carolina State University, the University of Maryland, the University of Virginia, Virginia Tech, Old Dominion University, and the College of William & Mary. Classes are offered on site and through distance education to about 40 graduate students in residence. (Students in residence at NIA are considered in residence at their home university.) NIA also provides Langley Research Center employees the opportunity to pursue a PhD while working.\n\nThe faculty comprises Langley Professors who share their time between NIA and their home schools:\n\nThe NIA Research and Innovation Laboratories opened in early 2012. The building, located at 1100 Exploration Way in Hampton, Virginia consists of a 14-laboratory, 60,000-square-foot building that houses research and development facilities including a wind tunnel, an unmanned aerial vehicles structures lab and a boron nanotube development lab, among other facilities. The new facility also host the Peninsula Technology Incubator (PTI), a subsidiary of NIA, which encourages entrepreneurship.\n\n\n"}
{"id": "17502363", "url": "https://en.wikipedia.org/wiki?curid=17502363", "title": "Nato wood", "text": "Nato wood\n\nNato wood is a collective name for wood from \"Mora\" trees (the best-known species are \"Mora excelsa\" (Mora) and \"Mora gonggrijpii\" (Morabukea). This should not be confused with Nyatoh (an Asian hardwood from the Sapotaceae family with a very similar look and characteristic to Honduras Mahogany, though totally unrelated).\n\nMora may vary in appearance, with reddish brown being the dominant color, but with varying shades and often with darker or lighter streaks. It has a similar appearance to mahogany, and as such it is often referred to as \"eastern mahogany\". Despite this, the two are unrelated. The heartwood is light to medium reddish brown. Wide pale yellow-brown sapwood is clearly demarcated from heartwood. It has a straight to interlocked grain, with a medium to coarse texture and good natural luster. The wood is dense and it is not particularly easy to dry or to work, although it finishes well. Mora wood species are not listed in the citeS Appendices or on the IUCN Red List of Threatened Species.\n\nBecause of its similar properties to more traditional tone woods like mahogany, many guitar manufacturers use nato in their construction. Epiphone, BC Rich, Eastwood, and Japan-based manufacturers Yamaha and Takamine are amongst them.\n\nThe wood is available in large solid cuts and is well above average in properties such as resistance to wear, strength and durability, making it an excellent candidate for heavy construction, industrial flooring, railroad ties and boatbuilding.\n\n"}
{"id": "12746283", "url": "https://en.wikipedia.org/wiki?curid=12746283", "title": "Neolithic Subpluvial", "text": "Neolithic Subpluvial\n\nThe Neolithic Subpluvial, or the Holocene Wet Phase, was an extended period (from about 7500–7000 BCE to about 3500–3000 BCE) of wet and rainy conditions in the climate history of northern Africa. It was both preceded and followed by much drier periods.\n\nThe Neolithic Subpluvial was the most recent of a number of periods of \"Wet Sahara\" or \"Green Sahara\", during which the Sahara region was much moister and supported a richer biota and human population than the present-day desert.\n\nThe Neolithic Subpluvial began during the 7th millennium BCE and was strong for about 2,000 years; it waned over time and ended after the 5.9 kiloyear event (3900 BCE). Then the drier conditions that prevailed prior to the Neolithic Subpluvial returned; desertification advanced, and the Sahara Desert formed (or re-formed). Arid conditions have continued through to the present day.\n\nDuring the Neolithic Subpluvial, large areas of North, Central, and East Africa had hydrographic profiles significantly different from later norms. Existing lakes had surfaces tens of meters higher than today, sometimes with alternative drainages: Lake Turkana, in present-day Kenya, drained into the Nile River basin. Lake Chad reached a maximum extent of some 400,000 square kilometers in surface area, larger than the modern Caspian Sea, with a surface level about 30 meters (100 feet) higher than its twentieth-century average. Some shallower lakes and river systems existed in the subpluvial era that later disappeared entirely, and are detectable today only via radar and satellite imagery.\n\nThe event is argued to have ended quickly in some places and more slowly in others. Local feedbacks between vegetation and the atmosphere may explain the variability in the records. However, the agents of initial devegetation are unknown since they seem to occur rapidly in some areas and slowly in others, out of phase with changing orbital precession. The introduction of domesticated animals correlates in many places to a rapid change from grassland to scrubland vegetation, and it is hypothesized that Neolithic humans may have potentially played a role in stripping vegetation from the landscape, which induced cascading effects to the ecosystem and climate. For thousands of years, the Sahara ecosystem supported rich and varied flora and fauna, as well as large populations of pastoralists. Researchers in 2018 demonstrated through a climate-vegetation model that abundant biota persisted longer than expected in regions where ancient pastoral societies once flourished, concluding that pastoral environment management contributed to regional delays of up to 500 years in the advancement of the Sahara's desertification between 6000 and 7000 years ago.\n\nNorth Africa enjoyed a fertile climate during the subpluvial era; what is now the Sahara supported a savanna type of ecosystem, with elephant, giraffe, and other grassland and woodland animals now typical of the Sahel region south of the desert, along with some now extinct megafauna such as \"Sivatherium\" and \"Pelorovis\". Historian and Africanist Roland Oliver has described the scene as follows:\n[In] the highlands of the central Sahara Desert beyond the Libyan Desert... in the great massifs of the Tibesti and the Hoggar, the mountaintops, today bare rock, were covered at this period with forests of oak and walnut, lime, alder and elm. The lower slopes, together with those of the supporting bastions — the Tassili and the Acacus to the north, Ennedi and Air to the south — carried olive, juniper and Aleppo pine. In the valleys, perennially flowing rivers teemed with fish and were bordered by seed-bearing grasslands.\n\nClement and fertile conditions during the Neolithic Subpluvial supported increased human settlement of the Nile Valley in Egypt, as well as neolithic societies in Sudan and throughout the present-day Sahara. Cultures producing rock art (notably that at Tassili n'Ajjer in southeastern Algeria) flourished during this period.\n\nThe practical consequences of these changes took the form of increased abundance of fish, waterfowl, freshwater mollusks, rodents, hippopotamus and crocodiles. The riches of this increased aquatic biomass were exploited by humans with rafts, boats, weirs, traps, harpoons, nets, hooks, lines and sinkers. This \"riparian\" (river) way of life supported much larger communities than could that of typical hunting bands. These changes, along with the local development of pottery (whereby liquids could be both stored and heated) resulted in a \"culinary revolution\" consisting of soup, fish stew and porridge. The last mentioned implies the cooking of gathered cereals.\n\nThe classic account of the riparian lifestyle of this period comes from investigations in Sudan during World War II by British archeologist Anthony Arkell. Arkell's report described a Late Stone Age settlement on a sandbank of the Blue Nile which was then about higher than its present flood stage. The countryside was clearly savanna, not the present-day desert, as evidenced by the bones of the most common species found in the middens — antelope, which require large expanses of seed-bearing grasses. These people probably lived mainly on fish, however, and Arkell concluded, based on the totality of the evidence, that rainfall at the time was at least three times that of today. The physical characteristics derived from skeletal remains suggested that these people were related to modern Nilotic peoples, such as the Nuer and Dinka. Subsequent radiocarbon dating firmly established Arkell's site to between 7000 and 5000 BCE. Based on common patterns at his site and at French-excavated sites already reported from Chad, Mali and Niger (e.g., bone harpoons and a characteristic \"wavy line\" pottery), Arkell inferred \"a common fishing and hunting culture spread by negroid people right across Africa at about the latitude of Khartoum at a time when the climate was so different that it was not desert.\" The originators of the wavy line pottery are as yet unidentified.\n\nIn the 1960s, the archeologist Gabriel Camps investigated the remains of a hunting and fishing community dating from about 6700 BCE in southern Algeria. These pottery-making people (the \"wavy line\" motif again) were black African rather than Mediterranean in origin and (according to Camps) evidenced definite signs of deliberate cultivation of grain crops as opposed to simply the gathering of wild grains. Later studies at the site have shown the culture to be hunter-gatherers and not agriculturalists, as all the grains were morphologically wild, and the society was not sedentary.\n\nHuman remains were found by archaeologists in 2000 at a site known as Gobero in the Ténéré Desert of northeastern Niger. The Gobero finds represent a uniquely preserved record of human habitation and burials from what is now called the Kiffian (7700–6200 BCE) and the Tenerian (5200–2500 BCE) cultures.\n\nDotted wavy line pottery and fishing cultures have also been located in the Lake Turkana region in poorly dated contexts. By 3000 BCE, it does not appear that the Turkana Basin was populated with harpoon and dotted wavy line pottery users, but fishing remained an important part of peoples' diets into the late Holocene.\n\n\n"}
{"id": "77438", "url": "https://en.wikipedia.org/wiki?curid=77438", "title": "Nephele", "text": "Nephele\n\nIn Greek mythology, Nephele (; , from νέφος \"nephos\" \"cloud\"; Latinized to \"Nubes\") was a cloud nymph who figured prominently in the story of Phrixus and Helle. Nephele was also the goddess of hospitality.\n\nGreek myth also has it that Nephele is the cloud whom Zeus created in the image of Hera to trick Ixion to test his integrity after displaying his lust for Hera during a feast as a guest of Zeus. Ixion failed in restraining his lust for Hera, thus fathering the Centaurs.\n\nNephele married Athamas, but he divorced her for Ino. Phrixus and Helle, the son and daughter of Athamas and Nephele, were hated by their stepmother, Ino. Ino hatched a devious plot to get rid of the twins, roasting all the town's crop seeds so they would not grow. The local farmers, frightened of famine, asked a nearby oracle for assistance. Ino bribed the men sent to the oracle to lie and tell the others that the oracle required the sacrifice of Phrixus. Before he was killed though, Phrixus and Helle were rescued by a flying golden ram sent by Nephele, their natural mother.\n\nPhrixus and Helle were instructed to not look down to Earth for the duration of their flight. Helle, though, did look down, and fell off the ram into the Hellespont (which was named after her, meaning \"Sea of Helle\") and drowned, but Phrixus survived all the way to Colchis, where King Aeetes took him in and treated him kindly, giving Phrixus his daughter, Chalciope, in marriage. In gratitude, Phrixus gave the king the Golden Fleece of the ram, which Aeetes hung in a tree in his kingdom. The Golden Fleece would later be taken by Jason and his Argonauts.\n\n"}
{"id": "18592630", "url": "https://en.wikipedia.org/wiki?curid=18592630", "title": "PDC Order of Merit", "text": "PDC Order of Merit\n\nThe PDC Order of Merit is a world ranking system used by one of the darts organisations, the Professional Darts Corporation (PDC). Following the 2007 PDC World Darts Championship it superseded a world ranking system based on points being awarded for performances in ranking tournaments.\n\nThe Order of Merit is similar to that employed in golf's European Tour. Prize money won during the previous two seasons is calculated and the rankings are determined from this money list.\nThe Professional Darts Corporation adopted an Order of Merit system in 2007, which is based on prize money won over two years for the main Order of Merit and separate one-year rankings for other PDC Pro Tour events.\n\nThe ProTour Order of Merit counts prize money won in Players Championship events, UK Open Qualifiers and European Tour events over a 12-month period. Players are seeded based on the ProTour Order of Merit to all Player Championship and European Tour events. It also is a main way to qualify to the major TV tournaments.\n\n\nBesides ProTour Order of Merit there is also the Players Championship Order of Merit and the European Tour Order of Merit. Both of these are based solely on the prize money won in that year's Players Championship or European Tour events respectively. The top 64 players on the Players Championship Order of Merit after the last Player Championship event are the only qualifiers to the Players Championship Finals. The top 32 players on the European Tour Order of Merit after the last European Tour event are the only qualifiers to the European Championship.\n\nThe PDC rankings determine exemptions from the qualifying competitions from each major event:\n\nThere is often a lot of confusion with televised tournaments and knowing which ones count towards the PDC Order of Merit. While a lot of televised tournaments are ranked, some are not, usually due to the tournament in question having restricted places e.g. Premier League.\n\nRanked Tournaments\n\nEuropean Tour (Ranked)\n\nUn-ranked Tournaments\n\nWorld Series of Darts (Un-ranked)\n\n\nPairs Tournaments (Un-ranked)\n\nUnder the previous ranking points system, Colin Lloyd was the world number one player in the PDC for most of 2005 and 2006, despite most of the major titles being shared between Phil Taylor, Raymond van Barneveld and John Part. Although Lloyd also won two major titles, he often accumulated ranking points in the less prestigious non-televised events, in which Taylor did not always compete. Similarly, Alan Warriner was world number one on four separate occasions before ever winning his first and only PDC major, the 2001 Grand Prix, while Taylor won eight world championships and a host of other titles during that period.\n\nFollowing the World Darts Council (now PDC) split from the British Darts Organisation during 1992-94 the WDC drew up its first ranking list in the run-up to its inaugural 1994 World Championship. Mike Gregory and Chris Johns later went back to the BDO set up and Bobby George and many of the non-UK players never competed in the early days of the WDC.\n\n\n"}
{"id": "54076293", "url": "https://en.wikipedia.org/wiki?curid=54076293", "title": "Paludiculture", "text": "Paludiculture\n\nPaludiculture is wet agriculture and forestry on peatlands. Paludiculture combines the reduction of greenhouse gas emissions from drained peatlands through rewetting with continued land use and biomass production under wet conditions .\n\nPeatlands store an enormous amount of carbon. Covering only 3 % of the land surface they store more than 450 GT of carbon which is more than the amount of carbon stored by forests (covering 30% of the land surface) , . Drained peatlands cause numerous negative environmental impacts such as greenhouse gas and nutrient emissions, subsidence and loss of biodiversity. Although only 0.3 % of all peatlands are drained, peatland drainage is responsible for 6 % of all human greenhouse gas emission . Peatland rewetting significantly reduces environmental impacts caused by drainage.\n\n\nThe Database of Potential Paludiculture plants (DPPP) lists more than 1,000 wetland plants , but only a minor fraction is suitable for paludiculture. Examples for potential and tested paludicultures are provided in the table below.\n\nTab. Examples for potential and tested paludicultures (modified after , ).\n"}
{"id": "471813", "url": "https://en.wikipedia.org/wiki?curid=471813", "title": "Perfect storm", "text": "Perfect storm\n\nA perfect storm is an event in which a rare combination of circumstances drastically aggravates the event. The term is used by analogy to an unusually severe storm that results from a rare combination of meteorological phenomena.\n\nThe Oxford English Dictionary has published references going back to 1718 for \"perfect storm\", though the earliest citations use the phrase in the sense of \"absolute\" or \"complete\", or for emphasis, as in \"a perfect stranger\".\n\nThe phrase appears in William Makepeace Thackeray's novel \"Vanity Fair\":\nThe first use of the expression in the meteorological sense comes from the March 20, 1936, issue of the \"Port Arthur News\" in Texas: \"The weather bureau describes the disturbance as \"the perfect storm\" of its type. Seven factors were involved in the chain of circumstances that led to \"the flood\".\nIn 1993, journalist and author Sebastian Junger planned to write a book about the 1991 Halloween Nor'easter storm. Technically, this storm was an extratropical cyclone. In the course of his research, he spoke with Bob Case, who had been a deputy meteorologist in the Boston office of the National Weather Service at the time of the storm. Case described to Junger the confluence of three different weather-related phenomena that combined to create what Case referred to as the \"perfect situation\" to generate such a storm:\n\nFrom that, Junger keyed on Case's use of the word \"perfect\" and coined the phrase \"perfect storm\", choosing to use \"The Perfect Storm\" as the title of his book.\n\nJunger published his book \"The Perfect Storm\" in 1997 and its success brought the phrase into popular culture. Its adoption was accelerated with the release of the 2000 feature film adaptation of Junger's book.\nSince the release of the movie, the phrase has grown to mean any event where a situation is aggravated drastically by an exceptionally rare combination of circumstances. \nAlthough the 1991 Halloween Nor'easter was a powerful storm by any measure, there have been other storms that have exceeded its strength. \nAccording to Case, the type of convergence of weather events to which he was referring, while unusual, is not exceptionally rare or unique, despite the way the phrase is commonly used.\n\nThe term \"perfect storm\" is nearly synonymous with \"worst-case scenario\", although the latter carries more of a hypothetical connotation.\n\n\"Perfect storm\" has also been used as a metaphor for a relationship such as in the popular hit songs \"Dark Horse\" by Katy Perry, \"Blank Space\" by Taylor Swift, \"Perfect Storm\" by Brad Paisley, \"Invincible\" by Kelly Clarkson, and \"Should've Been Us\" by Tori Kelly.\n\nFrom the beginning, the phrase was in heavy use during the financial crisis of 2007–2012, even to the point of pundits anticipating \"another perfect storm\".\n\nThe phrase was awarded the top prize by Lake Superior State University in their 2007 list of words that deserve to be banned for overuse.\n\n\n"}
{"id": "3441384", "url": "https://en.wikipedia.org/wiki?curid=3441384", "title": "Plaggen soil", "text": "Plaggen soil\n\nPlaggen soil or plaggic anthrosol is a type of soil created in parts of northwest Europe in the Middle Ages, as a result of so-called \"plaggen\" agriculture on marginal podzol soils.\n\nIn order to fertilize the fields, pieces of heath or grass including roots and humus (\"plaggen\") were cut and used as bedding for cattle. In springtime, this bedding, enriched with slurry was then spread over the fields near the village as manure. The long term practice of this form of agriculture created a rich agricultural soil to a depth of between 40 cm and over 1.50 m, unlike modern arable soils, which tend to be just 30 centimetres deep. The raised fields give rise to a typical landscape with sharp breaks in elevation and are called Plaggenesche in Germany or \"Es\" in Dutch. This form of agriculture stopped around 1900 with the introduction of fertilizers.\n\nIn Orkney these soils were created already in the 12th to 13th centuries, and on some islands in Shetland these methods continued to be used until the 1960s.\n\nThe Maori of New Zealand's agriculture included plaggen soil forming practices that increased drainage for kumara crops.\n"}
{"id": "46533089", "url": "https://en.wikipedia.org/wiki?curid=46533089", "title": "The Blob (Pacific Ocean)", "text": "The Blob (Pacific Ocean)\n\nThe Blob is a large mass of relatively warm water in the Pacific Ocean off the coast of North America. It was first detected in late 2013 and continued to spread throughout 2014 and 2015.\n\nSea surface temperature indicated that The Blob persisted into 2016, but was thought to have dissipated later that year. By September 2016, \"The Blob\" resurfaced and made itself known to meteorologists. This warm water mass is unusual in ocean conditions and is considered to have a role in the formation of the unusual weather conditions felt in the Pacific Coast of North America. The warm waters of the Blob are nutrient poor and have adversely affected marine life.\n\nThe Blob was first detected in the autumn of 2013 and the early months of 2014 by Nicholas Bond of the Joint Institute for the Study of the Atmosphere and Ocean of the University of Washington, and his colleagues, when a large circular body of sea-water did not cool as expected and remained much warmer than the average normal temperatures for that location and season.\n\nBond, who is the State Climatologist for Washington, coined the term \"The Blob\", with the term first appearing in an article in the monthly newsletter of the Office of the Washington State Climatologist for June 2014.\n\nInitially the Blob was reported as being wide and deep. It expanded and reached the size long, wide and deep, in the month of June 2014 when the term \"The Blob\" was coined. The Blob now hugs the coast of North America from Mexico to Alaska and beyond, over a stretch of and more, and has formed three distinct patches, the first, off the coast of Canada, Washington, Oregon, and California, a region known to oceanographers as the Coastal Upwelling Domain; the second off Alaska and in the Bering Sea; and the third and smallest, off Southern California and Mexico.\n\nIn February 2014, the temperature of the Blob was around warmer than what was usual for the time of year.\n\nA NOAA scientist noted in September 2014, based on ocean temperature records, that the North Pacific Ocean had not previously experienced temperatures so warm since climatologists began taking recordings.\nThe immediate cause of the phenomenon is the lower than normal rates of heat loss from the sea to the atmosphere, compounded with lower than usual water circulation resulting in a static upper layer of water. Both of these are attributed to a static high pressure region in the atmosphere, termed the Ridiculously Resilient Ridge, which has existed since spring 2014. The lack of air movement impacts the wind-forced currents and the wind-generated stirring of surface waters. These in turn have influenced the weather in the Pacific Northwest from the winter of 2013–2014 onwards and may have been associated with the unusually hot summer experienced in the continental Pacific Northwest in 2014.\n\nThe reason for the phenomenon is unclear. Some experts consider that the wedge of warm water portends a cyclical change with the surface waters of the mid-latitude Pacific Ocean flipping from a cold phase to a warm phase in a cycle known as the Pacific decadal oscillation (PDO). This poorly-understood change happens at irregular intervals of years or decades. During a warm phase, the west Pacific becomes cooler and part of the eastern ocean warms; during the cool phase, these changes reverse. Scientists believe a cold phase started in the late 1990s and the arrival of the Blob may be the start of the next warm phase. The PDO phases may also be related to the likelihood of El Nino events.\n\nNASA climatologist William Patzert predicts that if the PDO is at work here, there will be widespread climatological consequences and southern California and the American South may be in for a period of high precipitation, with an increase in the rate of global warming. Another climatologist, Matt Newman of the University of Colorado, does not think the Blob fits the pattern of a shift in the PDO. He believes the unusually warm water is due to the persistent area of high pressure stationary over the northeastern Pacific Ocean. Dan Cayan of the Scripps Institution of Oceanography is unsure about the ultimate cause of the phenomenon, but states \"there's no doubt that this anomaly in sea surface temperature is very meaningful\".\n\nSea surface temperature anomalies are a physical indicator which adversely affect the zooplankton (mainly copepods) in the Northeast Pacific and specifically in the Coastal Upwelling Domain. Warm waters are much less nutrient-rich than the cold upwelling waters which were the norm till recently off the Pacific Coast. This results in reduced phytoplankton productivity with knock on effects on the zooplankton which feed on it and the higher levels of the food chain. The Northwest Fisheries Science Center, Seattle has predicted reduced catches of coho and Chinook salmon, a major contributing factor being the raised temperatures of seawater in the Blob.\n\nSalmon catches in 2015 have dropped as the fish migrated away having found low levels of zooplankton. Thousands of sea lion pups are starving in California leading to forced beachings.\nThousands of Cassin's auklets in Oregon have starved due to lack of food.\n\nIn addition, animals which favour warm waters and which have never been seen as far north as Alaska, have been spotted, examples being the warm water thresher sharks (\"Alopias\" spp) and ocean sunfish (\"Mola mola\"). In the spring of 2016, acres of Velella velella were reported in the waters south of the Copper River Delta.\n\nThe discovery of a skipjack tuna (\"Katsuwonus pelamis\"), primarily a fish of warm tropical waters, off Copper River, in Alaska, north of the previous geographic limit, and a dead sooty storm-petrel (\"Oceanodroma tristrami\"), a species native to Northern Asia and Hawaii, along with a few brown boobies (\"Sula leucogaster\") in the Farallon Islands of California, besides other such records, has led to worries amongst marine biologists that the food web across the Pacific is in danger of disruption.\n\nBiologists from The University of Queensland observed the first ever mass bleaching event for Hawaiian coral reefs in 2014, and attributed it to the blob.\n\nResearch from the University of Washington found positive temperature anomalies in the NE Pacific Ocean (upper ~100 m, greater than 2.5 °C, with temperatures at the coast below normal) for the winter period of 2013–2014. Heat loss from the ocean during the winter time was suppressed. During spring and summer 2014 the warmer sea surface temperature anomalies reached coastal waters. The anomaly may have had a significant effect on the unusually warm summer of 2014, with record high temperatures over parts of land in the Pacific Northwest. Offshore sea surface temperatures (SSTs) in the NE Pacific for the month of February were the greatest at least since the 1980s, possibly as early as 1900. Additionally they found anomalous sea surface pressure SSP, with a peak magnitude approaching 10 hPa, a record high value for the years of 1949–2014.\n\nCanadian senior climatologist David Phillips noted in May 2015 about the coming winter season, \"If that blob continues, if it stays warm ... and then you add to that El Nino, it may complement each other and then it may be the year winter is cancelled.\"\n\n"}
{"id": "56147458", "url": "https://en.wikipedia.org/wiki?curid=56147458", "title": "Toqui Formation", "text": "Toqui Formation\n\nThe Toqui Formation is a geological formation in the Aysén Region of southern Chile. It has been dated to the Tithonian stage of the Late Jurassic by uranium–lead dating of zircons, providing an age of 147 ± 0.1 Ma. It consists of an sequence of clastic sedimentary sandstones and conglomerates, interbedded with volcanic tuffs and ignimbrite. The dinosaurs \"Chilesaurus\" and indeterminate diplodocids are known from the formation. The formation was deposited in a fluvio-deltaic environment.\n\n"}
{"id": "12621766", "url": "https://en.wikipedia.org/wiki?curid=12621766", "title": "Trevor Pescott", "text": "Trevor Pescott\n\nTrevor William Pescott (born 1934) is an Australian naturalist, conservationist and writer, based in Geelong, Victoria. He was born in Ballarat and educated in Geelong, qualifying with a Diploma of Civil Engineering from the Gordon Institute of Technology. He was subsequently employed as a municipal engineer with the Shire of Corio until his retirement.\n\nPescott was instrumental in the reestablishment of the Geelong Field Naturalists Club in 1961, serving as its President for three years and editing its magazine, the \"Geelong Naturalist\". From 1960 he wrote a weekly column (\"By Field and Lane\") in the \"Geelong Advertiser\". He has been a regional representative to the Royal Australasian Ornithologists Union and a foundation committee member of the Environment Studies Association of Victoria. In 1973 he was involved in the formation of the Geelong Environment Council. In 1982 Deakin University awarded him an honorary Master of Science degree.\n\nIn 1983 Pescott was awarded the Australian Natural History Medallion.\n\nAs well as numerous articles in magazines and journals, books authored and edited by Pescott include:\n"}
{"id": "33987834", "url": "https://en.wikipedia.org/wiki?curid=33987834", "title": "Zonguldak basin", "text": "Zonguldak basin\n\nThe Zonguldak basin of North Western Turkey has been mined for coal since the late 1800s. The basin takes its name after Zonguldak, Turkey, and is approximately 41° N. The Zonguldak basin is the only basin in Turkey with minable coal deposits. Geographically, the Zonguldak is roughly elliptical in shape with its long axis oriented roughly SW – NE, and is adjacent to the Black Sea. Three main regions have been recognized in the Zonguldak basin. These are the Armutcuk, the Zonguldak, and the Amasra from west to east respectively.\n\nThe Zongdulak basin has undergone two major periods of deposition. The first period of deposition began in the Paleozoic and the second began in the Cretaceous. Isolated areas of deposition in the basin occurred during the Late Permian through the Triassic and the Latest Jurassic.\n\nThe Zonguldak basin first experienced deposition in the Ordovician. Deposition begins with the lower Ordovician Soḡuksu Formation. The Soḡuksu Fm. ranges from 700 m – 1100 m thick. At its base it consists of green shale and sandstone and coarsens upwards to arkosic conglomerates. The lower Ordovician Aydos Formation conformably overlies the Soḡuksu. It is a conglomerate of quartzitic sandstone and ranges in thickness from 50–200 m. The Findikli Formation was deposited during the upper Ordovician, Silurian, and lower most Devonian in the Zonguldak basin. It ranges from 300 – 450 m thick. Its facies are indicative of a mixed siliclastic – carbonate shelf environment that is shallowing through time.\n\nThe red crossbedded sandstones of the Ferizli Formation overlie the marly deposits of the Fendikli Formation. The oolitic sandstones contain iron and are an iron ore. The formation, like the Findikli Fm., shows a shift toward shallower depositional environments and a shift to higher energy areas of deposition. The younger sediments of the Ferizli Fm. become progressively more enriched in calcium carbonate and eventually give way to the Yilanli Formation.\n\nThe Yilanli Formation is Visean in age and is the beginning of the coal related sequences in the Zonguldak basin. The Yilanli is a dolomitic limestone unit with calcareous black and gray shales. It was deposited in a shallow marine passive margin setting. It is conformably overlain by the Alacaagzi Formation, and has accumulated over 1000 m of sediment. The Alacaagzi Formation contains economic deposits of coal. It is comprised predominantly of crossbedded black shales and silts in the lower sections of the unit and progressively becomes composed of sands, shale bearing coals, and conglomerates towards the top of the formation. Facies analysis in the Alacaagzi Formation is suggestive of a coastal environments including: lacustrine, fluviatial, and fan deposits.\n\nConformably overlaying the Alacaagzi Formation is the Kozlu Formation. The Kozlu contains 19 coal seams totaling 30 – 32 m. The Kozlu is composed of successional conglomerate, sand, silt, mud, and coal deposits. The Karadon Formation conformably overlies the Kozlu. The Karadon formation is lithologically similar to the Kozlu Fm. but contains less coal seams. An angular unconformity spans the top of the Karadon formation and ranges from 46.5 Ma – 194 Ma in duration.\n\nDeposition resumes in the western portion of the Zonguldak basin with the deposition of the Çakraz Formation. The Çakraz spans the upper Permian through the Lower Jurassic. Unconformably overlying the Çakraz Fm. is the Inalti Formation. The Inalti was deposited during the upper Jurassic and is truncated by an unconformity. The carbonates of the Inalti are representative of a shallow passive margin setting.\n\nDuring the late Cretaceous, the Zonguldak basin was roughly 25° N, and was experiencing subsidence due to the formation of a back arc, the Black Sea. As a result, the Zonguldak experienced deposition from the early Cretaceous through the Eocene. Different authors present differing stratigraphic columns of the Zonguldak basin and this analysis will preferentially report more current research. The lithologies deposited during this period of deposition include: limestones, mudstones, siltstones, and dolomites. The Albian, 105-100 Ma, Zonguldak Formation is predominantly limestone with areas of dolomitization. It is conformably overlain by the Albian, 105-112 Ma, Kilimli Formation. The Kilimli is composed of sandstone and carbonaceous sandstone.\n\nThe Kilimli is unconformably overlain by the sandy limestone of the Cemaller Formation. The unconformity lasts at least 6.5 Ma and the Zonguldak basin experiences continuous deposition from the Turonian – Campanian. The Cemaller Fm. is overlain by the siltstone and limestone of the Baþköy formation. The Dinlence Formation overlies the Cemaller and consists of andesites and andesitic tuffites. It is possible that the Dinlence is the Yemislicay Formation since it too contains andesites and andesitic tuffites. The Dinlence is overlain by the marls, and limestones of the Alapý Formation.\n\nDuring the middle Paleozoic the Zonguldak basin was part of the south facing passive margin of the Laurasian plate. During the Carboniferous the temperature of the sediment water interface was near 25 °C and heat flow into the Zonguldak basin was about 1.3 heat flow units (HFU). Backstripping analysis of the Alacaagzi Fm, the lowest coal-bearing formation, reaches a maximum temperature and depth of 100 °C and 2.4 km respectively in the Zonguldak area during the Carboniferous. Similarly, the base of Kozlu Fm reaches maximum temperatures of 85, 85, and 100 °C in the Armutcuk, the Zonguldak, and the Amasra regions respectively.\n\nThe Zonguldak basin was tectonically active during the late Paleozoic and this strongly influenced its structural and burial history due to the Hercynian orogeny. The Hercynian orogeny was the result of a continent-continent collision between Laurasia and Gondwana. This collision created many E-NE/ W-SW striking faults, folds, and tilted the Paleozoic sediments. This uplift of the basin, near the end of the Westphalian, halted deposition and created the angular unconformity at the top of the Karadon Fm. Heat flow remained constant in the Zonguldak basin during the Hercynian Orogeny, while the uplift caused a decrease in the temperatures the sediments experienced. For example, at the end of the Permian the top of the Alacaagzi is roughly 70 °C and 1.6 km below the sediment surface in the Zonguldak area.\n\nDuring the Cretaceous the Zonguldak basin experienced general subsidence, rifting, and faulting. This led to another period of deposition in the region and faulted the coal seams. This faulting provided a pathway for meteoric water to enter the coal seams.\n\nDuring the Aptian, the Intrapontide Ocean, the ocean separating the Western Pontides tectonic region of Turkey form the Sakarya Continent, underwent subduction. This led to the formation of a back arc basin, the Black Sea. The start of this subduction is responsible for the unconformity between the Kilimi and Cemaller Fms and marks the beginning of the Alpide orogeny in the region. The andesitic volcaniclastic sediments of the Yemislicay support the subduction of oceanic crust in the region during this time. The Zonguldak basin was able to sustain deposition after the start of the Alpide orogeny due to rifting in the Black Sea basin. The rifting in the Black Sea also increased heat flow into the Zonguldak basin during the Cretaceous. Heat flows were as high as 1.5-1.75 HFU, and the temperature of the sediment water interface was about 25 °C.\n\nThe Intra-Pontide Ocean stopped subducting with the collision between the Western Pontides terrain and the Eastern Pontides terrain. The Aplide orogeny stopped deposition and uplifted the Zonguldak basin during the Eocene epoch beginning at 42 Ma. The coal bearing formations experienced the highest temperatures at the onset of the Alpide orogeny. For example, the base of the Kozlu Fm experienced temperatures of 125, 175, and 140 °C in the Armutcuk, the Zonguldak, and the Amasra regions respectively.\n\nThe Alpide tectonic provinces in Anatolia, from North to South, are the: Pontides, Anatolides, Tarides, and Border Folds. These provinces have rough East-West strike. The Zonguldak basin is currently being uplifted by the Alpide orogeny. Progressively older sediments outcrop toward the north of the basin.\n\nThe coals of the Alacaagzi Fm, Kozlu Fm, and Karadon Fm are of bituminous rank. The Alacaagzi, Kozlu, and Karadon Fms contain greater than: 70% total organic carbon (TOC), 81% TOC, and 81% TOC respectively.\n\nThe coals of the Zonguldak basin follow the mean evolution of type III kerogens. The coals of the Zonguldak basin show vitrinite reflectances (Ro) of 0.45 – 1.70%. Hoşgörmez et al., (2002) determined that the coals of the Kozlu Fm exhibit Ro of 1.0 – 1.2% which gives them a coal rank of high volatile A bituminous. Additionally, coalification increased with depth, and the coals became more aromatic with depth. The calorification of the coals also increased with depth.\n\nThe two broad scale pathways of methane production, thermogenic and biogenic generation, account for the majority of methane generation in coals. Thermogenic production of methane in coals begins at temperatures around 80 °C and peaks around 0.7 – 1.6% of vitrinite reflectance. Biogenic generation of methane takes place through two chemically distinguishable pathways. These pathways are carbon dioxide reduction; and acetate fermentation and methanol/methyl utilization. Typically biogenic production takes place early in the maturation of a coal bed, since the temperatures observed during the coalification process are high enough for sterilization. A coal bed may produce methane later in its history if it is uplifted and fractured. The uplifting of the beds cools them enough for colonization by microbes and fractures and faults provide inoculation pathways by the infiltration of surface water.\n\nThe coals of the Zonguldak basin were subjected to a complex depositional and tectonic history, and this influenced the basins methane generation. The Alacaagzi Fm did not pass the 80 °C isotherm until it had been buried for 25 Ma. The Kozlu Fm experienced two different conditions during its first 260 Ma. The bottom of the Kozlu was mostly below the 80 °C isotherm while the top of the formation was above it. With deposition in the Cretaceous, the Kozlu Fm was buried beneath the 80 °C Isotherm. The Alacaagzi, Kozlu were uplifted past the 80 °C around 5 Ma. At this point the rocks had been fractured and meteoric water could inoculate the system with methanogenic microbes.\n\nIsotopic data from wells in the Zonguldak basin suggest that the methane is primarily thermogenic in nature. There may have been some initial microbial methane generation in the coal beds or generation after the basin had been uplifted and meteoric water could enter the beds. Reinoculation is supported by the evidence of isotopically lighter gas occurring near cleats in the coal beds.\n\nThe organic rich shales of the Yilani contain up to 7.9% TOC, and the shales and siltstones of the coalbearing formations can contain 2 – 26% TOC. The organic matter is found as type II kerogen. While the Yilani entered the gas window, isotopic data suggest that most of the gas in the basin was derived from the Kozlu coal deposits and the associated organic rich shales.\n\nThe predominant source rock in the Zonguldak basin is coal. The most prolific source rock is the Kozlu Fm containing the greatest volume of coal and the greatest amount of methane. This is in corroboration with the Ro values that suggest thermogenic production of methane in the Zonguldak basin would have been high. Methane generated by shale may be contributing a small amount to the total amount of methane found in the basin but the majority is coal derived. Coal derived methane appears to be mostly thermogenic in origin with some biogenic production.\n\nCoal is the primary reservoir lithology in the Zonguldak basin. Coal, since it is a solid hydrocarbon, cannot migrate. Coal is also an important reservoir lithology in the basin for methane. Methane in coal beds is primarily found in a sorbed state, while a very small fraction is found as a free gas. The gas is in the micro-porous structure of the coal at near liquid densities. Hoşgörmez et al. (2002) estimated that the coals of the Zongulak basin contain up to 12 cm g of methane. Additionally, 90% of the methane in the Karadon Fm is adsorbed to the coal while 10% of it is found as free gas. The total volume of coal bed methane in the Karadon Fm in the Amasra region has been estimated to be between 862.5-2600 million cubic metres.\n\nThe dolomites of the Yilani Fm are characterized as potential reservoir units. The sandstone units in the Alacaagzi, Kozlu, and Karadon Fms are also potential reservoirs. Another formation with good reservoir qualities is the Yemislicay or Dinlence Fm. The base of the Yemislicay is characterized by a red pelagic limestone interlain with volcaniclastic sediments.\n\nDue to the microporous nature of coal, coal is a significant seal in the Zonguldak basin. Outside of the coal bearing formations, the only other formation that can serve as a seal is the Kilimli Formation.\n\nCoal mines include Armutçuk coal mine and Karadon coal mine\n\n"}
{"id": "68523", "url": "https://en.wikipedia.org/wiki?curid=68523", "title": "Ænon", "text": "Ænon\n\nÆnon, more commonly written Aenon, is the site mentioned by the Gospel of John as the place where John was baptising after his encounter with Jesus.\n\n\"Ænon\" is the Greek rendition of the Semitic term for \"spring\" or \"natural fountain\", like the Hebrew and Arabic \"ayn\". In the water-poor Middle East, places owning a spring tend to be named after that water source, so that toponyms consisting of or containing the Construct state word \"ein-\" are common. The particular site mentioned in the Gospel of John is therefore closer identified as \"Aenon near Salim\". is the only place in the Bible where the name Aenon is found.\n\nThe name Aenon is commonly used amongst Baptist organizations and churches.\n\nBoth names, \"Aenon\" and \"Salim\", are not unique, and the Gospel text offers only two additional hints about where Aenon might be located: the most direct information is that \"there was plenty of water there\" (), and the second is that it was west of the River Jordan because at Aenon John's disciples talk of the site where John first encountered Jesus as being \"on the other side of the Jordan\" () which is taken to mean east of the river. We also know from that that first encounter happened at \"Bethany on the other side of the Jordan\".\n\nOne possible location is near the upper source of the Wadi Fa'rah, an open valley extending from Mount Ebal to the Jordan River which is full of springs. There is a place called 'Ainun four miles north of the springs (see Easton's Bible Dictionary).\n\nAnother possible location, which is supported by Eusebius' description in his \"Onomasticon\" (written before AD 324), is at \"a village in the (Jordan) valley, at the eighth milestone from Scythopolis (Beit She'an), ... called Salumias.\" This view was already supported by the 19th-century Smith's Bible Dictionary and the 1915 International Standard Bible Encyclopedia and is still favoured by some.\n\nThe 6th-century Madaba Map shows the location of Ænon right across the Jordan from Bethabara, near Jericho. Bethabara is in some, but not all, versions of the Gospel of John the place where John was baptising during his encounter with Jesus. The map and archaeological findings at the site indicate that at least during part of the Byzantine period, this was the site venerated as Aenon. The two relevant map inscriptions read\n\n\nWith the Dead Sea shown on the right side of the map giving context, Bethabara is on the west of the Jordan, while Ænon is on the east.\n\n\n"}
