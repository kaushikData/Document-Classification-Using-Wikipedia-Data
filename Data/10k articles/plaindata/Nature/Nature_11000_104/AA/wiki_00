{"id": "592903", "url": "https://en.wikipedia.org/wiki?curid=592903", "title": "(52760) 1998 ML14", "text": "(52760) 1998 ML14\n\n, provisional designation , is a stony asteroid, classified as near-Earth object of the Apollo group and potentially hazardous asteroid, approximately 1 kilometer in diameter. It was discovered on 24 June 1998, by the LINEAR survey at the Lincoln Laboratory's Experimental Test Site in Socorro, New Mexico.\n\n orbits the Sun at a distance of 0.9–3.9 AU once every 3 years and 9 months (1,366 days). Its orbit has an eccentricity of 0.62 and an inclination of 2° with respect to the ecliptic. It is also a Mars-crossing asteroid.\n\nShortly after its discovery, was imaged by radar at Goldstone and Arecibo.\n\nThe study showed that the asteroid has a rotation period of 15 hours, and a shape that is roughly spherical, with some steep protrusions and large craters.\n\nOn August 24, 2013 it passed at a distance of 21.9 Lunar distances. It was hoped to be observed by Goldstone radar.\n\nThis minor planet was numbered by the Minor Planet Center on 16 February 2003. As of 2018, it has not been named.\n\n"}
{"id": "11142859", "url": "https://en.wikipedia.org/wiki?curid=11142859", "title": "100,000-year problem", "text": "100,000-year problem\n\nThe 100,000-year problem (\"100 ky problem\", \"100 ka problem\") of the Milankovitch theory of orbital forcing refers to a discrepancy between the reconstructed geologic temperature record and the reconstructed amount of incoming solar radiation, or insolation over the past 800,000 years. Due to variations in the Earth's orbit, the amount of insolation varies with periods of around 21,000, 40,000, 100,000, and 400,000 years. Variations in the amount of incident solar energy drive changes in the climate of the Earth, and are recognised as a key factor in the timing of initiation and termination of glaciations.\n\nWhile there is a Milankovitch cycle in the range of 100,000 years, related to Earth's orbital eccentricity, its contribution to variation in insolation is much smaller than those of precession and obliquity. The 100,000-year-problem refers to the lack of an obvious explanation for the periodicity of ice ages at roughly 100,000 years for the past million years, but not before, when the dominant periodicity corresponded to 41,000 years.\nThe unexplained transition between the two periodicity regimes is known as the mid-Pleistocene transition, dated to some 800,000 years ago.\n\nThe related \"400,000-year-problem\" refers to the absence of a 400,000-year periodicity due to orbital eccentricity in the geological temperature record over the past 1.2 million years.\n\nThe geologic temperature record can be reconstructed from sedimentary evidence. Perhaps the most useful indicator of past climate is the fractionation of oxygen isotopes, denoted \"δ\"O. This fractionation is controlled mainly by the amount of water locked up in ice and the absolute temperature of the planet, and has allowed a timescale of marine isotope stages to be constructed.\n\nBy the late 1990s, records of air (in the Vostok ice core) and marine sediments was available and was compared with estimates of insolation, which should affect both temperature and ice volume. As described by Shackleton (2000), the deep-sea sediment record of \"is dominated by a 100,000-year cyclicity that is universally interpreted as the main ice-age rhythm\". Shackleton (2000) adjusted the time scale of the Vostok ice core record to fit the assumed orbital forcing and used spectral analysis to identify and subtract the component of the record that in this interpretation could be attributed to a linear (directly proportional) response to the orbital forcing. The residual signal (the remainder), when compared with the residual from a similarly retuned marine core isotope record, was used to estimate the proportion of the signal that was attributable to ice volume, with the rest (having attempted to allow for the Dole effect) being attributed to temperature changes in the deep water.\n\nThe 100,000-year component of ice volume variation was found to match sea level records based on coral age determinations, and to lag orbital eccentricity by several thousand years, as would be expected if orbital eccentricity were the pacing mechanism. Strong non-linear \"jumps\" in the record appear at deglaciations, although the 100,000-year periodicity was not the strongest periodicity in this \"pure\" ice volume record.\n\nThe separate deep sea temperature record was found to vary directly in phase with orbital eccentricity, as did Antarctic temperature and CO; so eccentricity appears to exert a geologically immediate effect on air temperatures, deep sea temperatures, and atmospheric carbon dioxide concentrations. Shackleton (2000) concluded: \"The effect of orbital eccentricity probably enters the paleoclimatic record through an influence on the concentration of atmospheric CO\".\n\nElkibbi and Rial (2001) identified the 100 ka cycle as one of five main challenges met by the Milankovitch model of orbital forcing of the ice ages.\n\nAs the 100,000-year periodicity only dominates the climate of the past million years, there is insufficient information to separate the component frequencies of eccentricity using spectral analysis, making the reliable detection of significant longer-term trends more difficult, although the spectral analysis of much longer palaeoclimate records, such as the Lisiecki and Raymo stack of marine cores and James Zachos' composite isotopic record, helps to put the last million years in longer term context. Hence there is still no clear proof of the mechanism responsible for the 100 ka periodicity—but there are several credible hypotheses.\n\nThe mechanism may be internal to the Earth system. The Earth's climate system may have a natural resonance frequency of 100 ka; that is to say, feedback processes within the climate automatically produce a 100 ka effect, much as a bell naturally rings at a certain pitch. Opponents to this claim point out that the resonance would have to have developed 1 million years ago, as a 100 ka periodicity was weak to non-existent for the preceding 2 million years. This is feasible—continental drift and sea floor spreading rate change have been postulated as possible causes of such a change. Free oscillations of components of the Earth system have been considered as a cause, but too few Earth systems have a thermal inertia on a thousand-year timescale for any long-term changes to accumulate. The most common hypothesis looks to the Northern Hemisphere ice sheets, which might expand through a few shorter cycles until large enough to undergo a sudden collapse. The 100,000-year problem has been scrutinized by José A. Rial, Jeseung Oh and Elizabeth Reischmann who find that master-slave synchronization between the climate systems natural frequencies and the eccentricity forcing started the 100 ky ice ages of the late Pleistocene and explain their large amplitude.\n\nOrbital inclination has a 100 ka periodicity, while eccentricity's 95 and 125ka periods could inter-react to give a 108ka effect. While it is possible that the less significant, and originally overlooked, inclination variability has a deep effect on climate, the eccentricity only modifies insolation by a small amount: 1–2% of the shift caused by the 21,000-year precession and 41,000-year obliquity cycles. Such a big impact from inclination would therefore be disproportionate in comparison to other cycles. One possible mechanism suggested to account for this was the passage of Earth through regions of cosmic dust. Our eccentric orbit would take us through dusty clouds in space, which would act to occlude some of the incoming radiation, shadowing the Earth.\n\nIn such a scenario, the abundance of the isotope He, produced by solar rays splitting gases in the upper atmosphere, would be expected to decrease—and initial investigations did indeed find such a drop in He abundance.\nOthers have argued possible effects from the dust entering the atmosphere itself, for example by increasing cloud cover (on July 9 and January 9, when the Earth passes through the invariable plane, mesospheric cloud increases). Therefore, the 100 ka eccentricity cycle can act as a \"pacemaker\" to the system, amplifying the effect of precession and obliquity cycles at key moments, with its perturbation.\n\nA similar suggestion holds the 21,636-year precession cycles solely responsible. Ice ages are characterized by the slow buildup of ice volume, followed by relatively swift melting phases. It is possible that ice built up over several precession cycles, only melting after four or five such cycles.\n\nA mechanism that may account for periodic fluctuations in solar luminosity has also been proposed as an explanation. Diffusion waves occurring within the sun can be modeled in such a way that they explain the observed climatic shifts on earth. However, the He signal again appears to contradict this finding.\n\nThe Dole effect describes trends in arising from trends in the relative importance of land-dwelling and oceanic photosynthesizers. Such a variation is a plausible cause of the phenomenon.\n\nThe recovery of higher-resolution ice cores spanning more of the past 1,000,000 years by the ongoing EPICA project may help shed more light on the matter. A new, high-precision dating method developed by the team allows better correlation of the various factors involved and puts the ice core chronologies on a stronger temporal footing, endorsing the traditional Milankovitch hypothesis, that climate variations are controlled by insolation in the northern hemisphere. The new chronology is inconsistent with the \"inclination\" theory of the 100,000-year cycle. The establishment of leads and lags against different orbital forcing components with this method—which uses the direct insolation control over nitrogen-oxygen ratios in ice core bubbles—is in principle a great improvement in the temporal resolution of these records and another significant validation of the Milankovitch hypothesis. An international climate modelling exercise (Abe-ouchi \"et al.\", Nature, 2013) demonstrated that climate models can replicate the 100,000-year cyclicity given the orbital forcing and carbon dioxide levels of the late Pleistocene. The isostatic history of ice sheets was implicated in mediating the 100,000-year response to the orbital forcing. Larger ice sheets are lower in elevation because they depress the continental crust upon which they sit, and are therefore more vulnerable to melting.\n"}
{"id": "10626475", "url": "https://en.wikipedia.org/wiki?curid=10626475", "title": "Agamassan", "text": "Agamassan\n\nAgamassan is a porous substrate used to safely absorb acetylene and thus allow the transport, storage and commercial exploitation of the otherwise unstable gas. It was developed and patented by the Swedish Nobel Laureate and industrialist Gustaf Dalén. Dalén was prominent in developing applications for acetylene.\n\nAcetylene can readily explode when in liquid or solid form or while being pressurized, if it is pure. Dalén himself was blinded in an acetylene explosion.\n\nIn 1896, French chemists Georges Claude and Albert Hess discovered that large quantities of acetylene could be dissolved in acetone and rendered nonexplosive. As the liquid was reduced by consumption or cooling, explosive acetylene gas would collect in the space above the liquid's surface. The solution was to compress acetylene in a porous medium.\n\nBefore Dalén's work, numerous attempts were made to find a mass sufficiently elastic to withstand shock without crumbling and producing cavities filled with explosive acetylene gas.\n\nAcetylene is shipped and stored in metal cylinders filled with agamassan, which is half-filled with dimethylformamide (DMF) or acetone. The acetylene is dissolved in the DMF or acetone. Such cylinders are safe to transport and use.\n\nIn Swedish, the porous filler is known as \"AGA-massan\", which would translate as \"AGA mass\", \"AGA body\", or \"AGA compound\". AGA was the company Dalén founded. The compound originally consisted of, among other things, asbestos, cement, and coal. The 1930 US patent also mentions kieselguhr (diatomaceous earth).\n\n"}
{"id": "19997315", "url": "https://en.wikipedia.org/wiki?curid=19997315", "title": "Alternative Energy: Political, Economic, and Social Feasibility", "text": "Alternative Energy: Political, Economic, and Social Feasibility\n\nAlternative Energy: Political, Economic, and Social Feasibility (Lanham, Maryland: Rowman & Littlefield, 2006. ), a 2006 book by Christopher A. Simon, discusses the transition from fossil fuels to renewable energy. The book has been called a \"sophisticated, insightful, and well written book on the current global push to adopt varying forms of alternative energy, from wind to solar, geothermal, hydrogen, and beyond\".\n\nIn 2008, Christopher Simon, associate professor of political science at the University of Nevada, Reno, was named the “Technology Educator of the Year” by Nevada's Center for Entrepreneurship and Technology.\n"}
{"id": "1052556", "url": "https://en.wikipedia.org/wiki?curid=1052556", "title": "Ataegina", "text": "Ataegina\n\nAtaegina or Ataecina (Spanish; ) was a popular goddess worshipped by the ancient Iberians, Lusitanians, and Celtiberians of the Iberian Peninsula.\n\nThe name \"Ataegina\" is most commonly derived from a Celtic source: the two roots \"*atte-\" and \"*geno-\" to mean \"Reborn\" or from \"*ad-akī-\" (Irish \"adaig\") meaning \"night\"; however her presence in decidedly non-Indo-European Iberian regions suggest that she may have an older, indigenous origin, in which case her name's etymology is more likely of an Iberian or Tartessian etymology. Epigraphs from the Badajoz region associate the goddess with the Roman Proserpina or Persephone which would make her a goddess presiding over Spring and seasonality, echoing the \"reborn\" derivation of the name.\n\nAtaegina was worshipped in Lusitania and Betica; there were also sanctuaries dedicated to Ataegina in Elvas (Portugal), and Mérida and Cáceres in Spain, along with other places, especially near the Guadiana river. She was one of the goddesses worshipped in \"Myrtilis\" (today's Mértola, Portugal), \"Pax Julia\" (Beja, Portugal) and especially the city of \"Turobriga\", whose precise location is unknown. A bronze plaque from Malpartida de Cáceres suggests associations with the goat as a sacred animal.\n\nA team claiming to be the discoverers of the dwarf planet and plutoid , Ortiz \"et al.\", proposed \"Ataecina\" as the name of the body, due to her mythical connections with Pluto (Proserpina was the wife of Pluto), and her association with southern Spain, near to the discoverers' observatory. This proposal was not however accepted by the International Astronomical Union, not only because there is a dispute over whether Ortiz had actually discovered Haumea, but also chthonic deities are reserved for the names of bodies orbiting in resonance 2:3 (plutino) with Neptune, which was not the case for Haumea, which is in resonance 7:12.\n\n"}
{"id": "26533936", "url": "https://en.wikipedia.org/wiki?curid=26533936", "title": "Basaltic andesite", "text": "Basaltic andesite\n\nBasaltic andesite is a volcanic rock containing about 55% silica. It is distinct from basalt and andesite in having a different percentage of silica content. Minerals in basaltic andesite include olivine, augite and plagioclase. Basaltic andesite can be found in volcanoes around the world, including in Central America and the Andes of South America.\n"}
{"id": "18398279", "url": "https://en.wikipedia.org/wiki?curid=18398279", "title": "Bermuda Weather Service", "text": "Bermuda Weather Service\n\nThe Bermuda Weather Service is Bermuda's national meteorological service. It provides public, marine, tropical and aviation weather forecasts as well as warnings and climatolological services. The service began operations under contract from the Department of Airport Operations, Ministry of Transport and Tourism, in 1995. Prior to that, the island's meteorological services were provided by a US Navy base on the island.\n\nOfficial website\n"}
{"id": "2339273", "url": "https://en.wikipedia.org/wiki?curid=2339273", "title": "Best available technology", "text": "Best available technology\n\nIn pollution abatement, the best available technology (or BAT) is the technology approved for limiting pollutant discharges with regard to an abatement strategy. Similar terms are \"best available techniques\", \"best practicable means\" or \"best practicable environmental option\". BAT is a moving target on practices, since developing societal values and advancing techniques may change what is currently regarded as \"reasonably achievable\", \"best practicable\" and \"best available\".\n\nA literal understanding will connect it with a \"spare no expense\" doctrine which prescribes the acquisition of the best state of the art technology available, without regard for traditional cost-benefit analysis. In practical use, the cost aspect is also taken into account. [See also discussions on the topic of the precautionary principle which, along with considerations of \"best available technologies\" and \"cost-benefit analyses\", is also involved in discussions leading to formulation of environmental policies and regulations (or opposition to same).]\n\n\"Best practicable means\" was used for the first time in UK national primary legislation in section 5 of the Salmon Fishery Act 1861 and another early use was found in the Alkali Act Amendment Act 1874, but before that appeared in the Leeds Act of 1848.\n\nThe \"BAT\" concept was first time used in the 1992 OSPAR Convention for the protection of the marine environment of the North-East Atlantic for all types of industrial installations (for instance, chemical plants).\n\nSome doctrine deem it already acquired the status of customary law.\n\nIn the United States, BAT or similar terminology is used in the Clean Air Act and Clean Water Act.\n\n\"Best available techniques not entailing excessive costs (BATNEEC)\", sometimes referred to as \"best available technology\", was introduced in 1984 with Directive 84/360/EEC and applied to air pollution emissions from large industrial installations.\n\nIn 1996, Directive 84/360/EEC was superseded by the Integrated pollution prevention and control directive (IPPC), 96/61/EC, which applied the framework concept of \"Best Available Techniques\" (BAT) to the integrated control of pollution to the three media air, water and soil. The concept is also part of the directive's recast in 2008 (2008/1/EC) and its successor directive, the Industrial Emissions Directive 2010/75/EU published in 2010.\n\nAccording to article 15(2) of the Industrial Emissions Directive, emission limit values and the equivalent parameters and technical measures in permits shall be based on the best available techniques, without prescribing the use of any technique or specific technology.\n\nThe directive includes a definition of best available techniques in article 3(10):\n\n\"best available techniques\" means the most effective and advanced stage in the development of activities and their methods of operation which indicates the practical suitability of particular techniques for providing the basis for emission limit values and other permit conditions designed to prevent and, where that is not practicable, to reduce emissions and the impact on the environment as a whole:\n\nBAT for a given industrial sector are described in BAT reference documents (BREFs) as defined in article 3(11) of the Industrial Emissions Directive. BREFs are the result of an exchange of information between European Union Member States, the industries concerned, non-governmental organisations promoting environmental protection and the European Commission pursuant to article 13 of the directive. This exchange of information is often called the Sevilla process because it is steered by the Institute for Prospective Technological Studies of the European Commissions' Joint Research Centre, which is based in Seville. The process is described in detail in Commission Implementing Decision 2012/119/EU. The most important chapter of the BREFs, the BAT conclusions, are published as implementing decisions of the European Commission in the Official Journal of the European Union. According to article 14(3) of the Industrial Emissions Directive, the BAT conclusions shall be the reference for setting permit conditions of large industrial installations.\n\nThe Clean Air Act requires that certain facilities employ Best Available Control Technology to control emissions.\n\nThe Clean Water Act (CWA) requires issuance of national industrial wastewater discharge regulations (called \"effluent guidelines\"), which are based on BAT and several related standards.\n\nIn the development of the effluent standards, the BAT concept is a \"model\" technology rather than a specific regulatory requirement. The U.S. Environmental Protection Agency (EPA) identifies a particular model technology for an industry, and then writes a regulatory performance standard based on the model. The performance standard is typically expressed as a numeric effluent limit measured at the discharge point. The industrial facility may use any technology that meets the performance standard.\n\nA related CWA provision for cooling water intake structures requires standards based on \"best technology available.\"\n\nThe concept of BAT is also used in a number of international conventions such as the Minamata Convention on Mercury, the Stockholm Convention on Persistent Organic Pollutants, or the OSPAR Convention for the protection of the marine environment of the North-East Atlantic.\n\n\n"}
{"id": "398638", "url": "https://en.wikipedia.org/wiki?curid=398638", "title": "Biogeochemical cycle", "text": "Biogeochemical cycle\n\nIn ecology and Earth science, a biogeochemical cycle or substance turnover or cycling of substances is a pathway by which a chemical substance moves through biotic (biosphere) and abiotic (lithosphere, atmosphere, and hydrosphere) compartments of Earth. There are biogeochemical cycles for carbon, oxygen, nitrogen, phosphorus, sulfur, and water; and there are human-induced cycles such as those for mercury and atrazine. In some cycles there are \"reservoirs\" where a substance remains for a long period of time (such as an ocean or lake for water).\n\nEcological systems (ecosystems) have many biogeochemical cycles operating as a part of the system, for example the water cycle, the carbon cycle, the nitrogen cycle, etc.\nAll chemical elements occurring in organisms are part of biogeochemical cycles. In addition to being a part of living organisms, these chemical elements also cycle through abiotic factors of ecosystems such as water (hydrosphere), land (lithosphere), and/or the air (atmosphere).\n\nThe living factors of the planet can be referred to collectively as the biosphere. All the nutrients—such as carbon, nitrogen, oxygen, phosphorus, and sulfur—used in ecosystems by living organisms are a part of a \"closed system\"; therefore, these chemicals are recycled instead of being lost and replenished constantly such as in an open system. \n\nThe flow of energy in an ecosystem is an \"open system\"; the sun constantly gives the planet energy in the form of light while it is eventually used and lost in the form of heat throughout the trophic levels of a food web. Carbon is used to make carbohydrates, fats, and proteins, the major sources of food energy. These compounds are oxidized to release carbon dioxide, which can be captured by plants to make organic compounds. The chemical reaction is powered by the light energy of the sun.\n\nIt is possible for an ecosystem to obtain energy without sunlight. Carbon must be combined with hydrogen and oxygen in order to be utilized as an energy source, and this process depends on sunlight. Ecosystems in the deep sea, where no sunlight can penetrate, use sulfur. Hydrogen sulfide near hydrothermal vents can be utilized by organisms such as the giant tube worm. In the sulfur cycle, sulfur can be forever recycled as a source of energy. Energy can be released through the oxidation and reduction of sulfur compounds (e.g., oxidizing elemental sulfur to sulfite and then to sulfate).\n\nAlthough the Earth constantly receives energy from the sun, its chemical composition is essentially fixed, as additional matter is only occasionally added by meteorites. Because this chemical composition is not replenished like energy, all processes that depend on these chemicals must be recycled. These cycles include both the living biosphere and the nonliving lithosphere, atmosphere, and hydrosphere.\n\nThe chemicals are sometimes held for long periods of time in one place. This place is called a \"reservoir\", which, for example, includes such things as coal deposits that are storing carbon for a long period of time. When chemicals are held for only short periods of time, they are being held in \"exchange pools\". Examples of exchange pools include plants and animals. \n\nPlants and animals utilize carbon to produce carbohydrates, fats, and proteins, which can then be used to build their internal structures or to obtain energy. Plants and animals temporarily use carbon in their systems and then release it back into the air or surrounding medium. Generally, reservoirs are abiotic factors whereas exchange pools are biotic factors. Carbon is held for a relatively short time in plants and animals in comparison to coal deposits. The amount of time that a chemical is held in one place is called its \"residence time\".\n\nThe most well-known and important biogeochemical cycles are shown below:\n\nThere are many biogeochemical cycles that are currently being studied for the first time as climate change and human impacts are drastically changing the speed, intensity, and balance of these relatively unknown cycles. These newly studied biogeochemical cycles include \n\nBiogeochemical cycles always involve hot equilibrium states: a balance in the cycling of the element between compartments. However, overall balance may involve compartments distributed on a global scale.\n\nAs biogeochemical cycles describe the movements of substances on the entire globe, the study of these is inherently multidisciplinary. The carbon cycle may be related to research in ecology and atmospheric sciences. Biochemical dynamics would also be related to the fields of geology and pedology (soil study).\n\nFunctions of biogeochemical cycles\n\n"}
{"id": "54568999", "url": "https://en.wikipedia.org/wiki?curid=54568999", "title": "Biological Hermeneutics", "text": "Biological Hermeneutics\n\nBiological Hermeneutics is the transdisciplinary study of written and printed media using artistic and scientific methods to trace the biological history of the text. For more on transdisciplinary study see transdisciplinarity.\n\nBiological Hermeneutics came into being after the development of the microscope during the 17th century. The most celebrated practitioner Robert Hooke devoted two of his 'Schema' of his ground breaking book \"Micrographia\" to the study of the microbiome of the book.\n\nSchema 12 was drawn from studying the red covers of a ‘small book’ which he judged to be made of ‘Sheeps skin’, he found:… a small white spot of hairy mould, multitudes of which I found to bespeck & whiten [the book]. These spots appear’d, through a good Microscope, to be a very pretty shap’d Vegetative body, which, from almost the same part of the Leather, shot out multitudes of small long cylindrical and transparent stalks …\n\nSchema 33 is dedicated to \"'the study of the small silver coloured\" book-worm'.\n\nThe development of the discipline stalled however with the ascendance of Sir Isaac Newton to the presidency of the Royal Society where he 'did much to obscure Hooke'.\n\nA collection of books maintaining the investigation of the transdiscipline can be found at Chetham's Library where the practice was developed from Hooke's initial investigations through the collecting policy of successive librarians who 'set out to acquire a major collection of books and manuscripts that would cover the whole range of available knowledge and would rival the college libraries of Oxford and Cambridge'\n\nIn order to collect biological material for later study books were sent out into the community as parish libraries. Gorton library is the last surviving example and has yet to be investigated using Biological Hermeneutic techniques.\n\nIn 1831 the foundation of the British Association for the Advancement of Science led to the popularisation of science and enabled a wider group to undertake their own investigations outside of the Royal Society creating a space for the further development of the practice.\n"}
{"id": "45311443", "url": "https://en.wikipedia.org/wiki?curid=45311443", "title": "Central Anatolian steppe", "text": "Central Anatolian steppe\n\nThe Central Anatolian steppe is a Palearctic ecoregion in the temperate grasslands, savannas, and shrublands Biome.\n\nIt is located in the Anatolia region section within central Turkey.\n\n"}
{"id": "11958967", "url": "https://en.wikipedia.org/wiki?curid=11958967", "title": "Climatological observers link", "text": "Climatological observers link\n\nThe Climatological Observers Link (COL) was founded in 1970 by a small group of amateur meteorologists following the exchange of correspondence in the magazine Weather - published by \nThe Royal Meteorological Society. It is the largest enthusiasts' weather observer network within the United Kingdom. The organisation aims to bring together those with an interest in observing the weather, their observations being compiled into monthly bulletins containing news, data and views.\n\nWeather knows no boundaries, and neither does the membership of COL. Stations range from those with a single raingauge to full-size synoptic and official climatological stations. Many of the stations are equipped with a Stevenson screen and Snowdon Raingauge, while some include Campbell–Stokes recorder for measuring sunshine and an Anemometer. Increasingly, members are employing Automatic weather stations.\n\nNot only keen to observer the weather, members are keen to share their expertise and information and data is frequently used in school/university projects, and by practitioners of the law and forensic science.\n"}
{"id": "26834979", "url": "https://en.wikipedia.org/wiki?curid=26834979", "title": "Condensation cloud", "text": "Condensation cloud\n\nA transient condensation cloud, also called Wilson cloud, is observable at large explosions in humid air.\n\nWhen a nuclear weapon or a large amount of a conventional explosive is detonated in sufficiently humid air, the \"negative phase\" of the shock wave causes a rarefaction (reduction in density) of the air surrounding the explosion, but not contained within it. This rarefaction results in a temporary cooling of that air, which causes a condensation of some of the water vapor contained in it. When the pressure and the temperature return to normal, the Wilson cloud dissipates.\n\nSince heat does not leave the affected air mass, this change of pressure is adiabatic, with an associated change of temperature. In humid air, the drop in temperature in the most rarefied portion of the shock wave can bring the air temperature below its dew point, at which moisture condenses to form a visible cloud of microscopic water droplets. Since the pressure effect of the wave is reduced by its expansion (the same pressure effect is spread over a larger radius), the vapor effect also has a limited radius. Such vapor can also be seen in low pressure regions during high–g subsonic maneuvers of aircraft in humid conditions.\n\nScientists observing the Operation Crossroads nuclear tests in 1946 at Bikini Atoll named that transitory cloud a \"Wilson cloud\" because of its similarity to the appearance of the inside of a Wilson cloud chamber, an instrument they would have been familiar with. (The cloud chamber effect is caused by a temporary reduction in pressure in a closed system and marks the tracks of electrically-charged sub-atomic particles.) Analysts of later nuclear bomb tests used the more general term \"condensation cloud\".\n\nThe shape of the shock wave, influenced by different speed in different altitudes, and the temperature and humidity of different atmospheric layers determines the appearance of the Wilson clouds. During nuclear tests, condensation rings around or above the fireball are commonly observed. Rings around the fireball may become stable and form rings around the rising stem of the mushroom cloud.\n\nThe lifetime of the Wilson cloud during nuclear air bursts can be shortened by the thermal radiation from the fireball, which heats the cloud above the dew point and evaporates the droplets.\n\nThe same kind of condensation cloud is sometimes seen above the wings of aircraft in a moist atmosphere. The top of a wing has a reduction of air pressure as part of the process of generating lift. This reduction in air pressure causes a cooling, just as above, and the condensation of water vapor. Hence, the small, transient clouds that appear.\n\nThe vapor cone of a transonic aircraft is another example of a condensation cloud.\n"}
{"id": "12011208", "url": "https://en.wikipedia.org/wiki?curid=12011208", "title": "Diathermancy", "text": "Diathermancy\n\nDiathermancy (from \"dia\" \"through\" and \"thermē\" \"heat\") is the property of some fluids that allows rays of light through them without itself being heated. A diathermanous fluid is thus \"permeable\" by heat.). Diathermancy was first described by German physicist and chemist Heinrich Magnus in the 1800s (). Atmospheric air \"is\" diathermanous; therefore, air is not heated by sunshine, but by long wave heat reflected by soil, and especially, by water on the Earth's surface. Water, on the contrary, \"is not\" diathermanous, and it is heated directly by sunshine.\n\nAtmospheric heat comes from long wave radiation from the soil and, mostly, from the water surface (oceans, lakes, rivers), since water is a not diathermanous body and covers three quarters of Earth's surface. Diathermancy cause subsidence on damp or water surfaces. That is because these areas tend to absorb heat radiation directly from the Sun but very slowly and also emits this radiation to the atmosphere very slowly. Therefore, cold ocean currents have very clear skies, without clouds, because subsidence from cold and heavy air avoids or limits convection since they are opposite processes.\n"}
{"id": "16189349", "url": "https://en.wikipedia.org/wiki?curid=16189349", "title": "Dystrophic lake", "text": "Dystrophic lake\n\nDystrophic lakes, also known as humic lakes, are lakes that contain high amounts of humic substances and organic acids. The presence of these substances causes the water to be brown in colour and have a generally low pH of around 4.0-6.0. Due to these acidic conditions, there is little biodiversity able to survive, consisting mostly of algae, phytoplankton, picoplankton, and bacteria. Ample research has been performed on the many dystrophic lakes located in Eastern Poland, but dystrophic lakes can be found in many areas of the world. \n\nLakes can be categorzied according to the increasing productivity as oligotrophic, mesotrophic, eutrophic, and hypereutrophic. Dystrophic lakes used to be classified as oligotrophic due to their low productivity. However, more recent research shows dystrophia can be associated with any of the trophic types. This is due to a wider possible pH range (acidic 4.0 to more neutral 8.0 on occasion) and other fluctuating properties like nutrient availability and chemical composition. Therefore, dystrophia can be categorized as a condition affecting trophic state rather than a trophic state in itself \n\nDystrophic lakes have a high level of dissolved organic carbon. This consists of contains organic carboxylic and phenolic acids, which keep water pH levels relatively stable by acting as a natural buffer. Therefore, the lake’s naturally acidic pH is largely unaffected by industrial emissions. Dissolved organic carbon also reduces the entry of ultraviolet radiation and can reduce the bioavailability of heavy metals by binding them. There is a significantly lowered calcium content in the water and sediment of a dystrophic lake when compared with a regular lake. Essential fatty acids, like EPA and DHA, are still present in the organisms in humic lakes, but are downgraded in nutritional quality by this acidic environment, resulting low nutritional quality of dystrophic lake's producers, such as phytoplankton. \nHydrochemical Dystrophy Index is a scale used to evaluate the dystrophy level of lakes. In 2016, Gorniak proposed a new set of rules for evaluating this index, using properties such as the surface water pH, electric conductivity, and concentrations of dissolved inorganic carbon, and dissolved organic carbon. \nBecause of different preexisting trophic status, lakes affected by dystrophia may differ strongly in their chemical composition from other dystrophic lakes. Studies of the chemical composition of dystrophic lakes have shown heightened levels of dissolved inorganic nitrogen and higher activities of lipase and glucosidase in polyhummic lakes when compared with oligohumic lakes. In oligohumic lakes, the surface microlayers have higher levels of phosphatase activity than the subsurface microlayers. The opposite is true when the lake is polyhumic. Both oligohumic and polyhumic lakes show higher aminopeptidase activity in the subsurface microlayers than in the surface microlayers.\n\nThe catchment area of a dystrophic lake is usually a coniferous forest rich with peat mosses that spread along the water surface. Despite the presence of ample nutrients, dystrophic lakes can be considered nutrient-poor, because their nutrients are trapped in organic matter, and, therefore. are unavailable to primary producers. The organic matter in dystrophic lakes is mainly is allochthonous: it is terrestrially derived: organic matter removed in the catchment area gradually fills this aquatic environment. Due to this organic matter rich environment, it is bacterioplankton that contraols for the rate of nutrient flux between the aquatic and terrestrial environments. The bacteria are found in high numbers and have great growth potentials despite dystrophic conditions. These bacteria drive the food web of humic lakes by providing energy and supplying usable forms of organic and inorganic carbon to other organisms, primiarily to phagotrophic and mixotrophic flagellates. Decomposition of organic matter by bacteria converts also organic nitrogen and phosphorus into their inorganic forms which are now available for uptake by primary producers which includes both large and small phytoplankton (algae and cyanobacteria). The biological activity of humic lakes is, however, dominated by bacterial metabolism, which dominates the food web. The chemistry of humic lakes makes it difficult for higher trophic levels such as planktivorous fish to establish themselves, leaving a simplified food web consisting mostly of plants, plankton, and bacteria. The dominance of the bacteria means that the dystrophic lakes to have a higher respiration rate than primary production rate.\n\nThe formation of a humic lake via organic runoff has a dramatic effect on the lake ecosystem. Chemical composition changes that increase the lake’s acidity make it difficult for fish and other organisms to proliferate. The quality of the lake for use as drinking water also decreases as the carbon concentration and acidity increase. The fish that do adapt to the increased acidity may also not be fit for human consumption, as the organic pollutants. Concentrations and mobility of heavy metals may also be altered as a result of changes in chemical composition of a humic lake.\n\nLakes are commonly known to be important sinks in the carbon cycle. Due to their high levels of dissolved organic carbon, dystrophic lakes are significantly larger carbon sinks than clear lakes. The elevated levels of carbon concentrations in humic lakes are affected by vegetation patterns in the catchment area, the runoff from which is the main source of organic material. However, changes in these levels can also be attributed to shifts in precipitation, modifications of soil mineralization rates, reduced sulphate deposition, and changes in temperature. All these factors can be affected by climate change. Overall, climate change is expected to increase the supply of organic carbon to lakes and therefore change the character of some to the dystrophic one .\n\nExamples of dystrophic lakes that have been studied by scientists include Lake Suchar II in Poland, and lakes Allgjuttern, Fiolen, and Brunnsjön in Sweden.\n"}
{"id": "10255178", "url": "https://en.wikipedia.org/wiki?curid=10255178", "title": "Eulimene", "text": "Eulimene\n\nEulimene (Ancient Greek: Εὐλιμήνη) was the name of two characters in Greek mythology.\n"}
{"id": "939966", "url": "https://en.wikipedia.org/wiki?curid=939966", "title": "Far Ultraviolet Spectroscopic Explorer", "text": "Far Ultraviolet Spectroscopic Explorer\n\nThe Far Ultraviolet Spectroscopic Explorer (FUSE) is a space-based telescope operated by the Johns Hopkins University Applied Physics Laboratory. \"FUSE\" was launched on a Delta II rocket on 24 June 1999, as a part of NASA's Origins program. \"FUSE\" detected light in the far ultraviolet portion of the electromagnetic spectrum, between 90.5-119.5 nanometres, which is mostly unobservable by other telescopes. Its primary mission was to characterize universal deuterium in an effort to learn about the stellar processing times of deuterium left over from the Big Bang.\n\"FUSE\" resides in a low Earth orbit, approximately 760 km (410 nmi) in altitude, with an inclination of 25 degrees and just less than a 100-minute orbital period. Its Explorer designation is Explorer 77.\n\nOn 12 July 2007, \"FUSE\" final reaction wheel, which is required for accurately pointing a spacecraft, failed and efforts to restart it were unsuccessful. An announcement was made on 6 September that because the fine control needed to perform its mission had been lost, the \"FUSE\" mission would be terminated.\n\nAlthough the original specification was to have a Wolter-type grazing incidence telescope, the final design of the \"FUSE\" telescope comprises four individual mirrors. Each of the four mirrors is a 39-by-35 cm (15.4-by-13.8 in) off-axis parabola. Two mirror segments are coated with silicon carbide for reflectivity at the shortest ultraviolet wavelengths, and two mirror segments are coated with lithium fluoride over aluminum that reflects better at longer wavelengths. This optimizes performance over the entire spectral range.\n\nEach mirror has a corresponding astigmatism-corrected, holographically-ruled diffraction grating, each one on a curved substrate so as to produce four 1.65 m (5.4 ft) Rowland circle spectrographs. The dispersed ultraviolet light is detected by two microchannel plate intensified double delay-line detectors, whose surfaces are curved to match the curvature of the focal plane.\n\nOver 400 scientific papers have been written using data from \"FUSE\", with subjects ranging from cool stars to the intergalactic medium. One of the primary science goals of \"FUSE\" was to study the abundance of deuterium, an isotope of hydrogen. Because of the large number of atomic absorption and emission lines in the far-ultraviolet, \"FUSE\" enabled many studies of galactic, extragalactic and intergalactic chemistry and chemical evolution.\n\nCanada credits work on the FUSE as helping them prepare for making the fine guidance sensors instrument on the James Webb Space Telescope. Canada's contribution is called FGS/NIRISS and is a combined Fine Guidance Sensor, spectrograph, and camera.\n\n\n"}
{"id": "3143195", "url": "https://en.wikipedia.org/wiki?curid=3143195", "title": "GIOVE", "text": "GIOVE\n\nGIOVE , or Galileo In-Orbit Validation Element, is the name for two satellites built for the European Space Agency (ESA) to test technology in orbit for the Galileo positioning system.\n\nGiove is the Italian word for \"Jupiter\". The name was chosen as a tribute to Galileo Galilei, who discovered the first four natural satellites of Jupiter, and later discovered that they could be used as a universal clock to obtain the longitude of a point on the Earth's surface.\n\nThe GIOVE satellites are operated by the GIOVE Mission (GIOVE-M) segment in the frame of the risk mitigation for the In Orbit Validation (IOV) of the Galileo positioning system.\n\nThese validation satellites were previously known as the \"Galileo System Testbed (GSTB) version 2 (GSTB-V2)\". In 2004 the \"Galileo System Test Bed Version 1 (GSTB-V1)\" project validated the on-ground algorithms for Orbit Determination and Time Synchronization (OD&TS). This project, led by ESA and European Satellite Navigation Industries, has provided industry with fundamental knowledge to develop the mission segment of the Galileo positioning system.\n\nGIOVE satellites transmitted multifrequency ranging signals equivalent to the signals of future Galileo: L1BC, L1A, E6BC, E6A, E5a, E5b. The main purpose of the GIOVE mission was to test and validate the reception and performance of novel code modulations designed for Galileo including new signals based on the use of the BOC (Binary Offset Carrier) technique, in particular the high-performance E5AltBOC signal.\n\nPreviously known as \"GSTB-V2/A\", this satellite was constructed by Surrey Satellite Technology Ltd (SSTL).\n\nIts mission has the main goal of claiming the frequencies allocated to Galileo by the ITU. It has two independently developed Galileo signal generation chains and also tests the design of two on-board rubidium atomic clocks and the orbital characteristics of the intermediate circular orbit for future satellites.\n\nGIOVE-A is the first spacecraft whose design is based upon SSTL's new Geostationary Minisatellite Platform (GMP) satellite bus, intended for geostationary orbit. GIOVE-A is also SSTL's first satellite outside low Earth orbit, operating in medium Earth orbit), and is SSTL's first satellite to use deployable Sun-tracking solar arrays. Previous SSTL satellites use body-mounted solar arrays, which generate less power per unit area as they do not face the Sun directly.\n\nIt was launched at 05:19 UTC on December 28, 2005 on a Soyuz-FG/Fregat from the Baikonur Cosmodrome in Kazakhstan.\n\nIt began communicating as planned at 09:01 UTC while circling the Earth at a height of 23,222 km. The satellite successfully transmitted its first navigation signals at 17:25 GMT on 12 January 2006. These signals were received at Chilbolton Observatory in Hampshire, UK and the ESA Station at Redu in Belgium. Teams from SSTL and ESA have measured the signal generated by GIOVE-A to ensure it meets the frequency-filing allocation and reservation requirements for the International Telecommunication Union (ITU), a process that was required to be complete by June 2006.\n\nThe GIOVE-A signal in space is fully representative of the Galileo signal from the point of view of frequencies and modulations, chip rates, and data rates. However, GIOVE-A can only transmit at two frequency bands at a time (i.e., L1+E5 or L1+E6).\n\nGIOVE-A codes are different from Galileo codes. The GIOVE-A navigation message is not representative from the structure and contents viewpoint (demonstration only purpose). The generation of pseudorange measurements and detailed analysis of the tracking noise and multipath performance of GIOVE-A ranging signals have been performed with the use of the GETR (Galileo Experimental Test Receiver) designed by Septentrio.\n\nThere has been some public controversy about the open source nature of some of the Pseudo-Random Noise (PRN) codes. In the early part of 2006, researchers at Cornell monitored the GIOVE-A signal and extracted the PRN codes. The methods used and the codes which were found were published in the June 2006 issue of \"GPS World\". ESA has now made the codes public.\n\nGIOVE A was retired (but not decommissioned) in June 2012, after being raised in altitude to make way for an operational satellite. It remains under command by SSTL.\n\nGIOVE-B (previously called \"GSTB-V2/B\"), has a similar mission, but has greatly improved signal generation hardware.\n\nIt was originally built by satellite consortium European Satellite Navigation Industries, but following re-organization of the project in 2007, the satellite prime contractor responsibility was passed to Astrium.\n\nGIOVE-B also has MEO environment characterization objectives, as well as signal-in-space and receiver experimentation objectives. GIOVE-B carries three atomic clocks: two rubidium standards and the first space-qualified passive hydrogen maser.\n\nThe launch was delayed due to various technical problems, and took place on 27 April 2008 at 04:16 Baikonur time (22:16 UTC Saturday) aboard a Soyuz-FG/Fregat rocket provided by Starsem. The Fregat stage was ignited three times to place the satellite into orbit. Giove-B reached its projected orbit after 02:00 UTC and successfully deployed its solar panels.\n\nGIOVE-B started transmitting navigation signals on May 7, 2008. The reception of the signals by GETR receivers and other means has been confirmed at a few ESA facilities.\n\nAccording to ESA, this is \"a truly historic step for satellite navigation since GIOVE-B is now, for the first time, transmitting the GPS-Galileo common signal using a specific optimised waveform, MBOC (multiplexed binary offset carrier), in accordance with the agreement drawn up in July 2007 by the EU and the US for their respective systems, Galileo and the future GPS III\".\n\n“\"Now with GIOVE-B broadcasting its highly accurate signal in space we have a true representation of what Galileo will offer to provide the most advanced satellite positioning services, while ensuring compatibility and interoperability with GPS\"”, said ESA Galileo Project Manager, Javier Benedicto.\n\nAfter launch, early orbit operations and platform commissioning, GIOVE-B's navigation payload was switched on and signal transmission commenced on May 7 and the quality of these signals is now being checked. Several facilities are involved in this process, including the GIOVE-B Control Centre at Telespazio's facilities in Fucino, Italy, the Galileo Processing Centre at ESA's European Space Research and Technology Centre (ESTEC), in the Netherlands, the ESA ground station at Redu, Belgium, and the Rutherford Appleton Laboratory (RAL) Chilbolton Observatory in the United Kingdom.\nChilbolton's 25-metre antenna makes it possible to analyse the characteristics of GIOVE-B signals with great accuracy and verify that they conform to the Galileo system's design specification. Each time the satellite is visible from Redu and Chilbolton, the large antennas are activated and track the satellite. GIOVE-B is orbiting at an altitude of 23 173 kilometres, making a complete journey around the Earth in 14 hours and 3 minutes.\nThe quality of the signals transmitted by GIOVE-B will have an important influence on the accuracy of the positioning information that will be provided by the user receivers on the ground. On board, GIOVE-B carries a passive hydrogen maser atomic clock, which is expected to deliver unprecedented stability performance.\nThe signal quality can be affected by the environment of the satellite in its orbit and by the propagation path of the signals travelling from space to ground. Additionally, the satellite signals must not create interference with services operating in adjacent frequency bands, and this is also being checked.\nGalileo teams within ESA and industry have the means to observe and record the spectrum of the signals transmitted by GIOVE-B in real time. Several measurements are performed relating to transmitted signal power, centre frequency and bandwidth, as well as the format of the navigation signals generated on board. This allows the analysis of the satellite transmissions in the three frequency bands reserved for it.\nThe GIOVE-B mission also represents an opportunity for validating in-orbit critical satellite technologies, characterising the Medium Earth Orbit (MEO) radiation environment, and to test a key element of the future Galileo system - the user receivers.\n\nWith the delays of GIOVE-B, the European Space Agency again contracted with SSTL for a second satellite, to ensure that the Galileo programme continues without any interruptions that could lead to loss of frequency allocations. Construction of GIOVE-A2 was terminated due to the successful launch and in-orbit operation of GIOVE-B.\n\nThe GIOVE Mission segment, or GIOVE-M, is the name of a project dedicated to the exploitation and experimentation of the GIOVE satellites. The GIOVE Mission was intended to ensure risk mitigation of the In Orbit Validation (IOV) phase of the Galileo positioning system.\n\nThe GIOVE Mission Segment began in October 2005 with the purpose of providing experimental results based on real data to be used for risk mitigation throughout the overall Galileo In Orbit Validation (IOV) phase of the Galileo positioning system. \n\nThe GIOVE Mission segment infrastructure was based on evolution of the Galileo System Test Bed Version 1 (GSTB-V1) infrastructure conceived to process data from the GIOVE-A and GIOVE-B satellites. The GIOVE Mission segment was composed of a central processing facility called the Giove Processing Center (GPC) and a network of thirteen experimental Giove Sensor Stations (GESS).\n\nThe main objectives of the GIOVE Mission Segment experimentation were in the areas of:\n\n"}
{"id": "1781326", "url": "https://en.wikipedia.org/wiki?curid=1781326", "title": "Institute of Space and Astronautical Science", "text": "Institute of Space and Astronautical Science\n\nThe ISAS originated as part of the Institute of Industrial Science of the University of Tokyo, where Hideo Itokawa experimented with miniature solid-fuel rockets (Pencil Rocket and Baby Rocket) in the 1950s. This experimentation eventually led to the development of the Κ (\"Kappa\") sounding rocket, which was used for observations during the International Geophysical Year. By 1960, the Κ-8 rocket had reached an altitude of 200 km.\n\nIn 1964, the rocket group and the \"Institute of Aeronautics\", along with scientific ballooning team, were merged to form within the University of Tokyo. The rocket evolved into the L (\"Lambda\") series, and, in 1970, L-4S-5 was launched as Japan's first artificial satellite Ohsumi.\n\nAlthough \"Lambda\" rockets were only sounding rockets, the next generation of M (\"Mu\") rockets was intended to be satellite launch vehicles from the start. Beginning in 1971, ISAS launched a series of scientific satellites to observe the ionosphere and magnetosphere. Since the launch of Hakucho in 1979, ISAS has had X-ray astronomy satellites consecutively in orbit, until it was briefly terminated by the launch failure of ASTRO-E.\n\nIn 1981, as a part of university system reform, and for the mission expansion, ISAS was spun out from University of Tokyo as an inter-university national research organization, \"Institute of Space and Astronautical Science\".\n\nIn 2003, three national aerospace organizations including ISAS were merged to form Japan Aerospace Exploration Agency (JAXA). The English name \"Institute of Space and Astronautical Science\" is still used, although the Japanese name was changed to 宇宙科学研究本部, (literally, \"Space Science Research Division\", whereas the previous name's literal translation was \"Space Science Laboratory\"). In 2010, the name was changed back to the previous .\n\n\n"}
{"id": "27788616", "url": "https://en.wikipedia.org/wiki?curid=27788616", "title": "Jacob Barnet affair", "text": "Jacob Barnet affair\n\nThe Jacob Barnet affair occurred in 1612 when a Jewish teacher by the name of Jacob Barnet was arrested and imprisoned by officials of the University of Oxford for changing his mind about being baptised.\n\nThroughout the Middle Ages, and until the 1850s the University of Oxford required all students and the faculty staff to be Christians and members of the established church (the Church of England). In addition, Edward I's ban on Jews living in England remained in force until Cromwell overturned it. Nevertheless, a few visiting Jewish Hebrew teachers taught students at the university privately, or worked in the Bodleian Library on Hebrew manuscripts.\n\nIn 1609, the French Huguenot scholar Isaac Casaubon invited Jacob Barnet, an Italian Jew, to his home in Drury Lane, London. During their time together, they discussed Jewish texts on various topics, and Barnet proved to Casaubon that Jesus had been buried in accordance with standard Jewish burial practice rather than (as argued by Cardinal Baronio) in a new way that became the method of Catholic burial. Casaubon thereafter employed Barnet as his secretary, and in 1610 the two of them came to Oxford.\n\nBarnet's personal qualities, as well as his erudition, meant that he was liked and respected by scholars at the university. While at Oxford, he decided to be baptised as a Christian, and told Casaubon of his decision; Casaubon told the Vice-Chancellor, who (like other members of the university) was pleased with Barnet's decision. Preparations were made for Barnet to be baptised at a grand service in the University Church of St Mary the Virgin.\n\nBarnet, however, did not attend the ceremony, having decided against converting; he left Oxford on foot. According to the 17th-century Oxford antiquarian Anthony Wood, Arthur Lake, the Warden of New College, Oxford, sent pursuers after Barnet on foot and on horseback; Lake was one of the \"learned Doctors\" of the university whom Wood said had been \"deceived\" by Barnet's \"tricks\". Barnet was apprehended and taken back to Oxford, where he refused to be baptised. He was then detained in the unpleasant conditions of the Bocardo Prison. In the meantime, William Twyss, who was to preach at the service, changed his sermon to address Barnet's change of heart, demonstrating (according to Wood) \"God's just judgment upon that perverse nation and people, whom he had given up to a reprobate sense even to this very day.\"\n\nCasaubon was appalled by the treatment of Barnet and considered it a \"violation of Christian ethics\". He later said that he did not think that changing one's mind on such a matter of religion was a criminal matter. He appealed on Barnet's behalf to King James I, who issued a warrant for his release. Some months after his arrest, he was put on a ship to France and exiled. Later, Barnet was an adviser at the French court on Jewish matters.\n"}
{"id": "57291471", "url": "https://en.wikipedia.org/wiki?curid=57291471", "title": "Jeanne Socrates", "text": "Jeanne Socrates\n\nJeanne Socrates (born 17 August 1942) is a British yachtswoman. She holds the record as the oldest female to have circumnavigated the world single-handed, and she is the only woman to have circumnavigated solo nonstop from N. America. She was awarded the Cruising Club of America's Blue Water Medal in 2013.\n\nOn 28 September 2017, after major injuries due to a fall from a ladder while working on her yacht \"Nereida\", a 38-foot Najad 380, she postponed a planned attempt to gain the record as the oldest circumnavigator of either sex, currently held by Japanese Minoru Saitō who sailed round the world in 2005 aged 71. \n\n"}
{"id": "38592096", "url": "https://en.wikipedia.org/wiki?curid=38592096", "title": "List of Award of Garden Merit flowering cherries", "text": "List of Award of Garden Merit flowering cherries\n\nThe following species and cultivars in the genus \"Prunus\" currently (2016)\nhold the Royal Horticultural Society's Award of Garden Merit. All are described as flowering or ornamental cherries, though they have mixed parentage, and some have several or unknown parents. They are valued for their spring blossom, and in some cases ornamental fruit and bark. This list does not include the edible, or culinary, fruit trees in the genus \"Prunus\" (cherries, peaches, almonds, plums etc.). Dimensions shown are the maximum, which can often be restricted by regular pruning. Many cultivars also lend themselves to bonsai treatment.\nA note on species names; where only \"Prunus\" is indicated, the species or hybrid name is unknown or conjectural.\n\n"}
{"id": "5876014", "url": "https://en.wikipedia.org/wiki?curid=5876014", "title": "List of Deinopidae species", "text": "List of Deinopidae species\n\nThis page lists all described species of the spider family Deinopidae as of Dec. 24, 2016.\n\n\"Deinopis\" \n\n\"Menneus\" \n\n\n"}
{"id": "2943384", "url": "https://en.wikipedia.org/wiki?curid=2943384", "title": "List of Lepidoptera that feed on birches", "text": "List of Lepidoptera that feed on birches\n\nBirches, \"Betula\" species, are used as food plants by the larvae of a large number of Lepidoptera species including:\n\nSpecies which feed exclusively on \"Betula\"\n\n\nSpecies which feed on \"Betula\" and other plants\n\n\n"}
{"id": "650558", "url": "https://en.wikipedia.org/wiki?curid=650558", "title": "List of Viola species", "text": "List of Viola species\n\nThis is a list of species in the plant genus \"Viola\", often known as violets or pansies.\n\n\"Viola\" is the largest genus in the family Violaceae, containing between 525 and 600 species.\n\nSpecies include:\nKnown hybrids in genus \"Viola\" include:\n"}
{"id": "46894512", "url": "https://en.wikipedia.org/wiki?curid=46894512", "title": "List of hills and mountains in Denmark", "text": "List of hills and mountains in Denmark\n\nThis is a list of hills and mountains in Denmark.\n\nThis table lists only hills in the country of Denmark, excluding Danish territories (Faroe Islands and Greenland). Also note that the listing only considers natural formations.\n\n\"Source: Kort & Matrikelstyrelsen, Faktoider.nu.\"\n\n"}
{"id": "53948906", "url": "https://en.wikipedia.org/wiki?curid=53948906", "title": "List of natural reservations of Suceava County", "text": "List of natural reservations of Suceava County\n\nThe list of natural reservation of Suceava County includes protected areas of national interest (nature reserves), located in the administrative territory of Suceava County, Romania.\n\n"}
{"id": "11277875", "url": "https://en.wikipedia.org/wiki?curid=11277875", "title": "List of rivers of Taiwan", "text": "List of rivers of Taiwan\n\nThis is a list of rivers in Taiwan which are over :\n\n\n\n\n"}
{"id": "6984374", "url": "https://en.wikipedia.org/wiki?curid=6984374", "title": "List of threatened flora of Australia", "text": "List of threatened flora of Australia\n\nThe list of threatened flora of Australia includes all plant species listed as critically endangered or endangered in Australia under the \"Environment Protection and Biodiversity Conservation Act 1999\" (EPBC Act).\n\n"}
{"id": "10326601", "url": "https://en.wikipedia.org/wiki?curid=10326601", "title": "Montroydite", "text": "Montroydite\n\nMontroydite is the mineral form of mercury(II) oxide with formula HgO. It is a rare mercury mineral. It was first described for an occurrence in the mercury deposit at Terlingua, Texas and named for Montroyd Sharp who was an owner of the deposit.\n\nMontroydite occurs in mercury deposits of hydrothermal origin. Associated minerals include: native mercury, cinnabar, metacinnabar, calomel, eglestonite, terlinguaite, mosesite, kleinite, edgarbaileyite, gypsum, calcite and dolomite.\n"}
{"id": "52792457", "url": "https://en.wikipedia.org/wiki?curid=52792457", "title": "Naval regions and districts of the Kriegsmarine", "text": "Naval regions and districts of the Kriegsmarine\n\nNaval regions and districts were the official shore establishment of Nazi Germany's Kriegsmarine during World War II. The Kriegsmarine shore establishment was divided into four senior regional commands, who were in turn subordinated to the operational Navy Group commanders who commanded all sea and shore naval forces within a particular geographical region. Within each naval region were several subordinate naval districts who were responsible for all navy shore activities within their area of responsibility, most significantly were the various German ports of occupied Europe.\n\nThe naval regions (\"Marineoberkommando\") were the senior most shore command in a given geographical area and were subordinate to the Navy Group commanders. A total of four naval regions were eventually established in occupied Europe during the Second World War. A deputy commander, known as the \"2. Admiral\" commanded staff units and oversaw regional administrative matters. Specifically, the deputy region commander oversaw the \"Schiffs–Stamm-Abteilung\" (Ship's Administration Department) which was a liaison for port commands and also served as the ultimate authority for personnel in transit or stationed in shore naval garrisons. For those permanent assigned to the ship's department, a subordinate \"Schiffs–Stamm-Regiment\" existed as an intermediary command.\n\nOther major subordinates to the regional command were the \"Befehlshaber der Sicherung\" (Commander of Security), \"Inspektion des Schiffsmaschinewesens\" (Naval engineering inspector), \"Artilleriearsenalinspektionen\" (Inspector of arsenals and artillery), and the \"Sanitätsamt der Marinestation\" (Medical department). A regional signals detachment (\"Marine–Nachrichten–Abteilung\") also existed to coordinate orders and messages between the various subordinate commands.\n\nAll naval regions were permanently assigned at least one navy shore combat unit. In most cases this was known as the \"Marine–Schützen–Bataillon\"; a larger formation known as a \"Marine–Bordflak–Brigade\" also existed. Engineering and pioneer naval units were typically grouped into a \"Marine–Festungspionier–Bataillon\". Regional commands were also responsible for the operation of all naval prisons. Naval prisoner-of-war camps were under the jurisdiction of a senior officer known as the \"Kommandantur des Marine–Kriegsgefangenen– und Interniertenlagers\".\n\nAll naval regions further maintained a legal office as well as a war correspondence company (\"Marinekriegsberichterkompanie\"). All induction and recruiting centers operated through an office known as the \"Marine–Abrechnungs– und Vorprüfungsamt\" while the \"Dienststelle für Eignungsprüfung\" administrated certification examinations for the various naval rates. Each naval region also maintained a billeting and housing office, known as the \"Abwicklungsamt\".\n\nThe North Sea naval region was the first to be established and was originally known as \"Der Kommandierende Admiral der Marinestation der Nordsee\". The command was formed from a preexisting unit of the Reichsmarine, known as the Marinestation der Nordsee. In the spring of 1943, the title was renamed as the \"Marineoberkommando der Nordsee\". Major subordinate districts were the \"Deutsches Marinekommando Italien\" (this command eventually became Naval Region South) and the \"Admiral in den Niederlanden\" which oversaw all German naval matters in the occupied Netherlands.\n\nThe following officers held the title of regional commander during the years of Naval region North Sea's existence.\n\n\nMajor port cities under the control of Naval Region North Sea were Wilhelmshaven, Hamburg, and Bremen. The regional command was also the authority for all naval observatories in the area. A central administrative office, known as the \"Heimatverwaltung West\" coordinated all shore activities while the \"Heimatverwaltung Ausland\" oversaw region personnel deployed to other areas of the Kriegsmarine. The \"Troßschiffverband Nord\" was the department responsible for the maintenance and upkeep of all troop ships on call for deployment into the North Sea.\n\nGermany had maintained a naval presence in the Baltic Sea since the 19th century, and in 1865 the earliest continuous command in the area, the Marinestation der Ostsee, was established in Kiel. By June 1935, the Reichsmarine had established a position known as \"Der Chef der Marinestation der Ostsee\". In November 1938, the Kriegsmarine created the post of \"Der Kommandierende General der Marinestation der Ostsee\", also headquartered at Kiel. The region was commanded by a full admiral (or general admiral) with a deputy known as the \"2. Admiral der Ostseestation\".\n\nSubordinated to the Baltic Sea regional commander were three \"coastal commanders\" (\"Küstenbefehlshaber\") who oversaw various harbor and coastal defense units. The port superintendent of Kiel (\"Marineintendantur Kiel\") also reported directly to the regional command as well as several inspection units for naval weapons, artillery, torpedoes, and well as an Inspector for Training and Education (\"Inspektion des Bildungswesens der Marine\"). The naval region also contained a signals unit, medical department, and personnel branch. The commander of U-boats was originally administratively subordinated to the Baltic regional commander, but became an independent separate command after 1938.\n\nIn mid 1942, the name of the command was shortened to \"Kommando der Marinestation der Ostsee\" and in 1943 adopted its final name as \"Marineoberkommando Ostsee\". The two primary subordinate naval districts were the \"Admiral Dänemark\" (controlling all shore based German naval forces in Denmark) and the \"Admiral Ostland\" which controlled naval shore forces east of Kiel, including those stationed in Poland.\n\nThe following Kriegsmarine officers held the position as Baltic Sea regional commander:\n\n\nShore activities in the Mediterranean Sea were originally overseen by an office, known as the \"Chef des Deutschen Marineverbindungsstabes\", headed by Rear Admiral Eberhard Weichold and established in June 1940. The following year, the office adopted the lengthy title \"Deutscher Admiral beim Admiralstab der königlich italienischen Marine\". In November 1941, the office was re-designated as the \"Befehlshaber des Deutschen Marinekommandos Italien\". In March 1943, the command was assumed by Rear Admiral Wilhelm Meendsen-Bohlken. Meedsen-Bohlken was briefly replaced by Vice Admiral Friedrich Ruge, in May 1943, before Meedsen-Bohlken returned to the same post that August. In July 1944, command was assumed by Vice Admiral Werner Löwisch. In January 1945 the Italian naval shore command was renamed as the \"Oberbefehlshaber Marineoberkommando Süd\".\n\nThe final Navy regional command established during the Second World War was the \"Marineoberkommando in Norwegen\", established in late 1943 to deal specifically with German naval forces in Norway. Admiral Otto Ciliax served as regional commander until the last month of the war when he was replaced by Admiral Theodor Krancke.\n\nThe headquarters of the Norwegian naval region was at Oslo where was maintained a headquarters staff, signals company, and war correspondence unit. A naval weapons office, known as the \"Torpedoarsenal Norwegen\" oversaw all logistics for naval arms, in particular submarine torpedoes, for Kriegsmarine units stationed in Norway. The region also operationally controlled a submarine netting group known as \"Netzsperrgruppe Nord\". In addition to regular naval shore commands,the Norwegian Naval Region also hosted four naval construction brigades (\"Bauaufsicht der Kriegsmarine\") which were stationed in Horten, Bergen, Trondheim, and Tromsø\n\nNaval districts were the direct operational forces for all shore units of the Kriegsmarine and were assigned coastal areas of responsibility as well as operational command of any permanently assigned submarine or ship flotillas (although administratively, these units were under the various type commanders). Most naval regions also maintained a staff headquarters unit, signals unit, war correspondence company, as well as a regional medical clinic.\n\nNavy districts were operationally subordinated to Navy group commanders and were organized by either geographical region or country of occupation. The \"Admiral Deutsche Bucht\" was headquartered in Wilhelmshaven and commanded German ports along the North Sea. The \"Admiral z.b.V. Südost\" was in command of inland waterways, river units, and was headquartered at Traunstein.\n\nAfter the occupation of France and the Low Countries, the Kriegsmarine established a single regional command for these areas which was known as \"Admiral West\". The command was first stood up in May 1940, while the Battle of France was still ongoing, with its first commander Admiral Karlgeorg Schuster. In June 1940, following the surrender of France, the command's name changed to \"Kommandierender Admiral Frankreich\" and was headquartered in Paris. In May 1941, command as \"Admiral Frankreich\" was passed to Otto Schultze. In August 1942, the final commander, Wilhelm Marschall was appointed and would hold the command until that November. At that time the naval region of France was broken up into smaller areas as a result of Case Anton when Germany occupied the entirety of France.\n\nThe three late war naval districts of France were:\n\n\nFriedrich Rieve commanded the English channel district during the Invasion of Normandy while Ernst Scheurlen commanded southern France during Operation Dragoon. In both these cases, the commands were disbanded shortly thereafter due to an overrun of the districts by Allied forces. The \"Atlantic Coast\" command, overseeing the majority of naval forces in western France, remained active until early 1945 under its final commander, Admiral Johannes Bachmann.\n\nA special naval area was also established for the city of Paris and was known as the \"Höheres Kommando der Marinedienststellen in Groß-Paris\" (Supreme Command for Naval Services in the Greater Paris Area). The command contained a headquarters staff, several transport units, a signals and communications division, legal office, and medical staff. Werner Lindenau served as naval commander of Paris from June 1943 until the Germans evacuated the city the following year.\n\nGerman port facilities in occupied Belgium were never formed into an independent command and were subordinated to other regions and naval districts. Naval shore authority in the Netherlands was originally a subordinate officer to Admiral West and was known as the \"Marinebefehlshaber in den Niederlanden\". The original commander was Lothar von Arnauld de la Perière who briefly held the post for a one month in May 1940 before command was assumed by Helmuth Kienast. In June 1943, the post was past to \"Vizeadmiral\" Kurt Caesar Hoffmann who was in turn relieved by Gustav Kleikamp in March 1943. the following month, the Netherlands district became an independent command known as the \"Kommandierender Admiral in den Niederlanden\". The final command of the district was Vice Admiral Rudolf Stange, who held command in January 1945 until the Germans evacuated the country in the face of advancing Allied forces.\n\nWhen German occupied Denmark in April 1940, the Kriegsmarine established a naval command for the entire country known as the \"Marinebefehlshaber Dänemark\". The command was first held by Admiral Raul Mewis and maintained two subordinate naval districts known as the \"Abschnitt Nordjütland\" and the \"Abschnitt Südjütland und dänische Inseln\". In March 1943 the name of the command was changed to the \"Kommandierender Admiral Dänemark\", frequently shortened to simply \"Admiral Dänemark\". The command was then assumed by Vice Admiral Hans-Heinrich Wurmbach, who held the post until the end of World War II. In April 1944, after Germany had placed all of Denmark under military occupation the previous fall, the command name was again changed to \"Kommandierender Admiral Skagerak\".\n\nThe German occupation of Norway, with its direct access to the North Sea, required the Kriegsmarine to form a major naval command to deal with the vastness of the Norwegian coastline, along with its many ports and harbors. The originally Norwegian naval command was known as the \"Kommandierender Admiral Norwegen\" and the post was held by Hermann Böhm between 1940 and 1943. By the end of 1940, the Norwegian naval area had been elevated to the status of a naval region (the region name would formally change in February 1943), with the following subordinate Norwegian naval regions established.\n\n\nThe Norwegian naval region and areas would continue in full operation until the end of World War II and consisted of the largest number of Kriegsmarine forces which remained intact upon Germany's surrender in May 1945.\n\nThe Baltic Sea naval area was first formed in November 1941, headquartered at Danzig, and responsible for German port and harbors east of the main naval region out of Kiel. The geographical area of the command was relatively small and the posted commander never held a higher rank than \"Kapitän zur See\". After Germany invaded the Soviet Union, and occupied the Baltic states, the command's responsibility increased and eventually held authority over several naval shore facilities, including medical units, arsenals, and communication commands in Libau, Reval, and Riga.\n\nTwo of the more unique units assigned to the Baltic area were a \"Pathologische Abteilung\", consisting of naval medical personnel conducting pathology research, as well as an island station at Tütters. The area command also oversaw several coastal monitoring stations (\"Küstenüberwachungsstellen\") which were incorporated into the Kriegsmarine system of sea defense zones.\n\nIn 1944, as the Baltic countries came under danger of liberation by Soviet forces, the Baltic Sea area was divided into two geographical regions (east and west) with Vice Admiral Werner Lange assuming command in the west (as \"Admiral Westliche Ostsee\") while Theodor Burchardi assumed command as \"Admiral östliche Ostsee\" in the east. Following liberation by Soviet forces, the naval commands in Riga were accused of war crimes for utilizing Slavic and Jewish slave labor for hard labor on German controlled docks.\n\nThe Kriegsmarine maintained four smaller naval commands to deal with various shore facilities not covered under another major naval area. The largest was the \"Admiral Nordmeer\", formed in October 1941 as a direct subordinate to the Naval regional commander for the North Sea. Hubert Schmundt served as the North Sea area commander until 1942 when he was replaced by August Thiele. Otto Klüber then held the post until command was assumed by a deputy in 1944.\n\nAn independent naval region was the \"Admiral Schwarzes Meer\", responsible for shore operations in the Black Sea. The command had originally been established as a navy expeditionary group before being renamed as the \"Deutsche Marinemission Rumänien\" in 1942. The name of the command was changed the following year to \"Admiral Schwarzes Meer\" before adopting its final name as the \"Kommandierender Admiral Schwarzes Meer\" in 1944. Several officers held this posting until Germany finally withdrew from the area in the face of Red Army advance.\n\nBlack Sea area commanders\n\n\nThe Black Sea area command held the same authority as a naval region and possessed a headquarters staff at Konstanza with an attached signals unit and naval pioneer battalion. The area command also held operational control over the deployment of two assigned submarine chaser flotillas as well as a flotilla of auxiliary minesweepers and patrol-sentry boats. The 30th U-boat Flotilla was also deployed to the area, however operational control was held by the \"Befehlshaber der U-Boote\". Later in the war, the Black sea area gained a submarine netting unit known as \"Netzsperrgruppe Schwarzes Meer\".\n\nIn addition to standard ports and harbors, the Black Sea area maintained a number of commands for smaller inlet naval stations, known as \"Seetransportstelle\". Around the Black Sea area were also interspersed naval directorate stations (\"Marine-Intendanturdienststelle\") which coordinated all activities across the geographical region.\n\nFollowing the German conquest of Yugoslavia and the invasion of Greece, the Kriegsmarine set up two naval commands for regional operations in the Aegean and Adriatic Seas. The Aegean naval command was first established in February 1941, under Rear Admiral Hans-Hubertus von Stosch. Command was then assumed in the fall of that year by Erich Förste, who held it until February 1943, when command was past to Werner Lange.\n\nThe Aegean naval command consisted of a headquarters staff as well as an attached signals unit and pioneer battalion. A naval garrison (\"Wachkompanie\") was stationed at Salamis while the shipyards in Athens also fell under the regional command. The region further maintained a transportation company, two war correspondence companies, and was the administrative senior authority for the third destroyer flotilla and the 23rd U-boat Flotilla. Later in the war, the region added a legal office, quartermaster command, as well as a submarine netting squadron (\"Netzsperrgruppe Süd\"). The region was also the reporting senior for two German hospital ships. \n\nThe Adriatic naval region (\"Admiral Adria\") was established in September 1943 under \"Vizeadmiral\" Joachim Lietzmann. The command originally consisted of a headquarters staff in Trieste accompanied by a communications unit and pioneer command. By 1944, smaller offices of the region, dealing with logistics, operations, torpedo armament, and naval artillery placements, had been established in Pula, Dubrovnik (Ragusa), Spalato, and Durrës. In July 1944, command was assumed by Vice Admiral Werner Löwisch.\n\nIn larger Naval regions, an intermediary command between the regions and local forces was the \"Navy Area\" (\"Marine–Abschnitt\") of which the Kriegsmarine established seventeen such areas during the Second World War. In occupied territories, as well as some major German ports, these areas were known as \"Kriegsmarinedienststellen\" (Navy War Service Areas) with fourteen established between 1941 and 1945. Navy areas were typically commanded by a senior naval officer, most often a \"Kapitän zur See\" or \"Korvettenkapitän\", who was known as \"Der Kommandant im Abschnitt\".\n\n\n\nSea defense zones were tactical naval areas, along the coastline of occupied Europe, intended to provide an operational command chain in the event of an actual enemy attack. The zones were commanded by an officer normally ranked as either \"Kapitän zur See\" or \"Konteradmiral\". The sea defense zone commander (\"Kommandant der Seeverteidigung\") answered to the Navy regional commanders and would take tactical control over all shore forces in a given area should an enemy launch an actual attack against a segment of German coastline.\n\nIn practice, the sea defense zones became well tested when the Allies invaded western Europe, in particular at the battle of Normandy. Sea Defense zone forces also fought fiercely to avoid losing Germany's submarine bases in France, in one case holding out for several months under Allied siege before surrendering.\n"}
{"id": "14414065", "url": "https://en.wikipedia.org/wiki?curid=14414065", "title": "Polar amplification", "text": "Polar amplification\n\nPolar amplification is the phenomenon that any change in the net radiation balance (for example greenhouse intensification) tends to produce a larger change in temperature near the poles than the planetary average. On a planet with an atmosphere that can restrict longwave radiation to space (a greenhouse effect), surface temperatures will be warmer than a simple planetary equilibrium temperature calculation would predict. Where the atmosphere or an extensive ocean is able to transport heat polewards, the poles will be warmer and equatorial regions cooler than their local net radiation balances would predict.\n\nIn the extreme, the planet Venus is thought to have experienced a very large increase in greenhouse effect over its lifetime, so much so that its poles have warmed sufficiently to render its surface temperature effectively isothermal (no difference between poles and equator). On Earth, water vapor and trace gasses provide a lesser greenhouse effect, and the atmosphere and extensive oceans provide efficient poleward heat transport. Both palaeoclimate changes and recent global warming changes have exhibited strong polar amplification, as described below.\n\nAn observation based study related to Arctic amplification was published in 1969 by Mikhail Budyko, the study conclusion has been summarized as, \"Sea ice loss affects Arctic temperatures through the surface albedo feedback.\" The same year a similar model was published by William D. Sellers. Both studies attracted significant attention since they hinted at the possibility for a runaway positive feedback within the global climate system.\n\nFeedbacks associated with sea ice and snow cover are widely cited as the main cause of recent terrestrial polar amplification. However, amplification is also observed in model worlds with no ice or snow. It appears to arise both from a (possibly transient) intensification of poleward heat transport and more directly from changes in the local net radiation balance (an overall decrease in outward radiation will produce a larger relative increase in net radiation near the poles than near the equator).\n\nSome examples of climate system feedbacks thought to contribute to recent polar amplification include the reduction of snow cover and sea ice, changes in atmospheric and ocean circulation, the presence of anthropogenic soot in the Arctic environment, and increases in cloud cover and water vapor. Most studies connect sea ice changes to polar amplification. Some models of modern climate exhibit Arctic amplification without changes in snow and ice cover. The individual processes contributing to polar warming are critical to understanding climate sensitivity.\n\nIt has been estimated that 70% of global wind energy is transferred to the ocean and takes place within the Antarctic Circumpolar Current (ACC). Eventually, upwelling due to wind-stress transports cold Antarctic waters through the Atlantic surface current, while warming them over the equator, and into the Arctic environment. Thus, warming in the Arctic depends on the efficiency of the global ocean transport and plays a role in the polar see-saw effect.\n\nDecreased oxygen and low-pH during La Niña are processes that correlate with decreased primary production and a more pronounced poleward flow of ocean currents. It has been proposed that the mechanism of increased Arctic surface air temperature anomalies during La Niña periods of ENSO may be attributed to the Tropically Excited Arctic Warming Mechanism (TEAM), when Rossby waves propagate more poleward, leading to wave dynamics and an increase in downward infrared radiation.\n\nPolar amplification is quantified in terms of a polar amplification factor, generally defined as the ratio of some change in a polar temperature to a corresponding change in a broader average temperature:\n\nwhere formula_2 is a change in polar temperature and formula_3 is, for example, a corresponding change in a global mean temperature.\n\nCommon implementations define the temperature changes directly as the anomalies in surface air temperature relative to a recent reference interval (typically 30 years). Others have used the ratio of the variances of surface air temperature over an extended interval.\n\nIt is observed that Arctic and Antarctic warming commonly proceed out of phase because of orbital forcing, resulting in the so-called polar see-saw effect.\n\nThe glacial / interglacial cycles of the Pleistocene provide extensive palaeoclimate evidence of polar amplification, both from the Arctic and the Antarctic. In particular, the temperature rise since the last glacial maximum years ago provides a clear picture. Proxy temperature records from the Arctic (Greenland) and from the Antarctic indicate polar amplification factors on the order of 2.0.\n\nSuggested mechanisms leading to the observed Arctic amplification include Arctic sea ice decline (open water reflects less sunlight than sea ice), and atmospheric heat transport from the equator to the Arctic.\n\nJennifer Francis told Scientific American in 2017, \"A lot more water vapor is being transported northward by big swings in the jet stream. That’s important because water vapor is a greenhouse gas just like carbon dioxide and methane. It traps heat in the atmosphere. That vapor also condenses as droplets we know as clouds, which themselves trap more heat. The vapor is a big part of the amplification story—a big reason the Arctic is warming faster than anywhere else.\"\n\nStudies have linked rapidly warming Arctic temperatures, and thus a vanishing cryosphere, to extreme weather in mid-latitudes. In particular, one hypothesis links polar amplification to extreme weather by changing the polar jet stream. However, a 2013 study noted that extreme events in particular associated with sea ice and snow cover decline have not yet been observed for long enough to distinguish natural climate variability from impacts related to recent climate change.\n\nStudies published in 2017 and 2018 identified stalling patterns of rossby waves, in the northern hemisphere jet stream, to have caused almost stationary extreme weather events, such as the 2018 European heatwave, the 2003 European heat wave, 2010 Russian heat wave, 2010 Pakistan floods - these events have been linked to global warming, the rapid heating of the Arctic.\n\nAccording to a 2009 study the Atlantic Multi-decadal Oscillation (AMO) is highly correlated with changes in Arctic temperature, suggesting that the Atlantic Ocean thermohaline circulation is linked to temperature variability in the Arctic on a multi-decadal time scale. A study in 2014 concluded that Arctic amplification significantly decreased cold-season temperature variability over the Northern Hemisphere in recent decades. Cold Arctic air intrudes into the warmer lower latitudes more rapidly today during autumn and winter, a trend projected to continue in the future except during summer, thus calling into question whether winters will bring more cold extremes. According to a 2015 study, based on computer modelling of aerosols in the atmosphere, up to 0.5 degrees Celsius of the warming observed in the Arctic between 1980 and 2005 is due to aerosol reductions in Europe.\n\n"}
{"id": "46980", "url": "https://en.wikipedia.org/wiki?curid=46980", "title": "Pollen", "text": "Pollen\n\nPollen is a fine to coarse powdery substance comprising pollen grains which are male microgametophytes of seed plants, which produce male gametes (sperm cells). Pollen grains have a hard coat made of sporopollenin that protects the gametophytes during the process of their movement from the stamens to the pistil of flowering plants, or from the male cone to the female cone of coniferous plants. If pollen lands on a compatible pistil or female cone, it germinates, producing a pollen tube that transfers the sperm to the ovule containing the female gametophyte. Individual pollen grains are small enough to require magnification to see detail. The study of pollen is called palynology and is highly useful in paleoecology, paleontology, archaeology, and forensics.\n\nPollen in plants is used for transferring haploid male genetic material from the anther of a single flower to the stigma of another in cross-pollination. In a case of self-pollination, this process takes place from the anther of a flower to the stigma of the same flower.\n\nPollen itself is not the male gamete. Each pollen grain contains vegetative (non-reproductive) cells (only a single cell in most flowering plants but several in other seed plants) and a generative (reproductive) cell. In flowering plants the vegetative tube cell produces the pollen tube, and the generative cell divides to form the two sperm cells.\n\nPollen is produced in the microsporangia in the male cone of a conifer or other gymnosperm or in the anthers of an angiosperm flower. Pollen grains come in a wide variety of shapes, sizes, and surface markings characteristic of the species (see electron micrograph, right). Pollen grains of pines, firs, and spruces are winged. The smallest pollen grain, that of the forget-me-not (\"Myosotis\" spp.), is around 6 µm (0.006 mm) in diameter. Wind-borne pollen grains can be as large as about 90–100 µm.\n\nIn angiosperms, during flower development the anther is composed of a mass of cells that appear undifferentiated, except for a partially differentiated dermis. As the flower develops, four groups of sporogenous cells form within the anther. The fertile sporogenous cells are surrounded by layers of sterile cells that grow into the wall of the pollen sac. Some of the cells grow into nutritive cells that supply nutrition for the microspores that form by meiotic division from the sporogenous cells.\n\nIn a process called microsporogenesis, four haploid microspores are produced from each diploid sporogenous cell (microsporocyte, pollen mother cell or meiocyte), after meiotic division. After the formation of the four microspores, which are contained by callose walls, the development of the pollen grain walls begins. The callose wall is broken down by an enzyme called callase and the freed pollen grains grow in size and develop their characteristic shape and form a resistant outer wall called the exine and an inner wall called the intine. The exine is what is preserved in the fossil record. Two basic types of microsporogenesis are recognised, simultaneous and successive. In simultaneous microsporogenesis meiotic steps I and II are completed prior to cytokinesis, whereas in successive microsporogenesis cytokinesis follows. While there may be a continuum with intermediate forms, the type of microsporogenesis has systematic significance. The predominant form amongst the monocots is successive, but there are important exceptions.\n\nDuring microgametogenesis, the unicellular microspores undergo mitosis and develop into mature microgametophytes containing the gametes. In some flowering plants, germination of the pollen grain may begin even before it leaves the microsporangium, with the generative cell forming the two sperm cells.\n\nExcept in the case of some submerged aquatic plants, the mature pollen grain has a double wall. The vegetative and generative cells are surrounded by a thin delicate wall of unaltered cellulose called the endospore or intine, and a tough resistant outer cuticularized wall composed largely of sporopollenin called the exospore or exine. The exine often bears spines or warts, or is variously sculptured, and the character of the markings is often of value for identifying genus, species, or even cultivar or individual. The spines may be less than a micron in length (spinulus, plural spinuli) referred to as spinulose (scabrate), or longer than a micron (echina, echinae) referred to as echinate. Various terms also describe the sculpturing such as reticulate, a net like appearance consisting of elements (murus, muri) separated from each other by a lumen (plural lumina).\n\nThe pollen wall protects the sperm while the pollen grain is moving from the anther to the stigma; it protects the vital genetic material from drying out and solar radiation. The pollen grain surface is covered with waxes and proteins, which are held in place by structures called sculpture elements on the surface of the grain. The outer pollen wall, which prevents the pollen grain from shrinking and crushing the genetic material during desiccation, is composed of two layers. These two layers are the tectum and the foot layer, which is just above the intine. The tectum and foot layer are separated by a region called the columella, which is composed of strengthening rods. The outer wall is constructed with a resistant biopolymer called sporopollenin.\n\nPollen apertures are regions of the pollen wall that may involve exine thinning or a significant reduction in exine thickness. They allow shrinking and swelling of the grain caused by changes in moisture content. Elongated apertures or furrows in the pollen grain are called colpi (singular: colpus) or sulci (singular: sulcus). Apertures that are more circular are called pores. Colpi, sulci and pores are major features in the identification of classes of pollen. Pollen may be referred to as inaperturate (apertures absent) or aperturate (apertures present). The aperture may have a lid (operculum), hence is described as operculate. However the term inaperturate covers a wide range of morphological types, such as functionally inaperturate (cryptoaperturate) and omniaperturate. Inaperaturate pollen grains often have thin walls, which facilitates pollen tube germination at any position. Terms such as uniaperturate and triaperturate refer to the number of apertures present (one and three respectively).\n\nThe orientation of furrows (relative to the original tetrad of microspores) classifies the pollen as sulcate or colpate. Sulcate pollen has a furrow across the middle of what was the outer face when the pollen grain was in its tetrad. If the pollen has only a single sulcus, it is described as monosulcate, has two sulci, as bisulcate, or more, as polysulcate. Colpate pollen has furrows other than across the middle of the outer faces. Eudicots have pollen with three colpi (tricolpate) or with shapes that are evolutionarily derived from tricolpate pollen. The evolutionary trend in plants has been from monosulcate to polycolpate or polyporate pollen.\n\nThe transfer of pollen grains to the female reproductive structure (pistil in angiosperms) is called pollination. This transfer can be mediated by the wind, in which case the plant is described as anemophilous (literally wind-loving). Anemophilous plants typically produce great quantities of very lightweight pollen grains, sometimes with air-sacs. Non-flowering seed plants (e.g., pine trees) are characteristically anemophilous. Anemophilous flowering plants generally have inconspicuous flowers. Entomophilous (literally insect-loving) plants produce pollen that is relatively heavy, sticky and protein-rich, for dispersal by insect pollinators attracted to their flowers. Many insects and some mites are specialized to feed on pollen, and are called palynivores.\n\nIn non-flowering seed plants, pollen germinates in the pollen chamber, located beneath the micropyle, underneath the integuments of the ovule. A pollen tube is produced, which grows into the nucellus to provide nutrients for the developing sperm cells. Sperm cells of Pinophyta and Gnetophyta are without flagella, and are carried by the pollen tube, while those of Cycadophyta and Ginkgophyta have many flagella.\n\nWhen placed on the stigma of a flowering plant, under favorable circumstances, a pollen grain puts forth a pollen tube, which grows down the tissue of the style to the ovary, and makes its way along the placenta, guided by projections or hairs, to the micropyle of an ovule. The nucleus of the tube cell has meanwhile passed into the tube, as does also the generative nucleus, which divides (if it hasn't already) to form two sperm cells. The sperm cells are carried to their destination in the tip of the pollen tube. Double-strand breaks in DNA that arise during pollen tube growth appear to be efficiently repaired in the generative cell that carries the male genomic information to be passed on to the next plant generation. However, the vegetative cell that is responsible for tube elongation appears to lack this DNA repair capability.\n\nPollen's sporopollenin outer sheath affords it some resistance to the rigours of the fossilisation process that destroy weaker objects; it is also produced in huge quantities. There is an extensive fossil record of pollen grains, often disassociated from their parent plant. The discipline of palynology is devoted to the study of pollen, which can be used both for biostratigraphy and to gain information about the abundance and variety of plants alive — which can itself yield important information about paleoclimates. Also, pollen analysis has been widely used for reconstructing past changes in vegetation and their associated drivers . \nPollen is first found in the fossil record in the late Devonian period, but at that time it is indistinguishable from spores. It increases in abundance until the present day.\n\nNasal allergy to pollen is called pollinosis, and allergy specifically to grass pollen is called hay fever. Generally, pollens that cause allergies are those of anemophilous plants (pollen is dispersed by air currents.) Such plants produce large quantities of lightweight pollen (because wind dispersal is random and the likelihood of one pollen grain landing on another flower is small), which can be carried for great distances and are easily inhaled, bringing it into contact with the sensitive nasal passages.\n\nPollen allergies are common in polar and temperate climate zones, where production of pollen is seasonal. In the tropics pollen production varies less by the season, and allergic reactions less.\nIn northern Europe, common pollens for allergies are those of birch and alder, and in late summer wormwood and different forms of hay. Grass pollen is also associated with asthma exacerbations in some people, a phenomenon termed thunderstorm asthma.\n\nIn the US, people often mistakenly blame the conspicuous goldenrod flower for allergies. Since this plant is entomophilous (its pollen is dispersed by animals), its heavy, sticky pollen does not become independently airborne. Most late summer and fall pollen allergies are probably caused by ragweed, a widespread anemophilous plant.\n\nArizona was once regarded as a haven for people with pollen allergies, although several ragweed species grow in the desert. However, as suburbs grew and people began establishing irrigated lawns and gardens, more irritating species of ragweed gained a foothold and Arizona lost its claim of freedom from hay fever.\n\nAnemophilous spring blooming plants such as oak, birch, hickory, pecan, and early summer grasses may also induce pollen allergies. Most cultivated plants with showy flowers are entomophilous and do not cause pollen allergies.\n\nThe number of people in the United States affected by hay fever is between 20 and 40 million, and such allergy has proven to be the most frequent allergic response in the nation. There are certain evidential suggestions pointing out hay fever and similar allergies to be of hereditary origin. Individuals who suffer from eczema or are asthmatic tend to be more susceptible to developing long-term hay fever.\n\nIn Denmark, decades of rising temperatures cause pollen to appear earlier and in greater numbers, as well as introduction of new species such as ragweed.\n\nThe most efficient way to handle a pollen allergy is by preventing contact with the material. Individuals carrying the ailment may at first believe that they have a simple summer cold, but hay fever becomes more evident when the apparent cold does not disappear. The confirmation of hay fever can be obtained after examination by a general physician.\n\nAntihistamines are effective at treating mild cases of pollinosis, this type of non-prescribed drugs includes loratadine, cetirizine and chlorpheniramine. They do not prevent the discharge of histamine, but it has been proven that they do prevent a part of the chain reaction activated by this biogenic amine, which considerably lowers hay fever symptoms.\n\nDecongestants can be administered in different ways such as tablets and nasal sprays.\n\nAllergy immunotherapy (AIT) treatment involves administering doses of allergens to accustom the body to pollen, thereby inducing specific long-term tolerance. Allergy immunotherapy can be administered orally (as sublingual tablets or sublingual drops), or by injections under the skin (subcutaneous). Discovered by Leonard Noon and John Freeman in 1911, allergy immunotherapy represents the only causative treatment for respiratory allergies.\n\nMost major classes of predatory and parasitic arthropods contain species that eat pollen, despite the common perception that bees are the primary pollen-consuming arthropod group. Many other Hymenoptera other than bees consume pollen as adults, though only a small number feed on pollen as larvae (including some ant larvae). Spiders are normally considered carnivores but pollen is an important source of food for several species, particularly for spiderlings, which catch pollen on their webs. It is not clear how spiderlings manage to eat pollen however, since their mouths are not large enough to consume pollen grains. Some predatory mites also feed on pollen, with some species being able to subsist solely on pollen, such as \"Euseius tularensis\", which feeds on the pollen of dozens of plant species. Members of some beetle families such as Mordellidae and Melyridae feed almost exclusively on pollen as adults, while various lineages within larger families such as Curculionidae, Chrysomelidae, Cerambycidae, and Scarabaeidae are pollen specialists even though most members of their families are not (e.g., only 36 of 40000 species of ground beetles, which are typically predatory, have been shown to eat pollen—but this is thought to be a severe underestimate as the feeding habits are only known for 1000 species). Similarly, Ladybird beetles mainly eat insects, but many species also eat pollen, as either part or all of their diet. Hemiptera are mostly herbivores or omnivores but pollen feeding is known (and has only been well studied in the Anthocoridae). Many adult flies, especially Syrphidae, feed on pollen, and three UK syrphid species feed strictly on pollen (syrphids, like all flies, cannot eat pollen directly due to the structure of their mouthparts, but can consume pollen contents that are dissolved in a fluid). Some species of fungus, including \"Fomes fomentarius\", are able to break down grains of pollen as a secondary nutrition source that is particularly high in nitrogen. Pollen may be valuable diet supplement for detritivores, providing them with nutrients needed for growth, development and maturation. It was suggested that obtaining nutrients from pollen, deposited on the forest floor during periods of pollen rains, allows fungi to decompose nutritionally scarce litter.\n\nSome species of \"Heliconius\" butterflies consume pollen as adults, which appears to be a valuable nutrient source, and these species are more distasteful to predators than the non-pollen consuming species.\n\nAlthough bats, butterflies and hummingbirds are not pollen eaters \"per se\", their consumption of nectar in flowers is an important aspect of the pollination process.\n\nBee pollen for human consumption is marketed as a food ingredient and as a dietary supplement. The largest constituent is carbohydrates, with protein content ranging from 7 to 35 percent depending on the plant species collected by bees.\n\nHoney produced by bees from natural sources contains pollen derived p-coumaric acid, an antioxidant and natural bactericide that is also present in a wide variety of plants and plant-derived food products.\n\nThe U.S. Food and Drug Administration (FDA) has not found any harmful effects of bee pollen consumption, except from the usual allergies. However, FDA does not allow bee pollen marketers in the United States to make health claims about their produce, as no scientific basis for these has ever been proven. Furthermore, there are possible dangers not only from allergic reactions but also from contaminants such as pesticides and from fungi and bacteria growth related to poor storage procedures. A manufacturers's claim that pollen collecting helps the bee colonies is also controversial.\n\nPine pollen () is traditionally consumed in Korea as an ingredient in sweets and beverages.\n\nThe growing industries in pollen harvesting for human and bee consumption rely on harvesting pollen baskets from honey bees as they return to their hives using a \"pollen trap\". When this pollen has been tested for parasites, it has been found that a multitude of pollinator viruses and eukaryotic parasites are present in the pollen. It is currently unclear if the parasites are introduced by the bee that collected the pollen or if it is from contamination to the flower. Though this is not likely to pose a risk to humans, it is a major issue for the bumblebee rearing industry that relies on thousands of tonnes of honey bee collected pollen per year. Several sterilization methods have been employed, though no method has been 100% effective at sterilizing, without reducing the nutritional value, of the pollen \n\nIn forensic biology, pollen can tell a lot about where a person or object has been, because regions of the world, or even more particular locations such a certain set of bushes, will have a distinctive collection of pollen species. Pollen evidence can also reveal the season in which a particular object picked up the pollen. Pollen has been used to trace activity at mass graves in Bosnia, catch a burglar who brushed against a \"Hypericum\" bush during a crime, and has even been proposed as an additive for bullets to enable tracking them.\n\nIn some Native American religions, pollen is used in prayers and rituals to symbolize life and renewal by sanctifying objects, dancing grounds, trails, and sandpaintings. It may also be sprinkled over heads or in mouths. Many Navajo people believe the body becomes holy when it travels over a trail sprinkled with pollen. \n\n\n\n"}
{"id": "13139823", "url": "https://en.wikipedia.org/wiki?curid=13139823", "title": "Post-classical history", "text": "Post-classical history\n\n\"For more maps, images and other media please see * \"\n\nPost-classical history (also called the Post-Antiquity era, Post-Ancient Era, or Pre-Modern Era) is a periodization commonly used by the school of \"world history\" instead of Middle Ages (Medieval), which is roughly synonymous. The period runs from about AD 500 to 1450 though there may be regional differences and debates. The era was globally characterized by the expansion of civilizations geographically, the development of three of the great world religions (Christianity, Islam, and Buddhism), and development of networks of trade between civilizations.\n\nIn Asia, the spread of Islam created a new empire and Islamic Golden Age with trade between the Asian, African and European continents, and advances in science in the medieval Islamic world. East Asia experienced the full establishment of power of Imperial China, which established several prosperous dynasties influencing Korea, Vietnam, and Japan. Religions such as Buddhism and Neo-Confucianism spread. Gunpowder was originally developed in China during the post-classical era. The Mongol Empire connected Europe and Asia creating safe trade and stability between the two regions. In total the population of the world doubled in the time period from approximately 210 million in AD 500 to 461 million in 1500. Population generally grew steadily throughout the period but endured some incidental declines in events including the Plague of Justinian, The Mongol Invasions and the Black Death.\n\n'Post-classical history' is a periodization used by historians employing a \"world history\" approach to history, specifically the school developed during the late 20th and early 21st centuries. Outside of world history, the term is also sometimes used to avoid erroneous pre-conceptions around the terms \"Middle Ages\", \"Medieval\" and \"Dark Ages\" (see medievalism).\n\nThe post-classical period corresponds roughly to the period from 500 to 1450 CE. Beginning and ending dates might vary depending on the region, with the period beginning at the end of the previous classical period: Han China (ending in 220), the Western Roman Empire (in 476), the Gupta Empire (in the 550s), and the Sasanian Empire (in 651).\n\nThe post-classical period is one of the five or six major periods world historians use: (1) early civilization; (2) classical societies; (3) post-classical; (4) early modern; (5) long nineteenth century; and (6) contemporary or modern era. (Sometimes the nineteenth century and modern are combined.) Although \"post-classical\" is synonymous with the Middle Ages of Western Europe, the term \"post-classical\" is not necessarily a member of the traditional tripartite periodisation of Western European history into 'classical', 'middle' and 'modern'.\n\nThe historical field of world history, which looks at common themes occurring across multiple cultures and regions, has enjoyed extensive development since the 1980s. However, World History research has tended to focus on early modern globalization (beginning around 1500) and subsequent developments, and views post-classical history as mainly pertaining to Afro-Eurasia. Historians recognize the difficulties of creating a periodization and identifying common themes that include not only this region but also, for example, the Americas, since they had little contact with Afro-Eurasia before the Columbian Exchange. Thus recent research has emphasised that 'a global history of the period between 500 and 1500 is still wanting' and that 'historians have only just begun to embark on a global history of the Middle Ages'.\n\nFor many regions of the world, there are well established histories. Although Medieval Studies in Europe tended in the nineteenth century to focus on creating histories for individual nation-states, much twentieth-century research focused, successfully, on creating an integrated history of medieval Europe. The Islamicate world likewise has a rich regional historiography, ranging from the fourteenth-century Ibn Khaldun to the twentieth-century Marshall Hodgson and beyond. Correspondingly, research into the network of commercial hubs which enabled goods and ideas to move between China in the East and the Atlantic islands in the West—which can be called the early history of globalisation—is fairly advanced; one key historian in this field is Janet Abu-Lughod. Understanding of communication within sub-saharan Africa or the Americas is, by contrast, far more limited.\n\nRecent history-writing, therefore, has begun to explore how it might be possible meaningfully to write history that spans the Old World, where human activities were fairly interconnected, and establishes its relationship with other worlds, such as the Americas and Oceania. In the assessment of James Belich, John Darwin, Margret Frenz, and Chris Wickham,\nGlobal history may be boundless, but global historians are not. Global history cannot usefully mean the history of everything, everywhere, all the time. [...] Three approaches [...] seem to us to have real promise. One is global history as the pursuit of significant historical problems across time, space, and specialism. This can sometimes be characterized as ‘comparative’ history. [...] Another is connectedness, including transnational relationships. [...] The third approach is the study of globalization [...]. Globalization is a term that needs to be rescued from the present, and salvaged for the past. To define it as always encompassing the whole planet is to mistake the current outcome for a very ancient process.\nA number of commentators have pointed to the history of the earth's climate as a useful approach to World History in the Middle Ages, noting that certain climate events had effects on all human populations.\n\nThe Post-classical era saw several common developments or themes. There was the expansion and growth of civilization into new geographic areas; the rise and/or spread of the three major world, or missionary, religions; and a period of rapidly expanding trade and trade networks.\n\nFirst was the expansion and growth of civilization into new geographic areas across Asia, Africa, Europe, Mesoamerica, and western South America. However, as noted by world historian Peter N. Stearns, there were no common global political trends during the post-classical period, rather it was a period of loosely organized states and other developments, but no common political patterns emerged. In Asia, China continued its historic dynastic cycle and became more complex, improving its bureaucracy. The creation of the Islamic Empires established a new power in the Middle East, North Africa, and Central Asia. Africa created the Songhai and Mali kingdoms in the West. The fall of Roman civilization not only left a power vacuum for the Mediterranean and Europe, but forced certain areas to build what some historians might call new civilizations entirely. An entirely different political system was applied in Western Europe (i.e. feudalism), as well as a different society (i.e. manorialism). But the once East Roman Empire, Byzantium, retained many features of old Rome, as well as Greek and Persian similarities. Kiev Rus' and subsequently Russia began development in Eastern Europe as well. In the isolated Americas, Mesoamerica saw the building of the Aztec Empire, while the Andean region of South America saw the establishment of the Inca Empire.\n\nReligion that envisaged the possibility that all humans could be included in a universal order had emerged already in the first millennium BC, particularly with Buddhism. In the following millennium, Buddhism was joined by two other major, universalising, missionary religions, both developing from Judaism: Christianity and Islam. By the end of the period, these three religions were between them widespread, and often politically dominant, across the Old World.\n\nFinally, communication and trade across Afro-Eurasia increased rapidly. The Silk Road continued to spread cultures and ideas through trade and throughout Europe, Asia, and Africa. Trade networks were established between West Europe, Byzantium, early Russia, the Islamic Empires, and the Far Eastern civilizations. In Africa the earlier introduction of the Camel allowed for a new and eventually large Trans-Saharan trade which connected Sub-Saharan West Africa to Eurasia. The Islamic Empires adopted many Greek, Roman, and Indian advances and spread them through the Islamic sphere of influence, allowing these developments to reach Europe, North and West Africa, and Central Asia. Islamic sea trade helped connect these areas, including those in the Indian Ocean and in the Mediterranean, replacing Byzantium in the latter region. The Christian Crusades into the Middle East (as well as Muslim Spain and Sicily) brought Islamic science, technology, and goods to Western Europe. Western trade into East Asia was pioneered by Marco Polo. Importantly, China began the sinicization (or Chinese influence) of regions like Japan, Korea, and Vietnam through trade and conquest. Finally, the growth of the Mongol Empire in Central Asia established safe trade such as to allow goods, cultures, ideas, and disease to spread between Asia, Europe, and Africa.\n\nThe Americas had their own trade network, however theirs was limited by the lack of draft animals and the wheel. In Oceania some of the island chains of Polynesia and Micronesia also engaged in trade with one another.\n\nDuring Post-Classical times, there is evidence that many regions of the world were affected similarly by global climate conditions however, direct effects in temperature and precipitation varied by region. According to Intergovernmental Panel on Climate Change changes did not all occur sanctimoniously at once. Generally however studies found that temperatures were relatively warmer, in the eleventh century, but colder by the early seventeenth century. It is uncertain the degree of climate change which occurred in all regions across the world, and whether such changes were all part of a global trend. Climate trends seemed to be more recognizable along the Northern Hemisphere than the Southern Hemisphere.\n\nThere are climate periods that could be roughly said to account for large scale climate trends in the Post Classical Period. These include the Late Antique Little Ice Age, the Medieval Warm Period and the Little Ice Age. The Extreme Weather Events of 536–537 were likely initiated by the eruption of the Lake llopango caldera in El Salvador. Sulfate emitted into the air initiated global cooling, migrations and crop failures worldwide possibly intensifying an already cooler time period. Records show that the world's temperature remained colder on average for at least a century afterwards.\n\nThe Medieval Warming Period from 950–1250 occurred mostly throughout the northern hemisphere causing many areas to have warmer summers, the high temperatures would only be surpassed by the Global Warming of the 20th/21st centuries. It has been hypothesized that the warm of temperatures allowed the Norse to colonize Greenland, due to ice-free waters at the time. Outside of Europe there is evidence of warming conditions, including higher temperatures in China and major North American droughts which adversely effected numerous cultures.\n\nAfter 1250, glaciers began to expand in Greenland effecting its Thermohaline circulation, cooling the entire North Atlantic. In the 14th century, the growing season in Europe became unreliable, meanwhile in China the cultivation of Oranges were driven southward by colder temperatures. Especially in Europe, the Little Ice Age had large cultural ramifications. The Little Ice Age would persist until the industrial revolution, far beyond the time-frame of the Post Classical Period. The causes for the little Ice-Age are unclear, possible explanations include sunspots, orbital cycles of the Earth, volcanic activity, ocean circulation, and man made population decline.\n\nThis timetable gives a basic overview of states, cultures and events which transpired roughly between the years 400 and 1500. Sections are broken by political and geographic location.\n\nIn Europe, Western civilization reconstituted after the Fall of the Western Roman Empire into the period now known as the Early Middle Ages (500–1000), during which the Catholic Church unified the region. The Early Middle Ages saw a continuation of trends begun in Late Antiquity: depopulation, deurbanization, and increased barbarian invasion.\n\nFrom the 7th until the 11th centuries Arabs, Magyars and Norse were all threats to the Christian Kingdoms that killed thousands of people over centuries. Raiders however, also created new trading networks. In western Europe the Frankish king Charlemagne attempted to kindle the rise of culture and science in the Carolingian Renaissance. In the year 800 Charlemagne founded the Holy Roman Empire in attempt to resurrect Classical Rome. The reign of Charlemange attempted to kindle a rise of learning and literacy in what has become known as the Carolingian Renaissance\n\nIn Eastern Europe, the Eastern Roman Empire survived in what is now called the Byzantine Empire which created the Code of Justinian that inspired the legal structures of modern European states. Ruled by religious Christian Orthodox emperors the Byzantine Eastern Orthodox Church Christianized the Kieven Rus, who were the foundation of modern-day Russia and Ukraine. Byzantium flourished as the leading power and trade center in its region in the Macedonian Renaissance until it was overshadowed by Italian City States and the Islamic Ottoman Empire near the end of the Middle Ages.\nLater in the period, the creation of the feudal system allowed greater degrees of military and agricultural organization. There was sustained urbanization in northern and western Europe. Later developments were marked by manorialism and feudalism, and evolved into the prosperous High Middle Ages. After 1000 the Christian kingdoms that had emerged from Rome's collapse changed dramatically in their cultural and societal character.\n\nDuring the High Middle Ages (c. 1000–1300), Christian-oriented art and architecture flourished and the Crusades were mounted to recapture the Holy Land from Muslim control. The influence of the emerging nation-state was tempered by the ideal of an international Christendom and the presence of the Roman Catholic Church in all western kingdoms. The codes of chivalry and courtly love set rules for proper behavior, while the Scholastic philosophers attempted to reconcile faith and reason. The age of Feudalism would be dramatically transformed by the cataclysm of the Black Death and its aftermath. This time would be a major underlying cause for the Renaissance. By the turn of the 16th century European or Western Civilization would be engaging in the Age of Discovery.\n\nThe term \"Middle Ages\" first appears in Latin in the 15th century and reflects the view that this period was a deviation from the path of classical learning, a path supposedly reconnected by Renaissance scholarship.\n\nThe Arabian peninsula and the surrounding Middle East and Near East regions saw dramatic change during the Postclassical Era caused primarily by the spread of Islam and the establishment of the Arabian Empires.\n\nIn the 5th century, the Middle East was separated by empires and their spheres of influence; the two most prominent were the Sasanian Empire of the Persians in what is now Iran and Iraq, and the Byzantine Empire in Anatolia (modern-day Turkey). The Byzantines and Sasanians fought with each other continually, a reflection of the rivalry between the Roman Empire and the Persian Empire seen during the previous five hundred years. The fighting weakened both states, leaving the stage open to a new power. Meanwhile, the nomadic Bedouin tribes who dominated the Arabian desert saw a period of tribal stability, greater trade networking and a familiarity with Abrahamic religions or monotheism.\n\nWhile the Byzantine Roman and Sassanid Persian empires were both weakened by the Byzantine–Sasanian War of 602–628, a new power in the form of Islam grew in the Middle East under Muhammad in Medina. In a series of rapid Muslim conquests, the Rashidun army, led by the Caliphs and skilled military commanders such as Khalid ibn al-Walid, swept through most of the Middle East, taking more than half of Byzantine territory in the Arab–Byzantine wars and completely engulfing Persia in the Muslim conquest of Persia. It would be the Arab Caliphates of the Middle Ages that would first unify the entire Middle East as a distinct region and create the dominant ethnic identity that persists today. These Caliphates included the Rashidun Caliphate, Umayyad Caliphate, Abbasid Caliphate, and later the Turkic-based Seljuq Empire.\nAfter Muhammad introduced Islam, it jump-started Middle Eastern culture into an Islamic Golden Age, inspiring achievements in architecture, the revival of old advances in science and technology, and the formation of a distinct way of life. Muslims saved and spread Greek advances in medicine, algebra, geometry, astronomy, anatomy, and ethics that would later finds it way back to Western Europe.\n\nThe dominance of the Arabs came to a sudden end in the mid-11th century with the arrival of the Seljuq Turks, migrating south from the Turkic homelands in Central Asia. They conquered Persia, Iraq (capturing Baghdad in 1055), Syria, Palestine, and the Hejaz. This was followed by a series of Christian Western Europe invasions. The fragmentation of the Middle East allowed joint European forces mainly from England, France, and the emerging Holy Roman Empire, to enter the region. In 1099 the knights of the First Crusade captured Jerusalem and founded the Kingdom of Jerusalem, which survived until 1187, when Saladin retook the city. Smaller crusader fiefdoms survived until 1291. In the early 13th century, a new wave of invaders, the armies of the Mongol Empire, swept through the region, sacking Baghdad in the Siege of Baghdad (1258) and advancing as far south as the border of Egypt in what became known as the Mongol conquests. The Mongols eventually retreated in 1335, but the chaos that ensued throughout the empire deposed the Seljuq Turks. In 1401, the region was further plagued by the Turko-Mongol, Timur, and his ferocious raids. By then, another group of Turks had arisen as well, the Ottomans.\n\nDuring the Postclassical Era, Africa was both culturally and politically affected by the introduction of Islam and the Arabic empires. This was especially true in the north, the Sudan region, and the east coast. However, this conversion was not complete nor uniform among different areas, and the low-level classes hardly changed their beliefs at all. Prior to the migration and conquest of Muslims into Africa, much of the continent was dominated by diverse societies of varying sizes and complexities. These were ruled by kings or councils of elders who would control their constituents in a variety of ways. Most of these peoples practiced spiritual, animistic religions. Africa was culturally separated between Saharan Africa (which consisted of North Africa and the Sahara Desert) and Sub-Saharan Africa (everything south of the Sahara). Sub-Saharan Africa was further divided into the Sudan, which covered everything north of Central Africa, including West Africa. The area south of the Sudan was primarily occupied by the Bantu peoples who spoke the Bantu language. From 1100 onward Christian Europe and the Islamic World became dependent on Africa for gold.\n\nSub Saharan Africa\n\nAfter 650 approximately urbanization expanded for the first time beyond the ancient kingdoms Aksum and Nubia. The Precolonial civilizations of African Civilization can be divided into three categories based on religion. (1) Christian Civilizations on the Horn of Africa (2) Islamic Civilizations which formed in the Niger River valley in West Africa, and on the coast of East Africa and (3) Traditional Societies which adhered to native African Religions. South of the Sahara African kingdoms developed based on continental trade with one another through land based routes and generally avoided sea trade.\n\nSub Saharan Africa was part of two large, separate trading networks, the Trans Saharan trade which bridged commerce between West and North Africa. Due to the huge profits from trade native African Islamic empires arose, including those of Ghana, Mali and Songhay. In the 14th century, Mana Masua king of Mali may have been the wealthiest person of his time. Within Mali, the city of Timbuktu was an international center of science and well known throughout the Islamic World, particularly from the University of Sankore.\nEast Africa was part of the Indian Ocean trade network, which included both Arab ruled Islamic cities on the East African Coast such as Mombasa and Traditional cities such as Great Zimbabwe which exported gold, copper and ivory to markets in the Middle East, South Asia, and Southeast Asia.\n\nThere has been difficulty applying the word 'medieval' or 'post classical' to the history of South Asia. This section follows historian Stein Burton's definition that corresponds from the 8th century to the 16th century, more of less following the same time frame of the Post Classical Period and the European Middle Ages.\n\nUntil the 13th century, there was no less than 20 to 40 different states on the Indian Subcontinent which hosted a variety of cultures, languages, writing systems and religions. In the beginning of the time period Buddhism was predominant throughout the area with the short lived Pala Empire on the Indo Gangetic Plain sponsoring the faith's institutions. One such institution was the Buddhist Nalanda University in modern-day Bihar, India was a center of scholarship and brought a divided South Asia onto the global intellectual stage. Classical India was unique for being the only country to mine gems before modern times, and to have a discipline for eye surgery. Another accomplishment was the invention of the \"Chaturanga\" game which later was exported to Europe and became Chess.\nIn Southern India, the Hindu Kingdom of Chola gained prominence with an overseas empire that controlled parts of modern-day Sri Lanka, Malaysia, and Indonesia as oversees territories and helped spread Hinduism into the historic culture of these places. In this time period, neighboring areas such as Afghanistan, Tibet, Southeast Asia were under South Asian influence.\n\nFrom 1206 onward a series of Turkic Islamic invasions based from modern day Afghanistan and Iran conquered massive portions of Northern India, founding the Delhi Sultante which remained supreme until the 16th century. The Delhi Sultanate introduced Islam to the conquered populations for the first time. Native religions fared differently, Buddhism declined in South Asia vanishing in many areas but Hinduism survived and reinforced itself in areas conquered by Muslims. In the far South the Kingdom of Vijanyagar was not conquered by any Muslim state in the period. The turn of the 16th century would see the rise of a new Islamic Empire – the Mughals and the establishment of European trade posts by the Portuguese.\n\nFrom the 8th century onward Southeast Asia stood to benefit from the trade taking place between South and East Asia, numerous kingdoms arose in the region due to the flow of wealth passing through the Strait of Malacca. While Southeast Asia had numerous outside influences India was the greatest source of inspiration for the region. North Vietnam as an exception was culturally closer to China for centuries due to conquest.\n\nSince rule from the third century BC North Vietnam continued to be subjugated by Chinese states, although they continually resisted periodically. There were three periods of Chinese Domination that spanned near 1100 years. Vietnam gained long lasting independence in the 10th century when China was divided. Nonetheless even as an independent state a sort of begrudging sinicization occurred. By the end of the Postclassical Era, Vietnam would be in control of its own Nguyễn dynasty. South Vietnam was governed by the ancient Hindu Champa Kingdom but was annexed by Vietnamese invaders in the 15th century.\n\nThe spread of Hinduism, Buddhism and maritime trade between China and South Asia created the foundation for Southeast Asia's first major empires; including the Khmer Empire from Cambodia and Sri Vijaya from Indonesia. During the Khmer Empire's height in the 12th century the city of Angkor Thom was among the largest of the pre-modern world due to its water management. King Jayavarman II constructed over a hundred hospitals throughout his realm. Nearby rose the Pagan Empire in modern-day Burma, using elephants as military might. The construction of the Buddhist Shwezigon Pagoda and its tolerance for believers of older polytheistic gods helped Theravada Buddhism become supreme in the region.\n\nIn Indonesia, Srivijaya from the 7th through 14th century was a Thalassocracy that focused on maritime city states and trade. Controlling the vital choke points of the Sunda and Malacca straits it became rich from trade ranging from Japan through Arabia. Gold, Ivory and Ceramics were all major commodities traveling through port cities. The Empire was also responsible for the construction of wonders such as Borobudur. During this time Indonesian sailors crossed the Indian Ocean; evidence suggests that they may have colonized Madagascar. Indian culture spread to the Philippines, likely through Indonesian trade resulting in the first documented use of writing in the archipelago and Indianized kingdoms.\n\nOver time changing economic and political conditions else where and wars weakened the traditional empires of South East Asia. While the Mongol Invasions did not directly annex Southeast Asia the war-time devastation paved way for the rise of new nations. In the 15th century the Khmer Empire was supplanted by the Thai Ayutthaya Kingdom and Sri Vijaya was overtaken by the Majapahit and later the Islamic Malacca Sultanate by 1450.\n\n The time fame of 500–1500 in East Asia's history and China in particular has been proposed as an accurate classification for the region's history within the context of global Post-classical history. There has been an attempt made in college courses to adapt the Post-Classical concept to Chinese terms.\n\nDuring this period the Eastern world empires continued to expand through trade, migration and conquests of neighboring areas. Japan and Korea went under the process of voluntary sinicization, or the impression of Chinese cultural and political ideas.\n\nKorea and Japan sinicized because their ruling class were largely impressed by China's bureaucracy. The major influences China had on these countries were the spread of Confucianism, the spread of Buddhism, and the establishment of centralized governance. In the times of the Sui, Tang and Song dynasties (581–1279), China remained the world's largest economy and most technologically advanced society. Inventions such as gunpowder, woodblock printing and the magnetic compass were improved upon. China stood in contrast to other areas at the time as the imperial governments exhibited concentrated central authority instead of feudalism.\n\nChina exhibited much interest in foreign affairs, during the Tang and Song dynasties. From the 7th through the 10th Tang China was focused on securing the Silk Road as the sell of its goods westwards was central to the nation's economy. For a time China, successfully secured its frontiers by integrating their nomadic neighbors such as the Gokturks into their civilization. The Tang dynasty expanded into Central Asia and received tribute from Eastern Iran. Western expansion ended with wars with the Umayyad Caliphate and the deadly An Lushan Rebellion which resulted in an deadly but uncertain death toll of millions.\n\nAfter the collapse of the Tang dynasty and subsequent civil wars came the second phase of Chinese interest in foreign relations. Unlike the Tang, the Song specialized in overseas trade and peacefully created a maritime network and China's population became concentrated in the south.. Chinese merchant ships reached Indonesia, India and Arabia. Southeast Asia's economy flourished from trade with Song China.With the country's emphasis on trade and economic growth, Song China's economy began to use machines to manufacture goods and coal as a source of energy. The advances of the Song in the 11th/12th centuries have been considered an early industrial revolution. Economic advancements came at the cost of military affairs and the Song became open to invasions from the north. China became divided as Song's northern lands were conquered by the Jurchen people. By 1200 there were five Chinese kingdoms stretching from modern day Turkestan to the Sea of Japan including the Western Liao, Western Xia, Jin, Southern Song and Dali. Because these states competed with each other they all were eventually annexed by the rising Mongol Empire before 1279.\n\nAfter seventy years of conquest, the Mongols proclaimed the Yuan dynasty and also annexed Korea; they failed to conquer Japan. Mongol conquerors also made China accessible to European travelers such as Marco Polo. The Mongol era was short lived due to plagues and famine. After revolution in 1368 the succeeding Ming dynasty ushered in a period of prosperity and brief foreign expeditions before isolating itself from global affairs for centuries.\n\nKorea and Japan however continued to have relations with China and with other Asian countries. In the 15th century Sejong the Great of Korea cemented his country's identity by creating the Hangul Writing system to replace use of Chinese Characters. Meanwhile, in Japan fell under military rule of the Kamakura and later Ashikaga Shogunate dominated by Samauri warriors.\n\nThis section explains events and trends which affected the geographic area of Eurasia. The civilizations within this area while being distinct from one another endured shared experiences.\n\nThe Mongol Empire which existed during the 13th and 14th centuries, was the largest continuous land empire in history. Originating in the steppes of Central Asia, the Mongol Empire eventually stretched from Central Europe to the Sea of Japan, extending northwards into Siberia, eastwards and southwards into the Indian subcontinent, Indochina, and the Iranian plateau, and westwards as far as the Levant and Arabia.\n\nThe Mongol Empire emerged from the unification of nomadic tribes in the Mongolia homeland under the leadership of Genghis Khan, who was proclaimed ruler of all Mongols in 1206. The empire grew rapidly under his rule and then under his descendants, who sent invasions in every direction. The vast transcontinental empire connected the east with the west with an enforced \"Pax Mongolica\" allowing trade, technologies, commodities, and ideologies to be disseminated and exchanged across Eurasia.\n\nThe empire began to split due to wars over succession, as the grandchildren of Genghis Khan disputed whether the royal line should follow from his son and initial heir Ögedei, or one of his other sons such as Tolui, Chagatai, or Jochi. After Möngke Khan died, rival \"kurultai\" councils simultaneously elected different successors, the brothers Ariq Böke and Kublai Khan, who then not only fought each other in the Toluid Civil War, but also dealt with challenges from descendants of other sons of Genghis. Kublai successfully took power, but civil war ensued as Kublai sought unsuccessfully to regain control of the Chagatayid and Ögedeid families.\n\nThe Battle of Ain Jalut in 1260 marked the high-water point of the Mongol conquests and was the first time a Mongol advance had ever been beaten back in direct combat on the battlefield. Though the Mongols launched many more invasions into the Levant, briefly occupying it and raiding as far as Gaza after a decisive victory at the Battle of Wadi al-Khazandar in 1299, they withdrew due to various geopolitical factors.\n\nBy the time of Kublai's death in 1294, the Mongol Empire had fractured into four separate khanates or empires, each pursuing its own separate interests and objectives: the Golden Horde khanate in the northwest; the Chagatai Khanate in the west; the Ilkhanate in the southwest; and the Yuan dynasty based in modern-day Beijing. In 1304, the three western khanates briefly accepted the nominal suzerainty of the Yuan dynasty, but it was later overthrown by the Han Chinese Ming dynasty in 1368. The Genghisid rulers returned to Mongolia homeland and continued rule in the Northern Yuan dynasty. All of the original Mongol Khanates collapsed by 1500, but smaller successor states remained independent until the 1700s. Descendants of Chagatai Khan created the Mughal Empire that ruled much of India in early modern times.\n\nThe Silk Road was a Eurasian trade route that played a large role in global communication and interaction. It stimulated cultural exchange; encouraged the learning of new languages; resulted in the trade of many goods, such as silk, gold, and spices; and also spread religion and disease. It is even claimed by some historians – such as Andre Gunder Frank, William Hardy McNeill, Jerry H. Bentley, and Marshall Hodgson – that the Afro-Eurasian world was loosely united culturally, and that the Silk Road was fundamental to this unity. This major trade route began with the Han dynasty of China, connecting it to the Roman Empire and any regions in between or nearby. At this time, Central Asia exported horses, wool, and jade into China for the latter's silk; the Romans would trade for the Chinese commodity as well, offering wine in return. The Silk Road would often decline and rise again in trade from the Iron Age to the Postclassical Era. Following one such decline, it was reopened in Central Asia by Han Dynasty General Ban Chao during the 1st century.\n\nThe Silk Road was also a major factor in spreading religion across Afro-Eurasia. Muslim teachings from Arabia and Persia reached East Asia. Buddhism spread from India, to China, to Central Asia. One significant development in the spread of Buddhism was the carving of the Gandhara School in the cities of ancient Taxila and the Peshwar, allegedly in the mid 1st century.\n\nThe route was vulnerable to spreading plague. The Plague of Justinian originated in East Asia and had a major outbreak in Europe in 542 causing the deaths of a quarter of the Mediterranean's population. Trade between Europe, Africa and Asia along the route was at least partially responsible for spreading the plague. There is a popular theory that the Black Death was caused by the Mongol conquests. The claim is that the direct link that it opened between the East and West provided the path for rats and fleas that carried the disease. Although there is no concrete historical evidence to this theory, the plague is considered endemic on the steppe.\n\nThere were vulnerabilities as well to changing political situations. The rise of Islam changed the Silk Road, because Muslim rulers generally closed the Silk Road to Christian Europe to an extent Europe would be cut off from Asia for centuries. Specifically, the political developments that affected the Silk Road included the emergence of the Turks, the political movements of the Sasanian and Byzantine empires, and the rise of the Arabs, among others.\nThe Silk Road flourished again in the 13th century during the reign of the Mongol Empire, which through conquest had brought stability in Central Asia comparable to the Pax Romana. It was claimed by a Muslim historian that Central Asia was peaceful and safe to transverse \"(Central Asia) enjoyed such a peace that a man might have journeyed from the land of sunrise to the land of sunset with a golden platter upon his head without suffering the least violence from anyone.\" \n\nAs such, trade and communication between Europe, East Asia, South Asia, and the Middle East required little effort. Handicraft production, art, and scholarship prospered, and wealthy merchants enjoyed cosmopolitan cities.\n\nThe Silk Road trade played a role in spreading the infamous Black Death. Originating in China, the bubonic plague was spread by Mongol warriors catapulting diseased corpses into enemy towns in the Crimea. The disease, spread by rats, was carried by merchant ships sailing across the Mediterranean that brought the plague back to Sicily, causing an epidemic in 1347. Nevertheless, after the 15th century, the Silk Road disappeared from regular use. This was primarily a result from the growing sea travel pioneered by Europeans, which allowed the trade of goods by sailing around the southern tip of Africa and into the Indian Ocean.\n\nThe term \"Post Classical Science\" is often used in Academic Circles and in college courses to combine the study of Medieval European Science and Medieval Islamic Science due to their interactions with one another. However Science from Eastern Eurasia, particularly from China was spread westward by Arabs due to both war and trade. The Islamic World also benefited from medical knowledge from South Asia.\n\nIn the case of the Western World and in Islamic realms much emphasis was placed on preserving the rationalist Greek Tradition of figures such as Aristotle. In the context of science within Islam there is a debate as to whether Islamic Scientists simply preserved accomplishments from Antiquity or built upon earlier Greek advances. Regardless, Classical European Science was brought back to the Christian Kingdoms due to the experience of the Crusades.\n\nAs a result of Persian trade in China, and the battle of the Talas River, Chinese innovations entered the Islamic Intellectual World. These include advances in astronomy and in paper-making.\n\nPaper making spread through the Islamic World as far west as Islamic Spain, before paper-making was acquired for Europe by the Reconquista. There is a debate on the transmission of gunpowder on whether the Mongols introduced Chinese gunpoweder weapons to Europe or if separate gunpowder weapons were invented in Europe independently.\n\nWithin Eurasia, there were four major civilization groups that had literate cultures and created literature and arts. These include Europe, The Middle East, South Asia and East\nAsia. Southeast Asia could be a possible fifth category but was influenced heavily from both South and East Asia literal cultures. All four cultures in Post-Classical Times used poetry, drama and prose. Throughout the period and until the 19th century poetry was the dominant form of literary expression. In the Middle East, South Asia, Europe and China great poetic works often used figurative language. Examples include, the Sanskrit \"Shakuntala\", the Arabic \"Thousand and one nights\", Old English \"Beowulf \" and works by the Chinese Du Fu. In Japan, prose uniquely thrived more than in other geographic areas. The \"Tale of Genji\" is considered the world's first realistic novel written in the 9th century.\n\nMusically, most regions of the world only used melodies as opposed to harmony. Medieval Europe was the lone exception to this rule, developing harmonic music in the 14th/15th century as musical culture transitioned form sacred music (meant for the church) to secular music. South Asian and Mid-Eastern music were similar to each other for their use of microtone. East-Asian music shared some similarities with European Music for using a pentatnotic scale.\n\nThe Postclassical Era of the Americas can be considered set at a different time span from that of Afro-Eurasia. As the developments of Mesoamerican and Andean civilization differ greatly from that of the Old World, as well as the speed at which it developed, the Postclassical Era in the traditional sense does not take place until near the end of the Medieval Age in Afro-Eurasia. As such, for the purposes of this article, the Classic stage of the Americas will be discussed here, which takes place from about 400 to 1400. For the technical Postclassical stage in American development, see Post-Classic stage.\n\nAs a continent there was little unified trade or communication. Advances in agriculture spread northward from Measoamerica indirectly through trade. Major cultural areas however still developed independently of each other.\n\nWhile there was little regular contact between the Americas and the Old World the Norse Vikings explored and even colonized Greenland and Canada as early as 1000. None of these settlements survived past Medieval Times. Outside of Scandinavia knowledge of the discovery of the Americas was interpreted as a remote island or the North Pole.\n\nThe Norse arriving from Greenland settled Greenland from approximately 980 to 1450. The Norse arrived in southern Greenland prior to the 13th century approach of Inuit Thule people in the area. The extent of the interaction between the Norse and Thule is unclear. Greenland was valuable to the Norse due to trade of ivory that came from the tusks of walruses. The Little Ice Age adversely effected the colonies and they vanished. Greenland would be lost to Europeans until Danish Colonization in the 18th century.\n\nThe Norse also explored and colonized farther south in Newfoundland Canada at L'Anse aux Meadows referred to by the Norse as \"Vinland\". The colony at most existed for twenty years and resulted in no known transmission of diereses or technology to the First Nations. To the Norse \"Vinland\" was known for plentiful grape vines to make superior wine. One reason for the colony's failure was constant violence with the native Beothuk tribe who the Norse referred to as Skraeling.\n\nAfter initial expeditions there is a possibility that the Norse continued to visit modern day Canada. Surviving records from Medieval Iceland indicate some sporadic voyages to a land called \"Markland\" possibly the coast of Labrador, Canada as late as the 1347 presumably to collect wood for deforested Greenland.\n\nIn northern North America, many hunter-gatherer and agricultural societies thrived in the diverse region. Native American tribes varied greatly in characteristics; some, including the Mississippian culture and the Ancestral Puebloans were complex chiefdoms. Other nations which inhabited the states of the modern northern United States and Canada had less complexity and did not follow technological changes as quickly. Approximately around the year 500 during the Woodland period , Native Americans began to transition to bows and arrows from spears for hunting and warfare. Technological advancement however was uneven. During the 12th century was the widespread adoption of Corn as a staple crop in the Eastern United States. Corn would continue to be the staple crop of natives in the Eastern United States and Canada until the Colombian Exchange.\nIn The Eastern United States rivers were the medium of trade and communication. Cahokia located in the modern U.S State of Illinois was among the most significant within the Mississippi Culture. Focused around Monks Mound archeology indicates the population increased exponentially after 1000 because it manufactured important tools for agriculture and cultural attractions. Around 1350 Cahokia was abandoned, environmental factors have been proposed for the city's decline.\n\nAt the same time Ancestral Puebloans constructed clusters of buildings in the Chaco Canyon site located in the State of New Mexico. Individual houses may have been occupied by more than 600 residents at any one time. Chaco Canyon was the only pre-Columbian site in the United States to build paved roads.\nPottery indicates asociety that was becoming more complex, Turkeys for the first time in the continental United States were also domesticated.\nAround 1150 the structures of Chaco Canyon were abandoned, likely as a result of severe drought. There were also other Pueblo complexes in the Southwestern United States. After reaching climaxes native complex societies in the United States declined and did not entirely recover before the arrival of European Explorers.\n\nAt the beginning of the global Post Classic Period, the city of Teotihuacan was at its zenith, housing over 125,000 people, at 450 A.D it was the sixth largest city in the world at the time. The city's residents built the Pyramid of the Sun the third largest pyramid of the world, oriented to follow astronomical events. Suddenly in the 6th and 7th centuries, the city suddenly declined possibly as a result of severe environmental damage caused by extreme weather events of 535–536. There is evidence that large parts of the city were burned, possibly in a domestic rebellion. The city's legacy would inspire all future civilizations in the region.\n\nFollowing Teotihuacan came the Classic Age of the Mayan Civilization clustered in dozens of city states on the Yucatán and modern day Guatemala. The most significant of these cities were Chichen Itza which often fiercely competed with its neighbors to be the dominant economic influence in the region. The Mayans had an upper caste of priests, who were well versed in astronomy, mathematics and writing. The Mayan developed the concept of zero, and a 365-day calendar which possibly per-dates its creation in Old-World societies. After 900, many Mayan cities suddenly declined in a period of drought.\n\nThe Toltec Empire arose from the Toltec culture, and were remembered as wise and benevolent leaders. One priest-king called Ce Acatl Topiltzin advocated against human sacrifice. After his death in 947, civil wars of religious character broke out between those who supported and opposed Topiltzin's teachings. Modern historians however are skeptical of the extent of Toltec and influence and believe that much of the information known about the Toltecs was created by the later Aztecs as an inspiration myth.\n\nIn the 1300s, a small band of violent, religious radicals called the Aztecs began minor raids throughout the area. Eventually they began to claim connections with the Toltec civilization, and insisted they were the rightful successors. They began to grow in numbers and conquer large areas of land. Fundamental to their conquest, was the use of political terror in the sense that the Aztec leaders and priests would command the human sacrifice of their subjugated people as means of humility and coercion. Most of the Mesoamerican region would eventually fall under the Aztec Empire. On the Yucatán Peninsula most of the Mayan People continued to be independent of the Aztecs but their traditional civilization declined. Aztec developments expanded cultivation, applying the use of chinampas, irrigation, and terrace agriculture; important crops included maize, sweet potatoes, and avocados.\n\nIn 1430 the city of Tenochtitlan allied with other powerful Nahuatl speaking cities- Texcoco and Tlacopan to create the Aztec Empire otherwise known as Triple-Alliance. Though referred to as an empire the Aztec Empire functioned as a system of tribute collection with Tenochtitlan at its center. By the turn of the 16h century \"flower wars\" between the Aztecs and rival states such as Tlaxcala had continued for over fifty years.\n\nSouth American civilization was concentrated in the Andean region which had already hosted complex cultures since 2,500 BC. East of the Andean region, the natives were generally semi nomadic. Discoveries on the Amazon River Basin indicate the region likely had a pre-contact population of five million people and hosted complex societies. Around the continent numerous agricultural peoples from Colombia to Argentina steadily advanced until European contact.\n\nDuring Ancient times the Andean Region had developed civilizations independent of outside influences including that of Mesoamerica. Through the Post Classical era a cycle of civilizations continued until Spanish Contact. Collectively Andean societies lacked currency, a written language and solid draft animals enjoyed by old world civilizations. Instead Andeans developed other methods to foster their growth, including use of the quipu system to communicate messages, lamas to carry smaller loads and an economy based on reciprocity. Societies were often based on strict social hierarchies and economic redistribution from the ruling class.\n\nIn the first half of the Post Classical Period the Andean Region was dominated by two almost equally powerful states. In the North of Peru was the Wari Empire and in the South of Peru and Bolivia was there is the Tiwanaku empire both of whom were inspired by the earlier Moche People. While the extent of their relationship to each other known, it is believed that they were in a Cold-War with one another, competing but avoiding direct conflict to avoid mutual assured destruction. Without war there was prosperity and around the year 700 Tiwanaku city hosted a population of 1.4. million. After the 8th century both states declined due to changing environmental conditions, laying the ground work for the Incas to emerge as a distinct culture centuries later.\n\nIn the 15th century the Inca Empire rose to annex all other nations in the area. Led by their, sun-god king, Sapa Inca, they slowly conquered what is now Peru, and built their society throughout the Andes cultural region. The Incas spoke the Quechua languages The Incas used the advances created by earlier Andean societies .Incas have been known to have used abacuses to calculate mathematics. The Inca Empire is known for some of its magnificent structures, such as Machu Picchu in the Cusco region. The empire expanded quickly northwards to Ecuador, Southwards to central Chile. To the north of the Inca Empire remained the independent Tairona and Musica Confederation who practiced agriculture and gold metallurgy.\n\nSeparate from developments in Afro-Eurasia and the Americas the region of greater Oceania continued to develop independently of the outside world. In Australia, the society of Aborigines and Melanesia changed little through the Post Classical Period, they had first arrived in the area from Africa around 50,000 BC. The only outside contact were encounters with fishermen of Indonesian origin. Polynesian and Micronesian Peoples are rooted from Taiwan and Southeast Asia and began their migration into the Pacific Ocean from 3000–1500 BC.\n\nDuring Post-classical Times the Micronesian and the Polynesian peoples constructed cities in some areas such as Nan Madol and Mu'a. Around 1200 AD the Tu'i Tonga Empire spread its influence far and wide throughout the South Pacific Islands, being described by academics as a maritime chiefdom which used trade networks to keep power centralized around the king's capital. Polynesians on outrigger canoes discovered and colonized some of the last uninhabited islands of earth. Hawaii, New Zealand and Easter Island were among the final places to be reached, settlers discovering pristine lands. Oral Tradition claimed that navigator Ui-te-Rangiora discovered icebergs in the Southern Ocean. In exploring and settling, Polynesian settlers did not strike at random but used their knowledge of wind and water currents to reach their destinations.\nThere is a hypothesis that Pre-Columbian contact took place between Polynesians and South America but this is in dispute. Traces of Sweet Potatoes native to South America have been discovered on the Cook Islands to 1000, but this may have occurred without human facilitation. There is also evidence Polynesian Chickens in Peru radiocarbon dated to the 14th/15th centuries, but the origins of the chickens were later stated to come from Eurasia. Linguistic evidence involving similarities of certain words for Axe and Sweet Potato appear to substantiate sporadic contact according to linguists.On the islands they settled some Polynesian groups became distinct from one another a significant example being the Maori of New Zealand, others island systems kept in contact with each other such has Hawaii and the Society Islands. Ecologically, Polynesians had the challenge of sustaining themselves within limited environments. Some settlements caused mass extinctions of some native plant and animal species over time by hunting species such as the Moa and introducing the Polynesian Rat. Easter Island settlers engaged in complete ecological destruction of their habtiat and their population crashed afterwards possibly due to the construction of the Easter Island Statues. Other colonizing groups adapted to accommodate to the ecology of specific islands such as the Moriori of the Chatham Islands.\n\nEuropeans on their voyages visited many Pacific Islands in the 16th and 17th century, but most areas of Oceania were not colonized until after the voyages of British explorer James Cook in the 1780s.\n\nAs the postclassical era drew to a close in the 15th century, many of the empires established throughout the period were in decline. The Byzantine Empire would soon be overshadowed in the Mediterranean by Italian city states such as Venice and Genoa and the Ottoman Turks. The Byzantines faced repeated attacks from eastern and western powers during the Fourth Crusade, and declined further until the loss of Constantinople to the Ottoman Turks in 1453.\n\nThe largest change came in terms of trade and technology. The global significance of the fall of the Byzantines was the disruption of overland routes between Asia and Europe. Traditional dominance of Nomadism in Eurasia declined and the Pax Mongolia which had allowed for interactions between different civilizations was no longer available. China, which had previously engaged in expansion and innovation became isolationist in the 14th century under the Ming and would remain so until the Industrial Revolution. Western Asia and South Asia were conquered by Gunpowder Empires which successfully utilized advances in military technology but closed the Silk Road.\nEuropeans – specifically the Kingdom of Portugal and various Italian explorers – intended to replace land travel with sea travel. Originally European exploration merely looked for new routes to reach known destinations. Portuguese Explorer Vasco De Gama traveled to India by sea in 1498 by circumnavigating Africa around the Cape of Good Hope. India and the coast of Africa were already known to Europeans but none had attempted a large trading mission prior to that time. Due to navigation advances Portugal would create a global colonial empire beginning with the conquest of Malacca in modern-day Malaysia from 1511.\n\nOther Explorers such as the Spanish sponsored Italian Christopher Columbus intended to engage in trade by traveling on unfamiliar routes west from Europe. The subsequent European discovery of the Americas in 1492 resulted in the Colombian exchange and the world's first globalization. Spanish Explorer Ferdinand Magellan performed the first known circumnavigation of Earth in 1521. The transfer of goods and diseases across oceans was unprecedented in creating a more connected world. From developments in navigation and trade modern history began.\n\n\n\"The History of the Medieval World: From the Conversion of Constantine to the First Crusade\" by Susan Wise Bauer\n\n\n"}
{"id": "42852", "url": "https://en.wikipedia.org/wiki?curid=42852", "title": "Radio frequency", "text": "Radio frequency\n\nRadio frequency (RF) refers to an oscillation rate of an alternating electric current or voltage or of a magnetic, electric or electromagnetic field or mechanical system in the frequency range from around twenty thousand times per second () to around three hundred billion times per second (). This is roughly between the upper limit of audio frequencies and the lower limit of infrared frequencies; these are the frequencies at which energy from an oscillating current can radiate off a conductor into space as radio waves. Different sources specify different upper and lower bounds for the frequency range. While RF usually refers to electrical rather than mechanical oscillations, mechanical RF systems are not uncommon (see mechanical filter and RF MEMS).\n\nElectric currents that oscillate at radio frequencies have special properties not shared by direct current or alternating current of lower frequencies.\n\nThe radio spectrum of frequencies is divided into bands with conventional names designated by the International Telecommunications Union (ITU):\nFrequencies of 1 GHz and above are conventionally called microwave, while frequencies of 30 GHz and above are designated millimeter wave.\nMore detailed band designations are given by the standard IEEE letter- band frequency designations and the EU/NATO frequency designations.\n\nRadio frequencies are generated and processed within very many functional units such as transmitters, receivers, computers, and televisions to name a few. Radio frequencies are also applied in carrier current systems including telephony and control circuits.\n\nRadio frequency (RF) energy, in the form of radiating waves or electrical currents, has been used in medical treatments for over 75 years, generally for minimally invasive surgeries using radiofrequency ablation including the treatment of sleep apnea. Magnetic resonance imaging (MRI) uses radio frequency waves to generate images of the human body.\n\nRadio frequencies at non-ablation energy levels are commonly used as a part of aesthetic treatments that can tighten skin, reduce fat by lipolysis and also apoptosis, or promote healing.\n\nRF diathermy is a medical treatment that uses RF induced heat as a form of physical therapy and in surgical procedures. It is commonly used for muscle relaxation. It is also a method of heating tissue electromagnetically for therapeutic purposes in medicine. Diathermy is used in physical therapy to deliver moderate heat directly to pathologic lesions in the deeper tissues of the body. Surgically, the extreme heat that can be produced by diathermy may be used to destroy neoplasms, warts, and infected tissues, and to cauterize blood vessels to prevent excessive bleeding. The technique is particularly valuable in neurosurgery and surgery of the eye. Diathermy equipment typically operates in the short-wave radio frequency (range 1–100 MHz) or microwave energy (range 434–915 MHz).\n\nPulsed electromagnetic field therapy (PEMF) is a medical treatment that purportedly helps to heal bone tissue reported in a recent NASA study. This method usually employs electromagnetic radiation of different frequencies - ranging from static magnetic fields, through extremely low frequencies (ELF) to higher radio frequencies (RF) administered in pulses.\n\nRadio frequency current through tissue will generate heat in the tissue and can cause burns.\n\nTest apparatus for radio frequencies can include standard instruments at the lower end of the range, but at higher frequencies the test equipment becomes more specialized.\n\n\n"}
{"id": "41738695", "url": "https://en.wikipedia.org/wiki?curid=41738695", "title": "Rainbow Valley Conservation Reserve", "text": "Rainbow Valley Conservation Reserve\n\nRainbow Valley Conservation Reserve is a protected area located south of Alice Springs, Northern Territory in Australia. The reserve was established in 1990 to protect the unique sandstone formations and the Aboriginal art, artifacts and sacred natural objects within an area of around a large sandstone bluff. The sandstone layers in the main formation resemble the colored stripes of a rainbow, with the red-orange hues of sandstone that is rich with iron creating a strong contrast with the lighter shaded sandstone that turns pale yellow or gold in the late day sun as it shines on the northwest-facing cliffs.\n\nRainbow Valley's main sandstone formation is known as \"Wurre\" by the local Aboriginals, the Twertentyeye group of Upper Southern Arrernte people, and is a significant part of their homeland which they call \"Imarnte\". Since 2008, the area has been jointly managed by the Twertentyeye and the Parks and Wildlife Commission of the Northern Territory (PWCNT) and is the first conservation reserve to have a joint management plan.\n\nThe Rainbow Valley access road is located south of Alice Springs as a branch off the Stuart Highway. The unsealed dirt access road heads east then southeast for to a parking lot situated on the west side of a claypan that extends northwest from the base of the main sandstone formation. Since there are some sandy sections along the access road, the official park site declares the road as \"recommended for 4WD vehicles only.\" The joint management plan's official document, however, refers to the access road as \"suitable for conventional vehicles driven with care\" but still recommends 4WD for the final around the claypan. A plan to re-align and improve the final section was in place as of June 2008.\n\nThe reserve is located in the arid center of the country where rain is irregular and droughts are common. The nearest place with official records, Alice Springs, has a median annual rainfall of and an evaporation rate of more than per year. No permanent water sources exist on the surface though there is an aquifer not far below the surface. A single rockhole does contain rainwater for long periods and was therefore an important source for the Aboriginal people after significant rainfall.\n\nThe cliffs and rocky outcrops in Rainbow Valley are composed of 350 million year old \"Hermannsburg Sandstone\". Below the surface there is a layer of \"Mereenie Sandstone\" which becomes exposed above ground level in the James Range, a mountain range to the south of the reserve. Various exposed sandstone joints, eroded honeycomb holes, iron-stained sandstone and fossils are found in the formations. Since these sandstones are very delicate they can be damaged by any human interaction. Climbing on or disturbing the formations is prohibited. The claypans are also delicate and visitors are advised to stay off them unless they are dry and a permit is obtained.\n\nThe colored bands in the rock layers of Rainbow Valley were created during a much wetter time in the history of this very dry region. Heavy rains would cause the reddish, iron-rich sandstone to dissolve and the subsequent dry seasons would cement those dissolved minerals on the surface, staining them a deeper red. The dark red caprock contains the most iron and is more resistant to erosion than the lighter colored sandstone layers, which delays the eventual collapse and disintegration of the formations.\n\nA marked trail leads to another featured formation called \"Mushroom Rock\" where fairy martin nests are located high up on the rock wall.\n\nMore than 400 plant species are found in Rainbow Valley including spinifex grasslands, acacia shrubs and coolibah trees in the western part of the reserve. Mulga trees grow close to the sandstone formations and even on top of them. Desert oaks are more common on the east side of the main formation.\n\nThe \"eremophila Rainbow Valley\" is a sandplain shrub listed as \"vulnerable\" under the \"Commonwealth Environmental Protection and Biodiversity Conservation Act\" (CEPBCA). The species survives only in a very restricted range and is not protected in any other reserve. \"Daviesia arthropoda\" is another rare shrub that grows on sand dunes in the reserve.\n\nThe observed animal species are 110 birds, 20 mammals, 46 reptiles and three frogs. Emus, bats, dingoes and honeypot ants are significant animals in the local Aboriginal culture. Bat species include the Gould's wattled bat and the lesser long-eared bat.\n\nMigratory black, brown and pied honeyeaters use the grevillea and eremophila shrubs as their breeding habitat, while the white-winged fairywren's habitat includes the zygochloa and spinifex grasslands. The grey falcon, redthroat and red-tailed black cockatoo are listed as \"lower risk near threatened\" under the \"Territory Parks and Wildlife Conservation Act\" (TPWCA).\n\nThe euro is the most observed mammal, while the black-flanked rock-wallaby is listed as \"vulnerable\" by the CEPBCA and \"near threatened\" by the TPWCA - the only mammal with a conservation listing in the reserve. The thorny devil and the trilling frog also live in the reserve.\n\nMore than forty Aboriginal archaeological sites have been found and recorded. These sites include petroglyphs (engraved rock), pictographs (painted rock), grinding stones, stone tools, quarries and camp sites. All archaeological sites are in a restricted access area which requires permission and a guide to enter.\n\nTo the south of the main sandstone formation, a massif called \"Ewerre\" by the Twertentyeye is registered as a sacred site, as well as all the surrounding area within of that rock. The black rocks lying on the northern side of the main formation are also considered significant natural objects that are not to be moved from their current locations.\n\nIn consideration of both the Aboriginal culture and the ideals of conservation of the area, visitors may only explore in the designated viewing and camping areas on the southwest side of the claypan, and along the trail to Mushroom Rock or other officially marked trails. All other areas, including the claypan, are restricted access requiring a guide.\n\nVisitors may camp in two designated areas. A camping fee is required and payable on site. There are gas barbecues, firepits, picnic tables and pit toilet facilities available.\n\n\n"}
{"id": "31533498", "url": "https://en.wikipedia.org/wiki?curid=31533498", "title": "Review of International Organizations", "text": "Review of International Organizations\n\nThe Review of International Organizations is a peer-reviewed academic journal that analyzes operations and policies of both governmental and non-governmental organizations. Scientific contributions cover agencies such as the International Monetary Fund, the World Trade Organization, the World Bank, the G7, the NATO, the European Court of Human Rights, the United Nations, and similar formal institutions. In addition, the journal offers research on networks of international cooperation, including the Global Development Network and the International Competition Forum. \n\nThe journal is published by Springer Boston. Its current editors are Axel Dreher (Editor-in-Chief, Heidelberg University), James Vreeland (Associate Editor, Princeton University) and Todd Sandler (Associate Editor, University of Texas at Dallas).\n\nAccording to the \"Journal Citation Reports\", the journal has a 2015 impact factor of 2.444, ranking it 11th out of 163 journals in the category \"Political Science\" and 6th out of 86 journals in the category \"International Relations\".\n\n"}
{"id": "9998690", "url": "https://en.wikipedia.org/wiki?curid=9998690", "title": "Sacred mountains", "text": "Sacred mountains\n\nSacred mountains are central to certain religions and are the subjects of many legends. For many, the most symbolic aspect of a mountain is the peak because it is believed that it is closest to heaven or other religious worlds. Many religions have traditions centered on sacred mountains, which either are or were considered holy (such as Mount Olympus in Greek mythology) or are related to famous events (like Mount Sinai in Judaism and descendant religions). In some cases, the sacred mountain is purely mythical, like the Hara Berezaiti in Zoroastrianism. Mount Kailash is believed to be the abode of the Hindu deity Shiva. Volcanoes, such as Mount Etna in Italy, were also considered sacred, Mount Etna being believed to have been the home of Vulcan, the Roman god of fire and the forge.\n\nCarpathian Mountains - an arc roughly 1,500 km (932 mi) long across Central Europe.\nMount Olympus is the highest mountain peak in Greece. It was once regarded as the “home of the Greek Gods/The Twelve Olympians of the Hellenistic World\". It was also considered the site of the War of the Titans (Titanomachy) where Zeus and his siblings defeated the Titans.\n\nMount Othrys is a mountain in Central Greece, which is believed to be the home of the Titans during the ten-year war with the Gods of Mount Olympus.\n\nMount Ida, also known as Mountain of the Goddess, refers to two specific mountains: one in the Greek island of Crete and the other in Turkey (formerly known as Asia Minor).\n\nMount Ida is the highest mountain on the island of Crete is the sacred mountain of the Titaness Rhea, also known as the mother of the Greek Gods. It is also believed to be the cave where Greek God Zeus was born and raised.\n\nThe other Mt. Ida is located in Northwestern Turkey alongside the ruins of Troy (in reference to the Hellenistic Period). The mountain was dedicated to Cybele, the Phrygian (modern-day Turkey) version of Earth Mother. Cybele was the goddess of caverns and mountains. Some refer to her as the “Great Mother” or “Mother of the Mountain”. The mythic Trojan War is said to have taken place at Mount Ida and that the Gods gathered upon the mountaintop to observe the epic fight. Mount Ida in Turkey is also represented in many of the stories of Greek author Homer such as Iliad and Odyssey.\n\nMount Athos, located in Greece, is also referred to as the Holy Mountain. It has great historical connections with religion and classical mythology. In religion it is believed that after the Ascension of the Lord, the Virgin Mary landed on the island and came upon a pagan temple. It was there that the pagan practitioners converted from paganism to Christianity. The Virgin Mary then blessed the land and claimed it her own.\n\nIn classical mythology, Mount Athos is named after the Thracian giant who battled Poseidon, God of the Sea, during the clash of the titans and Gods. It is also said that Greek historian was given the task of creating a canal through the mountain after the failed journey of Persian leader, Xerxes. Overtime, Alexander the Great has become associated with the mountain for his worldly powers. The myth states that Roman architect Dinocrates had wanted to carve Alexander the Great's figure onto the top of the mountain in tribute to him.\n\nThe ancient Inca displayed a connection with death and their mountains. It is well known by scholars that the Inca sensed a deep reservoir of spirituality along the mountain range. Situating their villages in the mountains, they felt these places acted as portal to the gods. Ritual child sacrifices called Capachochas were conducted annually, where the most precious gift that could be given (innocent, blemishless, perfect human life) would be sacrificed to the gods. Tremendous effort would be taken as the sacrificial victims would be paraded alive throughout the cities, with multiple festivals and feasts taking place. The final destination would be the tops of some of the highest mountains near their villages, leaving these sacrifices to freeze in the snow. These would take place during great times of distress, during times of famine, violent periods of war, and even during times of political shift. This connection with the mountain as a sacred space is paramount. There would be no other place that would be sufficient or acceptable enough for the gods to accept these gifts. It is neither a surprise nor a coincidence that their honored dead were placed on the highest peaks of the mountains to express the shared connection between the sacred mountain, the gods, and the dead.\n\nVarious cultures around the world maintain the importance of mountain worship and sacredness. One example is the Taranaki peoples of New Zealand. The Taranaki center their whole life around the sacred mountain, the Mount Taranaki. It is no wonder that they shared the same name, as they shared their livelihood from its streams. The rivers that flowed down its steep terrain fed the plants, animals, and gave the tribe all they needed for life. The Taranaki tribe places this mountain into a context of a love story, spelling out the history of their creation in a battle over love, defeat, and a happy ending where this Taranaki Mountain found love with a neighboring volcano. This narrative plays out in the lives of the tribesmen where the mountain is their love, their life force. Life is given from megalith, and when life is taken away, the people are ultimately returned to the mountain. This mountain can be explained as anthropomorphisised, a living organism of its own.\n\nIn Korea, people have maintained ancient ways of worshiping mountain spirits. While they are not in fact worshiping the land itself, the gods associated with this worship are united to the land. These spirits are female entities to whom people pay tribute while passing by the mountains, asking for good luck and protection. People also travel to these mountains to ask for fertility. While people generally hold to these female deities for protection or to perpetuate life, one of their most important functions is to protect the dead. The ponhyangsansin is a guardian spirit that is protecting an important clan grave site in the village. Each mountain goddess has an equally interesting story that is tied to their accounts of war against Japan, and the historical legacy of their emperors. Each spirit learned difficult lessons and experienced some sort of hardship. These legacies in the mountains serve as a kind of monument to the history of Korea. While many of the accounts may be true, their details and accuracy are shrouded by time and ritual. While the inaugurations of new ponhyang san sin are not being conducted, fallen important clansmen and leaders are strategically placed in the mountains in order for these strong, heroine-like spirits may fiercely guard their graves. The history of Korea is in turn protecting its own future.\n\nIn Japan, Mount Koya-san is the home to one of the holiest Buddhist monastery complexes in the country. It was founded by a saint, Kukai, who is also known as Kobo Dashi and is regarded as a famous wandering mystic; his teachings are infamous throughout Japan and he is credited with being an important figure in shaping early Japanese culture. Buddhists believe that Kobo Dashi is not dead, but will instead awake and assist in bringing enlightenment to all people, alongside the Buddha and other bodhisattvas. It is believed that he was shown the sacred place to build the monastery by a forest god; this site is now the location of a large cemetery that is flanked by 120 esoteric Buddhist temples. Approximately a million pilgrims visit Mount Koya-san a year; these pilgrims have included both royals and commoners who wish to pay their respects to Kobo Dashi. Mount Fuji, known as Fuji-san in Japanese, is another sacred mountain in Japan. Several Shinto temples flank its base, which all pay homage to the mountain. A common belief is that Fuji-san is the incarnation of the earth spirit itself. The Fuki-ko sect maintains that the mountain is a holy being, and the home to the goddess Sengen-sama. Annual fire festivals are held there in her honor. Fuji-san is also the site of pilgrimages; reportedly, 40,000 people climb up to its summit every year.\n\nTibet's Mount Kailash is a sacred place to four religions: Buddhism, Jainism, Hinduism, Bon Po (a native Tibetan religion prior to Buddhism), and Ayyavazhi religions. According to some Hindu tradition, Kailash is the home of the deity Shiva. In Hindu religion, Mount Kailash also plays an important role in Rama's journey in the ancient Sanskrit epic, Ramayana. Buddhists hold that Kailash is the home of Samvara, a guardian deity, and a representation of Buddha. Buddhists believe that Mount Kailash has supernatural powers that are able to clean the sins of a lifetime of any person. Followers of Jainism believe that Kailash is the site where the founder of Jainism reached enlightenment. Bon Po teaches that Kailash is the home of a wind goddess.\n\nMount Meru is a cosmic mountain which is described to be one of the highest points on Earth and is the center of all creation. In the Hindu religion, it is believed that Meru is home to the god Brahma, who is believed to be the father of the human race and all the demigods produced afterward. Indian cosmology believes that the sun, moon, and stars all revolve around Mount Meru. Folklore suggests the mountain rose up from the ground piercing the heavens giving it the moniker \"navel of the universe\".\n\nAccording to the Torah, and consequently the Old Testament of the Bible, Mount Sinai is the location that Moses received the Ten Commandments directly from God. The tablets form the covenant, which is a central cornerstone of Jewish faith. Saint Catherine's Monastery is located at the foot of Sinai. It was founded by empress Helena, who was the mother of the first Christian Roman emperor, Constantine. It was completed under the rule of Justinian two centuries later. The monastery was visited by the prophet Muhammed, who blessed it and promised “that it would be cherished by Muslims for all time”. Today, the monastery is home to a group of Greek Orthodox monks, as well as a large collection of Byzantine art, illuminated manuscripts, icons, and books; the collection of icons in particular has been proclaimed one of the oldest in the world.\n\nThe Navajo possess a strong belief system in regards to the natural-supernatural world and have a belief that objects have a supernatural quality. For example, the Navajo consider mountains to be sacred. There are four peaks, which are believed to have supernatural aspects. The mountains each represent a borderline of the original Navajo tribal land. The mountain ranges include Mount Taylor, the San Francisco Peaks, Blanca Peak, and Hesperus Peak located in the La Plata Mountains.\n\nEach mountain/peak is representative of a color, direction, and correlates with a cultural light phenomenon dealing with the cosmic scheme of the rising and of the setting sun. Directionally, the mountains are described in a clockwise motion following the movement of the sun beginning with the eastern mountain of Blanca Peak. Blanca Peak is associated with the color white and the \"Dawn Man\" referring to the rising of the sun. Next in the south is Mt. Taylor, which is associated with the color blue and the \"Horizontal Blue Man\" referring to the daytime. In the west is the San Francisco Peaks, which is representative of the color yellow and the \"Horizontal Yellow Woman\" and is associated with the setting of the sun. And finally in the north is the Hesperus Peak of the La Plata Mountains which is given the color black and belongs to the light phenomenon of the \"Darkness Woman\" representing the nighttime.\n\nHistory shows that mountains were commonly part of a complex system of mountain and ancestor worship. Having immortalized fallen brethren in the edifice, the people share a common allegiance with all the other people of a community. The meanings that were etched into the mountain and mound terrain connected the villagers. They were all subject to the same landscape and village history, which were bound together by their cultural significance. The history of ancestors could be told by simply pointing at specific mountains and remembering the stories that were passed down throughout the generations. The worship of ancestors and the mountains were largely inseparable. An interconnected web between history, landscape, and culture was thus formed. Examples of this would be the Hindu belief that Mount Kailas is the final resting place for the\nsouls of the dead, as well as the large cemetery placed on Mount Koya-san.\n\nSacred mountains can also provide an important piece of a culture's identity. For example, Messerli and Ives write, “The Armenian people regard Mount Ararat, a volcano in eastern Turkey believed to be the site of Noah's Ark in the Bible, to be a symbol of their natural and cultural identity”. As a result of the mountain's role as a part of a cultural identity, even people who do not live close to the mountain feel that events occurring to the mountain are relevant to their own personal lives. This results in communities banning certain activities near the mountain, especially if those activities are seen as potentially destructive to the sacred mountain itself.\n\nTo date, Kailash has never been climbed, largely due to the fact that the idea of climbing the mountain is seen as a major sacrilege. Instead, the worshipful embark on a pilgrimage known as the kora. The kora consists of a 32-mile path that circles the mountain, which typically takes five days with little food and water. Various icons, prayer flags, and other symbols of the four religions that believe Kailash is sacred mark the way. To Buddhists and Hindus, the pilgrimage is considered a major moment in a person's spiritual life. Olsen writes, “One circuit is believed to erase a lifetime of sin, while 108 circuits is believed to ensure enlightenment”.\n\nAs one of the most sacred mountains in the Middle East, mentioned in the Old Testament can be seen on the mountain's summit, such as the area where Moses “sheltered from the total glory of God”.\n\nSacred Mountains are often seen as a site of revelation and inspiration. Mount Sinai is an example, as this is the site where the covenant is revealed to Moses. Mount Tabor is where it is supposed Jesus was revealed to be the Son of God. Muhammed is said to have received his first revelation on Mount Hira. The mountains' roles as places of revelation and transformation often serve to attract tourists as much as they do religious pilgrims. However, in some cases, the financial revenue is overlooked and sacred mountains are conserved first due to their role in the community.\n\nMembers of The Aetherius Society conduct pilgrimages to 19 mountains around the world that they describe as being \"holy mountains\".\n\nSacred mountains are often viewed as the source of a power which is to be awed and revered. Often, this means that access to the sacred mountain is restricted. This could result in climbing being banned from a sacred mountain completely (as in the case of Mount Kailas) or for secular society to give the mountain a wide berth. Because of the respect accorded to a mountain's sacred power, many areas have been declared off limit for construction and remain conserved. For example, a large amount of forest has been preserved due to its proximity to Mount Koya-san. Additionally, sacred mountains can be seen as the source of something vital. This could be a blessing, water, life, or healing. Mount Kailas's role as the source for four major rivers is celebrated in India and not simply seen as mundane. Rather, this also adds to its position as a sacred place, especially considering the sacred position of the Ganges river in Indian culture. Mountains that are considered home to deities are also central to prayers for the blessings from the gods reputed to live there. This also creates a sense of purity in the source of the mountain. This prompts people to protect streams from pollution that are from sacred mountains, for example.\n\nViews of preservation and sacredness become problematic when dealing with diverse populations. When one observes the sacred mountain of the Sacramento Valley in the United States, it becomes clear that methods and opinions stretch over a vastly differing body of protesters. Shasta Mountain was first revered by the Native American tribe, the Wintu. Shasta was in effect a standing monument for the individuals of their cultural history. This bounded view of sacred mountains changed drastically during the 1800s. It is commonly assumed that sacred mountains are limited by a single society, trapped in a time capsule with only one definition to explain it: the indigenous tribe. Shasta's glory had expanded to multiple regions of the world, communities of differing religions making their pilgrimage up to the summits of this glorious mountain. The Wintu tribe did not hold a monopoly on the sacredness anymore. There were others contesting to the meanings, adding new rituals and modifying old ones. With the advent of new technology and desires to turn this mountain into a skiing lodge, angry voices from all over the world rose up with variants of demands on why and how we should preserve this beautiful mountain.\n\nAlmost every day different religious practices such as nude bathing, camping out with magic crystals, yoga, and many “quasi-Christian” groups such as the I AM march their ways up to the tips of this mountain. With this activity the mountain pathways become clustered, cluttered and littered. Even the pathways’ existence leads to erosion, and further slow degradation of the mountain. The Wintu tribe has voiced concerns and asked for support from the government to regulate the activities practiced on “their” mountain saying that “they are disturbed by the lack of respect” shown for this piece of land. It has become greatly debated if the more vulnerable and “spiritually desirable” places of the mountain should be closed and maintained only by the Wintu tribe, who see this land as a sacred graveyard of their ancestors, or open to all who seek spiritual fulfillment such as the modern-day group of the I AM.\n\n\n\n"}
{"id": "44096654", "url": "https://en.wikipedia.org/wiki?curid=44096654", "title": "Sarah Fraser Robbins", "text": "Sarah Fraser Robbins\n\nSarah Fraser Robbins (December 27, 1911 - February 9, 2002) was a writer and educator in the field of natural history and a dedicated environmentalist.\n\nHer scientific specialty was the creatures that inhabit the shallow waters of the seacoast of Massachusetts. She was a fervent birder as well. She was the first director of education at the Peabody Museum of Salem, 1971-1981. She spent many years before and after that time exploring the dwellers of the waters, littoral zone, and sky near her house in Gloucester, Massachusetts. For almost twenty years she served on the board of directors of the Massachusetts Audubon Society and contributed regular columns to the Society’s magazines. She was also a member of the Society of Woman Geographers, an elite group of adventurers and travelers. She rode elephants to see tigers in India, flew over the Alps in a hot air balloon, and fished in Afghanistan.\n\nSarah Fraser was the youngest of five children, one boy and four girls, of George Corning Fraser (born February 25, 1872 in New York City, died November 15, 1935 in Dallas, Texas) and Jane Gardener Tutt (born August 4, 1874 in Danville, Kentucky, died December 25, 1936 in New York City). They were married December 5, 1895 in St. Louis, Missouri. Sarah was born in Morristown, New Jersey on December 27, 1911. Almost a fifty-year resident of Gloucester, she died in Boston on February 9, 2002 at the age of 90.\n\nSarah’s father was a lawyer in New York City and amateur geologist by avocation. He had a great spirit of wanderlust that he passed on to his children. He enjoyed taking his daughters on summer field trips to the western United States, especially Utah.\n\nSarah was educated at Brearley School in New York City, became a debutante, and was honored at a dinner and dance given by her older sisters in November, 1930. She followed her older sister, Ann, to Bryn Mawr College. She graduated in 1934 with a degree in geology, with distinction. During her senior year she received the Elizabeth S. Shippen Prize in Science. In 1934 and 1935 she returned to Brearley to teach science. In 1984, at her fiftieth reunion, she was chosen by her Bryn Mawr classmates to present the class gift to the college.\n\nOn May 2, 1936, in the garden of the estate at Morristown, she married Chandler Robbins II of Boston, the son of physician Dr. William Bradford Robbins and his wife Marian Bennett Robbins. Chandler Robbins II was born in Boston on November 21, 1906 and died in Boston on June 2, 1955 of cancer. His entire career, except for the World War II years, was spent with the Bates Manufacturing Company of Lewiston, Maine, one of the greatest textile companies in America.\n\nThe young couple moved to Auburn, Maine, where the first three of five children were born: Hanson Corning, born in 1937; Theodore Bennett, born in 1939; and Marian, born in 1941 and died in 1975. Two other daughters, Sarah, born in 1943, and Jane, born in 1945, were born in Washington, D.C. while their father served in the production section of the research and development division of the Office of the Quartermaster General. At the time of Chandler Robbins’s death, he was described as “assistant to the president in charge of research and development” for the Bates Manufacturing Company.\n\nAfter renting summer houses on Gloucester for many years, Sarah Fraser's maternal aunt Myra Tutt purchased a house on Aileen Terrace, Eastern Point in 1928. At her death in 1946, Miss Tutt bequeathed the house on the harbor to her niece. For almost ten years, until Chandler Robbins’s death, the family spent summers in Gloucester and the school year in Auburn. Immediately after her husband’s death, Mrs. Robbins moved into the Eastern Point house and lived there all year round until her death in 2002.\n\nSarah’s greatest friend and traveling companion was Dorothy Addams Brown, a summer and later full-time resident of Eastern Point. Dotty was born in Boston in 1923 and died in Gloucester in 2014. Addams Brown was the first woman vice president of the Boston Safe Deposit and Trust Company.\nIn 1956 Robbins began her volunteer work at the Peabody Museum of Salem, now the Peabody Essex Museum. This was the beginning of twenty-five years of work at the Museum. In 1958, she first appears in the annual report of the director of the Peabody Museum, Ernest Dodge. In that year she was a volunteer working under Dorothy Snyder on the renovation of the \"Mammals of Essex County\" exhibit. In 1961, she was made Honorary Curator of Natural History. In 1971, she was made the first Director of Education of the Museum. The position was made possible by an anonymous donation. In 1981, she is listed as Director Emerita. She was then 70 years old.\n\nWhile working at the museum in 1971, she gave an introduction to Physical Geology, a 6-session presentation on the “Living Landscape of Essex County,” and a 2-session in-service teacher training at the Massachusetts Audubon center in Gloucester on the physical geology of Essex County, Massachusetts, including the sea shore.\nIn 1972, she gave a 12-session lecture course, “How to Look at the Landscape,” and two 6-session courses on “At the Edge of the Tide” and “Living Landscapes of Essex County,” as well as lectures on whaling and Alaska.\n\nIn 1973, she and Clarice Yentsch co-authored \"The Sea is All About Us\", a guidebook to the marine environments of Cape Ann and other northern New England waters.\n\nIn 1974, she ran a 5-week marine science program for almost one hundred children of Gloucester and neighboring Rockport, Massachusetts, overseeing a staff of eight teachers.\n\nIn 1975, she presided over a symposium at Harvard University of the National Association of Underwater Instructors. She also led geology field trips by bus and whale watches by boat. She re-ran the previous year's program for Gloucester school children.\n\nIn 1976, she spent some time in New Guinea; she became editor of \"Aquasphere\", the magazine of the New England Aquarium; and she gave a 4-session course in Oceanography for the United States Power Squadrons.\n\nIn 1977, she was involved in planning a course on the environment with the extension service of the University of Massachusetts, and also started planning a “Discovery Room” for the Peabody Museum.\n\nIn 1978 and 1979, she was the naturalist aboard the schooner Harvey Gamage on week-long cruises among the Virgin Islands. She also ran seminars for elementary school teachers at Salem State College. After 1978, the museum director ceased detailing her activities.\n\nRobbins retired in July 1981. During all her years at the Peabody Museum (which became the Peabody Essex Museum in 1992), she provided for the professional development of teachers to take leadership roles. By the end of her tenure, the museum's Education Department was providing programs for over thirty thousand children and nine thousand adults annually.\n\nIn 2003, in her memory, the Peabody Essex Museum established the Sarah Fraser Robbins Directorship of the new Art & Nature Center. This center features original exhibits that investigate the interconnection between people and nature through contemporary art, historical objects and interactive experiences.\n\nIn 1961, Robbins, with other Eastern Point residents, prevailed upon members of the Raymond family to give what ultimately became almost forty acres of land on Eastern Point to the Massachusetts Audubon Society.\n\nIn 1978, Robbins, her daughter Sarah, and Philip Weld, Jr. swam almost a mile and a half in the open water of Gloucester Harbor to protest the ongoing pollution of the harbor waters. Every year since then, open water swimmers have commemorated that swim; 2014 is the 36th annual swim. The current course is about 1.2 miles out and back in the harbor. Until 1993, the swim was sponsored by the Massachusetts Audubon Society. In that year its name was changed to “Celebrate the Clean Harbor,” since the conditions had immensely improved. The Weld family sponsored a harbor cleanup research and monitoring program under the auspices of the Massachusetts Society to ensure that the federal funding necessary that the program was spent wisely. Currently, the race is sponsored by the New England Marathon Swimming Association. Robbins swam it for many years, and her daughter Sarah has succeeded her.\n\nIn 1970, the University of Massachusetts Amherst bought the defunct Consolidated Lobster Company buildings at Hodgkins Cove on the northwest side of Cape Ann to set up a marine research station to study the “basic productivity of marine water.” That same year, Charles Yentsch arrived to serve as the director, and brought his wife Clarice. Clarice Yentsch, familiar only with the ecosystems of southern waters, sought out Robbins to teach her about northern New England waters. In late June, 1974, the Yentsches resigned, and they, with most of their team of researchers and the research vessel R. V. Bigelow, moved to Boothbay, Maine where they established the Bigelow Laboratory for Ocean Sciences.\n\nMaritime Gloucester, formerly the Gloucester Maritime Heritage Center, is located on the Gloucester waterfront. The education center at Maritime Gloucester, formally the Sarah Fraser Robbins Marine Science Center, was dedicated November 15, 2008. On June 21, 2014, Maritime Gloucester presented the first Sarah Fraser Robbins Environmental Award to Dr. Molly Lutcavage, director of research at the University of Massachusetts Large Pelagics Research Center–in absentia, because she was in Hawaii establishing a cooperative satellite tuna tagging project. This was also the occasion of the formal launch of a re-edition of the book \"The Sea is All About Us\", which Robbins and Clarice Yentsch had co-authored in 1973.\n\nRobbins had a regular column, “The Curious Naturalist,” which appeared in the magazines of the Massachusetts Audubon Society. She contributed articles between 1958 and 1971, almost all on the creatures of the littoral zone of Gloucester.\n\nIn 1973, she was the senior author of a book, co-authored by Clarice Yentsch, entitled \"The Sea is All About Us\", which was based on fifty of the articles that Sarah had contributed to the Audubon Society’s magazine with added material. It was jointly published by the Peabody Museum and the Cape Ann Society for Marine Science.\nShe also published articles on the seashore in Aquasphere, the journal of the New England Aquarium, and many small, regional journals concerned with the environment.\nThe guidebook and the two education centers are concrete reminders of Robbins's legacy as a provider of programs which brought natural history to thousands of people. She was an early example of a “citizen scientist.” The Sarah Fraser Robbins Environmental Award, first given by Maritime Gloucester in 2014, is established in her name to commemorate this legacy.\n"}
{"id": "20503277", "url": "https://en.wikipedia.org/wiki?curid=20503277", "title": "Silicon drift detector", "text": "Silicon drift detector\n\nSilicon drift detectors (SDDs) are X-ray radiation detectors used in x-ray spectrometry (XRF and EDS) and electron microscopy. Their chief characteristics compared with other X-ray detectors are:\n\nLike other solid state X-ray detectors, silicon drift detectors measure the energy of an incoming photon by the amount of ionization it produces in the detector material. This varying ionization produces varying charge, which the detector electronics measure for each incoming photon. In the SDD, this material is high purity silicon with a very low leakage current. The high purity allows for the use of Peltier cooling instead of the traditional liquid nitrogen. The major distinguishing feature of a SDD is the transversal field generated by a series of ring electrodes that causes charge carriers to 'drift' to a small collection electrode. The 'drift' concept of the SDD (which was imported from particle physics) allows significantly higher count rates coupled with a very low capacitance of the detector.\n\nIn older detector designs, the collection electrode is centrally located with an external FET (field effect transistor) to convert the current into a voltage and thus represents the first stage of amplification. Newer designs integrate the FET directly into the chip, which greatly improves energy resolution and throughput. This is due to the reduction of capacitance between anode and FET, which reduces electronic noise.\n\nOther designs move the anode and FET outside of the irradiated area. This causes a slightly longer response time, which leads to a slightly lower throughput (750,000 counts per second instead of 1,000,000). However, due to the smaller anode size, this leads to better energy resolutions (down to 123 eV for Mn Kα wavelength). Combined with improved or adapted signal processing, it is possible to maintain the silicon drift detector's energy resolution up to 100,000 counts per second.\n"}
{"id": "3173180", "url": "https://en.wikipedia.org/wiki?curid=3173180", "title": "Sonochemistry", "text": "Sonochemistry\n\nIn chemistry, the study of sonochemistry is concerned with understanding the effect of ultrasound in forming acoustic cavitation in liquids, resulting in the initiation or enhancement of the chemical activity in the solution. Therefore, the chemical effects of ultrasound do not come from a\ndirect interaction of the ultrasonic sound wave with the molecules in the solution. Sound waves propagating through a liquid at ultrasonic frequencies do so with a wavelength that is dramatically longer than molecular dimensions or the bond length between atoms in the molecule. Therefore, the sound wave cannot affect that vibrational energy of the bond, and can therefore not directly increase the internal energy of a molecule. Instead, sonochemistry arises from acoustic cavitation: the formation, growth, and implosive collapse of bubbles in a liquid. The collapse of these bubbles is an almost adiabatic process, thereby resulting in the massive build-up of energy inside the bubble, resulting in extremely high temperatures and pressures in a microscopic region of the sonicated liquid. The high temperatures and pressures result in the chemical excitation of any matter that was inside of, or in the immediate surroundings of the bubble as it rapidly imploded. A broad variety of outcomes can result from acoustic cavitation, including sonoluminescence, increased chemical activity in the solution due to the formation of primary and secondary radical reactions, and increase chemical activity through the formation of new, relatively stable chemical species that can diffuse further into the solution to create chemical effects (for example, the formation of hydrogen peroxide from the combination of two hydroxyl radicals formed following the dissociation of water vapor inside the collapsing bubbles what water is exposed to ultrasound.\n\nThe influence of sonic waves traveling through liquids was first reported by Robert Williams Wood (1868–1955) and Alfred Lee Loomis (1887–1975) in 1927. The experiment was about the frequency of the energy that it took for sonic waves to \"penetrate\" the barrier of water. He came to the conclusion that sound does travel faster in water, but because of the water's density compared to our earth's atmosphere it was incredibly hard to get the sonic waves into the water. After lots of research they decided that the best way to disperse sound into the water was to make loud noises into the water by creating bubbles that were made at the same time as the sound. One of the easier ways that they put sound into the water was they simply yelled. But another road block they ran into was the ratio of the amount of time it took for the lower frequency waves to penetrate the bubbles walls and access the water around the bubble, and then time from that point to the point on the other end of the body of water. But despite the revolutionary ideas of this article it was left mostly unnoticed. Sonochemistry experienced a renaissance in the 1980s with the advent of inexpensive and reliable generators of high-intensity ultrasound.\n\nUpon irradiation with high intensity sound or ultrasound, acoustic cavitation usually occurs. Cavitation – the formation, growth, and implosive collapse of bubbles irradiated with sound — is the impetus for sonochemistry and sonoluminescence. Bubble collapse in liquids produces enormous amounts of energy from the conversion of kinetic energy of the liquid motion into heating the contents of the bubble. The compression of the bubbles during cavitation is more rapid than thermal transport, which generates a short-lived localized hot-spot. Experimental results have shown that these bubbles have temperatures around 5000 K, pressures of roughly 1000 atm, and heating and cooling rates above 10 K/s. These cavitations can create extreme physical and chemical conditions in otherwise cold liquids.\n\nWith liquids containing solids, similar phenomena may occur with exposure to ultrasound. Once cavitation occurs near an extended solid surface, cavity collapse is nonspherical and drives high-speed jets of liquid to the surface. These jets and associated shock waves can damage the now highly heated surface. Liquid-powder suspensions produce high velocity interparticle collisions. These collisions can change the surface morphology, composition, and reactivity.\n\nThree classes of sonochemical reactions exist: homogeneous sonochemistry of liquids, heterogeneous sonochemistry of liquid-liquid or solid–liquid systems, and, overlapping with the aforementioned, sonocatalysis. Sonoluminescence is a consequence of the same cavitation phenomena that is responsible for homogeneous sonochemistry. The chemical enhancement of reactions by ultrasound has been explored and has beneficial applications in mixed phase synthesis, materials chemistry, and biomedical uses. Because cavitation can only occur in liquids, chemical reactions are not seen in the ultrasonic irradiation of solids or solid–gas systems.\n\nFor example, in chemical kinetics, it has been observed that ultrasound can greatly enhance chemical reactivity in a number of systems by as much as a million-fold; effectively acting to activate heterogenous catalysts. In addition, in reactions at liquid-solid interfaces, ultrasound breaks up the solid pieces and exposes active clean surfaces through microjet pitting from cavitation near the surfaces and from fragmentation of solids by cavitation collapse nearby. This gives the solid reactant a larger surface area of active surfaces for the reaction to proceed over, increasing the observed rate of reaction. , \n\nWhile the application of ultrasound often generates mixtures of products, a paper published in 2007 in the journal \"Nature\" described the use of ultrasound to selectively affect a certain cyclobutane ring-opening reaction. Atul Kumar has reported multicomponent reaction Hantzsch ester synthesis in Aqueous Micelles using ultrasound.\n\nSome water pollutants, especially chlorinated organic compounds, can be destroyed sonochemically.\n\nSonochemistry can be performed by using a bath (usually used for ultrasonic cleaning) or with a high power probe, called an ultrasonic horn.\n\n\n"}
{"id": "27160752", "url": "https://en.wikipedia.org/wiki?curid=27160752", "title": "Southeast Australia temperate savanna", "text": "Southeast Australia temperate savanna\n\nThe Southeast Australia temperate savanna ecoregion is a large area of grassland dotted with eucalyptus trees running north-south across central New South Wales, Australia.\n\nIt is a dry area of low hills and valleys of which the southern section is the wheat-growing plain known as the Riverina and the northern section is low hills and plains mostly used for grazing sheep running north to the plains of the Darling River basin and the New South Wales–Queensland border. Rivers of the savanna include the Murray River and the Murrumbidgee in the south and the Darling River in the north. Rainfall is low and irregular, from 300–500 mm per year becoming less the further westward and inland you go.\n\nThe dry climate sustains hardy shrubs and grasses scattered with small patches of the bimble box and coolibah eucalyptus trees that once covered most of this part of Australia. The Riverina area nearer the coast contains red river gum and black box.\n\nThe effect of massive numbers of sheep on the grassland was dramatic and was noted by settlers in the grassland regions. The original soil of the grasslands was soft and absorbed rain readily, but heavy continuous stock grazing drove a degradation sequence that shifted the botanical composition of native grasslands from an ecosystem regulated by large, perennial tussock grasses such as Themeda triandra (Kangaroo Grass) to one containing abundant disturbance tolerant native grasses such as Rytidosperma spp.\n\nThese grasslands are the western limit for much of the wildlife that lives here as further west is desert. Wildlife of the savanna includes mammals such as the mouse-like kultarr marsupial (\"Antechinomys laniger\"), tiger quoll (\"Dasyurus maculatus\"), and brush-tailed rock-wallaby (\"Petrogale penicillata\"). The western barred bandicoot (\"Perameles bougainville fasciata\") and bridled nail-tail wallaby that once lived here are now presumed extinct in New South Wales. Birds include the endangered bush stone-curlew (\"Burhinus grallarius\"), superb parrot (\"Polytelis swainsonii\"), red goshawk (\"Erythrotriorchis radiatus\"), malleefowl (\"Leipoa ocellata\") and plains-wanderer (\"Pedionomus torquatus\"), and reptiles include an endangered skink \"Anomalopus mackayi\". The Riverina grasslands are home to birds such as the freckled duck, and wintering populations of swift parrot (\"Lathamus discolor\").\n\nActive preservation of habitats is required because much of the savanna has been converted to pasture or wheatland. This is particularly so in the Riverina where most has been cleared for wheat planting, a process that is ongoing, while the grasslands are vulnerable to overgrazing, and rivers including the Murray and Murrumbidgee are depleted by being water sources for large irrigation projects. As land is cleared it becomes habitat for invasive species such as noisy miner bird (\"Manorina melanophrys\") and Australian raven (\"Corvus coronoides\"). The main protected area is the steep volcanic outcrops of Warrumbungle National Park. There are small areas of parkland elsewhere and plans to create more, but there are no large areas of original savanna under protection.\n"}
{"id": "19936884", "url": "https://en.wikipedia.org/wiki?curid=19936884", "title": "Speed record", "text": "Speed record\n\nA speed record is a world record for speed by a person, animal, or vehicle. The function of speed record is to record the speed of moving animate objects such as humans, animals or vehicles.\n\nOverall speed record is the record for the highest average speed regardless of any criteria, categories or classes that all the more specific records belong to, provided that the route was completed. It helps to compare various performances that differ by the type of the craft, vessel or vehicle, the departure and the arrival points (provided that the distances are comparable), number, age and gender of the crew members, departure date, etc. The distance used for calculating the overall speed record is usually the distance in a straight line. In the case of man-powered races, overall speed record doesn't always reflect the best performance. It is highly dependent on technological advantages generating the speed of the craft, vessel or vehicle.\n\n\n\n\n\n"}
{"id": "782675", "url": "https://en.wikipedia.org/wiki?curid=782675", "title": "Stephen Moss", "text": "Stephen Moss\n\nStephen Moss is a British natural historian, birder, author and television producer.\n\nHe is best known for producing wildlife series, many of them presented by Bill Oddie, including:\n\nFor some of these, he also authored accompanying books.\n\nIn 2009, he was one of the first recipients of the British Trust for Ornithology's Dilys Breese Medal, at a ceremony at the House of Lords.\n\nHe is married, with five children and lives in Somerset, having moved there from West London.\n\n\n\n"}
{"id": "42690935", "url": "https://en.wikipedia.org/wiki?curid=42690935", "title": "Toxic hotspot", "text": "Toxic hotspot\n\nToxic hotspots are locations where emissions from specific sources such as water or air pollution may expose local populations to elevated health risks, such as cancer. These emissions contribute to cumulative health risks of emissions from other sources nearby. Urban, highly populated areas around pollutant emitters such as old factories and waste storage sites are often toxic hotspots.\n\nThe 1984 Bhopal disaster in India, the world's worst chemical disaster, is a prime example of a significant toxic hotspot. The toxic gas leaked from the understaffed Union Carbide plant killed up to 20,000 people and left 120,000 others chronically ill. Bhopal continues to face pollution problems from the abandoned factory today.\n\nAir pollution hotspots are areas where air pollution emissions expose individuals to increased negative health effects. Hotspots denote areas in which a population's exposure to pollution and estimated health risks are high. Air pollution hotspots are particularly common in highly populated, urban areas, where there may a combination of stationary sources (e.g. industrial facilities) and mobile sources (e.g. cars and trucks) of pollution. Emissions from these sources can cause respiratory disease, childhood asthma, cancer, and other health problems. A fine particulate matter such as diesel soot, which contributes to more than 3.2 million premature deaths around the world each year, is a significant problem. It is very small and can lodge itself within the lungs and enter the bloodstream. Diesel soot is concentrated in densely populated areas, and one in six people in the U.S. live near a diesel pollution hot spot.\n\nWhile air pollution hotspots affect a variety of populations, some groups are more likely to be located in hotspots. Previous studies have shown disparities in exposure to pollution by race and/or income (cite one of the early readings from our syllabus, e.g. Mohai & Pellow, or Saha). Hazardous land uses (toxic storage and disposal facilities, manufacturing facilities, major roadways) tend to be located where property values and income levels are low. Low socioeconomic status can be a proxy for other kinds of social vulnerability, including race, a lack of ability to influence regulatory permitting and a lack of ability to move to neighborhoods with less environmental pollution. These communities bear a disproportionate burden of environmental pollution and are more likely to face health risks such as cancer or asthma.\n\nStudies show that patterns in race and income disparities not only indicate a higher exposure to pollution but also higher risk of adverse health outcomes. Communities characterized by low socioeconomic status and racial minorities can be more vulnerable to cumulative adverse health impacts resulting from elevated exposure to pollutants than more privileged communities. Blacks and Latinos generally face more pollution than whites and Asians, and low-income communities bear a higher burden of risk than affluent ones. Racial discrepancies are particularly distinct in suburban areas of the South and metropolitan areas of the West. Residents in public housing, who are generally low-income with poor access to health care and cannot move to healthier neighborhoods, are highly affected by nearby refineries and chemical plants.\n\nCommunity groups and academic researchers have argued the unequal distribution of pollution on the poor and communities of color is an “environmental justice”.\n\nPolicy makers and researchers concerned with improving environmental justice for communities situated next to major sources of air pollution have developed a number of regulatory tools to identify air pollution hotspots. The EPA, for example, utilizes their Risk-Screening Environmental Indictors (RSEI) model to identify hotspots from a score of 3 to 15, with higher scores indicating closer proximity to hazards. Individual states have also taken steps to improve identification and surveillance. California's AB 2588 Air Toxics “Hot Spots” Program, enacted in 1987, seeks to collect emission data, determine health risks, and notify local residents of major risks. By identifying hotspots regulators hope these tools will help them reduce pollution and inform nearby populations through the health risk assessments of individual pollutants and facilities that are summed in each zone to develop a total lifetime cancer risk.\nAir pollution hot spots are also at issue in pollution-trading programs, such as cap-and-trade systems designed to control pollution. These programs can potentially exacerbate effects from air pollution hotspots if the differences in chemical hazards are ignored. These programs also cause pollution to be mitigated towards where credit-buying firms are located. Factories can purchase emissions reduction credits from other firms, which leads to concentrated areas of pollution since facilities that sell their credits are “exporting” their pollution to firms more likely to buy credits. However, some studies have noted that these claims have not materialized. Evan Ringquist, a professor at Indiana University of Public and Environmental Affairs, states that there is little empirical evidence to suggest the emergence of hotspots.\n\nLocated in the East San Francisco Bay, the neighborhood of West Oakland is home to mainly low-income African American and Latino residents who are exposed to a disproportionate amount of airborne toxins as compared to the rest of the surrounding Alameda County. West Oakland's close proximity to highways and the Port of Oakland leave residents highly exposed to pollutants caused by moving and stationary sources of diesel pollution, thus leaving them at higher risk for health complications such as asthma and even shorter life expectancy than surrounding neighborhoods averages.\n\nHigh emissions of toxic chemicals and airborne particulate matter in West Oakland that cause health issues are due to diesel fuels used for transportation in the Port of Oakland and surrounding highways. Traffic and transportation-related air pollutants include carbon monoxide, nitrogen dioxide, black carbon, and diesel particulate matter. Residents are more exposed to harmful pollutants compared to other areas of the Bay Area and Oakland and therefore more at risk for harmful health effects. Compared to the State of California, West Oakland produces 90 times more diesel emission particulates per square mile per day. These pollutants have detrimental health effects such as asthma and reduced life expectancy while putting children at higher susceptibility for health complications.\n\nInequitable economic, residential, and environmental conditions in this low-income community of color leave residents of West Oakland with poor and inequitable health outcomes. African-American and Latino children of 10–18 years in West Oakland are more susceptible to onset lung defects such as asthma. According to Alameda County Vital Statistics, an African American child born in West Oakland is expected to live 14 fewer years than a white child born in the more wealthy Oakland Hills. Children 5 and under in west Oakland visit the emergency room for asthma three times more often than children in the county as a whole.\n\nThere are multiple efforts and strategies to spur legislation for equitable environmental conditions in low-income communities. There are many environmental justice groups and organizations in the Bay Area that encourage community participation in pursuing environmental justice. For example, data is collected by a Community-based participatory research (CBPR) and collaborated with West Oakland Environmental Indicators Project (WOEIP) in order to find effective and accurate findings to prove injustice and eventually spur reform in environmental policy. These research efforts can be used to document and communicate trends in air quality in West Oakland to policymakers. Effectiveness of efforts by these groups are multiplied by and increasing availability of environmental poverty lawyers who empower legislation in the legal system.\n\nRichmond, located in the San Francisco Bay Area, is an evolving, multi-cultural community that has transformed itself from an over-polluted industrial town to a pioneer in an environmental justice movement. The city has been host to numerous oil refineries, including the Chevron Corporation refinery, which opened in 1901 under the ownership of Pacific Coast Oil. The Chevron Refinery is a leading source of air quality violations in the state of California. Richmond residents are also exposed to pollution from the Santa Fe train line and the presence of heavy traffic and diesel trucks along the Richmond Parkway. However, residents are most concerned with air pollution health impacts from the Chevron Refinery. In 1999, Richmond measure significantly higher on Air Quality Indices (AQI) (an indicator of how polluted is air is) compared to national level. Air pollution emission from the Chevron refinery includes benzene, ethylbenzene, toluene, xylene, nitrous dioxide, and sulfur dioxide, which are known to cause elevated cancer risks and respiratory illness. Rates of child and adult asthma are especially elevated among Richmond residents.\n\nRichmond residents have struggled to improve local air quality. The city has a significant non-white, low-income population. According to 2010 U.S. Census, of Richmond's 103,701 person populations, “one in six residents lives below the federal poverty level, and more than eight in 10 are people of color. In North Richmond, next to one of the nation’s largest refineries, 97 percent of residents are non-white and nearly one in four live in poverty”. Low-income communities have differential access to political power, and their collective political voice is often less able to contest decisions impacting industrial operations. The combination of poverty, poor access to clean air, and poor political power can result in inequality in which communities of color bear a disproportionate burden of pollution and, therefore, suffer from greater environmental health risks.\n\nBecause Richmond is an air pollution hotspot, Richmond residents have applied different strategies since the 1980s to try to improve local air quality. The first EJ movement in the area started in the late 1980s, when the activist tried to stop construction of a garbage incinerator near North Richmond. Sixteen years later, local citizen utilizes “Bucket Brigades” to document a handful of criteria air pollutants such as sulfur dioxide [SO2], carbon monoxide [CO], nitrous dioxide [NO2], and ozone [O3].This study involves citizens to actively collecting the samples of emissions from Chevron's refineries, especially during accidents, fires, leaks, and explosions. The “sniffers” alert the “samplers” to collect the air samples when they notice a problem. The “samplers” then contact the Coordinator to check the bucket and perform the paperwork before submitting the samples to the Laboratory, in which the results will be reported to CBE, an environmental justice organization. The “Bucket Brigades” did not only raise the awareness local citizens to fight against the air pollution in their area but also their participation.\n\nAs the number of activists and participants grew in numbers, their position in the battle against environmental injustice was further fortified with the election Green-party mayor of Richmond, Gayle McLaughlin, as well as three new council members sympathetic to their cause in 2008. In July 2008, despite the council failing to halt the Chevron's plan to build more refineries in the area due to rising gasoline prices during that time, the council succeeded to acquire $61 million from the oil company for community programs.\n\nDue to great forces from the local communities and fellow EJ activists in Richmond area, Chevron has been making progress to embrace cleaner environment. In 2005, local activists managed to convince Bay Area Air Quality Management District to tighten the air pollution regulations by increasing the frequency of fines of facility incidents. Since then, Chevron has been flaring 10 times less than before. On top of that, Chevron has invested $150 million for building gas turbine in order to reduce air emission, increase energy efficiency, as well as provide most electrical and steam power Chevron requires to operate.\n\nBonnoris noted, “The environmental justice movement posits that the distribution of environmental harms and benefits should be fairly apportioned among all communities”. As Bonnoris argued, the burden of air pollution is disproportionally distributed among communities based on their racial, social or economic status. Disproportion distribution of air pollution among communities can be a violation of the Equal Protection Clause of the Constitution because it violates equal protection of residents’ public health.\n\nLos Angeles is known for the nation's worst air quality and its “sharp inequalities in environmental exposures”. Wilmington, Los Angeles is a neighborhood located on the southern part of Los Angeles, California. 54,512 people live in Wilmington, the median household income is $40,627, about 86 percentage of them are Latino and only 5.1% of Wilmington residents 25 or older have a four-year degree.\n\nWilmington, most of its residents are ethnic minorities, is possible to bear more environmental burden than other communities in Los Angeles because it is located next to several sources of air pollution. For example, Wilmington has \"the highest concentration of refineries in the State\". Emissions from refineries in Wilmington include carbon dioxide, sulfur dioxide and benzene. Wilmington has higher concentration of diesel particulate matter due to emissions from diesel trucks from the ports of Los Angeles and Long Beach. The risks associated with diesel are often underestimated since existing epidemiological studies cannot isolate exposure to diesel PM. However, exposure to diesel particulate matter can cause “irritation to the eyes, nose, throat and lungs”, asthma, “exhaust immunological effects”, and cancer.\n\nSeveral NGOs have worked to improve the accuracy of Wilmington air quality data and air quality in order to protect approximately 1400 children who live or visit schools or childcare facilities at Wilmington. The environmental group “Coalition For a Safe Environment” installed an air pollution monitoring devices on the residential buildings in Wilmington in order to prove that emissions from local oil refineries and diesel trucks to the ports pollute the air in Wilmington, disproportionately affecting Wilmington residents to suffer from health problems including lung diseases and respiratory diseases.\n\nThe town of Hinkley, California, located in the Mojave Desert, had its groundwater contaminated with hexavalent chromium starting in 1952, resulting in a legal case against Pacific Gas & Electric (PG&E) and a multimillion-dollar settlement in 1996. The legal case was dramatized in the film \"Erin Brockovich\", released in 2000.\n\nPG&E operates a compressor station in Hinkley for natural gas transmission pipelines. The natural gas has to be re-compressed approximately every , and the station uses large cooling towers to cool the gas after it has been compressed.\nBetween 1952 and 1966, the water used in these cooling towers contained hexavalent chromium – now recognized as a carcinogen – to prevent rust in the machinery. The water was stored between uses in unlined ponds, which allowed it to percolate into the groundwater. This severely contaminated the groundwater, affecting soil and contaminating water wells near the compressor station, with a plume approximately long and nearly wide.\n\nThe Pacific Proving Grounds was the name used to describe a number of sites in the Marshall Islands and a few other sites in the Pacific Ocean, used by the United States to conduct nuclear testing at various times between 1946 and 1962. In July 1947, after the first atomic weapons testing at Bikini Atoll, the United States entered into an agreement with the United Nations to govern the Trust Territory of the Pacific Islands as a strategic trusteeship territory. The Trust Territory is composed of 2,000 islands spread over of the North Pacific Ocean. On July 23, 1947, the United States Atomic Energy Commission announced the establishment of the Pacific Proving Grounds.\n\n105 atmospheric (i.e., not underground) nuclear tests were conducted there, many of which were of extremely high yield. While the Marshall Islands testing composed 14% of all U.S. tests, it composed nearly 80% of the total yields of those detonated by the U.S., with an estimated total yield of around 210 megatons, with the largest being the 15 Mt Castle Bravo shot of 1954 which spread considerable nuclear fallout on many of the islands, including several which were inhabited, and some that had not been evacuated.\n\nMany of the islands which were part of the Pacific Proving Grounds continue to be contaminated by nuclear fallout, and many of those who were living on the islands at the time of testing has suffered from an increased incidence of various health problems. Through the Radiation Exposure Compensation Act of 1990, at least $759 million has been paid to Marshall Islanders as compensation for their exposure to U.S. nuclear testing. Following the Castle Bravo accident, $15.3 million was paid to Japan.\n\nThe Nevada Test Site (NTS), is a United States Department of Energy reservation located in southeastern Nye County, Nevada, about 65 miles (105 km) northwest of the city of Las Vegas. Formerly known as the Nevada Proving Grounds,<ref name=\"DOE/NV-1024\"></ref> the site was established on 11 January 1951 for the testing of nuclear devices, covering approximately of desert and mountainous terrain. Nuclear testing at the Nevada Test Site began with a bomb dropped on Frenchman Flat on 27 January 1951. Many of the iconic images of the nuclear era come from the NTS.\n\nDuring the 1950s, the mushroom clouds from atmospheric tests could be seen for almost . The city of Las Vegas experienced noticeable seismic effects, and the distant mushroom clouds, which could be seen from the downtown hotels, became tourist attractions. St. George, Utah, received the brunt of the fallout of above-ground nuclear testing in the Yucca Flats/Nevada Test Site. Winds routinely carried the fallout of these tests directly through St. George and southern Utah. Marked increases in cancers, such as leukemia, lymphoma, thyroid cancer, breast cancer, melanoma, bone cancer, brain tumors, and gastrointestinal tract cancers, were reported from the mid-1950s through 1980.\n\nFrom 1986 through 1994, two years after the United States put a hold on full-scale nuclear weapons testing, 536 anti-nuclear protests were held at the Nevada Test Site involving 37,488 participants and 15,740 arrests, according to government records. Those arrested included the astronomer Carl Sagan and the actors Kris Kristofferson, Martin Sheen, and Robert Blake.\n\nThe Nevada Test Site contains 28 areas, 1,100 buildings, 400 miles (640  km) of paved roads, 300 miles of unpaved roads, ten heliports, and two airstrips. The most recent test was a sub-critical test of the properties of plutonium, conducted underground on December 7, 2012.\n\nThe Semipalatinsk Test Site, also known as \"The Polygon\", was the primary testing venue for the Soviet Union's nuclear weapons. It is located on the steppe in northeast Kazakhstan (then the Kazakh SSR), south of the valley of the Irtysh River. The scientific buildings for the test site were located around 150 km west of the town of Semipalatinsk (later renamed Semey), near the border of East Kazakhstan Province and Pavlodar Province with most of the nuclear tests taking place at various sites further to the west and south, some as far as into Karagandy Province.\n\nThe Soviet Union conducted 456 nuclear tests at Semipalatinsk from 1949 until 1989 with little regard for their effect on the local people or environment. The full impact of radiation exposure was hidden for many years by Soviet authorities and has only come to light since the test site closed in 1991.\n\nFrom 1996 to 2012, a secret joint operation of Kazakh, Russian, and American nuclear scientists and engineers secured the waste plutonium in the tunnels of the mountains.\n\n"}
{"id": "10126260", "url": "https://en.wikipedia.org/wiki?curid=10126260", "title": "Triplochiton scleroxylon", "text": "Triplochiton scleroxylon\n\nTriplochiton scleroxylon is a tree of the genus \"Triplochiton\" of the family \"Malvaceae\". The timber is known by the common names African whitewood, abachi, obeche in Nigeria, wawa in Ghana, ayous in Cameroon and sambawawa in Ivory Coast. \n\nThe species is distributed around the tropical areas of Western Africa. Trees grow to 20-60m tall with a 1-1.5m wide trunk.\n\nThe timber yielded is typically pale yellow and is moderately soft and light for a hardwood.\n\nThe timber is used in the manufacture of veneer, furniture, picture frames and mouldings. It is also used by guitar makers. \"Gibson\" and \"Fender Japan\" have used the wood to produce limited edition guitars.\n\nThe tree is a host of the African silk moth, \"Anaphe venata\", whose caterpillars feed on the leaves and spin cocoons which are then used to make silk.\n\nThe wood is exploited in its natural habitat, a harvest that is unsustainable in some areas. However, it remains classed as 'least concern' on the IUCN Red List. \n"}
{"id": "516757", "url": "https://en.wikipedia.org/wiki?curid=516757", "title": "Video camera tube", "text": "Video camera tube\n\nVideo camera tubes were devices based on the cathode ray tube that were used to capture television images prior to the introduction of charge-coupled devices (CCDs) in the 1980s. Several different types of tubes were in use from the early 1930s to the 1980s.\n\nIn these tubes, the cathode ray was scanned across an image of the scene to be broadcast. The resultant current was dependent on the brightness of the image on the target. The size of the striking ray was tiny compared to the size of the target, allowing 483 horizontal scan lines per image in the NTSC format, or 576 lines in PAL.\n\nAny vacuum tube which operates using a focused beam of electrons, \"cathode rays\", is known as a cathode ray tube (CRT). These are usually seen as display devices as used in television receivers and computer displays. The camera pickup tubes described in this article are also CRTs, but they display no image.\n\nIn June 1908, the scientific journal \"Nature\" published a letter in which Alan Archibald Campbell-Swinton, fellow of the Royal Society (UK), discussed how a fully electronic television system could be realized by using cathode ray tubes (or \"Braun\" tubes, after its inventor, Karl Braun) as both imaging and display devices. He noted that the \"real difficulties lie in devising an efficient transmitter\", and that it was possible that \"no photoelectric phenomenon at present known will provide what is required\". A cathode ray tube was successfully demonstrated as a displaying device by the German Professor Max Dieckmann in 1906, his experimental results were published by the journal \"Scientific American\" in 1909. Campbell-Swinton later expanded on his vision in a presidential address given to the Röntgen Society in November 1911. The photoelectric screen in the proposed transmitting device was a mosaic of isolated rubidium cubes. His concept for a fully electronic television system was later popularized by Hugo Gernsback as the \"Campbell-Swinton Electronic Scanning System\" in the August 1915 issue of the popular magazine \"Electrical Experimenter\".\n\nIn a letter to \"Nature\" published in October 1926, Campbell-Swinton also announced the results of some \"not very successful experiments\" he had conducted with G. M. Minchin and J. C. M. Stanton. They had attempted to generate an electrical signal by projecting an image onto a selenium-coated metal plate that was simultaneously scanned by a cathode ray beam. These experiments were conducted before March 1914, when Minchin died, but they were later repeated by two different teams in 1937, by H. Miller and J. W. Strange from EMI, and by H. Iams and A. Rose from RCA. Both teams succeeded in transmitting \"very faint\" images with the original Campbell-Swinton's selenium-coated plate, but much better images were obtained when the metal plate was covered with zinc sulphide or selenide, or with aluminum or zirconium oxide treated with caesium. These experiments are the base of the future vidicon. A description of a CRT imaging device also appeared in a patent application filed by Edvard-Gustav Schoultz in France in August 1921, and published in 1922, although a working device was not demonstrated until some years later.\n\nAn image dissector is a camera tube that creates an \"electron image\" of a scene from photocathode emissions (electrons) which pass through a scanning aperture to an anode, which serves as an electron detector. Among the first to design such a device were German inventors Max Dieckmann and Rudolf Hell, who had titled their 1925 patent application \"Lichtelektrische Bildzerlegerröhre für Fernseher\" (\"Photoelectric Image Dissector Tube for Television\"). The term may apply specifically to a dissector tube employing magnetic fields to keep the electron image in focus, an element lacking in Dieckmann and Hell's design, and in the early dissector tubes built by American inventor Philo Farnsworth.\n\nDieckmann and Hell submitted their application to the German patent office in April 1925, and a patent was issued in October 1927. Their experiments on the image dissector were announced in the volume 8 (September 1927) of the popular magazine \"Discovery\" and in the May 1928 issue of the magazine \"Popular Radio\". However, they never transmitted a clear and well focused image with such a tube.\n\nIn January 1927, American inventor and television pioneer Philo T. Farnsworth applied for a patent for his \"Television System\" that included a device for \"the conversion and dissecting of light\".\nIts first moving image was successfully transmitted on September 7 of 1927,\nand a patent was issued in 1930. Farnsworth quickly made improvements to the device, among them introducing an electron multiplier made of nickel and deploying a \"longitudinal magnetic field\" in order to sharply focus the electron image.\nThe improved device was demonstrated to the press in early September 1928.\nThe introduction of a multipactor in October 1933 and a multi-dynode \"electron multiplier\" in 1937 made Farnsworth's image dissector the first practical version of a fully electronic imaging device for television. Unfortunately, it had very poor light sensitivity, and was therefore primarily useful only where illumination was exceptionally high (typically over 685 cd/m²). However, it was ideal for industrial applications, such as monitoring the bright interior of an industrial furnace. Due to their poor light sensitivity, image dissectors were rarely used in television broadcasting, except to scan film and other transparencies.\n\nIn April 1933, Farnsworth submitted a patent application also entitled \"Image Dissector\", but which actually detailed a CRT-type camera tube. This is among the first patents to propose the use of a \"low-velocity\" scanning beam and RCA had to buy it in order to sell image orthicon tubes to the general public. However, Farnsworth never transmitted a clear and well focused image with such a tube.\n\nThe optical system of the image dissector focuses an image onto a photocathode mounted inside a high vacuum. As light strikes the photocathode, electrons are emitted in proportion to the intensity of the light (see photoelectric effect). The entire electron image is deflected and a scanning aperture permits only those electrons emanating from a very small area of the photocathode to be captured by the detector at any given time. The output from the detector is an electric current whose magnitude is a measure of the brightness of the corresponding area of the image. The electron image is periodically deflected horizontally and vertically (\"raster scanning\") such that the entire image is read by the detector many times per second, producing an electrical signal that can be conveyed to a display device, such as a CRT monitor, to reproduce the image.\n\nThe image dissector has no \"charge storage\" characteristic; the vast majority of electrons emitted by the photocathode are excluded by the scanning aperture, and thus wasted rather than being stored on a photo-sensitive target, as in the iconoscope or image orthicon (see below), which largely accounts for its low light sensitivity.\n\nAn iconoscope is a camera tube that projects an image on a special \"charge storage\" plate containing a mosaic of electrically isolated photosensitive granules separated from a common plate by a thin layer of isolating material, somewhat analogous to the human eye's retina and its arrangement of photoreceptors. Each photosensitive granule constitutes a tiny capacitor that accumulates and stores electrical charge in response to the light striking it. An electron beam periodically sweeps across the plate, effectively scanning the stored image and discharging each capacitor in turn such that the electrical output from each capacitor is proportional to the average intensity of the light striking it between each discharge event.\n\nThe problem of low sensitivity to light resulting in low electrical output from transmitting or \"camera\" tubes would be solved with the introduction of charge-storage technology by the Hungarian engineer Kálmán Tihanyi in the beginning of 1925. His solution was a camera tube that accumulated and stored electrical charges (\"photoelectrons\") within the tube throughout each scanning cycle. The device was first described in a patent application he filed in Hungary in March 1926 for a television system he dubbed \"Radioskop\". After further refinements included in a 1928 patent application, Tihanyi's patent was declared void in Great Britain in 1930, and so he applied for patents in the United States.\n\nIn 1923, while employed by the Westinghouse Electric Corporation in Pittsburgh, Pennsylvania, Russian-born American engineer Vladimir Zworykin presented a project for a totally electronic television system to the company's general manager. In July 1925, Zworykin submitted a patent application titled \"Television System\" that included a charge storage plate constructed of a thin layer of isolating material (aluminum oxide) sandwiched between a screen (300 mesh) and a colloidal deposit of photoelectric material (potassium hydride) consisting of isolated globules. The following description can be read between lines 1 and 9 in page 2: \"The photoelectric material, such as potassium hydride, is evaporated on the aluminum oxide, or other insulating medium, and treated so as to form a colloidal deposit of potassium hydride consisting of minute globules. Each globule is very active photoelectrically and constitutes, to all intents and purposes, a minute individual photoelectric cell\". Its first image was transmitted in late summer of 1925, and a patent was issued in 1928. However the quality of the transmitted image failed to impress H.P. Davis, the general manager of Westinghouse, and Zworykin was asked \"to work on something useful\". A patent for a television system was also filed by Zworykin in 1923, but this filing is not a definitive reference because extensive revisions were done before a patent was issued fifteen years later and the file itself was divided into two patents in 1931.\n\nThe first practical iconoscope was constructed in 1931 by Sanford Essig, when he accidentally left a silvered mica sheet in the oven too long. Upon examination with a microscope, he noticed that the silver layer had broken up into a myriad of tiny isolated silver globules. He also noticed that, \"the tiny dimension of the silver droplets would enhance the image resolution of the iconoscope by a quantum leap.\" As head of television development at Radio Corporation of America (RCA), Zworykin submitted a patent application in November 1931, and it was issued in 1935. Nevertheless, Zworykin's team was not the only engineering group working on devices that used a charge stage plate. In 1932, the EMI engineers Tedham and McGee under the supervision of Isaac Shoenberg applied for a patent for a new device they dubbed the \"Emitron\". A 405-line broadcasting service employing the Emitron began at studios in Alexandra Palace in 1936, and patents were issued in the United Kingdom in 1934 and in the USA in 1937.\n\nThe iconoscope was presented to the general public at a press conference in June 1933, and two detailed technical papers were published in September and October of the same year. Unlike the Farnsworth image dissector, the Zworykin iconoscope was much more sensitive, useful with an illumination on the target between 4ft-c (43lx) and 20ft-c (215lx). It was also easier to manufacture and produced a very clear image. The iconoscope was the primary camera tube used by RCA broadcasting from 1936 until 1946, when it was replaced by the image orthicon tube.\n\nThe original iconoscope was noisy, had a high ratio of interference to signal, and ultimately gave disappointing results, especially when compared to the high definition mechanical scanning systems then becoming available. The EMI team under the supervision of Isaac Shoenberg analyzed how the Emitron (or iconoscope) produces an electronic signal and concluded that its real efficiency was only about 5% of the theoretical maximum. This is because secondary electrons released from the mosaic of the charge storage plate when the scanning beam sweeps across it may be attracted back to the positively charged mosaic, thus neutralizing many of the stored charges. Lubszynski, Rodda, and McGee realized that the best solution was to separate the photo-emission function from the charge storage one, and so communicated their results to Zworykin.\n\nThe new video camera tube developed by Lubszynski, Rodda and McGee in 1934 was dubbed \"the super-Emitron\". This tube is a combination of the image dissector and the Emitron. It has an efficient photocathode that transforms the scene light into an electron image; the latter is then accelerated towards a target specially prepared for the emission of secondary electrons. Each individual electron from the electron image produces several secondary electrons after reaching the target, so that an amplification effect is produced. The target is constructed of a mosaic of electrically isolated metallic granules separated from a common plate by a thin layer of isolating material, so that the positive charge resulting from the secondary emission is stored in the granules. Finally, an electron beam periodically sweeps across the target, effectively scanning the stored image, discharging each granule, and producing an electronic signal like in the iconoscope.\n\nThe super-Emitron was between ten and fifteen times more sensitive than the original Emitron and iconoscope tubes and, in some cases, this ratio was considerably greater. It was used for an outside broadcasting by the BBC, for the first time, on Armistice Day 1937, when the general public could watch in a television set how the King lay a wreath at the Cenotaph. This was the first time that anyone could broadcast a live street scene from cameras installed on the roof of neighbor buildings.\n\nOn the other hand, in 1934, Zworykin shared some patent rights with the German licensee company Telefunken. The \"image iconoscope\" (\"Superikonoskop\" in Germany) was produced as a results of the collaboration. This tube is essentially identical to the super-Emitron, but the target is constructed of a thin layer of isolating material placed on top of a conductive base, the mosaic of metallic granules is missing. The production and commercialization of the super-Emitron and image iconoscope in Europe were not affected by the patent war between Zworykin and Farnsworth, because Dieckmann and Hell had priority in Germany for the invention of the image dissector, having submitted a patent application for their \"Lichtelektrische Bildzerlegerröhre für Fernseher\" (\"Photoelectric Image Dissector Tube for Television\") in Germany in 1925, two years before Farnsworth did the same in the United States.\n\nThe image iconoscope (Superikonoskop) became the industrial standard for public broadcasting in Europe from 1936 until 1960, when it was replaced by the vidicon and plumbicon tubes. Indeed, it was the representative of the European tradition in electronic tubes competing against the American tradition represented by the image orthicon. The German company Heimann produced the Superikonoskop for the 1936 Berlin Olympic Games, later Heimann also produced and commercialized it from 1940 to 1955, finally the Dutch company Philips produced and commercialized the image iconoscope and multicon from 1952 to 1958.\n\nThe super-Emitron is a combination of the image dissector and the Emitron. The scene image is projected onto an efficient continuous-film semitransparent photocathode that transforms the scene light into a light-emitted electron image, the latter is then accelerated (and focused) via electromagnetic fields towards a target specially prepared for the emission of secondary electrons. Each individual electron from the electron image produces several secondary electrons after reaching the target, so that an amplification effect is produced, and the resulting positive charge is proportional to the integrated intensity of the scene light. The target is constructed of a mosaic of electrically isolated metallic granules separated from a common plate by a thin layer of isolating material, so that the positive charge resulting from the secondary emission is stored in the capacitor formed by the metallic granule and the common plate. Finally, an electron beam periodically sweeps across the target, effectively scanning the stored image and discharging each capacitor in turn such that the electrical output from each capacitor is proportional to the average intensity of the scene light between each discharge event (as in the iconoscope).\n\nThe image iconoscope is essentially identical to the super-Emitron, but the target is constructed of a thin layer of isolating material placed on top of a conductive base, the mosaic of metallic granules is missing. Therefore, secondary electrons are emitted from the surface of the isolating material when the electron image reaches the target, and the resulting positive charges are stored directly onto the surface of the isolated material.\n\nThe original iconoscope was very noisy due to the secondary electrons released from the photoelectric mosaic of the charge storage plate when the scanning beam swept it across. An obvious solution was to scan the mosaic with a low-velocity electron beam which produced less energy in the neighborhood of the plate such that no secondary electrons were emitted at all. That is, an image is projected onto the photoelectric mosaic of a charge storage plate, so that positive charges are produced and stored there due to photo-emission and capacitance, respectively. These stored charges are then \"gently\" discharged by a \"low-velocity electron scanning beam\", preventing the emission of secondary electrons. Not all the electrons in the scanning beam may be absorbed in the mosaic, because the stored positive charges are proportional to the integrated intensity of the scene light. The remaining electrons are then deflected back into the anode, captured by a special grid, or deflected back into an electron multiplier.\n\n\"Low-velocity scanning beam\" tubes have several advantages; there are low levels of spurious signals and high efficiency of conversion of light into signal, so that the signal output is maximum. However, there are serious problems as well, because the electron beam \"spreads\" and accelerates in a direction parallel to the target when it scans the image's borders and corners, so that it produces secondary electrons and one gets an image that is well focused in the center but blurry in the borders. Henroteau was among the first inventors to propose in 1929 the use of \"low-velocity electrons\" for stabilizing the potential of a charge storage plate, but Lubszynski and the EMI team were the first engineers in transmitting a clear and well focused image with such a tube. Another improvement is the use of a semitransparent charge storage plate. The scene image is then projected onto the back side of the plate, while the low-velocity electron beam scans the photoelectric mosaic at the front side. This configurations allows the use of a straight camera tube, because the scene to be transmitted, the charge storage plate, and the electron gun can be aligned one after the other.\n\nThe first fully functional low-velocity scanning beam tube, the CPS Emitron, was invented and demonstrated by the EMI team under the supervision of Isaac Shoenberg. In 1934, the EMI engineers Blumlein and McGee filed for patents for \"television transmitting systems\" where a charge storage plate was shielded by a pair of special grids, a negative (or slightly positive) grid lay very close to the plate, and a positive one was placed further away. The velocity and energy of the electrons in the scanning beam were reduced to zero by the decelerating electric field generated by this pair of grids, and so a low-velocity scanning beam tube was obtained. The EMI team kept working on these devices, and Lubszynski discovered in 1936 that a clear image could be produced if the trajectory of the low-velocity scanning beam was nearly perpendicular (orthogonal) to the charge storage plate in a neighborhood of it. The resulting device was dubbed the cathode potential stabilized Emitron, or CPS Emitron. The industrial production and commercialization of the CPS Emitron had to wait until the end of the second world war.\n\nOn the other side of the ocean, the RCA team led by Albert Rose began working in 1937 on a low-velocity scanning beam device they dubbed the orthicon. Iams and Rose solved the problem of guiding the beam and keeping it in focus by installing specially designed deflection plates and deflection coils near the charge storage plate to provide a\nuniform axial magnetic field. The orthicon was the tube used in RCA's television demonstration at the 1939 New York World's Fair, its performance was similar to the image iconoscope's one, but it was also unstable under sudden flashes of bright light, producing \"the appearance of a large drop of water evaporating slowly over part of the scene\".\n\nThe image orthicon, (sometimes abbreviated IO) was common in American broadcasting from 1946 until 1968. A combination of the image dissector and the orthicon technologies, it replaced the iconoscope in the United States, which required a great deal of light to work adequately.\n\nThe image orthicon tube was developed at RCA by Albert Rose, Paul K. Weimer, and Harold B. Law. It represented a considerable advance in the television field, and after further development work, RCA created original models between 1939 and 1940. The National Defense Research Committee entered into a contract with RCA where the NDRC paid for its further development. Upon RCA's development of the more sensitive image orthicon tube in 1943, RCA entered into a production contract with the U.S. Navy, the first tubes being delivered in January 1944. RCA began production of image orthicons for civilian use in the second quarter of 1946.\n\nWhile the iconoscope and the intermediate orthicon used capacitance between a multitude of small but discrete light sensitive collectors and an isolated signal plate for reading video information, the image orthicon employed direct charge readings from a continuous \"electronically charged\" collector. The resultant signal was immune to most extraneous signal \"crosstalk\" from other parts of the target, and could yield extremely detailed images. For instance, image orthicon cameras were still being used by NASA for capturing Apollo/Saturn rockets nearing orbit, although the television networks had phased the cameras out. Only they could provide sufficient detail.\n\nAn image orthicon camera can take television pictures by candlelight because of the more ordered light-sensitive area and the presence of an electron multiplier at the base of the tube, which operated as a high-efficiency amplifier. It also has a logarithmic light sensitivity curve similar to the human eye. However, it tends to flare in bright light, causing a dark halo to be seen around the object; this anomaly is referred to as \"blooming\" in the broadcast industry when image orthicon tubes were in operation. Image orthicons were used extensively in the early color television cameras, where the increased sensitivity of the tube was essential to overcome the very inefficient optical system of the camera.\n\nThe image orthocon tube was at one point colloquially referred to as an \"Immy\". Harry Lubcke, the then-President of the Academy of Television Arts & Sciences, decided to have their award named after this nickname. Since the statuette was female, it was feminized into \"Emmy\".\n\nAn image orthicon consists of three parts: a photocathode with an image store (\"target\"), a scanner that reads this image (an electron gun), and a multistage electron multiplier.\n\nIn the image store, light falls upon the photocathode which is a photosensitive plate at a very negative potential (approx. -600 V), and is converted into an electron image (a principle borrowed from the image dissector). This electron \"rain\" is then accelerated towards the target (a very thin glass plate acting as a semi-isolator) at ground potential (0 V), and passes through a very fine wire mesh (near 200 wires per cm), very near (a few hundredths of cm) and parallel to the target, acting as a screen grid at a slightly positive voltage (approx +2 V). Once the image electrons reach the target, they cause a \"splash\" of electrons by the effect of secondary emission. On average, each image electron ejects several \"splash\" electrons (thus adding amplification by secondary emission), and these excess electrons are soaked up by the positive mesh effectively removing electrons from the target and causing a positive charge on it in relation to the incident light in the photocathode. The result is an image painted in positive charge, with the brightest portions having the largest positive charge.\nA sharply focused beam of electrons (a cathode ray) is generated by the electron gun at ground potential and accelerated by the anode (the first dynode of the electron multiplier) around the gun at a high positive voltage (approx. +1500 V). Once it exits the electron gun, its inertia makes the beam move away from the dynode towards the back side of the target. At this point the electrons lose speed and get deflected by the horizontal and vertical deflection coils, effectively scanning the target. Thanks to the axial magnetic field of the focusing coil, this deflection is not in a straight line, thus when the electrons reach the target they do so perpendicularly avoiding a sideways component. The target is nearly at ground potential with a small positive charge, thus when the electrons reach the target at low speed they are absorbed without ejecting more electrons. This adds negative charge to the positive charge until the region being scanned reaches some threshold negative charge, at which point the scanning electrons are reflected by the negative potential rather than absorbed (in this process the target recovers the electrons needed for the next scan). These reflected electrons return down the cathode ray tube toward the first dynode of the electron multiplier surrounding the electron gun which is at high potential. The number of reflected electrons is a linear measure of the target's original positive charge, which, in turn, is a measure of brightness.\n\nThe mysterious dark \"orthicon halo\" around bright objects in an IO-captured image is based on the fact that the IO relies on the emission of photoelectrons, but very bright illumination can produce more of them locally than the device can successfully deal with. At a very bright point on a captured image, a great preponderance of electrons is ejected from the photosensitive plate. So many may be ejected that the corresponding point on the collection mesh can no longer \"soak them up\", and thus they fall back to nearby spots on the target instead, much as water splashes in a ring when a rock is thrown into it. Since the resultant \"splashed\" electrons do not contain sufficient energy to eject further electrons where they land, they will instead neutralize any positive charge that has been built-up in that region. Since darker images produce less positive charge on the target, the excess electrons deposited by the splash will be read as a \"dark\" region by the scanning electron beam.\n\nThis effect was actually \"cultivated\" by tube manufacturers to a certain extent, as a small, carefully controlled amount of the dark halo has the effect of \"crispening\" the visual image due to the contrast effect. (That is, giving the illusion of being more sharply focused than it actually is). The later Vidicon tube and its descendants (see below) do not exhibit this effect, and so could not be used for broadcast purposes until special \"detail correction\" circuitry could be developed.\n\nA vidicon tube is a video camera tube design in which the target material is a photoconductor. The Vidicon was developed in the 1950s at RCA by P. K. Weimer, S. V. Forgue and R. R. Goodrich as a simple alternative to the structurally and electrically complex Image Orthicon. While the initial photoconductor used was selenium, other targets–including silicon diode arrays–have been used.\nThe vidicon is a storage-type camera tube in which a charge-density pattern is formed by the imaged scene radiation on a photoconductive surface which is then scanned by a beam of low-velocity electrons. The fluctuating voltage coupled out to a video amplifier can be used to reproduce the scene being imaged. The electrical charge produced by an image will remain in the face plate until it is scanned or until the charge dissipates. By using a Pyroelectric material such as Triglycene Sulphate (TGS) as the target, a vidicon sensitive over a broad portion of the infrared spectrum. is possible. This technology was a precursor to modern microbolometer technology.\n\nPrior to the design and construction of the Galileo probe to Jupiter in the late 1970s to early 1980s, NASA used Vidicon cameras on nearly all the unmanned deep space probes equipped with the remote sensing ability. Vidicon tubes were also used aboard the first three Landsat earth imaging satellites launched in 1972, as part of each spacecraft's Return Beam Vidicon (RBV) imaging system. The Uvicon, a UV-variant Vidicon was also used by NASA for UV duties.\n\nVidicon tubes were popular in 1970s and 1980s after which they were rendered obsolete by CCD and CMOS sensors.\n\nPlumbicon is a registered trademark of Philips for its lead(II) oxide (PbO) target vidicons. Used frequently in broadcast camera applications, these tubes have low output, but a high signal-to-noise ratio. They have excellent resolution compared to Image Orthicons, but lack the artificially sharp edges of IO tubes, which cause some of the viewing audience to perceive them as softer. CBS Labs invented the first outboard edge enhancement circuits to sharpen the edges of Plumbicon generated images.\nCompared to Saticons, Plumbicons have much higher resistance to burn-in, and comet and trailing artifacts from bright lights in the shot. Saticons though, usually have slightly higher resolution. After 1980, and the introduction of the diode-gun Plumbicon tube, the resolution of both types was so high, compared to the maximum limits of the broadcasting standard, that the Saticon's resolution advantage became moot. While broadcast cameras migrated to solid-state charge-coupled devices, Plumbicon tubes remained a staple imaging device in the medical field.\n\nUntil 2016, Narragansett Imaging was the last company making Plumbicons, using factories Philips built in Rhode Island, USA. While still a part of Philips, the company purchased EEV's (English Electric Valve) lead oxide camera tube business, and gained a monopoly in lead-oxide tube production.\n\nSaticon is a registered trademark of Hitachi from 1973, also produced by Thomson and Sony. It was developed in a joint effort by Hitachi and NHK Science & Technology Research Laboratories (NHK is The Japan Broadcasting Corporation). Its surface consists of selenium with trace amounts of arsenic and tellurium added (SeAsTe) to make the signal more stable. SAT in the name is derived from (SeAsTe).\n\nOriginally developed by Toshiba in 1972 as chalnicon, Pasecon is a registered trademark of Heimann GmbH from 1977. Its surface consists of cadmium selenide trioxide (CdSeO). Due to its wide spectral response, it is labelled as \"panchromatic selenium vidicon\", hence the achronym 'pasecon'.\n\nNewvicon is a registered trademark of Matsushita from 1974. The Newvicon tubes were characterized by high light sensitivity. Its surface consists of a combination of zinc selenide (ZnSe) and zinc cadmium Telluride (ZnCdTe).\n\nTrinicon is a registered trademark of Sony. It uses a vertically striped RGB color filter over the faceplate of an otherwise standard vidicon imaging tube to segment the scan into corresponding red, green and blue segments. Only one tube was used in the camera, instead of a tube for each color, as was standard for color cameras used in television broadcasting. It is used mostly in low-end consumer cameras, though Sony also used it in some moderate cost professional cameras in the 1980s, such as the DXC-1800 and BVP-1 models.\n\nAlthough the idea of using color stripe filters over the target was not new, the Trinicon was the only tube to use the primary RGB colors. This necessitated an additional electrode buried in the target to detect where the scanning electron beam was relative to the stripe filter. Previous color stripe systems had used colors where the color circuitry was able to separate the colors purely from the relative amplitudes of the signals. As a result, the Trinicon featured a larger dynamic range of operation.\n\nAll the vidicon type tubes except the vidicon itself were able to use a light biasing technique to improve the sensitivity and contrast. The photosensitive target in these tubes suffered from the limitation that the light level had to rise to a particular level before any video output resulted. Light biasing was a method whereby the photosensitive target was illuminated from a light source just enough that no appreciable output was obtained, but such that a slight increase in light level from the scene was enough to provide discernible output. The light came from either an illuminator mounted around the target, or in more professional cameras from a light source on the base of the tube and guided to the target by light piping. The technique would not work with the baseline vidicon tube because it suffered from the limitation that as the target was fundamentally an insulator, the constant low light level built up a charge which would manifest itself as a form of 'fogging'. The other types had semiconducting targets which did not have this problem.\n\nEarly color cameras used the obvious technique of using separate red, green and blue image tubes in conjunction with a color separator, a technique still in use with 3CCD solid state cameras today. It was also possible to construct a color camera that used a single image tube. One technique has already been described (Trinicon above). A more common technique and a simpler one from the tube construction standpoint was to overlay the photosensitive target with a color striped filter having a fine pattern of vertical stripes of green, cyan and clear filters (i.e. Green; Green+Blue & Green+Blue+Red) repeating across the target. The advantage of this arrangement was that for virtually every color, the video level of the green component was always less than the cyan, and similarly the cyan was always less than the white. Thus the contributing images could be separated without any reference electrodes in the tube. If the three levels were the same, then that part of the scene was green. This method suffered from the disadvantage that the light levels under the three filters were almost certain to be different, with the green filter passing not more than one third of the available light.\n\nVariations on this scheme exist, the principal one being to use two filters with color stripes overlaid such that the colors form vertically oriented lozenge shapes overlaying the target. The method of extracting the color is similar however.\n\nDuring the 1930s and 1940s, field-sequential color systems were developed which used synchronized motor-driven color-filter disks at the camera's image tube and at the television receiver. Each disk consisted of red, blue, and green transparent color filters. In the camera, the disk was in the optical path, and in the receiver, it was in front of the CRT. Disk rotation was synchronized with vertical scanning so that each vertical scan in sequence was for a different primary color. This method allowed regular black-and-white image tubes and CRTs to generate and display color images. A field-sequential system developed by Peter Goldmark for CBS was demonstrated to the press on September 4, 1940, and was first shown to the general public on January 12, 1950. Guillermo González Camarena independently developed a field-sequential color disk system in Mexico in the early 1940s, for which he requested a patent in Mexico on August 19 of 1940 and in the USA in 1941. Gonzalez Camarena produced his color television system in his laboratory Gon-Cam for the Mexican market and exported it to the Columbia College of Chicago, who regarded it as the best system in the world.\n\nThe phenomenon known as \"magnetic focusing\" was discovered by A. A. Campbell-Swinton in 1896,\nhe found that a longitudinal magnetic field generated by an axial coil can focus an electron beam. This phenomenon was immediately corroborated by J. A. Fleming, and Hans Busch gave a complete mathematical interpretation in 1926.\n\nDiagrams in this article show that the focus coil surrounds the camera tube; it is much longer than the focus coils for earlier TV CRTs. Camera-tube focus coils, by themselves, have essentially parallel lines of force, very different from the localized semi-toroidal magnetic field geometry inside a TV receiver CRT focus coil. The latter is essentially a magnetic lens; it focuses the \"crossover\" (between the CRT's cathode and G1 electrode, where the electrons pinch together and diverge again) onto the screen.\n\nThe electron optics of camera tubes differ considerably. Electrons inside these long focus coils take helical paths as they travel along the length of the tube. The center (think local axis) of one of those helices is like a line of force of the magnetic field. While the electrons are traveling, the helices essentially don't matter. Assuming that they start from a point, the electrons will focus to a point again at a distance determined by the strength of the field. Focusing a tube with this kind of coil is simply a matter of trimming the coil's current. In effect, the electrons travel along the lines of force, although helically, in detail.\n\nThese focus coils are essentially as long as the tubes themselves, and surround the deflection yoke (coils). Deflection fields bend the lines of force (with negligible defocusing), and the electrons follow the lines of force.\n\nIn a conventional magnetically deflected CRT, such as in a TV receiver or computer monitor, basically the vertical deflection coils are equivalent to coils wound around an horizontal axis. That axis is perpendicular to the neck of the tube; lines of force are basically horizontal. (In detail, coils in a deflection yoke extend some distance beyond the neck of the tube, and lie close to the flare of the bulb; they have a truly distinctive appearance.)\n\nIn a magnetically focused camera tube (there are electrostatically focused vidicons), the vertical deflection coils are above and below the tube, instead of being on both sides of it. One might say that this sort of deflection starts to create S-bends in the lines of force, but doesn't become anywhere near to that extreme.\n\nThe size of video camera tubes is simply the overall outside diameter of the glass envelope. This differs from the size of the sensitive area of the target which is typically two thirds of the size of the overall diameter. Tube sizes are always expressed in inches for historical reasons. A one-inch camera tube has a sensitive area of approximately two thirds of an inch on the diagonal or about 16 mm.\n\nAlthough the video camera tube is now technologically obsolete, the size of solid state sensors is still expressed as the equivalent size of a camera tube. For this purpose a new term was coined and it is known as the optical format. The optical format is approximately the true diagonal of the sensor multiplied by 3/2. The result is expressed in inches and is usually (though not always) rounded to a convenient fraction - hence the approximation. For instance, a has a diagonal of and therefore an optical format of 8.0*3/2=, which is rounded to the convenient imperial fraction of . The parameter is also the source of the \"Four Thirds\" in the Four Thirds system and its Micro Four Thirds extension—the imaging area of the sensor in these cameras is approximately that of a video-camera tube at approximately .\n\nAlthough the optical format size bears no relationship to any physical parameter of the sensor, its use means that a lens that would have been used with (say) a four thirds inch camera tube will give roughly the same angle of view when used with a solid-state sensor with an optical format of four thirds of an inch\n\nModern CCD and CMOS-based sensors offer many advantages over their tube counterparts. These include a lack of image lag, high overall picture quality, high light sensitivity and dynamic range, a better signal-to-noise ratio and significantly higher reliability and ruggedness. Other advantages include the elimination of the respective high and low-voltage power supplies required for the electron beam and heater filament, elimination of the drive circuitry for the focusing coils, no warm-up time and a significantly lower overall power consumption. Despite these advantages, acceptance and incorporation of solid-state sensors into television and video cameras was not immediate. Early sensors were of lower resolution and performance than picture tubes, and were initially relegated to consumer-grade video recording equipment.\n\nAlso, video tubes had progressed to a high standard of quality and were \"standard issue\" equipment to networks and production entities. Those entities had a substantial investment in not only tube cameras, but also in the ancillary equipment needed to correctly process tube-derived video. A switch-over to solid-state image sensors rendered much of that equipment (and the investments behind it) obsolete and required new equipment optimized to work well with solid-state sensors, just as the old equipment was optimized for tube-sourced video.\n\n\n"}
{"id": "7006160", "url": "https://en.wikipedia.org/wiki?curid=7006160", "title": "Willy–Nicky correspondence", "text": "Willy–Nicky correspondence\n\nThe Willy–Nicky correspondence was a set of messages relayed between Wilhelm II, German Emperor, and Nicholas II, Emperor of Russia during the eve of the First World War.\n\nKaiser Wilhelm II and Tsar Nicholas II were third cousins (both were great-great-grandsons of Paul I of Russia) as well as being second cousins once removed (both were descended from Frederick William III of Prussia) and the Kaiser was a first cousin of Nicholas's wife, Alix of Hesse. The emperors corresponded in English and were accustomed to calling each other \"Willy\" and \"Nicky\" but would use their counterparts' formal names in formal communications.\n\nThe source of the telegrams is \"The German White Book\", a pamphlet of official documents published to justify the German Government's position after the outbreak of war. The term \"Willy-Nicky Telegrams\" is derived from \"The Willy-Nicky Correspondence\", the title of a book by Herman Bernstein published in 1918 which revealed the personal telegraphic correspondence between the two emperors during the period June 1904 to August 1907.\n\nThe telegrams start with a plea from the Tsar to the Kaiser to try to stop the serious developments that led up to the World War. An excerpt:\n\nUltimately, the correspondence changes tone and the two leaders warn each other of impending mobilization due to factors out of their control, while retaining the notion that mobilization does not mean war. An excerpt of the last telegram:\n\nThe Willy-Nicky telegrams were discussed during the war by representatives of belligerent nations, during the Paris Peace Conference, and on into the interwar years, and beyond. In recent years academic historians have reassessed the exchange. They paid special attention to the telegram of Nicholas II dated July 29, 1914 (two days before the war):\nOn July 29, 1914, Nicholas suggested submitting the Austro-Serbian problem to the Hague Conference (in Hague tribunal) – Wilhelm did not address this in his subsequent telegram. According to Beck, the German Foreign Office omitted this telegram in publishing the correspondence between the Kaiser and the tsar. After the publication of this telegram by the Russian government on January 31, 1915 in the Official Gazette \"Governmental Herald\", the German Foreign Office explained that they regarded this telegram as too \"unimportant\". In contrast, Russian Foreign Ministry (Minister Sazonov), as well as the French Ambassador in Russia (Maurice Paléologue) believed the telegram very important. Paléologue, Beck and some other authors accused Wilhelm in that he had not supported the proposal of Nicholas to submit the Austro-Serbian problem to the Hague Tribunal for adjustment, and thus abandoned the chance for a peaceful resolution to this problem.\n\nA \"flurry of telegrams\" between the Kaiser and the Tsar led to the cancellation of Russian general mobilization by the Tsar on 29 July, but under pressure from Sazonov this was resumed two days later.\n\n"}
{"id": "11405124", "url": "https://en.wikipedia.org/wiki?curid=11405124", "title": "Winning the Oil Endgame", "text": "Winning the Oil Endgame\n\nWinning the Oil Endgame: Innovation for Profits, Jobs and Security is a 2005 book by Amory B. Lovins, E. Kyle Datta, Odd-Even Bustnes, Jonathan G. Koomey, and Nathan J. Glasgow, published by the Rocky Mountain Institute. It presents an independent, transdisciplinary analysis of four ways to reduce petroleum dependence in the United States:\n\nThe authors explain that the problems of oil dependence are manageable, suggesting that oil dependence is a problem we need no longer have. The proposed solutions to oil dependence are profitable and U.S. oil dependence can be eliminated by proven and attractive technologies that create wealth, enhance choice, and strengthen common security. The authors argue that America can lead the world into the post-petroleum era and create a vibrant economy. (p.xiii)\n\n\"Winning the Oil Endgame\" has received many positive reviews and the Wall Street Journal called the book \"Perhaps the most rigorous and surely the most dramatic analysis of what it will take to wean us from foreign oil ... carried out by the Rocky Mountain Institute, a respected center of hard-headed, market-based research.\"\n\nAmory Lovins has published 28 books and hundreds of papers. His work has been recognized by the Right Livelihood Award, Onassis, Nissan, Shingo and Mitchell prizes, a MacArthur Fellowship, the Happold Medal, eight honorary doctorates, and the Heinz, Lindbergh, World Technology, and Hero of the Planet Awards. Lovins has also acted as a consultant to many Fortune 500 companies.\n\n\n"}
{"id": "46933351", "url": "https://en.wikipedia.org/wiki?curid=46933351", "title": "Ziki Shaked", "text": "Ziki Shaked\n\nZiki Shaked (; born 1955) is an Israeli captain, sailing instructor, and founder of the school of sailing in Eilat.\n\nIn 2010–2012, he traveled around the world on his yacht, \"Lorraine-D\", and joined a small group of Israeli captains who traveled around the world under the Israeli flag.\n\nThe yacht \"Lorraine-D\" started from Eilat and two years later came back to Eilat. The route passed through the Suez Canal into the Mediterranean Sea, the Atlantic Ocean, through the Panama Canal to the Pacific Ocean, the Indian Ocean, the Gulf of Aden, and the Red Sea.\n\nThe boat travelled to unique places, such as the Galápagos Islands, Easter Island, the Pitcairn Islands, and Vanuatu. At various times, people from different countries of the world, including Israel, Russia, Finland, and France, joined this journey.\n"}
