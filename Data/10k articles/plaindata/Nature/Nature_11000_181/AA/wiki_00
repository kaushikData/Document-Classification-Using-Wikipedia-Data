{"id": "4082546", "url": "https://en.wikipedia.org/wiki?curid=4082546", "title": "12AT7", "text": "12AT7\n\n12AT7 (also known in Europe by the Mullard–Philips tube designation of ECC81) is a miniature 9-pin medium-gain (60) dual-triode vacuum tube popular in guitar amplifiers. It belongs to a large family of dual triode vacuum tubes which share the same pinout (EIA 9A), including in particular the very commonly used low-mu 12AU7 and high-mu 12AX7.\n\nThe 12AT7 has somewhat lower voltage gain than the 12AX7, but higher transconductance and plate current, which makes it suitable for high frequency applications.\n\nOriginally the tube was intended for operation in VHF circuits, such as TV sets and FM tuners, as an oscillator/frequency converter, but it also found wide use in audio as a driver and phase-inverter in vacuum tube push–pull amplifier circuits.\n\nThis tube is essentially two 6AB4s or two EC92s in a single envelope.\n\nThe tube has a center-tapped filament so it can be used in either 6.3V 300mA or 12.6V 150mA heater circuits.\n\n\n"}
{"id": "52081", "url": "https://en.wikipedia.org/wiki?curid=52081", "title": "Antihydrogen", "text": "Antihydrogen\n\nAntihydrogen () is the antimatter counterpart of hydrogen. Whereas the common hydrogen atom is composed of an electron and proton, the antihydrogen atom is made up of a positron and antiproton. Scientists hope studying antihydrogen may shed light on the question of why there is more matter than antimatter in the observable universe, known as the baryon asymmetry problem. Antihydrogen is produced artificially in particle accelerators. In 1999, NASA gave a cost estimate of $62.5 trillion per gram of antihydrogen (equivalent to $ trillion today), making it the most expensive material to produce. This is due to the extremely low yield per experiment, and high opportunity cost of using a particle accelerator.\n\nAccelerators first detected hot antihydrogen in the 1990s. ATHENA studied cold in 2002. It was first trapped by the Antihydrogen Laser Physics Apparatus (ALPHA) team at CERN in 2010, who then measured the structure and other important properties. ALPHA, AEGIS, and GBAR plan to further cool and study atoms.\n\nIn 2016, the ALPHA experiment measured the atomic electron transition between the two lowest energy levels of antihydrogen, 1S–2S. The results, which are identical to that of hydrogen within the experimental resolution, support the idea of matter–antimatter symmetry and CPT symmetry.\n\nIn the presence of a magnetic field the 1S–2S transition splits into two hyperfine transitions with slightly different frequencies. The team calculated the transition frequencies for normal hydrogen under the magnetic field in the confinement volume as:\n\nA single-photon transition between S states is prohibited by quantum selection rules, so to elevate ground state positrons to the 2S level, the confinement space was illuminated by a laser tuned to half the calculated transition frequencies, stimulating allowed two photon absorption.\n\nAntihydrogen atoms excited to the 2S state can then evolve in one of several ways:\n\n\nBoth the ionization and spin-flip outcomes cause the atom to escape confinement. The team calculated that, assuming antihydrogen behaves like normal hydrogen, roughly half the antihydrogen atoms would be lost during the resonant frequency exposure, as compared to the no-laser case. With the laser source tuned 200 kHz below half the transition frequencies, the calculated loss was essentially the same as for the no-laser case.\n\nThe ALPHA team made batches of antihydrogen, held them for 600 seconds and then tapered down the confinement field over 1.5 seconds while counting how many antihydrogen atoms were annihilated. They did this under three different experimental conditions:\n\n\nThe two controls, off-resonance and no-laser, were needed to insure that the laser illumination itself was not causing annihilations, perhaps by liberating normal atoms from the confinement vessel surface that could then combine with the antihydrogen.\n\nThe team conducted 11 runs of the three cases and found no significant difference between the off-resonance and no laser runs, but a 58% drop in the number of events detected after the resonance runs. They were also able to count annihilation events during the runs and found a higher level during the resonance runs, again with no significant difference between the off-resonance and no laser runs. The results were in good agreement with predictions based on normal hydrogen and can be \"interpreted as a test of CPT symmetry at a precision of 200 ppt.\"\n\nThe CPT theorem of particle physics predicts antihydrogen atoms have many of the characteristics regular hydrogen has; i.e. the same mass, magnetic moment, and atomic state transition frequencies (see \"atomic spectroscopy\"). For example, excited antihydrogen atoms are expected to glow the same color as regular hydrogen. Antihydrogen atoms should be attracted to other matter or antimatter gravitationally with a force of the same magnitude that ordinary hydrogen atoms experience. This would not be true if antimatter has negative gravitational mass, which is considered highly unlikely, though not yet empirically disproven (see \"gravitational interaction of antimatter\").\n\nWhen antihydrogen comes into contact with ordinary matter, its constituents quickly annihilate. The positron annihilates with an electron to produce gamma rays. The antiproton, on the other hand, is made up of antiquarks that combine with quarks in either neutrons or protons, resulting in high-energy pions, that quickly decay into muons, neutrinos, positrons, and electrons. If antihydrogen atoms were suspended in a perfect vacuum, they should survive indefinitely.\n\nAs an antielement, it is expected to have exactly the same properties as hydrogen. For example, antihydrogen would be a gas under standard conditions and combine with antioxygen to form antiwater, .\n\nIn 1995, the first antihydrogen was produced by a team led by Walter Oelert at CERN. using a method first proposed by Charles Munger Jr, Stanley J Brodsky and Ivan Schmidt Andrade.\n\nIn the LEAR, antiprotons from an accelerator were shot at xenon clusters, producing electron-positron pairs. Antiprotons can capture positrons with probability about , so this method is not suited for substantial production, as calculated. Fermilab measured a somewhat different cross section, in agreement with predictions of quantum electrodynamics. Both resulted in highly energetic, or hot, anti-atoms, unsuitable for detailed study.\n\nSubsequently, CERN built the Antiproton Decelerator (AD) to support efforts towards low-energy antihydrogen, for tests of fundamental symmetries. The AD will supply several CERN groups. CERN expects their facilities will be capable of producing 10 million antiprotons per minute.\n\nExperiments by the ATRAP and ATHENA collaborations at CERN, brought together positrons and antiprotons in Penning traps, resulting in synthesis at a typical rate of 100 antihydrogen atoms per second. Antihydrogen was first produced by ATHENA in 2002, and then by ATRAP and by 2004, millions of antihydrogen atoms were made. The atoms synthesized had a relatively high temperature (a few thousand kelvins), and would hit the walls of the experimental apparatus as a consequence and annihilate. Most precision tests require long observation times.\n\nALPHA, a successor of the ATHENA collaboration, was formed to stably trap antihydrogen. While electrically neutral, its spin magnetic moments interact with an inhomogeneous magnetic field; some atoms will be attracted to a magnetic minimum, created by a combination of mirror and multipole fields.\n\nIn November 2010, the ALPHA collaboration announced that they had trapped 38 antihydrogen atoms for a sixth of a second, the first confinement of neutral antimatter. In June 2011, they trapped 309 antihydrogen atoms, up to 3 simultaneously, for up to 1,000 seconds. They then studied its hyperfine structure, gravity effects, and charge. ALPHA will continue measurements along with experiments ATRAP, AEGIS and GBAR.\n\nLarger antimatter atoms such as antideuterium (), antitritium (), and antihelium () are much more difficult to produce. Antideuterium, antihelium-3 () and antihelium-4 () nuclei have been produced with such high velocities that synthesis of their corresponding atoms poses several technical hurdles.\n\n"}
{"id": "177089", "url": "https://en.wikipedia.org/wiki?curid=177089", "title": "Atomic energy", "text": "Atomic energy\n\nAtomic energy is energy carried by atoms. The term originated in 1903 when Ernest Rutherford began to speak of the possibility of \"atomic energy\". The term was popularized by H. G. Wells in the phrase, \"splitting the atom\", devised at a time prior to the discovery of the nucleus. Atomic energy may include:\n\n\nAtomic energy is the source of nuclear power, which uses sustained nuclear fission to generate heat and electricity.\n"}
{"id": "21647769", "url": "https://en.wikipedia.org/wiki?curid=21647769", "title": "Circum-Superior Belt", "text": "Circum-Superior Belt\n\nThe Circum-Superior Belt is a widespread Paleoproterozoic large igneous province in the Canadian Shield of Northern, Western and Eastern Canada. It extends more than from northeastern Manitoba through northwestern Ontario, southern Nunavut to northern Quebec. Igneous rocks of the Circum-Superior Belt are mafic-ultramafic in composition, deposited in the Labrador Trough near Ungava Bay, the Cape Smith Belt near the southern shore of Hudson Strait and along the eastern shore of Hudson Bay in its northern portion; the Thompson and Fox River belts in the northwest and the Marquette Range Supergroup in its southern portion.\n\nA number of magmatic features are present in the Circum-Superior Belt, including dikes, sills and volcanics that comprise geologic formations. This geologic belt is considered to be a large igneous province because its magmatic rocks were emplaced over an extremely short geological time span. Even though the Circum-Superior Belt was emplaced during an extremely short geological time span, the associated magmas were probably derived from a number of separate sources.\n\nMost of the Circum-Superior Belt lies along the margin of the Superior Craton, which is the most extensive fragment of Archean crust on Earth. However, a number of igneous rocks within the Superior craton remain undated, indicating the existence of magmatic rocks with the same age as those of the Circum-Superior Belt is probable. It contains two large copper-nickel mining districts; the nickel-bearing Thompson Belt at the northwestern portion of the Superior craton and the Cape Smith Belt at the northern portion of the Circum-Superior Belt.\n\nThe Circum-Superior Belt was formed 1,884 to 1,864 million years ago when the Superior craton was surrounded by mountain building processes, including the Trans-Hudson, New Quebec and Penokean orogenies. The major Trans-Hudson orogeny had its appearance when the Superior craton collided with the Rae-Hearne craton 1,900 to 1,800 million years ago. Massive orogenic belts with a change in horizontal direction are represented by the double promontory structure of the Superior craton that seem to have come from the beginning of a rifting event. The New Quebec orogen, also known as the Labrador Trough, lies at the northeastern portion of the Superior craton and is related to ocean closure and collision with the southeastern portion of the Rae craton. At 1,900 and 1,800 million years ago, an ocean closure and collision with the Wisconian arc terrane resulted in the creation of the Penokean orogeny at the southern Superior craton margin. The last collision occurred on the southeastern portion of the Superior craton to produce the Grenville orogeny 1,100 million years ago.\n\nBecause most of the Circum-Superior Belt was formed by widespread mafic-ultramafic magmatism 1,884 to 1,864 million years ago along the Superior craton margin during these orogenies, a number of different suggestions have been made to explain the questionable origins of this large igneous province. It is also not clear if the Circum-Superior Belt has a single origin or it has several origins. Suggestions include back-arc rifting, foredeep flexure, mantle plumes and the breakup of a microcontinent. The geochemical indication of the Circum-Superior Belt is also poorly known; either it contains major regional differences or it is the same throughout the magmatic zone. With the discovery of the Pickle Crow dike swarm throughout the western Superior craton, the likelihood of other 1,880 million year old dike groups throughout the Superior craton remains. This is partly because several dike zones in the Superior craton remain undated. The relationship of the Circum-Superior Belt with similar age magmatism throughout the nearby Trans-Hudson belt and elsewhere on Earth is also unknown. This includes the 1,860 million year old magmatism of the East Kimberly event in Australia and 1,860 million year old magmatism of the Mashonaland event in Africa. The other questionable suggestion related to the Circum-Superior Belt is the existence of a suggested 1,900 million year old global superplume event.\n\nThe long Labrador Trough, extending from Ungava Bay through Quebec and Labrador, includes two volcano-sedimentary series, the first ranging from 2,170 to 2,140 million years old and second ranging from 1,883 to 1,870 million years old. This magmatism is considered to have formed as a result of back-arc volcanism. The youngest magmatic series (1883-1870 Ma) contains 1,880 million-year-old carbonatites and lamprophyres. 1,883 to 1,874 million-year-old mafic and a few ultramafic magmas comprise the Willbob and Hellancourt formations and Montagnais sills. The youngest magmatism of the youngest magmatic series is 1,870 million-year-old felsic and carbonatitic volcanics. These igneous rocks of the Labrador Trough cover an area of .\n\nTo the northwest at the northern tip of Quebec near Hudson Strait, the Cape Smith Belt includes the 2,040 to 1,970 million-year-old Povungnituk volcano-sedimentary group and the 1,880 million-year-old Chukotat Group. The thick Chukotat Group is made of picritic and tholeiitic basalts. These basaltic lavas are intruded by narrow mafic and ultramafic sills. At least three different types of lava compositions exist in the Chukotat Group, including olivine phyric, pyroxene-phyric and plagioclase phyric. The upper unit of the Chukotat Group is 1,870 million years old whereas the lower unit is associated with the Katiniq Suite sills, which cut through the underlying Povungnituk Group. In 1989, the Katiniq Suite sills were thought to be 1,918 million years old, but more recent dating and a reinterpretation of the original age in 2004 suggests that the Katiniq Suite sills are closer to 1,880 million years old. Therefore, the age range for the Chutotat Group is 1,880 to 1,870 million years. Volcanism of the Chukotat Group might have originated from rifting of a microcontinent that now forms the southwestern portion of Baffin Island.\nOn the Belcher Islands of southern Nunavut, two volcanic groups are known as the Flaherty and Eskimo volcanics. The underlying Eskimo volcanics are related with the Richmond Gulf, Persillon, Pachi and Nastapoka Group volcanics. The 1,998 million-year-old Minto dikes are also interpreted to be related with the Eskimo volcanics. The overlying Flaherty volcanics remain undated apart from a lead-lead dating of . However, the Flaherty volcanics are suggested to have relationships with the Sutton Inlier and Haig sills. Geochemical indications suggest that the overlying Flaherty volcanics might also have relationships with the Povungnituk volcano-sedimentary group in the Cape Smith Belt, indicating the Flaherty volcanics might be 2,040 to 1,960 million years old. Sills on the Belcher and Snowy islands in Hudson Bay are dated to 1,870 million years old, indicating the 1,880 million-year-old magmatism also exists in this section of the Circum–Superior large igneous province.\n\nThe Fox River Belt in northern Manitoba is composed of sediments, volcanics and sills. Fox River Belt sills and Molsen dikes are 1,883 million years old, but the Molsen dikes at the northwestern Superior craton margin intrude an older, 2,090 to 2,070 million-year-old dike swarm. The Ospwagan Group is younger than and the 1,864 million-year-old Winnipegosis komatiite belt lies to the southwest. Numerous tectonic settings have been suggested for triggering magmatism in the Fox River Belt, including a marginal basin rifting event.\n\nAt the southern portion of the Circum-Superior Belt, a group of fragmental sediments composed of iron formation was formed during a period of magmatic activity in the Marquette Range Supergroup. Included in the Marquette Range Supergroup is the Hemlock Formation, a bimodal volcanic group that is estimated to have an age of . Another volcanic series in the Marquette Range Supergroup, known as the Gunflint Formation, has an age of . Further geologic units that are related to the Gunflint Formation include the Badwater volcanics and the Kiernan sills. A number of origins have suggested for the Marquette Range Supergroup magmatism. This includes subsidence being driven ahead related to thrusting of the Penokean orogeny or a possible back-arc basin, and lateral flow through the Pickle Crow dikes transported magma from the Fox River Belt area through the Superior craton for placement in the Marquette Range Supergroup. This suggested long-range origin has been suggested for magmatism of the 2,215 million-year-old Nipissing sills as well, which the Ungava dike swarm could have transported magma to the Nipissing sills area.\n\nBefore 2003, all magmatism of the Circum-Superior Belt was thought to only occur along the outer margin of the Superior craton. However, the Pickle Crow dike was discovered in 2003 in the interior of the Superior craton and it has since been recognized as a magmatic event related to the Circum-Superior Belt. The dike is dated to 1,880 million years old and associated dikes are traced for at least . These dikes likely extend over across the western portion of the Superior craton from near the Fox River Belt in the north to near Lake Superior in the south. This magmatic crossing creates a relationship with the 1,880 million-year-old magmatism in the northwestern portion of the Circum-Superior Belt and magmatism in the Marguette Range Supergroup on the southern portion of the Circum-Superior Belt. In addition, the north-northwest trend of the Pickle Crow dikes and the absolute north-northeastern trend of the Molson dike swarm combine to an area north of the northwestern portion of the Circum-Superior Belt. This might determine the zone of a mantle plume that was the source for the 1,880 million-year-old magmatism in the Circum-Superior Belt.\n\nThe Circum-Superior Belt is the host for widespread mineral deposits, including copper, nickel and platinum group elements. However, the origins of this widespread mineralization is unknown. The Thompson Belt in Manitoba is one of the most comprehensive nickel producing zones on Earth. It has the potential to contain platinum group elements, but the age of the mafic-ultramafic volcanic rocks comprising the nickel deposits are not well known. Since its foundation during the 1950s, numerous mining operations throughout the Thompson Belt have produced over four billion pounds of nickel. At least two nickel deposits are in progress by Vale Inco at the Thompson and Birchtree mines. At least 70 million pounds of nickel has been mined since 2005. At the city of Thompson, nickel of the Thompson Belt is smelted and refined in facilities. This smelting and refining process contributes to about one-third of the total nickel output in Canada.\n\nIn the Cape Smith Belt of northern Quebec, the Raglan Mine lies in copper-nickel deposits of the ultramafic Katiniq Suite sills. The Katiniq Suite sills are also within an area that is presently explored for nickel, copper and platinum group element deposits. Copper, nickel and platinum group elements are associated with mafic-ultramafic rocks in the Labrador Trough that were formed during a period of magmatism 1,883 to 1,870 million years ago.\n\n"}
{"id": "22742223", "url": "https://en.wikipedia.org/wiki?curid=22742223", "title": "Data center infrastructure efficiency", "text": "Data center infrastructure efficiency\n\nData center infrastructure efficiency (DCIE), is a performance improvement metric used to calculate the energy efficiency of a data center. DCIE is the percentage value derived, by dividing information technology equipment power by total facility power.\n\n"}
{"id": "207247", "url": "https://en.wikipedia.org/wiki?curid=207247", "title": "Denali", "text": "Denali\n\nDenali () (also known as Mount McKinley, its former official name) is the highest mountain peak in North America, with a summit elevation of above sea level. With a topographic prominence of and a topographic isolation of , Denali is the third most prominent and third most isolated peak on Earth, after Mount Everest and Aconcagua. Located in the Alaska Range in the interior of the U.S. state of Alaska, Denali is the centerpiece of Denali National Park and Preserve.\n\nThe Koyukon people who inhabit the area around the mountain have referred to the peak as \"Denali\" for centuries. In 1896, a gold prospector named it \"Mount McKinley\" in support of then-presidential candidate William McKinley; that name was the official name recognized by the Federal government of the United States from 1917 until 2015. In August 2015, following the 1975 lead of the State of Alaska, the United States Department of the Interior announced the change of the official name of the mountain to Denali.\n\nIn 1903, James Wickersham recorded the first attempt at climbing Denali, which was unsuccessful. In 1906, Frederick Cook claimed the first ascent, which was later proven to be false. The first verifiable ascent to Denali's summit was achieved on June 7, 1913, by climbers Hudson Stuck, Harry Karstens, Walter Harper, and Robert Tatum, who went by the South Summit. In 1951, Bradford Washburn pioneered the West Buttress route, considered to be the safest and easiest route, and therefore the most popular currently in use.\n\nOn September 2, 2015, the U.S. Geological Survey announced that the mountain is high, not , as measured in 1952 using photogrammetry.\n\nDenali is a granitic pluton lifted by tectonic pressure from the subduction of the Pacific Plate beneath the North American Plate; at the same time, the sedimentary material above and around the mountain was stripped away by erosion. The forces that lifted Denali also cause many deep earthquakes in Alaska and the Aleutian Islands. The Pacific Plate is seismically active beneath Denali, a tectonic region that is known as the \"McKinley cluster\".\n\nDenali has a summit elevation of above sea level, making it the highest peak in North America and the northernmost mountain above 6,000 meters elevation in the world. Measured from base to peak at some , it is among the largest mountains situated entirely above sea level (although some Asian mountains i.e. Rakaposhi, Dhaulagiri and Nanga Parbat are even larger in this regard ). Denali rises from a sloping plain with elevations from , for a base-to-peak height of . By comparison, Mount Everest rises from the Tibetan Plateau at a much higher base elevation. Base elevations for Everest range from on the south side to on the Tibetan Plateau, for a base-to-peak height in the range of . Denali's base-to-peak height is little more than half the of the volcano Mauna Kea, which lies mostly under water.\n\nDenali has two significant summits: the South Summit is the higher one, while the North Summit has an elevation of and a prominence of approximately . The North Summit is sometimes counted as a separate peak (see e.g., fourteener) and sometimes not; it is rarely climbed, except by those doing routes on the north side of the massif.\n\nFive large glaciers flow off the slopes of the mountain. The Peters Glacier lies on the northwest side of the massif, while the Muldrow Glacier falls from its northeast slopes. Just to the east of the Muldrow, and abutting the eastern side of the massif, is the Traleika Glacier. The Ruth Glacier lies to the southeast of the mountain, and the Kahiltna Glacier leads up to the southwest side of the mountain. With a length of , the Kahiltna Glacier is the longest glacier in the Alaska Range.\n\nThe Koyukon Athabaskans who inhabit the area around the mountain have for centuries referred to the peak as \"Dinale\" or \"Denali\". The name is based on a Koyukon word for \"high\" or \"tall\". During the Russian ownership of Alaska, the common name for the mountain was \"Bolshaya Gora\" (, \"bolshaya\" = Russian for \"big\"; \"gora\" = Russian for \"mountain\"), which is the Russian translation of \"Denali\". It was briefly called Densmore's Mountain in the late 1880s and early 1890s after Frank Densmore, an Alaskan prospector who was the first European to reach the base of the mountain.\n\nIn 1896, a gold prospector named it \"McKinley\" as political support for then-presidential candidate William McKinley, who became president the following year. The United States formally recognized the name Mount McKinley after President Wilson signed the Mount McKinley National Park Act of February 26, 1917. In 1965, Lyndon B. Johnson declared the north and south peaks of the mountain the \"Churchill Peaks\", in honor of British statesman Winston Churchill. The Alaska Board of Geographic Names changed the name of the mountain to \"Denali\" in 1975, which was how it is called locally. However, a request in 1975 from the Alaska state legislature to the United States Board on Geographic Names to do the same at the federal level was blocked by Ohio congressman Ralph Regula, whose district included McKinley's hometown of Canton.\n\nOn August 30, 2015, just ahead of a presidential visit to Alaska, the Barack Obama administration announced the name \"Denali\" would be restored in line with the Alaska Geographic Board's designation. U.S. Secretary of the Interior Sally Jewell issued the order changing the name to Denali on August 28, 2015, effective immediately. Jewell said the change had been \"a long time coming\". The renaming of the mountain received praise from Alaska's senior U.S. senator, Lisa Murkowski, who had previously introduced legislation to accomplish the name change, but it drew criticism from several politicians from President McKinley's home state of Ohio, such as Governor John Kasich, U.S. Senator Rob Portman, U.S. House Speaker John Boehner, and Representative Bob Gibbs, who described Obama's action as \"constitutional overreach\" because he said an act of Congress is required to rename the mountain. The \"Alaska Dispatch News\" reported that the Secretary of the Interior has authority under federal law to change geographic names when the Board of Geographic Names does not act on a naming request within a \"reasonable\" period of time. Jewell told the \"Alaska Dispatch News\" that \"I think any of us would think that 40 years is an unreasonable amount of time.\"\n\nIndigenous names for Denali can be found in seven different Alaskan languages. The names fall into two categories. To the south of the Alaska Range in the Dena'ina and Ahtna languages the mountain is known by names that are translated as \"big mountain\". To the north of the Alaska Range in the Lower Tanana, Koyukon, Upper Kuskokwim, Holikachuk, and Deg Xinag languages the mountain is known by names that are translated as \"the high one\", \"the tall one\" (Koyukon, Lower and Middle Tanana, Upper Kuskokwim, Deg Xinag, and Holikachuk), or \"big mountain\" (Ahtna and Dena'ina). Asked about the importance of the mountain and its name, Will Mayo, former president of the Tanana Chiefs Conference, an organization that represents 42 Athabaskan tribes in the Alaskan interior, said \"It’s not one homogeneous belief structure around the mountain, but we all agree that we’re all deeply gratified by the acknowledgment of the importance of Denali to Alaska’s people.\"\n\nThe following table lists the Alaskan Athabascan names for Denali.\nThe Koyukon Athabaskans, living in the Yukon, Tanana and Kuskokwim basins, were the first Native Americans with access to the flanks of the mountain. A British naval captain and explorer, George Vancouver, is the first European on record to have sighted Denali, when he noted \"distant stupendous mountains\" while surveying the Knik Arm of the Cook Inlet on May 6, 1794. The Russian explorer Lavrenty Zagoskin explored the Tanana and Kuskokwim rivers in 1843 and 1844, and was likely the first European to sight the mountain from the other side.\n\nWilliam Dickey, a New Hampshire-born resident of Seattle, Washington who had been digging for gold in the sands of the Susitna River, wrote, after his returning from Alaska, an account in the \"New York Sun\" that appeared on January 24, 1897. His report drew attention with the sentence \"We have no doubt that this peak is the highest in North America, and estimate that it is over high.\" Until then, Mount Logan in Canada's Yukon Territory was believed to be the continent’s highest point. Though later praised for his estimate, Dickey admitted that other prospector parties had also guessed the mountain to be over .\nOn November 5, 2012, the United States Mint released a twenty-five cent piece depicting Denali National Park. It is the fifteenth of the America the Beautiful Quarters series. The reverse features a Dall sheep with the peak of Denali in the background.\n\nThe first recorded attempt to climb Denali was by Judge James Wickersham in 1903, via the Peters Glacier and the North Face, now known as the Wickersham Wall. Because of the route's history of avalanche danger, it was not successfully climbed until 1963.\n\nFamed explorer Dr. Frederick Cook claimed the first ascent of the mountain in 1906. His claim was regarded with some suspicion from the start, but was also widely believed. It was later proved false, with some crucial evidence provided by Bradford Washburn when he was sketched on a lower peak.\n\nIn 1910, four area locals – Tom Lloyd, Peter Anderson, Billy Taylor, and Charles McGonagall – known as the Sourdough Expedition, attempted to climb Denali despite a lack of climbing experience. The group spent approximately three months on the mountain. Their purported summit ascent day included carrying a bag of doughnuts each, a thermos of hot chocolate, and a 14-foot (4.2 m) spruce pole. Two of them reached the North Summit, the lower of the two, and erected the pole near the top. According to the group, the time they took to reach the summit was a total of 18 hours. Until the first ascent in 1913, their claims were disbelieved, in part due to false claims they had climbed both summits.\n\nIn 1912, the Parker-Browne expedition nearly reached the summit, turning back within just a few hundred yards of it due to harsh weather. The day after their descent, the Great Earthquake of 1912 shattered the glacier they had ascended.\n\nThe first ascent of the main summit of Denali came on June 7, 1913, by a party led by Hudson Stuck and Harry Karstens. The first man to reach the summit was Walter Harper, an Alaska Native. Robert Tatum also made the summit. Using the mountain's contemporary name, Tatum later commented, \"The view from the top of Mount McKinley is like looking out the windows of Heaven!\" They ascended the Muldrow Glacier route pioneered by the earlier expeditions, which is still often climbed today. Stuck confirmed, via binoculars, the presence of a large pole near the North Summit; this report confirmed the Sourdough ascent, and today it is widely believed that the Sourdoughs did succeed on the North Summit. However, the pole was never seen before or since, so there is still some doubt. Stuck also discovered that the Parker-Browne party were only about 200 feet (61 m) of elevation short of the true summit when they turned back.\n\nThe mountain is regularly climbed today. In 2003, around 58% of climbers reached the top. But by 2003, the mountain had claimed the lives of nearly 100 mountaineers over time. The vast majority of climbers use the West Buttress Route, pioneered in 1951 by Bradford Washburn, after an extensive aerial photographic analysis of the mountain. Climbers typically take two to four weeks to ascend Denali. It is one of the Seven Summits; summiting all of them is a challenge for mountaineers.\n\nOn August 4, 2018, 5 people died in the K2 Aviation de Havilland Beaver (DHC-2) crash near Denali.\n\n\n\nThe Japan Alpine Club installed a meteorological station on a ridge near the summit of Denali at an altitude of in 1990. In 1998, this weather station was donated to the International Arctic Research Center at the University of Alaska Fairbanks. In June 2002, a weather station was placed at the level. This weather station was designed to transmit data in real-time for use by the climbing public and the science community. Since its establishment, annual upgrades to the equipment have been performed with instrumentation custom built for the extreme weather and altitude conditions. This weather station is the third-highest weather station in the world.\n\nThe weather station recorded a temperature of on December 1, 2003. On the previous day of November 30, 2003, a temperature of combined with a wind speed of to produce a North American record windchill of .\n\nEven in July, this weather station has recorded temperatures as low as and windchills as low as .\n\nThe mountain is characterized by extremely cold weather. Temperatures as low as and wind chills as low as have been recorded by an automated weather station located at . According to the National Park Service, in 1932 the -Lindley expedition recovered a self-recording minimum thermometer left near Browne's Tower, at about , on Denali by the Stuck-Karstens party in 1913. The spirit thermometer was calibrated down to , and the lowest recorded temperature was below that point. Harry J. Lek took the thermometer back to Washington, D.C. where it was tested by the United States Weather Bureau and found to be accurate. The lowest temperature that it had recorded was found to be approximately . Another thermometer was placed at the level by the U.S. Army Natick Laboratory, and was there from 1950 to 1969. The coldest temperature recorded during that period was also .\n\nBesides the North Summit mentioned above, other features on the massif which are sometimes included as separate peaks are:\n\nNearby peaks include:\n\n\n\n"}
{"id": "42963136", "url": "https://en.wikipedia.org/wiki?curid=42963136", "title": "Desert dry wash", "text": "Desert dry wash\n\nDesert dry wash is a North American desert vegetation type (or biome) occurring in the flat bottoms of canyons and drainages that lack water at or near the surface most of the year, and are subject to periodic severe flooding events. Desert dry wash is contrasted with desert riparian vegetation, which occurs in desert canyons and drainages where there is year-round water at or near the surface. Plants must either be able to survive the severe flooding conditions or be able to reestablish themselves before the next flooding event. Some of these plants have evolved so that in order for their seeds to germinate, the seeds must be scarified or abraded by tumbling sand, gravel, and rocks during the flooding event. They must then quickly send down roots deep enough to be able to tap into deep underground water reserves, in order to survive the dry period after the flooding. Common dominant species of the desert dry wash include smoke tree (\"Psorothamnus spinosus\"), desert willow (\"Chilopsis linearis\"), catclaw (\"Senegalia greggii\"), cheesebush (\"Ambrosia salsola\"), and waterweed (\"Baccharis sergiloides\"). \n"}
{"id": "1287870", "url": "https://en.wikipedia.org/wiki?curid=1287870", "title": "Dine's compensation", "text": "Dine's compensation\n\nIn meteorology, Dines' compensation states that net mass convergence into a given column of air must be balanced by a net mass divergence from the same column of air. The implication is that rising air in the atmosphere must be balanced by equal sinking or subsiding air.\n\nDines' compensation applies especially in mesoscale circulations (i.e. supercells) and in macroscale and mesoscale tropical circulations. For instance, it is not uncommon to see anti-cyclonic cirrus outflow from a hurricane in visible satellite imagery.\n\nDines' compensation applies differently in the mid-latitudes, as upper-level highs are not necessarily associated with surface lows. Jet streaks and other upper level features, however, can contribute or support lower level convergence/divergence.\n"}
{"id": "2991011", "url": "https://en.wikipedia.org/wiki?curid=2991011", "title": "EL34", "text": "EL34\n\nThe EL34 is a thermionic valve or vacuum tube of the power pentode type. It has an international octal base (indicated by the '3' in the part number) and is found mainly in the final output stages of audio amplification circuits and was designed to be suitable as a series regulator by virtue of its high permissible voltage between heater and cathode and other parameters. The American RETMA tube designation number for this tube is 6CA7. The USSR analog was 6P27S (Cyrillic: 6П27C).\n\nIn common with all 'E' prefix tubes, using the Mullard–Philips tube designation, the EL34 has a heater voltage of 6.3 V. According to the data sheets found in old vacuum tube reference manuals, a pair of EL34s with 800 V plate voltage can produce 90 watts output in class AB1 in push–pull configuration. However, this configuration is rarely found. One application of this type was in \"Australian Sound\" public address amplifiers commonly used in government schools in Australia in the 1950s, using four EL34s for ≈200 watts. More commonly found is a pair of EL34s running class AB1 in push–pull around 375–450 V plate voltage and producing 50 watts output (if fixed bias is used), while a quad of EL34s running class AB1 in push–pull typically run anywhere from 425 to 500 V plate voltage and produces 100 watts output. This configuration is typically found in guitar amplifiers.\n\nThe EL34 is a pentode, while the 6L6, which delivers a similar range of power output, is a beam tetrode which RCA referred to as a \"beam power tube\". Although power pentodes and beam tetrodes have some differences in their principles of operation (the beam forming plates of the beam tetrode or fifth electrode (3rd grid) of the pentode, both serving to hinder the return of unabsorbed electrons from the anode (or plate) to the 4th electrode (2nd grid)) and have some internal construction differences, they are functionally closely equivalent. Unlike the 6L6, (EIA base 7AC) the EL34 has its grid 3 connection brought out to a separate Pin (Pin 1) (EIA base 8ET) and its heater draws 1.5 Amps compared to the 0.9 Amp heater in the 6L6. However, Sylvania (and possibly GE) marketed a tube as 6CA7 which was not only in a markedly different 'fat boy' envelope, but used a beam forming plate much like a 6L6. Examining the mica spacer on the top of the tube will confirm the lack of a suppressor grid. Although these tubes have similar (but not identical) characteristics, they are made very differently.\n\nThe EL34 was introduced in 1949 by Philips the parent company of Mullard and, although no longer made by them, is manufactured by JJ Electronic, Shuguang, Svetlana and Reflector (Sovtek, Electro-Harmonix, Tung-Sol and some brands), amongst others. Some firms make a related tube called an E34L which is rated to require a higher grid bias voltage, but which may be interchangeable in some equipment.\nThe EL34 was widely used in higher-powered audio amplifiers of the 1960s and 1970s, such as the very popular Dynaco Stereo 70 and the Leak TL25(mono) and Stereo 60, and is also widely used in high-end guitar amplifiers because it is characterized by greater distortion (considered desirable in this application) at lower power than other octal tubes such as 6L6, KT88 or 6550. The EL34 is found in many British guitar amps and is associated with the \"British Tone\" (Vox (musical equipment), Marshall, Hiwatt, Orange) as compared to the 6L6 which is generally associated with the \"American Tone\" (Fender/Mesa Boogie, and the earlier classic Marshall \"Plexi\" amps used the KT 66, a beam tetrode similar to the 6L6, as well).\n\n\n\n\n\n"}
{"id": "16842841", "url": "https://en.wikipedia.org/wiki?curid=16842841", "title": "Earth physical characteristics tables", "text": "Earth physical characteristics tables\n\nThese are tables showing the physical characteristics of Earth.\n"}
{"id": "31450053", "url": "https://en.wikipedia.org/wiki?curid=31450053", "title": "Energy accidents", "text": "Energy accidents\n\nEnergy resources bring with them great social and economic promise, providing financial growth for communities and energy services for local economies. However, the infrastructure which delivers energy services can break down in an energy accident, sometimes causing much damage, and energy fatalities can occur, and with many systems often deaths will happen even when the systems are working as intended.\n\nHistorically, coal mining has been the most dangerous energy activity and the list of historical coal mining disasters is a long one. Underground mining hazards include suffocation, gas poisoning, roof collapse and gas explosions. Open cut mining hazards are principally mine wall failures and vehicle collisions. In the US alone, more than 100,000 coal miners have been killed in accidents over the past century, with more than 3,200 dying in 1907 alone.\n\nAccording to Benjamin K. Sovacool, 279 \"major\" energy accidents occurred from 1907 to 2007 and they caused 182,156 deaths with $41 billion in property damages, with these figures not including deaths from smaller accidents.\n\nHowever, by far the greatest energy fatalities that result from energy generation by humanity, is the creation of air pollution. The most lethal of which, particulate matter, which is primarily generated from the burning of fossil fuels and biomass is (counting outdoor air pollution effects only) estimated to cause 2.1 million deaths annually.\n\nAccording to Benjamin K. Sovacool, while responsible for less than 1 percent of the total number of energy accidents, hydroelectric facilities claimed 94 percent of reported immediate fatalities. Results on immediate fatalities are dominated by one disaster in which Typhoon Nina in 1975 washed out the Shimantan Dam (Henan Province, China) and 171,000 people perished. While the other major accident that involved greater than 1000 immediate deaths followed the rupture of the NNPC petroleum pipeline in 1998 and the resulting explosion. The other singular accident described by Sovacool is the \"predicted\" latent death toll of greater than 1000, as a result of the 1986 steam explosion at the Chernobyl nuclear reactor in the Ukraine. With approximately 4000 deaths in total, to eventually result in the decades ahead due to the radio-isotope pollution released.\n\nIn the oil and gas industry, the need for improved safety culture and training within companies is evidenced by the finding that workers new to a company are more likely to be involved in fatalities.\n\nCoal mining accidents resulted in 5,938 immediate deaths in 2005, and 4746 immediate deaths in 2006 in China alone according to the World Wildlife Fund. Coal mining is the most dangerous occupation in China, the death rate for every 100 tons of coal mined is 100 times that of the death rate in the US and 30 times that achieved in South Africa. Moreover, 600,000 Chinese coal miners, as of 2004, were suffering from Coalworker's pneumoconiosis (known as \"black lung\") a disease of the lungs caused by long-continued inhalation of coal dust. And the figure increases by 70,000 miners every year in China.\n\nHistorically, coal mining has been a very dangerous activity and the list of historical coal mining disasters is a long one. In the US alone, more than 100,000 coal miners were killed in accidents over the past century, with more than 3,200 dying in 1907 alone. In the decades following this peak, an annual death toll of 1,500 miner fatalities occurred every year in the US until approximately the 1970s. Coal mining fatalities in the US between 1990 and 2012 have continued to decline, with fewer than 100 each year. (See more Coal mining disasters in the United States)\n\nIn the United States, in the 2000s, after three decades of regulation on the Environmental impact of the coal industry, including regulations in the 1970s and 1990s from the Clean Air Act, an act created to cut down on pollution related deaths from fossil fuel usage, US coal fired power plants were estimated, in the 2000s, to continue to cause between 10,000 and 30,000 latent, or air pollution related deaths per year, due to the emissions of sulfur dioxide, nitrogen oxides and directly emitted particulate matter that result when coal is burnt.\n\nAccording to the World Health Organization in 2012, urban outdoor air pollution, from the burning of fossil fuels and biomass is estimated to cause 3 million deaths worldwide per year and indoor air pollution from biomass and fossil fuel burning is estimated to cause approximately 4.3 million premature deaths. In 2013 a team of researchers estimated the number of premature deaths caused by particulate matter in outdoor air pollution as 2.1 million, occurring annually.\n\nBenjamin Sovacool says that while hydroelectric plants were responsible for the most fatalities, nuclear power plants rank first in terms of their economic cost, accounting for 41 percent of all property damage. Oil and hydroelectric follow at around 25 percent each, followed by natural gas at 9 percent and coal at 2 percent. Excluding Chernobyl and the Shimantan Dam, the three other most expensive accidents involved the Exxon Valdez oil spill (Alaska), The Prestige oil spill (Spain), and the Three Mile Island nuclear accident (Pennsylvania). However analysis presented in the international Journal, \"Human and Ecological Risk Assessment\" found that coal, oil, Liquid petroleum gas and hydro accidents have cost more than nuclear power accidents.\n\nModern-day U.S. regulatory agencies frequently implement regulations on conventional pollution if one life or more is predicted saved per $6 million to $8 million of economic costs incurred.\n\n\n\n"}
{"id": "30612343", "url": "https://en.wikipedia.org/wiki?curid=30612343", "title": "Energy in Malta", "text": "Energy in Malta\n\nEnergy in Malta describes energy production, consumption and import in Malta.\n\nMalta has no domestic resource of fossil fuels and no gas distribution network. Gross consumption has increased by 53% in 1990-2004. In 2008 the renewable energy market was at an early stage in Malta. Only solar energy and biofuels were used. The potential for solar and wind is substantial according to the EU. Energy import dependency was 100% in 2004.\n\nIn 2005 100% of electricity was from oil and in 2017 it was natural gas with oil as backup. Malta has four electricity plants operational and the total combined nominal installed capacity is 537.8 MW. The Malta–Sicily interconnector, which has been in operation since April 2015, allows for an electricity link between the Maltese Islands and the Italian electricity market has bidirectional flow capacity of 200 MW.\n\nAll transport fuel is petroleum, or derived from the same (diesel, etc.)\n\nThe European Union Directive 2009/28/EC set Malta's target share of renewable energy at 10% by the year 2020. The mandatory 10% target for transport concern also Malta.\n\nThe National Renewable Energy Action Plan for Malta is given in July 2010. According to the NREAP Malta's fuel mis in 2020 will be:\n\n\nTotal primary energy consumption was 0.9 Mtoe in 2004 and electricity generation 2.2 TWh.\n\n\n"}
{"id": "9363637", "url": "https://en.wikipedia.org/wiki?curid=9363637", "title": "Equivalent dumping coefficient", "text": "Equivalent dumping coefficient\n\nAn equivalent dumping coefficient is a mathematical coefficient used in the calculation of the energy dispersed when a structure moves. As a civil engineering term, it defines the \"percent of a cycle of oscillation that is absorbed (converted to heat by friction)\" for the structure or sub-structure under analysis. Usually it is assumed that the equivalent dumping coefficient is linear, which is to say invariant compare to oscillatory amplitude. Modern seismic studies have shown this not to be a satisfactory assumption for larger civic structures, and have developed sophisticated amplitude and frequency based functions for \"equivalent dumping coefficient\".\n\nWhen a building moves, the materials it is made from absorb a fraction of the kinetic energy (this is especially true of concrete) due primarily to friction and to viscous or elastomeric resistance which convert motion or kinetic energy to heat.\n"}
{"id": "17894123", "url": "https://en.wikipedia.org/wiki?curid=17894123", "title": "Extinction cross", "text": "Extinction cross\n\nThe extinction cross is an optical phenomenon that is seen when trying to extinguish a laser beam or non-planar white light using crossed polarizers. Ideally, crossed (90° rotated) polarizers block all light, since light which is polarized along the polarization axis of the first polarizer is perpendicular to the polarization axis of the second. When the beam is not perfectly collimated, however, a characteristic fringing pattern is produced.\n\n\n"}
{"id": "53099706", "url": "https://en.wikipedia.org/wiki?curid=53099706", "title": "F Orionis", "text": "F Orionis\n\nThe Bayer designation f Orionis is shared by two star systems in the constellation Orion:\n"}
{"id": "50615030", "url": "https://en.wikipedia.org/wiki?curid=50615030", "title": "Falih Rıfkı Atay Nature Park", "text": "Falih Rıfkı Atay Nature Park\n\nFalih Rıfkı Atay Nature Park () is a nature park located in Sarıyer district of Istanbul Province, Turkey. \n\nSituated northwest of Bahçeköy neighborhood of Sarıyer and next to the Neşet Suyu Nature Park, it covers an area of . It was established in 2011, and is one of the nine nature parks inside the Belgrad Forest. The protected area is named in honor of journalist, writer and politician Falih Rıfkı Atay (1894–1971).\n\nSerbs who were taken prisoners of war at the Siege of Belgrade (1521) by Ottoman sultan Suleiman the Magnificent (reigned 1520–1566), were brought to Istanbul and settled in a village, which used to lie within the park boundaries. The nature park contains the ruins of a church, which is a protected historic building and was registered as cultural heritage in November 1999.\n\nThe nature park offers outdoor recreational activities such as hiking, cycling and picnicing for visitors on daily basis. There are playgrounds for children. Admission is charged for visitors and vehicles and an open-air restaurant serves the visitors.\n\nThe nature park has rich flora and fauna.\n\nFlora\n\nThe park is the habitat for diverse species of plant. The main trees present are oak (\"Quercus robur\") and hornbeam (\"Carpinus betulus\"). Other deciduous trees include sessile oak (\"Quercus petraea\"), kasnak oak (\"Quercus vulcanica\") and shrubs are blackberry (\"Rubus plicatus\"), butcher's-broom (\"Ruscus aculeatus\"), tree heath (\"Erica arborea\") and bay laurel (\"Laurus nobilis\"). Some uncommon trees include silver linden (\"Tilia argentea\") and oriental beech (\"Fagus orientalis\"). Anatolian catbrier (\"Smilax excelsa\"), aubretia (\"Aubrieata cultorum\"), wild strawberry (\"Fragaria\") and cathip (\"Nepeta cataria\") are some of the flowering plants found in the nature park.\n\nFauna\n\nMainly observed fauna of the nature park are porcupines, squirrels, turtles, magpies, crows, woodpeckers, sparrows and finches. Across the nature park, there is a deer farm ().\n\n"}
{"id": "22812784", "url": "https://en.wikipedia.org/wiki?curid=22812784", "title": "Federation of Earth Science Information Partners", "text": "Federation of Earth Science Information Partners\n\nEarth Science Information Partners (ESIP) is a community of data and information technology practitioners that come together to coordinate Earth science interoperability efforts. Participation in ESIP allows members to enhance their data management capabilities.\n\nESIP arranges collaboration through in-person meetings and virtually through collaboration space on the Web. Partners use these forums for knowledge exchange and collaboration.\n\nCreated by NASA in 1998, the ESIP Federation was formed in response to a National Research Council recommendation calling for the involvement of community stakeholders in the development of NASA’s EOSDIS as a critical element of the U.S. Global Change Research Program (http://www.gcrio.org/USGCRP/LaJolla/cover.html). ESIP includes more than 120 member organizations. ESIP membership includes federal data centers, government research laboratories, research universities, education resource providers, technology developers, and nonprofit and commercial enterprises.\n\nESIP is a community drawn from agencies and individuals who provide handling for Earth and environmental science data and information. ESIP was founded in 1998 by NASA in response to a National Research Council (NRC) review of the Earth Observation System Data and Information System (EOSDIS). The NRC called on NASA to develop a new, distributed structure that would be operated and managed by the Earth science community that would include those responsible for all elements of Earth observation, including observation, research, and ultimately, application and education.\n\nBeginning with 24 NASA-funded partners, ESIP's purpose was to evolve methods to make Earth science data easy to preserve, locate, access and use by research, education, and commercial interests. NASA developed the ESIP Federation by starting with a set of working prototype projects called ESIPs, representing both the research and applications development communities. These prototype projects were joined by nine NASA data archive centers to form the core of the early ESIP Federation and were responsible for creating its governing structures and the collaborative community it is today.\n\nBy 2001, the ESIP Federation created a non-profit corporation called the Foundation for Earth Science (Foundation). Through a Memorandum of Understanding with the ESIP Federation, the foundation provided management support to the ESIP Federation as it moved from an operational prototype to an independent organization.\n\nIn 2002, Foundation staff were hired to support the work of the ESIP Federation. The foundation helped create operating policies for the ESIP Federation and facilitated the development of its first strategic plan, adopted by the ESIP Federation’s Assembly in 2004. NOAA’s data centers joined the ESIP Federation.\n\nBeginning in July 2007 in Madison, Wisconsin, a Strategic Planning Working Group was formed to develop a new vision of the ESIP Federation in its second decade.\n\nThe ESIP Federation’s partner organizations include all NOAA, NASA and USGS Earth observing data centers, government research laboratories, research universities, modelers, education resource providers, technology developers, nonprofits and commercial enterprises.\n\nIn 2009 and 2010 new ESIP Federation communities formed around data preservation and stewardship, information quality, and data visualization.\n\nESIP is made up of more than 110 member organizations that span NASA, NOAA, EPA, USGS and DOE research-funded groups. ESIP's partners represent earth science data and technology interests. There are four types of partners; Type I includes Data Centers, Type II are data and information product providers, Type III are commercial and non-commercial organizations that develop tools for Earth Science and Type IV are the funding providers, NASA, NOAA and USGS. A full listing of ESIP Federation Partners is at the organization's website.\n\nTechnology\n\nScience\n\nApplied science\n\n\n"}
{"id": "29013335", "url": "https://en.wikipedia.org/wiki?curid=29013335", "title": "GEOBASE", "text": "GEOBASE\n\nGEOBASE is a database, multidisciplinary in scope, which indexes bibliographic information and abstracts for the Geographical, Earth, and Ecological sciences, published by Engineering Information, a subsidiary of Elsevier. The broad subject coverage includes earth sciences, ecology, geomechanics, human geography, physical geography, social geography and oceanography. Development studies are also included in this database.\n\nCoverage includes 2000 peer reviewed journal, and trade journal titles. Other journal titles and books are included in the archival coverage of this database. With more than 2 million records, it has temporal coverage from 1980 to the present. Each year, at least 100,000 additional citations and abstracts are added, and it is updated every two weeks. Access is covered through both online (internet), and CD-ROM.\n\nOther types of publications indexed in this database are magazine articles, product reviews, directories and all related materials. International literature coverage pertains to Non-English language papers, and lesser available books, conference proceedings and reports.\n\nSubject coverage also includes cartography, hydrology, climatology, meteorology, energy, paleontology, environment, petrology, geochemistry, photogrammetry, geomorphology, sedimentology, geophysics, and volcanology.\n\nThe GEOBASE database is covered in print, in the following abstracts journals:\n\nThis database is published monthly, and contains abstracts from 2000 journals. It provides bibliographic coverage of each abstracted journal. \"Geographical Abstracts: Physical Geography\", and \"Fluid Abstracts: Civil Engineering\" are considered to be of related interest.\n\nThis database was formed by the union of the following abstracts journals: \n\nThis database is published monthly, and contains abstracts from 2000 journals. It provides bibliographic coverage of each abstracted journal.\n\n"}
{"id": "39870257", "url": "https://en.wikipedia.org/wiki?curid=39870257", "title": "Gentherm Incorporated", "text": "Gentherm Incorporated\n\nGentherm Incorporated, formerly called Amerigon, created the first thermoelectrically heated and cooled seat system for the automotive industry. Called the \"Climate Control Seat\" system, it was first adopted by the Ford Motor Company and introduced as an option on the model year 2000 Lincoln Navigator in 1999. Today it is available on more than 50 vehicles sold by Ford, General Motors, Toyota (Lexus), Kia, Hyundai, Nissan (Infinity), Range Rover and Jaguar Land Rover.\n\nThe company today is a developer and marketer of thermal management technologies for heating and cooling and temperature control devices for a variety of industries.\n\nGentherm is publicly traded on Nasdaq under the symbol THRM and is headquartered in Northville, MI. Gentherm's thermoelectric technologies are based on the Peltier Effect, the 1834 discovery that passing an electric current through a sandwich of two dissimilar metals will make them hot on one side and cold (the lack of heat) on the other.\n\nSince 2005, Gentherm has been partnering with BMW and Ford on a project that is backed by the U.S. Department of Energy focused on the development of an automotive thermoelectric generator (ATEG) that converts waste exhaust heat into electrical power based on the Seebeck Effect. A prototype of the ATEG was named one of the most promising innovations for 2012 by Car and Driver magazine.\n\nIn December 2014 the company announced that it will open a new automotive plant in Prilep, Macedonia and that will employ 1,000 people. This is Gentherm's first facility in Macedonia.\n"}
{"id": "28536264", "url": "https://en.wikipedia.org/wiki?curid=28536264", "title": "Geothermal power in Indonesia", "text": "Geothermal power in Indonesia\n\nGeothermal power in Indonesia is an increasingly significant source of renewable energy. As a result of its volcanic geology, it is often reported that Indonesia has 40% of the world's potential geothermal resources, estimated at 28,000 megawatts (MW).\n\nCurrently Indonesia is the world's third largest geothermal electricity producer after the United States and the Philippines. Installed production capacity (2011) is almost 1,200 MW from six geothermal fields in Java, North Sumatra and North Sulawesi. In 2007, geothermal energy represented 1.9% of the country's total energy supply and 3.7% of its electric power.\n\nAt the 2010 World Geothermal Congress in Bali, President Susilo Bambang Yudhoyono announced a plan to build 44 new geothermal plants by 2014, more than tripling capacity to 4,000 MW. By 2025, Indonesia aims to produce more than 9,000 MW of geothermal power, becoming the world's leading geothermal energy producer. This would account for 5% of Indonesia's total energy needs.\n\nA detailed report on the geothermal sector in Indonesia issued in 2015 by the Asian Development Bank and World Bank, \"Unlocking Indonesia's Geothermal Potential\", indicated that reforms in key areas of policy were likely to be needed to stimulate sustained expansion in the sector.\n\nThe first proposal on energy from volcanoes came in 1918 during the Dutch colonial era. In 1926, five test borings were drilled in Java's Kawah Kamojang field, the third being the first that was successful. In the early 1980s, it was still discharging superheated steam from a depth of 66 metres at a temperature of 140 °C and a pressure of 3.5 to 4 bars. A prefeasibility study for electricity generation was initiated in 1972 by Geothermal Energy New Zealand. The first generator was inaugurated in 1983 by President Suharto and subsequently expanded in 1987. Current capacity is 140 MW.\n\nSince the mid-1980s, Chevron, the world's largest geothermal power producer, has operated two geothermal fields in West Java at Salak and Darajat with a combined capacity of around 365 MW. Between 1989 and 1997 explorations were conducted at the Sibayak geothermal field in northern Sumatra, and subsequently a 12 MW plant has been placed in operation.\n\nIn 1991, the Indonesia Geothermal Association (\"Asosiasi Panasbumi Indonesia\" - API), a non-governmental organisation, was established to promote and advertise geothermal energy. It has approximately 500 members including geothermal experts, companies, and stakeholders. The Wayang Windu Geothermal Power Station in West Java, owned by British Star Energy, has been in operation since 2000. It currently comprises two units with a total capacity of 227 MW. There are plans for a third unit of 127 MW which is expected to be on-stream by mid-2013.\n\nExploration of the Bedugul Geothermal Field in Bali started in 1974 and though production capacity was estimated at 175 MW in 2008, the project is on hold after being opposed by local residents.\n\nAt the 2010 World Geothermal Congress in Bali, several companies were awarded the rights to develop geothermal fields and power plants: Golden Spike Indonesia won the tender to develop a power plant at Mount Ungaran in Central Java, Sokoria Geothermal Indonesia gained rights to develop a plant at Ende, on Flores island, while Supreme Energy was chosen to develop plants at Mount Rajabasa in Lampung and Solok in West Sumatra. These projects were estimated to require a total investment of US$1.68 billion.\n\nAs of 2010, a total of 265 potential sites for plants have been identified across the country. Development of the industry, however, involves a range of complex policy issues, some of which are proving to be a continuing source of controversy. In mid-2011, for example, the Indonesian Government issued an expected regulation providing certain guarantees for investors with the aim of encouraging increased investment in the geothermal sector. However, investor response was guarded, suggesting that key aspects had not been addressed in the regulation.\n\nIn late 2013, PT Pertamina Geothermal Energy (PGE) -- a geothermal business branch of state oil and gas company PT Pertamina—said that it planned to develop eight new geothermal plants with a total capacity of 655 MW (expected to require $2.0 bn of new investments). These included:\n\nOf these, several were to be financed with loans from World Bank and Japan International Cooperation Agency.\n\nIn addition, work is starting on the Sarulla geothermal plant in North Sumatra with a total planned capacity of 320 MW. The plant has been on the books since the early 1990s but development was stalled over various issues. The plant, expected to cost around $1.65 billion, will be built with financial support from the Asian Development Bank along with the Japan Bank for International Cooperation and other lenders. The first 110 MW started in 2017.\n\nAccording to the Renewable Energy Policy Network's \"Renewables 2013 Global Status Report\", Indonesia has the third largest installed generating capacity in the world in the geothermal sector. With 1.3 GW installed capacity, Indonesia trails only the United States (3.4 GW) and the Philippines (1.9 GW). However it leads Mexico (1.0 GW), Italy (0.9 GW), New Zealand (0.8 GW), Iceland (0.7 GW), and Japan (0.5 GW).\n\nIn recent years, the Indonesian Government has announced plans for two 'fast-track' increases in the total capacity of Indonesia's electricity generation network of 10,000 MW each. Under the second 10,000 MW fast-track plan it was forecast that a relatively large share of 3,970 MW would be installed in geothermal plants. But under the first 10,000 MW fast-track plan, investment in the geothermal sector appears to be lagging.\n\n\nExpansion in the sector appears to be being held back by a range of factors including an uncertain regulatory environment (including, especially, uncertainty over land laws) and the perceived risks of development. The Indonesian Government's plans for development of the geothermal sector rely largely on private sector investment. But numerous reports indicate that private sector investors are concerned about a range of risks including technical (geological) risks, regulatory risks stemming from uncertain government policy, and financial risks arising from the pricing policies determined by the Indonesian Government. For example, coal has been indirectly subsidised through the Domestic Market Obligation policy, which requires coal companies to sell at a government-specified, subsidised rate to the national utility. By comparison, geothermal power has enjoyed relatively unfavourable tender processes and is sold at higher prices. This makes it difficult for geothermal plants to compete with conventional fuels.\n\nThere is disagreement within the Indonesian Government as to how to mitigate risks or, where that is not possible, who should bear these risks. Policy makers in the power sector, with an eye to meeting the government's official investment targets, are often inclined to the view that at least some of the risks should be borne by the Indonesian Government through the national budget managed by the Ministry of Finance. Official policy from the Ministry of Finance has traditionally been cautious, resisting the suggestion that unspecified risks should be borne by the Indonesian budget.\n\nIn response to reports about certain of the risks that private sector investors were concerned about, in mid-2011 the government issued a regulation intended to provide guarantees that the state electricity utility PLN would meet financial obligations to independent power producers (IPPs) who invested in the geothermal sector. But the regulation was quickly criticised by representatives of private investors as being too limited and for failing to clarify important concerns.\n\nPricing policy\n\nPrices have been another important policy issue in the sector. In an effort to encourage private sector investment, the Indonesian government has been establishing a feed-in tariff scheme by instructing state electricity utility PLN to purchase power from geothermal projects at various rates ranging from around 6.5 US cents to over 12 US cents per kWh. The government is also preparing a regulation that is expected to specify the price that the PLN must purchase power from geothermal plans in the second 10,000 MW fast-track electricity sector program which the government has announced; this regulation is expected to be finalised by early 2012.\n\nAccording to the Ministry of Forestry, around 80% of geothermal reserves are located in designated conserved forest areas. The 2009 mineral and coal mining law lists geothermal exploration as a mining activity so a presidential decree would be required to allow geothermal activities conserved forest areas. According to the ministry, geothermal mining is unlikely to cause environmental harm. In May 2011 the Indonesian government imposed a two-year moratorium on logging. However this excepts the energy sector, including geothermal activities.\n\n\n"}
{"id": "55397", "url": "https://en.wikipedia.org/wiki?curid=55397", "title": "Hadean", "text": "Hadean\n\nThe Hadean () is a geologic eon of the Earth predating the Archean. It began with the formation of the Earth about 4.6 billion years ago and ended, as defined by the ICS, 4 billion years ago. , the ICS describes its status as \"informal\". Geologist Preston Cloud coined the term in 1972, originally to label the period before the earliest-known rocks on Earth. W. Brian Harland later coined an almost synonymous term, the \"Priscoan period\", from \"priscus\", the Latin word for \"ancient\". Other, older texts simply refer to the eon as the Pre-Archean.\n\n\"Hadean\" (from Hades, the Greek god of the underworld, and the underworld itself) describes the hellish conditions then prevailing on Earth: the planet had just formed and was still very hot owing to its recent accretion, the abundance of short-lived radioactive elements, and frequent collisions with other Solar System bodies.\n\nSince few geological traces of this eon remain on Earth, there is no official subdivision. However, the Lunar geologic timescale embraces several major divisions relating to the Hadean, so these are sometimes used in an informal sense to refer to the same periods of time on Earth.\n\nThe Lunar divisions are:\n\nIn 2010, an alternative scale was proposed that includes the addition of the Chaotian and Prenephelean Eons preceding the Hadean, and divides the Hadean into three eras with two periods each. The Paleohadean era consists of the Hephaestean () and the Jacobian periods (). The Mesohadean is divided into the Canadian () and the Procrustean periods (). The Neohadean is divided into the Acastan () and the Promethean periods (). , this has not been adopted by the IUGS.\n\nIn the last decades of the 20th century geologists identified a few Hadean rocks from Western Greenland, Northwestern Canada, and Western Australia. In 2015, traces of carbon minerals interpreted as \"remains of biotic life\" were found in 4.1-billion-year-old rocks in Western Australia.\n\nThe oldest dated zircon crystals, enclosed in a metamorphosed sandstone conglomerate in the Jack Hills of the Narryer Gneiss Terrane of Western Australia, date to 4.404 ± 0.008 Ga. This zircon is a slight outlier, with the oldest consistently-dated zircon falling closer to 4.35 Ga—around 200 million years after the hypothesized time of the Earth's formation.\n\nIn many other areas, xenocryst (or relict) Hadean zircons enclosed in older rocks indicate that younger rocks have formed on older terranes and have incorporated some of the older material. One example occurs in the Guiana shield from the Iwokrama Formation of southern Guyana where zircon cores have been dated at 4.22 Ga.\n\nA sizeable quantity of water would have been in the material that formed the Earth. Water molecules would have escaped Earth's gravity more easily when it was less massive during its formation. Hydrogen and helium are expected to continually escape (even to the present day) due to atmospheric escape.\nPart of the ancient planet is theorized to have been disrupted by the impact that created the Moon, which should have caused melting of one or two large regions of the Earth. Earth's present composition suggests that there was not complete remelting as it is difficult to completely melt and mix huge rock masses. However, a fair fraction of material should have been vaporized by this impact, creating a \"rock vapor atmosphere\" around the young planet. The rock vapor would have condensed within two thousand years, leaving behind hot volatiles which probably resulted in a heavy atmosphere with hydrogen and water vapor. Liquid water oceans existed despite the surface temperature of because at an atmospheric pressure of above 27 atmospheres, caused by the heavy atmosphere, water is still liquid. As cooling continued, subduction and dissolving in ocean water removed most from the atmosphere but levels oscillated wildly as new surface and mantle cycles appeared.\n\nStudies of zircons have found that liquid water must have existed as long ago as 4.4 billion years ago, very soon after the formation of the Earth. This requires the presence of an atmosphere. The cool early Earth theory covers a range from about 4.4 to about 4.1 billion years.\n\nA September 2008 study of zircons found that Australian Hadean rock holds minerals pointing to the existence of plate tectonics as early as 4 billion years.\nIf this is true, the time when Earth finished its transition from having a hot, molten surface and atmosphere full of carbon dioxide, to being very much like it is today, can be roughly dated to about 4.0 billion years ago. The actions of plate tectonics and the oceans trapped vast amounts of carbon dioxide, thereby reducing the greenhouse effect and leading to a much cooler surface temperature and the formation of solid rock, and possibly even life.\n\n\n"}
{"id": "21244416", "url": "https://en.wikipedia.org/wiki?curid=21244416", "title": "Hypergiant", "text": "Hypergiant\n\nA hypergiant (luminosity class 0 or Ia) is among the very rare kinds of stars that typically show tremendous luminosities and very high rates of mass loss by stellar winds. The term \"hypergiant\" is defined as luminosity class 0 (zero) in the MKK system. However, this is rarely seen in the literature or in published spectral classifications, except for specific well-defined groups such as the yellow hypergiants, RSG (red supergiants), or blue B(e) supergiants with emission spectra. More commonly, hypergiants may be classed as Ia-0 or Ia, but red supergiants are rarely assigned these spectral classifications. Astronomers are mostly interested in these stars because they relate to understanding stellar evolution, especially with star formation, stability, and their expected demise as supernovae. \n\nIn 1956, the astronomers Feast and Thackeray used the term \"super-supergiant\" (later changed into hypergiant) for stars with an absolute magnitude brighter than \"M\" = −7 (\"M\" will be larger for very cool and very hot stars, for example at least −9.7 for a B0 hypergiant). In 1971, Keenan suggested that the term would be used only for supergiants showing at least one broad emission component in Hα, indicating an extended stellar atmosphere or a relatively large mass loss rate. The Keenan criterion is the one most commonly used by scientists today. \n\nObservation of a highly luminous star is insufficient for it to be defined as a hypergiant. That requires the detection of the spectral signatures of atmospheric instability and high mass loss. So it is quite possible for non-hypergiant supergiant stars to have the same or higher luminosity as a hypergiant of the same spectral class. Additionally, hypergiants are expected to have characteristic broadening and red-shifting of their spectral lines producing a distinctive shape known as a P Cygni profile. The use of hydrogen emission is not helpful for defining the coolest hypergiants, and these are largely classified on luminosity since mass loss is almost inevitable for the class.\n\nStars with an initial mass above about quickly move away from the main sequence and increase somewhat in luminosity to become blue supergiants. They cool and enlarge at approximately constant luminosity to become a red supergiant, then contract and increase in temperature as the outer layers are blown away. They may \"bounce\" backwards and forwards executing one or more \"blue loops\", still at a fairly steady luminosity, until they explode as a supernova or completely shed their outer layers to become a Wolf–Rayet star. Stars with an initial mass above about are simply too luminous to develop a stable extended atmosphere and so they never cool sufficiently to become red supergiants. The most massive stars, especially rapidly rotating stars with enhanced convection and mixing, may skip these steps and move directly to the Wolf–Rayet stage.\n\nThis means that stars at the top of the Hertzsprung–Russell diagram where hypergiants are found may be newly evolved from the main sequence and still with high mass, or much more evolved post-red supergiant stars that have lost a significant fraction of their initial mass, and these objects cannot be distinguished simply on the basis of their luminosity and temperature. High-mass stars with a high proportion of remaining hydrogen are more stable, while older stars with lower masses and a higher proportion of heavy elements have less stable atmospheres due to increased radiation pressure and decreased gravitational attraction. These are thought to be the hypergiants, near the Eddington limit and rapidly losing mass.\n\nThe yellow hypergiants are thought to be generally post-red supergiant stars that have already lost most of their atmospheres and hydrogen. A few more stable high mass yellow supergiants with approximately the same luminosity are known and thought to be evolving towards the red supergiant phase, but these are rare as this is expected to be a rapid transition. Because yellow hypergiants are post-red supergiant stars, there is a fairly hard upper limit to their luminosity at around , but blue hypergiants can be much more luminous, sometimes several million .\n\nAlmost all hypergiants exhibit variations in luminosity over time due to instabilities within their interiors, but these are small except for two distinct instability regions where luminous blue variables (LBVs) and yellow hypergiants are found. Because of their high masses, the lifetime of a hypergiant is very short in astronomical timescales: only a few million years compared to around 10 billion years for stars like the Sun. Hypergiants are only created in the largest and densest areas of star formation and because of their short lives, only a small number are known despite their extreme luminosity that allows them to be identified even in neighbouring galaxies. The time spent in some phases such as LBVs can be as short as a few thousand years.\n\nAs the luminosity of stars increases greatly with mass, the luminosity of hypergiants often lies very close to the Eddington limit, which is the luminosity at which the radiation pressure expanding the star outward equals the force of the star's gravity collapsing the star inward. This means that the radiative flux passing through the photosphere of a hypergiant may be nearly strong enough to lift off the photosphere. Above the Eddington limit, the star would generate so much radiation that parts of its outer layers would be thrown off in massive outbursts; this would effectively restrict the star from shining at higher luminosities for longer periods.\n\nA good candidate for hosting a continuum-driven wind is Eta Carinae, one of the most massive stars ever observed. With an estimated mass of around 130 solar masses and a luminosity four million times that of the Sun, astrophysicists speculate that Eta Carinae may occasionally exceed the Eddington limit. The last time might have been a series of outbursts observed in 1840–1860, reaching mass loss rates much higher than our current understanding of what stellar winds would allow.\n\nAs opposed to line-driven stellar winds (that is, ones driven by absorbing light from the star in huge numbers of narrow spectral lines), continuum driving does not require the presence of \"metallic\" atoms — atoms other than hydrogen and helium, which have few such lines — in the photosphere. This is important, since most massive stars also are very metal-poor, which means that the effect must work independently of the metallicity. In the same line of reasoning, the continuum driving may also contribute to an upper mass limit even for the first generation of stars right after the Big Bang, which did not contain any metals at all.\n\nAnother theory to explain the massive outbursts of, for example, Eta Carinae is the idea of a deeply situated hydrodynamic explosion, blasting off parts of the star's outer layers. The idea is that the star, even at luminosities below the Eddington limit, would have insufficient heat convection in the inner layers, resulting in a density inversion potentially leading to a massive explosion. The theory has, however, not been explored very much, and it is uncertain whether this really can happen.\n\nAnother theory associated with hypergiant stars is the potential to form a pseudo-photosphere, that is a spherical optically dense surface that is actually formed by the stellar wind rather than being the true surface of the star. Such a pseudo-photosphere would be significantly cooler than the deeper surface below the outward-moving dense wind. This has been hypothesized to account for the \"missing\" intermediate-luminosity LBVs and the presence of yellow hypergiants at approximately the same luminosity and cooler temperatures. The yellow hypergiants are actually the LBVs having formed a pseudo-photosphere and so apparently having a lower temperature.\n\nHypergiants are evolved, high luminosity, high-mass stars that occur in the same or similar regions of the HR diagram to stars with different classifications. It is not always clear whether the different classifications represent stars with different initial conditions, stars at different stages of an evolutionary track, or is just an artifact of our observations. Model details vary but there are many areas of agreement. Some of these distinctions are not necessarily helpful in establishing relationships between different types of stars or the differences between them since they have been developed based on differing criteria and for different purposes.\n\nAlthough most supergiant stars are less luminous than hypergiants of the same temperature, a few fall in the same luminosity range. Ordinary supergiants lack the strong H emission and broadened spectral lines that indicate rapid mass loss in the hypergiants. Lower mass supergiants do not return from the red supergiant phase, either exploding as supernovae or leaving behind a white dwarf.\n\nLuminous blue variables are a class of highly luminous hot stars that display characteristic spectral variation. They often lie in a \"quiescent\" zone with hotter stars generally being more luminous, but periodically undergo large surface eruptions and move to a narrow zone where stars of all luminosities have approximately the same temperature, around 8,000K. This \"active\" zone is near the hot edge of the unstable \"void\" where yellow hypergiants are found, with some overlap. It is not clear whether yellow hypergiants ever manage to get past the instability void to become LBVs or explode as a supernova.\n\nBlue hypergiants are found in the same parts of the HR diagram as LBVs but do not necessarily show the LBV variations. Some but not all LBVs show the characteristics of hypergiant spectra at least some of the time, but many authors would exclude all LBVs from the hypergiant class and treat them separately. Blue hypergiants that do not show LBV characteristics may be progenitors of LBVs, or vice versa, or both. Lower mass LBVs may be a transitional stage to or from cool hypergiants or are different type of object.\n\nWolf–Rayet stars are extremely hot stars that have lost much or all of their outer layers. WNL is a term used for late stage (i.e. cooler) Wolf–Rayet stars with spectra dominated by nitrogen. Although these are generally thought to be the stage reached by hypergiant stars after sufficient mass loss, it is possible that a small group of hydrogen-rich WNL stars are actually progenitors of blue hypergiants or LBVs. These are the closely related Ofpe (O-type spectra plus H, He, and N emission lines, and other peculiarities) and WN9 (the coolest nitrogen Wolf–Rayet stars) which may be a brief intermediate stage between high mass main-sequence stars and hypergiants or LBVs. Quiescent LBVs have been observed with WNL spectra and apparent Ofpe/WNL stars have changed to show blue hypergiant spectra. High rotation rates cause massive stars to shed their atmospheres quickly and prevent the passage from main sequence to supergiant, so these directly become Wolf–Rayet stars. Wolf Rayet stars, slash stars, cool slash stars (aka WN10/11), Ofpe, Of, and Of stars are not considered hypergiants. Although they are luminous and often have strong emission lines, they have characteristic spectra of their own.\n\nHypergiants are difficult to study due to their rarity. Many hypergiants have highly variable spectra, but they are grouped here into broad spectral classes.\n\nSome luminous blue variables are classified as hypergiants, during at least part of their cycle of variation:\n\nUsually B-class, occasionally late O or early A:\n\nIn Galactic Center Region:\n\nIn Westerlund 1:\nYellow hypergiants with late A -K spectra.\n\n\nIn Westerlund 1:\nPlus at least two probable cool hypergiants in the recently discovered Scutum Red Supergiant Clusters: F15 and possibly F13 in RSGC1 and Star 49 in RSGC2.\n\nM type spectra, the largest known stars.\n\nA survey expected to capture virtually all Magellanic Cloud red hypergiants detected around a dozen M class stars M−7 and brighter, around a quarter of a million times more luminous than the Sun, and from about 1,000 times the radius of the Sun upwards.\n\n"}
{"id": "33490510", "url": "https://en.wikipedia.org/wiki?curid=33490510", "title": "ISO 6943", "text": "ISO 6943\n\nISO 6943 is a specification created by the International Organisation for Standardisation for a method in determining the tension fatigue of vulcanised rubber.\n"}
{"id": "10958224", "url": "https://en.wikipedia.org/wiki?curid=10958224", "title": "International Geoscience Programme", "text": "International Geoscience Programme\n\nThe International Geoscience and Geoparks Programme (IGCP) is a cooperative enterprise of UNESCO (the United Nations Educational, Scientific and Cultural Organization) and the International Union of Geological Sciences (IUGS).\n\nIt was launched in 1972 and originally termed the \"International Geological Correlation Programme\", the source of the acronym IGCP which it retains. For decades the programme was known as the \"International Geoscience Programme\". In November 2015 the name was changed to \"International Geoscience and Geoparks Programme\" as the global geoparks were made part of the programme.\n\nThe aim of the IGCP is to facilitate research cooperation among geoscientists across frontiers and national boundaries, through joint research work, meetings and workshops. At the present time IGCP has about 400 active projects involving thousands of scientists from about 150 countries.\n"}
{"id": "53465035", "url": "https://en.wikipedia.org/wiki?curid=53465035", "title": "Kalamos Island biological field station", "text": "Kalamos Island biological field station\n\nThe Kalamos Island biological field station is a research station located in the island Kalamos, in the Ionian Sea, in Western Greece. It is situated in the core of the inner Ionian marine protected area, site GR22220003 of the Natura 2000 network. The marine area is additionally protected under the Agreement on the Conservation of Cetaceans of the Black Sea, Mediterranean Sea and contiguous Atlantic area (ACCOBAMS).\n\nThe station is a base for year-round research activities in ecology, ecosystem management and sustainability issues such as permaculture. It was created as part of the Kalamos and Kastos sustainable development program of Terra Sylvestris, a non-governmental non profit organization that established the program in order to bring about sustainable development through rewilding in the area of the Island of Kalamos, Kastos and adjacent smaller islands and their marine environment.\n\nThe station conducts and facilitates a wide variety of research projects, ranging from biodiversity conservation to environmental justice to permaculture. The biological field station is also the base for the volunteer and internship programs of Terra Sylvestris, which enables people from all over the world to participate in the activities of Terra Sylvestris in the area and specifically the biological field station. The station is a member of the Organization of Biological Field Stations and the Global Ecovillage Network. The research station provides facilities for students as well as other visiting researchers and practitioners in the fields of ecology and biodiversity conservation to participate in or conduct projects in scientific research, ecosystem monitoring and ecosystem management.\n\n"}
{"id": "55179161", "url": "https://en.wikipedia.org/wiki?curid=55179161", "title": "Karaekşi Nature Park", "text": "Karaekşi Nature Park\n\nKaraekşi Nature Park ( or more formally, Karaekşi Nature Park and Trout Hatchery ) is a nature park in Mersin Province, Turkey\n\nThe nature park situated in Hacınuhlu village of Mut ilçe (district) in Mersin Province at . Its distance to Mut is about . It was declared a nature park by the Ministry of Forest and Water Management in 2011. It covers an area of . The park is in a forest of plane trees and Turkish pines. It stretches along a creek flowing into Göksu River. There are trout ponds, restaurants ,children parks, a parking lot etc. in Karaekşi.\n"}
{"id": "12391596", "url": "https://en.wikipedia.org/wiki?curid=12391596", "title": "Kathleen McArthur", "text": "Kathleen McArthur\n\nKathleen McArthur (1915–2000), was an Australian naturalist, writer, botanical illustrator and conservationist. She was born in Brisbane, Queensland to Catherine and Daniel Evans. Her mother was a daughter of the Durack pastoral family, her father a co-founder of an engineering firm. She married Malcolm McArthur in 1938 and had three children before divorcing in 1947. From 1942 she lived at Caloundra on the Sunshine Coast of Queensland.\n\nMcArthur was a strong environmentalist and a co-founder, with Judith Wright, David Fleay and Brian Clouston, of the Wildlife Preservation Society of Queensland in 1962, and served as vice-president from then until 1965. In 1963 she founded the Caloundra branch of the society.\n\nShe was involved in several campaigns during the 1960s and 1970s to preserve landscapes threatened by economic development, including the Pumicestone Passage, the Great Barrier Reef and Cooloola. Much campaign work was funded through her growing and selling native plants as well as through exhibitions of her wildflower paintings. She was especially concerned for the Wallum country of south-eastern Queensland, a habitat characterised by floristically-rich coastal heath and swamps on deep sandy soils.\n\nThe spider, \"Ozicrypta mcarthurae\", was named after her for her outstanding contribution to conservation. In 1996 she was awarded an honorary doctorate by James Cook University of North Queensland.\n\nMcArthur wrote a weekly column, \"Wildlife and Landscape\", for her local paper. She also started the Lunch Hour Theatre in Caloundra, a monthly event for which she wrote scripts based on environmental, biographical and historical subjects. Books authored (and illustrated) by McArthur include:\n\n\n"}
{"id": "2001135", "url": "https://en.wikipedia.org/wiki?curid=2001135", "title": "Lacus Doloris", "text": "Lacus Doloris\n\nLacus Doloris (Latin for \"Lake of Sorrow\") is a small lunar mare located in the Terra Nivium region at 17.1° N, 9.0° E. It is 110 km in diameter.\n\n"}
{"id": "58731925", "url": "https://en.wikipedia.org/wiki?curid=58731925", "title": "List of Birketts", "text": "List of Birketts\n\nBirketts are the 541 English peaks described in Bill Birkett's 1994 guidebook, \"Complete Lakeland Fells\". The author defined them as all hills within the boundary of the Lake District National Park in Cumbria which are over in height.\n\nBill Birkett's book became a popular list for peak bagging in the Lake District, along with the equally popular Wainwrights. Because both lists are based on historical books, unlike for example the Murdos, their constituents remain fixed, regardless of revisions to height or other metrics. In this regard, they are similar to the Scottish lowlands, Donalds. The Long Distance Walkers Association maintains a register of people who have completed the Birketts. One of Birkett's peaks, Pillar Rock, which is also classed as a Nuttall, but not a Wainwright, requires climbing ropes and climbing equipment to summit.\n\nThere are 541 Birketts, which include 209 of the 214 Wainwrights, and 59 of the 116 Wainwright Outlying Fells. Birketts range from hills, such as the smallest Birkett, Great Stickle, at , to major mountains in the British Isles, such as Scafell Pike, at just over . While 65 of the Birketts have a prominence above , and are Marilyns, 159 have a prominence below , and 42 of these are below . 54 of the 514 peaks are solely Birketts, and meet no other mountain or hill classification in the British Isles.\n\nThis list is from the \"Database of British and Irish Hills\" (\"DoBIH\") in October 2018, and are peaks the DoBIH marks as being Birketts (\"B\"). The DoBIH updates their measurements as more surveys are recorded, so these tables should not be amended or updated unless the entire DoBIH data is re–downloaded again.\n\nThis list is from the \"Database of British and Irish Hills\" (\"DoBIH\") in October 2018, and are five Lake District peaks the DoBIH marks as being Wainwrights (\"W\"), but not Birketts (\"B\"). The DoBIH updates their measurements as more surveys are recorded, so these tables should not be amended or updated unless the entire DoBIH data is re-downloaded again.\n\nThe DoBIH uses the following codes for the various classifications of mountains and hills in the British Isles, which many of the above peaks also fall into:\n<br>\n\nsuffixes:<br>\n= twin\n\n\n"}
{"id": "1430471", "url": "https://en.wikipedia.org/wiki?curid=1430471", "title": "List of Hieracium species", "text": "List of Hieracium species\n\nThe genus Hieracium is a very large genus of flowering plants in the sunflower family (Asteraceae).\n\nThe database IPNI gives more than 12,100 named taxa, including subspecies and synonyms.\n\nThe following list consists of about 1,000 accepted species and cited synonyms. Bold for endangered species.\n\nA more detailed discussion is given in the article \"Hieracium\".\n\n\n\n"}
{"id": "4410971", "url": "https://en.wikipedia.org/wiki?curid=4410971", "title": "List of Lepidoptera that feed on Cirsium", "text": "List of Lepidoptera that feed on Cirsium\n\nCirsium thistle species are used as food plants by the larvae of some Lepidoptera species, including:\n\n\n"}
{"id": "1758281", "url": "https://en.wikipedia.org/wiki?curid=1758281", "title": "List of countries by carbon dioxide emissions per capita", "text": "List of countries by carbon dioxide emissions per capita\n\nThis is a list of countries by carbon dioxide emissions per capita from 1990 through 2011. All data were calculated by the US Department of Energy's Carbon Dioxide Information Analysis Center (CDIAC), mostly based on data collected from country agencies by the United Nations Statistics Division. Countries are ranked by their metric tonnes of carbon dioxide emissions per capita in 2009. The data only consider carbon dioxide emissions from the burning of fossil fuels and cement manufacture, but not emissions from land use such as deforestation. Emissions from international shipping or bunker fuels are also not included in national figures, which can make a significant difference for small countries with important ports.\n\nThe carbon dioxide emissions of a country are only an indicator of one greenhouse gas. For a more complete idea of how a country influences climate change, gases such as methane and nitrous oxide should be taken into account. This is particularly so in agricultural economies.\n\nCarbon dioxide emissions are also known for earlier periods. A study of a global sample of twelve countries provide estimates for emissions since 1800 and explores the long-run drivers of carbon dioxide emissions by decomposing changes in carbon emissions into population, income, technological and energy mix changes.\n\n\nSource: United Nations Millennium Development Goals Indicators (accessed 27 September 2012).\n\n"}
{"id": "26466468", "url": "https://en.wikipedia.org/wiki?curid=26466468", "title": "List of dragons in games", "text": "List of dragons in games\n\nThis is a list of dragons in games. If there are many dragons then only the most notable are mentioned.\n\nGuide to Roles:\n\n\nFantasy card games often feature dragons, often many of them, and thus this sub-section only mentions the more popular or important ones.\nDragon is a creature subtype in .\n\n\nDragon is also a monster type in the Yu-Gi-Oh! Trading Card Game. Dragons in Yu-Gi-Oh! include:\n\nSeveral races and clans within the Cardfight!! Vanguard Trading Card Game are heavily based around dragons. A few of the races that are based on dragons include:\n\n\n\n\n"}
{"id": "2641255", "url": "https://en.wikipedia.org/wiki?curid=2641255", "title": "List of mountains on Mars by height", "text": "List of mountains on Mars by height\n\nThis is a list of mountains on Mars by height above mean surface level. The listed elevations are relative to the Martian datum (the elevation defined as zero by average martian atmospheric pressure and planet radius). Elevation is \"not\" the height above the surrounding terrain.\n\n\nNotable extreme elevations on Earth and Venus are included (in bold and \"Italics\") for comparison, where the given elevations are relative to mean sea level.\n\n\n\n"}
{"id": "58695566", "url": "https://en.wikipedia.org/wiki?curid=58695566", "title": "List of pipeline accidents in the United States in 2016", "text": "List of pipeline accidents in the United States in 2016\n\nThe following is a list of pipeline accidents in the United States in 2016. It is one of several lists of U.S. pipeline accidents. See also list of natural gas and oil production accidents in the United States.\n\nThis is not a complete list of all pipeline accidents. For natural gas alone, the Pipeline and Hazardous Materials Safety Administration (PHMSA), a United States Department of Transportation agency, has collected data on more than 3,200 accidents deemed serious or significant since 1987.\n\nA \"significant incident\" results in any of the following consequences:\n\nPHMSA and the National Transportation Safety Board (NTSB) post incident data and results of investigations into accidents involving pipelines that carry a variety of products, including natural gas, oil, diesel fuel, gasoline, kerosene, jet fuel, carbon dioxide, and other substances. Occasionally pipelines are repurposed to carry different products.\n\n"}
{"id": "15501978", "url": "https://en.wikipedia.org/wiki?curid=15501978", "title": "List of waves named after people", "text": "List of waves named after people\n\nThis is a list of waves named after people (eponymous waves).\n"}
{"id": "10501328", "url": "https://en.wikipedia.org/wiki?curid=10501328", "title": "Maliades", "text": "Maliades\n\nIn Greek mythology the Maliades or Meliades are three types of Nymph.\n\n1. The Maliades, another name for the Epimeliads\n\n2. The Meliads, another name for the Meliae.\n\n3. The Maliades, the name for the naiads of the river Spercheios on mount Othrys in Malis. Also known as Spercheides. They were the daughters of Zeus or of the river-god Spercheios and Deino.\n"}
{"id": "4414442", "url": "https://en.wikipedia.org/wiki?curid=4414442", "title": "Masao Kawai", "text": "Masao Kawai\n\n"}
{"id": "1184778", "url": "https://en.wikipedia.org/wiki?curid=1184778", "title": "National Bamboo Project of Costa Rica", "text": "National Bamboo Project of Costa Rica\n\nThe National Bamboo Project of Costa Rica was established in 1986 with the dual aims of reducing deforestation by means of replacing timber with bamboo as a primary building material and providing low cost housing for Costa Rica's rural poor. By cultivating and building with an indigenous form of giant bamboo called Guadua, the National Bamboo Project was able to raise thousands of new homes for the poor, benefit the environment, and advance bamboo-based building technology. \n\nIn 1995, the National Bamboo Project was handed over to the FUNBAMBU Foundation to maintain and continue the project's mission of creating low-cost bamboo housing.\n\n"}
{"id": "24056954", "url": "https://en.wikipedia.org/wiki?curid=24056954", "title": "Pola (festival)", "text": "Pola (festival)\n\nPola is a bull-respecting festival celebrated by farmers mainly in the Indian state of Chhattisgarh and Maharashtra,Northern parts of Telangana as Polala Amavasya (పొలాల అమావాస్య). On the day of Pola, the farmers decorate and respect their bulls. Pola falls on the day of the \"Pithori Amavasya\" (the new moon day) in the month of Shravana (usually in August).\n\nPola is mainly a farmer's festival, wherein farmers respect their bulls and oxe, to thank them for their support in farming. It occurs after the monsoon sowing and field work, typically in late August or early September. On the day of Pola, the bulls are first given a bath, and then decorated with ornaments and shawls. Their horns are painted, and their necks are adorned with garlands of flowers. The bulls do not work that day, and they are part of procession where farmers celebrate the crop season.\n\nThe work of decorated bulls, accompanied by the music and dancing, are carried out in the evenings. The first bullock to go out is an old bullock with a wooden frame (called \"makhar\") tied on its horns. This bullock is made to break a rope of mango leaves stretched between two posts, and is followed by all the other cattle in the village.\n\nThe festival is found among Marathas in central and eastern Maharashtra. A similar festival is observed by Hindus in other parts of India, and is called \"Mattu Pongal\" in south and \"Godhan\" in north and west India.\n"}
{"id": "2467376", "url": "https://en.wikipedia.org/wiki?curid=2467376", "title": "Rock Creek (California)", "text": "Rock Creek (California)\n\nRock Creek (California) may refer to:\n\n\n"}
{"id": "56710028", "url": "https://en.wikipedia.org/wiki?curid=56710028", "title": "Rydberg polaron", "text": "Rydberg polaron\n\nA Rydberg polaron is an exotic state of matter, created at low temperatures, in which a very large atom contains other ordinary atoms in the space between the nucleus and the electrons. For the formation of this atom, scientists had to combine two fields of atomic physics: Bose-Einstein condensates and Rydberg atoms. Rydberg atoms are formed by exciting a single atom into a high-energy state, in which the electron is very far from the nucleus. Bose-Einstein condensates are a state of matter that is produced at temperatures close to absolute zero. \n\nPolarons are induced by using a laser to excite Rydberg atoms contained as impurities in a Bose-Einstein condensate. In those Rydberg atoms, the average distance between the electron and its nucleus can be as large as several hundred nanometres, which is more than a thousand times the radius of a hydrogen atom. Under that circumstances, the distance between the nucleus and the electron of the excited Rydberg atoms is higher than the average distance of the atoms of the condensate. As a result, some atoms lie inside the orbit of the Rydberg atom's electron. \n\nAs the atoms don't have an electric charge, they only produce a minimal force on the electron. However, the electron is slightly scattered at the neutral atoms, without even leaving its orbit, and the weak bond that is generated between the Rydberg atom and the atoms inside of it, tying them together, is known as the Rydberg Polaron. The new state of matter was predicted by theorists at Harvard University in 2016 and confirmed in 2018 by spectroscopy in an experiment using a strontium Bose-Einstein condensate. Theoretically, up to 170 ordinary strontium atoms could fit closely inside the new orbital of the Rydberg atom, depending on the radius of the Rydberg atom and the density of the Bose-Einstein condensate. The theoretical work for the experiment was performed by theorists at Vienna University of Technology and Harvard University, while the actual experiment and observation took place at Rice University in Houston, Texas. \n\n\n"}
{"id": "27068", "url": "https://en.wikipedia.org/wiki?curid=27068", "title": "Sahara Desert (ecoregion)", "text": "Sahara Desert (ecoregion)\n\nThe Sahara Desert ecoregion, as defined by the World Wide Fund for Nature (WWF), includes the hyper-arid center of the Sahara, between 18° and 30° N. It is one of several desert and xeric shrubland ecoregions that cover the northern portion of the African continent.\n\nThe Sahara Desert is the world's largest hot desert, located in North Africa. It stretches from the Red Sea to the Atlantic Ocean. The vast desert encompasses several ecologically distinct regions. The Sahara Desert ecoregion covers an area of in the hot, hyper-arid center of the Sahara, surrounded on the north, south, east, and west by desert ecoregions with higher rainfall and more vegetation.\n\nThe North Saharan steppe and woodlands ecoregion lies to the north and west, bordering the Mediterranean climate regions of Africa's Mediterranean and North Atlantic coasts. The North Saharan steppe and woodlands receives more regular winter rainfall than the Sahara Desert ecoregion. The South Saharan steppe and woodlands ecoregion lies to the south, between the Sahara Desert ecoregion and the Sahel grasslands. The South Saharan steppe and woodlands receives most of its annual rainfall during the summer. The Red Sea coastal desert lies in the coastal strip between the Sahara Desert ecoregion and the Red Sea.\n\nSome mountain ranges rise up from the desert and receive more rainfall and cooler temperatures. These Saharan mountains are home to two distinct ecoregions; the West Saharan montane xeric woodlands in the Ahaggar, Tassili n'Ajjer, Aïr, and other ranges in the western and central Sahara Desert, and the Tibesti-Jebel Uweinat montane xeric woodlands in the Tibesti and Jebel Uweinat of the eastern Sahara.\n\nThe surface of the desert ranges from large areas of sand dunes (erg), to stone plateaus (hamadas), gravel plains (reg), dry valleys (wadis), and salt flats. The only permanent river that crosses the ecoregion is the Nile River, which originates in central Africa and empties northwards into the Mediterranean Sea. Some areas encompass vast underground aquifers resulting in oases, while other regions severely lack water reserves.\nThe Sahara Desert features a hot desert climate (Köppen climate classification \"BWh\"). The Sahara Desert is one of the driest and hottest regions of the world, with a mean temperature sometimes over and the average high temperatures in summer are over for months at a time, and can even soar to . In desert rocky mountains such as the Tibesti in Libya or the Hoggar in Algeria, average highs in summer are slightly moderated by the high elevation and are between at elevation. Daily variations may also be extreme: a swing from has been observed. Typical temperature swings are between .\n\nPrecipitation in the Sahara Desert is scarce, as the whole desert generally receives less than of rain per year except on the northernmost and southernmost edge as well as in the highest desert mountains. More than half of the desert area is hyper-arid and virtually rainless, with an average annual precipitation below and many consecutive years may pass without any rainfall. The south of the Sahara Desert, along the boundary with the hot semi-arid climate (\"BSh\") of the Sahel, receives most of its annual rainfall during the highest-sun months (summer) when the Inter-Tropical Convergence Zone moves up from the south. Wind- and sandstorms occur in early spring. Local inhabitants protect themselves from the heat, the sunshine, the dry air, the high diurnal temperature ranges and the sometimes dusty or sandy winds by covering their heads, such as the cheche garment worn by Tuareg.\n\nThe Sahara was one of the first regions of Africa to be farmed. Some 5,000 years ago, the area was not so arid and the vegetation might have been closer to a savanna. Previous fauna may be recognised in stone carvings. However, desertification set in around 3000 BCE, and the area became much like it is today.\n\nThe Sahara is largely undisturbed. The most degradation is found in areas where there is water, such as aquifer oases or along the desert margins where some rain usually falls most years. In these areas, animals such as addaxes, scimitar-horned oryxes, and bustards are over-hunted for their meat. Only one area of conservation is recorded in the Sahara: the Zellaf Nature Reserve in Libya. \n"}
{"id": "13363496", "url": "https://en.wikipedia.org/wiki?curid=13363496", "title": "Snow bridge", "text": "Snow bridge\n\nA snow bridge is an arc across a crevasse, a crack in rock, a creek, or some other opening in terrain. It is typically formed by snow drift, which first creates a cornice, which may gradually grow to reach the other side of the opening.\n\nA snow bridge may completely cover the opening and thus presents danger: it creates an illusion of unbroken surface while hiding the opening under a layer of snow of unknown thickness, possibly only several centimetres thick.\n\nSnow bridges may also be formed inside a crevasse making it appear shallow.\n\nSince a snow bridge is thicker and stronger at the edge of a crevasse, a fall through a bridge usually happens at some distance from the crevasse edge.\n\n"}
{"id": "64599", "url": "https://en.wikipedia.org/wiki?curid=64599", "title": "Soil salinity", "text": "Soil salinity\n\nSoil salinity is the salt content in the soil; the process of increasing the salt content is known as salinization. Salts occur naturally within soils and water. Salination can be caused by natural processes such as mineral weathering or by the gradual withdrawal of an ocean. It can also come about through artificial processes such as irrigation and road salt.\n\nSalts are a natural component in soils and water.\nThe ions responsible for salination are: Na, K, Ca, Mg and Cl.\nAs the Na (sodium) predominates, soils can become sodic. Sodic soils present particular challenges because they tend to have very poor structure which limits or prevents water infiltration and drainage.\n\nOver long periods of time, as soil minerals weather and release salts, these salts are flushed or leached out of the soil by drainage water in areas with sufficient precipitation. In addition to mineral weathering, salts are also deposited via dust and precipitation. In dry regions salts may accumulate, leading to naturally saline soils. This is the case, for example, in large parts of Australia. Human practices can increase the salinity of soils by the addition of salts in irrigation water. Proper irrigation management can prevent salt accumulation by providing adequate drainage water to leach added salts from the soil. Disrupting drainage patterns that provide leaching can also result in salt accumulations. An example of this occurred in Egypt in 1970 when the Aswan High Dam was built. The change in the level of ground water before the construction had enabled soil erosion, which led to high concentration of salts in the water table. After the construction, the continuous high level of the water table led to the salination of the arable land.\n\nSalinity in drylands can occur when the water table is between two and three metres from the surface of the soil. The salts from the groundwater are raised by capillary action to the surface of the soil. This occurs when groundwater is saline (which is true in many areas), and is favored by land use practices allowing more rainwater to enter the aquifer than it could accommodate. For example, the clearing of trees for agriculture is a major reason for dryland salinity in some areas, since deep rooting of trees has been replaced by shallow rooting of annual crops.\n\nSalinity from irrigation can occur over time wherever irrigation occurs, since almost all water (even natural rainfall) contains some dissolved salts. When the plants use the water, the salts are left behind in the soil and eventually begin to accumulate. Since soil salinity makes it more difficult for plants to absorb soil moisture, these salts must be leached out of the plant root zone by applying additional water. This water in excess of plant needs is called the leaching fraction. Salination from irrigation water is also greatly increased by poor drainage and use of saline water for irrigating agricultural crops.\n\nSalinity in urban areas often results from the combination of irrigation and groundwater processes. Irrigation is also now common in cities (gardens and recreation areas).\n\nThe consequences of salinity are\n\nSalinity is an important land degradation problem. Soil salinity can be reduced by leaching soluble salts out of soil with excess irrigation water. Soil salinity control involves watertable control and flushing in combination with tile drainage or another form of subsurface drainage. A comprehensive treatment of soil salinity is available from the United Nations Food and Agriculture Organization.\n\nHigh levels of soil salinity can be tolerated if salt-tolerant plants are grown. Sensitive crops lose their vigor already in slightly saline soils, most crops are negatively affected by (moderately) saline soils, and only salinity-resistant crops thrive in severely saline soils. The University of Wyoming and the Government of Alberta report data on the salt tolerance of plants.\n\nField data in irrigated lands, under farmers' conditions, are scarce, especially in developing countries. However, some on-farm surveys have been made in Egypt, India, and Pakistan. Some examples are shown in the following gallery, with crops arranged from sensitive to very tolerant..\n\nFrom the FAO/UNESCO Soil Map of the World the following salinised areas can be derived.\n\n\n"}
{"id": "740344", "url": "https://en.wikipedia.org/wiki?curid=740344", "title": "Starsiege", "text": "Starsiege\n\nStarsiege is a mecha-style vehicle simulation game developed by Dynamix and released in 1999. \"Starsiege\" is set in the / universe, which contains its predecessors \"Earthsiege\" (1994), \"Battledrome\" (1995), and \"Earthsiege 2\" (1996). This universe also includes action game \"Hunter Hunted\" (1996), strategy games \"\" (1997) and \"\" (1998). It also includes the sequels \"\" (actually released before \"Starsiege\") and all subsequent \"Tribes\" titles. In 2015, this game and the rest of the \"Metaltech/Tribes\" series were released as freeware by Hi-Rez Studios, but Battledrome and the Cyberstorm series were not.\n\n\"Starsiege\" takes place in the 29th century, portraying the conflict between humanity and the artificially intelligent Cybrid war machines. Played out in various locations throughout the solar system, the story examines both civil unrest in the colonies and an all-or-nothing genocidal invasion by the machines. Bipedal mecha known as HERCs are the mainstay of ground-based combat, and the focus of gameplay.\n\nHumanity is nominally united in an interplanetary Empire, led from Earth by the Immortal Emperor Solomon Petresun. Petresun's policy is the defence of Earth at all costs. While Earth is prosperous and well protected, the colonies on Luna, Mars, and Venus suffer from increasingly harsh regulations and production quotas. The combat units of the Empire are represented by the Imperial Police, Terran Defense Force and the Imperial Knights. The former paramilitary group is responsible for maintaining order in the colonies. The Terran Defense Force are the standard military with bases from Mercury to Titan. The Knights, led by Grand Master Caanon Weathers, are the military's elite and are provided with the best pilots and equipment.\n\nThe inequality between the colonies and Earth foments rebellion. In 2802 there are two guerilla movements on Mars, one that concentrates on destroying and capturing Imperial infrastructure and supplies and another bent on killing Imperial personnel and sympathizers. Both groups operate from underground bases and make do with modified mining HERCs and tanks. The rebels partially offset their disadvantages with superior weapons taken from the alien \"Tharsis Cache\"; an underground stockpile of alien technology discovered by rebels while digging new tunnels. Eventually the rebellion becomes too great for the police to contain and the Knights are deployed to Mars to crush the insurrection.\n\nThe Cybrids are a race of sentient robots responsible for the first Earthsiege. They are led by the first Cybrid, Prometheus, who is revered with god-like status. The Cybrids established themselves in the outer solar system after being defeated two centuries before during the first Earthsiege. Since then they have built up their strength for another bid to destroy humanity and claim Earth for their own. Like the Martian rebels, the Cybrids discover their own cache of alien weapons and adapt it to use, but their cache is inferior to the Tharsis Cache.\n\nThe game offers two story campaigns, with different endings. The Human campaign puts the player in control of a Martian rebel, initially fighting the Empire before humanity unites against the Cybrid invasion midway through the campaign. The human campaign culminates in an attack on Prometheus on Pluto. The Cybrid campaign starts with their invasion across the outer colonies and proceeds to Earth, ending in an assault on the Imperial palace to kill Petresun.\n\nAs a simulation, \"Starsiege\" offers players the ability to pilot a wide variety of massive bipedal war machines known as \"HERCULAN\"s (Humaniform-Emulation Roboticized Combat Unit with Leg-Articulated Navigation) (or 'HERCs' for short), as well as several tanks. Set in 2829, \"Starsiege\" contains an array of advanced technology, and numerous upgrades are available for each vehicle. \"Starsiege\" takes place across a number of planets and moons in the solar system, offering a range of different locations throughout the game and in multiplayer battles, including Earth, Titan, Luna, Mars, Venus, and Mercury. There are two campaigns, Human and Cybrid.\n\nGameplay in \"Starsiege\" revolves around mechanized combat - piloting HERCs and tanks in combat against opposing vehicles. Both types of vehicles can be controlled via any combination of keyboard, joystick, or mouse input. Starsiege abandoned the \"torso-twist\" gameplay mechanic common in many mecha simulations (including preceding games in the series), a feature that would normally allow the user to swivel the HERC's upper body independently of its legs. In Starsiege, torso orientation is fixed forward, but the player can move the aiming recticle across the screen with a mouse, a feature GameSpot compared to playing a first-person shooter. In both campaigns, the player is eventually assigned squadmates and is able to issue basic commands to them.\n\nEvery vehicle has unique performance, though this can be modified somewhat through customization of parts. Tanks and HERCs both utilize armor for defense, but HERCs also can equip rechargeable shields for additional protection. Other part choices include weapons, engine, and engine boosters. Customizing the player's vehicle is an important element of gameplay, particularly in multiplayer - a proper balance between all of the components is necessary to assure the player a reasonable chance of success.\n\nMultiplayer gameplay includes classic modes deathmatch, team deathmatch, and capture the flag.\n\nIn February 1999, Dynamix announced that it would launch \"Starsiege\" with a shipment of 250,000 units to retailers.\n\n\"Starsiege\" received \"generally favorable reviews\" according to the review aggregation website GameRankings. IGN highlighted the well presented package and cutscenes, graphically impressive (whilst sparse) landscapes, intuitive controls and the longevity of the multiplayer mode. The minimal sound effects were criticised, with muddled voice-overs, and some of human HERC models were felt to be a bit bland and generic. GameSpot said, \"Starsiege brings new life to a genre otherwise devoid of it, even if it doesn't really succeed in elevating robot sims out of their long-term rut\".\n\nCNET Gamecenter nominated \"Starsiege\" for its 1999 \"Best Sci-Fi Simulation\" award, but gave the prize to \"MechWarrior 3\".\n\nThe first-person shooters \"\" (1999; released before \"Starsiege\"), \"Tribes 2\" (2001), \"Tribes Aerial Assault\" (2002), \"\" (2004) and \" (2012)\" followed this game.\n\nStarsiege 2845 was a game in development from 2003 to 2007. Like the later Tribes Universe game developed in 2010-2011, it stagnated into hiatus and was not completed.\n\n\"Starsiege\" can be perceived as the bridge between the \"Earthsiege\" series and \"Tribes\" series.\n"}
{"id": "10113242", "url": "https://en.wikipedia.org/wiki?curid=10113242", "title": "String-net liquid", "text": "String-net liquid\n\nIn condensed matter physics, a string-net is an extended object whose collective behavior has been proposed as a physical mechanism for topological order by Michael A. Levin and Xiao-Gang Wen. A particular string-net model may involve only closed loops; or networks of oriented, labeled strings obeying branching rules given by some gauge group; or still more general networks.\n\nThe string-net model is claimed to show the derivation of photons, electrons, and U(1) gauge charge, small (relative to the Planck mass) but nonzero masses, and suggestions that the leptons, quarks, and gluons can be modeled in the same way. In other words, string-net condensation provides a unified origin for photons and electrons (or gauge bosons and fermions). It can be viewed as an origin of light and electron (or gauge interactions and Fermi statistics).\nHowever, their model does not account for the chiral coupling between the fermions and the SU(2) gauge bosons in the standard model.\n\nFor strings labeled by the positive integers, string-nets are the spin networks studied in loop quantum gravity. This has led to the proposal by Levin and Wen, and Smolin, Markopoulou and Konopka that loop quantum gravity's spin networks can give rise to the standard model of particle physics through this mechanism, along with fermi statistics and gauge interactions. To date, a rigorous derivation from LQG's spin networks to Levin and Wen's spin lattice has yet to be done, but the project to do so is called quantum graphity, and in a more recent paper, Tomasz Konopka, Fotini Markopoulou, Simone Severini argued that there are some similarities to spin networks (but not necessarily an exact equivalence) that gives rise to U(1) gauge charge and electrons in the string net mechanism.\n\nHerbertsmithite may be an example of string-net matter.\n\nZ2 spin liquid obtained using slave-particle approach may be the first theoretical example of string-net liquid.\n\nThe toric code is a two dimensional spin lattice that acts as a quantum error-correcting code. It is defined on a two dimensional lattice with toric boundary conditions with a spin-1/2 on each link. It can be shown that the ground state of the standard toric code Hamiltonian is an \"equal weight superposition\" of closed string states. Such a ground state is an example of a string-net condensate which has the same topological order\nas the Z2 spin liquid above.\n"}
{"id": "24384610", "url": "https://en.wikipedia.org/wiki?curid=24384610", "title": "TIRA (System)", "text": "TIRA (System)\n\nThe Tracking & Imaging Radar (TIRA) system serves as the central experimental facility for the development and investigation of radar techniques for the detection and reconnaissance of objects in space, and to a certain degree also of air targets. TIRA has a 34-metre parabolic dish antenna is a monopulse radar operating at 1.333 GHz or 22.5 cm (L band) and 16.7 GHz or 1.8 cm (Ku band) wavelengths. The L-band is usually used for tracking debris with a 0.45° beam width, at 1 MW peak power. The system is capable of determining orbits from direction angles, range and Doppler shift for single targets. The detection size threshold is about 2 cm at 1000 km range. The radar conducts regular ‘beam park’ experiments, where the radar beam is pointed in a fixed direction on the celestial sphere for 24 hours, scanning 360° in a narrow strip a complete Earth rotation. The tracking sensitive can be enhanced when the TIRA system is used as a transmitter, part of a bistatic radar system. In conjunction with the Effelsberg Radio Telescope, functioning as a receiver, the combined system has a detection size threshold of 1 cm. The Ku-band is used for imaging in Inverse Synthetic Aperture Radar (ISAR) mode, with 13 kW peak power, the radar is capable of producing images with range resolutions better than 7 cm. The dish can be turned full 360° in azimuth with speed of 24° per second and 90° in elevation. The radar is protected by a radome with 47 meters diameter – one of the largest in the world. \n\nDue to its capabilities, the system is used as a radar tracking system for space debris and other in-orbit object in the ESA's Space Situational Awareness Programme (SSA). \n\nTIRA is located at the FGAN () site, in Wachtberg near Bonn, Germany. It is run by the Fraunhofer-FHR – the Fraunhofer-Institut für Hochfrequenzphysik und Radartechnik (High Frequency Physics and Radar Techniques).\n\n"}
{"id": "19826061", "url": "https://en.wikipedia.org/wiki?curid=19826061", "title": "Tropical ecology", "text": "Tropical ecology\n\nTropical ecology is the study of the relationships between the biotic and abiotic components of the tropics, or the area of the Earth that lies between the Tropic of Cancer and the Tropic of Capricorn (23.4378° N and 23.4378° S, respectively). The tropical climate experiences hot, humid weather and rainfall year-round. While many might associate the region solely with the rainforests, the tropics are home to a wide variety of ecosystems that boast a great wealth of biodiversity, from exotic animal species to seldom-found flora. Tropical ecology began with the work of early English naturalists and eventually saw the establishment of research stations throughout the tropics devoted to exploring and documenting these exotic landscapes. The burgeoning ecological study of the tropics has led to increased conservation education and programs devoted to the climate. This climatic zone offers numerous advantages to ecologists conducting a wide array of studies, from rich biodiversity to vast lands untainted by man.\n\nThe roots of tropical ecology can be traced to the voyages of European naturalists in the late 19th and early 20th centuries. Men who might be considered early ecologists such as Alexander Von Humboldt, Thomas Belt, Henry Walter Bates, and even Charles Darwin sailed to tropical locations and wrote extensively about the exotic flora and fauna they encountered. While many naturalists were simply drawn to the exotic nature of the tropics, some historians argue that the naturalists conducted their studies on tropical islands in order to increase the likelihood that their work might bring about social and political change. In any case, these early explorations and the subsequent writings that came from them comprise much of the early work of tropical ecology and served to spark further interest in the tropics among other naturalists. Henry Walter Bates, for example, wrote extensively about a species of toucan he encountered while traveling along the Amazon River. Bates discovered that if one toucan called out, the other surrounding toucans would mimic his or her call, and the forest would quickly fill with the sounds of toucans; this was one of the first documented studies of animal mimicry. Alexander Von Humboldt voyaged throughout South America, from Venezuela through the Andes Mountains. There, Humboldt and his associate, Aimé Bonpland, stumbled upon an interesting ecological concept. As the pair traveled from the base of the mountains to the peak, they noticed that the species of plants and animals would change according to which climatic zone they were in relative to their elevation. This simple discovery aided the theorization of the \"life zone concept,\" which would eventually give way to the popularization of the concept of ecosystems. Another voyager, William Beebe, researched many species of birds in tropical locations and published a large gamut of academic works on his findings that greatly shaped the field of ornithology. According to his biographer Carol Grant Gould, \"The effects William Beebe had on science... are enormous and lasting. He made an effective transition between the Victorian natural historian, content to collect and classify the natural world, and the modern experimental biologist.\" The work of these early pioneers not only lead to an increased interest in the burgeoning field of tropical ecology, but also had far reaching implications for scientific study on the whole.\n\nThe tropics receive a lot of attention when it comes to conservation and management due to increased public awareness of the significance of tropical ecosystems and the delicacy with which they must be treated. The rainforests are subjects of heightened attention due to the excessive deforestation and logging that occurs in those ecosystems. In the 1980s, the United Nations Food and Agriculture Organization conducted a study that concluded that 15.4 million hectares (100 acres) of tropical forest was lost per year. In addition, 5.6 million hectares were logged each year. This landmark study sparked widespread interest in the tropical ecosystem, and a great number of non-profits and outspoken ecologists engaged in an extended fight to \"save the rainforest\" that continues today. This battle has manifested itself in a number of ways, one of which is the outcropping of biodiversity institutes in tropical locations dedicated to stopping the excessive deforestation of the landscape, one of the most notable of which was established in Costa Rica. The work of the Costa Rican National Biodiversity Institute (INBio) has served as a model for other biodiversity institutes. First, it must be noted that rainforests harbor the most alkaloid-producing plants of any biome; alkaloids are compounds that are crucial to the production of Western drugs. Due to the abundance of these compounds, pharmaceutical companies all over the world look to the rainforests for new medicinal treatments. In the early 1990s, the heads of INBio signed a deal with the pharmaceutical behemoth Merck that called for cooperation between the two entities in discovering and exploring new natural treatments in the Costa Rican rainforests. Ecologists, government officials, and corporations alike praised this decision as decisive progress in an ongoing struggle to work cooperatively in utilizing tropical biodiversity while ensuring the stability of tropical ecosystems.\n\nIt is advantageous for ecologists and naturalists to study plants, animals, and ecosystems in the tropical climate for a number of reasons. For one, the tropics are home to a wide array of ecosystems, from rainforests to deserts. In that sense, the tropics are a great place for ecologists to conduct diverse studies without traveling too far from a research center. Secondly, the temperature in the tropics rarely hinders plant growth and activity; flora can be studied nearly year round, as cold weather never stunts plant activity. In addition to climatic reasons, the traditionally sparse population of the tropics has greatly aided research in the area, as the landscape is largely untainted by mankind and machinery. While this may not be the case so much as of late, the vast amounts of untapped land in the tropics still make for prime research territory. Finally, the tropics are valuable to ecologists because they are home to some of the oldest lands on Earth, including Chile's Atacama Desert and Australia's Peneplain. Thus, plant communities have been growing and evolving for millions of uninterrupted years, which makes for interesting study. That being said, while it may be advantageous to study ecology in the tropics, this is not to say that it is without difficulty. The ecosystems native to the tropics and the biodiversity they boast are dwindling. Half of the species located in biodiversity hotspots are in danger of extinction, and many of the plants with potential medicinal uses are dying off. In this sense, ecological study in the tropics is not as easily conducted as it once was; this is the reason why much of the modern ecological work in the field is aimed towards conservation and management as opposed to general research.\n\n"}
{"id": "6411296", "url": "https://en.wikipedia.org/wiki?curid=6411296", "title": "Vagabond (boat)", "text": "Vagabond (boat)\n\nVagabond is a yacht specifically designed to sail in icy waters. In 2001, she was the first boat to go through the North-East passage without wintering. In 2002, she came back to France via the North-west Passage, completing the first circumnavigation around the Arctic ocean. \"Vagabond\" now serves as a logistic support for scientific expeditions in the Arctic.\n\n"}
