{"id": "47313797", "url": "https://en.wikipedia.org/wiki?curid=47313797", "title": "1982–83 El Niño event", "text": "1982–83 El Niño event\n\nThe 1982–83 El Niño event was one of the strongest El Niño events since records were kept.\n\nIt led to widespread flooding across the southern United States, droughts in Indonesia and Australia, and lack of snow in northern areas of the United States. The estimated economic impact was over US$8 billion. This El Niño event also led to an abnormal number of hurricanes in the Pacific Ocean during this time span; the strongest hurricane up to 1983 hit Hawaii during this El Niño event.\n\nIt led to declines of 77% among Galápagos penguins and 49% among flightless cormorants. In addition to these losses in penguins and cormorants, this El Niño event caused a quarter of adult native sea lions and fur seals on Peru's coast to starve, while the entirety of both seals' pup populations perished. In the Galápagos Islands, the event killed much of the macroalgae in the area, and \"Desmarestia tropica\" is now possibly extinct from overgrazing by herbivores caused by overfishing of predator fish resulting from the event. In Ecuador, heavy rainfall and flooding led to high fish and shrimp harvests; however, the large amounts of standing water also allowed mosquito populations to thrive, leading to large outbreaks of malaria.\n"}
{"id": "13799977", "url": "https://en.wikipedia.org/wiki?curid=13799977", "title": "Achamana", "text": "Achamana\n\nAchamanam (achamana, achmana) is one of the most important rituals in the Hindu tradition. It is a purification ritual that is believed to cure all physical and mental illnesses. \n"}
{"id": "194268", "url": "https://en.wikipedia.org/wiki?curid=194268", "title": "Astronautics", "text": "Astronautics\n\nAstronautics (or cosmonautics) is the theory and practice of navigation beyond Earth's atmosphere.\n\nThe term \"astronautics\" (originally \"astronautique\" in French) was coined in the 1920s by J.-H. Rosny, president of the Goncourt academy, in analogy with aeronautics. Because there is a degree of technical overlap between the two fields, the term aerospace is often used to describe both at once. In 1930, Robert Esnault-Pelterie published the first book on the new research field.\n\nAs with aeronautics, the restrictions of mass, temperatures, and external forces require that applications in space survive extreme conditions: high-grade vacuum, the radiation bombardment of interplanetary space and the magnetic belts of low Earth orbit. Space launch vehicles must withstand titanic forces, while satellites can experience huge variations in temperature in very brief periods. Extreme constraints on mass cause astronautical engineers to face the constant need to save mass in the design in order to maximize the actual payload that reaches orbit.\n\nThe early history of astronautics is theoretical: the fundamental mathematics of space travel was established by Isaac Newton in his 1687 treatise Philosophiae Naturalis Principia Mathematica. Other mathematicians, such as Swiss Leonhard Euler and Franco-Italian Joseph Louis Lagrange also made essential contributions in the 18th and 19th centuries. In spite of this, astronautics did not become a practical discipline until the mid-20th century. On the other hand, the question of spaceflight puzzled the literary imaginations of such figures as Jules Verne and H. G. Wells. At the beginning of the 20th century, Russian cosmist Konstantin Tsiolkovsky derived the rocket equation, the governing equation for a rocket-based propulsion, enabling computation of the final velocity of a rocket from the mass of spacecraft (formula_1), combined mass of propellant and spacecraft (formula_2) and exhaust velocity of the propellant (formula_3).\n\nBy the early 1920s, American Robert Goddard was developing liquid-propellant rockets, which would in a few brief decades become a critical component in the designs of such famous rockets as the V-2 and Saturn V.\n\nThe Prix d'Astronautique (Astronautics Prize) awarded by the Société astronomique de France, the French astronomical society, was the first prize on this subject. The international award, established by aviation and astronautical pioneer Robert Esnault-Pelterie and André-Louis Hirsch, was given from 1929-1939 in recognition of the study of interplanetary travel and astronautics.\n\nBy the mid 1950s, the Space Race between the USSR and the USA had begun.\n\nAlthough many regard astronautics itself as a rather specialized subject, engineers and scientists working in this area must be knowledgeable in many distinct fields.\n\n\n"}
{"id": "55602215", "url": "https://en.wikipedia.org/wiki?curid=55602215", "title": "Aydıncık Nature Park", "text": "Aydıncık Nature Park\n\nAydıncık Nature Park is a nature park in Turkey. It is at and situated to the east of Aydıncık ilçe (district) of Mersin Province. Its distance to Aydıncık centrum is about and to Mersin is about . Gilindire Cave is to the east of the nature park. It was declared a picnic area in 1988 and a nature park in 2011.\n\nThe park is at the east side of Aydıncık bay, facing Aydıncık Islands and the town. \nThe total area of the park is . The natural flora consists of Turkish pine (Pinus brutia), myrtle (myrtus communis), kermes oak (quercus coccifera) and laurel (laurus nobilis), and spini broom (calicotome villosa). Mediterranean gull (chthyaetus melanocephalus), Mediterranean monk seal (monachus monachus ) and various small reptiles make up the fauna around the park. \n"}
{"id": "19594534", "url": "https://en.wikipedia.org/wiki?curid=19594534", "title": "Black Hills", "text": "Black Hills\n\nThe Black Hills (; ; ) are a small and isolated mountain range rising from the Great Plains of North America in western South Dakota and extending into Wyoming, United States. Black Elk Peak (formerly known as Harney Peak), which rises to , is the range's highest summit. The Black Hills encompass the Black Hills National Forest. The name \"Black Hills\" is a translation of the Lakota \"\". The hills were so-called because of their dark appearance from a distance, as they were covered in trees.\n\nNative Americans have a long history in the Black Hills. After conquering the Cheyenne in 1776, the Lakota took over the territory of the Black Hills, which became central to their culture. In 1868, the U.S. government signed the Fort Laramie Treaty of 1868, establishing the Great Sioux Reservation west of the Missouri River, and exempting the Black Hills from all white settlement forever. However, when settlers discovered gold there in 1874, as a result of George Armstrong Custer's Black Hills Expedition, miners swept into the area in a gold rush. The US government took back the Black Hills and in 1889 reassigned the Lakota, against their wishes, to five smaller reservations in western South Dakota, selling off 9 million acres of their former land. Unlike most of South Dakota, the Black Hills were settled by European Americans primarily from population centers to the west and south of the region, as miners flocked there from earlier gold boom locations in Colorado and Montana.\n\nAs the economy of the Black Hills has shifted from natural resources (mining and timber) since the late 20th century, the hospitality and tourism industries have grown to take its place. Locals tend to divide the Black Hills into two areas: \"The Southern Hills\" and \"The Northern Hills\". The Southern Hills is home to Mount Rushmore, Wind Cave National Park, Jewel Cave National Monument, Black Elk Peak (the highest point in the United States east of the Rockies, formerly known as Harney Peak), Custer State Park (the largest state park in South Dakota), the Crazy Horse Memorial (the largest sculpture in the world), and the Mammoth Site in Hot Springs, the world's largest mammoth research facility.\n\nAttractions in the Northern Hills include Spearfish Canyon, historic Deadwood, and the Sturgis Motorcycle Rally, held each August. The first Rally was held on August 14, 1938 and the 75th Rally in 2015 saw more than 1 million bikers visit the Black Hills. Devils Tower National Monument, located in the Wyoming Black Hills, is an important nearby attraction and was the United States' first national monument.\n\nAlthough written history of the region begins with the Sioux domination of the land over the native Arikara tribes, researchers have carbon-dating and stratigraphic records to analyze the early history of the area. Scientists have been able to utilize carbon-dating to evaluate the age of tools found in the area, which indicate a human presence that dates as far back as 11,500 BC with the Clovis culture. Stratigraphic records indicate environmental changes in the land, such as flood and drought patterns. For example, large-scale flooding of the Black Hill basins occurs at a probability rate of 0.01, making such floods occur once in every 100 years. However, during The Medieval Climate Anomaly, or the Medieval Warm Period, flooding increased in the basins. A stratigraphic record of the area shows that during this 400-year period, thirteen 100-year floods occurred in four of the region's basins, while the same four basins from the previous 800 years only experienced nine floods.\n\nThe Arikara arrived by AD 1500, followed by the Cheyenne, Crow, Kiowa and Pawnee.\nThe Lakota (also known as Sioux) arrived from Minnesota in the 18th century and drove out the other tribes, who moved west. They claimed the land, which they called \"\" (Black Mountains). The mountains commonly became known as the Black Hills.\n\nFrançois and Louis de La Vérendrye probably travelled near the Black Hills in 1743. Fur trappers and traders had some dealings with the Native Americans.\n\nEuropean Americans increasingly encroached on Lakota territory. After defeating the Lakota Sioux, the United States government made peace under the Fort Laramie Treaty of 1868, establishing the Great Sioux Reservation west of the Missouri River and acknowledging their control of the Teton range. In this treaty, they protected the Black Hills \"forever\" from European-American settlement. Both the Sioux and Cheyenne also claimed rights to the land, saying that in their cultures, it was considered the \"axis mundi\", or sacred center of the world.\n\nAlthough rumors of gold in the Black Hills had circulated for decades (see Thoen Stone and Pierre-Jean De Smet), it was not until 1874 that Brevet Major General George Armstrong Custer of the 7th US Cavalry led an expedition there and discovered gold in French Creek. An official announcement of gold was made by the newspaper reporters accompanying the expedition. The following year, the Newton-Jenney Party conducted the first detailed survey of the Black Hills. The surveyor for the party, Dr. Valentine McGillycuddy, was the first European American to ascend to the top of Black Elk Peak. This highest point in the Black Hills is 7,242 feet above sea level.\n\nDuring the 1875–1878 gold rush, thousands of miners went to the Black Hills; in 1880, the area was the most densely populated part of the Dakota Territory. Three large towns developed in the Northern Hills: Deadwood, Central City, and Lead. Around these were groups of smaller gold camps, towns, and villages. Hill City and Custer City sprang up in the Southern Hills. Railroads were quickly constructed to the previously remote area. From 1880 on, the gold mines yielded about $4,000,000 annually, and the silver mines about $3,000,000 annually.\n\nThe conflict over control of the region sparked the Black Hills War (1876), also known as the Great Sioux War, the last major Indian War on the Great Plains. Following the defeat of the Lakota and their Cheyenne and Arapaho allies in 1876, the United States took control of the Black Hills and another strip of land, in violation of the Treaty of Fort Laramie. The Lakota never accepted the validity of the US appropriation in 1877. They have continued to try to reclaim the property and filed a suit against the federal government.\n\nIn 1889, the United States dismantled the Great Sioux Reservation, forcing the peoples on to five smaller reservations west of the Missouri River. It made available 9 million acres throughout this area for purchase for ranching or homesteading, in the same year that North Dakota and South Dakota were admitted to the Union. Many of the early farms established by homesteaders in the 20th century failed, as they were too small for farming in the arid regions. People made many mistakes and plowed the grasses holding the earth on the plains, causing the Dust Bowl of the 1930s.\n\nOn July 23, 1980, in \"United States v. Sioux Nation of Indians\", the Supreme Court of the United States ruled that the Black Hills were illegally taken by the federal government and ordered remuneration of the initial offering price plus interest, nearly $106 million. The Lakota refused the settlement, as they wanted the Black Hills returned to them. The money remains in an interest-bearing account, which, as of 2015, amounts to over $1.2 billion, but the Lakota still refuse to take the money. They believe that accepting the settlement would allow the US government to justify taking ownership of the Black Hills.\n\nIn 2012, United Nations Special Rapporteur James Anaya conducted a 12-day tour of Native Americans' land to determine how the U.S. is carrying out the United Nations Declaration on the Rights of Indigenous Peoples, endorsed in 2010 by the Obama administration. Anaya met with tribes in seven states on reservations and in urban areas as well as with members of the Obama administration and the Senate Committee on Indian Affairs. In an appeal issued August 21, 2012, Anaya brought a sale of over 1,900 acres of land in Black Hills by the Reynolds family to the attention of the U.S. government, and asked that it disclose measures taken by federal or state governments to address Sioux concerns over the sale of the land within Reynolds Prairie. These acres consist of five land tracts, including the sacred Pe' Sla site for Dakota, Lakota, and Nakota peoples; natives to Black Hills fund raised in order to buy the land during the Reynolds' sale. On January 15, 2013, the U.S. responded, telling Anaya that it \"understands several tribes purchased the Pe' Sla sacred site around November 30, 2012\" meaning the Pe' Sla is officially Sioux land.\n\nThe geology of the Black Hills is complex. A Tertiary mountain-building episode is responsible for the uplift and current topography of the Black Hills region. This uplift was marked by volcanic activity in the northern Black Hills. The southern Black Hills are characterized by Precambrian granite, pegmatite, and metamorphic rocks that comprise the core of the entire Black Hills uplift. This core is rimmed by Paleozoic, Mesozoic, and Cenozoic sedimentary rocks. The stratigraphy of the Black Hills is laid out like a target, as it is an oval dome, with rings of different rock types dipping away from the center.\n\nThe 'bulls eye' of this target is called the granite core. The granite of the Black Hills was emplaced by magma generated during the Trans-Hudson orogeny and contains abundant pegmatite. The core of the Black Hills has been dated to 1.8 billion years. There are other localized deposits that have been dated to around 2.2 to 2.8 billion years. One of these is located in the northern hills. It is called French Creek Granite although it has been metamorphosed into gneiss. The other is called the Bear Mountain complex, and it is located in the west central part of the hills.\n\n\"Making a concentric ring around the core is the metamorphic zone. The rocks in this ring are all very old, as much as 2 billion years and older. This zone is very complex, filled with many diverse rock types. The rocks were originally sedimentary, until there was a collision between the North American continent and a terrane. This collision, called the Trans-Hudson Orogeny, caused the original rocks to fold and twist into a vast mountain range. Over the millions of years, these tilted rocks, which in many areas are tilted to 90 degrees or more, eroded. Today we see the evidence of this erosion in the Black Hills, where the metamorphic rocks end in an angular unconformity below the younger sedimentary layers.\n\nThe final layers of the Black Hills consist of sedimentary rocks. The oldest lie on top of the metamorphic layers at a much shallower angle. This rock called the Deadwood Formation is mostly sandstone and was the original source of gold found in the Deadwood area. Above the Deadwood Formation lies the Englewood Formation and Pahasapa limestone, which is the source of the more than 200 caves found in the Black Hills, including Jewel Cave and Wind Cave. The Minnelusa Formation is next and is composed of highly variable sandstones and limestones followed by the Opeche shale and the Minnekahta limestone.\n\nThe next rock layer, the Spearfish Formation, forms a valley around the hills called the Red Valley and is often referred to as the Race Track. It is mostly red shale with beds of gypsum, and circles much of the Black Hills. These shale and gypsum beds as well as the nearby limestone beds of the Minnekahta are used in the manufacture of cement at a cement plant in Rapid City. Next is the shale and sandstone Sundance Formation, which is topped by the Morrison Formation and the Unkpapa sandstone.\n\nThe outermost feature of the dome stands out as a hogback ridge. The ridge is made out of the Lakota Formation and the Fallriver sandstone, which are collectively called the Inyan Kara Group. Above this, the layers of rocks are less distinct and are all mainly grey shale with three exceptions: the Newcastle sandstone; the Greenhorn limestone, which contains many shark teeth fossils; and the Niobrara Formation, which is composed mainly of chalk. These outer ridges are called cuestas.\n\nThe preceding layers were deposited in a horizontal manner. All of them can be seen in core samples and well logs from the flattest parts of the Great Plains. It took a period of uplift to bring them to their present topographical levels in the Black Hills. This uplift, called the Laramide orogeny, began around the beginning of the Cenozoic and left a line of igneous rocks through the northern hills superimposed on the rocks already discussed. This line extends from Bear Butte in the east to Devils Tower in the west. Evidence of Cenozoic volcanic eruptions, if this happened, has long since been eroded away.\n\nThe Black Hills also have a 'skirt' of gravel covering them in areas, which are called pediments. Formed as the waterways cut down into the uplifting hills, they represent the former locations of today's rivers. These beds are generally around 10,000 years old or younger, judging by the artifacts and fossils found. A few places, mainly in the high elevations, are older, as old as 20 million years, according to camel and rodent fossils found. Some gravels have been found but for the most part, these older beds have been eroded away.\n\nAs with the geology, the biology of the Black Hills is complex. Most of the Hills are a fire-climax ponderosa pine forest, with Black Hills spruce (\"Picea glauca\" var. \"densata\") occurring in cool moist valleys of the Northern Hills. Oddly, this endemic variety of spruce does not occur in the moist Bear Lodge Mountains, which make up most of the Wyoming portion of the Black Hills. Large open parks (mountain meadows) with lush grassland rather than forest are scattered through the Hills (especially the western portion), and the southern edge of the Hills, due to the rainshadow of the higher elevations, are covered by a dry pine savannah, with stands of mountain mahogany and Rocky Mountain juniper.\n\nWildlife is both diverse and plentiful. Black Hills creeks are known for their trout, while the forests and grasslands offer good habitat for American bison, white-tailed and mule deer, pronghorn, bighorn sheep, mountain lions, and a variety of smaller animals, like prairie dogs, American martens, American red squirrels, Northern flying squirrels, yellow-bellied marmots, and fox squirrels. Biologically, the Black Hills is a meeting and mixing place, with species common to regions to the east, west, north, and south. The Hills do, however, support some endemic taxa, the most famous of which is probably white-winged junco (\"Junco hyemalis aikeni\"). Some other endemics are Cooper's Rocky Mountain snail, Black Hills subspecies of red-bellied snake, and a Black Hills subspecies of southern red-backed vole. Some birds that are only in the Black Hills and not the rest of South Dakota are pinyon jay, gray jay, three-toed woodpecker, black-backed woodpecker, American dipper, ruffed grouse, and others.\n\nThe northern Black Hills approximate Lawrence and Meade Counties and are roughly equivalent to the Northern Hills District of the Black Hills National Forest. The central Black Hills (the Mystic District of the Black Hills National Forest) are located in Pennington County west of Rapid City. The southern Black Hills are in Custer County and are administered in the national forest's Hell Canyon District. Finally, Wyoming's Black Hills follow the Bearlodge District, approximately Weston and Crook Counties.\n\nGeologically separate from the Black Hills are the Elk Mountains, a small range forming the southwest portion of the region.\n\nThe region is home to Mount Rushmore National Memorial, Wind Cave National Park, Jewel Cave National Monument, Black Elk Peak, Custer State Park (the largest state park in South Dakota, and one of the largest in the US), Bear Butte State Park, Devils Tower National Monument, and the Crazy Horse Memorial. The Black Hills also hosts the Sturgis Motorcycle Rally each August. The rally was started in 1940 and the 65th Rally in 2005 saw more than 550,000 bikers visit the Black Hills. It is a key part of the regional economy.\n\nThe George S. Mickelson Trail is a recently opened multi-use path through the Black Hills that follows the abandoned track of the historic railroad route from Edgemont to Deadwood. The train used to be the only way to bring supplies to the miners in the Hills. The trail is about 110 miles in length, and can be used by hikers, cross-country skiers, and cyclists. The cost is two dollars per day, or ten dollars annually.\n\nToday, the major city in the Black Hills is Rapid City, with an incorporated population of almost 70,000 and a metropolitan population of 125,000. It serves a market area covering much of five states: North and South Dakota, Nebraska, Wyoming, and Montana. In addition to tourism and mining (including coal, specialty minerals, and the now declining gold mining), the Black Hills economy includes ranching (sheep and cattle, primarily, with bison and ratites becoming more common), timber (lumber), Ellsworth Air Force Base, and some manufacturing, including Black Hills gold jewelry, cement, electronics, cabinetry, guns and ammunition.\n\nIn many ways, the Black Hills functions as a very spread-out urban area with a population (not counting tourists) of 250,000. Other important Black Hills cities and towns include:\n\n\n"}
{"id": "10952676", "url": "https://en.wikipedia.org/wiki?curid=10952676", "title": "Blue Eye, Albania", "text": "Blue Eye, Albania\n\nThe Blue Eye () is a water spring and natural phenomenon occurring near Muzinë in Vlorë County, southern Albania. A popular tourist attraction, the clear blue water of the river bubbles forth from a depth of more than fifty-metres. Divers have descended to fifty metres, but it is still unclear what the actual depth of the karst hole is.\n\nThis is the initial water source of Bistricë river , 25 km long, which ends in the Ionian Sea south of Sarandë.\n\nThe source stands at an altitude of 152 m and has a discharge rate of 18400 l/s.\n\nThe immediate area is a Nature Monument and is characterized by oak and sycamore trees. In summer 2004, the source was temporarily dried up.\n\n\n \n"}
{"id": "522227", "url": "https://en.wikipedia.org/wiki?curid=522227", "title": "California chaparral and woodlands", "text": "California chaparral and woodlands\n\nThe California chaparral and woodlands is a terrestrial ecoregion of lower northern, central, and southern California (United States) and northwestern Baja California (Mexico), located on the west coast of North America. It is an ecoregion of the Mediterranean forests, woodlands, and scrub Biome, and part of the Nearctic ecozone.\n\nThe California chaparral and woodlands ecoregion is subdivided into three smaller ecoregions.\n\n\nMost of the population of California and Baja California lives in these ecoregions, which includes the San Francisco Bay Area, Ventura County, the Greater Los Angeles Area, San Diego County, and Tijuana.\n\nThe California Central Valley grasslands ecoregion, as well as the coniferous Sierra Nevada forests, Northern California coastal forests, and Klamath-Siskiyou forests of northern California and southwestern Oregon, share many plant and animal affinities with the California chaparral and woodlands. Many botanists consider the California chaparral and woodlands, Sierra Nevada forests, Klamath-Siskiyou forests, and Northern California coastal forests as a single California Floristic Province, excluding the deserts of eastern California, which belong to other floristic provinces. Many Bioregionalists, including poet Gary Snyder, identify the central and northern Coast Ranges, Klamath-Siskiyou, the Central Valley, and Sierra Nevada as the Shasta Bioregion or the Alta California Bioregion.\nThe ecoregion includes a great variety of plant communities, including grasslands, oak savannas and woodlands, chaparral, and coniferous forests, including southern stands of the tall coast redwood (\"Sequoia sempervirens\"). The flora of this ecoregion also includes tree species such as Gray or foothill pine (\"Pinus sabiniana\"), Scrub oak (\"Quercus dumosa\"), California buckeye (\"Aesculus californica\"), the rare Gowen cypress (\"Cupressus goveniana)\", the rare Monterey cypress (\"Cupressus macrocarpa\"), and a wealth of endemic plant species, including the extremely rare San Gabriel Mountain liveforever (\"Dudlea densiflora\"), Catalina mahogany (\"Cercocarpus traskiae\"), and the threatened most beautiful jewel-flower (\"Streptanthus albidus\" ssp. \"Peramoenus\"). Hesperoyucca whipplei, colloquially known as Chaparral Yucca, is commonplace throughout the lower elevations of the climate zone.\n\nSpecies include the California gnatcatcher (\"Polioptila californica\"), Costa's hummingbird (\"Calypte costae\"), coast horned lizard (\"Phrynosoma coronatum\"), and rosy boa (\"Lichanura trivirgata\"). Other animals found here are the Heermann kangaroo rat (\"Dipodomys heermanni\"), Santa Cruz kangaroo rat (\"Dipodomys venustus\"), and the endangered white-eared pocket mouse (\"Perognathus alticolus\").\n\nAnother notable insect resident of this ecoregion is the rain beetle (\"Plecoma\" sp.) It spends up to several years living underground in a larval stage and emerges only during wet-season rains to mate.\n\nChaparral, like most Mediterranean shrublands, is highly fire resilient and historically burned with high-severity, stand replacing events every 30 to 100 years. Historically, Native Americans burned chaparral to promote grasslands for textiles and food. Though adapted to infrequent fires, chaparral plant communities can be exterminated by frequent fires especially with climate change induced drought. Today, frequent accidental ignitions can convert chaparral from a native shrubland to nonnative annual grassland and drastically reduce species diversity, especially under global-change-type drought.\n\nThe region has been heavily affected by grazing, logging, dams and water diversions, and intensive agriculture and urbanization, as well as competition by numerous introduced or exotic plant and animal species. Some unique plant communities, like southern California's Coastal Sage Scrub, have been nearly eradicated by agriculture and urbanization. As a result, the region now has many rare and endangered species, including the California condor (\"Gymnogyps californianus\").\n\n"}
{"id": "5816", "url": "https://en.wikipedia.org/wiki?curid=5816", "title": "Cenozoic", "text": "Cenozoic\n\nThe Cenozoic Era () meaning \"new life\", is the current and most recent of the three Phanerozoic geological eras, following the Mesozoic Era and extending from 66 million years ago to the present day.\n\nThe Cenozoic is also known as the \"Age of Mammals,\" because the extinction of many groups allowed mammals to greatly diversify so that large mammals dominated it. The continents also moved into their current positions during this era.\n\nEarly in the Cenozoic, following the K-Pg extinction event, most of the fauna was relatively small, and included small mammals, birds, reptiles, and amphibians. From a geological perspective, it did not take long for mammals and birds to greatly diversify in the absence of the large reptiles that had dominated during the Mesozoic. A group of avians known as the \"terror birds\" grew larger than the average human and were formidable predators. Mammals came to occupy almost every available niche (both marine and terrestrial), and some also grew very large, attaining sizes not seen in most of today's mammals.\n\nThe Earth's climate had begun a drying and cooling trend, culminating in the glaciations of the Pleistocene Epoch, and partially offset by the Paleocene-Eocene Thermal Maximum.\n\n\"Cenozoic,\" meaning \"new life,\" is derived from Greek \"kainós\" \"new,\" and \"zōḗ\" \"life.\" The era is also known as the \"Cænozoic\", \"Caenozoic\", or \"Cainozoic\" (). The name \"Cenozoic\" (originally: \"Kainozoic\") was proposed in 1840 by the British geologist John Phillips (1800–1874).\n\nThe Cenozoic is divided into three periods: the Paleogene, Neogene, and Quaternary; and seven epochs: the Paleocene, Eocene, Oligocene, Miocene, Pliocene, Pleistocene, and Holocene. The Quaternary Period was officially recognized by the International Commission on Stratigraphy in June 2009, and the former term, Tertiary Period, became officially disused in 2004 due to the need to divide the Cenozoic into periods more like those of the earlier Paleozoic and Mesozoic eras. The common use of epochs during the Cenozoic helps paleontologists better organize and group the many significant events that occurred during this comparatively short interval of time. Knowledge of this era is more detailed than any other era because of the relatively young, well-preserved rocks associated with it.\n\nThe Paleogene spans from the extinction of non-avian dinosaurs, 66 million years ago, to the dawn of the Neogene, 23.03 million years ago. It features three epochs: the Paleocene, Eocene and Oligocene. \n\nThe Paleocene epoch lasted from 66 million to 56 million years ago. Modern placental mammals originated during this time. The Paleocene is a transitional point between the devastation that is the K-T extinction, to the rich jungle environment that is the Early Eocene. The Early Paleocene saw the recovery of the earth. The continents began to take their modern shape, but all the continents and the subcontinent of India were separated from each other. Afro-Eurasia was separated by the Tethys Sea, and the Americas were separated by the strait of Panama, as the isthmus had not yet formed. This epoch featured a general warming trend, with jungles eventually reaching the poles. The oceans were dominated by sharks as the large reptiles that had once predominated were extinct. Archaic mammals filled the world such as creodonts (extinct carnivores, unrelated to existing Carnivora).\n\nThe Eocene Epoch ranged from 56 million years to 33.9 million years ago. In the Early-Eocene, species living in dense forest were unable to evolve into larger forms, as in the Paleocene. There was nothing over the weight of 10 kilograms. Among them were early primates, whales and horses along with many other early forms of mammals. At the top of the food chains were huge birds, such as Paracrax. The temperature was 30 degrees Celsius with little temperature gradient from pole to pole. In the Mid-Eocene, the Circumpolar-Antarctic current between Australia and Antarctica formed. This disrupted ocean currents worldwide and as a result caused a global cooling effect, shrinking the jungles. This allowed mammals to grow to mammoth proportions, such as whales which, by that time, had become almost fully aquatic. Mammals like \"Andrewsarchus\" were at the top of the food-chain. The Late Eocene saw the rebirth of seasons, which caused the expansion of savanna-like areas, along with the evolution of grass. The end of the Eocene was marked by the Eocene-Oligocene extinction event, the European face of which is known as the Grande Coupure.\n\nThe Oligocene Epoch spans from 33.9 million to 23.03 million years ago. The Oligocene featured the expansion of grass which had led to many new species to evolve, including the first elephants, cats, dogs, marsupials and many other species still prevalent today. Many other species of plants evolved in this period too. A cooling period featuring seasonal rains was still in effect. Mammals still continued to grow larger and larger.\n\nThe Neogene spans from 23.03 million to 2.58 million years ago. It features 2 epochs: the Miocene, and the Pliocene.\n\nThe Miocene epoch spans from 23.03 to 5.333 million years ago and is a period in which grass spread further, dominating a large portion of the world, at the expense of forests. Kelp forests evolved, encouraging the evolution of new species, such as sea otters. During this time, perissodactyla thrived, and evolved into many different varieties. Apes evolved into 30 species. The Tethys Sea finally closed with the creation of the Arabian Peninsula, leaving only remnants as the Black, Red, Mediterranean and Caspian Seas. This increased aridity. Many new plants evolved: 95% of modern seed plants evolved in the mid-Miocene.\n\nThe Pliocene epoch lasted from 5.333 to 2.58 million years ago. The Pliocene featured dramatic climactic changes, which ultimately led to modern species and plants. The Mediterranean Sea dried up for several million years (because the ice ages reduced sea levels, disconnecting the Atlantic from the Mediterranean, and evaporation rates exceeded inflow from rivers). \"Australopithecus\" evolved in Africa, beginning the human branch. The isthmus of Panama formed, and animals migrated between North and South America, wreaking havoc on local ecologies. Climatic changes brought: savannas that are still continuing to spread across the world; Indian monsoons; deserts in central Asia; and the beginnings of the Sahara desert. The world map has not changed much since, save for changes brought about by the glaciations of the Quaternary, such as the Great Lakes, Hudson Bay, and the Baltic sea.\n\nThe Quaternary spans from 2.58 million years ago to present day, and is the shortest geological period in the Phanerozoic Eon. It features modern animals, and dramatic changes in the climate. It is divided into two epochs: the Pleistocene and the Holocene.\nThe Pleistocene lasted from 2.58 million to 11,700 years ago. This epoch was marked by ice ages as a result of the cooling trend that started in the Mid-Eocene. There were at least four separate glaciation periods marked by the advance of ice caps as far south as 40° N in mountainous areas. Meanwhile, Africa experienced a trend of desiccation which resulted in the creation of the Sahara, Namib, and Kalahari deserts. Many animals evolved including mammoths, giant ground sloths, dire wolves, saber-toothed cats, and most famously \"Homo sapiens\". 100,000 years ago marked the end of one of the worst droughts in Africa, and led to the expansion of primitive humans. As the Pleistocene drew to a close, a major extinction wiped out much of the world's megafauna, including some of the hominid species, such as Neanderthals. All the continents were affected, but Africa to a lesser extent. It still retains many large animals, such as hippos.\n\nThe Holocene began 11,700 years ago and lasts to the present day. All recorded history and \"the history of the world\" lies within the boundaries of the Holocene epoch. Human activity is blamed for a mass extinction that began roughly 10,000 years ago, though the species becoming extinct have only been recorded since the Industrial Revolution. This is sometimes referred to as the \"Sixth Extinction\". It is often cited that over 322 recorded species have become extinct due to human activity since the Industrial Revolution, but the rate may be as high as 500 veterbrate species alone, the majority of which have occurred after 1900.\n\nEarly in the Cenozoic, following the K-Pg event, the planet was dominated by relatively small fauna, including small mammals, birds, reptiles, and amphibians. From a geological perspective, it did not take long for mammals and birds to greatly diversify in the absence of the dinosaurs that had dominated during the Mesozoic. Some flightless birds grew larger than humans. These species are sometimes referred to as \"terror birds,\" and were formidable predators. Mammals came to occupy almost every available niche (both marine and terrestrial), and some also grew very large, attaining sizes not seen in most of today's terrestrial mammals.\n\nEarly animals were the Entelodon (a so-called \"hell pig\"), Paraceratherium (a hornless rhinoceros relative) and Basilosaurus (an early whale). The extinction of many large diapsid groups, such as flightless dinosaurs, Plesiosauria and Pterosauria allowed mammals and birds to greatly diversify and become the world's predominant fauna.\n\nGeologically, the Cenozoic is the era when the continents moved into their current positions. Australia-New Guinea, having split from Pangea during the early Cretaceous, drifted north and, eventually, collided with South-east Asia; Antarctica moved into its current position over the South Pole; the Atlantic Ocean widened and, later in the era (2.8 million years ago), South America became attached to North America with the isthmus of Panama.\n\nIndia collided with Asia creating the Himalayas; Arabia collided with Eurasia, closing the Tethys Ocean and creating the Zagros Mountains, around .\n\nThe break-up of Gondwana in Late Cretaceous and Cenozoic times led to a shift in the river courses of various large African rivers including the Congo, Niger, Nile, Orange, Limpopo and Zambezi.\n\nThe Paleocene–Eocene Thermal Maximum at about was a significant global warming event; however, since the Azolla event of , the Cenozoic Era has been a period of long-term cooling. After the tectonic creation of Drake Passage at , when South America fully detached from Antarctica during the Oligocene, the climate cooled significantly due to the advent of the Antarctic Circumpolar Current which brought cool deep Antarctic water to the surface. The cooling trend continued in the Miocene, with relatively short warmer periods. When South America became attached to North America creating the Isthmus of Panama around , the Arctic region cooled due to the strengthening of the Humboldt and Gulf Stream currents, eventually leading to the glaciations of the Quaternary ice age, the current interglacial of which is the Holocene Epoch.\nRecent analysis of the geomagnetic reversal frequency, oxygen isotope record, and tectonic plate subduction rate, which are indicators of the changes in the heat flux at the core mantle boundary, climate and plate tectonic activity, shows that all these changes indicate similar rhythms on million years' timescale in the Cenozoic Era occurring with the common fundamental periodicity of ∼13 Myr during most of the time.\n\nDuring the Cenozoic, mammals proliferated from a few small, simple, generalized forms into a diverse collection of terrestrial, marine, and flying animals, giving this period its other name, the Age of Mammals, despite the fact that there are more than twice as many bird species as mammal species. The Cenozoic is just as much the age of savannas, the age of co-dependent flowering plants and insects, and the age of birds. Grass also played a very important role in this era, shaping the evolution of the birds and mammals that fed on it. One group that diversified significantly in the Cenozoic as well were the snakes. Evolving in the Cenozoic, the variety of snakes increased tremendously, resulting in many colubrids, following the evolution of their current primary prey source, the rodents.\n\nIn the earlier part of the Cenozoic, the world was dominated by the gastornithid birds, terrestrial crocodiles like \"Pristichampsus\", and a handful of primitive large mammal groups like uintatheres, mesonychids, and pantodonts. But as the forests began to recede and the climate began to cool, other mammals took over.\n\nThe Cenozoic is full of mammals both strange and familiar, including chalicotheres, creodonts, whales, primates, entelodonts, saber-toothed cats, mastodons and mammoths, three-toed horses, giant rhinoceros like \"Indricotherium\", the rhinoceros-like brontotheres, various bizarre groups of mammals from South America, such as the vaguely elephant-like pyrotheres and the dog-like marsupial relatives called borhyaenids and the monotremes and marsupials of Australia.\n\n\n\n"}
{"id": "7971222", "url": "https://en.wikipedia.org/wiki?curid=7971222", "title": "Chapman State Park", "text": "Chapman State Park\n\nChapman State Park is a Pennsylvania state park in Pleasant Township, Warren County, Pennsylvania near Clarendon, in the United States. The man-made Chapman Lake covers of the park. Chapman State Park is named in honor of Dr. Leroy E. Chapman. Dr. Chapman was a state senator from 1929 until 1963. He was part of several civic groups that pushed for the creation of a state park in Warren County. Chapman State Park, opened in 1951, is adjacent to Allegheny National Forest and State Game Land 29 just off U.S. Route 6.\n\nChapman State Park is open for year-round recreation. Chapman Lake is open for swimming, boating, and fishing. A large picnic area is near the beach and overlooks the lake. Five pavilions are available by reservation or first-come, first-served. A rustic, wooded campground is open spring through fall. Twelve miles (19 km) of trails are open to hiking. Chapman State Park is also open to hunting and fishing in the streams as well as the lake. The park stays open in the winter for cross-country skiing, snowmobiling and ice fishing.\n\nThe sand beach on Chapman Lake is open from 8:00 am until sunset. Beginning in 2008 lifeguards will not be posted at the beach. The beach opens for the summer on Memorial Day and closes Labor Day weekend. A concession is open in the beach area offering snacks, beverages, and ice cream treats.\n\nGas powered boats are prohibited on Chapman Lake. Electric powered and non powered boats must have a current registration with any state or a launch permit from the Pennsylvania Fish and Boat Commission. A concession is open on the shores of the lake for renting canoes, kayaks and paddle boats.\n\nChapman lake provides a habitat for warm water and cold water fish. Fishermen may catch brook and brown trout, bluegill, sunfish, yellow perch, largemouth bass, and sucker. West Branch Tionesta Creek and Farnsworth Run have trout in the park and in the surrounding Allegheny National Forest.\n\nVisitors to Chapman State Park have several choices for over accommodations. The rustic campground in a wooded area has 83 campsites, with two shower houses and water hydrants. Many campsites offer 30 Amp or 50 Amp electric service. Approximately half the sites are pet friendly. Three cottages are available to rent. The cottages sleep up to five people in single and double bunks. Each cottage has wooden floors, a porch, electric heat, lights, and outlets. The cottages also have a picnic table and fire ring in the yard area. In addition to the more traditional cottages two Mongolian style yurts are available to rent. These round structures are mounted on a wooden platform and have a cooking stove, refrigerator, tables, chairs, countertop, electric lights, heat and outlets. Picnic tables and fire rings are in the yard area.\n\nChapman State Park is a trailhead for an extensive network of trails in the Allegheny National Forest. All backpackers are asked to register at the park office and leave word about where they plan to hike and when they plan to return. Hikers are also encouraged to take a map and compass.\n\nOver of Chapman State Park are open to hunting. Hunters may park at the park to gain access to the surrounding state game lands and Allegheny National Forest. Common game species are white-tailed deer, American black bear, wild turkey, eastern gray squirrel, and ruffed grouse. All hunters are expected to follow the rules and regulations of the Pennsylvania Game Commission.\n\nThe following state parks are within of Chapman State Park:\n\n"}
{"id": "5684672", "url": "https://en.wikipedia.org/wiki?curid=5684672", "title": "Circumhorizontal arc", "text": "Circumhorizontal arc\n\nA circumhorizontal arc is an optical phenomenon that belongs to the family of ice halos formed by the refraction of sun- or moonlight in plate-shaped ice crystals suspended in the atmosphere, typically in cirrus or cirrostratus clouds. In its full form, the arc has the appearance of a large, brightly spectrum-coloured band (red being the topmost colour) running parallel to the horizon, located far below the Sun or Moon. The distance between the arc and the Sun or Moon is twice as far as the common 22-degree halo. Often, when the halo-forming cloud is small or patchy, only fragments of the arc are seen. As with all halos, it can be caused by the Sun as well as (but much more rarely) the Moon.\n\nOther currently accepted names for the circumhorizontal arc are circumhorizon arc or lower symmetric 46° plate arc. The misleading term \"fire rainbow\" is sometimes used to describe this phenomenon, although it is neither a rainbow, nor related in any way to fire. The term, apparently coined in 2006, may originate in the occasional appearance of the arc as \"flames\" in the sky, when it occurs in fragmentary cirrus clouds.\n\nThe halo is formed by sunlight entering horizontally-oriented, flat, hexagonal ice crystals through a vertical side face and leaving through the near horizontal bottom face (plate thickness does not affect the formation of the halo). In principle, Parry oriented column crystals may also produce the arc, although this is rare. The 90° inclination between the ray entrance and exit faces produce the well-separated spectral colours. The arc has a considerable angular extent and thus, rarely is complete. When only fragments of a cirrus cloud are in the appropriate sky and sun position, they may appear to shine with spectral colours.\n\nHow often a circumhorizontal arc is seen, depends on the location and the latitude of the observer. In the United States it is a relatively common halo, seen several times each summer in any one place. In contrast, it is a rare phenomenon in northern Europe for several reasons. Apart from the presence of ice-containing clouds in the right position in the sky, the halo requires that the light source (Sun or Moon) be very high in the sky, at an elevation of 58° or greater. This means that the solar variety of the halo is impossible to see at locations north of 55°N or south of 55°S. A lunar circumhorizon arc might be visible at other latitudes, but is much rarer since it requires a nearly full Moon to produce enough light. At other latitudes the solar circumhorizontal arc is visible, for a greater or lesser time, around the summer solstice. Slots of visibility for different latitudes and locations may be looked up here. For example, in London, England the sun is only high enough for 140 hours between mid-May and late July, whereas Los Angeles has the sun higher than 58 degrees for 670 hours between late March and late September.\n\nA water glass experiment (known about since at least 1920) may be modified slightly to create an artificial circumhorizontal arc. Illuminating under a very steep angle from below the side face of a nearly completely water-filled cylindrical glass will refract the light into the water. The glass should be situated at the edge of a table. The second refraction at the top water-air interface will then project a hyperbola at a vertical wall behind it. The overall refraction is then equivalent to the refraction through an upright hexagonal plate crystal when the rotational averaging is taken into account. A colorful artificial circumhorizontal arc will then appear projected on the wall. Using a spherical projection screen instead will result in a closer analogy to the natural halo counterpart. Other artificial halos can be created by similar means.\n\nCircumhorizontal arcs, especially when only fragments can be seen, are sometimes confused with cloud iridescence. This phenomenon also causes clouds to appear multi-coloured, but it originates from diffraction (typically by liquid water droplets or ice crystals) rather than refraction. The two phenomena can be distinguished by several features. Firstly, a circumhorizon arc always has a fixed location in the sky in relation to the Sun or Moon (namely below it at an angle of 46°), while iridescence can occur in different positions (often directly around the Sun or Moon). Secondly, the colour bands in a circumhorizon arc always run horizontally with the red on top, while in iridescence they are much more random in sequence and shape, which roughly follows the contours of the cloud that causes it. Finally, the colours of a circumhorizon arc are pure and spectral (more so than in a rainbow), while the colours in cloud iridescence have a more washed-out, \"mother of pearl\" appearance.\n\nConfusion with other members of the halo family, such as sun dogs or the circumzenithal arc, may also arise, but these are easily dismissed by their entirely different positions in relation to the Sun or Moon. More difficult is the distinction between the circumhorizontal arc and the infralateral arc, both of which almost entirely overlap when the Sun or Moon is at a high elevation. The difference is that the circumhorizontal arc always runs parallel to the horizon (although pictures typically show it as a curved line due to perspective distortion), whereas the infralateral arc curves upward at its ends.\n\n\n"}
{"id": "307192", "url": "https://en.wikipedia.org/wiki?curid=307192", "title": "Climax community", "text": "Climax community\n\nIn ecology, climax community, or climatic climax community, is a historic term for a biological community of plants, animals, and fungi which, through the process of ecological succession in the development of vegetation in an area over time, have reached a steady state. This equilibrium was thought to occur because the climax community is composed of species best adapted to average conditions in that area. The term is sometimes also applied in soil development. Nevertheless, it has been found that a \"steady state\" is more apparent than real, particularly if long-enough periods of time are taken into consideration. Notwithstanding, it remains a useful concept.\n\nThe idea of a single climax, which is defined in relation to regional climate, originated with Frederic Clements in the early 1900s. The first analysis of succession as leading to something like a climax was written by Henry Cowles in 1899, but it was Clements who used the term \"climax\" to describe the idealized endpoint of succession.\n\nClements described the successional development of an ecological communities comparable to the ontogenetic development of individual organisms. Clements suggested only comparisons to very simple organisms. Later ecologists developed this idea that the ecological community is a \"superorganism\" and even sometimes claimed that communities could be homologous to complex organisms and sought to define a single climax-type for each area. The English botanist Arthur Tansley developed this idea with the \"polyclimax\"—multiple steady-state end-points, determined by edaphic factors, in a given climatic zone. Clements had called these end-points other terms, not climaxes, and had thought they were not stable, because by definition climax vegetation is best-adapted to the climate of a given area. Henry Gleason's early challenges to Clements's organism simile, and other strategies of his for describing vegetation, were largely disregarded for several decades until substantially vindicated by research in the 1950s and 1960s (below). Meanwhile, climax theory was deeply incorporated in both theoretical ecology and in vegetation management. Clements's terms such as pre-climax, post-climax, plagioclimax and disclimax continued to be used to describe the many communities which persist in states that diverge from the climax ideal for a particular area.\n\nThough the views are sometimes attributed to him, Clements never argued that climax communities must always occur, or that the different species in an ecological community are tightly integrated physiologically, or that plant communities have sharp boundaries in time or space. Rather, he employed the idea of a climax community—of the form of vegetation best adapted to some idealized set of environmental conditions—as a conceptual starting point for describing the vegetation in a given area. There are good reasons to believe that the species best adapted to some conditions might appear there, when those conditions occur. But much of Clements's work was devoted to characterizing what happens when those ideal conditions do not occur. In those circumstances, vegetation other than the ideal climax will often occur instead. But those different kinds of vegetation can still be described as deviations from the climax ideal. Therefore, Clements developed a very large vocabulary of theoretical terms describing the various possible causes of vegetation, and various non-climax states vegetation adopts as a consequence. His method of dealing with ecological complexity was to define an ideal form of vegetation—the climax community—and describe other forms of vegetation as deviations from that ideal.\n\nDespite the overall abandonment of climax theory, during the 1990s use of climax concepts again became more popular among some theoretical ecologists. Many authors and nature-enthusiasts continue to use the term \"climax\" in a diluted form to refer to what might otherwise be called mature or old-growth communities. The term \"climax\" has also been adopted as description for a late successional stage for marine macroinvertebrate communities.\n\nAdditionally, some contemporary ecologists still use the term \"disclimax\" to describe an ecosystem dominated by invasive species that competitively prevent the re-introduction of once native species. This concept borrows from Clement's earliest interpretation of climax as referring to an ecosystem that is resistant to colonization by outside species. The term disclimax was used in-context by Clements (1936), and despite being an anthropogenic phenomenon which prevents the facilitation and succession to a true climax community, it is one of the only examples of climax that can be observed in nature.\n"}
{"id": "11611342", "url": "https://en.wikipedia.org/wiki?curid=11611342", "title": "Coastal-Marine Automated Network", "text": "Coastal-Marine Automated Network\n\nThe Coastal-Marine Automated Network (C-MAN) is a meteorological observation network along the coastal United States. Consisting of about sixty stations installed on lighthouses, at capes and beaches, on near shore islands, and on offshore platforms, the stations record atmospheric pressure, wind direction, speed and gust, and air temperature; however, some C-MAN stations are designed to also measure sea surface temperature, water level, waves, relative humidity, precipitation, and visibility. \n\nThe network is maintained by the National Data Buoy Center (NDBC) of the National Weather Service (NWS), which is part of National Oceanic and Atmospheric Administration (NOAA), and data is ingested into numerical weather prediction computer models. It was created in the early 1980s to maintain observations that were about to be discontinued by other programs. Data is processed and transmitted similarly to the moored buoy system.\n\nIn 2002, C-MAN was added to the NOAA Observing System Architecture (NOSA).\n\n\n"}
{"id": "374163", "url": "https://en.wikipedia.org/wiki?curid=374163", "title": "Crevasse", "text": "Crevasse\n\nA crevasse is a deep crack, or fracture, found in an ice sheet or glacier, as opposed to a crevice that forms in rock. Crevasses form as a result of the movement and resulting stress associated with the shear stress generated when two semi-rigid pieces above a plastic substrate have different rates of movement. The resulting intensity of the shear stress causes a breakage along the faces.\n\nCrevasses often have vertical or near-vertical walls, which can then melt and create seracs, arches, and other ice formations. These walls sometimes expose layers that represent the glacier's stratigraphy. Crevasse size often depends upon the amount of liquid water present in the glacier. A crevasse may be as deep as 100 metres, as wide as 20 metres, and up to several hundred metres long.\n\nA crevasse may be covered, but not necessarily filled, by a snow bridge made of the previous years' accumulation and snow drifts. The result is that crevasses are rendered invisible, and thus potentially lethal to anyone attempting to navigate their way across a glacier. Occasionally a snow bridge over an old crevasse may begin to sag, providing some landscape relief, but this cannot be relied upon. Anyone planning to travel on a glacier should be trained in crevasse rescue.\n\nThe presence of water in a crevasse can significantly increase its penetration. Water-filled crevasses may reach the bottom of glaciers or ice sheets and provide a direct hydrologic connection between the surface, where significant summer melting occurs, and the bed of the glacier, where additional water may moisten and lubricate the bed and accelerate ice flow.\n\n\n\n"}
{"id": "56229825", "url": "https://en.wikipedia.org/wiki?curid=56229825", "title": "Croatian-Romanian-Slovak friendship proclamation", "text": "Croatian-Romanian-Slovak friendship proclamation\n\nDuring World War II, a joint friendship proclamation was created between the Kingdom of Romania, the Independent State of Croatia and the State of Slovakia against any further Hungarian expansion. Ion Antonescu, the Marshal of Romania, engaged in some intra-Axis diplomacy and created the alliance in May 1942. The union was similar to the interbellic Little Entente.\n\nLater in the war, Slovak troops and Croatian naval and air units operated amicably from Romanian soil. In June, the Hungarians responded with a particularly blatant cross-border raid at Turda, near Kolozsvár (today Cluj-Napoca, Romania); one of ten clashes that month. Matters had gone too far for Hitler, who brought pressure to bear on Antonescu and Miklós Horthy to gain their public recognition that the Second Vienna Award was irrevocable. On 1 August 1942, Antonescu fudged the issue by announcing he would make no territorial claims until after the war, but in private, he never ceased to press Hitler for the return of Northern Transylvania.\n\n"}
{"id": "41994482", "url": "https://en.wikipedia.org/wiki?curid=41994482", "title": "DICE model", "text": "DICE model\n\nThe Dynamic Integrated Climate-Economy model, referred to as the DICE model or Dice model, is a computer-based integrated assessment model developed by 2018 Nobel Laureate William Nordhaus that “integrates in an end-to-end fashion the economics, carbon cycle, climate science, and impacts in a highly aggregated model that allows a weighing of the costs and benefits of taking steps to slow greenhouse warming.\" Nordhaus also developed the RICE model (Regional Integrated Climate-Economy model), a variant of the DICE model that was updated and developed alongside the DICE model. Researchers who collaborated with Nordhaus to develop the model include David Popp, Zili Yang, and Joseph Boyer.\n\nThe DICE model is one of the three main integrated assessment models used by the United States Environmental Protection Agency, and it provides estimates intermediate between the other two models.\n\nAccording to a summary of the DICE and RICE models prepared by Stephen Newbold, the earliest precursor to DICE was a linear programming model of energy supply and demand in two 1977 papers of William Nordhaus. Although dynamic (in that it considered the changing levels of supply of fuel based on supply and demand and the consequence impact on carbon dioxide emissions) the model did not attempt to measure the economic \"impact\" of climate change. A 1991 paper by Nordhaus developed a steady-state model of both the economy and climate, coming quite close to the DICE model.\n\nThe model appears to have first been proposed by economist William Nordhaus in a discussion paper for the Cowles Foundation in February 1992. He also wrote a brief note outlining the main ideas in an article for \"Science\" in November 1992. A subsequent revised model was published in \"Resource and Energy Economics\" in 1993.\n\nNordhaus published an improved version of the model in the October 1994 book \"Managing the Global Commons: The Economics of Climate Change\", with the first chapter as well as an appendix containing a computer program both freely available online. Marian Radetzki reviewed the book for \"The Energy Journal\".\n\nIn 1996, Nordhaus and Zili Yang published an article titled \"A regional dynamic general-equilibrium model of alternative climate-change strategies\" at The American Economic Review, established the RICE (Regional Integrated model of Climate and the Economy) model..\n\nIn 1998, Nordhaus published a revised version of the DICE model in multiple papers, one of which was coauthored with Joseph Boyer in order to understand the effects of the proposed Kyoto Protocol.\n\nIn 1999, Nordhaus published computer programs and spreadsheets implementing a revised version of the DICE model as well as a variant called the RICE model (RICE stands for \"Regional Integrated Climate-Economics\", signifying that the modeling of economics and climate are being done only for a particular region rather than the whole world).\n\nIn 2000, Nordhaus and Boyer co-authored a book published by MIT Press titled \"Warming the World: Economic Models of Global Warming\" with a detailed description of the updated DICE and RICE models.\n\nIn 2001, Nordhaus published revised spreadsheets for the RICE model.\n\nIn November 2006, Nordhaus published a new version of the DICE model with updated data, and used it to review the Stern Review.\n\nIn 2010, updated RICE and DICE models were published, and the new RICE model was explained by Nordhaus in an article for the \"Proceedings of the National Academy of Sciences\" (US).\n\nIn 2013, the book \"The Climate Casino\" by Nordhaus, with updated discussion of the DICE and RICE models and the broader policy implications, was published by Yale University Press. A background on the latest version of the models as used in the book was published on Nordhaus' website.\n\nA number of variants of the DICE model have been published by researchers working separately from Nordhaus.\n\nThe DICE model is also included in advanced university coursework related to environmental and energy economics and climate change.\n\nThe DICE and RICE models have received considerable attention from others studying the economic impact of climate change. it is one of the models used by the Environmental Protection Agency for estimating the social cost of carbon. Stephen Newbold of the Environmental Protection Agency in the United States reviewed the models in 2010.\n\nThe Basque Centre for Climate Change, in an October 2009 review of integrated assessment models for climate change, discussed the DICE model in detail.\n\nA report from the Heritage Foundation, a conservative think tank in the United States, called the DICE model \"flawed beyond use for policymaking\" on account of its extreme sensitivity to initial assumptions. Similar criticisms, including criticisms of the specific choice of discount rates chosen in the model, have been made by others.\n\n"}
{"id": "13566984", "url": "https://en.wikipedia.org/wiki?curid=13566984", "title": "Double layer (surface science)", "text": "Double layer (surface science)\n\nA double layer (DL, also called an electrical double layer, EDL) is a structure that appears on the surface of an object when it is exposed to a fluid. The object might be a solid particle, a gas bubble, a liquid droplet, or a porous body. The DL refers to two parallel layers of charge surrounding the object. The first layer, the surface charge (either positive or negative), consists of ions adsorbed onto the object due to chemical interactions. The second layer is composed of ions attracted to the surface charge via the Coulomb force, electrically screening the first layer. This second layer is loosely associated with the object. It is made of free ions that move in the fluid under the influence of electric attraction and thermal motion rather than being firmly anchored. It is thus called the \"diffuse layer\".\n\nInterfacial DLs are most apparent in systems with a large surface area to volume ratio, such as a colloid or porous bodies with particles or pores (respectively) on the scale of micrometres to nanometres. However, DLs are important to other phenomena, such as the electrochemical behaviour of electrodes.\n\nDLs play a fundamental role in many everyday substances. For instance, homogenized milk exists only because fat droplets are covered with a DL that prevents their coagulation into butter. DLs exist in practically all heterogeneous fluid-based systems, such as blood, paint, ink and ceramic and cement slurry.\n\nThe DL is closely related to electrokinetic phenomena and electroacoustic phenomena.\n\nWhen an \"electronic\" conductor is brought in contact with a solid or liquid \"ionic\" conductor (electrolyte), a common boundary (interface) among the two phases appears. Hermann von Helmholtz was the first to realize that charged electrodes immersed in electrolyte solutions repel the co-ions of the charge while attracting counterions to their surfaces. Two layers of opposite polarity form at the interface between electrode and electrolyte.\nIn 1853 he showed that an electrical double layer (DL) is essentially a molecular dielectric and stores charge electrostatically. Below the electrolyte's decomposition voltage, the stored charge is linearly dependent on the voltage applied.\n\nThis early model predicted a constant differential capacitance independent from the charge density depending on the dielectric constant of the electrolyte solvent and the thickness of the double-layer.\n\nThis model, with a good foundation for the description of the interface, does not consider important factors including diffusion/mixing of ions in solution, the possibility of adsorption onto the surface and the interaction between solvent dipole moments and the electrode.\n\nLouis Georges Gouy in 1910 and David Leonard Chapman in 1913 both observed that capacitance was not a constant and that it depended on the applied potential and the ionic concentration. The \"Gouy-Chapman model\" made significant improvements by introducing a diffuse model of the DL. In this model the charge distribution of ions as a function of distance from the metal surface allows Maxwell–Boltzmann statistics to be applied. Thus the electric potential decreases exponentially away from the surface of the fluid bulk.\n\nThe Gouy-Chapman model fails for highly charged DLs. In 1924 Otto Stern suggested combining the Helmholtz model with the Gouy-Chapman model: In Stern's model, some ions adhere to the electrode as suggested by Helmholtz, giving an internal Stern layer, while some form a Gouy-Chapman diffuse layer.\n\nThe Stern layer accounts for ions' finite size and consequently an ion's closest approach to the electrode is on the order of the ionic radius. The Stern model has its own limitations, namely that it effectively treats ions as point charges, assumes all significant interactions in the diffuse layer are Coulombic, and assumes dielectric permittivity to be constant throughout the double layer and that fluid viscosity is constant plane.\n\nD. C. Grahame modified the Stern model in 1947. He proposed that some ionic or uncharged species can penetrate the Stern layer, although the closest approach to the electrode is normally occupied by solvent molecules. This could occur if ions lose their solvation shell as they approach the electrode. He called ions in direct contact with the electrode \"specifically adsorbed ions\". This model proposed the existence of three regions. The inner Helmholtz plane (IHP) passes through the centres of the specifically adsorbed ions. The outer Helmholtz plane (OHP) passes through the centres of solvated ions at the distance of their closest approach to the electrode. Finally the diffuse layer is the region beyond the OHP.\n\nIn 1963 J. O'M. Bockris, M. A. V. Devanathan and Klaus Müller proposed the BDM model of the double-layer that included the action of the solvent in the interface. They suggested that the attached molecules of the solvent, such as water, would have a fixed alignment to the electrode surface. This first layer of solvent molecules displays a strong orientation to the electric field depending on the charge. This orientation has great influence on the permittivity of the solvent that varies with field strength. The IHP passes through the centers of these molecules. Specifically adsorbed, partially solvated ions appear in this layer. The solvated ions of the electrolyte are outside the IHP. Through the centers of these ions pass the OHP. The diffuse layer is the region beyond the OHP.\n\nFurther research with double layers on ruthenium dioxide films in 1971 by Sergio Trasatti and Giovanni Buzzanca demonstrated that the electrochemical behavior of these electrodes at low voltages with specific adsorbed ions was like that of capacitors. The specific adsorption of the ions in this region of potential could also involve a partial charge transfer between the ion and the electrode. It was the first step towards understanding pseudocapacitance.\n\nBetween 1975 and 1980 Brian Evans Conway conducted extensive fundamental and development work on ruthenium oxide electrochemical capacitors. In 1991 he described the difference between 'Supercapacitor' and 'Battery' behavior in electrochemical energy storage. In 1999 he coined the term supercapacitor to explain the increased capacitance by surface redox reactions with faradaic charge transfer between electrodes and ions.\n\nHis \"supercapacitor\" stored electrical charge partially in the Helmholtz double-layer and partially as the result of faradaic reactions with \"pseudocapacitance\" charge transfer of electrons and protons between electrode and electrolyte. The working mechanisms of pseudocapacitors are redox reactions, intercalation and electrosorption.\n\nThe physical and mathematical basics of electron charge transfer absent chemical bonds leading to pseudocapacitance was developed by Rudolph A. Marcus. Marcus Theory explains the rates of electron transfer reactions—the rate at which an electron can move from one chemical species to another. It was originally formulated to address outer sphere electron transfer reactions, in which two chemical species change only in their charge, with an electron jumping. For redox reactions without making or breaking bonds, Marcus theory takes the place of Henry Eyring's transition state theory which was derived for reactions with structural changes. Marcus received the Nobel Prize in Chemistry in 1992 for this theory.\n\nThere are detailed descriptions of the interfacial DL in many books on colloid and interface science and microscale fluid transport. There is also a recent IUPAC technical report on the subject of interfacial double layer and related electrokinetic phenomena.\n\nAs stated by Lyklema, \"...the reason for the formation of a \"relaxed\" (\"equilibrium\") double layer is the non-electric affinity of charge-determining ions for a surface...\" This process leads to the buildup of an electric surface charge, expressed usually in C/m. This surface charge creates an electrostatic field that then affects the ions in the bulk of the liquid. This electrostatic field, in combination with the thermal motion of the ions, creates a counter charge, and thus screens the electric surface charge. The net electric charge in this screening diffuse layer is equal in magnitude to the net surface charge, but has the opposite polarity. As a result, the complete structure is electrically neutral.\n\nThe diffuse layer, or at least part of it, can move under the influence of tangential stress. There is a conventionally introduced slipping plane that separates mobile fluid from fluid that remains attached to the surface. Electric potential at this plane is called electrokinetic potential or zeta potential (also denoted as ζ-potential).\n\nThe electric potential on the external boundary of the Stern layer versus the bulk electrolyte is referred to as Stern potential. Electric potential difference between the fluid bulk and the surface is called the electric surface potential.\n\nUsually zeta potential is used for estimating the degree of DL charge. A characteristic value of this electric potential in the DL is 25 mV with a maximum value around 100 mV (up to several volts on electrodes). The chemical composition of the sample at which the ζ-potential is 0 is called the point of zero charge or the iso-electric point. It is usually determined by the solution pH value, since protons and hydroxyl ions are the charge-determining ions for most surfaces.\n\nZeta potential can be measured using electrophoresis, electroacoustic phenomena, streaming potential, and electroosmotic flow.\n\nThe characteristic thickness of the DL is the Debye length, κ. It is reciprocally proportional to the square root of the ion concentration \"C\". In aqueous solutions it is typically on the scale of a few nanometers and the thickness decreases with increasing concentration of the electrolyte.\n\nThe electric field strength inside the DL can be anywhere from zero to over 10 V/m. These steep electric potential gradients are the reason for the importance of the DLs.\n\nThe theory for a flat surface and a symmetrical electrolyte is usually referred to as the Gouy-Chapman theory. It yields a simple relationship between electric charge in the diffuse layer σ and the Stern potential Ψ:\n"}
{"id": "971289", "url": "https://en.wikipedia.org/wiki?curid=971289", "title": "Dropsonde", "text": "Dropsonde\n\nA dropsonde is an expendable weather reconnaissance device created by the National Center for Atmospheric Research (NCAR), designed to be dropped from an aircraft at altitude over water to measure (and therefore track) storm conditions as the device falls to the surface. The sonde contains a GPS receiver, along with pressure, temperature, and humidity (PTH) sensors to capture atmospheric profiles and thermodynamic data. It typically relays these data to a computer in the aircraft by radio transmission.\n\nSince the early 1970s, hurricane hunters have employed dropsondes while flying over the ocean to obtain meteorological data on the structure of hurricanes deemed to be of possible concern to land locations in the northern Atlantic and northeastern Pacific oceans. Dropsonde instruments are typically the only way to measure the wind and pressure near the sea surface within the core of such cyclones, allowing meteorologists to reliably establish the storm's intensity and size. The data obtained is typically fed into supercomputers for numerical weather prediction, enabling forecasters to better track and predict what will happen to the hurricane. During a typical hurricane season, the 53d Weather Reconnaissance Squadron Hurricane Hunters deploys 1000 to 1500 sondes on training and storm missions.\n\nAircraft reconnaissance missions are also sometimes requested to investigate the broader atmospheric structure over the ocean when cyclones may pose a significant threat to the United States. These interests include not only potential hurricanes, but also possible snow events (like nor'easters) or significant tornado outbreaks. The dropsondes are used to supplement the large gaps over oceans within the global network of daily radiosonde launches. Typically satellite data provides an estimate of conditions in such areas, but the increased precision of sondes can improve forecasts, particularly of the storm path.\n\nDropsondes may also be employed during meteorological research projects.\n\nThe sonde is a lightweight system designed to be operated by one person and is launched through a chute installed in the measuring aircraft. The device's descent is slowed and stabilized by a small square-cone parachute, allowing for more readings to be taken before it reaches the ocean surface. The parachute is designed to immediately deploy after release so as to reduce or eliminate any pendulum effect, and the device typically drops for three to five minutes. The sonde has a casing of stiff cardboard to protect electronics and form a more stable aerodynamic profile.\n\nTo obtain data in a tropical cyclone, an aircraft (in the US, operated either by NOAA or the U.S. Air Force) flies into the system. A series of dropsondes are typically released as the plane passes through the storm, typically launched with greatest frequency near the center of the storm, including into the eyewall and eye (center), if one exists. Most drops are performed at a flight level of around 10,000 feet (approx. 3,000 meters).\n\nThe dropsonde sends back coded data, which includes:\n\nAlso included in the report is information on the aircraft, the mission, the dropsonde itself, and other remarks.\n\nA driftsonde is a high altitude, durable weather balloon holding a transmitter and a bank (35 in the first models) of miniature dropsonde capsules which can then be dropped at automatic intervals or remotely. The water-bottle-sized transmitters in the dropsondes have enough power to send information to the balloon during their parachute-controlled fall. The balloon carries a larger transmitter powerful enough to relay readings to a satellite. The single-use sensor packages cost US$300 to $400 each.\n\nAfter being introduced in April 2007, around a thousand a year are expected to be used to track winds in hurricane breeding grounds off of West Africa, which are outside the operating region of Hurricane Hunter planes.\n\n\n"}
{"id": "458540", "url": "https://en.wikipedia.org/wiki?curid=458540", "title": "Dry stone", "text": "Dry stone\n\nDry stone, sometimes called drystack or, in Scotland, drystane, is a building method by which structures are constructed from stones without any mortar to bind them together. Dry stone structures are stable because of their unique construction method, which is characterized by the presence of a load-bearing façade of carefully selected interlocking stones.\n\nDry stone construction is best known in the context of stone walls, traditionally used for the boundaries of fields and churchyards, or as retaining walls for terracing, but dry stone sculptures, buildings, bridges, and other structures also exist.\n\nThe art of dry stone walling, was inscribed in 2018 on the UNESCO representative list of the intangible cultural heritage of humanity, for dry stone walls in countries such as France, Greece, Italy, Croatia and Spain.\n\nSome dry-stone wall constructions in north-west Europe have been dated back to the Neolithic Age. Some Cornish hedges are believed by the Guild of Cornish Hedgers to date from 5000 BC, although there appears to be little dating evidence. In County Mayo, Ireland, an entire field system made from dry-stone walls, since covered in peat, have been carbon-dated to 3800 BC. The cyclopean walls of the acropolis of Mycenae, Greece, have been dated to 1350 BC and those of Tiryns slightly earlier. In Belize, the Mayan ruins at Lubaantun illustrate use of dry stone construction in architecture of the 8th and 9th centuries AD.\n\nTerminology varies regionally. When used as field boundaries, dry stone structures often are known as dykes, particularly in Scotland. Dry stone walls are characteristic of upland areas of Britain and Ireland where rock outcrops naturally or large stones exist in quantity in the soil. They are especially abundant in the West of Ireland, particularly Connemara. They may also be found throughout the Mediterranean, including retaining walls used for terracing. Such constructions are common where large stones are plentiful (for example, in The Burren) or conditions are too harsh for hedges capable of retaining livestock to be grown as reliable field boundaries. Many thousands of miles of such walls exist, most of them centuries old.\n\nIn the United States they are common in areas with rocky soils, such as New England, New York, New Jersey, and Pennsylvania and are a notable characteristic of the bluegrass region of central Kentucky as well as Virginia, where they are usually referred to as \"rock fences\" or \"stone fences\", and the Napa Valley in north central California. The technique of construction was brought to America primarily by English and Scots-Irish immigrants. The technique was also taken to Australia (principally western Victoria and some parts of Tasmania and New South Wales) and New Zealand (especially Otago).\n\nSimilar walls also are found in the Swiss-Italian border region, where they are often used to enclose the open space under large natural boulders or outcrops.\n\nThe higher-lying rock-rich fields and pastures in Bohemia's South-Western border range of Šumava (e.g. around the mountain river of Vydra) are often lined by dry stone walls built of field-stones removed from the arable or cultural land. They serve both as cattle/sheep fences and the lot's borders. Sometimes also the dry stone terracing is apparent, often combined with parts of stone masonry (house foundations and shed walls) that are held together by a clay-cum-needles \"composite\" mortar. \n\nIn Peru in the 15th century AD, the Inca made use of otherwise unusable slopes by building dry stone walls to create terraces. They also employed this mode of construction for freestanding walls. Their ashlar type construction in Machu Picchu uses the classic Inca architectural style of polished dry-stone walls of regular shape. The Incas were masters of this technique, in which blocks of stone are cut to fit together tightly without mortar. Many junctions are so perfect that not even a knife fits between the stones. The structures have persisted in the high earthquake region because of the flexibility of the walls and that in their double wall architecture, the two portions of the walls incline into each other.\n\nA wall's style and method of construction will vary, depending on the type of stone available, its intended use and local tradition. Most older walls are constructed from stones and boulders cleared from the fields during preparation for agriculture (\"field stones\") but many also from stone quarried nearby. For modern walls, quarried stone is almost always used. The type of wall built will depend on the nature of the stones available.\n\nOne type of wall is called a \"double\" wall and is constructed by placing two rows of stones along the boundary to be walled. The foundation stones are ideally set into the ground so as to rest firmly on the subsoil. The rows are composed of large flattish stones, diminishing in size as the wall rises. Smaller stones may be used as chocks in areas where the natural stone shape is more rounded. The walls are built up to the desired height layer-by-layer (\"course by course\") and, at intervals, large tie-stones or \"through stones\" are placed which span both faces of the wall and sometimes project. These have the effect of bonding what would otherwise be two thin walls leaning against each other, greatly increasing the strength of the wall. Diminishing the width of the wall as it gets higher, as traditionally done in Britain, also strengthens the wall considerably. The voids between the facing stones are carefully packed with smaller stones (\"filling\", \"hearting\").\n\nThe final layer on the top of the wall also consists of large stones, called \"capstones\", \"coping stones\" or \"copes\". As with the tie stones, the capstones span the entire width of the wall and prevent it breaking apart. In some areas, such as South Wales, there is a tradition of placing the coping stones on a final layer of flat stones slightly wider than the top of the wall proper (\"coverbands\").\n\nIn addition to gates a wall may contain smaller purposely built gaps for the passage or control of wildlife and livestock such as sheep. The smaller holes usually no more than 8  inches in height are called 'Bolt Holes' or 'Smoots'. Larger ones may be between eighteen and 24 inches in height, these are called a 'Cripple Hole'.\n\nBoulder walls are a type of single wall in which the wall consists primarily of large boulders, around which smaller stones are placed. Single walls work best with large, flatter stones. Ideally, the largest stones are being placed at the bottom and the whole wall tapers toward the top. Sometimes a row of capstones completes the top of a wall, with the long rectangular side of each capstone perpendicular to the wall alignment.\n\nGalloway dykes consist of a base of double-wall construction or larger boulders with single-wall construction above. They appear to be rickety, with many holes, which deters livestock (and people) from attempting to cross them. These dykes are principally found in locations with exceptionally high winds, where a solid wall might be at risk of being unsettled by the buffeting. The porous nature of the wall significantly reduces wind force but takes greater skill to construct. They are also found in grazing areas where they are used to maximize the utility of the available stones (where ploughing was not turning up ever more stones).\n\nAnother variation is the \"Cornish hedge\" or Welsh \"clawdd\", which is a stone-clad earth bank topped by turf, scrub, or trees and characterised by a strict inward-curved batter (the slope of the \"hedge\"). As with many other varieties of wall, the height is the same as the width of the base, and the top is half the base width.\n\nDifferent regions have made minor modifications to the general method of construction — sometimes because of limitations of building material available, but also to create a look that is distinctive for that area. Whichever method is used to build a dry stone wall, considerable skill is required. Correcting any mistakes invariably means disassembling down to the level of the error. Selection of the correct stone for every position in the wall makes an enormous difference to the lifetime of the finished product, and a skilled waller will take time making the selection.\n\nAs with many older crafts, skilled wallers, today, are few in number. With the advent of modern wire fencing, fields can be fenced with much less time and expense using wire than using stone walls; however, the initial expense of building dykes is offset by their sturdiness and consequent long, low-maintenance lifetimes. As a result of the increasing appreciation of the landscape and heritage value of dry stone walls, wallers remain in demand, as do the walls themselves. A nationally recognised certification scheme is operated in the UK by the Dry Stone Walling Association, with four grades from Initial to Master Craftsman.\n\nNotable examples include:\n\nWhile the dry-stone technique is generally used for field enclosures, it also was used for buildings. The traditional turf-roofed Highland blackhouse was constructed using the double wall dry stone method. When buildings are constructed using this method, the middle of the wall is generally filled with earth or sand in order to eliminate draughts. During the Iron Age, and perhaps earlier, the technique also was used to build fortifications such as the walls of Eketorp Castle (Öland, Sweden), Maiden Castle, North Yorkshire, Reeth, Dunlough Castle in southwest Ireland and the rampart of the Long Scar Dyke. Many of the dry-stone walls that exist today in Scotland can be dated to the 14th century or earlier when they were built to divide fields and retain livestock. Some extremely well built examples are found on the lands of Muchalls Castle.\n\nDry stone walls can be built against embankments or even vertical terraces. If they are subjected to lateral earth pressure, they are retaining walls of the type gravity wall. The weight of the stones resists the pressure from the retained soil, including any surcharges, and the friction between the stones causes most of them to act as if being a monolithic gravity wall of the same weight. Dry stone retaining walls were once built in great numbers for agricultural terracing and also to carry paths, roads and railways. Although dry stone is seldom used for these purposes today, a great many are still in use and maintained. New ones are often built in gardens and nature conservation areas. Dry stone retaining structures continue to be a subject of research.\n\nSince at least the Middle Ages some bridges capable of carrying horse or carriage traffic have been constructed using drystone techniques. An example of a well-preserved bridge of this type is a double arched limestone bridge in Alby, Sweden on the island of Öland, \"(shown at right)\".\n\nIn northeastern Somalia, on the coastal plain 20 km to Aluula's east are found ruins of an ancient monument in a platform style. The structure is formed by a rectangular dry stone wall that is low in height; the space in between is filled with rubble and manually covered with small stones. Relatively large standing stones are also positioned on the edifice's corners. Near the platform are graves, which are outlined in stones. 24 m by 17 m in dimension, the structure is the largest of a string of ancient platform and enclosed platform monuments exclusive to far northeastern Somalia. Burial sites near Burao in the northwestern part of the country likewise feature a number of old stelae.\n\nIn Great Britain, Ireland and Switzerland, it is possible to find small dry stone structures built as signs, marking mountain paths or boundaries of owned land. In many countries, cairns, as they are called in Scotland, are used as road and mountain top markers.\n\n\n\n"}
{"id": "23591022", "url": "https://en.wikipedia.org/wiki?curid=23591022", "title": "Energy certificate", "text": "Energy certificate\n\nAn energy certificate is a transferable certificate, record or guarantee, in any form (including electronic) in relation to the amount of a specific type of energy or material goods consumed by an energy conversion device in the production of a quantity of energy or material goods and/or the attributes of the method and quality of its production.\n\nEnergy certificates for renewable energy are also referred to as:\n\nEnergy certificates issued under national legislation are normally used to provide evidence of compliance with an obligation on electricity producers, suppliers or consumers to use energy of a specific type or in order to qualify for financial support: qualifying plant are often high-quality cogenerators, or produce electricity from renewable sources. Examples of this within Europe are the Renewable Obligation Certificates (ROCs) issued under the Renewables Obligation, and Levy Exemption Certificates (LECs) issued under the Climate Change Levy - originally part of the Finance Act 2001 - within the UK; Certificati Verdi within Italy; Elcerts within Sweden; and also within the three regions (Brussels, Flanders and Wallonia) of Belgium. At the time of writing, almost all such support schemes are national in character only, the transfer of certificates to and from other countries not being the intention of the policymakers. A notable exception is the Climate Change Levy: LECs are issued by the UK regulator to electricity producers both in the UK and in a number of European countries and exported to the UK, where they are purchased as proof of production of renewable energy production.\n\nThe European Union has also created internationally-transferable \"guarantees of origin\" to provide proof to consumers of the source of their electricity, as required by Directive 2009/72/EC: these are used by electricity suppliers when calculating the proportions of energy sources (e.g. fossil, nuclear etc.) in their supplied energy; and by government in calculating the \"residual mix\" (i.e. the blend of different sources of electricity produced in a country, adjusted for imports and exports. Directive 2009/28/EC and Directive 2012/27/EC give life to (respectively) guarantees of origin for renewable energy and highly-efficient cogeneration, for use within the European Union and those countries with which it is bound by treaty (currently the European Economic Area and Energy Community of South East Europe countries). The international transfer of guarantees of origin is facilitated by the Association of Issuing Bodies' European Energy Certificate System. \n\nEnergy certificates are also used in other countries, including the United States of America, Australia, Turkey and Japan.\n\n The Environmental Tracking Network of North America (ETNNA)\n"}
{"id": "19982813", "url": "https://en.wikipedia.org/wiki?curid=19982813", "title": "Energy in Armenia", "text": "Energy in Armenia\n\nEnergy in Armenia describes energy and electricity production, import and consumption in Armenia. \n\nArmenia has no proven reserves of oil or natural gas and currently imports nearly all gas it from Russia. The Iran-Armenia Natural Gas Pipeline has the capacity to provide twice the country's 2008 natural gas consumption and has the potential to provide energy security for Armenia as an alternative to the Russian-dominated imports that flow through the Georgian border.\n\nDespite a lack of fossil fuel, Armenia has significant domestic electricity generation resources. The Armenian electrical energy sector has had a surplus capacity ever since emerging from a severe post-Soviet crisis in the mid-1990s thanks to the reopening of the nuclear power station at Metsamor. The Metsamor Nuclear Power Plant provides 42.9% of the country's electricity. Armenia has plans to build a new NPP in order to replace the aging Metsamor which was built in 1979. The country also has eleven hydroelectric power plants and has plans to build a geothermal power plant in Syunik. Most of the rest of Armenia's electricity is generated by the natural gas-fired thermal power plants in Yerevan (completed in 2010) and Hrazdan.\n\nUpon gaining independence, Armenia signed the European Energy Charter in December 1991, the charter is now known as the Energy Charter Treaty which promotes integration of global energy markets. Armenia is also a partner country of the EU INOGATE energy programme, which has four key topics: enhancing energy security, convergence of member state energy markets on the basis of EU internal energy market principles, supporting sustainable energy development, and attracting investment for energy projects of common and regional interest. Since 2011, Armenia holds observer member status in the EU's Energy Community.\n\nIt is estimated that nearly 80 percent of Armenia's energy system is under Russian control. \n\nBefore collapse of USSR oil imports made up for about 50% primary energy supply in Armenia, which were as high as 8000 ktoe compared to some 3100 ktoe in 2016 . \n\nBack then oil imports made its way to Armenia via a direct rail link from Armenia-Georgia-Russia, but since the Abkhazia-Georgia border is closed fuel is transported across the Black Sea to Georgia from where it makes its way to Armenia via rail cars. Further restriction to Armenian oil imports represents economic blockade maintained by Azerbaijan to the East, and Turkey to the West. The blockade began shortly after break-out of Nagorno-Karabakh struggle for independence and was upheld ever since, despite a cease fire agreement in 1994.\n\nTotal primary energy supply in Armenia in 2016 amounted to 3121 ktoe (1000 tonnes of oil equivalent). This roughly matches or surpasses production of previous years.\n\nArmenia has no proven oil or gas reserves. Earlier explorations failed to deliver satisfactory results in the past .\n\nIn 2018 new permits for oil and gas exploration were issued to Tashir Group affiliated companies.\n\nAccording to ArmStat no oil was imported in 2016, but rather its refinement products.\n\nArmenian and Iranian authorities have for years been discussing an oil pipeline (distinct from the existing Iran-Armenia natural gas pipeline) that will pump Iranian oil products to Armenia; however, as of early 2011, no concrete dates have been set for the construction. Armenian Energy Minister Armen Movsisian has said that the construction will take two years and cost Armenia about $100 million. Earlier Iran's Oil Minister has said that the 365-kilometer pipeline could go on stream by 2014. Iran plans to export 1.5 million liters of gasoline and diesel fuel a day to Armenia through the pipeline; Armenia’s annual demand for refined oil products stands at around 400,000 metric tons.\n\nNatural gas represents a large portion of total energy consumption in Armenia, accounting for 50% and is the primary means of winter heating in the country. \n\nGazprom Armenia (owned by the Russian gas giant Gazprom) owns the natural gas pipeline network within Armenia and holds a monopoly over the import and distribution of natural gas to consumers and businesses. \n\nArmenia's thermal power stations (which supply approximately 24% of Armenia's electricity needs) run on natural gas, making Armenia (at the present time) dependent on imported Russian gas. \n\nThe Russian gas export monopoly Gazprom supplies Armenia with gas through a pipeline that runs through Georgia. In 2007, Gazprom provided Armenia with just under 2 billion cubic meters of natural gas. As a transit fee, Armenia pays Georgia approximately 10% of the gas that was destined to reach Armenia. Russian natural gas supplies to Georgia and Armenia are provided by two main pipelines: the North Caucasus-Transcaucasus pipeline (1,200 mm diameter) and the Mozdok-Tbilisi pipeline (700 mm diameter).\n\nIn 2008, Armenia imported 2.2 billion cubic meters of natural gas from Russia.\n\nA new gas pipeline, the Iran-Armenia Natural Gas Pipeline, was completed in October, 2008. It is owned and operated by Gazprom Armenia and links Armenia to neighboring Iran, which has the world's second largest natural gas reserve after Russia. It has a capacity to pump 2.3-2.5 billion cubic meters of Iranian gas per year. However, although Iran is ready to export gas to Armenia, the Armenian Ministry of Energy claimed in October 2008 that it \"does not yet have a need\" for Iranian gas. Analysts have said that Armenia's reluctance to import Iranian gas is a result of pressure from Russia which maintains a monopoly over Armenia's natural gas market.\n\nGazprom wholly owns a crucial 24-mile section of the pipeline which Armenia surrendered in exchange for natural gas supplies from Russia at prices well below the European average until 2009. According to an analyst, Armenia \"effectively bargained away its future prospects for energy sources in return for cheaper prices now.\" While Armenia could diversify its gas supply, with control of the Iran-Armenia gas pipeline, Gazprom now controls the competitors' supply.\n\nIn 2009 Armenia was importing 1-1.5 million cubic meters of Iranian natural gas, paying for this by electricity exports. In 2010 Iran will sell about 150 million cubic meters of natural gas to Armenia. A natural gas measuring center was installed late 2009/early 2010 at the Armenian-Iranian border to replace a provisional gas measuring station.\n\nIn 2018 as part of gas for electricity swap deal Armenia receives about 370 million cubic meters of gas a year from Iran, which is converted into electricity and is shipped back to Iran. \n\nAccording to the agreements reached in 2017 by Karapetyan government gas import price stands at $150 for one thousand cubic meters throughout year 2018. Gazprom Armenia sells it to Armenian households at almost $300.\n\nThe examination done by the working group set by the instruction of PM Pashinyan revealed in October 2018 that gas tariffs can be reduced by at least 10%.\n\nSince 1996 three main energy sources for electricity generation in Armenia were natural gas, nuclear power and hydropower.\nDespite a lack of fossil fuel, Armenia has significant domestic electricity generation resources. In 2006, non-thermal domestic electricity generation accounted for 76% of total generation: 43% nuclear and 33% hydroelectric. In comparison, in 2002, these numbers were 56%, 32%, and 26%.\n\nIn 2006, Armenia's power plants generated a total of 5,940.9 million KWh of electricity of which 5,566.7 million KWh were delivered (374.2 million KWh – or 6.3% – was consumed by the producing plants). Thus, in 2006, Armenia's power plants \"on average\" generated 678.2 MW of power, while the country's electricity consumption rate \"on average\" was 635.5 MW.\n\nArmenia has a total of 11 power stations and 17 220 kV substations. A map of Armenia's National Electricity Transmission Grid can be found at the website of the Global Energy Network Institute here .\n\nArmenia's Metsamor Nuclear Power Plant has an installed capacity of 815 MW, though only one unit of 407.5 MW is currently in operation. \n\nBecause Turkey despite of its WTO obligation illegally blockades Armenian borders nuclear fuel must be flown in from Russia. Used fuel is sent back to Russia.\n\nDespite an abundance of renewable energy sources in the country, the government of Armenia is currently discussing the issue of constructing a new nuclear power plant.\n\nDuring 2010-2017 thermal power plants (running on imported natural gas from Russia and Iran) provided about one-third of Armenia's electricity.\n\nThermal power plants (running on natural gas) in Armenia have an established capacity of 1,756 MW.\n\nThe following table lists the three thermal power plants which together account for 24% of Armenia's domestic electricity generation.\n\nIn April 2010, a new natural gas-fired thermal power plant was inaugurated in Yerevan, making it the first major energy facility built in the country since independence. The plant will reportedly allow Armenia to considerably cut back on use of natural gas for electricity production, because officials say it will also be twice as efficient as the plant’s decommissioned unit and four other Soviet-era facilities of its kind functioning in the central Armenian town of Hrazdan. With a capacity of 242 megawatts, its gas-powered turbine will be able to generate approximately one-quarter of Armenia’s current (as of 2010) electricity output. The state-of-the-art plant was built in Yerevan in place of an obsolete facility with a $247 million loan provided by the Japanese government through the Japan Bank of International Cooperation (JBIC). The long-term loan was disbursed to the Armenian government on concessional terms in 2007.\n\nArmenia’s energy sector will expand further after the ongoing construction of the Hrazdan thermal plant’s new and even more powerful Fifth Unit. Russia’s Gazprom monopoly acquired the incomplete facility in 2006 as part of a complex agreement with the Armenian government that raised its controlling stake in the Armenian gas distribution network to a commanding 80 percent. The Russian giant pledged to spend more than $200 million on finishing its protracted construction by 2011.\n\nThe new Yerevan and Hrazdan TPP facilities will pave the way for large-scale Armenian imports of natural gas from neighboring Iran through a pipeline constructed in late 2008. Armenia began receiving modest amounts of Iranian gas in May 2009. With Russian gas essentially meeting its domestic needs, it is expected that the bulk of that gas will be converted into electricity and exported to the Islamic Republic.\n\nIn late December 2010, the Armenian Energy Ministry announced that the fifth block of the Hrazdan thermal power plant will go online by April 2011. Although construction on the fifth block began in the late 1980s, the Armenian government tried to unsuccessfully finish it in the late 1990s. The current project is part of a 2006 deal between Gazprom and the Armenian government, in which Gazprom acquired the incomplete facility and increased its stake in Armenia's gas distribution network, in turn pledging to spend $200 million in completing the project by 2011.\n\nHydropower plants have an established capacity of 1,038 MW.\n\nThe economically justified hydropower potential of Armenia is around 3.600 GWh/year. From this amount, 1.500 GWh/year (or about 42% of economically justified hydropower potential) has been developed already.\n\nArmenia has 9 hydroelectric power plants which together accounted for 33% of its domestic electricity generation. The plants are grouped along two cascades: the Sevan–Hrazdan Cascade and the Vorotan Cascade. The following table lists the details of each cascade:\n\nBy 2020, it is expected that the Meghri HPP (also known as the Araks Hydro Power Plant) with 140 MW capacity and the Loriberd HPP with 60 MW capacity will be built with the cumulative generation of 1,012 million kWh/year. The Meghri Hydro Power Plant is a joint Armenian-Iranian project to be constructed on the Araks River near Armenia's southern border town of Meghri.\n\nIn 2010, the energy ministers of Armenia and Iran signed a document on the long-anticipated construction of two hydropower stations on the Arax River. The agreement stipulates that the $323 million project will be fundamentally financed and operated by Iran, 793 million kWh of energy transported to Iran annually, and the stations transferred to Armenia’s ownership 15 years later. Construction was expected to commence in 2011 and take five years to complete. By 2018 construction is not completed.\n\nAccording to a USAID sponsored report, 313 small hydroelectric power plants (small HPPs) with an installed capacity of 243.366 MW and an average yearly electricity production of 737.38 GWh are installed in the country. In 2006, the small HPPs produced 166.6 GWh of electricity.\n\nAccording to a study sponsored by the United States Department of Energy (DOE) and the United States Agency for International Development (USAID) in 2002-2003, the \"theoretical\" wind power potential of Armenia is 4,900 MWe in 4 zones with a total area of 979 km.\n\nAs of 2008, the Lori 1 Wind power plant is Armenia's only wind power plant. Completed in December 2005 by the Iranian company \"Sunir\" with funding from Iran, it consists of 4 wind turbines and has a capacity of 2.64 MWe. It is located along the Bazum Mountains at Pushkin Pass () in Armenia's northern region of Lori. In 2006, the Lori 1 WPP generated only 2.6 GWh of electricity (a yearly average of 296.8 KWe—about 11% of installed capacity).\n\nWind power in Armenia is underdeveloped and as of 2008, Armenia has only one wind power farm located in the Lori marz. The Armenian and Iranian energy sectors are currently jointly constructing the Iran-Armenia Wind Farm which is set to become the country's largest wind farm, having an installed electric capacity of 90 MW.\n\nAccording to the report of Renewable Energy Roadmap for Armenia () the technical potential of the solar energy in the country is exceeding 1000 MW, or around 2% of the country's annual energy consumption. Solar energy utilization in the country remains low due to solar's tendency for less efficient and less reliable energy generation in comparison with nuclear, natural gas and hydroelectric energy. \n\nArmenia is constructing the Jermaghbyur Geothermal Power Plant which will be the country's largest geothermal power plant having an installed electric capacity of 150 MW.\n\nIn addition to generating electricity, both the Yerevan Thermal Power Plant and the Hrazdan Thermal Power Plants can provide thermal energy to consumers and industry.\n\n\n"}
{"id": "33377106", "url": "https://en.wikipedia.org/wiki?curid=33377106", "title": "Energy in Oman", "text": "Energy in Oman\n\nEnergy use in Oman was 175 TWh and 61 TWh per million people in 2009. In 2008, primary energy use in Oman grew to 191 TWh and 69 TWh per million people.\n\nOman is a country in the Middle East. Its current GDP per capita has expanded continuously over the past 50 years. It grew 339% in the 1960s and reached a peak growth of 1,370% in 1976.. Oman both imports and exports energy.\n\nWhen Oman declined as an entrepot for arms and slaves in the mid-19th century, much of its former prosperity vanished; the economy turned almost exclusively to agriculture, camel and goat herding, fishing, and traditional handicrafts. Today, petroleum (oil) exports fuel the economy. Revenues from petroleum products have enabled Oman's dramatic development and modernization over the past 300 years.\n\nOil was first discovered in 1964, near Fahud in the western desert. Petroleum Development Oman (PDO) began production in August 1967. The Omani Government owns 60% of PDO, and foreign interests own 40% (Royal Dutch Shell owns 34%; the remaining 6% is owned by Total and Partex). In 1976, Oman's oil production rose to 366,000 barrels (58,000 m³) per day but declined to about 285,000 barrels (45,000 m³) per day in the late 1980s due to the depletion of recoverable reserves. From 1981 to 1986, Oman compensated for declining oil prices by increasing production levels to 600,000 b/d; however, when oil prices collapsed in 1986, revenues dropped dramatically. Production was cut back temporarily in coordination with the Organization of Petroleum Exporting Countries (OPEC). Production levels again reached 600,000 b/d by mid-1987, which helped increase revenues. Oman's economic performance improved significantly in 1999 due largely to the mid-year upturn in oil prices. The government moved ahead with privatization of its utilities, and the development of the commercial law to encourage foreign investment. Oman liberalized its markets in an effort to join the World Trade Organization (WTO) and was accepted in 2000. By the mid-2000s, production had climbed to more than 900,000 b/d and where they remain. \nOman is not a member of OPEC.\n\nIn November 2017, Oman Oilfield received steam generated from 1,021 MW Solar Plant.\n\nOman LNG is an LNG plant in operation since September 2000. It is supplied with gas in central Oman from Saih Rowl, the gas field is operated by Petroleum Development Oman (PDO).\n\n"}
{"id": "33335105", "url": "https://en.wikipedia.org/wiki?curid=33335105", "title": "Energy in Yemen", "text": "Energy in Yemen\n\nEnergy in Yemen describes energy and electricity production, consumption and import in Yemen. Energy policy of Yemen will describe the politics of Yemen related to energy more in detail. Yemen n is net energy exporter.\n\nPrimary energy use in Yemen was 87 TWh and 4 TWh/million people in 2008 and 88 TWh (4 TWh/M) in 2009.\n\nAccording to the World Bank, Yemen has the lowest level of electricity connection in the Middle East, with only 40% of the population having access to electricity. Rural areas are particularly badly affected. Industrial concerns, hospitals and hotels have their own back-up generators. To address these shortages, a 340-MW gas-fired power plant is currently under construction-and close to completion-at Marib. Further expansion to the facility, which will add an additional 400 MW of output, is already planned. Yemen has received considerable support for the development of its power generation network in recent years, with contributions coming from Saudi Arabia, France, the US, as well as multilateral donors such as the World Bank. Consequently, a National Rural Electrification Program is now in place and the construction of three substations, along with the necessary transmission lines, is currently under way. Yemen is also looking into the development of wind power, although plans for the construction of a nuclear power generating facility have been shelved. Electrical production is 5.665 billion kWh (2007 estimate). Electrical consumption is about 4.133 billion kWh.\n\nYemen population increased 16.0% in five years 2004-2009. According to OECD/World Bank population growth in Yemen was from 20 million to 24 million in 6 years (2004-2010).\n\nYemen LNG (YLNG) is the first Liquefied natural gas (LNG) project in Yemen.\n\n"}
{"id": "16679865", "url": "https://en.wikipedia.org/wiki?curid=16679865", "title": "Glacier growing", "text": "Glacier growing\n\nGlacier growing, artificial glaciation or glacier grafting, is a practice carried out in the Hindu Kush and Himalaya regions aimed at creating small new glaciers to increase water supply for crops and in some cases to sustain micro hydro power. In order to encourage the growth of a glacier local farmers acquire ice from naturally occurring glaciers, and carry it to high altitude areas where the ice is put inside a small cave dug out in a scree-slope. Along with the ice other ingredients such as water, salt, sawdust, wheat husks and charcoal are also placed at the site. The use of glacier grafting is an old skill of the mountain farmers of Baltistan and Gilgit, where it is used for irrigation purposes since at least the 19th century. This technique was described by Lieutenant David Lockhart Robertson Lorimer (1876–1962) in the 1920s. Allegedly glacier grafting also has been used to block mountain passes.\n\nIn the high Himalaya water is the limiting factor for agriculture and many farmers experience scarcity of water in late autumn - a period critical to the maturation of crops. Farmers living in watersheds without glaciers are especially vulnerable since they largely depend on snow melt for irrigation, in contrast to other areas where glaciers are a reliable source of water. In such communities glacier grafting is often attempted as a means to encourage the growth of new glaciers and thus ensure the existence of water resources.\n\nThe first step involves looking for a suitable location to glacier growing. The preferred terrain, according to glacier growers in Baltistan and Gilgit, is in shadowed scree-slopes overlooked by steep headwalls. Commonly the sites are located between 4,000-5,000 metres above sea level. Such locations are susceptible to snowfall and avalanches during winter and spring, creating an environment conducive to the accumulation of ice.\n\nIce is transported in baskets of woven willow twigs by teams of two and two, who take turns to carry the baskets. This usually involves ascents from lower lying valleys (around 2,000-3,000 metres above sea level) up to the site selected for the glacier growing.\n\nSimilar efforts are being carried out by the noted engineer Chewang Norphel, in the adjacent Ladakh region.\n\n"}
{"id": "56451291", "url": "https://en.wikipedia.org/wiki?curid=56451291", "title": "Hellenistic theatre of Dion", "text": "Hellenistic theatre of Dion\n\nThe largest building of the Archaeological Park of Dion in northern Greece is the Hellenistic-era theatre. It is located in the south of the village of Dion, Pieria and is often used during the summer for performances of the Olympus Festival.\n\nThe theatre is located approximately 180 meters south of the entrance to the archaeological park.\n\nThe form of the theatre corresponds to the typical theatre of Greek antiquity. It is an open-air structure that was built in a northeastern direction on the slope of a low, natural (partially heaped) hill. The \"orchestra\" was built on mashed soil and was surrounded by a drainage construction, to drain the rainwater. The drainage is uncovered, over two bridges it could be crossed by the actors. The \"orchestra\" has a diameter of about 26 meters. The stage was probably made of wood and was a bit higher than the current stage. Underneath the \"orchestra\" was an underground corridor, connecting two rooms.\n\nUnique to Hellenistic theatres was the type of seats of the auditorium, the \"cavea\"; The semicircular rows of seats were covered with 50 by 50 by 7 centimeters of mud bricks, the seats were a half brick width high. Before the beginning of the Roman period, the seats were covered with marble. The current form of the theater is the result of a modern reconstruction on the antique foundations. The seats in the spectator area are now covered with wooden boards.\n\nThe gable of the theater building was adorned with a Doric entablature; the roof was covered with tiles in the Laconic style.\n\nKing Archelaos held a nine-day festival in honor of the nine Pieric Muses, which also included theatre competitions. He invited Euripides to Dion, who wrote the plays of Archelaos and the Bacchae. Both plays were probably also performed in Dion.\n\nThe current theatre was built during the Hellenistic period, presumably during the reign of King Philip V. An earlier theatre occupied the same site, presumably destroyed during the assault of the Aetolian League, around 220 BC. Philip V immediately rebuilt the city of Dion, the shrines and the theatre. Within the structure was found a large quantity of coins depicting Philip V. In Roman times (from 168 BC) were removed useful building materials of the theatre and built a Roman theater near the sanctuary of Zeus.\n\nAfter completion of renovation work, the theatre has been regularly hosting performances of the Olympus Festival since 1991.\n\nThe theatre was discovered in 1806 by the English explorer William M. Leake. In 1855 the find was confirmed by the French archaeologist Léon Heuzey. The first test excavations were carried out in 1970 under the direction of Professor G. Bakalakis. The regular excavation work began in 1973 under the direction of Professor Pandermalis. After the works rested for two years, they were resumed in 1977 by the architect and archaeologist Professor G. Karadedos. Since the building in the Roman period, was not paid any further attention, its basic structure remained unchanged. The excavations were carried out very carefully; thus, valuable information was obtained to allow conclusions about the original condition of the complex. The orchestra, the stage, the drainage, parts of the theater building and the main part of the Cavea were found. After the excavations were completed in 1988, Karadedos implemented a study for the “Conservation, Promotion and Temporary Re-operation of the Hellenistic Theatre of Dion”.\n\n\n"}
{"id": "170465", "url": "https://en.wikipedia.org/wiki?curid=170465", "title": "Jacob Le Maire", "text": "Jacob Le Maire\n\nJacob Le Maire (c. 1585, Antwerp or Amsterdam - 22 December 1616, at sea) was a Dutch mariner who circumnavigated the earth in 1615 and 1616. The strait between Tierra del Fuego and Isla de los Estados was named the Le Maire Strait in his honor, though not without controversy. It was Le Maire himself who proposed to the council aboard \"Eendracht\" that the new passage should be called by his name and the council unanimously agreed with Le Maire. The author or authors of \"The Relation\" took \"Eendracht\" captain Schouten’s side by proclaiming:\n\n\"Eendracht\" then rounded Cape Horn, proving that Tierra del Fuego was not a continent.\n\nJacob Le Maire was one of 22 children of Maria Walraven of Antwerp and Isaac Le Maire (1558–1624) of Tournai, who was then already a prosperous merchant in Antwerp. Isaac and Maria married shortly before the Spanish siege of Antwerp in 1585 after which they fled to settle in Amsterdam. Jacob is thought to have been the oldest son, born perhaps the same year. Isaac was very successful in Amsterdam, and became one of the founders of the Dutch East Indies Company (VOC). However, in 1605 Isaac Le Maire was forced to leave the company after a dispute and for the next decade tried to break the company's monopoly on the trade to the East Indies.\n\nBy 1615 Isaac had established a new company (the \"Australian Company\") with the goal to find a new route to the Pacific and the Spice Islands, thereby evading the restrictions of the VOC. He contributed to the outfitting of two ships, the \"Eendracht\" and \"Hoorn\", and put his son Jacob in charge of trading during the expedition. The experienced ship master Willem Schouten was captain of the \"Eendracht\" and a participant of the enterprise in equal shares with Isaac Le Maire.\n\nOn 14 June 1615 Jacob le Maire and Willem Schouten sailed from Texel in the United Provinces. On 29 January 1616 they rounded Cape Horn, which they named for the \"Hoorn\", which was lost in a fire. The Dutch city of Hoorn was also the birthplace of Schouten. After failing to moor at the Juan Fernández Islands in early March, the ships crossed the Pacific in a fairly straight line, visiting several of the Tuamotus. Between 21 and 24 April 1616 they were the first Westerners to visit the (Northern) Tonga islands: \"Cocos Island\" (Tafahi), \"Traitors Island\" (Niuatoputapu), and \"Island of Good Hope\" (Niuafo'ou). On 28 April they discovered the Hoorn Islands (Futuna and Alofi), where they were very well received and stayed until 12 May. They then followed the north coasts of New Ireland and New Guinea and visited adjacent islands, including, on 24 July, what became known as the Schouten Islands.\n\nThey reached the Northern Moluccas in August and finally Ternate, the headquarters of the VOC, on 12 September 1616. Here they were enthusiastically welcomed by Governor-General Laurens Reael, admiral Steven Verhagen, and the governor of Ambon, Jasper Jansz.\n\nThe \"Eendracht\" sailed on to Java and reached Batavia on 28 October with a remarkable 84 of the original 87 crew members of both ships on board. Although they had opened an unknown route, Jan Pietersz Coen of the VOC claimed infringement of its monopoly of trade to the Spice Islands. Le Maire and Schouten were arrested and the \"Eendracht\" was confiscated. After being released, they returned from Batavia to Amsterdam in the company of Joris van Spilbergen, who was on a circumnavigation of the earth himself, be it via the traditional Strait of Magellan.\n\nLe Maire was aboard the ship \"Amsterdam\" on this journey home, but died en route. Van Spilbergen was at his deathbed and took Le Maire's report of his trip, which he included in his book \"Mirror of the East and West Indies\". The rest of the crew arrived in the Netherlands on 1 July 1617, two years and 17 days after they departed. Jacob's father Isaac challenged the confiscation and the conclusion of the VOC, but it took him until 1622 until a court ruled in his favor. He was awarded 64,000 pounds and retrieved his son's diaries (which he then published as well), and his company was allowed trade via the newly discovered route. Unfortunately, by then, the Dutch West Indies Company had claimed the same waters.\n\n\n"}
{"id": "5874274", "url": "https://en.wikipedia.org/wiki?curid=5874274", "title": "List of Hexathelidae species", "text": "List of Hexathelidae species\n\nThis page lists all described species of the spider family Hexathelidae.\n\n\"Bymainiella\" \n\n\"Hexathele\" \n\n\"Mediothele\" \n\n\"Paraembolides\" \n\n\"Plesiothele\" \n\n\"Scotinoecus\" \n\n\"Teranodes\" \n\n"}
{"id": "47085896", "url": "https://en.wikipedia.org/wiki?curid=47085896", "title": "List of Peniophora species", "text": "List of Peniophora species\n\nThis is a list of species in genus \"Peniophora\". , Index Fungorum lists 176 species in the genus.\nA B C D E F G H I J K L M N O P Q R S T U V U W X Y Z\n\n"}
{"id": "27461497", "url": "https://en.wikipedia.org/wiki?curid=27461497", "title": "List of Sisyrinchium species", "text": "List of Sisyrinchium species\n\n\n"}
{"id": "47522164", "url": "https://en.wikipedia.org/wiki?curid=47522164", "title": "List of blizzards", "text": "List of blizzards\n\nThis is a list of blizzards, arranged alphabetically by the continents. The list states blizzards in various countries since 1972.\n\n"}
{"id": "14935505", "url": "https://en.wikipedia.org/wiki?curid=14935505", "title": "List of common weeds of Queensland", "text": "List of common weeds of Queensland\n\nThere are a number of commonly occurring weeds or invasive plant species in Queensland, Australia. These plants typically produce large numbers of seeds, often excellent at surviving and reproducing in disturbed environments and are commonly the first species to colonise and dominate in these conditions. Weeds may reduce native biodiversity, affect agricultural productivity, the environment, human health and amenity.\n\nSome of the more common weeds of Queensland are listed below. Weeds that are not yet common or established but pose a significant threat are identified by an asterix. Weeds that are identified as Weeds of National Significance are noted as \"WoNS\".\n\n\n\n"}
{"id": "9132844", "url": "https://en.wikipedia.org/wiki?curid=9132844", "title": "List of foliage plant diseases (Commelinaceae)", "text": "List of foliage plant diseases (Commelinaceae)\n\nThis is a list of diseases of foliage plants belonging to the family Commelinaceae.\n\n"}
{"id": "18077092", "url": "https://en.wikipedia.org/wiki?curid=18077092", "title": "List of ministers of climate change", "text": "List of ministers of climate change\n\nA list of ministers of climate change or officials in charge of cabinet positions with portfolios dealing primarily with climate change and issues related to mitigation of global warming.\n\n\n"}
{"id": "14693213", "url": "https://en.wikipedia.org/wiki?curid=14693213", "title": "List of mountain peaks of Mexico", "text": "List of mountain peaks of Mexico\n\nThis article comprises three sortable tables of major mountain peaks of Mexico.\n\nThe summit of a mountain or hill may be measured in three principal ways:\n\nOf the 40 highest major summits of Mexico, three peaks exceed elevation, eight peaks exceed , and 28 peaks exceed elevation.\n\nOf these 40 peaks, five are located in Jalisco, five in Coahuila, four in Oaxaca, six in Puebla, four in the state of Mexico, three in Chiapas, two in Nuevo León, two in Veracruz, two in Michoacán, two in Querétaro, two in Durango, two in Chihuahua, two in San Luis Potosí, and one each in Morelos, Tlaxcala, Distrito Federal, Colima, Guerrero, Guanajuato, Zacatecas, Baja California, Aguascalientes, Sinaloa, and Sonora. Volcán Tacaná lies on the international border between Chiapas and Guatemala, and nine other peaks lie on a state border.\n\nOf the 40 most prominent summits of México, only Pico de Orizaba exceeds of topographic prominence, Popocatépetl exceeds , five peaks exceed , and 26 peaks are ultra-prominent summits with at least of topographic prominence.\n\nOf these 40 peaks, five are located in Oaxaca, five in Baja California, four in Puebla, four in Jalisco, four in Nuevo León, four in Coahuila, three in Veracruz, three in México, three in Baja California Sur, two in Michoacán, two in Querétaro, and one each in Morelos, Guerrero, Tlaxcala, Guanajuato, Durango, Chiapas, and Distrito Federal. Five peaks lie on a state border.\n\nOf the 40 most isolated major summits of México, only Pico de Orizaba exceeds of topographic isolation. Four peaks exceed , 14 peaks exceed , and 33 peaks exceed of topographic isolation.\n\nOf these 40 peaks, five are located in Coahuila, four in Baja California, four in Oaxaca, three in Puebla, three in Jalisco, three in Baja California Sur, two in Veracruz, two in Nuevo León, two in Chihuahua, two in Chiapas, two in México, two in Michoacán, two in Querétaro, and one each in Colima, Durango, Guerrero, Sonora, Morelos, Guanajuato, San Luis Potosí, Zacatecas, Tlaxcala, and Nayarit. Six peaks lie on a state border.\n\n\n"}
{"id": "8591764", "url": "https://en.wikipedia.org/wiki?curid=8591764", "title": "List of stars in Musca", "text": "List of stars in Musca\n\nThis is the list of notable stars in the constellation Musca, sorted by decreasing brightness.\n\n\n"}
{"id": "10026727", "url": "https://en.wikipedia.org/wiki?curid=10026727", "title": "List of tropical and subtropical moist broadleaf forests ecoregions", "text": "List of tropical and subtropical moist broadleaf forests ecoregions\n\nThis is a list of tropical and subtropical moist broadleaf forest ecoregions (TSMFs), arranged by ecozone\n\n"}
{"id": "32838600", "url": "https://en.wikipedia.org/wiki?curid=32838600", "title": "Lists of species", "text": "Lists of species\n\nThis is a list of lists of species.\n\n\n\n"}
{"id": "1819715", "url": "https://en.wikipedia.org/wiki?curid=1819715", "title": "Marine geology", "text": "Marine geology\n\nMarine geology or geological oceanography is the study of the history and structure of the ocean floor. It involves geophysical, geochemical, sedimentological and paleontological investigations of the ocean floor and coastal zone. Marine geology has strong ties to geophysics and to physical oceanography.\n\nMarine geological studies were of extreme importance in providing the critical evidence for sea floor spreading and plate tectonics in the years following World War II. The deep ocean floor is the last essentially unexplored frontier and detailed mapping in support of both military (submarine) objectives and economic (petroleum and metal mining) objectives drives the research.\n\nThe Ring of Fire around the Pacific Ocean with its attendant intense volcanism and seismic activity poses a major threat for disastrous earthquakes, tsunamis and volcanic eruptions. Any \"early warning\" systems for these disastrous events will require a more detailed understanding of marine geology of coastal and island arc environments.\n\nThe study of littoral and deep sea sedimentation and the precipitation and dissolution rates of calcium carbonate in various marine environments has important implications for global climate change.\n\nThe discovery and continued study of mid-ocean rift zone volcanism and hydrothermal vents, first in the Red Sea and later along the East Pacific Rise and the Mid-Atlantic Ridge systems were and continue to be important areas of marine geological research. The extremophile organisms discovered living within and adjacent to those hydrothermal systems have had a pronounced impact on our understanding of life on Earth and potentially the origin of life within such an environment.\n\nOceanic trenches are hemispheric-scale long but narrow topographic depressions of the sea floor. They also are the deepest parts of the ocean floor.\n\nThe Mariana Trench (or Marianas Trench) is the deepest known submarine trench, and the deepest location in the Earth's crust itself. A subduction zone where the Pacific Plate is being subducted under the Philippine Sea Plate. The bottom of the trench is further below sea level than Mount Everest is above sea level.\n\n\n\n"}
{"id": "16649968", "url": "https://en.wikipedia.org/wiki?curid=16649968", "title": "Maris Pacifici", "text": "Maris Pacifici\n\nMaris Pacifici is more accurately named the \"Descriptio Maris Pacifici\", Description of the Pacific Ocean. It was the first dedicated map of the Pacific to be printed and is considered an important advancement in cartography.\n\nThis map was drawn by Abraham Ortelius in 1589, based upon a map of America from the same year that was drawn by Frans Hogenberg. Some details of the map may have been influenced by a 1568 description of Japan in a manuscript by Vaz Dourado, rather than a map, hence its peculiar shape.\n\nThe land mass illustrated to the south of all of the Pacific and South America is a representation of Terra Australis.\n\n"}
{"id": "1955573", "url": "https://en.wikipedia.org/wiki?curid=1955573", "title": "Matthew 3:11", "text": "Matthew 3:11\n\nMatthew 3:11 is the eleventh verse of the third chapter of the Gospel of Matthew in the New Testament. The verse occurs in the section relating the preachings of John the Baptist. In this verse he predicts that he will be followed by someone much greater than himself. The main theme of this verse is that John will soon be supplanted by a much greater figure and that John's water baptism is just a preparation for the much greater baptism by fire and spirit that will occur under the second coming of the Christian messiah Jesus, an original Christian concept that, according to Jewish scholars, lacks any fundament in the Hebrew scripture.\n\nIn the King James Version of the Bible the text reads:\n\nThe New International Version translates the passage as:\n\nFor a collection of other versions see BibRef Matthew 3:11\n\nThis verse links up with the Gospel of Mark for the first time since . In Mark this verse is mirrored by and . This verse is also found in Luke at . However the context is somewhat different in Luke John is addressing a receptive multitude in Matthew it is assumed he is still speaking to the Pharisees and Sadducees introduced in . Schweizer notes that despite this, the verse is still written as though it is addressing all Israel. Matthew has also entirely skipped the content found in -. This is understandable as the response from the crowd is not in keeping with the hostile and unrepentant Pharisees and Sadducees.\n\nFrance notes that the word translated as \"after\" is not chronological, rather it means the one who is a follower or disciple. This links in with the reference to shoes. At the time the disciple of a Rabbi would be expected to perform menial chores. However shoes, a word perhaps better translated as sandals, were considered unclean, a tradition that persists in the Middle East today. Thus the disciple would not deal with them, and such a task would be left to the lowest slave. Thus John the Baptist is presenting himself as very lowly indeed. Matthew slightly differs from the wording found in Luke and Mark. In those two gospels John is not worthy of untying the messiah's sandals, in Matthew he is unworthy of carrying them.\n\nJohn predicts a much stronger form of baptism by the Holy Spirit and by fire. It is from this verse that the expression \"baptism by fire\" comes from. Hill notes for many years scholars felt that linking the Holy Spirit with fire, a symbol of God's wrath, clashed with the portrayal of the Spirit elsewhere in the New Testament, which saw it as a purely loving and helpful force incompatible with a destructive judgement. A number of theories were proposed to address this, some translations dropped the word fire to create a less destructive image. Another option is that \"Holy Spirit\" should actually read \"wind\", as the same word can be used for wind and spirit in Greek. This would also link it to the next verse. This all changed with the discovery of the Dead Sea Scrolls found at Qumran, near where John the Baptist was said to be preaching. In a number of the texts the Holy Spirit is linked to God's wrath and judgement leading most scholars to include that the wording here is original and that there were different views of the Holy Spirit circulating in the first century. Nolland notes that many scholars have attempted to use this verse as evidence for the Christian baptism ritual, but he does not believe that Jesus' baptism by fire and holy spirit can be so linked.\n\nWhether the more powerful one coming after is a reference to God or Jesus is a matter of debate. After this verse Jesus immediately enters the narrative, and the corporeal metaphor of carrying his shoes would seem to describe a human figure. On the other hand, this violent imagery contradicts the idea of the Messiah as a bringer of peace. Schnackenburg argues the wording in this passage is deliberately obscure between the two options.\n"}
{"id": "22422342", "url": "https://en.wikipedia.org/wiki?curid=22422342", "title": "Relative species abundance", "text": "Relative species abundance\n\nRelative species abundance is a component of biodiversity and refers to how common or rare a species is relative to other species in a defined location or community. Relative abundance is the percent composition of an organism of a particular kind relative to the total number of organisms in the area. Relative species abundances tend to conform to specific patterns that are among the best-known and most-studied patterns in macroecology. Different populations in a community exist in relative proportions; this idea is known as relative abundance.\n\nRelative species abundance and species richness describe key elements of biodiversity. Relative species abundance refers to how common or rare a species is relative to other species in a given location or community.\n\nUsually relative species abundances are described for a single trophic level. Because such species occupy the same trophic level they will potentially or actually compete for similar resources. For example, relative species abundances might describe all terrestrial birds in a forest community or all planktonic copepods in a particular marine environment.\n\nRelative species abundances follow very similar patterns over a wide range of ecological communities. When plotted as a histogram of the number of species represented by 1, 2, 3, ..., \"n\" individuals usually fit a hollow curve, such that most species are rare, (represented by a single individual in a community sample) and relatively few species are abundant (represented by a large number of individuals in a community sample)(Figure 1). This pattern has been long-recognized and can be broadly summarized with the statement that \"most species are rare\". For example, Charles Darwin noted in 1859 in \"The Origin of Species\" that \"... rarity is the attribute of vast numbers of species in all classes...\"\n\nSpecies abundance patterns can be best visualized in the form of relative abundance distribution plots. The consistency of relative species abundance patterns suggests that some common macroecological \"rule\" or process determines the distribution of individuals among species within a trophic level.\n\nRelative species abundance distributions are usually graphed as frequency histograms (\"Preston plots\"; Figure 2) or rank-abundance diagrams (\"Whittaker Plots\"; Figure 3).\n\nFrequency histogram (Preston plot):\n\nRank-abundance diagram (Whittaker plot):\n\nWhen plotted in these ways, relative species abundances from wildly different data sets show similar patterns: frequency histograms tend to be right-skewed (e.g. Figure 2) and rank-abundance diagrams tend to conform to the curves illustrated in Figure 4.\n\nResearchers attempting to understand relative species abundance patterns usually approach them in a descriptive or mechanistic way. Using a descriptive approach biologists attempt to fit a mathematical model to real data sets and infer the underlying biological principles at work from the model parameters. By contrast, mechanistic approaches create a mathematical model based on biological principles and then test how well these models fit real data sets.\n\nI. Motomura developed the geometric series model based on benthic community data in a lake. Within the geometric series each species' level of abundance is a sequential, constant proportion (\"k\") of the total number of individuals in the community. Thus if \"k\" is 0.5, the most common species would represent half of individuals in the community (50%), the second most common species would represent half of the remaining half (25%), the third, half of the remaining quarter (12.5%) and so forth.\n\nAlthough Motomura originally developed the model as a statistical (descriptive) means to plot observed abundances, the \"discovery\" of his paper by Western researchers in 1965 led to the model being used as a niche apportionment model – the \"niche-preemption model\". In a mechanistic model \"k\" represents the proportion of the resource base acquired by a given species.\n\nThe geometric series rank-abundance diagram is linear with a slope of –\"k\", and reflects a rapid decrease in species abundances by rank (Figure 4). The geometric series does not explicitly assume that species colonize an area sequentially, however, the model fits the concept of niche preemption, where species sequentially colonize a region and the first species to arrive receives the majority of resources. The geometric series model fits observed species abundances in highly uneven communities with low diversity. This is expected to occur in terrestrial plant communities (as these assemblages often show strong dominance) as well as communities at early successional stages and those in harsh or isolated environments (Figure 5).\n\n\"where\":\n\nThe logseries was developed by Ronald Fisher to fit two different abundance data sets: British moth species (collected by Carrington Williams) and Malaya butterflies (collected by Alexander Steven Corbet). The logic behind the derivation of the logseries is varied however Fisher proposed that sampled species abundances would follow a negative binomial from which the zero abundance class (species too rare to be sampled) was eliminated. He also assumed that the total number of species in a community was infinite. Together, this produced the logseries distribution (Figure 4). The logseries predicts the number of species at different levels of abundance (\"n\" individuals) with the formula:\n\n\"where:\"\n\nThe number of species with 1, 2, 3, ..., \"n\" individuals are therefore:\n\nThe constants \"α\" and \"x\" can be estimated through iteration from a given species data set using the values \"S\" and \"N\". Fisher's dimensionless \"α\" is often used as a measure of biodiversity, and indeed has recently been found to represent the fundamental biodiversity parameter \"θ\" from neutral theory (see below).\n\nUsing several data sets (including breeding bird surveys from New York and Pennsylvania and moth collections from Maine, Alberta and Saskatchewan) Frank W. Preston (1948) argued that species abundances (when binned logarithmically in a Preston plot) follow a Normal (Gaussian) distribution, partly as a result of the Central Limit Theorem (Figure 4). This means that the abundance distribution is Lognormal. According to his argument, the right-skew observed in species abundance frequency histograms (including those described by Fisher \"et al.\" (1943)) was, in fact, a sampling artifact. Given that species toward the left side of the \"x\"-axis are increasingly rare, they may be missed in a random species sample. As the sample size increases however, the likelihood of collecting rare species in a way that accurately represents their abundance also increases, and more of the normal distribution becomes visible. The point at which rare species cease to be sampled has been termed \"Preston's veil line\". As the sample size increases Preston's veil is pushed farther to the left and more of the normal curve becomes visible(Figure 6). Williams' moth data, originally used by Fisher to develop the logseries distribution, became increasingly lognormal as more years of sampling were completed.\n\nPreston's theory has an application: if a community is truly lognormal yet under-sampled, the lognormal distribution can be used to estimate the true species richness of a community. Assuming the shape of the total distribution can be confidently predicted from the collected data, the normal curve can be fit via statistical software or by completing the Gaussian formula:\n\n\"where:\"\n\nIt is then possible to predict how many species are in the community by calculating the total area under the curve (\"N\"):\n\nThe number of species missing from the data set (the missing area to the left of the veil line) is simply \"N\" minus the number of species sampled. Preston did this for two lepidopteran data sets, predicting that, even after 22 years of collection, only 72% and 88% of the species present had been sampled.\n\nThe Yule model is based on a much earlier, Galton–Watson model which was used to describe the distribution of species among genera. The Yule model assumes random branching of species trees, with each species (branch tip) having the equivalent probability of giving rise to new species or becoming extinct. As the number of species within a genus, within a clade, has a similar distribution to the number of individuals within a species, within a community (i.e. the \"hollow curve\"), Sean Nee (2003) used the model to describe relative species abundances. In many ways this model is similar to niche apportionment models, however, Nee intentionally did not propose a biological mechanism for the model behavior, arguing that any distribution can be produced by a variety of mechanisms.\n\n\"Note\": This section provides a general summary of niche apportionment theory, more information can be found under niche apportionment models.\n\nMost mechanistic approaches to species abundance distributions use niche-space, i.e. available resources, as the mechanism driving abundances. If species in the same trophic level consume the same resources (such as nutrients or sunlight in plant communities, prey in carnivore communities, nesting locations or food in bird communities) and these resources are limited, how the resource \"pie\" is divided among species determines how many individuals of each species can exist in the community. Species with access to lots of resources will have higher carrying capacities than those with little access. Mutsunori Tokeshi later elaborated niche apportionment theory to include niche filling in unexploited resource space. Thus, a species may survive in the community by carving out a portion of another species' niche (slicing up the pie into smaller pieces) or by moving into a vacant niche (essentially making the pie larger, for example, by being the first to arrive in a newly available location or through the development of a novel trait that allows access previously unavailable resources). Numerous niche apportionment models have been developed. Each make different assumptions about how species carve up niche-space.\n\nThe Unified Neutral Theory of Biodiversity and Biogeography (UNTB) is a special form of mechanistic model that takes an entirely different approach to community composition than the niche apportionment models. Instead of species populations reaching equilibrium within a community, the UNTB model is dynamic, allowing for continuing changes in relative species abundances through drift.\n\nA community in the UNTB model can be best visualized as a grid with a certain number of spaces, each occupied with individuals of different species. The model is zero-sum as there are a limited number of spaces that can be occupied: an increase in the number of individuals of one species in the grid must result in corresponding decrease in the number of individuals of other species in the grid. The model then uses birth, death, immigration, extinction and speciation to modify community composition over time.\n\n\nThe UNTB model produces a dimensionless \"fundamental biodiversity\" number, \"θ\", which is derived using the formula:\n\n\"where\":\n\nRelative species abundances in the UNTB model follow a zero-sum multinomial distribution. The shape of this distribution is a function of the immigration rate, the size of the sampled community (grid), and \"θ\". When the value of \"θ\" is small, the relative species abundance distribution is similar to the geometric series (high dominance). As \"θ\" gets larger, the distribution becomes increasingly s-shaped (log-normal) and, as it approaches infinity, the curve becomes flat (the community has infinite diversity and species abundances of one). Finally, when \"θ\" = 0 the community described consists of only one species (extreme dominance).\n\nAn unexpected result of the UNTB is that at very large sample sizes, predicted relative species abundance curves describe the metacommunity and become identical to Fisher's logseries. At this point \"θ\" also becomes identical to Fisher's formula_2 for the equivalent distribution and Fisher's constant \"x\" is equal to the ratio of birthrate : deathrate. Thus, the UNTB unintentionally offers a mechanistic explanation of the logseries 50 years after Fisher first developed his descriptive model.\n"}
{"id": "3345336", "url": "https://en.wikipedia.org/wiki?curid=3345336", "title": "Riparian zone", "text": "Riparian zone\n\nA riparian zone or riparian area is the interface between land and a river or stream. Riparian is also the proper nomenclature for one of the fifteen terrestrial biomes of the Earth. Plant habitats and communities along the river margins and banks are called riparian vegetation, characterized by hydrophilic plants. Riparian zones are important in ecology, environmental resource management, and civil engineering because of their role in soil conservation, their habitat biodiversity, and the influence they have on fauna and aquatic ecosystems, including grasslands, woodlands, wetlands, or even non-vegetative areas. In some regions the terms riparian woodland, riparian forest, riparian buffer zone, riparian corridor and riparian strip are used to characterize a riparian zone. The word \"riparian\" is derived from Latin \"ripa\", meaning river bank.\n\nRiparian zones may be natural or engineered for soil stabilization or restoration. These zones are important natural biofilters, protecting aquatic environments from excessive sedimentation, polluted surface runoff and erosion. They supply shelter and food for many aquatic animals and shade that limits stream temperature change. When riparian zones are damaged by construction, agriculture or silviculture, biological restoration can take place, usually by human intervention in erosion control and revegetation. If the area adjacent to a watercourse has standing water or saturated soil for as long as a season, it is normally termed a wetland because of its hydric soil characteristics. Because of their prominent role in supporting a diversity of species, riparian zones are often the subject of national protection in a biodiversity action plan. These are also known as a \"Plant or Vegetation Waste Buffer\".\n\nResearch shows that riparian zones are instrumental in water quality improvement for both surface runoff and water flowing into streams through subsurface or groundwater flow. Riparian zones can play a role in lowering nitrate contamination in surface runoff, such as manure and other fertilizers from agricultural fields, that would otherwise damage ecosystems and human health. Particularly, the attenuation of nitrate or denitrification of the nitrates from fertilizer in this buffer zone is important. The use of wetland riparian zones shows a particularly high rate of removal of nitrate entering a stream and thus has a place in agricultural management.\n\nRiparian zones dissipate stream energy. The meandering curves of a river, combined with vegetation and root systems, slow the flow of water, which reduces soil erosion and flood damage. Sediment is trapped, reducing suspended solids to create less turbid water, replenish soils, and build stream banks. Pollutants are filtered from surface runoff, enhancing water quality via biofiltration.\n\nThe riparian zones also provide wildlife habitat, increased biodiversity, and wildlife corridors, enabling aquatic and riparian organisms to move along river systems avoiding isolated communities. Riparian vegetation can also provide forage for wildlife and livestock.\n\nRiparian zones are also important for the fish that live within rivers, such as brook and charr. Impacts to riparian zones can affect fish, and restoration is not always sufficient to recover fish populations.\n\nThey provide native landscape irrigation by extending seasonal or perennial flows of water. Nutrients from terrestrial vegetation (e.g. plant litter and insect drop) are transferred to aquatic food webs. The vegetation surrounding the stream helps to shade the water, mitigating water temperature changes. The vegetation also contributes wood debris to streams, which is important to maintaining geomorphology.\n\nFrom a social aspect, riparian zones contribute to nearby property values through amenity and views, and they improve enjoyment for footpaths and bikeways through supporting foreshoreway networks. Space is created for riparian sports such as fishing, swimming and launching for vessels and paddlecraft.\n\nThe riparian zone acts as a sacrificial erosion buffer to absorb impacts of factors including climate change, increased runoff from urbanization and increased boat wake without damaging structures located behind a setback zone.\n\nThe protection of riparian zones is often a consideration in logging operations. The undisturbed soil, soil cover, and vegetation provide shade, plant litter, and woody material, and reduce the delivery of soil eroded from the harvested area. Factors such as soil types and root structures, climatic conditions and vegetative cover determine the effectiveness of riparian buffering.\n\nThe assortment of riparian zone trees varies from those of wetlands and typically consists of plants that are either emergent aquatic plants, or herbs, trees and shrubs that thrive in proximity to water.\n\nHerbaceous Perennial: \n\nHerbaceous Perennial:\n\nIn western North America and the Pacific coast, the riparian vegetation includes:\n\nRiparian trees\n\nRiparian shrubs\n\nOther plants\n\nIn Asia there are different types of riparian vegetation, but the interactions between hydrology and ecology are similar as occurs in other geographic areas.\n\nTypical riparian vegetation in Temperate New South Wales, Australia include:\n\nTypical riparian zone trees in Central Europe include:\n\nLand clearing followed by floods can quickly erode a riverbank, taking valuable grasses and soils downstream, and later allowing the sun to bake the land dry. Natural Sequence Farming techniques have been used in the Upper Hunter Valley of New South Wales, Australia, in an attempt to rapidly restore eroded farms to optimum productivity.\n\nThe Natural Sequence Farming technique involves placing obstacles in the water's pathway to lessen the energy of a flood, and help the water to deposit soil and seep into the flood zone. Another technique is to quickly establish ecological succession by encouraging fast-growing plants such as \"weeds\" (pioneer species) to grow. These may spread along the watercourse and cause environmental degradation, but may stabilize the soil, place carbon into the ground, and protect the land from drying. The weeds will improve the streambeds so that trees and grasses can return, and later ideally replace the weeds. There are several other techniques used by government and non-government agencies to address riparian and streambed degradation, ranging from the installation of bed control structures such as log sills to the use of pin groynes or rock emplacement.\n\n\n\n"}
{"id": "52111625", "url": "https://en.wikipedia.org/wiki?curid=52111625", "title": "Samandere Waterfall", "text": "Samandere Waterfall\n\nSamandere Waterfall () is a waterfall in Düzce Province, northwestern Turkey. It is the first ever registered natural monument of the country.\n\nThe waterfall is located in Samandere village of Beyköy district, southeast of Düzce. It is far from Beyköy, from the state highway and from the motorway . The road to the waterfall on a length of was widened and asphalted for easy access in 2015.\n\nIn 2016, the municipality of Düzce launched free-of-charge transportation by bus to the waterfall from the city center on daily basis during the summer months.\n\nThe waterfall is on a tributary of Uğur Creek, which flows into Lake Efteni. There is a cave in upstream of the waters forming the waterfall, which submerge and outcrop there. The area consists of monumental trees along the -long stream, three waterfalls and a deep canyon called \"Cadı Kazanı\" (literally: Witches Cauldron). The site is a popular visitor attraction, which offers campsites, picnicing areas and hiking trails for outdoor recreation. The waterfall site features a footbridge and observation decks with railing. \n\nOn December 10, 1988, the waterfall and its surroundings covering an area of , was registered by the Nature Reserve and Nature Parks Administration of the Ministry of Forest and Water Management as the first ever natural monument of the country. The natural monument is run by the Municipality of Düzce according to a protocol signed later by the parts.\n\nThe waterfall sustained great damage following a flood disaster occurred on July 16-17, 2009. It was restored after maintenance works in 2009 and 2010.\n"}
{"id": "826258", "url": "https://en.wikipedia.org/wiki?curid=826258", "title": "Scintillation (physics)", "text": "Scintillation (physics)\n\nScintillation is a flash of light produced in a transparent material by the passage of a particle (an electron, an alpha particle, an ion, or a high-energy photon). See scintillator and scintillation counter for practical applications.\n\nThe process of scintillation is one of luminescence whereby light of a characteristic spectrum is emitted following the absorption of radiation. The emitted radiation is usually less energetic than that absorbed. Scintillation is an inherent molecular property in conjugated and aromatic organic molecules and arises from their electronic structures. Scintillation also occurs in many inorganic materials, including salts, gases, and liquids.\n\nFor photons such as gamma rays, thallium activated NaI crystals (NaI(Tl)) are often used. For a faster response (but only 5% of the output) CsF crystals can be used.\n\nIn organic molecules scintillation is a product of π-orbitals. Organic materials form molecular crystals where the molecules are loosely bound by Van der Waals forces. The ground state of C is 1s 2s 2p. In valence bond theory, when carbon forms compounds, one of the 2s electrons is excited into the 2p state resulting in a configuration of 1s 2s 2p. To describe the different valencies of carbon, the four valence electron orbitals, one 2s and three 2p, are considered to be mixed or hybridized in several alternative configurations. For example, in a tetrahedral configuration the s and p orbitals combine to produce four hybrid orbitals. In another configuration, known as trigonal configuration, one of the p-orbitals (say p) remains unchanged and three hybrid orbitals are produced by mixing the s, p and p orbitals. The orbitals that are symmetrical about the bonding axes and plane of the molecule (sp) are known as σ-electrons and the bonds are called σ-bonds. The p orbital is called a π-orbital. A π-bond occurs when two π-orbitals interact. This occurs when their nodal planes are coplanar.\n\nIn certain organic molecules π-orbitals interact to produce a common nodal plane. These form delocalized π-electrons that can be excited by radiation. The de-excitation of the delocalized π-electrons results in luminescence.\n\nThe excited states of π-electron systems can be explained by the perimeter free-electron model (Platt 1949). This model is used for describing polycyclic hydrocarbons consisting of condensed systems of benzenoid rings in which no C atom belongs to more than two rings and every C atom is on the periphery.\n\nThe ring can be approximated as a circle with circumference l. The wave-function of the electron orbital must satisfy the condition of a plane rotator:\n\nThe corresponding solutions to the Schrödinger wave equation are:\n\nwhere q is the orbital ring quantum number; the number of nodes of the wave-function. Since the electron can have spin up and spin down and can rotate about the circle in both directions all of the energy levels except the lowest are doubly degenerate.\n\nThe above shows the π-electronic energy levels of an organic molecule. Absorption of radiation is followed by molecular vibration to the S state. This is followed by a de-excitation to the S state called fluorescence. The population of triplet states is also possible by other means. The triplet states decay with a much longer decay time than singlet states, which results in what is called the slow component of the decay process (the fluorescence process is called the fast component). Depending on the particular energy loss of a certain particle (dE/dx), the \"fast\" and \"slow\" states are occupied in different proportions. The relative intensities in the light output of these states thus differs for different dE/dx. This property of scintillators allows for pulse shape discrimination: it is possible to identify which particle was detected by looking at the pulse shape. Of course, the difference in shape is visible in the trailing side of the pulse, since it is due to the decay of the excited states.\n\n"}
{"id": "533423", "url": "https://en.wikipedia.org/wiki?curid=533423", "title": "Solar water heating", "text": "Solar water heating\n\nSolar water heating (SWH) is the conversion of sunlight into heat for water heating using a solar thermal collector. A variety of configurations are available at varying cost to provide solutions in different climates and latitudes. SWHs are widely used for residential and some industrial applications.\n\nA sun-facing collector heats a working fluid that passes into a storage system for later use. SWH are active (pumped) and passive (convection-driven). They use water only, or both water and a working fluid. They are heated directly or via light-concentrating mirrors. They operate independently or as hybrids with electric or gas heaters. In large-scale installations, mirrors may concentrate sunlight into a smaller collector.\n\nThe global solar thermal market is dominated by China, Europe, Japan and India, although Israel was one of the first countries to mandate installation of SWH in 1980, leading to a flourishing industry.\n\nRecords of solar collectors in the U.S. date to before 1900, involving a black-painted tank mounted on a roof. In 1896 Clarence Kemp of Baltimore enclosed a tank in a wooden box, thus creating the first 'batch water heater' as they are known today. Frank Shuman built the world’s first solar thermal power station in Maadi, Egypt, using parabolic troughs to power a 60-70 horsepower engine that pumped 6,000 gallons of water per minute from the Nile River to adjacent cotton fields.\n\nFlat-plate collectors for solar water heating were used in Florida and Southern California in the 1920s. Interest grew in North America after 1960, but especially after the 1973 oil crisis.\n\nSolar power is in use in Australia, Canada, China, Germany, India, Israel, Japan, Portugal, Romania, Spain, the United Kingdom and the United States.\n\nIsrael, Cyprus and Greece are the \"per capita\" leaders in the use of solar water heating systems supporting 30%–40% of homes.\n\nFlat plate solar systems were perfected and used on a large scale in Israel. In the 1950s a fuel shortage led the government to forbid heating water between 10 pm and 6 am. Levi Yissar built the first prototype Israeli solar water heater and in 1953 he launched the NerYah Company, Israel's first commercial manufacturer of solar water heating. Solar water heaters were used by 20% of the population by 1967. Following the energy crisis in the 1970s, in 1980 Israel required the installation of solar water heaters in all new homes (except high towers with insufficient roof area). As a result, Israel became the world leader in the use of solar energy \"per capita\" with 85% of households using solar thermal systems (3% of the primary national energy consumption), estimated to save the country of oil a year.\n\nIn 2005, Spain became the world's first country to require the installation of photovoltaic electricity generation in new buildings, and the second (after Israel) to require the installation of solar water heating systems, in 2006.\n\nAfter 1960, systems were marketed in Japan.\n\nAustralia has a variety of national and state and regulations for solar thermal starting with MRET in 1997.\n\nSolar water heating systems are popular in China, where basic models start at around 1,500 yuan (US$235), around 80% less than in Western countries for a given collector size. At least 30 million Chinese households have one. The popularity is due to efficient evacuated tubes that allow the heaters to function even under gray skies and at temperatures well below freezing.\n\nThe type, complexity and size of a solar water heating system is mostly determined by:\n\n\nThe minimum requirements of the system are typically determined by the amount or temperature of hot water required during winter, when a system's output and incoming water temperature are typically at their lowest. The maximum output of the system is determined by the need to prevent the water in the system from becoming too hot.\n\nFreeze protection measures prevent damage to the system due to the expansion of freezing transfer fluid. Drainback systems drain the transfer fluid from the system when the pump stops. Many indirect systems use antifreeze (e.g., propylene glycol) in the heat transfer fluid.\n\nIn some direct systems, collectors can be manually drained when freezing is expected. This approach is common in climates where freezing temperatures do not occur often, but can be less reliable than an automatic system as it relies on an operator.\n\nA third type of freeze protection is freeze-tolerance, where low pressure water pipes made of silicone rubber simply expand on freezing. One such collector now has European Solar Keymark accreditation.\n\nWhen no hot water has been used for a day or two, the fluid in the collectors and storage can reach high temperatures in all non-drainback systems. When the storage tank in a drainback system reaches its desired temperature, the pumps stop, ending the heating process and thus preventing the storage tank from overheating.\n\nSome active systems deliberately cool the water in the storage tank by circulating hot water through the collector at times when there is little sunlight or at night, losing heat. This is most effective in direct or thermal store plumbing and is virtually ineffective in systems that use evacuated tube collectors, due to their superior insulation. Any collector type may still overheat. High pressure, sealed solar thermal systems ultimately rely on the operation of temperature and pressure relief valves. Low pressure, open vented heaters have simpler, more reliable safety controls, typically an open vent.\n\nSimple designs include a simple glass-topped insulated box with a flat solar absorber made of sheet metal, attached to copper heat exchanger pipes and dark-colored, or a set of metal tubes surrounded by an evacuated (near vacuum) glass cylinder. In industrial cases a parabolic mirror can concentrate sunlight on the tube. Heat is stored in a hot water storage tank. The volume of this tank needs to be larger with solar heating systems to compensate for bad weather and because the optimum final temperature for the solar collector is lower than a typical immersion or combustion heater. The heat transfer fluid (HTF) for the absorber may be water, but more commonly (at least in active systems) is a separate loop of fluid containing anti-freeze and a corrosion inhibitor delivers heat to the tank through a heat exchanger (commonly a coil of copper heat exchanger tubing within the tank). Copper is an important component in solar thermal heating and cooling systems because of its high heat conductivity, atmospheric and water corrosion resistance, sealing and joining by soldering and mechanical strength. Copper is used both in receivers and primary circuits (pipes and heat exchangers for water tanks).\n\nAnother lower-maintenance concept is the 'drain-back'. No anti-freeze is required; instead, all the piping is sloped to cause water to drain back to the tank. The tank is not pressurized and operates at atmospheric pressure. As soon as the pump shuts off, flow reverses and the pipes empty before freezing can occur.\nResidential solar thermal installations fall into two groups: passive (sometimes called \"compact\") and active (sometimes called \"pumped\") systems. Both typically include an auxiliary energy source (electric heating element or connection to a gas or fuel oil central heating system) that is activated when the water in the tank falls below a minimum temperature setting, ensuring that hot water is always available. The combination of solar water heating and back-up heat from a wood stove chimney can enable a hot water system to work all year round in cooler climates, without the supplemental heat requirement of a solar water heating system being met with fossil fuels or electricity.\n\nWhen a solar water heating and hot-water central heating system are used together, solar heat will either be concentrated in a pre-heating tank that feeds into the tank heated by the central heating, or the solar heat exchanger will replace the lower heating element and the upper element will remain to provide for supplemental heat. However, the primary need for central heating is at night and in winter when solar gain is lower. Therefore, solar water heating for washing and bathing is often a better application than central heating because supply and demand are better matched. In many climates, a solar hot water system can provide up to 85% of domestic hot water energy. This can include domestic non-electric concentrating solar thermal systems. In many northern European countries, combined hot water and space heating systems (solar combisystems) are used to provide 15 to 25% of home heating energy. When combined with storage, large scale solar heating can provide 50-97% of annual heat consumption for district heating.\n\n\"Direct\" or \"open loop\" systems circulate potable water through the collectors. They are relatively cheap. Drawbacks include:\n\nThe advent of freeze-tolerant designs expanded the market for SWH to colder climates. In freezing conditions, earlier models were damaged when the water turned to ice, rupturing one or more components.\n\n\"Indirect\" or \"closed loop\" systems use a heat exchanger to transfer heat from the \"heat-transfer fluid\" (HTF) fluid to the potable water. The most common HTF is an antifreeze/water mix that typically uses non-toxic propylene glycol. After heating in the panels, the HTF travels to the heat exchanger, where its heat is transferred to the potable water. Indirect systems offer freeze protection and typically overheat protection.\n\n\"Passive\" systems rely on heat-driven convection or heat pipes to circulate the working fluid. Passive systems cost less and require low or no maintenance, but are less efficient. Overheating and freezing are major concerns.\n\n\"Active\" systems use one or more pumps to circulate water and/or heating fluid\".\" This permits a much wider range of system configurations.\n\nPumped systems are more expensive to purchase and to operate. However, they operate at higher efficiency can be more easily controlled.\n\nActive systems have controllers with features such as interaction with a backup electric or gas-driven water heater, calculation and logging of the energy saved, safety functions, remote access and informative displays.\n\nAn \"integrated collector storage\" (ICS or batch heater) system uses a tank that acts as both storage and collector. Batch heaters are thin rectilinear tanks with a glass side facing the sun at noon. They are simple and less costly than plate and tube collectors, but they may require bracing if installed on a roof (to support  lbs of water), suffer from significant heat loss at night since the side facing the sun is largely uninsulated and are only suitable in moderate climates.\n\nA \"convection heat storage unit\" (CHS) system is similar to an ICS system, except the storage tank and collector are physically separated and transfer between the two is driven by convection. CHS systems typically use standard flat-plate type or evacuated tube collectors. The storage tank must be located above the collectors for convection to work properly. The main benefit of CHS systems over ICS systems is that heat loss is largely avoided since the storage tank can be fully insulated. Since the panels are located below the storage tank, heat loss does not cause convection, as the cold water stays at the lowest part of the system.\n\n\"Pressurized antifreeze\" systems use a mix of antifreeze (almost always non-toxic propylene glycol) and water mix for HTF in order to prevent freeze damage.\n\nThough effective at preventing freeze damage, antifreeze systems have drawbacks:\n\nA \"drainback system\" is an active indirect system where the HTF (usually pure water) circulates through the collector, driven by a pump. The collector piping is not pressurized and includes an open drainback reservoir that is contained in conditioned or semi-conditioned space. The HTF remains in the drainback reseervoir unless the pump is operating and returns there (emptying the collector) when the pump is switched off. The collector system, including piping, must drain via gravity into the drainback tank. Drainback systems are not subject to freezing or overheating. The pump operates only when appropriate for heat collection, but not to protect the HTF, increasing efficiency and reducing pumping costs.\n\nPlans for solar water heating systems are available on the Internet. DIY SWH systems are usually cheaper than commercial ones, and they are used both in the developed and developing world.\n\nSolar thermal collectors capture and retain heat from the sun and use it to heat a liquid. Two important physical principles govern the technology of solar thermal collectors:\n\nFlat plate collectors are an extension of the idea to place a collector in an 'oven'-like box with glass directly facing the Sun. Most flat plate collectors have two horizontal pipes at the top and bottom, called headers, and many smaller vertical pipes connecting them, called risers. The risers are welded (or similarly connected) to thin absorber fins. Heat-transfer fluid (water or water/antifreeze mix) is pumped from the hot water storage tank or heat exchanger into the collectors' bottom header, and it travels up the risers, collecting heat from the absorber fins, and then exits the collector out of the top header. Serpentine flat plate collectors differ slightly from this \"harp\" design, and instead use a single pipe that travels up and down the collector. However, since they cannot be properly drained of water, serpentine flat plate collectors cannot be used in drainback systems.\n\nThe type of glass used in flat plate collectors is almost always low-iron, tempered glass. Such glass can withstand significant hail without breaking, which is one of the reasons that flat-plate collectors are considered the most durable collector type.\n\nUnglazed or formed collectors are similar to flat-plate collectors, except they are not thermally insulated nor physically protected by a glass panel. Consequently, these types of collectors are much less efficient. For pool heating applications, the water to be heated is often colder than the ambient roof temperature, at which point the lack of thermal insulation allows additional heat to be drawn from the surrounding environment.\n\nEvacuated tube collectors (ETC) are a way to reduce the heat loss, inherent in flat plates. Since heat loss due to convection cannot cross a vacuum, it forms an efficient isolation mechanism to keep heat inside the collector pipes. Since two flat glass sheets are generally not strong enough to withstand a vacuum, the vacuum is created between two concentric tubes. Typically, the water piping in an ETC is therefore surrounded by two concentric tubes of glass separated by a vacuum that admits heat from the sun (to heat the pipe) but that limits heat loss. The inner tube is coated with a thermal absorber. Vacuum life varies from collector to collector, from 5 years to 15 years.\n\nFlat plate collectors are generally more efficient than ETC in full sunshine conditions. However, the energy output of flat plate collectors is reduced slightly more than ETCs in cloudy or extremely cold conditions. Most ETCs are made out of annealed glass, which is susceptible to hail, failing given roughly golf ball -sized particles. ETCs made from \"coke glass,\" which has a green tint, are stronger and less likely to lose their vacuum, but efficiency is slightly reduced due to reduced transparency. ETCs can gather energy from the sun all day long at low angles due to their tubular shape.\n\nOne way to power an active system is via a photovoltaic (PV) panel. To ensure proper pump performance and longevity, the (DC) pump and PV panel must be suitably matched. Although a PV-powered pump does not operate at night, the controller must ensure that the pump does not operate when the sun is out but the collector water is not hot enough.\n\nPV pumps offer the following advantages:\n\nA bubble pump (also known as geyser pump) is suitable for flat panel as well as vacuum tube systems. In a bubble pump system, the closed HTF circuit is under reduced pressure, which causes the liquid to boil at low temperature as the sun heats it. The steam bubbles form a geyser, causing an upward flow. The bubbles are separated from the hot fluid and condensed at the highest point in the circuit, after which the fluid flows downward toward the heat exchanger caused by the difference in fluid levels. The HTF typically arrives at the heat exchanger at 70 °C and returns to the circulating pump at 50 °C. Pumping typically starts at about 50 °C and increases as the sun rises until equilibrium is reached.\n\nA \"differential controller\" senses temperature differences between water leaving the solar collector and the water in the storage tank near the heat exchanger. The controller starts the pump when the water in the collector is sufficiently about 8–10 °C warmer than the water in the tank, and stops it when the temperature difference reaches 3–5 °C. This ensures that stored water always gains heat when the pump operates and prevents the pump from excessive cycling on and off. (In direct systems the pump can be triggered with a difference around 4 °C because they have no heat exchanger.)\n\nThe simplest collector is a water-filled metal tank in a sunny place. The sun heats the tank. This was how the first systems worked. This setup would be inefficient due to the equilibrium effect: as soon as heating of the tank and water begins, the heat gained is lost to the environment and this continues until the water in the tank reaches ambient temperature. The challenge is to limit the heat loss.\n\nICS or batch collectors reduce heat loss by thermally insulating the tank. This is achieved by encasing the tank in a glass-topped box that allows heat from the sun to reach the water tank. The other walls of the box are thermally insulated, reducing convection and radiation. The box can also have a reflective surface on the inside. This reflects heat lost from the tank back towards the tank. In a simple way one could consider an ICS solar water heater as a water tank that has been enclosed in a type of 'oven' that retains heat from the sun as well as heat of the water in the tank. Using a box does not eliminate heat loss from the tank to the environment, but it largely reduces this loss.\n\nStandard ICS collectors have a characteristic that strongly limits the efficiency of the collector: a small surface-to-volume ratio. Since the amount of heat that a tank can absorb from the sun is largely dependent on the surface of the tank directly exposed to the sun, it follows that the surface size defines the degree to which the water can be heated by the sun. Cylindrical objects such as the tank in an ICS collector have an inherently small surface-to-volume ratio. Collectors attempt to increase this ratio for efficient warming of the water. Variations on this basic design include collectors that combine smaller water containers and evacuated glass tube technology, a type of ICS system known as an Evacuated Tube Batch (ETB) collector.\n\nETSCs can be more useful than other solar collectors during winter season. ETCs can be used for heating and cooling purposes in industries like pharmaceutical and drug, paper, leather and textile and also for residential houses, hospitals nursing home, hotels swimming pool etc.\n\nAn ETC can operate at a range of temperatures from medium to high for solar hot water, swimming pool, air conditioning and solar cooker.\n\nETCs higher operational temperature range (up to ) makes them suitable for industrial applications such as steam generation, heat engine and solar drying.\n\nFloating pool covering systems and separate STCs are used for pool heating.\n\nPool covering systems, whether solid sheets or floating disks, act as insulation and reduce heat loss. Much heat loss occurs through evaporation, and using a cover slows evaporation.\n\nSTCs for nonpotable pool water use are often made of plastic. Pool water is mildly corrosive due to chlorine. Water is circulated through the panels using the existing pool filter or supplemental pump. In mild environments, unglazed plastic collectors are more efficient as a direct system. In cold or windy environments evacuated tubes or flat plates in an indirect configuration are used in conjunction with a heat exchanger. This reduces corrosion. A fairly simple differential temperature controller is used to direct the water to the panels or heat exchanger either by turning a valve or operating the pump. Once the pool water has reached the required temperature, a diverter valve is used to return water directly to the pool without heating. Many systems are configured as drainback systems where the water drains into the pool when the water pump is switched off.\n\nThe collector panels are usually mounted on a nearby roof, or ground-mounted on a tilted rack. Due to the low temperature difference between the air and the water, the panels are often formed collectors or unglazed flat plate collectors. A simple rule-of-thumb for the required panel area needed is 50% of the pool's surface area. This is for areas where pools are used in the summer season only. Adding solar collectors to a conventional outdoor pool, in a cold climate, can typically extend the pool's comfortable usage by months and more if an insulating pool cover is used. Most solar hot water systems are capable of heating a pool by around 5-8 °C and often by as much as 10 °C. \n\nAn active solar energy system analysis program may be used to optimize the solar pool heating system before it is built.\n\nThe amount of heat delivered by a solar water heating system depends primarily on the amount of heat delivered by the sun at a particular place (insolation). In the tropics insolation can be relatively high, e.g. 7 kWh/m² per day, versus e.g., 3.2 kWh/m² per day in temperate areas. Even at the same latitude average insolation can vary a great deal from location to location due to differences in local weather patterns and the amount of overcast. Calculators are available for estimating insolation at a site.\n\nBelow is a table that gives a rough indication of the specifications and energy that could be expected from a solar water heating system involving some 2 m of absorber area of the collector, demonstrating two evacuated tube and three flat plate solar water heating systems. Certification information or figures calculated from those data are used. The bottom two rows give estimates for daily energy production (kWh/day) for a tropical and a temperate scenario. These estimates are for heating water to 50 °C above ambient temperature.\n\nWith most solar water heating systems, the energy output scales linearly with the collector surface area.\nThe figures are fairly similar between the above collectors, yielding some 4 kWh/day in a temperate climate and some 8 kWh/day in a tropical climate when using a collector with a 2 m absorber. In the temperate scenario this is sufficient to heat 200 litres of water by some 17 °C. In the tropical scenario the equivalent heating would be by some 33 °C. Many thermosiphon systems have comparable energy output to equivalent active systems. The efficiency of evacuated tube collectors is somewhat lower than for flat plate collectors because the absorbers are narrower than the tubes and the tubes have space between them, resulting in a significantly larger percentage of inactive overall collector area. Some methods of comparison calculate the efficiency of evacuated tube collectors based on the actual absorber area and not on the space occupied as has been done in the above table. Efficiency is reduced at higher temperatures.\n\nIn sunny, warm locations, where freeze protection is not necessary, an ICS (batch type) solar water heater can be cost effective.\nIn higher latitudes, design requirements for cold weather add to system complexity and cost.\nThis increases \"initial\" costs, but not life-cycle costs. The biggest single consideration is therefore the large initial financial outlay of solar water heating systems. Offsetting this expense can take years.\nThe payback period is longer in temperate environments.\nSince solar energy is free, operating costs are small.\nAt higher latitudes, solar heaters may be less effective due to lower insolation, possibly requiring larger and/or dual-heating systems. In some countries government incentives can be significant.\n\nCost factors (positive and negative) include:\n\nPayback times can vary greatly due to regional sun, extra cost due to frost protection needs of collectors, household hot water use etc.\nFor instance in central and southern Florida the payback period could easily be 7 years or less rather than the 12.6 years indicated on the chart for the U.S.\n\nThe payback period is shorter given greater insolation. However, even in temperate areas, solar water heating is cost effective. The payback period for photovoltaic systems has historically been much longer. Costs and payback period are shorter if no complementary/backup system is required. thus extending the payback period of such a system.\n\nAustralia operates a system of Renewable Energy Credits, based on national renewable energy targets.\n\nThe Toronto Solar Neighbourhoods Initiative offers subsidies for the purchase of solar water heating units.\n\nThe source of electricity in an active SWH system determines the extent to which a system contributes to atmospheric carbon during operation. Active solar thermal systems that use mains electricity to pump the fluid through the panels are called 'low carbon solar'. In most systems the pumping reduces the energy savings by about 8% and the carbon savings of the solar by about 20%. However, low power pumps operate with 1-20W. Assuming a solar collector panel delivering 4 kWh/day and a pump running intermittently from mains electricity for a total of 6 hours during a 12-hour sunny day, the potentially negative effect of such a pump can be reduced to about 3% of the heat produced.\n\nHowever, PV-powered active solar thermal systems typically use a 5–30 W PV panel and a small, low power diaphragm pump or centrifugal pump to circulate the water. This reduces the operational carbon and energy footprint.\n\nAlternative non-electrical pumping systems may employ thermal expansion and phase changes of liquids and gases.\n\nRecognised standards can be used to deliver robust and quantitative life cycle assessments (LCA). LCA considers the financial and environmental costs of acquisition of raw materials, manufacturing, transport, using, servicing and disposal of the equipment. Elements include:\nIn terms of energy consumption, some 60% goes into the tank, with 30% towards the collector (thermosiphon flat plate in this case). In Italy, some 11 giga-joules of electricity are used in producing SWH equipment, with about 35% goes toward the tank, with another 35% towards the collector. The main energy-related impact is emissions. The energy used in manufacturing is recovered within the first 2–3 years of use (in southern Europe).\n\nBy contrast the energy payback time in the UK is reported as only 2 years. This figure was for a direct system, retrofitted to an existing water store, PV pumped, freeze tolerant and of 2.8 sqm aperture. For comparison, a PV installation took around 5 years to reach energy payback, according to the same comparative study.\n\nIn terms of CO emissions, a large fraction of the emissions saved is dependent on the degree to which gas or electricity is used to supplement the sun. Using the Eco-indicator 99 points system as a yardstick (i.e. the yearly environmental load of an average European inhabitant) in Greece, a purely gas-driven system may have fewer emissions than a solar system. This calculation assumes that the solar system produces about half of the hot water requirements of a household.\n\nA test system in Italy produced about 700 kg of CO, considering all the components of manufacture, use and disposal. Maintenance was identified as an emissions-costly activity when the heat transfer fluid (glycol-based) was replaced. However, the emissions cost was recovered within about two years of use of the equipment.\n\nIn Australia, life cycle emissions were also recovered. The tested SWH system had about 20% of the impact of an electrical water heater and half that of a gas water heater.\n\nAnalysing their lower impact retrofit freeze-tolerant solar water heating system, Allen \"et al.\" (qv) reported a production CO impact of 337 kg, which is around half the environmental impact reported in the Ardente \"et al.\" (qv) study.\n\n\n\n\n\n\nAll relevant participants of the Large-scale Renewable Energy Target and Small-scale Renewable Energy Scheme must comply with the above Acts.\n\n\n"}
{"id": "35779275", "url": "https://en.wikipedia.org/wiki?curid=35779275", "title": "Solenoid (meteorology)", "text": "Solenoid (meteorology)\n\nIn the context of meteorology, a solenoid is a tube-shaped region in the atmosphere where isobaric (constant pressure) and isopycnal (constant density) surfaces intersect, causing vertical circulation. They are so-named because they are driven by the solenoid term of the vorticity equation. Examples of solenoids include the sea breeze circulation and the mountain–plains solenoid.\n"}
{"id": "1673804", "url": "https://en.wikipedia.org/wiki?curid=1673804", "title": "Starvation (glaciology)", "text": "Starvation (glaciology)\n\nIn glaciology, starvation occurs when a glacier retreats, not because of temperature increases, but due to precipitation so low that the ice flow downward into the zone of ablation exceeds the replenishment from snowfall. Eventually, the ice will move so far down that it either calves into the ocean or melts.\n\nWhen starvation does occur, however, it can almost always be reversed by slight changes in precipitation, such as are brought about by mountain ranges. Thus, even if glaciers do not cover a lowland due to low precipitation, glaciation is almost certain to occur at higher elevations.\n\nStarvation of continental ice sheets is known to have occurred during the period \"before\" the Last Glacial Maximum in many areas of Canada and the West Siberian Plain.\n\nIt is thought that, after the end of the Eemian Stage, continental ice sheets first formed near or beyond their northern margins (that is, in the extreme northwest of Siberia and the Yukon Territory, Northwest Territories and Nunavut in North America). However, as an ice sheet advances, precipitation at its centre (known as a \"dome\") tends to become very low because high-pressure systems form due to the very cold temperatures above the ice. This meant that at the northern edge of the ice sheets, there was almost no replenishment of the ice, and as it fell to lower elevations, even if it did not melt, it was not being replaced.\n\nThus, as the continental ice sheets of Quaternary glaciations advanced south according to each Milankovitch cycle, their northern edges were starved and it is believed that starvation caused them to retreat substantially \"southward\" by the time the southern limits of maximum glaciation were approached. Of course, in areas such as the Russian Far East, eastern Siberia and Beringia, glaciers were, in effect, starved before they could form at all.\n\nSome have also argued that starvation, as well as increasing temperatures, played a significant role in the decay of continental ice sheets after the LGM. The argument is that as fresh water from the melting edges of the ice sheet reached the sea, the flow of warm water which fed the ice sheets was stopped and deglaciation during the summer accelerated. This, however, is a highly controversial position.\n\nStarvation of glaciers is believed to have occurred during the Little Ice Age in parts of Alaska, the Himalayas and the Karakoram. This is because these glaciers do not follow the general global patterns of glacial advance during warm periods and retreat during cold periods, which would imply that their size is \"controlled\" by the amount of precipitation they receive (because temperatures are so low that the increases deemed from global warming, for example, would fail to melt them to any degree whatsoever).\n\n"}
{"id": "33896250", "url": "https://en.wikipedia.org/wiki?curid=33896250", "title": "The Pocket Guide to British Birds", "text": "The Pocket Guide to British Birds\n\nThe Pocket Guide to British Birds is a guide written by British naturalist and expert on wild flowers Richard Sidney Richmond Fitter, and illustrated by Richard Richardson, which was first published by Collins in 1952. Reprinted in 1953 and 1954, a second more revised 287-page editions was published by Collins in 1966, and in 1968.\n"}
{"id": "33571", "url": "https://en.wikipedia.org/wiki?curid=33571", "title": "Williams tube", "text": "Williams tube\n\nThe Williams tube, or the Williams–Kilburn tube after inventors Freddie Williams (26 June 1911 – 11 August 1977), and Tom Kilburn (11 August 1921 – 17 January 2001), is an early form of computer memory. It was the first random-access digital storage device, and was used successfully in several early computers.\n\nThe Williams tube works by displaying a grid of dots on a cathode ray tube (CRT). Due to the way CRTs work, this creates a small charge of static electricity over each dot. The charge at the location of each of the dots is read by a thin metal sheet just in front of the display. Since the display faded over time, it was periodically refreshed. In comparison to the contemporary acoustic delay line memory, the Williams–Kilburn tube was much faster, since the cycling took place at the speed of the electrons inside the vacuum tube, as opposed to the speed of sound within the delay line. However, the system was adversely affected by any nearby electrical fields, and required constant alignment to keep operational. Williams–Kilburn tubes were used primarily on high-speed computer designs.\n\nWilliams and Kilburn applied for British patents on 11 December 1946, and 2 October 1947, followed by United States patent applications on 10 December 1947, and 16 May 1949.\n\nThe Williams tube depends on an effect called secondary emission that occurs on cathode ray tubes (CRTs). When the electron beam strikes the phosphor that forms the display surface, it normally causes it to light up; however, if the beam energy is above a given threshold (depending on the phosphor mix) it also causes electrons to be struck out of the phosphor. These electrons travel a short distance before being attracted back to the CRT surface and falling on it a short distance away. The overall effect is to cause a slight positive charge in the immediate region of the beam where there is a deficit of electrons, and a slight negative charge around the dot where those electrons land. The resulting charge well remains on the surface of the tube for a fraction of a second while the electrons flow back to their original locations. The lifetime depends on the electrical resistance of the phosphor and the size of the well.\n\nThe process of creating the charge well is used as the write operation in a computer memory, storing a single binary digit, or bit. A collection of dots or spaces, often one horizontal row on the display, represents a computer word. There is a relationship between the size and spacing of the dots and their lifetime, as well as the ability to reject crosstalk with adjacent dots. This places an upper limit on the memory density, and each Williams tube could typically store about 1024 to 2560 bits of data. Because the electron beam is essentially inertia-free and can be moved anywhere on the display, the computer can access any location, making it a random access memory. Typically, the computer would load the address as an X and Y pair into the driver circuitry and then trigger a time base generator that would sweep the selected locations, reading from or writing to the internal registers, normally implemented as flip-flops.\n\nReading the memory took place via a secondary effect caused by the writing operation. During the short period when the write takes place, the redistribution of charges in the phosphor creates an electrical current that induces voltage in any nearby conductors. This is read by placing a thin metal sheet just in front of the display side of the CRT. During a read operation, the beam writes to the selected bit locations on the display. Those locations that were previously written to are already depleted of electrons, so no current flows, and no voltage appears on the plate. This allows the computer to determine there was a \"1\" in that location. If the location had not been written to previously, the write process will create a well and a pulse will be read on the plate, indicating a \"0\".\n\nReading a memory location creates a charge well whether or not one was previously there, destroying the original contents of that location, and so any read has to be followed by a write to reinstate the original data. In some systems this was accomplished using a second electron gun inside the CRT that could write to one location while the other was reading the next. Since the display would fade over time, the entire display had to be periodically refreshed using the same basic method. However, as the data is read and then immediately written, this operation can be carried out by external circuitry while the central processing unit (CPU) was busy carrying out other operations. This refresh operation is similar to the memory refresh cycles of DRAM in modern systems.\n\nSince the refresh process caused the same pattern to continually reappear on the display, there was a need to be able to erase previously written values. This was normally accomplished by writing to the display just beside the original location. The electrons released by this new write would fall into the previously written well, filling it back in. The original systems produced this effect by writing a small dash, which was easy to accomplish without changing the master timers and simply producing the write current for a slightly longer period. The resulting pattern was a series of dots and dashes. There was a considerable amount of research on more effective erasing systems, with some systems using out-of-focus beams or complex patterns.\n\nSome Williams tubes were made from radar-type cathode ray tubes with a phosphor coating that made the data visible, while other tubes were purpose-built without such a coating. The presence or absence of this coating had no effect on the operation of the tube, and was of no importance to the operators, since the face of the tube was covered by the pickup plate. If a visible output was needed, a second tube connected in parallel with the storage tube, with a phosphor coating, but without a pickup plate, was used as a display device.\n\nDeveloped at the University of Manchester in England, it provided the medium on which the first electronically stored-memory program was implemented in the Manchester Baby computer, which first successfully ran a program on 21 June 1948. In fact, rather than the Williams tube memory being designed for the Baby, the Baby was a testbed to demonstrate the reliability of the memory. Tom Kilburn wrote a 17-line program to calculate the highest proper factor of 2. Tradition at the university has it that this was the only program Kilburn ever wrote.\n\nWilliams tubes tended to become unreliable with age, and most working installations had to be \"tuned\" by hand. By contrast, mercury delay line memory was slower and not truly random access, as the bits were presented serially, which complicated programming. Delay lines also needed hand tuning, but did not age as badly and enjoyed some success in early digital electronic computing despite their data rate, weight, cost, thermal and toxicity problems. However, the Manchester Mark 1, which used Williams tubes, was successfully commercialised as the Ferranti Mark 1. Some early computers in the United States also used Williams tubes, including the IAS machine (originally designed for Selectron tube memory), the UNIVAC 1103, Whirlwind I, IBM 701, IBM 702 and the Standards Western Automatic Computer (SWAC). Williams tubes were also used in the Soviet Strela-1 and in the Japan TAC (Tokyo Automatic Computer).\n\nNotes\nBibliography\n\n\n"}
{"id": "354286", "url": "https://en.wikipedia.org/wiki?curid=354286", "title": "Yamuna", "text": "Yamuna\n\nThe Yamuna (Hindustani: ), also known as the Jumna or Jamuna (not to be mistaken with the Jamuna of Bangladesh), is the second largest tributary river of the Ganges (Ganga) and the longest tributary in India. Originating from the Yamunotri Glacier at a height of on the southwestern slopes of Banderpooch peaks of the Lower Himalaya in Uttarakhand, it travels a total length of and has a drainage system of , 40.2% of the entire Ganges Basin. It merges with the Ganges at Triveni Sangam, Allahabad, which is a site of the Kumbh Mela, a Hindu festival held every 12 years.\n\nIt crosses several states: Haryana and Uttar Pradesh, passing by Uttarakhand and later Delhi, and meeting its tributaries on the way, including Tons, its largest tributary, Chambal, its longest tributary which has its own large basin, followed by Sindh, the Betwa, and Ken. The Yamuna does not pass across Himachal Pradesh, but receives water from that state via the Tons. It helps create the highly fertile alluvial Yamuna-Ganges Doab region between itself and the Ganges in the Indo-Gangetic plain. Nearly 57 million people depend on the Yamuna's waters. With an annual flow of about 10,000 cubic billion metres (cbm; 8.1 billion acre⋅ft) and usage of 4,400 cbm (of which irrigation constitutes 96 per cent), the river accounts for more than 70 per cent of Delhi's water supply. Like the Ganges, the Yamuna is highly venerated in Hinduism and worshipped as the goddess Yamuna. In Hindu mythology she is the daughter of the Sun God, Surya, and the sister of Yama, the God of Death, hence also known as Yami. According to popular legends, bathing in its sacred waters frees one from the torments of death.\n\nAt the Hathni Kund Barrage, its waters are diverted into two large canals: the Western Yamuna Canal flowing towards Haryana and the Eastern Yamuna Canal towards Uttar Pradesh. Beyond that point the Yamuna is joined only by the Somb, a seasonal rivulet from Haryana, and by the highly polluted Hindon River near Noida, so that it continues only as a trickling sewage-bearing drain before joining the Chambal at Pachnada in the Etawah District of Uttar Pradesh. The water of Yamuna is of \"reasonably good quality\" through its length from Yamunotri in the Himalayas to Wazirabad barrage in Delhi, about ; below this, the discharge of wastewater through 15 drains between Wazirabad barrage and Okhla barrage renders the river severely polluted. \n\nOne official described the river as a \"sewage drain\" with biochemical oxygen demand (BOD) values ranging from 14 to 28 mg/l and high coliform content. There are three main sources of pollution in the river: household and municipal disposal sites, soil erosion resulting from deforestation occurring to make way for agriculture, and resulting chemical wash-off from fertilizers, herbicides, and pesticides and run-off from commercial activity and industrial sites. The Yamuna from its origin at Yamunotri to Okhla barrage is called the Upper Yamuna.\n\nThe present Sarsuti river which originates in the Shivalik hills in Himachal and Haryana border and merges with Ghaggar River near Pehowa is the palaeochannel of Yamuna. Yamuna changed its course to the east due to a shift in the slope of the earth's crust caused by plate tectonics.\n\nThe source of Yamuna lies in the Yamunotri Glacier at an elevation of , on the south-western slopes of Banderpooch peaks, which lie in the Mussoorie range of the Lower Himalayas, north of Haridwar in Uttarkashi district, Uttarakhand. Yamunotri temple, a shrine dedicated to the goddess Yamuna, is one of the holiest shrines in Hinduism, and part of the Chota Char Dham Yatra circuit. Also standing close to the temple, on its trek route that follows the right bank of the river, lies Markendeya Tirtha, where the sage Markandeya wrote the Markandeya Purana.\n\nFrom Markendeya Tirtha, the river flows southwards for about , through the Lower Himalayas and the Shivalik Hills Range. Morainic deposits are found along the steep Upper Yamuna, highlighted with geomorphic features such as interlocking spurs, steep rock benches, gorges and stream terraces. Large terraces formed over a long period of time can be seen in the lower course of the river, such as those near Naugoan. An important part of its early catchment area, totalling , lies in Himachal Pradesh. The Tons, Yamana's largest tribuary, drains a large portion of the upper catchment area and holds more water than the main stream. It rises from the Hari-ki-dun valley and merges after Kalsi near Dehradun. The drainage system of the river stretches between Giri-Sutlej catchment in Himachal and Yamuna-Bhilangna catchment in Garhwal, also draining the ridge of Shimla. Kalanag () is the highest point of the Yamuna basin. Other tributaries in the region are the Giri, Rishi Ganga, Kunta, Hanuman Ganga and Bata, which drain the upper catchment area of the Yamuna basin.\n\nFrom the upper catchment area, the river descends onto the plains of Doon Valley, at Dak Pathar near Dehradun. Flowing through the Dakpathar Barrage, the water is diverted into a canal for power generation. Further downstream, the Assan River joins the Yamuna at the Asan Barrage, which hosts a bird sanctuary. After passing the Sikh pilgrimage town of Paonta Sahib, the Yamuna reaches Tajewala in Yamuna Nagar district (named after the river) of Haryana. A dam built here in 1873 is the origin of two important canals, the Western and Eastern Yamuna Canals, which irrigate the states of Haryana and Uttar Pradesh. The Western Yamuna Canal (WYC) crosses Yamuna Nagar, Karnal and Panipat before reaching the Haiderpur treatment plant, which contributes to Delhi's municipal water supply. The Yamuna receives wastewater from Yamuna Nagar and Panipat cities; beyond this it is replenished by seasonal streams and groundwater accrual. During the dry season, the Yamuna remains dry in many stretches between the Tajewala dam and Delhi, where it enters near the Palla barrage after traversing .\n\nThe Yamuna defines the state borders between Himachal Pradesh and Uttarakhand, and between Haryana, Delhi and Uttar Pradesh. When the Yamuna reaches the Indo-Gangetic plain, it runs almost parallel to the Ganges, the two rivers creating the Ganges-Yamuna Doab region. Spread across , one-third of the alluvial plain, the region is known for its agricultural output, particularly for the cultivation of basmati rice. The plain's agriculture supports one-third of India's population.\n\nSubsequently, the Yamana flows through the states of Delhi, Haryana and Uttar Pradesh] before merging with the Ganges at a sacred spot known as Triveni Sangam in Allahabad. Pilgrims travel by boats to platforms erected in midstream to offer prayers. During the Kumbh Mela, held every 12 years, large congregations of people immerse themselves in the sacred waters of the confluence. The cities of Baghpat, Delhi, Noida, Mathura, Agra, Firozabad, Etawah, Kalpi, Hamirpur, and Allahabad lie on its banks. At Etawah, it meets it another important tributary, Chambal, followed by a host of tributaries further down, including, Sindh, the Betwa, and Ken.\n\nAlong its length, the Yamuna has many notable tributaries:\n\nThe name \"Yamuna\" seems to be derived from the Sanskrit word \"yama\", meaning 'twin', and it may have been applied to the river because it runs parallel to the Ganges. The Yamuna is mentioned at many places in the Rig Veda, which was composed during the Vedic period  CE, and also in the later Atharvaveda, and the Brahmanas including Aitareya Brahmana and Shatapatha Brahmana. In the Rigveda, the story of the Yamuna describes her \"excessive love\" for her twin, Yama, who in turn asks her to find a suitable match for herself, which she does in Krishna.\n\nThe tale is further detailed in the 16th century Sanskrit hymn, \"Yamunashtakam\", an ode by the philosopher Vallabhacharya. Here the story of her descent to meet her beloved Krishna and to purify the world has been put into verse. The hymn also praises her for being the source of all spiritual abilities. And while the Ganges is considered an epitome of asceticism and higher knowledge and can grant \"Moksha\" or liberation, it is Yamuna, who, being a holder of infinite love and compassion, can grant freedom, even from death, the realm of her elder brother. Vallabhacharya writes that she rushes down the Kalinda Mountain, and describes her as the daughter of Kalinda, giving her the name \"Kalindi\", the backdrop of Krishna Leela. The text also talks about her water being of the colour of Lord Krishna, which is dark (Shyam). The river is referred to as Asita in some historical texts.\n\nIt is mentioned as Iomanes (Ioames) in the surveys of Seleucus I Nicator, an officer of Alexander the Great and one of the Diadochi, who visited India in 305 BCE. Greek traveller and geographer Megasthenes visited India sometime before 288 BCE (the date of Chandragupta's death) and mentioned the river in his \"Indica\", where he described the region around it as the land of Surasena. In \"Mahabharata\", the Pandava capital of Indraprastha was situated on the banks of Yamuna, considered to be the site of modern Delhi.\n\nGeological evidence indicates that in the distant past the Yamuna was a tributary of the Ghaggar River (also known as the Vedic Sarasvati River), but that it later changed its course eastward due to a tectonic event, becoming a tributary of the Ganges. This may have led to the Sarasvati River drying up, the end of many Harappan civilisation settlements, and creation of the Thar desert. However, recent geological research suggests that the diversion of the Yamuna to the Ganges may have occurred during the Pleistocene, and thus could not be connected to the decline of the Harappan civilisation in the region.\n\nMost of the great empires which ruled over a majority of India were based in the highly fertile Ganges–Yamuna basin, including the Magadha (), Maurya Empire (321–185 BCE), Shunga Empire (185–73 BCE), Kushan Empire (1st–3rd centuries CE), and Gupta Empire (280–550 CE), and many had their capitals here, in cities like Pataliputra or Mathura. These rivers were revered throughout these kingdoms that flourished on their banks; since the period of Chandragupta II ( 375–415 CE), statues both the Ganges and Yamuna became common throughout the Gupta Empire. Further to the South, images of the Ganges and Yamuna are found amidst shrines of the Chalukyas, Rashtrakutas (753–982), and on their royal seals; prior to them, the Chola Empire also added the river into their architectural motifs. The Three River Goddess shrine, next to the Kailash rock-cut Temple at Ellora, shows the Ganges flanked by the Yamuna and Saraswati.\n\nThe goddess of the river, also known as Yami, is the sister of Yama, the god of death, and the daughter of Surya, the Sun god, and his wife Saranyu. Yamuna, referred to respectfully as Yamunaji, holds a very important position in Pushti Marga, a large sect of Hinduism based on the ShuddhAdvaita, in which Shri Krishna is the main deity, propagated by VallabhAcharya / MahaPrabhuji.\n\nThe river Yamuna is connected to the religious beliefs surrounding Krishna and various stories of the two are found in Hindu religious texts, especially the Puranas. One such story is \"Kaliya Daman\" about the subduing of Kaliya, a \"Nāga\" which had inhabited the river and terrorised the people of Braja. Yamuna, according to the legends, is closely related to Lord Krishna and Mahabharata. Krishna was taken across the Yamuna on the night of his birth. Krishna's maternal uncle Kansa had planned to kill all his nephews, as his eighth nephew was predicted to be his Kāla. When Vasudeva, carrying Krishna in a basket, reached the river Yamuna, on the stormy night of Krishna's birth, Yamuna is said to have parted to make way for Vasudeva. Krishna and the Gopis also used to play on the banks of the Yamunaji as children.\n\nThe stretch of the river from its origin at Yamunotri to Okhla barrage in Delhi is called \"Upper Yamuna\". A Memorandum of Understanding (MoU) was signed amongst the five basin states (Himachal Pradesh, Uttar Pradesh, Uttarakhand, Haryana, Rajasthan, and Delhi) on 12 May 1994 for sharing of its waters. This led to the formation of Upper Yamuna River Board under India's Ministry of Water Resources, whose primary functions are: regulation of the available flows amongst the beneficiary states and monitoring the return flows; monitoring conservation and upgrading the quality of surface and groundwater; maintaining hydro-meteorological data for the basin; overviewing plans for watershed management; and monitoring and reviewing the progress of all projects up to and including Okhla barrage.\n\nFlood forecasting systems are established at Poanta Sahib, where Tons, Pawar and Giri tributaries meet. The river take 60 hours to travel from Tajewala to Delhi, thus allowing a two-day advance flood warning period. The Central Water Commission started flood-forecasting services in 1958 with its first forecasting station on Yamuna at Delhi Railway Bridge.\n\nYamuna has the following six functional barrages (eight including old replaced barrages, nine including a new proposed barrage), from north-west to south-east:\n\nUse of the Yamuna's waters for irrigation in the Indo-Gangetic Plains is enhanced by its many canals, some dating to the 14th century Tughlaq dynasty, which built the \"Nahr-i-Bahisht\" (Paradise) parallel to the river. The \"Nahr-i-Bahisht\" was restored and extended by the Mughals in the first half of the 17th century, by engineer Ali Mardan Khan, starting from Benawas where the river enters the plains and terminating near the Mughal capital of Shahjahanabad, the present city of Delhi.\n\nAs the Yamuna enters the Northern Plains near Dakpathar at an elevation of , the Eastern Yamuna Canal commences at the Dakpathar Barrage and pauses at the Asan and Hathnikund Barrages before continuing south.\n\nThe Western Yamuna Canal (WYC) was built in 1335 CE by Firuz Shah Tughlaq. Excessive silting caused it to stop flowing , when the British Raj undertook a three-year renovation in 1817 by Bengal Engineer Group. The Tajewala Barrage dam was built in 1832–33 to regulate the flow of water, and was replaced by the modern Hathni Kund Barrage in 1999.\n\nThe main canal is long. When including its branches and many major and minor irrigation channels, it has a total length of The WYC begins at the Hathni Kund Barrage about from Dakpathar and south of Doon Valley. The canals irrigate vast tracts of land in the region in Ambala, Karnal, Sonepat, Rohtak, Jind, Hisar and Bhiwani districts.\n\nThe major branch canals are:\n\n\nA proposed heavy freight canal, the Sutlej–Yamuna Link (SYL), is being built westwards from near the Yamuna's headwaters through the Punjab region near an ancient caravan route and highlands pass to the navigable parts of the Sutlej–Indus watershed. This will connect the Ganges, which flows to the east coast of the subcontinent, with points west (via Pakistan). When completed, the SYL will allow shipping from India's east coast to the west coast and the Arabian sea, shortening important commercial links for north-central India's large population. The canal starts near Delhi, and is designed to transfer Haryana's share of from the Indus Basin.\n\nYamuna is one of the National Waterways of India, designated as NW110 in Haryana, Delhi and Uttar Pradesh. Some of its sections are being developed for navigation:\n\nIn 1909, the waters of the Yamuna were distinguishable as clear blue, when compared to the silt-laden yellow of the Ganges. However, due to high-density population growth and rapid industrialisation, Yamuna has become one of the most-polluted rivers in the world. The Yamuna is particularly polluted downstream of New Delhi, the capital of India, which dumps about 58% of its waste into the river. A recent study shows that there is 100% urban metabolism of River Yamuna as it passes through the National Capital Territory (NCT) of Delhi.\n\nNew Delhi generates per day (MLD) of sewage. Though many attempts have been made to process it, these efforts have proven futile. Although the government of India has spent nearly $500 million to clean up the river, the Yamuna continues to be polluted with garbage while most sewage treatment facilities are underfunded or malfunctioning. In addition, the water in the river remains stagnant for almost nine months a year, aggravating the situation. Delhi alone contributes around 3,296 MLD of sewage to the river. The government of India over the next five years has prepared plans to rebuild and repair the sewage system and the drains that empty into the river.\n\nTo address river pollution, measures have been taken by the Ministry of Environment and Forests (MoEF) in 12 towns of Haryana, 8 towns of Uttar Pradesh, and Delhi, under the Yamuna Action Plan (YAP) which has been implemented since 1993 by the MoEF's National River Conservation Directorate (NRCD). The Japan Bank for International Cooperation is participating in the YAP in 15 of the towns (excluding 6 towns of Haryana included later on the direction of the Supreme Court of India) with soft loan assistance of 17.773 billion Japanese yen (equivalent to about 700 crore [7 billion rupees]) while the government of India is providing the funds for the remaining 6 towns. In 2007, the Indian government's plans to repair sewage lines were predicted to improve the water quality of the river 90% by the year 2010.\n\nThe last barrage across the Yamuna river is the Mathura barrage at Gokul for supply of drinking water to that city. Downstream of this barrage, many pumping stations are constructed to feed the river water for irrigation needs. These pumping stations are near Pateora Danda , Samgara , Ainjhi , Bilas Khadar , and Samari . Depletion of the base flows available in the river during the non-monsoon months by these pump houses is exacerbating river pollution from Mathura to Allahabad in the absence of adequate fresh water to dilute the polluted drainage from habitations and industries.\n\nIn 2009, the Union government announced to the Lok Sabha (Indian Parliament), the failure of the Ganga Action Plan and the YAP, saying that \"rivers Ganga and Yamuna are no cleaner now than two decades ago\" despite spending over 1,700 crore (17 billion rupees) to control pollution. According to a Centre for Science and Environment (CSE) official, these plans adopted the Thames model, based on a centralised sewage treatment system. This meant that a huge sum of money and a 24-hour power supply were needed to manage the treatment plants, while only an 8-hour power supply was available, contributing to the failure.\n\nIn August 2009, the Delhi Jal Board (DJB) initiated its plan for resuscitating the Yamuna's stretch in Delhi by constructing interceptor sewers, at the cost of about 1,800 crore (18 billion rupees).\n\nOn 25 April 2014, the National Green Tribunal Act (NGA) recommended the government to declare a stretch of the Yamuna in Delhi and Uttar Pradesh as a conservation zone. A report prepared by the Ministry of Environment and Forests (MoEF) panel was submitted to the NGA on the same day. Under the Yamuna Action Plan (YAP-I and YAP-II), pollution cleanup of Yamuna was conducted in line with the biological oxygen demand of Yamuna. Under these two phases, 286 schemes, including 39 sewage treatment plants, were completed in 21 towns of Delhi, Uttar Pradesh, and Haryana at a cost of 1,453.17 crore (14.5 billion rupees). Sewage treatment capacity of 767.25 million litres per day was created by these efforts.\n\n\n\n\n"}
{"id": "20660104", "url": "https://en.wikipedia.org/wiki?curid=20660104", "title": "Yer Tanrı", "text": "Yer Tanrı\n\nYer Tanrı is the goddess of earth in Turkic mythology. Also known as Yer Ana.\n\nWith her father Gök Tengri and her brother and husband Kayra, she was the parent of Ay Tanrı, Umay, Ülgen, Koyash, and Erlik. As a fertility goddess, she was recognized as the giver of crops and abundance. In the Spring and in the Autumn — before the beginning of the agricultural season and after the harvest — she was worshiped with sacrifices of food.\n\nYer Tanry was considered to be both a mother and wife to Gök Tengri. She appeared as a force of nature. In ancient Turkic mythology there was a theory that mortals were the product of the union of Tengri and Yer (Earth). In the Orkhon inscriptions it says: \"In the beginning there was a blue sky above, a dark land below, and human sons in-between.\" (\"Üze kök tengri asra yagiz yir kilindukda ikin ara kişi oğlı kılınmış.\") The Turkic people revered the Earth Goddess (Yer Ana) as a giver of crops and abundance. In the Spring, before the beginning of the agricultural season and in the Autumn, after the harvest, as a sign of gratitude for the abundance of food and happiness, the ancient Turkic peoples and Mongols made a sacrifice to the Earth Goddess. Milk, kumys and tea were offered, and pleas were made for a fertile land and a rich yield.\n\n\n"}
