{"id": "20848458", "url": "https://en.wikipedia.org/wiki?curid=20848458", "title": "Adularescence", "text": "Adularescence\n\nAdularescence is an optical phenomenon, similar to labradorescence and aventurescence, that is produced in gemstones such as moonstones.\n\nThe effect of adularescence, also commonly referred to as \"schiller\" or \"shiller\", is best described as a milky, bluish luster or glow originating from below the surface of the gemstone. The schiller, appearing to move as the stone is turned (or as the light source is moved), gives the impression of lunar light floating on water (accounting for moonstone's name). Though white schiller is the most common, in rarer specimens, orange or blue lusters are produced.\n\nThis effect is most typically produced by adularia, from which the name derives. Adularescence appears in numerous other gemstones, notably common opal, rose quartz and agate. However, due to inclusions in these other stones, the effect is displayed differently. The schiller is scattered by inclusions and appears hazy; non-hazy specimens are specially referred to as \"milky\". Thus, adularescence occurring in non-adularia gemstones is termed differently – the \"girasol effect\" and opalescence (for opals only) are two such terms. When the schiller forms an indistinct band, it is said to display a chatoyant effect. Only clearly defined bands are referred to as \"cat's eyes\".\n\nAs an optical phenomenon, adularescence exists only in the presence of light; it is a product of the interaction between light and the internal microstructures of the mineral and not a property of the mineral itself. The effect is produced by alternating layers of two types at a scale near the wavelength of light (c. 0.5 micron) – this leads to light scattering and interference.\n"}
{"id": "48868479", "url": "https://en.wikipedia.org/wiki?curid=48868479", "title": "Aeropause", "text": "Aeropause\n\nAeropause is the region in which the functional effects of the atmosphere on man and craft begin to cease.\n\nIn the 1950s, there were discussions between the U. S. Air Force School of Medicine Aviation and the Lovelace Foundation regarding how to support the efforts to accomplish manned travel in the upper atmosphere. A research plan was developed that encompassed the aeromedical, aeronautical, astrophysical, and biological aspects that were deemed vital to manned travel in the upper atmosphere. At San Antonio, Texas in November 1951 a symposium was held with a focus aimed at forecasting the future research needed for manned flight that approached the upper limits of the atmosphere. At the symposium, the presentations and discussions focused on 4 major disciplines that comprised the areas of astrophysics, aeronautical engineering, radiobiology, and aviation medicine.\n\nAt the time when the term aeropause became relevant to the pursuits of mankind into the upper regions of Earth’s atmosphere, there did not exist a precise description for the word. The judgement of experts in the various fields was solicited and input was sought to define the term aeropause. The terms from aeromedical and aeronautical disciplines along with terms from geophysics, astrophysics, and radiobiology were not sufficient to depict this region of the atmosphere where human endeavors sought to venture and explore. The current terms in use were limited and insufficient. The terms available and that came under consideration were aerosphere, aeropause, and astronautics.\nAccording to Clayton S. White, the expression aeropause is a coined word first spoken by Dr. Konrad Buettner of the Department of Space Medicine at Randolph Field during a conference. Again, referring to White: \"aerosphere was visualized as that region in which flight was possible currently. The aeropause was the region just above this, to be different yesterday, today, and tomorrow, as progress in aviation ensued\".\n\nHeinz Haber, Department of Space Medicine at Randolph Field, an expert in space medicine sought a more functional definition and said the: \"aeropause should be defined as that region in which the functional effects of the atmosphere on man and craft begin to cease\". The aeronautical engineer defined the aeropause as those areas of the atmosphere where the physiological necessities of the aircrew became the limiting factors for the design of aircraft and supporting equipment.\n\nThe study of the aeropause requires a blend of several disciplines from the biological sciences and the physical sciences. Important fields necessary for research that involves the aeropause include aviation medicine, geophysics, astronomy, astrophysics, aeronautical engineering, biophysics, and radiobiology.\n"}
{"id": "14528300", "url": "https://en.wikipedia.org/wiki?curid=14528300", "title": "Aerospace industry in the United Kingdom", "text": "Aerospace industry in the United Kingdom\n\nThe aerospace industry of the United Kingdom is the fourth-largest national aerospace industry in the world and the third largest in Europe, with a global market share of 6.4% in 2016. In 2013, the industry employed 84,000 people. Domestic companies with a large presence in the British aerospace industry include BAE Systems (the world's third-largest defence contractor), Britten-Norman, Cobham, GKN, Hybrid Air Vehicles, Meggitt, QinetiQ, Rolls Royce (the world's second-largest maker of defence aero engines) and Ultra Electronics. Foreign companies with a major presence include Boeing, Bombardier, Airbus (including its Astrium, Cassidian and Surrey Satellite Technology subsidiaries), Leonardo (including its AgustaWestland and Selex ES subsidiaries), General Electric (including its GE Aviation Systems subsidiary), Lockheed Martin, MBDA (37.5% owned by BAE Systems), Safran (including its Messier-Dowty and Turbomeca subsidiaries) and Thales Group (including its UK-based Thales Air Defence, Thales Avionics and Thales Optronics subsidiaries). Current manned aircraft in which the British aerospace industry has a major role include the AgustaWestland AW101, AgustaWestland AW159, Airbus A320 family, Airbus A330, Airbus A340, Airbus A380, Airbus A400M, BAE Hawk, Boeing 767, Boeing 777, Boeing 787, Bombardier CRJ700, Bombardier CSeries, Bombardier Learjet 85, Britten-Norman Defender, Britten-Norman Islander, Eurofighter Typhoon, Hawker 800, Lockheed Martin C-130J Super Hercules and Lockheed Martin F-35 Lightning II. Current unmanned aerial vehicles in which the British aerospace industry has a major role include BAE Taranis, HAV 304 Airlander 10, QinetiQ Zephyr and Watchkeeper WK450.\n\nThe British aerospace industry has made many important contributions to the history of aircraft and was solely, or jointly, responsible for the development and production of the first aircraft with an enclosed cabin (the Avro Type F), the first jet aircraft to enter service for the Allies in World War II (the Gloster Meteor), the first commercial jet airliner to enter service (the de Havilland Comet), the first aircraft capable of supercruise (the English Electric Lightning), the first supersonic commercial jet airliner to enter service (the Aérospatiale-BAC Concorde), the first fixed-wing V/STOL combat aircraft to enter service (the Hawker Siddeley Harrier), the first twin-engined widebody commercial jet airliner (the Airbus A300), the first digital fly-by-wire commercial aircraft (the Airbus A320), and the largest commercial aircraft to enter service to date (the Airbus A380).\n\n\n\nPrivate flying initially stimulated the UK aviation industry and by October 1913 there were over 80 private airworthy aeroplanes, more than the airworthy planes in the recently formed Royal Flying Corps. Commercial flying only really started in 1919. Before the war there were no regular air services.\n\nWhilst it was the military market that really was the source of aviation development, in the years leading up to 1914 it was, in the UK, rather sporadic. In 1909 development on behalf of the Government was stopped as being too costly. In April 1911 Britain had only 6 military aeroplanes, 2 of which were obsolete. The French War Department owned 208. However, by the start of WW1 the Naval Wing of the R.F.C. had 93 and the Military Wing had 179.\n\nAs a new technology, there was a great deal of interest from a variety of sources but often it was individuals just enthused by aviation. Between 1909 and 1914 there were about 200 active constructors, although many of them only made one or two planes. But even the production of the larger firms was not very substantial, British and Colonial Aeroplane Company, one of the largest produced just over 200 planes between 1910 and 1914.\n\nMost of the aviation pioneers, such as Geoffrey de Havilland, Thomas Sopwith, Richard Fairey, Robert Blackburn, Frederick Handley Page, A.V. Roe and the Short Brothers had a training in engineering and their companies were usually privately financed. There were several large engineering companies who also got involved, such as Vickers in 1911, Armstrong Whitworth in 1912 British and Colonial Aeroplane Company in 1910 and Aircraft Manufacturing Company in 1912.\n\nAlong with these companies there was the early development of seaplanes, particularly near Southampton, by companies such as S. E. Saunders (originally boat builders) and Pemberton-Billing (later Supermarine). Finally, there were several French subsidiary companies who built aero-engines.\n\nUnsurprisingly the First World War led to a massive increase in the number of companies engaged in aircraft production, 1,529 companies in October 1918, but once the War was over the vast majority returned to their pre-war activities. However, the aircraft being produced in 1918 were essentially enhanced versions of the 1914 aircraft. The development of the aviation industry between 1914 and 1918 was more one of production and logistics than scientific or technical.\n\nOn 2 January 1918 the Air Ministry was founded and on 1 April 1918 the Royal Air Force was established, independent of the Army and Royal Navy. Both organisations were to fashion the nature of the aviation industry in the UK.\n\nThe first task for the government at the end of the war was to dispose of their stocks of aircraft and to deal with those on order. The Ministry of Munitions set up a Disposal Board and sold the entire surplus stock to a private company, Aircraft Disposals Company, with Frederick Handley Page as one of the key personnel.\n\nAs soon as the war was finished and the government demand for aircraft ceased some of the remaining aircraft companies tried to diversify into other activities but with limited success or simply closed down. For instance, Airco looked at car manufacture and was bought by the Daimler Company parent company Birmingham Small Arms whilst Martinsyde and Sopwith briefly tried motor cycles. By 1920 the British aerospace industry consisted of 28 aeroplane constructors and a dozen aero engine designers. However, much of their work was of a trivial nature and engine orders were so low that Rolls Royce nearly left the aviation sector.\n\nThe aviation industry was left with the core of pre-war producers and a few companies whose interest in aviation had been aroused. This latter category included companies such as the Norwich engineering firm Boulton & Paul, Westland Aircraft, the wartime offshoot of engine manufacturers Petters Ltd and Gloucestershire, later, Gloster Aircraft Company formed from Cheltenham-based luxury liner outfitters H. H. Martyn.\n\nNonetheless there was still determination to stay particularly from the enthusiastic pioneers such de Havilland and Sopwith. As soon as Airco and Sopwith Aviation Company were declared bankrupt,(due to the Treasury demanding payment for excess profits) within months Tommy Sopwith and Geoffrey de Havilland both established new companies, H.G. Hawker Engineering later Hawker Aircraft and De Havilland Aircraft Company.\n\nThe Government established a Civil Aerial Transport Committee (that included H.G. Wells and Tommy Sopwith) that reported in December 1918. Their key recommendation was that steps should be taken to foster civil aviation in order, in part, to maintain a manufacturing base that could supply the country’s military needs. However, Government policy for civil aviation was, initially, according to the then Secretary of State for Air, Winston Churchill, on 11 March 1920 in the House of Commons to let it \"fly by itself……any attempt to support it artificially by floods of State money will not ever produce a really sound commercial aviation service which the public will use, and will impose a burden of an almost indefinite amount upon the Exchequer\".\n\nAir transport companies were established in 1919-20, several of which were subsidiaries of aircraft manufacturers, such as Handley-Page, Airco and Blackburn Aircraft. A number of the companies failed or found themselves in difficulty, due to high operating cost, low demand that was also seasonal, high fares and heavily subsidised French competition and so it was decided in April 1922 to offer support and by October subsidies were given to individual airlines operating set routes.\n\nMatters were improved when aircraft specifically designed for commercial operation were introduced. The DH.34 and Handley Page W.8 lowered the operating costs for airlines, making them more economically viable.\n\nEventually, however, the state did involve itself in civil aviation and on the advice of the Hambling Committee, creating Imperial Airways in 1924 from the four main air transport companies. However, the Air Ministry did not actively engage with the development of commercial aircraft, despite the recommendation of the 1918 Civil Aerial Transport Committee and was later criticised by the 1938 Cadman Report for this. \nThe Air Ministry worked in the early years on the basis that there would be no war in Europe in the immediate future and that the main requirement for aircraft would be policing the colonies. Such activity would not require sophisticated aeroplanes to be developed. \n\nTo ensure that the aircraft industry did not shrink to a size dangerous for national defence there came into being an arrangement with Society of British Aircraft Constructors that contracts could be shared around a limited number of companies, this became known as The Ring. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgustaWestland is an international helicopter manufacturer owned by Leonardo of Italy. In the United Kingdom, the company has one factory in Yeovil, employing more than 4,000 people. Its main products with a large British content are the EH101, the Super and Future Lynx and the AW139 and AW149.\n\nAirbus (a subsidiary of Airbus) directly employs around 13,000 people at its UK division Airbus UK, with estimates that it supports another 140,000 jobs in the wider UK economy. The traditional UK workshare in Airbus aircraft is around 20%. Airbus has major sites at Filton in the city of Bristol and at Broughton in north Wales. Filton is the main research and development and support centre for all Airbus wings, fuel systems and landing gear integration. Broughton, which employs over 5,000 people, is the main wing manufacturing centre for all Airbus aircraft and also builds the fuselage and wings of the Hawker 800. Since 2006 Airbus has also had a small development centre in the Midlands.\n\nAirbus Defence and Space (a subsidiary of Airbus) is the largest space company in Europe and employs around 2,700 people in the UK. It has sites at Stevenage (1,200 employees), Portsmouth (1,400 employees) and Poynton (120 employees).\n\nThe UK-headquartered BAE Systems is the world's second-largest defence contractor and it employs around 36,400 people in the UK. The largest aerospace related locations of BAE Systems are Warton, Samlesbury and Brough. The final assembly line for the British Eurofighter Typhoons, a collaborative European programme, is located at Warton. All flight test activity for manned aircraft is undertaken from Warton, which is also the development centre within BAE Systems, for unmanned aerial vehicles (UAVs), UCAVs and the Saudi Tornado upgrade programme. Samlesbury is the production hub of the Military Air Solutions division of BAE Systems. Here, components for the Eurofighter Typhoon, the F35 Lightning II, the Hawk, UAVs, UCAVs and Airbus aircraft get built. At Brough, the BAE Hawk gets produced and final assembled, flight tests are done at Warton. Overall, Military Air Solution has 14,000 employees spread across eight sites in the United Kingdom.\n\nThe Britten-Norman Group is the last remaining independent aircraft manufacturer in the United Kingdom, with about 100 employees. It is best known for its design of rugged transport aircraft, such as the Islander, Trislander and Defender 4000. To reduce costs, the company (resident on the Isle of Wight) did not perform manufacture of the airframes, but instead outsourced this to Romania. However, it has now moved production of all aircraft back to Daedalus Airfield and also performs in the European hub for the Cirrus SR20 and SR22 final assembly and delivery.\n\nThe Canadian company, Bombardier, employs about 5,000 people in its aerospace division in the UK. It can trace its roots back to Shorts Brothers in Northern Ireland. The company has significant workshares in most Bombardier aircraft with its specialities being fuselages and nacelles.\n\nCobham plc employs more than 12,000 people in the UK and elsewhere. Its most important products include refuelling equipment and communication systems.\n\nGE Aviation Systems, formerly known as Smiths Aerospace, is a division of General Electric, with about 10,000 employees, half of which work in the UK.\n\nGKN Aerospace is a division of the British company GKN, which employs approximately 5,000 people, mainly in the UK and the USA. In the UK, its most important facility is on the Isle of Wight, where it has a carbon composite centre of excellence. There it designed, and used to produce, the composite wing spar for the Airbus A400M now produced at GKN's New purpose built Western Approach, Bristol site. The company is also known for producing the cell of the Super Lynx and Future Lynx helicopters. It is the former owner of Westland Helicopters.\n\nMBDA is the largest European missile house, owned by BAE Systems (37.5%), Airbus (37.5%) and Leonardo (25%). It operates across Europe with main capabilities in the United Kingdom, France, Germany, Italy and Poland and offices in the USA. In the UK, the main sites are Bristol (software and systems) Bolton (production), Stevenage (R&D and integration) and London (management). MBDA's missile programmes include ASRAAM, Meteor, Storm Shadow, Rapier, Sea Wolf, CAMM and Brimstone among others.\n\nQinetiQ was formed from parts of the former Defence Evaluation and Research Agency (DERA). It has close to 12,000 employees and is one of the major players in the British aerospace industry. QinetiQ's main aerospace business relates to satellites, UAVs and reconnaissance systems.\n\nThe UK-headquartered Rolls-Royce Group is the world's second-largest maker of aircraft engines (behind General Electric). It has over 50,000 employees, of whom about 23,000 are based in the United Kingdom. The company's main UK factories are at Derby and Bristol. In Derby, the three shaft Trent engines get developed and produced. The current line up includes the Trent 700 for the Airbus A330, the Trent 900 for the Airbus A380, the Trent 1000 for the Boeing 787 and the Trent XWB for the Airbus A350 XWB, among others. In Bristol, the company has concentrated its military aerospace business with the British final assembly line for the EJ200 engine for the Eurofighter Typhoon, the only final assembly line for the British-French Adour engine and other programmes, such as significant parts of the workshare, in the international TP400 turboprop engine for the Airbus A400M and the General Electric/Rolls-Royce F136 engine for the F-35 Lightning II. Recently, Bristol has also been confirmed as the centre for the development and testing of the civil RB282 engine, which will, however, be produced in Virginia.\n\n\nLeonardo MW is a Leonardo company and an international leader in electronic and information technologies for defence systems, aerospace, data, infrastructures, land security and protection and sustainable ’smart’ solutions.\n\nThe company is an integrated global business with a workforce of approximately 17,000 and total revenues in excess of €3.5 billion. Alongside core operations in Italy and the UK, the company has an established industrial and commercial footprint in the United States, Germany, Turkey, Romania, Brazil, Saudi Arabia and India.\n\nSurrey Satellite Technology is a small satellite development and production company. It currently has c.600 employees and is the world leader in small satellites. In its 22-year history, it has developed satellites for 27 missions. The two Galileo satellite navigation proofing satellites, GIOVE-A and GIOVE-A2, are two of their better-known satellites. Originally a spin-out company from the University of Surrey, Surrey Satellite Technology is now 99% owned by the Airbus Defence and Space division of Airbus.\n\nThales Group UK has wide-ranging capabilities including avionics, UAVs, simulation capabilities and other things.\n\nTrifibre are Manufacturers of bespoke Flight Cases, protective Cases for the Aerospace Industry.\n\n\n"}
{"id": "2036194", "url": "https://en.wikipedia.org/wiki?curid=2036194", "title": "Arabian-Nubian Shield", "text": "Arabian-Nubian Shield\n\nThe Arabian-Nubian Shield (ANS) is an exposure of Precambrian crystalline rocks on the flanks of the Red Sea. The crystalline rocks are mostly Neoproterozoic in age. Geographically - and from north to south - the ANS includes parts of Israel, Palestine, Jordan, Egypt, Saudi Arabia, Sudan, Eritrea, Ethiopia, Yemen, and Somalia. The ANS in the north is exposed as part of the Sahara Desert and Arabian Desert, and in the south in the Ethiopian Highlands, Asir province of Arabia and Yemen Highlands.\n\nThe ANS was the site of some of man's earliest geologic efforts, principally by the ancient Egyptians to extract gold from the rocks of Egypt and NE Sudan. This was the most easily worked of all metals and does not tarnish. All of the gold deposits in Egypt and northern Sudan were found and exploited by Egyptians. The earliest preserved geologic map was made in 1150 BCE to show the location of gold deposits in Eastern Egypt; it is known as the Turin papyrus. New gold discoveries have been found in Sudan, Eritrea, and Saudi Arabia.\n\nPharonic Egyptians also quarried granite near Aswan and floated this down the Nile to be used as facing for the pyramids. The Greek name for Aswan, \"Syene\"; is the type locality for the igneous rock syenite. The Romans followed this tradition and had many quarries especially in the northern part of the Eastern Desert of Egypt where porphyry and granite were mined and shaped for shipment. \n\nPrecious and industrial metals, including gold, silver, copper, zinc, tin, and lead, have been mined in Saudi Arabia for at least 5,000 years. The most productive mine in Saudi Arabia, Mahd adh Dhahab (\"Cradle of Gold\"), has been periodically exploited for its mineral wealth for hundreds or even thousands of years and is reputed to be the original source of King Solomon's legendary gold. Today, mining at Mahd adh Dhahab is conducted by the Saudi Arabian Mining Company, Ma'aden. Deposits of iron, tungsten, mineral sands, copper and phosphates have been found in many locations. Mining in the Eastern Desert of Egypt and Sudan is limited due to shortage of water and infrastructure. One option would be to bring water from the Nile by pipeline.\n\nThe Arabian-Nubian Shield (ANS) is the northern half of a great collision zone called the East African Orogeny. This collision zone formed near the end of Neoproterozoic time when East and West Gondwana collided to form the supercontinent Gondwana. The East African orogeny extends southward to the Mozambique Belt, and is a subset of the overall Pan-African orogeny. The assembly of Gondwana coincided with the breakup of Rodinia, closure of the Mozambique Ocean, and growth of the shield at 870 Ma This shield growth extended for the next 300 Ma., and included island arc convergence and terrane suturing at 780 Ma, with final assembly by 550 Ma. At this time, the East African Orogen became a passive margin and the southern shore of the Paleo-Tethys Ocean. \n\nThe shield is divided into crustal blocks or tectonostratigraphic terranes delineated by ophiolite shear zones or sutures. These terranes are paired across the Red Sea, starting from the south, these include Nakfa (870-840 Ma) with Asir (785-720 Ma,850-790 Ma), Haya (870-790 Ma) with Jiddah (870-760 Ma), Gabgaba (735-700 Ma) and Gebeit (832-810 Ma) with Hijaz (870-807 Ma), and Eastern Desert (810-720 Ma) with Midyan (780-710 Ma). In addition the Halfa (2.6-1.2 Ga,750-718 Ma) and Bayuda (806 Ma) terranes are in the western portion of the shield, and the Hulayfah (720 Ma), Ha'il (740 Ma), Afif (750-695 Ma,840-820 Ma,1.86-1.66 Ga), Ad Dawadimi (695-680 Ma), and Ar Rayn (667 Ma) terranes in the eastern portion.\n\nKey amalgamation events, starting 780-760 Ma, with the formation of the Tabalah-Tarj Shear Zone, the gneiss Afaf Belt, and the 600 km long and 565 km wide Bi'r Umq and Nakasib Suture (780-760 Ma), an ophiolite-decorated fold-shear zone, between the Jiddah-Haya and Hijaz-Gebeit Terranes. Then between 750-660 Ma, the Atmur-Delgo Suture formed as Halfa Terrane ophiolite nappes were thrust onto the Bayuda Terrane. Simultaneously, the Allaqi-Heiani-Sol and Hamed-Onib-Yanbu Suture formed, consisting of nappes and portions of ophiolite along an east-trending shear zone between the Gebeit-Hijaz and Eastern Desert Terrane and Midyan Terranes. Between 680-640 Ma, the 600 km long and 5-30 km wide Hulayfah-Ad Dafinah-Ruwah Suture formed between the Afif Terrance and terranes to the southwest. Simultaneously, the Halaban Suture formed between the Afif and Ad Dawadimi Terranes as a nappe of Halaban ophiolite thrust westward. In addition, the Ar Amar Suture, consisting of the Al Amar Fault zone with ophiolite lenses, between the Ad Dawadimi and Ar Rayan Terranes, while the Nabitah Fault Zone formed in Asir Terrane. The final amalgamaton event occurred 650-600 Ma, when the Keraf Suture, consisting of ophiolite folded and sheared rocks, formed between the Bayuda-Halfa and Gebeit-Gabgaba Terranes.\n\nPost-amalgamation events include the formation of the Huqf Supergroup (732-540 Ma) in Oman and W. Saudi Arabia, which accumulated in basement basins, the first 1100 m of which include glaciomarine deposits with diamictites and dropstones from the Sturtian and Marinoan glaciations. Gneiss belts and domes forming in the Late Neoproterozoic include the Kirsh gneiss in the Arabian shield and the Meatiq gneiss dome in the Eastern Desert. Late Neoproterozoic shear zones include the Hamisana Shear Zone (665-610 Ma), the Ar Rika- Qazaz Shear Zone (640-610 Ma) within the Najd Fault System, and the Oko Shear Zone (700-560 Ma). \n\nA number of features have been ascribed to late stage extensional tectonics including a widespread NE-SW trending dyke swarm, NE-SW trending normal faults and NW-SE trending sedimentary basins filled with post-orogenic molasse deposits\n\nCrustal weaknesses before 500 Ma influenced continental rifting, as the Arabian peninsula moved away from Africa, and the formation of the Red Sea Basin at the start of the Oligocene. By then, some of the Paleozoic and Mesozoic rocks had been eroded, if ever deposited. In fact, the 1200 km wide ANS orogenic belt, has a present-day layered crustal structure, with a uniform Moho depth of 35-45 km. Post-rift deposition of evaporites occurred until the Pliocene, when a marine environment took over.\n\nAs Rosemarie and Dietrich Klemm point out, \"...gold deposits exploited in antiquity occur almost exclusively in the Neoproterozoic sequences of the ANS in the Eastern Desert in Egypt and Northern Sudan.\" The shield in this part of Africa consists of a cratonic African basement or \"infrastructure\", overlain by a Pan-African overthrust \"superstructure\". The infrastructure consists of migmatite gneiss and gneiss domes such as Gebel Hafafit and Gebel Meatiq. The metamorphism is associated with overthrust tectonics, but bear no relationship to the ancient gold mines. The superstructure consists of an ophiolite-like sequences with island arc volcanics, Hammamat sediments, and post orogenic granites. The ophiolites range in age from 746-832 Ma and are mainly serpentites with elevated gold values of 25 ppb. The Hammamat sediments, common in Wadi Hammamat and referred to as \"bekhen\" stone, consist of greywackes and siltstones, which are slightly enriched in gold. The Hammamat sediments include dike intrusions and the dacite to rhyolite Dokhan volcanics, which formed in the early stages of orogeny at 600-625 Ma. These volcanics include the Roman imperial porphyry quarries. The granite intrusions include two sequences, an older one 614-709 Ma, and a younger sequence at 544-596 Ma, which includes the Aswan granite at 565 Ma. The margin of the includes granodiorite and diorite, and most importantly, auriferous quartz veins. These veins mineralized from hydrothermal flow inside tectonic extensional gaps, or within cavities from shearing. These characteristics were exploited by New Kingdom of Egypt prospectors. This is especially true for ancient gold exploitations oriented in NNW-SSE shear zones, such as the sites at Hammama, Abu Had-North, Wad Atalla el-Mur, Atalla, Umm el Esh Sarga, Fawakhir, El-Sid, Umm Soleimat and Hamuda.\n\nWadi el-Sid was the chief mining area for the New Kingdom of Egypt, with high gold grades of 30 grams per ton (g/t) in the mineralized quartz veins within sheared ophiolite sequences of serpentinite and metabasalt, imbricated with Hammamat sediments, in direct contact with the tonalite margins of the Fawakhir granite pluton. The ophiolite nappe dates from 850 to 770 Ma, while the Fawakhir pluton dates from 574 ma. These gold-rich veins are oriented according to post-tectonic extension, something the Egyptian prospectors understood. \n\nThe well of Umm el-Fawakhir area includes a Large Ptolemaic settlement and round stone mills dating from the Roman or Early Arab Period to the oval stone mills of the New Kingdom. Even fist hammers from the Old/Middle Kingdom are present. Tailings were reworked by the Louison Company from the 1930s until 1956.\n\n\n\n\n"}
{"id": "18483373", "url": "https://en.wikipedia.org/wiki?curid=18483373", "title": "Beard and Chuang model", "text": "Beard and Chuang model\n\nThe Beard and Chuang model is a well known and leading theoretical force balance model used to derive the rotational cross-sections of raindrops in their equilibrium state by employing Chebyshev polynomials in series. \nThe radius-vector of the raindrop's surface formula_1 in vertical angular direction formula_2 is equal to\n\nformula_3,\n\nwhere shape coefficients formula_4 are defined for the raindrops with different equivolumetric diameter as in following table\n\nThe description of raindrop shape has some rather practical uses. Understanding rain is particularly important with regard to the propagation of electromagnetic signals. A portion of atmosphere that has rain in it, or a rain cell, has the characteristic of attenuating and de-polarizing EM signals that pass through it. The attenuation of such a signal is approximately proportional to the square of the frequency of the signal, and the de-polarization is proportional to the shape distribution of raindrops in the rain cell. \n\n"}
{"id": "36322233", "url": "https://en.wikipedia.org/wiki?curid=36322233", "title": "Cable fault location", "text": "Cable fault location\n\nCable fault location is the process of locating periodic faults, such as insulation faults in underground cables, and is an application of electrical measurement systems. In this process, mobile shock discharge generators are among the devices used.\n\nCable faults are damage to cables which effect a resistance in the cable. If allowed to persist, this can lead to a voltage breakdown. There are different types of cable faults, which must first be classified before they can be located. The insulation of the cable plays a significant role in this. While paper-impregnated cables are particularly susceptible to external chemical and thermal influences, in high-voltage PE or XLPE cables the polyethylene insulation of the conductor is affected, leading to partial breakdowns and cracks that “eat away” the insulation.\n\nA contact between conductor and screen generates a varying resistance.\n\nThe contact between multiple conductors generates a varying resistance.\n\nSheath faults are damage of the cable sheath that allows the surroundings contact with the cable screen.\n\nWater penetrates into the cable sheath and contacts the conductors. Impedance changes at the fault location make measuring more difficult. The resistance usually lies in the high-ohmic range.\n\nCombination of series and parallel resistances, usually in the form of a wire break. The voltage is interrupted, i.e. Ω=∞ .\n\nTo locate a fault in the cable, the cable must first be tested for faults. Cable testing is therefore usually performed first in cable fault location. During the cable test, flash-overs are generated at the weak points in the cable, which can then be localised.\n\nThe measures necessary for determining fault locations can be subdivided into individual steps.\n\nInsulation and resistance measurement provides information on the fault characteristics. An insulation test measures the insulation resistance between conductor and screen; from the periodic measurement of resistance you can derive the absorption properties of the insulating material.\n\nPre-location is used to determine the fault distance. There are predominantly two methods for this.\n\nA pulse induced at the starting end of the cable reaches the cable fault with a speed of v/2 and then is reflected back toward the starting end of the cable. The elapsed time multiplied by the diffusion speed v/2 gives the distance to the source of the fault. See also: \"Time-domain reflectometer\".\n\nIn the transient method, a breakdown is triggered at the cable fault. This effects a low-resistance short circuit for a few milliseconds. This in turn produces two travelling waves diffusing in opposite directions. These waves are reflected at the cable ends so that they then travel toward each other again in the direction of the cable fault. The waves are unable to pass the fault because of the arc produced by the short circuit, so they are therefore reflected back again as with the pulse reflection method, which due to the burning short circuit results in a reversal of polarity. There are various ways to decouple and analyse these transients.\n\nRoute tracing is used to determine where the faulty cable lies and pinpointing is the process of determining the exact position of the cable fault.\n\nIn cable identification, the faulty cables are identified from the fault-free cables at the already determined site.\n\nIn addition to pulse reflection method and transient method, there are two popular loop tests for finding the location of faults in underground cables.\n\nMurray loop test employes the principle of wheatstone bridge for locating the fault.To perform this test, it is necessary to have a sound cable running alongside the faulty cable. One end of the faulted cable is connected through a pair of resistors to the voltage source. Also a null detector is connected. The other end of the cable is shorted. The circuit is shown in the figure at right. The bridge is brought to balance by changing the values of \"R\" and \"R\". Then the distance to the fault location is calculated by solving the bridge equation. See also: Murray loop bridge\n\nThe similar Varley loop uses fixed resistors for RB1 and RB2, and inserts a variable resistor in the faulted leg. Test sets for cable testing can be connected for either bridge technique. If the fault resistance is high, the sensitivity of the Murray bridge is reduced and the Varley loop may be more suitable.\n\nAfter the cable fault is identified and located, it is then possible to “burn it in” using burner devices, in other words to convert it from a high-impedance fault to a low-impedance fault. For this a Burn Down Instrument, such as Baur ATG2 Burn Down Transformer or a similar device, can be used. A Burn Down Instrument has a Voltage Generator connected via Transformer and allows individual control of output voltage and current, a vital step for burning down High Impedance Faults.\n\nThe conventionally used aid in cable fault testing and location is the cable test van. The van is installed with conventional cable measuring systems for quickly reaching the location of any cable fault. In 20 years that followed, over 2000 fault location vehicles were manufactured, more than half of which were intended for the former USSR. These methods of cable fault location quickly became established in Western Europe as well.\n\n"}
{"id": "18365940", "url": "https://en.wikipedia.org/wiki?curid=18365940", "title": "Cellular confinement", "text": "Cellular confinement\n\nCellular confinement systems (CCS)—also known as geocells—are widely used in construction for erosion control, soil stabilization on flat ground and steep slopes, channel protection, and structural reinforcement for load support and earth retention. Typical cellular confinement systems are geosynthetics made with ultrasonically welded high-density polyethylene (HDPE) strips or novel polymeric alloy (NPA)—and expanded on-site to form a honeycomb-like structure—and filled with sand, soil, rock, gravel or concrete.\n\nResearch and development of cellular confinement systems (CCS) began with the U.S. Army Corps of Engineers in 1975 to devise a method for building tactical roads over soft ground. Engineers found that sand-confinement systems performed better than conventional crushed stone sections and they could provide an expedient construction technique for access roads over soft ground, without being adversely affected by wet weather conditions.\n\nEfforts for civilian commercialization of the cellular confinement system by the Presto Products Company, led to the Geoweb®. This cellular confinement system was made from high density polyethylene (HDPE), relatively strong, lightweight and suitable for geosynthetic extruding manufacturing. The cellular confinement system was used for load support, slope erosion control and channel lining and earth retention applications in the United States and Canada in the early 1980s.\n\nEarly research (Bathurst and Jarrett, 1988) found that cellular confinement reinforced gravel bases are \"equivalent to about twice the thickness of unreinforced gravel bases\" and that geocells performed better than single sheet reinforcement schemes (geotextiles and geogrids) and were more effective in reducing lateral spreading of infill under loading than conventional reinforced bases. However, Richardson (2004) (who was onsite at the US Corps of Engineers CCS Vicksburg facility) laments 25 years later on the \"near absence of research papers on geocells in all of the geosynthetic national and international conferences.\"\n\nA comprehensive review of available research literature by Yuu, et al (2008) concluded that the use of CCS technology in base reinforcement of paved roads and railways in particular was limited, due to the lack of design methods, lack of advanced research in the last two decades and limited understanding of the reinforcement mechanisms. Fortunately in the last decade research and development in geocell systems expanded significantly. Extensive research has been conducted in recent years on CCS reinforcement for roadway applications at many leading research institutes around the world, to understand the mechanisms and influencing factors of confinement reinforcement, evaluate its effectiveness in improving roadway performance, and develop design methods for roadway applications (Han, et al. 2011).\nExtensive research has been conducted in recent years on CCS reinforcement for roadway applications at many leading research institutes around the world, to understand the mechanisms and influencing factors of confinement reinforcement, evaluate its effectiveness in improving roadway performance, and develop design methods for roadway applications. \n\nHan (2013) summarizes comprehensive research conducted at the University of Kansas including static and cyclic plate loading tests, full-scale moving wheel tests, and numerical modeling on geocell-reinforced base courses with different infill materials and discusses the main research findings from these studies regarding permanent, elastic, and creep deformations, stiffness, bearing capacity, and stress distribution, and the development of design methods for geocell-reinforced bases. These studies showed that base courses reinforced with Novel Polymeric Alloy geocells reduced the vertical stresses at the interface between subgrade and base course, reduced permanent and creep deformations, increased elastic deformation, stiffness, and bearing capacity of base courses. Additional literature reviews can be found in Kief et al (2013). and Marto (2013) \n\nThe strength and stiffness of pavement layers determines the performance of highway pavements while aggregate use impacts the cost of duration of installation; therefore alternatives are needed to improve pavement quality using new materials with less aggregate usage (Rajagopal et al 2012). Geocells are recognized as a suitable geosynthetic reinforcement of granular soils to support static and moving wheel loads on roadways, railways and similar applications. But stiffness of the geocells was identified as a key influencing factor for geocell reinforcement, and hence the rigidity of the entire pavement structure.\nUtilizing recent advances in polymer and nano technology, extensive R&D was carried out to improve geocell wall stiffness, thermal and elastic properties and long term creep resistance by PRS Geotech. The result was a cellular confinement system (PRS-Neoloy) manufactured from Neoloy, a novel polymeric alloy (NPA). NPA is a composite alloy of polyamide nano-fibers dispersed in a polyethylene matrix. It provides ductility similar to HDPE with elastic behavior similar to engineering thermoplastics, to create a stiffer and creep resistant CCS more suitable for heavy duty applications, such as base reinforcement of highways, railways, container yards, etc. that are subject to long-term heavy static and dynamic loading.\n\nLaboratory plate loading tests, full-scale moving wheel tests, and field demonstrations showed that the performance of geocell-reinforced bases depends on the elastic modulus of the geocell. Geocells with a higher elastic modulus had a higher bearing capacity and stiffness of the reinforced base. NPA Geocells showed higher results in ultimate bearing capacity, stiffness, and reinforcement relative to geocells made from HDPE (Pokharel, et al, 2009). NPA geocells showed better creep resistance and better retention of stiffness and creep resistance particularly at elevated temperatures, verified by plate load testing, numerical modeling and full scale trafficking tests (Han, et al. 2011)(Pokharel, et al 2011).\n\nCCS have been successfully installed in thousands of projects worldwide. However, it is incumbent to differentiate between low load applications, such as slope and channel applications, and new heavy-duty applications, such as in the base layer of asphalt pavement structures of heavily trafficked motorways and highways. While all polymeric materials used in CCS creep over time and under loading, the question is; what is the rate of degradation, under which conditions, how will this impact performance, and when will it fail?\nThe lifespan of CCS in slope protection applications, for example, is less critical as vegetative growth and root interlock stabilize the soil. This in effect compensates for any long-term loss of confinement in the CCS. Similarly, load support applications for low volume roads that are not subject to heavy loading usually have a short design life; therefore minor loss of performance is tolerable. However, in critical applications such as reinforcement of the structural layer of asphalt highway pavements, long-term dimensional stability is critical. The required design life for such roads under heavy traffic loads is typically 20–25 years, requiring verifiable long-term durability.\n\nThere were few test standards for geocells and fewer for their use in design. Test standards for CCS were developed more than 40 years ago, while other test methods evolved from 2D planar geosynthetics. These do not reflect the composite behavior of 3D geometry of CCS, nor do they test long-term parameters such as: dynamic elastic stiffness, permanent plastic deformation and oxidation resistance. However, ISO/ASTM procedures have been developed for testing polymers in the space and automobile industries, as well as for other geosynthetic products. These new standards for CCS were proposed and under discussion by leading experts in geosynthetics in ASTM technical committee D-35. The stated goal is to set new industry standards that more accurately reflect 3D cellular confinement system geometry and material performance in the field rather than lab tests of individual strips and virgin materials that are typically used today.\n\nA recent development in standards for the use of reinforcement geosynthetics in roadways was recently published by in the Netherlands. This standard covers geocell (as well as geogrid) applications, support mechanisms, and design principles. It also emphasizes the importance of the geocell material attributes (stiffness and creep resistance) and how they influence long-term reinforcement factors. Additional guidelines for the use of geocells in roadway applications are currently under development by the ISO and ASTM organizations, but have not yet been published.\n\nA Cellular Confinement System when infilled with compacted soil creates a new composite entity that possesses enhanced mechanical and geotechnical properties. When the soil contained within a CCS is subjected to pressure, as in the case of a load support application, it causes lateral stresses on perimeter cell walls. The 3D zone of confinement reduces the lateral movement of soil particles while vertical loading on the contained infill results in high lateral stress and resistance on the cell-soil interface. These increase the shear strength of the confined soil, which:\nConfinement from adjacent cells provides additional resistance against the loaded cell through passive resistance, while lateral expansion of the infill is restricted by high hoop strength. Compaction is maintained by the confinement, resulting in long-term reinforcement.\n\nOn site, the geocell sections are fastened together and placed directly on the subsoil's surface or on a geotextile filter placed on the subgrade surface and propped open in an accordion-like fashion with an external stretcher assembly. The sections expand to an area of several tens of meters and consist of hundreds of individual cells, depending on the section and cell size. They are then filled with various infill materials, such as soil, sand, aggregate or recycled materials and then compacted using vibratory compactors. Surface layers many be of asphalt or unbound gravel materials.\n\nCellular Confinement Systems (CCS) have been used to improve the performance of both paved and unpaved roads by reinforcing the soil in the subgrade-base interface or within the base course. The effective load distribution of CCS creates a strong, stiff cellular mattress. This 3D mattress reduces vertical differential settlement into soft subgrades, improves shear strength, and enhances load-bearing capacity, while reducing the amount of aggregate material required to extend the service life of roads. As a composite system, cellular confinement strengthens the aggregate infill, thereby simultaneously enabling the use of poorly graded inferior material (e.g. local native soils, quarry waste or recycled materials) for infill as well as reducing the structural support layer thickness.\nTypical load support applications include reinforcement of base and subbase layers in flexible pavements, including: asphalt pavements; unpaved access, service and haul roads; military roads, railway substructure and ballast confinement; working platforms in intermodal ports; airport runways and aprons, permeable pavements; pipeline road support; green parking facilities and emergency access areas.\n\nThe three-dimensional lateral confinement of CCS along with anchoring techniques ensures the long-term stability of slopes using vegetated topsoil, aggregate or concrete surfacing (if exposed to severe mechanical and hydraulic pressures). The enhanced drainage, frictional forces and cell-soil-plant interaction of CCS prevents downslope movement and limits the impact of raindrops, channeling and hydraulic shear stresses. The perforations in the 3D cells allow the passage of water, nutrients and soil organisms. This encourages plant growth and root interlock, which further stabilizes the slope and soil mass, and facilitates landscape rehabilitation. Typical applications include: construction cut and fill slopes and stabilization; road and rail embankments; pipeline stabilization and storage facility berms; quarry and mine site restoration; channel and coastline structures. They can be built as an underlying mass or as a facing.\n\nCCS provide steep vertical mechanically stabilized earth structures (either gravity or reinforced walls) for steep faces, walls and irregular topography. Construction of CCS earth retention is simiplified as each layer is structurally sound thereby providing access for equipment and workers, while eliminating the need for concrete formwork and curing. Local soil can be used for infill when suitable and granular, while the outer faces enable a green or tan fascia of the horizontal terraces/rows utilizing topsoil. Walls also can be used for lining channels and in cases of high flow, it is required that the outer cells contain concrete or cementious slurry infill. CCS have been used to reinforce soft or uneven soil foundations for large area footings, for retaining wall strip footings, for load sharing of covers over pipelines and other geotechnical applications.\n\nCCS provides membrane liner protection, while creating stable soil, berms and slopes, for non-slip protection and durable impoundment of liquids and waste. Infill treatment depends on the contained materials: concrete for ponds and reservoirs; gravel for landfill drainage and leachates, vegetated infill for landscape rehabilitation. Concrete work is efficient and controlled as CCS functions as ready-made forms; CCS with concrete forms a flexible slab that accommodates minor subgrade movement and prevents cracking. In medium and low flow-velocities, CCS with geomembranes and gravel cover can be used to create impermeable channels, thereby eliminating the need for concrete.\n\nCCS is a green solution that makes civil infrastructure projects more sustainable. In load support applications, by reducing the amount and type of infill needed to reinforce soil, the usage of haul and earthmoving equipment is reduced. This in turn decreases fuel use, pollution and the carbon footprint, and at the same time minimizes on-site disruption from dust, erosion and runoff. When used for slope applications, perforated CCS provides excellent soil protection, water drainage and growth stratum for plants. The long-term design life of advanced CCS technology means that maintenance and the associated environmental costs are significantly reduced, as are long-term economic costs.\n\n\n\n"}
{"id": "4055462", "url": "https://en.wikipedia.org/wiki?curid=4055462", "title": "Chaneque", "text": "Chaneque\n\nChanekeh, Chaneque or Ohuican Chaneque, as they were called by the Aztecs, are legendary creatures in Mexican folklore. They are conceived of as small, sprite-like beings, elemental forces and guardians of nature.\n\nBy tradition, these beings would attack intruders, frightening them so that their soul would abandon their body, which the chaneques enclosed in the depth of the land. If the victim did not recover their soul through a specific ritual, he or she would become ill and die soon after.\n\nIn some contemporary legends, chaneques are described as children with the face of old men or women, that make people go stray during three or seven days, after which the victims cannot recall anything that happened... although it is thought that they are taken by the chaneques to their home in the Underworld, of which the entrance is a dry \"kapok\" tree. \nIn Catholic beliefs, the chaneque are the souls of the children who died without Christian baptism, and may be from precolonial times, they are a sort of violent child demon who prey on people who wander in the forest or jungles of Mexico, they confuse people to make them lost and prey on them at night, eating them, to get rid of them you have to turn your shirt inside out or yell Juan 3 times to break their spell ^.\n\nSimilar mythical beings are common in Mesoamerican and other Latin American folkloric traditions generally, referred to in Spanish as \"duende\". In the folkloric tradition of the Yucatán Peninsula, these elementals are known as \"aluxob\" in Yucatec Maya.\n"}
{"id": "6134", "url": "https://en.wikipedia.org/wiki?curid=6134", "title": "Charybdis", "text": "Charybdis\n\nCharybdis (; Ancient Greek: Χάρυβδις, , \"Kharybdis\") was a sea monster in the Greek Mythology, which was later rationalized as a whirlpool and considered a shipping hazard in the Strait of Messina.\n\nThe sea monster Charybdis was believed to live under a small rock on one side of a narrow channel. Opposite her was Scylla, another sea monster, that lived inside a much larger rock. The sides of the strait were within an arrow-shot of each other, and sailors attempting to avoid one of them would come in reach of the other. To be \"between Scylla and Charybdis\" therefore means to be presented with two opposite dangers, the task being to find a route that avoids both. Three times a day, Charybdis swallowed a huge amount of water, before belching it back out again, creating large whirlpools capable of dragging a ship underwater. In some variations of the story, Charybdis was simply a large whirlpool instead of a sea monster.\n\nThe theoretical size of Charybdis remains unknown, yet in order to consume Greek ships the whirlpool can be estimated to about 23 meters (75 ft) across. Charybdis has been associated with the Strait of Messina, off the coast of Sicily and opposite a rock on the mainland identified with Scylla. Were Charybdis to be located in the Strait of Messina it would in fact have the size to accommodate the whirlpool. A whirlpool does exist there, caused by currents meeting, but it is dangerous only to small craft in extreme conditions.\n\nA later myth makes Charybdis the daughter of Poseidon and Gaia and living as a loyal servant to her father.\n\nCharybdis aided her father Poseidon in his feud with her paternal uncle Zeus and, as such, helped him engulf lands and islands in water. Zeus, angry over the land she stole from him, captured and chained her to the sea-bed. Charybdis was then cursed by the god into a hideous bladder of a monster, with flippers for arms and legs, and an uncontrollable thirst for the sea. As such, she drank the water from the sea thrice a day to quench it, which created whirlpools. She lingered on a rock with Scylla facing her directly on another rock, making a strait.\n\n Odysseus faced both Charybdis and Scylla while rowing through a narrow channel. He ordered his men to avoid Charybdis, thus forcing them to pass near Scylla, which resulted in the deaths of six of his men. Later, stranded on a raft, Odysseus was swept back through the strait and passed near Charybdis. His raft was sucked into her maw, but he survived by clinging to a fig tree growing on a rock over her lair. On the next outflow of water, when his raft was expelled, Odysseus recovered it and paddled away safely.\n\nThe Argonauts were able to avoid both dangers because Hera ordered the Nereid nymph Thetis, Achilles' mother, to guide them through the perilous passage.\n\nAristotle mentions in his \"Meteorologica\" that Aesop once teased a ferryman by telling him a myth concerning Charybdis. With one gulp of the sea she brought the mountains to view; islands appeared after the next. The third is yet to come and will dry the sea altogether, thus depriving the ferryman of his livelihood.\n\n"}
{"id": "34558735", "url": "https://en.wikipedia.org/wiki?curid=34558735", "title": "Clymene (mythology)", "text": "Clymene (mythology)\n\nIn Greek mythology, the name Clymene or Klymene (; , \"Kluménē\") may refer to:\n\n"}
{"id": "41054127", "url": "https://en.wikipedia.org/wiki?curid=41054127", "title": "Coastal sediment transport", "text": "Coastal sediment transport\n\nCoastal sediment transport (a subset of sediment transport) is the interaction of coastal land forms to various complex interactions of physical processes. The primary agent in coastal sediment transport is wave activity (see Wind wave), followed by tides and storm surge (see Tide and Storm surge), and near shore currents (see Sea#Currents) . Wind-generated waves play a key role in the transfer of energy from the open ocean to the coastlines. In addition to the physical processes acting upon the shore, the size distribution of the sediment is a critical determination for how the beach will change (see Grain size determination). These various interactions generate a wide variety of beaches. (see Beach). Other than the interactions between coastal land forms and physical processes there is also the addition of modification of these landforms through anthropogenic sources (see human modifications). Some of the anthropogenic sources of modification have been put in place to halt erosion or prevent harbors from filling up with sediment. In order to assist community planners, local governments, and national governments a variety of models have been developed to predict the changes of beach sediment transport at coastal locations. Typically, during large wave events, the sediment gets transported off the beach face a deposited offshore generating a sandbar. Once the significant wave event has diminished, the sediment then gets slowly transported back onshore.\n\nIn the mid-1970s a significant amount of attention was paid to coastal sediment transport. In part, due to the National Sea Grant College Program and the U.S. Congress Mandated Sea Grant Act of 1976. One of the research areas included \"the development and the experimental verification of hydrodynamic laws governing the transport of marine sediments in the flow fields occurring in coastal waters.\" From this request for research, the Office of Sea Grant reviewed, accepted, and funded the Nearshore Sediment Transport Study (NSTS). Due to unforeseen complications the NSTS conducted only two major field experiments and a validation experiment. This was a significant contribution to the field of coastal sediment transport and helped initialize a great deal of future research.\n\n\nA variety of measurements are used to determine the beach profile, sediment grain size, and various other important parameters to determine what is influencing coastal sediment transport. Below are a few of the multitude.\n\nA three-wheeled vehicle deployed at the beach to measure the beach profile. (more information can be found at http://frf.usace.army.mil/vehicles2.stm)\n\nIn order to determine what the profile of a beach looks like, one method for determination is the Emory Beach Profiling Method. Initiating a benchmark, the researcher establishes a control point to start the surveys at. Typically this is far enough away from the swash zone that large changes in elevation will not occur during the sampling time. Once the initial benchmark is established, the researcher will take the Emory sampling device and measure the change in elevation over the distance the device is covering. Then, they will pick up the device and move it to the end point of their last survey, and so on. Until they reach the shoreline. Typically this is done during neap tide (see Tide for more information on neap tide).\n\nSince the sand grain diameters can vary throughout the entire beach the median grain size is used to determine sediment fall velocity. Determining sediment fall velocity allows the determination of what sediment is left where...\n\n\nModels for the prediction of sediment transport in coastal regions have been used since the mid 1970s. Some transport models are:\n"}
{"id": "21122151", "url": "https://en.wikipedia.org/wiki?curid=21122151", "title": "Code letters", "text": "Code letters\n\nCode letters or ship's call sign (or callsign) were a method of identifying ships before the introduction of modern navigation aids and today also. Later, with the introduction of radio, code letters were also used as radio call signs.\n\nIn 1857, the United Kingdom sponsored the \"Commercial Code of Signals for the Use of All Nations at Sea\", which introduced four letter flag signal codes to identify individual ships. The Commercial Code of Signals, c. 1900, was modified to become the International Code of Signals. By the 1860s, individual ships were being allocated code letters in the United States and Europe. From 1874, code letters were recorded in Lloyd's Register as part of each individual vessel's entry in the register. Generally, code letters allocated to a ship remained with that ship, although there are known cases where new code letters have been allocated following a change of port of registry or owner. Code Letters were sometimes reallocated once a ship had been struck from the register, but no two ships bore the same code letters at the same time. With the introduction of radio for communications, code letters were used also as radio call signs.\n\nCode letters used the twenty-six flags that represent the letters of the alphabet, plus the ten flags that represent the digits 0 - 9 also have been used. The substitute flags have not been used for call signs.\n\nEach flag has own name. If the ship's call sign is \"3EJH2\" (Panama Flag) the seamen never say \"Three E J H Two\". They say \"Three Echo Juliet Hotel Two\" to avoid misunderstanding as every country seamen have own pronunciation of letters and during speech over radio letters can be inaudible.\n\nIf call sign has 4 characters, the first character or figure of ship's call signs means country code for the ships registered under this country flag. If call sign has 5 characters, the first two characters or figure plus character of ship's call signs means country code for the ships registered under this country flag. The variations 4 or 5 characters due to 36 characters (26 letters + 10 digits) are not enough for all countries. For or the Soviet Union was used character \"U\" as the first character in call signs: cargo ship \"Metallurg Anosov\" had call sign \"USMW\" . In case that the ship changes the flag she has to change call sign also. For example, the ship \"Heinrich Arp\": Code Letters \"RDWL\" (1923-34) were changed to Code Letters \"DHKV\" (1934-45) and from 1946 once more to the Soviet Union Ship's call sign (unknown, but first character was \"U\").\n\nIf the ship is scrapped or sunk, her call sign can be given to another ship and, usually after a long time.\n\nThe last three characters of ship's call sign usually mean nothing, but can be one of them used as a code of the government Shipping Companies if the country has more than one Shipping companies.\n\nToday, each sea-going ship must keep on board the book or computer's play-disk \"List of Ship Stations and Maritime Mobile Service Identity Assignments\" of ITU publication, fresh edition, where listed all sea-going ships and their call signs also. This book must be fresh due to renewal (new edition had place every some years). in this book (or disk) mentioned:\n\"Call sign formed from the international call sign series in accordance with Article 19, Section III of the Radio Regulations (RR). The sign = (equal) in this column indicates that the name of the ship is used to identify the station in radiotelephony.\"\n\nSome canals or narrow places have special requirements for the vessels to hoist their call sign flags during the transit through the area. The Suez Canal was once such place where this requirement was made. Thanks to technological advances in the navigation abilities of marine craft, this action is no longer compulsory.\n"}
{"id": "31557892", "url": "https://en.wikipedia.org/wiki?curid=31557892", "title": "Ductility (Earth science)", "text": "Ductility (Earth science)\n\nIn Earth science, as opposed to Materials Science, Ductility refers to the capacity of a rock to deform to large strains without macroscopic fracturing. Such behavior may occur in unlithified or poorly lithified sediments, in weak materials such as halite or at greater depths in all rock types where higher temperatures promote crystal plasticity and higher confining pressures suppress brittle fracture. In addition, when a material is behaving ductilely, it exhibits a linear stress vs strain relationship past the elastic limit.\n\nDuctile deformation is typically characterized by diffuse deformation (i.e. lacking a discrete fault plane) and on a stress-strain plot is accompanied by steady state sliding at failure, compared to the sharp stress drop observed in experiments during brittle failure.\n\nThe brittle-ductile transition zone is characterized by a change in rock failure mode, at an approximate average depth of 10–15 km (~ 6.2–9.3 miles) in continental crust, below which rock becomes less likely to fracture and more likely to deform ductilely. The zone exists because as depth increases confining pressure increases, and brittle strength increases with confining pressure whilst ductile strength decreases with increasing temperature. The transition zone occurs at the point where brittle strength equals ductile strength. In glacial ice this zone is at approximately depth.\n\nNot all materials, however, abide by this transition. It is possible and not rare for material above the transition zone to deform ductilely, and for material below to deform in a brittle manner. The depth of the material does exert an influence on the mode of deformation, but other substances, such as loose soils in the upper crust, malleable rocks, biological debris, and more are just a few examples of that which does not deform in accordance to the transition zone.\n\nThe type of dominating deformation process also has a great impact on the types of rocks and structures found at certain depths within the Earth's crust. As evident from Fig. 1.1, different geological formations and rocks are found in accordance to the dominant deformation process. Gouge and Breccia form in the uppermost, brittle regime while Cataclasite and Pseudotachylite form in the lower parts of the brittle regime, edging upon the transition zone. Mylonite forms in the more ductile regime at greater depths while Blastomylonite forms well past the transition zone and well into the ductile regime, even deeper into the crust.\n\nDuctility is a material property that can be expressed in a variety of ways. Mathematically, it is commonly expressed as a \"total quantity of elongation\" or a \"total quantity of the change in cross sectional area\" of a specific rock until macroscopic brittle behavior, such as fracturing, is observed. For accurate measurement, this must be done under several controlled conditions, including but not limited to Pressure, Temperature, Moisture Content, Sample Size, etc., for all can impact the measured ductility. It is important to understand that even the same type of rock or mineral may exhibit different behavior and degrees of ductility due to internal heterogeneities small scale differences between each individual sample. The two quantities are expressed in the form of a ratio or a percent.\n\n% Elongation of a Rock = formula_1 \n\nWhere:\n\nformula_2 = Initial Length of Rock\n\nformula_3 = Final Length of Rock\n\n% Change in Area of a Rock = formula_4 \n\nWhere:\n\nformula_5 = Initial Area\n\nformula_6 = Final Area\n\nFor each of these methods of quantifying, one must take measurements of both the initial and final dimensions of the rock sample. For Elongation, the measurement is a uni-dimensional initial and final length, the former measured before any Stress is applied and the latter measuring the length of the sample after fracture occurs. For Area, it is strongly preferable to use a rock that has been cut into a cylindrical shape before stress application so that the cross-sectional area of the sample can be taken.\n\nCross-Sectional Area of a Cylinder = Area of a Circle = formula_7\n\nUsing this, the initial and final areas of the sample can be used to quantify the % change in the area of the rock.\n\nAny material is shown to be able to deform ductilely or brittlely, in which the type of deformation is governed by both the external conditions around the rock and the internal conditions sample. External conditions include temperature, confining pressure, presence of fluids, etc. while internal conditions include the arrangement of the crystal lattice, the chemical composition of the rock sample, the grain size of the material, etc.\n\nDuctilely Deformative behavior can be grouped into three categories: Elastic, Viscous, and Crystal-Plastic Deformation.\n\nElastic Deformation\n\nElastic Deformation is deformation which exhibits a linear stress-strain relationship (quantified by Young's Modulus) and is derived from Hooke's Law of spring forces (see Fig. 1.2). In elastic deformation, objects show no permanent deformation after the stress has been removed from the system and return to their original state.\n\nformula_8\n\nWhere:\n\nformula_9 = Stress (In Pascals)\n\nformula_10 = Young's Modulus (In Pascals)\n\nformula_11 = Strain (Unitless)\n\nViscous Deformation\n\nViscous Deformation is when rocks behave and deform more like a fluid than a solid. This often occurs under great amounts of pressure and at very high temperatures. In viscous deformation, stress is proportional to the strain rate, and each rock sample has its own material property called its Viscosity. Unlike elastic deformation, viscous deformation is permanent even after the stress has been removed.\n\nformula_12\n\nWhere:\n\nformula_9 = Stress (In Pascals)\n\nformula_14 = Viscosity (In Pascals * Seconds)\n\nformula_15 = Strain Rate (In 1/Seconds)\n\nCrystal-Plastic Deformation\n\nCrystal-Plastic Deformation occurs at the atomic scale and is governed by its own set of specific mechanisms that deform crystals by the movements of atoms and atomic planes through the crystal lattice. Like viscous deformation, it is also a permanent form of deformation. Mechanisms of crystal-plastic deformation include Pressure solution, Dislocation creep, and Diffusion creep.\n\nIn addition to rocks, biological materials such as wood, lumber, bone, etc. can be assessed for their ductility as well, for many behave in the same manner and possess the same characteristics as abiotic Earth materials. This assessment was done in Hiroshi Yoshihara's experiment, \"Plasticity Analysis of the Strain in the Tangential Direction of Solid Woo Subjected to Compression Load in the Longitudinal Direction.\" The study aimed to analyze the behavioral rheology of 2 wood specimens, the Sitka Spruce and Japanese Birch. In the past, it was shown that solid wood, when subjected to compressional stresses, initially has a linear stress-strain diagram (indicative of elastic deformation) and later, under greater load, demonstrates a non-linear diagram indicative of ductile objects. To analyze the rheology, the stress was restricted to uniaxial compression in the longitudinal direction and the post-linear behavior was analyzed using plasticity theory. Controls included moisture content in the lumber, lack of defects such as knots or grain distortions, temperature at 20 C, relative humidity at 65%, and size of the cut shapes of the wood samples.\n\nResults obtained from the experiment exhibited a linear stress-strain relationship during elastic deformation but also an unexpected non-linear relationship between stress and strain for the lumber after the elastic limit was reached, deviating from the model of plasticity theory. Multiple reasons were suggested as to why this came about. First, since wood is a biological material, it was suggested that under great stress in the experiment, the crushing of cells within the sample could have been a cause for deviation from perfectly plastic behavior. With greater destruction of cellular material, the stress-strain relationship is hypothesized to become more and more nonlinear and non-ideal with greater stress. Additionally, because the samples were inhomogeneous (non-uniform) materials, it was assumed that some bending or distortion may have occurred in the samples that could have deviated the stress from being perfectly uniaxial. This may have also been induced by other factors like irregularities in the cellular density profile and distorted sample cutting.\n\nThe conclusions of the research accurately showed that although biological materials can behave like rocks undergoing deformation, there are many other factors and variables that must be considered, making it difficult to standardize the ductility and material properties of a biological substance.\n\nPeak Ductility Demand is a quantity used particularly in the fields of architecture, geological engineering, and mechanical engineering. It is defined as the amount of ductile deformation a material must be able to withstand (when exposed to a stress) without brittle fracture or failure. This quantity is particularly useful in the analysis of failure of structures in response to earthquakes and seismic waves.\n\nIt has been shown that earthquake aftershocks can increase the peak ductility demand with respect to the mainshocks by up to 10%.\n"}
{"id": "22191625", "url": "https://en.wikipedia.org/wiki?curid=22191625", "title": "Elektrizitätsmuseum", "text": "Elektrizitätsmuseum\n\nThe Elektrizitätsmuseum (Museum of Electricity) is in Münchenstein, in the canton of Basel-Country in Switzerland.\n\nThe Elektrizitätsmuseum belongs to the electric utility Elektra Birseck Münchenstein (EBM), and was opened in 1997. Exhibits explore the history and development of power production and its use. The collection contains rare historic equipment and is complemented by a laboratory in which visitors can experiment with electric power.\n\n\n"}
{"id": "177696", "url": "https://en.wikipedia.org/wiki?curid=177696", "title": "Energy economics", "text": "Energy economics\n\nEnergy economics is a broad scientific subject area which includes topics related to supply and use of energy in societies. Due to diversity of issues and methods applied and shared with a number of academic disciplines, energy economics does not present itself as a self-contained academic discipline, but it is an applied subdiscipline of economics. From the list of main topics of economics, some relate strongly to energy economics:\nEnergy economics also draws heavily on results of energy engineering, geology, political sciences, ecology etc. Recent focus of energy economics includes the following issues:\n\nSome institutions of higher education (universities) recognise energy economics as a viable career opportunity, offering this as a curriculum. The University of Cambridge, Massachusetts Institute of Technology and the Vrije Universiteit Amsterdam are the top three research universities, and Resources for the Future the top research institute. There are numerous other research departments, companies and professionals offering energy economics studies and consultations.\n\nEnergy related issues have been actively present in economic literature since the 1973 oil crisis, but have their roots much further back in the history. As early as 1865, W.S. Jevons expressed his concern about the eventual depletion of coal resources in his book \"The Coal Question\". One of the best known early attempts to work on the economics of exhaustible resources (incl. fossil fuel) was made by H. Hotelling, who derived a price path for non-renewable resources, known as Hotelling's rule.\n\nLeading journals of energy economics include:\n\nThere are several other journals that regularly publish papers in energy economics:\n\nThere is also a handbook in three volumes.\n\nMuch progress in energy economics has been made through the conferences of the International Association for Energy Economics, the model comparison exercises of the (Stanford) Energy Modeling Forum and the meetings of the International Energy Workshop.\n\nIDEAS/RePEc has a collection of recent working papers.\n\nIDEAS/RePEc has a list of energy economists and a ranking of the same. Here are the top 20 leading energy economists as of December 2016:\n\n\n"}
{"id": "46348501", "url": "https://en.wikipedia.org/wiki?curid=46348501", "title": "Evolution of the cochlea", "text": "Evolution of the cochlea\n\nCochlea is Latin for “snail, shell or screw” and originates from the Greek word κοχλίας \"kohlias\". The modern definition, the auditory portion of the inner ear, originated in the late 17th century. Within the mammalian cochlea exists the organ of Corti, which contains hair cells that are responsible for translating the vibrations it receives from surrounding fluid-filled ducts into electrical impulses that are sent to the brain to process sound. This spiral-shaped cochlea is estimated to have originated during the early Cretaceous Period, around 120 million years ago. Further, the auditory innervation of the spiral-shaped cochlea also traces back to the Cretaceous period. The evolution of the human cochlea is a major area of scientific interest because of its favourable representation in the fossil record. During the last century, many scientists such as evolutionary biologists and paleontologists strove to develop new methods and techniques to overcome the many obstacles associated with working with ancient, delicate artifacts. In the past, scientists were limited in their ability to fully examine specimens without causing damage to them. In more recent times, technologies such as micro-CT scanning became available. These technologies allow for the visual differentiation between fossilized animal materials and other sedimentary remains. With the use of X-ray technologies, it is possible to ascertain some information about the auditory capabilities of extinct creatures, giving insight to human ancestors as well as their contemporary species.\n\nWhile the basic structure of the inner ear in lepidosaurs (lizards and snakes), archosaurs (birds and crocodilians) and mammals is similar, and the organs are considered to be homologous, each group has a unique type of auditory organ. The hearing organ arose within the lagenar duct of stem reptiles, lying between the saccular and lagenar epithelia. In lepidosaurs, the hearing organ, the basilar papilla, is generally small, with at most 2000 hair cells, whereas in archosaurs the basilar papilla can be much longer (>10mm in owls) and contain many more hair cells that show two typical size extremes, the short and the tall hair cells. In mammals, the structure is known as the organ of Corti and shows a unique arrangement of hair cells and supporting cells. All mammalian organs of Corti contain a supporting tunnel made up of pillar cells, on the inner side of which there are inner hair cells and outer hair cells on the outer side. The definitive mammalian middle ear and the elongated cochlea allows for better sensitivity for higher frequencies.\n\nAs in all lepidosaurs and archosaurs, the single-ossicle (columellar) middle ear transmits sound to the footplate of the columella, which sends a pressure wave through the inner ear. In snakes, the basilar papilla is roughly 1mm long and only responds to frequencies below about 1 kHz. In contrast, lizards tend to have two areas of hair cells, one responding below and the other above 1 kHz. The upper frequency limit in most lizards is roughly 5–8 kHz. The longest lizard papillae are about 2mm long and contain 2000 hair cells and their afferent innervating fibers can be very sharply tuned to frequency.\n\nIn birds and crocodilians, the similarity of the structure of the basilar papilla betrays their close evolutionary relationship. The basilar papilla is up to about 10mm long and contains up to 16500 hair cells. While most birds have an upper hearing limit of only about 6 kHz, the barn owl can hear up to 12 kHz and thus close to the human upper limit.\n\nEgg-laying mammals, the monotremes (spiny anteater and platypus), do not have a spiral cochlea, but one shaped more like a banana, up to about 7 mm long. Like in lepidosaurs and archosaurs, it contains a lagena, a vestibular sensory epithelium, at its tip. Only in therian mammals (marsupials and placentals) is the cochlea truly coiled 1.5 to 3.5 times. Whereas in monotremes there are many rows of both inner and outer hair cells in the organ of Corti, in therian (marsupial and placental) mammals the number of inner hair-cell rows is one, and there are generally only three rows of outer hair cells.\n\nAmphibians have unique inner ear structures. There are two sensory papillae involved in hearing, the basilar (higher frequency) and amphibian (lower frequency) papillae, but it is uncertain whether either is homologous to the hearing organs of lepidosaurs, archosaurs and mammals and we have no idea when they arose.\n\nFish have no dedicated auditory epithelium, but use various vestibular sensory organs that respond to sound. In most teleost fishes it is the saccular macula that responds to sound. In some, such as goldfishes, there is also a special bony connection to the gas bladder that increases sensitivity allowing hearing up to about 4 kHz.\n\nThe size of cochlea has been measured throughout its evolution based on the fossil record. In one study, the basal turn of the cochlea was measured, and it was hypothesized that cochlear size correlates with body mass. The size of the basal turn of the cochlea was not different in Neanderthals and Holocene humans, however it became larger in early modern humans and Upper Paleolithic humans. Furthermore, the position and orientation of the cochlea is similar between Neanderthals and Holocene humans, relative to plane of the lateral canal, whereas early modern and upper Paleolithic humans have a more superiorly placed cochlea than Holocene humans. When comparing hominins of the Middle Pleistocene and Neanderthals and Holocene humans, the apex of the cochlea faces more inferiorly in the hominins than the latter two groups. Finally, the cochlea of European middle Pleistocene hominins faces more inferiorly than Neanderthals, modern humans, and Homo erectus.\nHuman beings, along with Apes, are the only mammals that do not have high frequency (>32 kHz) hearing. Humans have long cochleae, but the space devoted to each frequency range is quite large (2.5mm per octave), resulting in a comparatively reduced upper frequency limit. The human cochlea has approximately 2.5 turns around the modiolus (the axis). Humans, like many mammals and birds, are able to perceive auditory signals that displace the eardrum by a mere picometre.\n\nBecause of its prominence and preserved state in the fossil record, until recently, the ear had been used to determine phylogeny. The ear itself contains different portions, including the outer ear, the middle ear, and the inner ear and all of these show evolutionary changes that are often unique to each lineage [14]. It was the independent evolution of a tympanic middle ear in the Triassic era that produced strong selection pressures towards improved hearing organs in the separate lineages of land vertebrates.\n\nThe cochlea is the tri-chambered auditory detection portion of the ear, consisting of the scala media, the scala tympani, and the scala vestibuli. Regarding mammals, placental and marsupial cochleae have similar cochlear responses to auditory stimulation as well as DC resting potentials. This leads to the investigation of the relationship between these therian mammals and researching their ancestral species to trace the origin of the cochlea.\n\nThis spiral-shaped cochlea that is in both marsupial and placental mammals is traced back to approximately 120 million years ago. The development of the most basic basilar papilla (the auditory organ that later evolved into the Organ of Corti in mammals) happened at the same time as the water-to-land transition of vertebrates, approximately 380 million years ago. The actual coiling or spiral nature of the cochlea occurred to save space inside the skull. The longer the cochlea, the higher is the potential resolution of sound frequencies given the same hearing range. The oldest of the truly coiled mammalian cochleae were approximately 4 mm in length.\n\nThe earliest evidence available for primates depicts a short cochlea with prominent laminae, suggesting that they had good high-frequency sensitivity as opposed to low-frequency sensitivity. After this, over a period of around 60 million years, evidence suggests that primates developed longer cochleae and less prominent laminae, which means that they had an improvement in low-frequency sensitivity and a decrease in high-frequency sensitivity. By the early Miocene period, the cycle of the elongation of the cochleae and the deterioration of the laminae was completed. Evidence shows that primates have had an increasing cochlear volume to body mass ratio over time. These changes in the cochlear labyrinth volume negatively affect the highest and lowest audible frequencies, causing a downward shift. Non-primates appear to have smaller cochlear labyrinth volumes overall when compared to primates. Some evidence also suggests that selective forces for the larger cochlear labyrinth may have started after the basal primate node.\nMammals are the subject of a substantial amount of research not only because of the potential knowledge to be gained regarding humans, but also because of their rich and abundant representation in the fossil record. The spiral shape of the cochlea evolved later on in the evolutionary pathway of mammals than previously believed, just before the therians split into the two lineages marsupials and placentals, about 120 million years ago.\n\nParallel to the evolution of the cochlea, prestins show an increased rate of evolution in therian mammals. Prestins are located in the outer hair cells of mammalian cochlea and are considered motor proteins. They are found in the hair cells of all vertebrates, including fish, but are thought to have initially been membrane transporter molecules. A high concentration of prestins are found only in the lateral membranes of therian outer hair cells (there is uncertainty with regard to concentrations in monotremes). This high concentration is not found in inner hair cells, and is also lacking in all hair cell types of non-mammals. Prestin also has a role in motility, which evolved a greater importance in the motor function in land vertebrates, but this developed vastly differently in different lineages. In certain birds and mammals, prestins function as both transporters and motors, but the strongest evolution to robust motor dynamics only evolved in therian mammals. It is hypothesized that this motor system is significant to the therian cochlea at high frequencies because of the distinctive cellular and bony composition of the organ of Corti that allows the prestins to intensify movements of the whole structure.\nModern ultra-sound echolocating species such as bats and toothed whales show highly evolved prestins, and these prestins show identical sequence alterations over time. Unusually, the sequences thus apparently evolved independent from each other during different time periods. Furthermore, the evolution of neurotransmitter receptor systems (acetylcholine) that regulate the motor feedback of the outer hair cells coincides with prestin evolution in therians. This suggests that there was a parallel evolution of a control system and a motor system in the inner ear of therian mammals.\n\nLand vertebrates evolved middle ears independently in each major lineage, and are this the result of parallel evolution. The configurations of the middle ears of monotreme and therian mammals can thus be interpreted as convergent evolution or homoplasy. Thus evidence from fossils demonstrate homoplasies for the detachment of the ear from the jaw. Furthermore, it is apparent that the land-based eardrum, or tympanic membrane, and connecting structures such as the Eustachian tube evolved convergently in multiple different settings as opposed to being a defining morphology.\n"}
{"id": "51631063", "url": "https://en.wikipedia.org/wiki?curid=51631063", "title": "Failed supernova", "text": "Failed supernova\n\nA failed supernova is an astronomical event in time domain astronomy in which a star suddenly brightens as in the early stage of a supernova, but then does not increase to the massive flux of a supernova. They could be counted as a subcategory of supernova imposters. They have sometimes misleadingly been called unnovae.\n\nFailed supernovae are thought to create stellar black holes by the collapsing of a red supergiant star in the early stages of a supernova. When the star can no longer support itself, the core collapses completely, forming a stellar-mass black hole, and consuming the nascent supernova without having the massive explosion. For a distant observer, the red supergiant star will seem to wink out of existence with little or no flare-up. The observed instances of these disappearances seem to involve supergiant stars with masses above 17 solar masses.\n\nFailed supernovae are one of several events that theoretically signal the advent of a black hole born from an extremely massive star, others including hypernovae and long-duration gamma-ray bursts.\n\nTheoretically, a red supergiant star may be too massive to explode into a supernova, and collapse directly into being a black hole, without the bright flash. They would however generate a burst of gravitational waves. This process would occur in the higher mass red supergiants, explaining the absence of observed supernovae with such progenitors.\n"}
{"id": "32159946", "url": "https://en.wikipedia.org/wiki?curid=32159946", "title": "Forest floor interception", "text": "Forest floor interception\n\nForest floor interception is the part of the (net) precipitation or throughfall that is temporarily stored in the top layer of the forest floor and successively evaporated within a few hours or days during and after the rainfall event. The forest floor can consist of bare soil, short vegetation (like grasses, mosses, creeping vegetation, etc.) or litter (i.e. leaves, twigs, or small branches).\n\n"}
{"id": "649042", "url": "https://en.wikipedia.org/wiki?curid=649042", "title": "Free energy suppression conspiracy theory", "text": "Free energy suppression conspiracy theory\n\nFree energy suppression (or new energy suppression) is a conspiracy theory that technologically viable, pollution-free, no-cost energy sources are being suppressed by government, corporations, or advocacy groups. Devices allegedly suppressed include perpetual motion machines, cold fusion generators, torus-based generators, reverse-engineered extraterrestrial technology and other generally unproven, low-cost energy sources..\n\nThe alleged suppression (or weakening) is claimed to have occurred since the mid-19th century and allegedly perpetrated by various government agencies, corporate powers, special interest groups, and fraudulent inventors. The special interest groups are usually claimed to be associated with the fossil fuel or nuclear industry, whose business model would be threatened.\n\nClaims of suppression include:\n\nSome examples of individuals who were allegedly suppressed, harassed or killed for their research are: Thomas Henry Moray, Stanley Meyer and Eugene Mallove.\n\n"}
{"id": "20521094", "url": "https://en.wikipedia.org/wiki?curid=20521094", "title": "Gemstone irradiation", "text": "Gemstone irradiation\n\nThe gemstone irradiation is a process in which a gemstone is artificially irradiated in order to enhance its optical properties. High levels of ionizing radiation can change the atomic structure of the gemstone's crystal lattice, which in turn alters the optical properties within it. As a result, the gemstone's color may be significantly altered or the visibility of its inclusions may be lessened. The process, widely practised in jewelry industry, is done in either a nuclear reactor for neutron bombardment, a particle accelerator for electron bombardment, or a gamma ray facility using the radioactive isotope cobalt-60. Irradiation has enabled the creation of gemstone colors that do not exist or are extremely rare in nature.\n\nThe term \"irradiation\" is a very broad one, which covers bombardment by subatomic particles as well as the use of the full range of electromagnetic radiation, including (in order of increasing frequency and decreasing wavelength) infrared radiation, visible light, ultraviolet radiation, X-rays and gamma rays.\nCertain natural gemstone colors, such as blue-to-green colors in diamonds, are the results of the exposure to natural radiation in the earth, which is usually alpha or beta particle. The limited penetrating ability of these particles result in partial coloring of the diamond's surface. Only high-energy radiation such as gamma ray or neutron can produce fully saturated body colors, and the sources of these types of radiation are rare in nature, which necessitates the artificial treatment in jewelry industry.\n\nIrradiation, particularly when done in a nuclear reactor, can make gemstones slightly radioactive, so they are typically set aside for a couple of months to allow any residual radioactivity to decay. The first documented artificially irradiated gemstone was created by English chemist Sir William Crookes in 1905, by burying a diamond in powdered radium bromide. After having been kept there for 16 months, the previously colorless diamond became green. This method produced a dangerously high degree of long-term residual radioactivity and is no longer in use. However, radium-treated green diamonds are still occasionally found in markets, which can be detected by a Geiger counter or by making autoradiographs on photographic films.\n\nThe concerns for possible health risks related to the residual radioactivity of the gemstones led to government regulations in many countries. In the United States, the Nuclear Regulatory Commission (NRC) has set strict limits on the allowable levels of residual radioactivity before an irradiated gemstone can be distributed in the country. All neutron- or electron beam-irradiated gemstones must be tested by an NRC-licensee prior to release for sales. In India, the Bhabha Atomic Research Centre started irradiating gemstones in the early 1970s. In Thailand, the Office of Atoms for Peace (OAP) conducts the process for private sectors, irradiating of gemstones from 1993 to 2003.\n\nThe most commonly irradiated gemstone is topaz, which becomes blue after the process. Blue topaz is very rare in nature and almost always the result of artificial irradiation. According to the American Gem Trade Association, approximately 30 million carats () of topaz are irradiated every year globally, 40 percent of which were done in the United States as of 1988. As of 2011, no topaz is neutron irradiated in the US; major treatment areas are Germany and Poland. A lot of linear accelerated treatment is done in Bangkok.\n\nDiamonds are usually irradiated to become yellow, blue-green or green, although other colors are possible.\n\nQuartz may be irradiated to produce amethyst and other colors.\n\nColorless beryls, also called goshenite, become pure yellow when irradiated, which are called golden beryl or heliodor.\n\nPearls are irradiated to produce gray blue or gray-to-black colors. Methods of using a cobalt-60 gamma ray facility to darken white Akoya pearls were patented in the early 1960s. But the gamma ray treatment does not alter the color of the pearl's nacre, therefore is not effective if the pearl has a thick or non-transparent nacre. Most black pearls available in markets prior to the late 1970s had been either irradiated or dyed.\n\nGemstones that have been subjected to artificial irradiation generally show no visible evidence of the process, although some diamonds irradiated in an electron beam may show color concentrations around the culet or along the keel line.\n\nIn topaz, some irradiation sources may produce mixtures of blue and yellow-to-brown colors, so heating is required as an additional procedure to remove the yellowish color.\n\nIn some cases, the new colors induced by artificial irradiation may fade rapidly when exposed to light or gentle heat, so some laboratories submit them to a \"fade test\" to determine color stability. Sometimes colorless or pink beryls become deep blue upon irradiation, which are called Maxixe-type beryl. However, the color easily fades when exposed to heat or light, so it has no practical jewelry application.\n\n"}
{"id": "46514307", "url": "https://en.wikipedia.org/wiki?curid=46514307", "title": "Glossary of caving and speleology", "text": "Glossary of caving and speleology\n\nThere are a number of terms that are used in connection with caves, caving and speleology. The following is an incomplete list.\n\n\n\n\n\n\n\n\n"}
{"id": "18899704", "url": "https://en.wikipedia.org/wiki?curid=18899704", "title": "GrADS", "text": "GrADS\n\nThe Grid Analysis and Display System (GrADS) is an interactive desktop tool that is used for easy access, manipulation, and visualization of earth science data. The format of the data may be either binary, GRIB, NetCDF, or HDF-SDS (Scientific Data Sets). GrADS has been implemented worldwide on a variety of commonly used operating systems and is freely distributed over the Internet.\n\nGrADS uses a 4-Dimensional data environment: longitude, latitude, vertical level, and time. Data sets are placed within the 4-D space by use of a data descriptor file. GrADS interprets station data as well as gridded data, and the grids may be regular, non-linearly spaced, Gaussian, or of variable resolution. Data from different data sets may be graphically overlaid, with correct spatial and time registration. It uses the \"ctl\" mechanism to join differing time group data sets. Operations are executed interactively by entering FORTRAN-like expressions at the command line. A rich set of built-in functions are provided, but users may also add their own functions as external routines written in any programming language.\n\nData may be displayed using a variety of graphical techniques: line and bar graphs, scatter plots, smoothed contours, shaded contours, streamlines, wind vectors, grid boxes, shaded grid boxes, and station model plots. Graphics may be output in PostScript or image formats. GrADS provides geophysically intuitive defaults, but the user has the option to control all aspects of graphics output.\n\nGrADS has a programmable interface (scripting language) that allows for sophisticated analysis and display applications. Scripts can display buttons and drop menus as well as graphics, and then take action based on user point-and-clicks. GrADS can be run in batch mode, and the scripting language facilitates using GrADS to do long overnight batch jobs. As of version 2.2.0, graphics display and printing are now handled as independent plug-ins. A C-language Python extension for GrADS called GradsPy was introduced in version 2.2.1.\n\n\n"}
{"id": "39212115", "url": "https://en.wikipedia.org/wiki?curid=39212115", "title": "Great Plains ecoregion", "text": "Great Plains ecoregion\n\nThe ecology of the Great Plains is diverse, largely owing to their great size. Differences in rainfall, elevation, and latitude create a variety of habitats including short grass, mixed grass, and tall-grass prairies, and riparian ecosystems.\nThe Great Plains extend from Mexico in the south through the central United States to central Canada. Many sub-regions exist within the area.\n\nThe region is home to many animals, including American bison, pronghorn, mule, and white tailed deer, and birds such as ducks, hawks, and sparrows, along with many invertebrate species.\n\nSettlement of \"America's breadbasket\" led to ecological destruction. Widespread agriculture led to the near-complete extermination of the American bison in the late 1800s and the reduction of the tallgrass prairie to less than 1% of its former extent. The plains are now largely agricultural, with large ranches and farms. However, restoration efforts in some areas, like Montana's American Prairie Reserve, are leading to the gradual expansion of the threatened ecosystem.\n\nThe climate is unique due to the many different wind patterns that flow throughout the region, traveling from east to west and north to south. Due to the fact that this region is geographically positioned in the center of the United States and Canada, there are many different air mass types that pass through and affect the constantly shifting weather patterns. This means that the Great Plains has a less consistent climate due to its central location than a region located on the coast. This is shown by how the western Great Plains is semi-arid, while the eastern portion of the Great Plains is much wetter. It has the four seasons of summer, autumn, winter, spring, but each season brings new extremes in the weather conditions. For example, the southern portions of the region typically experience 70 to 100 days each year over 90 °F, while the northern portions typically see only 10 to 20 days above 90 °F. It’s the air masses that come in from all directions that bring this variable climate.\n\nEach air mass type brings in different temperature and moisture properties. The continental polar air mass brings in cold and dry air from central Canada, traveling south across the region. The continental tropical air mass comes in from the Gulf of Mexico and the Caribbean, bringing in hot and dry air while moving north. The maritime tropical air mass comes from the southwest United States and Northern Mexico, and it tends to bring in warm and moist air, but sometimes the air that comes in is dry. The last air mass that affects this ecoregion is the maritime polar air mass. It comes in from the Pacific Ocean and moves east over the mountain regions. It brings in cool moist air that changes to warm dry air after moving over the mountains. These air masses cause the seasons to be very extreme and drastic. The winter time brings harsh and varied weather. The midsummer months bring in warm moist and dry air, depending on the area within the region and what air masses affect those areas.\n\nParalleling the varying climate patterns is the precipitation. The areas nearest the Gulf of Mexico, where the atmospheric moisture is greatest, will receive more than forty inches of precipitation annually. The wastern areas of the region, such as Montana, receive less than fourteen inches annually. In the winter time, the southern region has less than an inch of snowfall, while the northern regions receive more than forty. The spring time is also a season that brings much precipitation to the Great Plains through the cold, dry air masses that interact with the air masses from the Gulf of Mexico, creating outbreaks of severe thunderstorms with heavy rainfall, high winds, hail, and tornadoes. Most of the winter season in the Northern Plains actually has a snow blanket over a majority of the winter season. This shows how there is consistent precipitation over the region during the winter months, while in the heat of summer there is more chance for drought with sporadic heavy rains.\n\nDue to the highly variable climatic regimes across the Great Plains, many aspects of climate change are not expected to affect all areas of the eco-region equally. In regards to precipitation, this means an exacerbation of extremes where dry areas in the south are expected to get drier and wetter areas in the north to get wetter. In turn this will increase the intensity of already problematic droughts across the region as well as creating the potential for flooding in the wetter north. The percent change in precipitation for both areas is dependent upon different emission scenarios; with higher emission levels in the future being conducive to greater extremes. Dramatic increases in average annual temperature are also expected, with average winter temperatures already having risen 7& nbsp;°F in the past 30 years. These increased temperatures are expected to cause warmer winters with warmer springs as well as hotter summers in the south-central plains.\n\nIn regards to the biotic communities of the Great Plains, the potential repercussions of these changes could be felt in a variety of ways. Extreme droughts could kill vegetation, potentially causing the collapse of agriculture in some areas increasing the risk of erosion. This loss of growing medium, nutrients and moisture retention could prove to be a devastating blow to any ecosystem that may try to reclaim the land as well as leaving the barren areas susceptible to more stress tolerant invasive species. Additionally, droughts could dry up prairie potholes essential for the breeding of many species, especially migratory waterbirds. Changes in temperature have the potential to cause range shifts for some species, possibly increasing competition between species that never previously shared a range and even decreasing populations of or eliminating species that can’t effectively spread or adapt to new conditions. Temperature changes, especially earlier springs, could also cause changes in phenology which could put organisms out of sync with their ecosystem and eventually lead to their decline. Other potential issues include a loss of biodiversity and decreased productivity within the ecoregion.\n\nOriginally massive glaciers that formed in Canada moved southward over the central and low-elevation plains located in the United States. These glaciers and their deposits had great effects on the surface of the land they covered, with biggest changes occurring between the Missouri and Ohio Rivers. One key abiotic factor that affects Great Plains is weather in relation to the low- relief topography as result of glacial smoothing. Low relief topography is used to describe areas that have little difference in altitude throughout the region. Low relief landscapes, such as the various types of grasslands found throughout the Great Plains, have an effect on rainfall distribution. Rainfall in this ecoregion increases from west to east resulting in various types of prairie grasslands.\n\nTopography in the Great Plains actually affects soil composition in areas of different elevation. Higher accumulations of soil organic matter are found in lower landscape positions such as grasslands than in higher landscape positions such as buttes, mesas, and escarpments found throughout the north western areas of the ecoregion. In the short grass regions such as the High Plains of the Great Plains, soil typically stores no moisture annually because vegetation depends on whatever water exists in the soil during dry spells. Soil in this region is typically drained, composed of loam and clay. Specialized plants such as various species of forbs and shrubs utilize this soil. Some adaptations that plants have acquired in this region include massive and intricate root systems that make up around 90 percent of the plants biomass. This allows the plants to stay securely planted in ground and have roots that reach moisture in the deepest sections of the soil. In tall grass prairies, water is less scarce and the soil contains more moisture resulting a smaller root biomass.\n\nThe Great Plains ecoregion comprises a number of water bodies which play an integral role in its unique hydrology. There are thirteen rivers that are considered to be located within the Great Plains region. Most of the rivers that originate in the Rocky Mountain region in the west are a source of irrigation for farms. These rivers benefit greatly from melted snow pack from the mountains, which feeds the rivers during the growing season. Another water source in the Great Plains is wetlands, with the greatest concentrations located in the northern glaciated region of the plains. Up to half of areas in the northern Great Plains are wetlands. These, as well as the wetlands in the Nebraska Sandhills, serve as major breeding, staging, and nesting habitat for migratory waterfowl. Playas, or temporary lakes, in the southwestern United States also provide habitats for migrating waterfowl from Canada and the United States during the winter.\n\nThe Ogallala aquifer, or the High Plains aquifer, is an integral fresh water source for the entirety of the Great Plains region, providing drinking water to 80% of the population and irrigating 13 million acres of land. Precipitation, seasonal lakes, and prehistoric water reserves serve as sources of water for the aquifer, which lies beneath 174,000 square miles of the Central and Southern regions, contains 3.25 billion acre-feet of water, and which is used by around 200,000 irrigation wells. Around 95% of the water pumped out of the aquifer is used for irrigation for the extensive areas of farmland in the Great Plains. The playa lakes, or seasonal lakes, are the primary sources of recharge for the aquifer, with an average of 0.5 inches per year as the recharge rate for the entire High Plains region. Population, agricultural, and economic growth have increased the demand for water in the areas that rely on the aquifer, causing the average level of water in the aquifer to drop by 13 feet since 1950.\n\nThe environmental threats that pose the most harm toward the Great Plains include water depletion, land degradation, and increasing temperature change. The winter months have become much warmer in the Plains, whether it is in the North, near North Dakota, or in the South, throughout Texas and bordering states, excluding the winters of 2014, 2015, and 2016. Though the winters are getting warmer, it is predicted that the summer months will have a greater increase than the temperatures in the winter months. The effects of this increase in temperature is predicted to cause more frequent extreme events such as heat waves, droughts, and heavy rainfall. This great increase in temperature will be the cause of the increased depletion of already declining water sources. Depleting water in the Great Plains will affect all populations in a negative way. \"Most of the water used in the Great Plains comes from the High Plains aquifer (sometimes referred to by the name of its largest formation, the Ogallala aquifer), which stretches from South Dakota to Texas.\" Conserving water in the Great Plains is one of the most important factors in keeping the Great Plains sustainable. It is also very important that farmers who use the land are sustainable in their practices. Since there are many different sustainable ways of farming, it is hard to decide which way would be the most sustainable. However, according to the Annals of the Association of American Geographers, farmers are not very likely to change their ways, leaving the outcome questionable for the Great Plains. \"What is really needed are new methods, concepts, and measuring techniques\". The biggest challenge in changing the sustainability in such a large ecoregion is getting the a large portion of farmers using the land to practice in a way that does not harm the land, which poses to be a challenge since there are so many different farming practices. \"Prairie conservation requires: 1) New technology...to prioritize and set context to save prairie, 2) ecologically based initiatives to reverse significant losses in area and condition of native grasslands, 3) rethinking of standardized tools in the range management profession, and 4) a new natural resource agency.\"\n\nThere are many different types of habitats in the Great Plains, because of its great size. Differences in latitude and longitude, as well as differences in elevation and proximity to water, shape the ecosystems of these grasslands.\n\nTallgrass prairies are found in the southern and eastern section of the great plains. It once covered 170 million acres in North America. Now, less than 4% remains, mostly in the Kansas Flint Hills. This area is lower and wetter than the High Plains and is warmer than many other regions. Some areas here receive more than 40 inches of annual precipitation. Grasses here include bluestems, along with many other species. Historically, many areas of the Midwest that are now forested were once tallgrass prairie. Fire is very important in maintaining the prairie. Without it, many areas can become forested.\n\nShort-grass prairies are found in the high plains of Colorado, Kansas, Montana, Nebraska, New Mexico, North Dakota, Oklahoma, South Dakota, Texas, and Wyoming. 70% of the original short-grass prairie remains today, making it one of the least fragmented prairie ecosystems.\n\nGrasslands occur where there is insufficient rain to support trees, thus only grasses and a few shrubs can survive. There are three kinds of grasslands on the great plains, short grass prairie, mixed grass, and long grass prairie. In each of these, grass species serve all the keystone roles. They provide food, shelter, act as larval hosts for numerous species and acted as the primary food for buffalo. These grasses are of vital importance to the ecosystem and protect the soil from the strong winds that whip through the prairie. They are all drought resistant and have strong short roots that hold the soil in place.\n\nIn short grass prairie there are two dominant plants, buffalo grass (\"Bouteloua dactyloides\"), is a strong and hardy grass that is the favorite of grazers. The second is blue grama (\"Bouteloua gracilis\"), which is essential for soil retention. In tallgrass prairie there are four dominant species, big bluestem grass (\"Andropogen gerardii\"), Indian grass (\"Sorghastrum nutans\"), switch grass (\"Panicum virgatum\"), and little bluestem (\"Schizachyrium scoparium\"). Big bluestem grass is 4–8 feet tall and was the favorite food of the buffalo.\n\nA \"keystone species\" is a species that \"has disproportionate importance in their community.\" Keystone species on the great plains include the bison and the prairie dog. Many other species live on the grasslands, including deer, rabbits, mice, and many types of birds.\n\nIn the Great Plains, the prairie dog is a keystone species. Studies comparing species abundances in areas of colonization against areas with no prairie dog colonization show clear evidence that the prairie dog does have a significant impact on its surroundings by altering vegetation and therefore affecting habitat and food availability for other species. There is a great mosaic of vegetative diversity within the Great Plains due to the prairie dog’s extensive grazing on long grasses. This mosaic supports a variety of small mammals. In addition to altering vegetation, the prairie dog also creates habitat for many other organisms by creating extensive tunnel systems that other small mammals such as the desert cottontail, striped skunk and deer mouse use for shelter. A strong characteristic of keystone species is their ability to create and modify other organism’s habitats and it is evident that the prairie dog does this. In conclusion, the prairie dog is an iconic animal species North America. Its close link to the ecology and structure of the Great Plains make it the defining keystone species of the ecoregion.\n\nThere are several types of prairie dogs in the ecoregion, including black-tailed, white-tailed, and Gunnison's, though the black-tailed is the most abundant and widespread.\n\nThe American bison (Bison bison) once roamed the Great Plains grasslands in vast herds. Their total population numbers were once in the tens of millions and spanned most of North America. The bison was, in colloquial terms, the lawnmower of the grasslands, but their dwindling numbers have severely reduced their ecological impact. The bison's large influence as a grazer, a major converter of plant to animal biomass, and a key link in nutrient recycling have been lost. Their grazing habits were pivotal in allowing for the establishment of much of the biodiversity observed today in the region, including the prairie dog. Along with fire, bison were responsible for the removal of excess plant material that accumulated in the grassland. With the accumulation of dead plant material, seed germination is greatly hindered and biodiversity is held stagnant. The purging of excess biomass helped to promote and maintain biodiversity among plant species on the plains. While the American bison once played a keystone role in both the establishment and maintenance of the Great Plain’s current biodiversity, the severely reduced population that still remains has little ecological effect on the Great Plains ecoregion.\n\nThe Indiana bat is an important predator within the Great Plains. The Indiana bat perpetuates biodiversity by consuming moths, mosquitoes, and flies under the night sky. This bat sleeps in abandoned caves and mines during the winter months for hibernation and under tree bark during the warmer seasons. This Indiana bat is endangered mainly due to human disturbance within the caves. However, help is underway to protect this species. Besides showing hospitality to these bats, gates are going up to prohibit visitors from entering the caves and mines during the hibernation months. Studies are also ensuing to try and discover other factors diminishing the Indiana bat’s population.\n\nAnother dwindling species of the Great Plains is the Small White Lady’s Slipper. There are only 100 of these orchids left. Invasive species and land conservationists have equally played a part in demolishing this population; as well as people plucking these flowers. The only working conservation action to salvage the Small White Lady’s Slippers requires controlled fires; eliminating surrounding invasive plants and providing the Small White Lady’s Slippers with enough surface area and nutrients to repopulate. This plant needs to grow next to a fungus in order to survive because of the symbiotic relationship between them.\n"}
{"id": "57685588", "url": "https://en.wikipedia.org/wiki?curid=57685588", "title": "Heart's Content Cable Station", "text": "Heart's Content Cable Station\n\nHeart's Content Cable Station is a former cable landing station located in Heart's Content, Newfoundland and Labrador. It served as the western terminus of the first permanent trans-oceanic submarine telegraph cable, while a sister cable station on Valentia Island, Ireland, served as the eastern terminus. The original cable was first brought ashore in Heart's Content on July 27, 1866, and the station remained in use until it was closed in 1965. The station was designated a Provincial Historic Site in 1974 and is now a museum. On December 20, 2017, it was announced that the Heart's Content Cable Station would be one of eight new sites nominated by the Canadian Government for UNESCO World Heritage Site status.\n\nThe cable was first brought ashore in July 27, 1866, after several failed attempts. The cable was brought to Heart's Content by the \"Great Eastern\", the largest steamship afloat at the time. Cable maintenance ships would regularly visit Heart's Content to repair and perform maintenance on the cables. The first messages were sent across the cable using Morse code, with three people working at the Heart's Content station to send and receive these messages. While the cable station was originally established in Heart's Content by the Anglo-American Telegraph Company, it was later taken over by the Western Union Telegraph Company in 1912. When the Anglo-American Telegraph Company owned the station, they commission the construction of staff housing in Heart's Content. The town saw another construction boom when Western Union purchased the station. At its peak, over 200 people in Heart's Content worked for the cable company, bringing in trained professionals from Canada and England. In the years succeeding World War One, cable traffic began to slow down and automated equipment started being installed at the station. The station was closed in 1965, due to the telegraph cable becoming obsolete with the emergence of trans-oceanic telephone cables and communications satellites.\n\nConstruction of the cable station office started in 1875 and was completed in 1876. The building was designed by J.J. Southcott, a prominent architect based in St. John's. In 1918, an extension was added to the building so that it could handle increased traffic. The original section of the building features a Gothic style bargeboard and is overall typical of the architecture of 19th century industrial buildings found in Newfoundland outports. The 1918 addition is reflective of both changes in technology and changes in society, as it features a second washroom for female staff.\n\nThe cable station has been a Provincial Historic Site of Newfoundland and Labrador since 1974. On December 20, 2017, Environment Minister Catherine McKenna announced that Heart's Content Cable Station was one of eight sites that would be added to Canada's tentative list of UNESCO World Heritage Sites. The justification for inscription was based on criteria (ii) and (iv). However, unlike the other eight newly proposed sites, Heart's Content Cable Station has yet to be listed by UNESCO on Canadian tentative list. The Canadian government is currently working with the government of the Republic of Ireland in order to create a transboundary World Heritage Site consisting of both the station at Heart's Content and the station on Valentia Island.\n"}
{"id": "452104", "url": "https://en.wikipedia.org/wiki?curid=452104", "title": "Hispanic America", "text": "Hispanic America\n\nHispanic America (Spanish: \"Hispanoamérica\", or \"América hispana\"), also known as Spanish America (Spanish: \"América española\"), is the region comprising the Spanish-speaking nations in the Americas.\n\nThese countries have significant commonalities with each other and with Spain, its former . In all of these countries, Spanish is the main language, sometimes sharing official status with one or more indigenous languages (such as Guaraní, Quechua, Aymara, or Mayan), or English (in Puerto Rico). Roman Catholicism is the predominant religion.\n\nHispanic America is sometimes grouped together with Brazil under the term \"Ibero-America\", meaning those countries in the Americas with cultural roots in the Iberian Peninsula. Hispanic America also contrasts with Latin America, which includes not only Hispanic America, but also Brazil, as well as the former French colonies in the Western Hemisphere (areas that are now in either the United States of America or Canada are usually excluded).\n\nThe Spanish conquest of the Americas began in 1492, and ultimately was part of a larger historical process of world discovery, through which various European powers incorporated a considerable amount of territory and peoples in the Americas, Asia, and Africa between the 15th and 20th centuries. Hispanic America became the main part of the vast Spanish Empire.\n\nNapoleon's takeover of Spain in 1808 and the consequent chaos initiated the dismemberment of the Spanish Empire, as the Hispanic American territories began their struggle for emancipation. By 1830, the only remaining Spanish American and Asian territories were the Philippine archipelago and the islands of Cuba and Puerto Rico, until the 1898 Spanish–American War.\n\nSpanish is the official language in most Hispanic American countries, and it is spoken by the vast majority of the population. Native American languages are widely spoken in Peru, Guatemala, Bolivia, Paraguay and Mexico, and to a lesser degree, in Panama, Ecuador, Colombia, Venezuela, Argentina, and Chile amongst other countries. In some Hispanic American countries, the population of speakers of indigenous languages tend to be very small or even non-existent (e.g. Uruguay). Mexico is possibly the only country that contains the largest variety of indigenous languages than any other Hispanic American country, and the most spoken native language is Nahuatl.\n\nIn Peru, Quechua is an official language, alongside Spanish and any other indigenous language in the areas where they predominate. In Ecuador, while holding no official status, the closely related Quichua is a recognized language of the indigenous people under the country's constitution; however, it is only spoken by a few groups in the country's highlands. In Bolivia, Aymara, Quechua and Guaraní hold official status alongside Spanish. Guaraní, along with Spanish, is an official language of Paraguay, and is spoken by a majority of the population (who are, for the most part, bilingual), and it is co-official with Spanish in the Argentine province of Corrientes. In Nicaragua, Spanish is the official language, but on the country's Caribbean coast English and indigenous languages such as Miskito, Sumo, and Rama also hold official status. Colombia recognizes all indigenous languages spoken within its territory as official, though fewer than 1% of its population are native speakers of these languages. Nahuatl is one of the 62 native languages spoken by indigenous people in Mexico, which are officially recognized by the government as \"national languages\" along with Spanish.\n\nOther European languages spoken in Hispanic America include: English, by some groups in Puerto Rico; German, in southern Chile and portions of Argentina, Venezuela, and Paraguay; Italian, in Argentina, Venezuela, and Uruguay; Ukrainian, Polish, and Russian in Argentina; and Welsh, in southern Argentina.\nYiddish and Hebrew can be heard around Buenos Aires. Non-European or Asian languages include Japanese in Peru, Bolivia, and Paraguay; Korean in Argentina and Paraguay; Arabic in Argentina, Colombia, Venezuela, and Chile; and Chinese throughout South America.\n\nIn several nations, especially in the Caribbean region, creole languages are spoken. Creole languages of mainland Latin America, similarly, are derived from European languages and various African tongues.\n\nThe Garifuna language is spoken along the Caribbean coast in Honduras, Guatemala, Nicaragua and Belize mostly by the Garifuna people a mixed race Zambo people who were the result of mixing between Indigenous Caribbeans and escaped Black slaves. Primarily an Arawakan language, it has influences from Caribbean and European languages.\n\nHispanic cuisine as the term is applied in the Western Hemisphere, is a misnomer. What is usually considered Hispanic cuisine in the United States is mostly Mexican and Central American cuisine. Mexican cuisine is composed of mainly indigenous—Aztec and Mayan—and Spanish influences.\n\nMexican cuisine is considered intangible cultural heritage by UNESCO and can be found all over the United States.\n\nIn the United States, with its growing Hispanic population, food staples from Mexican cuisine and the cuisine from other Hispanic countries have become widely available. Over the years, the blending of these cuisines has produced unique American forms such as Tex-Mex cuisine. This cuisine, which originated in Texas, is based on maize products, heavily spiced ground beef, cheese and tomato sauces with chilies. This cuisine is widely available not just in the United States but across other countries, where American exports are found. In Florida, Cuban food is widely available. All of these Hispanic foods in the United States have evolved in character as they have been commercially americanized by large restaurant chains and food companies.\n\nThe cuisine of Spain has many regional varieties, with Mediterranean flavors based on olive oil, garlic, and tomatoes and due to its long Atlantic and Mediterranean coastlines, has been graced with a great variety and availability of seafood. In the inland communities of Spain, there is a long tradition of cured meat of different kinds, in addition to an abundance of dishes such as roasts and stews, based on beef, pork, lamb, and poultry. The European and Arab heritage of Spain is reflected in its food, along with cosmopolitan influences beginning in the many new ingredients brought in from the New World since the 16th century, e.g. tomatoes, potatoes, or chocolate, and the more modern tastes introduced from Europe since the 19th century, especially through French and Italian dishes. It is only in the last ten years that Hispanic American dishes have been introduced in Spain. In the United States and Canada, the number of Hispanic restaurants has become a growing trend, following the \"tapas\"-style restaurants fashion that first appeared in North America in the 1990s.\n\nCuban, Dominican, and Puerto Rican cuisines, on the other hand, tend to use a lot of pork and can depend heavily on starchy root vegetables, plantain, and rice. The most prominent influences on their Spanish culinary traditions were introduced by African slaves, and to a lesser degree, French influence from Haiti and later Chinese immigrants. The use of spicy chile peppers of varying degrees of strength used as flavour enhancers in Mexican tradition is practically unknown in traditional Spanish–Caribbean dishes. The cuisine of Haiti, a country with a Francophone majority, is very similar to its regional neighbors in terms of influences and ingredients used.\n\nThe Argentine diet is heavily influenced by the country's position as one of the world's largest beef and wine producers, and by the impact that European immigration had on its national culture. Grilled meats are a staple of most meals as are pastas, potatoes, rice, paella and a variety of vegetables (Argentina is a huge exporter of agricultural products). Italian influence is also seen in the form of pizza and ice cream, both of which are integral components of national cuisine. Chilean cuisine is similar to that of Argentina, though seafood is much more dominant in this coastal nation. As another one of the world's largest producers, wine is as much a staple drink to Chileans as beer is to Germans.\n\nIn Colombia, Ecuador and Peru, potato dishes are typical since the potato is originally from this region. Beef and chicken are common sources of meat. In the Highlands is the \"cuy\", a South American name for guinea pig, a common meat. Given the coastal location, both countries have extensive fishing fleets, which provide a wealth of seafood options, including the signature South American dish, ceviche. While potato is an important ingredient in the Highlands, Rice is the main side dish on the coast.\n\nThis diversity in staples and cuisine is also evident in the differing regional cuisines within the national borders of the individual countries.\n\nWhile relatively unknown, there is a flag representing the countries of Spanish America, its people, history and shared cultural legacy.\n\nIt was created in October 1933 by Ángel Camblor, captain of the Uruguayan army. It was adopted by all the states of Spanish America during the Pan-American Conference of the same year in Montevideo, Uruguay.\n\nThe white background stands for peace, the Inti sun god of Inca mythology symbolizes the light shining on the Americas, and the three crosses represent Christopher Columbus' caravels, the \"Niña\", \"Pinta\", and \"Santa María\", used in his first voyage from Spain to the New World in 1492. The deep lilac color of the crosses evokes the color of the lion on the coat of arms of the medieval Crown of Castile.\n"}
{"id": "43235565", "url": "https://en.wikipedia.org/wiki?curid=43235565", "title": "List of Crinum species", "text": "List of Crinum species\n\n, the World Checklist of Selected Plant Families lists 105 species of \"Crinum\":\n"}
{"id": "9315563", "url": "https://en.wikipedia.org/wiki?curid=9315563", "title": "List of New England Fifty Finest", "text": "List of New England Fifty Finest\n\nThe New England Fifty Finest is a list of mountains in New England, used in the mountaineering sport of peak bagging. The list comprises the 50 summits with the highest topographic prominence — a peak's height above the lowest contour which encloses that peak and no higher peak. The list includes 20 peaks in Maine, 15 in Vermont, 14 in New Hampshire, and one in Massachusetts.\n\nThis list differs substantially from lists of peaks by elevation, such as the New England 4000 Footers. For instance, only one peak in the Presidential Range is on this list because the others do not have a major prominence, being connected to Mount Washington by ridgelines that are nowhere below . Mount Washington has an elevation above sea level of but has a prominence of about because it stands that high above its key col — the lowest ground on the ridge line connecting Washington to the higher peaks of the southern Appalachian Mountains. Washington's key col is at the Champlain Canal in New York, the lowest ground on the water divide between the watersheds of the Hudson and Saint Lawrence Rivers. \n\nOf the 48 New Hampshire Four-thousand Footers, only eight are also on this list, including Mount Lafayette and Carter Dome, which are the high points of the Franconia Range and the Carter-Moriah Range, respectively. The list includes several monadnocks, including the eponymous Mount Monadnock, and the high points of several small mountain ranges which have high prominence by virtue of their isolation from higher peaks by surrounding low ground.\n\n \n\n"}
{"id": "8326145", "url": "https://en.wikipedia.org/wiki?curid=8326145", "title": "List of Ramsar sites in Russia", "text": "List of Ramsar sites in Russia\n\nRamsar sites are natural locations under the protection of the Ramsar Convention for the conservation and sustainable utilization of wetlands. As of March 2013 there were 35 Ramsar sites in Russia, totalling an area of .\n\nThe first Russian sites registered in the Ramsar Convention, on 11 October 1976 (during the Soviet era), were Kandalaksha Bay Lake Khanka and the Volga River delta.\n\n\n"}
{"id": "13301982", "url": "https://en.wikipedia.org/wiki?curid=13301982", "title": "List of Sonoran Desert wildflowers", "text": "List of Sonoran Desert wildflowers\n\nThe wildflowers of the Sonoran Desert typically appear after a rain, some after the winter rains, and some after the summer \"monsoons.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "13279935", "url": "https://en.wikipedia.org/wiki?curid=13279935", "title": "List of botanical gardens in Japan", "text": "List of botanical gardens in Japan\n\nThis list of botanical gardens in Japan is intended to include all significant botanical gardens and arboretums in Japan.\n\n\n\n"}
{"id": "17233058", "url": "https://en.wikipedia.org/wiki?curid=17233058", "title": "List of environmental reports", "text": "List of environmental reports\n\nThis is a list of notable environmental reports. In this context they relate to the impacts of human activity on the environment.\n\n\n"}
{"id": "539943", "url": "https://en.wikipedia.org/wiki?curid=539943", "title": "List of national parks of Norway", "text": "List of national parks of Norway\n\nNorway has 47 national parks, of which 37 are on the mainland and 7 on Svalbard. National parks in Norway are stricter than many other countries, and nearly all motorized vehicles are prohibited. The freedom to roam applies, thus hiking, skiing and camping throughout the park are permitted, given that consideration to nature is taken. Roads, accommodation and national park centers are located outside the national parks. The parks are under the management of the Norwegian Directorate for Nature Management and the local county governor.\n\nYtre Hvaler is a marine park and all parks in Svalbard also contain marine areas. Sør-Spitsbergen is the largest park, covering an area of , although only is land. The largest park on the mainland is Hardangervidda, which covers an area of . Gutulia is the smallest, covering .\n\nAt least 60% of Norway's area is mountainous, lakes or bogs (non-arable land, some of it is used as pastures); 37% is forest of various kinds; and only 3% arable land. It is estimated that between 1900 and 2003 areas more than 5 km from intense construction activity has decreased from 48% to 12% in Norway.\n\nUntil about one hundred years ago there was relatively little threat to ecosystems in Norway. The first initiatives to protect land were voiced in 1904, by Yngvar Nielsen, leader of the Norwegian Mountain Touring Association (DNT). The association continued to lobby cases in 1923 and 1938. The natural protection act of 1954 prepared a legal basis for establishing protection areas, and the two first national parks were established in 1962 and 1963. The act of 1954 also established \"Statens naturvernråd\" (\"Governmental Natural protection council\") as an advisory body for the government. The council presented a draft for further natural protecting in 1964, suggesting 16 national parks. These suggestions were approved by Stortinget. It took 25 years, until 1989, before 15 of their suggestions were fulfilled. The 16th suggestion became a \"naturreservat\". The council presented another suggestion in 1986, and this was approved by Stortinget in April 1993. Following this approval, a \"second generation\" of national parks, as well as expanding borders for the elder, were established from 2001.\n\nThe post-industrial era that started in the last 1960s saw areas being protected as national parks or other protected status as a means to regulate the construction of vacation homes, roads, fishing, hunting, and gathering plants. This trend has accelerated in the last 10 years. In addition to preserving rare plant and animal life, areas are protected to maintain reference points for environmental research, recreational resources for Norwegians, and as an inheritance for future generations. The Directorate for Nature Management maintains indicators for the health of nature in Norway, including such measures as biological diversity, erosion, signs of pollution.\n\nFor the most part, national parks are open to hiking, cross-country skiing and camping. Most have a limited number of overnight cabins.\n\nIn addition to national parks, the Norwegian government has designated larger areas for protection. Included in these areas are 153 landscapes covering 14071 km; 1,701 nature reserves covering 3,418 km; 24 national parks covering 21,650 km; 102 natural memorials, and 98 smaller protected areas. This accounts for 12.1% of Norway's mainland area.\n\nThe Norwegian government aims to increase this area over time to at least 15%. They have signalled an interest in preserving marine ecosystems, including the fjords of the western parts of Norway, and the archipelago southwest from Oslo.\n\nThere are also several national park proposals: Solværøyene, Storheia; Raet; Jomfruland; Melkevatn–Hjertvatn–Børsvatn, Okstindan; Frafjordheiene; Oksøy-Ryvingen; Setesdal Vesthei, Trollheimen, Lyngsalpan.; Østmarka.\n\n"}
{"id": "19265746", "url": "https://en.wikipedia.org/wiki?curid=19265746", "title": "List of the major 3000-meter summits of California", "text": "List of the major 3000-meter summits of California\n\nThe following sortable table comprises the 46 mountain peaks of the U.S. State of California with at least of topographic elevation and at least of topographic prominence.\n\nTopographic elevation is the vertical distance above the reference geoid, a mathematical model of the Earth's sea level as an equipotential gravitational surface. The topographic prominence of a summit is the elevation difference between that summit and the highest or key col to a higher summit. The topographic isolation of a summit is the minimum great-circle distance to a point of equal elevation.\n\nThis article defines a significant summit as a summit with at least of topographic prominence, and a major summit as a summit with at least of topographic prominence. An ultra-prominent summit is a summit with at least of topographic prominence. There are 126 ultra-prominent summits in the United States.\n\nAll elevations include an adjustment from the National Geodetic Vertical Datum of 1929 (NGVD 29) to the North American Vertical Datum of 1988 (NAVD 88). For further information, please see this United States National Geodetic Survey note.\n\nIf an elevation or prominence is calculated as a range of values, the arithmetic mean is shown.\n\n\n\nCalifornia, List Of The Major 3000-Meter Summits Of\n"}
{"id": "36099054", "url": "https://en.wikipedia.org/wiki?curid=36099054", "title": "Mauritius v. United Kingdom", "text": "Mauritius v. United Kingdom\n\nMauritius v. United Kingdom was an arbitration case concerning the status of the Chagos Archipelago and the attempts of the United Kingdom government to create a Marine Protected Area in British Indian Ocean Territory. The dispute was arbitrated by a arbitral tribunal constituted under Annex VII of the 1982 United Nations Convention on Law of the Sea. The Permanent Court of Arbitration was asked on the 31st of March 2011 to function as registry in the proceedings.\n\nIn 2011 the government of Mauritius challenged Sir Christopher Greenwood's role in the arbitration proceedings on the grounds that his role as a UK Foreign and Commonwealth legal adviser could bias him in favour of the United Kingdom's claims to the Chagos Islands. However, this was rejected by the tribunal on the basis that this \"neither constituted nor continued an already existing relationship.\" \n\nOn the 15 January 2013 the tribunal released procedural order no. 2. In this order the tribunal rejected a British request that the tribunal should deal with British jurisdictional challenges in a preliminary phase.\n\nOn the 18 March 2015, the arbitral tribunal ruled that the Chagos Marine Protected Area was \"not in accordance with the provisions of the Convention\" and declared unanimously that in establishing the MPA surrounding the Chagos Archipelago the United Kingdom had breached its obligations under Articles 2(3), 56(2), and 194(4) of the Convention.\n\n\n"}
{"id": "44884722", "url": "https://en.wikipedia.org/wiki?curid=44884722", "title": "National Geothermal Data System", "text": "National Geothermal Data System\n\nThe National Geothermal Data System (NGDS) is an American distributed data network that collects and provides public access to digital geothermal exploration and development information. Data includes borehole temperature measurements, geothermal gradients, active faults, and geochemical analyses.\n\nNGDS was initially funded by the United States Department of Energy Geothermal Technologies Program (awards DE-EE0001120 and DE-EE002850), as part of the American Recovery and Reinvestment Act of 2009.\n\nThe National Geothermal Data System makes use of the large collection of hard copy documents stored in state geological survey archives. These documents include maps, field notes and well logs relevant to geothermal exploration and development. Some of the information was originally gathered for use by the oil industry. NGDS facilitates the digitization of this data, and ensures that data from various sources is stored in a compatible format to facilitate standardized search terms and geospatial analyses. Participating agencies maintain ownership and control of data they contribute.\n\nOnce digitized, the NGDS provides free public access to the data by means of a distributed network of online databases, and also provide the public with free and open-source software with which to search and view the data.\n\nNGDS primary contributors include the United States Geological Survey, Southern Methodist University, and the Association of American State Geologists.\n\nMost agencies that contribute data to NGDS host their data on their own servers; some smaller agencies submit their data to contract-designated \"hubs\", while still owning their data. NGDS hub states include Arizona, Illinois, Kentucky, and Nevada.\n\nParticipating agencies also submit metadata records to a central web-accessible catalog, describing the data that has been contributed to NGDS. Both NGDS data and the NGDS catalog can be accessed by common web browsers and web applications. NGDS data can also be accessed by geographic information system software applications including ArcGIS, UDig, QGIS, and GvSIG.\n\n"}
{"id": "35372106", "url": "https://en.wikipedia.org/wiki?curid=35372106", "title": "Natural History Society of Northumbria", "text": "Natural History Society of Northumbria\n\nThe Natural History Society of Northumbria is a voluntary organization to promote the study of natural history and protect the wildlife of the North East of England.\n\nIts offices and library are in the Great North Museum: Hancock, whose building, land and collections it owns. It leases them to Newcastle University, on whose behalf they are administered by Tyne & Wear Archives & Museums. It possesses a substantial natural history library and archive, and maintains the Gosforth Park Nature Reserve. It also carries out research and provides lectures, field outings and educational courses, as well as publishing scientific papers. It has over 950 members.\n\nThe key events in the history of the NHSN are as follows.\n\n\nJohn Hancock (1808–1890) was an ornithologist, producing his Catalogue of the Birds of Northumberland and Durham in 1874. His greatest talent, however, was as a taxidermist, and his collection of mounted British birds can still be seen today in the Bird Gallery of the Great North Museum: Hancock.\n\nAlbany Hancock (1806–1873), brother of John Hancock, specialised in the anatomy of sea creatures, especially sea slugs or nudibranchs, and depicted them in minute detail. His watercolour drawings are held in the Society's archives.\n\nJoshua Alder (1792–1867) was a zoologist, specialising in tunicates and gastropods.\n\nWilliam Chapman Hewitson (1806–1878) was a wealthy collector, particularly of beetles, lepidopterans, bird's nests and eggs. He built up an extensive collection of butterflies of the world, and was an accomplished illustrator.\n\n"}
{"id": "51593574", "url": "https://en.wikipedia.org/wiki?curid=51593574", "title": "Natural gas in Israel", "text": "Natural gas in Israel\n\nNatural gas in Israel is a primary energy source in Israel, mainly utilized for electricity production and to lesser degree in the industry. Israel began producing natural gas from its own offshore gas fields in 2004. Between 2005 to 2012, Israel had imported gas from Egypt via the al-Arish-Ashkelon pipeline, which was terminated due to Egyptian Crisis of 2011-14. As of 2014, Israel produced over 7.5 billion cubic meters (bcm) of natural gas a year. Israel had 199 billion cubic meters (cu m) of proven reserves of natural gas as of the start of 2016. In early 2017, Israel began exporting natural gas to the Kingdom of Jordan.\n\nHistorically, Israel relied on external imports for meeting most of its energy needs, spending an amount equivalent to over 5% of its GDP per year in 2009 on imports of energy products. The transportation sector relies mainly on gasoline and diesel fuel, while the majority of electricity production is generated using imported coal. As of 2013, Israel was importing about 100 mln barrels of oil per year. The country possesses negligible reserves of crude oil but does have abundant domestic natural gas resources which were discovered in large quantities starting in 2009, after many decades of previously unsuccessful exploration.\n\nUntil the early 2000s, natural gas use in Israel was minimal. In the late 1990s, the government of Israel decided to encourage the usage of natural gas because of environmental, cost, and resource diversification reasons. At the time however, there were no domestic sources of natural gas and the expectation was that gas would be supplied from overseas in the form of LNG and by a future pipeline from Egypt (which eventually became the Arish–Ashkelon pipeline). Plans were made for the Israel Electric Corporation to construct several gas-driven power plants, for erecting a national gas distribution grid, and for an LNG import terminal. Soon thereafter, gas began to be located within Israeli territory, first in modest amounts and a decade later in very large quantities located in deep water off the Israeli coastline. This has greatly intensified the utilization of natural gas within the Israeli economy, especially in the electrical generation and industrial sectors, with consumption growing from an annual average of between 2000 and 2002 to in 2010.\n\nIn 2000, a modest discovery was made when a 33-billion-cubic-metre (BCM), or 1,200-billion-cubic-foot, natural-gas field was located offshore Ashkelon, with commercial production starting in 2004. however, this field is nearly depleted—earlier than expected due to increased pumping to partially compensate for the loss of imported Egyptian gas in the wake of unrest associated with the fall of the Mubarak regime in 2011. In 2009, a significant gas find named Tamar, with proven reserves of 223 BCM or (307 BCM total proven + probable) was located in deep water approximately west of Haifa, as well as a smaller 15 BCM () field situated nearer the coastline. Furthermore, results of 3D seismic surveys and test drilling conducted since 2010 have confirmed that an estimated 621 BCM () natural-gas deposit exists in a large underwater geological formation nearby the large gas field already discovered in 2009. An article in \"The Economist\" stated that Israel had \"verified\" gas finds of 35 trillion cubic feet as of early 2014. The US Energy Information Administration listed Israel as having 7.0 trillion cubic feet of proved reserves as of 1 January 2015.\n\nThe Tamar field began commercial production on 30 March 2013 after four years of extensive development works. The supply of gas from Tamar is expected to provide a boost to the Israeli economy, which has suffered losses of more than NIS20 billion between 2011 and 2013 resulting from the disruption of gas supplies from neighboring Egypt (and which are not expected to resume due to Egypt's decision to indefinitely suspend its gas supply agreement to Israel). As a result, Israel, as well as its other neighbor Jordan, which also suffered from disruption of gas deliveries from Egypt, had to resort to importing significantly more expensive and polluting liquid heavy fuels as substitute sources of energy. The ensuing energy crisis in Israel was lifted once the Tamar field came online in 2013, while Jordan committed to a US$10 billion, 15-year gas supply deal totaling 45 BCM from the Israeli Leviathan field which is scheduled to come online in late 2019. The agreement is estimated to save Jordan US$600 million per year in energy costs. In 2018, the owners of the Tamar and Leviathan fields announced that they are negotiating an agreement with a consortium of Egyptian firms, subject to regulatory approval in both countries, for the supply of up to 64 BCM of gas over 10 years valued at up to US$15 billion. Although Egypt has been making strides in developing new gas fields in recent years to help it meet rising domestic demand, it also has idle LNG exporting capacity and the deal has the potential to help make it an important regional gas export hub. \n\nThe large gas discoveries so far have confirmed that the Levant basin of the Eastern Mediterranean contains significant quantities of natural gas and, potentially, crude oil. Consequently, additional exploration for oil and gas off Israel's coastline is continuing. A source close to Prime Minister Benjamin Netanyahu has valued Israel's natural gas reserves at $130 billion, while in 2012 \"BusinessWeek\" estimated the reserves' value at $240 billion. The businesses involved in exploration aim to export a share of future production, but others argue that it would be preferable, on geopolitical grounds, to use the gas within the country instead of other energy sources. In early 2012 the Israeli cabinet announced plans to set up a sovereign wealth fund (called \"the Israeli Citizens' Fund\") that would allocate part of the royalties from energy exploration to education, defense and overseas investments.\n\nList of Natural gas-fired power stations in Israel:\n\n"}
{"id": "31201406", "url": "https://en.wikipedia.org/wiki?curid=31201406", "title": "Nuclear energy in Yemen", "text": "Nuclear energy in Yemen\n\nYemen has called for establishing The Arab Atomic Energy Agency for nuclear researches and using them for peaceful means, especially generating electricity.\n"}
{"id": "2371292", "url": "https://en.wikipedia.org/wiki?curid=2371292", "title": "Oil and gas industry metering and control system", "text": "Oil and gas industry metering and control system\n\nRemote gas well sites require local flow metering of the mineral reserve's gas flow rate for asset and revenue accounting purposes. Differential pressure flow meters are commonly used for this purpose.\n\nTraditionally, local flow metering was done using high maintenance mechanical circular chart recorders. Today these have been replaced with electrically powered remote terminal units (RTU). Multiple remote terminal units communicate to a central host system via radio systems or tap into the cellular phone system. The host (or central control room) communicates with the RTUs and radio communication infrastructure is referred to as a Supervisory Control and Data Acquisition (SCADA) system. In addition to gas flow metering, the RTU also provides some local, self-contained, site control such as well shut-in in the event of abnormal gas flow conditions. However the bulk of the RTU's function is to provide the host with site specific data which includes the above-mentioned gas flow metering data, plus process related data including pipeline and/or well pressure, condensate tank levels etc.\n\nThe distinguishing feature of the remote gas well RTU is a \"gas flow computer\". This is essentially a sophiscated subprogram or flow computer algorithm. The oil well RTU is much less complex since liquid oil flow metering is simpler. In the case of electrical utility RTU, there is a critical need for precise event time monitoring so that the first breaker to trip (closest to the fault) can be determined.\nAs these sites are remote such that utility electrical power is rarely available, the RTUs must be powered by an array of solar panels plus batteries. The batteries enable the RTU to continue to function when the sun is below the horizon or is obscured by heavy cloud cover. These RTUs also must be extremely rugged and energy efficient, i.e., must function to −35 °C. Energy efficient RTUs vastly reduce the cost of the solar battery system especially at higher latitudes.\n"}
{"id": "19099956", "url": "https://en.wikipedia.org/wiki?curid=19099956", "title": "Oil reserves in Iraq", "text": "Oil reserves in Iraq\n\nOil reserves in Iraq are considered the world’s second -largest proven oil reserves, with 140 billion barrels. The sources for this oil is primarily located in the Shiite Muslims-majority and Arab Sunni Muslims-dominated areas on the other hand are comparatively lacking.\n\nAs a result of military occupation and civil unrest, the official statistics have not been revised since 2001 and are largely based on 2-D seismic data from three decades ago. International geologists and consultants have estimated that unexplored territory may contain vastly larger reserves. The majority of Iraq's proven reserves of oil comes from the following cities: Basra (Being #1), Baghdad (Being #2), Ramadi (Being #3), and finally, Ba'aj (Being the last oil rich city).\n\nA measure of the uncertainty about Iraq's oil reserves is indicated by widely differing estimates. The U.S. Department of Energy (DOE) estimated in 2003 that Iraq had . The United States Geological Survey (USGS) in 1995 estimated proven reserves were . Iraq's prewar deputy oil minister said that potential reserves might be . The source of the uncertainty is that due to decades of war and unrest, many of Iraq's oil wells are run down and unkept. Repairs to the wells and oil facilities should make far more oil available economically from the same deposits. Iraq may prove to contain the largest extractable deposits of oil in the entire Middle East once these upgrading and facility improvements have advanced.\nAfter more than a decade of sanctions and two Gulf Wars, Iraq’s oil infrastructure needs modernization and investment. Despite a large reconstruction effort, the Iraqi oil industry has not been able to meet hydrocarbon production and export targets. The World Bank estimates that an additional $1 billion per year would need to be invested just to maintain current production. Long-term Iraq reconstruction costs could reach $100 billion or higher, of which more than a third will go to the oil, gas and electricity sectors. Another challenge to Iraq's development of the oil sector is that resources are not evenly divided across sectarian lines. Most known resources are in the Shiite areas of the south and the Kurdish north, with few resources in control of the Sunni population in the center.\n\nIn 2006, Iraq's oil production averaged , down from around of production prior to the coalition invasion in 2003. Iraq's reserve to production ratio is 158 years. After the end of the invasion the production increased on a high level, even though there is an invasion from the so-called \"ISIL\" the production in March 2016 stood at 4.55 million barrels a day. Which seems to well become a new all-time peak year for Iraq if OPEC talks about freezing or reduce production held in April 2016 will not lead to a reduction. The old peak was 1979 with 171.6 million tons of oil compared to 136.9 million tons produced in 2011 and 152.4 million tons in 2012.\n\nOn June 30 and December 11, 2009, the Iraqi Ministry of Oil awarded contracts to international oil companies for some of Iraq's many oil fields. The winning oil companies entered joint ventures with the Iraqi Ministry of Oil, and the terms of the awarded contracts include extraction of oil for a fixed gain of $1.40 per barrel for the oil companies with the remainder going to Iraq. The fees will only be paid once a production threshold set by the Iraqi ministry of oil is reached.\n\nOil fields contracted include the \"super-giant\" Majnoon Field, Halfaya Field, West Qurna Field and Rumaila Field. The East Baghdad Field, situated in part under Sadr City, did not receive any bids and the Iraqi oil ministry is considering working the field itself. Oil minister Hussein al-Shahristani told Iraqi public television that the increasing oil production \"would finance infrastructure projects across Iraq - schools, roads, airports, housing, hospitals\".\n\n\n"}
{"id": "35886797", "url": "https://en.wikipedia.org/wiki?curid=35886797", "title": "Omega Cygni", "text": "Omega Cygni\n\nThe Bayer designation Omega Cygni (ω Cyg / ω Cygni) is shared by two star systems, in the constellation Cygnus:\n"}
{"id": "38791409", "url": "https://en.wikipedia.org/wiki?curid=38791409", "title": "Qiongzhusian age", "text": "Qiongzhusian age\n\nThe Qiongzhusian age is a regional subdivision (in China) of Cambrian Series 2 Stage 3; it is correlated with late Atdabanian rocks elsewhere and overlain by the Canglangpuian age.\n\n \n"}
{"id": "357170", "url": "https://en.wikipedia.org/wiki?curid=357170", "title": "Ralph Appelbaum Associates", "text": "Ralph Appelbaum Associates\n\nRalph Appelbaum Associates (RAA) is one of the world's largest museum exhibition design firms. It has offices in New York City, London, Beijing, Berlin, Moscow, and Dubai.\n\nThe firm was founded in 1978 by Ralph Appelbaum (born 1942), a graduate of Pratt Institute and former Peace Corps volunteer (in Peru). Appelbaum currently directs RAA's undertakings, and retains daily involvement in selected commissions.\n\nThe \"New York Times\" reported in 1999 that the firm was composed of \"architects, designers, editors, model builders, historians, childhood specialists, one poet, one painter and one astrophysicist.\"\n\nThe company's best-known project is the United States Holocaust Memorial Museum in Washington, D.C., which is the United States' official memorial to the Holocaust. Established in 1993, the museum has been described as a \"turning point in museology\". \n\nAccording to its website, RAA has completed \"700 commissions in over 40 countries\".\n\n\n\n\n\n\n\n\n"}
{"id": "4029669", "url": "https://en.wikipedia.org/wiki?curid=4029669", "title": "Sierra de los Tuxtlas", "text": "Sierra de los Tuxtlas\n\nThe Sierra de Los Tuxtlas (Tuxtlas Mountains) are a volcanic belt and mountain range along the southeastern Veracruz Gulf coast in Eastern Mexico. The Los Tuxtlas Biosphere Reserve (Biósfera Los Tuxtlas) includes the coastal and higher elevations of the Sierra de Los Tuxtlas.\n\nThe volcanic mountains were used as a basalt source by the Olmec culture during the Early Formative period (1500 BCE to about 400 BCE). Quarried basalt was transported by raft through a network of rivers, to sites in the Olmec heartland for use in creating monuments, including colossal heads.\n\nPeaks in this range include Volcano Santa Marta and Volcano San Martín Tuxtla, both rising above 1,700 meters. San Martín Tuxtla is the only recently active volcano in the belt, erupting in 1664 and again in May 1793. It is a broad alkaline shield volcano with a one kilometer wide summit. Hundreds of smaller cinder cones are prevalent throughout the Sierra.\n\nOther, extinct volcanoes include San Martin Pajapan (1,160 meters) and Cerro El Vigia (800 meters).\n\nThe Sierra de Los Tuxtlas volcanoes are an insular anomaly. The volcanoes are separated from the nearest volcano in the Trans-Mexican Volcanic Belt to the west by about 150 miles (250 km), and from the Central American Volcanic Belt to the southeast by almost 200 miles (330 km).\n\nThe upper flanks of the San Martin Tuxtla and Santa Marta volcanoes are covered with the neotropical Sierra de los Tuxtlas tropical rainforest ecoregion, of the tropical and subtropical moist broadleaf forests biome. The lower portions are covered with stunted pastures and grasslands.\n\nVolcan San Martin rainfrog, \"Craugastor vulcani\", is an endangered frog endemic to rain and cloud forests of Sierra de los Tuxtlas. The area is also home to an endemic species of giant scarab beetle, \"Dynastes moroni\", described in 2005.\n\n\n\n"}
{"id": "13044800", "url": "https://en.wikipedia.org/wiki?curid=13044800", "title": "Sliver (textiles)", "text": "Sliver (textiles)\n\nA sliver (rhymes with diver) is a long bundle of fiber that is generally used to spin yarn. A sliver is created by carding or combing the fibre, which is then drawn into long strips where the fibre is parallel. When sliver is drawn further and given a slight twist, it becomes roving. \n\n"}
{"id": "40024054", "url": "https://en.wikipedia.org/wiki?curid=40024054", "title": "Submarine pipeline", "text": "Submarine pipeline\n\nA submarine pipeline (also known as marine, subsea or offshore pipeline) is a pipeline that is laid on the seabed or below it inside a trench. In some cases, the pipeline is mostly on-land but in places it crosses water expanses, such as small seas, straits and rivers. Submarine pipelines are used primarily to carry oil or gas, but transportation of water is also important. A distinction is sometimes made between a \"flowline\" and a pipeline. The former is an \"intrafield\" pipeline, in the sense that it is used to connect subsea wellheads, manifolds and the platform \"within\" a particular development field. The latter, sometimes referred to as an \"export pipeline\", is used to bring the resource to shore. Sizeable pipeline construction projects need to take into account a large number of factors, such as the offshore ecology, geohazards and environmental loading – they are often undertaken by multidisciplinary, international teams.\nOne of the earliest and most critical tasks in a submarine pipeline planning exercise is the route selection. This selection has to consider a variety of issues, some of a political nature, but most others dealing with geohazards, physical factors along the prospective route, and other uses of the seabed in the area considered. This task begins with a fact-finding exercise, which is a standard desk study that includes a survey of geological maps, bathymetry, fishing charts, aerial and satellite photography, as well as information from navigation authorities.\n\nThe primary physical factor to be considered in submarine pipeline construction is the state of the seabed – whether it is smooth (\"i.e.\", relatively flat) or uneven (corrugated, with high points and low points). If it is uneven, the pipeline will include free spans when it connects two high points, leaving the section in between unsupported. If an unsupported section is too long, the bending stress exerted onto it (due to its weight) may be excessive. Vibration from current-induced vortexes may also become an issue. Corrective measures for unsupported pipeline spans include seabed leveling and post-installation support, such as berm or sand infilling below the pipeline. The strength of the seabed is another significant parameter. If the soil is not strong enough, the pipeline may sink into it to an extent where inspection, maintenance procedures and prospective tie-ins become difficult to carry out. At the other extreme, a rocky seabed is expensive to trench and, at high points, abrasion and damage of the pipeline's external coating may occur. Ideally, the soil should be such as to allow the pipe to settle into it to some extent, thereby providing it with some lateral stability.\n\nOther physical factors to be taken into account prior to building a pipeline include the following:\n\nProper planning of a pipeline route has to factor in a wide range of human activities that make use of the seabed along the proposed route, or that are likely to do so in the future. They include the following:\n\nSubmarine pipelines generally vary in diameter from for gas lines, to for high capacity lines. Wall thicknesses typically range from to . The pipe can be designed for fluids at high temperature and pressure. The walls are made from high-yield strength steel, 350-500 MPa (50,000-70,000 psi), weldability being one of the main selection criteria. The structure is often shielded against external corrosion by coatings such as bitumastic or epoxy, supplemented by cathodic protection with sacrificial anodes. Concrete or fiberglass wrapping provides further protection against abrasion. The addition of a concrete coating is also useful to compensate for the pipeline's negative buoyancy when it carries lower density substances.\n\nThe pipeline's inside wall is not coated for petroleum service. But when it carries seawater or corrosive substances, it can be coated with epoxy, polyurethane or polyethylene; it can also be cement-lined. In the petroleum industry, where leaks are unacceptable and the pipelines are subject to internal pressures typically in the order of 10 MPa (1500 psi), the segments are joined by full penetration welds. Mechanical joints are also used. A pig is a standard device in pipeline transport, be it on-land or offshore. It is used to test for hydrostatic pressure, to check for dents and crimps on the sidewalls inside the pipe, and to conduct periodic cleaning and minor repairs.\n\nPipeline construction involves two procedures: assembling a large number of pipe segments into a full line, and installing that line along the desired route. Several systems can be used – for a submarine pipeline, the choice in favor of any one of them is based on the following factors: physical and environmental conditions (\"e.g.\" currents, wave regime), availability of equipment and costs, water depth, pipeline length and diameter, constraints tied to the presence of other lines and structures along the route. These systems are generally divided into four broad categories: \"pull/tow\", \"S-lay\", \"J-lay\" and \"reel-lay\".\n\nIn the pull/tow system, the submarine pipeline is assembled onshore and then towed to location. Assembly is done either parallel or perpendicular to the shoreline – in the former case, the full line can be built prior to tow out and installation. A significant advantage with the pull/tow system is that pre-testing and inspection of the line are done onshore, not at sea. It allows to handle lines of any size and complexity. As for the towing procedures, a number of configurations can be used, which may be categorized as follows: surface tow, near-surface tow, mid-depth tow and off-bottom tow.\n\nIn the S-lay system, the pipeline assembly is done at the installation site, on board a vessel that has all the equipment required for joining the pipe segments: pipe handling conveyors, welding stations, X-ray equipment, joint-coating module, etc. The \"S\" notation refers to the shape of the pipeline as it is laid onto the seabed. The pipeline leaves the vessel at the stern or bow from a supporting structure called a \"stinger\" that guides the pipe's downward motion and controls the convex-upward curve (the \"overbend\"). As it continues toward the seabed, the pipe has a convex-downward curve (the \"sagbend\") before coming into contact with the seabed (\"touch down point\"). The sagbend is controlled by a tension applied from the vessel (via \"tensioners\") in response to the pipeline's submerged weight. The pipeline configuration is monitored so that it will not get damaged by excessive bending. This on-site pipeline assembly approach, referred to as \"lay-barge\" construction, is known for its versatility and self-contained nature – despite the high costs associated with this vessel's deployment, it is efficient and requires relatively little external support. But it may have to contend with severe sea states – these adversely affect operations such as pipe transfer from supply boats, anchor-handling and pipe welding. Recent developments in lay-barge design include dynamic positioning and the J-lay system.\n\nIn areas where the water is very deep, the S-lay system may not be appropriate because the pipeline leaves the stinger to go almost straight down. To avoid sharp bending at the end of it and to mitigate excessive sag bending, the tension in the pipeline would have to be high. Doing so would interfere with the vessel's positioning, and the tensioner could damage the pipeline. A particularly long stinger could be used, but this is also objectionable since that structure would be adversely affected by winds and currents. The J-lay system, one of the latest generations of lay-barge, is better suited for deep water environments. In this system, the pipeline leaves the vessel on a nearly vertical ramp (or tower). There is no overbend – only a sagbend of catenary nature (hence the \"J\" notation), such that the tension can be reduced. The pipeline is also less exposed to wave action as it enters the water. However, unlike for the S-lay system, where pipe welding can be done simultaneously at several locations along the vessel deck's length, the J-lay system can only accommodate one welding station. Advanced methods of automatic welding are used to compensate for this drawback.\n\nIn the reel-lay system, the pipeline is assembled \"onshore\" and is spooled onto a large drum typically about x in size, mounted on board a purpose-built vessel. The vessel then goes out to location to lay the pipeline. Onshore facilities to assemble the pipeline have inherent advantages: they are not affected by the weather or the sea state and are less expensive than seaborne operations. Pipeline supply can be coordinated: while one line is being laid at sea, another one can be spooled onshore. A single reel can have enough capacity for a full length flow line. The reel-lay system, however, can only handle lower diameter pipelines – up to about 400 mm (16 in). Also, the kind of steel making up the pipes must be able to undergo the required amount of plastic deformation as it is bent to proper curvature (by a spiral J-tube) when reeled around the drum, and straightened back (by a straightener) during the layout operations at the installation site.\n\nSeveral methods are used to stabilise and protect submarine pipelines and their components. These may be used alone or in combinations.\n\nA submarine pipeline may be laid inside a trench as a means of safeguarding it against fishing gear (\"e.g.\" anchors) and trawling activity. This may also be required in shore approaches to protect the pipeline against currents and wave action (as it crosses the surf zone). Trenching can be done prior to pipeline lay (\"pre-lay trenching\"), or afterward by seabed removal from below the pipeline (\"post-lay trenching\"). In the latter case, the trenching device rides on top of, or straddles, the pipeline. \nSeveral systems are used to dig trenches in the seabed for submarine pipelines:\n″A buried pipe is far better protected than a pipe in an open trench.″ This is commonly done either by covering the structure with rocks quarried from a nearby shoreline. Alternatively, the soil excavated from the seabed during trenching can be used as backfill. A significant drawback to burial is the difficulty in locating a leak should it arise, and for the ensuing repairing operations.\n\nMattresses may be laid over the pipeline, or both under and over it depending on the substrate.\n\nClamps holding the pipeline to piles may be used to prevent lateral movement.\n\nPrecast concrete saddle blocks may be used to provide lateral support and hold the pipeline down more firmly.\n\nThese may be packed at the sides or under a pipeline to provide vertical and/or lateral support.\n\nGravel may be dumped over parts of a pipeline to reduce scour and help stabilise against lateral movement.\n\nThe Espoo Convention created certain requirements for notification and consultation where a project is likely to have transboundary environmental effects. Scholars are divided on how effective Espoo is at mitigating environmental harm. Law of the Sea concepts involved in the construction of transboundary pipelines concern territorial waters, continental shelves, exclusive economic zones, freedom of the high seas and protection of the environment. Under international law the high seas are open to all states to law underwater pipelines and for various other types of construction.\n\nUnderwater pipelines pose environmental risk because pipelines themselves may become damaged by ship's anchors, corrosion, tectonic activity, or as a result of defective construction and materials. Stanislav Patin has said that study on the effects of natural gas on underwater ecosystems, fish and other marine organisms has been limited. Researchers found a cause-effect relationship between mass fish mortality and natural gas leaks after drilling accidents in the Sea of Azov in 1982 and 1985.\n\nConcerns about the environmental risks of underwater pipelines have been raised on numerous occasions. There have been at least two serious incidents involving oil pipelines on the UK's continental shelf. There have also been several \"minor spills and gas leaks\" involving other North Sea pipelines. In 1980 a pipeline was damaged by a ship's anchor and in 1986 a pipeline valve failed due to pressure changed. Both incidents resulted in oil spills. Several Baltic countries expressed concerns about the Nord Stream pipeline. The route of the 1,200 km underwater pipeline would travel through fishing areas of the Baltic Sea, as well as area where chemical weapons from World War II had been discarded.\n\n"}
{"id": "41600205", "url": "https://en.wikipedia.org/wiki?curid=41600205", "title": "Table of stars with Flamsteed designations", "text": "Table of stars with Flamsteed designations\n\nThis table lists those stars/objects which have Flamsteed designations by the constellation in which those stars/objects lie. The name given is that of the article if it does not reflect the Flamsteed designation. If the star has a Greek-letter Bayer designation this is used in preference except where such designation contains an extra attached number; for example, \"Rho-1 Cancri\" is less common than \"55 Cancri\".\n\n"}
{"id": "1446490", "url": "https://en.wikipedia.org/wiki?curid=1446490", "title": "Temperature gradient", "text": "Temperature gradient\n\nA temperature gradient is a physical quantity that describes in which direction and at what rate the temperature changes the most rapidly around a particular location. The temperature gradient is a dimensional quantity expressed in units of degrees (on a particular temperature scale) per unit length. The SI unit is kelvin per meter (K/m). It can be found in the formula for dQ/dt, the rate of heat transfer per second.\n\nTemperature gradients in the atmosphere are important in the atmospheric sciences (meteorology, climatology and related fields).\n\nAssuming that the temperature \"T\" is an intensive quantity, i.e., a single-valued, continuous and differentiable function of three-dimensional space (often called a scalar field), i.e., that\n\nwhere \"x\", \"y\" and \"z\" are the coordinates of the location of interest, then the temperature gradient is the vector quantity defined as\n\nOn a global and annual basis, the dynamics of the atmosphere (and the oceans) can be understood as attempting to reduce the large difference of temperature between the poles and the equator by redistributing warm and cold air and water, known as Earth's heat engine.\n\nDifferences in air temperature between different locations are critical in weather forecasting and climate. The absorption of solar light at or near the planetary surface increases the temperature gradient and may result in convection (a major process of cloud formation, often associated with precipitation). \nMeteorological fronts are regions where the horizontal temperature gradient may reach relatively high values, as these are boundaries between air masses with rather distinct properties.\n\nClearly, the temperature gradient may change substantially in time, as a result of diurnal or seasonal heating and cooling for instance. This most likely happens during an inversion. For instance, during the day the temperature at ground level may be cold while it's warmer up in the atmosphere. As the day shifts over to night the temperature might drop rapidly while at other places on the land stay warmer or cooler at the same elevation. This happens on the West Coast of the United States sometimes due to geography.\n\nExpansion and contraction of rock, caused by temperature changes during a wildfire, through thermal stress weathering, may result in thermal shock and subsequent structure failure.\n\n\n\n"}
{"id": "3104154", "url": "https://en.wikipedia.org/wiki?curid=3104154", "title": "Tournaisian", "text": "Tournaisian\n\nThe Tournaisian is in the ICS geologic timescale the lowest stage or oldest age of the Mississippian, the oldest subsystem of the Carboniferous. The Tournaisian age lasted from Ma to Ma. It is preceded by the Famennian (the uppermost stage of the Devonian) and is followed by the Viséan.\n\nThe Tournaisian was named after the Belgian city of Tournai. It was introduced in scientific literature by Belgian geologist André Hubert Dumont in 1832. Like many Devonian and lower Carboniferous stages, the Tournaisian is a unit from West European regional stratigraphy that is now used in the official international time scale.\n\nThe Tournaisian correlates with the regional North American Kinderhookian and lower Osagean stages and the Chinese Tangbagouan regional stage. In British stratigraphy, the Tournaisian contains three substages: the Hastarian, Ivorian and lower part of the Chadian (the upper part falls in the Viséan).\n\nThe base of the Tournaisian (which is also the base of the Carboniferous system) is at the first appearance of the conodont \"Siphonodella sulcata\" within the evolutionary lineage from \"Siphonodella praesulcata\" to \"Siphonodella sulcata\". The first appearance of ammonite species \"Gattendorfia subinvoluta\" is just above this and was used as a base for the Carboniferous in the past. The GSSP for the Tournaisian is near the summit of La Serre hill, in the commune of Cabrières, in the Montagne Noire (southern France). The GSSP is in a section on the southern side of the hill, in an 80 cm deep trench, about 125 m south of the summit, 2.5 km southwest of the village of Cabrières and 2.5 km north of the hamlet of Fontès.\n\nThe top of the Tournaisian (the base of the Viséan) is at the first appearance of the fusulinid species \"Eoparastaffella simplex\" (morphotype 1/morphotype 2).\n\nThe Tournaisian contains eight conodont biozones:\n\nThe Tournaisian coincides with Romer's gap, a period of remarkable little terrestrial fossils, thus constituting a discontinuity between the Devonian and the more modern terrestrial ecosystems of the Carboniferous.\n\n\n"}
{"id": "1957708", "url": "https://en.wikipedia.org/wiki?curid=1957708", "title": "Vahana", "text": "Vahana\n\nVahana (, , literally \"that which carries, that which pulls\") denotes the being, typically an animal or mythical entity, a particular Hindu deity is said to use as a vehicle. In this capacity, the vahana is often called the deity's \"mount\". Upon the partnership between the deity and his vahana is woven much iconography and mythology. Deities are often depicted riding (or simply mounted upon) the vahana. Other times, the vahana is depicted at the deity's side or symbolically represented as a divine attribute. The vahana may be considered an accoutrement of the deity: though the vahana may act independently, they are still functionally emblematic or even syntagmatic of their \"rider\". The deity may be seen sitting or standing on the vahana. They may be sitting on a small platform called a \"howdah\", or riding on a saddle or bareback. \"Vah\" in Sanskrit means \"to carry\" or \"to transport\".\n\nIn Hindu iconography, positive aspects of the vehicle are often emblematic of the deity that it carries. Nandi the bull, vehicle of Shiva, represents strength and virility. Dinka the mouse, vehicle of Ganesha, represents speed and sharpness. Parvani the peacock, vehicle of Skanda, represents splendor and majesty. The hamsa, vehicle of Saraswati, represents wisdom, grace and beauty.\n\nHowever, the vehicle animal also symbolizes the evil forces over which the deity dominates. Mounted on Parvani, Skanda reins in the peacock's vanity. Seated on Dinka the rat (Mushika), Ganesh crushes useless thoughts, which multiply like rats in the dark. Shani, protector of property, has a vulture, raven or crow in which he represses thieving tendencies. Under Shani's influence, the vahana can make even malevolent events bring hope.\n\nThe vehicle of a deity can vary according to the source, the time, and the place. In popular tradition, the origin of each vehicle is told in thousands of different ways. Three examples:\n\nThe vahana and deity to which they support are in a reciprocal relationship. Vahana serve and are served in turn by those who engage them. Many vahana may also have divine powers or a divine history of their own. Case in point, the aforementioned Nataraja story, represents a of Hindu gods with local gods, syncretizing their mythos as their territories began to overlap. According to one source, \"they could be a synthesis between Vedic deities and autochthonous Dravidian totemic deities.\n\nThe animal correspondences of Hindu vehicles are not consistent with Greek and Roman mythology, or other belief systems which may tie a particular animal to a particular deity. For example, the goddess Lakshmi of the Hindus has elephants, or an owl, or (a rare instance of a non-animal vehicle) the lotus blossom as her vehicle. The goddess Athena of ancient Greece also had an owl as her emblematic familiar, but the meanings invested in the owls by the two different belief systems are not the same, nor are the two goddesses themselves similar, despite their mutual identification with owls.\n\nLakshmi is, among other things, primarily the goddess of wealth, and her owl is a warning against distrust and isolationism, even selfishness. Athena, though also a goddess of prosperity, is primarily the goddess of wisdom, and her owl symbolizes secret knowledge and scholarship. Perhaps due to their shared geography, the Greco-Roman interpretation is paralleled in Roman Catholic iconography, in which St. Jerome, most famed for editing the New Testament, is often (though not always) depicted with an owl as a symbol of wisdom and scholarship. Depending on the tribe, Native American religious iconography attributes a wide range of attributes to the owl, both positive and negative, as do the Ainu and Russian cultures, but none parallel the Hindu attributes assigned to the owl as Lakshmi's divine vehicle.\n\nSome hold that similar analyses could be performed cross-culturally for any of the other Hindu divine vehicles, and in each case, any parallels with the values assigned to animal totems in other cultures are likely to be either coincidence, or inevitable (as in linking bulls to virility), rather than evidence of parallel development. In dialectic, this is countered by the retort that each totem or vahana, as an aspect of \"ishta-devata\" (or an \"ishta-devata\" or \"asura\" in its own right), has innumerable ineffable teachings, insights and spiritual wisdom; comparative analysis yields benefit, though knowledge and understanding is not served by collapsing their qualities into homogenous signification.\n\nThese correspondences are not always consistent. Ganesh, for example, is sometimes shown with a peacock as his vehicle, although a peacock is the customary vehicle of his brother Kartikeya (also known as Murugan, Subramanya, Skanda and other names) as well as the vehicle sometimes associated with the goddess Saraswati. Even more rarely, the elephant-headed Ganesh may be seen riding another elephant, or a lion, or a many-headed serpent.\n\nAs the \"vahana\", the mount or vehicle of a deity, serves the function of doubling a God's or Goddess' powers. The vahana also represents the devotee's mind which allows the deity to guide the devotee. Durga the warrioress could not have destroyed the demon Mahishasura without the aid of her vehicle, lion, which was given by her father Himalaya, for the stated purpose. Lakshmi, goddess of fortune, dispenses both material and spiritual riches from her mount, Uluka the owl. Ganesh, remover of obstacles, cannot go everywhere despite his elephant-like strength. However, his vehicle, Mushika the mouse, who can crawl into the smallest crevice or Akhuketana the rat, who can survive just about anywhere, can assist Ganesh to overcome the greatest obstacles.\n\n\n"}
