{"id": "55575415", "url": "https://en.wikipedia.org/wiki?curid=55575415", "title": "2017 TD6", "text": "2017 TD6\n\nOn 19 October 2017, the asteroid transited Earth at a nominal distance of , which corresponds to 0.5 lunar distances (LD). On the following day it also passed near the Moon at . Peaking near a magnitude of 18, the object was too faint to be seen—except for the largest telescopes.\n\nAs of 2018, has a poorly determined orbit with an uncertainty of 6 and a short observation arc of 8 days only. Due to its small size, the asteroid is likely to remain unobserved until its next, still relatively distant approach, predicted to occur in March 2044, at a distance of or 5.3 LD from Earth.\n\n\n"}
{"id": "44074755", "url": "https://en.wikipedia.org/wiki?curid=44074755", "title": "Anastasios Tsonis", "text": "Anastasios Tsonis\n\nAnastasios Tsonis is an American atmospheric scientist and distinguished professor at the University of Wisconsin–Milwaukee.\n\nTsonis was born in the Greek city of Elefsis. He received his BS from Aristotelian University in 1976 and his PhD from McGill University in 1982.\n\nAfter receiving his PhD, Tsonis became a postdoctoral fellow at the Atmospheric Environmental Service in Canada from 1982–1985. He then joined the University of Wisconsin–Milwaukee, where he has remained ever since.\n\nTsonis's career began focusing on mathematical models of atmospheric processes, such as vertical wind speeds.\n\nMore recently, Tsonis has become known for his research pertaining to global warming, especially natural influences on global temperatures. In 2009, Tsonis, with Kyle Swanson, published a paper reporting that natural climate shifts are superimposed on the warming trend observed during the 20th century. They concluded that \"a break in the global mean temperature trend from the consistent warming over the 1976/77–2001/02 period may have occurred.\" The authors also argued that \"there are times when different types of natural variation in the climate synchronize, which shifts the climate to a new state\", and that this may explain the supposed cessation of warming that, according to him, began in 2001 or 2002. They contend that this shift changed the climate state from \"warming\" to \"cooling\". Tsonis has argued that natural factors, especially ocean currents, may contribute more to climate change than human activity, and that the Earth is \"now in a period of cooling that could last up to fifty years.\" In 2013, he reiterated his view that this cooling trend was occurring, and might continue for the next 15 years. That year, shortly after the IPCC Fifth Assessment Report was released, he also criticized the reliability of climate models, saying that they \"don't agree with each other – and they don't agree with reality.\"\n"}
{"id": "19480112", "url": "https://en.wikipedia.org/wiki?curid=19480112", "title": "Arctic methane emissions", "text": "Arctic methane emissions\n\nArctic methane release is the release of methane from seas and soils in permafrost regions of the Arctic. While a long-term natural process, it is exacerbated by global warming. This results in a positive feedback effect, as methane is itself a powerful greenhouse gas.\n\nThe Arctic region is one of the many natural sources of the greenhouse gas methane. Global warming accelerates its release, due to both release of methane from existing stores, and from methanogenesis in rotting biomass. Large quantities of methane are stored in the Arctic in natural gas deposits, permafrost, and as undersea clathrates. Permafrost and clathrates degrade on warming, thus large releases of methane from these sources may arise as a result of global warming. Other sources of methane include submarine taliks, river transport, ice complex retreat, submarine permafrost and decaying gas hydrate deposits.\n\nConcentrations in the Arctic atmosphere are higher by 8–10% than that in the Antarctic atmosphere. During cold glacier epochs, this gradient decreases to practically insignificant levels. Land ecosystems are considered the main sources of this asymmetry, although it has been suggested that \"the role of the Arctic Ocean is significantly underestimated.\" Soil temperature and moisture levels have been found to be significant variables in soil methane fluxes in tundra environments.\n\nThe release of methane from the Arctic is in itself a major contributor to global warming as a result of polar amplification. Recent observations in the Siberian arctic show increased rates of methane release from the Arctic seabed. Land-based permafrost, also in the Siberian arctic, was estimated in 2013 to release 17 million tonnes of methane per year – a significant increase on the 3.8 million tons estimated in 2006, and estimates before then of just 0.5 million tonnes. This compares to around 500 million tonnes released into the atmosphere annually from all sources.\n\nShakhova et al. (2008) estimate that not less than 1,400 gigatonnes (Gt) of carbon is presently locked up as methane and methane hydrates under the Arctic submarine permafrost, and 5–10% of that area is subject to puncturing by open taliks. They conclude that \"release of up to 50 Gt of predicted amount of hydrate storage [is] highly possible for abrupt release at any time\". That would increase the methane content of the planet's atmosphere by a factor of twelve.\n\nIn 2008 the United States Department of Energy National Laboratory system identified potential clathrate destabilization in the Arctic as one of the most serious scenarios for abrupt climate change, which have been singled out for priority research. The US Climate Change Science Program released a report in late December 2008 estimating the gravity of the risk of clathrate destabilization, alongside three other credible abrupt climate change scenarios.\n\nStudy findings based on NASA's CARVE mission concluded in 2015, that methane emissions in the Arctic during the cold season are higher than previously thought. The press release by JPL explained:\nHong et al. (2017) studied the seepage from large mounds of hydrates in the shallow arctic seas at Storfjordrenna, in the Barents Sea close to Svalbard. They showed that though the temperature of the sea bed has fluctuated seasonally over the last century, between 1.8 and 4.8 °C, it has only affected release of methane to a depth of about 1.6 meters. Hydrates can be stable through the top 60 meters of the sediments and the current rapid releases came from deeper below the sea floor. They concluded that the increase in flux started hundreds to thousands of years ago well before the onset of warming that others speculated as its cause, and that these seepages are not increasing due to momentary warming. Summarizing his research, Hong stated:\nFurther research by Klaus Wallmann et al. (2018) found that the hydrate release is due to the rebound of the sea bed after the ice melted. The methane dissociation began around 8,000 years ago when the land began to rise faster than the sea level, and the water as a result started to get shallower with less hydrostatic pressure. This dissociation therefore was a result of the uplift of the sea bed rather than anthropogenic warming. The amount of methane released by the hydrate dissociation was small. They found that the methane seeps originate not from the hydrates but from deep geological gas reservoirs (seepage from these formed the hydrates originally). They concluded that the hydrates acted as a dynamic seal regulating the methane emissions from the deep geological gas reservoirs and when they were dissociated 8,000 years ago, weakening the seal, this led to the higher methane release still observed today.\n\nA 2015 study concluded that Arctic sea ice decline accelerates methane emissions from the Arctic tundra. One of the study researchers noted, \"The expectation is that with further sea ice decline, temperatures in the Arctic will continue to rise, and so will methane emissions from northern wetlands.\"\n\nA 2014 study found evidence for methane cycling below the ice sheet of the Russell Glacier, based on subglacial drainage samples which were dominated by Proteobacteria. During the study, the most widespread surface melt on record for the past 120 years was observed in Greenland; on 12 July 2012, unfrozen water was present on almost the entire ice sheet surface (98.6%). The findings indicate that methanotrophs could serve as a biological methane sink in the subglacial ecosystem, and the region was, at least during the sample time, a source of atmospheric methane. Scaled dissolved methane flux during the 4 months of the summer melt season was estimated at 990 Mg CH4. Because the Russell-Leverett Glacier is representative of similar Greenland outlet glaciers, the researchers concluded that the Greenland Ice Sheet may represent a significant global methane source. A study in 2016 concluded that methane clathrates may exist below Greenland's and Antarctica's ice sheets, based on past evidence.\n\nSea ice loss is correlated with warming of Northern latitudes. This has melting effects on permafrost, both in the sea, and on land. Lawrence et al. suggest that current rapid melting of the sea ice may induce a rapid melting of arctic permafrost. This has consequential effects on methane release, and wildlife. Some studies imply a direct link, as they predict cold air passing over ice is replaced by warm air passing over the sea. This warm air carries heat to the permafrost around the Arctic, and melts it. This permafrost then releases huge quantities of methane. Methane release can be gaseous, but is also transported in solution by rivers. \"New Scientist\" states that \"Since existing models do not include feedback effects such as the heat generated by decomposition, the permafrost could melt far faster than generally thought.\"\n\nThere is another possible mechanism for rapid methane release. As the Arctic Ocean becomes more and more ice free, the ocean absorbs more of the incident energy from the sun. The Arctic Ocean becomes warmer than the former ice cover and much more water vapour enters the air. At times when the adjacent land is colder than the sea, this causes rising air above the sea and an off-shore wind as air over the land comes in to replace the rising air over the sea. As the air rises, the dew point is reached and clouds form, releasing latent heat and further reinforcing the buoyancy of the air over the ocean. All this results in air being drawn from the south across the tundra rather than the present situation of cold air flowing toward the south from the cold sinking air over the Arctic Ocean. The extra heat being drawn from the south further accelerates the warming of the permafrost and the Arctic Ocean with increased release of methane.\n\nSinkholes discovered in the Yamal Peninsula in Siberia, Russia beginning in July 2014 are believed by Russian researchers to have been caused by methane released due to permafrost thawing. Near the bottom of the first sinkhole, air contained unusually high concentrations of methane, according to tests conducted by the researchers. This hypothesis points to the destabilization of gas hydrates containing huge amounts of methane gas.\n\nAccording to researchers at Norway's Centre for Arctic Gas Hydrate (CAGE), through a process called geothermal heat flux, the Siberian permafrost which extends to the seabed of the Kara Sea, a section of the Arctic Ocean between the Yamal Peninsula and Novaya Zemlya, is thawing. According to a CAGE researcher, Aleksei Portnov,\n\nMethane hydrate is leaking in an area of at least 7500 m2. In some areas gas flares extend up to . Prior to their research it was proposed that methane was tightly sealed into the permafrost by water depths up to . Close to the shore however, where the permafrost seal tapers to as little as , there are significant amounts of gas leakage.\n\nSea ice, and the cold conditions it sustains, serves to stabilise methane deposits on and near the shoreline, preventing the clathrate breaking down and outgassing methane into the atmosphere, causing further warming. Melting of this ice may release large quantities of methane, a powerful greenhouse gas into the atmosphere, causing further warming in a strong positive feedback cycle.\n\nEven with existing levels of warming and melting of the Arctic region, submarine methane releases linked to clathrate breakdown have been discovered, and demonstrated to be leaking into the atmosphere. A 2011 Russian survey off the East Siberian coast found plumes wider than one kilometer releasing methane directly into the atmosphere.\n\nAccording to monitoring carried out in 2003/2004 by Shakhova et al., the surface layer of shelf water in the East Siberian Sea and Laptev Sea was supersaturated up to 2500% relative to then present average atmospheric methane content of 1.85 ppm. Anomalously high concentrations (up to 154 nM or 4400% supersaturation) of dissolved methane in the bottom layer of shelf water suggest that the bottom layer is somehow affected by near-bottom sources. Considering the possible formation mechanisms of such plumes, their studies indicated thermoabrasion and the effects of shallow gas or gas hydrates release.\n\nResearch in 2008 in the Siberian Arctic has shown clathrate-derived methane being released through perforations in the seabed permafrost.\n\nThe climatic effects of a potential release of methane from global ocean clathrates may be significant on timescales of 1–100 thousand years, depending on the water temperature.\n\n\n"}
{"id": "1214384", "url": "https://en.wikipedia.org/wiki?curid=1214384", "title": "Black Orpheus", "text": "Black Orpheus\n\nBlack Orpheus (Brazilian Portuguese: \"Orfeu Negro\" ) is a 1959 romantic tragedy film made in Brazil by French director Marcel Camus and starring Marpessa Dawn and Breno Mello. It is based on the play \"Orfeu da Conceição\" by Vinicius de Moraes, which is itself an adaptation of the Greek legend of Orpheus and Eurydice, set in the modern context of a \"favela\" (\"slum\") in Rio de Janeiro during \"Carnaval\". The film was an international co-production among production companies in Brazil, France and Italy.\n\nThe film is particularly noted for its soundtrack by two Brazilian composers: Antônio Carlos Jobim, whose song \"A Felicidade\" opens the film; and Luiz Bonfá, whose \"Manhã de Carnaval\" and \"Samba de Orfeu\" have become classics of \"bossa nova\". The songs sung by the character Orfeu were dubbed by singer Agostinho dos Santos.\n\nLengthy passages of the film were shot in the Morro da Babilônia, a \"favela\" in the Leme neighbourhood of Rio de Janeiro.\n\nA marble Greek \"bas relief\" explodes to reveal black men dancing the samba to drums in a \"favela\". Eurydice (Marpessa Dawn) arrives in Rio de Janeiro, and takes a trolley driven by Orfeu (Breno Mello). New to the city, she rides to the end of the line, where Orfeu introduces her to the station guard, Hermes (Alexandro Constantino), who gives her directions to the home of her cousin Serafina (Léa Garcia).\n\nAlthough engaged to Mira (Lourdes de Oliveira), Orfeu is not very enthusiastic about the upcoming marriage. The couple go to get a marriage license. When the clerk at the courthouse hears Orfeu's name, he jokingly asks if Mira is Eurydice, annoying her. Afterward, Mira insists on getting an engagement ring. Though Orfeu has just been paid, he would rather use his money to get his guitar out of the pawn shop for the carnival. Mira finally offers to loan Orfeu the money to buy her ring.\n\nWhen Orfeu goes home, he is pleased to find Eurydice staying next door with Serafina. Eurydice has run away to Rio to hide from a strange man who she believes wants to kill her. The man – Death dressed in a stylized skeleton costume – finds her, but Orfeu gallantly chases him away. Orfeu and Eurydice fall in love, yet are constantly on the run from both Mira and Death. When Serafina's sailor boyfriend Chico (Waldemar De Souza) shows up, Orfeu offers to let Eurydice sleep in his home, while he takes the hammock outside. Eurydice invites him to her bed.\n\nOrfeu, Mira, and Serafina are the principal members of a samba school, one of many parading during Carnival. Serafina decides to have Eurydice dress in her costume so that she can spend more time with her sailor. A veil conceals Eurydice's face; only Orfeu is told of the deception. During the parade, Orfeu dances with Eurydice rather than Mira.\n\nEventually, Mira spots Serafina among the spectators and rips off Eurydice's veil. Eurydice is forced once again to run for her life first from Mira, then from Death. Trapped in Orfeu's own trolley station, she hangs from a power line to get away from Death and is killed accidentally by Orfeu when he turns the power on and electrocutes her. Death tells Orfeu \"Now she's mine,\" before knocking him out.\n\nDistraught, Orfeu looks for Eurydice at the Office of Missing Persons, although Hermes has told him she is dead. The building is deserted at night, with only a janitor sweeping up. He tells Orfeu that the place holds only papers and that no people can be found there. Taking pity on Orfeu, the janitor takes him down a large darkened spiral staircase – a reference to the mythical Orpheus' descent into the underworld – to a Macumba ritual, a regional form of the Afro-Brazilian religion Candomblé.\n\nAt the gate, there is a dog named Cerberus, after the three-headed dog of Hades in Greek mythology. During the ritual, the janitor tells Orfeu to call to his beloved by singing. The spirit of Eurydice inhabits the body of an old woman and speaks to him. Orfeu wants to gaze upon her, but Eurydice begs him not to lest he lose her forever. When he turns and looks anyway, he sees the old woman, and Eurydice's spirit departs, as in the Greek myth.\n\nOrfeu wanders in mourning. He retrieves Eurydice's body from the city morgue and carries her in his arms across town and up the hill toward his home, where his shack is burning. A vengeful Mira, running amok, flings a stone that hits him in the head and knocks him over a cliff to his death with Eurydice still in his arms.\n\nTwo children, Benedito and Zeca – who have followed Orfeu throughout the film – believe Orfeu's tale that his guitar playing causes the sun to rise every morning. After Orfeu's death, Benedito insists that Zeca pick up the guitar and play so that the sun will rise. Zeca plays, and the sun comes up. A little girl appears, gives Zeca a single flower, and the three children dance.\n\n\n\n\"Black Orpheus\" won the Palme d'Or at the 1959 Cannes Film Festival, the 1960 Academy Award for Best Foreign Language Film, the 1960 Golden Globe Award for Best Foreign Film and the 1961 BAFTA Award for Best Foreign Language Film. In the last case, Brazil was credited together with France and Italy.\n\n\"Black Orpheus\" was cited by Jean-Michel Basquiat as one of his early musical influences, while Barack Obama notes in his memoir \"Dreams from My Father\" (1995) that it was his mother's favorite film.\n\nObama, however, did not share his mother's preferences upon first watching the film during his first years at Columbia University: \"I suddenly realized that the depiction of the childlike blacks I was now seeing on the screen, the reverse image of Conrad's dark savages, was what my mother had carried with her to Hawaii all those years before, a reflection of the simple fantasies that had been forbidden to a white, middle-class girl from Kansas, the promise of another life: warm, sensual, exotic, different.\"\n\nThe film's soundtrack also inspired Vince Guaraldi's 1962 album \"Jazz Impressions of Black Orpheus\".\n\n\n\n"}
{"id": "176552", "url": "https://en.wikipedia.org/wiki?curid=176552", "title": "Chatham Islands", "text": "Chatham Islands\n\nThe Chatham Islands form an archipelago in the Pacific Ocean about east of the South Island of New Zealand. It consists of about ten islands within a radius, the largest of which are Chatham Island and Pitt Island. Some of these islands, once cleared for farming, are now preserved as nature reserves to conserve some of the unique flora and fauna.\nThe resident population is 600 (). The islands' economy is largely dependent on conservation, tourism, farming, and fishing. \n\nThe archipelago is called \"Rēkohu\" (\"Misty Sun\") in the indigenous Moriori language, and \"Wharekauri\" in Māori. The Moriori are the indigenous people of the Chatham Islands, and members of the Māori Ngāti Mutunga tribe have also settled on the island. It has officially been part of New Zealand since 1842 and includes the country's easternmost point, the Forty-Fours. \n\nLocal administration of the Chatham Islands is provided by the Chatham Islands Council, whose powers are similar to other unitary authorities. The islands are listed with the New Zealand Outlying Islands. The islands are an immediate part of New Zealand, but not part of any region or district, but instead \"Area Outside Territorial Authority\", like all the other outlying islands except the Solander Islands.\n\nThe islands are at about , roughly east of Christchurch, New Zealand. The nearest mainland New Zealand point to the Chatham Islands is Cape Turnagain, in the North Island at a distance of . The nearest mainland city to the islands is Hastings, New Zealand, located to the North-West. The two largest islands, Chatham Island and Pitt Island, constitute most of the total area of , with a dozen scattered islets covering the rest. \n\nThe islands sit on the Chatham Rise, a large, relatively shallowly submerged (no more than deep at any point) part of the Zealandia continent that stretches east from near the South Island. The Chatham Islands, which emerged only within the last four million years, are the only part of the Chatham Rise showing above sea level.\n\nThe islands are hilly with coasts being a varied mixture including cliffs and dunes, beaches, and lagoons. Pitt is more rugged than Chatham, although the highest point () is on a plateau near the southernmost point of the main island (at , south of Lake Te Rangatapu). The plateau is dotted with numerous lakes and lagoons, flowing mainly from the island's nearby second highest point, Maungatere Hill, at 294 metres. Notable are the large Te Whanga Lagoon, and Huro and Rangitahi. Chatham has a number of streams, including Te Awainanga and Tuku. \n\nChatham and Pitt are the only inhabited islands, with the remaining smaller islands being conservation reserves with restricted or prohibited access. The livelihoods of the inhabitants depend on agriculture, with the island being an exporter of coldwater crayfish, and increasing tourism.\n\nThe names of the main islands, in the order of occupation are:\n\nChatham Islands have an oceanic climate characterised by a narrow temperature range and relatively frequent rainfall. Its isolated position far from any sizeable landmass renders the record temperature for main settlement Waitangi to be just . The climate is cool, wet and windy, with average high temperatures between in summer, and between in July, the Southern Hemisphere winter. Snow is extremely rare, being recorded near sea level in July 2015 after several decades. \n\nThe International Date Line lies to the east of the Chathams, even though the islands lie east of 180° longitude. The Chathams observe their own time, 45 minutes ahead of New Zealand time, including during periods of daylight saving time; the Chatham Standard Time Zone is distinctive as one of very few that differ from others by a period other than a whole hour or half-hour. (New Zealand Time orients itself to 180° longitude.)\n\nThe Chatham Islands are subdivided into seven survey districts:\n\n\nThe natural vegetation of the islands was a mixture of forest, scrubby heath, and swamp, but today most of the land is fern or pasture-covered, although there are some areas of dense forest and areas of peat bogs and other habitats. Of interest are the akeake trees, with branches trailing almost horizontally in the lee of the wind. The ferns in the forest understory include \"Blechnum discolor\".\n\nThe islands are home to a rich bio-diversity including about fifty endemic plants adapted to the cold and the wind, such as Chatham Islands forget-me-not (\"Myosotidium hortensia\"), Chatham Islands sow-thistle \"(Embergeria grandifolia)\", rautini (\"Brachyglottis huntii\"), Chatham Islands kakaha (\"Astelia chathamica\"), soft speargrass (\"Aciphylla dieffenbachii\"), and Chatham Island akeake or Chatham Island tree daisy (\"Olearia traversiorum\").\n\nThe islands are a breeding ground for huge flocks of seabirds and are home to a number of endemic birds, some of which are seabirds and others which live on the islands. The best known species are the magenta petrel (IUCN classification CR]) and the black robin (IUCN classification EN), both of which came perilously close to extinction before drawing the attention of conservation efforts. Other endemic species are the Chatham oystercatcher, the Chatham gerygone, Chatham pigeon, Forbes' parakeet, the Chatham snipe and the shore plover. The endemic Chatham shag (IUCN classification CR), Pitt shag (IUCN classification EN) and the Chatham albatross (IUCN classification VU) are at risk of capture by a variety of fishing gear, including fishing lines, trawls, gillnets, and pots.\n\nFor accounts and notes on seabird species seen in the Chathams between 1960 and 1993 online.\n\nA number of species have gone extinct since European settlement, including the three endemic species of rails, the Chatham raven, and the Chatham fernbird.\n\nAlso, a number of marine mammals are found in the waters of the Chathams, including New Zealand sea lions, leopard seals, and southern elephant seals. Many whale species are attracted to the rich food sources of the Chatham Rise.\n\nMuch of the natural forest of these islands has been cleared for farming, but Mangere and Rangatira Islands are now preserved as nature reserves to conserve some of these unique flora and fauna. Another threat to wildlife comes from introduced species which prey on the indigenous birds and reptiles, whereas on Mangere and Rangatira, livestock has been removed and native wildlife is recovering.\n\nThe first human inhabitants of the Chathams were Polynesian tribes who settled the islands about 1500 CE, and in their isolation became the Moriori. The former belief, which arose in the 1800s, was that the original Moriori migrated directly from the more northerly Polynesian islands, just as with the settlement of New Zealand by the ancestors of the Māori. However, linguistic research indicates instead that the ancestral Moriori were Māori wanderers from New Zealand.\nAs Howe (2003) puts it,\nScholarship over the past 40 years has radically revised the model offered a century earlier by Smith: the Moriori as a pre-Polynesian people have gone (the term Moriori is now a technical term referring to those ancestral Māori who settled the Chatham Islands).'\n\nThe plants cultivated by the Māori arrivals were ill-suited for the colder Chathams, so the Moriori lived as hunter-gatherers and fishermen. While their new environment deprived them of the resources with which to build ocean-going craft for long voyages, the Moriori invented what was known as the waka korari, a semi-submerged craft, constructed of flax and lined with air bladders from kelp. This craft was used to travel to the outer islands on 'birding' missions. The Moriori society was a peaceful society and bloodshed was outlawed by the chief Nunuku after generations of warfare. Arguments were solved by consensus or by duels rather than warfare, but at the first sign of bloodshed, the fight was over.\n\nThe name \"Chatham Islands\" comes from the ship of the Vancouver Expedition, whose captain William R. Broughton landed on 29 November 1791, claimed possession for Great Britain and named the islands after the First Lord of the Admiralty, John Pitt, 2nd Earl of Chatham. A relative of his, Thomas Pitt, was a member of the Vancouver Expedition. Sealers and whalers soon started hunting in the surrounding ocean with the islands as their base. It is estimated that 10 to 20 percent of the indigenous Moriori soon died from diseases introduced by foreigners. The sealing and whaling industries ceased activities about 1861, while fishing remained as a major economic activity.\n\nChatham Islands date their anniversary on 29 November, and observe it 30 November.\n\nOn 19 November 1835 and later on 5 December, about 900 Ngāti Mutunga and Ngāti Tama previously resident in Te Whanganui-A-Tara (Wellington) and led by the chief Matioro arrived on the brig \"Lord Rodney\". The first mate of the ship had been 'kidnapped and threatened with death' unless the captain took the Māori settlers on board. The group, which included men, women and children, brought with them 78 tonnes of seed potato, 20 pigs and seven large canoes called \"waka\".\n\nThe incoming Māori were received and initially cared for by the local Moriori. Soon, Ngāti Mutunga and Ngāti Tama began to \"takahi\", or walk the land, to lay claim to it. When it became clear that the visitors intended to stay, the Moriori withdrew to their marae at te Awapatiki. There, after holding a \"hui\" (consultation) to debate what to do about the Māori settlers, the Moriori decided to stay with their policy of non-aggression. \n\nNgāti Mutunga and Ngāti Tama in turn saw the meeting as a precursor to warfare on the part of Moriori and responded. The Māori attacked and in the ensuing action killed over 260 Moriori. A Moriori survivor recalled: \"[The Māori] commenced to kill us like sheep... [We] were terrified, fled to the bush, concealed ourselves in holes underground, and in any place to escape our enemies. It was of no avail; we were discovered and killed — men, women and children — indiscriminately.\" A Māori chief, Te Rakatau Katihe, said: \"We took possession ... in accordance with our custom, and we caught all the people. Not one escaped. Some ran away from us, these we killed; and others also we killed — but what of that? It was in accordance with our custom.\" Despite the Chatham Islands being made part of New Zealand in 1842, Māori kept Moriori slaves until 1863.\n\nAfter the killings, Moriori were forbidden to marry Moriori, or to have children with each other. All became slaves of the Māori until the 1860s. Many died in despair. Many Moriori women had children by their Māori masters. A number of Moriori women eventually married either Māori or European men. Some were taken away from the Chathams and never returned. Ernst Dieffenbach, who visited the Chathams on a New Zealand Company ship in 1840, reported that the Moriori were the virtual slaves of Māori and were severely mistreated, with death being a blessing. By the time the slaves were released in 1862, only 160 remained, hardly 10% of the 1835 population.\n\nIn early May 1838 (some reports say 1839 but this is contradicted by ship records) the French whaling vessel \"Jean Bart\" anchored off Waitangi to trade with the Māori. The number of Māori boarding frightened the French, escalating into a confrontation in which the French crew were killed and the \"Jean Bart\" was run aground at Ocean Bay, to be ransacked and burned by Ngāti Mutunga. When word of the incident reached the French naval corvette \"Heroine\" in the Bay of Islands in September 1838, it set sail for the Chathams, accompanied by the whalers \"Adele\" and \"Rebecca Sims\". The French arrived on 13 October and, after unsuccessfully attempting to entice some Ngāti Tama aboard, proceeded to bombard Waitangi. The next morning about a hundred armed Frenchmen went ashore, burning buildings, destroying \"waka\", and seizing pigs and potatoes. The attacks mostly affected Ngāti Tama, weakening their position relative to Ngāti Mutunga.\n\nIn 1840, Ngāti Mutunga decided to attack Ngāti Tama at their \"pa\". They built a high staging next to the \"pa\" so they could fire down on their former allies. Fighting was still in progress when the New Zealand Company ship \"Cuba\" arrived as part of a scheme to buy land for settlement. The Treaty of Waitangi, at that stage, did not apply to the islands. The company negotiated a truce between the two warring tribes. In 1841, the New Zealand Company had proposed to establish a German colony on the Chathams. The proposal was discussed by the directors and John Ward signed an agreement with Karl Sieveking of Hamburg on 12 September 1841. However, when the Colonial Office said that the islands were to be part of the colony of New Zealand and any Germans settling there would be treated as aliens, Joseph Somes claimed that Ward had been acting on his own initiative. The proposed leader John Beit and the expedition went to Nelson instead.\n\nThe company was then able to purchase large areas of land at Port Hutt (which the Māori called Whangaroa) and Waitangi from Ngāti Mutanga and also large areas of land from Ngāti Tama. This did not stop Ngāti Mutunga from trying to get revenge for the death of one of their chiefs. They were satisfied after they killed the brother of a Ngāti Tama chief. The tribes agreed to an uneasy peace which was finally conformed in 1842.\n\nReluctant to give up slavery, Matioro and his people chartered a brig in late 1842 and sailed to Auckland Island. While Matioro was surveying the island, two of the chiefs who had accompanied him decided the island was too inhospitable for settlement, and set sail before he had returned, stranding him and his followers until Pākehā settlers arrived in 1849.\n\nAn all-male group of German Lutheran missionaries arrived in the Chathams in 1843. After a group of women were sent out to join them, three years later, several marriages ensued, and many members of the present-day population can trace their ancestry back to the missionary families.\n\nIn 1865, the Māori leader Te Kooti was exiled on the Chatham Islands along with a large group of Māori rebels called the Hauhau, followers of Pai Mārire who had murdered missionaries and fought against government forces mainly on the East Coast of the North Island of New Zealand. The rebel prisoners were paid one shilling a day to work on sheep farms owned by the few European settlers. Sometimes they worked on road and track improvements. They were initially guarded by 26 guards, half of whom were Māori. They lived in \"whare\" along with their families. The prisoners helped build a redoubt of stone surrounded by a ditch and wall. Later, they built 3 stone prison cells.\n\nThe Moriori community is organised as the Hokotehi Moriori Trust. The Moriori have received recognition from the Crown and the New Zealand government and some of their claims against those institutions for the generations of neglect and oppression have been accepted and acted on. Moriori are recognised as the original people of Rekohu. The Crown also recognised the Ngāti Mutunga Māori as having indigenous status in the Chathams by right of 160-odd years of occupation.\n\nThe population of the islands is around 600, including members of both ethnic groups. In January 2005, the Moriori celebrated the opening of the new Kopinga Marae (meeting house).\n\nModern descendants of the 1835 Māori conquerors claimed a share in ancestral Māori fishing rights. This claim was granted. Now that the primordial population, the Moriori, have been recognised to be former Māori—over the objections of some of the Ngāti Mutunga—they too share in the ancestral Māori fishing rights. Both groups have been granted fishing quotas.\n\nChatham and Pitt Islands are inhabited, with 600 residents in the 2013 Census. The town of Waitangi is the main settlement with some 200 residents. There are other villages such as Owenga, Te One and Kaingaroa, where there are two primary schools. A third school is on Pitt Island. There are also the fishing villages of Owenga and Port Hutt.\n\nWaitangi facilities include a hospital with resident doctor, bank, several stores, and engineering and marine services. The main shipping wharf is located here.\n\nAccording to the 2013 census there were 264 occupied dwellings, 69 unoccupied dwellings, and 3 dwellings under construction.\n\nOf the residential population, 315 (52.5%) were male compared to 48.7% nationally, and 285 (47.5%) were female, compared to 51.3% nationally. The archipelago had a median age of 41.5 years, 3.5 years above the national median age of 38.0 years. People aged 65 and over made up 12.0% of the population, compared to 14.3% nationally, and people under 15 years made up 20.0%, compared to 20.4% nationally.\n\nThe Chatham Islands' ethnicity is made up of (national figures in brackets): 73.5% European (74.0%), 59.3% Māori (14.9%), 1.1% Pacific Islanders (7.4%), 0.5% Asian (11.8%), 0.0% Middle Eastern, Latin American or African (1.2%), and 3.2% other (1.7%). Note that where a person reported more than one ethnic group, they have been counted in each applicable group. As a result, percentages do not add up to 100.\n\nThe unemployment rate is of 2.5% of people 15 years and over, compared to 7.4% nationally. The median annual income of all people 15 years and over was $31,500, compared to $28,500 nationally. Of those, 31.0% earned under $20,000, compared to 38.2% nationally, while 31.0% earned over $50,000, compared to 26.7% nationally.\n\nVisitors to the Chathams usually arrive by air from Auckland, Christchurch or Wellington (around 1.5 – 2 hours from Christchurch on a Convair 580) to Tuuta Airport on Chatham Island. While freight generally arrives by ship (2 days sailing time), the sea journey takes too long for many passengers, and is not always available.\n\nThe Chathams are part of New Zealand so there are no border controls or formalities on arrival, but visitors are advised to have prearranged their accommodation on the islands. Transport operators may refuse to carry passengers without accommodation bookings. There is no scheduled public transport but accommodation providers are normally able to arrange transport.\n\nTasman Empire Airways Ltd (TEAL) initially serviced the Chathams by air using flying boats. With the withdrawal of TEAL, the RNZAF maintained an infrequent service with Short Sunderland flying boats. NZ4111 was damaged on takeoff from Te Whanga Lagoon on 4 November 1959 and remains as a wreck on the island. The last flight by RNZAF flying boats was on 22 March 1967. For many years Bristol Freighter aircraft served the islands, a slow and noisy freight aircraft converted for carrying passengers by installing a removable passenger compartment equipped with airline seats and a toilet in part of the cargo hold. The air service primarily served to ship out high-value export crayfish products.\n\nThe grass landing field at Hapupu, at the northern end of the Island, proved a limiting factor, as few aircraft apart from the Bristol Freighter had both the range to fly to the islands and the ruggedness to land on the grass airstrip. Although other aircraft did use the landing field occasionally, they would often require repairs to fix damage resulting from the rough landing. Hapupu is also the site of the JM Barker (Hapupu) National Historic Reserve (one of only two in New Zealand) where there are momori rakau (Moriori tree carvings).\n\nIn 1981, after many years of requests by locals and the imminent demise of the ageing Bristol Freighters, the construction of a sealed runway at Karewa, Tuuta Airport, allowed more modern aircraft to land safely. The Chathams' own airline, Air Chathams, now operates services to Auckland on Thursdays, Wellington on Mondays, Wednesdays and Fridays and Christchurch on Tuesdays. The timetable varies seasonally, but generally planes depart the Chathams around 10.30 am (Chathams Time) and arrive in the mainland around noon. There they refuel and reload, and depart again at around 1 pm back to the Chathams. Air Chathams operates twin turboprop Convair 580 aircraft in combi (freight and passenger) configurations and Fairchild Metroliners.\n\nThe ship \"Rangatira\" provided a freight service from Timaru to the Chatham Islands from March 2000 to August 2015. The MV \"Southern Tiare\" provides a freight service between Napier, Timaru and the Chathams.\n\nThere is a small section of tar sealed road between Waitangi and Te One, but the majority of the islands' roads are gravel.\n\nUntil the 1980s, the Chathams were in the Lyttelton electorate, but since then they have formed part of the Rongotai general electorate, which mostly lies in Wellington. Paul Eagle is the MP for Rongotai. The Te Tai Tonga Māori seat (held since 2011 by Rino Tirikatene) includes the Chatham Islands.\n\nLocal government on the islands, uniquely within New Zealand, involves a council established by its own Act of Parliament, the Chatham Islands Council Act 1995 (Statute No 041, Commenced: 1 November 1995). The Chatham Islands Council operates as a district council with regional council functions, making it in effect a unitary authority but with not quite as many responsibilities as the others. The Council comprises a Mayor and eight Councillors, one of whom is also Deputy Mayor. Certain regional council functions are being administered by Environment Canterbury, the Canterbury Regional Council.\n\nIn the 2010 local government elections, Chatham Islands had NZ's highest rate of returned votes, with 71.3 percent voting.\n\nPolicing is carried out by a sole-charge constable appointed by the Wellington police district, who has often doubled as an official for many government departments, including court registrar (Department for Courts), customs officer (New Zealand Customs Service) and immigration officer (Department of Labour – New Zealand Immigration Service).\n\nA District Court judge sent from either the North Island or the South Island presides over court sittings, but urgent sittings may take place at the Wellington District Court.\n\nBecause of the isolation and small population, some of the rules governing daily activities undergo a certain relaxation. For example, every transport service operated solely on Great Barrier Island, the Chatham Islands or Stewart Island/Rakiura need not comply with section 70C of the Transport Act 1962 (the requirements for drivers to maintain driving-hours logbooks). Drivers subject to section 70B must nevertheless keep record of their driving hours in some form.\n\nFrom 1 July 2015 the Canterbury District Health Board assumed responsibility from the Hawkes Bay District Health Board for providing publicly funded health services for the island.\n\nThree schools are located on the Chathams, at Kaingaroa, Te One, and Pitt Island. Pitt Island and Kaingaroa are staffed by sole charge principals, while Te One has three teachers and a principal. These schools cater for children from year 1 to 8. No secondary school is present on the Chathams. The majority of secondary school-aged students leave the island for boarding schools in mainland New Zealand. A small number remain on the island and carry out their secondary education through correspondence.\n\nMost of the Chatham Island economy is based on fishing and crayfishing, with only a fragment of the economic activity in adventure tourism. This economic mix has been stable for the past 50 years, as little infrastructure or population is present to engage in higher levels of industrial or telecommunications activity.\n\nAir Chathams has its head office in Te One.\n\nTwo 225-kW wind turbines and diesel generators provide power on Chatham island, at costs of five to ten times that of electricity on the main islands of New Zealand. During 2014, 65% of the electricity was generated from diesel generators, the balance from wind.\n\n\n\n\n"}
{"id": "10109665", "url": "https://en.wikipedia.org/wiki?curid=10109665", "title": "Chilton and Colburn J-factor analogy", "text": "Chilton and Colburn J-factor analogy\n\nChilton–Colburn J-factor analogy is a successful and widely used analogy between heat, momentum, and mass transfer. The basic mechanisms and mathematics of heat, mass, and momentum transport are essentially the same. Among many analogies (like Reynolds analogy, Prandtl–Taylor analogy) developed to directly relate heat transfer coefficients, mass transfer coefficients, and friction factors Chilton and Colburn J-factor analogy proved to be the most accurate. \n\nIt is written as follows,\n\nformula_1\n\nThis equation permits the prediction of an unknown transfer coefficient when one of the other coefficients is known. The analogy is valid for fully developed turbulent flow in conduits with \"Re\" > 10000, 0.7 < \"Pr\" < 160, and tubes where \"L\"/\"d\" > 60 (the same constraints as the Sieder–Tate correlation). The wider range of data can be correlated by Friend–Metzner analogy.\n\nRelationship between Heat and Mass;\n\nformula_2\n\n\n\n"}
{"id": "32826371", "url": "https://en.wikipedia.org/wiki?curid=32826371", "title": "Cry of the Kalahari", "text": "Cry of the Kalahari\n\nCry of the Kalahari (1984) is an autobiographical book detailing two young American zoologists, Mark and Delia Owens, and their experience studying wildlife in the Kalahari desert in Botswana in the mid-1970s. There they lived and worked for seven years in an unexplored area named Deception Valley in the Central Kalahari Game Reserve. With no roads and no people and the nearest civilization eight hours away they had only each other and the animals they studied as company, most of which had never seen humans before. Their research focused mainly on lions, brown hyenas, jackals and other African carnivores. \"Cry of the Kalahari\" is the personal story of the Owens' encounters with these and a myriad of other animals and depicts their own struggle to live and work in such an inhospitable and unforgiving environment.\n\n\"Cry of the Kalahari\" was a national and international bestseller, translated into seven languages and is the 1985 John Burroughs Medal winner.\n\n"}
{"id": "433879", "url": "https://en.wikipedia.org/wiki?curid=433879", "title": "Cubical atom", "text": "Cubical atom\n\nThe cubical atom was an early atomic model in which electrons were positioned at the eight corners of a cube in a non-polar atom or molecule. This theory was developed in 1902 by Gilbert N. Lewis and published in 1916 in the article \"The Atom and the Molecule\" and used to account for the phenomenon of valency. \nLewis's theory was based on Abegg's rule. It was further developed in 1919 by Irving Langmuir as the cubical octet atom. The figure below shows structural representations for elements of the second row of the periodic table.\n\nAlthough the cubical model of the atom was soon abandoned in favor of the quantum mechanical model based on the Schrödinger equation, and is therefore now principally of historical interest, it represented an important step towards the understanding of the chemical bond. The 1916 article by Lewis also introduced the concept of the electron pair in the covalent bond, the octet rule, and the now-called Lewis structure.\n\nSingle covalent bonds are formed when two atoms share an edge, as in structure C below. This results in the sharing of two electrons. Ionic bonds are formed by the transfer of an electron from one cube to another, without sharing an edge (A). An intermediate state B where only one corner is shared was also postulated by Lewis.\n\nDouble bonds are formed by sharing a face between two cubic atoms. This results in sharing four electrons:\n\nTriple bonds could not be accounted for by the cubical atom model, because there is no way of having two cubes share three parallel edges. Lewis suggested that the electron pairs in atomic bonds have a special attraction, which result in a tetrahedral structure, as in the figure below (the new location of the electrons is represented by the dotted circles in the middle of the thick edges). This allows the formation of a single bond by sharing a corner, a double bond by sharing an edge, and a triple bond by sharing a face. It also accounts for the free rotation around single bonds and for the tetrahedral geometry of methane. \n\n"}
{"id": "1478282", "url": "https://en.wikipedia.org/wiki?curid=1478282", "title": "Early Jurassic", "text": "Early Jurassic\n\nThe Early Jurassic epoch (in chronostratigraphy corresponding to the Lower Jurassic series) is the earliest of three epochs of the Jurassic period. The Early Jurassic starts immediately after the Triassic-Jurassic extinction event, 201.3 Ma (million years ago), and ends at the start of the Middle Jurassic 174.1 Ma.\n\nCertain rocks of marine origin of this age in Europe are called \"Lias\" and that name was used for the period, as well, in 19th-century geology. In southern Germany rocks of this age are called Black Jurassic.\n\nThere are two possible origins for the name Lias: the first reason is it was taken by a geologist from an English quarryman's dialect pronunciation of the word \"layers\"; secondly, sloops from north Cornish ports such as Bude would sail across the Bristol Channel to the Vale of Glamorgan to load up with rock from coastal limestone quarries (lias limestone from South Wales was used throughout North Devon/North Cornwall as it contains calcium carbonate to fertilise the poor quality Devonian soils of the West Country); the Cornish would pronounce the layers of limestone as 'laiyers' or 'lias'.\n\nThere are extensive Liassic outcrops around the coast of the United Kingdom, in particular in Glamorgan, North Yorkshire and Dorset. The 'Jurassic Coast' of Dorset is often associated with the pioneering work of Mary Anning of Lyme Regis. The facies of the Lower Jurassic in this area are predominantly of clays, thin limestones and siltstones, deposited under fully marine conditions.\nLias Group strata form imposing cliffs on the Vale of Glamorgan coast, in southern Wales. Stretching for around between Cardiff and Porthcawl, the remarkable layers of these cliffs, situated on the Bristol Channel are a rhythmic decimetre scale repetition of limestone and mudstone formed as a late Triassic desert was inundated by the sea.\n\nThere has been some debate over the actual base of the Hettangian stage, and so of the Jurassic system itself. Biostratigraphically, the first appearance of psiloceratid ammonites has been used; but this depends on relatively complete ammonite faunas being present, a problem that makes correlation between sections in different parts of the world difficult. If this biostratigraphical indicator is used, then technically the Lias Group—a lithostratigraphical division—spans the Jurassic / Triassic boundary.\n\nDuring this period, ammonoids, which had almost died out at the end-of-Triassic extinction, radiated out into a huge diversity of new forms with complex suture patterns (the ammonites proper). Ammonites evolved so rapidly, and their shells are so often preserved, that they serve as important zone fossils. There were several distinct waves of ammonite evolution in Europe alone.\n\nThe Early Jurassic was an important time in the evolution of the marine reptiles. The Hettangian saw the already existing Rhaetian ichthyosaurs and plesiosaurs continuing to flourish, while at the same time a number of new types of these marine reptiles appeared, such as \"Ichthyosaurus\" and \"Temnodontosaurus\" among the ichthyosaurs, and \"Eurycleidus\", \"Macroplata\", and \"Rhomaleosaurus\" among the plesiosaurs (all Rhomaleosauridae, although as currently defined this group is probably paraphyletic). All these plesiosaurs had medium-sized necks and large heads. In the Toarcian, at the end of the Early Jurassic, the thalattosuchians (marine \"crocodiles\") appeared, as did new genera of ichthyosaurs (\"Stenopterygius\", \"Eurhinosaurus\", and the persistently primitive \"Suevoleviathan\") and plesiosaurs (the elasmosaurs (long-necked) \"Microcleidus\" and \"Occitanosaurus\", and the pliosaur \"Hauffiosaurus\").\n\nOn land, a number of new types of dinosaurs—the heterodontosaurids, scelidosaurs, stegosaurs, and tetanurans—appeared, and joined those groups like the coelophysoids, prosauropods and the sauropods that had continued over from the Triassic. Accompanying them as small carnivores were the sphenosuchian and protosuchid crocodilians. In the air, new types of pterosaurs replaced those that had died out at the end of the Triassic. But in the undergrowth were various types of early mammals, as well as tritylodont mammal-like reptiles, lizard-like sphenodonts, and early lissamphibians.\n\n\n\n"}
{"id": "54854477", "url": "https://en.wikipedia.org/wiki?curid=54854477", "title": "Energy in South America", "text": "Energy in South America\n\nEnergy use, import and production in South America is described in the following articles:\n"}
{"id": "57006389", "url": "https://en.wikipedia.org/wiki?curid=57006389", "title": "Eurilla Conservation Park", "text": "Eurilla Conservation Park\n\nEurilla Conservation Park is a protected area located in the Australian state of South Australia in the suburb of Crafers in the Adelaide Hills state government region about south-east of the state capital of Adelaide and about north of the town centre in Stirling.\nThe conservation park consists of land in section 535 in the cadastral unit of the Hundred of Onkaparinga. It is located to the east of the Mount Lofty Summit Road about south of the summit of Mount Lofty and is bounded on its northern boundary by the Cleland Conservation Park. It was proclaimed under the \"National Parks and Wildlife Act 1972\" on 22 September 1977. As of 2016, it covered an area of .\n\nIn 1980, it was described as follows: The main feature, and reason for dedication of the park, is an undisturbed bog consisting of a dense mat of the rare coral fern (\"Gleichenia microphylla\") and a sizeable colony of mature king fern (\"Todea barbara\"), an endangered species in South Australia. These specimens are amongst the finest in the state. An excellent bog habitat surrounded by \"Eucalyptus obliqua\" open forest over an open shrub stratum of \"Exocarpos cupressiformis\", \"Banksia marginata\" and \"Pultenaea daphnoides\". A dense ground stratum consists of a wide variety of herbs, grasses and forbs. There are many fallen logs in various stages of decay together with a substantial accumulation of forest litter. The park is substantially undisturbed and surrounded by native vegetation on three sides. This area has not been burnt since 1920, and suffers only minor influence from introduced species.\n\nThe conservation park is classified as an IUCN Category III protected area. In 1980, it was listed on the now-defunct Register of the National Estate.\n\n \n"}
{"id": "49419155", "url": "https://en.wikipedia.org/wiki?curid=49419155", "title": "Flywheel storage power system", "text": "Flywheel storage power system\n\nA flywheel-storage power system uses a flywheel for energy storage, (see Flywheel energy storage) and can be a comparatively small storage facility with a peak power of up to 20 MW. It typically is used to stabilize to some degree power grids, to help them stay on the grid frequency, and to serve as a short-term compensation storage. Unlike common storage power plants, such as the pumped storage power plants with capacities up to 1000 MW, the benefits from flywheel storage power plants can be obtained with a facility in the range of a few kW to several 10 MW. They are comparable in this application with battery storage power plants.\n\nPossible areas of application are places where electrical energy can be obtained and stored, and must be supplied again to compensate for example, fluctuations in the seconds range in wind or solar power. These storage facilities consist of individual flywheels in a modular design. Energy up to 150 kW can be absorbed or released per flywheel. Through combinations of several such flywheel accumulators, which are individually housed in buried underground vacuum tanks, a total power of up to several 10 MW can be achieved. The electrical connections power low voltage motors via a DC intermediate circuit and the power converter systems are comparable to those found in plants used in the high-voltage direct current transmissions application. \n\nSometimes battery storage power stations are built with flywheel storage power systems in order to conserve battery power. Flywheels can handle rapid fluctuations better.\n\nIn vehicles small storage of power flywheels are used as an additional mechanism with batteries, to store the braking energy by regeneration. Power can be stored in the short term and then released back into the acceleration phase of a vehicle with very large electrical currents. This conserves battery power. \n\nFlywheel storage for trams are a good application. During braking (such as when arriving at a station), high energy peaks are found which can not be always fed back into the power grid due to overloading danger. The flywheel energy storage power plants are in containers on side of the tracks and take the excess electrical energy. For example, up to 200 000 kWh energy per brake system are annually recovered in Zwickau.\n\nIn Stephentown, New York, Beacon Power operates in a flywheel storage power plant with 200 flywheels of 25 kWh capacity and 100 kW of power. Ganged together this gives 5 MWh capacity and 20 MW of power. The units operate at a peak speed at 15,000 rpm. The rotor flywheel consists of wound CFRP fibers which are filled with resin. The installation is intended primarily for frequency control. This service is sold to the New York power grid.\n\nStadtwerke München (SWM, Munich, Germany) uses a flywheel storage power system to stabilize the power grid, as well as control energy and to compensate for deviations from renewable energy sources. The plant originates from the Jülich Stornetic GmbH. The system consists of 28 flywheels and has a capacity of 100 kWh and a capacity of 600 kilovolt-amperes (kVA). The flywheels rotate at a peak speed of 45,000 rpm.\n\nIn Ontario, Canada, Temporal Power Ltd. has operated a flywheel storage power plant since 2014. It consists of 10 flywheels made of steel. Each flywheel weighs four tons and is 2.5 meters high. The maximum rotational speed is 11,500 rpm. The maximum power is 2 MW. The system is used for frequency regulation. After a successful three-year trial period, the system is to be expanded to 20 MW and 100 MW.\n\nThe city of Fresno in California is running flywheel storage power plants built by Amber Kinetics to store solar energy, which is produced in excess quantity in the daytime, for consumption at night. \n\nOn the island of Aruba is currently a 5 MW flywheel storage power plant built by Temporal Power Ltd. The island of Aruba intends to convert its energy supply to 100 percent renewables by 2020.\n\nIt is now (since 2013) possible to build a flywheel storage system that loses just 5 percent of the energy stored in it, per day (i.e.the self-discharge rate).\n\n"}
{"id": "44208525", "url": "https://en.wikipedia.org/wiki?curid=44208525", "title": "Geoheritage", "text": "Geoheritage\n\nThe derivation of the term Geoheritage is from \"geological heritage\". It is thus as heritage category comparable to other forms of natural heritage, such as biodiversity. Some geoheritage sites are related to human activity such as mining, and can also be viewed in terms of cultural heritage.\n\n\"Geoheritage\" is also the title of a periodical published by Springer from 2009.\n\nThe first reference to geoheritage as such was at a 1993 conference held in the UK, the Malvern International Conference on Geological and Landscape Conservation (Joyce 1994b; O'Halloran et al. 1994), geoconservation.\n\nThe term geological heritage was first mentioned at the First International Symposium on the Conservation of our Geological Heritage at Digne, France in 1991. The matter is further discussed in 2002 by Sharples.\n\nConceptually, geoheritage derives from various writings of Busby et al. 2001 and Hallam 1989).\n\nIn Sharples 1995 the original concept of geoheritage was further developed to include the protection of dynamic geological processes and geodiversity.\n\nM Brocx & V Semeniuk (Journal of the Royal Society of Western Australia, 90: 53-87, 2007) offer the following definition.\n\nGeoheritage encompasses global, national, statewide, and local features of geology, at all scales\nthat are intrinsically important sites or culturally important sites offering information or insights\ninto the evolution of the Earth; or into the history of science, or that can be used for research,\nteaching, or reference.\n\n“Geotourism is a knowledge -based tourism, an interdisciplinary integration of the tourism industry with conservation and interpretation of abiotic nature attributes, besides considering related cultural issues, within the geosites for the general public”.It is seen around the world through the growth of geoparks as well as independently in many natural and urban areas where tourism’s focus is on the geological environment.\n\nIn Australia, the term geoheritage appeared initially in Bradbury (1993), and Sharples (1993).\n\nIn Australia there are sites which have natural features (such as Fossil Hill at Cliefden Caves, NSW); cultural features (such as the site of the discovery of the first limestone in inland Australia at Cliefden Caves); scenically important sites such as the Three Sisters in the Blue Mountains, of New South Wales, Australia; and indigenous culturally important sites (such as Uluru in the Northern Territory in central Australia).\n\nThe Geological Agency of the Indonesian Energy and Resources Ministry has declared nine geological sites in the province of Yogyakarta in Indonesia. These are:\n\nIn Sleman Regency:\n\n\nIn Bantul Regency:\n\n\nIn Kulon Progo Regency:\n\nIn Gunung Kidul Regency:\n\n\nThe Geological Society of Spain and the Geological and Mining Institute of Spain have produced a list of internationally important geosites (sites of geological interest).\nThis work, which began in 1999, is part of the Global Geosites project promoted by the International Union of Geological Sciences in the 1990s and subsequently supported by UNESCO. Initially, geological contexts were identified (21 such contexts were listed by 2014), and then representative sites within these themes. The list of sites is not a closed one, and there is a mechanism for considering further nominations.\n\nTeide volcano, Tenerife, has been designated a World Heritage Site in part for its geological interest. Some other WHSs in Spain are of geological interest, but were selected for other features. For example, Spain has one of the two sites of the WHS Heritage of Mercury. Almadén and Idrija. However, the criteria by which Almadén was assessed by UNESCO relate to its mining heritage rather than geological interest.\n\n"}
{"id": "34309396", "url": "https://en.wikipedia.org/wiki?curid=34309396", "title": "Groutite", "text": "Groutite\n\nGroutite is a manganese oxide mineral with formula MnO(OH). It is a member of the diaspore group and is trimorphous with manganite and feitknechtite. It forms lustrous black crystals in the orthorhombic system.\n\nIt occurs in weathered banded iron formations, metamorphosed manganese ore bodies and hydrothermal ore environments.\nIt was first described in 1945 for an occurrence in the Mahnomen mine, Cuyuna Range, Crow Wing County, Minnesota and named for petrologist Frank Fitch Grout (1880–1958), of the University of Minnesota.\n"}
{"id": "39011211", "url": "https://en.wikipedia.org/wiki?curid=39011211", "title": "ISTTOK", "text": "ISTTOK\n\nThe ISTTOK Tokamak (\"Instituto Superior Técnico TOKamak\") is a research fusion reactor (tokamak) of the Instituto Superior Técnico. It has a circular cross-section due to a poloidal graphite limiter and an iron core transformer. Its particularity is that it is one of the few tokamaks operating in AC (alternating plasma current) regime, as well in DC regime. In 2013, the AC operation allowed the standard discharges to extend from 35 ms to more than 1s.\n\n\n\n"}
{"id": "10519988", "url": "https://en.wikipedia.org/wiki?curid=10519988", "title": "Ice jam", "text": "Ice jam\n\nIce jams occur on rivers when floating ice accumulates at a natural or man-made feature that impedes its progress downstream. Ice jams can significantly reduce the flow of a river and cause upstream flooding—sometimes called ice dams. Ice jam flooding can also occur downstream when the jam releases in an outburst flood. In either case, flooding can cause damage to structures on shore. \n\nAn ice blockage on a river is usually called an \"ice jam,\" but sometimes an \"ice dam\". An ice jam is an obstruction on a river formed by blocks of ice. Defined by the International Association of Hydraulic Research (IAHR) Working Group on River Ice Hydraulics an ice jam is a \"...a stationary accumulation of fragmented ice or frazil that restricts flow\" on a river or stream. The jam may effectively create a dam with an accumulation of anchor ice on the bottom of the river. On rivers the obstruction may be a change of width, structure, bend or decrease in gradient. \n\nIce jam floods are less predictable and potentially more destructive than open-water flooding and can produce much deeper and faster flooding. Ice jam floods also may occur during freezing weather, and may leave large pieces of ice behind, but they are much more localized than open-water floods. Ice jams also damage an economy by causing river-side industrial facilities such as hydro-electric generating stations to shut down and to interfere with ship transport. The United States averages 125 million dollars in losses to ice jams per year.\n\nIce jams on rivers usually occur in the springtime as the river ice begins to \"break up\", but may also occur in early winter during \"freeze-up\". The break-up process is described in three phases: pre-break-up, break-up and final drive. \"Pre-break-up\" usually begins with increased springtime river flow, water level, and temperatures fracturing the river ice and separating it from the shore. Changes in river height from dam releases may also affect the pre-break-up. During the \"break-up\", the ice in areas of rapids is carried downstream as an ice floe and may jam on still frozen sections of ice on calm water or against structures in the river such as the Honeymoon Bridge, destroyed in 1938 by an ice jam. Smaller jams may dislodge, flow downstream and form a larger jam. During the \"final drive\", a large jam will dislodge and take out the remaining jams, clearing the river of ice in a matter of hours. Ice jams usually occur in spring, but they can happen as winter sets in when the downstream part becomes frozen first. Freeze-up jams may be larger because the ice is stronger and temperatures are continuing to cool unlike a spring break-up when the environment is warming, but are less likely to suddenly release water.\n\nThree types of natural ice jams can occur:\n\nIce jams also occur at sharp bends in the river, at man-made objects such as bridge piers, and at confluences.\n\nIn the northern hemisphere, northerly flowing rivers tend to have more ice jams because the upper, more southerly reaches thaw first and the ice gets carried downstream into the still-frozen northerly part. There are three physical hazards of ice jams. The ice floe can form a dam that floods the areas upstream of the jam. This occurred during the 2009 Red River Flood and the 2009 Alaska floods. As the ice jam breaks apart, a sudden surge of water breaking through can then flood areas downstream of the jam. The third hazard is that the ice buildup and final drive may damage structures in or near the river and boats in the river.\n\nIce jams may scour the river bed, causing damage or benefit to wildlife habitats and possibly damage to structures in the river.\n\nEarly warnings of an ice jam include using trained observers to monitor break-up conditions and ice motion detectors.\n\nThe prevention of ice jams may be accomplished by\n\nWhere floods threaten human habitation, the blockage may be artificially cleared. Ice blasting using dynamite may be used, except in urban areas, as well as other mechanical means such as excavation equipment, or permanent measures such as ice control structures and flood control. Occasionally, military aircraft have been used to bomb ice jams with limited success as part of an effort to clear them.\n\n\n"}
{"id": "42413857", "url": "https://en.wikipedia.org/wiki?curid=42413857", "title": "Kate's Well", "text": "Kate's Well\n\nSt. Catherine's Well or Kate's Well is a historical natural spring well of significant interest and sits on holy ground, at the foot of Kirk O' Shott's Parish Church, otherwise known as (Shottskirk) in the village of Salsburgh, North Lanarkshire. The well dates back to the 14th century, and derives from the Churches former past when it was once a Catholic place of worship as St. Catherines Chapel, which has origins from Catherine of Sienna.\n\nThe water runs off from nearby hills and has a jovial longstanding joke within the nearby village of how the water runs through the Shottskirk cemetery bodies, which of course is neither true or founded.\n\nKate's Well is also the scene of the local legendary giant Bertram de Shotts's demise; a gripping tale is told how a young man, namely Willielmo De Muirhead, 1st Laird of Muirhead, killed the Giant. With cunning patience he ambushed Bertram de Shotts, immobilising him by slicing both his hamstrings as he lay down to drink at Kate's Well. Disorientated, Bertram de Shotts was then decapitated in an unpleasant death. A proud, and now wealthy, De Muirhead then carried the blooded head to the King and was rewarded with a 'Hawk's Flight' of land. This land subsequently became Muirhead's Lauchope estate.\n\nThe well itself received a much needed boost through a grant organized thanks to the local Community Council group in the early 2000s, which allowed its extensive renovation.\n\n"}
{"id": "13068602", "url": "https://en.wikipedia.org/wiki?curid=13068602", "title": "Kodiak–Bowie Seamount chain", "text": "Kodiak–Bowie Seamount chain\n\nThe Kodiak–Bowie Seamount chain, also called the Pratt–Welker Seamount chain and the Kodiak Seamounts, is a seamount chain in southeastern Gulf of Alaska stretching from the Aleutian Trench in the north to Bowie Seamount, the youngest volcano in the chain, which lies west of the Queen Charlotte Islands, British Columbia, Canada. The oldest volcano in the chain is the Kodiak Seamount. Although the Kodiak Seamount is the oldest extant seamount in the Kodiak-Bowie chain, the adjacent lower slope contains transverse scars indicating earlier subduction of seamounts.\n\nThe Kodiak–Bowie Seamount chain are mostly extinct volcanoes that formed above the Bowie hotspot. This is a 100-to-150-km-wide morphological swell presumably of thickened hotspot generated crust, although there are no seismic refraction data across the swell to define crustal thickness. The crest of one such peak, Patton Seamount originally formed off Washington state as a submerged volcano 33 million years ago. Over time, as the Pacific Plate moved steadily northwest, Patton Seamount was carried off the Bowie hotspot and into the Gulf of Alaska. New volcanoes were formed one after another over the hotspot, creating the Kodiak–Bowie Seamount chain.\n\nExplorations of the Kodiak–Bowie Seamount chain have shown that despite the fact that most of the seamounts were created by the Bowie hotspot, all are unique in their size, shape, and volcanic features. The seamounts teem with deep-sea corals, sponges, and fish. Recent expeditions to these seamounts using manned submersibles and ROVs have discovered many marine species and have greatly expanded the knowledge of the range of deep sea corals in this region. For example, the Bowie Seamount is a biologically rich area with a dynamic and productive ecosystem. Because of this unique biological rich area, Bowie Seamount was declared a Pilot Marine Protected Area on December 8, 1998.\n\nThe Kodiak–Bowie seamount chain is at the northern triple junction between the Pacific, North American, and Juan de Fuca plates. Available age determinations on Kodiak and Giacomini Seamounts give an approximate average rate of movement along the chain of per year.\n\nVolcanoes in the chain include:\n\n"}
{"id": "52638116", "url": "https://en.wikipedia.org/wiki?curid=52638116", "title": "LONGi Green Energy Technology", "text": "LONGi Green Energy Technology\n\nLONGi Green Energy Technology, formerly Xi'an Longi Silicon Materials Corporation, is one of the six major Chinese manufacturers of photovoltaics and a developer of solar projects. Longi is the world largest manufacturer of monocrystalline silicon wafers and is listed on the Shanghai Stock Exchange.\n\nThe company was founded February 14, 2000 as Xi'an LONGi Silicon Materials Corporation, with its corporate headquarters in Xian, China. It changed its name in February 2017 to LONGi Green Energy Technology Co Ltd. to better reflect its wider manufacturing scope after its acquisition of LERRI. It also dropped the Xi'an location as part of the name.\n\n\nLONGI Silicon Materials is engaged in the research, manufacture and distribution of monocrystalline ingots. It is the world's largest silicon single crystal manufacturer. It has rapidly broken world solar efficiency records three times within five months. Fast Company listed Xi'an LONGi Silicon Materials one among \"Most Innovative Companies 2013\" \"For supplying the solar industry with high-quality silicon wafers at low cost.\" LONGi Solar, a subsidiary of LONGI Green Energy Technology, recently achieved a new industry record with 23.6% conversion efficiency with its P-type monocrystalline PERC (passivated emitter rear cell) solar cells, toward which an increasing number of manufacturers worldwide are migrating. The technique involves taking a silicon wafer, typically 1 to 2 mm thick, and making a multitude of parallel, transverse slices across the wafer, creating a large number of slivers that have a thickness of 50 micrometres and a width equal to the thickness of the original wafer. These slices are rotated 90 degrees, so that the surfaces corresponding to the faces of the original wafer become the edges of the slivers. The result is to convert, for example, a 150 mm diameter, 2 mm-thick wafer having an exposed silicon surface area of about 175 cm per side into about 1000 slivers having dimensions of 100 mm × 2 mm × 0.1 mm, yielding a total exposed silicon surface area of about 2000 cm per side. The electrical doping and contacts that had been on the face of the wafer are now located at the edges of the sliver, rather than at the front and rear as in the case of conventional wafer cells, as a result of this rotation. This results in making the cell sensitive on both sides, from both the front and rear of the cell (a property known as \"bifaciality\"). Such results need to be certified by a reliable and trusted external agency, and this accomplishment has been analyzed and certified by China's National Center of Supervision and Inspection on Solar Photovoltaic Product Quality (CPVT).\n\nLONGi claimed in October 2017 that they had achieved the record for a monocrystalline solar cell with a conversion efficiency (23.6%) higher than previously thought possible for a PERC cell. In early 2018 they announced a new efficiency record of 23.6%.\n\nIn December 2017, LONGi reported a record bifaciality reading of 82.15% for its ‘Hi-MO2’ mono PERC bifacial module. The company's strategic plan is to triple to 45GW by 2020 its capacity to produce monocrystalline ingots and wafers.\n\nLongi Silicon is a member of the Silicon Module Super League (SMSL), which had been a group of big-six c-Si module suppliers in the solar PV industry today until Longi was admitted. The other six members of the SMSL group are Canadian Solar, Hanwha Q CELLS, JA Solar, Jinko Solar, Trina Solar, and GCL.\n\nLongi Silicon has been listed on the Shanghai Stock Exchange (security code: 601012) since April 2012.\n\nLONGi has been called the fastest growing PV manufacturer in the industry. LONGi annual revenue in 2013 was derived entirely from selling around US$330 million of mono c-Si wafers, but by 2016 that annual revenue had skyrocketed to approximately US$1.67 billion. That was a nearly 94% increase over the 2015 fiscal year, which had itself generated a revenue growth of around 61% over the year before.\n\nLONGi has plants in China, India, and Malaysia, and has acquired production facilities from other companies, including from US manufacturer SunEdison. \"See SunEdison.\" However, Photon.Info reports that Longi Green Energy is mulling an open manufactory in the USA. Further, in a lengthy article in \"PV Magazine\" Longi Silicon and Zhonghuan Semiconductor announce their shared plans for over 10GW of new expansion of additional capacity increases for their mono-crystalline products. Additionally, Longi and ET Solar announced on 25 July, 2017, the establishment of their joint venture to explore overseas markets.\n\nIn March 2018, LONGi announced an agreement to develop a major solar manufacturing hub in Saudi Arabia to support the Kingdom’s plans to install 200GW of solar power plants in Kingdom of Saudi Arabia (KSA). Their ‘Solar-for-Solar” strategy for this development is historic in that it avoids the long smokestack criticism by \"building the manufacturing plants that would be powered entirely by solar energy to provide the lowest manufacturing carbon footprint.\"\n\n\n"}
{"id": "23825615", "url": "https://en.wikipedia.org/wiki?curid=23825615", "title": "List of Hawaii tornadoes", "text": "List of Hawaii tornadoes\n\nThe islands of Hawaii, situated in the Pacific Ocean, rarely experience tornadoes, averaging about one per year. The state ranks as the 48th most active in terms of touch downs, with 40 confirmed tornadoes since 1950. None of these tornadoes have caused loss of life and none exceeded F2 intensity. This list of tornadoes in the state is likely incomplete, as official records date back only to 1950 for tornadoes in the United States, and Hawaii did not become a state until August 1959.\n\nThe most costly tornado occurred on January 28, 1971. Although the intensity of it is unknown, damages from the tornado were estimated at $2.5 million. The largest outbreak of tornadoes took place during a two-day span, starting on January 27, 1971 and ending the following day. During this event, three tornadoes were confirmed and two others were reported.\n\n\n\n\n"}
{"id": "20817144", "url": "https://en.wikipedia.org/wiki?curid=20817144", "title": "List of Indian state trees", "text": "List of Indian state trees\n\nIndia, officially the Republic of India is a country in South Asia. It is made up of 29 states and 7 union territories. All Indian states have their own government and the Union territories come under the jurisdiction of the Central Government. As most of the other countries India too has a national emblem—the Lion Capital of Sarnath.\n\nApart from India's national emblem, each of its States and Union Territories have their own state seals and symbols which include state animals, birds, trees, flowers etc. A list of state trees of India is given below. See Symbols of Indian states and territories for a complete list of all State characters and seals.\n\n\n"}
{"id": "3301826", "url": "https://en.wikipedia.org/wiki?curid=3301826", "title": "List of Lepidoptera that feed on Vaccinium", "text": "List of Lepidoptera that feed on Vaccinium\n\nVaccinium species are used as food plants by the larvae of a number of Lepidoptera species, including:\n\nSpecies which feed exclusively on \"Vaccinium\"\n\n\nSpecies which feed on \"Vaccinium\" and other plants\n\n\n"}
{"id": "58336775", "url": "https://en.wikipedia.org/wiki?curid=58336775", "title": "List of Pandanus species", "text": "List of Pandanus species\n\nThis is a list of species in the genus \"Pandanus\".\n\n"}
{"id": "44756", "url": "https://en.wikipedia.org/wiki?curid=44756", "title": "List of national parks of Sweden", "text": "List of national parks of Sweden\n\nNational parks of Sweden are managed by the Swedish Environmental Protection Agency (EPA) () and owned by the state. The goal of the national park service is to create a system of protected areas that represent all the distinct natural regions of the country. In 1909, Sweden became the first country in Europe to establish such parks when nine were opened following the Riksdag passing of a law on national parks that year. This was followed by the establishment of seven parks between 1918 and 1962 and thirteen between 1982 and 2009, with the latest being Kosterhavet National Park. There are currently 29 national parks in Sweden, comprising a total area of 731,589 hectares (1,807,796 acres); six more are scheduled to open by 2013.\n\nAccording to the EPA, Swedish national parks must represent unique landscape types and be effectively protected and used for research, recreation, and tourism without damaging nature. Mountain terrain dominates approximatively 90% of the parks' combined area. The reason for this is the extensive mountain areas taken up by the large northern parks—Sarek National Park and Padjelanta National Park each cover approximately . Many of the northern parks are part of the Laponian area, one of Sweden's UNESCO World Heritage Sites due to its preserved natural landscape and habitat for the native reindeer-herding Sami people. The southernmost parks—Söderåsen National Park, Dalby Söderskog National Park and Stenshuvud National Park—are covered with broadleaf forest and together cover approximately . Fulufjället National Park is part of PAN Parks, a network founded by the World Wildlife Fund (WWF) to provide better long-term conservation and tourism management of European national parks.\n\nIn 2008, after investigations and interviews with the participating counties, the Swedish Environmental Protection Agency laid down a plan to establish 13 new national parks in the near future. According to the plan, seven of the parks will be established between 2009 and 2013, the first being Kosterhavet National Park which was inaugurated in September 2009. It is currently unknown when the six remaining parks will be established.\n\n"}
{"id": "24890561", "url": "https://en.wikipedia.org/wiki?curid=24890561", "title": "List of national trees", "text": "List of national trees\n\nThis is a list of national trees, most official, but some unofficial:\n\n"}
{"id": "22491380", "url": "https://en.wikipedia.org/wiki?curid=22491380", "title": "List of rivers of the Republic of the Congo", "text": "List of rivers of the Republic of the Congo\n\nThis is a list of rivers in the Republic of the Congo. This list is arranged by Drainage basin, with respective tributaries indented under each larger stream's name.\n\n\n"}
{"id": "3187768", "url": "https://en.wikipedia.org/wiki?curid=3187768", "title": "List of species used in bonsai", "text": "List of species used in bonsai\n\nList of species commonly used in bonsai.\n\n\n"}
{"id": "8591458", "url": "https://en.wikipedia.org/wiki?curid=8591458", "title": "List of stars in Corvus", "text": "List of stars in Corvus\n\nThis is the list of notable stars in the constellation Corvus, sorted by decreasing brightness.\n\n\n"}
{"id": "1643621", "url": "https://en.wikipedia.org/wiki?curid=1643621", "title": "List of wort plants", "text": "List of wort plants\n\nThis is an alphabetical listing of wort plants, meaning plants that employ the syllable \"wort\" in their English-language common names.\n\nAccording to the Oxford English Dictionary's Ask Oxford site, \"A word with the suffix \"-wort\" is often very old. The Old English word was \"wyrt\", from Proto-Indo-European origins that connect it to \"root\". It was often used in the names of herbs and plants that had medicinal uses, the first part of the word denoting the complaint against which it might be specially efficacious. By the middle of the 17th-century \"-wort\" was beginning to fade from everyday use.\n\nThe \"Naturalist Newsletter\" states, \"\"Wort\" derives from the Old English \"wyrt\", which simply meant \"plant\". The word goes back even further, to the common ancestor of English and German, to the Germanic \"wurtiz\". \"Wurtiz\" also evolved into the modern German word \"Wurzel\", meaning \"root\".\"\n"}
{"id": "16407485", "url": "https://en.wikipedia.org/wiki?curid=16407485", "title": "Lists of Dungeons &amp; Dragons monsters", "text": "Lists of Dungeons &amp; Dragons monsters\n\nThis is intended to be a comprehensive list of creatures that have appeared in various \"Dungeons & Dragons\" works. Each individual list covers a span of years by edition of the game, with monsters being listed chronologically by book in which they appeared.\n\nAlthough efforts have been made to include all creatures, there are likely to be omissions and other errors. At any particular time, there will be variations in the level of brief detail, and there are some duplications, not all of which are errors as there are some name duplications amongst the creatures.\n\nThe original edition of \"Dungeons & Dragons\" consisted of a boxed set by Gary Gygax and Dave Arneson printed in 1974, and several pamphlet-sized supplements printed through 1976. The volume \"Monsters & Treasure\" in the original set, and the supplements (\"Greyhawk\", \"Blackmoor\" and \"Eldritch Wizardry\") included a section of monsters.\n\n\nThis edition of Dungeons & Dragons began in 1981, as a revision of the introductory \"Dungeons & Dragons Basic Set\" established it as a separate version of the game that ran concurrently with both 1st edition and 2nd edition \"Advanced Dungeons & Dragons\" until the line was ended in 1994. The Basic Rulebook collected many of the monsters from the previous D&D supplements, and the subsequent \"Basic Set\", \"Expert Set\", \"Companion Set\", \"Master Set\", and \"Immortals Set\" all added more new monsters to the game. The Creature Catalogue expanded on these sets even further, collecting monsters that had appeared in basic D&D modules and adding new monsters as well.\n\n\nIntroduced in 1977, the \"Advanced Dungeons & Dragons\" game built upon the original edition of \"D&D\". This edition also introduced the concept of a \"Monster Manual\", a separate book to deal with just monsters. The original \"Monster Manual\" collected the monsters from the original D&D books, and other sources, and expanded on the monster format. The original \"Fiend Folio\" and \"Monster Manual II\" were also printed during the run of \"AD&D\" 1st edition, and numerous monsters appeared in other modules and game supplements at the time.\n\n\nInitially, the 2nd edition of \"AD&D\" replaced the idea of a hardbound \"Monster Manual\" with a loose-leaf \"Monstrous Compendium\" series that eventually numbered 14 volumes. These volumes greatly expanded the detail level on the previous edition's monsters, and returned most of the 1st edition monsters to the game. Due to popular demand (as the format was considered too fragile and unwieldy), the \"Monstrous Compendium\" series eventually ended and was replaced with the 384-page \"Monstrous Manual\" in 1993, which reprinted many of the creatures previously featured in the \"Monstrous Compendium\" series. This book was followed up by four \"Monstrous Compendium Annuals\" in the following years, and many new monsters were introduced in game modules and supplements throughout 2nd edition.\n\n\nA new \"Monster Manual\" was published in 2000 as part of the core rulebooks for \"D&D\" 3rd edition. The monster format was greatly altered to match the new edition. Just like with 1st edition, this edition included a \"Fiend Folio\" and \"Monster Manual II\", and debuted many new monsters in various game supplements.\n\n\nThe version 3.5 rules included a revision of the 3rd edition \"Monster Manual\", and continued the \"Monster Manual\" series with books III-V. As with previous versions of the game, a number of new monsters debuted in a variety of game supplements in this era.\n\n\n\n"}
{"id": "13473147", "url": "https://en.wikipedia.org/wiki?curid=13473147", "title": "Lyotropic liquid crystal", "text": "Lyotropic liquid crystal\n\nA liquid crystalline mesophase is called lyotropic (a portmanteau of lyo- \"dissolve\" and -tropic \"change\" ) if formed by dissolving an amphiphilic mesogen in a suitable solvent, under appropriate conditions of concentration, temperature and pressure. A mixture of soap and water is an everyday example of a lyotropic liquid crystal.\n\nHistorically, the term was used to describe the common behavior of materials composed of amphiphilic molecules upon the addition of a solvent. Such molecules comprise a water-loving hydrophilic head-group (which may be ionic or non-ionic) attached to a water-hating, hydrophobic group.\n\nThe micro-phase segregation of two incompatible components on a nanometer scale results in different type of solvent-induced extended anisotropic arrangement, depending on the volume balances between the hydrophilic part and hydrophobic part. In turn, they generate the long-range order of the phases, with the solvent molecules filling the space around the compounds to provide fluidity to the system.\n\nIn contrast to thermotropic liquid crystals, lyotropics liquid crystals have therefore an additional degree of freedom, that is the concentration that enables them to induce a variety of different phases. As the concentration of amphiphilic molecules is increased, several different type of lyotropic liquid crystal structures occur in solution. Each of these different types has a different extent of molecular ordering within the solvent matrix, from spherical micelles to larger cylinders, aligned cylinders and even bilayered and multiwalled aggregates.\n\nExamples of amphiphilic compounds are the salts of fatty acids, phospholipids. Many simple amphiphiles are used as detergents. A mixture of soap and water is an everyday example of a lyotropic liquid crystal.\n\nBiological structures such as fibrous proteins showings relatively long and well-defined hydrophobic and hydrophilic ‘‘blocks’’ of aminoacids can also show lyotropic liquid crystalline behaviour.\n\nA typical amphiphilic flexible surfactant can form aggregates through a self-assembly process that results of specific interactions between the molecules of the amphiphilic mesogen and those of the non-mesogenic solvent.\n\nIn aqueous media, the driving force of the aggregation is the \"hydrophobic effect\". The aggregates formed by amphiphilic molecules are characterised by structures in which the hydrophilic head-groups expose their surface to aqueous solution, shielding the hydrophobic chains from contact with water.\n\nFor most lyotropic systems aggregation occurs only when the concentration of the amphiphile exceeds a critical concentration (known variously as the critical micelle concentration (CMC) or the critical aggregation concentration (CAC)).\n\nAt very low amphiphile concentration, the molecules will be dispersed randomly without any ordering. At slightly higher (but still low) concentration, above the CMC, self-assembled amphiphile aggregates exist as independent entities in equilibrium with monomeric amphiphiles in solution, but with no long ranged orientational or positional (translational) order. As a result, phases are isotropic (i.e. not liquid crystalline). These dispersions are generally referred to as 'micellar solutions', often denoted by the symbol L, while the constituent spherical aggregates are known as 'micelles'.\n\nAt higher concentration, the assemblies will become ordered. True lyotropic liquid crystalline phases are formed as the concentration of amphiphile in water is increased beyond the point where the micellar aggregates are forced to be disposed regularly in space. For amphiphiles that consist of a single hydrocarbon chain the concentration at which the first liquid crystalline phases are formed is typically in the range 25–30 wt%.\n\nThe simplest liquid crystalline phase that is formed by spherical micelles is the 'micellar cubic', denoted by the symbol I. This is a highly viscous, optically isotropic phase in which the micelles are arranged on a cubic lattice. At higher amphiphile concentrations the micelles fuse to form cylindrical aggregates of indefinite length, and these cylinders are arranged on a long-ranged hexagonal lattice. This lyotropic liquid crystalline phase is known as the 'hexagonal phase', or more specifically the 'normal topology' hexagonal phase and is generally denoted by the symbol H.\n\nAt higher concentrations of amphiphile the 'lamellar phase' is formed. This phase is denoted by the symbol L and can be considered the lyotropic equivalent of a smectic A mesophase. This phase consists of amphiphilic molecules arranged in bilayer sheers separated by layers of water. Each bilayer is a prototype of the arrangement of lipids in cell membranes.\n\nFor most amphiphiles that consist of a single hydrocarbon chain, one or more phases having complex architectures are formed at concentrations that are intermediate between those required to form a hexagonal phase and those that lead to the formation of a lamellar phase. Often this intermediate phase is a bicontinuous cubic phase.\n\nIn principle, increasing the amphiphile concentration beyond the point where lamellar phases are formed would lead to the formation of the inverse topology lyotropic phases, namely the inverse cubic phases, the inverse hexagonal columnar phase (columns of water encapsulated by amphiphiles, (H) and the inverse micellar cubic phase (a bulk liquid crystal sample with spherical water cavities). In practice inverse topology phases are more readily formed by amphiphiles that have at least two hyrocarbon chains attached to a headgroup. The most abundant phospholipids that are found in cell membranes of mammalian cells are examples of amphiphiles that readily form inverse topology lyotropic phases.\n\nEven within the same phases, self-assembled structures are tunable by the concentration: For example, in lamellar phases, the layer distances increase with the solvent volume. Since lyotropic liquid crystals rely on a subtle balance of intermolecular interactions, it is more difficult to analyze their structures and properties than those of thermotropic liquid crystals.\n\nThe objects created by the amphiphiles are usually spherical (as in the case of micelles), but may also be disc-like (bicelles), rod-like, or biaxial (all three micelle axes are distinct). These anisotropic self-assembled nano-structures can then order themselves in much the same way as thermotropic liquid crystals do, forming large-scale versions of all the thermotropic phases (such as a nematic phase of rod-shaped micelles).\n\nIt is possible that specific molecules are dissolved in lyotropic mesophases, where they can be located mainly inside, outside, or at the surface of the aggregates.\n\nSome of such molecules act as dopants, inducing specific properties to the whole phase, other ones can be considered simple guests with limited effect on the surrounding environment but possibly strong consequences on their physico-chemical properties, and some of them are used as probe to detect molecular-level properties of the whole mesophase in specific analytical techniques.\n\nThe term lyotropic has also been applied to the liquid crystalline phases that are formed by certain polymeric materials, particularly those consisting of rigid rod-like macromolecules, when they are mixed with appropriate solvents. Examples are suspensions of rod-like viruses such as the Tobacco Mosaic Virus as well as man-made colloidal suspensions of non-spherical colloidal particles. Other examples include DNA and Kevlar, which dissolve in sulfuric acid to give a lyotropic phase. It is noted that in these cases the solvent acts to lower the melting point of the materials thereby enabling the liquid crystalline phases to be accessible. These liquid crystalline phases are closer in architecture to thermotropic liquid crystalline phases than to the conventional lyotropic phases. In contrast to the behaviour of amphiphilic molecules, the lyotropic behaviour of the rod-like molecules does not involve self-assembly.\n\n"}
{"id": "1166647", "url": "https://en.wikipedia.org/wiki?curid=1166647", "title": "Magnetic reconnection", "text": "Magnetic reconnection\n\nMagnetic reconnection is a physical process occurring in highly conducting plasmas in which the magnetic topology is rearranged and magnetic energy is converted to kinetic energy, thermal energy, and particle acceleration. Magnetic reconnection occurs on timescales intermediate between slow resistive diffusion of the magnetic field and fast Alfvénic timescales.\n\nAccording to simple resistive magnetohydrodynamics (MHD) theory, reconnection happens because the plasma's electrical resistivity near the boundary layer opposes the currents necessary to sustain the change in the magnetic field. The need for such a current can be seen from one of Maxwell's equations,\n\nThe resistivity of the current layer allows magnetic flux from either side to diffuse through the current layer, cancelling outflux from the other side of the boundary. When this happens, the plasma is pulled out by magnetic tension along the direction of the magnetic field lines. The resulting drop in pressure pulls more plasma and magnetic flux into the central region, yielding a self-sustaining process.\n\nA current problem in plasma physics is that observed reconnection happens much faster than predicted by MHD in high Lundquist number plasmas (i.e. fast magnetic reconnection). Solar flares, for example, proceed 13-14 orders of magnitude faster than a naive calculation would suggest, and several orders of magnitude faster than current theoretical models that include turbulence and kinetic effects. One possible mechanism to explain the discrepancy is that the electromagnetic turbulence in the boundary layer is sufficiently strong to scatter electrons, raising the plasma's local resistivity. This would allow the magnetic flux to diffuse faster.\n\nThe qualitative description of the reconnection process is such that magnetic field lines from different magnetic domains (defined by the field line connectivity) are spliced to one another, changing their patterns of connectivity with respect to the sources. It is a violation of an approximate conservation law in plasma physics, called the Alfvén's Theorem, and can concentrate mechanical or magnetic energy in both space and time. Solar flares, the largest explosions in the Solar System, may involve the reconnection of large systems of magnetic flux on the Sun, releasing, in minutes, energy that has been stored in the magnetic field over a period of hours to days. Magnetic reconnection in Earth's magnetosphere is one of the mechanisms responsible for the aurora, and it is important to the science of controlled nuclear fusion because it is one mechanism preventing magnetic confinement of the fusion fuel.\n\nIn an electrically conductive plasma, magnetic field lines are grouped into 'domains'— bundles of field lines that connect from a particular place to another particular place, and that are topologically distinct from other field lines nearby. This topology is approximately preserved even when the magnetic field itself is strongly distorted by the presence of variable currents or motion of magnetic sources, because effects that might otherwise change the magnetic topology instead induce eddy currents in the plasma; the eddy currents have the effect of canceling out the topological change.\n\nIn two dimensions, the most common type of magnetic reconnection is separator reconnection, in which four separate magnetic domains exchange magnetic field lines. Domains in a magnetic plasma are separated by \"separatrix surfaces\": curved surfaces in space that divide different bundles of flux. Field lines on one side of the separatrix all terminate at a particular magnetic pole, while field lines on the other side all terminate at a different pole of similar sign. Since each field line generally begins at a north magnetic pole and ends at a south magnetic pole, the most general way of dividing simple flux systems involves four domains separated by two separatrices: one separatrix surface divides the flux into two bundles, each of which shares a south pole, and the other separatrix surface divides the flux into two bundles, each of which shares a north pole. The intersection of the separatrices forms a \"separator\", a single line that is at the boundary of the four separate domains. In separator reconnection, field lines enter the separator from two of the domains, and are spliced one to the other, exiting the separator in the other two domains (see the first figure).\n\nIn three dimensions, the geometry of the field lines become more complicated than the two-dimensional case and it is possible for reconnection to occur in regions where a separator does not exist, but with the field lines connected by steep gradients. These regions are known as quasi-sepratrix layers (QSLs), and have been observed in theoretical configurations and solar flares.\n\nThe first theoretical framework of magnetic reconnection was established by Peter Sweet and Eugene Parker at a conference in 1956. Sweet pointed out that by pushing two plasmas with oppositely directed magnetic fields together, resistive diffusion is able to occur on a length scale much shorter than a typical equilibrium length scale. Parker was in attendance at this conference and developed scaling relations for this model during his return travel.\n\nThe Sweet-Parker model describes time-independent magnetic reconnection in the resistive MHD framework when the reconnecting magnetic fields are antiparallel (oppositely directed) and effects related to viscosity and compressibility are unimportant. The initial velocity is simply an formula_2 velocity, so\nwhere formula_4 is the out-of-plane electric field, formula_5 is the characteristic inflow velocity, and formula_6 is the characteristic upstream magnetic field strength. By neglecting displacement current, the low-frequency Ampere's law, formula_7, gives the relation\nwhere formula_9 is the current sheet half-thickness. This relation uses that the magnetic field reverses over a distance of formula_10. By matching the ideal electric field outside of the layer with the resistive electric field formula_11 inside the layer (using Ohm's law), we find that\nwhere formula_13 is the magnetic diffusivity. When the inflow density is comparable to the outflow density, conservation of mass yields the relationship\nwhere formula_15 is the half-length of the current sheet and formula_16 is the outflow velocity. The left and right hand sides of the above relation represent the mass flux into the layer and out of the layer, respectively. Equating the upstream magnetic pressure with the downstream dynamic pressure gives\nwhere formula_18 is the mass density of the plasma. Solving for the outflow velocity then gives\nwhere formula_20 is the Alfvén velocity. With the above relations, the dimensionless reconnection rate formula_21 can then be written in two forms, the first in terms of formula_22 using the result earlier derived from Ohm's law, the second in terms of formula_23 from the conservation of mass as\nSince the dimensionless Lundquist number formula_25 is given by\nthe two different expressions of formula_21 are multiplied by each other and then square-rooted, giving a simple relation between the reconnection rate formula_21 and the Lundquist number formula_25\n\nSweet-Parker reconnection allows for reconnection rates much faster than global diffusion, but is not able to explain the fast reconnection rates observed in solar flares, the Earth's magnetosphere, and laboratory plasmas. Additionally, Sweet-Parker reconnection neglects three-dimensional effects, collisionless physics, time-dependent effects, viscosity, compressibility, and downstream pressure. Numerical simulations of two-dimensional magnetic reconnection typically show agreement with this model. Results from the Magnetic Reconnection Experiment (MRX) of collisional reconnection show agreement with a generalized Sweet-Parker model which incorporates compressibility, downstream pressure and anomalous resistivity.\n\nOne of the reasons why Sweet-Parker reconnection is slow is that the aspect ratio of the reconnection layer is very large in high Lundquist number plasmas. The inflow velocity, and thus the reconnection rate, must then be very small. In 1964, Harry Petschek proposed a mechanism where the inflow and outflow regions are separated by stationary slow mode shocks. The aspect ratio of the diffusion region is then of order unity and the maximum reconnection rate becomes\n\nThis expression allows for fast reconnection and is almost independent of the Lundquist number.\n\nSimulations of resistive MHD reconnection with uniform resistivity showed the development of elongated current sheets in agreement with the Sweet-Parker model rather than the Petschek model. When a localized anomalously large resistivity is used, however, Petschek reconnection can be realized in resistive MHD simulations. Because the use of an anomalous resistivity is only appropriate when the particle mean free path is large compared to the reconnection layer, it is likely that other collisionless effects become important before Petschek reconnection can be realized.\n\nIn the Sweet-Parker model, the common assumption is that the magnetic diffusivity is constant. This can be estimated using the equation of motion for an electron with mass formula_32and electric charge formula_33:\n\nwhere formula_35 is the collision frequency. Since in the steady state, formula_36, then the above equation along with the definition of electric current, formula_37, where formula_38 is the electron number density, yields\n\nNevertheless, if the drift velocity of electrons exceeds the thermal velocity of plasma, a steady state cannot be achieved and magnetic diffusivity should be much larger than what is given in the above. This is called anomalous resistivity, formula_40, which can enhance the reconnection rate in the Sweet-Parker model by a factor of formula_41.\n\nAnother proposed mechanism is known as the Bohm diffusion across the magnetic field. This replaces the Ohmic resistivity with formula_42, however, its effect, similar to the anomalous resistivity, is still too small compared with the observations.\n\nLazarian and Vishniac (1999) considered the magnetic reconnection in the presence of a random component of magnetic field in a totally ionized and inviscid plasma assuming that the resistive effects could be described with an Ohmic resistivity. For the turbulent flow in the reconnection region, a model for magnetohydrodynamic turbulence should be used such as the model developed by Goldreich and Sridhar in 1995. One can imagine that within small scales of the turbulent flow, the Sweet-Parker model is applicable. Lazarian and Vishniac showed that, in general, this cannot affect the final result. In fact, their model is independent of small scale physics which determines the local reconnection rate. According to this model, for a current sheet of the length formula_43, the upper limit for reconnection velocity is given by\n\nwhere formula_45. Here formula_46, and formula_47are turbulence injection length scale and velocity respectively and formula_48is the Alfvén velocity. This model has been successfully tested by numerical simulations.\n\nOn length scales shorter than the ion inertial length formula_49 (where formula_50 is the ion plasma frequency), ions decouple from electrons and the magnetic field becomes frozen into the electron fluid rather than the bulk plasma. On these scales, the Hall effect becomes important. Two-fluid simulations show the formation of an X-point geometry rather than the double Y-point geometry characteristic of resistive reconnection. The electrons are then accelerated to very high speeds by Whistler waves. Because the ions can move through a wider \"bottleneck\" near the current layer and because the electrons are moving much faster in Hall MHD than in standard MHD, reconnection may proceed more quickly. Two-fluid/collisionless reconnection is particularly important in the Earth's magnetosphere.\n\nMagnetic reconnection occurs during solar flares, coronal mass ejections, and many other events in the solar atmosphere. The observational evidence for solar flares includes observations of inflows/outflows, downflowing loops, and changes in the magnetic topology. In the past, observations of the solar atmosphere were done using remote imaging; consequently, the magnetic fields were inferred or extrapolated rather than observed directly. However, the first direct observations of solar magnetic reconnection were gathered in 2012 (and released in 2013) by the High Resolution Coronal Imager.\n\nMagnetic reconnection events that occur in the Earth's magnetosphere (in the dayside magnetopause and in the magnetotail) were observed by spacecrafts such as Cluster II and the Magnetospheric Multiscale Mission. Cluster II is a four-spacecraft mission, with the four spacecraft arranged in a tetrahedron to separate the spatial and temporal changes as the suite flies through space. It has observed numerous reconnection events in which the Earth's magnetic field reconnects with that of the Sun (i.e. the Interplanetary Magnetic Field). These include 'reverse reconnection' that causes sunward convection in the Earth's ionosphere near the polar cusps; 'dayside reconnection', which allows the transmission of particles and energy into the Earth's vicinity and 'tail reconnection', which causes auroral substorms by injecting particles deep into the magnetosphere and releasing the energy stored in the Earth's magnetotail. The Magnetospheric Multiscale Mission, launched on 13 March 2015, improved the spatial and temporal resolution of the Cluster II results by having a tighter constellation of spacecraft. This led to a better understanding of the behavior of the electrical currents in the electron diffusion region.\n\nOn 26 February 2008, THEMIS probes were able to determine the triggering event for the onset of magnetospheric substorms. Two of the five probes, positioned approximately one third the distance to the Moon, measured events suggesting a magnetic reconnection event 96 seconds prior to Auroral intensification. Dr. Vassilis Angelopoulos of the University of California, Los Angeles, who is the principal investigator for the THEMIS mission, claimed, \"Our data show clearly and for the first time that magnetic reconnection is the trigger.\".\n\nMagnetic reconnection have also been observed in numerous laboratory experiments. For example, studies on the LArge Plasma Device (LAPD) at UCLA have observed and mapped quasi-sepratrix layers near the magnetic reconnection region of a two flux rope system, while experiments on the Magnetic Reconnection Experiment (MRX) at the Princeton Plasma Physics Laboratory (PPPL) have confirmed many aspects of magnetic reconnection, including the Sweet-Parker model in regimes where the model is applicable.\n\nThe confinement of plasma in devices such as tokamaks, spherical tokamaks, and reversed field pinches requires the presence of closed magnetic flux surfaces. By changing the magnetic topology, magnetic reconnection degrades confinement by disrupting these closed flux surfaces, allowing the hot central plasma to mix with cooler plasma closer to the wall.\n\n\n\n"}
{"id": "47692268", "url": "https://en.wikipedia.org/wiki?curid=47692268", "title": "Mercury pollution in the ocean", "text": "Mercury pollution in the ocean\n\nMercury is a toxic heavy metal which cycles through atmosphere, water, and soil in various forms to different parts\nof the world. Due to this natural cycle, irrespective of which part of the world releases mercury it could affect an entirely different part of the world making mercury pollution a global concern. Mercury pollution is now identified as a global problem and awareness has been raised on an international action plan to minimize anthropogenic mercury emissions and clean up mercury pollution. The 2002 Global Mercury Assessment concluded that \"International actions to address the global mercury problem should not be delayed”. Among many environments that are under the impact of mercury pollution, the ocean is one which cannot be neglected as it has the ability to act as a “storage closet” for mercury. According to a recent model study the total anthropogenic mercury released into the ocean is estimated to be around 80,000 to 45,000 metric tons and two thirds of this enormous amount is estimated to be found in waters shallower than 1000m level where many consumable fish live. Mercury can get bio-accumulated in marine food chains in the form of highly toxic methyl mercury which can cause health risks to human seafood consumers. According to statistics, about 66% of the global fish consumption comes from ocean. Therefore, it is important to monitor and regulate oceanic mercury levels to prevent more and more mercury reaching human population through seafood consumption.\n\nMercury release occurs by both natural and anthropogenic processes. Natural processes are mainly geogenic such as volcanic activities and land emissions through soil. Volcanoes release mercury from the underground reservoirs upon eruption. Land emissions are usually observed in the regions closer to plate tectonic boundaries where soils are enriched with minerals such as cinnabar containing Mercury sulfide(HgS). This mercury is released by either natural weathering of the rocks or by geothermal reactions. While natural phenomena account for a certain percentage of present-day emissions, anthropogenic emissions alone have increased mercury concentration in the environment by threefold. Global Mercury Assessment 2013 states main anthropogenic sources of mercury emission are artisanal and small - scale gold mining, fossil fuel burning and primary production of non-ferrous metals. Other sources such as cement production, consumer products waste, contaminated sites and chlor-alkali industry also contributes in relatively small percentages.\n\nMercury enters the ocean in different ways. Atmospheric deposition is the largest source of mercury to the oceans. Atmospheric deposition introduces three types of mercury to the ocean. Gaseous elemental mercury (Hg0) enters the ocean through air-water exchange. Inorganic mercury (Hg2+/HgII) and particle-bound mercury (Hg(P)) enters through wet and dry deposition. In addition, mercury enters the ocean via rivers, estuaries, sediments, and, hydrothermal vents etc. These sources also release organic mercury compounds such as Methyl mercury. Once they are in the ocean they can undergo many reactions primarily grouped as; redox reactions (gain or loss of electrons), adsorption processes (binding to solid particles), methylation and demethylation (addition or removal of a methyl group).\n\nMercury can enter seas and the open ocean as a result of the down-stream movement and re-deposition of contaminated sediments from urban estuaries. For example, high total Hg content up to 5 mg/kg and averaging about 2 mg/kg occur in the surface sediments and sediment cores of the tidal River Mersey, UK, due to discharge from historical industries located along the banks of the tidal river including industries such as historical chlor-alkali industry. Sediments along a 100 km stretch of the Thames Estuary have also been shown to have total Hg contents of up to 12 mg/kg and a mean of 2 mg/kg with the highest concentrations found at depth in and around London. A gradual and statistically significant decrease in sedimentary Hg content occurs in the Thames as a results of greater distance from the historical and current point-sources, sorption and in-river deposition in the mud reaches as well as dilution by marine sands from the Southern North Sea. In contrast sediments entering the ocean from the marsh creeks of East Coast USA and mangroves fringing the South China Sea generally have moderate sedimentary Hg (<0.5 mg/kg).\n\nReduction and oxidation of mercury mostly occur closer to the ocean water surface. These are either driven by sunlight or by microbial activity. Under UV radiation, elemental mercury oxidizes and dissolves directly in ocean water or binds to other particles. The reverse reaction reduces some mercury Hg2+ to elemental mercury Hg(0) and returns to the atmosphere. Fine aerosols in the atmosphere such as ocean water droplets can act as small reaction chambers in this process providing the special reaction conditions required. Oxidation and reduction of mercury in the ocean are not very simple reversible reactions. Shown below is the proposed pathway of ocean aerosol mercuric photochemistry suggesting that it occurs through a reactive intermediate:\n\nPhoto oxidation is suspected to be driven by OH. radical and reduction is driven by wind and surface layer disturbances. In the dark, mercury redox reactions continue due to microbial activity. The biological transformations are different and have a smaller rate compared to sunlight driven processes above. Inorganic mercury Hg2+ and methyl mercury has the ability to get adsorbed in to particles. A positive correlation of binding is observed for the amount of organic matter vs. the concentration of these mercury species showing that most of them bind to organic matter. This phenomenon can determine the bioavailability and toxicity of mercury in the ocean. Some methyl mercury is released to the ocean through river run-off. However, most of the methyl mercury found in the ocean is produced in –situ (inside the ocean itself). \nMethylation of inorganic mercury can occur via biotic and abiotic pathways. However, biotic pathways are more predominant. The reactions illustrated in a simplified scheme below are actually parts of complex enzyme driven metabolic pathways taking place inside microbial cells.\n\nIn abiotic reactions, humic substances act as methylating agents and therefore this process occur at shallow sea levels where decomposing organic matter is available to combine with inorganic mercury Hg2+.9 Mercury methylation studies in Polar Regions have also shown a positive correlation between methylation and chlorophyll content in water showing there could also be biogenic pathways for methyl mercury production. Produced methyl mercury gets accumulated in microbes. Due to the high permeability and absence of degradation for methyl mercury in other species that depend on those microbes, this very toxic compound gets biomagnified through marine food chains to the top predators. Human population consumes many types of marine fish who are top predators in the food chains which puts their health in great danger. Therefore, finding possible solutions to minimize further mercury emissions and cleaning up the already existing mercury pollution is extremely important.\n\nOceanic mercury pollution presents a serious threat to human health. The United States Environmental Protection Agency (EPA) states that mercury consumption by people of all ages can result in loss of peripheral vision, weakened muscles, impairment of hearing and speech, and deteriorated movement coordination. Infants and developing children face even more serious health risks because mercury exposure inhibits proper brain and nervous system development, damaging memory, cognitive thinking, language abilities, attention, and fine motor skills. The case of Minamata disease that occurred in Minamata Bay, Japan in the 1950s demonstrated the frightening effects of exposure to extremely high concentrations of mercury. Adult patients experienced extreme salivation, limb deformity, and irreversible dysarthria and intelligence loss. In children and fetuses (exposed to mercury through the mother's consumption of contaminated seafood), extensive brain lesions were observed and the patients experienced more serious effects like cerebral palsy, mental retardation, and primitive reflexes. In order to avoid the toxic effects of mercury exposure, the United States EPA advises a mercury dose limit of 0.1 µg/kg/day.\n\nIn addition to human health, animal health is also seriously threatened by mercury pollution in the ocean. The effects of high mercury levels on animal health were revealed by the severe mercury poisoning in Minamata Bay in which many animals exhibited extremely strange behaviors and high mortality rates after consuming contaminated seafood or absorbing mercury from the seawater. The cat population essentially disappeared due to cats drowning in the ocean and simply collapsing dead and it became commonplace to witness birds falling out of the sky and fish swimming in circles. Low concentrations of mercury compounds were also found to cause irreparable damage to organisms in a study that subjected zebrafish to low levels of methyl mercury and mercuric chloride. The zebrafish experienced a 100% mortality rate after 24 hour exposure to a mercuric chloride concentration of 1000 µg/L and a methylmercury concentration of just 100 µg/L. Additionally, both mercury species generated a decreased hatch rate, tail deformity, and diminished tail movement ability. The fact that even low concentrations of mercury compounds can cause irreparable damage to organisms displays the extreme danger that mercury poses to the environment.\n\nCleaning up the existing mercury pollution could be a tedious process. Nevertheless, there is some promising ongoing research bringing hope to the challenging task. One such research is based nanotechnology. It uses synthesized aluminum oxide nanoparticles (Al2O3) mimicking the coral structures. These structures absorb heavy metal toxins effectively due to high surface/volume ratio and the quality of surface. In nature, it has been long observed corals can absorb heavy metal ions due to its surface structure and this new technique has used to nanotechnology to create “synthetic corals” which may help clean mercury in the ocean. The reactions involved in synthesizing this material are;\n\nAnother novel material (Patent application: PCT/US15/55205) is still under investigation which looks at the possibility of cleaning mercury pollution using orange peels as raw material. This technology produces sulfur limonene polysulphide (proposed material) using sulfur and limonene. Using industrial byproducts to manufacture this polymer makes it a highly sustainable approach.The scientists say 50% of the mercury content could be reduced with a single treatment using this polymer.\n\nIn addition to the cleaning processes, minimizing usage of coal power and shifting to cleaner energy sources, reducing small scale artisanal gold mining, proper treatment of industrial mercury waste, and implementation of policies are sound approaches to reduce mercury emissions in the long term-large scale plan. Public awareness is critical in achieving this goal. Proper disposal of mercury containing items such as medicinal packaging and thermometers, using mercury-free bulbs and batteries, buying consumer products with zero or minimum mercury emission to the environment can make a significant difference in recovering world’s ecosystems from mercury pollution leaving minimum legacy of mercury pollution in the ocean for our future generations.\n\n\n"}
{"id": "14330683", "url": "https://en.wikipedia.org/wiki?curid=14330683", "title": "Ministry of Petroleum and Energy", "text": "Ministry of Petroleum and Energy\n\nThe Royal Norwegian Ministry of Petroleum and Energy () is a Norwegian ministry responsible for energy, including petroleum and natural gas production in the North Sea. It is led by Minister of Petroleum and Energy Terje Søviknes (Progress Party). The department must report to the legislature, the Storting.\n\nThe ministry is divided into the following sections:\n\n\nSubordinate government agencies:\n\nWholly owned limited companies:\n\nPartially owned public limited companies:\n\n"}
{"id": "48598205", "url": "https://en.wikipedia.org/wiki?curid=48598205", "title": "Miraah", "text": "Miraah\n\nMiraah is a solar plant that is under construction for the production of steam in Oman.\nIn July 2015, Petroleum Development Oman and GlassPoint Solar announced that they signed a $600 million agreement to build the 1 GWth solar field. The project will be the world's largest solar field measured by peak thermal capacity.\n\n\nMiraah will be one of the world’s largest solar plants. The solar thermal facility will harness the sun’s energy to produce steam used in oil production. Once complete, it will deliver the largest peak energy output of any solar plant in the world.\n\nThe 1 GWth project will reduce the amount of natural gas used to generate steam for thermal enhanced oil recovery (EOR). In thermal EOR, steam is injected into an oil reservoir to heat the oil, making it easier to pump to the surface. Miraah will generate an average of 6,000 tons of solar steam each day, providing a substantial portion of the steam required at the Amal oilfield operated by Petroleum Development Oman (PDO).\n\nThe mega project dwarfs all previous solar EOR installations and is more than 100 times larger than the pilot project built by GlassPoint for PDO in 2012. The pilot was completed safely, on time and on budget, and has been operating successfully for more than two years. The pilot exceeded PDO’s expectations for steam delivery and system reliability, paving the way for this significant expansion.\n\nThe enclosed trough solar field uses curved mirrors to focus sunlight onto a pipe filled with water. The concentrated sunlight boils the water to create steam, which is fed directly to the oilfield’s existing steam distribution network. The steam generated is exactly the same quality, temperature and pressure as steam produced by burning natural gas.\n\nA glasshouse protects the solar array from harsh oilfield conditions like wind and dust storms. As a result, GlassPoint can use lightweight and inexpensive components inside the glasshouse. Automated washing reduces costs further and preserves scarce water resources.\n\nThe technology is proven and easy to scale by building projects in standard glasshouse modules. GlassPoint’s production-line approach constructs several glasshouses in parallel and commissions them in modules of four for rapid deployment.\n\nIn August 2017, GlassPoint and its contractors crossed the threshold of 1.5 million man-hours worked without lost time injury (LTI) at Miraah.\n\nIn November 2017, GlassPoint and Petroleum Development Oman (PDO) completed construction on the first block of the Miraah solar plant safely on schedule and on budget, and successfully delivered steam to the Amal West oilfield.\n"}
{"id": "26961816", "url": "https://en.wikipedia.org/wiki?curid=26961816", "title": "Monocerotis", "text": "Monocerotis\n\nMonocerotis is the Latin genitive of the constellation name Monoceros.\n\nObjects within the constellation include:\n\n\n\n\n\n"}
{"id": "56899479", "url": "https://en.wikipedia.org/wiki?curid=56899479", "title": "Museums and exhibitions at Mount Olympus", "text": "Museums and exhibitions at Mount Olympus\n\nArchaeological and historical finds, as well as contemporary works of art are displayed in the museums and exhibitions at Mount Olympus.\n\nHere are the finds of the archaeological site of Dion and the surrounding area exhibited. The museum is divided into three floors. In the basement there are coins, pottery and antique building materials. On the ground floor is a small cinema, the exhibition shows mainly finds of the sanctuaries of Dion. Upstairs is the famous water organ, the Hydraulis. There are also changing exhibitions of archaeological finds from the wider area.\n\nIn a separate building, the Archaeotheke, the approximately 100 m² mosaic of the Epiphany of Dionysus is displayed.\n\nThe ground floor of the building houses the offices of archaeologists, the laboratory and workshops, the museum is upstairs. Currently, only a few of the many finds from Pydna, the necropolis of Pydna, Methone, Makrygialos and its surroundings can be seen in the museum. Some smaller, mostly clay exhibits and amphorae, some of which are used as urns or sarcophagi for toddlers, are exhibited. The museum is not open to the public yet.\n\nThe building, built by Greek Macedonians living abroad, deals with the life and work of Alexander the Great. In addition to the permanent exhibition, the building also serves representative purposes.\n\nExhibits of the museum include icons from the 17th century, precious vestments, old wood carvings and books, written and bound by the monks of the monastery. During the liberation struggle against the Ottomans, the monks stored food and ammunition for the militants and cared for the wounded.\n\nHistorical documents, from the document approving the construction of the monastery, to photographs of a soldier of the German Wehrmacht, which show the old monastery shortly before its destruction, prove the past of the monastery. Released in silver are relics, vestments, an epitaph woven with silver threads, documents, books, icons and inlaid pieces of furniture. Above the museum is the library of the monastery, which is not accessible to the public.\n\nInformation boards and models explain the origin and geological structure of the Olympus. Displayed are fossils, any type of stones occurring in the mountains and photographs of geologically significant objects. Special exhibits are fossils of marine animals that were found in the Olympus at an altitude of about 1000 meters.\n\nThe exhibition takes the visitor through all regions of the mountains. Starting from the village Litochoro, the animals and plants of different altitudes are explained by means of display boards in Greek and English language. Interactive screens allow 360° visibility from different locations; a small cinema shows a 3-D movie about the Olympus massif. Furthermore, there is information about archaeological sites, monasteries, mythology, geology and the history of the first ascent of the summit.\n\nThe Nautical Museum was founded to preserve the tradition of the merchant shipping industry. The exhibits are mainly from private ownership, partly from shipowners or the navy. Certificates, logbooks and old photographs are exhibited alongside nautical instruments and nautical objects. A special feature is the replica of the bridge of a merchant ship with all instruments.\n\nDuring the summer months, exhibitions with changing themes take place here as part of the Olympus Festival. Frequently, the respective host country of the Olympus Festival uses the opportunity to present its art and culture here. Occasionally artists from Greece organize exhibitions of their works. You can see mosaics, paintings, photographs, sculptures, prints etc.\n\nThe museum is intended to preserve the culture of the Pontic Greeks, who come from the Black Sea region. On display are furniture, tools, costumes and embroidery. The replica of a typical residential building shows how people lived before their expulsion.\n\nThe exhibition follows the theme Asia Minor. The club shows in his museum pictures, photographs, traditional costumes, uniforms, traditional clothing and items for the daily use, mostly gifted from the refugees of Asia Minor.\n\n\n"}
{"id": "11763521", "url": "https://en.wikipedia.org/wiki?curid=11763521", "title": "Nucleate boiling", "text": "Nucleate boiling\n\nNucleate boiling is a type of boiling that takes place when the surface temperature is hotter than the saturated fluid temperature by a certain amount but where the heat flux is below the critical heat flux. For water, as shown in the graph below, nucleate boiling occurs when the surface temperature is higher than the saturation temperature (T) by between to . The critical heat flux is the peak on the curve between nucleate boiling and transition boiling. The heat transfer from surface to liquid is greater than that in film boiling.\n\nTwo different regimes may be distinguished in the nucleate boiling range. When the temperature difference is between approximately to above T, isolated bubbles form at nucleation sites and separate from the surface. This separation induces considerable fluid mixing near the surface, substantially increasing the convective heat transfer coefficient and the heat flux. In this regime, most of the heat transfer is through direct transfer from the surface to the liquid in motion at the surface and not through the vapor bubbles rising from the surface.\n\nBetween and above T, a second flow regime may be observed. As more nucleation sites become active, increased bubble formation causes bubble interference and coalescence. In this region the vapor escapes as jets or columns which subsequently merge into slugs of vapor.\n\nInterference between the densely populated bubbles inhibits the motion of liquid near the surface. This is observed on the graph as a change in the direction of the gradient of the curve or an inflection in the boiling curve. After this point, the heat transfer coefficient starts to reduce as the surface temperature is further increased although the product of the heat transfer coefficient and the temperature difference (the heat flux) is still increasing.\n\nWhen the relative increase in the temperature difference is balanced by the relative reduction in the heat transfer coefficient, a maximum heat flux is achieved as observed by the peak in the graph. This is the critical heat flux. At this point in the maximum, considerable vapor is being formed, making it difficult for the liquid to continuously wet the surface to receive heat from the surface. This causes the heat flux to reduce after this point. At extremes, film boiling commonly known as the Leidenfrost effect is observed.\nThe process of forming steam bubbles within liquid in micro cavities adjacent to the wall if the wall temperature at the heat transfer surface rises above the saturation temperature while the bulk of the liquid (heat exchanger) is subcooled. The bubbles grow until they reach some critical size, at which point they separate from the wall and are carried into the main fluid stream. There the bubbles collapse because the temperature of bulk fluid is not as high as at the heat transfer surface, where the bubbles were created. This collapsing is also responsible for the sound a water kettle produces during heat up but before the temperature at which bulk boiling is reached.\n\nHeat transfer and mass transfer during nucleate boiling has a significant effect on the heat transfer rate. This heat transfer process helps quickly and efficiently to carry away the energy created at the heat transfer surface and is therefore sometimes desirable—for example in nuclear power plants, where liquid is used as a coolant.\n\nThe effects of nucleate boiling take place at two locations:\n\nThe nucleate boiling process has a complex nature. A limited number of experimental studies provided valuable insights into the boiling phenomena, however these studies provided often contradictory data due to internal recalculation (state of chaos in the fluid not applying to classical thermodynamic methods of calculation, therefore giving wrong return values) and have not provided conclusive findings yet to develop models and correlations. Nucleate boiling phenomenon still requires more understanding.\n\nThe nucleate boiling regime is important to engineers because of the high heat fluxes possible with moderate temperature differences. The data can be correlated by equation of the form,\n\nformula_1\n\nThe Nusselt number is defined as,\n\nformula_2\n\nwhere q/A is the total heat flux, formula_3 is the maximum bubble diameter as it leaves the surface, formula_4 is the excess temperature, formula_5 is the thermal conductivity of the liquid and formula_6 is the Prandtl number of the liquid. The bubble Reynolds number, formula_7 is defined as,\n\nformula_8\n\nWhere formula_9 is the average mass velocity of the vapor leaving the surface and formula_10 is the liquid viscosity.\n\nRohsenow has developed the first and most widely used correlation for nucleate boiling,\n\n<math>\\frac{q}{A}=\n"}
{"id": "23550", "url": "https://en.wikipedia.org/wiki?curid=23550", "title": "Philips", "text": "Philips\n\nKoninklijke Philips N.V. (literally \"Royal Philips\", stylized as PHILIPS) is a Dutch multinational technology company headquartered in Amsterdam currently focused in the area of healthcare and lighting. It was founded in Eindhoven in 1891 by Gerard Philips and his father Frederik, with their first products being light bulbs. It was once one of the largest electronic conglomerates in the world and currently employs around 74,000 people across 100 countries. The company gained its royal honorary title in 1998 and dropped the \"Electronics\" in its name in 2013.\n\nPhilips is organized into two main divisions: Philips Consumer health and well-being (formerly Philips Consumer Electronics and Philips Domestic Appliances and Personal Care) and Philips Professional Healthcare (formerly Philips Medical Systems). The lighting division was spun off as a separate company, Signify N.V. (formerly Philips Lighting prior to 2018). The company started making electric shavers in 1939 under the Philishave brand, and post-war they developed the Compact Cassette format and co-developed the Compact Disc format with Sony, as well as numerous other technologies. As of 2012, Philips was the largest manufacturer of lighting in the world as measured by applicable revenues. \n\nPhilips has a primary listing on the Euronext Amsterdam stock exchange and is a component of the Euro Stoxx 50 stock market index. It has a secondary listing on the New York Stock Exchange. Acquisitions include that of Signetics and Magnavox. They also have had a sports club since 1913 called PSV Eindhoven.\nThe Philips Company was founded in 1891, by Gerard Philips and his father Frederik Philips. Frederik, a banker based in Zaltbommel, financed the purchase and setup of an empty factory building in Eindhoven, where the company started the production of carbon-filament lamps and other electro-technical products in 1892. This first factory has been adapted and is used as a museum.\n\nIn 1895, after a difficult first few years and near bankruptcy, the Philipses brought in Anton, Gerard's younger brother by sixteen years. Though he had earned a degree in engineering, Anton started work as a sales representative; soon, however, he began to contribute many important business ideas. With Anton's arrival, the family business began to expand rapidly, resulting in the founding of Philips Metaalgloeilampfabriek N.V. (Philips Metal Filament Lamp Factory Ltd.) in Eindhoven in 1908, followed in 1912, by the foundation of Philips Gloeilampenfabrieken N.V. (Philips Lightbulb Factories Ltd.). After Gerard and Anton Philips changed their family business by founding the Philips corporation, they laid the foundations for the later electronics multinational.\n\nIn the 1920s, the company started to manufacture other products, such as vacuum tubes. In 1939, they introduced their electric razor, the \"Philishave\" (marketed in the US using the Norelco brand name). The \"Chapel\" is a radio with built-in loudspeaker, which was designed during the early 1930s.\n\nOn 11 March 1927, Philips went on the air with shortwave radio station PCJJ (later PCJ) which was joined in 1929 by sister station PHOHI (Philips Omroep Holland-Indië). PHOHI broadcast in Dutch to the Dutch East Indies (now Indonesia) while PCJJ broadcast in English, Spanish and German to the rest of the world.\n\nThe international program on Sundays commenced in 1928, with host Eddie Startz hosting the \"Happy Station\" show, which became the world's longest-running shortwave program. Broadcasts from the Netherlands were interrupted by the German invasion in May 1940. The Germans commandeered the transmitters in Huizen to use for pro-Nazi broadcasts, some originating from Germany, others concerts from Dutch broadcasters under German control.\n\nPhilips Radio was absorbed shortly after liberation when its two shortwave stations were nationalised in 1947 and renamed Radio Netherlands Worldwide, the Dutch International Service. Some PCJ programs, such as \"Happy Station\", continued on the new station.\n\nPhilips was instrumental in the revival of the Stirling engine when, in the early 1930s, the management decided that offering a low-power portable generator would assist in expanding sales of its radios into parts of the world where mains electricity was unavailable and the supply of batteries uncertain. Engineers at the company's research lab carried out a systematic comparison of various power sources and determined that the almost forgotten Stirling engine would be most suitable, citing its quiet operation (both audibly and in terms of radio interference) and ability to run on a variety of heat sources (common lamp oil – \"cheap and available everywhere\" – was favored). They were also aware that, unlike steam and internal combustion engines, virtually no serious development work had been carried out on the Stirling engine for many years and asserted that modern materials and know-how should enable great improvements.\n\nEncouraged by their first experimental engine, which produced 16 W of shaft power from a bore and stroke of , various development models were produced in a program which continued throughout World War II. By the late 1940s, the 'Type 10' was ready to be handed over to Philips's subsidiary Johan de Witt in Dordrecht to be produced and incorporated into a generator set as originally planned. The result, rated at 180/200 W electrical output from a bore and stroke of , was designated MP1002CA (known as the \"Bungalow set\"). Production of an initial batch of 250 began in 1951, but it became clear that they could not be made at a competitive price, besides with the advent of transistor radios with their much lower power requirements meant that the original rationale for the set was disappearing. Approximately 150 of these sets were eventually produced.\n\nIn parallel with the generator set Philips developed experimental Stirling engines for a wide variety of applications and continued to work in the field until the late 1970s, though the only commercial success was the 'reversed Stirling engine' cryocooler. However, they filed a large number of patents and amassed a wealth of information, which they later licensed to other companies.\n\nThe first Philips shaver was introduced in the 1930s, and was simply called Philishave. In the US, it was called Norelco. The Philishave has remained part of the Philips product line-up until the present.\n\nOn 9 May 1940, the Philips directors learned that the German invasion of the Netherlands was to take place the following day. Having prepared for this, Anton Philips and his son in law Frans Otten, as well as other Philips family members, fled to the United States, taking a large amount of the company capital with them. Operating from the US as the North American Philips Company, they managed to run the company throughout the war. At the same time, the company was moved (on paper) to the Netherlands Antilles to keep it out of German hands.\n\nOn 6 December 1942, the British No. 2 Group RAF undertook Operation Oyster, which heavily damaged the Philips Radio factory in Eindhoven with few casualties among the Dutch workers and civilians. The Philips works in Eindhoven was bombed again by the RAF on 30 March 1943.\n\nFrits Philips, the son of Anton, was the only Philips family member to stay in the Netherlands. He saved the lives of 382 Jews by convincing the Nazis that they were indispensable for the production process at Philips. In 1943 he was held at the internment camp for political prisoners at Vught for several months because a strike at his factory reduced production. For his actions in saving the hundreds of Jews, he was recognized by Yad Vashem in 1995 as a \"Righteous Among the Nations\".\n\nAfter the war the company was moved back to the Netherlands, with their headquarters in Eindhoven.\nIn 1949, the company began selling television sets. In 1950, it formed Philips Records, which eventually formed part of PolyGram.\n\nPhilips introduced the audio Compact Audio Cassette tape in 1963, and it was wildly successful. Compact cassettes were initially used for dictation machines for office typing stenographers and professional journalists. As their sound quality improved, cassettes would also be used to record sound and became the second mass media alongside vinyl records used to sell recorded music.\nPhilips introduced the first combination portable radio and cassette recorder, which was marketed as the \"radiorecorder\", and is now better known as the boom box. Later, the cassette was used in telephone answering machines, including a special form of cassette where the tape was wound on an endless loop. The C-cassette was used as the first mass storage device for early personal computers in the 1970s and 1980s. Philips reduced the cassette size for the professional needs with the Mini-Cassette, although it would not be as successful as the Olympus Microcassette. This became the predominant dictation medium up to the advent of fully digital dictation machines. Philips continued with computers through the early 1990s (see separate article: Philips Computers).\n\nIn 1972, Philips launched the world's first home video cassette recorder, in the UK, the N1500. Its relatively bulky video cassettes could record 30 minutes or 45 minutes. Later one-hour tapes were also offered. As competition came from Sony's Betamax and the VHS group of manufacturers, Philips introduced the N1700 system which allowed double-length recording. For the first time, a 2-hour movie could fit onto one video cassette. In 1977, the company unveiled a special promotional film for this system in the UK, featuring comedian Denis Norden. The concept was quickly copied by the Japanese makers, whose tapes were significantly cheaper. Philips made one last attempt at a new standard for video recorders with the Video 2000 system, with tapes that could be used on both sides and had 8 hours of total recording time. As Philips only sold its systems on the PAL standard and in Europe, and the Japanese makers sold globally, the scale advantages of the Japanese proved insurmountable and Philips withdrew the V2000 system and joined the VHS Coalition.\nPhilips had developed a LaserDisc early on for selling movies, but delayed its commercial launch for fear of cannibalizing its video recorder sales. Later Philips joined with MCA to launch the first commercial LaserDisc standard and players. In 1982, Philips teamed with Sony to launch the Compact Disc; this format evolved into the CD-R, CD-RW, DVD and later Blu-ray, which Philips launched with Sony in 1997 and 2006 respectively.\n\nIn 1984, the Dutch Philips Group bought out nearly a one-third share and took over the management of German company Grundig.\n\nIn 1984, Philips split off its activities on the field of photolithographic integrated circuit production equipment, the so-called wafer steppers, into a joint venture with ASM International, located in Veldhoven under the name ASML. Over the years, this new company has evolved into the world's leading manufacturer of chip production machines at the expense of competitors like Nikon and Canon.\n\nIn 1991, the company's name was changed from N.V. Philips Gloeilampenfabrieken to Philips Electronics N.V. At the same time, North American Philips was formally dissolved, and a new corporate division was formed in the US with the name Philips Electronics North America Corp.\n\nIn 1991-1992, Philips along with their subsidiary Magnavox, released the Philips CD-i, a combined CD player and home video game console. It sold one million units and was discontinued in 1998 after being heavily criticized amongst the gaming community.\n\nIn 1997, the company officers decided to move the headquarters from Eindhoven to Amsterdam along with the corporate name change to Koninklijke Philips Electronics N.V., the latter of which was finalized on 16 March 1998.\n\nThe move of the headquarters to Amsterdam was completed in 2001. Initially, the company was housed in the Rembrandt Tower. In 2002 it moved again, this time to the Breitner Tower. Philips Lighting, Philips Research, Philips Semiconductors (spun off as NXP in September 2006) and Philips Design, are still based in Eindhoven. Philips Healthcare is headquartered in both Best, Netherlands (near Eindhoven) and Andover, Massachusetts, United States (near Boston).\n\nIn 2000, Philips bought Optiva Corporation, the maker of Sonicare electric toothbrushes. The company was renamed Philips Oral Healthcare and made a subsidiary of Philips DAP. In 2001, Philips acquired Agilent Technologies' Healthcare Solutions Group (HSG) for EUR 2 billion. Philips created a computer monitors joint venture with LG called LG.Philips Displays in 2001.\nIn 2004, Philips abandoned the slogan \"Let's make things better\" in favour of a new one: \"Sense and simplicity\".\n\nIn December 2005 Philips announced its intention to sell or demerge its semiconductor division. On 1 September 2006, it was announced in Berlin that the name of the new company formed by the division would be NXP Semiconductors. On 2 August 2006, Philips completed an agreement to sell a controlling 80.1% stake in NXP Semiconductors to a consortium of private equity investors consisting of Kohlberg Kravis Roberts & Co. (KKR), Silver Lake Partners and AlpInvest Partners. On 21 August 2006, Bain Capital and Apax Partners announced that they had signed definitive commitments to join the acquiring consortium, a process which was completed on 1 October 2006.\n\nIn 2006 Philips bought out the company Lifeline Systems headquartered in Framingham, Massachusetts in a deal valued at $750 million, its biggest move yet to expand its consumer-health business (M). In August 2007, Philips acquired the company Ximis, Inc. headquartered in El Paso, Texas for their Medical Informatics Division. In October 2007, it purchased a Moore Microprocessor Patent (MPP) Portfolio license from The TPL Group.\n\nOn 21 December 2007, Philips and Respironics, Inc. announced a definitive agreement pursuant to which Philips acquired all of the outstanding shares of Respironics for US$66 per share, or a total purchase price of approximately €3.6 billion (US$5.1 billion) in cash.\n\nOn 21 February 2008, Philips completed the acquisition of VISICU Baltimore, Maryland through the merger of its indirect wholly owned subsidiary into VISICU. As a result of that merger, VISICU has become an indirect wholly owned subsidiary of Philips. VISICU was the creator of the eICU concept of the use of Telemedicine from a centralized facility to monitor and care for ICU patients.\n\nThe Philips physics laboratory was scaled down in the early 21st century, as the company ceased trying to be innovative in consumer electronics through fundamental research.\n\nIn January 2011, Philips agreed to acquire the assets of Preethi, a leading India-based kitchen appliances company. On 27 June 2011, Philips acquired Sectra Mamea AB, the mammography division of Sectra AB, together with the MicroDose brand.\n\nBecause net profit slumped 85 percent in Q3 2011, Philips announced a cut of 4,500 jobs to match part of an €800 million ($1.1 billion) cost-cutting scheme to boost profits and meet its financial target. In 2011, the company posted a loss of €1.3 billion, but earned a net profit in Q1 and Q2 2012, however the management wanted €1.1 billion cost-cutting which was an increase from €800 million and may cut another 2,200 jobs until end of 2014.\nIn March 2012, Philips announced its intention to sell, or demerge its television manufacturing operations to TPV Technology.\n\nOn 5 December 2012, the antitrust regulators of the European Union fined Philips and several other major companies for fixing prices of TV cathode-ray tubes in two cartels lasting nearly a decade.\n\nOn 29 January 2013, it was announced that Philips had agreed to sell its audio and video operations to the Japan-based Funai Electric for €150 million, with the audio business planned to transfer to Funai in the latter half of 2013, and the video business in 2017. As part of the transaction, Funai was to pay a regular licensing fee to Philips for the use of the Philips brand. The purchase agreement was terminated by Philips in October because of breach of contract and the consumer electronics operations remain under Philips. Philips said it would seek damages for breach of contract in the US$200-million sale. In April 2016, the International Court of Arbitration ruled in favour of Philips, awarding compensation of €135 million in the process.\n\nIn April 2013, Philips announced a collaboration with Paradox Engineering for the realization and implementation of a \"pilot project\" on network-connected street-lighting management solutions. This project was endorsed by the San Francisco Public Utilities Commission (SFPUC).\n\nIn 2013, Philips omitted the word \"Electronics\" from its name, which is now Royal Philips N.V. On 13 November 2013, Philips unveiled its new brand line \"Innovation and You\" and a new design of its shield mark. The new brand positioning is cited by Philips to signify company's evolution and emphasize that innovation is only meaningful if it is based on an understanding of people's needs and desires.\n\nOn 28 April 2014, Philips agreed to sell their Woox Innovations subsidiary (consumer electronics) to Gibson Brands for $US135 million. On 23 September 2014, Philips announced a plan to split the company into two, separating the lighting business from the healthcare and consumer lifestyle divisions. it moved to complete this in March 2015 to an investment group for $3.3 billion\n\nOn February 2015, Philips acquired Volcano Corporation to strengthen its position in non-invasive surgery and imaging. In June 2016, Philips spun off its lighting division to focus on the healthcare division. In June 2017, Philips announced it would acquire US-based Spectranetics Corp, a manufacturer of devices to treat heart disease, for €1.9 billion (£1.68 billion) expanding its current image-guided therapy business.\n\nIn 2018, the lighting products division known as Philips Lighting N.V. was renamed Signify N.V. It continues to produce and market Philips-branded products such as Philips Hue color-changing LED light bulbs.\n\nPast and present CEOs:\n\nCEOs lighting\n\n\nPast and Present CFOs (Chief Financial Officer)\n\nIn January 2013, Hugo Barbosa Vazquez was hired to own market analysis and forecasting activities across all Philips businesses (Consumer Lifestyle, Healthcare and Lighting) and geographies.\n\nCompanies acquired by Philips through the years include ADAC Laboratories, Agilent Healthcare Solutions Group, Amperex, ATL Ultrasound, EKCO, Lifeline Systems, Magnavox, Marconi Medical Systems, Mullard, Optiva, Preethi, Pye, Respironics, Inc., Sectra Mamea AB, Signetics, VISICU, Volcano, VLSI, Ximis, portions of Westinghouse and the consumer electronics operations of Philco and Sylvania. Philips abandoned the Sylvania trademark which is now owned by Havells Sylvania except in Australia, Canada, Mexico, New Zealand, Puerto Rico and the USA where it is owned by Osram. Formed in November 1999 as an equal joint venture between Philips and Agilent Technologies, the light-emitting diode manufacturer Lumileds became a subsidiary of Phillips Lighting in August 2005 and a fully owned subsidiary in December 2006. An 80.1 percent stake in Lumileds was sold to Apollo Global Management in 2017.\n\nPhilips is registered in the Netherlands as a naamloze vennootschap and has its global headquarters in Amsterdam. At the end of 2013 Philips had 111 manufacturing facilities, 59 R&D Facilities across 26 countries and sales and service operations in around 100 countries.\n\nPhilips is organized into three main divisions: Philips Consumer Lifestyle (formerly Philips Consumer Electronics and Philips Domestic Appliances and Personal Care), Philips Healthcare (formerly Philips Medical Systems) and Philips Lighting. Philips achieved total revenues of €22.579 billion in 2011, of which €8.852 billion were generated by Philips Healthcare, €7.638 billion by Philips Lighting, €5.823 billion by Philips Consumer Lifestyle and €266 million from group activities. At the end of 2011 Philips had a total of 121,888 employees, of whom around 44% were employed in Philips Lighting, 31% in Philips Healthcare and 15% in Philips Consumer Lifestyle.\n\nPhilips invested a total of €1.61 billion in research and development in 2011, equivalent to 7.1% of sales. Philips Intellectual Property and Standards is the group-wide division responsible for licensing, trademark protection and patenting. Philips currently holds around 54,000 patent rights, 39,000 trademarks, 70,000 design rights and 4,400 domain name registrations.\n\nPhilips Thailand was established in 1952. It is a subsidiary which produces healthcare, lifestyle and lighting products. Philips started manufacturing in Thailand in 1960 with an incandescent lamp factory. Philips has diversified its production facilities to include a fluorescent lamp factory and a luminaries factory, serving Thai and worldwide markets.\n\nPhilips Hong Kong began operation in 1948. Philips Hong Kong houses the global headquarters of Philips' Audio Business Unit. It also house Philips' Asia Pacific regional office and headquarters for its Design Division, Domestic Appliances & Personal Care Products Division, Lighting Products Division and Medical System Products Division.\n\nIn 1974, Philips opened a lamp factory in Hong Kong. This has a capacity of 200 million pieces a year and is certified with ISO 9001:2000 and ISO 14001. Its product portfolio includes prefocus, lensend and E10 miniature light bulbs.\n\nPhilips established in Zhuhai, Guangdong in 1990. The site mainly manufactures Philishaves and healthcare products. In early 2008, Philips Lighting, a division of Royal Philips Electronics, opened a small engineering center in Shanghai to adapt the company's products to vehicles in Asia.\n\nPhilips began operations in India in 1930, with the establishment of Philips Electrical Co. (India) Pvt Ltd in Kolkata as a sales outlet for imported Philips lamps. In 1938, Philips established its first Indian lamp-manufacturing factory in Kolkata. In 1948, Philips started manufacturing radios in Kolkata. In 1959, a second radio factory was established near Pune. This was closed and sold around 2006. In 1957, the company converted into a public limited company, renamed \"Philips India Ltd\". In 1970 a new consumer electronics factory began operations in Pimpri near Pune. This is now called the 'Philips Healthcare Innovation Centre'. Also, a manufacturing facility 'Philips Centre for Manufacturing Excellence' was set up in Chakan, Pune in 2012. In 1996, the Philips Software Centre was established in Bangalore, later renamed the Philips Innovation Campus. In 2008, Philips India entered the water purifier market. In 2014, Philip's was ranked 12th among India's most trusted brands according to the Brand Trust Report, a study conducted by Trust Research Advisory.\n\nPhilips has been active in Israel since 1948 and in 1998, set up a wholly owned subsidiary, Philips Electronics (Israel) Ltd. The company has over 700 employees in Israel and generated sales of over $300 million in 2007.\n\nPhilips Medical Systems Technologies Ltd. (Haifa) is a developer and manufacturer of Computerized Tomography (CT), diagnostic and Medical Imaging systems. The company was founded in 1969 as Elscint by Elron Electronic Industries and was acquired by Marconi Medical Systems in 1998, which was itself acquired by Philips in 2001.\n\nPhilips Semiconductors formerly had major operations in Israel; these now form part of NXP Semiconductors.\n\nPhilips has been active in Pakistan since 1948 and has a wholly owned subsidiary, Philips Pakistan Limited (Formerly Philips Electrical Industries of Pakistan Limited).\n\nThe head office is in Karachi with regional sales offices in Lahore and Rawalpindi.\n\nPhilips France has its headquarters in Suresnes. The company employs over 3600 people nationwide.\n\nPhilips Lighting has manufacturing facilities in Chalon-sur-Saône (fluorescent lamps), Chartres (automotive lighting), Lamotte-Beuvron (architectural lighting by LEDs and professional indoor lighting), Longvic (lamps), Miribel (outdoor lighting), Nevers (professional indoor lighting).\n\nPhilips Germany was founded in 1926 in Berlin. Now its headquarters is located in Hamburg. Over 4900 people are employed in Germany.\n\n\nPhilips' Greece is headquartered in Halandri, Attica. As of 2012 Philips has no manufacturing plants in Greece, although there have been in the past.\n\nPhilips founded its Italian headquarter in 1918, basing it in Monza (Milan) where it still operates, for commercial activities only.\n\nPhilips' operations in Poland include: a European financial and accounting centre in Łódź; Philips Lighting facilities in Bielsko-Biała, Pabianice, Piła, and Kętrzyn; and a Philips Domestic Appliances facility in Białystok.\n\nPhilips started business in Portugal in 1927, as \"Philips Portuguesa S.A.R.L.\". Currently, Philips Portuguesa S.A. is headquartered in Oeiras near Lisbon. There were three Philips factories in Portugal: the FAPAE lamp factory in Lisbon; the Carnaxide magnetic-core memory factory near Lisbon, where the Philips Service organization was also based; and the Ovar factory in northern Portugal making camera components and remote control devices. The company still operates in Portugal with divisions for commercial lighting, medical systems and domestic appliances.\n\nPhilips Sweden has two main sites, Kista, Stockholm County, with regional sales, marketing and a customer support organization and Solna, Stockholm County, with the main office of the mammography division.\n\nPhilips UK has its headquarters in Guildford. The company employs over 2500 people nationwide.\n\n\nIn the past, Philips UK also included:\n\nPhilips Canada was founded in 1934. It is well known in medical systems for diagnosis and therapy, lighting technologies, shavers, and consumer electronics.\n\nThe Canadian headquarters are located in Markham, Ontario.\n\nFor several years, Philips manufactured lighting products in two Canadian factories. The London, Ontario, plant opened in 1971. It produced A19 lamps (including the \"Royale\" long life bulbs), PAR38 lamps and T19 lamps (originally a Westinghouse lamp shape). Philips closed the factory in May 2003. The Trois-Rivières, Quebec plant was a Westinghouse facility which Philips continued to run it after buying Westinghouse's lamp division in 1983. Philips closed this factory a few years later, in the late 1980s.\n\nPhilips Mexicana SA de CV is headquartered in Mexico City. Philips Lighting has manufacturing facilities in: Monterrey, Nuevo León; Ciudad Juárez, Chihuahua; and Tijuana, Baja California. Philips Consumer Electronics has a manufacturing facility in Ciudad Juárez, Chihuahua. Philips Domestic Appliances formerly operated a large factory in the Industrial Vallejo sector of Mexico City but this was closed in 2004.\n\nPhilips' Electronics North American headquarters is in Andover, Massachusetts. In early 2018, it was announced that the US headquarters would move to Cambridge, Massachusetts by 2020. Philips Lighting has its corporate office in Somerset, New Jersey, with manufacturing plants in Danville, Kentucky, Dallas, Salina, Kansas and Paris, Texas and distribution centers in Mountain Top, Pennsylvania El Paso, Texas, Ontario, California and Memphis, Tennessee. Philips Healthcare is headquartered in Cambridge, Massachusetts and operates a health-tech hub in Nashville, Tennessee with over 1000 jobs. The North American sales organization is based in Bothell, Washington. There are also manufacturing facilities in Andover, Massachusetts, Bothell, Washington, Baltimore, Maryland, Cleveland, Ohio, Foster City, California, Gainesville, Florida, Milpitas, California and Reedsville, Pennsylvania. Philips Healthcare also formerly had a factory in Knoxville, Tennessee. Philips Consumer Lifestyle has its corporate office in Stamford, Connecticut. Philips Lighting has a Color Kinetics office in Burlington, Massachusetts. Philips Research North American headquarters is in Cambridge, Massachusetts.\n\nIn 2007, Philips entered into a definitive merger agreement with North American luminaires company Genlyte Group Incorporated, which provides the company with a leading position in the North American luminaires (also known as ˜lighting fixtures\"), controls and related products for a wide variety of applications, including solid state lighting. The company also acquired Respironics, which was a significant gain for its healthcare sector. On 21 February 2008 Philips completed the acquisition of VISICU Baltimore, Maryland. VISICU was the creator of the eICU concept of the use of Telemedicine from a centralized facility to monitor and care for ICU patients.\n\nPhilips Australia was founded in 1927 and is headquartered in North Ryde, New South Wales and also manages the New Zealand operation from there. The company currently employs around 800 people. Regional sales and support offices are located in Melbourne, Brisbane, Adelaide, Perth and Auckland.\n\nCurrent activities include: Philips Healthcare (also responsible for New Zealand operations); Philips Lighting (also responsible for New Zealand operations); Phillips Oral Healthcare, Phillips Professional Dictation Solutions, Phillips Professional Display Solutions, Phillips AVENT Professional, Philips Consumer Lifestyle (also responsible for New Zealand operations); Philips Sleep & Respiratory Care (formerly Respironics), with its ever-increasing national network of Sleepeasy Centres ; Philips Dynalite (Lighting Control systems, acquired in 2009, global design and manufacturing centre) and Philips Selecon NZ (Lighting Entertainment product design and manufacture).\n\nPhilips do Brasil () was founded in 1924 in Rio de Janeiro. In 1929, Philips started to sell radio receivers. In the 1930s, Philips was making its light bulbs and radio receivers in Brazil. From 1939 to 1945, World War II forced Brazilian branch of Philips to sell bicycles, refrigerators and insecticides. After the war, Philips had a great industrial expansion in Brazil, and was among the first groups to establish in Manaus Free Zone. In the 1970s, Philips Records was a major player in Brazil recording industry. Nowadays, Philips do Brasil is one of the largest foreign-owned companies in Brazil. Philips uses the brand Walita for domestic appliances in Brazil.\n\nPhilips subsidiary Philips-Duphar(nl) manufactured pharmaceuticals for human and veterinary use and products for crop protection. Duphar was sold to Solvay in 1990. In subsequent years Solvay sold off all divisions to other companies (crop protection to UniRoyal, now Chemtura, the veterinary division to Fort Dodge, a division of Wyeth, and the pharmaceutical division to Abbott Laboratories).\n\nPolyGram, Philips' music television and movies division, was sold to Seagram in 1998; merged into Universal Music Group. Philips Records continues to operate as record label of UMG, its name licensed from its former parent.\n\nOrigin, now part of Atos Origin, is a former division of Philips.\n\nASM Lithography is a spin-off from a division of Philips.\n\nHollandse Signaalapparaten was a manufacturer of military electronics. The business was sold to Thomson-CSF in 1990 and is now Thales Nederland.\n\nNXP Semiconductors, formerly known as Philips Semiconductors, was sold a consortium of private equity investors in 2006. On 6 August 2010, NXP completed its IPO, with shares trading on NASDAQ.\n\nPhilips used to sell major household appliances (whitegoods) under the name Philips. After selling the Major Domestic Appliances division to Whirlpool Corporation it changed from Philips Whirlpool to Whirlpool Philips and finally to just Whirlpool. Whirlpool bought a 53% stake in Philips' major appliance operations to form Whirlpool International. Whirlpool bought Philips' remaining interest in Whirlpool International in 1991.\n\nPhilips Cryogenics was split off in 1990 to form the Stirling Cryogenics BV, Netherlands. This company is still active in the development and manufacturing of Stirling cryocoolers and cryogenic cooling systems.\n\nNorth American Philips distributed AKG Acoustics products under the AKG of America, Philips Audio/Video, Norelco and AKG Acoustics Inc. branding until AKG set up its North American division in San Leandro, California in 1985. (AKG's North American division has since moved to Northridge, California.)\n\nPolymer Vision was a Philips spin-off that manufactured a flexible e-ink display screen. The company closed in 2009.\n\nPhilips' core products are consumer electronics and electrical products (including small domestic appliances, shavers, beauty appliances, mother and childcare appliances, electric toothbrushes and coffee makers (products like Smart Phones, audio equipment, Blu-ray players, computer accessories and televisions are sold under license)); and healthcare products (including CT scanners, ECG equipment, mammography equipment, monitoring equipment, MRI scanners, radiography equipment, resuscitation equipment, ultrasound equipment and X-ray equipment);\n\n\n\nPhilips healthcare products include:\n\n\n\n\n\n\n\nIn 1913, in celebration of the 100th anniversary of the liberation of the Netherlands, Philips founded \"Philips Sports Vereniging\" (Philips Sports Club, now commonly known as PSV). The club is active in numerous sports but is now best known for its football team, PSV Eindhoven, and swimming team. Philips owns the naming rights to Philips Stadion in Eindhoven, which is the home ground of PSV Eindhoven.\n\nOutside of the Netherlands, Philips sponsors and has sponsored numerous sports clubs, sports facilities and events. In November 2008 Philips renewed and extended its F1 partnership with AT&T Williams. Philips owns the naming rights to the \"Philips Championship\", the premier basketball league in Australia, traditionally known as the National Basketball League. From 1988 to 1993 Philips was the principal sponsor of the Australian rugby league team The Balmain Tigers and Indonesian football club side Persiba Balikpapan. From 1998 to 2000, Philips sponsored the Winston Cup #7 entry for Geoff Bodine Racing, later Ultra Motorsports, for drivers Geoff Bodine and Michael Waltrip. From 1999 to 2018, Philips held the naming rights to Philips Arena in Atlanta, home of the Atlanta Hawks of the National Basketball Association and former home of the defunct Atlanta Thrashers of the National Hockey League.\n\nOutside of sports, Philips sponsors the international \"Philips Monsters of Rock festival\".\n\nPhilips is running the EcoVision4 initiative in which it committed to a number of environmentally positive improvements by 2012.\n\nAlso Philips marks its \"green\" products with the Philips Green Logo, identifying them as products that have a significantly better environmental performance than their competitors or predecessors.\n\nIn 2011, Philips won a $10 million cash prize from the US Department of Energy for winning its L-Prize competition, to produce a high-efficiency, long operating life replacement for a standard 60-W incandescent lightbulb. The winning LED lightbulb, which was made available to consumers in April 2012, produces slightly more than 900 lumens at an input power of only 10 W.\n\nIn Greenpeace's 2012 Guide to Greener Electronics, that ranks electronics manufacturers on sustainability, climate and energy and how green their products are, Philips ranks 10th place with a score of 3.8/10. The company was the top scorer in the Energy section due to its energy advocacy work calling upon the EU to adopt a 30% reduction for greenhouse gas emissions by 2020. It is also praised for its new products which are free from PVC plastic and BFRs. However, the guide criticizes Phillips' sourcing of fibres for paper, arguing it must develop a paper procurement policy which excludes suppliers involved in deforestation and illegal logging.\n\nPhilips have made some considerable progress since 2007 (when it was first ranked in this guide), in particular by supporting the Individual Producer Responsibility principle, which means that the company is accepting the responsibility for the toxic impacts of its products on e-waste dumps around the world.\n\n\n"}
{"id": "43939378", "url": "https://en.wikipedia.org/wiki?curid=43939378", "title": "Pressure-induced hydration", "text": "Pressure-induced hydration\n\nPressure-induced hydration (PIH), also known as “super-hydration”, is a special case of pressure-induced insertion whereby water molecules are injected into the pores of microporous materials. In PIH, a microporous material is placed under pressure in the presence of water in the pressure-transmitting fluid of a diamond anvil cell.\n\nEarly physical characterization and initial diffraction experiments in zeolites were followed by the first unequivocal structural characterization of PIH in the small-pore zeolite natrolite (NaAlSiO x 16HO), which in its fully super-hydrated form, NaAlSiO x 32HO, doubles the amount of water it contains in its pores.\n\nPIH has now been demonstrated in natrolites containing Li, K, Rb and Ag as monovalent cations as well as in large-pore zeolites, pyrochlores, clays and graphite oxide.\n\nUsing the noble gases Ar, Kr, and Xe as well as CO as pressure-transmitting fluids, researchers have prepared and structurally characterized the products of reversible, pressure-induced insertion of Ar Kr, and CO as well as the irreversible insertion of Xe and water.\n"}
{"id": "17601646", "url": "https://en.wikipedia.org/wiki?curid=17601646", "title": "Restoration of the Everglades", "text": "Restoration of the Everglades\n\nThe restoration of the Everglades is an ongoing effort to remedy damage inflicted on the environment of southern Florida during the 20th century. It is the most expensive and comprehensive environmental repair attempt in history. The degradation of the Everglades became an issue in the United States in the early 1970s after a proposal to construct an airport in the Big Cypress Swamp. Studies indicated the airport would have destroyed the ecosystem in South Florida and Everglades National Park. After decades of destructive practices, both state and federal agencies are looking for ways to balance the needs of the natural environment in South Florida with urban and agricultural centers that have recently and rapidly grown in and near the Everglades.\n\nIn response to floods caused by hurricanes in 1947, the Central and Southern Florida Flood Control Project (C&SF) was established to construct flood control devices in the Everglades. The C&SF built of canals and levees between the 1950s and 1971 throughout South Florida. Their last venture was the C-38 canal, which straightened the Kissimmee River and caused catastrophic damage to animal habitats, adversely affecting water quality in the region. The canal became the first C&SF project to revert when the canal began to be backfilled, or refilled with the material excavated from it, in the 1980s.\n\nWhen high levels of phosphorus and mercury were discovered in the waterways in 1986, water quality became a focus for water management agencies. Costly and lengthy court battles were waged between various government entities to determine who was responsible for monitoring and enforcing water quality standards. Governor Lawton Chiles proposed a bill that determined which agencies would have that responsibility, and set deadlines for pollutant levels to decrease in water. Initially the bill was criticized by conservation groups for not being strict enough on polluters, but the Everglades Forever Act was passed in 1994. Since then, the South Florida Water Management District (SFWMD) and the U.S. Army Corps of Engineers have surpassed expectations for achieving lower phosphorus levels.\n\nA commission appointed by Governor Chiles published a report in 1995 stating that South Florida was unable to sustain its growth, and the deterioration of the environment was negatively affecting daily life for residents in South Florida. The environmental decline was predicted to harm tourism and commercial interests if no actions were taken to halt current trends. Results of an eight-year study that evaluated the C&SF were submitted to the United States Congress in 1999. The report warned that if no action was taken the region would rapidly deteriorate. A strategy called the Comprehensive Everglades Restoration Plan (CERP) was enacted to restore portions of the Everglades, Lake Okeechobee, the Caloosahatchee River, and Florida Bay to undo the damage of the past 50 years. It would take 30 years and cost $7.8 billion to complete. Though the plan was passed into law in 2000, it has been compromised by politics and funding problems.\n\nThe Everglades are part of a very large watershed that begins in the vicinity of Orlando. The Okeechobee River drains into Lake Okeechobee, a lake with an average depth of . During the wet season when the lake exceeds its capacity, the water leaves the lake in a very wide and shallow river, approximately long and wide. This wide and shallow flow is known as \"sheetflow\". The land gradually slopes toward Florida Bay, the historical destination of most of the water leaving the Everglades. Before drainage attempts, the Everglades comprised , taking up a third of the Florida peninsula.\n\nSince the early 19th century the Everglades have been a subject of interest for agricultural development. The first attempt to drain the Everglades occurred in 1882 when a Pennsylvania land developer named Hamilton Disston constructed the first canals. Though these attempts were largely unsuccessful, Disston's purchase of land spurred tourism and real estate development of the state. The political motivations of Governor Napoleon Bonaparte Broward resulted in more successful attempts at canal construction between 1906 and 1920. Recently reclaimed wetlands were used for cultivating sugarcane and vegetables, while urban development began in the Everglades.\n\nThe 1926 Miami Hurricane and the 1928 Okeechobee Hurricane caused widespread devastation and flooding which prompted the Army Corps of Engineers to construct a dike around Lake Okeechobee. The four-story wall cut off water from the Everglades. Floods from hurricanes in 1947 motivated the U.S. Congress to establish the Central and Southern Florida Flood Control Project (C&SF), responsible for constructing of canals and levees, hundreds of pumping stations and other water control devices. The C&SF established Water Conservation Areas (WCAs) in 37% of the original Everglades, which acted as reservoirs providing excess water to the South Florida metropolitan area, or flushing it into the Atlantic Ocean or the Gulf of Mexico. The C&SF also established the Everglades Agricultural Area (EAA), which grows the majority of sugarcane crops in the United States. When the EAA was first established, it encompassed approximately 27% of the original Everglades.\n\nBy the 1960s, urban development and agricultural use had decreased the size of the Everglades considerably. The remaining 25% of the Everglades in its original state is protected in Everglades National Park, but the park was established before the C&SF, and it depended upon the actions of the C&SF to release water. As Miami and other metropolitan areas began to intrude on the Everglades in the 1960s, political battles took place between park management and the C&SF when insufficient water in the park threw ecosystems into chaos. Fertilizers used in the EAA began to alter soil and hydrology in Everglades National Park, causing the proliferation of exotic plant species. However, a proposition to build a massive jetport in the Big Cypress Swamp in 1969 focused attention on the degraded natural systems in the Everglades. For the first time, the Everglades became a subject of environmental conservation.\n\nEnvironmental protection became a national priority in the 1970s. \"Time\" magazine declared it the Issue of the Year in January 1971, reporting that it was rated as Americans' \"most serious problem confronting their community—well ahead of crime, drugs and poor schools\". When South Florida experienced a severe drought from 1970 to 1975, with Miami receiving only of rain in 1971— less than average—media attention focused on the Everglades. With the assistance of governor's aide Nathaniel Reed and U.S. Fish and Wildlife Service biologist Arthur R. Marshall, politicians began to take action. Governor Reubin Askew implemented the Land Conservation Act in 1972, allowing the state to use voter-approved bonds of $240 million to purchase land considered to be environmentally unique and irreplaceable. Since then, Florida has purchased more land for public use than any other state. In 1972 President Richard Nixon declared the Big Cypress Swamp—the intended location for the Miami jetport in 1969—to be federally protected. Big Cypress National Preserve was established in 1974, and Fakahatchee Strand State Preserve was created the same year.\n\nIn 1976, Everglades National Park was declared an International Biosphere Reserve by UNESCO, which also listed the park as a World Heritage Site in 1979. The Ramsar Convention designated the Everglades a Wetland of International Importance in 1987. Only three locations on earth which have appeared on all three lists: Everglades National Park, Lake Ichkeul in Tunisia, and Srebarna Lake in Bulgaria.\n\nIn the 1960s, the C&SF came under increased scrutiny from government overseers and conservation groups. Critics maintained its size was comparable to the Tennessee Valley Authority's dam-building projects during the Great Depression, and that the construction had run into the billions of dollars without any apparent resolution or plan. The projects of the C&SF have been characterized as part of \"crisis and response\" cycles that \"ignored the consequence for the full system, assumed certainty of the future, and succeeded in solving the momentary crisis, but set in motion conditions that exaggerate future crises\". The last project, to build a canal to straighten the winding floodplain of the Kissimmee River that had historically fed Lake Okeechobee which in turn fed the Everglades, began in 1962. Marjory Stoneman Douglas later wrote that the C&SF projects were \"interrelated stupidity\", crowned by the C-38 canal. Designed to replace a meandering river with a channel, the canal was completed in 1971 and cost $29 million. It supplanted approximately of marshland with retention ponds, dams, and vegetation. Loss of habitat has caused the region to experience a drastic decrease of waterfowl, wading birds, and game fish. The reclaimed floodplains were taken over by agriculture, bringing fertilizers and insecticides that washed into Lake Okeechobee. Even before the canal was finished, conservation organizations and sport fishing and hunting groups were calling for the restoration of the Kissimmee River.\nArthur R. Marshall led the efforts to undo the damage. According to Douglas, Marshall was successful in portraying the Everglades from the Kissimmee Chain of Lakes to Florida Bay—including the atmosphere, climate, and limestone—as a single organism. Rather than remaining the preserve of conservation organizations, the cause of restoring the Everglades became a priority for politicians. Douglas observed, \"Marshall accomplished the extraordinary magic of taking the Everglades out of the bleeding-hearts category forever\". At the insistent urging of Marshall, newly elected Governor Bob Graham announced the formation of the \"Save Our Everglades\" campaign in 1983, and in 1985 Graham lifted the first shovel of backfill for a portion of the C-38 canal. Within a year the area was covered with water returning to its original state. Graham declared that by the year 2000, the Everglades would resemble its predrainage state as much as possible. The Kissimmee River Restoration Project was approved by Congress in the Water Resources Development Act of 1992. The project was estimated to cost $578 million to convert only of the canal; the cost was designed to be divided between the state of Florida and the U.S. government, with the state being responsible for purchasing land to be restored. A project manager for the Army Corps of Engineers explained in 2002, \"What we're doing on this scale is going to be taken to a larger scale when we do the restoration of the Everglades\". The entire project is estimated to be completed by 2011.\n\nAttention to water quality was focused in South Florida in 1986 when a widespread algal bloom occurred in one-fifth of Lake Okeechobee. The bloom was discovered to be the result of fertilizers from the Everglades Agricultural Area. Although laws stated in 1979 that the chemicals used in the EAA should not be deposited into the lake, they were flushed into the canals that fed the Everglades Water Conservation Areas, and eventually pumped into the lake. Microbiologists discovered that, although phosphorus assists plant growth, it destroys periphyton, one of the basic building blocks of marl in the Everglades. Marl is one of two types of Everglades soil, along with peat; it is found where parts of the Everglades are flooded for shorter periods of time as layers of periphyton dry. Most of the phosphorus compounds also rid peat of dissolved oxygen and promote algae growth, causing native invertebrates to die, and sawgrass to be replaced with invasive cattails that grow too tall and thick for birds and alligators to nest in. Tested water showed 500 parts per billion (ppb) of phosphorus near sugarcane fields. State legislation in 1987 mandated a 40% reduction of phosphorus by 1992.\n\nAttempts to correct phosphorus levels in the Everglades met with resistance. The sugarcane industry, dominated by two companies named U.S. Sugar and Flo-Sun, was responsible for more than half of the crop in the EAA. They were well represented in state and federal governments by lobbyists who enthusiastically protected their interests. According to the Audubon Society, the sugar industry, nicknamed \"Big Sugar\", donated more money to political parties and candidates than General Motors. The sugar industry attempted to block government-funded studies of polluted water, and when the federal prosecutor in Miami faulted the sugar industry in legal action to protect Everglades National Park, Big Sugar tried to get the lawsuit withdrawn and the prosecutor fired. A costly legal battle ensued from 1988 to 1992 between the State of Florida, the U.S. government, and the sugar industry to resolve who was responsible for water quality standards, the maintenance of Everglades National Park and the Arthur R. Marshall Loxahatchee National Wildlife Refuge.\n\nA different concern about water quality arose when mercury was discovered in fish during the 1980s. Because mercury is damaging to humans, warnings were posted for fishermen that cautioned against eating fish caught in South Florida, and scientists became alarmed when a Florida panther was found dead near Shark River Slough with mercury levels high enough to be fatal to humans. When mercury is ingested it adversely affects the central nervous system, and can cause brain damage and birth defects. Studies of mercury levels found that it is bioaccumulated through the food chain: animals that are lower on the chain have decreased amounts, but as larger animals eat them, the amount of mercury is multiplied. The dead panther's diet consisted of small animals, including raccoons and young alligators. The source of the mercury was found to be waste incinerators and fossil fuel power plants that expelled the element in the atmosphere, which precipitated with rain, or in the dry season, dust. Naturally occurring bacteria in the Everglades that function to reduce sulfur also transform mercury deposits into methylmercury. This process was more dramatic in areas where flooding was not as prevalent. Because of requirements that reduced power plant and incinerator emissions, the levels of mercury found in larger animals decreased as well: approximately a 60% decrease in fish and a 70% decrease in birds, though some levels still remain a health concern for people.\n\nIn an attempt to resolve the political quagmire over water quality, Governor Lawton Chiles introduced a bill in 1994 to clean up water within the EAA that was being released to the lower Everglades. The bill stated that the \"Everglades ecosystem must be restored both in terms of water quality and water quantity and must be preserved and protected in a manner that is long term and comprehensive\". It ensured the Florida Department of Environmental Protection (DEP) and the South Florida Water Management District (SFWMD) would be responsible for researching water quality, enforcing water supply improvement, controlling exotic species, and collecting taxes, with the aim of decreasing the levels of phosphorus in the region. It allowed for purchase of land where pollutants would be sent to \"treat and improve the quality of waters coming from the EAA\".\n\nCritics of the bill argued that the deadline for meeting the standards was unnecessarily delayed until 2006—a period of 12 years—to enforce better water quality. They also maintained that it did not force sugarcane farmers, who were the primary polluters, to pay enough of the costs, and increased the threshold of what was an acceptable amount of phosphorus in water from 10 ppb to 50 ppb. Governor Chiles initially named it the Marjory Stoneman Douglas Act, but Douglas was so unimpressed with the action it took against polluters that she wrote to Chiles and demanded her name be stricken from it. Despite criticism, the Florida legislature passed the Act in 1994. The SFWMD stated that its actions have exceeded expectations earlier than anticipated, by creating Stormwater Treatment Areas (STA) within the EAA that contain a calcium-based substance such as lime rock layered between peat, and filled with calcareous periphyton. Early tests by the Army Corps of Engineers revealed this method reduced phosphorus levels from 80 ppb to 10 ppb. The STAs are intended to treat water until the phosphorus levels are low enough to be released into the Loxahatchee National Wildlife Refuge or other WCAs.\n\nThe intrusion of urban areas into wilderness has had a substantial impact on wildlife, and several species of animals are considered endangered in the Everglades region. One animal that has benefited from endangered species protection is the American Alligator (\"Alligator mississippiensis\"), whose holes give refuge to other animals, often allowing many species to survive during times of drought. Once abundant in the Everglades, the alligator was listed as an endangered species in 1967, but a combined effort by federal and state organizations and the banning of alligator hunting allowed it to rebound; it was pronounced fully recovered in 1987 and is no longer an endangered species. However, alligators' territories and average body masses have been found to be generally smaller than in the past, and because populations have been reduced, their role during droughts has become limited.\n\nThe American Crocodile (\"Crocodylus acutus\") is also native to the region and has been designated as endangered since 1975. Unlike their relatives the alligators, crocodiles tend to thrive in brackish or salt-water habitats such as estuarine or marine coasts. Their most significant threat is disturbance by people. Too much contact with humans causes females to abandon their nests, and males in particular are often victims of vehicle collisions while roaming over large territories and attempting to cross U.S. 1 and Card Sound Road in the Florida Keys. There are an estimated 500 to 1,000 crocodiles in southern Florida.\nThe most critically endangered of any animal in the Everglades region is the Florida panther (\"Puma concolor coryi\"), a species that once lived throughout the southeastern United States: there were only 25–30 in the wild in 1995. The panther is most threatened by urban encroachment, because males require approximately for breeding territory. A male and two to five females may live within that range. When habitat is lost, panthers will fight over territory. After vehicle collisions, the second most frequent cause of death for panthers is intra-species aggression. In the 1990s urban expansion crowded panthers from southwestern Florida as Naples and Ft. Myers began to expand into the western Everglades and Big Cypress Swamp. Agencies such as the Army Corps of Engineers and the U.S. Fish and Wildlife Service were responsible for maintaining the Clean Water Act and the Endangered Species Act, yet still approved 99% of all permits to build in wetlands and panther territory. A limited genetic pool is also a danger. Biologists introduced eight female Texas cougars (\"Puma concolor\") in 1995 to diversify genes, and there are between 80 and 120 panthers in the wild .\n\nPerhaps the most dramatic loss of any group of animals has been to wading birds. Their numbers were estimated by eyewitness accounts to be approximately 2.5 million in the late 19th century. However, snowy egrets (\"Egretta thula\"), roseate spoonbills (\"Platalea ajaja\"), and reddish egrets (\"Egretta rufescens\") were hunted to the brink of extinction for the colorful feathers used in women's hats. After about 1920 when the fashion passed, their numbers returned in the 1930s, but over the next 50 years actions by the C&SF further disturbed populations. When the canals were constructed, natural water flow was restricted from the mangrove forests near the coast of Florida Bay. From one wet season to the next, fish were unable to reach traditional locations to repopulate when water was withheld by the C&SF. Birds were forced to fly farther from their nests to forage for food. By the 1970s, bird numbers had decreased 90%. Many of the birds moved to smaller colonies in the WCAs to be closer to a food source, making them more difficult to count. Yet they remain significantly fewer in number than before the canals were constructed.\n\nAround 6 million people moved to South Florida between 1940 and 1965. With a thousand people moving to Miami each week, urban development quadrupled. As the human population grew rapidly, the problem of exotic plant and animal species also grew. Many species of plants were brought into South Florida from Asia, Central America, or Australia as decorative landscaping. Exotic animals imported by the pet trade have escaped or been released. Biological controls that keep invasive species smaller in size and fewer in number in their native lands often do not exist in the Everglades, and they compete with the embattled native species for food and space. Of imported plant species, melaleuca trees (\"Melaleuca quinquenervia\") have caused the most problems. Melaleucas grow on average in the Everglades, as opposed to in their native Australia. They were brought to southern Florida as windbreaks and deliberately seeded in marsh areas because they absorb vast amounts of water. In a region that is regularly shaped by fire, melaleucas are fire-resistant and their seeds are more efficiently spread by fire. They are too dense for wading birds with large wingspans to nest in, and they choke out native vegetation. Costs of controlling melaleucas topped $2 million in 1998 for Everglades National Park. In Big Cypress National Preserve, melaleucas covered at their most pervasive in the 1990s.\nBrazilian pepper (\"Schinus terebinthifolius\") was brought to Southern Florida as an ornamental shrub and was dispersed by the droppings of birds and other animals that ate its bright red berries. It thrives on abandoned agricultural land growing in forests too dense for wading birds to nest in, similar to melaleucas. It grows rapidly especially after hurricanes and has invaded pineland forests. Following Hurricane Andrew, scientists and volunteers cleared damaged pinelands of Brazilian pepper so the native trees would be able to return to their natural state.\n\nThe species that is causing the most impediment to restoration is the Old World climbing fern (\"Lygodium microphyllum\"), introduced in 1965. The fern grows rapidly and thickly on the ground, making passage for land animals such as black bears and panthers problematic. The ferns also grow as vines into taller portions of trees, and fires climb the ferns in \"fire ladders\" to scorch portions of the trees that are not naturally resistant to fire.\n\nSeveral animal species have been introduced to Everglades waterways. Many tropical fish are released, the most detrimental being the blue tilapia (\"Oreochromis aureus\"), which builds large nests in shallow waters. Tilapia also consume vegetation which would normally be used by young native fishes for cover and protection.\n\nReptiles have a particular affinity for the South Florida ecosystem. Virtually all lizards appearing in the Everglades have been introduced, such as the brown anole (\"Anolis sagrei\") and the tropical house gecko (\"Hemidactylus mabouia\"). The herbivorous green iguana (\"Iguana iguana\") can reproduce rapidly in wilderness habitats. However, the reptile that has earned media attention for its size and potential to harm children and domestic pets is the Burmese python (\"Python bivittatus\"), which has spread quickly throughout the area. The python can grow up to long and competes with alligators for the top of the food chain.\n\nThough exotic birds such as parrots and parakeets are also found in the Everglades, their impact is negligible. Conversely, perhaps the animal that causes the most damage to native wildlife is the domestic or feral cat. Across the U.S., cats are responsible for approximately a billion bird deaths annually. They are estimated to number 640 per square mile; cats living in suburban areas have devastating effects on migratory birds and marsh rabbits.\n\nHurricane Andrew struck Miami in 1992, with catastrophic damage to Homestead Air Force Base in Homestead. A plan to rejuvenate the property in 1993 and convert it into a commercial airport was met with enthusiasm from local municipal and commercial entities hoping to recoup $480 million and 11,000 jobs lost in the local community by the destruction and subsequent closing of the base. On March 31, 1994, the base was designated as a reserve base, functioning only part-time. A cursory environmental study performed by the Air Force was deemed insufficient by local conservation groups, who threatened to sue in order to halt the acquisition when estimates of 650 flights a day were projected. Groups had previously been alarmed in 1990 by the inclusion of Homestead Air Force Base on a list of the U.S. Government's most polluted properties. Their concerns also included noise, and the inevitable collisions with birds using the mangrove forests as rookeries. The Air Force base is located between Everglades National Park and Biscayne National Park, giving it the potential to cause harm to both. In 2000, Secretary of the Interior Bruce Babbitt and the director of the U.S. Environmental Protection Agency expressed their opposition to the project, despite other Clinton Administration agencies previously working to ensure the base would be turned over to local agencies quickly and smoothly as \"a model of base disposal\".\nAlthough attempts were made to make the base more environmentally friendly, in 2001 local commercial interests promoting the airport lost federal support.\n\nDespite the successes of the Everglades Forever Act and the decreases in mercury levels, the focus intensified on the Everglades in the 1990s as quality of life in the South Florida metropolitan areas diminished. It was becoming clear that urban populations were consuming increasingly unsustainable levels of natural resources. A report entitled \"The Governor's Commission for a Sustainable South Florida\", submitted to Lawton Chiles in 1995, identified the problems the state and municipal governments were facing. The report remarked that the degradation of the natural quality of the Everglades, Florida Bay, and other bodies of water in South Florida would cause a significant decrease in tourism (12,000 jobs and $200 million annually) and income from compromised commercial fishing (3,300 jobs and $52 million annually). The report noted that past abuses and neglect of the environment had brought the region to \"a precipitous juncture\" where the inhabitants of South Florida faced health hazards in polluted air and water; furthermore, crowded and unsafe urban conditions hurt the reputation of the state. It noted that though the population had increased by 90% over the previous two decades, registered vehicles had increased by 166%. On the quality and availability of water, the report stated, \"[The] frequent water shortages ... create the irony of a natural system dying of thirst in a subtropical environment with over 53 inches of rain per year\".\n\nRestoration of the Everglades, however, briefly became a bipartisan cause in national politics. A controversial penny-a-pound (2 cent/kg) tax on sugar was proposed to fund some of the necessary changes to be made to help decrease phosphorus and make other improvements to water. State voters were asked to support the tax, and environmentalists paid $15 million to encourage the issue. Sugar lobbyists responded with $24 million in advertising to discourage it and succeeded; it became the most expensive ballot issue in state history. How restoration might be funded became a political battleground and seemed to stall without resolution. However, in the 1996 election year, Republican senator Bob Dole proposed that Congress give the State of Florida $200 million to acquire land for the Everglades. Democratic Vice President Al Gore promised the federal government would purchase of land in the EAA to turn it over for restoration. Politicking reduced the number to , but both Dole's and Gore's gestures were approved by Congress.\n\nAs part of the Water Resources Development Act of 1992, Congress authorized an evaluation of the effectiveness of the Central and Southern Florida Flood Control Project. A report known as the \"Restudy\", written by the U.S. Army Corps of Engineers and the South Florida Water Management District, was submitted to Congress in 1999. It cited indicators of harm to the system: a 50% reduction in the original Everglades, diminished water storage, harmful timing of water release, an 85 to 90% decrease in wading bird populations over the past 50 years, and the decline of output from commercial fisheries. Bodies of water including Lake Okeechobee, the Caloosahatchee River, St. Lucie estuary, Lake Worth Lagoon, Biscayne Bay, Florida Bay, and the Everglades reflected drastic water level changes, hypersalinity, and dramatic changes in marine and freshwater ecosystems. The Restudy noted the overall decline in water quality over the past 50 years was caused by loss of wetlands that act as filters for polluted water. It predicted that without intervention the entire South Florida ecosystem would deteriorate. Canals took roughly of water to the Atlantic Ocean or Gulf of Mexico daily, so there was no opportunity for water storage, yet flooding was still a problem. Without changes to the current system, the Restudy predicted water restrictions would be necessary every other year, and annually in some locations. It also warned that revising some portions of the project without dedicating efforts to an overall comprehensive plan would be insufficient and probably detrimental.\n\nAfter evaluating ten plans, the Restudy recommended a comprehensive strategy that would cost $7.8 billion over 20 years. The plan advised taking the following actions:\n\nThe implementation of all of the advised actions, the report stated, would \"result in the recovery of healthy, sustainable ecosystems throughout south Florida\". The report admitted that it did not have all the answers, though no plan could. However, it predicted that it would restore the \"essential defining features of the pre-drainage wetlands over large portions of the remaining system\", that populations of all animals would increase, and animal distribution patterns would return to their natural states. Critics expressed concern over some unused technology; scientists were unsure if the quarries would hold as much water as was being suggested, and whether the water would harbor harmful bacteria from the quarries. Overtaxing the aquifers was another concern—it was not a technique that had been previously attempted.\n\nThough it was optimistic, the Restudy noted, It is important to understand that the 'restored' Everglades of the future will be different from any version of the Everglades that has existed in the past. While it certainly will be vastly superior to the current ecosystem, it will not completely match the pre-drainage system. This is not possible, in light of the irreversible physical changes that have made (\"sic\") to the ecosystem. It will be an Everglades that is smaller and somewhat differently arranged than the historic ecosystem. But it will be a successfully restored Everglades, because it will have recovered those hydrological and biological patterns which defined the original Everglades, and which made it unique among the world’s wetland systems. It will become a place that kindles the wildness and richness of the former Everglades.\n\nThe report was the result of many cooperating agencies that often had conflicting goals. An initial draft was submitted to Everglades National Park management who asserted not enough water would be released to the park quickly enough—that the priority went to delivering water to urban areas. When they threatened to refuse to support it, the plan was rewritten to provide more water to the park. However, the Miccosukee Indians have a reservation in between the park and water control devices, and they threatened to sue to ensure their tribal lands and a $50 million casino would not be flooded. Other special interests were also concerned that businesses and residents would take second priority after nature. The Everglades, however, proved to be a bipartisan cause. The Comprehensive Everglades Restoration Plan (CERP) was authorized by the Water Resources Development Act of 2000 and signed into law by President Bill Clinton on December 11, 2000. It approved the immediate use of $1.3 billion for implementation to be split by the federal government and other sources.\n\nThe State of Florida reports that it has spent more than $2 billion on the various projects since CERP was signed. More than of Stormwater Treatment Areas (STA) have been constructed to filter of phosphorus from Everglades waters. An STA covering was constructed in 2004, making it the largest manmade wetland in the world. Fifty-five percent of the land necessary for restoration, totaling , has been purchased by the State of Florida. A plan named \"Acceler8\", to hasten the construction and funding of the project, was put into place, spurring the start of six of eight construction projects, including that of three large reservoirs.\n\nDespite the bipartisan goodwill and declarations of the importance of the Everglades, the region still remains in danger. Political maneuvering continues to impede CERP: sugar lobbyists promoted a bill in the Florida legislature in 2003 that increased the acceptable amount of phosphorus in Everglades waterways from 10 ppb to 15 ppb and extended the deadline for the mandated decrease by 20 years. A compromise of 2016 was eventually reached. Environmental organizations express concern that attempts to speed up some of the construction through Acceler8 are politically motivated; the six projects Acceler8 focuses on do not provide more water to natural areas in desperate need of it, but rather to projects in populated areas bordering the Everglades, suggesting that water is being diverted to make room for more people in an already overtaxed environment. Though Congress promised half the funds for restoration, after the War in Iraq began and two of CERP's major supporters in Congress retired, the federal role in CERP was left unfulfilled. According to a story in \"The New York Times\", state officials say the restoration is lost in a maze of \"federal bureaucracy, a victim of 'analysis paralysis' \". In 2007, the release of $2 billion for Everglades restoration was approved by Congress, overriding President George W. Bush's veto of the entire Water Development Project the money was a part of. Bush's rare veto went against the wishes of Florida Republicans, including his brother, Governor Jeb Bush. A lack of subsequent action by the Congress prompted Governor Charlie Crist to travel to Washington D.C. in February 2008 and inquire about the promised funds. By June 2008, the federal government had spent only $400 million of the $7.8 billion legislated. Carl Hiaasen characterized George W. Bush's attitude toward the environment as \"long-standing indifference\" in June 2008, exemplified when Bush stated he would not intervene to change the Environmental Protection Agency's (EPA) policy allowing the release of water polluted with fertilizers and phosphorus into the Everglades.\n\nFlorida still receives a thousand new residents daily and lands slated for restoration and wetland recovery are often bought and sold before the state has a chance to bid on them. The competitive pricing of real estate also drives it beyond the purchasing ability of the state.  Because the State of Florida is assisting with purchasing lands and funding construction, some of the programs under CERP are vulnerable to state budget cuts. In June 2008 Governor Crist announced that the State of Florida will buy U.S. Sugar for $1.7 billion. The idea came when sugar lobbyists were trying to persuade Crist to relax restriction of U.S. Sugar's practice of pumping phosphorus-laden water into the Everglades. According to one of the lobbyists who characterized it as a \"duh moment\", Crist said, \"If sugar is polluting the Everglades, and we're paying to clean the Everglades, why don't we just get rid of sugar?\" The largest producer of cane sugar in the U.S. will continue operations for six years, and when ownership transfers to Florida, of the Everglades will remain undeveloped to allow it to be restored to its pre-drainage state.\n\nIn September 2008 the National Research Council (NRC), a nonprofit agency providing science and policy advice to the federal government, submitted a report on the progress of CERP. The report noted \"scant progress\" in restoration because of problems in budgeting, planning, and bureaucracy. The NRC report called the Everglades one of the \"world's treasured ecosystems\" that is being further endangered by lack of progress: \"Ongoing delay in Everglades restoration has not only postponed improvements—it has allowed ecological decline to continue\". It cited the shrinking tree islands, and the negative population growth of the endangered \"Rostrhamus sociabilis\" or Everglades snail kite, and \"Ammodramus maritimus mirabilis\", the Cape Sable seaside sparrow. The lack of water reaching Everglades National Park was characterized as \"one of the most discouraging stories\" in implementation of the plan. The NRC recommended improving planning on the state and federal levels, evaluating each CERP project annually, and further acquisition of land for restoration. Everglades restoration was earmarked $96 million in federal funds as part of the American Recovery and Reinvestment Act of 2009 with the intention of providing civil service and construction jobs while simultaneously implementing the legislated repair projects.\n\nIn January 2010, work began on the C-111 canal, built in the 1960s to drain irrigated farmland, to reconstruct it to keep from diverting water from Everglades National Park. Two other projects focusing on restoration were also scheduled to start in 2010. Governor Crist announced the same month that $50 million would be earmarked for Everglades restoration. In April of the same year, a federal district court judge sharply criticized both state and federal failures to meet deadlines, describing the cleanup efforts as being slowed by \"glacial delay\" and government neglect of environmental law enforcement \"incomprehensible\".\n\n\n\n\n"}
{"id": "958286", "url": "https://en.wikipedia.org/wiki?curid=958286", "title": "Risø DTU National Laboratory for Sustainable Energy", "text": "Risø DTU National Laboratory for Sustainable Energy\n\nRisø DTU National Laboratory for Sustainable Energy () was a scientific research organization north of Roskilde, Denmark.\n\nThe Risø DTU organisation was founded in 1956 and dissolved on 1 January 2012. The location is now known as DTU Risø Campus and the buildings are home to a number of institutes under the Technical University of Denmark (DTU) and separately is also home to Aarhus University Dept of Environmental Science and part of Dept of Bioscience. Risø covers an area of more than 2.6 square kilometres.\n\nFrom 1 January 2008, it was made an institute of the Technical University of Denmark (DTU). On 1 January 2007, the Technical University of Denmark merged with the Danish Institute for Food and Veterinary Research, the Danish Institute for Fisheries Research, Danish National Space Center, the Danish Transport Research Institute and Risø National Laboratory. Before this, Risø National Laboratory was a research institute under the Danish Ministry of Science, Technology and Innovation and consisted of eight research departments: Biosystems, Polymer Department, Fuel Cells and Solid State Chemistry, Materials Research, Optics and Plasma Research, Radiation Research, Systems Analysis and Wind Energy.\n\nRisø was founded in 1956, but not officially inaugurated until 1958. Niels Bohr played a key role in the founding of Risø and was chairman of the Nuclear Energy Commission charged to promote the peaceful use of nuclear power.\n\nThe mission of Risø was \"to create new knowledge based on world-class research, and to ensure that our knowledge is used to promote the development of an innovative and sustainable society\" (from the web page).\n\nRisø is the site of three research nuclear reactors: DR-1, DR-2 and DR-3. DR-3 is a DIDO class nuclear reactor. All reactors are shut down and undergoing decommissioning.\n\nRisø was in its later years particularly noted for its involvement in wind energy and solid-oxide fuel cells.\n\nRisø had strong competences in climate change effects studies and had \"state of the art\" facilities for realistic climate change experiments and monitoring. These included\n\nThe organization employed about 700 staff (660 person-years) in 2005.\n\nOn 1 January 2012 Risø DTU was dissolved. The location is now called DTU Risø Campus and is home to a number of DTU institutes.\n\n\nWind Atlas Analysis and Application Program (WAsP) is a tool used in the wind energy industry to simulate wind flow over terrain and estimate the long-term energy production of wind turbines and wind farms. It has been in development by Risø National Laboratory for over 25 years, and runs on PCs using Microsoft Windows. The name WAsP is short for WAAAP (\"W, some As, and a P\"), the acronym of the software name. Current version is 12.0 \n\n\n"}
{"id": "35562101", "url": "https://en.wikipedia.org/wiki?curid=35562101", "title": "Sacred natural site", "text": "Sacred natural site\n\nA sacred natural site is a natural feature or a large area of land or water having special spiritual significance to peoples and communities. Sacred natural sites consist of all types of natural features including mountains, hills, forests, groves, trees, rivers, lakes, lagoons, caves, islands and springs. The interest in sacred natural sites, from the perspective of nature conservation, lies in the component of biological diversity that they harbor.\n\nSacred natural sites are natural features in or areas of land or water having special spiritual significance to peoples and communities. This working definition is broad and can be used as a basis for more specific articulations. Whilst “sacred natural sites” is the main term used, for reasons of variety and readability, other terms are used interchangeably, including sacred site, sacred place and sacred area.\n\nThe interest in sacred natural sites from the perspective of nature conservation lies in the components of biological diversity that they harbour, such as the species of animals and plants, the habitats and ecosystems, as well as the ecological dynamics and functions that support life within and outside the places. Linked to such biological diversity is the array of distinct human cultures that care for them and hold them sacred.\n\nSacred natural sites consist of all types of natural features including mountains, hills, forests, groves, rivers, lakes, lagoons, caves, islands and springs. They can vary in size from the very small: an individual tree, small spring, or a single rock formation, to whole landscapes and mountain ranges. They consist of geological formations, distinct landforms, specific ecosystems and natural habitats. They are predominantly terrestrial but are also found in inshore marine areas, islands and archipelagos. They may also be the location of temples, shrines, mosques and churches, and they can incorporate other features such as pilgrimage trails. In some sites nature is itself sacred, while in others sanctity is conferred by connections with spiritual heroes, religious structures or sacred histories.\n\nSacred natural sites are just one of many domains where religions or belief systems interact with nature. Most if not all religions have mythology, cosmology, theology or ethics related to earth, nature and land. Contemporarily, such connections are increasingly being revived or rearticulated through ethical positions expressed for example in statements that many of the mainstream faiths have produced, setting out their relationship to the natural world and their responsibility towards the planet.\n\nSacred sites associated with living cultures always have institutions and rules associated with them. These institutions are usually religious or spiritual in nature and may be distinct from other parts of society, while in some communities of indigenous and traditional peoples, sacred site institutions are closely integrated within society with little distinction between the sacred and secular, the religious and civil.\n\nThe vast majority of sacred natural sites were arguably founded by indigenous or folk religions and spiritualities, but many were subsequently adopted or co-opted by mainstream religions. There is consequently a considerable 'layering' and mixing of religious and other spiritual or belief systems. Within the larger mainstream religions there are many if not more autonomous or semi-autonomous sub-groups. While fifty per cent of the world's population profess to belong to either Christianity or Islam and many others are Hindus or Buddhists, 80 per cent of all people ascribe to a mainstream religion, a large part of which continue to adhere to at least some traditional or folk religion. Sacred natural sites are thus connected to a wide range of socio-cultural systems and institutions, some more complex than others, and to different dynamics of change and cultural interaction.\n\nEstablishing a duality between 'indigenous', in the sense of being native or belonging to a place, and 'mainstream', while pragmatic for discussion, does present some problems. Several mainstream faiths can be considered indigenous in much of their range e.g. Daoism, Shinto, Hinduism and Jainism, while Zoroastrianism now has very few followers and is essentially no longer 'mainstream'. More problematic is that this duality renders invisible the many merged or syncretic faiths and folk variants of mainstream religions where elements of the preceding indigenous beliefs are still practiced. These folk religions can have much stronger nature ethics than the more symbolic orthodox form.\n\nWithin human history, religion has been used (or abused) as a tool of domination. These issues, although much reduced, have not gone away and some faiths still seek converts from other faiths. The destruction of sacred sites has been part of that domination and still continues today. Conversely, most faiths over long periods of time have peaceably co-existed and shared sacred sites. Mutual respect and accommodation have often been reached. Further compassion and peace-building lie at the heart of many religious traditions and belief systems.\n\nSacred natural sites are, with the exception of Antarctica, found on every continent and probably in every country. Some of them are surely among the oldest venerated places of earth and at the same time new sacred natural sites are still being established, in some cases by migrants to new countries. Paleo-anthropological evidence indicates that earlier humans such as Neanderthals practised the cult of ancestors in burial sites over 60,000 years ago, which is arguably one of the origins of sacred sites. Ancestor worship and veneration of burial grounds seem to be a common trait of every culture of modern humans, as well as the adoration of natural features of great significance such as high mountains or large rivers. Australian sacred sites may go back at least 50,000 years; rock art considered of a sacred nature date to 20,000 years ago, and some of the Neolithic henges date from 5,000 years ago.\n\nAt a landscape level, anthropologists have long recognized the sacred status that cultures have given to nature not only in specific sacred sites, but also in larger areas of cultural significance and entire landscapes. Interest on the importance of sacred sites for living cultures has seen an upsurge since the mid 1990s, which has contributed to the exploration of new paradigms and multidisciplinary views to the advantage of both the understanding and conservation of sacred sites.\nBecause of their diversity, origins, and different and varying degrees of sacrality of their elements, it is not really possible to have full knowledge about the number of sacred sites existing in the world today. Exhaustively documenting sacred natural sites would have to be done by bottom-up identification at the community level, which is not really practicable. However, estimates have been made for some countries, notably India, where at least 13,720 sacred groves have been reported and experts estimate that the total number for the country may be in the range of 100,000 to 150,000. India may be exceptional because of its size, cultural diversity and widespread practices about sacred groves, but it would not be unrealistic to estimate that sacred natural sites must exist in the hundreds of thousands.\n\nMany sacred natural sites have been well protected over long time periods and have seen low levels of utilization. Many are demonstrably high in biodiversity and represent a strong biodiversity conservation opportunity. Sacred natural sites also represent ancient and profound cultural values. The roles of sacred sites’ custodians from indigenous, local community and mainstream religions are expressions of dedicated efforts that cultures that have specifically, if not always consciously, cared for nature in various ways.\n\nWhile sacred natural sites are connected to the human spirit and intangible heritage they also have strong material components. In addition to being places where animals and plant species survive, they provide resources such as water and medicines and other ecosystem services, they are the location of events and ceremonies, and traditionally are sites of education. They link to livelihoods in many ways and the concepts of cultural services and human wellbeing are associated with them. They support pilgrimages and tourism, both of which have large associated service sectors and generate significant economic activity.\n\nFollowing a seminal workshop organized by UNESCO in 1998, international conservation organisations like WWF and IUCN, working with indigenous groups and networks such as the Rigoberta Menchu Tum Foundation, started to explore ways to integrate sacred natural sites in their conservation work. A number of international events and processes followed, and case studies and scientific and practitioner articles started to appear in books and journals. In 2003 IUCN’s Specialist Group on the Cultural and Spiritual Values of Protected Areas (CSVPA) and UNESCO started work on guidelines for the management of sacred natural sites. This Group has advanced a significant amount of work on sacred natural sites, including through specific projects such as the Delos Initiative. Among international conservation NGO’s, The Nature Conservancy has developed a planning tool for the conservation of sacred sites and cultural heritage in protected areas and tested it across countries in Central America such as Honduras, El Salvador, Mexico and Guatemala. WWF studied sacred sites in one hundred protected areas.\n\nThe urgent need for the protection of sacred natural sites has also been recognized by the Convention on Biological Diversity (CBD) and the UN Permanent Forum on Indigenous Issues. The CBD in 2004 developed the Akwe Kon voluntary guidelines for the conduct of cultural, environmental and social impact assessments regarding proposed developments that may affect sacred sites and on lands and waters traditionally occupied or used by indigenous and local communities.\n\nAt the political level, as described before, the adoption of the United Nations Declaration on the Rights of Indigenous Peoples is an important benchmark. Article 12 in particular provides significant political leverage for developing appropriate policies for the protection and recognition of sacred natural sites at the national level. It states: “Indigenous peoples have the right to manifest, practice, develop and teach their spiritual and religious traditions, customs and ceremonies; the right to maintain, protect, and have access in privacy to their religious and cultural sites; the right to the use and control of their ceremonial objects; and the right to the repatriation of their human remains.”.\n\nIt is particularly important to raise the concept of free prior, informed consent (FPIC), which has emerged as a standard for engaging with indigenous people and local communities. This is particularly important with regard to sacred natural sites. For many custodians of sacred natural sites secrecy is of the utmost importance and needs serious consideration and respect. At the same time it needs to be recognised that research and inventory can be powerful tools for the communication and conservation of sacred natural sites.\n\nVerschuuren et al. (2010) identified significant global changes, many of which affect sacred natural sites and their custodian communities. These include:\n\nMany of the drivers of these global changes are mutually reinforcing and affect cultural and biological diversity and the many services that sacred natural sites provide to human well-being. \n\nGenerating a greater recognition of the sacred dimensions of nature focused on sacred natural sites is expected to be an important means of building public support for the policies that conserve biodiversity, ecosystem services, and the diversity of human adaptations to a changing environment.\n\n\n"}
{"id": "40069741", "url": "https://en.wikipedia.org/wiki?curid=40069741", "title": "Swedish–Russian Arc-of-Meridian Expedition", "text": "Swedish–Russian Arc-of-Meridian Expedition\n\nThe Swedish–Russian Arc-of-Meridian expedition took place during five summer seasons and one winter season at Svalbard, from 1899. The purpose of the mission was to measure the meridian arcs, in order to calculate whether earth flattening was larger at the poles.\n\nThe measurements were done by an establishing a chain of triangulation points from Keilhaufjellet in Sørkapp Land to Vesle Tavleøya north of Nordaustlandet. The Russians were responsible for the southern measurements, while the Swedes performed the northern measurements from a base at Crozierpynten in the fjord of Sorgfjorden.\n"}
{"id": "53530644", "url": "https://en.wikipedia.org/wiki?curid=53530644", "title": "Three Holy Mountains", "text": "Three Holy Mountains\n\nThe are three mountains revered by tradition in Japan.\nThey include:\n"}
{"id": "212146", "url": "https://en.wikipedia.org/wiki?curid=212146", "title": "Twinkling", "text": "Twinkling\n\nTwinkling, or scintillation, is a generic term for variations in apparent brightness or position of a distant luminous object viewed through a medium. If the object lies outside the Earth's atmosphere, as in the case of stars and planets, the phenomenon is termed \"astronomical scintillation\"; within the atmosphere, the phenomenon is termed \"terrestrial scintillation.\" As one of the three principal factors governing astronomical seeing, atmospheric twinkling is defined as variations in illuminance only.\n\nIn simple terms, twinkling of stars is caused by the passing of light through different layers of a turbulent atmosphere. Most scintillation effects are caused by anomalous refraction caused by small-scale fluctuations in air density usually related to temperature gradients. Scintillation effects are always much more pronounced near the horizon than near the zenith (straight up), since the light near the horizon passes through a thicker layer of atmosphere. Atmospheric twinkling is measured quantitatively using a scintillometer. The effects of twinkling are reduced by using a larger receiver aperture. This effect is known as \"aperture averaging\".\n\nWhile light from stars and other astronomical objects are likely to twinkle, twinkling usually does not cause images of planets to flicker appreciably.\n\nStars twinkle because they are so far from Earth that they appear as point sources of light easily disturbed by Earth's atmospheric turbulence, which acts like lenses and prisms diverting the light's path. Large astronomical objects closer to Earth, like the Moon and other planets, encompass many points in space and can be resolved as objects with observable diameters. With multiple observed points of light traversing the atmosphere, their light's deviations average out and the viewer perceives less variation in light coming from them.\n\n"}
{"id": "8994925", "url": "https://en.wikipedia.org/wiki?curid=8994925", "title": "USC Wrigley Institute for Environmental Studies", "text": "USC Wrigley Institute for Environmental Studies\n\nThe USC Wrigley Institute for Environmental Studies (WIES) is an environmental research and education facility run by the University of Southern California. It is an organized research unit that encompasses a wide range of faculty and topics across the university as well as operating a marine laboratory at the edge of Two Harbors, California on Catalina Island approximately 22 miles (35 km) south-southwest of Los Angeles. \n\nThe USC Wrigley Institute has specialized programs in environmental microbiology, geobiology, ocean biogeochemistry, living marine resources (including fisheries and aquaculture), climate change, coastal environmental quality and the urban ocean. The Institute is also home to the USC Sea Grant Program, part of the National Sea Grant Program through the National Oceanic and Atmospheric Administration.\n\nThe mission of the Wrigley Institute is to encourage responsible and creative decisions in society by providing an objective source of environmental science, and to foster an understanding of the natural world among people of all ages. The faculty conduct academic research that is both good basic science and directly relevant to the needs of society. The Institute operates a \"K-gray\" educational program with extensive outreach into the major student populations of greater Los Angeles. It also creates real linkages between the academic scholarship and decision-making in society.\n\nThe Catalina Island facility centers around the Philip K. Wrigley Marine Science Center (WMSC). This campus on Catalina Island includes, a laboratory building, a dormitory and cottage-style housing, a cafeteria, a hyperbaric chamber, and a large waterfront staging area complete with dock, pier, helipad, moorings, boats and diving lockers. The Institute lies adjacent to Big Fisherman's Cove, a no-take protected refuge. In addition to facilities for researchers and graduate students, the campus is home of USC's Catalina Semester, a 15-week intensive program in marine and environmental studies, as well as educational programs for pre-college students, families, executives and senior citizens. It is one of a handful of marine laboratories in the United States that is specifically open to students and faculty from other institutions.\n\nUSC opened its first facility on the island in 1965 after a grant of more than of land to USC by the Wrigley family. The Science Center is named after Philip K. Wrigley, the son of the founder of the famous gum company. The Wrigley Institute was founded in 1995 after a donation by William and Julie Wrigley.\n\nIn the summer 2007, USC began work on installing six pre-built 48-ton, Tuscan-style houses to the island to house prominent scientists and corporate executives so they would not be placed in the standard dormitories. The homes would add over 20 rooms, and transportation to the remote campus involved both barges to transport them across the ocean channel and heavy cranes to pull the houses up the hill to their final location. \n\nUSC provides regular semi-weekly boat transportation to the facility from the Southern California Marine Institute on Terminal Island.\n\n"}
{"id": "23558328", "url": "https://en.wikipedia.org/wiki?curid=23558328", "title": "Ukeep", "text": "Ukeep\n\nUKEEP is a credit facility developed by the European Bank for Reconstruction and Development (EBRD), targeting Ukrainian private companies in all sectors looking to invest in energy efficiency or renewable energy projects. The UKEEP credit line is provided through participating banks in Ukraine, who in turn on-lend to Ukrainian private companies applying for UKEEP financing. Investments are anticipated to decrease energy consumption, increase own energy production or make energy usage more efficient.\n\nUKEEP is active and is scheduled to run until the end of 2012. UKEEP has so far committed approximately US$102 million to energy efficiency projects in various sectors. Together, these projects will lead to energy savings of more than 2,115,000 MWh per year – equivalent to the household electricity consumption of more than 520,000 households. As a result, CO emissions will decrease by more than 504,000 tonnes per year – equivalent to the annual emissions of more than 225,000 passenger cars.\n\nAt company level the UKEEP concept has turned out to be very profitable with individual Ukrainian companies saving up to 85% of their energy consumption by investing in new and more energy efficient technologies. The success of UKEEP has resulted in EBRD launching similar concepts in several other Eastern European countries.\n\n\n\n"}
{"id": "9780448", "url": "https://en.wikipedia.org/wiki?curid=9780448", "title": "Volcanic Seven Summits", "text": "Volcanic Seven Summits\n\nThe Volcanic Seven Summits are the highest volcanoes on each of the seven continents, just as the Seven Summits are the highest peaks on each of the seven continents. Summiting all seven is regarded as a mountaineering challenge, first postulated as such in 1999.\n\nTwo of the Volcanic Seven Summits are also in the Seven Summits list. Mount Kilimanjaro and Mount Elbrus, which were formed volcanically, are the highest peaks of their respective continents.\n\nDue to different interpretations of continental borders (geological, geographical, geopolitical) several definitions for the highest summits per continent and the number of continents are possible. The number of seven continents used here is based on the continent model used in Western Europe and the United States. The continents as defined here are on a geological and geographical basis, not geopolitical.\n\nAn additional complication in determining the highest volcanic summits is defining exactly what constitutes a volcano and how much topographic prominence it must have relative to any nearby non-volcanic peaks in order to qualify. For the purposes of this list, the summits must be an actual eruptive volcanic center, not merely made of volcanic rocks which were uplifted by other geological processes. In addition, a topographic prominence of at least is required, so that the list includes only genuine volcanic mountains and not minor outpourings of lava which happened to leak to the Earth's surface in high-altitude regions (see \"Asia\" below).\n\nNo serious dispute exists as to the highest volcanoes in Africa, North America, and Antarctica-—respectively, Kilimanjaro, Pico de Orizaba, and Mount Sidley.\n\nAlthough there are a few minor and inactive volcanoes on the Australian mainland, this list recognizes that the island of New Guinea is part of the Australian continent. Numerous scientific papers written in the 1970s and 1980s confirm that Mount Giluwe in Papua New Guinea is in fact an old eroded volcano,\nunlike the higher mountains of New Guinea which are all non-volcanic in origin.\n\nEven if this continent is defined instead as Oceania (thus adding New Zealand and Polynesia including Hawaii), Giluwe remains the highest volcano since it exceeds the elevation of Mauna Kea in Hawaii and any volcano in New Zealand.\n\nThe generally accepted geographical border between Europe and Asia runs along the crest of the Ural Mountains in central Russia and of the Caucasus along the southern border of Russia. Since the massive twin-peaked stratovolcano of Mount Elbrus rises just north of the crest, it is the highest summit in Europe and also the highest volcano.\n\nSome geologists, though, consider the Kuma-Manych depression as the geological border between Asia and Europe. Such definition would render Elbrus entirely in Asia, making it the highest volcano of that continent (see below) and making Mount Etna (a 3350-metre active stratovolcano in Sicily, Italy) the highest volcano in Europe. Mount Teide in the Canary Islands, while active, taller than Etna and within the territory of a European country, would not be considered because geologically the Canaries belong to the African continent.\n\nAlthough Aconcagua, the highest peak in South America and the highest peak in the western hemisphere, does have a volcanic origin, its current high point is due to geological processes rather than being strictly volcanic. Due to this, Aconcagua is not considered to be a volcano on its own, at least not as a member of Volcanic Seven Summits.\n\nTopographic maps of the Argentina and Chile border region which contains the highest peaks suffer from poor accuracy, with elevation errors exceeding in many cases. However, the current consensus based on the most recent measurements places Ojos del Salado as the 2nd highest peak and highest volcano in South America, significantly higher than Monte Pissis.\n\nThe Mount Damavand is a very large isolated stratovolcano with over of topographic prominence.\n\nThere are more than 70 volcanic vents known as the Kunlun Volcanic Group in Tibet at higher elevations than Damavand's summit, the highest of which has a reported elevation of (). Peaks in this volcanic group are not considered volcanic mountains but instead a type of pyroclastic cone. Information about these cones is extremely scarce and the listed elevations and prominences is of unknown accuracy and reliability. It is disputed whether any of these cones have a prominence greater than . The volcanoes in the list below all have prominences far exceeding that threshold.\n\n\"NOTE: Two of the Volcanic Seven Summits, Kilimanjaro and Elbrus, are also members of the Seven Summits. Ojos del Salado is also a member of the Seven Second Summits.\"\n\nDefining the second highest volcanoes on each continent is a bit more complicated, because the continental definitions become critical.\n\nThe problem between Australia and Oceania: Mount Hagen in Papua New Guinea is certainly the second highest volcano on the Australian continent, but expanding the continental definition to span also the broad definition of Oceania drops Hagen to 4th behind Mauna Kea and Mauna Loa on the Island of Hawaii.\n\nIn Europe, Kazbek is the second highest volcano. It lies on the border of Russia and Georgia, whose European status is sometimes disputed, although Kazbek lies entirely on the European side of the Caucasus watershed. The river Terek rises to the south and west of Kazbek but drains northwards to Russia.\n\nAll variant definitions are listed in the table below, so there are 8 volcanoes included:\n\" Mount Kenya is also a member of the Seven Second Summits.\"\n\n\" Territory claimed by New Zealand. However, most nations do not recognize Antarctic territorial claims.\"\n\nIn 2011, Mario Trimeri became the first person to complete both the Volcanic Seven Summits and Seven Summits. \n\nThe youngest person to complete the Volcanic Seven Summits and Seven Summits was Daniel Bull from Australia. His climbs took place between 2006 and 2017, completing the feat at the age of 36. He was also the first Australian to accomplish the feat.\n\n"}
{"id": "2188689", "url": "https://en.wikipedia.org/wiki?curid=2188689", "title": "Weather front", "text": "Weather front\n\nA weather front is a boundary separating two masses of air of different densities, and is the principal cause of meteorological phenomena outside the tropics. In surface weather analyses, fronts are depicted using various colored triangles and half-circles, depending on the type of front. The air masses separated by a front usually differ in temperature and humidity.\n\nCold fronts may feature narrow bands of thunderstorms and severe weather, and may on occasion be preceded by squall lines or dry lines. Warm fronts are usually preceded by stratiform precipitation and fog. The weather usually clears quickly after a front's passage. Some fronts produce no precipitation and little cloudiness, although there is invariably a wind shift.\n\nCold fronts and occluded fronts generally move from west to east, while warm fronts move poleward. Because of the greater density of air in their wake, cold fronts and cold occlusions move faster than warm fronts and warm occlusions. Mountains and warm bodies of water can slow the movement of fronts. When a front becomes stationary—and the density contrast across the frontal boundary vanishes—the front can degenerate into a line which separates regions of differing wind velocity, known as a shearline. This is most common over the open ocean.\n\nThe Bergeron classification is the most widely accepted form of air mass classification. Air mass classifications are indicated by three letters. The first letter describes its moisture properties, with c used for continental air masses (dry) and m for maritime air masses (moist). The second letter describes the thermal characteristic of its source region: T for tropical, P for polar, A for arctic or Antarctic, M for monsoon, E for equatorial, and S for superior air (dry air formed by significant upward motion in the atmosphere). The third letter designates the stability of the atmosphere. If the air mass is colder than the ground below it, it is labeled k. If the air mass is warmer than the ground below it, it is labeled w. Fronts separate air masses of different types or origins, and are located along troughs of lower pressure.\n\nA surface weather analysis is a special type of weather map which provides a view of weather elements over a geographical area at a specified time based on information from ground-based weather stations. Weather maps are created by plotting or tracing the values of relevant quantities such as sea-level pressure, temperature, and cloud cover onto a geographical map to help find synoptic scale features such as weather fronts. Surface weather analyses have special symbols which show frontal systems, cloud cover, precipitation, or other important information. For example, an \"H\" may represent high pressure, implying fair weather. An \"L\" on the other hand may represent low pressure, which frequently accompanies precipitation. Low pressure also creates surface winds deriving from high pressure zones. Various symbols are used not just for frontal zones and other surface boundaries on weather maps, but also to depict the present weather at various locations on the weather map. In addition, areas of precipitation help determine the frontal type and location.\n\nThere are two different meanings used within meteorology to describe weather around a frontal zone. The term \"anafront\" describes boundaries which show instability, meaning air rises rapidly along and over the boundary to cause significant weather changes. A \"katafront\" is weaker, bringing smaller changes in temperature and moisture, as well as limited rainfall.\n\nA cold front is located at the leading edge of the temperature drop off, which in an isotherm analysis shows up as the leading edge of the isotherm gradient, and it normally lies within a sharp surface trough. Cold fronts often bring heavy thunderstorms, rain, and hail. Cold fronts can produce sharper changes in weather and move up to twice as quickly as warm fronts, since cold air is denser than warm air and rapidly replaces the warm air preceding the boundary. On weather maps, the surface position of the cold front is marked with the symbol of a blue line of triangle-shaped pips pointing in the direction of travel, and it is placed at the leading edge of the cooler air mass. Cold fronts come in association with a low-pressure area. The concept of colder, dense air \"wedging\" under the less dense warmer air is often used to depict how air is lifted along a frontal boundary. The cold air wedging underneath warmer air creates the strongest winds just above the ground surface, a phenomenon often associated with property-damaging wind gusts. This lift would then form a narrow line of showers and thunderstorms if enough moisture were present. However, this concept isn't an accurate description of the physical processes; upward motion is not produced because of warm air \"ramping up\" cold, dense air, rather, frontogenetical circulation is behind the upward forcing.\n\nWarm fronts are at the leading edge of a homogeneous warm air mass, which is located on the equatorward edge of the gradient in isotherms, and lie within broader troughs of low pressure than cold fronts. A warm front moves more slowly than the cold front which usually follows because cold air is denser and harder to remove from the Earth's surface.\n\nThis also forces temperature differences across warm fronts to be broader in scale. Clouds ahead of the warm front are mostly stratiform, and rainfall gradually increases as the front approaches. Fog can also occur preceding a warm frontal passage. Clearing and warming is usually rapid after frontal passage. If the warm air mass is unstable, thunderstorms may be embedded among the stratiform clouds ahead of the front, and after frontal passage thundershowers may continue. On weather maps, the surface location of a warm front is marked with a red line of semicircles pointing in the direction of travel.\n\nAn occluded front is formed when a cold front overtakes a warm front, and usually forms around mature low-pressure areas. The cold and warm fronts curve naturally poleward into the point of occlusion, which is also known as the triple point. It lies within a sharp trough, but the air mass behind the boundary can be either warm or cold. In a cold occlusion, the air mass overtaking the warm front is cooler than the cool air ahead of the warm front and plows under both air masses. In a warm occlusion, the air mass overtaking the warm front is warmer than the cold air ahead of the warm front and rides over the colder air mass while lifting the warm air.\n\nA wide variety of weather can be found along an occluded front, with thunderstorms possible, but usually their passage is associated with a drying of the air mass. Within the occlusion of the front, a circulation of air brings warm air upward and sends drafts of cold air downward, or vice versa depending on the occlusion the front is experiencing. Precipitations and clouds are associated with the \"trowal\", the projection on the Earth's surface of the tongue of warm air aloft formed during the occlusion process of the depression.\n\nOccluded fronts are indicated on a weather map by a purple line with alternating half-circles and triangles pointing in direction of travel. The trowal is indicated by a series of blue and red junction lines.\n\nA stationary front is a non-moving (or stalled) boundary between two air masses, neither of which is strong enough to replace the other. They tend to remain essentially in the same area for extended periods of time, usually moving in waves. There is normally a broad temperature gradient behind the boundary with more widely spaced isotherm packing.\n\nA wide variety of weather can be found along a stationary front, but usually clouds and prolonged precipitation are found there. Stationary fronts either dissipate after several days or devolve into shear lines, but they can transform into a cold or warm front if conditions aloft change. Stationary fronts are marked on weather maps with alternating red half-circles and blue spikes pointing in opposite directions, indicating no significant movement.\n\nWhen stationary fronts become smaller in scale, degenerating to a narrow zone where wind direction changes significantly over a relatively short distance, they become known as shearlines. A shearline is depicted as a line of red dots and dashes. Stationary fronts may bring snow or rain for a long period of time.\n\nA similar phenomenon to a weather front is the dry line, which is the boundary between air masses with significant moisture differences. When the westerlies increase on the north side of surface highs, areas of lowered pressure will form downwind of north–south oriented mountain chains, leading to the formation of a lee trough. Near the surface during daylight hours, warm moist air is denser than dry air of greater temperature, and thus the warm moist air wedges under the drier air like a cold front. At higher altitudes, the warm moist air is less dense than the dry air and the boundary slope reverses. In the vicinity of the reversal aloft, severe weather is possible, especially when a triple point is formed with a cold front. A weaker form of the dry line seen more commonly is the lee trough, which displays weaker differences in moisture. When moisture pools along the boundary during the warm season, it can be the focus of diurnal thunderstorms.\n\nThe dry line may occur anywhere on earth in regions intermediate between desert areas and warm seas. The southern plains west of the Mississippi River in the United States are a particularly favored location. The dry line normally moves eastward during the day and westward at night. A dry line is depicted on National Weather Service (NWS) surface analyses as an orange line with scallops facing into the moist sector. Dry lines are one of the few surface fronts where the pips indicated do not necessarily reflect the direction of motion.\n\nOrganized areas of thunderstorm activity not only reinforce pre-existing frontal zones, but can outrun cold fronts in a pattern where the upper level jet splits apart into two streams, with the resultant Mesoscale Convective System (MCS) forming at the point of the upper level split in the wind pattern running southeast into the warm sector parallel to low-level thickness lines. When the convection is strong and linear or curved, the MCS is called a squall line, with the feature placed at the leading edge of the significant wind shift and pressure rise. Even weaker and less organized areas of thunderstorms lead to locally cooler air and higher pressures, and outflow boundaries exist ahead of this type of activity, which can act as foci for additional thunderstorm activity later in the day.\n\nThese features are often depicted in the warm season across the United States on surface analyses and lie within surface troughs. If outflow boundaries or squall lines form over arid regions, a haboob may result. Squall lines are depicted on NWS surface analyses as an alternating pattern of two red dots and a dash labelled SQLN or SQUALL LINE, while outflow boundaries are depicted as troughs with a label of OUTFLOW BOUNDARY.\n\nFronts are the principal cause of significant weather. \"Convective precipitation\" (showers, thundershowers, and related unstable weather) is caused by air being lifted and condensing into clouds by the movement of the cold front or cold occlusion under a mass of warmer, moist air. If the temperature differences of the two air masses involved are large and the turbulence is extreme because of wind shear and the presence of a strong jet stream, \"roll clouds\" and tornadoes may occur.\n\nIn the warm season, lee troughs, breezes, outflow boundaries and occlusions can lead to convection if enough moisture is available. \"Orographic precipitation\" is precipitation created through the lifting action of air moving over terrain such as mountains and hills, which is most common behind cold fronts that move into mountainous areas. It may sometimes occur in advance of warm fronts moving northward to the east of mountainous terrain. However, precipitation along warm fronts is relatively steady, as in rain or drizzle. Fog, sometimes extensive and dense, often occurs in pre-warm-frontal areas. Although, not all fronts produce precipitation or even clouds because moisture must be present in the air mass which is being lifted.\n\nFronts are generally guided by winds aloft, but do not move as quickly. Cold fronts and occluded fronts in the Northern Hemisphere usually travel from the northwest to southeast, while warm fronts move more poleward with time. In the Northern Hemisphere a warm front moves from southwest to northeast. In the Southern Hemisphere, the reverse is true; a cold front usually moves from southwest to northeast, and a warm front moves from northwest to southeast. Movement is largely caused by the pressure gradient force (horizontal differences in atmospheric pressure) and the Coriolis effect, which is caused by Earth's spinning about its axis. Frontal zones can be slowed down by geographic features like mountains and large bodies of warm water.\n\n\n\n"}
