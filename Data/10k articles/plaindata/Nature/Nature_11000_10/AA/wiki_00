{"id": "1063491", "url": "https://en.wikipedia.org/wiki?curid=1063491", "title": "6L6", "text": "6L6\n\n6L6 is the designator for a vacuum tube introduced by Radio Corporation of America in July 1936. At the time Philips had already developed and patented power pentode designs, which were rapidly replacing power triodes due to their greater efficiency. The beam tetrode design of the 6L6 allowed RCA to circumvent Philips' pentode patent.\n\nThe 6L6 is a descendant of the \"Harries Valve\" developed by British engineer J. Owen Harries and marketed by the Hivac Co. Ltd. in 1935. Harries is believed to have been the first engineer to discover the \"critical distance\" effect, which maximized the efficiency of a power tetrode, by positioning its anode at a distance which is a specific multiple of the screen grid-cathode distance. This design also minimized interference of secondary emission electrons dislodged from the anode.\n\nEMI engineers Cabot Bull and Sidney Rodda improved the Harries design with a pair of beam plates, connected to the cathode, which directed the electron streams into two narrow areas and also acted like a suppressor grid to redirect some secondary electrons back to the anode. The beam tetrode design was also undertaken to avoid the patents which the giant Philips firm held on power pentodes in Europe. Because this overall design eliminated the \"tetrode kink\" (negative resistance) in the lower parts of the tetrode's voltage-current characteristic curves, which sometimes caused tetrode amplifiers to become unstable, MOV (Marconi-Osram Valve, a subsidiary of EMI jointly owned with General Electric Company Ltd) marketed this tube family under the sobriquet \"KT\", meaning \"kinkless tetrode\".\n\nBecause MOV's engineers did not feel the kinkless tetrode could be successfully mass-produced, they licensed the design to RCA. This proved to be a poor business decision on MOV's part. RCA subsequently had enormous success with the 6L6. It replaced the use of power triodes in public-address amplifiers almost overnight. So many applications were found for the 6L6 that a complete list would be impossible to assemble. MOV introduced their version, the KT66, a year later.\nRCA's first version was an early octal base tube. Like most with this base it had a metal, rather than glass, envelope. Later versions, including the 6L6G, 6L6GA, 6L6GB, 5881, 5932, 7027, and the final version 6L6GC had glass envelopes, which made radiation cooling of the anode easier. The voltage and power rating of the 6L6 series were gradually pushed upwards by adding features such as a Micanol base, thicker plates, thicker grid wires, grid cooling fins, and special ultra-black plate coatings. The original metal version was rated for 19 watts dissipation while the later 6L6GC is usually rated for 30 watts. A \"W\" in the descriptor, as in 6L6WGB, identifies the tube as designed for mechanically rugged environments, such as military or airborne use.\n\nEarly variations included transmitting tubes such as the 807 (1937) with 6.3V heater, plate (anode) connected to a top cap, and equivalent 12.6V 1625, the smaller 6V6 (1936), the many KT versions marketed in Europe, and a subsequent vast array of audio and RF power tubes. One of the largest-volume post-WWII applications was in the basic design of television sweep power tubes, starting with the 6BG6G (1946), a modified 807. TV designs rarely used transistors in place of sweep tubes—a challenging high-power and high-speed application—until the 1970s.\n\nThe 807 was preferred to the similar 6L6 by amateur radio enthusiasts because high transient voltages on the 6L6's anode when operating in class C could cause a flashover between pins 2 and 3 on the octal base, whereas this was not a problem with the top-cap anode of the otherwise identical 807, physically distant from all the base pins.\n\nIn guitar amplifiers, this flashover problem sometimes occurs if the amplifier is operated without the speakers connected, causing the self inductance of the output transformer primary winding to generate high voltages when the current changes due to the applied signal. For this reason the speaker terminals of 6L6 tube amplifiers are sometimes short-circuited by a switching 6.3 mm jack when the speakers are disconnected.\n\nFurther testimony for this device's success would be even simpler: the 6L6GC version was still being manufactured and used, primarily in guitar amplifiers. Manufacture continued in Russia (two factories), China (two factories), and Slovakia. (In 2006, Ei Electronics in Serbia discontinued making tubes.) The 6L6 has had one of the longest active lifetimes of any electronic component, more than 70 years.\n\n\n\n\n\n"}
{"id": "9570543", "url": "https://en.wikipedia.org/wiki?curid=9570543", "title": "Abu (god)", "text": "Abu (god)\n\nAbu in Sumerian religion was a minor god of plants. He was one of the eight deities born to relieve the illness of Enki. \nAbu means \"father of plants and vegetation.\" \n\nStephen Langdon has proposed that Abu may have been an early name of Tammuz, on the basis that Abu was identified as the consort of Inanna, and that the name Abu did not appear in texts later than the Third Dynasty of Ur. \n\n"}
{"id": "57632784", "url": "https://en.wikipedia.org/wiki?curid=57632784", "title": "Anne Aallonen", "text": "Anne Aallonen\n\nAnne Aallonen (born 15 July 1967) is a Finnish born Hong Kong former professional tennis player.\n\nOn 23 October 1989, she reached her highest WTA singles ranking of 179. On 20 August 1990, she also reached her highest WTA doubles ranking of 116.\n\nAnne Aallonen debuted for the Finland Fed Cup team in 1985, winning her singles match in the tie against the Chinese Taipei Fed Cup team. In 1999 she competed for the Hong Kong Fed Cup team.\n\n"}
{"id": "23589578", "url": "https://en.wikipedia.org/wiki?curid=23589578", "title": "Assimilative capacity", "text": "Assimilative capacity\n\nAssimilative capacity refers to the ability of a body of water to cleanse itself; its capacity to \nreceive waste waters or toxic substances without deleterious effects and without damage to aquatic life or humans who consume the water. \nIt is level to which water body or nature control the toxicity without affecting the aquatic life.\n\nAssimilative capacity is a quantitatively useful concept codified in the Clean Water Act and other laws and regulations that is unrelated to the perception of an environmental crisis. Assimilative capacity specifically refers to the capacity for a water body to absorb constituents without exceeding a specific concentration, such as a water quality objective. Water quality objectives are set and periodically revised by regulatory agencies, such as the EPA, to define the limits of water quality for different uses, which include human health, but also other ecologically important functions, wildlife habitat, irrigated agriculture, etc. For example, if the irrigation water quality objective for salt is 450 mg/L of total dissolved solids, the assimilative capacity of a water body would be the amount of salt that could be added to the water such that it's concentration would not exceed 450 mg/L.\n"}
{"id": "797472", "url": "https://en.wikipedia.org/wiki?curid=797472", "title": "Bone ash", "text": "Bone ash\n\nBone ash is a white material produced by the calcination of bones. Typical bone ash consists of about 55.82% calcium oxide, 42.39% phosphorus pentoxide, and 1.79% water. The exact composition of these compounds varies depending upon the type of bones being used, but generally the formula for bone ash is: Ca(OH)(PO). Bone ash usually has a density around 3.10 g/mL and a melting point of 1670 °C (3038 °F). Most bones retain their cellular structure through calcination.\n\nThe raw material for bone china is about 50% bone ash derived from animal bones. These bones undergo multiple processing stages during which all meat is removed and the bone is completely cleaned. Once cleaned, the bone is heated to about 1000 °C (1832 °F) so that all additional organic material is removed from the bone and the bone becomes sterilized. Lastly, the newly sterilized bone is ground with water into fine particles which can be used as a raw material for bone china. Bone ash plays an important role in the creation of bone china, as the phosphate of the bone generates beta tricalcium phosphate, and other compounds from the bone create a calcium crystal called anorthite. Synthetic alternatives dicalcium phosphate and tricalcium phosphate are used as substitutes for bone ash. Most bone china are produced with synthetic alternatives rather than bone ash.\n\nBone ash can be used alone as an organic fertilizer or it can be treated with sulfuric acid to form a \"single superphosphate\" fertilizer which is more water soluble: \n\nSimilarly, phosphoric acid can be used to form \"triple superphosphate\", a more concentrated phosphorus fertilizer which excludes the gypsum content found in single superphosphate:\n\nBone ash is used in machine shops for various purposes. Examples include polishing compounds, protective powder coatings for metal tools, and as a sealant for seams and cracks. As a powder coating, bone ash has many unique characteristics. First of all, the powder has high thermal stability, so it maintains its form in extremely high temperatures. The powder coating itself adheres to metal well and does not drip, run, cause much corrosion, or create noticeable streaks. Using the bone ash is easy as well, as it comes in a powder form, is easy to clean up, and does not separate into smaller parts (therefore requiring no extra mixing).\n\nBone ash is a material often used in cupellation, a process by which precious metals (such as gold and silver) are removed from base metals.\n\nIn cupellation, base metals in an impure sample are oxidized with the help of lead and are vaporized and absorbed into a porous cupellation material, typically made of magnesium or calcium. This leaves the precious metals which do not oxidize behind. Bone ash's extremely porous and calcareous structure as well as its high melting point makes it an ideal candidate for cupellation.\n\n\n"}
{"id": "85126", "url": "https://en.wikipedia.org/wiki?curid=85126", "title": "Camenae", "text": "Camenae\n\nIn Roman mythology, the Camenae (; also \"Casmenae\", \"Camoenae\") were originally goddesses of childbirth, wells and fountains, and also prophetic deities.\n\nThere were four Camenae: \n\nThe last two were sometimes specifically referred to as the Carmentae, and in ancient times might have been two aspects of Carmenta rather than separate figures; in later times, however, they are distinct beings believed to protect women in labour.\n\nCarmenta was chief among the nymphs. Her festival day, the Carmentalia, featured water ritually drawn by Vestal Virgins from the spring outside the Porta Capena.\n\nThe Camenae were later identified with the Greek Muses; in his translation of Homer's \"Odyssey\", Livius Andronicus rendered the Greek word \"Mousa\" as \"Camena\", and Horace refers to poetic inspiration as the \"soft breath of the Greek Camena\" (spiritum Graiae tenuem Camenae) in Odes II.16.\n\n\n"}
{"id": "4606615", "url": "https://en.wikipedia.org/wiki?curid=4606615", "title": "Candace Savage", "text": "Candace Savage\n\nCandace Sherk Savage (born 1949) is a Canadian non-fiction writer. She won the 2012 Hilary Weston Writers' Trust Prize for Nonfiction for \"A Geography of Blood: Unearthing Memory from a Prairie Landscape\".\nCandace Sherk was born in the Peace River Country of Alberta, Canada, and attended the University of Alberta. She is a frequent contributor to numerous periodicals including \"Canadian Geographic\". A selection of her magazine articles was collected in \"Curious by Nature\" (2005).\n\nSavage lives in Saskatchewan.\n\n\n"}
{"id": "3511814", "url": "https://en.wikipedia.org/wiki?curid=3511814", "title": "Christmas pickle", "text": "Christmas pickle\n\nThe Christmas pickle is a Christmas tradition for some people in the United States. A decoration in the shape of a pickle is hidden on a Christmas tree, with the finder receiving either a reward or good fortune for the following year. There are a number of different origin stories attributed to the tradition, including an origination in Germany. This theory has since been discounted, and it is now thought to be an American tradition created in the late 19th century.\n\nIn the tradition, an ornamental pickle is placed on a Christmas tree as one of the Christmas decorations. On Christmas morning, the first child to find the pickle on the tree would receive an extra present from Santa Claus or would be said to have a year of good fortune.\n\nBerrien Springs, Michigan was known as the Christmas pickle capital of the world. A pickle parade was held from 1992 until about 2003. The village is in the area of Michigan known for cucumber production.\n\nThis tradition is commonly believed by Americans to come from Germany and be referred to as a Weihnachtsgurke, but this is probably apocryphal. In fact, the tradition is completely unknown in Germany. It has been suggested that the origin of the Christmas pickle may have been developed for marketing purposes in the 1890s to coincide with the importation of glass Christmas tree decorations from Germany. Woolworths was the first company to import these types of decorations into the United States in 1890, and glass blown decorative vegetables were imported from France from 1892 onwards. Despite the evidence showing that the tradition did not originate in Germany, the concept of Christmas pickles has since been imported from the United States and they are now on sale in the country traditionally associated with it.\n\nOne suggested origin has been that the tradition came from Camp Sumter during the American Civil War. The Bavarian-born Private John C. Lower had enlisted in the 103rd Pennsylvania Infantry, but was captured in April 1864 and taken to the prison camp. As the story is told, on Christmas Eve he begged a guard for a pickle while starving. The guard provided the pickle, which Lower later credited for saving his life. After returning to his family, he began a tradition of hiding a pickle on their Christmas tree each year.\n\nAnother origin which comes from Berrien Springs is a Victorian era tale of St. Nicholas saving two Spanish children who were trapped in a barrel of pickles by an innkeeper.\n"}
{"id": "23854748", "url": "https://en.wikipedia.org/wiki?curid=23854748", "title": "Cloud drop effective radius", "text": "Cloud drop effective radius\n\nThe cloud drop effective radius (alternatively cloud effective radius or effective radius) is a weighted mean of the size distribution of cloud droplets. The term was defined in 1974 by James E. Hansen and Larry Travis as the ratio of the third to the second moment of a droplet size distribution to aid in the inversion of remotely sensed data. Physically, it is an area weighted radius of the cloud drop particles.\n\nMathematically, this can be expressed as\nformula_1.\n\nThe global effective particle radius has different values for water and ice clouds: the former is around 14 μm, whereas for ice it is around 25 μm. Studies also indicate that the effective cloud droplet radius is larger over oceans than over ground by 15%-20%. By contrast, the difference in the ice particle size over land and oceans is much smaller (only 5%).\n\n"}
{"id": "52791879", "url": "https://en.wikipedia.org/wiki?curid=52791879", "title": "D Carinae", "text": "D Carinae\n\nThe Bayer designations d Carinae and D Carinae are distinct.\n\n"}
{"id": "38807433", "url": "https://en.wikipedia.org/wiki?curid=38807433", "title": "Deep-focus earthquake", "text": "Deep-focus earthquake\n\nA deep-focus earthquake in seismology (also called a plutonic earthquake) is an earthquake with a hypocenter depth exceeding 300 km. They occur almost exclusively at convergent boundaries in association with subducted oceanic lithosphere. They occur along a dipping tabular zone beneath the subduction zone known as the Wadati–Benioff zone.\n\nPreliminary evidence for the existence of deep-focus earthquakes was first brought to the attention of the scientific community in 1922 by Herbert Hall Turner. In 1928, Kiyoo Wadati proved the existence of earthquakes occurring well beneath the lithosphere, dispelling the notion that earthquakes occur only with shallow focal depths.\n\nDeep-focus earthquakes give rise to minimal surface waves. Their focal depth causes the earthquakes to be less likely to produce seismic wave motion with energy concentrated at the surface. The path of deep-focus earthquake seismic waves from focus to recording station goes through the heterogeneous upper mantle and highly variable crust only once. Therefore, the body waves undergo less attenuation and reverberation than seismic waves from shallow earthquakes, resulting in sharp body wave peaks.\n\nThe pattern of energy radiation of an earthquake is represented by the moment tensor solution, which is graphically represented by beachball diagrams. An explosive or implosive mechanism produces an isotropic seismic source. Slip on a planar fault surface results in what is known as a double-couple source. Uniform outward motion in a single plane due to normal shortening gives rise is known as a compensated linear vector dipole source. Deep-focus earthquakes have been shown to contain a combination of these sources.\n\nShallow-focus earthquakes are the result of the sudden release of strain energy built up over time in rock by brittle fracture and frictional slip over planar surfaces. However, the physical mechanism of deep focus earthquakes is poorly understood. Subducted lithosphere subject to the pressure and temperature regime at depths greater than 300 km should not exhibit brittle behavior, but should rather respond to stress by plastic deformation. Several physical mechanisms have been proposed for the nucleation and propagation of deep-focus earthquakes; however, the exact process remains an outstanding problem in the field of deep earth seismology.\n\nThe following four subsections outline proposals which could explain the physical mechanism allowing deep focus earthquakes to occur. With the exception of solid-solid phase transitions, the proposed theories for the focal mechanism of deep earthquakes hold equal footing in current scientific literature.\n\nThe earliest proposed mechanism for the generation of deep-focus earthquakes is an implosion due to a phase transition of material to a higher density, lower volume phase. The olivine-spinel phase transition is thought to occur at a depth of 410 km in the interior of the earth. This hypothesis proposes that metastable olivine in oceanic lithosphere subducted to depths greater than 410 km undergoes a sudden phase transition to spinel structure. The increase in density due to the reaction would cause an implosion giving rise to the earthquake. This mechanism has been largely discredited due to the lack of a significant isotropic signature in the moment tensor solution of deep-focus earthquakes.\n\nDehydration reactions of mineral phases with high weight percent water would increase the pore pressure in a subducted oceanic lithosphere slab. This effect reduces the effective normal stress in the slab and allow slip to occur on pre-existing fault planes at significantly greater depths that would normally be possible. Several workers suggest that this mechanism does not play a significant role in seismic activity beyond 350 km depth due to the fact that most dehydration reactions will have reached completion by a pressure corresponding to 150 to 300 km depth (5-10 GPa).\n\nTransformational faulting, also known as anticrack faulting, is the result of the phase transition of a mineral to a higher density phase occurring in response to shear stress in a fine-grained shear zone. The transformation occurs along the plane of maximal shear stress. Rapid shearing can then occur along these planes of weakness, giving rise to an earthquake in a mechanism similar to a shallow-focus earthquake. Metastable olivine subducted past the olivine-wadsleyite transition at 320--410 km depth (depending on temperature) is a potential candidate for such instabilities. Arguments against this hypothesis include the requirements that the faulting region should be very cold, and contain very little mineral-bound hydroxyl. Higher temperatures or higher hydroxyl contents preclude the metastable preservation of olivine to the depths of the deepest earthquakes.\n\nA shear instability arises when heat is produced by plastic deformation faster than it can be conducted away. The result is thermal runaway, a positive feedback loop of heating, material weakening and strain-localisation within the shear zone. Continued weakening may result in partial melting along zones of maximal shear stress. Plastic shear instabilities leading to earthquakes have not been documented in nature, nor have they been observed in natural materials in the laboratory. Their relevance to deep earthquakes therefore lies in mathematical models which use simplified material properties and rheologies to simulate natural conditions.\n\nThe strongest deep-focus earthquake in seismic record was the magnitude 8.3 Okhotsk Sea earthquake that occurred at a depth of 609 km in 2013. The deepest earthquake ever recorded was a small 4.2 earthquake in Vanuatu at a depth of 735.8 km in 2004.\n"}
{"id": "20962425", "url": "https://en.wikipedia.org/wiki?curid=20962425", "title": "Diaspore (botany)", "text": "Diaspore (botany)\n\nIn botany, a diaspore is a plant dispersal unit consisting of a seed or spore plus any additional tissues that assist dispersal. In some seed plants, the diaspore is a seed and fruit together, or a seed and elaiosome. In a few seed plants, the diaspore is most or all of the plant, and is known as a tumbleweed.\n\nDiaspores are common in weedy and ruderal species. Collectively, diaspores, seeds, and spores that have been modified for migration are known as \"disseminules\".\n\nA diaspore of seed plus elaiosome is a common adaptation to seed dispersal by ants (myrmecochory). This is most notable in Australian and South African sclerophyll plant communities. Typically, ants carry the diaspore to their nest, where they may eat the elaiosome and discard the seed, and the seed may subsequently germinate.\nA diaspore of seed(s) plus fruit is common in plants dispersed by frugivores. Fruit-eating bats typically carry the diaspore to a favorite perch, where they eat the fruit and discard the seed. Fruit-eating birds typically swallow small seeds but, like bats, may carry larger seeded fruits to a perch where they eat the fruit and discard the seed. Diaspores such as achenes and samarae are dispersed primarily by wind; samaras are dispersed also by sailing or tumbling as they fall in still air. Drift fruits and some others are dispersed by water.\n\nTumbleweeds are dispersed by wind, sometimes over very long distances. These occur in a variety of weedy and ruderal species native to steppes and deserts. Grasses have various units of dispersal: rarely the caryopsis alone, often a diaspore. Disarticulation occurs below, between, or above the glumes and at all nodes. Although in some species the diaspore is a foxtail, in a few (the \"tumble grasses\") it is like a tumbleweed.\n\n"}
{"id": "140558", "url": "https://en.wikipedia.org/wiki?curid=140558", "title": "Fiber", "text": "Fiber\n\nFiber or fibre (see spelling differences, from the Latin fibra) is a natural or synthetic substance that is significantly longer than it is wide. Fibers are often used in the manufacture of other materials. The strongest engineering materials often incorporate fibers, for example carbon fiber and ultra-high-molecular-weight polyethylene.\n\nSynthetic fibers can often be produced very cheaply and in large amounts compared to natural fibers, but for clothing natural fibers can give some benefits, such as comfort, over their synthetic counterparts.\n\nNatural fibers develop or occur in the fiber shape, and include those produced by plants, animals, and geological processes. They can be classified according to their origin:\n\nHuman-made or chemical fibers are fibers whose chemical composition, structure, and properties are significantly modified during the manufacturing process. Man-made fibers consist of regenerated fibers and synthetic fibers.\nSemi-synthetic fibers are made from raw materials with naturally long-chain polymer structure and are only modified and partially degraded by chemical processes, in contrast to completely synthetic fibers such as nylon (polyamide) or dacron (polyester), which the chemist synthesizes from low-molecular weight compounds by polymerization (chain-building) reactions. The earliest semi-synthetic fiber is the cellulose regenerated fiber, rayon. Most semi-synthetic fibers are cellulose regenerated fibers.\n\nCellulose fibers are a subset of man-made fibers, regenerated from natural cellulose. The cellulose comes from various sources: rayon from tree wood fiber, Modal from beech trees, bamboo fiber from bamboo, seacell from seaweed, etc. In the production of these fibers, the cellulose is reduced to a fairly pure form as a viscous mass and formed into fibers by extrusion through spinnerets. Therefore, the manufacturing process leaves few characteristics distinctive of the natural source material in the finished products.\n\nSome examples of this fiber type are:\n\nHistorically, cellulose diacetate and -triacetate were classified under the term rayon, but are now considered distinct materials.\n\nSynthetic come entirely from synthetic materials such as petrochemicals, unlike those man-made fibers derived from such natural substances as cellulose or protein.\n\nFiber classification in reinforced plastics falls into two classes: (i) short fibers, also known as discontinuous fibers, with a general aspect ratio (defined as the ratio of fiber length to diameter) between 20 and 60, and (ii) long fibers, also known as continuous fibers, the general aspect ratio is between 200 and 500.\n\nMetallic fibers can be drawn from ductile metals such as copper, gold or silver and extruded or deposited from more brittle ones, such as nickel, aluminum or iron.\nSee also Stainless steel fibers.\n\nCarbon fibers are often based on oxidized and via pyrolysis carbonized polymers like PAN, but the end product is almost pure carbon.\n\nSilicon carbide fibers, where the basic polymers are not hydrocarbons but polymers, where about 50% of the carbon atoms are replaced by silicon atoms, so-called poly-carbo-silanes. The pyrolysis yields an amorphous silicon carbide, including mostly other elements like oxygen, titanium, or aluminium, but with mechanical properties very similar to those of carbon fibers.\n\nFiberglass, made from specific glass, and optical fiber, made from purified natural quartz, are also man-made fibers that come from natural raw materials, silica fiber, made from sodium silicate (water glass) and basalt fiber made from melted basalt.\n\nMineral fibers can be particularly strong because they are formed with a low number of surface defects, asbestos is a common one.\n\n\nMicrofibers in textiles refer to sub-denier fiber (such as polyester drawn to 0.5 denier). Denier and Dtex are two measurements of fiber yield based on weight and length. If the fiber density is known, you also have a fiber diameter, otherwise it is simpler to measure diameters in micrometers. Microfibers in technical fibers refer to ultra fine fibers (glass or meltblown thermoplastics) often used in filtration. Newer fiber designs include extruding fiber that splits into multiple finer fibers. Most synthetic fibers are round in cross-section, but special designs can be hollow, oval, star-shaped or trilobal. The latter design provides more optically reflective properties. Synthetic textile fibers are often crimped to provide bulk in a woven, non woven or knitted structure. Fiber surfaces can also be dull or bright. Dull surfaces reflect more light while bright tends to transmit light and make the fiber more transparent.\n\nVery short and/or irregular fibers have been called fibrils. Natural cellulose, such as cotton or bleached kraft, show smaller fibrils jutting out and away from the main fiber structure.\n\n"}
{"id": "26681607", "url": "https://en.wikipedia.org/wiki?curid=26681607", "title": "Gembone", "text": "Gembone\n\nGembone is mineralized bone, often dinosaur bone, which has had the individual cells fossilized with precious minerals. It is one of four gemstones created from organisms (the others being Pearl, Ammolite, and Amber). Many minerals can be found in Gembone including hematite, iron, pyrite, jasper, marcasite, agate, quartz or other crystal.\n"}
{"id": "59075217", "url": "https://en.wikipedia.org/wiki?curid=59075217", "title": "Heidy Mader", "text": "Heidy Mader\n\nProfessor Heidy M. Mader of the University of Bristol is a British physicist who specialises in the flow of materials and particularly in the flow of lava from volcanic eruptions. She is the editor-in-chief of the \"Journal of Volcanology and Geothermal Research\".\n"}
{"id": "6914199", "url": "https://en.wikipedia.org/wiki?curid=6914199", "title": "Hinode", "text": "Hinode\n\nHinode (; , , Sunrise), formerly Solar-B, is a Japan Aerospace Exploration Agency Solar mission with United States and United Kingdom collaboration. It is the follow-up to the Yohkoh (Solar-A) mission and it was launched on the final flight of the M-V-7 rocket from Uchinoura Space Center, Japan on 22 September 2006 at 21:36 UTC (23 September, 06:36 JST). Initial orbit was perigee height 280 km, apogee height 686 km, inclination 98.3 degrees. Then the satellite maneuvered to the quasi-circular sun-synchronous orbit over the day/night terminator, which allows near-continuous observation of the Sun. On 28 October 2006, the probe's instruments captured their first images.\n\nThe data from Hinode are being downloaded to the Norwegian, terrestrial Svalsat station, operated by \"Kongsberg\" a few kilometres west of Longyearbyen, Svalbard. From there, data was transmitted by Telenor through a fibre-optic network to mainland Norway at Harstad, and on to data users in North America, Europe and Japan.\n\nHinode was planned as a three-year mission to explore the magnetic fields of the Sun. It consists of a coordinated set of optical, extreme ultraviolet (EUV), and x-ray instruments to investigate the interaction between the Sun's magnetic field and its corona. The result will be an improved understanding of the mechanisms that power the solar atmosphere and drive solar eruptions. The EUV imaging spectrometer ( EIS ) was built by a consortium led by the Mullard Space Science Laboratory (MSSL) in the UK. NASA, the space agency of the United States, was involved with three science instrument components: the Focal Plane Package (FPP), the X-Ray Telescope (XRT), and the Extreme Ultraviolet Imaging Spectrometer (EIS) and shares operations support for science planning and instrument command generation.\n\nHinode carries three main instruments to study the Sun:\n\n\n\n\n"}
{"id": "916433", "url": "https://en.wikipedia.org/wiki?curid=916433", "title": "Hot Bird", "text": "Hot Bird\n\nHot Bird is a group of satellites operated by Eutelsat, located at 13°E over the Equator (orbital position) and with a transmitting footprint over Asia, Europe, North Africa, \nAmericas and the Middle East.\n\nOnly digital radio and television channels are transmitted by the Hot Bird constellation, both free-to-air and encrypted. In addition there are a few interactive and IP services. The satellites currently operate at 13° East and are numbered 13B, 13C and 13D.\n\nHot Bird 1 was launched by Ariane 44LP on 28 March 1995. The 13° east slot predates the launch, with Eutelsat 1F1 having been located there as early as 1983, and Eutelsat 2F1 having also served time at the location. It has reached end-of-life.\n\nHot Bird 3 was launched by Ariane 44LP on 2 September 1997 and intended to be moved to 10°E to become Eurobird 10. During the drift from 13°E to 10°E, the satellite suffered loss of power from one solar array. It was nevertheless successfully moved to 10°E, but could only operate at a reduced capacity. Since then, it is operating at 4°E under the name Eurobird 4. At last it was moved to 75°E and renamed to ABS_1B. It has reached end-of-life.\n\nHot Bird 4 was launched by Ariane 42P on 27 February 1998 and redeployed to 7°W in July 2006, becoming Atlantic Bird 4 / Nilesat 103\n\nHot Bird 5 was launched by Atlas-2A on 9 October 1998 and re-located to 25.5°E and renamed Eurobird 2. Six transponders are leased to Arabsat under the name Badr 2, after having been called Arabsat 2D.\n\nHot Bird 6 was launched by Atlas V 401 on 21 July 2002. Starting on 12 June 2009, the day of Iranian elections, deliberate interference affecting this satellite was traced to Iran. Hot Bird 6 is the primary carrier for BBC Persian Television. As of 2013, it is replaced with Hot Bird 10 (Hot Bird 13D)\n\nHot Bird 7 was lost in December 2002 during the Ariane 5 ECA launch. Its replacement, Hot Bird 7A (a Spacebus 3000B3) was successfully launched on 11 March 2006.\n\nHot Bird 8 was launched by Proton on 5 August 2006. With a launch mass of 4.9 tonnes, Hot Bird 8 is the largest and the most powerful broadcast satellite serving Europe.\n\nHot Bird 9 was launched by Ariane 5 ECA in December 2008. Its entry into service enabled the Hot Bird 7A satellite to be redeployed to 9° East and rebranded Eurobird 9A, increasing capacity to 38 transponders at this orbital position.\n\nHot Bird 10 was launched by Ariane 5 ECA in February 2009 with NSS-9, Spirale A and Spirale B. The Eutelat 33E satellite is located at 33° East, Eutelsat’s premium video neighbourhood for cable and satellite broadcasting in Europe, North Africa and the Middle East.\n\n\nUp to 1000 television and radio channels are available Free-To-Air.\n\n"}
{"id": "53911039", "url": "https://en.wikipedia.org/wiki?curid=53911039", "title": "Laboratoire des sciences du climat et de l'environnement", "text": "Laboratoire des sciences du climat et de l'environnement\n\nThe Laboratoire des sciences du climat et de l'environnement (LSCE, Climate and Environment Sciences Laboratory) is a laboratory for the study of climate and in particular climate change. It is part of the Institute Pierre Simon Laplace, and located on campuses in L'Orme des Merisiers and Gif sur Yvette.\n\nThe group plays a prominent role in the framework of the Intergovernmental Panel on Climate Change and includes modellers in glaciology, remote sensing and air quality study.\n\n"}
{"id": "292984", "url": "https://en.wikipedia.org/wiki?curid=292984", "title": "Lahar", "text": "Lahar\n\nA lahar (, from ) is a violent type of mudflow or debris flow composed of a slurry of pyroclastic material, rocky debris and water. The material flows down from a volcano, typically along a river valley.\n\nLahars are extremely destructive: they can flow tens of metres per second (22 mph or more), they have been known to be up to deep, and large flows tend to destroy any structures in their path. They have even been known to decimate entire settlements. Notable lahars include those at Mount Pinatubo and Nevado del Ruiz, the latter of which killed thousands of people and caused extensive damage to infrastructure.\n\nThe word \"lahar\" is of Javanese origin. The geological term was introduced by Berend George Escher in 1922.\n\nA lahar is a volcanic mudflow or debris flow. Lahars have the consistency, viscosity and approximate density of wet concrete: fluid when moving, solid at rest. Lahars can be huge. The Osceola Lahar produced by Mount Rainier (Washington) some 5600 years ago resulted in a wall of mud deep in the White River canyon, which covered an area of over , for a total volume of .\n\nA lahar of sufficient size and intensity can erase virtually any structure in its path, and is capable of carving its own pathway, making the prediction of its course difficult. Conversely, a lahar quickly loses force when it leaves the channel of its flow: even frail huts may remain standing, while at the same time being buried to the roof line in mud. A lahar's viscosity decreases with time, and can be further thinned by rain, but it nevertheless solidifies quickly when coming to a stop.\n\nLahars vary in size and speed. Small lahars less than a few metres wide and several centimetres deep may flow a few metres per second. Large lahars hundreds of meters wide and tens of meters deep can flow several tens of metres per second (22 mph or more): much too fast for people to outrun. With the potential to flow at speeds up to , and flow distances of more than , a lahar can cause catastrophic destruction in its path.\n\nLahars from the 1985 Nevado del Ruiz eruption in Colombia caused the Armero tragedy, which killed an estimated 23,000 people, when the city of Armero was buried under of mud and debris. A lahar caused New Zealand's Tangiwai disaster, where 151 people died after a Christmas Eve express train fell into the Whangaehu River in 1953. Lahars have been responsible for 17% of volcano-related deaths between 1783 and 1997. A lahar can cause fatalities years after its precipitating eruption. For example, the Cabalantian tragedy occurred four years subsequent to the 1991 eruption of Mount Pinatubo.\n\nLahars have several possible causes:\nIn particular, although lahars are typically associated with the effects of volcanic activity, lahars can occur even without any current volcanic activity, as long as the conditions are right to cause the collapse and movement of mud originating from existing volcanic ash deposits.\n\nSeveral mountains in the world, including Mount Rainier in the United States, Mount Ruapehu in New Zealand, Merapi and Galunggung in Indonesia, are considered particularly dangerous due to the risk of lahars. Several towns in the Puyallup River valley in Washington state, including Orting, are built on top of lahar deposits that are only about 500 years old. Lahars are predicted to flow through the valley every 500 to 1,000 years, so Orting, Sumner, Puyallup, Fife, and the Port of Tacoma face considerable risk.\nThe USGS has set up lahar warning sirens in Pierce County, Washington, so that people can flee an approaching debris flow in the event of a Mount Rainier eruption.\n\nA lahar warning system has been set up at Mount Ruapehu by the New Zealand Department of Conservation and hailed as a success after it successfully alerted officials to an impending lahar on 18 March 2007.\n\nSince mid-June 1991, when violent eruptions triggered Mount Pinatubo's first lahars in 500 years, a system to monitor and warn of lahars has been in operation. Radio-telemetered rain gauges provide data on rainfall in lahar source regions, acoustic flow monitors on stream banks detect ground vibration as lahars pass, and manned watchpoints further confirm that lahars are rushing down Pinatubo's slopes. This system has enabled warnings to be sounded for most but not all major lahars at Pinatubo, saving hundreds of lives. Physical preventative measures by the Philippine government were not adequate to stop over of mud from flooding many villages around Mount Pinatubo from 1992 through 1998.\n\nScientists and governments try to identify areas with a high risk of lahars based on historical events and computer models. Volcano scientists play a critical role in effective hazard education by informing officials and the public about realistic hazard probabilities and scenarios (including potential magnitude, timing, and impacts); by helping evaluate the effectiveness of proposed risk-reduction strategies; by helping promote acceptance of (and confidence in) hazards information through participatory engagement with officials and vulnerable communities as partners in risk reduction efforts; and by communicating with emergency managers during extreme events. An example of such a model is TITAN2D. These models are directed towards future planning: identifying low-risk regions to place community buildings, discovering how to mitigate lahars with dams, and constructing evacuation plans.\n\nIn 1985, the volcano Nevado del Ruiz erupted in central Colombia. As pyroclastic flows erupted from the volcano's crater, they melted the mountain's glaciers, sending four enormous lahars down its slopes at . The lahars picked up speed in gullies and coursed into the six major rivers at the base of the volcano; they engulfed the town of Armero, killing more than 20,000 of its almost 29,000 inhabitants.\n\nCasualties in other towns, particularly Chinchiná, brought the overall death toll to 23,000. Footage and photographs of Omayra Sánchez, a young victim of the tragedy, were published around the world. Other photographs of the lahars and the impact of the disaster captured attention worldwide and led to controversy over the degree to which the Colombian government was responsible for the disaster.\n\nThe 1991 eruption of Mount Pinatubo caused lahar flows: the first eruption itself killed six people, but the lahar flows killed more than 1500. The eye of Typhoon Yunya passed over the volcano during its eruption on June 15, 1991. The rain from the typhoon triggered the flow of volcanic ash, boulders, and water down the rivers surrounding the volcano. In Pampanga, Angeles City and neighbouring cities and towns were damaged by the volcano's sticky lahar floods when Sapang Balen Creek and the Abacan River became the channels for the mudflows and carried it to the heart of the city and surrounding areas.\n\nOver of mud inundated and damaged the towns of Castillejos, San Marcelino and Botolan in Zambales, Porac and Mabalacat City in Pampanga, Tarlac City, Capas, Concepcion and Bamban in Tarlac. The lahar floods down the Sacobia-Bamban River scoured all structures in its path, including the bridges and dikes by the Parua River in Concepcion. The Tarlac River in Tarlac City was inundated by over of lahar, causing the river to lose the ability to hold water.\n\nOn the morning of October 1, 1995, pyroclastic material which clung to the slopes of Pinatubo and surrounding mountains rushed down because of heavy rain, and turned into an lahar flood. These mudflows killed hundreds of people in Barangay Cabalantian in Bacolor. The Philippine government under President Fidel V. Ramos ordered the construction of the FVR Mega Dike in an attempt to protect people from further mudflows.\n\nAnother typhoon-volcano lahar hit the Philippines in 2006; see Typhoon Reming.\n\n\n"}
{"id": "23649740", "url": "https://en.wikipedia.org/wiki?curid=23649740", "title": "Lawrence Mott", "text": "Lawrence Mott\n\nJordan Lawrence Mott IV (1881–1931), often referred to as Jordan Lawrence Mott III and better known as Lawrence Mott, was an American novelist and writer on the outdoor life. He was the great-grandson of Jordan L. Mott (born 1799), who founded the J. L. Mott Iron Works in New York City. His grandfather was Jordan Lawrence Mott II (10 November 1829 – 26 July 1915), and his father was Jordan Lawrence Mott III (born 13 May 1857).\n\nAfter graduating from Harvard, Mott worked as a journalist, and married Carolyn Pitkin (1881–1967). In 1912 he sailed to China on a freighter, the \"Indrade\", with a light opera singer, Mrs Francis Hewitt Bowne: he was listed as purser and she was disguised as a cabin boy. The couple married in 1928 after their respective partners had divorced them. His published works include \"Jules of the Great Heart: “free” trapper and outlaw in the Hudson Bay region in the early days\" (1905), \"To the Credit of the Sea\" (1907), \"The White Darkness, and other stories of the Great North-West\" (1907), and \"Prairie, Snow and Sea\" (1910). He pioneered fishing for steelhead on the North Umpqua River, Oregon, and a bridge and a section of the North Umpqua Trail bear the name Mott in his memory. He established a fishing camp near Steamboat Creek, where he died, of leukemia, in 1931.\n"}
{"id": "5642622", "url": "https://en.wikipedia.org/wiki?curid=5642622", "title": "Leopold matrix", "text": "Leopold matrix\n\nThe Leopold matrix is a qualitative environmental impact assessment method pioneered in 1971. It is used to identify the potential impact of a project on the environment. The system consists of a matrix with columns representing the various activities of the project, and rows representing the various environmental factors to be considered. The intersections are filled in to indicate the magnitude (from -10 to +10) and the importance (from 1 to 10) of the impact of each activity on each environmental factor.\n\nMeasurements of magnitude and importance tend to be related, but do not necessarily directly correlate. Magnitude can be measured, in terms of how much area is affected by the development and how badly, but importance is a more subjective measurement. While a proposed development may have a large impact in terms of magnitude, the effects it causes may not actually significantly affect the environment as a whole. The example given by Leopold is of a stream that significantly alters the erosion patterns in a specific area, which will have a significant magnitude, but may not be important, provided the stream in question is swift moving and transports large amounts of soil anyway. In this case, an impact of significant magnitude may not actually be important to the environment in question.\n\n"}
{"id": "48043615", "url": "https://en.wikipedia.org/wiki?curid=48043615", "title": "List of Solar System extremes", "text": "List of Solar System extremes\n\nThis article describes extreme locations of the Solar System. Entries listed in bold are Solar System-wide extremes.\n\n\n\n"}
{"id": "41422923", "url": "https://en.wikipedia.org/wiki?curid=41422923", "title": "List of dust storms", "text": "List of dust storms\n\nThis is a list of significant dust storms.\n\n"}
{"id": "26413989", "url": "https://en.wikipedia.org/wiki?curid=26413989", "title": "List of fen plants", "text": "List of fen plants\n\nThe following is a list of plant species to be found in a north European fen habitat with some attempt to distinguish between reed bed relicts and the carr pioneers. However, nature does not come in neat compartments so that for example, the odd stalk of common reed will be found in carr.\n\n\n\n\n"}
{"id": "3784112", "url": "https://en.wikipedia.org/wiki?curid=3784112", "title": "List of mountains in Romania", "text": "List of mountains in Romania\n\nThis is an (incomplete) list of mountains in Romania. There are 12 peaks over 2,500 m in Romania.\n\n"}
{"id": "38696877", "url": "https://en.wikipedia.org/wiki?curid=38696877", "title": "List of nature centers in Rhode Island", "text": "List of nature centers in Rhode Island\n\nThis is a list of nature centers and environmental education centers in the state of Rhode Island. \nTo use the sortable tables: click on the icons at the top of each column to sort that column in alphabetical order; click again for reverse alphabetical order.\n\n"}
{"id": "8591368", "url": "https://en.wikipedia.org/wiki?curid=8591368", "title": "List of stars in Camelopardalis", "text": "List of stars in Camelopardalis\n\nThis is the list of notable stars in the constellation Camelopardalis, sorted by decreasing brightness.\n\n\n"}
{"id": "29215186", "url": "https://en.wikipedia.org/wiki?curid=29215186", "title": "List of taxa published in Bulletin de la Société Sciences Nat", "text": "List of taxa published in Bulletin de la Société Sciences Nat\n\nThe following is a list of the taxa described in the \"Bulletin de la Société Sciences Nat\". The \"Bulletin de la Société Sciences Nat\" published 83 issues between 1972 and 1995.\n\nTaxon names are followed by the last names of the authors and the issue and page references. The publications dates are listed below.\n"}
{"id": "20692837", "url": "https://en.wikipedia.org/wiki?curid=20692837", "title": "List of tributaries of the Tigris", "text": "List of tributaries of the Tigris\n\nThis is a list of tributaries of the Tigris by order of entrance.\n\nThe Tigris originates in Turkey, forms a part of the borders of Turkey-Syria and flows through Iraq. It joins the Euphrates forming Shatt al-Arab, which empties into the Persian Gulf.\n"}
{"id": "206295", "url": "https://en.wikipedia.org/wiki?curid=206295", "title": "Mare Spumans", "text": "Mare Spumans\n\nMare Spumans (from Latin: \"foaming sea\") is a lunar mare located just south of Mare Undarum on the lunar near side. It is one of the many elevated lakes contained in the Crisium basin, surrounding Mare Crisium. The surrounding basin material is of the Nectarian epoch, while the mare basalt being of the Upper Imbrian epoch. The crater Petit (formerly ) is located on the western rim of the mare. This crater is white and surrounded by a well-defined ray system.\n"}
{"id": "3335767", "url": "https://en.wikipedia.org/wiki?curid=3335767", "title": "Meander", "text": "Meander\n\nA meander is one of a series of regular sinuous curves, bends, loops, turns, or windings in the channel of a river, stream, or other watercourse. It is produced by a stream or river swinging from side to side as it flows across its floodplain or shifts its channel within a valley. A meander is produced by a stream or river as it erodes the sediments comprising an outer, concave bank (cut bank) and deposits this and other sediment downstream on an inner, convex bank which is typically a point bar. The result of sediments being eroded from the outside concave bank and their deposition on an inside convex bank is the formation of a sinuous course as a channel migrates back and forth across the down-valley axis of a floodplain. The zone within which a meandering stream shifts its channel across either its floodplain or valley floor from time to time is known as a meander belt. It typically ranges from 15 to 18 times the width of the channel. Over time, meanders migrate downstream, sometimes in such a short time as to create civil engineering problems for local municipalities attempting to maintain stable roads and bridges.\n\nThe degree of meandering of the channel of a river, stream, or other watercourse is measured by its sinuosity. The sinuosity of a watercourse is the ratio of the length of the channel to the straight line down-valley distance. Streams or rivers with a single channel and sinuosities of 1.5 or more are defined as meandering streams or rivers.\n\nThe term derives from the Meander River located in present-day Turkey and known to the Ancient Greeks as Μαίανδρος \"Maiandros\" (Latin: \"Maeander\"), characterised by a very convoluted path along the lower reach. As a result, even in Classical Greece (and in later Greek thought) the name of the river had become a common noun meaning anything convoluted and winding, such as decorative patterns or speech and ideas, as well as the geomorphological feature. Strabo said: ‘…its course is so exceedingly winding that everything winding is called meandering.’\n\nThe Meander River is located south of Izmir, east of the ancient Greek town of Miletus, now Milet, Turkey. It flows through a graben in the Menderes Massif, but has a flood plain much wider than the meander zone in its lower reach. Its modern Turkish name is the Büyük Menderes River.\n\nWhen a fluid is introduced to an initially straight channel which then bends, the sidewalls induce a pressure gradient that causes the fluid to alter course and follow the bend. From here, two opposing processes occur: (1) irrotational flow and (2) secondary flow. For a river to ‘meander’, secondary flow must dominate.\n\nIrrotational flow: From Bernoulli's equations, high pressure results in low velocity. Therefore, \"in the absence of secondary flow\" we would expect low fluid velocity at the outside bend and high fluid velocity at the inside bend. This classic fluid mechanics result is \"irrotational vortex flow.\" In the context of meandering rivers, its effects are dominated by those of secondary flow.\n\nSecondary flow: A force balance exists between pressure forces pointing to the inside bend of the river and centrifugal forces pointing to the outside bend of the river. In the context of meandering rivers, a boundary layer exists within the thin layer of fluid that interacts with the river bed. Inside that layer and following standard boundary-layer theory, the velocity of the fluid is effectively zero. Centrifugal force, which depends on velocity, is also therefore effectively zero. Pressure force, however, remains unaffected by the boundary layer. Therefore, within the boundary layer, pressure force dominates and fluid moves along the bottom of the river from the outside bend to the inside bend. This initiates helicoidal flow: Along the river bed, fluid roughly follows the curve of the channel but is also forced toward the inside bend; away from the river bed, fluid also roughly follows the curve of the channel but is forced, to some extent, from the inside to the outside bend. Ultimately, the downstream velocity of the fluid is convectively transported to the outside bend, resulting in higher velocities at the outside bend. This secondary flow effect dominates over that of irrotational flow: In real meandering rivers, we observe higher downstream fluid velocities at the outside bends.\n\nThe higher (lower) velocities at the outside (inside) bend result in higher (lower) shear stresses and therefore results in erosion (deposition). Thus meander bends erode at the outside bend, causing the river to becoming increasingly sinuous (until cutoff events occur). Deposition at the inside bend occur such that for most natural meandering rivers, the river width remains nearly constant, even as the river evolves.\n\nThe technical description of a meandering watercourse is termed meander geometry or meander planform geometry. It is characterized as an irregular waveform. Ideal waveforms, such as a sine wave, are one line thick, but in the case of a stream the width must be taken into consideration. The bankfull width is the distance across the bed at an average cross-section at the full-stream level, typically estimated by the line of lowest vegetation.\n\nAs a waveform the meandering stream follows the down-valley axis, a straight line fitted to the curve such that the sum of all the amplitudes measured from it is zero. This axis represents the overall direction of the stream.\n\nAt any cross-section the flow is following the sinuous axis, the centerline of the bed. Two consecutive crossing points of sinuous and down-valley axes \ndefine a meander loop. The meander is two consecutive loops pointing in opposite transverse directions. The distance of one meander along the down-valley axis \nis the meander length or wavelength. The maximum distance from the down-valley axis to the sinuous axis of a loop is the meander width or amplitude. The course at that point is the apex.\n\nIn contrast to sine waves, the loops of a meandering stream are more nearly circular. The curvature varies from a maximum at the apex to zero at a crossing point (straight line), also called an inflection, because the curvature changes direction in that vicinity. The radius of the loop is the straight line perpendicular to the down-valley axis intersecting the sinuous axis at the apex. As the loop is not ideal, additional information is needed to characterize it. The orientation angle is the angle between sinuous axis and down-valley axis at any point on the sinuous axis.\nA loop at the apex has an outer or concave bank and an inner or convex bank. The meander belt is defined by an average meander width measured from outer bank to outer bank instead of from centerline to centerline. If there is a flood plain, it extends beyond the meander belt. The meander is then said to be free—it can be found anywhere in the flood plain. If there is no flood plain, the meanders are fixed.\n\nVarious mathematical formulae relate the variables of the meander geometry. As it turns out some numerical parameters can be established, which appear in the formulae. The waveform depends ultimately on the characteristics of the flow but the parameters are independent of it and apparently are caused by geologic factors. In general the meander length is 10–14 times, with an average 11 times, the fullbank channel width and 3 to 5 times, with an average of 4.7 times, the radius of curvature at the apex. This radius is 2–3 times the channel width.\n\nA meander has a depth pattern as well. The cross-overs are marked by riffles, or shallow beds, while at the apices are pools. In a pool direction of flow is downward, scouring the bed material. The major volume, however, flows more slowly on the inside of the bend where, due to decreased velocity, it deposits sediment.\n\nThe line of maximum depth, or channel, is the thalweg or thalweg line. It is typically designated the borderline when rivers are used as political borders. The thalweg hugs the outer banks and returns to center over the riffles. The meander arc length is the distance along the thalweg over one meander. The river length is the length along the centerline.\n\nMeander formation is a result of natural factors and processes. The waveform configuration of a stream is constantly changing. Fluid flows around a bend in a vortex. Once a channel begins to follow a sinusoidal path, the amplitude and concavity of the loops increase dramatically due to the effect of helical flow sweeping dense eroded material towards the inside of the bend, and leaving the outside of the bend unprotected and therefore vulnerable to accelerated erosion, forming a positive feedback loop. In the words of Elizabeth A. Wood:‘…this process of making meanders seems to be a self-intensifying process…in which greater curvature results in more erosion of the bank, which results in greater curvature…’\n\nThe cross-current along the floor of the channel is part of the secondary flow and sweeps dense eroded material towards the inside of the bend. The cross-current then rises to the surface near the inside and flows towards the outside, forming the helical flow. The greater the curvature of the bend, and the faster the flow, the stronger is the cross-current and the sweeping.\n\nDue to the conservation of angular momentum the speed on the inside of the bend is faster than on the outside.\n\nSince the flow velocity is diminished, so is the centrifugal pressure. However, the pressure of the super-elevated column prevails, developing an unbalanced gradient that moves water back across the bottom from the outside to the inside. The flow is supplied by a counter-flow across the surface from the inside to the outside. This entire situation is very similar to the Tea leaf paradox. This secondary flow carries sediment from the outside of the bend to the inside making the river more meandering.\n\nAs to why streams of any size become sinuous in the first place, there are a number of theories, not necessarily mutually exclusive.\n\nThe stochastic theory can take many forms but one of the most general statements is that of Scheidegger: ‘The meander train is assumed to be the result of the stochastic fluctuations of the direction of flow due to the random presence of direction-changing obstacles in the river path.’\nGiven a flat, smooth, tilted artificial surface, rainfall runs off it in sheets, but even in that case adhesion of water to the surface and cohesion of drops produce rivulets at random. Natural surfaces are rough and erodible to different degrees. The result of all the physical factors acting at random is channels that are not straight, which then progressively become sinuous. Even channels that appear straight have a sinuous thalweg that leads eventually to a sinuous channel.\n\nIn the equilibrium theory, meanders decrease the stream gradient until an equilibrium between the erodibility of the terrain and the transport capacity of the stream is reached. A mass of water descending must give up potential energy, which, given the same velocity at the end of the drop as at the beginning, is removed by interaction with the material of the stream bed. The shortest distance; that is, a straight channel, results in the highest energy per unit of length, disrupting the banks more, creating more sediment and aggrading the stream. The presence of meanders allows the stream to adjust the length to an equilibrium energy per unit length in which the stream carries away all the sediment that it produces.\n\nGeomorphic refers to the surface structure of the terrain. Morphotectonic means having to do with the deeper, or tectonic (plate) structure of the rock. The features included under these categories are not random and guide streams into non-random paths. They are predictable obstacles that instigate meander formation by deflecting the stream. For example, the stream might be guided into a fault line (morphotectonic).\n\nA cut bank is an often vertical bank or cliff that forms where the outside, concave bank of a meander cuts into the floodplain or valley wall of a river or stream. A cutbank is also known either as a river-cut cliff, river cliff, or a bluff and spelled as cutbank. Erosion that forms a cut bank occurs at the outside bank of a meander because helicoidal flow of water keeps the bank washed clean of loose sand, silt, and sediment and subjects it to constant erosion. As a result, the meander erodes and migrates in the direction of the outside bend, forming the cut bank.\n\nAs the cut bank is undermined by erosion, it commonly collapses as slumps into the river channel. The slumped sediment, having been broken up by slumping, is readily eroded and carried toward the middle of the channel. The sediment eroded from a cut bank tends to be deposited on the point bar of the next downstream meander, and not on the point bar opposite it. This can be seen in areas where trees grow on the banks of rivers; on the inside of meanders, trees, such as willows, are often far from the bank, whilst on the outside of the bend, the tree roots are often exposed and undercut, eventually leading the trees to fall into the river.\n\nA meander cutoff, also known as either a cutoff meander or abandoned meander, is a meander that has been abandoned by its stream after the formation of a neck cutoff. A lake that occupies a cutoff meander is known as an \"oxbow lake\". Cutoff meanders that have cut downward into the underlying bedrock are known in general as incised cutoff meanders. As in the case of the Anderson Bottom Rincon, incised meanders that have either steep-sided, often vertical walls, are often, but not always, known as rincons in the southwest United States. \"Rincon\" in English is a nontechnical word in the southwest United States for either a small secluded valley, an alcove or angular recess in a cliff, or a bend in a river.\n\nThe meanders of a stream or river that has cut its bed down into the bedrock are known as either incised, intrenched, entrenched, inclosed or ingrown meanders. Some Earth scientists recognize and use a finer subdivision of incised meanders. Thornbury argues that \"incised\" or \"inclosed meanders\" are synonyms that are appropriate to describe any meander incised downward into bedrock and defines \"enclosed\" or \"entrenched meanders\" as a subtype of incised meanders (inclosed meanders) characterized by a symmetrical valley sides. He argues that the symmetrical valley sides are the direct result of rapid down-cutting of a watercourse into bedrock. In addition, as proposed by Rich, Thornbury argues that incised valleys with a pronounced asymmetry of cross section, which he called \"ingrown meanders\", are the result of the lateral migration and incision of a meander during a period of slower channel downcutting. Regardless, the formation of both entrenched meanders and ingrown meanders is thought to require that base level falls as a result of either relative change in mean sea level, isostatic or tectonic uplift, the breach of an ice or landslide dam, or regional tilting. Classic examples of incised meanders are associated with rivers in the Colorado Plateau, the Kentucky River Palisades in central Kentucky, and streams in the Ozark Plateau.\n\nAs noted above, it was initially either argued or presumed that an incised meander is characteristic of an antecedent stream or river that had incised its channel into underlying strata. An antecedent stream or river is one that maintains its original course and pattern during incision despite the changes in underlying rock topography and rock types. However, later geologists argue that the shape of an incised meander is not always, if ever, \"inherited,\" e.g., strictly from an antecedent meandering stream where it meander pattern could freely develop on a level floodplain. Instead, they argue that as fluvial incision of bedrock proceeds, the stream course is significantly modified by variations in rock type and fractures, faults, and other geological structures into either \"lithologically conditioned meanders\" or \"structurally controlled meanders\".\n\nThe oxbow lake, which is the most common type of fluvial lake, is a crescent-shaped lake that derives its name from its distinctive curved shape. Oxbow lakes are also known as cutoff lakes. Such lakes form regularly in undisturbed floodplains as a result of the normal process of fluvial meandering. Either a river or stream forms a sinuous channel as the outer side of its bends are eroded away and sediments accumulate on the inner side, which forms a meandering horseshoe-shaped bend. Eventually as the result of its meandering, the fluvial channel cuts through the narrow neck of the meander and forms a cutoff meander. The final break-through of the neck, which is called a neck cutoff, often occurs during a major flood because that is when the watercourse is out of its banks and can flow directly across the neck and erode it with the full force of the flood.\n\nAfter a cutoff meander is formed, river water flows into its end from the river builds small delta-like feature into either end of it during floods. These delta-like features block either end of the cutoff meander to form a stagnant oxbow lake that is separated from the flow of the fluvial channel and independent of the river. During floods, the flood waters deposit fine-grained sediment into the oxbow lake. As a result, oxbow lakes tend to become filled in with fine-grained, organic-rich sediments over time.\n\nA point bar, which is also known as a meander bar, is a fluvial bar that is formed by the slow, often episodic, addition of individual accretions of noncohesive sediment on the inside bank of a meander by the accompanying migration of the channel toward its outer bank. This process is called lateral accretion. Lateral accretion occurs mostly during high water or floods when the point bar is submerged. Typically, the sediment consists of either sand, gravel, or a combination of both. The sediment comprising some point bars might grade downstream into silty sediments. Because of the decreasing velocity and strength of current from the thalweg of the channel to the upper surface of point bar when the sediment is deposited the vertical sequence of sediments comprising a point bar becomes finer upward within an individual point bar. For example, it is typical for point bars to fine upward from gravel at the base to fine sands at the top. The source of the sediment is typically upstream cut banks from which sand, rocks and debris has been eroded, swept, and rolled across the bed of the river and downstream to the inside bank of a river bend. On the inside bend, this sediment and debris is eventually deposited on the slip-off slope of a point bar.\n\nScroll-bars are a result of continuous lateral migration of a meander loop that creates an asymmetrical ridge and swale topography on the inside of the bends. The topography is generally parallel to the meander, and is related to migrating bar forms and back bar chutes, which carve sediment from the outside of the curve and deposit sediment in the slower flowing water on the inside of the loop, in a process called lateral accretion. Scroll-bar sediments are characterized by cross-bedding and a pattern of fining upward. These characteristics are a result of the dynamic river system, where larger grains are transported during high energy flood events and then gradually die down, depositing smaller material with time (Batty 2006). Deposits for meandering rivers are generally homogeneous and laterally extensive unlike the more heterogeneous braided river deposits.\nThere are two distinct patterns of scroll-bar depositions; the eddy accretion scroll bar pattern and the point-bar scroll pattern. When looking down the river valley they can be distinguished because the point-bar scroll patterns are convex and the eddy accretion scroll bar patterns are concave.\n\nScroll bars often look lighter at the tops of the ridges and darker in the swales. This is because the tops can be shaped by wind, either adding fine grains or by keeping the area unvegetated, while the darkness in the swales can be attributed to silts and clays washing in during high water periods. This added sediment in addition to water that catches in the swales is in turn is a favorable environment for vegetation that will also accumulate in the swales.\n\nDepending upon whether a meander is part of an entrenched river or part of a freely meandering river within a floodplain, the term slip-off slope can refer to two different fluvial landforms that comprise the inner, convex, bank of a meander loop. In case of a freely meandering river on a floodplain, a \"slip-off slope\" is the inside, gently sloping bank of a meander on which sediments episodically accumulate to form a point bar as a river meanders. This type of slip-off slope is located opposite the cutbank. This term can also be applied to the inside, sloping bank of a meandering tidal channel.\n\nIn case of an entrenched river, a \"slip-off slope\" is a gently sloping bedrock surface that rises from the inside, concave bank of an asymmetrically entrenched river. This type of slip-off slope is often covered by a thin, discontinuous layer of alluvium. It is produced by the gradual outward migration of the meander as a river cuts downward into bedrock. A terrace on the slip-off slope of a meander spur, known as slip-off slope terrace, can formed by a brief halt during the irregular incision by an actively meandering river.\n\nThe meander ratio or sinuosity index is a means of quantifying how much a river or stream meanders (how much its course deviates from the shortest possible path). It is calculated as the length of the stream divided by the length of the valley. A perfectly straight river would have a meander ratio of 1 (it would be the same length as its valley), while the higher this ratio is above 1, the more the river meanders.\n\nSinuosity indices are calculated from the map or from an aerial photograph measured over a distance called the reach, which should be at least 20 times the average fullbank channel width. The length of the stream is measured by channel, or thalweg, length over the reach, while the bottom value of the ratio is the downvalley length or air distance of the stream between two points on it defining the reach.\n\nThe sinuosity index plays a part in mathematical descriptions of streams. The index may require elaboration, because the valley may meander as well—i.e., the downvalley length is not identical to the reach. In that case the valley index is the meander ratio of the valley while the channel index is the meander ratio of the channel. The channel sinuosity index is the channel length divided by the valley length and the standard sinuosity index is the channel index divided by the valley index. Distinctions may become even more subtle.\n\nSinuosity Index has a non-mathematical utility as well. Streams can be placed in categories arranged by it; for example, when the index is between 1 and 1.5 the river is sinuous, but if between 1.5 and 4, then meandering. The index is a measure also of stream velocity and sediment load, those quantities being maximized at an index of 1 (straight).\n\n\n"}
{"id": "29175559", "url": "https://en.wikipedia.org/wiki?curid=29175559", "title": "Michael Viney", "text": "Michael Viney\n\nMichael Viney MRIA (born 1933) is an artist, author, broadcaster, and journalist, based in Ireland. He was born in Brighton, England. He is best known for his writings on nature.\n\nIn the 1960s he wrote for \"The Irish Times\" about social issues such as the fate of people in institutional care. His articles were later incorporated into the Ryan Report on institutional abuse of children in Ireland.\n\nViney has published \"Another Life\", a weekly column in \"The Irish Times\", since 1977 when he settled in rural Murrisk, near the coast south of Louisburgh. Over the years the focus of the column has shifted from sustainability to natural history.\n\nIn 1966, Viney won a Jacob's Award for his RTÉ Television documentary, \"Too Many Children\".\n\nHe is a member of Aosdána, an association of people who have achieved distinction in the arts.\n\nHe was elected to the Royal Irish Academy in May 2017.\n\nViney´s books include:\n"}
{"id": "7277803", "url": "https://en.wikipedia.org/wiki?curid=7277803", "title": "Ministry of Petroleum (Iran)", "text": "Ministry of Petroleum (Iran)\n\nThe Ministry of Petroleum (MOP) ( \"Vezârat-e Naft\") manages the oil industry, the producer of oil and petrochemical products. MoP is in charge of all issues pertaining to exploration, extraction, exploitation, distribution and exportation of crude oil and oil products. In addition, according to the \"Imports and Exports Regulation Act\", issuing import licenses for such products is also among the functions of the Ministry of Petroleum. According to BP, Iran's has of proven oil reserves and 29.61 trillion cubic meters of proven gas reserves. Iran ranks third in the world in oil reserves and second in gas reserves. It is responsible for applying the principle of Iranian ownership and sovereignty over oil and gas reserves. Also, it is undertake the separation of sovereignty tasks from management and development of country's oil and gas industry.\n\nThe Ministry of petroleum was established after revolution in Iran and in the interim government of Bazargan, after departure of Hasan Nazia, the managing director of National Iranian Oil Company from the country in 1979. The organizational structure of this ministry consists of a central headquarters and four subsidiaries, including National Iranian Oil Company, National Iranian Gas Company, National Iranian Petrochemical Company and National Iranian Oil Refining and Distribution Company. It monitors the operations of exploration, extraction, marketing and sale of crude oil, natural gas and oil products in the country through its subsidiaries and subsidiaries. In addition to meeting its major energy needs, the ministry supplies over 80% of foreign currency earnings by exporting crude oil and refined petroleum products.\n\nAccording to the Fourth Economic, Social and Cultural Development Plan, the Government has been required to transfer at least 10% of the activities related to the exploration, extraction and production of crude oil to the private sector, while in the meantime retaining its ownership of oil resources. This is also the case in other fields of the Ministry of Petroleum's activities.\n\nIran plans to invest $500 billion in the oil sector until 2025. As of 2010, US$70 billion worth of oil and gas projects are under construction. Iran's annual oil and gas revenues will reach $250 billion by 2015.\n\nThe Ministry of petroleum of Islamic Republic of Iran was formed with the aim of applying the principle of Iranian national ownership and sovereignty to oil and gas resources, and separating sovereignty functions from company in the management and development of oil and gas industry of the country. Since the petroleum industry has a special role in the country's economy as a propellant industry and plays a key role in achieving the major goals of national economy, the ministry's performance is very important.\n\nIran holds 836.47 billion barrels of liquid hydrocarbon reserves (crude oil, liquids and gas condensate) and about 34 trillion gas reserves. It is ranked first in the world in terms of having a total hydrocarbon reserves and in terms of energy security in the world. Also, the privileges like geopolitical position of the country and availability of powerful human capital have given it more strength.\n\nThe National Petroleum Procurement Proposal was signed by 17 representatives of National Petroleum Commission on December 8, 1950. In the text of message was following: “we are proposing for Iranian oil industry to be announced in all regions of the country without exception under the name of well-being of Iranian people and in order to contribute to peace of the world: all exploration, extraction and exploitation operations be in the control of government.” \n\nFollowing the announcement of this proposal, “the law of oil Nationalization throughout the country and two-month extension to Petroleum Commission to study around implementation of this principle” passed in National Assembly and eventually in the Senate on March 29, 1950. Thus, The National Iranian Oil Company was established.\n\nFirst board of directors of National Iranian Oil Company was constituted by implementing the law of oil industry nationalization and after expropriation of former British oil company in June 1951. Then, new rules were adopted for this new company.\n\nThe legal framework for activities of National Iranian Oil Company in discussion of hydrocarbons sources and its products was determined by approving the “Law on Development of Petrochemical Industries (with subsequent amendments)” on July 20, 1965 and the “Law on Development of Gas Industry” on May 25, 1972. In addition, the extent of Iranian or foreign companies and firms has clarified to participate in petrochemical product plans.\n\nFinally, a detailed description of presenting and receiving proposals, signing contracts, contract termination, conservation and preventing environmental pollution, maintaining Iran's interests and pricing conditions were presented by the approval of first “Oil Act” on August 8, 1974, in addition to defining the terms and conditions of work within hydrocarbon resources of whole country.\n\nUpon approval of first “Oil Act”, the “Law on Statute of National Iranian Oil Company” was ratified in five seasons on May 17, 1977.\n\n“General and capital”, “subject, duties, rights and authorities of company”, “the entity of company”, “balance sheet and profit and loss account” have formed first four chapters of the statute. In the fifth chapter of this law is also addressed to “other regulations”.\n\nSubsequently, the “Statute of National Petrochemical Company” and “Statute of National Iranian Gas Company” were approved on November 21, and November 25, 1977, respectively.\n\nAfter Islamic Revolution of Iran, the editing and approval of new laws were also on the agenda of Islamic Consultative Assembly with the necessity of following some principles and with regard to departure of foreign experts. Hence, new oil law was approved on October 9, 1987.\n\nFollowing the announcement of this proposal, “the law of oil Nationalization throughout the country and two-month extension to Petroleum Commission to study around implementation of this principle” passed in National Assembly and eventually in the Senate on March 29, 1950. Thus, The National Iranian Oil Company was established.\n\nFirst board of directors of National Iranian Oil Company was constituted by implementing the law of oil industry nationalization and after expropriation of former British oil company in June 1951. Then, new rules were adopted for this new company.\n\nThe legal framework for activities of National Iranian Oil Company in discussion of hydrocarbons sources and its products was determined by approving the “Law on Development of Petrochemical Industries (with subsequent amendments)” on July 20, 1965 and the “Law on Development of Gas Industry” on May 25, 1972. In addition, the extent of Iranian or foreign companies and firms has clarified to participate in petrochemical product plans.\n\nFinally, a detailed description of presenting and receiving proposals, signing contracts, contract termination, conservation and preventing environmental pollution, maintaining Iran's interests and pricing conditions were presented by the approval of first “Oil Act” on August 8, 1974, in addition to defining the terms and conditions of work within hydrocarbon resources of whole country.\n\nUpon approval of first “Oil Act”, the “Law on Statute of National Iranian Oil Company” was ratified in five seasons on May 17, 1977.\n\n“General and capital”, “subject, duties, rights and authorities of company”, “the entity of company”, “balance sheet and profit and loss account” have formed first four chapters of the statute. In the fifth chapter of this law is also addressed to “other regulations”.\n\nSubsequently, the “Statute of National Petrochemical Company” and “Statute of National Iranian Gas Company” were approved on November 21, and November 25, 1977, respectively.\n\nAfter Islamic Revolution of Iran, the editing and approval of new laws were also on the agenda of Islamic Consultative Assembly with the necessity of following some principles and with regard to departure of foreign experts. Hence, new oil law was approved on October 9, 1987.\n\nThe Iranian constitution prohibits the granting of petroleum rights on a concessionary basis or direct equity stake. However, the 1987 Petroleum Law permits the establishment of contracts between the ministry, state companies and \"local and foreign national persons and legal entities.\" Buyback contracts, for instance, are arrangements in which the contractor funds all investments, receives remuneration from the National Iranian Oil Company (NIOC) in the form of an allocated production share, then transfers operation of the field to NIOC after a set number of years, at which time the contract is completed.\n\nSince the 1979 revolution in Iran, the country has been under constant US unilateral sanctions. The first U.S. sanctions against Iran were formalized in November 1979, and during the hostage crisis, many sanctions were leveled against the Iranian government. By 1987 the import of Iranian goods into the United States had been banned. In 1995, President of the United States Bill Clinton issued Executive Order 12957, banning U.S. investment in Iran's energy sector, followed a few weeks later by Executive Order 12959 eliminating all trade and investment and virtually all interaction between the United States and Iran.\n\nSpecifically the ministry has been on the sanction list of the European Union since 16 October 2012.\n\nThe features of fifth development plan in oil industry include: a systemic template of a set of interconnected components that interact with each other to exchange data, information, materials and products, and they perform a targeted move. Also, different parts of the plan have been coordinated and have been seen as a value chain in industry as a whole.\n\nObjective 1: increase the share and improve position of oil, gas and petrochemical industry in the region and the world, to increase extraction of oil and gas with priority of common fields with neighboring countries, increasing refining capacity\n\nObjective 2: Optimum use of hydrocarbon reserves of the country as backing and stimulus for sustainable economic development of the country.\n\nObjective 3: Use of oil and gas industry capacity to defend national interest Objective 4: Implement energy management to prevent waste in the country's fuel consumption, reducing energy intensity and granting targeted subsidies\n\nObjective 5: Establishing effective and constructive interaction with energy producer and consumer countries; playing management role of Iran in energy distribution and transit.\n\nObjective 6: Realizing the general policies of article 44 of the constitution in oil industry\n\nObjective 7: Achieve advanced technology in oil, gas and petrochemical industries to reach the second position of science and technology in the region.\n\nObjective 8: Changing the look to oil and gas and its revenues, from source of public funding to “economic productive resources and capitals”\n\nObjective 9: Increase productivity in various sectors of oil industry in order to grow GDP (Gross Domestic Product)\n\nNational Iranian Oil Company (NIOC) is in charge of oil and gas exploration and production, processing and oil transportation.\nNational Iranian South Oil Company (NISOC) is an important subsidiary of NIOC. NISOC is producing about 83% percent of all crude oil and 16% percent of natural gas produced in Iran.\n\nNational Iranian Oil Company subsidiaries:\n\nNational Iranian Gas Company (NIGC) manages gathering, treatment, processing, transmission, distribution, and exports of gas and gas liquids.\n\nThe huge reserves of natural gas put Iran in the second place, in terms of the natural gas reserve quantity, among other countries, only next to the Russian Federation, with an estimate of proven reserve quantity close to 23 bcm. Iran's gas reserves are exploited primarily for domestic use.\n\nNational Iranian Petrochemical Company (NPC) handles petrochemical production, distribution, and exports. National Iranian Petrochemical Company's output capacity will increase to over 100 million tpa by 2015 from an estimated 50 million tpa in 2010 thus becoming the world' second largest chemical producer globally after Dow Chemical with Iran housing some of the world's largest chemical complexes.\n\nNational Iranian Oil Refining and Distribution Company (NIORDC) handles oil refining and transportation, with some overlap to NIOC.\n\nThere are eight refineries with a potential capacity of and one refinery complex in the country with a total refining capacity of over (in Tehran, Tabriz, Isfahan, Abadan, Kermanshah, Shiraz, Bandar Abbas, Arak and Lavan Island) and a storage capacity of 8 milliard litre. Abundance of basic material, like natural gas, in the country provide favorable conditions for development and expansion of petrochemical plants.\n\n\n\nIran’s total revenues from the sale of oil amounted to $77 billion in Iranian year 1387 (2008–09). The average sale price of Iran’s crude oil during that year was $100 per barrel. According to the National Iranian Oil Company, Iran’s average daily production of crude oil stood at per day. Of this amount, 55% was exported and the remainder was consumed domestically. As of 2010, oil income accounts for 80% of Iran's foreign currency revenues and 60% of the nation's overall budget.\nIran exported over of oil in the one year to 21 March 2010, averaging around a day. The exports included around of light crude and more than of heavy crude oil. Japan, China, South Africa, Brazil, Pakistan, Sri Lanka, Spain, India and the Netherlands are the main importers of Iran's crude oil. Iran's annual oil revenues reached $100 billion in 2011. Iran's annual oil \"and gas\" revenues are expected to reach $250 billion by 2015, including $100 billion from Iran's South Pars giant gas field.\n\nAs of 2012, the Ministry of Petroleum in Iran handles 4,000 public (non-oil) projects across the country. The estimated value of the projects stands at 53,868 trillion rials (approximately $4 trillion).\n\n\n"}
{"id": "21097089", "url": "https://en.wikipedia.org/wiki?curid=21097089", "title": "National Oceanographic Partnership Program", "text": "National Oceanographic Partnership Program\n\nThe National Oceanographic Partnership Program (NOPP) facilitates interagency and multi-sectoral partnerships to address federal ocean science and technology research priorities. Through this collaboration, federal agencies can leverage resources to invest in priorities that fall between agency missions or are too large for any single agency to support. In its first 20 years, NOPP invested more than $468 million to support over 200 research and education projects with over 600 partners. A comparable amount of in-kind support has been committed by the research and education community.\n\nNOPP was established in 1997 through the National Oceanographic Partnership Act (PL 104-201, 10 USC 7901-7903) to improve the nation’s knowledge of the ocean, with the goals of promoting national security, advancing economic development, protecting quality of life, and strengthening science education and communication.\n\nNOPP policies are determined by the NOPP Committee, which is composed of Federal agency representatives committed to advancing ocean science and technology initiatives through partnerships. The NOPP Committee establishes NOPP implementation procedures and selects NOPP projects through agency-issued calls for proposals. The Biodiversity Ad-Hoc Working Group and Federal Renewable Ocean Energy Working Group (FROEWG) are subcommittees of the NOPP Committee focused on facilitating interagency communications and collaborations around their respective focus areas. \n\nNOPP also supports the Interagency Working Group on Facilities and Infrastructure (IWG-FI) and the Ocean Research Advisory Panel (ORAP). IWG-FI is a subgroup of the National Science and Technology Council’s Subcommittee on Ocean and Science Technology. IWG-FI reviews and evaluates Federal infrastructure regarding facilities (e.g., ships) necessary for conducting ocean research and observation, and is involved in evaluating future needs and planning future investments in ocean-related facilities. ORAP provides independent recommendations to federal agencies that relate to the ocean and is composed of representatives from the National Academies, state governments, academic institutions, and ocean industries. \n\nNOPP has significantly impacted the realm of ocean science and technology and results from NOPP research projects have informed both federal ocean policy and federal and regional natural resource management. Through its outreach efforts and support of the National Ocean Sciences Bowl, NOPP has inspired careers in STEM fields. \n\nNOPP contributions have increased the volume and efficiency of ocean research and stimulated the development of applied ocean technology. Perhaps the most important role of NOPP has been to increase multi-disciplinary, cross-sector research partnering and strengthen communication about the most pressing research needs within the national ocean science community. \n\nIn general, NOPP projects fall within the categories of ocean observation systems, marine infrastructure and technology, earth systems modelling, coastal and marine resources, ocean education, and marine life. Projects that exemplify the highest level of success in achieving NOPP goals and working in diverse sector partnerships are awarded the yearly NOPP Excellence in Partnering Award. Some examples of NOPP-funded projects include: \n\n\n"}
{"id": "6839453", "url": "https://en.wikipedia.org/wiki?curid=6839453", "title": "Orbiting Solar Observatory", "text": "Orbiting Solar Observatory\n\nThe Orbiting Solar Observatory (abbreviated OSO) Program was the name of a series of American space telescopes primarily intended to study the Sun, though they also included important non-solar experiments. Eight were launched successfully into Low Earth orbit by NASA between 1962 and 1975 using Delta rockets. Their primary mission was to observe an 11-year sun spot cycle in UV and X-ray spectra. The initial seven (OSO 1–7) were built by Ball Aerospace, then known as Ball Brothers Research Corporation (BBRC), in Boulder Colorado. OSO 8 was built by Hughes Space and Communications Company, in Culver City, California.\n\nThe basic design of the entire series featured a rotating section, the \"Wheel,\" to provide gyroscopic stability. A second section, the \"Sail,\" was driven electrically against the Wheel's rotation, and stabilized to point at the Sun. The Sail carried pointed solar instruments, and also the array of solar photovoltaic cells which powered the spacecraft.\nThe critical bearing between the Wheel and the Sail was a major feature of the design, as it had to operate smoothly for months in the hard vacuum of space without normal lubrication. It also carried both the power from the Sail and the data from the pointed solar instruments to the Wheel, where most of the spacecraft functions were located.\nAdditional science instruments could also be located in the Wheel, generally looking out on a rotating radius vector which scanned the sky, and also across the Sun, every few seconds.\n\nOSO B suffered an incident during integration and checkout activities on 14 April 1964. The satellite was inside the Spin Test Facility at Cape Canaveral attached to the third stage of its Delta C booster when a technician accidentally ignited the booster through static electricity. The third-stage motor activated, launched itself and the satellite into the roof, and ricocheted into a corner of the facility until burning out. Three technicians were burned to death. The satellite, although damaged, was able to be repaired using a combination of prototype parts, spare flight parts and new components. It was launched ten months later on 3 February 1965 and was designated OSO 2 on orbit.\n\nOSO C never made it to orbit. Liftoff took place on 25 August 1965 and all went well through the second stage burn. During the coasting phase prior to third stage separation, its rocket motor ignited prematurely. This registered on ground readouts as an attitude disturbance followed by loss of second stage telemetry, and although the third stage managed to separate itself, it suffered from an 18% drop in thrust. The OSO spacecraft could not attain orbital velocity and instead fell back into the atmosphere and burned up. The failure was suspected to have been caused by a modification to the igniter mechanism in the third stage after some minor technical difficulties experienced on the previous Delta C launch (TIROS 10 on 2 Jul).\n\nThe Advanced Orbiting Solar Observatory (AOSO) program was developed in the mid 1960s as a more advanced version of the OSO series. Conceived as a polar-orbiting satellite system, these spacecraft would continuously monitor the Sun and surrounding environment with detectors and electronic imaging ranging from x-rays to visual light. Due to budget constraints, the AOSO program was cancelled in 1965. Instead, it was replaced by the OSO-I, OSO-J and OSO-K satellites. Only OSO-I, which became OSO 8, was ever launched.\n\n\n"}
{"id": "14271517", "url": "https://en.wikipedia.org/wiki?curid=14271517", "title": "Pancastikayasara", "text": "Pancastikayasara\n\nPañcastikayasara (en: the essence of reality), is an ancient Jain text authored by Acharya Kundakunda. Kundakunda explains the Jain concepts of \"dravya\" (substance) and Ethics. The work serves as a brief version of the Jaina philosophy. There are total 180 verses written in Prakrit language. The text is about five (\"panch\") \"āstikāya\", substances that have both characteristics, viz. existence as well as body.\n\nThe five \"āstikāya\" mentioned in the text are :— \n"}
{"id": "20806819", "url": "https://en.wikipedia.org/wiki?curid=20806819", "title": "Pantellerite", "text": "Pantellerite\n\nPantellerite is type of volcanic rock, specifically a peralkaline rhyolite. It has a higher iron and lower aluminium composition than comendite. It is named after Pantelleria, a volcanic island in the Strait of Sicily and the type location for this rock. On Pantelleria the rock is usually found as a vitrophyre containing phenocrysts of anorthoclase or sanidine. Quartz is found only in the most strongly peralkaline rocks. Mafic minerals may include aegirine, fayalite, aenigmatite, ilmenite, and sodic amphibole (often arfvedsonite or ferrorichterite).\n"}
{"id": "1930545", "url": "https://en.wikipedia.org/wiki?curid=1930545", "title": "Pastonian Stage", "text": "Pastonian Stage\n\nThe Pastonian interglacial, now called the Pastonian Stage (from Paston, Norfolk), is the name for an early or middle Pleistocene stage used in the British Isles. It precedes the Beestonian Stage and follows the Pre-Pastonian Stage. Unfortunately the precise age of this stage cannot yet be defined in terms of absolute dating or MIS stages. The Pre-Pastonian Stage is equivalent to the Tiglian C5-6 Stage of Europe and the Pre-Illinoian I glaciation of the early Pre-Illinoian Stage of North America.\nDeciduous woodland, increased including species such as Hornbeam (\"Carpinus\"), Elm (\"Ulmus\"), Hazel (\"Corylus\"), and Spruce (\"Picea\"). Towards the end of the period, there is evidence for a fall in sea levels and an increase in grassland species.\n\n\n\n"}
{"id": "14444088", "url": "https://en.wikipedia.org/wiki?curid=14444088", "title": "Positronium hydride", "text": "Positronium hydride\n\nPositronium hydride, or hydrogen positride is an exotic molecule consisting of a hydrogen atom bound to an exotic atom of positronium (that is a combination of an electron and a positron). Its formula is PsH. It was predicted to exist in 1951 by A Ore, and subsequently studied theoretically, but was not observed until 1990. R. Pareja, R. Gonzalez from Madrid trapped positronium in hydrogen laden magnesia crystals. The trap was prepared by Yok Chen from the Oak Ridge National Laboratory. In this experiment the positrons were thermalized so that they were not traveling at high speed, and they then reacted with H ions in the crystal. In 1992 it was created in an experiment done by David M. Schrader and F.M. Jacobsen and others at the Aarhus University in Denmark. The researchers made the positronium hydride molecules by firing intense bursts of positrons into methane, which has the highest density of hydrogen atoms. Upon slowing down, the positrons were captured by ordinary electrons to form positronium atoms which then reacted with hydrogen atoms from the methane.\n\nPsH is constructed from one proton, two electrons, and one positron. The binding energy is . The lifetime of the molecule is 0.65 nanoseconds. Positronium deuteride also has the same lifetime.\n\nThe decay of positronium is easily observed by detecting the two 511 keV gamma ray photons emitted in the decay. The energy of the photons from positronium should differ slightly by the binding energy of the molecule. However this has not yet been detected.\n\nThe structure of PsH is as a diatomic molecule, with a chemical bond between the two positively charged centres. The electrons are more concentrated around the proton.\nPredicting the properties of PsH is a four body Coulomb problem. Calculated using the stochastic variational method, the size of the molecule is larger than dihydrogen, which has a bond length of 0.7413 Å. In PsH the positron and proton are separated on average by 3.66 a (1.94 Å). The positronium in the molecule is swollen compared to the positronium atom, increasing to 3.48 a compared to 3 a. Average distance of the electrons from the proton is larger than the dihydrogen molecule, at 2.31 a with the maximum density at 2.8 au.\n\nDue to its short lifetime establishing the chemistry of positronium hydride poses difficulties. Theoretical calculations can predict what can happen. One method of formation is through alkali metal hydrides reacting with positrons. Molecules with dipole moments greater than 1.625 debye are predicted to attract and hold positrons in a bound state. Crawford's model predicts this positron capture. However in the case of lithium hydride, sodium hydride and potassium hydride molecules, this adduct decomposes and positronium hydride and the alkali positive ion form.\n\nPsH is a simple exotic compound. Other compounds of positronium are possible by the reactions e + AB →PsA + B. Other substances that contain positronium are di-positronium and the ion Ps with two electrons. Molecules of Ps with normal matter include halides and cyanide.\n"}
{"id": "8887825", "url": "https://en.wikipedia.org/wiki?curid=8887825", "title": "Provisional Military Dictatorship of Mughan", "text": "Provisional Military Dictatorship of Mughan\n\nThe Provisional Military Dictatorship of Mughan was a British-controlled anti-communist short-lived state founded in the Lankaran region on August 1, 1918. The Mughan government did not support independence of Azerbaijan and it was led by white Russian colonel V.T. Sukhorukov who acted under the protection of the British occupation of Baku. Mughan declared to be an autonomous part of \"single and indivisible Russia.\" On December 1918, it was reorganized as \"Mughan Territorial Administration\". On April 25, 1919, a violent protest organized by Talysh workers of pro-Bolshevik orientation exploded in Lankaran and deposed the Mughan Territorial Administration. On May 15, the Extraordinary Congress of the \"Councils of Workers' and Peasants' Deputies\" of Lankaran district proclaimed the \"Mughan Soviet Republic\".\n"}
{"id": "14828359", "url": "https://en.wikipedia.org/wiki?curid=14828359", "title": "Pulse (physics)", "text": "Pulse (physics)\n\nIn physics, a pulse is a generic term describing a single disturbance that moves through a transmission medium. This medium may be vacuum (in the case of electromagnetic radiation) or matter, and may be indefinitely large or finite.\n\nConsider a pulse moving through a medium - perhaps through a rope or a slinky. When the pulse reaches the end of that medium, what happens to it depends on whether the medium is fixed in space or free to move at its end. For example, if the pulse is moving through a rope and the end of the rope is held firmly by a person, then it is said that the pulse is approaching a fixed end. On the other hand, if the end of the rope is fixed to a stick such that it is free to move up or down along the stick when the pulse reaches its end, then it is said that the pulse is approaching a free end.\n\nA pulse will reflect off a free end and return with the same direction of displacement that it had before reflection. That is, a pulse with an upward displacement will reflect off the end and return with an upward displacement.\n\nThis is illustrated by figures 1 and 2 that were obtained by the numerical integration of the wave equation.\n\nA pulse will reflect off a fixed end and return with the opposite direction of displacement. In this case, the pulse is said to have inverted. That is, a pulse with an upward displacement will reflect off the end and return with a downward displacement.\n\nThis is illustrated by figures 3 and 4 that were obtained by the numerical integration of the wave equation. In addition it is illustrated in the animation of figure 5.\n\nWhen there exists a pulse in a medium that is connected to another less heavy or less dense medium, the pulse will reflect as if it were approaching a free end (no inversion). Contrarily, when a pulse is traveling through a medium connected to a heavier or denser medium, the pulse will reflect as if it were approaching a fixed end (inversion).\n\nDark pulses are characterized by being formed from a localized reduction of intensity compared to a more intense continuous wave background. Scalar dark solitons (linearly polarized dark solitons) can be formed in all normal dispersion fiber lasers mode-locked by the nonlinear polarization rotation method and can be rather stable. Vector dark solitons are much less stable due to the cross-interaction between the two polarization components. Therefore, it is interesting to investigate how the polarization state of these two polarization components evolves.\n\nIn 2008, the first dark pulse laser was reported in a quantum dot diode laser with a saturable absorber.\n\nIn 2009, the dark pulse fiber laser was successfully achieved in an all-normal dispersion erbium-doped fiber laser with a polarizer in cavity. Experimentation has revealed that apart from the bright pulse emission, under appropriate conditions the fiber laser could also emit single or multiple dark pulses. Based on numerical simulations, the dark pulse formation in the laser is a result of dark soliton shaping.\n\n"}
{"id": "11071543", "url": "https://en.wikipedia.org/wiki?curid=11071543", "title": "Return to the Centre of the Earth", "text": "Return to the Centre of the Earth\n\nReturn to the Centre of the Earth is a studio album by the English keyboardist Rick Wakeman, released on 15 March 1999 on EMI Classics. The album is a sequel to his 1974 concept album \"Journey to the Centre of the Earth\", itself based on the same-titled science fiction novel by Jules Verne. Wakeman wrote a new story of three unnamed travellers who attempt to follow the original journey two hundred years later, including the music which features guest performances from Ozzy Osbourne, Bonnie Tyler, Tony Mitchell, Trevor Rabin, Justin Hayward, and Katrina Leskanich. The story is narrated by Patrick Stewart. Recording was delayed after Wakeman was hospitalised with a life threatening case of double pneumonia and pleurisy, and needed time to recover.\n\nUpon release, the album reached number 34 on the UK Albums Chart.\n\nIn 1974, Wakeman released his second solo album \"Journey to the Centre of the Earth\", a concept album based on the same-titled science fiction novel by Jules Verne. It tells the story of Professor Lidenbrook, his nephew Axel, and their guide Hans who follow a passage to the Earth's centre originally discovered by Arne Saknussemm, an Icelandic alchemist. The idea to produce a sequel album first came to Wakeman in 1991 during a solo tour of Italy, when a journalist suggested to record a new and extended version of \"Journey\" with new technology. Several weeks later, during the Union Tour with Yes, Wakeman set up the tentative plan of re-recording the album live in concert with added music in time for its twentieth anniversary in 1994. During the tour's stop in New York City, Wakeman visited the office of Arista Records and spoke about the idea to an acquaintance, but it was turned down. Wakeman recalled, \"He said ... you recorded and wrote [\"Journey\"] with what you knew existed with instruments and recording techniques, so you pushed as far you could go. Now if you do it again, is different because you would not be pushing anything\". Wakeman was advised to put the idea on hold and think about a new \"epic\" album with a new story and music, of which he'll \"know when the right time is\".\n\nAfter the meeting at Arista, Wakeman went on to pursue other projects and forgot about the idea until it was revisited in 1996, when he received telephone calls from four record companies within a period of two months, willing to fund and release a new \"epic\" album from him. \"By the time of the first call I thought: 'Perhaps this is what my friend [at Arista] meant, because it appears to be a good time'\". After working about a possible budget for a new album, one of the record companies dropped out but interest from the remaining three had remained. Wakeman began the search for its story which started with Verne's other famous novel \"Around the World in Eighty Days\", and proceeded to write music for it. He scrapped the idea soon after, partly due to Richard Branson's world record attempts to circumnavigate the Earth by hot air balloon and thinking people will relate his music to the event. Soon after, Wakeman came across a newspaper article by Steven Spielberg, \"who was talking about have sequels for making films, how you have a story and you spin up from the story for a whole new story, but you have a relationship, which is very comfortable for the people who listen a whole new story, new characters, but there's still a relationship.\" This prompted the thought in Wakeman's mind, after revisiting the original book of \"Journey\", a new story, set two hundred years later, around three travellers who followed the original route but descend from a different entrance so they could experience a new journey. Wakeman purposefully unassigned names or genders for the travellers, \"because they could be the person listening\".\n\nWakeman's new idea was well received by the three record companies, and he was asked to produce a demo tape of some songs, narration, and orchestral parts. However, a problem arose when Wakeman was asked about his backing band as he wished for them and the orchestra not to be restricted to one style, and in his mind saw each group perform a variety of styles, playing \"rock things, heavy metal ... I want the band playing a classical thing\". Despite being told to continue with the demo regardless, Wakeman expressed some concern about whether his idea was understood properly by the labels; his two eldest sons, Oliver and Adam Wakeman, advised him not to do the album if it could not be produced to his liking. Wakeman came close to shelving the entire project until Nic Caciappo, an editor of the Yes information service and magazine in California, told his friend Dwight Dereiter of EMI-Capitol at a dinner about Wakeman's problem. A synopsis of the album was sent to Dereiter, who liked it and forwarded it to the European office of EMI Classics, the label's classical music division, as he thought they would understand it better. With further assistance from Frank Rodgers of the music publisher The Product Exchange who soon took over as management for the project, the idea arrived at label president Richard Lyttelton, who invited Wakeman to lunch to discuss the album further in February 1998. Lyttleton supported Wakeman's idea and offered a recording contract, agreeing to put a further £100,000 into the budget and release the album, which Wakeman accepted.\n\nRecording began in March 1998 and took place in six different locations, including Wakeman's home studio named Bajonor on the Isle of Man. In its original form the album had a running time of 126 minutes, leaving Wakeman having to cut it down to under 80 minutes in order to fit it on a single compact disc. The result, Wakeman said, resulted in a more \"direct\" album. He purposefully kept the music a secret from his family, which Oliver thought was strange as he usually plays his work to them. Adam assisted in the choir arrangements.\n\nLyttelton wanted Wakeman to record the album with a group of musicians that he had never worked with before in order to push Wakeman and the album to \"new limits\". The idea was strange to Wakeman at first as he already had his rock band the English Rock Ensemble, but said Lyttelton was \"100% right\" in his suggestion when the album was finished. To perform his music, Wakeman recruited guitarist Fraser Thorneycroft-Smith, bassist Phil Williams, and drummer Simon Hanson. Lyttelton gave Wakeman the freedom of choosing the singers for the album, suggesting to use \"the right singer for the right song\". Wakeman chose singers of a variety of backgrounds and styles to perform guest lead vocals on six tracks; \"Buried Alive\" is sung by Ozzy Osbourne, \"Is Anybody There?\" by Bonnie Tyler, \"Mr. Slow\" by Tony Mitchell, \"Never is a Long, Long Time\" by Trevor Rabin, \"Still Waters Run Deep\" by Justin Hayward, and \"Ride of Your Life\" by Katrina Leskanich.\n\nA narrator was not decided upon until shortly before Wakeman signed his contract with EMI when Gilbert Heatherwick, the head of EMI in the United States, asked who would take the role and suggested English actor Patrick Stewart. Wakeman was aware of the higher cost of booking Stewart, but Lyttelton liked the suggestion and agreed. Stewart's parts were recorded in August 1998 at POP Sound Studios in Santa Monica, California at a session that was originally booked for two hours. However, Stewart enjoyed the experience so much he allowed the session to continue for the entire day at no extra cost, cancelling the other arrangements he had scheduled.\n\nRecording was disrupted midway through the recording process by Wakeman's failing health. For three months, he worked 22-hour days on the album which took a toll on him mentally and physically. In August 1998, shortly after his arrival from recording Stewart's narration tracks in Los Angeles, Wakeman was hospitalised after he collapsed on a golf course with a life threatening case of double pneumonia and pleurisy, and showed signs of Legionnaire's disease. At one point, his doctors gave him just 48 hours to live. Wakeman's illness led to the initial dates for recording the orchestra to be cancelled and rearranged for December 1998.\n\nFor the orchestra, Wakeman originally suggested to use a symphony orchestra and choir from Belgrade with an unknown narrator in order to keep the album's budget at a minimum, but Lyttelton felt happy to use a more well known one and was later glad he \"resisted the temptation\" to go with Wakeman's idea as he wanted to make the album \"to the fullest\". The two agreed to use the London Symphony Orchestra and the English Chamber Choir that alone added £122,000 to the budget. When it came to recording their parts at Studio 1 at CTS Studios in Wembley, London, Wakeman recalled the experience as the most nerve wrecking experience of his music career. Shortly before the orchestra played, he recalled: \"I will hear for the very first time whether at all the arrangements I have done will work, will sound perfect or whether it'll sound terrible, as if the LSO was a third rate brass band. I asked myself what these EMI directors would've done if it had sounded terrible. ... Those final twenty seconds have been the most silent twenty seconds of my life. As if in slow motion I saw the baton going up and even when I only heard a rough mix in the control room it was as if thick clouds were making way for the sun to emerge. That moment all stress left my body as I turned around and only saw laughing faces. If I still had doubts, they all left that same instance.\"\n\nWhen recording for the album was finished in December 1998, almost 300 people were involved with the making of the album, which cost £2 million to produce, a considerable amount of money in comparison to Wakeman's earlier albums which were produced on much lower budgets. Wakeman heard the album in its entirety for the first time on 17 December 1998, and received a CD of it in mid-January 1999.\n\nOn 9 February 1999, the album received a 300-guest launch party arranged by EMI at the Natural History Museum in South Kensington, London. The album's release followed on 15 March. A promotional \"radio edit\" of the album was made with the songs edited to around four minutes, and distributed to radio stations to allow the album to gain airplay. It reached a peak of number 34 on the UK Albums Chart during its three-week stay on the chart. EMI set a goal of selling 300,000 copies of the album worldwide, but sales had only reached 195,000 copies two years after its release. Targets were met in each territory except the United States, where just 25,000 copies were sold which Wakeman felt disappointed about.\n\nThe album received mixed reviews from music critics. The \"Birmingham Evening Mail\" wrote the album is \"twice as long and equally as ambitious\" as the original and rates Stewart's \"precise narration\". The orchestra and choir \"enter into the spirit of things with gusto\", but the review concluded with \"expect a punk rock backlash in the year 2001\". A review in \"The Boston Herald\" by Kevin R. Convey gave the album 1-and-a-half stars out of five, saying Wakeman \"hasn't lost his touch\" and that the sequel \"is every bit as pompous and bombastic as the original\", which contained a \"thoroughly silly script\" for its narration and \"risible\" lyrics. Convey concluded: \"Those who love \"Journey\" probably will enjoy this as well. Others may want to find more creative ways to give themselves a headache\". In October 1999, a review from Shawn Perry for About.com praised Stewart's performance for his \"infectious precision\" in his narration and the album's opening of \"lush orchestrations, slyly garnishing Stewert's poignant articulations throughout\". Perry thought Wakeman's keyboards sound \"seemingly shrouded ... certainly not as distinctive as Wakeman's sound can be\", but welcomed \"Buried Alive\" as the point when the album \"sonically surges forward\" and for Osbourne's vocals and Wakeman's solo. From then on, Perry thought the album takes an \"ethereal tone ... with no real central theme to convey\" but considered Tyler's and Hayward's songs as highlights. Perry concluded that the album acts as a \"self-fulfilling aspiration\" for Wakeman, and thought the audience lack the patience to sit through the album.\n\nInitially, Wakeman wanted to perform the album on the Spanish island of Tenerife, as close to Mount Teide as possible, with the Orquesta Sinfónica de Tenerife, but the difficulties in performing around such an ecological area led to the idea being scrapped. Material from \"Return to the Centre of the Earth\" was performed live for the first time as part of Wakeman's 25-date Half a Century Tour, playing a selection of material across his career in churches and cathedrals across the United Kingdom from May 1999. A tour of the album, complete with a stage set designed by Dean, was shelved.\n\nWakeman has performed the album live in its entirety twice, both times in Québec, Canada. The premiere took place on 30 June 2001 in Trois-Rivières with Wakeman's band the English Rock Ensemble, then formed of his son Adam Wakeman on keyboards, guitarist Ant Glynne, bassist Lee Pomeroy, and drummer Tony Fernandez. Vocals were performed in English by Luck Mervil and Fabiola Toupin. The second performance followed on 15 July 2006 on the Plains of Abraham, Quebec City as part of the annual Quebec City Summer Festival. Wakeman was accompanied by a 45-piece orchestra conducted by Gilles Bellemare, the 20-piece Vocalys Ensemble Choir, the English Rock Ensemble, and guest vocals by Jon Anderson, Annie Villeneuve, and Vincent Marois, with narration from Guy Nadon. The concert was accompanied by giant screens and a light and firework display. Wakeman has stated that this show was the highlight of his career.\n\nAll music, narration, and lyrics written and produced by Rick Wakeman; all odd-numbered tracks narrated by Patrick Stewart.\n\nCredits are adapted from the album's CD liner notes.\n\n\n\n\n"}
{"id": "20068474", "url": "https://en.wikipedia.org/wiki?curid=20068474", "title": "Sound energy", "text": "Sound energy\n\nSound energy is a form of energy related with the vibration of matter. The SI unit of sound energy is the joule (J). Sound is a mechanical wave and as such consists physically in oscillatory elastic compression and in oscillatory displacement of a fluid. Therefore, the medium acts as storage for both potential and kinetic energy as well.\n\nConsequently, the sound energy in a volume of interest is defined as the sum of the potential and kinetic energy densities integrated over that volume:\nHere:\n\n"}
{"id": "3814851", "url": "https://en.wikipedia.org/wiki?curid=3814851", "title": "Steam-electric power station", "text": "Steam-electric power station\n\nThe steam-electric power station is a power station in which the electric generator is steam driven. Water is heated, turns into steam and spins a steam turbine which drives an electrical generator. After it passes through the turbine, the steam is condensed in a condenser. The greatest variation in the design of steam-electric power plants is due to the different fuel sources.\n\nAlmost all coal, nuclear, geothermal, solar thermal electric power plants, waste incineration plants as well as many natural gas power plants are steam-electric. Natural gas is frequently combusted in gas turbines as well as boilers. The waste heat from a gas turbine can be used to raise steam, in a combined cycle plant that improves overall efficiency.\n\nWorldwide, most electric power is produced by steam-electric power plants, which produce about 86% of all electric generation. The only other types of plants that currently have a significant contribution are hydroelectric and gas turbine plants, which can burn natural gas or diesel. Photovoltaic panels, wind turbines and binary cycle geothermal plants are also non-steam electric, but currently do not produce much electricity.\n\nReciprocating steam engines have been used for mechanical power sources since the 18th Century, with notable improvements being made by James Watt. The very first commercial central electrical generating stations in New York and London, in 1882, also used reciprocating steam engines. As generator sizes increased, eventually turbines took over due to higher efficiency and lower cost of construction. By the 1920s any central station larger than a few thousand kilowatts would use a turbine prime mover.\n\nThe electric efficiency of a conventional steam-electric power plant, considered as saleable energy produced at the plant busbars compared with the heating value of the fuel consumed, is typically 33 to 48% efficient, limited as all heat engines are by the laws of thermodynamics (See: Carnot cycle). The rest of the energy must leave the plant in the form of heat. This waste heat can be disposed of with cooling water or in cooling towers. If the waste heat is instead utilized for e.g. district heating, it is called cogeneration. An important class of steam power plants are associated with desalination facilities; these are typically found in desert countries with large supplies of natural gas and in these plants, freshwater production and electricity are equally important co-products.\n\nSince the efficiency of the plant is fundamentally limited by the ratio of the absolute temperatures of the steam at turbine input and output, efficiency improvements require use of higher temperature, and therefore higher pressure, steam. Historically, other working fluids such as mercury have been experimentally used in a mercury vapour turbine power plant, since these can attain higher temperatures than water at lower working pressures. However, the obvious hazards of toxicity, and poor heat transfer properties, have ruled out mercury as a working fluid.\n\nSteam-electric power plants utilize a surface condenser cooled by water circulating through tubes. The steam which was used to turn the turbine is exhausted into the condenser. The steam is therefore condensed as it comes in contact with the cool tubes full of circulating water. This condensed steam is withdrawn from the bottom of the surface condenser. The condensed steam is now water, commonly referred to as condensate water.\n\nThe adjacent image is a diagram of one of the many typical surface condenser designs.\n\nFor best efficiency, the temperature in the condenser must be kept as low as practical in order to achieve the lowest possible pressure in the condensing steam. Since the condenser temperature can almost always be kept significantly below 100 C where the vapor pressure of water is much less than atmospheric pressure, the condenser generally works under vacuum. Thus leaks of non-condensable air into the closed loop must be prevented. Plants operating in hot climates may have to reduce output if their source of condenser cooling water becomes warmer; unfortunately this usually coincides with periods of high electrical demand for air conditioning. If a good source of cooling water is not available, cooling towers may be used to reject waste heat to the atmosphere. A large river or lake can also be used as a \"heat sink\" for cooling the condensers; temperature rises in naturally occurring waters may have undesirable ecological effects, but may also incidentally improve yields of fish in some circumstances.\n\nIn the case of a conventional steam-electric power plant utilizing a drum boiler, the surface condenser removes the latent heat of vaporization from the steam as it changes states from vapor to liquid. The heat content (btu) in the steam is referred to as Enthalpy. The condensate pump then pumps the condensate water through a feedwater heater. The feedwater heating equipment then raises the temperature of the water by utilizing extraction steam from various stages of the turbine.\n\nPreheating the feedwater reduces the irreversibilities involved in steam generation and therefore improves the thermodynamic efficiency of the system. This reduces plant operating costs and also helps to avoid thermal shock to the boiler metal when the feedwater is introduced back into the steam cycle.\n\nOnce this water is again inside the boiler or steam generator, the process of adding the latent heat of vaporization or Enthalpy is underway. The boiler transfers energy to the water by the chemical reaction of burning some type of fuel. The water enters the boiler through a section in the convection pass called the economizer. From the economizer it passes to the steam drum. Once the water enters the steam drum it goes down the downcomers to the lower inlet waterwall headers. From the inlet headers the water rises through the waterwalls and is eventually turned into steam due to the heat being generated by the burners located on the front and rear waterwalls (typically). As the water is turned into steam/vapor in the waterwalls, the steam/vapor once again enters the steam drum. The steam/vapor is passed through a series of steam and water separators and then dryers inside the steam drum. The steam separators and dryers remove the water droplets from the steam and the cycle through the waterwalls is repeated. This process is known as natural circulation.\n\nAny droplets of liquid water carried over into the turbine can produce destructive erosion of the turbine blades.\n\nGeothermal plants need no boiler since they use naturally occurring steam sources. Heat exchangers may be used where the geothermal steam is very corrosive or contains excessive suspended solids. Nuclear plants also boil water to raise steam, either directly passing the working steam through the reactor or else using an intermediate heat exchanger.\n\nAs the steam is conditioned by the drying equipment inside the drum, it is piped from the upper drum area into an elaborate set up of tubing in different areas of the boiler. The areas known as superheater and reheater. The steam vapor picks up energy and its temperature is now superheated above the saturation temperature. The superheated steam is then piped through the main steam lines to the valves of the high-pressure turbine.\n\n"}
{"id": "12006784", "url": "https://en.wikipedia.org/wiki?curid=12006784", "title": "Steam accumulator", "text": "Steam accumulator\n\nA steam accumulator is an insulated steel pressure tank containing hot water and steam under pressure. It is a type of energy storage device. It can be used to smooth out peaks and troughs in demand for steam. Steam accumulators may take on a significance for energy storage in solar thermal energy projects. An example is the PS10 solar power tower plant near Seville, Spain and one planned for the \"solar steam train\" project in Sacramento, California.\n\nIt was invented in 1874 by the Scottish engineer Andrew Betts Brown.\n\nThe tank is about half-filled with cold water and steam is blown in from a boiler via a perforated pipe near the bottom of the drum. Some of the steam condenses and heats the water. The remainder fills the space above the water level. When the accumulator is fully charged the condensed steam will have raised the water level in the drum to about three-quarters full and the temperature and pressure will also have risen.\n\nSteam can be drawn off as required, either for driving a steam turbine or for process purposes (e.g. in chemical engineering), by opening a steam valve on top of the drum. The pressure in the drum will fall but the reduced pressure causes more water to boil and the accumulator can go on supplying steam (while gradually reducing pressure and temperature) for some time before it has to be re-charged.\n\nThis steam table shows the relationship between pressure and temperature in a boiler or steam accumulator:\nAbbreviations and notes\n\n\n\n\n"}
{"id": "42274295", "url": "https://en.wikipedia.org/wiki?curid=42274295", "title": "The Snakes of Europe", "text": "The Snakes of Europe\n\nThe Snakes of Europe is a book by the Belgian-British zoologist George Albert Boulenger, published in 1913, which is described in the author's preface as the first book written in English describing the snakes found in Europe.\n"}
{"id": "22850277", "url": "https://en.wikipedia.org/wiki?curid=22850277", "title": "Tiaojishan Formation", "text": "Tiaojishan Formation\n\nThe Tiaojishan Formation is a geological formation in Hebei and Liaoning, People's Republic of China, dating to the middle-late Jurassic period (Bathonian-Oxfordian stages). It is known for its fossil plants, and is made up mainly of pyroclastic rock interspersed with basic volcanic and sedimentary rocks. Previously, the Tiaojishan Formation was grouped together with the underlying Haifanggou Formation (also known as the Jiulongshan Formation) as a single \"Lanqui Formation.\" \nMost researchers now agree that the Daohugou Bed, of formerly controversial dating, is a part of the Tiaojishan formation.\n\nThe geology of the Daohugou Bed is confusing because it is complex and does not conform; meaning that elements and layers of rock of different ages are mixed up together by folding and erosion and by volcanic activity. Liu et al. (2006) concluded that the rocks that bear the Daohugou Biota also include the Tiaojishan and Lanqi Formations. They demonstrated that the Jiulongshan Formation is older (Middle Jurassic), and that the Tuchengzi Formation is younger (Late Jurassic). However, many other researchers consider the Daohugou to be a part of the Jiulongshan Formation itself.\n\nFieldwork published in 2006 has also found that the beds are consistent over a large area; from western Liaoning into Ningcheng county of Inner Mongolia (Nei Mongol).\n\nUsing Argon–argon dating, Wang and colleagues in 2005 dated part of the Tiaojishan Formation to about 160 million years ago, the beginning of the Oxfordian stage, the first stage of the Upper Jurassic epoch. In 2006, a study by Liu and colleagues used U-Pb zircon dating to conclude that the Tiaojishan Formation correlates with the Daohugou Beds, and the complete chronological range of this shared biota dates to between 168 and 164/152 Ma ago. A subsequent study, published in 2008, refined the age range of the formation further, finding that the lower boundary of the Tiaojishan was formed 165 Ma ago, and the upper boundary somewhere between 156-153 Ma ago.\n\nThe age of the Daohugou bed has been debated, and a number of studies, using different methodologies, have reached conflicting conclusions. Various papers have placed the fossils here as being anywhere from the Middle Jurassic period (169 million years ago) to the Early Cretaceous period (122 ma). One of the first studies on the age of the Daohugou beds, published in 2004 by He \"et al.\", found them to be Early Cretaceous, only a few million years older than the overlying Jehol beds of the Yixian Formation. The 2004 study primarily used Argon–argon dating of a tuff within the Daohugou Beds to determine its age.\n\nHowever, subsequent studies cast doubt on this relatively recent age. In a 2006 study, Gao & Ren criticized He \"et al.\" for not including enough specifics and detail in their paper, and also took issue with their radiometric dating of the Daohugou tuff. The tuff, Gao and Ren argued, contains crystals with a variety of diverse radiometric ages, some up to a billion years old, so using dates from only a few of these crystals could not determine the overall age of the deposits. Gao and Ren went on to defend a Middle Jurassic age for the beds based on biostratigraphy (the use of index fossils), and the bed's relationship to a layer that is known to mark the Middle Jurassic-Late Jurassic boundary.\n\nAnother study, published in 2006 by Wang \"et al.\", argued that the 159-164 million years old Tiaojishan Formation underlies, rather than overlies, the Daohugou Beds. Unlike the earlier study by Gao and Ren, Wang \"et al.\" found an overall similarity between the fossil animals found in the Daohugou Beds and those from the Yixian Formation. The authors stated that\n\"vertebrate fossils such as \"Liaoxitriton\", \"Jeholopterus\" and feathered maniraptorans show much resemblance to those of the Yixian Formation. In other words, despite the absence of \"Lycoptera\", a typical fish of the Jehol Biota, the Daohugou vertebrate assemblage is closer to that of the Early Cretaceous Jehol Biota than to any other biota.\"\nWang \"et al.\" concluded that the Daohugou probably represents the earliest evolutionary stages of the Jehol Biota, and that it \"belongs to the same cycle of volcanism and sedimentation as the Yixian Formation of the Jehol Group.\" However, a later study by Ji \"et al.\" argued that the key indicator of the Jehol biota are the index fossils \"Peipiaosteus\" and \"Lycoptera\". Under this definition, the earliest evolutionary stage of the Jehol Biota is represented by the Huajiying Formation, and the Daohugou Formation is excluded due to the absence of \"Lycoptera\" fossils. \nLater in 2006, Liu \"et al.\" published their own study of the age of the Daohugou beds, this time using Zircon Uranium-lead dating on the volcanic rocks overlying and underlying salamander-bearing layers (salamanders are often used as index fossils). Liu \"et al.\" found that the beds formed between 164-158 million years ago, in the Middle to Late Jurassic. A 2012 study by Gao and Shubin agreed with this assessment, and reported an Argon–argon date of 164 plus or minus 4 million years ago for the Daohugou horizon.\n\nBased on the plant life present in the Tiaojishan Formation, Wang Yongdong and colleagues determined that the climate in Liaoning during the mid Jurassic would have been subtropical to temperate, warm and humid.\n\nBeautifully preserved fossils of dinosaurs, pterosaurs, salamanders, insects, arachnids and other invertebrates, conifers, ginkgoes, cycads, horsetails, and ferns, and even the earliest known gliding mammal (\"Volaticotherium\") and an aquatic protomammal (\"Castorocauda\") have been discovered in these rocks. These organisms were part of the Daohugou Biota, which formed the local ecosystem of that Jurassic time. The tuffaceous composition of some rock layers show that this was a volcanic area, occasionally experiencing heavy ashfalls from eruptions. The landscape then was dominated by mountain streams and deep lakes surrounded by forests of gymnosperm trees. Some authors have concluded that the Daohugou Biota is an early stage of the Jehol Biota, while recent work has demonstrated that the two are distinct.\n\nThe forests of the Daohugou biota grew in a humid, warm - temperate climate and were dominated by gymnosperm trees. There were ginkgopsids like \"Ginkoites\", \"Ginkgo\", \"Baiera\", \"Czekanowskia\", and \"Phoenicopsis\". There were also conifers like \"Pityophyllum\", \"Rhipidiocladus\", \"Elatocladus\", \"Schizolepis\", and \"Podozamites\". Also, Lycopsids like \"Lycopodites\" and \"Sellaginellities\", horsetails (Sphenopsida) like \"Equisetum\", cycads like \"Anomozamites\", and ferns (Filicopsida) like \"Todites\" and \"Coniopteris\".\n\nThe following orders are represented in the formation; Ephemeroptera, Odonata, Plecoptera, Blattodea, Orthoptera, Hemiptera, Neuroptera, Coleoptera, Hymenoptera, and Diptera.\n\nAn indeterminate aeschnoid (insect) species is known from Liaoning.\n\nSurvey based on Wang \"et al.\" 2006 unless otherwise noted.\n\nCycad-like plants, the most abundant plant group in the formation. 27 species in 11 genera.\n\nPrehistoric ginkgo trees, common, with 11 species present in 6 genera.\n\nConifers, 5 species present in 4 genera.\n\nLeptosporangiate ferns, represented by 17 species in 8 genera, are the second most abundant plant type in the formation.\n\nCycads, fairly diverse, with 10 species present in 2 genera.\n"}
{"id": "1613999", "url": "https://en.wikipedia.org/wiki?curid=1613999", "title": "Tokyoite", "text": "Tokyoite\n\nTokyoite is a rare barium manganese vanadate mineral with the chemical formula: Ba(Mn,Fe)OH(VO). It is the manganese analogue of the iron rich gamagarite and the barium analogue of the lead vanadate, brackebuschite.\n\nIt occurs in low-grade metamorphosed sedimentary manganese ore deposits associated with hyalophane, braunite and tamaite.\n\nIt was first reported for an occurrence in the Shiromaru Mine, Okutama, Tama district, Tokyo Prefecture, Kantō region, Honshu Island, Japan and approved by the IMA in 2003. It has been found in two mines in Italy and one in Japan, for which it was named.\n"}
