{"id": "53522763", "url": "https://en.wikipedia.org/wiki?curid=53522763", "title": "Abra de Río Frío Natural Monument", "text": "Abra de Río Frío Natural Monument\n\nThe Abra de Río Frío Natural Monument () Is a protected natural space located in the municipality of San Cristóbal, in the state of Táchira, Venezuela. Received the status of natural monument on February 18, 1993.\n\nThe natural space aims to protect the geological and orographic structure of the open cold river, the only natural step through the Andean Cordilleras, linking the high western plains and tectonic Táchira depression.\n\nThe area is of a very populated vegetation, whose flora plays a regulating role of the microclimatic conditions in its surroundings. The Cerros de Blanquisal are known for their scenic beauty. Close to its borders, which extend to the banks of the river Uribante, join the rivers Frío and Quinimari.\n\nThe natural area also protects the transitability of the road that connects San Cristóbal with the regions of the Uribante.\n\n"}
{"id": "10256922", "url": "https://en.wikipedia.org/wiki?curid=10256922", "title": "Acaste", "text": "Acaste\n\nAcaste (; Ancient Greek: Ακαστη \"Akastê\" means \"unstable\" or \"irregular\" from \"akastatos\") was a name attributed to two characters in Greek mythology.\n\n\n"}
{"id": "58536715", "url": "https://en.wikipedia.org/wiki?curid=58536715", "title": "Alaska water resource region", "text": "Alaska water resource region\n\nThe Alaska water resource region is one of 21 major geographic areas, or regions, in the first level of classification used by the United States Geological Survey to divide and sub-divide the United States into successively smaller hydrologic units. These geographic areas contain either the drainage area of a major river, or the combined drainage areas of a series of rivers.\n\nThe Alaska region, which is listed with a 2-digit hydrologic unit code (HUC) of 19, has an approximate size of , and consists of 6 subregions, which are listed with the 4-digit HUCs 1901 through 1906.\n\nThis region includes the drainage within the state of Alaska. Includes all of Alaska.\n\n"}
{"id": "43238710", "url": "https://en.wikipedia.org/wiki?curid=43238710", "title": "Antarctic sea ice", "text": "Antarctic sea ice\n\nAntarctic sea ice is the sea ice of the Southern Ocean. It extends far north in winter and retreats almost to the coastline each summer. Sea ice is frozen seawater that is usually less than a few meters thick. This is in contrast to ice shelves, which are formed by glaciers, float in the sea, and are up to a kilometer thick. There are two subdivisions of sea ice: fast ice, which is attached to land; and ice floes, which are not.\n\nSea ice in the Southern Ocean melts from the bottom instead of from the surface like Arctic ice because it is covered in snow. As a result, melt ponds are rarely observed. On average, Antarctic sea ice is younger, thinner, warmer, saltier, and more mobile than Arctic sea ice. Due to its inaccessibility, it is not as well-studied as Arctic ice.\n\nThe Antarctic sea ice cover is highly seasonal, with very little ice in the austral summer, expanding to an area roughly equal to that of Antarctica in winter. It peaks (~18 × 10^6 km^2) during September, which marks the end of austral winter, and retreats to a minimum (~3 × 10^6 km^2) in February. Consequently, most Antarctic sea ice is first year ice, a few meters thick, but the exact thickness is not known. The mass of 18 million km^2 of ice, for each meter of thickness, is 18,000 km^3 and roughly 16 gigatonnes (billion metric tons).\n\nSince the ocean off the Antarctic coast is almost always much warmer than the air over it, the extent of the sea ice is largely controlled by the winds and currents that push it northwards. If it is pushed quickly, the ice can travel much further north before it melts. Most ice is formed along the coast, as the northward-moving ice leaves areas of open water (coastal latent heat polynyas), which rapidly freeze.\n\nBecause Antarctic ice is mainly first-year ice, which is not as thick as multiyear ice, it is generally less than a few meters thick. Snowfall and flooding of the ice can thicken it substantially, and the layer structure of Antarctic ice is often quite complex.\n\nRecent changes in wind patterns, which are connected to regional changes in the number of extratropical cyclones and anticyclones, around Antarctica have advected the sea ice farther north in some areas and not as far north in others (see images). The net change is a slight increase in the area of sea ice in the Antarctic seas (unlike the Arctic Ocean, which is showing a much stronger decrease in the area of sea ice). Increased sea ice extent does not indicate that the Southern Ocean is cooling, since the Southern Ocean is warming.\n\nThe IPCC AR5 report concluded that \"it is \"very likely\"\" that annual mean Antarctic sea ice extent increased 1.2 to 1.8% per decade, which is 0.13 to 0.20 million km per decade, during the period 1979 to 2012. IPCC AR5 also concluded that due to the lack of data it is not possible to determine the trend in total volume or mass of the sea ice. The increase in sea ice area probably has a number of causes. These are tied to changes in the southern hemispheric westerly winds, which are a combination of natural variability and forced change from greenhouse gases and the ozone hole. Another possible driver is ice-shelves melting, which increases freshwater input to the ocean; this increases the stratification of the ocean surface layer and so reduces the ability of warm subsurface water to reach the surface. A 2015 study found this effect in climate models run to simulate future climate change, resulting in an increase of sea ice in the winter months.\n\nAtmospheric and oceanic drivers likely have contributed to the formation of regionally varying trends in Antarctic sea-ice extent. For example, temperatures in the atmosphere and Southern Ocean have increased during the period 1979–2004. However, sea ice grows faster than it melts, due to a weakly stratified Ocean. Thus, this oceanic mechanism is, among others, contributing to an increase in the net ice production, potentially resulting in more sea ice. \nAlthough thickness observations are limited, modelling suggests that observed ice-drift toward the coastal regions makes an additional contribution for dynamical sea-ice thickening during autumn and winter.\nObserved autumn and spring trends in the number of extratropical cyclones, anticyclones and blocks, which have a strong thermodynamic control through temperature advection, and a strong dynamic control through ice-drift, on sea-ice extent during the same and also during following seasons are almost everywhere around Antarctica in agreement with the observed, regionally varying, trends in sea-ice extent. Consequently, the near-surface winds steered around weather systems are thought to explain large parts of the inhomogeneous Antarctica sea-ice trends.\n\nAfter gradual increases in sea ice as referenced above, southern hemisphere spring (i.e. September, October and November) 2016 saw a rapid decline in Antarctic sea ice. \n\nMonitoring changes in sea ice is important as this impacts the psychrophiles that live here.\n\nChanges in Antarctic sea ice are also important because of implications for atmospheric and oceanic circulation. When sea ice forms, it rejects salt (ocean water is saline but sea ice is largely fresh) so dense salty water is formed which sinks and plays a key role in formation of Antarctic Bottom Water.\n\nThe force of moving ice is considerable; it can crush ships that are caught in the ice pack, and severely limits the areas where ships can reach the land, even in summer. Icebreakers, iceports and ice piers are used to land supplies.\n\n"}
{"id": "85037", "url": "https://en.wikipedia.org/wiki?curid=85037", "title": "Appias", "text": "Appias\n\nIn ancient Rome, Appias was a statue of a nymph near the Appiades Fountain in the Forum of Caesar. Ovid wrote that the fountain was in the middle of the Temple of Venus Genetrix and surrounded by statues of nymphs who were called \"The Appiades\" (; plural form of Appias). Traditionally the Appiades are said to be of Concordia, Minerva, Pax, Venus, and Vesta.\n\nIn Roman mythology, Appias was a naiad who lived in the Appian Well outside the temple to Venus Genitrix in the Roman Forum.\n\nIn one of his letters, Cicero refers to a statue of Minerva as \"Appias\". In this case, he derived this surname from the name of Appius Claudius Pulcher, whom he intended to flatter.\n\n"}
{"id": "56083647", "url": "https://en.wikipedia.org/wiki?curid=56083647", "title": "Backscattering cross section", "text": "Backscattering cross section\n\nBackscattering cross section is a property of an object that determines what proportion of incident wave energy is scattered from the object, back in the direction of the incident wave. It is defined as the area which intercepts an amount of power in the incident beam which, if radiated isotropically, would yield a reﬂected signal strength at the transmitter of the same magnitude as the actual object produces.\n\n"}
{"id": "52667783", "url": "https://en.wikipedia.org/wiki?curid=52667783", "title": "Budhigandaki Hydroelectric Project", "text": "Budhigandaki Hydroelectric Project\n\nThe Budhi Gandaki Hydroelectric is a proposed hydroelectric project on the Budhi Gandaki River. Development by Nepal Electricity Authority. the extent of the area that will be inundated by the reservoir of the planned 1,200 MW project and the place where the people living there will be relocated. The project is expected to displace 45,000 people.\n"}
{"id": "7214", "url": "https://en.wikipedia.org/wiki?curid=7214", "title": "Callisto (mythology)", "text": "Callisto (mythology)\n\nIn Greek mythology, Callisto or Kallisto (; ) was a nymph, or the daughter of King Lycaon; the myth varies in such details. She was one of the followers of Artemis, or Diana for the Romans, who attracted Zeus (Jupiter). He transformed himself into the figure of Artemis and seduced her in this disguise. She became pregnant and when this was eventually discovered, she was expelled from Artemis's group, after which a furious Hera (Juno, wife of her seducer) transformed her into a bear. Later, just as she was about to be killed by her son when he was hunting, she was set among the stars as Ursa Major (\"the Great Bear\"). She was the bear-mother of the Arcadians, through her son Arcas by Zeus.\n\nThe fourth Galilean moon of Jupiter is named after Callisto.\nAs a follower of Artemis, Callisto, who Hesiod said was the daughter of Lycaon, king of Arcadia, took a vow to remain a virgin, as did all the nymphs of Artemis. But to have sex with her, Zeus disguised himself as Artemis (Diana) herself, in order to lure her into his embrace. Callisto was then turned into a bear, as Hesiod described:\n\n...but afterwards, when she was already with child, was seen bathing and so discovered. Upon this, the goddess was enraged and changed her into a beast. Thus she became a bear and gave birth to a son called Arcas.\n\nEither Artemis \"slew Kallisto with a shot of her silver bow,\" perhaps urged by the wrath of Juno (Hera) or later Arcas, the eponym of Arcadia, nearly killed his bear-mother, when she had wandered into the forbidden precinct of Zeus. In every case, Zeus placed them both in the sky as the constellations Ursa Major, called \"Arktos\" (αρκτος), the \"Bear\", by Greeks, and Ursa Minor.\nAccording to Ovid, it was Jupiter (Zeus) who took the form of Diana (Artemis) so that he might evade his wife Juno’s detection, forcing himself upon Callisto while she was separated from Diana and the other nymphs. Callisto's subsequent pregnancy was discovered several months later while she was bathing with Diana and her fellow nymphs. Diana became enraged when she saw that Callisto was pregnant and expelled her from the group. Callisto later gave birth to Arcas. Juno then took the opportunity to avenge her wounded pride and transformed the nymph into a bear. Sixteen years later Callisto, still a bear, encountered her son Arcas hunting in the forest. Just as Arcas was about to kill his own mother with his javelin, Jupiter averted the tragedy by placing mother and son amongst the stars as Ursa Major and Minor, respectively. Juno, enraged that her attempt at revenge had been frustrated, appealed to Tethys that the two might never meet her waters, thus providing a poetic explanation for their circumpolar positions in ancient times (see below).\n\nCallisto's story was sometimes depicted in classical art, where the moment of transformation into a bear was the most popular. From the Renaissance on a series of major history paintings as well as many smaller cabinet paintings and book illustrations, usually called \"Diana and Callisto\", depicted the traumatic moment of discovery of the pregnancy, as the goddess and her nymphs bathed in a pool, following Ovid's account. The subject's attraction was undoubtedly mainly the opportunity it offered for a group of several females to be shown largely nude. \n\nTitian's \"Diana and Callisto\" (1556-1559), was the greatest (though not the first) of these, quickly disseminated by a print by Cornelius Cort. Here, as in most subsequent depictions, Diana points angrily, as Callisto is held by two nymphs, who may be pulling off what little clothing remains on her. Other versions include one by Rubens, and \"Diana Bathing with her Nymphs with Actaeon and Callisto\" by Rembrandt, which unusually combines the moment with the arrival of Actaeon. The basic composition is rather unusually consistent. Carlo Ridolfi said there was a version by Giorgione, who died in 1510, though his many attributions to Giorgione of paintings that are now lost are treated with suspicion by scholars. Other, less dramatic, treatments before Titian established his composition are by Palma Vecchio and Dosso Dossi.\n\nAlthough Ovid places the discovery in the ninth month of Callisto's pregnancy, in paintings she is generally shown with a rather modest bump for late pregnancy. With the \"Visitation\" in religious art, this was the leading recurring subject in history painting that required showing pregnancy in art, which Early Modern painters still approached with some caution. In any case, the narrative required that the rest of the group had not previously noticed the pregnancy.\n\nCallisto being seduced by Zeus/Jupiter in disguise was also a popular subject, usually called \"Jupiter and Callisto\"; it was the clearest common subject with lesbian lovers from classical mythology. The two lovers are usually shown happily embracing in a bower. The violent rape described by Ovid as following Callisto's realization of what is going on is rarely shown. In versions before about 1700 Callisto may show some doubt about what is going on, as in the versions by Rubens. It was especially popular in the 18th century, when depictions were increasingly erotic; François Boucher painted several versions.\n\nAeschylus' tragedy \"Callisto\" is lost.\n\nThe name \"Kalliste\" (Καλλίστη), \"most beautiful\", may be recognized as an epithet of the goddess herself, though none of the inscriptions at Athens that record priests of \"Artemis Kalliste\" (Άρτεμις Καλλίστη), date before the third century BCE. Artemis Kalliste was worshiped in Athens in a shrine which lay outside the Dipylon gate, by the side of the road to the Academy. W. S. Ferguson suggested that Artemis Soteira and Artemis Kalliste were joined in a common cult administered by a single priest. The bearlike character of Artemis herself was a feature of the Brauronia.\n\nThe myth in \"Catasterismi\" may be derived from the fact that a set of constellations appear close together in the sky, in and near the Zodiac sign of Libra, namely Ursa Minor, Ursa Major, Boötes, and Virgo. The constellation Boötes, was explicitly identified in the Hesiodic \"Astronomia\" (Αστρονομία) as Arcas, the \"Bear-warden\" (\"Arktophylax\"; Αρκτοφύλαξ):\n\nHe is Arkas the son of Kallisto and Zeus, and he lived in the country about Lykaion. After Zeus had seduced Kallisto, Lykaon, pretending not to know of the matter, entertained Zeus, as Hesiod says, and set before him on the table the babe [Arkas] which he had cut up.\n\nThe stars of Ursa Major were all circumpolar in Athens of 400 BCE, and all but the stars in the Great Bear's left foot were circumpolar in Ovid's Rome, in the first century CE. Now, however, due to the precession of the equinoxes, the feet of the Great Bear constellation do sink below the horizon from Rome and especially from Athens; however, Ursa Minor (Arcas) does remain completely above the horizon, even from latitudes as far south as Honolulu and Hong Kong.\n\nAccording to Julien d'Huy, who used phylogenetic and statistical tools, the story could be a recent transformation of a Palaeolithic myth.\n\n\n\n\n"}
{"id": "43640292", "url": "https://en.wikipedia.org/wiki?curid=43640292", "title": "Celtic rain forest", "text": "Celtic rain forest\n\nThe Celtic rain forest is the wet forest in Ireland, western Scotland, and western Wales, near the Atlantic Ocean, which is dominated by sessile oak (\"Quercus petraea\"), downy birch (\"Betula pubescens\") and hazel (\"Corylus avellana\"). The large number of rainy or misty days, high humidity, overall high annual precipitation, and small annual temperature variation (equable temperature), makes this an important habitat numerous common and rare species of mosses, liverworts, and lichens. There is an exceptional number of epiphytic plants (plants growing on or hanging from trees without being parasitic. The ground is covered with a deep blanketing of mosses and liverworts, which rise up the trunks of the trees onto the horizontal branches and up into the canopy.\n\nThe Scottish Natural History Scientific Advisory Committee writes, \"the whole area is a lichenologists’ Mecca\".\n\nRavines are full of tangled vegetation.\n\nTrees include oaks, ash, elm, cherry, and willow.\n\nRare lichen communities are found using the mosses as a substrate, and add colour to the understory. Lungworts are lichens in the \"Lobaria\" genus, and four of the species can be huge, up to or more across. \"Pannaria\", \"Parmeliella\", and \"Degeliaspecies\" genus lichens add a lead-grey color. \"Stictas\" genus lichens are very dark. The fruit of jelly lichens (\"Biatora sphaeroides\") are pink, those of \"Dimerella lutea\" are bright yellow, and those of dog lichen in the \"Peltigera\" genus make chestnut colored fruits in the shape of shields. The weight of the lichens using mosses as a substrate gradually causes the moss carpeting to peel off the trees, where heaps rare lichens can be found on the ground.\n\nThe more alkaline bark of ash and hazel favour growth specklebellies (\"Pseudocyphellaria spp.\"), custard (\"Parmentaria chilense\").\n\nIn the grazed birch woodland on higher ground, the bark has a high acidity due to leaching by the high rainfall. This area is dominated by silvery-grey leafy species of lichens that grow directly on the tree bark, not on mosses.\n\nHistorically wood from this forest was gathered by repeatedly cutting down the tree stems to near the ground coppiced), where it resprouted. The wood was used for charcoal, tanning, and bobbin-making. These practices ended in the mid-1800s. There is currently wildland management for conservation.\nSince the 20th century, conservation effort has resulted in many of the woods being protected and managed to address problems such as invasive Rhododendron, excessive grazing from sheep and deer, and non-native plantation trees.\n\n"}
{"id": "49557879", "url": "https://en.wikipedia.org/wiki?curid=49557879", "title": "ClearPath Foundation", "text": "ClearPath Foundation\n\nClearPath Foundation is a nonprofit organization based in Charlotte, NC and Washington, D.C. that is focused on \"conservative clean energy\". According to a press release, the organization was founded to propose and support policies that accelerate clean energy without expanding the size of government.\n\nClearPath was founded by Republican entrepreneur and philanthropist Jay Faison in 2013 to change the conservative viewpoint on clean energy. After selling his majority stake in the audio-visual company SnapAV, Faison donated $165 million to start ClearPath, with a mission of \"accelerating conservative clean energy solutions\"\n\nClearPath advances its mission through \"strategic grant-making, advocacy, and digital platforms\", and focuses on energy policy, polling, and analysis. ClearPath has conducted polling on Americans' attitudes towards clean energy with Kristen Soltis Anderson, finding that \"72% of Republicans\nsupport accelerating the development of clean energy\".\n\nThe ClearPath website lists five principles used for analyzing policy. ClearPath believes in \"small government, free markets, and American innovation\", as well as pollution risk management, cost-benefit analysis and energy security.\n\n"}
{"id": "52819317", "url": "https://en.wikipedia.org/wiki?curid=52819317", "title": "Code of Openness", "text": "Code of Openness\n\nCode of Openness (CPO) is an open initiative of prostep ivip under the patronage of the German Federal Ministry for Economic Affairs and Energy (German acronym: BMWi). The acronym CPO originally stands for the abbreviation of Code of PLM Openness.\n\nOpenness is a capability provided by an IT system, and it is characterized by interoperability, portability and extensibility. These capabilities are implemented using IT interfaces, standards and the IT architecture. All these are technical aspects of openness, Openness is also based on non-technical aspects, which are related to the partnership between the involved partners (IT customers, IT vendors and/or IT service providers). The development of the CPO was inspired by the spirit of a \"code of conduct\".\n\nThereby, the CPO goes far beyond the requirement to provide IT standards and related interfaces. It aims seamless connectivity and the easy integration of IT in networked IT-environments and therefore combines technological IT-requirements with those of IT customer and users. CPO a standard catalogue that defines measurable criteria (‘shall’, ‘should’, ‘may’) for the following categories: interoperability, infrastructure, extensibility, interfaces, standards, architecture as well as partnership.\n\nFrom July 2011 to February 2012 representatives of BMW, Daimler, Dassault Systèmes, IBM, Oracle, PTC, SAP, Siemens PLM Software, T-Systems and Volkswagen specified the first version of the CPO, which was publicly introduced by the CIO of BMW and Continental at a conference within the context of the CeBIT 2012.\n\nIn 2012 and 2013 the CPO was continuously enhanced. Since 2014 the internationalization as well as the industrial roll-out was driven forward actively. Companies like e.g. Airbus, Ford, Fuji Heavy Industries, Hino, Honda, Isuzu, Mazda, Mitsubishi, Nissan, Suzuki, thyssenkrupp, Toyota, Volvo and Yamaha joined the initiative.\n\nWithin the following, it became more and more clear that the CPO Criteria do not only serve the original target PLM, but also for assuring openness in IoT scenarios. Consequently, in April 2016 the German Minister for Economic Affairs and Energy, Sigmar Gabriel, declared the patronage of the BMWi for the CPO: \"The German industry relies on the fact, that smart products and services can be offered and applied globally. With regard to this, interoperability is the key. A certification assures trust with regard to the broad application of information and communication technology (ICT), removes technological barriers and boosts the power of the German economy.\"\n\nTogether with the BMWi prostep ivip currently specifies the CPO-related certification procedure. Pilot-certifications have been conducted in 2017. Companies like CONWEAVER, HCL, PROSTEP, PTC and Siemens PLM were the first who received this certificate. In parallel, an accredited certification program is worked out together with the DAkkS. Additionally, related next steps on EU-level and in Japan (together with the METI) are planned.\n\nThe CPO, Guidelines with hints and interpretation help, templates and the CPO annual report are published via the CPO-site of ProSTEP iViP. The CPO itself and associated certification criteria will be published as DIN SPEC 91372. The first part, DIN SPEC 91372-1:2018-03, is already available.\n\n"}
{"id": "35946562", "url": "https://en.wikipedia.org/wiki?curid=35946562", "title": "Culmicole", "text": "Culmicole\n\nA culmicole is an organism that lives on the apexes of grass leaves and stems. An example of a culmicole are species of planthoppers, which spend their lives perched on grass blades. The name was first coined by Lincoln et al. in 1985.\n"}
{"id": "34227677", "url": "https://en.wikipedia.org/wiki?curid=34227677", "title": "Dynamic Ionosphere CubeSat Experiment", "text": "Dynamic Ionosphere CubeSat Experiment\n\nThe Dynamic Ionosphere CubeSat Experiment (DICE) is a scientific mission consisting of two Miniaturized Satellites DICE-1 and DICE-2 flying in formation. The satellites are an unusual 1.5U variant of the CubeSat design for microsatellites. Both satellites were launched from Vandenberg Air Force Base in October 2011 atop a Delta II rocket. This was a multi-payload mission with four other CubeSats, AubieSat-1, M-Cubed, Explorer-1_Prime and RAX-2.\n\nThe satellites are intended to map changes in the Earth's Plasmasphere caused by Geomagnetic storms.\n\nOn board control is provided by a Pumpkin FM430 flight control module containing a Texas Instruments MPS430 microcontroller. Communications are provided by a half-duplex UHF modem with a 1.5 Mbit/s downlink (465 MHz) and 19.2 kbit/s uplink (450 MHz). The satellites carry four Electric Field Probe sensors on telescopic booms, two DC Langmuir probes for detection of ions and a three-axis magnetometer for measuring magnetic fields.\n\n"}
{"id": "22888855", "url": "https://en.wikipedia.org/wiki?curid=22888855", "title": "Earl Lemley Core", "text": "Earl Lemley Core\n\nEarl Lemley Core (1902–1984) was a botanist and botanical educator, researcher and author as well as a local West Virginia historian. He was founder (1936) of the Southern Appalachian Botanical Club and editor of its journal, \"Castanea\", for thirty-five years. He was a teacher and professor at West Virginia University (WVU) for over forty-four years (1928–72). He served for four years on the Morgantown City Council and was mayor of Morgantown for two years. The Earl L. Core Arboretum at WVU was named in his honor in 1967.\n\nCore was born on January 20, 1902, at Core, West Virginia, the son of Harry Michael and Clara Edna (\"née\" Lemley) Core. He graduated from Morgantown High School, taught in rural schools (1920–23) and then attended WVU, earning Bachelor of Arts (1926) and Master of Arts (1928) degrees. He married Freda Bess Garrison on June 8, 1925. (They eventually parented four children: Ruth, Merle, Harry, and David.) He earned a Doctor of Philosophy degree (1936, Columbia University) with a dissertation on the systematics of the sedge genus \"Scleria\".\n\nCore became an instructor at WVU in 1928 and remained on the faculty for over 44 years. He progressed to assistant professor (1934), associate professor (1941), professor (1942), and professor emeritus (1972) and was chairman of the Biology Department from 1948 to 1966. He served as curator of the university herbarium from 1934 until his retirement in 1972. In addition, he served as a member of the summer faculty at Ohio State University during 1939-41 and of Concord College in 1961.\n\nCore was named botanist for the Colombia Cinchona Mission, Bogota, Colombia, from 1943 to 1945 during which assignment he explored in the Andes Mountains in search of wartime sources of quinine from the \"Cinchona\" tree.\n\nIn the course of his career, Core authored numerous technical articles, several books, and hundreds of newspaper articles. Two notable textbooks that became standards were \"General Biology\" by P.D. Strausbaugh, B.R. Weimer, and Earl L. Core and \"A New Manual for the Biology Laboratory\" by Core and Weimer. His botanical texts were \"The Flora of West Virginia\" (a four volume series written with Strausbaugh), \"Flora of the Erie Islands\", \"Spring Wild Flowers\", \"Plant Taxonomy\", \"Vegetation of West Virginia\", and \"The Wondrous Year\", a collection of weekly botanical writings he prepared for the \"Charleston (West Virginia) Gazette\" newspaper.\n\nIn 1937, Core wrote \"The Chronicles of Core\", a history of his home community and in 1960 he published \"Morgantown Disciples\", a history of the First Christian Church of Morgantown, West Virginia. Late in life he embarked upon an extensive five-volume history of Monongalia County, West Virginia (1974–84), completing the last volume shortly before his death. (This material had been published over a period of 12 years in a weekly column of the Morgantown \"Dominion Post\" newspaper.)\n\n\n"}
{"id": "51245900", "url": "https://en.wikipedia.org/wiki?curid=51245900", "title": "Geothermal energy in Italy", "text": "Geothermal energy in Italy\n\nGeothermal energy in Italy is mainly used for electric power production. \n\nItaly is located above a relatively thin crust, with four large areas of underground heat:\n\nA 2018 report by the Italian Geothermal Union indicated that Italy has additional geothermal energy potential which has yet to be utilized.\n\nResearch into the potential for geothermal energy started in 1977, following the oil crisis, with work of ENEL and ENI, which started jointly to bore hundreds of wells in Italy, creating a complete map of the underground resource. But in the '90s, the exploratory activity stopped.\n\nFollowing results a mapping of Italy in four areas:\n\n\nItaly uses its lower temperature fluids for spas, agriculture, industry and district heating. A large portion of house heating is concentrated in the Abano spa area, in northeast Italy. As district heating the most important plants are in Ferrara and Vicenza in the eastern Po Valley, about 1990. Smaller district heating plants are found in Bagno di Romagna and Acqui Terme.\n\n\n"}
{"id": "2454477", "url": "https://en.wikipedia.org/wiki?curid=2454477", "title": "Gypcrust", "text": "Gypcrust\n\nGypcrete or gypcrust is a hardened layer of soil, consisting of around 95% gypsum (calcium sulfate). Gypcrust is an arid zone duricrust. It can also occur in a semiarid climate in a basin with internal drainage, and is initially developed in a playa as an evaporate. Gypcrete is the arid climate's equivalent to calcrete, which is a duricrust that is unable to generate in very arid climates.\n\nGypcrust horizons can be up to thick with a 75-97% gypsum (CaSO∙2HO) content. The majority of gypsum-rich layers occur where the average annual rainfall is less than 250 mm because gypsum is moderately soluble (c. 2.6 g at 25 °C) and is normally leached out under higher rainfall conditions. Gypsum cements are rarely, if ever, as strong as calcretes or silcretes.\n\nGypcrust forms in a manner similar to that of caliche, which is composed of calcium carbonate. The development of gypcrust has 3 main stages. The first stage is primary crystallization of the surface brines or groundwater; the second stage is transportation and redeposition by wind or water; and the third stage is post-depositional alteration above or below the capillary fringe. Most gypcrust is formed either as a result of soil-forming processes or through the precipitation of cementing agents from groundwater.\n\nThere are two models that are used to illustrate the influence groundwater has on the formations of duricrusts like gypcrust: \"per ascensum\" and \"per descensum\". The \"per ascensum\" model demonstrates a situation where the water table is relatively close to the surface, allowing solutions to be drawn upwards by evaporation and eventually cement near-surface sediments once they become concentrated enough to trigger precipitation. The \"per ascensum\" model is applicable to environments with high rates of surface evaporation like deserts. This type of system only produces thin duricrust layers since the process ultimately seals the surface horizons, which consequently decreases the potential for further evaporation. This model best depicts the formation of gypcrust.\nThe \"per descensum\" model describes a system different from that of the formation of gypcrust in which precipitation of minerals occurs at a depth from downward-percolating solutions. This type of system explains the formation of thick duricrust horizons.\n\nGypcretes form in four distinct conditions: in well drained soils, as buried evaporates, in hydromorphic soils, or by the exposure of subsurface horizons by erosion.\n\nGypcrete can be a loose and powdery deposit or a massive crystalline structure. The profile of a gypcrust outcrop can have three layers. The bottom layer is the sand rose horizon at the water table where gypsum develops as aggregates of crystals. The middle layer is composed of massive gypcrete cemented sand, which forms above the water table during evaporation from the capillary fringe; newly formed gypcrete will be hard, and will soften with age. The uppermost layer is usually rich in gypsified roots and has a banded or nodular structure.\n\nGypcrete has been used successfully for road construction in the Sahara. Well-cemented gypcrusts may also provide adequate bearing capacity for structures, however it must be ensured that the underlying uncemented material is not overloaded to avoid collapse.\n"}
{"id": "3481599", "url": "https://en.wikipedia.org/wiki?curid=3481599", "title": "Hare Krishna Food for Life", "text": "Hare Krishna Food for Life\n\nHare Krishna Food for Life is the world's largest vegetarian non-profit food relief organization. Its efforts span the globe, with projects occupying over 60 countries. Volunteers provide up to 2,000,000 free meals daily. Food For Life does not only tackle only one form of hunger but reaches out to all in need, including; the homeless, disadvantaged children throughout India; and victims of natural disasters around the world.\n\nWith roots in India, the Food for Life project is a modern-day revival of the ancient Vedic culture of hospitality with its belief in the equality of all beings. It was conceived of and began by the International Society for Krishna Consciousness in 1974 and is thus commonly known as \"ISKCON Food For Life\" or \"Hare Krishna Food For Life\". It has been lauded by \"The New York Times\" Vegetarian Times, as well as Paul McCartney and Nelson Mandela amongst others, for its relief efforts worldwide.\n\nFood for Life as a project was initially inspired by an elderly Indian Swami, known as A. C. Bhaktivedanta Swami Prabhupada, Founder Acharya of ISKCON. In 1974 when watching a group of village children fighting with dogs over scraps of food, the Swami became upset and told his students, \"No one within ten miles of a temple should go hungry... I want you to immediately begin serving food.\" In response to his plea, members of ISKCON and volunteers around the world were inspired to expand that original effort into a global network of kitchens, cafes, vans, and mobile services, all providing free food, and establishing daily delivery routes in many large cities around the world. Since that day, Food for Life has grown into the world’s largest vegan/vegetarian food relief program. The distribution of sanctified plant-based meals has been and will continue to be an essential part of India’s Vedic culture of hospitality from which Food for Life was born.\n\nWith volunteers serving up to 2,000,000 free plant-based meals daily to schools, as well as from mobile vans and to disaster areas. FOOD FOR LIFE is now the largest food relief in the world, eclipsing even the United Nations World Food Programme.\n\nFood For Life volunteers have provided food for the poor and homeless during several recent disasters.\n\n\nIn total, Food for Life has distributed more than 2 billion meals since its inception.\n\nFood for Life has expanded its reach to include, eco projects such as Working Villages International; as well as orphanages such as Gokulam – Bhaktivedanta Children’s Home Gokulam in Sri Lanka, a refuge where needy children receive food, shelter, medical care, education and loving care.\n\nIn the war zone of Sarajevo, Bosnia and Herzegovina, volunteers visited orphanages, homes for the elderly, hospitals, institutes for handicapped children, and basement shelters on a daily basis throughout the three-year conflict; an estimated 20 tons of food have been distributed since 1992.\n\nIn a New York Times article dated (December 12, 1995) volunteers in Chechnya were described as having \"a reputation like the one Mother Teresa has in Calcutta: it's not hard finding people to swear they are saints.\"\n\nFood for Life was the first food relief agency to respond to the tsunami disaster of December 2004. On the same afternoon the great tsunami hit, Vaisnava monks at ISKCON's temple in Chennai, India were preparing their weekly Sunday vegetarian feast, when they heard of the disaster. They immediately raced to the most affected areas on the southeast coastline of India and began serving thousands of people with their preprepared vegetable curry. Over the following 6 months, Food for Life Volunteers in Sri Lanka, India, Europe, USA and Australia provided more than 350,000 freshly cooked meals, along with medical care, water, clothing, and shelter for children at ISKCON's orphanage in Colombo, the Bhaktivedanta Children's Home.\n\nFood for Life Global Volunteers responded to the Hurricane Katrina disaster in late August 2005 by providing vegan meals to families relocated to Mississippi and Texas. Up to 800 meals were served daily.\n\nVolunteers from Udhampur, Jammu, Amritsar and Haridwar under the guidance of His Holiness Navayogendra Swami Maharaj, a prominent disciple of A.C. Bhaktivedanta Swami Prabhupada, came together to provide relief for victims of the 2005 earthquake in Pakistan. Working from an ISKCON temple in Udhampur, which was within the earthquake-affected region, the volunteers loaded trucks with drinking water, rice, bread, and blankets.\n\nFood for Life Global's principle affiliate, the Food for Life Annamrita program, was founded by ISKCON Food Relief Foundation (IFRF), believes in providing children with the right nutrition to support their education. IFRF's Food for Life Annamrita program is based on the belief that \"you become what you eat.\" The nutritious meals this program serves daily encourages over a million children to attend school. One of their goals is to help every child in India get a full education by providing wholesome meals. They are currently serving 1.3 million meals daily from dozens of high-tech kitchens across 10 states.\n\nFood for Life Global is an international non-profit charitable organization that provides plant-based foods in over 60 countries around the world, for mal-nourished people; people in disaster areas; wherever there is a need, they provide it. Food for Life Global was started, founded in 1974, so they are 40 years old. So I want to say, Happy birthday, congratulations. It’s great to see so much veggie food helping people out around the world, bringing people together in this fantastic way. Thank you, Food for Life Global for doing this. Thank you for all of you who work for Food for Life Global. We thank you. You do a great job. Happy birthday to you. Keep it going for another 40 years, 50, 60, keep it going. We love you.\n— Paul McCartney, London\n\n“…while the Kremlin has been willing to spend trillions of rubles on its soldiers, only one Russian civic organization has come to Chechnya to provide emergency aid for its often homeless and sometimes starving compatriots – the Russian branch of FOOD FOR LIFE.” \n— Financial Times of London, London\n\n“…here they [Food for Life] have a reputation like the one Mother Teresa has in Calcutta: it is not hard finding someone to swear they are saints.” \n— Michael Specter (Grozny Journal), The New York Times\n\n\"FOOD FOR LIFE is the real Reconstruction and Development Programme. The understanding that if I have a plate of food, let me share it with my neighbour . . . let those who are feeling sad come together with us, and together we can share this burden. This understanding should be taken from FOOD FOR LIFE and transmitted to the entire country.\"\n— Thabo Mbeki (Deputy President of South Africa), Durban\n\n“… though it may not get top mention on the nightly news, FOOD FOR LIFE is among the world’s most intrepid relief organizations, in at least one case delivering food to a war-torn region after the Red Cross and other agencies gave up.” \n— Vegetarian Times, USA\n\n\"Another important building block for new democracy is the love and goodwill we show to each other. That is the spirit of Masakhane, of bringing one another together. It is also the spirit of today’s festival organized by Food for Life.\"\n— Nelson Mandela, Durban\n\n“We don’t have education about how to eat. We are eating too much meat and people are getting sick with the time. We have to show to the people what they need to eat. The doors are open for Food for Life Global. We are going to work together to get better food for our kids into the schools.”\n— Jose “Pepe” Mujica, President of Uruguay\n\n\"I congratulate you for your fine achievements on behalf of the homeless….FOOD FOR LIFE’s success in providing housing, food, and social services has long attracted the attention of this office.\"\n— Arlen Specter (US Senate), USA\n\n“In Bangalore, Jaipur and other cities, Akshaya Patra (FOOD FOR LIFE) meals are cooked in the most modern kitchens and good quality food is delivered to schools. Corporate bodies should also be involved in this process by creating public-private partnerships like Akshaya Patra.” – Comments by Prime Minister Atal Bihari Vajpayee\n— Financial Express India, India\n\n\"The Australian Government recognizes the valuable work the Hare Krishnas are doing with their FOOD FOR LIFE program.\"\n— Eric Fitzgibbon MP (Australian Parliament), Australia\n\n\"Many people were in tears to see the efforts of the FFL volunteers. Many of those who received it commented that it was the “best food they have had in a long time, even before the hurricane hit!”\n— Susan Tydings Frushour (Red Cross), USA\n\n“The Food for Life cooks have established themselves as the chief emergency feeding program in war-torn Chechnya.” \n— Moscow Tribune, Russia\n\n“The fact the police and the Food for Life organization are looking to work together …… represents very positive policing.”\n— Police Gazette, QLD, Australia\n\n\"I pray that your FOOD FOR LIFE program will expand to bring about a peaceful world.\"\n— Salambek Hadjiev (Former Prime Minister of Chechnya), Chechnya\n\nFood for Life Global (FFLG) was founded in 1995 in Maryland USA but closed it offices at the end of 2014. It re-established its offices in Slovenia where it continues to serve as the headquarters and coordinating office for all Food for Life projects worldwide. The organization is currently registered under the name: Humanitarno društvo FFL Global in Kamnik, Slovenia with registration number 4077911000 (matična številka), TAX ID Nr. 28209397 (davčna številka). It continues to have a presence in the United States through it strategic partner, A Well-Fed World.\n\n\nPaul Rodney Turner, also known as Priyavrata das or the \"food yogi,\" is the international director.\n\n\nSome Food for Life programs have suffered severe criticism from ISKCON leaders and devotees who believe them to be a major deviation from Srila Prabhupada's original preaching mission by their promotion of so-called \"mundane welfare activities\". According to these opponents, Srila Prabhupada was strongly opposed to food distribution done without chanting of the names of Krsna and without preaching.\n\n\n"}
{"id": "14896", "url": "https://en.wikipedia.org/wiki?curid=14896", "title": "Inductor", "text": "Inductor\n\nAn inductor, also called a coil, choke, or reactor, is a passive two-terminal electrical component that stores energy in a magnetic field when electric current flows through it. An inductor typically consists of an insulated wire wound into a coil around a core. \n\nWhen the current flowing through an inductor changes, the time-varying magnetic field induces an electromotive force (\"e.m.f.\") (voltage) in the conductor, described by Faraday's law of induction. According to Lenz's law, the induced voltage has a polarity (direction) which opposes the change in current that created it. As a result, inductors oppose any changes in current through them.\n\nAn inductor is characterized by its inductance, which is the ratio of the voltage to the rate of change of current. In the International System of Units (SI), the unit of inductance is the henry (H) named for 19th century American scientist Joseph Henry. In the measurement of magnetic circuits, it is equivalent to weber/ampere. Inductors have values that typically range from 1µH (10H) to 20H. Many inductors have a magnetic core made of iron or ferrite inside the coil, which serves to increase the magnetic field and thus the inductance. Along with capacitors and resistors, inductors are one of the three passive linear circuit elements that make up electronic circuits. Inductors are widely used in alternating current (AC) electronic equipment, particularly in radio equipment. They are used to block AC while allowing DC to pass; inductors designed for this purpose are called chokes. They are also used in electronic filters to separate signals of different frequencies, and in combination with capacitors to make tuned circuits, used to tune radio and TV receivers.\n\nAn electric current flowing through a conductor generates a magnetic field surrounding it. The magnetic flux linkage formula_1 generated by a given current formula_2 depends on the geometric shape of the circuit. Their ratio defines the inductance formula_3. Thus\n\nThe inductance of a circuit depends on the geometry of the current path as well as the magnetic permeability of nearby materials. An inductor is a component consisting of a wire or other conductor shaped to increase the magnetic flux through the circuit, usually in the shape of a coil or helix. Winding the wire into a coil increases the number of times the magnetic flux lines link the circuit, increasing the field and thus the inductance. The more turns, the higher the inductance. The inductance also depends on the shape of the coil, separation of the turns, and many other factors. By adding a \"magnetic core\" made of a ferromagnetic material like iron inside the coil, the magnetizing field from the coil will induce magnetization in the material, increasing the magnetic flux. The high permeability of a ferromagnetic core can increase the inductance of a coil by a factor of several thousand over what it would be without it.\n\nAny change in the current through an inductor creates a changing flux, inducing a voltage across the inductor. By Faraday's law of induction, the voltage induced by any change in magnetic flux through the circuit is given by \n\nReformulating the definition of formula_3 above, we obtain\nIt follows, that\n\nfor formula_3 independent of time. \n\nSo inductance is also a measure of the amount of electromotive force (voltage) generated for a given rate of change of current. For example, an inductor with an inductance of 1 henry produces an EMF of 1 volt when the current through the inductor changes at the rate of 1 ampere per second. This is usually taken to be the constitutive relation (defining equation) of the inductor.\n\nThe dual of the inductor is the capacitor, which stores energy in an electric field rather than a magnetic field. Its current–voltage relation is obtained by exchanging current and voltage in the inductor equations and replacing \"L\" with the capacitance \"C\".\n\nThe polarity (direction) of the induced voltage is given by Lenz's law, which states that the induced voltage will be such as to oppose the change in current. For example, if the current through an inductor is increasing, the induced voltage will be positive at the terminal through which the current enters and negative at the terminal through which it leaves, tending to oppose the additional current. The energy from the external circuit necessary to overcome this potential \"hill\" is being stored in the magnetic field of the inductor. If the current is decreasing, the induced voltage will be negative at the terminal through which the current enters and positive at the terminal through which it leaves, tending to maintain the current. In this case energy from the magnetic field is being returned to the circuit.\n\nOne intuitive explanation as to why a potential difference is induced on a change of current in an inductor goes as follows:\n\nWe know that the work done per unit charge on a charged particle when passing the inductor is formula_10. The negative sign indicates that the work is done \"against\" the emf, and is not done \"by\" the emf.\n\nBy knowing that formula_2 is the charge per unit time, it follows that the rate of energy formula_12 done against the emf is given by\nWe may proceed to state that\n\nIf the magnetic field in the inductor approaches the level at which the core saturates, the inductance will begin to change with current and thus we will henceforth denote the inductance formula_3 with formula_16 to accommodate for this dependency. Neglecting losses, the energy formula_12 stored by an inductor with a current formula_18 passing through it, is equal to the amount of work required to establish the current through the inductor. This is given by:\n\nIf the inductance is constant over the current range formula_20 , the stored energy is \n\nFor inductors with magnetic cores, the above equation is only valid for linear regions of the magnetic flux, at currents below the saturation level of the inductor, where the inductance is approximately constant. Where this is not the case, the integral form must be used with formula_16 variable.\n\nIn circuit theory, inductors are idealized as obeying the mathematical relation (2) above precisely. An \"ideal inductor\" has inductance, but no resistance or capacitance, and does not dissipate energy. However real inductors have nonideal properties which cause their behavior to depart from this simple model. They have resistance (due to the resistance of the wire and energy losses in the core), and parasitic capacitance due to electric potential between the turns of wire. This capacitive reactance rises with frequency; at some frequency, the inductor will behave as a resonant circuit, becoming self-resonant. Above the self-resonant frequency the capacitive reactance is the dominant part of the impedance. At higher frequencies, resistive losses in the windings increase due to skin effect and proximity effect.\n\nInductors with ferromagnetic cores have additional energy losses due to hysteresis and eddy currents in the core, which increase with frequency. At high currents, magnetic core inductors also show sudden departure from ideal behavior due to nonlinearity caused by magnetic saturation of the core. An inductor radiates electromagnetic energy into surrounding space and circuits, and may absorb electromagnetic emissions from other circuits, causing electromagnetic interference (EMI). For real-world inductor applications, these parasitic parameters may be as important as the inductance.\n\nAn early solid-state electrical switching and amplifying device called a saturable reactor exploits saturation of the core as a means of stopping the inductive transfer of current via the core.\n\nThe winding resistance appears as a resistance in series with the inductor; it is referred to as DCR (DC resistance). This resistance dissipates some of the reactive energy. The quality factor (or \"Q\") of an inductor is the ratio of its inductive reactance to its resistance at a given frequency, and is a measure of its efficiency. The higher the Q factor of the inductor, the closer it approaches the behavior of an ideal inductor. High Q inductors are used with capacitors to make resonant circuits in radio transmitters and receivers. The higher the Q is, the narrower the bandwidth of the resonant circuit.\n\nThe Q factor of an inductor is defined as, where \"L\" is the inductance, \"R\" is the DCR, \"ω\" is the radian operating frequency, and the product \"ωL\" is the inductive reactance:\n\n\"Q\" increases linearly with frequency if \"L\" and \"R\" are constant. Although they are constant at low frequencies, the parameters vary with frequency. For example, skin effect, proximity effect, and core losses increase \"R\" with frequency; winding capacitance and variations in permeability with frequency affect \"L\".\n\nAt low frequencies and within limits, increasing the number of turns \"N\" improves \"Q\" because \"L\" varies as \"N\" while \"R\" varies linearly with \"N\". Similarly, increasing the radius \"r\" of an inductor improves \"Q\" because \"L\" varies as \"r\" while \"R\" varies linearly with \"r\". So high \"Q\" air core inductors often have large diameters and many turns. Both of those examples assume the diameter of the wire stays the same, so both examples use proportionally more wire. If the total mass of wire is held constant, then there would be no advantage to increasing the number of turns or the radius of the turns because the wire would have to be proportionally thinner.\n\nUsing a high permeability ferromagnetic core can greatly increase the inductance for the same amount of copper, so the core can also increase the Q. Cores however also introduce losses that increase with frequency. The core material is chosen for best results for the frequency band. High Q inductors must avoid saturation; one way is by using a (physically larger) air core inductor. At VHF or higher frequencies an air core is likely to be used. A well designed air core inductor may have a Q of several hundred.\n\nInductors are used extensively in analog circuits and signal processing. Applications range from the use of large inductors in power supplies, which in conjunction with filter capacitors remove ripple which is a multiple of the mains frequency (or the switching frequency for switched-mode power supplies) from the direct current output, to the small inductance of the ferrite bead or torus installed around a cable to prevent radio frequency interference from being transmitted down the wire. Inductors are used as the energy storage device in many switched-mode power supplies to produce DC current. The inductor supplies energy to the circuit to keep current flowing during the \"off\" switching periods and enables topographies where the output voltage is higher than the input voltage.\n\nA tuned circuit, consisting of an inductor connected to a capacitor, acts as a resonator for oscillating current. Tuned circuits are widely used in radio frequency equipment such as radio transmitters and receivers, as narrow bandpass filters to select a single frequency from a composite signal, and in electronic oscillators to generate sinusoidal signals.\n\nTwo (or more) inductors in proximity that have coupled magnetic flux (mutual inductance) form a transformer, which is a fundamental component of every electric utility power grid. The efficiency of a transformer may decrease as the frequency increases due to eddy currents in the core material and skin effect on the windings. The size of the core can be decreased at higher frequencies. For this reason, aircraft use 400 hertz alternating current rather than the usual 50 or 60 hertz, allowing a great saving in weight from the use of smaller transformers. Transformers enable switched-mode power supplies that isolate the output from the input.\n\nInductors are also employed in electrical transmission systems, where they are used to limit switching currents and fault currents. In this field, they are more commonly referred to as reactors.\n\nInductors have parasitic effects which cause them to depart from ideal behavior. They create and suffer from electromagnetic interference (EMI). Their physical size prevents them from being integrated on semiconductor chips. So the use of inductors is declining in modern electronic devices, particularly compact portable devices. Real inductors are increasingly being replaced by active circuits such as the gyrator which can synthesize inductance using capacitors.\nAn inductor usually consists of a coil of conducting material, typically insulated copper wire, wrapped around a core either of plastic (to create an air-core inductor) or of a ferromagnetic (or ferrimagnetic) material; the latter is called an \"iron core\" inductor. Since power inductors require high induction levels, high permeability and low saturation points in the core materials are not ideal. The high permeability of the ferromagnetic core increases the magnetic field and confines it closely to the inductor, thereby increasing the inductance. Low frequency inductors are constructed like transformers, with cores of electrical steel laminated to prevent eddy currents. 'Soft' ferrites are widely used for cores above audio frequencies, since they do not cause the large energy losses at high frequencies that ordinary iron alloys do. Inductors come in many shapes. Some inductors have an adjustable core, which enables changing of the inductance. Inductors used to block very high frequencies are sometimes made by stringing a ferrite bead on a wire.\n\nSmall inductors can be etched directly onto a printed circuit board by laying out the trace in a spiral pattern. Some such planar inductors use a planar core. Small value inductors can also be built on integrated circuits using the same processes that are used to make transistors. Aluminium interconnect is typically used, laid out in a spiral coil pattern. However, the small dimensions limit the inductance, and it is far more common to use a circuit called a \"gyrator\" that uses a capacitor and active components to behave similarly to an inductor. Regardless of the design, because of the low inductances and low power dissipation on-die inductors allow, they're currently only commercially used for high frequency RF circuits.\nInductors used in power regulation systems, lighting, and other systems that require low-noise operating conditions, are often partially or fully shielded. In telecommunication circuits employing induction coils and repeating transformers shielding of inductors in close proximity reduces circuit cross-talk.\n\nThe term \"air core coil\" describes an inductor that does not use a magnetic core made of a ferromagnetic material. The term refers to coils wound on plastic, ceramic, or other nonmagnetic forms, as well as those that have only air inside the windings. Air core coils have lower inductance than ferromagnetic core coils, but are often used at high frequencies because they are free from energy losses called core losses that occur in ferromagnetic cores, which increase with frequency. A side effect that can occur in air core coils in which the winding is not rigidly supported on a form is 'microphony': mechanical vibration of the windings can cause variations in the inductance.\n\nAt high frequencies, particularly radio frequencies (RF), inductors have higher resistance and other losses. In addition to causing power loss, in resonant circuits this can reduce the Q factor of the circuit, broadening the bandwidth. In RF inductors, which are mostly air core types, specialized construction techniques are used to minimize these losses. The losses are due to these effects:\n\nTo reduce parasitic capacitance and proximity effect, high Q RF coils are constructed to avoid having many turns lying close together, parallel to one another. The windings of RF coils are often limited to a single layer, and the turns are spaced apart. To reduce resistance due to skin effect, in high-power inductors such as those used in transmitters the windings are sometimes made of a metal strip or tubing which has a larger surface area, and the surface is silver-plated.\n\nSmall inductors for low current and low power are made in molded cases resembling resistors. These may be either plain (phenolic) core or ferrite core. An ohmmeter readily distinguishes them from similar-sized resistors by showing the low resistance of the inductor.\n\nFerromagnetic-core or iron-core inductors use a magnetic core made of a ferromagnetic or ferrimagnetic material such as iron or ferrite to increase the inductance. A magnetic core can increase the inductance of a coil by a factor of several thousand, by increasing the magnetic field due to its higher magnetic permeability. However the magnetic properties of the core material cause several side effects which alter the behavior of the inductor and require special construction:\n\nLow-frequency inductors are often made with laminated cores to prevent eddy currents, using construction similar to transformers. The core is made of stacks of thin steel sheets or laminations oriented parallel to the field, with an insulating coating on the surface. The insulation prevents eddy currents between the sheets, so any remaining currents must be within the cross sectional area of the individual laminations, reducing the area of the loop and thus reducing the energy losses greatly. The laminations are made of low-conductivity silicon steel to further reduce eddy current losses.\n\nFor higher frequencies, inductors are made with cores of ferrite. Ferrite is a ceramic ferrimagnetic material that is nonconductive, so eddy currents cannot flow within it. The formulation of ferrite is xxFeO where xx represents various metals. For inductor cores soft ferrites are used, which have low coercivity and thus low hysteresis losses.\n\nAnother material is powdered iron cemented with a binder.\n\nIn an inductor wound on a straight rod-shaped core, the magnetic field lines emerging from one end of the core must pass through the air to re-enter the core at the other end. This reduces the field, because much of the magnetic field path is in air rather than the higher permeability core material and is a source of electromagnetic interference. A higher magnetic field and inductance can be achieved by forming the core in a closed magnetic circuit. The magnetic field lines form closed loops within the core without leaving the core material. The shape often used is a toroidal or doughnut-shaped ferrite core. Because of their symmetry, toroidal cores allow a minimum of the magnetic flux to escape outside the core (called \"leakage flux\"), so they radiate less electromagnetic interference than other shapes. Toroidal core coils are manufactured of various materials, primarily ferrite, powdered iron and laminated cores.\n\nProbably the most common type of variable inductor today is one with a moveable ferrite magnetic core, which can be slid or screwed in or out of the coil. Moving the core farther into the coil increases the permeability, increasing the magnetic field and the inductance. Many inductors used in radio applications (usually less than 100 MHz) use adjustable cores in order to tune such inductors to their desired value, since manufacturing processes have certain tolerances (inaccuracy). Sometimes such cores for frequencies above 100 MHz are made from highly conductive non-magnetic material such as aluminum. They decrease the inductance because the magnetic field must bypass them.\n\nAir core inductors can use sliding contacts or multiple taps to increase or decrease the number of turns included in the circuit, to change the inductance. A type much used in the past but mostly obsolete today has a spring contact that can slide along the bare surface of the windings. The disadvantage of this type is that the contact usually short-circuits one or more turns. These turns act like a single-turn short-circuited transformer secondary winding; the large currents induced in them cause power losses.\n\nA type of continuously variable air core inductor is the \"variometer\". This consists of two coils with the same number of turns connected in series, one inside the other. The inner coil is mounted on a shaft so its axis can be turned with respect to the outer coil. When the two coils' axes are collinear, with the magnetic fields pointing in the same direction, the fields add and the inductance is maximum. When the inner coil is turned so its axis is at an angle with the outer, the mutual inductance between them is smaller so the total inductance is less. When the inner coil is turned 180° so the coils are collinear with their magnetic fields opposing, the two fields cancel each other and the inductance is very small. This type has the advantage that it is continuously variable over a wide range. It is used in antenna tuners and matching circuits to match low frequency transmitters to their antennas.\n\nAnother method to control the inductance without any moving parts requires an additional DC current bias winding which controls the permeability of an easily saturable core material. See Magnetic amplifier.\n\nA choke is an inductor designed specifically for blocking high-frequency alternating current (AC) in an electrical circuit, while allowing DC or low-frequency signals to pass. It usually consists of a coil of insulated wire wound on a magnetic core, although some consist of a donut-shaped \"bead\" of ferrite material strung on a wire. Like other inductors, chokes resist changes in current passing through them increasingly with frequency. The difference between chokes and other inductors is that chokes do not require the high Q factor construction techniques that are used to reduce the resistance in inductors used in tuned circuits.\n\nThe effect of an inductor in a circuit is to oppose changes in current through it by developing a voltage across it proportional to the rate of change of the current. An ideal inductor would offer no resistance to a constant direct current; however, only superconducting inductors have truly zero electrical resistance.\n\nThe relationship between the time-varying voltage \"v\"(\"t\") across an inductor with inductance \"L\" and the time-varying current \"i\"(\"t\") passing through it is described by the differential equation:\n\nWhen there is a sinusoidal alternating current (AC) through an inductor, a sinusoidal voltage is induced. The amplitude of the voltage is proportional to the product of the amplitude (\"I\") of the current and the frequency (\"f\") of the current.\n\nIn this situation, the phase of the current lags that of the voltage by π/2 (90°). For sinusoids, as the voltage across the inductor goes to its maximum value, the current goes to zero, and as the voltage across the inductor goes to zero, the current through it goes to its maximum value.\n\nIf an inductor is connected to a direct current source with value \"I\" via a resistance \"R\" (at least the DCR of the inductor), and then the current source is short-circuited, the differential relationship above shows that the current through the inductor will discharge with an exponential decay:\n\nThe ratio of the peak voltage to the peak current in an inductor energised from an AC source is called the reactance and is denoted \"X\".\n\nThus,\n\nReactance is measured in ohms but referred to as \"impedance\" rather than resistance; energy is stored in the magnetic field as current rises and discharged as current falls. Inductive reactance is proportional to frequency. At low frequency the reactance falls; at DC, the inductor behaves as a short-circuit. As frequency increases the reactance increases and at a sufficiently high frequency the reactance approaches that of an open circuit.\n\nIn filtering applications,with respect to a particular load impedance, an inductor has a corner frequency defined as:\n\nWhen using the Laplace transform in circuit analysis, the impedance of an ideal inductor with no initial current is represented in the \"s\" domain by:\n\nwhere\n\nIf the inductor does have initial current, it can be represented by: \n\nInductors in a parallel configuration each have the same potential difference (voltage). To find their total equivalent inductance (\"L\"):\n\nThe current through inductors in series stays the same, but the voltage across each inductor can be different. The sum of the potential differences (voltage) is equal to the total voltage. To find their total inductance:\n\nThese simple relationships hold true only when there is no mutual coupling of magnetic fields between individual inductors.\n\nMutual inductance occurs when the magnetic field of an inductor induces a magnetic field in an adjacent inductor. Mutual induction is the basis of transformer construction.\n\nThe table below lists some common simplified formulas for calculating the approximate inductance of several inductor constructions.\n\n\n\n"}
{"id": "49697796", "url": "https://en.wikipedia.org/wiki?curid=49697796", "title": "Jerusalem District Electricity Company", "text": "Jerusalem District Electricity Company\n\nThe Jerusalem District Electricity Company (JDECO) is an electricity company established in its current form in 1956 that has the exclusive rights to supply electricity to consumers in the districts of East Jerusalem, Bethlehem, Ramallah and Jericho. The company does not have its own power stations, but buys over 95% of its electricity from Israel Electric Corporation (IEC) and the remainder from Jordanian National Electric Power Company. Jordanian electricity is only used in the Jericho district.\n\nJDECO supplies electricity to 30% of households in the West Bank and East Jerusalem. JDECO supplies electricity in its license area, while IEC sells electricity directly to the PA to distribute in areas not covered by JDECO. JDECO recorded a net loss of about NIS 2.6 million in 2011. In 2012, JDECO owed NIS 458 million to IEC.\n\nThe Jerusalem District Electricity Company was founded in 1914 by Ottoman authority, before the British Mandate for Palestine. The Company was established in its current form in 1956 under Jordan authority.\n\nJDECO has had a monopoly over supplying electricity in the larger Jerusalem area for nearly 100 years. Its first concession was signed during the British Mandate and has been extended under Jordanian rule. In 1988, Jordan extended the concession for another 60 years, but Israel has only agreed to an extension until 2030. The Israel Electricity Authority has granted JDECO a 20-year license for electricity distribution in East Jerusalem, which currently runs to 2030, and an annually renewable license for the supply of electricity to consumers. JDECO’s activities in East Jerusalem are regulated by the Israel Electricity Authority, and in the West Bank they are regulated by the Palestinian Authority (PA) or, in some cases, by the Israeli Civil Administration.\n\nJDECO is a joint-stock company. As at 2016, 25% of its shares were owned by the municipalities of Jerusalem, Ramallah, Al-Bireh, Bethlehem, Beit Sahour, Beit Jala and Jericho, while the remaining 75% were owned by over 3,000 private shareholders. The board of directors consists of 18 members: 9 representatives of the municipalities and 9 representatives of the private shareholders.\n\nThe company has four area branches, Jerusalem, Ramallah, Bethlehem and Jericho. In 2011, JDECO employed about 450 workers.\n\nJDECO is responsible for connecting new consumers to the grid, as well as metering and billing. It has exclusive rights within its license areas. \n\nJDECO does not have its own power stations, but purchases over 95% of its electricity from Israel Electric Corporation (IEC) and the remainder from Jordanian National Electric Power Company. Jordanian electricity is permitted to be used only in the Jericho district. \n\nIn 2011, all of the electricity distributed by the company in East Jerusalem was purchased from IEC. JDECO‘s activities in the Jerusalem area constitute about 1/3 of the company’s total economic activity.\n\nMost of the electricity sold by JDECO is supplied by IEC. However, by 2012, JDECO’s debt to IEC was NIS 458 million, and growing. By February 2015, IEC was owed NIS 1.9 billion, most of which was owed by the Palestinian Authority and JDECO. \n\nOn 23 February 2015, IEC intentionally cut off electricity to the West Bank for about 45 minutes due to unpaid debts. Two days later it again cut off electricity, stating it was a warning to the Palestinian Authority to begin paying down the debt. IEC stated that it is losing NIS 85 million per month on power supplied to Nablus and Jenin that is not being paid for, causing the majority of IEC’s quarterly loss. The Palestinians accused IEC of collective punishment; while IEC stated that it must operate independently and is treating this as it would any customer who does not pay its debts.\n\nIn March 2016, the debts were NIS 1.7 billion; and on 31 March, IEC again cut power, this time to the Jericho area. On 4 April, IEC cut power in the Bethlehem area, and the following day it cut power in the Hebron area. On 6 April, IEC restored full power to the West Bank after it received a payment of NIS 20 million, and an agreement to receive a full debt repayment schedule within seven days.\n\n\n"}
{"id": "1925933", "url": "https://en.wikipedia.org/wiki?curid=1925933", "title": "Lake stratification", "text": "Lake stratification\n\nLake stratification is the separation of lakes into three layers:\n\n\nThe thermal stratification of lakes refers to a change in the temperature at different depths in the lake, and is due to the change in water's density with temperature. Cold water is denser than warm water and the epilimnion generally consists of water that is not as dense as the water in the hypolimnion. However, the temperature of maximum density for freshwater is 4 °C. In temperate regions where lake water warms up and cools through the seasons, a cyclical pattern of overturn occurs that is repeated from year to year as the cold dense water at the top of the lake sinks. For example, in dimictic lakes the lake water turns over during the spring and the fall. This process occurs more slowly in deeper water and as a result, a thermal bar may form. If the stratification of water lasts for extended periods, the lake is meromictic. Conversely, for most of the time, the relatively shallower meres are unstratified; that is, the mere is considered all epilimnion.\n\nThe accumulation of dissolved carbon dioxide in three meromictic lakes in Africa (Lake Nyos and Lake Monoun in Cameroon and Lake Kivu in Rwanda) is potentially dangerous because if one of these lakes is triggered into limnic eruption, a very large quantity of carbon dioxide can quickly leave the lake and displace the oxygen needed for life by people and animals in the surrounding area.\n\nNatural resource and environmental managers are often challenged by problems caused by lake and pond thermal stratification. Fish die-offs have been directly associated with thermal gradients, stagnation, and ice cover. Excessive growth of plankton may limit the recreational use of lakes and the commercial use of lake water. With severe thermal stratification in a lake, the quality of drinking water also can be adversely affected. For fisheries managers, the spatial distribution of fish within a lake is often adversely affected by thermal stratification and in some cases may indirectly cause large die-offs of recreationally important fish. One commonly used tool to reduce the severity of these lake management problems is to eliminate or lessen thermal stratification through aeration. Many types of aeration equipment have been used to thermally destratify lakes. Aeration has met with some success, although it has rarely proved to be a panacea.\n\nhttp://onlinelibrary.wiley.com/doi/10.1111/j.1752-1688.1972.tb05092.x/abstract\n\nhttp://onlinelibrary.wiley.com/doi/10.1111/j.1752-1688.1972.tb05181.x/abstract\n\nhttp://www.tandfonline.com/doi/abs/10.1577/1548-8640(1972)34%5B175%3AEOTMOA%5D2.0.CO%3B2#preview\n\n\n\nAquatic Science\nHypoxia\nFreshwater ecosystems\nWater column\n"}
{"id": "10677691", "url": "https://en.wikipedia.org/wiki?curid=10677691", "title": "List of Corymbia species", "text": "List of Corymbia species\n\nThis in an alphabetical list of the 127 species in the genus \"Corymbia\".\n\n\n"}
{"id": "19294082", "url": "https://en.wikipedia.org/wiki?curid=19294082", "title": "List of Ramsar sites in Ukraine", "text": "List of Ramsar sites in Ukraine\n\nUkraine has 33 Ramsar sites designated as \"Wetlands of International Importance\". Ramsar sites in Ukraine have a total surface area of approximately 744,651 hectares. The Ramsar Convention on Wetlands came into effect for Ukraine on December 1, 1991.\n"}
{"id": "19591263", "url": "https://en.wikipedia.org/wiki?curid=19591263", "title": "List of Ultras of Malay Archipelago", "text": "List of Ultras of Malay Archipelago\n\nThis is a list of ultra prominent peaks (with topographic prominence greater than 1,500 metres) in Indonesia, East Malaysia and East Timor.\n\n\"See also: For a complete list of ultras located on the island of New Guinea, see List of Ultras of Oceania.\"\n\n\"For the list of ultras located in the Philippines, see List of Ultras of the Philippines.\"\n\n<br>\n"}
{"id": "42738637", "url": "https://en.wikipedia.org/wiki?curid=42738637", "title": "List of cucumber varieties", "text": "List of cucumber varieties\n\nThis is a list of varieties or cultivars of cucumber, a widely cultivated vine in the gourd family, Cucurbitaceae. The cucumber vine bears edible fruit.\n"}
{"id": "33876088", "url": "https://en.wikipedia.org/wiki?curid=33876088", "title": "List of ecoregions in Bhutan", "text": "List of ecoregions in Bhutan\n\nThe ecoregions of Bhutan generally vary according to altitude and precipitation. Bhutan occupies in the eastern Himalaya, at altitudes ranging from to . The dry, plain-like valleys of western and central Bhutan tend to be relatively densely populated and intensely cultivated. The wetter eastern valleys, however, tend to be steeper, narrower ravines. At lower and middle elevations, Indomalayan biomes range from tropical and subtropical forests to temperate coniferous forests. In the northern mountainous regions, Bhutan is largely Palearctic, comprising temperate coniferous forests, montane grasslands and shrublands, and swaths without any ecozone in its highest glacial elevations.\n\nBelow is a list of ecoregions in Bhutan.\n\n"}
{"id": "35297769", "url": "https://en.wikipedia.org/wiki?curid=35297769", "title": "List of ecoregions in Portugal", "text": "List of ecoregions in Portugal\n\nThe following is a list of ecoregions in Portugal, including the Azores and Madeira, according to the Worldwide Fund for Nature (WWF). \n\n\n\n\n\n"}
{"id": "4473614", "url": "https://en.wikipedia.org/wiki?curid=4473614", "title": "List of first ascents", "text": "List of first ascents\n\nThe following list summarizes notable first ascents of mountains and peaks around the world, in chronological order. It does not list new routes to previously climbed summits.\n\nAbbreviations in the reference list: AAJ: American Alpine Journal, AJ: The Alpine Journal, HJ: The_Himalayan Journal.\n\n"}
{"id": "9020822", "url": "https://en.wikipedia.org/wiki?curid=9020822", "title": "List of mustard diseases", "text": "List of mustard diseases\n\nThis article is a list of diseases of mustard (\"Brassica juncea\" var. \"crispifolia\" and \"B. nigra\").\n\n"}
{"id": "385334", "url": "https://en.wikipedia.org/wiki?curid=385334", "title": "List of particles", "text": "List of particles\n\nThis article includes a list of the different types of atomic- and sub-atomic particles found or hypothesized to exist in the whole of the universe categorized by type. Properties of the various particles listed are also given, as well as the laws that the particles follow. For individual lists of the different particles, see the list below.\n\nElementary particles are particles with no measurable internal structure; that is, it is unknown whether they are composed of other particles. They are the fundamental objects of quantum field theory. Many families and sub-families of elementary particles exist. Elementary particles are classified according to their spin. Fermions have half-integer spin while bosons have integer spin. All the particles of the Standard Model have been experimentally observed, recently including the Higgs boson. Many other hypothetical elementary particles, such as the graviton, have been proposed, but not observed experimentally.\n\nFermions are one of the two fundamental classes of particles, the other being bosons. Fermion particles are described by Fermi–Dirac statistics and have quantum numbers described by the Pauli exclusion principle. They include the quarks and leptons, as well as any composite particles consisting of an odd number of these, such as all baryons and many atoms and nuclei.\n\nFermions have half-integer spin; for all known elementary fermions this is . All known fermions, except neutrinos, are also Dirac fermions; that is, each known fermion has its own distinct antiparticle. It is not known whether the neutrino is a Dirac fermion or a Majorana fermion. Fermions are the basic building blocks of all matter. They are classified according to whether they interact via the strong interaction or not. In the Standard Model, there are 12 types of elementary fermions: six quarks and six leptons.\n\nQuarks are the fundamental constituents of hadrons and interact via the strong interaction. Quarks are the only known carriers of fractional charge, but because they combine in groups of three (baryons) or in pairs of one quark and one antiquark (mesons), only integer charge is observed in nature. Their respective antiparticles are the antiquarks, which are identical except that they carry the opposite electric charge (for example the up quark carries charge +, while the up antiquark carries charge −), color charge, and baryon number. There are six flavors of quarks; the three positively charged quarks are called \"up-type quarks\" while the three negatively charged quarks are called \"down-type quarks\".\n\nLeptons do not interact via the strong interaction. Their respective antiparticles are the antileptons, which are identical, except that they carry the opposite electric charge and lepton number. The antiparticle of an electron is an antielectron, which is nearly always called a \"positron\" for historical reasons. There are six leptons in total; the three charged leptons are called \"electron-like leptons\", while the neutral leptons are called \"neutrinos\". Neutrinos are known to oscillate, so that neutrinos of definite flavor do not have definite mass, rather they exist in a superposition of mass eigenstates. The hypothetical heavy right-handed neutrino, called a \"sterile neutrino\", has been left off the list.\n\nBosons are one of the two fundamental classes of particles, the other being fermions. Bosons are characterized by Bose–Einstein statistics and all have integer spins. Bosons may be either elementary, like photons and gluons, or composite, like mesons.\n\nAccording to the Standard Model the elementary bosons are:\n\nThe Higgs boson is postulated by the electroweak theory primarily to explain the origin of particle masses. In a process known as the \"Higgs mechanism\", the Higgs boson and the other gauge bosons in the Standard Model acquire mass via spontaneous symmetry breaking of the SU(2) gauge symmetry. The Minimal Supersymmetric Standard Model (MSSM) predicts several Higgs bosons. A new particle expected to be the Higgs boson was observed at the CERN/LHC on 14 March 2013, around the energy of 126.5 GeV with an accuracy of close to five sigma (99.9999%, which is accepted as definitive). The Higgs mechanism giving mass to other particles has not been observed.\n\nElementary bosons responsible for the four fundamental forces of nature are called force particles (gauge bosons). Strong interaction is mediated by the gluon, weak interaction is mediated by the W and Z bosons.\n\nThe graviton, listed separately above, is a hypothetical particle that has been included in some extensions to the standard model to mediate the gravitational force. It is in a peculiar category between known and hypothetical particles: As an unobserved particle that is not predicted by, nor required for the Standard Model, it belongs in the table of hypothetical particles, below. But gravitational force itself is a certainty, and expressing that known force in the framework of a quantum field theory requires a boson to mediate it.\n\nSupersymmetric theories predict the existence of more particles, none of which have been confirmed experimentally :\n\nNote: just as the photon, Z boson and W bosons are superpositions of the B, W, W, and W fields – the photino, zino, and wino are superpositions of the bino, wino, wino, and wino by definition.<br>No matter if one uses the original gauginos or this superpositions as a basis, the only predicted physical particles are neutralinos and charginos as a superposition of them together with the Higgsinos.\nOther theories predict the existence of additional bosons:\n\nMirror particles are predicted by theories that restore parity symmetry.\n\n\"Magnetic monopole\" is a generic name for particles with non-zero magnetic charge. They are predicted by some GUTs.\n\n\"Tachyon\" is a generic name for hypothetical particles that travel faster than the speed of light (and so paradoxically experience time in reverse due to inversal of Theory of relativity) and have an imaginary rest mass.\n\nPreons were suggested as subparticles of quarks and leptons, but modern collider experiments have all but ruled out their existence.\n\nKaluza–Klein towers of particles are predicted by some models of extra dimensions. The extra-dimensional momentum is manifested as extra mass in four-dimensional spacetime.\n\nHadrons are defined as strongly interacting composite particles. Hadrons are either:\n\nQuark models, first proposed in 1964 independently by Murray Gell-Mann and George Zweig (who called quarks \"aces\"), describe the known hadrons as composed of valence quarks and/or antiquarks, tightly bound by the color force, which is mediated by gluons. A \"sea\" of virtual quark-antiquark pairs is also present in each hadron.\n\nOrdinary baryons (composite fermions) contain three valence quarks or three valence antiquarks each.\n\nOrdinary mesons are made up of a valence quark and a valence antiquark. Because mesons have spin of 0 or 1 and are not themselves elementary particles, they are \"composite\" bosons. Examples of mesons include the pion, kaon, and the J/ψ. In quantum hydrodynamic models, mesons mediate the residual strong force between nucleons.\n\nAt one time or another, positive signatures have been reported for all of the following exotic mesons but their existences have yet to be confirmed.\n\nAtomic nuclei consist of protons and neutrons. Each type of nucleus contains a specific number of protons and a specific number of neutrons, and is called a \"nuclide\" or \"isotope\". Nuclear reactions can change one nuclide into another. See table of nuclides for a complete list of isotopes.\n\nAtoms are the smallest neutral particles into which matter can be divided by chemical reactions. An atom consists of a small, heavy nucleus surrounded by a relatively large, light cloud of electrons. Each type of atom corresponds to a specific chemical element. To date, 118 elements have been discovered or created.\n\nThe atomic nucleus consists of protons and neutrons. Protons and neutrons are, in turn, made of quarks.\n\nMolecules are the smallest particles into which a non-elemental substance can be divided while maintaining the physical properties of the substance. Each type of molecule corresponds to a specific chemical compound. Molecules are a composite of two or more atoms. See list of compounds for a list of molecules. A molecule is generally combined in a fixed proportion. It is the most basic unit of matter and is homogenous.\n\nQuasiparticles are effective particles that exist in many particle systems. The field equations of condensed matter physics are remarkably similar to those of high energy particle physics. As a result, much of the theory of particle physics applies to condensed matter physics as well; in particular, there are a selection of field excitations, called quasi-particles, that can be created and explored. These include:\n\n\n\n"}
{"id": "8249800", "url": "https://en.wikipedia.org/wiki?curid=8249800", "title": "List of rivers named Sainte-Anne", "text": "List of rivers named Sainte-Anne\n\nThere are many rivers in the province of Quebec, Canada, with similar names:\n\n\nOther names using \"River Sainte-Anne\"\n\n"}
{"id": "52823070", "url": "https://en.wikipedia.org/wiki?curid=52823070", "title": "Lovelock's theorem", "text": "Lovelock's theorem\n\nLovelock's theorem of general relativity says that from a local gravitational action which contains only second derivatives of the four-dimensional spacetime metric, then the only possible equations of motion are the Einstein field equations. The theorem was described by British physicist David Lovelock in 1971.\n\nIn four dimensional space, any tensor formula_1 whose components are function of metric tensor formula_2 and its first and second derivatives (but linear in the second derivatives of formula_2), and also symmetric and divergenceless, then field equation in vacuum formula_4, then only possible form of formula_1 is \nwhere formula_7 and formula_8 are just simple constant numbers and formula_9 is the Einstein tensor.\n\nThe only possible second-order Euler–Lagrange expression obtainable in a four-dimensional space from a scalar density of the form formula_10 is\nformula_11\n\nLovelock's theorem means that if we want to modify the Einstein field equations, then we have five options.\n\n\n"}
{"id": "36615359", "url": "https://en.wikipedia.org/wiki?curid=36615359", "title": "Motiongram", "text": "Motiongram\n\nA motiongram is a spatiotemporal display of motion, created from a video recording. Motiongrams are created using a video processing technique, in which a motion image is collapsed into a series of 1 pixel wide stripes and plotted next to one another.\n\nThe traditional way of representing (human) motion visually, is either by displaying individual frames from a video file as a keyframe display or by doing one or more forms of feature extraction and subsequent plotting of the resultant data. Neither of these are ideal to give a good impression of the actual motion happening in the sequence. Keyframe displays only show postures and not motion, while feature graphs often rely on multiple analysis steps. Motiongrams are useful as an intermediary step to show spatiotemporal information of a movement sequence, but with no need for doing a full analysis of the data.\n\nThe term motiongram was first proposed by Alexander Refsum Jensenius in 2006, and the technique has later been refined by him and others. The technique was inspired by the pioneering work of Muybridge and Marey from the 19th century, as well as the slit-scan community in the 20th century. Motiongrams resemble slit-scan photographs, but are different in that they are created from frame-differenced motion-images. The result is that only motion is shown in the final display.\n\nAn overview of creating a motiongram is shown in Figure 1. The process starts by reading a video stream, and doing simple image adjustments, e.g., changing the brightness and contrast. The next step involves producing the motion image by calculating the absolute frame difference between successive video frames, followed by applying some noise removal algorithms. The motiongram is created by calculating the normalized mean value for each row or column in the motion image. This means that for each image matrix of size MxN, a Mx1 or 1xN matrix is calculated. Drawing these 1 pixel wide “stripes” next to each other over time results in the final motiongram.\n\nThe motiongram technique has been implemented as modules in the open framework Jamoma for Max, as well as for the EyesWeb platform and in Matlab. There are also two standalone applications for OSX and Windows: VideoAnalysis (non-realtime) and AudioVideoAnalysis (realtime).\n\nMotiongrams allow for quick navigation in video material and for comparative analysis of motion qualities. Although quite rough, it is easy to see differences in the quantity of motion and similarities in upward/downward patterns between motion sequences.\n\nSince motiongrams are made by averaging over either the rows or columns of a video file, only one dimension will be shown in the final motiongram. Thus a horizontal motiongram will mainly represent vertical motion, while a vertical motiongram will mainly represent horizontal motion.\n"}
{"id": "487539", "url": "https://en.wikipedia.org/wiki?curid=487539", "title": "Mount Tarawera", "text": "Mount Tarawera\n\nMount Tarawera is the volcano responsible for one of New Zealand's largest historic eruptions. Located 24 kilometres southeast of Rotorua in the North Island, it consists of a series of rhyolitic lava domes that were fissured down the middle by an explosive basaltic eruption in 1886, which killed an estimated 120 people. These fissures run for about 17 kilometres northeast-southwest.\n\nThe volcano's component domes include Ruawahia Dome (the highest at 1,111 metres), Tarawera Dome and Wahanga Dome. It is surrounded by several lakes, most of which were created or drastically altered by the 1886 eruption. These lakes include Lakes Tarawera, Rotomahana, Rerewhakaaitu, Okataina, Okareka, Tikitapu (Blue Lake) and Rotokakahi (Green Lake). The Tarawera River runs northeastwards across the northern flank of the mountain from Lake Tarawera.\n\nMount Tarawera erupted around 1315. The ash thrown from this event may have affected temperatures around the globe and precipitated the Great Famine of 1315–17 in Europe.\n\nShortly after midnight on the morning of 10 June 1886, a series of more than 30 increasingly strong earthquakes were felt in the Rotorua area and an unusual sheet lightning display was observed from the direction of Tarawera. At around 2:00 am a larger earthquake was felt and followed by the sound of an explosion. By 2:30 am Mount Tarawera's three peaks had erupted, blasting three distinct columns of smoke and ash thousands of metres into the sky. At around 3.30 am, the largest phase of the eruption commenced; vents at Rotomahana produced a pyroclastic surge that destroyed several villages within a 6 kilometre radius, and the Pink and White Terraces appeared to be obliterated.\n\nThe eruption was heard clearly as far away as Blenheim and the effects of the ash in the air were observed as far south as Christchurch, over 800 km away. In Auckland the sound of the eruption and the flashing sky was thought by some to be an attack by Russian warships.\n\nAlthough the official contemporary death toll was 153, exhaustive research by physicist Ron Keam only identified 108 people killed by the eruption. Much of the discrepancy was due to misspelled names and other duplications. Allowing for some unnamed and unknown victims, he estimated that the true death toll was 120 at most. Some people claim that many more people died.\n\nThe eruption also buried many Māori villages, including Te Wairoa, which has now become a tourist attraction (the buried village of Te Wairoa), and the world-famous Pink and White Terraces were thought lost. A small portion of the Pink Terraces was reportedly rediscovered under Lake Rotomahana 125 years later. In 2017, using a lost 1859 survey of the old lake and terraces, researchers finally georeferenced the old Lake Rotomahana and the original Pink and White Terrace locations. Approximately 2 cubic kilometres of tephra was erupted, more than Mount St. Helens ejected in 1980. Many of the lakes surrounding the mountain had their shapes and areas dramatically altered, especially the eventual enlargement of Lake Rotomahana, the largest crater involved in the eruption, as it re-filled with water. The rift created during the eruption extends 17 km across the mountain, Lake Rotomahana and through the Waimangu Volcanic Rift Valley. Some of the local survivors at Te Wairoa took shelter in a Maori meeting house, a wharenui, named Hinemihi, which was later taken to England and erected in the grounds of Clandon Park, the seat of the 4th Earl Onslow, who had been governor-general of New Zealand at the time.\n\nOne legend surrounding the 1886 eruption is that of the phantom canoe. Eleven days before the eruption, a boat full of tourists returning from the Terraces saw what appeared to be a war canoe approach their boat, only to disappear in the mist half a mile from them. One of the witnesses was a clergyman, a local Maori man from the Te Arawa iwi. Nobody around the lake owned such a war canoe, and nothing like it had been seen on the lake for many years.\nIt is possible that the rise and fall of the lake level caused by pre-eruption fissures had freed a burial \"waka\" (canoe) from its resting place. Traditionally dead chiefs were tied in an upright position. A number of letters have been published from the tourists who experienced the event.\n\nThough skeptics maintained that it was a freak reflection seen on the mist, tribal elders at Te Wairoa claimed that it was a \"waka wairua\" (spirit canoe) and was a portent of doom. It has been suggested that the waka was actually a freak wave on the water, caused by seismic activity below the lake, but locals believe that a future eruption will be signaled by the reappearance of the canoe. \n\n\n"}
{"id": "1355641", "url": "https://en.wikipedia.org/wiki?curid=1355641", "title": "Noil", "text": "Noil\n\nNoil is the short fiber left over from combing wool or spinning silk and used as a decorative additive for many spinning projects, like rovings and yarns. Silk noil is also called \"raw silk\", although that is a misnomer. As noil is a relatively short fiber, fabric made from noil is weaker and considered less valuable.\n\nSilk noil may also be made from the short fibres, directly sourced from the silkworm cocoons. Rather than the continuous length of silk, shorter fibers, which are generally not used to create high quality silk are used for silk noil, which has a slightly rough texture. It is relatively weaker and has low resilience. It tends to have very low lustre, which makes it appear more like cotton than silk.\n\nNoil silk has the advantage of being made from protein. Thus, it has a better texture and depth that cotton – and gives a nice fall and drape.\n\nSilk noil is also blended or appended with heavier fabrics like velvets and satins to create varied textures. Made out of the strongest natural fibres (with a protein base) around, the Noil Sarees are not slippery like synthetic fibres and absorb moisture well. Noils are easily dyed, and can also be made waterproof, by using a polyurethane coating. This also increases their usage in furnishings industry. \n\nSilk noil hails from China, from where it was exported to Europe in the middle ages, especially to Italy. It was used to create silk blends, through the first half of the 14th century. However, over the time the use decreased.\n\nWith an increase in demand and variety of alternatives and low-cost substitutes, Noil has re-surfaced – experiencing a sort of revival. In India, noil is used to make sarees, materials and furnishings.\n"}
{"id": "11005679", "url": "https://en.wikipedia.org/wiki?curid=11005679", "title": "Passenger miles per gallon", "text": "Passenger miles per gallon\n\nPassenger miles per gallon (PMPG) is a metric to evaluate the energy efficiency of a vehicle or transportation mode. The PMPG can be obtained by multiplying the miles per gallon of fuel (MPG) by either the passenger capacity or the average occupancy. The occupancy of personal vehicles is typically lower than capacity by a considerable degree and thus the values computed based on capacity and on occupancy will often be quite different.\n\n"}
{"id": "3104242", "url": "https://en.wikipedia.org/wiki?curid=3104242", "title": "Serpukhovian", "text": "Serpukhovian\n\nThe Serpukhovian is in the ICS geologic timescale the uppermost stage or youngest age of the Mississippian, the lower subsystem of the Carboniferous. The Serpukhovian age lasted from Ma to Ma. It is preceded by the Visean and is followed by the Bashkirian.\n\nThe Serpukhovian correlates with the lower part of the Namurian stage of European stratigraphy and the middle and upper parts of the Chesterian stage of North American stratigraphy.\n\nThe Serpukhovian stage was proposed in 1890 by Russian stratigrapher Sergei Nikitin and was introduced in the official stratigraphy of European Russia in 1974. It was named after the city of Serpukhov, near Moscow. The ICS later used the upper Russian subdivisions of the Carboniferous in its international geologic time scale.\n\nThe base of the Serpukhovian is at the first appearance of the conodont \"Lochriea crusiformis\". In 2007, no GSSP had been assigned to the Serpukhovian stage yet. The top of the stage (the base of the Pennsylvanian subsystem and Bashkirian stage) is at the first appearance of the conodont \"Declinognathodus nodiliferus\". It is also slightly above the first appearance of the foram \"Globivalvulina bulloides\", genozone of the ammonoid genus \"Homoceras\" and the ammonoid biozone of \"Isohomoceras subglobosum\".\n\nThe Serpukhovian stage includes four conodont biozones:\n\nIn Russian stratigraphy, the Serpukhovian is subdivided into three substages, from bottom to top: Tarusian, Steshevian, and Protvian, named after places near Serpukhov (Tarusa and Protva). In British stratigraphy, the Serpukhovian (lower Namurian) contains three substages. These are from bottom to top: Pendleian, Arnsbergian and Chokierian (only the lower Chokierian falls in the Serpukhovian, the top falls in the Bashkirian).\n\n\n\n"}
{"id": "22290028", "url": "https://en.wikipedia.org/wiki?curid=22290028", "title": "Shell shock", "text": "Shell shock\n\nShell shock is a term coined in World War I to describe the type of posttraumatic stress disorder many soldiers were afflicted with during the war (before PTSD itself was a term). \nIt is a reaction to the intensity of the bombardment and fighting that produced a helplessness appearing variously as panic and being scared, flight, or an inability to reason, sleep, walk or talk.\n\nDuring the War, the concept of shell shock was ill-defined. Cases of \"shell shock\" could be interpreted as either a physical or psychological injury, or simply as a lack of moral fibre. The term \"shell shock\" is still used by the Veterans Administration to describe certain parts of PTSD, but mostly it has entered into popular imagination and memory, and it is often identified as the signature injury of the War.\n\nIn World War II and thereafter, diagnosis of \"shell shock\" was replaced by that of combat stress reaction, a similar but not identical response to the trauma of warfare and bombardment.\n\nDuring the early stages of World War I in 1914, soldiers from the British Expeditionary Force began to report medical symptoms after combat, including tinnitus, amnesia, headaches, dizziness, tremors, and hypersensitivity to noise. While these symptoms resembled those that would be expected after a physical wound to the brain, many of those reporting sick showed no signs of head wounds. By December 1914 as many as 10% of British officers and 4% of enlisted men were suffering from \"nervous and mental shock\".\n\nThe term \"shell shock\" came into use to reflect an assumed link between the symptoms and the effects of explosions from artillery shells. The term was first published in 1915 in an article in \"The Lancet\" by Charles Myers. Some 60–80% of shell shock cases displayed acute neurasthenia, while 10% displayed what would now be termed symptoms of conversion disorder, including mutism and fugue.\n\nThe number of shell shock cases grew during 1915 and 1916 but it remained poorly understood medically and psychologically. Some doctors held the view that it was a result of hidden physical damage to the brain, with the shock waves from bursting shells creating a cerebral lesion that caused the symptoms and could potentially prove fatal. Another explanation was that shell shock resulted from poisoning by the carbon monoxide formed by explosions.\n\nAt the same time an alternative view developed describing shell shock as an emotional, rather than a physical, injury. Evidence for this point of view was provided by the fact that an increasing proportion of men suffering shell shock symptoms had not been exposed to artillery fire. Since the symptoms appeared in men who had no proximity to an exploding shell, the physical explanation was clearly unsatisfactory.\n\nIn spite of this evidence, the British Army continued to try to differentiate those whose symptoms followed explosive exposure from others. In 1915 the British Army in France was instructed that:\n\nHowever, it often proved difficult to identify which cases were which, as the information on whether a casualty had been close to a shell explosion or not was rarely provided.\n\nAt first, shell-shock casualties were rapidly evacuated from the front line – in part because of fear of their unpredictable behaviour. As the size of the British Expeditionary Force increased, and manpower became in shorter supply, the number of shell shock cases became a growing problem for the military authorities. At the Battle of the Somme in 1916, as many as 40% of casualties were shell-shocked, resulting in concern about an epidemic of psychiatric casualties, which could not be afforded in either military or financial terms.\n\nAmong the consequences of this were an increasing official preference for the psychological interpretation of shell shock, and a deliberate attempt to avoid the medicalisation of shell shock. If men were 'uninjured' it was easier to return them to the front to continue fighting. Another consequence was an increasing amount of time and effort devoted to understanding and treating shell shock symptoms.\n\nBy the Battle of Passchendaele in 1917, the British Army had developed methods to reduce shell shock. A man who began to show shell-shock symptoms was best given a few days' rest by his local medical officer. Col. Rogers, Regimental Medical Officer, 4th Battalion Black Watch wrote:\n\nIf symptoms persisted after a few weeks at a local Casualty Clearing Station, which would normally be close enough to the front line to hear artillery fire, a casualty might be evacuated to one of four dedicated psychiatric centres which had been set up further behind the lines, and were labelled as \"NYDN – Not Yet Diagnosed Nervous\" pending further investigation by medical specialists.\n\nEven though the Battle of Passchendaele generally became a byword for horror, the number of cases of shell shock were relatively few. 5,346 shell shock cases reached the Casualty Clearing Station, or roughly 1% of the British forces engaged. 3,963 (or just under 75%) of these men returned to active service without being referred to a hospital for specialist treatment. The number of shell shock cases reduced throughout the battle, and the epidemic of illness was ended.\n\nDuring 1917, \"shell shock\" was entirely banned as a diagnosis in the British Army, and mentions of it were censored, even in medical journals.\n\nThe treatment of chronic shell shock varied widely according to the details of the symptoms, the views of the doctors involved, and other factors including the rank and class of the patient.\n\nThere were so many officers and men suffering from shell shock that 19 British military hospitals were wholly devoted to the treatment of cases. Ten years after the war, 65,000 veterans of the war were still receiving treatment for it in Britain. In France it was possible to visit aged shell shock victims in hospital in 1960.\n\nRecent research by Johns Hopkins University has found that the brain tissue of combat veterans who have been exposed to improvised explosive devices (IEDs) exhibit a pattern of injury in the areas responsible for decision making, memory and reasoning. This evidence has led the researchers to conclude that shell shock may not only be a psychological disorder, since the symptoms exhibited by sufferers from the First World War are very similar to these injuries.\n\nSome men suffering from shell shock were put on trial, and even executed, for military crimes including desertion and cowardice. While it was recognised that the stresses of war could cause men to break down, a lasting episode was likely to be seen as symptomatic of an underlying lack of character. For instance, in his testimony to the post-war Royal Commission examining shell shock, Lord Gort said that shell shock was a weakness and was not found in \"good\" units. The continued pressure to avoid medical recognition of shell shock meant that it was not, in itself, considered an admissible defence.\n\nExecutions of soldiers in the British Army were not commonplace. While there were 240,000 Courts Martial and 3080 death sentences handed down, in only 346 cases was the sentence carried out. 266 British soldiers were executed for \"Desertion\", 18 for \"Cowardice\", 7 for \"Quitting a post without authority\", 5 for \"Disobedience to a lawful command\" and 2 for \"Casting away arms\". On 7 November 2006 the government of the United Kingdom gave them all a posthumous conditional pardon.\n\nThe British government produced a \"Report of the War Office Committee of Enquiry into \"Shell-Shock\"\" which was published in 1922. Recommendations from this included:\n\n\nPart of the concern was that many British veterans were receiving pensions and had long-term disabilities.\n\nBy 1939, some 120,000 British ex-servicemen had received final awards for primary psychiatric disability or were still drawing pensions – about 15% of all pensioned disabilities – and another 44,000 or so … were getting pensions for ‘soldier’s heart’ or Effort Syndrome. There is, though, much that statistics do not show, because in terms of psychiatric effects, pensioners were just the tip of a huge iceberg.\n\nWar correspondent Philip Gibbs wrote:\nSomething was wrong. They put on civilian clothes again and looked to their mothers and wives very much like the young men who had gone to business in the peaceful days before August 1914. But they had not come back the same men. Something had altered in them. They were subject to sudden moods, and queer tempers, fits of profound depression alternating with a restless desire for pleasure. Many were easily moved to passion where they lost control of themselves, many were bitter in their speech, violent in opinion, frightening.\n\nOne British writer between the wars wrote:\nThere should be no excuse given for the establishment of a belief that a functional nervous disability constitutes a right to compensation. This is hard saying. It may seem cruel that those whose sufferings are real, whose illness has been brought on by enemy action and very likely in the course of patriotic service, should be treated with such apparent callousness. But there can be no doubt that in an overwhelming proportion of cases, these patients succumb to ‘shock’ because they get something out of it. To give them this reward is not ultimately a benefit to them because it encourages the weaker tendencies in their character. The nation cannot call on its citizens for courage and sacrifice and, at the same time, state by implication that an unconscious cowardice or an unconscious dishonesty will be rewarded.\n\nAt the beginning of World War II, the term \"shell shock\" was banned by the British Army, though the phrase \"postconcussional syndrome\" was used to describe similar traumatic responses.\n\nShell shock has had a profound impact in British culture and the popular memory of World War I. At the time, war writers like the poets Siegfried Sassoon and Wilfred Owen dealt with shell shock in their work. Sassoon and Owen spent time at Craiglockhart War Hospital, which treated shell shock casualties. Author Pat Barker explored the causes and effects of shell shock in her Regeneration Trilogy, basing many of her characters on real historical figures and drawing on the writings of the first world war poets and the army doctor W. H. R. Rivers.\n\n\n\n"}
{"id": "13713794", "url": "https://en.wikipedia.org/wiki?curid=13713794", "title": "Shortgrass prairie", "text": "Shortgrass prairie\n\nThe shortgrass prairie is an ecosystem located in the Great Plains of North America. The prairie includes lands to the west as far as the eastern foothills of the Rocky Mountains and extends east as far as Nebraska and north into Saskatchewan. The prairie stretches through parts of Alberta, Wyoming, Montana, North Dakota, South Dakota, and Kansas, and passes south through the high plains of Colorado, Oklahoma, Texas, and New Mexico.\n\nThe prairie was formerly maintained by grazing pressure of American bison, which is the keystone species. The two most dominant grasses in the shortgrass prairie are blue grama (\"Bouteloua gracilis\") and buffalograss (\"Bouteloua dactyloides\"), the two less dominant grasses in the prairie are greasegrass (\"Tridens flavus\") and sideoats grama (\"Bouteloua curtipendula\"). Due to its semiarid climate, the shortgrass prairie receives on average less precipitation than that of the tall and mixed grass prairies to the east.\n\nThe shortgrass prairie has a long human history. The Kiowa, Comanche, and Arapahoe peoples occupied the land, hunting bison and pronghorn. Seasonally, these tribes would stage hunts in the adjacent mountains such as the Rocky Mountains. To manage the prairie these tribes and their predecessors likely used fire. They would create fuel breaks, a gap in vegetation or other combustible material that acts as a barrier to slow or stop the progress of a brushfire or wildfire. A firebreak may occur naturally in areas without vegetation or other fuel, such as a river, lake or canyon around their settlements. These fuel breaks would also entice large herbivores to patches of fresh new growth.\n\nEuropean explorers, trappers, and fur traders began to settle the shortgrass prairie. They developed an extractive economy that led to the later growth and industrialization of the prairie. In the mid- and late 19th century the railroads expanded transportation channels, helping to increase settlement, predominantly in rural and small towns. While more people began to settle in the prairie, large-scale cattle and sheep ranching increased as well. This later led to the development of gold, silver, and copper mining communities.\n\nIn the 1920s, El Niño played a big role in the success of crop growing in the short grass plains. El Niño caused more precipitation throughout the prairie, promoting plant growth. The success encouraged farmers to buy more efficient farming equipment. With the new equipment, farmers turned up the native land, exposing the soil. By the time the 1930s came around, it was too late to protect the soil with grass. The unprotected soil contributed to the Dust Bowl by being blown around and creating dust storms.\n\nThe Food Security Act of 1985 allowed for lower commodity prices and income supports. This Act also laid the foundation for the dairy herd buyout program. The Act made changes to several other USDA programs.\n\nFarmers enrolled in the program agree to abolish environmentally destroyed land from agricultural production and cattle grazing to improve and regrow healthy grass and habitats in exchange for a yearly rental payment.\n\nToday much of the shortgrass prairie is grazed by domestic livestock, with a human population that still is dependent upon agriculture. However, energy and mining exploration have increased. Over time, there has been a precipitous decline of many species, but inhabitants of the region today are demonstrating that sound land management practices can help sustain the native species, natural communities, and ecosystems.\n\nThe shortgrass prairie is a long thin stretch of territory that starts at the top of the country and makes its way to the bottom. Due to this, the climate varies from North to South, but is essentially the same from East to West. The temperature in the North is significantly colder on average then the temperature in the South. Also, there is more precipitation to the south, and more precipitation to the East. An interesting distinction about the shortgrass prairie compared to the tall and mixed grass prairies is that it has a one to two month summer drought, where the other two do not. This means that it also the driest prairie of the three.(cite ecology book) In addition, this region has various amounts of hailstorms, blizzards, tornadoes, and dust storms.\n\nThere are two significant population trends currently impacting the shortgrass prairie region. Firstly, the population in the region is decreasing, with many of those people moving westward. Additionally, more people are moving to metropolitan areas, and about three quarters of the population in this region live in those metropolitan areas. The human population today is still mainly dependent on agriculture, but fields such as energy exploration and mining have become more popular in the area. Due to the increase in people this has affected the ecosystem of the region and there has been a decrease of amount of species and diversity of those species.\n\nLarge portions of central grasslands of the United States are used for intensive agriculture. The shortgrass prairie has copious amounts for economic potential as it is estimated that only about 50 percent of the shortgrass prairie is still uncultivated. The shortgrass prairie yields for a lot of crop production, and in this specific prairie wheat is the major crop grown. Other major crops grown are maize, soybeans, and cotton.\n\nThe dry grasslands of the shortgrass prairie yield for extensive grazing operations. Typically cow-calf operations with the young animal sold for finishing in feedlots. Stocking rates and the economy in this region highly depend on the amount of precipitation, range conditions, and other environmental factors.\n\nParts of the shortgrass prairie are untouched and pastoral. Many artists and photographers travel to this prairie for inspiration and economic opportunities. Paintings and photographs are often sold at high prices for their aesthetic beauty. The Dust Bowl brought a lot of artistic and photographers to this area in seek of fame and economic opportunities.\n\nThe shortgrass prairie is located on the western side of the Great Plains with the Colorado Rockies to its west and the mixed grass prairie to its east. However, it is pretty much impossible to define exact boundaries of the prairie. This is due to the shifting of plant communities over time and space because of the dynamics of grassland vegetation. So, the prairie extends to the eastern part of the Rocky Mountains to the west, up to Canada to the North, as far as Nebraska to the East, and as far as parts of Texas to the South. Those are just the general boundaries of the shortgrass prairie which is everything inside those said boundaries.\n\nIn Colorado, which contains a substantial portion of the shortgrass prairie biome, no legal ecosystem protection exists. More than 85% of prairie is privately owned and used for agriculture, particularly for dry land wheat, irrigated corn, soybeans and alfalfa. Roughly half of the original prairie extent is still present, however conservation in the long run is uncertain. Urban expansion is likely to continue having an impact. Climate change has less of an effect here than in other areas of Colorado due to the lower elevation, but can still be expected to affect the biome.\n\nThe Prairie Dog Coalition is a non- profit group of scientists, organizations and citizens who are fighting for the protection of prairie dogs and their environments. The alliance educates people on the declining populations of prairie dogs and engages with projects likely to destroy prairie dog habitat.\n\nThe shortgrass prairie was once filled with huge herds of free-ranging bison and pronghorn. The prairie also teemed with large prairie dog colonies, deer and elk, and predators such as gray wolves and grizzly bears. The prairie is home to healthy populations of plains blue grama, a vast array of songbirds and raptors, carpets of buffalo grass and a broad diversity and abundance of wildflowers and butterflies. It was a landscape so teeming with life it has been compared to the South American Pampas. Today the most popular animal on the prairie is domestic cattle. The short grass prairie is used to having animals graze the land, so the pressure of grazing animals does not harm it. Pronghorn and prairie dogs still inhibit the prairie however, in fewer numbers. Top predators have been replaced by coyotes.\n\nEcological processes on a large-scale level such as climate, fire and grazing have strong influences in this system. Today, the shortgrass prairie has suffered the greatest biological destruction of any major biome in North America. The three central processes historically shaping the shortgrass prairie are herbivory, drought, and fire. Through habitat destruction, extermination of native herbivores and predators, proliferation of noxious weeds, and altered fire regimes have negatively been impacted.\n\nThe short grass prairie consists of many kinds of birds, reptiles and mammals. Most of these animals have adapted to living in such an open area, many having adapted to living under ground or traveling long distances to find shelter. \nGrassland birds are part of the fastest decreasing groups of animals in North America. Grassland birds that reside in the short grass prairie add to this decrease by being Colorado’s largest category of declining animals. Some of birds that still inhabit the short grass prairie are the Cassin's sparrow, loggerhead shrike, sandhill crane, scaled quail, Swainson's hawk, burrowing owl, mountain plover and McCown's longspur. Although the loggerhead shrike and scaled quail birds are among the more common birds to see in the short grass prairie, they are also some of the few who are on the fastest decline. \nRound-tailed horned lizard, Texas garter snake, Texas horned lizard, Texas long-nosed snake and Western Massasauga are among the most dominant reptiles in the short grass prairie. Most of these animals are cold blooded, so in the winter months they live under ground until spring comes. \n\nCattle, pronghorn and white-tailed deer are the most abundant mammals on the short grass prairie today. Domestic cattle were placed in the prairie and have essentially replaced the native species that used to live in the short grass prairie such as bison and elk. In addition, the top predators used to be Gray wolf and Grizzly bear, but today, coyotes have replaced those animals. \nPrairie dogs were once the most abundant animals in the short grass prairie, living in colonies across a range that historically spanned 11 states. Presently, prairie dogs are found in 1 percent of their former range. The decrease has been driven by poisoning campaigns, habitat disruption, and hunting. The decline in prairie dogs has significantly impacted many of the other animals that reside in the short grass prairie, including the black-footed ferret, whose diet relies on prairie dogs. Other animals negatively affected by the decline of prairie dogs are the mountain plover, swift fox, ferruginous hawk and the burrowing owl.\n\nThe short grass prairie consists of different varieties of vegetation. Notably abundant grasses are blue grama, sod- forming grass, and buffalo grass. Less prevalent is galleta grass. These grasses are native to the short grass prairie and therefor are drought and grazing resistant. Not many plant varieties appear in short grass prairies owing to its extreme changes in annual precipitation and temperature from one year to the next. Two of the main plants that are able to thrive are soap weed yucca and plains prickly pear cactus. In the years of greater precipitation, otherwise dormant wildflowers bloom in the spring, quickly diminishing in the hotter and drier summer months.\n\n"}
{"id": "54893319", "url": "https://en.wikipedia.org/wiki?curid=54893319", "title": "South Pacific garbage patch", "text": "South Pacific garbage patch\n\nThe South Pacific garbage patch is an area of elevated levels of marine debris and plastic particle pollution, most of which is concentrated within the ocean's pelagic zone. It is located within the South Pacific Gyre, which itself spans from waters east of Australia to the South American continent, as far north as the Equator, and south until reaching the Antarctic Circumpolar Current. The degradation of plastics in the ocean also leads to a rise in the level of toxins in the area. This garbage patch is the most recently discovered having only been confirmed in mid-2017. The South Pacific garbage patch has been compared in nature to the Great Pacific garbage patch's state in 2007, making the former ten years younger. The garbage patch is impossible to detect using satellites, or other visual means as most particles are smaller than a grain of rice.\n\nEvidence pointing to the existence of a garbage patch in the South Pacific gyre was discovered in early 2011 and its existence was confirmed in mid-2017. The discovery was made after a research voyage made by the 5 Gyres Institute, led by Executive Director Dr. Marcus Erikson. This voyage marked the first time the South Pacific gyre had been sampled for plastic pollution. From March to April 2011, following a route based on a model of ocean currents developed by Nikolia Maximenko of the University of Hawaii, which predicts floating debris accumulation zones. The expedition started taking samples off the coast of Robinson Crusoe Island, Chile, and began working its way west, collecting a new sample each 50 nautical miles, reaching the waters off Easter Island, and eventually Pitcairn Island.\n\nA second water sampling voyage departing from Long Beach, California, launching November 2, 2016, and lasting approximately six months, was led by Oceanographer and Captain Charles J. Moore, and a team of volunteer researchers from Algalita Marine Research and Education, an organization which he founded. Upon departure the vessel began its journey south along the Baja California peninsula and on to the Galapagos Islands, continuing southwest on to Easter Island. After departing Easter Island the crew then headed eastward to the Juan Fernandez Islands, after which it continued north following the coast of Chile, with stopping points at Antofagasta, Chile, and Arica, Chile, before heading further out to sea for its return journey to Long Beach.\n\nDuring the 5 Gyres expedition, 48 samples were taken from a 2,424 nautical sweep. The researchers found an increase in plastic pollution density, averaging 26,898 particles per square kilometer, but spiking at up to 396,342 particles per square kilometer, peaking near the center of the predicted accumulation zone, with some estimates as high as one million particles per square kilometer.\n\nThe composition of the garbage patch consists mainly of microbeads, tiny abrasives less than 5 micrometers in size usually found in certain personal hygiene products, microscopic fibers from washing clothes, fishing debris from southern hemisphere fishermen, and microscopic fragments of larger pieces which have been broken down in the ocean.\n\nThe elevated levels of pollutants can be detected over a vast area estimated to be 2.6 million square kilometers (one million square miles), or about 1.5 times the size of Texas, with the debris found along a nearly 2,500 nautical mile straight line route.\n\nAs the plastic particles are primarily found in the pelagic layer of the ocean they experience high levels of Photodegradation, which causes the plastics to break down into ever smaller pieces. These pieces eventually become so small that even microorganisms can ingest and metabolize them converting these plastics into carbon dioxide. In some instances these microplastics absorb directly into a microorganisms' biomolecules. However, before reaching this state any number of organisms could potentially interact with these plastics. During their expedition in 2016-17, Charles Moore and Algalita found that more than 35% of south Pacific Lanternfish had consumed plastic particles. When ingested by the fish the chemical compounds found in these plastics cannot be digested. This can effect Humans as the Lanternfish is a food source for both salmon and tuna. In their PNAS journal, Dr Van Sebille and his colleagues report data showing that in 1960 less than 5% of seabirds were found to have consumed waste material, while as of August 2015 that figure climbed to about 90%. It is predicted that by 2050, 99%of seabirds will have consumed such materials. Scientists studying the stomach contents of Laysan Albatross chicks report a 40% mortality rate before fledgling. When the stomach contents were analyzed following necropsies, they were found to contain plastic waste. Not only do plastic pellets used in manufacturing worldwide absorb toxic chemicals such as DDT and PCBs from the water, but can even leach chemicals such as biphenyl. It is estimated that up to 267 marine species are affected by plastic pollution.\n\nResearchers led by chemist Katsuhiko Saido, a graduate from Nihon University's College of Pharmacy in Japan have collected seawater samples worldwide, including from waters of the United States, Japan, India, and Europe. All samples collected were found to contain polystyrene derivatives. Polystyrene is a plastic found in styrofoam and many household and consumer goods. The scientists then simulated the decomposition of polystyrene in the open ocean. The results of this simulation showed that polystyrene, which begins breaking down at temperatures of 86° and higher. As it does so it breaks down into harmful chemicals, such as Bisphenol A (BPA), which can cause reproductive harm in animals, styrene monomer, a suspected carcinogen, and styrene trimer, a by-product of polystyrene.\n\nOne study shows estimates of 5.25 trillion individual pieces of microplastcs, weighing nearly 267,000 tons are currently floating in our oceans. It has been estimated that since being invented, 8.3 billion tons of plastics has been produced, with 80% (6.64 billion tons) being dumped in landfills, on land, and in the oceans. Plastic particles don't biodegrade or break down and instead just fragment into smaller pieces. If current trends in the amount of plastics flowing into our oceans continues, combined with overfishing, will result in plastics outweighing fish in the oceans by 2050.\n\n"}
{"id": "10039876", "url": "https://en.wikipedia.org/wiki?curid=10039876", "title": "State of the Environment", "text": "State of the Environment\n\nThe term State of the Environment normally relates to an analysis of trends in the environment of a particular place. This analysis can encompass aspects such as water quality, air quality, land use, ecosystem health and function, along with social and cultural matters.\n\nHuman activity places pressure on many aspects of the environment. For instance, deforestation results in the invasion of weed species, habitat displacement, and, when undertaken on a large scale, adversely affects air quality and carbon dioxide sequestration.\n\nExamples of pressures under the Pressure-State-Response (\"PSR\") framework include: pollutants discharged from factories, or draining into a river from the land; it could be the removal of forest from the land or over-harvesting by fishermen or hunters.\n\nIn this framework, only pressures introduced by human interaction with the environment are considered. Natural pressures such as extreme weather are only considered in the context of human-induced climate change (i.e. global warming).\n\nA \"state\" is the condition of the environment at a particular time. This is assessed by measuring various aspects of the atmosphere, air, water, land and organisms.\n\nThe European Environment Agency has extended the pressure-state-response framework to include driving forces and impacts (see DPSIR).\n\nState of Environment reports have been prepared by countries such as New Zealand and Australia. State of the Environment reporting is also undertaken fairly extensively throughout New Zealand by territorial and regional authorities.\n\n\n"}
{"id": "29392", "url": "https://en.wikipedia.org/wiki?curid=29392", "title": "Summer", "text": "Summer\n\nSummer is the hottest of the four temperate seasons, falling after spring and before autumn. At the summer solstice, the days are longest and the nights are shortest, with day-length decreasing as the season progresses after the solstice. The date of the beginning of summer varies according to climate, tradition, and culture. When it is summer in the Northern Hemisphere, it is winter in the Southern Hemisphere, and vice versa.\n\nFrom an astronomical view, the equinoxes and solstices would be the middle of the respective seasons, but sometimes astronomical summer is defined as starting at the solstice, the time of maximal insolation, often identified with the 21st day of June or December. A variable seasonal lag means that the meteorological center of the season, which is based on average temperature patterns, occurs several weeks after the time of maximal insolation. The meteorological convention is to define summer as comprising the months of June, July, and August in the northern hemisphere and the months of December, January, and February in the southern hemisphere. Under meteorological definitions, all seasons are arbitrarily set to start at the beginning of a calendar month and end at the end of a month. This meteorological definition of summer also aligns with the commonly viewed notion of summer as the season with the longest (and warmest) days of the year, in which daylight predominates. The meteorological reckoning of seasons is used in Australia, Austria, Denmark, Russia and Japan. It is also used by many in the United Kingdom. In Ireland, the summer months according to the national meteorological service, Met Éireann, are June, July and August. However, according to the Irish Calendar, summer begins on 1 May and ends on 1 August. School textbooks in Ireland follow the cultural norm of summer commencing on 1 May rather than the meteorological definition of 1 June.\n\nDays continue to lengthen from equinox to solstice and summer days progressively shorten after the solstice, so meteorological summer encompasses the build-up to the longest day and a diminishing thereafter, with summer having many more hours of daylight than spring. Reckoning by hours of daylight alone, summer solstice marks the midpoint, not the beginning, of the seasons. Midsummer takes place over the shortest night of the year, which is the summer solstice, or on a nearby date that varies with tradition.\n\nWhere a seasonal lag of half a season or more is common, reckoning based on astronomical markers is shifted half a season. By this method, in North America, summer is the period from the summer solstice (usually 20 or 21 June in the Northern Hemisphere) to the autumn equinox.\n\nReckoning by cultural festivals, the summer season in the United States is traditionally regarded as beginning on Memorial Day weekend (the last Weekend in May) and ending on Labor Day (the first Monday in September) 1981, more closely in line with the meteorological definition for the parts of the country that have four-season weather. The similar Canadian tradition starts summer on Victoria Day one week prior (although summer conditions vary widely across Canada's expansive territory) and ends, as in the United States, on Labour Day.\n\nIn Chinese astronomy, summer starts on or around 5 May, with the \"jiéqì\" (solar term) known as lìxià (立夏), i.e. \"establishment of summer\", and it ends on or around 6 August.\n\nIn southern and southeast Asia, where the monsoon occurs, summer is more generally defined as lasting from March, April, May and June, the warmest time of the year, ending with the onset of the monsoon rains.\n\nBecause the temperature lag is shorter in the oceanic temperate southern hemisphere, most countries in this region use the meteorological definition with summer starting on 1 December and ending on the last day of February.\n\nSummer is traditionally associated with hot or warm weather. In the Mediterranean regions, it is also associated with dry weather, while in other places (particularly in Eastern Asia because of the Monsoon) it is associated with rainy weather. The wet season is the main period of vegetation growth within the savanna climate regime. Where the wet season is associated with a seasonal shift in the prevailing winds, it is known as a monsoon.\n\nIn the northern Atlantic Ocean, a distinct tropical cyclone season occurs from 1 June to 30 November. The statistical peak of the Atlantic hurricane season is 10 September. The Northeast Pacific Ocean has a broader period of activity, but in a similar time frame to the Atlantic. The Northwest Pacific sees tropical cyclones year-round, with a minimum in February and March and a peak in early September. In the North Indian basin, storms are most common from April to December, with peaks in May and November. In the Southern Hemisphere, the tropical cyclone season runs from 1 November until the end of April with peaks in mid-February to early March.\n\nThunderstorm season in the United States and Canada runs in the spring through summer. These storms can produce hail, strong winds and tornadoes, usually during the afternoon and evening.\n\nSchools and universities typically have a summer break to take advantage of the warmer weather and longer days. In almost all countries, children are out of school during this time of year for summer break, although dates vary. In the United States, public schools usually end in late May in Memorial Day weekend, while colleges finish in early May, although some schools get out on the last or second last Thursday in May. In England and Wales, school ends in mid-July and resumes again in early September; in Scotland, the summer holiday begins in late June and ends in mid- to late-August. Similarly, in Canada the summer holiday starts on the last or second-last Friday in June and ends in late August or on the first Monday of September, with the exception of when that date falls before Labour Day, in which case, ends on the second Monday of the month. In Russia the summer holiday begins at the end of May and ends on August 31. In the Southern Hemisphere, school summer holiday dates include the major holidays of Christmas and New Year's Day. School summer holidays in Australia, New Zealand and South Africa begin in early December and end in early February, with dates varying between states. In South Africa, the new school-year usually starts during the 2nd week of January, thus aligning the academic year with the Calendar year. In India, school ends in late April and resumes in early or mid June. In Cameroon and Nigeria, schools usually finish for summer vacation in mid-July, and resume in the later weeks of September or the first week of October.\n\nA wide range of public holidays fall during summer, including:\n\nPeople generally take advantage of the high temperatures by spending more time outdoors during summer. Activities such as travelling to the beach and picnics occur during the summer months. Sports such as association football, basketball, American football, volleyball, skateboarding, baseball, softball, cricket, tennis and golf are played. Water sports also occur. These include water skiing, wakeboarding, swimming, surfing, tubing and water polo. The modern Olympics have been held during the summer months every four years since 1896. The 2000 Summer Olympics, in Sydney, however, were held during the Australian Spring.\n\nSummer is normally a low point in television viewing, and television schedules generally reflect this by not scheduling new episodes of their most popular shows between the end of May sweeps and the beginning of the television season in September, instead scheduling low-cost reality television shows and burning off commitments to already-cancelled series. There is an exception to this with children's television. Many television shows made for children and are popular with children are released during the summer months, especially on children's cable channels such as the Disney Channel in the United States, as children are off school. Disney Channel, for example, ends its preschool programming earlier in the day for older school age children in the summer months while it reverts to the original scheduling as the new school year begins. Conversely, the music and film industries generally experience higher returns during the summer than other times of the year and market their summer hits accordingly. Summer is most popular for animated movies to be released theatrically in movie theaters.\n\nWith most school-age children and college students (except those attending summer school) on summer vacation during the summer months, especially in the United States, travel and vacationing traditionally peaks during the summer, with the volume of travel in a typical summer weekend rivaled only by Thanksgiving. Teenagers and college students often take summer jobs in industries that cater to recreation. Business activity for the recreation, tourism, restaurant, and retail industries peak during the summer months as well as the holiday season.\n\n"}
{"id": "42400502", "url": "https://en.wikipedia.org/wiki?curid=42400502", "title": "The TerraMar Project", "text": "The TerraMar Project\n\nThe TerraMar Project, based in New York, New York, is an environmentalist non-profit organization involved in protecting the world's oceans.\n\nTerraMar was founded in September 26, 2012 at the Blue Ocean Film Festival and Conservation Conference in Monterey, California, and focuses on the 64% of the ocean that lies outside any single country's jurisdiction. Their mission is to create a \"global ocean community\" based around the idea of shared ownership of the global commons, also known as the high seas or international waters.\n\n\n"}
{"id": "26171620", "url": "https://en.wikipedia.org/wiki?curid=26171620", "title": "Thure E. Cerling", "text": "Thure E. Cerling\n\nThure E. Cerling is a Distinguished Professor of Geology and Geophysics and a Distinguished Professor of Biology at the University of Utah. Cerling is a leading expert in the evolution of modern landscapes including modern mammals and their associated grassland ecologies and stable isotope analyses of the atmosphere. Cerling lives in Salt Lake City, Utah.\n\nCerling's research interests are primarily focused on Earth surface geochemistry processes and on the geological record of ecological change. Particularly, working on conservation biology, Cerling has analyzed the modern animal diet and physiology by using stable isotopes as natural tracers as well as studying dietary changes of different mammalian lineages extending over millions of years.\n\nEmphasizing continental ecologies of lakes and modern soils and ecosystems, Cerling has written extensievely about the evolution of ecosystems, the inception and strengthening of monsoons, and the atmosphere over geological time scales through evidence gathered about the fractionation of stable istopes in these systems.\n\nCurrent research work includes a focus on the development of landforms in semi-arid regions, the geology of Old World paleo-anthropologic sites and on contaminant migration in surface and ground waters, including the use of tritium and helium as hydrological tracers.\n\nThure E. Cerling received his Bachelor of Science degree in geology and chemistry from Iowa State University, in Ames, Iowa, in 1972, and, in 1973, his Master of Science in geology from Iowa State. In 1977 he was awarded a Ph.D. in geology from the University of California at Berkeley. From 1977 to 1979 he worked as a research scientist at Oak Ridge National Laboratory and, from 1979 he has been a member of the University of Utah's faculty.\n\nWith the publication of \"Expansion of C4 ecosystems as an indicator of global ecological change in the late Miocene\" in 1993, Cerling, helped by Yang Wang and Jay Quade, made relevant studies relatively to carbon isotopes. Thanks to a deep analysis of palaeovegetation from palaeosols and palaeodiet measured in fossil tooth enamel, was demonstrated a global increase in the biomass of plants using C4 photosynthesis between 7 and 5 million years ago. The decrease of atmospheric CO2 concentrations over the history below a threshold that favored the C3-photosynthesizing plants was considered as a valid reason for the global expansion of C4 biomass.\nThe publication \"Global vegetation change through the Miocene/Pliocene boundary\" in 1997 confirmed these results, demonstrating even how at lower latitudes the change appeared to occur earlier because of the threshold for C3 photosynthesis is higher at warmer temperatures.\n\nThure Cerling and James Ehleringer, a biology professor at the University of Utah, founded Isoforensics in 2003, a company with the aim of interpreting the stable isotope composition of various biological and synthetic materials. This was the first step for the discovery they made which was first published on February 25, 2008, by the \"Proceedings of the National Academy of Sciences\" with the title \"Hydrogen and oxygen isotope ratios in human hair are related to geography\".\nTo know where people have been and where they lived for a while are information that became available by analyzing the stable isotope composition of their scalp hair. Cerling discovered that a strand of hair could provide valuable clues about a person's travels by studying the variation of hydrogen-2 (δ2H) and oxygen-18 (δ18O) isotopes and comparing them to the ones in the drinking water. The extent of the information that can be deduced depends on the length of the hair: the longer is the hair, the greater is the extraction of information. The variation with geography of isotope concentrations is linked with precipitations, cloud temperatures and with the amount of water that evaporates from soil and plants. When clouds move off the ocean towards inland the ratios of oxygen-18 to oxygen-16 and hydrogen-2 to hydrogen-1 tend to decrease because of the rain water with oxygen-18 and hydrogen-2, being heavier, tends to fall first.\nSamples of tap water were collected from more than 600 cities across the United States as well as hair samples from the barbershops in 65 cities in 20 states. The comparison showed that both hair and drinking water samples had the same isotopic variations. In order to display these information, the scientists produced color-coded maps based on the correlation of the isotopes in hair to those in drinking water. This maps show how ratios of hydrogen and oxygen isotopes in scalp hair vary in different areas of the United States. It was so proved that the water drank by a human being leaves in the hair an evidence which contain oxygen and hydrogen isotopes equal to the ones in the tap water.\nThis technique would have been a new tool for policemen, anthropologists, archaeologists and doctors.\n\nProfessor Cerling, helped by James Ehleringer and Christopher Remien (two University of Utah colleagues), George Wittemyer of Colorado State University and member of \"Save the Elephants\" in Nairobi, and Iain Douglas-Hamilton, who founded the association \"Save the Elephants\", conducted a research around the Samburu and Buffalo Springs national reserves in northern Kenya analyzing carbon and other stable isotopes in elephant tail hair to discover where and what Victoria, Anastasia and Cleopatra, three daughters of a mother elephant named Queen Elizabeth, usually eat over a six-years period (2000–2006). In order to monitor their life, the elephants were equipped with a Global Positioning System that recorded their positions every hour for the whole research period. For getting the sample of tail hair, elephants were immobilized with drug-filled dart guns when necessary. Considering that the hair grows about an inch per month, a single hair contained isotopic information to diet during an 18-month period.\n\nThe analysis of ratios of carbon-13 to carbon-12 along the length of a single elephant hair led Cerling and his crew to understand the elephants' diet. During the wet season, after the grass had grown long enough for elephants to grab with their trunks, their tail hair showed the presence of different form of carbon, indicating a high amount of high-protein grass. On the other hand, during the dry season, the results obtained by the analysis of the hair pointed out how elephants had switched over to shrubs and trees.\n\nFor what concern the Samburu-Buffalo Springs, five weeks after the rainy season had started, the grass became rich in nutrients and the females were most likely to conceive, giving birth 22 months later, just in time for another rainy season to provide nutrients to the grass they would have eaten: the cycle could restart.\nThe research also pointed out how developed is the competition between elephants and cattle: during the typical wet season diet of elephants, the overgrazing by cattle caused the grass to be very short, resulting in a limited access to it for elephants, out-competing them. This situation could have influenced the elephants' ability to bulk up for pregnancy.\n\nAll these analyses pointed out even that there are some elephant families friendlier than others and showed how there are dominant families that settle down in the best places, where there is plenty of food and water.\n\n\n"}
{"id": "1919695", "url": "https://en.wikipedia.org/wiki?curid=1919695", "title": "Timeline of solar cells", "text": "Timeline of solar cells\n\nIn theory, solar energy has been used by humans as early as 7th century B.C. when our ancestors discovered how to light fires using glass as a magnifier.\n\nAnother early use for solar energy is in 1776, when Horace de Saussure, a swiss physicist, invented the first solar oven. The solar oven used sunlight to heat meals and no electricity was required.\n\nLater on, in the 19th century, it is observed that the sunlight striking certain materials generates detectable electric current. This discovery has laid the foundation of solar cells. Solar cells have gone on to be used in many applications. They have historically been used in situations where electrical power from the grid was unavailable.\n\n\n\n\n\n\n\n\n\n"}
{"id": "235175", "url": "https://en.wikipedia.org/wiki?curid=235175", "title": "Trace element", "text": "Trace element\n\nA trace element is a chemical element whose concentration (or other measure of amount) is very low (a \"trace amount\"). The exact definition depends on the field of science:\n\n\n"}
{"id": "174576", "url": "https://en.wikipedia.org/wiki?curid=174576", "title": "Transform fault", "text": "Transform fault\n\nA transform fault or transform boundary is a plate boundary where the motion is predominantly horizontal. It ends abruptly and is connected to another transform, a spreading ridge, or a subduction zone.\n\nMost of these faults are hidden in the deep ocean, where they offset divergent boundaries in short zigzags resulting from seafloor spreading, the best-known (and most destructive) being those on land at the margins of continental tectonic plates. A transform fault is the only type of strike-slip fault that is classified as a plate boundary.\n\nThese faults are also known as conservative plate boundaries, since they neither create nor destroy lithosphere.\n\nGeophysicist and geologist John Tuzo Wilson recognized that the offsets of oceanic ridges by faults do not follow the classical pattern of an offset fence or geological marker in Reid's rebound theory of faulting, from which the sense of slip is derived. The new class of faults, called transform faults, produce slip in the opposite direction from what one would surmise from the standard interpretation of an offset geological feature. Slip along transform faults does not increase the distance between the ridges it separates; the distance remains constant in earthquakes because the ridges are spreading centers. This hypothesis was confirmed in a study of the fault plane solutions that showed the slip on transform faults points in the opposite direction than classical interpretation would suggest.\n\nTransform faults are closely related to transcurrent faults and are commonly confused. Both types of fault are strike-slip or side-to-side in movement; nevertheless, transform faults end at the junction of another plate boundary or fault type, while transcurrent faults die out without a junction. In addition, transform faults have equal deformation across the entire fault line, while transcurrent faults have greater displacement in the middle of the fault zone and less on the margins. Finally, transform faults can form a tectonic plate boundary, while transcurrent faults cannot.\n\nThe effect of a fault is to relieve strain, which can be caused by compression, extension, or lateral stress in the rock layers at the surface or deep in the Earth's subsurface. Transform faults specifically relieve strain by transporting the strain between ridges or subduction zones. They also act as the plane of weakness, which may result in splitting in rift zones.\n\nTransform faults are commonly found linking segments of mid-oceanic ridges or spreading centres. These mid-oceanic ridges are where new seafloor is constantly created through the upwelling of new basaltic magma. With new seafloor being pushed and pulled out, the older seafloor slowly slides away from the mid-oceanic ridges toward the continents. Although separated only by tens of kilometers, this separation between segments of the ridges causes portions of the seafloor to push past each other in opposing directions. This lateral movement of seafloors past each other is where transform faults are currently active. \nTransform faults move differently from a strike-slip fault at the mid-oceanic ridge. Instead of the ridges moving away from each other, as they do in other strike-slip faults, transform-fault ridges remain in the same, fixed locations, and the new ocean seafloor created at the ridges is pushed away from the ridge. Evidence of this motion can be found in paleomagnetic striping on the seafloor.\n\nA paper written by Gerya theorizes that the creation of the transform faults between the ridges of the mid-oceanic ridge is attributed to rotated and stretched sections of the mid-oceanic ridge. This occurs over a long period of time with the spreading center or ridge slowly deforming from a straight line to a curved line. Finally, fracturing along these planes forms transform faults. As this takes place, the fault changes from a normal fault with extensional stress to a strike slip fault with lateral stress. In the study done by Bonatti and Crane, peridotite and gabbro rocks were discovered in the edges of the transform ridges. These rocks are created deep inside the Earth's mantle and then rapidly exhumed to the surface. This evidence helps to prove that new seafloor is being created at the mid-oceanic ridges and further supports the theory of plate tectonics.\n\nActive transform faults are between two tectonic structures or faults. Fracture zones represent the previously active transform-fault lines, which have since passed the active transform zone and are being pushed toward the continents. These elevated ridges on the ocean floor can be traced for hundreds of miles and in some cases even from one continent across an ocean to the other continent.\n\nThe most prominent examples of the mid-oceanic ridge transform zones are in the Atlantic Ocean between South America and Africa. Known as the St. Paul, Romanche, Chain, and Ascension fracture zones, these areas have deep, easily identifiable transform faults and ridges. Other locations include: the East Pacific Ridge located in the South Eastern Pacific Ocean, which meets up with San Andreas Fault to the North.\n\nTransform faults are not limited to oceanic crust and spreading centers; many of them are on continental margins. The best example is the San Andreas Fault on the Pacific coast of the United States. The San Andreas Fault links the East Pacific Rise off the West coast of Mexico (Gulf of California) to the Mendocino Triple Junction (Part of the Juan de Fuca plate) off the coast of the Northwestern United States, making it a ridge-to-transform-style fault. The formation of the San Andreas Fault system occurred fairly recently during the Oligocene Period between 34 million and 24 million years ago. During this period, the Farallon plate, followed by the Pacific plate, collided into the North American plate. The collision led to the subduction of the Farallon plate underneath the North American plate. Once the spreading center separating the Pacific and the Farallon plates was subducted beneath the North American plate, the San Andreas Continental Transform-Fault system was created.\nOther examples include:\n\nIn his work on transform-fault systems, geologist Tuzo Wilson said that transform faults must be connected to other faults or tectonic-plate boundaries on both ends; because of that requirement, transform faults can grow in length, keep a constant length, or decrease in length. These length changes are dependent on which type of fault or tectonic structure connect with the transform fault. Wilson described six types of transform faults:\n\n\"Growing length:\" In situations where a transform fault links a spreading center and the upper block of a subduction zone or where two upper blocks of subduction zones are linked, the transform fault itself will grow in length.\n\n\"Constant length:\" In other cases, transform faults will remain at a constant length. This steadiness can be attributed to many different causes. In the case of ridge-to-ridge transforms, the constancy is caused by the continuous growth by both ridges outward, canceling any change in length. The opposite occurs when a ridge linked to a subducting plate, where all the lithosphere (new sea floor) being created by the ridge is subducted, or swallowed up, by the subduction zone. Finally, when two upper subduction plates are linked there is no change in length. This is due to the plates moving parallel with each other and no new lithosphere is being created to change that length.\n\nDecreasing length faults: In rare cases, transform faults can shrink in length. These occur when two descending subduction plates are linked by a transform fault. In time as the plates are subducted, the transform fault will decrease in length until the transform fault disappears completely, leaving only two subduction zones facing in opposite directions.\n\n\n"}
{"id": "54716184", "url": "https://en.wikipedia.org/wiki?curid=54716184", "title": "United States Energy Association", "text": "United States Energy Association\n\nThe United States Energy Association (USEA) is the U.S. Member Committee of the World Energy Council. Headquartered in Washington, D.C., USEA is an association of public and private energy-related organizations, corporations, and government agencies. \nThe association hosts annual events such as the Carbon Sequestration Leadership Forum, Energy Supply Forum, and State of the Energy Industry Forum.\n\nBarry Worthington has served as USEA’s executive director since 1988. Worthington chairs the Clean Electricity Production working group within the UNECE Committee on Sustainable Energy. He also sits on numerous energy boards, including the National Energy Foundation (chairman) and Energy Law Foundation.\n\nWorthington meets with domestic and international energy leaders to discuss energy infrastructure partnerships. He often advocates for energy cultivation in developing countries, claiming there are \"few priorities greater for the world than getting people linked to the grid.\" Worthington is a firm supporter of energy \"sovereignty.\"\n\nVicky Bailey currently chairs USEA’s board of directors. She succeeded Jack Futcher, the President and COO of Bechtel.\n\nFor 25 years, USEA has been a partner with USAID, expanding energy infrastructure, improving energy access, and reducing energy poverty in developing economies through international energy partnerships. A major function of USEA’s is to help USAID expand energy infrastructure and programs in developing countries. In 2012, the association launched the U.S.-East Africa Geothermal Partnership (EAGP), a public-private partnership “offering assistance at early stages of project development in East Africa.” Through the Djibouti Geothermal Partnership, Ethiopia Geothermal Partnership, and Kenya Electricity Generating Company (KenGen), USEA partners with the Department of Energy and local governments to promote U.S. companies’ involvement in developing additional geothermal generation capacity. According to USEA, the number of U.S. companies conducting geothermal work in East Africa has more than tripled since EAGP’s inception.\n\nUSEA represents the interests of the U.S. energy sector through public education and advocacy. The association supports an “all-of-the-above energy strategy,” from renewable energy to fossil fuels. USEA advocates for the exploration and production of oil and natural gas.\n\n"}
{"id": "24726925", "url": "https://en.wikipedia.org/wiki?curid=24726925", "title": "Vladimir Alganov", "text": "Vladimir Alganov\n\nVladimir Petrovich Alganov (; born 22 October 1952 in Leningrad) is a Russian spy. He was Soviet KGB officer in Warsaw, Poland in the 1980s and Russian SVR officer in the same city in the 1990s.\n\nIn 1996, Poland's Prime Minister Józef Oleksy resigned because of his links to Alganov.\n\nAlganov was deported from Poland in 1997.\n\nIn 2005 Lithuanian authorities said that Alganov had been issued a long-term Lithuanian visa in 2002 and Alganov had met managers of the Ignalina Nuclear Power Plant.\n\nIn 2003, Alganov secretly met Jan Kulczyk in a restaurant in Vienna, Austria. The conversation was recorded by Polish intelligence officers. According to Antoni Macierewicz, a member of the investigative board:\n\nAlso present at the meeting was Aleksander Żagiel, Alganov's Vienna-based business partner.\n"}
{"id": "32390439", "url": "https://en.wikipedia.org/wiki?curid=32390439", "title": "Yozgat Pine Grove National Park", "text": "Yozgat Pine Grove National Park\n\nThe Yozgat Pine Grove National Park (), is a national park consisting of pine trees in Yozgat, Central Anatolia Region of Turkey. It was established on February 5, 1958 as the country's first national park.\n\nThe park, a forest island on hills within wide steppes in the region, covers an area of and its average elevation is above sea level. Yozgat Pine Grove National Park is administered by the Directorate-General of Forestry, a governmental agency of the Ministry of Forestry and Water Affairs. The species of pine trees within the national park are found only in the higher elevations of Caucasus Mountains. According to Ali Şimşek, the director of the park, the trees, between 350 and 500 years old, are under protection. Some of the trees are tagged with their age on them.\n\nThe national park is located south of the city Yozgat. It is a popular recreational area for the residents of the city. The park has various facilities for visitors like a three-star hotel, campsite, restaurant, cafeteria and playground.\n"}
{"id": "57136484", "url": "https://en.wikipedia.org/wiki?curid=57136484", "title": "Zenith Star", "text": "Zenith Star\n\nZenith Star was a Directed-energy weapon that started development as part of the Strategic Defense Initiative.\n\nIt included the Alpha laser, a high energy hydrogen fluoride chemical laser, and the LAMP mirror which was a 7 segment adaptive optics mirror.\n\nZenith Star was never put in orbit, but the Alpha LAMP Integration (ALI) project carried out some ground-based tests.\n\n"}
